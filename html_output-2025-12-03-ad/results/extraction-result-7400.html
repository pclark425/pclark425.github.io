<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-7400 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-7400</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-7400</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-139.html">extraction-schema-139</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models being used to detect anomalies in lists or tabular data, including the methods, datasets, evaluation metrics, and results.</div>
                <p><strong>Paper ID:</strong> paper-270703007</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2406.15781v1.pdf" target="_blank">DABL: Detecting Semantic Anomalies in Business Processes Using Large Language Models</a></p>
                <p><strong>Paper Abstract:</strong> Detecting anomalies in business processes is crucial for ensuring operational success. While many existing methods rely on statistical frequency to detect anomalies, it's important to note that infrequent behavior doesn't necessarily imply undesirability. To address this challenge, detecting anomalies from a semantic viewpoint proves to be a more effective approach. However, current semantic anomaly detection methods treat a trace (i.e., process instance) as multiple event pairs, disrupting long-distance dependencies. In this paper, we introduce DABL, a novel approach for detecting semantic anomalies in business processes using large language models (LLMs). We collect 143,137 real-world process models from various domains. By generating normal traces through the playout of these process models and simulating both ordering and exclusion anomalies, we fine-tune Llama 2 using the resulting log. Through extensive experiments, we demonstrate that DABL surpasses existing state-of-the-art semantic anomaly detection methods in terms of both generalization ability and learning of given processes. Users can directly apply DABL to detect semantic anomalies in their own datasets without the need for additional training. Furthermore, DABL offers the capability to interpret the causes of anomalies in natural language, providing valuable insights into the detected anomalies.</p>
                <p><strong>Cost:</strong> 0.02</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e7400.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e7400.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models being used to detect anomalies in lists or tabular data, including the methods, datasets, evaluation metrics, and results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>DABL</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Detecting semantic AnomaLies in Business processes using LLMs</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A fine-tuned Llama 2-Chat 13B model (QLoRA) trained on playouts of 143,137 real-world BPMN process models and synthetic ordering/exclusion anomalies to detect semantic anomalies in business-process traces and to produce natural-language explanations for the causes.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Llama 2-Chat</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Decoder-only large language model, instruction/chat-tuned variant (chat interface) fine-tuned with QLoRA.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>13B</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_detection_approach</strong></td>
                            <td>Supervised fine-tuning of an LLM on synthetic normal and anomalous traces (fine-tuning + prompt-based classification and explanation).</td>
                        </tr>
                        <tr>
                            <td><strong>prompt_template</strong></td>
                            <td>In the following business process trace, each executed activity is separated by a comma: {trace}. Is this trace normal or anomalous? If anomalous: What's the cause of the anomaly? (e.g., "The activity 'X' is executed too early, it should be executed after 'Y'.")</td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td>Playout-generated normal traces from 143,137 BPMN process models collected from BPMAI, FBPM and SAP-SAM producing 1,574,381 normal traces; synthetic anomalous traces produced by simulating ordering anomalies (skip, insert, rework, early, late) and exclusion anomalies (by turning exclusive nodes into parallel nodes and filtering out traces that are actually normal). Fine-tuning used QA pairs formed from traces with labels and natural-language causes.</td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Categorical sequential traces (lists of activity names; event-log traces).</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td>Synthetic dataset generated from BPMAI, FBPM, SAP-SAM process models; evaluated on two test splits denoted D1 (unseen processes) and D2 (seen processes, unseen anomalies).</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>Precision, Recall, F1-score, Accuracy for anomaly detection; ROUGE-2 and ROUGE-L (precision/recall/F1) for explanation quality.</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>On D1 (generalization to unseen processes): Precision 94.06%, Recall 89.79%, F1 91.88%, Accuracy 92.39%. On D2 (seen processes): Precision 98.12%, Recall 95.64%, F1 96.87%, Accuracy 97.03%. Explanation (cause) performance â€” D1 ROUGE-2 F1 74.32% (P 74.48%, R 74.49%), ROUGE-L F1 76.02% (P 76.29%, R 76.11%); D2 ROUGE-2 F1 84.54% (P 84.92%, R 84.61%), ROUGE-L F1 86.56% (P 86.96%, R 86.66%).</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Compared to SEM, SENSE-SVM, SENSE-BERT on same testbeds. On D1 best baseline (by some metrics) SENSE-SVM: Prec 87.95%, Rec 51.12%, F1 62.20%, Acc 52.50%; SENSE-BERT: Prec 48.17%, Rec 97.74%, F1 64.53%, Acc 48.47%; SEM: Prec 48.67%, Rec 46.84%, F1 47.72%, Acc 50.81%. On D2: SENSE-BERT: Prec 93.16%, Rec 62.88%, F1 75.08%, Acc 80.28%; SENSE-SVM: Prec 90.28%, Rec 28.64%, F1 43.49%, Acc 64.82%; SEM: Prec 71.91%, Rec 48.63%, F1 58.02%, Acc 66.75. DABL outperformed all baselines on F1 and accuracy in both D1 and D2.</td>
                        </tr>
                        <tr>
                            <td><strong>zero_shot_or_few_shot</strong></td>
                            <td>Fine-tuned (supervised). The fine-tuned model demonstrates zero-shot applicability to unseen processes (evaluated on D1) but training itself is supervised.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Authors note ROUGE-based explanation scores may be underestimated because multiple valid natural-language explanations exist but only one reference was used; ambiguity in cause interpretation. Paper reports that off-the-shelf LLMs (GPT-3.5, GPT-4, GLM-3, untuned Llama 2) lack domain knowledge and often fail to give specific answers without fine-tuning. No explicit failure-rate breakdown for DABL beyond comparative metrics.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost</strong></td>
                            <td>Fine-tuning performed for two epochs using Adam optimizer with initial LR 5e-5, polynomial LR decay, batch size 64 on a single NVIDIA A6000 GPU (48 GB). Inference cost/latency not reported.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'DABL: Detecting Semantic Anomalies in Business Processes Using Large Language Models', 'publication_date_yy_mm': '2024-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7400.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e7400.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models being used to detect anomalies in lists or tabular data, including the methods, datasets, evaluation metrics, and results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>SENSE-BERT</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>SENSE (BERT-based variant)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A semantic anomaly detection approach that extends BERT with a classification head to detect anomalous event pairs extracted from traces; traces are classified as anomalous if any event-pair is flagged anomalous.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>BERT (fine-tuned)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Encoder Transformer (BERT) with additional output classification layer for two-class event-pair anomaly detection.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_detection_approach</strong></td>
                            <td>Supervised fine-tuning on event-pair classification (divide trace into event pairs in eventually-follow relation; classify pairs as normal/anomalous).</td>
                        </tr>
                        <tr>
                            <td><strong>prompt_template</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td>Trained on normal event pairs extracted from normal traces and synthetic anomalous event pairs (randomly generated non-normal pairs) as described by Caspary et al.; for D1 the authors used open-source pretrained SENSE models, for D2 trained on D2's normal traces.</td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Event-pair textual pairs extracted from categorical traces (pairwise relations).</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td>Evaluated on the paper's D1 and D2 synthetic testbeds (same trace corpora produced from BPMN models).</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>Precision, Recall, F1-score, Accuracy (trace-level: a trace is anomalous if any event-pair flagged anomalous).</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>D1: Precision 48.17%, Recall 97.74%, F1 64.53%, Accuracy 48.47%. D2: Precision 93.16%, Recall 62.88%, F1 75.08%, Accuracy 80.28%.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Compared to DABL and other semantic methods (SEM, SENSE-SVM); shows very high recall but low precision on D1 (many false positives).</td>
                        </tr>
                        <tr>
                            <td><strong>zero_shot_or_few_shot</strong></td>
                            <td>Supervised (fine-tuned).</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Treats traces as event pairs which disrupts long-distance dependencies; prone to excessive sensitivity (high recall, low precision) in cross-process/generalization settings.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'DABL: Detecting Semantic Anomalies in Business Processes Using Large Language Models', 'publication_date_yy_mm': '2024-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7400.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e7400.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models being used to detect anomalies in lists or tabular data, including the methods, datasets, evaluation metrics, and results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>SENSE-SVM</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>SENSE (SVM-based variant)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>SENSE approach using SVM classification on vector representations of event pairs (GloVe embeddings) to detect anomalous event pairs; a trace is anomalous if any pair is anomalous.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>SVM (with GloVe embeddings)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Traditional SVM classifier trained on vector embeddings of event-pair text (GloVe).</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_detection_approach</strong></td>
                            <td>Supervised classification on event-pair embeddings.</td>
                        </tr>
                        <tr>
                            <td><strong>prompt_template</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td>Normal event pairs from traces with synthetic anomalous pairs; trained per-dataset (used open-source models for D1 and trained for D2).</td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Event-pair textual pairs (categorical).</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td>Paper's D1 and D2 synthetic testbeds.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>Precision, Recall, F1-score, Accuracy.</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>D1: Precision 87.95%, Recall 51.12%, F1 62.20%, Accuracy 52.50%. D2: Precision 90.28%, Recall 28.64%, F1 43.49%, Accuracy 64.82%.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Compared to DABL and other semantic methods (SENSE-BERT, SEM); shows high precision but low recall (misses many anomalies).</td>
                        </tr>
                        <tr>
                            <td><strong>zero_shot_or_few_shot</strong></td>
                            <td>Supervised (trained per dataset).</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Limited sensitivity (low recall), likely misses anomalies due to pairwise framing and classical classifier limitations.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'DABL: Detecting Semantic Anomalies in Business Processes Using Large Language Models', 'publication_date_yy_mm': '2024-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7400.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e7400.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models being used to detect anomalies in lists or tabular data, including the methods, datasets, evaluation metrics, and results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>SEM (van der Aa et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>SEM (semantic execution anomaly detection with knowledge base / BERT parsing)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A semantic anomaly detection pipeline that parses activity names with BERT to extract actions and business objects and applies a knowledge base of assertions (from VerbOcean or abstract process representations) to detect semantic violations.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>BERT (used for activity parsing)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Pretrained BERT used to parse activity labels (extract action and object); knowledge-base rule checking applied on parsed assertions.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_detection_approach</strong></td>
                            <td>Semantic rule checking using parsed activity assertions and a knowledge base; not direct LLM classification of traces.</td>
                        </tr>
                        <tr>
                            <td><strong>prompt_template</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td>Knowledge base built from VerbOcean or abstract process model representations; BERT fine-tuned for parsing activity names as described in the referenced work.</td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Categorical activity labels / event traces represented as parsed action-object pairs.</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td>Evaluated by authors on their datasets; in this paper used as a baseline on D1 and D2.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>Precision, Recall, F1-score, Accuracy.</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>D1: Precision 48.67%, Recall 46.84%, F1 47.72%, Accuracy 50.81%. D2: Precision 71.91%, Recall 48.63%, F1 58.02%, Accuracy 66.75%.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Compared against SENSE variants and DABL; SEM shows moderate precision but lower recall, and dependence on quality of knowledge extraction.</td>
                        </tr>
                        <tr>
                            <td><strong>zero_shot_or_few_shot</strong></td>
                            <td>Supervised for parsing and KB construction; rule-based checking during inference.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Performance depends heavily on the quality and coverage of the knowledge base and parsing; may not capture long-distance dependencies across a whole trace.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'DABL: Detecting Semantic Anomalies in Business Processes Using Large Language Models', 'publication_date_yy_mm': '2024-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7400.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e7400.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models being used to detect anomalies in lists or tabular data, including the methods, datasets, evaluation metrics, and results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GPT-3.5</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>GPT-3.5 (OpenAI)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A large instruction-following LLM from OpenAI used in the paper for qualitative comparison on trace-level anomaly detection and explanation in zero-shot settings; authors report it struggled to provide specific answers without domain context.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-3.5</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Transformer-based instruction-following LLM (chat-capable); accessed in zero-shot prompting mode for qualitative examples.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_detection_approach</strong></td>
                            <td>Zero-shot prompting (no fine-tuning); asked whether traces are normal/anomalous and to explain causes.</td>
                        </tr>
                        <tr>
                            <td><strong>prompt_template</strong></td>
                            <td>Same Q/A style prompt used for DABL: "In the following business process trace... Is this trace normal or anomalous?"</td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Categorical sequential traces (activity lists).</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td>Qualitative examples from the paper (no formal testbed numbers reported).</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>Qualitatively reported as often non-definitive; lacked domain-specific answers and sometimes answered 'difficult to determine' or gave generic plausible-normal responses.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Compared qualitatively to GPT-4, GLM-3, untuned Llama 2 and DABL; DABL outperformed these off-the-shelf models in specificity and correctness for semantic anomalies.</td>
                        </tr>
                        <tr>
                            <td><strong>zero_shot_or_few_shot</strong></td>
                            <td>Zero-shot (no examples provided).</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Reported lack of prior domain knowledge for business processes leading to vague or non-specific outputs; inability to reliably detect semantic anomalies without fine-tuning.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'DABL: Detecting Semantic Anomalies in Business Processes Using Large Language Models', 'publication_date_yy_mm': '2024-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7400.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e7400.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models being used to detect anomalies in lists or tabular data, including the methods, datasets, evaluation metrics, and results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GPT-4</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>GPT-4 (OpenAI)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A state-of-the-art OpenAI LLM used by authors for qualitative comparison on anomaly detection in process traces; similarly observed to be limited in specificity without domain fine-tuning.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-4</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Large multimodal-capable transformer-based LLM (chat/instruction tuned); used in zero-shot elicitation experiments in the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_detection_approach</strong></td>
                            <td>Zero-shot prompting with the same trace QA prompts.</td>
                        </tr>
                        <tr>
                            <td><strong>prompt_template</strong></td>
                            <td>Same trace-level Q/A prompt as used for DABL evaluation.</td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Categorical sequential traces.</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td>Qualitative examples only.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>Qualitative: produced plausible but often non-definitive answers; authors emphasize it lacked process-specific knowledge compared to DABL.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Compared to GPT-3.5, GLM-3, Llama 2 (untuned) and DABL; DABL gave more specific anomaly identifications/explanations.</td>
                        </tr>
                        <tr>
                            <td><strong>zero_shot_or_few_shot</strong></td>
                            <td>Zero-shot in paper's comparisons.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Same as GPT-3.5: limited domain-specific correctness without fine-tuning.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'DABL: Detecting Semantic Anomalies in Business Processes Using Large Language Models', 'publication_date_yy_mm': '2024-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7400.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e7400.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models being used to detect anomalies in lists or tabular data, including the methods, datasets, evaluation metrics, and results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GLM-3</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>GLM-3</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A large bilingual pre-trained model referenced and used qualitatively in comparisons; reported to be inadequate for specific semantic anomaly detection without domain adaptation.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GLM-3</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Large pre-trained multilingual/bilingual transformer-style model (referenced as a contemporary LLM).</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_detection_approach</strong></td>
                            <td>Zero-shot prompting for qualitative trace examples.</td>
                        </tr>
                        <tr>
                            <td><strong>prompt_template</strong></td>
                            <td>Same trace Q/A prompt.</td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Categorical traces.</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td>Qualitative examples only in paper.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>Qualitatively reported as not offering definitive anomaly judgments without further domain knowledge/fine-tuning.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Compared qualitatively to GPT-3.5, GPT-4, Llama 2, and DABL; DABL outperformed in specificity.</td>
                        </tr>
                        <tr>
                            <td><strong>zero_shot_or_few_shot</strong></td>
                            <td>Zero-shot.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Lacked process-specific knowledge; produced generic responses.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'DABL: Detecting Semantic Anomalies in Business Processes Using Large Language Models', 'publication_date_yy_mm': '2024-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7400.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e7400.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models being used to detect anomalies in lists or tabular data, including the methods, datasets, evaluation metrics, and results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Llama 2 (untuned)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Llama 2 (open-source LLM)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>The base Llama 2 family is referenced and used qualitatively; the paper fine-tunes the Llama 2-Chat 13B variant to produce DABL but also compares untuned Llama 2 outputs qualitatively.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Llama 2 (base/chat variants)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Decoder-only open-source LLM family; paper uses the chat variant for fine-tuning (13B) and references untuned Llama 2 qualitatively.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>13B (the chat variant fine-tuned for DABL); untuned sizes not explicitly enumerated for qualitative comparisons.</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_detection_approach</strong></td>
                            <td>Zero-shot prompting when untuned; supervised fine-tuning when used as DABL (see DABL entry).</td>
                        </tr>
                        <tr>
                            <td><strong>prompt_template</strong></td>
                            <td>Same QA prompt template for traces.</td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Categorical traces.</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td>Qualitative examples; DABL used Llama 2-Chat 13B as base for fine-tuning.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>Untuned outputs were less decisive and specific than DABL; no quantitative metrics reported for untuned model.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Untuned Llama 2 compared unfavorably to fine-tuned DABL.</td>
                        </tr>
                        <tr>
                            <td><strong>zero_shot_or_few_shot</strong></td>
                            <td>Zero-shot for untuned evaluations; DABL is fine-tuned.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Without fine-tuning, insufficient domain knowledge for reliable semantic anomaly detection in traces.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'DABL: Detecting Semantic Anomalies in Business Processes Using Large Language Models', 'publication_date_yy_mm': '2024-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7400.8">
                <h3 class="extraction-instance">Extracted Data Instance 8 (e7400.8)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models being used to detect anomalies in lists or tabular data, including the methods, datasets, evaluation metrics, and results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>AnomalyGPT</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>AnomalyGPT: Detecting industrial anomalies using large vision-language models</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Mentioned in related work as an example combining image encoders with LLMs for industrial anomaly detection (vision + LLM pipeline); cited as related LLM-based anomaly work, not evaluated in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>AnomalyGPT: Detecting industrial anomalies using large vision-language models</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_detection_approach</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>prompt_template</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>zero_shot_or_few_shot</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'DABL: Detecting Semantic Anomalies in Business Processes Using Large Language Models', 'publication_date_yy_mm': '2024-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7400.9">
                <h3 class="extraction-instance">Extracted Data Instance 9 (e7400.9)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models being used to detect anomalies in lists or tabular data, including the methods, datasets, evaluation metrics, and results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Myriad</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Myriad (large multimodal model with vision experts for IAD)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Mentioned in related work as a multimodal approach applying vision experts with large models for industrial anomaly detection; only cited, not used or evaluated in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Myriad: Large multimodal model by applying vision experts for industrial anomaly detection</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_detection_approach</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>prompt_template</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>zero_shot_or_few_shot</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'DABL: Detecting Semantic Anomalies in Business Processes Using Large Language Models', 'publication_date_yy_mm': '2024-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7400.10">
                <h3 class="extraction-instance">Extracted Data Instance 10 (e7400.10)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models being used to detect anomalies in lists or tabular data, including the methods, datasets, evaluation metrics, and results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LogGPT</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>LogGPT: Exploring ChatGPT for log-based anomaly detection</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Referenced as a study investigating use of ChatGPT for log-based anomaly detection (system logs); cited as related work, not used in this paper's experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>LogGPT: Exploring chatgpt for log-based anomaly detection</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>ChatGPT/GPT family (as studied by referenced work)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_detection_approach</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>prompt_template</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>System logs (time-ordered textual logs) â€” in referenced work, not in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>zero_shot_or_few_shot</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'DABL: Detecting Semantic Anomalies in Business Processes Using Large Language Models', 'publication_date_yy_mm': '2024-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7400.11">
                <h3 class="extraction-instance">Extracted Data Instance 11 (e7400.11)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models being used to detect anomalies in lists or tabular data, including the methods, datasets, evaluation metrics, and results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LLMAD / related LLM AD works</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Other LLM-based anomaly detection studies (LLMAD, LLMAD, etc.)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>The paper cites a small set of recent works that apply LLMs to different anomaly detection modalities (time series, system logs, images+LLMs); these are mentioned as context but not evaluated.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_detection_approach</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>prompt_template</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>zero_shot_or_few_shot</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'DABL: Detecting Semantic Anomalies in Business Processes Using Large Language Models', 'publication_date_yy_mm': '2024-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Semantic anomaly detection with large language models <em>(Rating: 2)</em></li>
                <li>AnomalyGPT: Detecting industrial anomalies using large vision-language models <em>(Rating: 2)</em></li>
                <li>Myriad: Large multimodal model by applying vision experts for industrial anomaly detection <em>(Rating: 2)</em></li>
                <li>LogGPT: Exploring chatgpt for log-based anomaly detection <em>(Rating: 2)</em></li>
                <li>Large Language Models can Deliver Accurate and Interpretable Time Series Anomaly Detection <em>(Rating: 2)</em></li>
                <li>Does this make sense? machine learning-based detection of semantic anomalies in business processes <em>(Rating: 2)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-7400",
    "paper_id": "paper-270703007",
    "extraction_schema_id": "extraction-schema-139",
    "extracted_data": [
        {
            "name_short": "DABL",
            "name_full": "Detecting semantic AnomaLies in Business processes using LLMs",
            "brief_description": "A fine-tuned Llama 2-Chat 13B model (QLoRA) trained on playouts of 143,137 real-world BPMN process models and synthetic ordering/exclusion anomalies to detect semantic anomalies in business-process traces and to produce natural-language explanations for the causes.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "Llama 2-Chat",
            "model_description": "Decoder-only large language model, instruction/chat-tuned variant (chat interface) fine-tuned with QLoRA.",
            "model_size": "13B",
            "anomaly_detection_approach": "Supervised fine-tuning of an LLM on synthetic normal and anomalous traces (fine-tuning + prompt-based classification and explanation).",
            "prompt_template": "In the following business process trace, each executed activity is separated by a comma: {trace}. Is this trace normal or anomalous? If anomalous: What's the cause of the anomaly? (e.g., \"The activity 'X' is executed too early, it should be executed after 'Y'.\")",
            "training_data": "Playout-generated normal traces from 143,137 BPMN process models collected from BPMAI, FBPM and SAP-SAM producing 1,574,381 normal traces; synthetic anomalous traces produced by simulating ordering anomalies (skip, insert, rework, early, late) and exclusion anomalies (by turning exclusive nodes into parallel nodes and filtering out traces that are actually normal). Fine-tuning used QA pairs formed from traces with labels and natural-language causes.",
            "data_type": "Categorical sequential traces (lists of activity names; event-log traces).",
            "dataset_name": "Synthetic dataset generated from BPMAI, FBPM, SAP-SAM process models; evaluated on two test splits denoted D1 (unseen processes) and D2 (seen processes, unseen anomalies).",
            "evaluation_metric": "Precision, Recall, F1-score, Accuracy for anomaly detection; ROUGE-2 and ROUGE-L (precision/recall/F1) for explanation quality.",
            "performance": "On D1 (generalization to unseen processes): Precision 94.06%, Recall 89.79%, F1 91.88%, Accuracy 92.39%. On D2 (seen processes): Precision 98.12%, Recall 95.64%, F1 96.87%, Accuracy 97.03%. Explanation (cause) performance â€” D1 ROUGE-2 F1 74.32% (P 74.48%, R 74.49%), ROUGE-L F1 76.02% (P 76.29%, R 76.11%); D2 ROUGE-2 F1 84.54% (P 84.92%, R 84.61%), ROUGE-L F1 86.56% (P 86.96%, R 86.66%).",
            "baseline_comparison": "Compared to SEM, SENSE-SVM, SENSE-BERT on same testbeds. On D1 best baseline (by some metrics) SENSE-SVM: Prec 87.95%, Rec 51.12%, F1 62.20%, Acc 52.50%; SENSE-BERT: Prec 48.17%, Rec 97.74%, F1 64.53%, Acc 48.47%; SEM: Prec 48.67%, Rec 46.84%, F1 47.72%, Acc 50.81%. On D2: SENSE-BERT: Prec 93.16%, Rec 62.88%, F1 75.08%, Acc 80.28%; SENSE-SVM: Prec 90.28%, Rec 28.64%, F1 43.49%, Acc 64.82%; SEM: Prec 71.91%, Rec 48.63%, F1 58.02%, Acc 66.75. DABL outperformed all baselines on F1 and accuracy in both D1 and D2.",
            "zero_shot_or_few_shot": "Fine-tuned (supervised). The fine-tuned model demonstrates zero-shot applicability to unseen processes (evaluated on D1) but training itself is supervised.",
            "limitations_or_failure_cases": "Authors note ROUGE-based explanation scores may be underestimated because multiple valid natural-language explanations exist but only one reference was used; ambiguity in cause interpretation. Paper reports that off-the-shelf LLMs (GPT-3.5, GPT-4, GLM-3, untuned Llama 2) lack domain knowledge and often fail to give specific answers without fine-tuning. No explicit failure-rate breakdown for DABL beyond comparative metrics.",
            "computational_cost": "Fine-tuning performed for two epochs using Adam optimizer with initial LR 5e-5, polynomial LR decay, batch size 64 on a single NVIDIA A6000 GPU (48 GB). Inference cost/latency not reported.",
            "uuid": "e7400.0",
            "source_info": {
                "paper_title": "DABL: Detecting Semantic Anomalies in Business Processes Using Large Language Models",
                "publication_date_yy_mm": "2024-06"
            }
        },
        {
            "name_short": "SENSE-BERT",
            "name_full": "SENSE (BERT-based variant)",
            "brief_description": "A semantic anomaly detection approach that extends BERT with a classification head to detect anomalous event pairs extracted from traces; traces are classified as anomalous if any event-pair is flagged anomalous.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "BERT (fine-tuned)",
            "model_description": "Encoder Transformer (BERT) with additional output classification layer for two-class event-pair anomaly detection.",
            "model_size": null,
            "anomaly_detection_approach": "Supervised fine-tuning on event-pair classification (divide trace into event pairs in eventually-follow relation; classify pairs as normal/anomalous).",
            "prompt_template": null,
            "training_data": "Trained on normal event pairs extracted from normal traces and synthetic anomalous event pairs (randomly generated non-normal pairs) as described by Caspary et al.; for D1 the authors used open-source pretrained SENSE models, for D2 trained on D2's normal traces.",
            "data_type": "Event-pair textual pairs extracted from categorical traces (pairwise relations).",
            "dataset_name": "Evaluated on the paper's D1 and D2 synthetic testbeds (same trace corpora produced from BPMN models).",
            "evaluation_metric": "Precision, Recall, F1-score, Accuracy (trace-level: a trace is anomalous if any event-pair flagged anomalous).",
            "performance": "D1: Precision 48.17%, Recall 97.74%, F1 64.53%, Accuracy 48.47%. D2: Precision 93.16%, Recall 62.88%, F1 75.08%, Accuracy 80.28%.",
            "baseline_comparison": "Compared to DABL and other semantic methods (SEM, SENSE-SVM); shows very high recall but low precision on D1 (many false positives).",
            "zero_shot_or_few_shot": "Supervised (fine-tuned).",
            "limitations_or_failure_cases": "Treats traces as event pairs which disrupts long-distance dependencies; prone to excessive sensitivity (high recall, low precision) in cross-process/generalization settings.",
            "computational_cost": null,
            "uuid": "e7400.1",
            "source_info": {
                "paper_title": "DABL: Detecting Semantic Anomalies in Business Processes Using Large Language Models",
                "publication_date_yy_mm": "2024-06"
            }
        },
        {
            "name_short": "SENSE-SVM",
            "name_full": "SENSE (SVM-based variant)",
            "brief_description": "SENSE approach using SVM classification on vector representations of event pairs (GloVe embeddings) to detect anomalous event pairs; a trace is anomalous if any pair is anomalous.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "SVM (with GloVe embeddings)",
            "model_description": "Traditional SVM classifier trained on vector embeddings of event-pair text (GloVe).",
            "model_size": null,
            "anomaly_detection_approach": "Supervised classification on event-pair embeddings.",
            "prompt_template": null,
            "training_data": "Normal event pairs from traces with synthetic anomalous pairs; trained per-dataset (used open-source models for D1 and trained for D2).",
            "data_type": "Event-pair textual pairs (categorical).",
            "dataset_name": "Paper's D1 and D2 synthetic testbeds.",
            "evaluation_metric": "Precision, Recall, F1-score, Accuracy.",
            "performance": "D1: Precision 87.95%, Recall 51.12%, F1 62.20%, Accuracy 52.50%. D2: Precision 90.28%, Recall 28.64%, F1 43.49%, Accuracy 64.82%.",
            "baseline_comparison": "Compared to DABL and other semantic methods (SENSE-BERT, SEM); shows high precision but low recall (misses many anomalies).",
            "zero_shot_or_few_shot": "Supervised (trained per dataset).",
            "limitations_or_failure_cases": "Limited sensitivity (low recall), likely misses anomalies due to pairwise framing and classical classifier limitations.",
            "computational_cost": null,
            "uuid": "e7400.2",
            "source_info": {
                "paper_title": "DABL: Detecting Semantic Anomalies in Business Processes Using Large Language Models",
                "publication_date_yy_mm": "2024-06"
            }
        },
        {
            "name_short": "SEM (van der Aa et al.)",
            "name_full": "SEM (semantic execution anomaly detection with knowledge base / BERT parsing)",
            "brief_description": "A semantic anomaly detection pipeline that parses activity names with BERT to extract actions and business objects and applies a knowledge base of assertions (from VerbOcean or abstract process representations) to detect semantic violations.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "BERT (used for activity parsing)",
            "model_description": "Pretrained BERT used to parse activity labels (extract action and object); knowledge-base rule checking applied on parsed assertions.",
            "model_size": null,
            "anomaly_detection_approach": "Semantic rule checking using parsed activity assertions and a knowledge base; not direct LLM classification of traces.",
            "prompt_template": null,
            "training_data": "Knowledge base built from VerbOcean or abstract process model representations; BERT fine-tuned for parsing activity names as described in the referenced work.",
            "data_type": "Categorical activity labels / event traces represented as parsed action-object pairs.",
            "dataset_name": "Evaluated by authors on their datasets; in this paper used as a baseline on D1 and D2.",
            "evaluation_metric": "Precision, Recall, F1-score, Accuracy.",
            "performance": "D1: Precision 48.67%, Recall 46.84%, F1 47.72%, Accuracy 50.81%. D2: Precision 71.91%, Recall 48.63%, F1 58.02%, Accuracy 66.75%.",
            "baseline_comparison": "Compared against SENSE variants and DABL; SEM shows moderate precision but lower recall, and dependence on quality of knowledge extraction.",
            "zero_shot_or_few_shot": "Supervised for parsing and KB construction; rule-based checking during inference.",
            "limitations_or_failure_cases": "Performance depends heavily on the quality and coverage of the knowledge base and parsing; may not capture long-distance dependencies across a whole trace.",
            "computational_cost": null,
            "uuid": "e7400.3",
            "source_info": {
                "paper_title": "DABL: Detecting Semantic Anomalies in Business Processes Using Large Language Models",
                "publication_date_yy_mm": "2024-06"
            }
        },
        {
            "name_short": "GPT-3.5",
            "name_full": "GPT-3.5 (OpenAI)",
            "brief_description": "A large instruction-following LLM from OpenAI used in the paper for qualitative comparison on trace-level anomaly detection and explanation in zero-shot settings; authors report it struggled to provide specific answers without domain context.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "GPT-3.5",
            "model_description": "Transformer-based instruction-following LLM (chat-capable); accessed in zero-shot prompting mode for qualitative examples.",
            "model_size": null,
            "anomaly_detection_approach": "Zero-shot prompting (no fine-tuning); asked whether traces are normal/anomalous and to explain causes.",
            "prompt_template": "Same Q/A style prompt used for DABL: \"In the following business process trace... Is this trace normal or anomalous?\"",
            "training_data": null,
            "data_type": "Categorical sequential traces (activity lists).",
            "dataset_name": "Qualitative examples from the paper (no formal testbed numbers reported).",
            "evaluation_metric": null,
            "performance": "Qualitatively reported as often non-definitive; lacked domain-specific answers and sometimes answered 'difficult to determine' or gave generic plausible-normal responses.",
            "baseline_comparison": "Compared qualitatively to GPT-4, GLM-3, untuned Llama 2 and DABL; DABL outperformed these off-the-shelf models in specificity and correctness for semantic anomalies.",
            "zero_shot_or_few_shot": "Zero-shot (no examples provided).",
            "limitations_or_failure_cases": "Reported lack of prior domain knowledge for business processes leading to vague or non-specific outputs; inability to reliably detect semantic anomalies without fine-tuning.",
            "computational_cost": null,
            "uuid": "e7400.4",
            "source_info": {
                "paper_title": "DABL: Detecting Semantic Anomalies in Business Processes Using Large Language Models",
                "publication_date_yy_mm": "2024-06"
            }
        },
        {
            "name_short": "GPT-4",
            "name_full": "GPT-4 (OpenAI)",
            "brief_description": "A state-of-the-art OpenAI LLM used by authors for qualitative comparison on anomaly detection in process traces; similarly observed to be limited in specificity without domain fine-tuning.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "GPT-4",
            "model_description": "Large multimodal-capable transformer-based LLM (chat/instruction tuned); used in zero-shot elicitation experiments in the paper.",
            "model_size": null,
            "anomaly_detection_approach": "Zero-shot prompting with the same trace QA prompts.",
            "prompt_template": "Same trace-level Q/A prompt as used for DABL evaluation.",
            "training_data": null,
            "data_type": "Categorical sequential traces.",
            "dataset_name": "Qualitative examples only.",
            "evaluation_metric": null,
            "performance": "Qualitative: produced plausible but often non-definitive answers; authors emphasize it lacked process-specific knowledge compared to DABL.",
            "baseline_comparison": "Compared to GPT-3.5, GLM-3, Llama 2 (untuned) and DABL; DABL gave more specific anomaly identifications/explanations.",
            "zero_shot_or_few_shot": "Zero-shot in paper's comparisons.",
            "limitations_or_failure_cases": "Same as GPT-3.5: limited domain-specific correctness without fine-tuning.",
            "computational_cost": null,
            "uuid": "e7400.5",
            "source_info": {
                "paper_title": "DABL: Detecting Semantic Anomalies in Business Processes Using Large Language Models",
                "publication_date_yy_mm": "2024-06"
            }
        },
        {
            "name_short": "GLM-3",
            "name_full": "GLM-3",
            "brief_description": "A large bilingual pre-trained model referenced and used qualitatively in comparisons; reported to be inadequate for specific semantic anomaly detection without domain adaptation.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "GLM-3",
            "model_description": "Large pre-trained multilingual/bilingual transformer-style model (referenced as a contemporary LLM).",
            "model_size": null,
            "anomaly_detection_approach": "Zero-shot prompting for qualitative trace examples.",
            "prompt_template": "Same trace Q/A prompt.",
            "training_data": null,
            "data_type": "Categorical traces.",
            "dataset_name": "Qualitative examples only in paper.",
            "evaluation_metric": null,
            "performance": "Qualitatively reported as not offering definitive anomaly judgments without further domain knowledge/fine-tuning.",
            "baseline_comparison": "Compared qualitatively to GPT-3.5, GPT-4, Llama 2, and DABL; DABL outperformed in specificity.",
            "zero_shot_or_few_shot": "Zero-shot.",
            "limitations_or_failure_cases": "Lacked process-specific knowledge; produced generic responses.",
            "computational_cost": null,
            "uuid": "e7400.6",
            "source_info": {
                "paper_title": "DABL: Detecting Semantic Anomalies in Business Processes Using Large Language Models",
                "publication_date_yy_mm": "2024-06"
            }
        },
        {
            "name_short": "Llama 2 (untuned)",
            "name_full": "Llama 2 (open-source LLM)",
            "brief_description": "The base Llama 2 family is referenced and used qualitatively; the paper fine-tunes the Llama 2-Chat 13B variant to produce DABL but also compares untuned Llama 2 outputs qualitatively.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "Llama 2 (base/chat variants)",
            "model_description": "Decoder-only open-source LLM family; paper uses the chat variant for fine-tuning (13B) and references untuned Llama 2 qualitatively.",
            "model_size": "13B (the chat variant fine-tuned for DABL); untuned sizes not explicitly enumerated for qualitative comparisons.",
            "anomaly_detection_approach": "Zero-shot prompting when untuned; supervised fine-tuning when used as DABL (see DABL entry).",
            "prompt_template": "Same QA prompt template for traces.",
            "training_data": null,
            "data_type": "Categorical traces.",
            "dataset_name": "Qualitative examples; DABL used Llama 2-Chat 13B as base for fine-tuning.",
            "evaluation_metric": null,
            "performance": "Untuned outputs were less decisive and specific than DABL; no quantitative metrics reported for untuned model.",
            "baseline_comparison": "Untuned Llama 2 compared unfavorably to fine-tuned DABL.",
            "zero_shot_or_few_shot": "Zero-shot for untuned evaluations; DABL is fine-tuned.",
            "limitations_or_failure_cases": "Without fine-tuning, insufficient domain knowledge for reliable semantic anomaly detection in traces.",
            "computational_cost": null,
            "uuid": "e7400.7",
            "source_info": {
                "paper_title": "DABL: Detecting Semantic Anomalies in Business Processes Using Large Language Models",
                "publication_date_yy_mm": "2024-06"
            }
        },
        {
            "name_short": "AnomalyGPT",
            "name_full": "AnomalyGPT: Detecting industrial anomalies using large vision-language models",
            "brief_description": "Mentioned in related work as an example combining image encoders with LLMs for industrial anomaly detection (vision + LLM pipeline); cited as related LLM-based anomaly work, not evaluated in this paper.",
            "citation_title": "AnomalyGPT: Detecting industrial anomalies using large vision-language models",
            "mention_or_use": "mention",
            "model_name": null,
            "model_description": null,
            "model_size": null,
            "anomaly_detection_approach": null,
            "prompt_template": null,
            "training_data": null,
            "data_type": null,
            "dataset_name": null,
            "evaluation_metric": null,
            "performance": null,
            "baseline_comparison": null,
            "zero_shot_or_few_shot": null,
            "limitations_or_failure_cases": null,
            "computational_cost": null,
            "uuid": "e7400.8",
            "source_info": {
                "paper_title": "DABL: Detecting Semantic Anomalies in Business Processes Using Large Language Models",
                "publication_date_yy_mm": "2024-06"
            }
        },
        {
            "name_short": "Myriad",
            "name_full": "Myriad (large multimodal model with vision experts for IAD)",
            "brief_description": "Mentioned in related work as a multimodal approach applying vision experts with large models for industrial anomaly detection; only cited, not used or evaluated in this paper.",
            "citation_title": "Myriad: Large multimodal model by applying vision experts for industrial anomaly detection",
            "mention_or_use": "mention",
            "model_name": null,
            "model_description": null,
            "model_size": null,
            "anomaly_detection_approach": null,
            "prompt_template": null,
            "training_data": null,
            "data_type": null,
            "dataset_name": null,
            "evaluation_metric": null,
            "performance": null,
            "baseline_comparison": null,
            "zero_shot_or_few_shot": null,
            "limitations_or_failure_cases": null,
            "computational_cost": null,
            "uuid": "e7400.9",
            "source_info": {
                "paper_title": "DABL: Detecting Semantic Anomalies in Business Processes Using Large Language Models",
                "publication_date_yy_mm": "2024-06"
            }
        },
        {
            "name_short": "LogGPT",
            "name_full": "LogGPT: Exploring ChatGPT for log-based anomaly detection",
            "brief_description": "Referenced as a study investigating use of ChatGPT for log-based anomaly detection (system logs); cited as related work, not used in this paper's experiments.",
            "citation_title": "LogGPT: Exploring chatgpt for log-based anomaly detection",
            "mention_or_use": "mention",
            "model_name": "ChatGPT/GPT family (as studied by referenced work)",
            "model_description": null,
            "model_size": null,
            "anomaly_detection_approach": null,
            "prompt_template": null,
            "training_data": null,
            "data_type": "System logs (time-ordered textual logs) â€” in referenced work, not in this paper.",
            "dataset_name": null,
            "evaluation_metric": null,
            "performance": null,
            "baseline_comparison": null,
            "zero_shot_or_few_shot": null,
            "limitations_or_failure_cases": null,
            "computational_cost": null,
            "uuid": "e7400.10",
            "source_info": {
                "paper_title": "DABL: Detecting Semantic Anomalies in Business Processes Using Large Language Models",
                "publication_date_yy_mm": "2024-06"
            }
        },
        {
            "name_short": "LLMAD / related LLM AD works",
            "name_full": "Other LLM-based anomaly detection studies (LLMAD, LLMAD, etc.)",
            "brief_description": "The paper cites a small set of recent works that apply LLMs to different anomaly detection modalities (time series, system logs, images+LLMs); these are mentioned as context but not evaluated.",
            "citation_title": "",
            "mention_or_use": "mention",
            "model_name": null,
            "model_description": null,
            "model_size": null,
            "anomaly_detection_approach": null,
            "prompt_template": null,
            "training_data": null,
            "data_type": null,
            "dataset_name": null,
            "evaluation_metric": null,
            "performance": null,
            "baseline_comparison": null,
            "zero_shot_or_few_shot": null,
            "limitations_or_failure_cases": null,
            "computational_cost": null,
            "uuid": "e7400.11",
            "source_info": {
                "paper_title": "DABL: Detecting Semantic Anomalies in Business Processes Using Large Language Models",
                "publication_date_yy_mm": "2024-06"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Semantic anomaly detection with large language models",
            "rating": 2,
            "sanitized_title": "semantic_anomaly_detection_with_large_language_models"
        },
        {
            "paper_title": "AnomalyGPT: Detecting industrial anomalies using large vision-language models",
            "rating": 2,
            "sanitized_title": "anomalygpt_detecting_industrial_anomalies_using_large_visionlanguage_models"
        },
        {
            "paper_title": "Myriad: Large multimodal model by applying vision experts for industrial anomaly detection",
            "rating": 2,
            "sanitized_title": "myriad_large_multimodal_model_by_applying_vision_experts_for_industrial_anomaly_detection"
        },
        {
            "paper_title": "LogGPT: Exploring chatgpt for log-based anomaly detection",
            "rating": 2,
            "sanitized_title": "loggpt_exploring_chatgpt_for_logbased_anomaly_detection"
        },
        {
            "paper_title": "Large Language Models can Deliver Accurate and Interpretable Time Series Anomaly Detection",
            "rating": 2,
            "sanitized_title": "large_language_models_can_deliver_accurate_and_interpretable_time_series_anomaly_detection"
        },
        {
            "paper_title": "Does this make sense? machine learning-based detection of semantic anomalies in business processes",
            "rating": 2,
            "sanitized_title": "does_this_make_sense_machine_learningbased_detection_of_semantic_anomalies_in_business_processes"
        }
    ],
    "cost": 0.020018249999999998,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>DABL: Detecting Semantic Anomalies in Business Processes Using Large Language Models
22 Jun 2024</p>
<p>Wei Guan guan-wei@sjtu.edu.cn 
Department of Computer Science and Engineering
Shanghai Jiao Tong University
ShanghaiChina</p>
<p>Jian Cao cao-jian@sjtu.edu.cn 
Department of Computer Science and Engineering
Shanghai Jiao Tong University
ShanghaiChina</p>
<p>Jianqi Gao 
Department of Computer Science and Engineering
Shanghai Jiao Tong University
ShanghaiChina</p>
<p>Haiyan Zhao zhaohaiyan1992@foxmail.com 
Department of Computer Science and Engineering
University of Shanghai for Science and Technology
ShanghaiChina</p>
<p>Shiyou Qian 
Department of Computer Science and Engineering
Shanghai Jiao Tong University
ShanghaiChina</p>
<p>DABL: Detecting Semantic Anomalies in Business Processes Using Large Language Models
22 Jun 202432B40218D0D5A8DD2EC658EF59F6849DarXiv:2406.15781v1[cs.CL]
Detecting anomalies in business processes is crucial for ensuring operational success.While many existing methods rely on statistical frequency to detect anomalies, it's important to note that infrequent behavior doesn't necessarily imply undesirability.To address this challenge, detecting anomalies from a semantic viewpoint proves to be a more effective approach.However, current semantic anomaly detection methods treat a trace (i.e., process instance) as multiple event pairs, disrupting long-distance dependencies.In this paper, we introduce DABL, a novel approach for detecting semantic anomalies in business processes using large language models (LLMs).We collect 143,137 real-world process models from various domains.By generating normal traces through the playout of these process models and simulating both ordering and exclusion anomalies, we fine-tune Llama 2 using the resulting log.Through extensive experiments, we demonstrate that DABL surpasses existing state-of-the-art semantic anomaly detection methods in terms of both generalization ability and learning of given processes.Users can directly apply DABL to detect semantic anomalies in their own datasets without the need for additional training.Furthermore, DABL offers the capability to interpret the causes of anomalies in natural language, providing valuable insights into the detected anomalies.</p>
<p>Introduction</p>
<p>Business process anomaly detection is geared towards identifying undesired behavior occurring during process execution, serving as a crucial component in guaranteeing the efficient and dependable operation of businesses.By pinpointing anomalies within business processes, these detection techniques facilitate timely intervention, maintenance, and optimization, consequently bolstering overall well-being.</p>
<p>Over the past few decades, notable advancements have been achieved in business process anomaly detection.Fig. 1 illustrates a comparison of various applicable methods for accomplishing this task.Traditional statistical-based approaches (Lu, Fang, and Fang 2022;Ko and Comuzzi 2022;Nolle et al. 2022;Guan et al. 2024) rely on analyzing statistical frequencies to identify anomalies.However, infrequent behavior is not necessarily anomalous; it may represent rare but acceptable behavior.Conversely, frequent behavior may not always be normal.Furthermore, these methods focus on providing anomaly scores and require manual specification of thresholds to distinguish between normal and anomalous instances, which is not suitable for real-world applications.Alternatively, methods based on conformance checking (Ebrahim and Golpayegani 2022; Sarno, Sinaga, and Sungkono 2020;Sinaga and Sarno 2016) detect anomalies by assessing the alignment between traces and their corresponding process models.Yet, accurately capturing complex processes within a process model remains a challenge, thereby restricting the utility of such approaches.The concept of semantic anomaly detection, recently introduced, addresses these challenges by identifying anomalies from a semantic viewpoint.For example, it can detect irregularities such as a claim being paid after having been rejected.Its grounding in natural language analysis allows for the consideration of typical behavior in standard processes, eliminating the necessity of having a specific process model at hand.However, existing semantic-based anomaly detection methods (van der Aa, Rebmann, and Leopold 2021; Caspary, Rebmann, and van der Aa 2023) treat a trace as multiple event pairs, disrupting long-distance dependencies and thus limiting their accuracy.Additionally, these methods interpret the cause of anomalies by providing anomalous event pairs, which can be confusing.</p>
<p>Recently, there have been significant advancements in large language models (LLMs).Due to their remarkable language comprehension abilities, LLMs such as GPT-3.5 (Ouyang et al. 2022), GPT-4 (Achiam et al. 2023), Llama 2 (Touvron et al. 2023), and GLM-3 (Zeng et al. 2022) have shown proficiency in tasks like summarization, paraphrasing, and instruction following in zero-shot scenarios.However, in the context of semantic anomaly detection in business processes, their performance is limited by a lack of prior domain knowledge.As illustrated in Fig. 1, they often struggle to provide specific answers.</p>
<p>To address the aforementioned issues, we propose DABL, a fine-tuned LLM designed to detect semantic anomalies in business processes.Due to the lack of event logs comprising traces from various domains with rich semantic information, we generated our training dataset by playing out 143,137 real-world process models from three different process model datasets.This resulted in 1,574,381 normal traces.The collected process models cover a broad range of domains, including common processes related to order and request handling, as well as specialized processes in fields such as software engineering and healthcare.Utilizing the generated normal traces, we then created synthetic anomalous traces.We introduced ordering anomalies, where activities should be executed in a different sequence (e.g., "accept request" followed by "check request"), and exclusion anomalies, where certain activities should not occur together within the same trace without an intermediate activity (e.g., "refusing the application" followed by "accepting the application" without "reapplying" in between).These generated normal and anomalous traces collectively form the training dataset.Finally, by incorporating traces into question and answer content, we fine-tune the Llama 2-Chat 13B model (Touvron et al. 2023), an open-source LLM, using QLoRA (Dettmers et al. 2024), to create a generic model capable of detecting semantic anomalies in business processes.Compared to existing anomaly detection methods, DABL offers the capability to interpret the causes of anomalies in natural language, providing valuable insights into the detected anomalies.Extensive experiments show that DABL surpasses state-of-the-art methods in both generalization ability and learning of given processes.Thanks to its strong generalization ability, users can apply our opensource, fine-tuned model directly to their datasets without the need for additional training.</p>
<p>Our contributions are summarized as follows:</p>
<p>â€¢ We introduce DABL, an innovative method for finetuning large language models (LLMs) to detect semantic anomalies in business processes.</p>
<p>â€¢ We introduce novel techniques for simulating business process anomalies, encompassing ordering anomalies and exclusion anomalies, thereby enabling precise finetuning of LLMs.</p>
<p>â€¢ Extensive experiments demonstrate that DABL outperforms state-of-the-art methods in both generalization ability and the learning of given processes.Tests on real-world datasets confirm the practical effectiveness of DABL.</p>
<p>Related Work Business Process Anomaly Detection</p>
<p>Existing business process anomaly detection methods can be divided into three categories: statistical-based, conformance checking-based, and semantic-based.</p>
<p>Statistical-based Methods Some of these methods construct probabilistic models to infer the probability values (i.e., anomaly score) of traces.For example, HPDTMC (Yang et al. 2020) (Rullo et al. 2020).Furthermore, the authors in (Ko andComuzzi 2022, 2021) employ one-hot encoding to convert traces into vector representations and detect anomalies using statistical leverage (Hoaglin and Welsch 1978).Recently, deep learning has been adopted to detect anomalies based on the reconstruction error.Given that traces exhibit sequential data characteristics, the authors in (Guan et al. 2023;Nolle et al. 2022;Krajsic and Franczyk 2021) embed LSTM or GRU within the autoencoder to enhance the model's reconstruction capabilities.The authors in (Huo et al. 2021;Guan et al. 2024; Niro and Werner 2024) transform traces into graphs and utilize graph neural networks (GNNs) to generate graph encodings, identifying anomalies by evaluating the reconstruction error of the graphs or traces.</p>
<p>Statistical-based methods detect anomalies by analyzing statistical frequencies.However, infrequent behavior is not necessarily anomalous, as it may represent rare but acceptable behavior.Conversely, frequent behavior may not always be normal.</p>
<p>Conformance Checking-based Methods The conformance checking-based approaches (Ebrahim and Golpayegani 2022; Sarno, Sinaga, and Sungkono 2020; Sinaga and Sarno 2016) utilize process models, which are either provided by the user or derived from logs using process mining techniques.Anomalies are detected through conformance checking techniques (Leemans, Fahland, and van der Aalst 2018), which assess the alignment between traces and the corresponding process model.When the trace deviates from the process model, it is considered anomalous.</p>
<p>The performance of these methods heavily depends on the quality of the process model.Additionally, complex processes are difficult to accurately represent with a process model, limiting the applicability of these methods.</p>
<p>Semantic-based Methods</p>
<p>The semantic-based methods detect anomalies through natural language analysis, aim-ing to detect process behaviors that deviate from a semantic point of view.</p>
<p>Van der Aa et al. (van der Aa, Rebmann, and Leopold 2021) fine-tune BERT (Devlin et al. 2018), a pre-trained language model, to parse the names of executed activities by extracting the action and business object.Then, a knowledge base capturing assertions about the interrelations that should hold among actions parsed from names of executed activities is applied.The knowledge is extracted either from VerbOcean (Chklovski and Pantel 2004) or from an abstract representation of the process model.Anomalies can be detected by checking if the recorded process behavior violates the assertions captured in the knowledge base.</p>
<p>Caspary et al. (Caspary, Rebmann, and van der Aa 2023) extract event pairs that are in an eventually-follow relation.To detect anomalous event pairs, they propose two approaches: an SVM-based approach and a BERT-based approach.The SVM-based approach transforms an event pair into a vector representation using GloVe embeddings.This vector is then fed into a trained SVM, which classifies whether the event pair is an anomaly.The BERT-based approach extends BERT with an additional output layer for two-class classification, determining whether an input event pair is anomalous or not.Both the SVM and the extended BERT model are trained using normal event pairs extracted from normal traces, along with anomalous event pairs simulated by randomly generating event pairs that are not normal.</p>
<p>However, existing semantic-based methods treat a trace as multiple event pairs, which disrupts long-distance dependencies.Additionally, these methods only identify anomalous event pairs to interpret the causes of anomalies, making them difficult to understand.In contrast, our DABL incorporates the entire trace into a novel prompt, allowing the LLMs to automatically capture long-distance dependencies.DABL also provides insightful interpretations of the causes of anomalies in natural language, making them easy to understand.</p>
<p>Large Language Models for Anomaly Detection</p>
<p>Motivated by the impressive cognitive abilities exhibited by large language models (LLMs) (Ouyang et al. 2022;Zeng et al. 2022;Achiam et al. 2023;Touvron et al. 2023), researchers have begun investigating their application for anomaly detection.</p>
<p>AnomalyGPT (Gu et al. 2024) and Myriad (Li et al. 2023) incorporate novel image encoders with LLMs for industrial anomaly detection (IAD).Elhafsi et al. (Elhafsi et al. 2023) apply an LLM to analyze potential confusion among observed objects in a scene, which could lead to taskrelevant errors in policy implementation.LLMAD (Liu et al. 2024) leverages LLMs for few-shot anomaly detection by retrieving and utilizing both positive and negative similar time series segments.In (Qi et al. 2023) and (Egersdoerfer, Zhang, and Dai 2023), authors devise effective prompts to apply LLMs for zero/few-shot system log anomaly detection.SheepDog (Wu and Hooi 2023) conducts fake news detection by preprocessing data using LLMs to reframe the news, customizing each article to match different writing styles.Sarda et al. (Sarda et al. 2023) propose a pipeline for automatic microservice anomaly detection and remediation based on LLMs.</p>
<p>Yet, the application of LLMs for business process anomaly detection remains unexplored.</p>
<p>Method</p>
<p>DABL is a novel conversational fine-tuned large language model, primarily designed to detect semantic anomalies in business processes and interpret their causes.Fig. 2 details the DABL training procedure, which consists mainly of dataset preparation and fine-tuning.DABL is implemented in Python, and the source code is accessible at https://github.com/guanwei49/DABL.</p>
<p>Dataset Preparation</p>
<p>To effectively fine-tune LLMs for developing a generic model capable of detecting semantic anomalies in business processes, a log meeting the following criteria is imperative: i) it must encompass both normal and anomalous traces, ii) it should contain rich semantic information (i.e., the activities should not be represented by meaningless characters), and iii) the traces within it should stem from diverse processes across various domains.Since such a log is not available in the real world, we generate normal traces by playout of the real-world process models from the BPM Academic Initiative (BPMAI) (Weske et al. 2020), fundamentals of business process management (FBPM) (Dumas et al. 2018), and SAP signavio academic models (SAP-SAM) (Sola et al. 2022).These process models cover a broad range of domains, including common processes related to order and request handling, as well as specialized processes from fields such as software engineering and healthcare.We then generate synthetic anomalies from these normal traces.We detail the dataset preparation in the following subsection.</p>
<p>Generation of Normal Traces</p>
<p>We select process models M from BPMAI, FBPM, and SAP-SAM that meet the following criteria: they are in BPMN notation (Chinosi and Trombetta 2012), described in English, and convertible into a sound workflow net.This results in a total set of 144,137 process models.Among these, 143,137 process models are used for generating training datasets, resulting in 1,574,381 normal traces, while the remaining 1,000 process models are used for generating test datasets.</p>
<p>Next, for each process model m âˆˆ M, we perform a playout to obtain the set of normal traces, denoted as L m .These traces are allowed by the process model m.To prevent infinite trace lengths, we limit each loop in the process model m to be executed a maximum of twice.</p>
<p>Anomaly Simulation Normal traces can be converted into anomalous ones by disrupting the order of executed activities (ordering anomalies) or by sequencing exclusive activities (exclusion anomalies).</p>
<p>Ordering anomalies: Ordering anomalies arise when activities ought to be executed in a different sequence.Five types of ordering anomalies, as identified in (Nolle et al. 2022), are frequently encountered in real-world business  Below are the causes for these anomaly types, which are currently in the plural form (i.e., 'activities', 'they').During implementation, they may need to be flexibly transformed into the singular form (i.e., 'activity', 'it').</p>
<p>â€¢ Skip: The activities ${e i , â€¢ â€¢ â€¢ , e j } are skipped before ${e j+1 }.
â€¢ Insert: The activities ${e â€² 1 , â€¢ â€¢ â€¢ , e â€² m }
should not be executed.</p>
<p>â€¢ Rework: The activities ${e i , â€¢ â€¢ â€¢ , e j } are reworked after ${e k }. â€¢ Early: The activities ${e i , â€¢ â€¢ â€¢ , e j } are executed too early, they should be executed after ${e iâˆ’1 }. â€¢ Late: The activities ${e i , â€¢ â€¢ â€¢ , e j } are executed too late, they should be executed before ${e j+1 }.</p>
<p>Here, ${e i , . . ., e j } represents converting the trace [e i , â€¢ â€¢ â€¢ , e j ] into a string format by enclosing each executed activity in apostrophes and separating them with commas, while using and before the penultimate and ultimate activities.For example, for the trace [A, B, C, D], the resulting string would be 'A', 'B', 'C' and 'D'.</p>
<p>However, the generated anomalies may actually represent a normal trace.For a process model m, we refine the set of generated ordering anomalies L o m by excluding traces present in L m from it.</p>
<p>Exclusion anomalies: Exclusion anomalies occur when certain activities should not have been executed together within the same trace without an intermediate activity.For instance, in the loan application process illustrated in Fig. 2, it is inappropriate to send an acceptance pack and reject an application within the same trace.</p>
<p>The process tree (Aalst, Buijs, and Dongen 2011), a specialized form of process model, is utilized for analyzing process structure.For instance, the process tree corresponding to the process model depicted in Fig. 2 is illustrated in Fig. 4. We begin by converting the gathered process model m into a process tree using the techniques presented in (van Zelst and Leemans 2020).Then, we replace an exclusive node (represented as Ã—) in the process tree with a parallel node (represented as âˆ§), resulting in a modified process model denoted as m â€² .This modification enables certain exclusive activities to be executed within the same trace to simulate exclusion anomalies.It is important to recognize that a single process tree may contain multiple exclusive nodes; therefore, we carry out this modification successively, resulting in multiple modified process models.Subsequently, we playout of all the modified models, restricting each loop to be executed a maximum of twice, to generate the set of traces, denoted as L m â€² .We refine L m â€² by excluding traces present in L m from it, resulting in the set of exclusion anomalies L e m .To extract the causes of exclusion anomalies, we need to identify activities that exhibit exclusion relationships.In a process tree, activities located under different branches of an exclusive node (represented as Ã—) exhibit such relationships.For example, in the process tree illustrated in Fig. 4, the activity set {'Prepare acceptance pack', 'Send acceptance pack'} and the activity set {'Reject application'} exhibit exclusion relationships.</p>
<p>Formally, consider a modified model m â€² , which results from modifying an exclusive node R in the process tree corresponding to the process model m.An exclusion anomaly t is generated from model m â€² .The node R has N branches, with the activity sets A 1 , â€¢ â€¢ â€¢ , A N under them.Activities within each activity set A i that do not appear in t are filtered out.The cause of this exclusion anomaly t is then:</p>
<p>â€¢ The activities ${A 1 } are mutually exclusive with the activities ${ i=2â€¢â€¢â€¢N A i }, meaning they should not be executed within the same process instance.</p>
<p>Question and Answer Content</p>
<p>To conduct prompt tuning on the LLM, we generate corresponding textual queries based on simulated anomalous traces.Specifically, each query consists of two components.The first component introduces the traces, such as "In the following business process trace, each executed activity is separated by a comma: [Send acceptance pack, Check credit history, Assess loan risk, Assess eligibility, Prepare acceptance pack]".The second component queries whether the trace is anomalous, asking, for instance, "Is this trace normal or anomalous?".The LLM first responds to whether the given trace is normal or anomalous.If it is anomalous, the LLM is asked about the cause of the anomaly, for example, "What causes this trace to deviate?".The LLM then explains the cause of the anomaly, such as "The activity 'Send acceptance pack' is executed too early, it should be executed after 'Prepare acceptance pack'.".This descriptive content about the anomaly's cause provides valuable insights and facilitates actions to maintain the health of the process execution.</p>
<p>Efficient Fine-Tuning on LLMs We employ the Adam optimizer (Kingma and Ba 2014) to fine-tune the LLMs for two epochs, setting the initial learning rate to 5 Ã— 10 âˆ’5 with polynomial learning rate decay.The mini-batch size is set to 64.The fine-tuning is carried out on an NVIDIA A6000 GPU with 48 GB of memory.</p>
<p>Experiments Experimental Setup</p>
<p>Datasets As mentioned in previous section, we allocate 1,000 process models for generating the test dataset D 1 .These models produce 14,387 normal traces, and we randomly simulate anomalies, resulting in 13,694 anomalous traces.In total, the test dataset D 1 comprises 28,081 traces.</p>
<p>From 143,137 process models used for generating the training dataset, we randomly select 1,000 process models to create the test dataset D 2 .These 1,000 process models produce 21,298 normal traces, and we randomly simulate anomalies, resulting in 19,627 anomalous traces.In total, the test dataset D 2 comprises 40,925 traces.Note that, although the normal traces within the test dataset D 2 are identical to those in the training dataset, the simulated anomalies are not.</p>
<p>In summary, the test dataset D 1 is used to evaluate the model's generalization ability, verifying if the model can detect anomalies of unseen processes.The test dataset D 2 aims to validate the model's performance on seen processes but unseen anomalies (i.e., learning of given processes).</p>
<p>Compared Methods Statistical-based and conformance checking methods can only be applied to datasets containing traces from a single process.However, our test datasets include traces from 1000 processes where no two traces are identical (i.e., traces with identical orders of activities are executed).Therefore, these methods cannot be compared.In our evaluation, we compare our DABL to existing semantic business process anomaly detection methods: SENSE (Caspary, Rebmann, and van der Aa 2023) and SEM (van der Aa, Rebmann, and Leopold 2021).SENSE offers both SVM-based and BERT-based models for detecting anomalous event pairs, which we denote as SENSE-SVM and SENSE-BERT, respectively.These methods divide traces into event pairs and determine whether each pair is normal or anomalous.If at least one event pair in a trace is identified as anomalous, the entire trace is classified as anomalous.It is important to note that SEM can only detect anomalous event pairs that share the same business object, automatically classifying pairs with distinct business objects as non-anomalous.Due to the high training costs, we utilize the open-source trained models provided by the authors for the test dataset D 1 .For the test dataset D 2 , we train the comparative models using the 21,298 normal traces available within it.The hyper-parameters of these methods are set to the values that yielded the best results reported in the original paper.</p>
<p>Evaluation Metrics Following existing anomaly detection methods, we employ precision, recall, F 1 -score and accuracy to evaluate the anomaly detection performance.</p>
<p>The recall-oriented understudy for gisting evaluation (ROUGE) (Lin 2004) is a software package and metric set designed to assess the quality of generated text by comparing it with ground truth text.In our evaluation of DABL's ability to interpret the cause of anomalies, we utilize ROUGE-2 and ROUGE-L metrics.</p>
<p>Quantitative Results</p>
<p>Anomaly Detection To evaluate the model's generalization ability, we conduct experiments on the test dataset D 1 .The results are shown in Table 1, with the best outcomes highlighted in bold.Our DBAL achieves the highest precision, F 1 -score, and accuracy, with both the F 1 -score and accuracy exceeding 90%.Although SENSE-BERT attains the best recall, it has the lowest precision and accuracy.Compared to other methods, DBAL maintains a balanced We conduct experiments on dataset D 2 to evaluate if the methods can learn the given processes.The results are presented in Table 2. Compared to the experiments on dataset D 1 , the precision of each method increases.This improvement is due to the incorporation of normal process behavior in the training dataset, thereby reducing false alarms.Consequently, the F 1 -score and accuracy also show significant improvements.Our DABL method stands out, achieving the best performance across all metrics, with the F 1score and accuracy showing improvements of 21.79% and 16.75%, respectively, over the best existing semantic-based anomaly detection method (i.e., SENSE-BERT).These results demonstrate that DABL can learn the given processes effectively, allowing users to further fine-tune DABL on their own processes to obtain a customized model.3 shows the results of DABL in interpreting the causes of anomalies.On dataset D 1 , both ROUGE-2 and ROUGE-L scores are relatively high, indicating that DABL performs well in identifying the causes of anomalies, even for processes not included in the training data.For dataset D 2 , DABL exhibits better performance because the normal behaviors of the processes are well-represented in the training data.Furthermore, the slight difference between recall and precision suggests that the model maintains a good balance.These results demonstrate that DABL is effective at interpreting the causes of anomalies in terms of both bigrams and longest common subsequences.</p>
<p>Interpretation of the Cause of Anomalies Table</p>
<p>However, these result values may be underestimated because the cause of an anomaly can be interpreted in various ways.For example, for a desired trace [A, B, C, D, E], the anomaly [A, B, E, C, D] can be interpreted as "The activities 'C' and 'D' are executed too late, they should be executed after 'B'" and "The activity 'E' is executed too early, it should be executed after 'D'."Nevertheless, we only provide one reference answer to calculate ROUGE-2 and ROUGE-L scores.Without further context or information, it is difficult to determine if the given business process trace is normal or anomalous.GPT-3.5 GPT-4 GLM-3 Llama 2 DABL Without knowing the standard sequence of activities or having additional context, it's difficult to say definitively whether this trace is normal or anomalous.This sequence of activities seems logical and typically follows an onboarding process in many organizations.It would be considered normal if this is the standard procedure for equipping new employees with the necessary tools and access to perform their job.</p>
<p>Qualitative Examples</p>
<p>A business process trace is a sequence of activities that are executed in a business process.Each executed activity is separated by a comma in the trace.</p>
<p>The trace is anomalous.</p>
<p>What's the origin of the anomaly?</p>
<p>æœºå™¨äººå­¦ DABL The activity 'Procure work equipment' is executed too early, it should be executed after 'Select necessary work equipment'.</p>
<p>æœºå™¨äººå­¦</p>
<p>Here is a trace of a business process, with each performed activity separated by a comma: [Sh goods, Contact container port, Contact airlines, Prepare delivery note].Is this trace normal anomalou</p>
<p>Based on the provided business process trace, it is difficult to determine if it is normal or anomalous without further context or information.GPT-3.5 GPT-4 GLM-3 Llama 2 DABL As an AI, I don't have the exact context or knowledge of the specific rules of the business process.However, based on the general order of operations in shipping and logistics, this trace seems norma Without additional context or a definition of what is considered normal in this specific process, we can only say that the given trace is not inherently anomalous based on the activities listed.</p>
<p>What is the difference between a trace and a log?A trace is a record of all the activities performed i a business process.A log is a record of all the activities performed in a business process.</p>
<p>The trace is anomalous.</p>
<p>What makes this trace anomalou</p>
<p>æœºå™¨äººå­¦ DABL The activity 'Contact airlines' is mutually exclusive with the activity 'Contact container port', meaning they should not be executed within the same process instance.Due to the absence of business process-related knowledge, existing LLMs may not offer definitive answers.In contrast, our DABL is proficient in identifying anomalies and interpreting their underlying causes, thanks to the integration of a vast array of process models from diverse domains in the training data.</p>
<p>Real-world Application</p>
<p>Travel Permit We apply our DABL on a real-world permit log from the BPI 2020 challenge (van Dongen 2020), which captures data on work trips conducted by university employees.The process flow involves the request for and approval of a travel permit, the trip itself, a subsequent travel declaration, as well as associated reimbursements.</p>
<p>This log contains 7,065 traces with 1,478 variants (traces with different orders of activities are executed).DABL iden- This sequence of activities seems logical and typically follows an onboarding process in many organizations.It would be considered normal if this is the standard procedure for equipping new employees with the necessary tools and access to perform their job.</p>
<p>A business process trace is a sequence of activities that are executed in a business process.Each executed activity is separated by a comma in the trace.</p>
<p>The trace is anomalous.</p>
<p>What's the origin of the anomaly?
äººå­¦ BL
The activity 'Procure work equipment' is executed too early, it should be executed after 'Select necessary work equipment'.</p>
<p>æœºå™¨äººå­¦</p>
<p>Here is a trace of a business process, with each performed activity separated by a comma: [Ship goods, Contact container port, Contact airlines, Prepare delivery note].Is this trace normal or anomalous?</p>
<p>Based on the provided business process trace, it is difficult to determine if it is normal or anomalous without further context or information.GPT-3.5 GPT-4 GLM-3 Llama 2 DABL As an AI, I don't have the exact context or knowledge of the specific rules of the business process.However, based on the general order of operations in shipping and logistics, this trace seems normal.</p>
<p>Without additional context or a definition of what is considered normal in this specific process, we can only say that the given trace is not inherently anomalous based on the activities listed.</p>
<p>What is the difference between a trace and a log?A trace is a record of all the activities performed in a business process.A log is a record of all the activities performed in a business process.</p>
<p>The trace is anomalous.</p>
<p>What makes this trace anomalous?</p>
<p>æœºå™¨äººå­¦ DABL The activity 'Contact airlines' is mutually exclusive with the activity 'Contact container port', meaning they should not be executed within the same process instance.tifies 562 anomalous variants.These detected anomalies reveal some interesting irregularity patterns illustrated in Table 4.These irregularity patterns include: trips starting before a permit is properly handled (A1), approved (A2), or even rejected (A3); the declaration being finally approved by a supervisor and payment handled despite the permit being rejected (A4); and requests for payment being approved before the permit is approved (A5).</p>
<p>Road Traffic Fine Management</p>
<p>We apply our DABL on another real-world event log from an information system managing road traffic fines (de Leoni and Mannhardt 2015), which captures the road traffic fine management process.The process flow involves the creation of a fine, appeal to the prefecture, addition of penalties, and fine payment.</p>
<p>This log contains 150,370 traces with 231 variants.DABL identifies 56 anomalous variants.These detected anomalies reveal some interesting irregularity patterns as detailed in Table 5.The examples illustrate irregularity patterns where the fine is repeatedly paid (A1), the fine is paid before the penalty is added (A2), and the result appeal from the prefecture is received before the appeal is sent to the prefecture (A3).</p>
<p>Conclusion</p>
<p>In this paper, we introduce DABL, a novel semantic business process anomaly detection model leveraging LLMs.Trained on 143,137 real-world process models from various domains, DABL excels at zero-shot detection of semantic anomalies and interprets their causes in natural language.Extensive experiments demonstrate DABL's generalization ability, allowing users to detect anomalies in their own datasets without additional training.</p>
<p>Figure 1 :
1
Figure 1: Comparison between our DABL with existing methods.</p>
<p>Figure 3 :
3
Figure 3: Different anomaly types applied to a normal trace.</p>
<p>Figure 4 :
4
Figure 4: Different anomaly types applied to a normal trace.</p>
<p>Fig. 5
5
Fig. 5 and Fig. 6 illustrate the performance of existing LLMs and DABL on early and exclusion anomalies, respectively.</p>
<p>Figure 5 :
5
Figure 5: Qualitative results of various LLMs on an early anomaly.</p>
<p>äººå­¦</p>
<p>Below is a business process trace, with each executed activity separated by a comma: [Add personal data, Procure work equipment, Select necessary work equipment, Set up access rights hardware and software].Is this trace normal or anomalous?Without further context or information, it is difficult to determine if the given business process trace is normal or anomalous.standard sequence of activities or having additional context, it's difficult to say definitively whether this trace is normal or anomalous.</p>
<p>Figure 6 :
6
Figure 6: Qualitative results of various LLMs on an exclusion anomaly.</p>
<p>[Check credit history, Assess loan risk, Assess eligibility, Reject application] [Check credit history, Assess loan risk, Assess eligibility, Prepare acceptance pack, Send acceptance pack] Check credit history, Assess loan risk, Assess eligibility, Prepare acceptance pack, Send acceptance pack]", "label": "normal"} {"trace": "[Send acceptance pack, Check credit history, Assess loan risk, Assess eligibility, Prepare acceptance pack]", "label": "anomalous", "cause": "The activity 'Send acceptance pack' is executed too early, it should be executed after 'Prepare acceptance pack'."}{"trace": "[Check credit history, Assess loan risk, Assess eligibility, Reject application, Prepare acceptance pack, Send acceptance pack]",
Process ModelApplicant Applicantnot eligible not eligibleReject Rejectapplication applicationCheck credit Check creditAssess loan Assess loanAssess Assesshistory historyrisk riskeligibility eligibilityPrepare PrepareSend SendApplicant eligible Applicant eligibleacceptance pack acceptance packacceptance pack acceptance packPlayout of Process ModelNormal TracesAnomaly Simulation{"trace": "[Check credit history, Assess loan risk, Assess eligibility, Reject application]","label": "normal"}Question and Answer Content: In the following business process trace, each executed activity is separated by a comma:{trace}. Is this trace normal or anomalous? \n The trace is {label}.\n What's the cause of the anomaly? \n {cause} Open-source LLM Open-source LLM Efficient Fine-Tuning on Open-Source LLMs {"trace": "[Check credit history Assess loan risk Develop Hypothesis Assess eligibility Reject application Normal Check credit history Assess loan risk Develop Hypothesis Assess eligibility Reject application NormalFine-Tuned LLM for Business Process Anomaly DetectionSkipCheck credit historyAssess loan riskDevelop HypothesisAssess eligibilityReject applicationInsertCheck credit historyAssess loan riskDevelop HypothesisAssess eligibilityExperimentReject applicationReworkCheck credit historyAssess loan riskDevelop HypothesisAssess loan riskAssess eligibilityReject applicationEarlyCheck credit historyAssess eligibilityAssess loan riskDevelop HypothesisReject applicationLateCheck credit history Develop HypothesisAssess eligibilityAssess loan riskReject application
"label": "anomalous", "cause": "The activity 'Reject application' is mutually exclusive with the activities 'Prepare acceptance pack' and 'Send acceptance pack', meaning they should not be executed within the same process instance."}Figure2:Detecting semantic anomalies in business processes using large language models.</p>
<p>Table 1 :
1
Semantic anomaly detection results on dataset D 1 .The best results are indicated using bold typeface.
Prec.(%) Rec.(%) F 1 (%) Acc.(%)SEM48.6746.847.7250.81SENSE-SVM87.951.122.2052.50SENSE-BERT48.1797.7464.5348.47DBAL94.0689.7991.8892.39</p>
<p>Table 2 :
2
Semantic anomaly detection results on dataset D 2 .The best results are indicated using bold typeface.
Prec.(%) Rec.(%) F 1 (%) Acc.(%)SEM71.9148.6358.0266.75SENSE-SVM90.2828.6443.4964.82SENSE-BERT93.1662.8875.0880.28DBAL98.1295.6496.8797.03</p>
<p>Table 3 :
3
The results of DABL in interpreting the causes of anomalies.
DatasetROUGE-2(%)ROUGE-L(%)Prec. Rec.F 1Prec. Rec.F 1D 174.48 74.49 74.32 76.29 76.11 76.02D 284.92 84.61 84.54 86.96 86.66 86.56precision and recall. SENSE-SVM exhibits limited sensi-tivity to anomalies, potentially overlooking many anoma-lies, thereby achieving high precision but markedly low re-call. Conversely, SENSE-BERT demonstrates excessive sen-sitivity, resulting in numerous false alarms, thus yieldinglow precision but high recall. These results demonstrate thatDBAL possesses a superior generalization ability for detect-ing anomalies in unseen processes.</p>
<p>Table 4 :
4
Irregularity patterns identified in the travel permit log.The activities 'Permit APPROVED by BUDGET OWNER' and 'Permit FINAL APPROVED by SUPERVISOR' are executed too late, they should be executed before 'Request For Payment APPROVED by BUDGET OWNER'.Permit SUBMITTED by EMPLOYEE; PAA: Permit APPROVED by ADMINISTRATION; PAB: Permit APPROVED by BUDGET OWNER; PAS: Permit APPROVED by SUPERVISOR; PFAS: Permit FI-NAL APPROVED by SUPERVISOR; PFAD: FINAL APPROVED by DIRECTOR; PRM: Permit REJECTED by MISSING; RSE: Request For Payment SUBMITTED by EMPLOYEE; RRA: Request For Payment REJECTED by ADMINISTRATION; RRE: Request For Payment REJECTED by EMPLOYEE; RAA: Request For Payment APPROVED by ADMINISTRATION; RAB: Request For Payment APPROVED by BUDGET OWNER; RFAS: Request For Payment FINAL APPROVED by SUPERVISOR; DSAE: Declaration SAVED by EMPLOYEE; DSE: Declaration SUBMITTED by EMPLOYEE; DRA: Declaration RE-JECTED by ADMINISTRATION; DRE: Declaration REJECTED by EMPLOYEE; DAA: Declaration APPROVED by ADMINISTRATION; DAB: Declaration APPROVED by BUDGET OWNER; DFAS: Declaration FINAL APPROVED by SUPERVISOR; RP: Request Payment; PH: Payment Handled; SR: Send Reminder; ST: Start trip; ET: End trip.
IDExample Trace
PSE:</p>
<p>Table 5 :
5
Irregularity patterns identified in the road traffic fine management log.Receive Result Appeal from Prefecture' is executed too early, it should be executed after 'Send Appeal to Prefecture'.Create Fine; SF: Send Fine; IFN: Insert Fine Notification; AP: Add penalty; P: Payment; RRAP: Receive Result Appeal from Prefecture; IDAP: Insert Date Appeal to Prefecture; SAP: Send Appeal to Prefecture.Below is a business process trace, with each executed activity separated by a comma: [Add personal data, Procure work equipment, Select necessary work equipment, Set up access rights hardware and software].Is this trace normal or anomalous?
IDExample Trace
CF:æœºå™¨äººå­¦</p>
<p>AcknowledgmentsThis work is supported by China National Science Foundation (Granted No. 62072301).
Towards improving the representational bias of process mining. W V D Aalst, J Buijs, B V Dongen, International Symposium on Data-Driven Process Discovery and Analysis. Springer2011</p>
<p>J Achiam, S Adler, S Agarwal, L Ahmad, I Akkaya, F L Aleman, D Almeida, J Altenschmidt, S Altman, S Anadkat, arXiv:2303.08774Gpt-4 technical report. 2023arXiv preprint</p>
<p>Does this make sense? machine learning-based detection of semantic anomalies in business processes. J Caspary, A Rebmann, H Van Der Aa, A Trombetta, International Conference on Business Process Management. Springer2023. 201234BPMN: An introduction to the standard</p>
<p>Verbocean: Mining the web for fine-grained semantic verb relations. T Chklovski, P , Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing. the 2004 Conference on Empirical Methods in Natural Language Processing2004</p>
<p>Representation Learning for Business Processes. P De Koninck, S Vanden Broucke, J De Weerdt, Business Process Management. M Weske, M Montali, I Weber, J Brocke, ChamSpringer International Publishing2018. act2vec, trace2vec, log2vec, and model2vec</p>
<p>M M De Leoni, F Mannhardt, Road Traffic Fine Management Process. 2015</p>
<p>Qlora: Efficient finetuning of quantized llms. T Dettmers, A Pagnoni, A Holtzman, L Zettlemoyer, Advances in Neural Information Processing Systems. 202436</p>
<p>Bert: Pre-training of deep bidirectional transformers for language understanding. J Devlin, M.-W Chang, K Lee, K Toutanova, M Dumas, L M Rosa, J Mendling, A H Reijers, arXiv:1810.04805J. Comput. Virol. Hacking Tech. Springer. Ebrahim, M.and Golpayegani, S. A. H. 20222018. 2018arXiv preprintAnomaly detection in business processes logs using social network analysis</p>
<p>Early exploration of using chatgpt for log-based anomaly detection on parallel file systems logs. C Egersdoerfer, D Zhang, D Dai, Proceedings of the 32nd International Symposium on High-Performance Parallel and Distributed Computing. the 32nd International Symposium on High-Performance Parallel and Distributed Computing2023</p>
<p>Semantic anomaly detection with large language models. A Elhafsi, R Sinha, C Agia, E Schmerling, I A Nesnas, M Pavone, Autonomous Robots. 4782023</p>
<p>Anomalygpt: Detecting industrial anomalies using large vision-language models. Z Gu, B Zhu, G Zhu, Y Chen, M Tang, J Wang, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence202438</p>
<p>GRASPED: A GRU-AE Network Based Multi-Perspective Business Process Anomaly Detection Model. W Guan, J Cao, Y Gu, S Qian, IEEE Transactions on Services Computing. 2023</p>
<p>GAMA: A multi-graph-based anomaly detection framework for business processes via graph neural networks. W Guan, J Cao, Y Gu, S Qian, 2024. 102405Information Systems</p>
<p>The hat matrix in regression and ANOVA. D C Hoaglin, R E Welsch, The American Statistician. 3211978</p>
<p>Graph Autoencoders for Business Process Anomaly Detection. S Huo, H VÃ¶lzer, P Reddy, P Agarwal, V Isahagian, V Muthusamy, Springer, S B Junior, P Ceravolo, E Damiani, N J Omori, G M Tavares, Business Process Management -19th International Conference, BPM, volume 12875 of Lecture Notes in Computer Science. 2021. 2020. 2020Anomaly Detection on Event Logs with a Scarcity of Labels. 2nd International Conference on Process Mining (ICPM</p>
<p>Detecting anomalies in business process event logs using statistical leverage. D P Kingma, J Ba, J Ko, M Comuzzi, arXiv:1412.6980Adam: A method for stochastic optimization. 2014. 2021549arXiv preprint</p>
<p>Keeping our rivers clean: Information-theoretic online anomaly detection for streaming business process events. Information Systems. J Ko, M Comuzzi, P Krajsic, B Franczyk, Procedia Computer Science. 1042022. 2021Semi-supervised anomaly detection in business process event data using selfattention based classification</p>
<p>Scalable process discovery and conformance checking. S J J Leemans, D Fahland, W M Van Der Aalst, Softw. Syst. Model. 1722018</p>
<p>Y Li, H Wang, S Yuan, M Liu, D Zhao, Y Guo, C Xu, G Shi, W Zuo, arXiv:2310.19070Myriad: Large multimodal model by applying vision experts for industrial anomaly detection. 2023arXiv preprint</p>
<p>Rouge: A package for automatic evaluation of summaries. C.-Y Lin, Text summarization branches out. 2004</p>
<p>Large Language Models can Deliver Accurate and Interpretable Time Series Anomaly Detection. J Liu, C Zhang, J Qian, M Ma, S Qin, C Bansal, Q Lin, S Rajmohan, D Zhang, arXiv:2405.15370Lu, K.; Fang, X.; and Fang, N. 2022. PN-BBN: A Petri Net-Based Bayesian Network for Anomalous Behavior Detection. Mathematics202410arXiv preprint</p>
<p>BINet: Multi-perspective business process anomaly classification. T Mikolov, K Chen, G Corrado, J Dean, T Nolle, S Luettgen, A Seeliger, M MÃ¼hlhÃ¤user, arXiv:2403.00775Workshop Track Proceedings. Niro, A.; and Werner, M. 2024. Detecting Anomalous Events in Object-centric Business Processes via Graph Neural Networks. Y Bengio, Y Lecun, Scottsdale, Arizona, USA2013. May 2-4, 2013. 2022103101458arXiv preprintEfficient Estimation of Word Representations in Vector Space</p>
<p>Training language models to follow instructions with human feedback. L Ouyang, J Wu, X Jiang, D Almeida, C Wainwright, P Mishkin, C Zhang, S Agarwal, K Slama, A Ray, Advances in neural information processing systems. 202235</p>
<p>An Anomaly Detection Technique for Business Processes Based on Extended Dynamic Bayesian Networks. S Pauwels, T Calders, Proceedings of the 34th ACM/SIGAPP Symposium on Applied Computing, SAC '19. the 34th ACM/SIGAPP Symposium on Applied Computing, SAC '19New York, NY, USAAssociation for Computing Machinery2019aISBN 9781450359337</p>
<p>S Pauwels, T Calders, Detecting Anomalies in Hybrid Business Process Logs. 2019b19</p>
<p>Loggpt: Exploring chatgpt for log-based anomaly detection. J Qi, S Huang, Z Luan, S Yang, C Fung, H Yang, D Qian, J Shang, Z Xiao, Z Wu, 2023 IEEE International Conference on High Performance Computing &amp; Communications, Data Science &amp; Systems, Smart City &amp; Dependability in Sensor, Cloud &amp; Big Data Systems &amp; Application. IEEE2023</p>
<p>A framework for the multi-modal analysis of novel behavior in business processes. A Rullo, A Guzzo, E Serra, E Tirrito, Intelligent Data Engineering and Automated Learning-IDEAL 2020: 21st International Conference. Guimaraes, PortugalSpringer2020. November 4-6, 2020Proceedings, Part I 21</p>
<p>Adarma auto-detection and auto-remediation of microservice anomalies by leveraging large language models. K Sarda, Z Namrud, R Rouf, H Ahuja, M Rasolroveicy, M Litoiu, L Shwartz, I Watts, Proceedings of the 33rd Annual International Conference on Computer Science and Software Engineering. the 33rd Annual International Conference on Computer Science and Software Engineering2023</p>
<p>Anomaly detection in business processes using process mining and fuzzy association rule learning. R Sarno, F Sinaga, K R Sungkono, J. Big Data. 72020</p>
<p>Business process anomali detection using multi-level class association rule learning. F Sinaga, R Sarno, IPTEK Journal of Proceedings Series. 212016</p>
<p>Natural language-based detection of semantic execution anomalies in event logs. D Sola, C Warmuth, B SchÃ¤fer, P Badakhshan, J.-R Rehse, T Kampik, Springer, H Touvron, L Martin, K Stone, P Albert, A Almahairi, Y Babaei, N Bashlykov, S Batra, P Bhargava, S Bhosale, arXiv:2307.09288Translating Workflow Nets to Process Trees: An Algorithmic Approach. 2022. 2023. 2021. 2020. 2020. 2020102279arXiv preprintAlgorithms</p>
<p>On the Use of Online Clustering for Anomaly Detection in Trace Streams. R Vertuam Neto, G Tavares, P Ceravolo, S Barbon, G Decker, M Dumas, M L Rosa, J Mendling, H A Reijers, XVII Brazilian Symposium on Information Systems, SBSI 2021. New York, NY, USA2021. 2020Association for Computing Machinery. ISBN 9781450384919. Model Collection of the Business Process Management Academic Initiative</p>
<p>J Wu, B Hooi, arXiv:2310.10830Fake News in Sheep's Clothing: Robust Fake News Detection Against LLM-Empowered Style Attacks. 2023arXiv preprint</p>
<p>Analysing Business Process Anomalies Using Discrete-time Markov chains. L Yang, S Mcclean, M Donnelly, K Khan, K Burke, 2020 IEEE 22nd International Conference on High Performance Computing and Communications; IEEE 18th International Conference on Smart City; IEEE 6th International Conference on Data Science and Systems. HPCC/SmartCity/DSS. 2020</p>
<p>A Zeng, X Liu, Z Du, Z Wang, H Lai, M Ding, Z Yang, Y Xu, W Zheng, X Xia, arXiv:2210.02414Glm-130b: An open bilingual pre-trained model. 2022arXiv preprint</p>            </div>
        </div>

    </div>
</body>
</html>