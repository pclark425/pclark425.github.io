<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-9158 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-9158</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-9158</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-161.html">extraction-schema-161</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLMs being used as text-based simulators in specific scientific subdomains, including details on the simulation task, the accuracy or evaluation results, and any factors or variables identified as affecting simulation accuracy.</div>
                <p><strong>Paper ID:</strong> paper-280000744</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2506.20291v1.pdf" target="_blank">A Literature Review on Simulation in Conversational Recommender Systems</a></p>
                <p><strong>Paper Abstract:</strong> Conversational Recommender Systems (CRSs) have garnered attention as a novel approach to delivering personalized recommendations through multi-turn dialogues. This review developed a taxonomy framework to systematically categorize relevant publications into four groups: dataset construction, algorithm design, system evaluation, and empirical studies, providing a comprehensive analysis of simulation methods in CRSs research. Our analysis reveals that simulation methods play a key role in tackling CRSs'main challenges. For example, LLM-based simulation methods have been used to create conversational recommendation data, enhance CRSs algorithms, and evaluate CRSs. Despite several challenges, such as dataset bias, the limited output flexibility of LLM-based simulations, and the gap between text semantic space and behavioral semantics, persist due to the complexity in Human-Computer Interaction (HCI) of CRSs, simulation methods hold significant potential for advancing CRS research. This review offers a thorough summary of the current research landscape in this domain and identifies promising directions for future inquiry.</p>
                <p><strong>Cost:</strong> 0.012</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e9158.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e9158.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLMs being used as text-based simulators in specific scientific subdomains, including details on the simulation task, the accuracy or evaluation results, and any factors or variables identified as affecting simulation accuracy.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LLM-REDIAL</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>LLM-REDIAL: A large-scale dataset for conversational recommender systems created from user behaviors with LLMs</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An LLM-based data-simulation pipeline that generates multi-turn conversational recommendation dialogues and feedback using instruction templates and per-turn goals to ensure semantic consistency; used to produce a large synthetic CRS dataset at low monetary cost.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>LLM-REDIAL: A largescale dataset for conversational recommender systems created from user behaviors with LLMs.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>scientific_subdomain</strong></td>
                            <td>Conversational Recommender Systems (CRSs) / Information access (recommendation)</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_task</strong></td>
                            <td>Generate multi-turn conversational recommendation dialogues and recommendation feedback (text-based user-system interactions) from seed user-behavior data using instruction templates and assigned turn-level goals.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>Descriptive quality metrics reported in the review (scale: number of dialogues/utterances; text diversity and dialogue quality assertions); cost-per-conversation comparison to crowdsourcing. No explicit numerical ML accuracy metrics reported in the review.</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_accuracy</strong></td>
                            <td>Not reported as a numerical accuracy value in this review; reported outcomes: dataset of 47.6k multi-turn dialogues, 482.6k utterances across 4 domains; described improvements in scale, text diversity, and dialogue quality compared to prior dataset (REDIAL).</td>
                        </tr>
                        <tr>
                            <td><strong>factors_affecting_accuracy</strong></td>
                            <td>['Bias propagation from seed datasets used to prompt/generate synthetic dialogues', 'Prompt template design (manual templates limit output flexibility)', 'Semantic inconsistency and dataset inextensibility in original/crowdsourced datasets', 'Gap between text semantic space (LLM output) and real behavioral semantics of users']</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Compared qualitatively and economically to REDIAL (crowdsourced dataset): REDIAL produced >10k dialogues via AMT (~$1 per conversation cost reported), while LLM-REDIAL produced 47.6k dialogues for a total cost of $750; described as higher scale and diversity but no direct numeric performance comparison on predictive tasks reported in review.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>No numeric accuracy given; reported limitations include propagation of seed-dataset bias into synthetic data, limited output flexibility from manual prompt templates, and the semantic gap between LLM text outputs and real user behavioral semantics.</td>
                        </tr>
                        <tr>
                            <td><strong>author_recommendations_or_insights</strong></td>
                            <td>Authors highlight benefits of cost and scale but caution about bias propagation and prompt-dependence; suggest introducing multi-modal considerations where applicable and improving prompt/template flexibility to better match real user behavior.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A Literature Review on Simulation in Conversational Recommender Systems', 'publication_date_yy_mm': '2025-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9158.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e9158.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLMs being used as text-based simulators in specific scientific subdomains, including details on the simulation task, the accuracy or evaluation results, and any factors or variables identified as affecting simulation accuracy.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>iEvaLM</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>iEvaLM (LLM-based evaluation approach for conversational recommendation)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An approach that leverages large language models as generative user simulators to evaluate conversational recommender systems, enabling more natural, flexible, and human-like offline evaluations via instruction-following LLMs.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Evaluating large language models as generative user simulators for conversational recommendation.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>scientific_subdomain</strong></td>
                            <td>Conversational Recommender Systems (CRSs) / System evaluation</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_task</strong></td>
                            <td>Use LLM(s) as generative user simulators to produce simulated user utterances, personalization requests, and feedback to evaluate CRS behaviour across multi-turn dialogues.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>Evaluation focused on behavioral and qualitative aspects such as item diversity, alignment with human preferences, request personalization, and feedback coherence; no single numeric accuracy metric reported in the review.</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_accuracy</strong></td>
                            <td>Not reported as numeric accuracy in this review; improvements in aspects like item diversity and alignment with human preferences are asserted when using careful prompting and model selection, but no concrete accuracy/F1/AUC numbers included.</td>
                        </tr>
                        <tr>
                            <td><strong>factors_affecting_accuracy</strong></td>
                            <td>['Prompt engineering and the choice of LLM (careful prompting and model selection improve outcomes)', 'LLM limitations such as hallucination and weaknesses in causal reasoning', "Mismatch between LLM world-knowledge breadth and typical human cognitive scope (producing 'cognitive supermen')", 'Neglect of explicit behavioral modeling (simulators operating in text semantic space rather than behavioral semantics)']</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Compared qualitatively against classical static user simulators (rule-based/toolkit simulators) and human evaluation; LLM-based simulators enable more generative and flexible utterances but are not declared as numerically superior on standard metrics in this review.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Intrinsic limitations uncovered in follow-up analytical validation studies: hallucinations, poor causal reasoning, over-broad knowledge leading to unrealistic simulated users, and gaps between textual semantics and real user behavior which reduce reliability for evaluation/emprical conclusions.</td>
                        </tr>
                        <tr>
                            <td><strong>author_recommendations_or_insights</strong></td>
                            <td>Recommend careful prompt design and model selection; acknowledge that LLM-based simulators cannot fully replace human subjects; further analytical validation and enhanced solutions are needed to mitigate intrinsic LLM limitations.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A Literature Review on Simulation in Conversational Recommender Systems', 'publication_date_yy_mm': '2025-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9158.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e9158.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLMs being used as text-based simulators in specific scientific subdomains, including details on the simulation task, the accuracy or evaluation results, and any factors or variables identified as affecting simulation accuracy.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>UsimAgent / Usimagent</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Usimagent: Large language models for simulating search users</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A referenced work that applies LLMs to simulate search users (information retrieval domain), demonstrating use of LLMs as text-based agents in search/user-behavior simulation outside recommendation.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Usimagent: Large language models for simulating search users.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>scientific_subdomain</strong></td>
                            <td>Information retrieval / Search user simulation</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_task</strong></td>
                            <td>Simulate search users' queries and interactions with search systems (text-based user-behavior generation for search evaluation).</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>Not specified in the review; the review only cites the paper as an example of LLM-based user simulation in search.</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_accuracy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>factors_affecting_accuracy</strong></td>
                            <td>['General LLM-related issues noted in review (hallucination, reasoning limits, gap between text semantics and behavioral semantics)', 'Prompting and model selection (implied by review discussion of LLM-based simulators)']</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Not specified in the review; referenced as part of broader LLM-based simulation literature in information access systems.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Not detailed in the review beyond the general limitations of LLM-based simulators (e.g., hallucination, behavioral-semantic gap).</td>
                        </tr>
                        <tr>
                            <td><strong>author_recommendations_or_insights</strong></td>
                            <td>Inclusion here serves to indicate that LLM-based text simulation is being applied beyond recommendation (to search); the review suggests further domain-specific validation is necessary.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A Literature Review on Simulation in Conversational Recommender Systems', 'publication_date_yy_mm': '2025-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9158.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e9158.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLMs being used as text-based simulators in specific scientific subdomains, including details on the simulation task, the accuracy or evaluation results, and any factors or variables identified as affecting simulation accuracy.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LLM-based simulations (general)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>LLM-based user and data simulations across domains (economic, information access, gaming, agent-based behavior)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>The review notes broad adoption of LLMs as text-based simulators across multiple scientific subdomains — including economic/social simulation, information access (recommendation and search), and gaming/agent-based human behavior — offering high-fidelity, reproducibility, and low-cost experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>scientific_subdomain</strong></td>
                            <td>Multiple: economic/social simulation, information access (recommendation/search), gaming, agent-based human behavior</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_task</strong></td>
                            <td>Text-based simulation of agents, users, and dialogues for empirical or experimental studies (e.g., role-playing users in CRSs, simulating societal/economic agents, gaming agents).</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>Varies by referenced study; review does not report specific unified metrics — emphasizes fidelity, reproducibility, flexibility, and low cost as qualitative evaluation aspects.</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_accuracy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>factors_affecting_accuracy</strong></td>
                            <td>['Domain complexity and unique action spaces of different scenarios (movie recommendation vs. other domains)', 'LLM innate limitations (hallucination, causal reasoning deficits)', 'Prompt template design and manual prompt dependence', 'Seed data bias and its propagation', 'Need for multi-modal modeling in some applications']</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Compared conceptually to traditional rule-based or algorithmic user simulators and to real-user/human-in-the-loop evaluations; LLM-based sims trade some realism in behavioral semantics for scalability and flexibility.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Cannot fully replace real users; produce unrealistic 'cognitive supermen' relative to typical human knowledge; output hallucination and reasoning failures; neglect of explicit behavioral modeling reduces reliability for empirical claims.</td>
                        </tr>
                        <tr>
                            <td><strong>author_recommendations_or_insights</strong></td>
                            <td>Advocate for domain-specific validation, incorporation of multi-modal signals where needed, better prompt/template automation, and integration of behavioral modeling to reduce the semantic-behavior gap.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A Literature Review on Simulation in Conversational Recommender Systems', 'publication_date_yy_mm': '2025-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9158.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e9158.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLMs being used as text-based simulators in specific scientific subdomains, including details on the simulation task, the accuracy or evaluation results, and any factors or variables identified as affecting simulation accuracy.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>WWW '24 analysis (How reliable is your simulator?)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>How reliable is your simulator? analysis on the limitations of current llm-based user simulators for conversational recommendation</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A study (referenced in the review) that analytically validates and diagnoses intrinsic limitations of LLM-based user simulators in CRSs and proposes improvements.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>How reliable is your simulator? analysis on the limitations of current llm-based user simulators for conversational recommendation.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>scientific_subdomain</strong></td>
                            <td>Conversational Recommender Systems (CRSs) / Evaluation methodologies</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_task</strong></td>
                            <td>Analytical validation of LLM-based user simulators' fidelity and limitations for CRS evaluation (diagnostic study rather than generation task).</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>Analytical and diagnostic metrics (not numerically specified in the review); aimed at identifying failure modes and reliability limits of LLM-based simulators.</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_accuracy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>factors_affecting_accuracy</strong></td>
                            <td>['Intrinsic LLM limitations (hallucination, causal reasoning weaknesses)', 'Mismatch between LLM textual outputs and real behavioral patterns', 'Over-generalized knowledge in LLMs vs. typical human cognitive scope']</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>This work is presented as a critical analysis of LLM-based simulators compared to expectations from human-based evaluation and traditional simulators; the review reports it uncovered intrinsic limitations and proposed enhanced solutions.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Identifies intrinsic limitations and reliability concerns for LLM-based simulators; specifics are described in the original paper (referenced) rather than quantified in this review.</td>
                        </tr>
                        <tr>
                            <td><strong>author_recommendations_or_insights</strong></td>
                            <td>Calls for analytical validation of LLM-based simulators, improved solutions to address hallucination/causal reasoning, and caution when using LLM-based simulators for empirical CRS research.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A Literature Review on Simulation in Conversational Recommender Systems', 'publication_date_yy_mm': '2025-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9158.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e9158.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLMs being used as text-based simulators in specific scientific subdomains, including details on the simulation task, the accuracy or evaluation results, and any factors or variables identified as affecting simulation accuracy.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>WWW '25 framework (controllable, scalable, human-involved)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>A LLM-based controllable, scalable, human-involved user simulator framework for conversational recommender systems</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A referenced framework that aims to make LLM-based CRS user simulators controllable and scalable while allowing human involvement, addressing some concerns in prior LLM-simulation work.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>A llm-based controllable, scalable, human-involved user simulator framework for conversational recommender systems.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>scientific_subdomain</strong></td>
                            <td>Conversational Recommender Systems (CRSs) / Simulation frameworks</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_task</strong></td>
                            <td>Provide a controllable and scalable LLM-based user-simulation infrastructure with human involvement for CRS evaluation and development.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>Not specified in the review excerpt; framework is positioned to improve controllability, scalability, and human-in-the-loop aspects of simulators.</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_accuracy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>factors_affecting_accuracy</strong></td>
                            <td>['Human-in-the-loop design choices', 'Controllability mechanisms and the extent of manual prompt engineering', 'Scalability trade-offs when integrating LLMs into evaluation pipelines']</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Presented as an advance over static, fixed-action-set simulators by adding controllability and human involvement; review does not provide numeric comparisons.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Not detailed in the review beyond general LLM simulator limitations; framework seeks to mitigate some known issues (scalability, controllability, human oversight).</td>
                        </tr>
                        <tr>
                            <td><strong>author_recommendations_or_insights</strong></td>
                            <td>Suggests combining human oversight with LLM generative capabilities to improve simulator utility and reliability; indicates directions for making LLM simulators more practical for CRS evaluation.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'A Literature Review on Simulation in Conversational Recommender Systems', 'publication_date_yy_mm': '2025-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>LLM-REDIAL: A largescale dataset for conversational recommender systems created from user behaviors with LLMs. <em>(Rating: 2)</em></li>
                <li>Evaluating large language models as generative user simulators for conversational recommendation. <em>(Rating: 2)</em></li>
                <li>Usimagent: Large language models for simulating search users. <em>(Rating: 2)</em></li>
                <li>How reliable is your simulator? analysis on the limitations of current llm-based user simulators for conversational recommendation. <em>(Rating: 2)</em></li>
                <li>A llm-based controllable, scalable, human-involved user simulator framework for conversational recommender systems. <em>(Rating: 2)</em></li>
                <li>User behavior simulation with large language model-based agents. <em>(Rating: 2)</em></li>
                <li>Generative agents: Interactive simulacra of human behavior. <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-9158",
    "paper_id": "paper-280000744",
    "extraction_schema_id": "extraction-schema-161",
    "extracted_data": [
        {
            "name_short": "LLM-REDIAL",
            "name_full": "LLM-REDIAL: A large-scale dataset for conversational recommender systems created from user behaviors with LLMs",
            "brief_description": "An LLM-based data-simulation pipeline that generates multi-turn conversational recommendation dialogues and feedback using instruction templates and per-turn goals to ensure semantic consistency; used to produce a large synthetic CRS dataset at low monetary cost.",
            "citation_title": "LLM-REDIAL: A largescale dataset for conversational recommender systems created from user behaviors with LLMs.",
            "mention_or_use": "use",
            "model_name": null,
            "model_description": null,
            "scientific_subdomain": "Conversational Recommender Systems (CRSs) / Information access (recommendation)",
            "simulation_task": "Generate multi-turn conversational recommendation dialogues and recommendation feedback (text-based user-system interactions) from seed user-behavior data using instruction templates and assigned turn-level goals.",
            "evaluation_metric": "Descriptive quality metrics reported in the review (scale: number of dialogues/utterances; text diversity and dialogue quality assertions); cost-per-conversation comparison to crowdsourcing. No explicit numerical ML accuracy metrics reported in the review.",
            "simulation_accuracy": "Not reported as a numerical accuracy value in this review; reported outcomes: dataset of 47.6k multi-turn dialogues, 482.6k utterances across 4 domains; described improvements in scale, text diversity, and dialogue quality compared to prior dataset (REDIAL).",
            "factors_affecting_accuracy": [
                "Bias propagation from seed datasets used to prompt/generate synthetic dialogues",
                "Prompt template design (manual templates limit output flexibility)",
                "Semantic inconsistency and dataset inextensibility in original/crowdsourced datasets",
                "Gap between text semantic space (LLM output) and real behavioral semantics of users"
            ],
            "comparison_baseline": "Compared qualitatively and economically to REDIAL (crowdsourced dataset): REDIAL produced &gt;10k dialogues via AMT (~$1 per conversation cost reported), while LLM-REDIAL produced 47.6k dialogues for a total cost of $750; described as higher scale and diversity but no direct numeric performance comparison on predictive tasks reported in review.",
            "limitations_or_failure_cases": "No numeric accuracy given; reported limitations include propagation of seed-dataset bias into synthetic data, limited output flexibility from manual prompt templates, and the semantic gap between LLM text outputs and real user behavioral semantics.",
            "author_recommendations_or_insights": "Authors highlight benefits of cost and scale but caution about bias propagation and prompt-dependence; suggest introducing multi-modal considerations where applicable and improving prompt/template flexibility to better match real user behavior.",
            "uuid": "e9158.0",
            "source_info": {
                "paper_title": "A Literature Review on Simulation in Conversational Recommender Systems",
                "publication_date_yy_mm": "2025-06"
            }
        },
        {
            "name_short": "iEvaLM",
            "name_full": "iEvaLM (LLM-based evaluation approach for conversational recommendation)",
            "brief_description": "An approach that leverages large language models as generative user simulators to evaluate conversational recommender systems, enabling more natural, flexible, and human-like offline evaluations via instruction-following LLMs.",
            "citation_title": "Evaluating large language models as generative user simulators for conversational recommendation.",
            "mention_or_use": "use",
            "model_name": null,
            "model_description": null,
            "scientific_subdomain": "Conversational Recommender Systems (CRSs) / System evaluation",
            "simulation_task": "Use LLM(s) as generative user simulators to produce simulated user utterances, personalization requests, and feedback to evaluate CRS behaviour across multi-turn dialogues.",
            "evaluation_metric": "Evaluation focused on behavioral and qualitative aspects such as item diversity, alignment with human preferences, request personalization, and feedback coherence; no single numeric accuracy metric reported in the review.",
            "simulation_accuracy": "Not reported as numeric accuracy in this review; improvements in aspects like item diversity and alignment with human preferences are asserted when using careful prompting and model selection, but no concrete accuracy/F1/AUC numbers included.",
            "factors_affecting_accuracy": [
                "Prompt engineering and the choice of LLM (careful prompting and model selection improve outcomes)",
                "LLM limitations such as hallucination and weaknesses in causal reasoning",
                "Mismatch between LLM world-knowledge breadth and typical human cognitive scope (producing 'cognitive supermen')",
                "Neglect of explicit behavioral modeling (simulators operating in text semantic space rather than behavioral semantics)"
            ],
            "comparison_baseline": "Compared qualitatively against classical static user simulators (rule-based/toolkit simulators) and human evaluation; LLM-based simulators enable more generative and flexible utterances but are not declared as numerically superior on standard metrics in this review.",
            "limitations_or_failure_cases": "Intrinsic limitations uncovered in follow-up analytical validation studies: hallucinations, poor causal reasoning, over-broad knowledge leading to unrealistic simulated users, and gaps between textual semantics and real user behavior which reduce reliability for evaluation/emprical conclusions.",
            "author_recommendations_or_insights": "Recommend careful prompt design and model selection; acknowledge that LLM-based simulators cannot fully replace human subjects; further analytical validation and enhanced solutions are needed to mitigate intrinsic LLM limitations.",
            "uuid": "e9158.1",
            "source_info": {
                "paper_title": "A Literature Review on Simulation in Conversational Recommender Systems",
                "publication_date_yy_mm": "2025-06"
            }
        },
        {
            "name_short": "UsimAgent / Usimagent",
            "name_full": "Usimagent: Large language models for simulating search users",
            "brief_description": "A referenced work that applies LLMs to simulate search users (information retrieval domain), demonstrating use of LLMs as text-based agents in search/user-behavior simulation outside recommendation.",
            "citation_title": "Usimagent: Large language models for simulating search users.",
            "mention_or_use": "mention",
            "model_name": null,
            "model_description": null,
            "scientific_subdomain": "Information retrieval / Search user simulation",
            "simulation_task": "Simulate search users' queries and interactions with search systems (text-based user-behavior generation for search evaluation).",
            "evaluation_metric": "Not specified in the review; the review only cites the paper as an example of LLM-based user simulation in search.",
            "simulation_accuracy": null,
            "factors_affecting_accuracy": [
                "General LLM-related issues noted in review (hallucination, reasoning limits, gap between text semantics and behavioral semantics)",
                "Prompting and model selection (implied by review discussion of LLM-based simulators)"
            ],
            "comparison_baseline": "Not specified in the review; referenced as part of broader LLM-based simulation literature in information access systems.",
            "limitations_or_failure_cases": "Not detailed in the review beyond the general limitations of LLM-based simulators (e.g., hallucination, behavioral-semantic gap).",
            "author_recommendations_or_insights": "Inclusion here serves to indicate that LLM-based text simulation is being applied beyond recommendation (to search); the review suggests further domain-specific validation is necessary.",
            "uuid": "e9158.2",
            "source_info": {
                "paper_title": "A Literature Review on Simulation in Conversational Recommender Systems",
                "publication_date_yy_mm": "2025-06"
            }
        },
        {
            "name_short": "LLM-based simulations (general)",
            "name_full": "LLM-based user and data simulations across domains (economic, information access, gaming, agent-based behavior)",
            "brief_description": "The review notes broad adoption of LLMs as text-based simulators across multiple scientific subdomains — including economic/social simulation, information access (recommendation and search), and gaming/agent-based human behavior — offering high-fidelity, reproducibility, and low-cost experiments.",
            "citation_title": "",
            "mention_or_use": "mention",
            "model_name": null,
            "model_description": null,
            "scientific_subdomain": "Multiple: economic/social simulation, information access (recommendation/search), gaming, agent-based human behavior",
            "simulation_task": "Text-based simulation of agents, users, and dialogues for empirical or experimental studies (e.g., role-playing users in CRSs, simulating societal/economic agents, gaming agents).",
            "evaluation_metric": "Varies by referenced study; review does not report specific unified metrics — emphasizes fidelity, reproducibility, flexibility, and low cost as qualitative evaluation aspects.",
            "simulation_accuracy": null,
            "factors_affecting_accuracy": [
                "Domain complexity and unique action spaces of different scenarios (movie recommendation vs. other domains)",
                "LLM innate limitations (hallucination, causal reasoning deficits)",
                "Prompt template design and manual prompt dependence",
                "Seed data bias and its propagation",
                "Need for multi-modal modeling in some applications"
            ],
            "comparison_baseline": "Compared conceptually to traditional rule-based or algorithmic user simulators and to real-user/human-in-the-loop evaluations; LLM-based sims trade some realism in behavioral semantics for scalability and flexibility.",
            "limitations_or_failure_cases": "Cannot fully replace real users; produce unrealistic 'cognitive supermen' relative to typical human knowledge; output hallucination and reasoning failures; neglect of explicit behavioral modeling reduces reliability for empirical claims.",
            "author_recommendations_or_insights": "Advocate for domain-specific validation, incorporation of multi-modal signals where needed, better prompt/template automation, and integration of behavioral modeling to reduce the semantic-behavior gap.",
            "uuid": "e9158.3",
            "source_info": {
                "paper_title": "A Literature Review on Simulation in Conversational Recommender Systems",
                "publication_date_yy_mm": "2025-06"
            }
        },
        {
            "name_short": "WWW '24 analysis (How reliable is your simulator?)",
            "name_full": "How reliable is your simulator? analysis on the limitations of current llm-based user simulators for conversational recommendation",
            "brief_description": "A study (referenced in the review) that analytically validates and diagnoses intrinsic limitations of LLM-based user simulators in CRSs and proposes improvements.",
            "citation_title": "How reliable is your simulator? analysis on the limitations of current llm-based user simulators for conversational recommendation.",
            "mention_or_use": "use",
            "model_name": null,
            "model_description": null,
            "scientific_subdomain": "Conversational Recommender Systems (CRSs) / Evaluation methodologies",
            "simulation_task": "Analytical validation of LLM-based user simulators' fidelity and limitations for CRS evaluation (diagnostic study rather than generation task).",
            "evaluation_metric": "Analytical and diagnostic metrics (not numerically specified in the review); aimed at identifying failure modes and reliability limits of LLM-based simulators.",
            "simulation_accuracy": null,
            "factors_affecting_accuracy": [
                "Intrinsic LLM limitations (hallucination, causal reasoning weaknesses)",
                "Mismatch between LLM textual outputs and real behavioral patterns",
                "Over-generalized knowledge in LLMs vs. typical human cognitive scope"
            ],
            "comparison_baseline": "This work is presented as a critical analysis of LLM-based simulators compared to expectations from human-based evaluation and traditional simulators; the review reports it uncovered intrinsic limitations and proposed enhanced solutions.",
            "limitations_or_failure_cases": "Identifies intrinsic limitations and reliability concerns for LLM-based simulators; specifics are described in the original paper (referenced) rather than quantified in this review.",
            "author_recommendations_or_insights": "Calls for analytical validation of LLM-based simulators, improved solutions to address hallucination/causal reasoning, and caution when using LLM-based simulators for empirical CRS research.",
            "uuid": "e9158.4",
            "source_info": {
                "paper_title": "A Literature Review on Simulation in Conversational Recommender Systems",
                "publication_date_yy_mm": "2025-06"
            }
        },
        {
            "name_short": "WWW '25 framework (controllable, scalable, human-involved)",
            "name_full": "A LLM-based controllable, scalable, human-involved user simulator framework for conversational recommender systems",
            "brief_description": "A referenced framework that aims to make LLM-based CRS user simulators controllable and scalable while allowing human involvement, addressing some concerns in prior LLM-simulation work.",
            "citation_title": "A llm-based controllable, scalable, human-involved user simulator framework for conversational recommender systems.",
            "mention_or_use": "mention",
            "model_name": null,
            "model_description": null,
            "scientific_subdomain": "Conversational Recommender Systems (CRSs) / Simulation frameworks",
            "simulation_task": "Provide a controllable and scalable LLM-based user-simulation infrastructure with human involvement for CRS evaluation and development.",
            "evaluation_metric": "Not specified in the review excerpt; framework is positioned to improve controllability, scalability, and human-in-the-loop aspects of simulators.",
            "simulation_accuracy": null,
            "factors_affecting_accuracy": [
                "Human-in-the-loop design choices",
                "Controllability mechanisms and the extent of manual prompt engineering",
                "Scalability trade-offs when integrating LLMs into evaluation pipelines"
            ],
            "comparison_baseline": "Presented as an advance over static, fixed-action-set simulators by adding controllability and human involvement; review does not provide numeric comparisons.",
            "limitations_or_failure_cases": "Not detailed in the review beyond general LLM simulator limitations; framework seeks to mitigate some known issues (scalability, controllability, human oversight).",
            "author_recommendations_or_insights": "Suggests combining human oversight with LLM generative capabilities to improve simulator utility and reliability; indicates directions for making LLM simulators more practical for CRS evaluation.",
            "uuid": "e9158.5",
            "source_info": {
                "paper_title": "A Literature Review on Simulation in Conversational Recommender Systems",
                "publication_date_yy_mm": "2025-06"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "LLM-REDIAL: A largescale dataset for conversational recommender systems created from user behaviors with LLMs.",
            "rating": 2,
            "sanitized_title": "llmredial_a_largescale_dataset_for_conversational_recommender_systems_created_from_user_behaviors_with_llms"
        },
        {
            "paper_title": "Evaluating large language models as generative user simulators for conversational recommendation.",
            "rating": 2,
            "sanitized_title": "evaluating_large_language_models_as_generative_user_simulators_for_conversational_recommendation"
        },
        {
            "paper_title": "Usimagent: Large language models for simulating search users.",
            "rating": 2,
            "sanitized_title": "usimagent_large_language_models_for_simulating_search_users"
        },
        {
            "paper_title": "How reliable is your simulator? analysis on the limitations of current llm-based user simulators for conversational recommendation.",
            "rating": 2,
            "sanitized_title": "how_reliable_is_your_simulator_analysis_on_the_limitations_of_current_llmbased_user_simulators_for_conversational_recommendation"
        },
        {
            "paper_title": "A llm-based controllable, scalable, human-involved user simulator framework for conversational recommender systems.",
            "rating": 2,
            "sanitized_title": "a_llmbased_controllable_scalable_humaninvolved_user_simulator_framework_for_conversational_recommender_systems"
        },
        {
            "paper_title": "User behavior simulation with large language model-based agents.",
            "rating": 2,
            "sanitized_title": "user_behavior_simulation_with_large_language_modelbased_agents"
        },
        {
            "paper_title": "Generative agents: Interactive simulacra of human behavior.",
            "rating": 1,
            "sanitized_title": "generative_agents_interactive_simulacra_of_human_behavior"
        }
    ],
    "cost": 0.01216775,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>A Literature Review on Simulation in Conversational Recommender Systems
25 Jun 2025</p>
<p>Haoran Zhang 
Tianjin University</p>
<p>Xin Zhao 
University of Electronic Science
Technology of China</p>
<p>Jinze Chen 
University of Washington</p>
<p>Junpeng Guo 
Tianjin University</p>
<p>Tianjin University
TianjinChina</p>
<p>A Literature Review on Simulation in Conversational Recommender Systems
25 Jun 2025ED625AB774DBFC16C345DC0F9F5740D610.1177/ToBeAssignedarXiv:2506.20291v1[cs.HC]Conversational recommender systemsSimulationHuman-computer interactionLiterature review
Conversational Recommender Systems (CRSs) have garnered attention as a novel approach to delivering personalized recommendations through multi-turn dialogues.This review developed a taxonomy framework to systematically categorize relevant publications into four groups: dataset construction, algorithm design, system evaluation, and empirical studies, providing a comprehensive analysis of simulation methods in CRSs research.Our analysis reveals that simulation methods play a key role in tackling CRSs' main challenges.For example, LLM-based simulation methods have been used to create conversational recommendation data, enhance CRSs algorithms, and evaluate CRSs.Despite several challenges, such as dataset bias, the limited output flexibility of LLM-based simulations, and the gap between text semantic space and behavioral semantics, persist due to the complexity in Human-Computer Interaction (HCI) of CRSs, simulation methods hold significant potential for advancing CRS research.This review offers a thorough summary of the current research landscape in this domain and identifies promising directions for future inquiry.</p>
<p>Introduction</p>
<p>CRSs are recommendation task-oriented information access systems that primarily interact with users through dialogue.Unlike conventional Recommender Systems (RSs), which may rely on static user data and profiles, CRSs can extract users' precise and fine-grained preferences through multi-turn conversations.Furthermore, CRSs differ from conventional dialogue systems (such as chit-chat systems) in their focus on delivering personalized recommendations.As depicted in Figure 1a, research on CRSs has garnered substantial attention in recent years, largely due to advancements in natural language processing and the emergence of pre-trained language models.CRSs possess the following characteristics: (1) System Architecture.As depicted in Figure 1b, current CRSs architectures are primarily categorized into two types: pipeline and end-to-end models.Despite the elegance of end-to-end CRSs, the isolation between dialogue and recommendation tasks complicates the construction of a unified end-to-end model.We do not rule out the possibility of future research to build a more effective unified model, but most current CRSs are pipeline-based.</p>
<p>(2) Complex Interaction.HCI in CRSs inherits all forms and properties of conventional RSs and dialogue systems, including conversations, clicks, multi-turn interactions, etc., thereby increasing complexity.(3) Vague Ground Truth.In CRSs, clear ground truth is almost non-existent.Systems must optimize within users' near-infinite dialogue content and preference states [1].These characteristics present significant research challenges for CRSs in data, algorithms, evaluation, and empirical research.Simulation methods, including data and user simulations, offer effective solutions to these challenges.In addition, several recent studies have begun to leverage the capabilities of large language models (LLMs) to develop CRS simulations [1,2,3].Given this emerging trend, we argue that summarizing the current research progress in this area is timely and essential.</p>
<p>A series of CRSs-focused reviews are related to our work, but most were completed before the remarkable progress of pre-trained language models [4,5,6], so they missed the phase of rapid development of CRSs driven by LLMs.The remaining relevant studies either centred on CRSs evaluation but ignored simulation methods [7], or covered user simulation for evaluating information access systems but couldn't focus on our topic [8].In short, no literature has deeply and systematically summarized simulation methods and their applications in CRSs, to our knowledge.Thus, our Literature Review aims to address two key issues:</p>
<p>(1) What is the role of simulation methods in CRSs research?</p>
<p>(2) What are the challenges and opportunities in existing studies?</p>
<p>Method</p>
<p>First, we conducted a title keyword search for "conversation<em> recommend</em>" across the dblp computer science bibliography.After removing preprints and duplicates, 447 relevant published articles on CRSs were retained.These</p>
<p>Findings</p>
<p>Simulation in CRSs Datasets Construction</p>
<p>Data serves as a foundational component of intelligent systems research.While conventional RSs and dialogue systems benefit from established benchmarking datasets, CRSs specific datasets remain critically underdeveloped [5].This methodological gap systematically constrains progress in both scholarly understanding and technical innovation within the domain.Not until 2018 was the first publicly available large-scale CRSs-specific dataset, REDIAL [19], constructed.REDIAL collected data via Amazon Mechanical Turk (AMT) in a crowdsourced manner, comprising over 10,000 real world recommendation centered dialogues from 956 users.Prior to REDIAL, most CRSs research data was synthesized from conventional recommendation, everyday conversations, or shopping reviews datasets [20].These synthetic datasets, either manually created or auto-generated [21], were mostly rigid and inflexible.Although REDIAL's data, collected via crowdsourcing, was not gathered in real CRS settings, its real-human-generated dialogues and interactions provide greater flexibility and authenticity.Consequently, following REDIAL, more crowdsourced datasets have emerged, including topic guided and oriented multitype dialogs, covering various recommendation scenarios like movies and restaurants, among others [4].</p>
<p>However, due to technological advancements and the growing data volume and quality requirements in CRSs research, datasets like REDIAL are no longer considered "large scale" and fail to meet the demands of datadriven system research, let alone real-world industrial applications.Most existing CRSs datasets suffer from data inextensibility and semantic inconsistency.Additionally, the cost of building datasets through crowdsourcing is rising sharply.</p>
<p>Generative models, particularly LLMs, exhibit superior capabilities in text understanding, dialogue generation, and role playing [22].Recently, some studies have employed LLM-based simulation methods to create conversational recommendation data, such as LLM-REDIAL [3].LLM-REDIAL generates multi-turn dialogues and recommendation feedback through instruction templates, assigning each dialogue turn a goal to ensure semantic consistency.The resulting synthetic dataset shows remarkable improvements in scale, text diversity, and dialogue quality.Moreover, LLMbased synthetic CRSs data offers significant cost advantages.For comparison, each conversation in REDIAL costs $1, excluding data processing and labeling expenses.In contrast, LLM-REDIAL, comprising 47.6k multi-turn dialogues with 482.6k utterances across 4 domains, only costs $750 in total.</p>
<p>Simulation in CRSs Algorithm Design</p>
<p>Studies in this category directly use simulation methods to address algorithmic issues in CRSs.For example, CFCRS enhances CRSs through counterfactual data augmentation [10].It leverages counterfactual learning to augment user preferences and uses the augmented preferences to simulate conversational data.CFCRS also performs interventions on the representations of target users' interacted entities and employs an adversarial training method with a curriculum schedule.This approach gradually optimizes the edit function, improving the recommendation capacity of CRSs.The User-centric User Simulator with Fuzzy Feedback (UUSFF) is a simulation framework that models user responses more naturally by incorporating fuzzy feedback based on users' inherent preferences [11].This framework allows users to respond to attribute questions based on both the attribute-item relations of the target item and their long-term interests in related items.Integrated into the Multi-Interest Multi-Round conversational recommendation framework, UUSFF enhances the effectiveness of the recommendation algorithm.</p>
<p>Simulation in CRSs Evaluation</p>
<p>Complexity challenges of CRSs Evaluation RSs are typically evaluated through three approaches: online evaluation (or human evaluation), offline evaluation, and user simulation.Online evaluation, considered the most ideal, is conducted in real-world settings using controlled experiments (A/B test) or quasi-experiments to assess algorithm performance and effectiveness.However, it faces significant challenges.The real environment is only accessible to a small number of researchers, and experiment deployment can negatively impact user experience, potentially eroding consumer trust, while also being costly and risky.Laboratory experiments, an alternative to online evaluation, use human subjects (not necessarily real users) without requiring a real environment, such as via AMT.Yet, this method faces issues with data quality control and still struggles with the scalecost balance.Offline evaluation, the most common method in algorithm and intelligent system research, uses publicly available offline datasets and computational metrics without actual deployment or human participants.This simplicity, however, comes at the cost of reduced validity, especially for CRSs.</p>
<p>Unlike the mature evaluation protocols and methods for conventional RSs and conventional dialogue systems, no consensus has been reached for CRSs evaluation.This is due to the complexity of CRSs.Firstly, conversational recommendation incorporates more direct user experience elements [23].Secondly, the interaction between users and the system is multi-turn and diverse.This complexity accentuates the high costs and ethical risks of online and laboratory experiments.It also exacerbates the limitations of single round evaluations and fixed ground truth in offline experiments.</p>
<p>User simulation in CRSs evaluation</p>
<p>In tackling the complexity challenges outlined in Section 3.3.1,a burgeoning area of research has centered on the development of user simulation methodologies for the evaluation of CRSs.User simulation leverages rule-based or algorithm-based user models to replicate authentic user interactions and feedback within offline settings.This approach offers significant advantages in terms of cost-effectiveness, flexibility, and adaptability, attributes that have propelled its growing prominence in the realm of information access system research [8].Krisztian Balog's team has made pioneering contributions to the evaluation of CRSs through user simulation.Their approach involves agenda-based simulation, which decomposes simulated users into four distinct modules: Natural Language Understanding (NLU), Natural Language Generation (NLG), preference model, and interaction model.The dialogue process is modeled as a Markov Decision Process (MDP), with a specifically designed CIR6 model for simulating the user's action space.This framework was initially applied to CRSs evaluation [12], and later evolved into UserSimCRS [14], the first comprehensive simulation-based evaluation toolkit in this field.Expanding on their foundational work in user simulation, the researchers further investigated user utterance reformulation and CRSs breakdowns.They recognized that user simulators have limited robustness when the system fails to understand generated user utterances.To tackle this issue, they conducted a user study to capture real users' reformulation patterns and integrated these insights into a user simulator [13].They defined CRSs Breakdowns as system failures, unexpected or irrelevant replies, which can disrupt conversation flow.To enhance system robustness against such breakdowns, the team developed a diagnostic and development tool aimed at improving CRSs [15].</p>
<p>The evaluation of CRSs primarily centers on humancomputer interaction, unlike conventional RSs.Current user simulators have limitations in that they are static, restricted to fixed action sets, and lack generative capabilities.The advent of LLMs has opened up new possibilities for user simulation.iEvaLM represents the first approach to employ LLMs for evaluating CRSs [2].By leveraging LLMs' remarkable instruction-following abilities, it devises user simulators, thereby liberating CRSs from rigid, human-crafted dialogue constraints and facilitating more natural and human-like interactions.Additionally, novel evaluation protocols have been put forward to gauge the accuracy of language models in mimicking human behavior within conversational recommendation settings (Yoon et al., 2024).These studies reveal that through careful prompting and model selection, improvements can be achieved in aspects such as item diversity, alignment with human preferences, request personalization, and feedback coherence.Furthermore, certain research endeavors have incorporated linguistic methods into CRS evaluation and developed LLM-based user simulators for assessment purposes [16], highlighting the multidisciplinary nature of CRSs evaluation.</p>
<p>Simulation in CRSs Empirical Study User simulations can be utilized in experimental or empirical research for CRSs.For instance, given that simulation evaluation methodologies are still in a state of development, certain studies have directed their attention toward evaluating simulation methods based on LLMs.One such investigation, building upon the iEvaLM framework, executed an analytical validation study [18].It uncovered intrinsic limitations associated with employing LLMs to develop user simulators for CRSs and consequently put forward an enhanced solution.</p>
<p>Due to field experiments' constraints, such as cost, ethical risks, and counterfactuals, using simulated users for empirical research has long appealed to the RSs [24].The remarkable role-playing capabilities LLMs have revitalized the simulation of human behavior [22].Recently, there has been extensive research on LLM-based simulations across various domains, including economic society, information access systems (encompassing recommendation and search), and gaming [25,26,27,28].This approach offers high fidelity, reproducibility, flexibility, low cost, and minimal ethical risks.Therefore, implementing LLM-based user simulations in CRSs environments could better explore general or specific empirical or experimental issues in recommendation.For instance, it could examine how emotions are transmitted between users and systems in CRSs.</p>
<p>Challenges and Opportunities</p>
<p>In the research on simulation for CRSs, challenges and opportunities are intertwined.For dataset construction and algorithm design focused on data simulation, the main challenge is the bias in seed datasets and its propagation during simulation.The advent of LLMs hasn't fully resolved this issue.In order to make the simulation system close to the real environment, multi-modal considerations need to be introduced in some application scenarios [29].Moreover, prompt templates in LLM-based simulations mostly depend on manual design, limiting output flexibility.Furthermore, a crucial challenge in algorithm design lies in the tight integration of simulation with recommendation processes.This integration should offer extra information and a correction basis for algorithm training while minimizing impact on efficiency, especially when LLMs are deployed.</p>
<p>In the research on system evaluation and empirical study in CRSs, user simulations, especially those based on LLMs, have certain advantages but still cannot directly replace real users.A common challenge is that LLM technology is still evolving.Most LLMs exhibit struggles with hallucination and causal reasoning.Existing LLM outputs are based on the text semantic space, and current simulations often neglect user behavior modeling.The gap between the text semantic space and behavioral semantics challenges the reliability of LLM-based behavior simulations.Although pre-trained LLMs are known for their world knowledge, most real users have a cognitive scope that cannot match this breadth.LLM-based user simulations often produce "cognitive supermen," leading to inaccurate evaluation and empirical research conclusions.Combining dialogue and recommendation areas makes it difficult to establish a universally accepted, unified evaluation protocol.Compared to current research that focuses on movie recommendations, simulations need to consider more diverse recommendation scenarios with unique logic and action spaces [30].User simulations should also evolve from single-mode text-based interactions to multi-mode simulations for better alignment with real users.</p>
<p>Conclusion</p>
<p>We systematically examined simulation methods and their applications in CRSs.Our findings reveal that, within CRSs research, the significance of static offline data is gradually being supplanted by interactive simulation environments.As technology evolves, to meet the requirements of datasets construction, evaluation protocols, and empirical research in CRSs, researchers are striving to strike a balance between costly yet authentic human participation and limited but simple offline data.Presently, despite numerous controversies and challenges, simulation seems to be the most promising path forward.</p>
<p>( a )
a
Development Trend and Key Time Nodes of CRSs.(b) Technical Architecture of CRSs.</p>
<p>Figure 1 .
1
Figure 1.The Current State of Research in CRSs (The statistics of the publications are as of July 1, 2025).</p>
<p>Table 1 .
1
Simulation Methods in CRSs -Taxonomy Framework.
TopicsPublicationSourceYearMain contributionDatasets Construction[3]ACL24A large-scale CRSs dataset constructed by leveraging LLMs.[9]ACL24A Review-Driven Persona-Knowledge GroundedConversational Recommendation Dataset.Algorithm Design[10] [11]KDD ACM ToRS23 24Counterfactual data augmentation for CRSs. User simulator with fuzzy feedback.[12]KDD20The first user simulation framework for CRSsevaluation, alternative of human evaluation.[13]SIGIR22Focus on simulating user utterances in CRSs.System Evaluation[14] [2]WSDM EMNLP23 23An extensible user simulation toolkit. The first LLM-based user simulator for CRSsevaluation.[15]CUI24Focus on robustness and effectiveness.[1]NAACL24The first evaluation protocol for LLM-based usersimulation in CRSs.[16]UMUAI24Use simulator to investigate the quality of thetheoretical background.[17]WWW25Emphasize the Controllability, Scalability,Human-Involves of user simulation.Empirical Study[18]WWW24Evaluate the evaluation methods for usersimulators based on LLMs.articles cover key themes in CRSs research. Through iter-ative screening based on relevance criteria, 11 publications
directly addressing simulation in CRSs were identified.To systematize findings, we developed a taxonomy framework aligned with core research objectives, organizing CRSs studies into four categories: (1) datasets construction, (2) algorithm design, (3) system evaluation, and (4) empirical studies.These 11 articles were mapped onto the framework to illustrate how simulation methods function across different research domains, as detailed in Table1.</p>
<p>Prepared using sagej.cls [Version: 2017/01/17 v1.20]
Prepared using sagej.cls
AcknowledgementsThis study is supported by the National Natural Science Foundation of China (No.72171165).
Evaluating large language models as generative user simulators for conversational recommendation. Yoon Se, Z He, J Echterhoff, 10.18653/v1/2024.naacl-long.83Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. Long Papers. the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language TechnologiesMexico City, MexicoAssociation for Computational Linguistics1</p>
<p>Rethinking the evaluation for conversational recommendation in the era of large language models. X Wang, X Tang, X Zhao, 10.18653/v1/2023.emnlp-main.621Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing. the 2023 Conference on Empirical Methods in Natural Language ProcessingSingaporeAssociation for Computational Linguistics</p>
<p>LLM-REDIAL: A largescale dataset for conversational recommender systems created from user behaviors with LLMs. T Liang, Jin C Wang, L , 10.18653/v1/2024.findings-acl.529Findings of the Association for Computational Linguistics: ACL 2024. Bangkok, ThailandAssociation for Computational Linguistics</p>
<p>Advances and challenges in conversational recommender systems: A survey. C Gao, W Lei, X He, 10.1016/j.aiopen.2021.06.002AI Open. 22021</p>
<p>Evaluating conversational recommender systems. D Jannach, 10.1007/s10462-022-10229-xArtificial Intelligence Review. 5632023</p>
<p>Conversational recommender systems techniques, tools, acceptance, and adoption: A state of the art review. D Pramod, P Bafna, 10.1016/j.eswa.2022.117539Expert Systems with Applications. 2031175392022</p>
<p>Conversational recommendation: A grand ai challenge. D Jannach, L Chen, 10.1002/aaai.12059AI Magazine. 4322022</p>
<p>User simulation for evaluating information access systems. K Balog, C Zhai, 10.1561/1500000098Foundations and Trends® in Information Retrieval. 181-22024</p>
<p>Pearl: A review-driven persona-knowledge grounded conversational recommendation dataset. M Kim, M Kim, Kim Bw, Hana Nd, Kwak , 10.18653/v1/2024.findings-acl.65Findings of the Association for Computational Linguistics: ACL 2024. Bangkok, ThailandAssociation for Computational Linguistics</p>
<p>Improving conversational recommendation systems via counterfactual data simulation. X Wang, K Zhou, X Tang, 10.1145/3580305.3599387Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining. KDD '23. the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining. KDD '23New York, NY, USAAssociation for Computing Machinery. ISBN 9798400701030</p>
<p>Multi-interest multiround conversational recommendation system with fuzzy feedback based user simulator. Q Shen, L Wu, Y Zhang, 10.1145/3616379ACM Trans Recomm Syst. 242024</p>
<p>Evaluating conversational recommender systems via user simulation. S Zhang, K Balog, 10.1145/3394486.3403202Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining. KDD '20. the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining. KDD '20New York, NY, USAAssociation for Computing Machinery</p>
<p>Analyzing and simulating user utterance reformulation in conversational recommender systems. S Zhang, Wang Mc, K Balog, 10.1145/3477495.3531936Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval. SIGIR '22. the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval. SIGIR '22New York, NY, USAAssociation for Computing Machinery. ISBN 9781450387323</p>
<p>Usersimcrs: A user simulation toolkit for evaluating conversational recommender systems. J Afzali, A M Drzewiecki, K Balog, 10.1145/3539597.3573029Proceedings of the Sixteenth ACM International Conference on Web Search and Data Mining. WSDM '23. the Sixteenth ACM International Conference on Web Search and Data Mining. WSDM '23New York, NY, USAAssociation for Computing Machinery</p>
<p>Identifying breakdowns in conversational recommender systems using user simulation. N Bernard, K Balog, 10.1145/3640794.3665539Proceedings of the 6th ACM Conference on Conversational User Interfaces. CUI '24. the 6th ACM Conference on Conversational User Interfaces. CUI '24New York, NY, USAAssociation for Computing Machinery9798400705113</p>
<p>Linguisticsbased dialogue simulations to evaluate argumentative conversational recommender systems. Di Bratto, M Origlia, A , Di Maro, M , 10.1007/s11257-024-09403-3User Modeling and User-Adapted Interaction. 3452024</p>
<p>A llm-based controllable, scalable, human-involved user simulator framework for conversational recommender systems. L Zhu, X Huang, Sang J , 10.1145/3696410.3714858Proceedings of the ACM on Web Conference 2025. WWW '25. the ACM on Web Conference 2025. WWW '25New York, NY, USAAssociation for Computing Machinery</p>
<p>How reliable is your simulator? analysis on the limitations of current llm-based user simulators for conversational recommendation. L Zhu, X Huang, Sang J , 10.1145/3589335.3651955Companion Proceedings of the ACM Web Conference 2024. WWW '24. New York, NY, USAAssociation for Computing Machinery</p>
<p>Towards deep conversational recommendations. R Li, S Kahou, H Schulz, Proceedings of the 32nd International Conference on Neural Information Processing Systems. NIPS '18. the 32nd International Conference on Neural Information Processing Systems. NIPS '18Red Hook, NY, USACurran Associates Inc</p>
<p>Towards conversational search and recommendation: System ask, user respond. Y Zhang, X Chen, Ai Q , 10.1145/3269206.3271776Proceedings of the 27th ACM International Conference on Information and Knowledge Management. CIKM '18. the 27th ACM International Conference on Information and Knowledge Management. CIKM '18New York, NY, USAAssociation for Computing Machinery</p>
<p>An automatic procedure for generating datasets for conversational recommender systems. A Suglia, C Greco, P Basile, CEUR Workshop Proceedings. 2017. 1866</p>
<p>Prepared using sagej.cls. </p>
<p>Role play with large language models. M Shanahan, K Mcdonell, L Reynolds, 10.1038/s41586-023-06647-8Nature. 62379872023</p>
<p>Crs-que: A user-centric evaluation framework for conversational recommender systems. Y Jin, L Chen, W Cai, 10.1145/3631534ACM Trans Recomm Syst. 212024</p>
<p>Consumption and performance: Understanding longitudinal dynamics of recommender systems via an agent-based simulation framework. J Zhang, G Adomavicius, A Gupta, 10.1287/isre.2019.0876Information Systems Research. 3112020</p>
<p>Generative agents: Interactive simulacra of human behavior. J S Park, O 'brien, J Cai, C J , 10.1145/3586183.3606763Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology. UIST '23. the 36th Annual ACM Symposium on User Interface Software and Technology. UIST '23New York, NY, USAAssociation for Computing Machinery9798400701320</p>
<p>User behavior simulation with large language model-based agents. L Wang, J Zhang, H Yang, DOI:10.1145ACM Trans Inf Syst. 4322025</p>
<p>Usimagent: Large language models for simulating search users. E Zhang, X Wang, P Gong, 10.1145/3626772.3657963Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval. SIGIR '24. the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval. SIGIR '24New York, NY, USAAssociation for Computing Machinery9798400704314</p>
<p>How does search affect personalized recommendations and user behavior? evidence from llm-based synthetic data. H Zhang, X Kang, J Guo, 10.1145/3701716.3717530Companion Proceedings of the ACM on Web Conference 2025. WWW '25. New York, NY, USAAssociation for Computing Machinery</p>
<p>Muse: A multimodal conversational recommendation dataset with scenariogrounded user profiles. Z Wang, X Yang, Y Liu, 2025</p>
<p>What else would i like? a user simulator using alternatives for improved evaluation of fashion conversational recommendation systems. M Vlachou, C Macdonald, 2024</p>            </div>
        </div>

    </div>
</body>
</html>