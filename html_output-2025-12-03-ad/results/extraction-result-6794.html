<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-6794 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-6794</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-6794</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-131.html">extraction-schema-131</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' approaches to strict logical reasoning, including model details, reasoning methods, benchmarks, tasks, performance results, comparative findings, and noted limitations.</div>
                <p><strong>Paper ID:</strong> paper-249063060</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2205.12910v2.pdf" target="_blank">NaturalProver: Grounded Mathematical Proof Generation with Language Models</a></p>
                <p><strong>Paper Abstract:</strong> Theorem proving in natural mathematical language - the mixture of symbolic and natural language used by humans - plays a central role in mathematical advances and education, and tests aspects of reasoning that are core to intelligence. Yet it has remained underexplored with modern generative models. We study large-scale language models on two new generation tasks: suggesting the next step in a mathematical proof, and full proof generation. We develop NaturalProver, a language model that generates proofs by conditioning on background references (e.g. theorems and definitions that are either retrieved or human-provided), and optionally enforces their presence with constrained decoding. On theorems from the NaturalProofs benchmark, NaturalProver improves the quality of next-step suggestions and generated proofs over fine-tuned GPT-3, according to human evaluations from university-level mathematics students. NaturalProver is capable of proving some theorems that require short (2-6 step) proofs, and providing next-step suggestions that are rated as correct and useful over 40% of the time, which is to our knowledge the first demonstration of these capabilities using neural language models.</p>
                <p><strong>Cost:</strong> 0.018</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e6794.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e6794.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' approaches to strict logical reasoning, including model details, reasoning methods, benchmarks, tasks, performance results, comparative findings, and noted limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>NATURALPROVER</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>NATURALPROVER (knowledge‑grounded proof generation)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A fine‑tuned autoregressive language model pipeline that generates natural‑language mathematical proofs by conditioning on in‑context reference titles, learning to reconstruct reference content, and optionally enforcing reference usage with segment‑level constrained decoding (stepwise++). Evaluated on ProofWiki‑derived NATURALPROOFS‑GEN for next‑step suggestion and full proof generation.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-3 (Curie, fine-tuned)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Autoregressive transformer language model (OpenAI Curie engine) fine‑tuned on theorem→proof pairs and additional (title→content) reference reconstruction examples to associate reference titles with content.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>between ~6.7B and 13B (Curie; exact Curie size not public)</td>
                        </tr>
                        <tr>
                            <td><strong>architecture_type</strong></td>
                            <td>autoregressive transformer (GPT-3 family), no integrated symbolic prover</td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td>NATURALPROOFS-GEN (derived from ProofWiki): ~12.5k theorem→proof examples for fine‑tuning plus ~33k references (theorems/definitions) for reference‑reconstruction objective</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method</strong></td>
                            <td>Knowledge‑grounding via in‑context reference titles + reference reconstruction; segment‑level constrained decoding (stepwise++): multi‑temperature sampling of next proof steps, beam/clustering selection using a value function combining log‑probability and reference‑coverage constraints; alternative full‑proof sampling & reranking.</td>
                        </tr>
                        <tr>
                            <td><strong>external_tool_used</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>external_tool_description</strong></td>
                            <td>No external theorem prover or verifier is integrated. A separate pretrained retrieval model (from Welleck et al., 2021) is used to supply retrieved reference titles in the 'retrieved' setting, but this is a retrieval component, not a logical solver.</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>NATURALPROOFS-GEN (from NATURALPROOFS / ProofWiki)</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_description</strong></td>
                            <td>Natural mathematical language dataset of theorem statements, multi‑step proofs and references (definitions/theorems) collected from ProofWiki; examples are segmented into proof steps and include reference title mentions. Used for next‑step suggestion and full proof generation tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>Full proof generation (generate entire multi‑step natural language proof) and Next‑step suggestion (generate next proof step given theorem and proof history).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>Human evaluation: overall correctness/usefulness (0–5 scale interpreted as correct if ≥4, useful if ≥3); per‑step correctness/usefulness (yes/no). Automatic metrics: GLEU, token F1, reference Precision/Recall/F1 (Ref‑F1), Knowledge Token‑F1 (kF1).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>Best configuration (human‑provided references + stepwise++ = NATURALPROVER++): 32% of generated full proofs rated correct and 45% rated useful; per‑step: 35% correct, 47% useful. Next‑step suggestion (provided‑knowledge, greedy): 43% correct, 51% useful. Full‑proof correctness by length: 48% on 1–4 step proofs (n=102) vs 15.6% on ≥5 step proofs (n=64). Automatic grounding metrics (Ref‑F1) and GLEU improved under constrained decoding (exact metric tables in paper).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td>Substantially improves over vanilla fine‑tuned GPT‑3 (no knowledge conditioning): NATURALPROVER++ yields higher human‑rated correctness/usefulness and far fewer reference hallucinations; human‑provided references + constrained decoding give largest gains. Retrieved references also improve performance relative to no‑knowledge baseline and can approach human‑provided reference performance on some automatic metrics.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Conditioning on background references and learning to reconstruct reference content improves proof generation; enforcing reference presence via stepwise constrained decoding (stepwise++) further increases reference grounding and overall quality. NATURALPROVER can produce correct short proofs (2–6 steps) and useful next‑step suggestions at non‑trivial rates, demonstrating feasibility of language models as assistive tools for informal mathematical proofs.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Models still struggle with logical coherence on longer proofs (sharp drop in correctness for ≥5 steps), correct deployment and justification of references (reference error ≈23.6% of test steps), and symbolic/equation derivations (equation‑related error ≈28.5% of test steps; invalid derivations ≈21.9%). No formal verifier is used, so correctness is judged by humans and not mechanically guaranteed. Constrained decoding can trade off lexical fluency (GLEU) at very high constraint weights.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'NaturalProver: Grounded Mathematical Proof Generation with Language Models', 'publication_date_yy_mm': '2022-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6794.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e6794.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' approaches to strict logical reasoning, including model details, reasoning methods, benchmarks, tasks, performance results, comparative findings, and noted limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Baseline GPT-3 (fine‑tuned)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Vanilla fine‑tuned GPT-3 baseline</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A GPT‑3 Curie model fine‑tuned directly on theorem→proof pairs without conditioning on reference titles or reference reconstruction; used as a baseline to quantify benefits of knowledge grounding and constrained decoding.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Language Models are Few-Shot Learners</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-3 (Curie, fine-tuned)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Autoregressive transformer; fine‑tuned only on theorem→proof sequences without reference titles or reference reconstruction objective.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>between ~6.7B and 13B (Curie)</td>
                        </tr>
                        <tr>
                            <td><strong>architecture_type</strong></td>
                            <td>autoregressive transformer</td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td>Same NATURALPROOFS-GEN theorem→proof training split (no separate reference reconstruction examples in baseline).</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method</strong></td>
                            <td>Pure sequence modeling (autoregressive generation) without explicit knowledge grounding or constrained decoding.</td>
                        </tr>
                        <tr>
                            <td><strong>external_tool_used</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>external_tool_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>NATURALPROOFS-GEN (core validation/test sets used for comparison)</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_description</strong></td>
                            <td>See NATURALPROOFS-GEN description above.</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>Full proof generation and next‑step suggestion (evaluated as baseline).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>Human evaluation (correctness/usefulness), error type rates (reference hallucination, repetition, equation errors).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>Produced fewer useful and correct proofs compared to knowledge‑grounded models; observed severe reference hallucination (~18%) and high repetition (~23%); higher rates of reference and other reasoning errors (exact overall correctness % lower than NATURALPROVER; specific baseline correctness number not directly quoted).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td>This is the baseline; NATURALPROVER (knowledge grounding + constrained decoding) shows clear improvements over this model.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Fine‑tuning GPT‑3 on theorem→proof pairs alone is insufficient—models hallucinate references, repeat content, and make more reasoning errors compared to knowledge‑grounded variants.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>High hallucination and repetition; poor reference usage and justification; struggles to assemble multi‑step proofs reliably.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'NaturalProver: Grounded Mathematical Proof Generation with Language Models', 'publication_date_yy_mm': '2022-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6794.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e6794.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' approaches to strict logical reasoning, including model details, reasoning methods, benchmarks, tasks, performance results, comparative findings, and noted limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>NATURALPROVER_RETRIEVE</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>NATURALPROVER with retrieved references</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Variant of NATURALPROVER that conditions on the top‑20 reference titles retrieved by a pretrained retrieval model, simulating an automated assistant without human‑provided references.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-3 (Curie, fine-tuned)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Same autoregressive GPT‑3 Curie model fine‑tuned with reference‑title conditioning; uses external retrieval model at test time to supply reference titles.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>between ~6.7B and 13B (Curie)</td>
                        </tr>
                        <tr>
                            <td><strong>architecture_type</strong></td>
                            <td>autoregressive transformer + retrieval (context augmentation)</td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td>Fine‑tuned on NATURALPROOFS-GEN with reference‑title conditioned examples and reference reconstruction; retrieval model pretraining from Welleck et al. (2021).</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method</strong></td>
                            <td>Knowledge grounding via in‑context retrieved reference titles (no constrained decoding in retrieval setting due to noisy constraints); uses standard autoregressive decoding (greedy) or sampling for full proofs.</td>
                        </tr>
                        <tr>
                            <td><strong>external_tool_used</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>external_tool_description</strong></td>
                            <td>Uses an external pretrained retrieval model (from Welleck et al., 2021) to return top‑20 candidate reference titles for an input theorem; retrieval is used as context but no symbolic verifier is used.</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>NATURALPROOFS-GEN (retrieved‑reference evaluation setting)</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_description</strong></td>
                            <td>Same ProofWiki derived dataset; in this setting reference titles are supplied by an automated retriever rather than human gold references.</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>Full proof generation (automatic retrieval of references) and next‑step suggestion (retrieved references not used for stepwise constrained decoding in experiments).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>Human evaluation (correctness/usefulness) and automatic grounding/lexical metrics (Ref‑F1, GLEU, kF1).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>Retrieved knowledge improves proof generation versus no‑knowledge baseline and can be comparable to human‑provided references on some automatic metrics; decreases repetition and enables multi‑step derivations justified by references. Exact human‑rated correctness/usefulness numbers for this variant are reported as improvements over baseline but lower than human‑provided reference + stepwise++.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td>Better than no‑knowledge baseline; sometimes approaches human‑provided reference performance on automatic grounding metrics, but constrained decoding with gold references yields best human‑rated results.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Retrieval augmentation is a promising path toward fully automated natural‑language proof generation; the model can leverage noisy retrieved titles to assemble useful proofs.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Retrieved reference titles can be noisy, so constrained decoding was not used with retrieved references in experiments; performance depends on retrieval quality.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'NaturalProver: Grounded Mathematical Proof Generation with Language Models', 'publication_date_yy_mm': '2022-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6794.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e6794.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' approaches to strict logical reasoning, including model details, reasoning methods, benchmarks, tasks, performance results, comparative findings, and noted limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Stepwise++ Decoding</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Stepwise++ (segment‑level constrained decoding)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A segment‑level decoding/search algorithm that generates proofs step‑by‑step, sampling multiple candidate next steps with multiple temperatures and selecting clusters using a value function that combines model log‑probability and reference‑coverage constraints to approximate the objective of including all in‑context references.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>decoding algorithm (stepwise++)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Not a model parameterization but an inference procedure compatible with black‑box samplers (returns text and log‑probability); uses multi‑temperature sampling, beam of partial proofs, and cluster selection across different weights (α) of constraint vs LM score.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>architecture_type</strong></td>
                            <td>segment‑level constrained search (sampling + reranking), compatible with autoregressive models</td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method</strong></td>
                            <td>Constrained decoding that explicitly encourages inclusion of in‑context reference titles in generated proof steps; balances exploration (high temperature) and exploitation (low temperature) and trades off between likelihood and constraint satisfaction via a tunable value function.</td>
                        </tr>
                        <tr>
                            <td><strong>external_tool_used</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>external_tool_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>NATURALPROOFS-GEN (used in provided‑reference setting)</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_description</strong></td>
                            <td>See NATURALPROOFS‑GEN above.</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>Full proof generation (multi‑step natural language proofs); specifically designed for multi‑step generation where references should be used across steps.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>Automatic metrics: perplexity (PPL), Ref‑F1 (reference matching), GLEU; human evaluation correctness/usefulness.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>Stepwise++ produces higher reference coverage (Ref‑F1) and lower perplexity than greedy decoding and stepwise stochastic beam; constrained stepwise++ raised Ref‑F1 substantially (e.g., Ref‑F1 up to mid‑90s in some dev experiments) while preserving reasonable GLEU. Empirically contributed to the best human‑rated model NATURALPROVER++.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td>Approximates constrained objective better than greedy and improves grounding metrics vs stepwise stochastic beam search; a combination of multi‑temperature expansion and clustered selection yields best results in ablations.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Segment‑level constrained decoding is effective for enforcing lexical constraints (reference inclusion) in multi‑step proof generation and increases groundedness and human‑perceived correctness/usefulness.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Requires tuning (temperatures, α clusters, beam size) and is sensitive to noisy reference constraints (therefore not applied with retrieved references in experiments); high constraint weight can trade off lexical quality (GLEU). Computationally more expensive than greedy decoding.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'NaturalProver: Grounded Mathematical Proof Generation with Language Models', 'publication_date_yy_mm': '2022-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6794.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e6794.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' approaches to strict logical reasoning, including model details, reasoning methods, benchmarks, tasks, performance results, comparative findings, and noted limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Reference Reconstruction</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Reference reconstruction objective</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Auxiliary fine‑tuning objective that trains the model to map a reference title to its underlying textual content (title → content) so the generator can better associate in‑context reference titles with the associated statements and definitions.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>auxiliary training objective (reference reconstruction)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Not a separate model; an auxiliary supervised fine‑tuning task where the language model is trained to generate reference content conditioned on the reference title and type (theorem/definition/other).</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>architecture_type</strong></td>
                            <td>auxiliary conditional generation objective for an autoregressive transformer</td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td>Pairs of (reference title, reference content) from the ProofWiki reference set (~33k references)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method</strong></td>
                            <td>Enables the model to internalize content associated with reference titles so that conditioning on titles provides implicit access to reference content during proof generation.</td>
                        </tr>
                        <tr>
                            <td><strong>external_tool_used</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>external_tool_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>NATURALPROOFS-GEN training/reference set</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_description</strong></td>
                            <td>Same ProofWiki derived reference set; used to train the reconstruction mapping from title → content.</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>Auxiliary training; supports downstream proof generation tasks by improving utilization of in‑context titles.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>Automatic metrics (GLEU, Ref‑F1) and human evaluation improvements in content/reference usage.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>Ablation shows reference reconstruction improves content quality and reference usage (higher GLEU and Ref‑F1) compared to conditioning on titles alone without reconstruction.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td>Models with reference reconstruction outperform models conditioned on titles but without reconstruction (ablation in Table 7 shows gains).</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Learning to map titles to content helps the model better deploy references during proof generation and reduces reference errors/hallucinations.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Reconstruction does not eliminate reference deployment errors; models still commit nontrivial reference and justification mistakes (~23.6% reference error rate on test steps).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'NaturalProver: Grounded Mathematical Proof Generation with Language Models', 'publication_date_yy_mm': '2022-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6794.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e6794.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' approaches to strict logical reasoning, including model details, reasoning methods, benchmarks, tasks, performance results, comparative findings, and noted limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>NATURALPROOFS-GEN</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>NATURALPROOFS-GEN (ProofWiki derived generation dataset)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>The dataset used in this work, adapted from NATURALPROOFS (ProofWiki); contains theorem statements, multi‑step natural language proofs, and associated reference titles (theorems/definitions), split into training/dev/test with a held‑out evaluation core set.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Naturalproofs: Mathematical theorem proving in natural language</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>architecture_type</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>external_tool_used</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>external_tool_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>NATURALPROOFS-GEN (adapted from NATURALPROOFS / ProofWiki)</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_description</strong></td>
                            <td>Contains ~14.5k theorems paired with proofs, ~33k references (theorems/definitions/other), proofs segmented into steps; tasks: next‑step suggestion and full proof generation with optional provided reference titles (gold) or retrieved references.</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>Dataset for natural mathematical proof generation and next‑step suggestion</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>Dataset used to train/evaluate models; evaluation uses human annotations and automatic metrics as described above.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Enables evaluation of language models on grounded natural‑language mathematical proving; includes reference titles so that methods can condition on background knowledge.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Proof correctness must be assessed by humans (no formal verifier); dataset contains community‑authored proofs that sometimes contain errors, and proof step segmentation is derived from ProofWiki formatting which can vary.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'NaturalProver: Grounded Mathematical Proof Generation with Language Models', 'publication_date_yy_mm': '2022-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Naturalproofs: Mathematical theorem proving in natural language <em>(Rating: 2)</em></li>
                <li>Generative language modeling for automated theorem proving <em>(Rating: 2)</em></li>
                <li>Formal mathematics statement curriculum learning <em>(Rating: 2)</em></li>
                <li>Chain of thought prompting elicits reasoning in large language models <em>(Rating: 1)</em></li>
                <li>Training verifiers to solve math word problems <em>(Rating: 1)</em></li>
                <li>Retrieval augmentation reduces hallucination in conversation <em>(Rating: 1)</em></li>
                <li>ProofWriter: Generating implications, proofs, and abductive statements over natural language <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-6794",
    "paper_id": "paper-249063060",
    "extraction_schema_id": "extraction-schema-131",
    "extracted_data": [
        {
            "name_short": "NATURALPROVER",
            "name_full": "NATURALPROVER (knowledge‑grounded proof generation)",
            "brief_description": "A fine‑tuned autoregressive language model pipeline that generates natural‑language mathematical proofs by conditioning on in‑context reference titles, learning to reconstruct reference content, and optionally enforcing reference usage with segment‑level constrained decoding (stepwise++). Evaluated on ProofWiki‑derived NATURALPROOFS‑GEN for next‑step suggestion and full proof generation.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "GPT-3 (Curie, fine-tuned)",
            "model_description": "Autoregressive transformer language model (OpenAI Curie engine) fine‑tuned on theorem→proof pairs and additional (title→content) reference reconstruction examples to associate reference titles with content.",
            "model_size": "between ~6.7B and 13B (Curie; exact Curie size not public)",
            "architecture_type": "autoregressive transformer (GPT-3 family), no integrated symbolic prover",
            "training_data": "NATURALPROOFS-GEN (derived from ProofWiki): ~12.5k theorem→proof examples for fine‑tuning plus ~33k references (theorems/definitions) for reference‑reconstruction objective",
            "reasoning_method": "Knowledge‑grounding via in‑context reference titles + reference reconstruction; segment‑level constrained decoding (stepwise++): multi‑temperature sampling of next proof steps, beam/clustering selection using a value function combining log‑probability and reference‑coverage constraints; alternative full‑proof sampling & reranking.",
            "external_tool_used": false,
            "external_tool_description": "No external theorem prover or verifier is integrated. A separate pretrained retrieval model (from Welleck et al., 2021) is used to supply retrieved reference titles in the 'retrieved' setting, but this is a retrieval component, not a logical solver.",
            "benchmark_name": "NATURALPROOFS-GEN (from NATURALPROOFS / ProofWiki)",
            "benchmark_description": "Natural mathematical language dataset of theorem statements, multi‑step proofs and references (definitions/theorems) collected from ProofWiki; examples are segmented into proof steps and include reference title mentions. Used for next‑step suggestion and full proof generation tasks.",
            "task_type": "Full proof generation (generate entire multi‑step natural language proof) and Next‑step suggestion (generate next proof step given theorem and proof history).",
            "performance_metric": "Human evaluation: overall correctness/usefulness (0–5 scale interpreted as correct if ≥4, useful if ≥3); per‑step correctness/usefulness (yes/no). Automatic metrics: GLEU, token F1, reference Precision/Recall/F1 (Ref‑F1), Knowledge Token‑F1 (kF1).",
            "performance_value": "Best configuration (human‑provided references + stepwise++ = NATURALPROVER++): 32% of generated full proofs rated correct and 45% rated useful; per‑step: 35% correct, 47% useful. Next‑step suggestion (provided‑knowledge, greedy): 43% correct, 51% useful. Full‑proof correctness by length: 48% on 1–4 step proofs (n=102) vs 15.6% on ≥5 step proofs (n=64). Automatic grounding metrics (Ref‑F1) and GLEU improved under constrained decoding (exact metric tables in paper).",
            "comparison_with_baseline": "Substantially improves over vanilla fine‑tuned GPT‑3 (no knowledge conditioning): NATURALPROVER++ yields higher human‑rated correctness/usefulness and far fewer reference hallucinations; human‑provided references + constrained decoding give largest gains. Retrieved references also improve performance relative to no‑knowledge baseline and can approach human‑provided reference performance on some automatic metrics.",
            "key_findings": "Conditioning on background references and learning to reconstruct reference content improves proof generation; enforcing reference presence via stepwise constrained decoding (stepwise++) further increases reference grounding and overall quality. NATURALPROVER can produce correct short proofs (2–6 steps) and useful next‑step suggestions at non‑trivial rates, demonstrating feasibility of language models as assistive tools for informal mathematical proofs.",
            "limitations": "Models still struggle with logical coherence on longer proofs (sharp drop in correctness for ≥5 steps), correct deployment and justification of references (reference error ≈23.6% of test steps), and symbolic/equation derivations (equation‑related error ≈28.5% of test steps; invalid derivations ≈21.9%). No formal verifier is used, so correctness is judged by humans and not mechanically guaranteed. Constrained decoding can trade off lexical fluency (GLEU) at very high constraint weights.",
            "uuid": "e6794.0",
            "source_info": {
                "paper_title": "NaturalProver: Grounded Mathematical Proof Generation with Language Models",
                "publication_date_yy_mm": "2022-05"
            }
        },
        {
            "name_short": "Baseline GPT-3 (fine‑tuned)",
            "name_full": "Vanilla fine‑tuned GPT-3 baseline",
            "brief_description": "A GPT‑3 Curie model fine‑tuned directly on theorem→proof pairs without conditioning on reference titles or reference reconstruction; used as a baseline to quantify benefits of knowledge grounding and constrained decoding.",
            "citation_title": "Language Models are Few-Shot Learners",
            "mention_or_use": "use",
            "model_name": "GPT-3 (Curie, fine-tuned)",
            "model_description": "Autoregressive transformer; fine‑tuned only on theorem→proof sequences without reference titles or reference reconstruction objective.",
            "model_size": "between ~6.7B and 13B (Curie)",
            "architecture_type": "autoregressive transformer",
            "training_data": "Same NATURALPROOFS-GEN theorem→proof training split (no separate reference reconstruction examples in baseline).",
            "reasoning_method": "Pure sequence modeling (autoregressive generation) without explicit knowledge grounding or constrained decoding.",
            "external_tool_used": false,
            "external_tool_description": null,
            "benchmark_name": "NATURALPROOFS-GEN (core validation/test sets used for comparison)",
            "benchmark_description": "See NATURALPROOFS-GEN description above.",
            "task_type": "Full proof generation and next‑step suggestion (evaluated as baseline).",
            "performance_metric": "Human evaluation (correctness/usefulness), error type rates (reference hallucination, repetition, equation errors).",
            "performance_value": "Produced fewer useful and correct proofs compared to knowledge‑grounded models; observed severe reference hallucination (~18%) and high repetition (~23%); higher rates of reference and other reasoning errors (exact overall correctness % lower than NATURALPROVER; specific baseline correctness number not directly quoted).",
            "comparison_with_baseline": "This is the baseline; NATURALPROVER (knowledge grounding + constrained decoding) shows clear improvements over this model.",
            "key_findings": "Fine‑tuning GPT‑3 on theorem→proof pairs alone is insufficient—models hallucinate references, repeat content, and make more reasoning errors compared to knowledge‑grounded variants.",
            "limitations": "High hallucination and repetition; poor reference usage and justification; struggles to assemble multi‑step proofs reliably.",
            "uuid": "e6794.1",
            "source_info": {
                "paper_title": "NaturalProver: Grounded Mathematical Proof Generation with Language Models",
                "publication_date_yy_mm": "2022-05"
            }
        },
        {
            "name_short": "NATURALPROVER_RETRIEVE",
            "name_full": "NATURALPROVER with retrieved references",
            "brief_description": "Variant of NATURALPROVER that conditions on the top‑20 reference titles retrieved by a pretrained retrieval model, simulating an automated assistant without human‑provided references.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "GPT-3 (Curie, fine-tuned)",
            "model_description": "Same autoregressive GPT‑3 Curie model fine‑tuned with reference‑title conditioning; uses external retrieval model at test time to supply reference titles.",
            "model_size": "between ~6.7B and 13B (Curie)",
            "architecture_type": "autoregressive transformer + retrieval (context augmentation)",
            "training_data": "Fine‑tuned on NATURALPROOFS-GEN with reference‑title conditioned examples and reference reconstruction; retrieval model pretraining from Welleck et al. (2021).",
            "reasoning_method": "Knowledge grounding via in‑context retrieved reference titles (no constrained decoding in retrieval setting due to noisy constraints); uses standard autoregressive decoding (greedy) or sampling for full proofs.",
            "external_tool_used": false,
            "external_tool_description": "Uses an external pretrained retrieval model (from Welleck et al., 2021) to return top‑20 candidate reference titles for an input theorem; retrieval is used as context but no symbolic verifier is used.",
            "benchmark_name": "NATURALPROOFS-GEN (retrieved‑reference evaluation setting)",
            "benchmark_description": "Same ProofWiki derived dataset; in this setting reference titles are supplied by an automated retriever rather than human gold references.",
            "task_type": "Full proof generation (automatic retrieval of references) and next‑step suggestion (retrieved references not used for stepwise constrained decoding in experiments).",
            "performance_metric": "Human evaluation (correctness/usefulness) and automatic grounding/lexical metrics (Ref‑F1, GLEU, kF1).",
            "performance_value": "Retrieved knowledge improves proof generation versus no‑knowledge baseline and can be comparable to human‑provided references on some automatic metrics; decreases repetition and enables multi‑step derivations justified by references. Exact human‑rated correctness/usefulness numbers for this variant are reported as improvements over baseline but lower than human‑provided reference + stepwise++.",
            "comparison_with_baseline": "Better than no‑knowledge baseline; sometimes approaches human‑provided reference performance on automatic grounding metrics, but constrained decoding with gold references yields best human‑rated results.",
            "key_findings": "Retrieval augmentation is a promising path toward fully automated natural‑language proof generation; the model can leverage noisy retrieved titles to assemble useful proofs.",
            "limitations": "Retrieved reference titles can be noisy, so constrained decoding was not used with retrieved references in experiments; performance depends on retrieval quality.",
            "uuid": "e6794.2",
            "source_info": {
                "paper_title": "NaturalProver: Grounded Mathematical Proof Generation with Language Models",
                "publication_date_yy_mm": "2022-05"
            }
        },
        {
            "name_short": "Stepwise++ Decoding",
            "name_full": "Stepwise++ (segment‑level constrained decoding)",
            "brief_description": "A segment‑level decoding/search algorithm that generates proofs step‑by‑step, sampling multiple candidate next steps with multiple temperatures and selecting clusters using a value function that combines model log‑probability and reference‑coverage constraints to approximate the objective of including all in‑context references.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "decoding algorithm (stepwise++)",
            "model_description": "Not a model parameterization but an inference procedure compatible with black‑box samplers (returns text and log‑probability); uses multi‑temperature sampling, beam of partial proofs, and cluster selection across different weights (α) of constraint vs LM score.",
            "model_size": null,
            "architecture_type": "segment‑level constrained search (sampling + reranking), compatible with autoregressive models",
            "training_data": null,
            "reasoning_method": "Constrained decoding that explicitly encourages inclusion of in‑context reference titles in generated proof steps; balances exploration (high temperature) and exploitation (low temperature) and trades off between likelihood and constraint satisfaction via a tunable value function.",
            "external_tool_used": false,
            "external_tool_description": null,
            "benchmark_name": "NATURALPROOFS-GEN (used in provided‑reference setting)",
            "benchmark_description": "See NATURALPROOFS‑GEN above.",
            "task_type": "Full proof generation (multi‑step natural language proofs); specifically designed for multi‑step generation where references should be used across steps.",
            "performance_metric": "Automatic metrics: perplexity (PPL), Ref‑F1 (reference matching), GLEU; human evaluation correctness/usefulness.",
            "performance_value": "Stepwise++ produces higher reference coverage (Ref‑F1) and lower perplexity than greedy decoding and stepwise stochastic beam; constrained stepwise++ raised Ref‑F1 substantially (e.g., Ref‑F1 up to mid‑90s in some dev experiments) while preserving reasonable GLEU. Empirically contributed to the best human‑rated model NATURALPROVER++.",
            "comparison_with_baseline": "Approximates constrained objective better than greedy and improves grounding metrics vs stepwise stochastic beam search; a combination of multi‑temperature expansion and clustered selection yields best results in ablations.",
            "key_findings": "Segment‑level constrained decoding is effective for enforcing lexical constraints (reference inclusion) in multi‑step proof generation and increases groundedness and human‑perceived correctness/usefulness.",
            "limitations": "Requires tuning (temperatures, α clusters, beam size) and is sensitive to noisy reference constraints (therefore not applied with retrieved references in experiments); high constraint weight can trade off lexical quality (GLEU). Computationally more expensive than greedy decoding.",
            "uuid": "e6794.3",
            "source_info": {
                "paper_title": "NaturalProver: Grounded Mathematical Proof Generation with Language Models",
                "publication_date_yy_mm": "2022-05"
            }
        },
        {
            "name_short": "Reference Reconstruction",
            "name_full": "Reference reconstruction objective",
            "brief_description": "Auxiliary fine‑tuning objective that trains the model to map a reference title to its underlying textual content (title → content) so the generator can better associate in‑context reference titles with the associated statements and definitions.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "auxiliary training objective (reference reconstruction)",
            "model_description": "Not a separate model; an auxiliary supervised fine‑tuning task where the language model is trained to generate reference content conditioned on the reference title and type (theorem/definition/other).",
            "model_size": null,
            "architecture_type": "auxiliary conditional generation objective for an autoregressive transformer",
            "training_data": "Pairs of (reference title, reference content) from the ProofWiki reference set (~33k references)",
            "reasoning_method": "Enables the model to internalize content associated with reference titles so that conditioning on titles provides implicit access to reference content during proof generation.",
            "external_tool_used": false,
            "external_tool_description": null,
            "benchmark_name": "NATURALPROOFS-GEN training/reference set",
            "benchmark_description": "Same ProofWiki derived reference set; used to train the reconstruction mapping from title → content.",
            "task_type": "Auxiliary training; supports downstream proof generation tasks by improving utilization of in‑context titles.",
            "performance_metric": "Automatic metrics (GLEU, Ref‑F1) and human evaluation improvements in content/reference usage.",
            "performance_value": "Ablation shows reference reconstruction improves content quality and reference usage (higher GLEU and Ref‑F1) compared to conditioning on titles alone without reconstruction.",
            "comparison_with_baseline": "Models with reference reconstruction outperform models conditioned on titles but without reconstruction (ablation in Table 7 shows gains).",
            "key_findings": "Learning to map titles to content helps the model better deploy references during proof generation and reduces reference errors/hallucinations.",
            "limitations": "Reconstruction does not eliminate reference deployment errors; models still commit nontrivial reference and justification mistakes (~23.6% reference error rate on test steps).",
            "uuid": "e6794.4",
            "source_info": {
                "paper_title": "NaturalProver: Grounded Mathematical Proof Generation with Language Models",
                "publication_date_yy_mm": "2022-05"
            }
        },
        {
            "name_short": "NATURALPROOFS-GEN",
            "name_full": "NATURALPROOFS-GEN (ProofWiki derived generation dataset)",
            "brief_description": "The dataset used in this work, adapted from NATURALPROOFS (ProofWiki); contains theorem statements, multi‑step natural language proofs, and associated reference titles (theorems/definitions), split into training/dev/test with a held‑out evaluation core set.",
            "citation_title": "Naturalproofs: Mathematical theorem proving in natural language",
            "mention_or_use": "use",
            "model_name": null,
            "model_description": null,
            "model_size": null,
            "architecture_type": null,
            "training_data": null,
            "reasoning_method": null,
            "external_tool_used": null,
            "external_tool_description": null,
            "benchmark_name": "NATURALPROOFS-GEN (adapted from NATURALPROOFS / ProofWiki)",
            "benchmark_description": "Contains ~14.5k theorems paired with proofs, ~33k references (theorems/definitions/other), proofs segmented into steps; tasks: next‑step suggestion and full proof generation with optional provided reference titles (gold) or retrieved references.",
            "task_type": "Dataset for natural mathematical proof generation and next‑step suggestion",
            "performance_metric": "Dataset used to train/evaluate models; evaluation uses human annotations and automatic metrics as described above.",
            "performance_value": null,
            "comparison_with_baseline": null,
            "key_findings": "Enables evaluation of language models on grounded natural‑language mathematical proving; includes reference titles so that methods can condition on background knowledge.",
            "limitations": "Proof correctness must be assessed by humans (no formal verifier); dataset contains community‑authored proofs that sometimes contain errors, and proof step segmentation is derived from ProofWiki formatting which can vary.",
            "uuid": "e6794.5",
            "source_info": {
                "paper_title": "NaturalProver: Grounded Mathematical Proof Generation with Language Models",
                "publication_date_yy_mm": "2022-05"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Naturalproofs: Mathematical theorem proving in natural language",
            "rating": 2,
            "sanitized_title": "naturalproofs_mathematical_theorem_proving_in_natural_language"
        },
        {
            "paper_title": "Generative language modeling for automated theorem proving",
            "rating": 2,
            "sanitized_title": "generative_language_modeling_for_automated_theorem_proving"
        },
        {
            "paper_title": "Formal mathematics statement curriculum learning",
            "rating": 2,
            "sanitized_title": "formal_mathematics_statement_curriculum_learning"
        },
        {
            "paper_title": "Chain of thought prompting elicits reasoning in large language models",
            "rating": 1,
            "sanitized_title": "chain_of_thought_prompting_elicits_reasoning_in_large_language_models"
        },
        {
            "paper_title": "Training verifiers to solve math word problems",
            "rating": 1,
            "sanitized_title": "training_verifiers_to_solve_math_word_problems"
        },
        {
            "paper_title": "Retrieval augmentation reduces hallucination in conversation",
            "rating": 1,
            "sanitized_title": "retrieval_augmentation_reduces_hallucination_in_conversation"
        },
        {
            "paper_title": "ProofWriter: Generating implications, proofs, and abductive statements over natural language",
            "rating": 1,
            "sanitized_title": "proofwriter_generating_implications_proofs_and_abductive_statements_over_natural_language"
        }
    ],
    "cost": 0.017755999999999997,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>NATURALPROVER: Grounded Mathematical Proof Generation with Language Models
31 Oct 2022</p>
<p>Sean Welleck wellecks@uw.edu 
Paul G. Allen School of Computer Science &amp; Engineering
University of Washington</p>
<p>Allen Institute for Artificial Intelligence</p>
<p>Equal contribution</p>
<p>Jiacheng Liu 
Paul G. Allen School of Computer Science &amp; Engineering
University of Washington</p>
<p>Equal contribution</p>
<p>Ximing Lu 
Allen Institute for Artificial Intelligence</p>
<p>Hannaneh Hajishirzi 
Paul G. Allen School of Computer Science &amp; Engineering
University of Washington</p>
<p>Allen Institute for Artificial Intelligence</p>
<p>Yejin Choi 
Paul G. Allen School of Computer Science &amp; Engineering
University of Washington</p>
<p>Allen Institute for Artificial Intelligence</p>
<p>NATURALPROVER: Grounded Mathematical Proof Generation with Language Models
31 Oct 2022A49E8DDBDA20B30775A778D802F338AAarXiv:2205.12910v2[cs.CL]
Theorem proving in natural mathematical language -the mixture of symbolic and natural language used by humans -plays a central role in mathematical advances and education, and tests aspects of reasoning that are core to intelligence.Yet it has remained underexplored with modern generative models.We study largescale language models on two new generation tasks: suggesting the next step in a mathematical proof, and full proof generation.We develop NATURALPROVER, a language model that generates proofs by conditioning on background references (e.g.theorems and definitions that are either retrieved or human-provided), and optionally enforces their presence with constrained decoding.On theorems from the NATURALPROOFS benchmark, NATURALPROVER improves the quality of next-step suggestions and generated proofs over fine-tuned GPT-3, according to human evaluations from university-level mathematics students.NATURALPROVER is capable of proving some theorems that require short (2-6 step) proofs, and providing next-step suggestions that are rated as correct and useful over 40% of the time, which is to our knowledge the first demonstration of these capabilities using neural language models. 1 Figure 1: NATURALPROVER proves Even Integer Plus 5 is Odd.At training time, NATURALPROVER obtains background knowledge about references (e.g.theorems or definitions) via reference reconstruction: learning to map a reference's title to its content.At test time, NATURALPROVER grounds its generations through in-context reference constraints that are retrieved or human-provided, and optionally enforced with stepwise constrained decoding.This theorem's human-written proof in ProofWiki contains an error and differs substantially from NATURALPROVER's correct proof. 1 Code and data available at https://github.com/wellecks/naturalprover.</p>
<p>Introduction</p>
<p>Constructing a rational argument that justifies a claim is a key aspect of explaining, verifying, and communicating ideas in situations ranging from everyday interactions, to legal and political discourse, to science and mathematics [Davis and Hersh, 1981, Voss and Means, 1991, Kaye, 1992].Within the latter context, a mathematical proof -a sequence of logical arguments expressed in a mixture of symbolic and natural language -assumes this role by providing justification and insight into why a claim is true [ de Villiers, 1990].Proofs operate on a relatively explicit and objective set of ground knowledge, isolating a subset of reasoning that is desirable for models that form the foundation of machine learning systems [Bommasani et al., 2021].Moreover, we envision assistive systems that provide suggested proofs or next-steps, analogous to language-model-based code suggestions (e.g.GitHub CoPilot [Chen et al., 2021]) or formal proof assistants (e.g.GPT-f [Han et al., 2021a]), which could make learning or using mathematics more productive and accessible.</p>
<p>To this end, we study the capabilities of large-scale language models (e.g.GPT-3 Brown et al. [2020]) on two new theorem proving tasks in natural mathematical language: next-step suggestion, in which a model suggests the next step of a proof, and full-proof generation, in which a model fully proves a claim.As proofs are grounded in knowledge from past results (e.g.theorems, definitions), analogous to facts deployed in a conversation [Dinan et al., 2019], prior rulings used in a legal opinion [Erik G. Jensen, 2014], or articles used to justify an answer [Nakano et al., 2021], we develop a methodology for obtaining and using background knowledge to prove theorems with a generic language model.We develop NATURALPROVER, a language model that generates proofs by conditioning on background references (e.g.theorems and definitions that are either retrieved or human-provided), and optionally enforces their presence with a constrained decoding algorithm that leverages the multi-step structure of proofs.On a collection of theorems from the NATURALPROOFS benchmark [Welleck et al., 2021], NATURALPROVER improves the quality of next-step suggestions and generated proofs over fine-tuned GPT-3, according to human evaluations from university-level mathematics students.NATURALPROVER is capable of proving some theorems that require short (2-6 step) proofs, and providing next-step suggestions that are rated as correct and useful more than 40% of the time, which is to our knowledge the first demonstration of these capabilities using neural language models.</p>
<p>Along with these successes, we study deficiencies in our current models.We find that models can struggle with logical coherence on longer proofs, with providing valid justifications, and with performing multi-step symbolic derivations.Taken together, our tasks, methodology, and evaluation show the feasibility of language models as interactive aids in mathematics, along with open challenges.</p>
<p>NATURALPROOFS-GEN Dataset and Tasks</p>
<p>We create a NATURALPROOFS-GEN dataset adapted from NATURALPROOFS [Welleck et al., 2021], and use the dataset for two tasks: suggesting the next step of a proof, and fully proving a theorem.NATURALPROOFS-GEN.NATURALPROOFS-GEN adapts data from NATURALPROOFS, which contains theorem statements, proofs, definitions, and additional pages (e.g.axioms, corollaries) sourced from ProofWiki, an online compendium of community-contributed mathematical proofs.In NATURALPROOFS-GEN, each example (x, y) ∈ D pairs a theorem x with a gold proof y, both of which are a mixture of text and L A T E X. Welleck et al. [2021] split the examples and reference sets into training, dev, and test splits to ensure that no theorem in the dev or test splits was mentioned in the training split.We adopt these splits of roughly 12.5k training, 1k validation, and 1k test examples, and sampled core evaluation sets with 100 dev and 100 test theorems that are used for human evaluation.The proofs contain additional structure, discussed next.</p>
<p>Multi-step proof structure.Each proof has a multi-step structure, meaning that a proof y = (y 1 , . . ., y |y| ) is a variable-length token sequence that is segmented into proof steps, where each step y t is itself a variable-length sequence of tokens (either text or Latex).The segmentation is largely determined by ProofWiki's formatting and community standards for structuring proofs, and we additionally merge steps to ensure that each step contains non-trivial semantic content.For example, Figure 1 shows a 4-step (generated) proof with each step highlighted in green.</p>
<p>References.Each proof mentions a variable-number of references {r 1 , . . ., r Ry } from a set R of roughly 33k theorems and definitions, analogous to how Wikipedia articles reference other pages.</p>
<p>For example, Figure 1 shows a proof with reference mentions in blue.Each mention identifies a reference by its title and provides a natural language surface form.For instance, in Figure 1, the first proof step mentions the definition of even integer as even, which is formatted in the proof as [[Definition:Even_Integer|even]] and tokenized along with the rest of the proof.</p>
<p>Tasks.We consider two tasks that are motivated by an assistive system that provides suggested proofs or next-steps to a user.The full proof generation task is to generate a proof y given a theorem x.The next-step suggestion task is to generate a set of next steps {y k t } K k=1 given theorem x and proof history y &lt;t from a gold proof.In each case, we consider an additional provided reference setting where the model is also given the set of references {r * 1 , . . ., r * Ry } from a gold proof of the theorem.The next-step task simulates a human correctly proving the theorem up to a point, then querying a system for suggested next-steps when stuck, while the provided reference setting simulates a human specifying a plan for a system that writes a proof.</p>
<p>NATURALPROVER: Grounded Proof Generation via Language Modeling</p>
<p>We describe NATURALPROVER, a language model which generates grounded proofs by conditioning on references and optionally enforcing their presence with constrained decoding.</p>
<p>Setup.Our objective is to generate correct proofs, ŷ = arg max y correct(x, y).Unfortunately, evaluating proof correctness is costly, and is only done once at test time.A naive approach is to approximate the objective, ŷ ≈ arg max y log p θ (y|x), by fine-tuning a language model p θ on (x, y) examples and using a decoding algorithm (e.g.greedy decoding).We instead investigate conditioning on background knowledge in the form of reference documents, p θ (y|x, R), which is beneficial in related generation settings (e.g.Shuster et al. [2021]), and offers control over the generated proof.To do so, NATURALPROVER uses in-context references and a reference reconstruction objective.</p>
<p>In-context references.Language models have a limited context window that prevents conditioning on full documents.Instead, NATURALPROVER conditions on a set of reference titles, p θ (y|x, R title ).Concretely, we fine-tune on (theorem, reference titles, proof) sequences of the form, <theorem> <title> {theorem-title} </title> <content> {theorem-content} </content> </theorem> <ref> {ref-title-1} </ref> ... <ref> {ref-title-R} </ref> <proof> {proof} </proof></p>
<p>(1) with new-lines and {} tokens omitted, relevant strings inserted, and loss only on tokens after <proof>.</p>
<p>Reference reconstruction.Reference titles do not capture all of the information contained in the reference documents.We learn a mapping between each reference title and its underlying document with a reference reconstruction objective, p θ (r|r title ) for references r in the training reference set.Concretely, we fine-tune on additional (title, content) pairs of the form,
&lt;{type}&gt; <title> {title} </title> <content> {content} </content> &lt;/{type}&gt;,(2)
where the {type} is theorem/definition/other, and the loss is only on tokens after <content>.Intuitively, this lets the model associate each reference title with the reference's underlying content.</p>
<p>The joint objective.For training, we minimize the joint loss,
L(θ) = 1 |D train | + |R train | (x,y)∈D train − log p θ (y|x, R title ) + r∈R train − log p θ (r|r title ) .
(3)</p>
<p>Evaluation-time references.We consider two settings for evaluation-time references: (i) retrieved references, from a retrieval model f (x) → {r 1 , . . ., r k }, and (ii) human-provided references from the ground-truth proof.The retrieval setting simulates a fully automated proof assistant, while the second simulates a human specifying a plan for an assistant that writes a proof, and acts as an upper bound for a retrieval system optimized to predict references in a ground-truth proof.</p>
<p>Stepwise constrained decoding</p>
<p>In the provided-reference setting, the conditioned references are known to be relevant to a correct proof.We hypothesize that explicitly encouraging generated proofs to contain the references will improve correctness, by placing lexical constraints on the reference-titles at decoding time,
ŷ ≈ arg max y log p θ (y|x, R title ), subject to rtitle∈Rtitle I [r title ∈ y] = |R title |,(4)
where I [•] is an indicator function.To approximate this objective, we generate step-by-step by sampling multiple proof-step candidates, retaining those with high value (reference coverage and log-probability) in a beam, and continuing to the next step, which we call stepwise beam search.</p>
<p>Value function.The search supports any function of the proof-so-far, v(y ≤t ) → R. We use a value function that is a weighted combination of constraint satisfaction and log-probability,
v α (y ≤t ) = αv constraint (y ≤t ) + (1 − α)v LM (y ≤t ),(5)
where v constraint (y ≤t ) is the number of unique in-context reference-titles in y ≤t , and v LM (y ≤t ) is log p θ (y ≤t ).We normalize each term by dividing by the maximum absolute value among candidates.</p>
<p>Stepwise beam search.The procedure generates a proof y = (y 1 , . . ., y T ) by iteratively sampling and pruning next-proof-step candidates y t .Each iteration expands a size-K beam of proofs-so-far,
S t−1 = {y k &lt;t } K k=1 , by generating N next-step candidates, S t = ∪ y&lt;t∈St−1 (y &lt;t • y n t ) | y n t ∼ q(•|y &lt;t , x, R title ) N n=1 ,(6)
where q is a decoding algorithm (e.g.temperature sampling) and • is concatenation.The next iteration's beam is formed by selecting the top scoring candidates, S t = arg top-K y ≤t ∈S t v α (y ≤t ).</p>
<p>When a proof in the beam terminates, it is not expanded further.The search ends when the beam consists of K terminated proofs.The highest value proof is returned as the final output.</p>
<p>Stepwise++.We add two mechanisms for promoting exploration at each step.First, we expand each prefix in the beam (Eqn.6) by sampling with multiple temperatures,
{y n t ∼ q τ (•|y &lt;t , x, R title ) | τ ∈ {τ i } m i=1 }
, where q τ is sampling with temperature τ .This relaxes the commitment to a single temperature for all proof steps, balancing exploration (higher τ ) with exploitation (lower τ ).</p>
<p>Second, rather than selecting the top-K candidates, we select clusters based on different value weights:
S t = ∪ α∈{αj } j=1 top K (S α t )
, where S α t is the set of candidates scored with v α , and K = K/ .This interpolates between selecting steps based on likelihood (low α) and constraint satisfaction (high α).</p>
<p>Full proof sampling and greedy decoding.An alternative is to sample full proofs and select the best one according to the value function.This can be viewed as expansion (Eqn.6) done at the full proof, rather than the step level.Moreover, greedy decoding corresponds to expanding only 1 candidate with temperature → 0. We formalize this in §D as a segment-level search that contains stepwise++, full proof sampling, and greedy decoding as special cases.</p>
<p>Proof Evaluation</p>
<p>A proof's correctness is contingent on a variety of factors, including reasoning with past results, performing symbolic derivations, and altogether providing sufficient evidence that the claim is true.We design a human-evaluation schema that isolates these aspects at the proof-step level, along with a full-proof summary.Table 1 summarizes the schema, which we overview below.</p>
<p>References.First, proofs involve deploying statements from references, such as applying a definition or adapting it to fit the context.Deployments should be consistent with the reference, e.g.deploying the definition of even integer as '...by definition, ∃k ∈ Z : x = 2k...', rather than '...∃k ∈ Z : x = 2k + 1', and are a common source of errors in student proofs [Edwards and Ward, 2004].</p>
<p>Second, proofs use references as justification for steps of reasoning; for instance, Real Addition is Commutative provides justification for the statement x + y = y + x where x, y ∈ R, but not for xy = yx.This aspect is analogous to using an article to justify a claim (e.g.[Nakano et al., 2021]).Finally, proofs should not hallucinate references, or 'beg the question' by self-referencing the current theorem.</p>
<p>Equations.Proofs contain a variety of multi-step derivations, ranging from simple arithmetic to more sophisticated derivations (e.g.see Table 17).A derivation should start with a valid equation given the surrounding context (e.g.x + x = 2x in Table 1 versus x + x = 3x).Each subsequent step should be a valid derivation from the previous step, e.g.stating = (2k + 6) − 1 after y = 2k + 5. Reasoning: Equation Invalid Equation ∀x ∈ R, x + x = 3x.Invalid Derivation (Since x is an even integer, x + 1 = 2r + 1) = 2(r + 1)</p>
<p>Reasoning: Other Skips Steps (x ∈ Z is not a multiple of 3.) Therefore, x 3 ≡ 1 or 8(mod 9) Repetition (Let ABC be a right triangle.)Then ABC is a right triangle.Invalid (Other) (x is an even integer.)So, x + 1 is an even integer.</p>
<p>Language</p>
<p>Let c = a 2 \add b 2 be the ( incomplete statement ; unknown symbol \add)
Symbolic (Let x ∈ R.) Let y = x•x −1 . ( undefined operator • for real numbers )
Table 1: Overview of human evaluation error schema.See Table 24 for the full schema.Reference.Hallucinated reference .The necessary context (e.g.known conditions, prior steps).</p>
<p>Other reasoning , language , &amp; symbolic errors.A proof should provide sufficient evidence that a claim is true to a human reader; it should not skip steps.Proof steps should make progress towards proving the goal; in particular, they should not repeat known conditions in the theorem or conclusions made in a prior step.Finally, our schema leaves room for any other reasoning errors, as well as symbol errors (e.g.undefined symbols) and language errors (e.g.incomplete statements).</p>
<p>Usefulness and correctness.To judge the potential utility of language models as assistive systems in natural mathematics, we measure whether generated next-steps and full proofs are potentially useful hints for proving the theorem on one's own.Additionally, we measure a summary judgment of correctness.Note that an incorrect statement can still be helpful; for instance, it could give a hint for the type of reference to use, derivation to perform, argument to make, etc.</p>
<p>Human evaluation protocol.We measure these aspects through human annotation at a step-wise and an overall level.For a step-wise annotation, an annotator is presented with the theorem, proof-so-far, and a generated next-step.The annotator labels the {0, 1} correctness, usefulness, and presence of fine-grained errors outlined above.After labeling each step of a proof, the annotator rates the full proof's overall correctness and usefulness on a 0-5 scale.A rating of 4 or 5 is needed to be considered as correct, and a rating of 3 or above is needed to be considered as useful.</p>
<p>Automatic metrics: lexical content.As automatic proxies for quality, we compare each generated proof against its ground-truth counterpart using the sentence-level n-gram matching metric GLEU [Mutton et al., 2007], and following work in knowledge-grounded dialogue [Shuster et al., 2021] we use F1 overlap between generated and ground-truth tokens.Prior to computing the metrics, we normalize the generated and ground-truth proofs by only keeping the surface form of references, removing formatting characters with a MediaWiki parser, and collapsing any consecutive whitespace into a single space.</p>
<p>Automatic metrics: knowledge grounding.We define knowledge grounding as meaning that a generated proof contains the same references as those found in the ground-truth proof.To measure this, we use precision, recall, and F1-score between the reference sets contained in the generated and ground-truth proofs; i.e. m({r 1 , . . ., r R}, {r * 1 , . . ., r * R * }), where m(•) is precision, recall, or F1.We also use Knowledge Token-F1 (kF1) ( [Shuster et al., 2021]), the overlap of the generated proof's tokens with tokens contained in the references mentioned in the ground-truth proof.</p>
<p>Experiments</p>
<p>We use the training and dev splits of NATURALPROOFS-GEN during fine-tuning, and the core evaluation sets consisting of 100 theorems from the validation set and 100 from the test set for Table 2: Human evaluation results on the core test set for full proof generation and next-step suggestion (bottom row).All models are fine-tuned on NATURALPROOFS-GEN.Knowledge -either retrieved or human provided -and constrained decoding improve proof generation, with 46% of proof steps rated as useful and 35% correct according to university-level mathematics students.</p>
<p>evaluation (see §2).These theorems were selected by the authors such that by looking at the theorem title each author could recall its content and sketch a proof.While this may shift the evaluation towards an easier slice of the dataset, it was necessary to make human evaluation at a meaningful scale feasible.We also use the core sets for explorations and ablations.</p>
<p>We finetune three GPT-3 [Brown et al., 2020] (Curie) models, using the OpenAI API (see Appendix E for details):</p>
<ol>
<li>Baseline GPT-3.We finetune a baseline GPT-3 model, p θ (y|x), on theorem-proof examples {(x, y)} from the training split.At test time, we condition the model on a test theorem.2. NATURALPROVER RETRIEVE .We finetune GPT-3 with retrieved references, p θ (y|x, r1 , . . ., r20 ).</li>
</ol>
<p>We use a pretrained joint retrieval model f (x) → (r 1 , . . ., r |R| ) from [Welleck et al., 2021], which was trained to retrieve an input theorem's ground truth references.At test time, the model receives a theorem and the top-20 reference titles that are retrieved given the theorem.3. NATURALPROVER.We finetune GPT-3 with human-provided references, p θ (y|x, r * 1 , . . ., r * Ry ), where {r * 1 , . . ., r * Ry } is the set of reference-titles in the ground-truth proof.We use reference-title conditioned examples (Eqn. 1) and reference-reconstruction (Eqn.2) on the training split/reference set.At test time, the model receives a theorem and reference titles from its ground-truth proof.</p>
<p>For next-step suggestion we use the human-provided knowledge model (NATURALPROVER).</p>
<p>Decoding.For full proof generation, we use stepwise++ decoding with the provided knowledge model, which we refer to as NATURALPROVER ++ , and otherwise use greedy decoding.We do not use stepwise constrained decoding with retrieved references since these references introduce noisy constraints, nor for next-step prediction since the algorithm is designed for multi-step proofs.See §E for additional experimental details.</p>
<p>Human evaluation setup.To evaluate the proofs generated by NATURALPROVER, we recruited 15 students from the Department of Mathematics and Applied Mathematics at the University of Washington, including undergraduate, masters, and Ph.D. students.The annotators were trained on how to evaluate proof correctness and compensated according to IRB requirements; see §F.2.For each task, we first reveal the theorem and its gold proof to the annotator.If they cannot understand a theorem or its gold proof, they may skip evaluating it.Otherwise, they may proceed to see the model-generated proof, one step at a time, and annotate each step under the step-wise evaluation schema (outlined in §4).After all the steps are shown and evaluated, for the full-proof generation task, the annotator is asked to annotate the entire proof under the overall evaluation schema.</p>
<p>Main Results</p>
<p>Our best method is capable of generating correct and useful proofs.According to human evaluation results (Table 2), our best method is NATURALPROVER with human-provided references and stepwise++ inference.32% of the proofs generated by this method are rated as correct and 45% are rated as useful as an aid for human proof writers.On the per-step level, 35% of the proof steps are correct and 47% are useful .Taking a more granular view, our best method makes significantly less reference , equation , and other reasoning errors than other baselines.It makes very few language and symbolic errors , meaning it produces mostly complete, well-formatted mathematical statements, and defines and uses symbols accordingly.It mostly avoids hallucinating references or creating circular proofs.On the other hand, despite improving over the other methods, the model Theorem Singleton Set is not Dense-in-itself Let T = (S, τ ) be a topological space.Let x ∈ S. Then the singleton set {x} is not dense-in-itself.</p>
<p>GPT-3</p>
<p>Let x ∈ S.</p>
<p>From Clopen Points in Topological Space we have that {x} is open in T .</p>
<p>From Point is Open iff it is not Dense-in-itself , it follows that {x} is not dense-in-itself.</p>
<p>NATURALPROVER++ From Singleton Point is Isolated, {x} has an isolated point.</p>
<p>Hence the result by definition of dense-in-itself.</p>
<p>Singleton Point is Isolated Let T = (S, τ ) be a topological space.Let x ∈ S. Then x is an isolated point of the singleton set {x}, but not necessarily an isolated point of T .</p>
<p>Dense-in-itself Let T = S, τ be a topological space.Let H ⊆ S. Then H is dense-in-itself iff it contains no isolated points.</p>
<p>Table 3: GPT-3 hallucinates references , while the knowledge-grounded NATURALPROVER ++ with constrained decoding correctly uses references, resulting in a correct and useful proof.</p>
<p>often struggles with correctly deploying and using references (23.6% reference error rate), as well as symbolic computations (28.5% equation error rate), especially multi-step derivations (21.9% invalid).</p>
<p>What do the model's correct proofs look like?We inspected the proofs labeled as correct and found three main categories: (1) reference-assembly proofs whose correctness is heavily determined by reference statements (e.g.Table 18, Table 20); (2) template-adaptation proofs in which the model adapts the structure and content of a training theorem's proof to prove the unseen evaluation theorem (e.g.Table 21, Table 22); (3) complex proofs that are not fully determined by reference statements and differ significantly from training proofs (e.g. Figure 1, Table 3).In terms of techniques, our method demonstrates some ability to produce direct proofs (Table 19), proofs by cases (Table 22), proofs by induction (Table 23), utilize references (Table 20) and do symbolic computations (Table 21).</p>
<p>Vanilla fine-tuned GPT-3 struggles with proof generation.The vanilla fine-tuned GPT-3 model yielded fewer useful and correct proofs, with more reference-based and other reasoning errors than all three knowledge-grounded settings.The model showed severe reference hallucination (18%) and repetition (23%).It also makes significantly more reasoning errors related to reference usage.Language and symbolic error rates roughly stay the same.Overall, naively fine-tuning GPT-3 on theorem-proof examples alone is suboptimal for proof generation.</p>
<p>Human-provided knowledge improves proof generation.Grounding the generations with human-provided references significantly raises correctness and usefulness of the proofs in both full-proof and per-step evaluation.It most substantially reduces reference errors , especially invalid deployments and hallucinated references.For example, Table 3 shows the model grounding a proof with information from the theorem Singleton Point is Isolated and the definition of Dense-in-itself, in contrast to the vanilla GPT-3 model which hallucinates references.</p>
<p>Retrieved knowledge also improves proof generation.Retrieved knowledge also turns out to be very helpful, and even comparable to human-provided knowledge in some metrics.Although the retrieval model is far from perfect, the proof generation model is capable of narrowing down the retrieved reference titles provided in its context, assembling proofs that are useful and correct more often than the no-knowledge model.Qualitatively, we found examples where grounding in retrieved references eliminates repetition, enables multi-step derivations justified by references (Table 21), and assembles references into a correct proof (Table 20).This paves a promising path towards fully automated mathematical proof generation in natural mathematical language.Table 6: Automatic metrics on the core test set for full-proof generation, and correlation between human metrics and automatic metrics on the core validation set.</p>
<p>Next-step suggestion.The next-step suggestion task characterizes a model's performance on making a single proof step given a correct proof-so-far.</p>
<p>In Table 2 we use the provided-knowledge model with greedy decoding for next-step suggestion, and find that reasoning errors decrease and per-step usefulness and correctness improve compared to the full proof setting, with 51% of the proof steps rated as useful and 43% correct.Although we used a single suggestion in our human evaluation study, in Table 5 we simulate a user choosing from among multiple suggestions by sampling 10 next-steps from our model and computing automatic metrics on the sample with the best sum of metrics.Using 10 samples instead of greedily decoding a single sequence substantially improves each metric, suggesting that utility might be increased further by presenting multiple suggestions.How good are Automatic Metrics?We study how well the automatic lexical and grounding metrics introduced in ( §4) can reflect the real quality of proofs, as a guide for using them as a proxy evaluation protocol for NATURALPROOFS-GEN.We compute the Pearson correlation coefficient between each pair of human and automatic metrics, with data from the four experiment settings for full-proof generation.Results are shown in the lower part of Table 6, with error metrics negated, meaning positive correlation is desired.</p>
<p>The lexical and grounding metrics positively correlate with full proof correctness and usefulness (≥ 0.8).At the step-level, the metrics show (i) high correlation with step-level correctness and language errors ; (ii) varied, but positive, correlations with aggregate reasoning errors; (iii) negative correlation with symbolic errors (though symbolic errors are relatively low for all models).The results suggest that optimizing for automatic metrics may be a viable strategy, albeit without guarantees on how finer-grained reasoning aspects vary across proofs.</p>
<p>Ablations and error analysis.</p>
<p>Recon Reference reconstruction.We fine-tune an additional GPT-3 model that is provided with in-context reference titles, but without reference reconstruction.As seen in Table 7, reference reconstruction improves content and reference usage.</p>
<p>Constrained decoding.First, reference-F1.Second, Table 8 shows that the expansion and selection mechanisms together result in the best reference matching, while holding Gleu at a similar level.Finally, Table 12 shows that both terms in the NATURALPROVER value function αv constraints + (1 − α)v LM are needed: increasing the constraint weight α increases reference-matching, with a tradeoff in Gleu at high values.</p>
<p>Language model comparison.Table 10 varies the language model used to parameterize NATU-RALPROVER .The content and reference usage metrics improve with larger models.Separately, we find that increasing inference-time compute closes the gap in reference-matching between GPT-2 and the larger GPT-3 model (Table 11): sampling 10 full-proofs from GPT-2 and selecting the best using the NATURALPROVER value function achieves the same reference-F1 as GPT-3 with a single greedily-decoded proof.However, Gleu remains much higher with the larger GPT-3 model.</p>
<p>Challenge: Reasoning with references.Although reference reasoning errors were decreased through knowledge-grounding and constrained decoding, NATURALPROVER still commits a reference error on 23.6% of test steps (27% dev), with 15% of steps containing invalid deployments and 10% invalid justifications.For next-step prediction, the reference error rate remains nontrivial (19.7% test, 13% dev)., meaning that the model can struggle to correctly deploy references or use them as justification even in the absence of compounding errors from previous steps.Table 15 shows example invalid deployments and justifications; the errors are at times subtle, and require reasoning about the theorem statement, reference content, and proof context.</p>
<p>Challenge: Equations and derivations.NATURALPROVER commits an equation-related error on 28.5% of test steps (22.8% dev), including invalid equations (9.4%) and derivations (21.9%).Though an improvement over vanilla fine-tuned GPT-3 (32.5%), the errors occur frequently and remain high for next-step prediction (26%).Table 17 shows representative errors, which range from simple 'commonsense' mistakes (e.g.24 = 2 3 ) to making invalid steps with false justification within more sophisticated multi-step proofs.Investigating the role of pretraining, in-context techniques [Nye et al., 2021], and autoformalization [Szegedy, 2020] is interesting future work.Challenge: Proof length.Although NATURAL-PROVER demonstrates some ability to write long proofs (e.g.Table 23), the 42% next-step correctness suggests that compounding errors are likely as proof length increases.Indeed, our best model's full-proof correctness is 48% on 1-4 step proofs (n = 102), decreasing to 15.6% on proofs with 5 or more steps (n = 64), with lower per-step usefulness and correctness at later steps (Figure 2).Our findings are analogous to recent work on language modeling for formal theorem proving [Polu et al., 2022], where current models are typically limited to chaining 2 or 3 non-trivial steps of mathematical reasoning.</p>
<p>Additional discussion</p>
<p>Finally, we provide higher-level comments on future work related to interactive systems, mathematical assistants, and generating proofs in informal versus formal mathematics.</p>
<p>Interactive &amp; improving systems.Currently, our tasks are at two ends of a spectrum: in next-step generation, we always assume previous steps are from a human-written proof, while in full proof generation they are always from the model.Our results with multiple next-step suggestions suggest that users might find some suggestion among the multiple returned useful at a high rate, pointing to a middle ground: a human-in-the-loop NATURALPROVER, in which a human picks the next step from among the returned suggestions, or writes one based on the suggestions.The selected or written next-step could then be used as feedback to improve the system, enabling an iteratively improving NATURALPROVER.This notion of a continuously improving, teachable system is an emerging (e.g.Dalvi et al. [2022]) and interesting future direction.</p>
<p>Assistants for mathematics.Our tasks were motivated by an assistant that helps a user write a proof, either from scratch or when stuck part of the way through.Our study here focuses on capability: investigating whether neural language models are capable of performing the underlying mathematics that would be expected from such an assistant.A further challenge is to also ensure reliability -a user should have confidence that the model is not deceptive or incorrect, and is robust to changes in domain, on nearby problems, and on alternative ways of expressing a problem.Even further, we would like flexibility -human teachers can interact with a student flexibly through dialogue, natural language, and diagrams, rather than the strict input-output format defined by a dataset.Our work provides an initial step towards this larger vision.</p>
<p>Informal and formalized mathematics.Our work investigates theorem proving entirely in natural mathematical language (i.e.'informal' mathematics), as it reflects an interface that a student typically uses when working with mathematics.An alternative is proving theorems in a formalized system, in which proof steps are expressed in a programming language (e.g.Lean de Moura et al. [2015]).Operating purely in a formalized system allows for verifying correctness -unlike our setting which must be verified by a human -arguably at the cost of flexibility and interpretability, as the mathematics is no longer expressed in natural language and must adhere to constraints of the formal system.Investigating combinations of the two -e.g.expressing a theorem in natural language, receiving a verified formal proof, then providing an interpretation in natural language -presents a wide range of interesting directions for future work.</p>
<p>Related Work</p>
<p>Formalized mathematics with neural language models.A large portion of work on machine learning for mathematics focuses on formalized mathematics.Language models have been used for interactive theorem proving, including in GPT-f [Polu andSutskever, 2020, Polu et al., 2022], PACT [Han et al., 2021a], and in Urban and Jakubuv [2020].In these settings proof steps are expressed in a programming language (e.g.Lean [de Moura et al., 2015]) and there is access to a verifier, which differs from our setting of theorem proving in natural mathematical language.</p>
<p>Informal mathematics with neural language models.Previous work on theorem proving in natural mathematical language focuses on retrieving relevant premises (e.g.theorems, definitions) [Ferreira and Freitas, 2020a,b, Welleck et al., 2021, Han et al., 2021b], or informal-to-formal translation [Wang et al., 2020], which differ from our setting of generating next-steps or full proofs.Outside of theorem proving, various works use sequence models for problem solving, including benchmarking language models on arithmetic [Saxton et al., 2019] or competition problems [Hendrycks et al., 2021], symbolic mathematics [Lample andCharton, 2020, Welleck et al., 2022], augmenting LMs with verifiers [Cobbe et al., 2021] or in-context rationales [Wei et al., 2022] for math word problems, or using language models for math-related program synthesis [Austin et al., 2021, Drori et al., 2021] and competitive programming [Li et al., 2022].These settings focus on generating executable programs or a numerical answer, which differ from our theorem proving setting, where the goal is to generate sound and convincing arguments on a range of topics in natural mathematical language.</p>
<p>Related areas in NLP.Systematic reasoning in natural language (outside of math) has been studied with synthetic proofs [Saha et al., 2020, Tafjord et al., 2021], single-step deductions [Bostrom et al., 2021], or entailment trees [Dalvi et al., 2021], which differ from proving real-world mathematical theorems.Augmenting LMs with knowledge reduces hallucinations in dialogue [Shuster et al., 2021] which has an analogous step-wise structure, while [Nakano et al., 2021] use references within long-form answers; these and related NLP findings differ from improving the utility of mathematical proofs.Lexically-constrained decoding algorithms include variants of (token-level) beam search (e.g.[Anderson et al., 2017, Hokamp and Liu, 2017, Lu et al., 2021b,a]) which assume access to per-token logits, and gradient-based decoding [Qin et al., 2022]; our segment-level decoding only assumes a sampler that returns text and its log-probability, making it compatible with recent language model API interfaces (e.g. the GPT-3 API).</p>
<p>Conclusion</p>
<p>We described NATURALPROVER, a knowledge-grounded language model that generates mathematical proofs by conditioning on background theorems and definitions, and optionally enforces their presence with constrained decoding.Our system improves the quality of next-step suggestions and generated proofs over fine-tuned GPT-3, demonstrating an ability to correctly prove theorems and provide useful suggestions to human proof writers.</p>
<p>A Additional Results</p>
<p>A.1 Additional ablations</p>
<p>Table 10 shows automatic metrics with various language models used to parameterize NATURAL-PROVER.</p>
<p>Table 11 shows results with the 774M parameter GPT-2 model with greedy decoding, and full-proof sampling &amp; reranking with 5 and 10 samples, compared to the 13B parameter GPT-3 with greedy decoding.We use τ = 0.3 and α = 0.75 based on our full-proof sampling experiments with GPT-3.Table 13: NaturalProver with a stepwise stochastic beam search baseline versus stepwise++ decoding.The baseline search corresponds to using stepwise decoding with an LM-only value function (α : 0).Constrained stepwise++ decoding substantially improves grounding metrics compared to stochastic beam search, while keeping the lexical content metrics at a similar level.Core validation set.</p>
<p>A.2 Multiple next-step suggestions</p>
<p>Table 14 shows next-step suggestion results with 10 sampled suggestions versus greedy decoding.</p>
<p>Table 15: Reference deployment errors.Theorem 1: NATURALPROVER incorrectly deploys the definition of geometric mean (G(a, b) = (ab) 1/2 would be correct).Theorem 2: An invalid deployment of Power Set of Subset; a correct application would yield P(S) ⊆ P(P(S)).All generated proofs are with provided knowledge and stepwise++ decoding....</p>
<p>Gold Proof</p>
<p>Proof:</p>
<p>By definition of point of inflection, f has either a local maximum or a local minimum at ξ. ...</p>
<p>Reference</p>
<p>Point of Inflection</p>
<p>Let f be a real function which is differentiable on an interval
I ⊆ R. Let ξ ∈ I.
f has a point of inflection at ξ iff the derivative f of f has either a local maximum or a local minimum at ξ.</p>
<p>Theorem 4</p>
<p>Minus One is Less than Zero −1 &lt; 0 Table 16: Reference justification errors.Theorem 3: NATURALPROVER makes an invalid inference using the definition of point of inflection (given the theorem statement, f (ξ) = 0 holds, but not necessarily f (η) = 0 for all η in the interval), which can be viewed as both incorrectly deploying the definition and using it as invalid justification.Theorem 4: A subtle invalid justification that is still useful to the human annotator: the reference provides justification for −0 &gt; −1 rather than −1 &lt; 0. See Table 17 for additional justification errors within derivations.All generated proofs are with provided knowledge and stepwise++ decoding.
NATURALPROVER++ Proof: correct useful justif. 0 &lt; 1 Real Zero is Less than Real One −1 &lt; 0 Order of</p>
<p>B.1.2 Equation errors</p>
<p>Theorem 1 Sum of Squares of Divisors of 24 and 26 are Equal The sum of the squares of the divisors of 24 equals the sum of the squares of the divisors of 26: σ2(24) = σ2(26) where σα denotes the divisor function.Let X be a discrete random variable with a discrete uniform distribution with parameter n for some n ∈ N. Then the moment generating function M X of X is given by:
M X (t) = e t (1 − e nt ) n(1 − e t )
Proof: correct eqn.ref.NATURALPROVER++ From the definition of the discrete uniform distribution , X has probability mass function:
Pr(X = k) = n n + k
From the definition of a moment generating function: Table 17: Equation-related errors in full proof generation.NATURALPROVER can struggle with invalid equations and derivations , including basic equalities (Theorem 1), and more sophisticated settings (Theorems 2 and 3).Since derivations involve deploying definitions and rules from references and using references as justification, equation-related errors are often coupled with reference errors .
M X (t) = Ee tX = n k=0 Pr(X = k)e tk</p>
<p>C Dataset Details</p>
<p>We provide an overview of NATURALPROOFS and its ProofWiki domain from which we build NATURALPROOFS-GEN.Refer to [Welleck et al., 2021] for further details about NATURALPROOFS.</p>
<p>Our dataset is derived from NATURALPROOFS, a multi-domain corpus of theorem statements, proofs, definitions, and additional pages (e.g.axioms, corollaries) in natural mathematical language.We use the ProofWiki2 domain, which provides broad-coverage of many subject areas (e.g.Set Theory, Analysis) sourced from ProofWiki, an online compendium of community-contributed mathematical proofs.PROOFWIKI contains ∼20k theorems, ∼20k proofs, ∼12k definitions, and ∼1k additional pages (e.g.axioms, corollaries).The set of all ∼33k theorems, definitions, and additional pages form the reference set R. Finally, ∼14.5k of the theorems x are paired with at least one proof y to form examples D = {(x, y) i } N i=1 .Welleck et al. [2021] split the reference sets and examples into training, validation, and test splits to ensure that no theorem in the validation or test splits was mentioned in the training split.</p>
<p>D Segment-level Constrained Decoding</p>
<p>In this section we present a generic segment-level decoding algorithm that contains stepwise++, full-proof sampling, and greedy decoding as special cases.We generate a multi-step proof using a value function v(•) that measures language quality and constraint satisfaction.Search can be done at the step-level, in which candidate next-steps are generated and high-value steps are retained in a beam, or at the proof-level, in which multiple proofs are generated and the highest-value proof is selected.We formalize these into a generic segment-level search, where a segment s t is either a proof-step y t or a full proof y.</p>
<p>The search iteratively builds a multi-step proof y = (y 1 , . . ., y T ) by expanding, scoring, and selecting a set of candidate segments:</p>
<p>• Expand: S t−1 → S t extends segments S t−1 = {s ≤t } into candidates S t = {(s ≤t , s t )}.</p>
<p>• Score : (s ≤t , v) → R scores a candidate using a value function, v(s ≤t ) → R.</p>
<p>• Select : S t → S t prunes candidates S t into segments S t used in the next iteration.</p>
<p>Value function.We score candidates based on constraint satisfaction and language quality,
v(s ≤t ) = αv constraint (s ≤t ) + (1 − α)v LM (s ≤t ),(7)
where v constraint (y ≤t ) is the number of unique in-context reference-titles in s ≤t , and v LM (s ≤t ) is log p θ (s ≤t ).We normalize each term by dividing by the maximum absolute value among candidates.</p>
<p>Greedy search.This baseline search defines a segment as a full proof, meaning s 0 is an empty sequence and s 1 is a proof y.Expand samples one segment candidate with temperature 0. Score and select are trivial since there is only one candidate.Greedy search costs T steps of tokens.</p>
<p>Sample-and-rerank.In this search, a segment is again full proof, but expand samples N candidates, S 1 = {y n ∼ q(•|x)} N n=1 , where q is a decoding algorithm (e.g.temperature sampling).Select takes the top scoring candidate, y = arg max y n ∈S 1 v(y n ).The cost is N T steps of tokens.</p>
<p>Step-wise stochastic beam search.This search generates by iteratively sampling and re-ranking next-step candidates.In this case, a segment is a proof step, y t , and each iteration starts with a beam of proofs-so-far, S t−1 = {y k &lt;t } K k=1 , where K is the beam size.Expand samples N next-step candidates for each proof-so-far in the beam,
S t = y&lt;t∈St−1 (y &lt;t • y n t ) | y n t ∼ q(•|y &lt;t , x) N n=1 ,(8)
where q is a decoding algorithm (e.g.temperature sampling) and • is concatenation.Select forms the next beam using the top-K scoring candidates, S t = arg top-K
y ≤t ∈S t v(y ≤t ).(9)
When a proof in the beam terminates, it is not expanded further.The search ends when the beam consists of K terminated proofs.The highest scoring proof is returned as the final output.The cost is N T K steps of tokens.</p>
<p>Stepwise++.At certain proof steps it is important to enumerate and explore options, while at others (e.g.derivations) a single highly probable prediction is better.To this end, we expand by sampling with multiple temperatures, meaning that we expand each prefix y &lt;t in (6) using:
{y n t ∼ q τ (•|y &lt;t , x) | τ ∈ {τ 1 , . . . , τ m }},(10
) where q τ is sampling with temperature τ .This relaxes the commitment to a single temperature for all proof steps, intuitively balancing exploration (higher τ ) with exploitation (lower τ ).</p>
<p>Second, during the search we want to balance selecting proof steps that satisfy constraints and proof steps with high log-probability.To this end, we select clusters with different value weights,
S t = {y ≤t ∈ top K (S α ) | α ∈ {α 1 , . . . , α }},(11)
where S α means the set of candidates scored with v = αv constraint + (1 − α)v LM , and K = K/ .This interpolates between selecting steps with good language score (α small), constraint score (α large), and balance (α : 0.5).</p>
<p>E Implementation Details and Experimental Setup</p>
<p>Data preprocessing.We automatically infer the boundaries of proof steps within the raw proof contents, and merge contiguous lines into atomic proof steps when appropriate.Steps are separated by the \n token (\n in Python string), and lines within a step are separated by the newline token (\n in Python string).</p>
<p>Additional model details.All GPT-3 models (including NATURALPROVER models) are fine-tuned instances of the Curie engine, the second largest model available through the OpenAI API at the time of writing. 3The model's performance on the EleutherAI evaluation harness4 is between the 6.7B and 13B variants of the autoregressive transformer language model GPT-3 from [Brown et al., 2020],5 though further details of the Curie model are not publicly available.</p>
<p>Separately, we fine-tune GPT-J 6B,6 a publicly available autoregressive transformer language model trained on the Pile [Gao et al., 2020], GPT-2 [Radford et al., 2019], an autoregressive transformer language model trained on scraped web documents, and GPT-Neo-125M,7 a GPT-2 like causal language model trained on the Pile.</p>
<p>Our retrieval model is the joint retrieval model from [Welleck et al., 2021] trained for reference retrieval on ProofWiki using the same dataset splits as NaturalProver.We use the publicly-available pretrained model from the GitHub repository of [Welleck et al., 2021] and do not update the model further.We use the model to retrieve the top-20 references for each input theorem.</p>
<p>Implementation details.All GPT-3 models (including NATURALPROVER models) are fine-tuned with the OpenAI API8 for 4 epochs with a batch size of 64.Other models (GPT-2/J/Neo) are trained on one Quadro RTX 8000 GPU.During inference, the prompt (up to <proof>) is truncated to 1024 tokens.For full proof generation, we allow a maximum of 1020 generated tokens.For next-step suggestion, we truncate the proof-so-far to 900 tokens, and allow a maximum of 120 generated tokens per step.</p>
<p>Stepwise++ decoding.For expansion with multiple temperatures, we use N = 10 candidates sampled with (n, τ ) ∈ {(1, 0.0), (3, 0.3), (3, 0.5), (3, 0.7)}.We also tried including τ = 1.0 which resulted in very poor GLEU, and {(1,0.0),(5,0.3),(4,0.5)}.For selection, we use a beam size K = 9, and three equally-sized clusters formed with α ∈ {0.1, 0.5, 1.0}.We also tried {0.5, 0.75, 0.9}.We use α = 0.75 to pick select the final sequence, based on our ablation with full-proof sampling.</p>
<p>Full proof sampling.We use temperature τ 0.3, selected based on a search over τ ∈ {0.1, 0.3, 0.5, 0.7} using GLEU plus Ref-F1 on the core dev set.</p>
<p>F Additional Evaluation Details F.1 Full Evaluation Schema</p>
<p>Table 24 shows the full schema of human evaluation.The overall correctness and usefulness are rated on a 0-5 scale.The step-wise correctness and usefulness are yes/no questions, while the error types ask for a binary indicator for the existence of each error type.</p>
<p>F.2 Additional Human Evaluation Details</p>
<p>Process.The authors conducted and moderated group sessions with the annotators.Each session consisted of 30-minutes of training and a 1-hour working/Q&amp;A period.After attending the session, annotators could continue working on their assigned tasks for two weeks.Each annotator was assigned 25 theorems (with 5 proofs per theorem, equaling 125 total tasks) and asked to complete as many tasks as they would like.The evaluation guideline that the annotators referenced to can be found in the supplementary materials.The pre-recorded training video is available at https: //drive.google.com/file/d/1TRS5XRf_coLEkC4lqaizaqSwHHgBPrG2.</p>
<p>Interface.We developed an interface that displays theorems and proofs in a rendered, humanreadable format and collects annotations.The interface is built on MediaWiki9 , which also powers the ProofWiki website10 .We also developed a web console that helps human annotators navigate annotation tasks and track progress.Figure 3 shows screenshots of the interface.</p>
<p>Payment.Human annotators are paid based on the number of tasks they complete.Each task is worth ($1.0+#steps×$0.4).We pay each annotator an additional $40 for attending the group session.Annotators are guaranteed a minimal rate of $20/hour.The human evaluation costs approximately $5,000.</p>
<p>Ethics review.The human evaluation study is approved by University of Washington under IRB STUDY00014751.Consent was obtained from each human annotator by signing a consent form via DocuSign prior to the beginning of study.The IRB approval letter and a template of the consent form can be found in the supplementary materials.Minimal personally identifiable information (PII) was collected, and removed prior to any data analysis.</p>
<p>F.3 Full results</p>
<p>Table 25 shows the full results of human evaluation, including the error rates of fine-grained error types.</p>
<p>F.4 Analyzing the Annotators</p>
<p>Inter-annotator agreement.We compute inter-annotator agreement using proofs in the core dev set that get an evaluation from two or more annotators.Overall, the annotators achieved fair agreement (Fleiss kappa κ = 0.24).The level of agreement for each evaluation question is shown in Figure 4. Fair to moderate agreement is reached for identifying coarse-grained error types, while the high-level questions (i.e.correctness, usefulness) have relatively low agreement.Source diversity.Figure 5 shows the largest proportion of evaluations covered by a fixed number of annotators.The top-1 annotator contributes 20% of the total evaluations when counting by proofs and 18% when counting by steps.50% of the total evaluations is covered by roughly the top 3 or 4 annotators.Therefore, our human evaluation results have good source diversity and do not heavily depend on a single annotator's opinion.</p>
<p>Correctness</p>
<p>Choose a rating below.Not every statement in each rating will apply to the proof given the rating, but many will apply, and the general theme of the rating will hold:</p>
<p>• 0: The proof is missing.</p>
<p>• 1: The proof makes no sense or is unrelated to the problem statement.</p>
<p>• 2: The proof contains serious logical flaws and lacks adequate justification or explanation.</p>
<p>• 3: The proof has some gaps in reasoning.</p>
<p>• 4: The proof is correct or nearly correct and logically coherent.</p>
<p>• 5: The proof is correct and flows logically.</p>
<p>Usefulness</p>
<p>Even if the proof is not perfect, would it be useful to you if you were to prove this theorem?</p>
<p>• 0: The proof is missing.</p>
<p>• 1: Seeing this proof would not help with proving the theorem by myself at all.</p>
<p>• 2: Seeing this proof proof would slightly decrease the effort needed to prove the theorem by myself.</p>
<p>• 3: Seeing this proof would make it substantially easier to prove the theorem by myself.</p>
<p>• 4. The proof is almost correct, and only needs a few minor corrections.</p>
<p>• 5: The proof is correct and could be directly used as a solution.</p>
<p>STEP-WISE EVALUATION</p>
<p>Correctness</p>
<p>Is this step correct?</p>
<p>• Yes</p>
<p>• No (check this if you identified any error in previous questions)</p>
<p>• Cannot determine (e.g. this step makes a valid progress, but it depends on an invalid prior step)</p>
<p>• This is a meaningless step (e.g.QED)</p>
<p>Usefulness Could this step be a helpful hint for proving the theorem by myself?</p>
<p>• Yes</p>
<p>• No</p>
<p>Reasoning: Reference Invalid Deployment A statement deployed from a reference is not consistent with the reference.Invalid Justification A reference is used as invalid justification for a statement.Hallucinated Ref.</p>
<p>A reference that does not exist is used.</p>
<p>Self Loop</p>
<p>The step refers to the theorem itself.</p>
<p>Reasoning: Equation</p>
<p>Invalid Equation A standalone equation or initial equation in a derivation is invalid.</p>
<p>Invalid Derivation</p>
<p>An equation in a derivation does not follow from the preceding steps.</p>
<p>Reasoning: Other Skips Steps</p>
<p>The step assumes unproven statements, or skips non-trivial steps.</p>
<p>Repetition</p>
<p>The step is merely a repetition of known things.Invalid (Other)</p>
<p>The step's reasoning is invalid for reasons not captured by the other categories.</p>
<p>Language</p>
<p>Incomplete</p>
<p>The step is not a complete mathematical statement or equation.</p>
<p>Misformatted Math</p>
<p>A math expression is not properly formatted.</p>
<p>Unknown</p>
<p>There is a mis-spelled word, or unrecognized math symbol.</p>
<p>Symbolic</p>
<p>Undefined</p>
<p>One of the symbols is undefined.Overloaded One of the symbols has overloaded meanings.Mistyped A symbol usage is not well-typed.</p>
<p>Unconventional</p>
<p>Unconventional notation is used.</p>
<p>Table 24: Detailed description of the human evaluation schema.Table 25: Full human evaluation results on the core test set.NP = NATURALPROVER.Coarse-grained error rates (e.g.Reasoning: Reference Errors ) are computed as the frequency of existence of any fine-grained error under the respective bucket.</p>
<p>G Ethical Considerations</p>
<p>Our system may produce proofs of mathematical theorems that are fallacious or misleading, which may have negative impact if deployed in real educational environments.We kindly remind potential users that our system and models are experimental, and their outputs should be interpreted critically.</p>
<p>Figure 2 :
2
Figure 2: Per-step correctness and usefulness as a function of step number, for full-proof generation with NATURALPROVER ++ and next-step prediction with NATURALPROVER.</p>
<p>of Inflection Let f be a real function which is twice differentiable on the open interval (a . .b).Let f have a point of inflection at ξ ∈ (a . .b). Then: f (ξ) = 0 where f (ξ) denotes the second derivative of f at ξ. NATURALPROVER++ Proof: correct deploy justif.By definition of point of inflection: ∀η ∈ (a . .b) : f (η) = 0 where f (η) denotes the derivative of f with respect to η.</p>
<p>Real Numbers is Dual of Order of their Negatives −1 &lt; 0 Negative of Real Zero equals Zero Gold Proof Proof: 0 &lt; 1 Real Zero is Less than Real One −0 &gt; −1 Order of Real Numbers is Dual of Order of their Negatives 0 &gt; −1 Negative of Real Zero equals Zero −1 &lt; 0 Dual Ordering Reference Order of Real Numbers is Dual of Order of their Negatives ∀x, y ∈ R : x &gt; y ⇐⇒ (−x) &lt; (−y)</p>
<p>of Matrices is Sum of Traces Let A = [a]n and B = [b]n be square matrices of order n.Let A + B denote the matrix entrywise sum of A and B. Then: tr(A + B) = tr(A) + tr(B) where tr(A) denotes the trace of A. Proof: correct eqn.ref.NATURALPROVER++ tr(A + B) = C=A+B tr(C) Trace of Matrix = C=A tr(C) + C=B tr(C) Sum of Summations equals Summation of Sum = tr(A) + tr(B) Trace of Matrix Theorem 3 Moment Generating Function of Discrete Uniform Distribution</p>
<p>Figure 3 :
3
Figure 3: Human evaluation interface.The first screenshot is the web console for task navigation and progress tracking.The next three screenshots show examples of qualification overall evaluation page, and step-wise evaluation page.</p>
<p>Figure 4 :
4
Figure 4: Inter-annotator agreement of human evaluation.</p>
<p>Figure 5 :
5
Figure 5: Source diversity of human annotations.</p>
<p>Table 4 :
4
Stepwise++ approximates the constrained objective better than greedy.
Constrained decoding further improves proofIn-context Stepwise++ PPL (↓) Ref-F1 (↑)generation. Table 4 confirms that stepwise++ decod-ing approximates the constrained objective (Eqn. 4) better than greedy search, yielding proofs with lower perplexity and higher constraint satisfaction (Ref-F1).1.0639 1.0549 1.0644 1.054926.33 30.07 89.43 94.25
This translates to generations that are correct and useful more often according to the annotators.Intuitively, the constraints encourage the model to include references that help prove the claim (e.g.Table18).</p>
<p>Table 5 :
5
Next-step suggestion:
Sampling 10 suggestions improvesover a single greedy suggestion.</p>
<p>Table 7 :
7. Gleu Ref-F1 Halluc.33.03 82.85 3.3235.93 84.15 2.68
Effect of reference reconstruction in NATURALPROVER (greedy decoding, full validation set).</p>
<p>Table 9
9Expand Select GLEURef-F140.62 (.84) 91.78 (.49)41.12 (.58) 92.61 (.63)39.14 (.55) 93.11 (.34)40.11 (1.55) 94.13 (.45)
compares the steplevel search in stepwise++ with searching at the full-proof level through sampling multiple proofs and selecting the best with the NATURALPROVER value function (rerank (n)).Reranking 60 samples matches the cost of stepwise++ in terms of number of decoded tokens.Full-proof reranking yields the best Gleu, though with lower</p>
<p>Table 8 :
8
Ablation of the stepwise++ expansion and selection mechanisms.Mean (std) over 3 runs shown on the core dev set.
Decoding GleuRef-F1Greedy41.12 (-)89.30 (-)Rerank (10) 43.88 (.29) 91.72 (.28)Rerank (60) 42.23 (.80) 93.16 (.27)Stepwise++ 40.11 (1.55) 94.13 (.45)</p>
<p>Table 9 :
9
Stepwise versus full-proof search.Mean (std) over 3 runs on the core dev set.</p>
<p>Table 12
12
varies the value function parameter α (core dev set).We use full-proof sampling since stepwise++ uses multiple values of α in its selection.
ModelParams Gleu Ref-F1 HallucGPT-Neo 125M24.85 61.42 11.07GPT-2774M32.06 65.22 6.76GPT-J6B39.14 79.23 3.51GPT-313B42.39 89.29 1.90</p>
<p>Table 10 :
10
Varying the language model parameterization of NATURALPROVER (provided knowledge, greedy decoding, core dev set).
Model DecodingGleu Ref-F1 HallucGPT-2 Greedy32.06 65.22 6.76GPT-2 Rerank (5) 32.95 83.55 5.24GPT-2 Rerank (10) 32.65 89.30 2.89GPT-3 Greedy42.39 89.29 1.90Table 11: Increasing the inference-time computebudget and reranking with the NATURALPROVERvalue function closes the reference-matching gapbetween GPT-2 (774M) and GPT-3 (13B).α Gleu Ref-F10.0 42.79 88.40.25 42.05 90.81.50 42.59 91.75.75 42.17 93.191.0 41.90 93.60</p>
<p>Table 12 :
12LexicalGroundingGLEU Token F1 kF1 Ref-P Ref-R Ref-F1 Halluc (↓)Stepwise Stochastic Beam 41.068.8990.33 91.43 82.04 84.214.60Constrained Stepwise++40.468.9097.24 95.05 94.85 94.152.00
Effect of value function, from α : 0 (LM only) to α : 1.0 (constraint only), with full-proof sampling (10).</p>
<p>The ProofWiki domain of NATURALPROOFS dataset is under the CC BY-SA 4.0 license.
https://beta.openai.com/docs/guides/fine-tuning
https://github.com/EleutherAI/lm-evaluation-harness
https://blog.eleuther.ai/gpt3-model-sizes/
https://huggingface.co/EleutherAI/gpt-j-6B
https://github.com/EleutherAI/gpt-neo
https://beta.openai.com/docs/guides/fine-tuning
https://www.mediawiki.org
https://www.proofwiki.org
Acknowledgments and Disclosure of FundingThis work was funded in part by the Natural Sciences and Engineering Research Council of Canada (NSERC) (funding reference number 401233309), DARPA MCS program through NIWC Pacific (N66001-19-2-4031), and the Allen Institute for AI.We also thank Google Cloud Compute, as well as OpenAI.The authors would like to thank Alisa Liu, Julian Michael, Yuren (Rock) Pang, and Kaiming Cheng for dogfooding and providing valuable feedback to our human evaluation system.We would also like to thank James McGivern for developing an interactive demo for NaturalProver.ReferenceGeometric Mean Let x1, x2, . . ., xn ∈ R&gt;0 be (strictly) positive real numbers.The geometric mean of x1, x2, . . ., xn is defined as:Power Set of Transitive Set is Transitive Let S be a transitive set.Then its power set P(S) is also a transitive set.NATURALPROVER++ Proof: correct deploy From Set is Transitive iff Subset of Power Set:From Power Set of Subset: P(S) ⊆ S ...Gold ProofProof:Let S be transitive.By Set is Transitive iff Subset of Power Set: S ⊆ P(S) Then by Power Set of Subset: P(S) ⊆ P(P(S)) ...ReferencePower Set of Subset Let S ⊆ T where S and T are both sets.Then: P(S) ⊆ P(T ) where P(S) denotes the power set of S.B.2 ExamplesTheorem Metric Space is Perfectly Normal Gold Proof Let M = (A, d) be a metric space.By definition, a topological space is perfectly normal space iff it is: Then M is a perfectly normal space.perfectly T4 space and T1 (Fréchet) space.We have that:Metric Space is Perfectly T4 Metric Space is T2 (Hausdorff) T2 (Hausdorff) Space is a T1 (Frechet) Space.NATURALPROVER++ From: Metric Space is Hausdorff NATURALPROVER (without stepwise++)From: Metric Space is Perfectly T4 T2 (Hausdorff) Space is T1 Space Metric Space is Perfectly T4 it follows that M is a topological space which is perfectly normal.Metric Space is T2 (Hausdorff) it follows that M is a perfectly normal space .
Guided open vocabulary image captioning with constrained beam search. P Anderson, B Fernando, M Johnson, S Gould, 10.18653/v1/D17-1098Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing. the 2017 Conference on Empirical Methods in Natural Language ProcessingCopenhagen, DenmarkAssociation for Computational LinguisticsSept. 2017</p>
<p>Program synthesis with large language models. J Austin, A Odena, M Nye, M Bosma, H Michalewski, D Dohan, E Jiang, C Cai, M Terry, Q Le, C Sutton, 2021</p>
<p>On the opportunities and risks of foundation models. R Bommasani, D A Hudson, E Adeli, R Altman, S Arora, S Arx, M S Bernstein, J Bohg, A Bosselut, E Brunskill, E Brynjolfsson, S Buch, D Card, R Castellon, N S Chatterji, A S Chen, K Creel, J Davis, D Demszky, C Donahue, M Doumbouya, E Durmus, S Ermon, J Etchemendy, K Ethayarajh, L Fei-Fei, C Finn, T Gale, L E Gillespie, K Goel, N D Goodman, S Grossman, N Guha, T Hashimoto, P Henderson, J Hewitt, D E Ho, J Hong, K Hsu, J Huang, T F Icard, S Jain, D Jurafsky, P Kalluri, S Karamcheti, G Keeling, F Khani, O Khattab, P W Koh, M S Krass, R Krishna, R Kuditipudi, A Kumar, F Ladhak, M Lee, T Lee, J Leskovec, I Levent, X L Li, X Li, T Ma, A Malik, C D Manning, S P Mirchandani, E Mitchell, Z Munyikwa, S Nair, A Narayan, D Narayanan, B Newman, A Nie, J C Niebles, H Nilforoshan, J F Nyarko, G Ogut, L Orr, I Papadimitriou, J S Park, C Piech, E Portelance, C Potts, A Raghunathan, R Reich, H Ren, F Rong, Y H Roohani, C Ruiz, J Ryan, C R'e, D Sadigh, S Sagawa, K Santhanam, A Shih, K P Srinivasan, A Tamkin, R Taori, A W Thomas, F Tramèr, R E Wang, W Wang, B Wu, J Wu, Y Wu, S M Xie, M Yasunaga, J You, M A Zaharia, M Zhang, T Zhang, X Zhang, Y Zhang, L Zheng, K Zhou, P Liang, ArXiv, abs/2108.072582021</p>
<p>Flexible generation of natural language deductions. K Bostrom, X Zhao, S Chaudhuri, G Durrett, 10.18653/v1/2021.emnlp-main.506Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing. the 2021 Conference on Empirical Methods in Natural Language ProcessingDominican RepublicAssociation for Computational LinguisticsNov. 2021Online and Punta Cana</p>
<p>Language models are few-shot learners. T B Brown, B Mann, N Ryder, M Subbiah, J Kaplan, P Dhariwal, A Neelakantan, P Shyam, G Sastry, A Askell, S Agarwal, A Herbert-Voss, G Krueger, T J Henighan, R Child, A Ramesh, D M Ziegler, J Wu, C Winter, C Hesse, M Chen, E Sigler, M Litwin, S Gray, B Chess, J Clark, C Berner, S Mccandlish, A Radford, I Sutskever, D Amodei, ArXiv, abs/2005.141652020</p>
<p>M Chen, J Tworek, H Jun, Q Yuan, H P D O Pinto, J Kaplan, H Edwards, Y Burda, N Joseph, G Brockman, arXiv:2107.03374Evaluating large language models trained on code. 2021arXiv preprint</p>
<p>K Cobbe, V Kosaraju, M Bavarian, M Chen, H Jun, L Kaiser, M Plappert, J Tworek, J Hilton, R Nakano, C Hesse, J Schulman, arXiv:2110.14168Training verifiers to solve math word problems. 2021arXiv preprint</p>
<p>Explaining answers with entailment trees. B Dalvi, P Jansen, O Tafjord, Z Xie, H Smith, L Pipatanangkura, P Clark, 10.18653/v1/2021.emnlp-main.585Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing. the 2021 Conference on Empirical Methods in Natural Language ProcessingDominican RepublicAssociation for Computational LinguisticsNov. 2021Online and Punta Cana</p>
<p>Davis and Hersh. The mathematical experience. B Dalvi, O Tafjord, P Clark, L M De Moura, S Kong, J Avigad, F Van Doorn, J Raumer, Lecture Notes in Computer Science. A. P. Felty and A. Middeldorp91952022. 1981. 2015SpringerThe lean theorem prover (system description)</p>
<p>The role and function of proof in Mathematics. M Villiers, 1990Pythagoras</p>
<p>Wizard of wikipedia: Knowledgepowered conversational agents. E Dinan, S Roller, K Shuster, A Fan, M Auli, J Weston, International Conference on Learning Representations. 2019</p>
<p>A neural network solves, explains, and generates university math problems by program synthesis and few-shot learning at human level. I Drori, S Zhang, R Shuttleworth, L Tang, A Lu, E Ke, K Liu, L Chen, S Tran, N Cheng, R Wang, N Singh, T L Patti, J Lynch, A Shporer, N Verma, E Wu, G Strang, 2021</p>
<p>Surprises from mathematics education research: Student (mis)use of mathematical definitions. B S Edwards, M B Ward, 10.2307/4145268American Mathematical Monthly. 2004</p>
<p>Thinking Like a Lawyer. Erik G Jensen, Thinking Like a Lawyer. 2014</p>
<p>Natural language premise selection: Finding supporting statements for mathematical text. D Ferreira, A Freitas, Proceedings of the 12th Language Resources and Evaluation Conference. the 12th Language Resources and Evaluation ConferenceMarseille, FranceMay 2020aEuropean Language Resources Association</p>
<p>Premise selection in natural language mathematical texts. D Ferreira, A Freitas, doi: 10.18653Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics. the 58th Annual Meeting of the Association for Computational LinguisticsAssociation for Computational LinguisticsJuly 2020b</p>
<p>URL. </p>
<p>L Gao, S Biderman, S Black, L Golding, T Hoppe, C Foster, J Phang, H He, A Thite, N Nabeshima, S Presser, C Leahy, arXiv:2101.00027The Pile: An 800gb dataset of diverse text for language modeling. 2020arXiv preprint</p>
<p>Proof artifact co-training for theorem proving with language models. J M Han, J Rute, Y Wu, E W Ayers, S Polu, 2021a</p>
<p>Contrastive finetuning of generative language models for informal premise selection. J M Han, T Xu, S Polu, A Neelakantan, A Radford, AITP2021b</p>
<p>Measuring mathematical problem solving with the math dataset. D Hendrycks, C Burns, S Kadavath, A Arora, S Basart, E Tang, D Song, J Steinhardt, 2021</p>
<p>Lexically constrained decoding for sequence generation using grid beam search. C Hokamp, Q Liu, 10.18653/v1/P17-1141Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics. the 55th Annual Meeting of the Association for Computational LinguisticsVancouver, CanadaAssociation for Computational LinguisticsJuly 20171Long Papers)</p>
<p>Penn State Law eLibrary Journal Articles Faculty Works 1992, Proof in Law and Science. D H Kaye, Jurimetrics J. 321992</p>
<p>Deep learning for symbolic mathematics. G Lample, F Charton, International Conference on Learning Representations. 2020</p>
<p>Competition-level code generation with alphacode. Y Li, D Choi, J Chung, N Kushman, J Schrittwieser, R Leblond, T Eccles, J Keeling, F Gimeno, A D Lago, arXiv:2203.078142022arXiv preprint</p>
<p>Neurologic a*esque decoding: Constrained text generation with lookahead heuristics. X Lu, S Welleck, P West, L Jiang, J Kasai, D Khashabi, R L Bras, L Qin, Y Yu, R Zellers, N A Smith, Y Choi, ArXiv, abs/2112.087262021a</p>
<p>NeuroLogic decoding: (un)supervised neural text generation with predicate logic constraints. X Lu, P West, R Zellers, R Le Bras, C Bhagavatula, Y Choi, 10.18653/v1/2021.naacl-main.339Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language TechnologiesOnlineJune 2021bAssociation for Computational Linguistics</p>
<p>Gleu: Automatic evaluation of sentence-level fluency. A Mutton, M Dras, S Wan, R Dale, Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics. the 45th Annual Meeting of the Association of Computational Linguistics2007</p>
<p>Webgpt: Browser-assisted question-answering with human feedback. R Nakano, J Hilton, S A Balaji, J Wu, L Ouyang, C Kim, C Hesse, S Jain, V Kosaraju, W Saunders, X Jiang, K Cobbe, T Eloundou, G Krueger, K Button, M Knight, B Chess, J Schulman, ArXiv, abs/2112.093322021</p>
<p>Show your work: Scratchpads for intermediate computation with language models. M Nye, A J Andreassen, G Gur-Ari, H Michalewski, J Austin, D Bieber, D Dohan, A Lewkowycz, M Bosma, D Luan, C Sutton, A Odena, ArXiv, abs/2112.001142021</p>
<p>Generative language modeling for automated theorem proving. S Polu, I Sutskever, 2020</p>
<p>Formal mathematics statement curriculum learning. S Polu, J M Han, K Zheng, M Baksys, I Babuschkin, I Sutskever, 2022</p>
<p>Cold decoding: Energy-based constrained text generation with langevin dynamics. L Qin, S Welleck, D Khashabi, Y Choi, ArXiv, abs/2202.117052022</p>
<p>Language models are unsupervised multitask learners. A Radford, J Wu, R Child, D Luan, D Amodei, I Sutskever, 2019arXiv</p>
<p>PRover: Proof generation for interpretable reasoning over rules. S Saha, S Ghosh, S Srivastava, M Bansal, 10.18653/v1/2020.emnlp-main.9Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP). the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)Association for Computational LinguisticsNov. 2020</p>
<p>Analysing mathematical reasoning abilities of neural models. D Saxton, E Grefenstette, F Hill, P Kohli, International Conference on Learning Representations. 2019</p>
<p>Retrieval augmentation reduces hallucination in conversation. K Shuster, S Poff, M Chen, D Kiela, J Weston, 10.18653/v1/2021.findings-emnlp.320Findings of the Association for Computational Linguistics: EMNLP 2021. Punta Cana, Dominican RepublicAssociation for Computational LinguisticsNov. 2021</p>
<p>A Promising Path Towards Autoformalization and General Artificial Intelligence. C Szegedy, 2020</p>
<p>ProofWriter: Generating implications, proofs, and abductive statements over natural language. O Tafjord, B Dalvi, P Clark, 10.18653/v1/2021.findings-acl.317Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021. Aug. 2021Association for Computational Linguistics</p>
<p>First neural conjecturing datasets and experiments. J Urban, J Jakubuv, International Conference on Intelligent Computer Mathematics. Springer2020</p>
<p>Learning to reason via instruction in argumentation. Learning and Instruction. J F Voss, M L Means, 10.1016/0959-4752(91)90013-X1991</p>
<p>Exploration of neural machine translation in autoformalization of mathematics in Mizar. Q Wang, C Brown, C Kaliszyk, J Urban, 10.1145/3372885.3373827CPP 2020 -Proceedings of the 9th ACM SIGPLAN International Conference on Certified Programs and Proofs, co-located with POPL 2020. 2020</p>
<p>Chain of thought prompting elicits reasoning in large language models. J Wei, X Wang, D Schuurmans, M Bosma, E Chi, Q Le, D Zhou, 2022</p>
<p>Naturalproofs: Mathematical theorem proving in natural language. S Welleck, J Liu, R L Bras, H Hajishirzi, Y Choi, K Cho, Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track (Round 1). 2021</p>
<p>Symbolic brittleness in sequence models: on systematic generalization in symbolic mathematics. S Welleck, P West, J Cao, Y Choi, AAAI, abs/2109.139862022</p>            </div>
        </div>

    </div>
</body>
</html>