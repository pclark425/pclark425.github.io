<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-7093 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-7093</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-7093</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-132.html">extraction-schema-132</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how large language models are used to synthesize novel chemical compounds for specific applications, including model details, generation methods, target applications, chemical representations, evaluation metrics, constraints, integration with external tools, datasets, reported performance, experimental validation, and reported challenges or limitations.</div>
                <p><strong>Paper ID:</strong> paper-8b281b474c45683b7b8cb63b3f186382c5d69ef2</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/8b281b474c45683b7b8cb63b3f186382c5d69ef2" target="_blank">Retro*: Learning Retrosynthetic Planning with Neural Guided A* Search</a></p>
                <p><strong>Paper Venue:</strong> International Conference on Machine Learning</p>
                <p><strong>Paper TL;DR:</strong> Experiments show that, the proposed Retro*, a neural-based A*-like algorithm that finds high-quality synthetic routes efficiently outperforms existing state-of-the-art with respect to both the success rate and solution quality, while being more efficient at the same time.</p>
                <p><strong>Paper Abstract:</strong> Retrosynthetic planning is a critical task in organic chemistry which identifies a series of reactions that can lead to the synthesis of a target product. The vast number of possible chemical transformations makes the size of the search space very big, and retrosynthetic planning is challenging even for experienced chemists. However, existing methods either require expensive return estimation by rollout with high variance, or optimize for search speed rather than the quality. In this paper, we propose Retro*, a neural-based A*-like algorithm that finds high-quality synthetic routes efficiently. It maintains the search as an AND-OR tree, and learns a neural search bias with off-policy data. Then guided by this neural network, it performs best-first search efficiently during new planning episodes. Experiments on benchmark USPTO datasets show that, our proposed method outperforms existing state-of-the-art with respect to both the success rate and solution quality, while being more efficient at the same time.</p>
                <p><strong>Cost:</strong> 0.013</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e7093.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e7093.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how large language models are used to synthesize novel chemical compounds for specific applications, including model details, generation methods, target applications, chemical representations, evaluation metrics, constraints, integration with external tools, datasets, reported performance, experimental validation, and reported challenges or limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Retro*</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Retro*: Learning Retrosynthetic Planning with Neural Guided A* Search</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A neural-guided A*-like retrosynthetic planning algorithm that maintains an AND-OR search tree and uses a learned value function to perform best-first expansions, optimizing for low-cost, feasible synthetic routes efficiently.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Retro*</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>neural-guided best-first (A*-like) search algorithm integrating a learned value oracle</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>training_data_description</strong></td>
                            <td>Value function trained offline on constructed retrosynthesis route dataset extracted from USPTO reactions and eMolecules building block availability (≈299k training routes after processing); one-step model trained on USPTO reaction templates (~1.3M reactions, ~380k distinct templates).</td>
                        </tr>
                        <tr>
                            <td><strong>generation_method</strong></td>
                            <td>Search-based synthesis route generation: Retro* selects frontier molecule nodes by estimated total cost V_t(m|T), expands with k one-step retrosynthesis proposals from a one-step model (template predictions), and updates tree values; it does not directly generate SMILES but composes multi-step routes from one-step proposals.</td>
                        </tr>
                        <tr>
                            <td><strong>chemical_representation</strong></td>
                            <td>Reaction templates (extracted via RDChiral) and Morgan fingerprints (ECFP) of radius 2, 2048 bits used to represent molecules for the value network; one-step model works on template indices that map to reactant sets.</td>
                        </tr>
                        <tr>
                            <td><strong>target_application</strong></td>
                            <td>Computer-assisted retrosynthetic planning for organic molecule synthesis (finding multi-step synthetic routes to make a target molecule from available building blocks).</td>
                        </tr>
                        <tr>
                            <td><strong>constraints_used</strong></td>
                            <td>Search constrained by available building blocks from eMolecules (commercial availability), top-50 predicted templates per one-step call (k=50), time limit measured as number of one-step model calls (hard limit 500 in experiments); test set filtered to routes covered by top-50 predictions and pruned by heuristic BFS to increase difficulty.</td>
                        </tr>
                        <tr>
                            <td><strong>integration_with_external_tools</strong></td>
                            <td>Uses RDChiral to extract and apply reaction templates; integrates a one-step retrosynthesis model (template-based MLP) as the proposal generator; uses Morgan fingerprint computation and caching for value updates. No molecular simulation or wet-lab tools used.</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_used</strong></td>
                            <td>USPTO reaction dataset (≈3.8M raw -> ≈1.3M usable reactions after filtering) split 80/10/10; eMolecules commercial building block list for route termination; constructed route datasets: 299,202 training routes, 65,274 validation routes, 189 test routes (after filtering).</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td>Success rate (fraction of test targets solved under time cutoff), number of one-step model calls (proxy for time), route length (number of reactions), total route cost defined as sum of reaction negative log-likelihoods, counts of routes shorter/better than expert routes.</td>
                        </tr>
                        <tr>
                            <td><strong>reported_results</strong></td>
                            <td>On filtered test set under limit of 500 one-step calls: Retro* success rate 86.84% (Retro*-0 79.47%, DFPN-E+ 53.68%, DFPN-E 55.26%, MCTS+ 35.79%, MCTS 33.68%, Greedy DFS 22.63%); time (one-step calls) shown as average calls: Retro* 156.58, Retro*-0 208.58, DFPN-E+ 289.42, DFPN-E 279.67, MCTS+ 365.21, MCTS 370.51, Greedy DFS 388.15; Retro* produced 50 shorter routes and 112 better (lower cost) routes than expert routes in the test set.</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_validation</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>challenges_or_limitations</strong></td>
                            <td>Does not perform wet‑lab synthesis validation; relies on quality of one-step model and reaction database (USPTO) and availability list (eMolecules); building-block and template coverage limit solvable targets; construction of benchmark routes can bias training; search still expensive if one-step calls are costly; extension from tree to full graph (shared intermediates) noted but not fully explored; admissibility requires a lower bound of V_m (0 is valid lower bound) and practical halting trades optimality for runtime.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Retro*: Learning Retrosynthetic Planning with Neural Guided A* Search', 'publication_date_yy_mm': '2020-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7093.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e7093.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how large language models are used to synthesize novel chemical compounds for specific applications, including model details, generation methods, target applications, chemical representations, evaluation metrics, constraints, integration with external tools, datasets, reported performance, experimental validation, and reported challenges or limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>One-step retrosynthesis model (B)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>One-step retrosynthesis prediction model (denoted B in paper)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A model that, given a product molecule, predicts up to k candidate one-step retrosynthetic reactions (reaction template, reactant set, and a cost); used by Retro* to expand nodes in the AND-OR search tree.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Template-based MLP one-step model (as implemented in experiments)</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>multi-class classifier over reaction templates (template-based one-step retrosynthesis)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>training_data_description</strong></td>
                            <td>Trained on the processed USPTO reaction dataset (~1.3M reactions) with ≈380k distinct reaction templates; training follows literature template-based approaches (Segler & Waller 2017).</td>
                        </tr>
                        <tr>
                            <td><strong>generation_method</strong></td>
                            <td>Predicts top-k reaction templates (k=50 in experiments); reactants obtained by applying predicted templates to the product molecule (via template application tools).</td>
                        </tr>
                        <tr>
                            <td><strong>chemical_representation</strong></td>
                            <td>Reaction templates (SMARTS/SMARTS-like templates) applied to product molecules; implicit use of molecular graph/SMILES for template application (extraction via RDChiral).</td>
                        </tr>
                        <tr>
                            <td><strong>target_application</strong></td>
                            <td>Proposal generator for retrosynthetic planning (provides candidate one-step disconnections for search algorithms).</td>
                        </tr>
                        <tr>
                            <td><strong>constraints_used</strong></td>
                            <td>Top-50 template predictions kept per call; templates that cannot be applied or produce invalid reactants were discarded during dataset extraction.</td>
                        </tr>
                        <tr>
                            <td><strong>integration_with_external_tools</strong></td>
                            <td>Template extraction and application performed with RDChiral; integrated into Retro* and baseline search algorithms (MCTS, DFPN-E, DFS).</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_used</strong></td>
                            <td>USPTO reaction dataset (processed subset: ~1.3M reactions); templates extracted via RDChiral.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td>Implicitly evaluated via downstream planning metrics (success rate, route cost/length); one-step model likelihood used to compute reaction cost (negative log-likelihood).</td>
                        </tr>
                        <tr>
                            <td><strong>reported_results</strong></td>
                            <td>Used to generate top-50 candidates per expansion; the paper reports downstream planning performance when using this one-step model (see Retro* aggregated results). No standalone one-step accuracy numbers reported in main text.</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_validation</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>challenges_or_limitations</strong></td>
                            <td>Template-based approach requires handling a very large number (~380k) of templates making classification hard; templates may be missing for reactions not in the dataset; template application can fail if mapping is incorrect; classification over many classes is challenging.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Retro*: Learning Retrosynthetic Planning with Neural Guided A* Search', 'publication_date_yy_mm': '2020-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7093.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e7093.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how large language models are used to synthesize novel chemical compounds for specific applications, including model details, generation methods, target applications, chemical representations, evaluation metrics, constraints, integration with external tools, datasets, reported performance, experimental validation, and reported challenges or limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>V_m value network</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Molecule value estimator V_m (neural network)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A neural network that estimates the minimal future cost to synthesize a single molecule (V_m); used as the learned heuristic in Retro* to guide best-first search.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>V_m neural estimator (single-layer fully connected network)</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>feed-forward regression network (fingerprint input → scalar value)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>single hidden layer, hidden dim = 128</td>
                        </tr>
                        <tr>
                            <td><strong>training_data_description</strong></td>
                            <td>Trained offline on constructed retrosynthesis routes (R_train) derived from USPTO reactions and eMolecules building blocks; input fingerprints computed from the same reaction molecules encountered during training.</td>
                        </tr>
                        <tr>
                            <td><strong>generation_method</strong></td>
                            <td>Not a generative model — outputs scalar estimated synthesis cost for molecule used as heuristic in search.</td>
                        </tr>
                        <tr>
                            <td><strong>chemical_representation</strong></td>
                            <td>Morgan (ECFP) fingerprint radius 2, 2048 bits as input representation.</td>
                        </tr>
                        <tr>
                            <td><strong>target_application</strong></td>
                            <td>Heuristic value estimation for retrosynthesis planning (guides Retro* expansion selection).</td>
                        </tr>
                        <tr>
                            <td><strong>constraints_used</strong></td>
                            <td>Consistency loss to enforce partial order: ensures best one-step solution remains prioritized by margin ε; regression loss to fit route cost; λ balances losses (λ=1 default).</td>
                        </tr>
                        <tr>
                            <td><strong>integration_with_external_tools</strong></td>
                            <td>Trained using constructed route dataset; used inline by Retro* to compute r_n and V_t values; integrated with template-based one-step model outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_used</strong></td>
                            <td>Constructed route dataset: 299,202 training routes, 65,274 validation routes, 189 test routes (after filtering).</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td>Indirectly evaluated by downstream planning metrics: difference in success rate and average one-step calls when Retro* uses learned V_m vs V_m=0 (Retro*-0 ablation).</td>
                        </tr>
                        <tr>
                            <td><strong>reported_results</strong></td>
                            <td>Learning V_m improves Retro* success rate by ~6% over Retro*-0 (86.84% vs 79.47% success rate) and reduces average one-step calls (156.58 vs 208.58); exact regression metrics for V_m are not reported.</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_validation</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>challenges_or_limitations</strong></td>
                            <td>Value estimator accuracy depends on quality and coverage of constructed route dataset; may be biased by route extraction heuristics; requires good generalization to unseen molecules; guarantees require a lower bound on V_m (0 is used as universal lower bound when exact V_m unknown).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Retro*: Learning Retrosynthetic Planning with Neural Guided A* Search', 'publication_date_yy_mm': '2020-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7093.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e7093.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how large language models are used to synthesize novel chemical compounds for specific applications, including model details, generation methods, target applications, chemical representations, evaluation metrics, constraints, integration with external tools, datasets, reported performance, experimental validation, and reported challenges or limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Seq2seq (LSTM / Transformer)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Sequence-to-sequence template-free retrosynthesis models (LSTM and Transformer variants)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Template-free one-step retrosynthesis approaches from literature that directly predict reactant SMILES from product SMILES using seq2seq architectures (LSTM or Transformer), mentioned as alternatives to template-based methods.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Retrosynthetic reaction prediction using neural sequence-to-sequence models</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>LSTM / Transformer seq2seq models (literature)</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>encoder-decoder sequence-to-sequence (neural translation of product → reactants)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>training_data_description</strong></td>
                            <td>Typically trained on reaction pairs (product→reactants) extracted from reaction corpora such as USPTO; the paper cites Liu et al. 2017 and Karpov et al. 2019 as examples.</td>
                        </tr>
                        <tr>
                            <td><strong>generation_method</strong></td>
                            <td>Direct generation of reactant SMILES strings conditioned on product SMILES (template-free), often using beam search decoding.</td>
                        </tr>
                        <tr>
                            <td><strong>chemical_representation</strong></td>
                            <td>SMILES (tokenized) as sequence input/output; sometimes augmented by molecular graphs or grammar tokens in other works.</td>
                        </tr>
                        <tr>
                            <td><strong>target_application</strong></td>
                            <td>One-step retrosynthesis prediction (serves as building block for multi-step planning), alternative to template-based generation.</td>
                        </tr>
                        <tr>
                            <td><strong>constraints_used</strong></td>
                            <td>Not specified in this paper beyond general literature practices (beam size, validity checks); template-free methods may include validity/chemistry filters in other works.</td>
                        </tr>
                        <tr>
                            <td><strong>integration_with_external_tools</strong></td>
                            <td>Mentioned in context of literature — not integrated into Retro* experiments; other works combine such models with search/tree planning.</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_used</strong></td>
                            <td>Literature commonly trains on USPTO reaction pairs; the paper references Liu et al. (2017) and Karpov et al. (2019).</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td>In literature: top-k accuracy for one-step prediction, validity of generated SMILES, and downstream planning metrics when used in multistep search; in this paper these methods are only cited, not evaluated.</td>
                        </tr>
                        <tr>
                            <td><strong>reported_results</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>experimental_validation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>challenges_or_limitations</strong></td>
                            <td>Paper notes template-free seq2seq models exist but does not evaluate them; general known issues include needing large reaction-pair corpora, generating invalid SMILES, difficulty modeling atom-mapping/stoichiometry, and often lacking explicit reaction templates making application in symbolic search nontrivial.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Retro*: Learning Retrosynthetic Planning with Neural Guided A* Search', 'publication_date_yy_mm': '2020-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Planning chemical syntheses with deep neural networks and symbolic ai <em>(Rating: 2)</em></li>
                <li>Retrosynthetic reaction prediction using neural sequence-to-sequence models <em>(Rating: 2)</em></li>
                <li>A transformer model for retrosynthesis <em>(Rating: 2)</em></li>
                <li>Computer-assisted retrosynthesis based on molecular similarity <em>(Rating: 1)</em></li>
                <li>Learning retrosynthetic planning through simulated experience <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-7093",
    "paper_id": "paper-8b281b474c45683b7b8cb63b3f186382c5d69ef2",
    "extraction_schema_id": "extraction-schema-132",
    "extracted_data": [
        {
            "name_short": "Retro*",
            "name_full": "Retro*: Learning Retrosynthetic Planning with Neural Guided A* Search",
            "brief_description": "A neural-guided A*-like retrosynthetic planning algorithm that maintains an AND-OR search tree and uses a learned value function to perform best-first expansions, optimizing for low-cost, feasible synthetic routes efficiently.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "Retro*",
            "model_type": "neural-guided best-first (A*-like) search algorithm integrating a learned value oracle",
            "model_size": null,
            "training_data_description": "Value function trained offline on constructed retrosynthesis route dataset extracted from USPTO reactions and eMolecules building block availability (≈299k training routes after processing); one-step model trained on USPTO reaction templates (~1.3M reactions, ~380k distinct templates).",
            "generation_method": "Search-based synthesis route generation: Retro* selects frontier molecule nodes by estimated total cost V_t(m|T), expands with k one-step retrosynthesis proposals from a one-step model (template predictions), and updates tree values; it does not directly generate SMILES but composes multi-step routes from one-step proposals.",
            "chemical_representation": "Reaction templates (extracted via RDChiral) and Morgan fingerprints (ECFP) of radius 2, 2048 bits used to represent molecules for the value network; one-step model works on template indices that map to reactant sets.",
            "target_application": "Computer-assisted retrosynthetic planning for organic molecule synthesis (finding multi-step synthetic routes to make a target molecule from available building blocks).",
            "constraints_used": "Search constrained by available building blocks from eMolecules (commercial availability), top-50 predicted templates per one-step call (k=50), time limit measured as number of one-step model calls (hard limit 500 in experiments); test set filtered to routes covered by top-50 predictions and pruned by heuristic BFS to increase difficulty.",
            "integration_with_external_tools": "Uses RDChiral to extract and apply reaction templates; integrates a one-step retrosynthesis model (template-based MLP) as the proposal generator; uses Morgan fingerprint computation and caching for value updates. No molecular simulation or wet-lab tools used.",
            "dataset_used": "USPTO reaction dataset (≈3.8M raw -&gt; ≈1.3M usable reactions after filtering) split 80/10/10; eMolecules commercial building block list for route termination; constructed route datasets: 299,202 training routes, 65,274 validation routes, 189 test routes (after filtering).",
            "evaluation_metrics": "Success rate (fraction of test targets solved under time cutoff), number of one-step model calls (proxy for time), route length (number of reactions), total route cost defined as sum of reaction negative log-likelihoods, counts of routes shorter/better than expert routes.",
            "reported_results": "On filtered test set under limit of 500 one-step calls: Retro* success rate 86.84% (Retro*-0 79.47%, DFPN-E+ 53.68%, DFPN-E 55.26%, MCTS+ 35.79%, MCTS 33.68%, Greedy DFS 22.63%); time (one-step calls) shown as average calls: Retro* 156.58, Retro*-0 208.58, DFPN-E+ 289.42, DFPN-E 279.67, MCTS+ 365.21, MCTS 370.51, Greedy DFS 388.15; Retro* produced 50 shorter routes and 112 better (lower cost) routes than expert routes in the test set.",
            "experimental_validation": false,
            "challenges_or_limitations": "Does not perform wet‑lab synthesis validation; relies on quality of one-step model and reaction database (USPTO) and availability list (eMolecules); building-block and template coverage limit solvable targets; construction of benchmark routes can bias training; search still expensive if one-step calls are costly; extension from tree to full graph (shared intermediates) noted but not fully explored; admissibility requires a lower bound of V_m (0 is valid lower bound) and practical halting trades optimality for runtime.",
            "uuid": "e7093.0",
            "source_info": {
                "paper_title": "Retro*: Learning Retrosynthetic Planning with Neural Guided A* Search",
                "publication_date_yy_mm": "2020-06"
            }
        },
        {
            "name_short": "One-step retrosynthesis model (B)",
            "name_full": "One-step retrosynthesis prediction model (denoted B in paper)",
            "brief_description": "A model that, given a product molecule, predicts up to k candidate one-step retrosynthetic reactions (reaction template, reactant set, and a cost); used by Retro* to expand nodes in the AND-OR search tree.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "Template-based MLP one-step model (as implemented in experiments)",
            "model_type": "multi-class classifier over reaction templates (template-based one-step retrosynthesis)",
            "model_size": null,
            "training_data_description": "Trained on the processed USPTO reaction dataset (~1.3M reactions) with ≈380k distinct reaction templates; training follows literature template-based approaches (Segler & Waller 2017).",
            "generation_method": "Predicts top-k reaction templates (k=50 in experiments); reactants obtained by applying predicted templates to the product molecule (via template application tools).",
            "chemical_representation": "Reaction templates (SMARTS/SMARTS-like templates) applied to product molecules; implicit use of molecular graph/SMILES for template application (extraction via RDChiral).",
            "target_application": "Proposal generator for retrosynthetic planning (provides candidate one-step disconnections for search algorithms).",
            "constraints_used": "Top-50 template predictions kept per call; templates that cannot be applied or produce invalid reactants were discarded during dataset extraction.",
            "integration_with_external_tools": "Template extraction and application performed with RDChiral; integrated into Retro* and baseline search algorithms (MCTS, DFPN-E, DFS).",
            "dataset_used": "USPTO reaction dataset (processed subset: ~1.3M reactions); templates extracted via RDChiral.",
            "evaluation_metrics": "Implicitly evaluated via downstream planning metrics (success rate, route cost/length); one-step model likelihood used to compute reaction cost (negative log-likelihood).",
            "reported_results": "Used to generate top-50 candidates per expansion; the paper reports downstream planning performance when using this one-step model (see Retro* aggregated results). No standalone one-step accuracy numbers reported in main text.",
            "experimental_validation": false,
            "challenges_or_limitations": "Template-based approach requires handling a very large number (~380k) of templates making classification hard; templates may be missing for reactions not in the dataset; template application can fail if mapping is incorrect; classification over many classes is challenging.",
            "uuid": "e7093.1",
            "source_info": {
                "paper_title": "Retro*: Learning Retrosynthetic Planning with Neural Guided A* Search",
                "publication_date_yy_mm": "2020-06"
            }
        },
        {
            "name_short": "V_m value network",
            "name_full": "Molecule value estimator V_m (neural network)",
            "brief_description": "A neural network that estimates the minimal future cost to synthesize a single molecule (V_m); used as the learned heuristic in Retro* to guide best-first search.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "V_m neural estimator (single-layer fully connected network)",
            "model_type": "feed-forward regression network (fingerprint input → scalar value)",
            "model_size": "single hidden layer, hidden dim = 128",
            "training_data_description": "Trained offline on constructed retrosynthesis routes (R_train) derived from USPTO reactions and eMolecules building blocks; input fingerprints computed from the same reaction molecules encountered during training.",
            "generation_method": "Not a generative model — outputs scalar estimated synthesis cost for molecule used as heuristic in search.",
            "chemical_representation": "Morgan (ECFP) fingerprint radius 2, 2048 bits as input representation.",
            "target_application": "Heuristic value estimation for retrosynthesis planning (guides Retro* expansion selection).",
            "constraints_used": "Consistency loss to enforce partial order: ensures best one-step solution remains prioritized by margin ε; regression loss to fit route cost; λ balances losses (λ=1 default).",
            "integration_with_external_tools": "Trained using constructed route dataset; used inline by Retro* to compute r_n and V_t values; integrated with template-based one-step model outputs.",
            "dataset_used": "Constructed route dataset: 299,202 training routes, 65,274 validation routes, 189 test routes (after filtering).",
            "evaluation_metrics": "Indirectly evaluated by downstream planning metrics: difference in success rate and average one-step calls when Retro* uses learned V_m vs V_m=0 (Retro*-0 ablation).",
            "reported_results": "Learning V_m improves Retro* success rate by ~6% over Retro*-0 (86.84% vs 79.47% success rate) and reduces average one-step calls (156.58 vs 208.58); exact regression metrics for V_m are not reported.",
            "experimental_validation": false,
            "challenges_or_limitations": "Value estimator accuracy depends on quality and coverage of constructed route dataset; may be biased by route extraction heuristics; requires good generalization to unseen molecules; guarantees require a lower bound on V_m (0 is used as universal lower bound when exact V_m unknown).",
            "uuid": "e7093.2",
            "source_info": {
                "paper_title": "Retro*: Learning Retrosynthetic Planning with Neural Guided A* Search",
                "publication_date_yy_mm": "2020-06"
            }
        },
        {
            "name_short": "Seq2seq (LSTM / Transformer)",
            "name_full": "Sequence-to-sequence template-free retrosynthesis models (LSTM and Transformer variants)",
            "brief_description": "Template-free one-step retrosynthesis approaches from literature that directly predict reactant SMILES from product SMILES using seq2seq architectures (LSTM or Transformer), mentioned as alternatives to template-based methods.",
            "citation_title": "Retrosynthetic reaction prediction using neural sequence-to-sequence models",
            "mention_or_use": "mention",
            "model_name": "LSTM / Transformer seq2seq models (literature)",
            "model_type": "encoder-decoder sequence-to-sequence (neural translation of product → reactants)",
            "model_size": null,
            "training_data_description": "Typically trained on reaction pairs (product→reactants) extracted from reaction corpora such as USPTO; the paper cites Liu et al. 2017 and Karpov et al. 2019 as examples.",
            "generation_method": "Direct generation of reactant SMILES strings conditioned on product SMILES (template-free), often using beam search decoding.",
            "chemical_representation": "SMILES (tokenized) as sequence input/output; sometimes augmented by molecular graphs or grammar tokens in other works.",
            "target_application": "One-step retrosynthesis prediction (serves as building block for multi-step planning), alternative to template-based generation.",
            "constraints_used": "Not specified in this paper beyond general literature practices (beam size, validity checks); template-free methods may include validity/chemistry filters in other works.",
            "integration_with_external_tools": "Mentioned in context of literature — not integrated into Retro* experiments; other works combine such models with search/tree planning.",
            "dataset_used": "Literature commonly trains on USPTO reaction pairs; the paper references Liu et al. (2017) and Karpov et al. (2019).",
            "evaluation_metrics": "In literature: top-k accuracy for one-step prediction, validity of generated SMILES, and downstream planning metrics when used in multistep search; in this paper these methods are only cited, not evaluated.",
            "reported_results": "",
            "experimental_validation": null,
            "challenges_or_limitations": "Paper notes template-free seq2seq models exist but does not evaluate them; general known issues include needing large reaction-pair corpora, generating invalid SMILES, difficulty modeling atom-mapping/stoichiometry, and often lacking explicit reaction templates making application in symbolic search nontrivial.",
            "uuid": "e7093.3",
            "source_info": {
                "paper_title": "Retro*: Learning Retrosynthetic Planning with Neural Guided A* Search",
                "publication_date_yy_mm": "2020-06"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Planning chemical syntheses with deep neural networks and symbolic ai",
            "rating": 2
        },
        {
            "paper_title": "Retrosynthetic reaction prediction using neural sequence-to-sequence models",
            "rating": 2
        },
        {
            "paper_title": "A transformer model for retrosynthesis",
            "rating": 2
        },
        {
            "paper_title": "Computer-assisted retrosynthesis based on molecular similarity",
            "rating": 1
        },
        {
            "paper_title": "Learning retrosynthetic planning through simulated experience",
            "rating": 1
        }
    ],
    "cost": 0.01304575,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>Retro<em>: Learning Retrosynthetic Planning with Neural Guided A</em> Search</h1>
<p>Binghong Chen ${ }^{1}$ Chengtao $\mathbf{L i}^{2}$ Hanjun Dai ${ }^{3}$ Le Song ${ }^{14}$</p>
<h4>Abstract</h4>
<p>Retrosynthetic planning is a critical task in organic chemistry which identifies a series of reactions that can lead to the synthesis of a target product. The vast number of possible chemical transformations makes the size of the search space very big, and retrosynthetic planning is challenging even for experienced chemists. However, existing methods either require expensive return estimation by rollout with high variance, or optimize for search speed rather than the quality. In this paper, we propose Retro<em>, a neural-based A</em>-like algorithm that finds high-quality synthetic routes efficiently. It maintains the search as an ANDOR tree, and learns a neural search bias with offpolicy data. Then guided by this neural network, it performs best-first search efficiently during new planning episodes. Experiments on benchmark USPTO datasets show that, our proposed method outperforms existing state-of-the-art with respect to both the success rate and solution quality, while being more efficient at the same time.</p>
<h2>1. Introduction</h2>
<p>Retrosynthetic planning is one of the fundamental problems in organic chemistry. Given a target product, the goal of retrosynthesis is to identify a series of reactions that can lead to the synthesis of the product, by searching backwards and iteratively applying chemical transformations to unavailable molecules. As thousands of theoretically-possible transformations can all be applied during each step of reactions, the search space of planning will be huge and makes the problem challenging even for experienced chemists.</p>
<p>The one-step retrosynthesis prediction, which predicts a list of possible direct reactants given product, serves as the foundation for realizing the multistep retrosynthetic planning.</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup>Existing methods roughly fall into two categories, either template-based or template-free. Each chemical reaction is associated with a reaction template that encodes how atoms and bonds change during the reaction. Given a target product, template-based methods predict the possible reaction templates, and subsequently apply the predicted reaction templates to target molecule to get corresponding reactants. Existing methods include retrosim (Coley et al., 2017), neuralsym (Segler \&amp; Waller, 2017) and GLN (Dai et al., 2019). Though conceptually straightforward, template-based methods need to deal with tens or even hundreds of thousands of possible reaction templates, making the classification task hard. Besides, templates are not always available for chemical reactions. Due to these reasons, people have also been developing template-free methods that could directly predict reactants. Most of existing methods employ seq2seq models like LSTM (Liu et al., 2017) or Transformer (Karpov et al., 2019) from neural machine translation literature.</p>
<p>While one-step methods are continuously being improved, most molecules in real world cannot be synthesized within one step. Possible number of synthesis steps could go up to 60 or even more. Since each molecule could be synthesized by hundreds of different possible reactants, the possible synthesis routes becomes countless for a single product. Such huge space poses challenges for efficient searching and planning, even with advanced one-step approaches.</p>
<p>Besides the huge search space, another challenge is the ambiguity in performance measure and benchmarking. It has been extremely hard to quantitatively analyze the performance of any multi-step retrosynthesis algorithms due to the ambiguous definition of 'good synthesis routes', nor are there any benchmark datasets for analyzing designed algorithms. Most common ways for quantitative analysis is to employ domain experts and let them judge if one synthesis route is better than the other based solely on their experiences, which is both time-consuming and costly.</p>
<p>Due to aforementioned challenges, there are less work proposed in the field of multi-step retrosynthetic planning. Previous works using Monte Carlo Tree Search (MCTS) (Segler et al., 2018; 2017) have achieved superior results over neuralor heuristic-based Breadth First Search (BFS). However, MCTS-based methods has several limitations in this setting:</p>
<ul>
<li>Each tree node corresponds to a set of molecules instead</li>
</ul>
<p>of single molecule. This addtional combinatorial aspect make the representation of tree node, and the estimation of its value even harder. Furthermore, reactions do not explicilty appear as nodes in the tree, which prevents their algorithm from exploiting the structure of subproblems.</p>
<ul>
<li>As the algorithm depends on online value estimation, the full rollout from vanilla MCTS may not be efficient for the planning need. Furthermore, the algorithm can not exploit historical data in that many good retrosynthesis plans may have been found previously, and "intuitions" on how to plan efficiently may be learned from these histories.</li>
</ul>
<p>For quantitative evaluation, they have employed numerous domain experts to conduct A-B tests over methods proposed by their algorithm and other baselines.</p>
<p>In this paper, we present a novel neural-guided tree search method, called Retro*1, for chemical retrosynthesis planning. In our method,</p>
<ul>
<li>We explicitly maintain information about reactions as nodes in an AND-OR tree, where a node with "AND" type corresponds to a reaction, and a node with "OR" type corresponds to a molecule. The tree captures the relations between candidate reactions and reactant molecules, which allows us to exploit structure of subproblems corresponding to a single molecule.</li>
<li>Based on the AND-OR tree representation, we propose an A*-like planning algorithm which is guided by a neural network learned from past retrosynthesis planning experiences. More specifially, The neural network learns a synthesis cost for each molecule, and it helps the search algorithm to pick the most promising molecule node to expand.</li>
</ul>
<p>Furthermore, we also propose a method for constructing benchmark synthesis routes data given reactions and chemical building blocks. Based on this, we construct a synthesis route dataset from benchmark reaction dataset USPTO. The route dataset is not only useful for quantitative analysis for predicted synthesis routes, but also work as training data for the neural network components in our method.</p>
<p>Below we summarize our contributions:</p>
<ul>
<li>We propose a novel learning-based retrosynthetic planning algorithm to learn from previous planning experience. The proposed algorithm outperforms state-of-theart methods by a large margin on a realworld benchmark dataset.</li>
<li>Our algorithm framework can induce a search algorithm that guarantees the optimal solution.</li>
<li>We propose a method for constructing synthesis route</li>
</ul>
<p><sup id="fnref2:0"><a class="footnote-ref" href="#fn:0">1</a></sup>datasets for quantitative analysis of multistep retorsynthetic planning methods.</p>
<p>Our planning algorithm is general in the sense that it can also be applied to other machine learning problems such as theorem proving (Yang \&amp; Deng, 2019) and hierarchical task planning (Erol, 1996). A synthetic task planning experiment is included in Appendix D to demonstrate the idea. Most related works have been mentioned in the first two sections. For more related works, please refer to Appendix E.</p>
<h2>2. Background</h2>
<p>In this section, we first state the problem and its background we are tackling in Section 2.1. Then in Section 2.2 and Section 2.3 we describe how MCTS and proof number search fit in the problem setting.</p>
<h3>2.1. Problem Statement</h3>
<p>One-step retrosynthesis: Denote the space of all molecule as $\mathcal{M}$. The one-step retrosynthesis takes a target molecule $t \in \mathcal{M}$ as input, and predicts a set of source reactants $\mathcal{S} \subset \mathcal{M}$ that can be used to synthesize $t$. This is the reverse problem of reaction outcome prediction. In our paper, we assume the existence of such one-step retrosynthesis model (or one-step model for simplicity in the rest of the paper) $B$,</p>
<p>$$
B(\cdot): \quad t \rightarrow\left{R_{i}, \mathcal{S}<em i="i">{i}, c\left(R</em>
$$}\right)\right}_{i=1}^{k</p>
<p>which outputs at most $k$ reactions $R_{i}$, the corresponding reactant sets $\mathcal{S}<em i="i">{i}$ and costs $c\left(R</em>}\right)$. The cost can be the actual price of the reaction $R_{i}$, or simply the negative loglikelihood of this reaction under model $B$. A one-step retrosynthesis model can be learned from a dataset of chemical reactions $\mathcal{D<em i="i">{\text {train }}=\left{\mathcal{S}</em>$ which have already been discovered by chemists in the past (Coley et al., 2017; Segler \&amp; Waller, 2017; Liu et al., 2017; Dai et al., 2019; Karpov et al., 2019).}, t_{i}\right}^{2</p>
<p>Retrosynthesis planning. Given a single target molecule $t \in \mathcal{M}$ and an initial set of molecules $\mathcal{I} \subset \mathcal{M}$, we are interested in synthesizing $t$ via a sequence of chemical reactions using reactants that are from or can be synthesized by $\mathcal{I}$. In this case, $\mathcal{I}$ corresponds to a set of molecules that are commercially available. The goal of retrosynthesis planning is to predict a sequence of reactions with reactants in $\mathcal{I}$ and will ultimately arrive at product $t$.</p>
<p>Instead of performing forward chaining like reasoning that starts from $\mathcal{I}$, a more efficient and commonly used method is to perform backward chaining that starts from the molecule $t$, and perform a series of one-step retrosynthesis prediction until all the reactants required are from $\mathcal{I}$. Beyond just finding such a synthesis route, our goal is to find the</p>
<p><sup id="fnref:1"><a class="footnote-ref" href="#fn:1">2</a></sup></p>
<p>retrosynthesis plan that are:</p>
<ul>
<li>High-quality:</li>
<li>The entire retrosynthesis plan should be chemically sound with high probability;</li>
<li>The reactants or chemical reactions required should have as low cost as possible;</li>
<li>Efficient: Due to the synthesis effort, the number of retrosynthesis steps should be limited.</li>
</ul>
<p>Our proposed Retro* is aiming at finding the best retrosynthesis plan with respect to above criteria in limited time. To achieve this, we also assume that the quality of a solution can be measured by the reaction cost, where such cost is known to our model.</p>
<h3>2.2. Monte Carlo Tree Search</h3>
<p><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Figure 1. Left: MCTS (Segler et al., 2018) for retrosynthesis planning. Each node represents a set of molecules. Orange nodes/molecules are available building blocks; Right: AND-OR stump illustration of $B(m)=P, Q$. Reaction $P$ requires molecule $c$ and $d$. Reaction $Q$ requires molecule $f$. Either $P$ or $Q$ can be used to synthesize $m$.</p>
<p>The Monte Carlo Tree Search (MCTS) has achieved ground breaking successes in two player games, such as GO (Silver et al., 2016; 2017). Its variant, UCT (Kocsis \&amp; Szepesvári, 2006), is especially powerful for balancing exploration and exploitation in online learning setting, and has been employed in Segler et al. (2018) for retrosynthesis planning. Specifically, as illustrated in Figure 1, the tree search start from the target molecule $t$. Each node $u$ in the current search tree $T$ represents a set of molecules $\mathcal{M}<em u="u">{u}$. Each child node $v \in \operatorname{ch}(u)$ of $u$ is obtained by selecting one molecule $m \in \mathcal{M}</em>}$ and a one-step retrosynthesis reaction $\left(R_{u v}, \mathcal{S<em u="u" v="v">{u v}, c\left(R</em>}\right)\right) \in B(m)$, where the resulting node $v$ contains molecule set $\mathcal{M<em u="u" v="v">{v}=\left(\mathcal{S}</em>$.
Despite its good performance, MCTS formulation for retrosynthesis planning has several limitations. First, the rollout needed in MCTS makes it time-consuming, and unlike in two-player zero-sum games, the retrosynthesis planning is essentially a single player game where the return estimated by random rollouts could be highly inaccurate. Second, since each tree node is a set of molecules instead of a single molecule, the combinatorial nature of this representation brings the sparsity in the variance estimation.} \cup \mathcal{M}_{u}\right) \backslash{m} \backslash \mathcal{I</p>
<h3>2.3. Proof Number Search and Variants</h3>
<p>The proof-number search (PNS) (Allis et al., 1994) is a game tree search that is designed for two-player game with binary goal. It tries to either prove or disprove the root node as fast as possible. In the retrosynthesis planning scenario, this corresponds to either proving the target molecule $t$ by finding a feasible planning path, or concluding that it is not synthesizable.</p>
<p>AND-OR Tree: The search tree of PNS is an AND-OR tree $T$, where each AND node needs all its children to be proved, while OR node requires at least one to be satisfied. Each node $u \in T$ is associated with a proof number $p n(u)$ that defines the minimum number of leaf nodes to be proved in order to prove $u$. Similarly, the disproof number $d n(u)$ finds the minimum number of leaf nodes needed to disprove $u$. With such definition, we can recursively define these numbers for internal nodes. Specifically, for AND node $u$,</p>
<p>$$
\begin{gathered}
p n(u)=\sum_{v \in c h(u)} p n(v), d n(u)=\min _{v \in c h(u)} d n(v) \
\text { and for proved nodes: } p n(u)=0, d n(u)=+\infty
\end{gathered}
$$</p>
<p>and for OR node $u$, we have</p>
<p>$$
\begin{gathered}
p n(u)=\min <em _in="\in" c="c" h_u_="h(u)" v="v">{v \in c h(u)} p n(v), d n(u)=\sum</em> d n(v) \
\text { and for disproved node: } p n(u)=+\infty, d n(u)=0
\end{gathered}
$$</p>
<p>Represent retrosynthesis planning using AND-OR tree: As illustrated in Figure 1, the application of one-step retrosynthesis model $B$ on molecule $m$ can be represented using one block of AND-OR tree (denoted as AND-OR stump), with molecule node as 'OR' node and reaction node as 'AND' node. This is because a molecule $m$ can be synthesized using any one of its children reactions (or-relation), and each reaction node requires all of its children molecules (and-relation) to be ready.</p>
<p>The search of PNS starts from the root node every time, and selects the child node with either minimum proof number or minimum disproof number, depends on whether the current node is an OR node or AND node, respectively. The process ends when a leaf node is reached, which can be either reaction or molecule node to be expanded. And after one step of retrosynthesis expansion, all the $p n(\cdot)$ and $d n(\cdot)$ of nodes along the path back to the root will be updated. The two-player game in this sense comes from the interleaving behavior of selecting proof and disproof numbers, where the first 'player' tries to prove the root while the second 'player' tries to disprove it. As both of the players behave optimally when the proof/disproof numbers are accurate, such perspective would bring the efficiency for finding a feasible synthesis path or prove that it is not synthesizable.</p>
<p>Variant: There have been several variants to improve different aspects of PNS, including different traversal strategy, different initialization methods of $p n(\cdot)$ and $d n(\cdot)$ for newly added nodes. The most recent work DFPN-E (Kishimoto</p>
<div class="codehilite"><pre><span></span><code><span class="nt">Algorithm</span><span class="w"> </span><span class="nt">1</span><span class="o">:</span><span class="w"> </span><span class="nt">Retro</span><span class="o">^</span><span class="w"> </span><span class="err">\</span><span class="o">((</span><span class="nt">t</span><span class="o">)</span><span class="err">\</span><span class="o">)</span>
<span class="w">    </span><span class="nt">Initialize</span><span class="w"> </span><span class="err">\</span><span class="o">(</span><span class="nt">T</span><span class="o">=(</span><span class="err">\</span><span class="nt">mathcal</span><span class="p">{</span><span class="err">V</span><span class="p">}</span><span class="o">,</span><span class="w"> </span><span class="err">\</span><span class="nt">mathcal</span><span class="p">{</span><span class="err">E</span><span class="p">}</span><span class="o">)</span><span class="err">\</span><span class="o">)</span><span class="w"> </span><span class="nt">with</span><span class="w"> </span><span class="err">\</span><span class="o">(</span><span class="err">\</span><span class="nt">mathcal</span><span class="p">{</span><span class="err">V</span><span class="p">}</span><span class="w"> </span><span class="err">\</span><span class="nt">leftarrow</span><span class="err">\</span><span class="p">{</span><span class="err">t\</span><span class="p">}</span><span class="o">,</span><span class="w"> </span><span class="err">\</span><span class="nt">mathcal</span><span class="p">{</span><span class="err">E</span><span class="p">}</span><span class="w"> </span><span class="err">\</span><span class="nt">leftarrow</span><span class="w"> </span><span class="err">\</span><span class="nt">emptyset</span><span class="err">\</span><span class="o">);</span>
<span class="w">    </span><span class="nt">while</span><span class="w"> </span><span class="nt">route</span><span class="w"> </span><span class="nt">not</span><span class="w"> </span><span class="nt">found</span><span class="w"> </span><span class="nt">do</span>
<span class="w">        </span><span class="err">\</span><span class="o">(</span><span class="nt">m_</span><span class="p">{</span><span class="err">\text</span><span class="w"> </span><span class="err">{next</span><span class="w"> </span><span class="p">}</span><span class="err">}</span><span class="w"> </span><span class="err">\</span><span class="nt">leftarrow</span><span class="w"> </span><span class="err">\</span><span class="nt">operatorname</span><span class="p">{</span><span class="err">argmin</span><span class="p">}</span><span class="nt">_</span><span class="p">{</span><span class="err">m</span><span class="w"> </span><span class="err">\in</span><span class="w"> </span><span class="err">\mathcal{F</span><span class="p">}</span><span class="o">(</span><span class="nt">T</span><span class="o">)</span><span class="err">}</span><span class="w"> </span><span class="nt">V_</span><span class="p">{</span><span class="err">t</span><span class="p">}</span><span class="o">(</span><span class="nt">m</span><span class="o">)</span><span class="err">\</span><span class="o">);</span>
<span class="w">        </span><span class="err">\</span><span class="o">(</span><span class="err">\</span><span class="nt">left</span><span class="err">\</span><span class="p">{</span><span class="err">R_{i</span><span class="p">}</span><span class="o">,</span><span class="w"> </span><span class="err">\</span><span class="nt">mathcal</span><span class="p">{</span><span class="err">S</span><span class="p">}</span><span class="nt">_</span><span class="p">{</span><span class="err">i</span><span class="p">}</span><span class="o">,</span><span class="w"> </span><span class="nt">c</span><span class="err">\</span><span class="nt">left</span><span class="o">(</span><span class="nt">R_</span><span class="p">{</span><span class="err">i</span><span class="p">}</span><span class="err">\</span><span class="nt">right</span><span class="o">)</span><span class="err">\</span><span class="nt">right</span><span class="err">\}</span><span class="nt">_</span><span class="p">{</span><span class="err">i=1</span><span class="p">}</span><span class="o">^</span><span class="p">{</span><span class="err">k</span><span class="p">}</span><span class="w"> </span><span class="err">\</span><span class="nt">leftarrow</span><span class="w"> </span><span class="nt">B</span><span class="err">\</span><span class="nt">left</span><span class="o">(</span><span class="nt">m_</span><span class="p">{</span><span class="err">\text</span><span class="w"> </span><span class="err">{next</span><span class="w"> </span><span class="p">}</span><span class="err">}\</span><span class="nt">right</span><span class="o">)</span><span class="err">\</span><span class="o">);</span>
<span class="w">        </span><span class="nt">for</span><span class="w"> </span><span class="err">\</span><span class="o">(</span><span class="nt">i</span><span class="w"> </span><span class="err">\</span><span class="nt">leftarrow</span><span class="w"> </span><span class="nt">1</span><span class="err">\</span><span class="o">)</span><span class="w"> </span><span class="nt">to</span><span class="w"> </span><span class="err">\</span><span class="o">(</span><span class="nt">k</span><span class="err">\</span><span class="o">)</span><span class="w"> </span><span class="nt">do</span>
<span class="w">            </span><span class="nt">Add</span><span class="w"> </span><span class="err">\</span><span class="o">(</span><span class="nt">R_</span><span class="p">{</span><span class="err">i</span><span class="p">}</span><span class="err">\</span><span class="o">)</span><span class="w"> </span><span class="nt">to</span><span class="w"> </span><span class="err">\</span><span class="o">(</span><span class="nt">T</span><span class="err">\</span><span class="o">)</span><span class="w"> </span><span class="nt">under</span><span class="w"> </span><span class="err">\</span><span class="o">(</span><span class="nt">m_</span><span class="p">{</span><span class="err">\text</span><span class="w"> </span><span class="err">{next</span><span class="w"> </span><span class="p">}</span><span class="err">}\</span><span class="o">);</span>
<span class="w">            </span><span class="nt">for</span><span class="w"> </span><span class="err">\</span><span class="o">(</span><span class="nt">j</span><span class="w"> </span><span class="err">\</span><span class="nt">leftarrow</span><span class="w"> </span><span class="nt">1</span><span class="err">\</span><span class="o">)</span><span class="w"> </span><span class="nt">to</span><span class="w"> </span><span class="err">\</span><span class="o">(</span><span class="err">\</span><span class="nt">left</span><span class="o">|</span><span class="err">\</span><span class="nt">mathcal</span><span class="p">{</span><span class="err">S</span><span class="p">}</span><span class="nt">_</span><span class="p">{</span><span class="err">i</span><span class="p">}</span><span class="err">\</span><span class="nt">right</span><span class="o">|</span><span class="err">\</span><span class="o">)</span><span class="w"> </span><span class="nt">do</span>
<span class="w">                </span><span class="nt">Add</span><span class="w"> </span><span class="err">\</span><span class="o">(</span><span class="err">\</span><span class="nt">mathcal</span><span class="p">{</span><span class="err">S</span><span class="p">}</span><span class="nt">_</span><span class="p">{</span><span class="err">i</span><span class="w"> </span><span class="err">j</span><span class="p">}</span><span class="err">\</span><span class="o">)</span><span class="w"> </span><span class="nt">to</span><span class="w"> </span><span class="err">\</span><span class="o">(</span><span class="nt">T</span><span class="err">\</span><span class="o">)</span><span class="w"> </span><span class="nt">under</span><span class="w"> </span><span class="err">\</span><span class="o">(</span><span class="nt">R_</span><span class="p">{</span><span class="err">i</span><span class="p">}</span><span class="err">\</span><span class="o">);</span>
<span class="w">        </span><span class="nt">Update</span><span class="w"> </span><span class="err">\</span><span class="o">(</span><span class="nt">V_</span><span class="p">{</span><span class="err">t</span><span class="p">}</span><span class="o">(</span><span class="nt">m</span><span class="o">)</span><span class="err">\</span><span class="o">)</span><span class="w"> </span><span class="nt">for</span><span class="w"> </span><span class="err">\</span><span class="o">(</span><span class="nt">m</span><span class="err">\</span><span class="o">)</span><span class="w"> </span><span class="nt">in</span><span class="w"> </span><span class="err">\</span><span class="o">(</span><span class="err">\</span><span class="nt">mathcal</span><span class="p">{</span><span class="err">F</span><span class="p">}</span><span class="o">(</span><span class="nt">T</span><span class="o">)</span><span class="err">\</span><span class="o">);</span>
<span class="w">    </span><span class="nt">return</span><span class="w"> </span><span class="nt">route</span><span class="o">;</span>
</code></pre></div>

<p>et al., 2019) builds on top of the depth-first variant of PNS with an additive cost in addition to classical update rule in Eq (3). Specifically, for an unsolved OR node,</p>
<p>$$
p n(u)=\min _{v \in c h(u)}(h(u, v)+p n(v))
$$</p>
<p>Here $h(u, v)$ is the function of the cost of corresponding one-step retrosynthesis. Together with manually defined thresholds, this method addresses the lopsided problem in retrosynthesis planning, i.e., the imbalance of branching factor between AND and OR nodes.</p>
<p>The variants of PNS has shown some promising results over MCTS for retrosynthesis planning. However, the twoplayer game formulation is designed for the speed of a proof, not necessarily the overall solution quality. Moreover, existing works rely on human expert to design $p n(\cdot), d n(\cdot)$ and thresholds during search. This makes it not only timeconsuming to tune, but also hard to generalize well when solving new target molecule $t$ or dealning with new one-step model or reaction data.</p>
<h2>3. Retro* Search Algorithm</h2>
<p>Our proposed Retro* is a retrosynthetic planning algorithm that works on the AND-OR search tree. It is significantly different from PNS which is also based on AND-OR tree, or other MCTS based methods in the following ways:</p>
<ul>
<li>Retro<em> utilizes AND-OR tree for single player game which only utilizes the global value estimation. This is different from PNS which models the problem as twoplayer game with both proof numbers and disproof numbers. The distinction of the objective makes Retro</em> advantageous in finding best retrosynthetic routes.</li>
<li>Retro* estimates the future value of frontier nodes with neural network that can be trained using historical retrosynthesis planning data. This is different from the expensive rollouts used in Segler et al. (2018), or the human designed heuristics in Kishimoto et al. (2019). This not only enables more accurate prediction during expansion, but also generalizes the knowledge learned from existing planning paths.</li>
</ul>
<h3>3.1. Overview of Retro*</h3>
<p>Retro* (Algorithm 1) is a best-first search algorithm, which exploits neural priors to directly optimize for the quality of the solution. The search tree $T$ is an AND-OR tree, with molecule node as 'OR' node and reaction node as 'AND' node. It starts the search tree $T$ with a single root molecule node that is the target molecule $t$. At each step, it selects a node $u$ in the frontier of $T$ (denoted as $\mathcal{F}(T)$ ) according to the value function. Then it expands $u$ with the one-step model $B(u)$ and grows $T$ with one AND-OR stump. Finally the nodes with potential dependency on $u$ will be updated. Below we first provide a big picture of the algorithm by explaining these steps one by one, then we look into details of value function design and its update in Section 3.2 and Section 3.3, respectively. Figure 2 summarizes these steps in high level.</p>
<p>Selection: Given a search tree $T$, we denote the molecule nodes as $\mathcal{V}^{m}(T)$ and reaction nodes as $\mathcal{V}^{r}(T)$, where the total nodes in $T$ will be $\mathcal{V}(T)=\mathcal{V}^{m}(T) \cup \mathcal{V}^{r}(T)$. The frontier $\mathcal{F}(T) \subseteq \mathcal{V}^{m}(T)$ contains all the molecule nodes in $T$ that haven't been expanded before. Since we want to minimize the total cost of the final solution, an ideal option to expand next would be the molecule node which is part of the best synthesis plan.</p>
<p>Suppose we already have a value function oracle $V_{t}(m \mid T)$ which tells us that under the current search tree $T$, the cost of the best plan that contains $m$ for synthesizing target $t$. We can use it to select the next node to expand:</p>
<p>$$
m_{\text {next }}=\operatorname{argmin}<em t="t">{m \in \mathcal{F}(T)} V</em>(m \mid T)
$$</p>
<p>A proper design of such $V_{t}(m \mid T)$ would not only improve search efficiency, but can also bring theoretical guarantees.</p>
<p>Expansion: After picking the node $m$ with minimum cost estimation $V_{t}(m \mid T)$, we will expand the search tree with $k$ one-step retrosynthesis proposals from $B(m)$. Specifically, for each proposed retrosynthesis reaction $\left(R_{i}, \mathcal{S}<em i="i">{i}, c\left(R</em>$, we create a molecule node under the reaction node $R$. This will create an AND-OR stump under node $m$. Unlike in MCTS (Segler et al., 2018) where multiple calls to $B(\cdot)$ is needed till a terminal state during rollout, here the expansion only requires a single call to the one-step model.}\right)\right) \in$ $B(m)$, we create a reaction node $R=R_{i}$ under node $m$, and for each molecule $m^{\prime} \in \mathcal{S}_{i</p>
<p>Update: Denote the search tree $T$ after expansion of node $m$ to be $T^{\prime}$. Such expansion obtains the corresponding cost information for one-step retrosynthesis. we utilize this more direct information to update $V_{t}\left(\cdot \mid T^{\prime}\right)$ of all other relevant nodes to provide a more accurate estimation of total cost.</p>
<p><img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Figure 2. Retro* algorithm framework. We use circles to represent molecule nodes, and squares to represent reaction nodes. An iteration consists of three phases. In the selection phase, one of the frontier molecule nodes is selected according to the cost estimation $V_{t}(m \mid T)$. Then the an AND-OR stump is expanded from the selected node. All the new reactions and molecules are added to the tree. Finally the values inside the tree are updated using the $V_{m} \mathrm{~s}$ from the newly added molecules. The left-most figure also serves as the illustration for computing $V_{t}(f \mid T) . V_{t}(f \mid T)=g_{t}(f \mid T)+h_{t}(f \mid T)$, where $g_{t}(f \mid T)=c(\mathcal{F})+c(R)$, and $h_{t}(f \mid T)=V_{a}+V_{c}+V_{f}+V_{k}$.</p>
<h3>3.2. Design of $V_{t}(m \mid T)$</h3>
<p>To properly design $V_{t}(m \mid T)$, we borrow the idea from A<em> algorithm. A</em> algorithm is a best-first search algorithm which uses the cost from start $g(\cdot)$ together with the estimation of future cost $h(\cdot)$ to select move. When such estimation is admissible, it will be guaranteed to return the optimal solution. Inspired by the A* algorithm, we decompose the value function into two parts:</p>
<p>$$
V_{t}(m \mid T)=g_{t}(m \mid T)+h_{t}(m \mid T)
$$</p>
<p>where $g_{t}(m \mid T)$ is the cost of current reactions that have happened in $T$, if $m$ should be in the final route, and $h_{t}(m \mid T)$ is the estimated cost for future reactions needed to complete such planning. Instead of explicitly calculate these two separately, we show an equivalent but simpler way to calculate $V_{t}(\cdot \mid T)$ directly.</p>
<p>Specifically, we first define $V_{m}(m \mid \emptyset)$, which is a boundary case of the value function oracle $V$ that simply tells how much cost is needed to synthesize molecule $m$. For the simplicity of notation, we denote it as $V_{m}$. Then we define the reaction number function $r n(\cdot \mid T): \mathcal{V}(T) \mapsto \mathbb{R}$ that is inspired by proof number but with different purpose:</p>
<p>$$
\begin{aligned}
&amp; r n(R \mid T)=c(R)+\sum_{m \in c h(R)} r n(m \mid T) \
&amp; r n(m \mid T)= \begin{cases}V_{m}, &amp; m \in \mathcal{F}(T) \
\min _{R \in c h(m)} r n(R \mid T), &amp; \text { otherwise }\end{cases}
\end{aligned}
$$</p>
<p>where $r n(R \mid T)$ and $r n(m \mid T)$ calculate for reaction node and molecule node, respectively. The reaction number tells the minimum estimated cost needed for a molecule or reaction to happen in the current tree. We further define $\operatorname{pr}(u \mid T): \mathcal{V}(T) \mapsto \mathcal{V}(T)$ to get the parent node of $u$, and $\mathcal{A}(u \mid T)$ be all the ancestors of node $u$. Note that $\operatorname{pr}(m \mid T) \in \mathcal{V}^{r}(T), \forall m \in \mathcal{V}^{m}(T)$ and vise versa. Then
function $V_{t}(m \mid T)$ will be:</p>
<p>$$
\begin{aligned}
V_{t}(m \mid T) &amp; =\sum_{r \in \mathcal{A}(m \mid T) \cap \mathcal{V}^{r}(T)} c(r) \
&amp; +\sum_{m^{\prime} \in \mathcal{V}^{m}(T), \operatorname{pr}\left(m^{\prime}\right) \in \mathcal{A}(m \mid T)} r n\left(m^{\prime} \mid T\right)
\end{aligned}
$$</p>
<p>The first summation calculates all the reaction cost that has happened along the path from node $m$ to root. Additionally, $\forall R \in \mathcal{A}(m \mid T) \cap \mathcal{V}^{r}(T)$, the child node $m^{\prime} \in c h(R)$ should also be synthesized, as each such reaction node $R$ is an AND node. This requirement is captured in the second summation of Eq (8). We can see that implicitly $g_{t}(m \mid T)$ sums up the cost associated with the reaction nodes in this route related to $m$, and $h_{t}(m \mid T)$ takes all the terms related to $V$. in Eq (7).</p>
<p>In Figure 2 we demonstrate the calculation of $V_{t}(m \mid T)$ with a simple example. Notice that we can compute the parts that relevant to $g_{t}(\cdot \mid T)$ with existing information. But we can only estimate the part of $h_{t}(\cdot \mid T)$ since the required reactions are not in the search tree yet. We will show how to learn this future estimation in Section 4.2.</p>
<h3>3.3. Updating $V_{t}(m \mid T)$</h3>
<p>After a node $m$ is expanded, there are several components needed to be updated to maintain the search tree state.</p>
<p>Update $r n(\cdot \mid T)$ : Following Eq (7), the reaction number for newly created molecule nodes $u$ under the subtree rooted at $m$ will be $V_{u}$, and the reaction nodes $R \in c h(m)$ will have the cost $c(R)$ added to the sum of reaction numbers in children. After that, all the nodes $u \in \mathcal{A}(m \mid T) \cup{m}$ would potentially have the reaction number updated following Eq (7). Thus this process requires the computation complexity to be $O(\operatorname{depth}(T))$. However in our implementation, we can update these nodes in a bottom-up fashion that starts from $m$, and stop anytime when an ancestor node</p>
<p>value doesn't change. This would speed up the update.
Update $V_{t}(\cdot \mid T)$ : Let $\mathcal{A}^{\prime}(m \mid T) \subseteq(\mathcal{A}(m \mid T) \cup{m}) \cap$ $\mathcal{V}^{m}(T)$ be the set of molecule nodes that have reaction number being updated in the stage above. From Eq (8) we can see, for any molecule node $u \in \mathcal{F}(T), V_{t}(u \mid T)$ will be recalculated if $\left{m^{\prime}: p r\left(m^{\prime}\right) \in \mathcal{A}(u \mid T)\right} \cap \mathcal{A}^{\prime}(m \mid T) \neq \emptyset$.</p>
<p>Remark: The expansion of a node $m$ can potentially affect all other nodes in $\mathcal{F}(T)$ in the worst case. However the expansion of a single molecule node $m$ will only affect another node $v$ in the frontier when it is on the current best synthesis solution that composes $V_{t}(v \mid T)$. For the actual implementation, we use efficient caching and lazy propagate mechanism, which will guarantee to only update the $V_{t}(v \mid T)$ when it is necessary. The implementation details of both above updates can be found in Appendix A.</p>
<h3>3.4. Guarantees on Finding the Optimal Solution</h3>
<p>Theorem 1 Assuming $V_{m}$ or its lowerbound is known for all encountered molecules $m$, Algorithm 1 is guaranteed to return an optimal solution, if the halting condition is changed to "the total costs of a found route is no larger than $\operatorname{argmin}<em t="t">{m \in \mathcal{F}(T)} V</em>(m)$ ".</p>
<p>The proof can be found in Appendix B.
Remark 1: If we define the cost of a reaction to be its negative log-likelihood, then 0 is the lowerbound of $V_{m}$ for any molecule $m$. The induced algorithm is guaranteed to find the optimal solution.</p>
<p>Remark 2: In practice, due to the limited time budget, we prefer the algorithm to return once a solution is found.</p>
<h3>3.5. Extension: Retro* on Graph Search Space</h3>
<p>We have been mainly illustrating the technique on a tree structured space. As the retrosynthesis planning is essentially performend on a directed graph (i.e., certain intermediate molecules may share the same reactants, which may further reduce the actual cost), the above calculation can be extended to the general bipartite graph $G$ with edges connecting $\mathcal{V}^{m}(G)$ and $\mathcal{V}^{r}(G)$. Due to the potential existence of loops, the calculation of Eq (7) will be performed using shortest path algorithm instead. As there will be no negative loops, shortest path algorithm will still converge. By viewing the search space as tree rather than graph, we may possibly find sub-optimal solution due to the repetition in state representation. However, as loopy synthesis is rare in real world, we mainly focus on the tree structured search in this paper, and will investigate this extension to bipartite graph space search in future work.</p>
<h2>4. Estimating $V_{m}$ from Planning Solutions</h2>
<p>Retro* requires the value function oracle $V_{m}$ to compute $V_{t}(\cdot \mid T)$ for expansion node selection. However in practice it is impossible to obtain the exact value of $V_{m}$ for every molecule $m$. Therefore we try to estimate it from previous planning data.</p>
<h3>4.1. Represention of $V_{m}$</h3>
<p>To parameterize $V_{m}$ for any molecule $m$, we first compute its Morgan fingerprint (Rogers \&amp; Hahn, 2010) of radius 2 with 2048 bits, and feed it into a single-layer fully connected neural network of hidden dimension 128, which then outputs a scalar representing $V_{m}$.</p>
<h3>4.2. Offline Learning of $V_{m}$</h3>
<p>Previous work has either used random rollout or human designed heuristics for estimating $V_{m}$, which may not be accurate enough to guide the search. Instead of learning it online during planning (Silver et al., 2017), we utilize the existing reactions in the training set $\mathcal{D}_{\text {train }}$ to train it.</p>
<p>Specifically, we construct retrosynthesis routes for feasible molecules in $\mathcal{D}<em _text="\text" _train="{train">{\text {train }}$, where the available set of molecule $\mathcal{M}$ is also given beforehand. The specific construction strategy will be covered in Section 5.1.2. The resulting dataset will be $\mathcal{R}</em>$ used in the planning solution.}}=\left{r t_{i}=\left(m_{i}, v_{i}, R_{i}, B\left(m_{i}\right)\right)\right}$, where each tuple $r t_{i}$ contains the target molecule $m_{i}$, the best entire route cost $v_{i}$, the one-step retrosynthesis candidates $B\left(m_{i}\right)$ which also contains the true one-step retrosynthesis $R_{i</p>
<p>The learning of $V_{m}$ consists of two parts, namely the value fitting which is a regression loss $\mathcal{L}<em i="i">{\text {reg }}\left(r t</em>}\right)=\left(V_{m_{i}}-v_{i}\right)^{2}$ and the consistency learning which maintains the partial order relationship between best one-step solution $R_{i}$ and other solutions $\left(R_{j}, \mathcal{S<em j="j">{j}, c\left(R</em>\right)$ :
$\mathcal{L}}\right)\right) \in B\left(m_{i<em i="i">{\text {con }}\left(r t</em>}, R_{j}\right)=\max \left{0, v_{i}+\epsilon-c\left(R_{j}\right)-\sum_{m^{\prime} \in \mathcal{S<em m_prime="m^{\prime">{j}} V</em>\right}$
where $\epsilon$ is a positive constant margin to ensure $r_{i}$ has higher priority for expansion than its alternatives even if the value estimates have tolerable noise. The overall objective is:}</p>
<p>$$
\begin{aligned}
\min <em _cdot_="(\cdot)">{V</em>}} &amp; \mathbb{E<em i="i">{r t</em>} \sim \mathcal{R<em _reg="{reg" _text="\text">{\text {train }}}\left[\mathcal{L}</em>\right)+\right. \
&amp; \left.\lambda \mathbb{E}}}\left(r t_{i<em j="j">{R</em>} \sim B\left(m_{i}\right) \backslash\left{R_{i}\right}}\left[\mathcal{L<em i="i">{\text {con }}\left(r t</em>\right)\right]\right]
\end{aligned}
$$}, R_{j</p>
<p>where $\lambda$ balances these two losses. In experiment we set it to be 1 by default.</p>
<h2>5. Experiments</h2>
<h3>5.1. Creating Benchmark Dataset</h3>
<h3>5.1.1. USPTO ReACTION DATASET</h3>
<p>We use the publicly available reaction dataset extracted from United States Patent Office (USPTO) to train one-step model</p>
<table>
<thead>
<tr>
<th>Algorithm</th>
<th>Retro*</th>
<th>Retro*-0</th>
<th>DFPN-E+</th>
<th>DFPN-E</th>
<th>MCTS+</th>
<th>MCTS</th>
<th>Greedy DFS</th>
</tr>
</thead>
<tbody>
<tr>
<td>Success rate</td>
<td>86.84%</td>
<td>79.47%</td>
<td>53.68%</td>
<td>55.26%</td>
<td>35.79%</td>
<td>33.68%</td>
<td>22.63%</td>
</tr>
<tr>
<td>Time</td>
<td>156.58</td>
<td>208.58</td>
<td>289.42</td>
<td>279.67</td>
<td>365.21</td>
<td>370.51</td>
<td>388.15</td>
</tr>
<tr>
<td>Shorter routes</td>
<td>50</td>
<td>52</td>
<td>59</td>
<td>59</td>
<td>18</td>
<td>14</td>
<td>11</td>
</tr>
<tr>
<td>Better routes</td>
<td>112</td>
<td>102</td>
<td>22</td>
<td>25</td>
<td>46</td>
<td>41</td>
<td>26</td>
</tr>
</tbody>
</table>
<p>Table 1. Performance summary. Time is measured by the number of one-step model calls, with a hard limit of 500. The number of shorter and better routes are obtained from the comparison against the expert routes, in terms of number of reactions and the total costs.
and extract synthesis routes. The whole dataset consists of $\sim 3.8 M$ chemical reactions published up to September 2016. For reactions with multiple products, we duplicate them into multiple ones with one product each. After removing the duplications and reactions with wrong atom mappings, we further extract reaction templates with RDChiral ${ }^{3}$ for all reactions and discard those whose reactants cannot be obtained by applying reaction templates to their products. The remaining $\sim 1.3 M$ reactions are further split randomly into train/val/test sets following $80 \% / 10 \% / 10 \%$ proportions.</p>
<p>With reaction data, we train a template-based MLP model (Segler \&amp; Waller, 2017) for one-step retrosynthesis. Following literature, we formulate the one-step retrosynthesis as a multi-class classification problem, where given a molecule as product, the goal is to predict possible reaction templates. Reactants are obtained by applying the predicted templates to product molecule. There are in total $\sim 380 K$ distinct templates. Throughout all experiments, we take the top-50 templates predicted by MLP model and apply them on each product to get corresponding reactant lists.</p>
<h3>5.1.2. Extracting Synthesis Routes</h3>
<p>To train our value function and quantitatively analyze the predicted routes, we construct synthesis routes based on USPTO reaction dataset and a list of commercially available building blocks from eMolecules ${ }^{4}$. eMolecules consists of $231 M$ commercially available molecules that could work as ending points for our searching algorithm.</p>
<p>Given the list of building blocks, we take each molecule that have appeared in USPTO reaction data and analyze if it can be synthesized by existing reactions within USPTO training data. For each synthesizable molecule, we choose the shortest-possible synthesis routes with ending points being available building blocks in eMolecules.</p>
<p>We obtain validation and test route datasets with slightly different process. For validation dataset, we first combine train and validation reaction dataset, and then repeat aforementioned extraction procedure on the combined dataset. Since we extract routes with more reactions, synthesizable</p>
<p><sup id="fnref3:0"><a class="footnote-ref" href="#fn:0">1</a></sup>molecules will include those who could not be synthesized with original reactions and those who have shorter routes. We exclude molecules with routes of same length as in training data, and pack the remaining as validation route dataset. We apply similar procedure to test data but make sure that there is no overlap between test and training/validation set.</p>
<p>We further clean the test route dataset by only keeping the routes whose reactions are all covered by the top- 50 predictions by the one-step model. To make the test set more challenging, we filter out the easier molecules by running a heuristic-based BFS planning algorithm, and discarding the solved molecules in a fixed time limit. After processing, we obtain 299202 training routes, 65274 validation routes, 189 test routes and the corresponding target molecules.</p>
<h3>5.2. Results</h3>
<p>We compare Retro* against DFPN-E (Kishimoto et al., 2019), MCTS (Segler et al., 2018) and greedy Depth First Search (DFS) on product molecules in test route dataset described in Section 5.1.2. Greedy DFS always prioritizes the reaction with the highest likelihood. MCTS is implemented with PUCT, where we used the reaction probability provided by the one-step model as the prior to bias the search.</p>
<p>We measure both route quality and planning efficiency to evaluate the algorithm. To measure the quality of a solution route, we compare its total cost as well as its length, i.e. number of reactions in the route. The cost function is defined as the negative log-likelihood of the reaction. Therefore, minimizing the total costs is equivalent to maximizing the likelihood of the route. To measure planning effiency, we use the number of calls to the one-step model ( $\approx 0.3 s$ per call) as a surrogate of time (since it will occupy $&gt;99 \%$ of running time) and compare the success rate under the same time limit.</p>
<p>Performance summary: The performances of all algorithms are summarized in Table 1. Under the time limit of 500 one-step calls, Retro<em> solves $31 \%$ more test molecules than the second best method, DFPN-E. Among all the solutions given by Retro</em>, 50 of them are shorter than expert routes, and 112 of them are better in terms of the total costs. We also conduct an ablation study to understand the importance of the learning component in Retro<em> by evaluating its non-learning version Retro</em>-0. Retro*-0 is obtained from</p>
<p><img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>Figure 3. Left: Counts of the best solutions among all algorithms in terms of length/cost; Mid: Sample solution route from Retro*. Numbers on the edges are the likelihoods of the reactions. Yellow nodes are building blocks; Right: The corresponding dotted box part in the expert route, much longer and less probable than the solution.</p>
<p>Retro<em> by setting $V_{m}$ to 0 , which is a lowerbound of any valid values. Comparing to baseline methods, Retro</em>-0 is also showing promising results. However, it is outperformed by Retro* by $6 \%$ in terms of success rate, demonstrating the performance gain brought by learning from previous planning experience.</p>
<p>To find out whether MCTS and DFPN-E can benefit from the learned value function oracle $V_{m}$ in Retro*, we replace the reward estimation by rollout in MCTS and the proof number initialization in DFPN-E by the same $V_{m}$, calling the strengthened algorithms MCTS+ and DFPN-E+. Value function helps MCTS as expected due to having a value estimate with less variance than rollout. The performance of DFPN-E is not improved because we dont have a good initialization of the disproof number.
<img alt="img-3.jpeg" src="img-3.jpeg" /></p>
<p>Figure 4. Influence of time limit on performance.
Influence of time limit: To show the influence of time limit on performance, we plot the success rate against the number of one-step model calls in Figure 4. We can see that Retro<em> not only outperforms baseline algorithms by a large margin at the beginning, but also is improving faster than the baselines, enlarging the performance gap as the time
limit increases.
Solution quality: To evaluate the overall solution quality, for each test molecule, we collect solutions from all algorithms, and compare the route lengths and costs (see Figure 3-left). We only keep the best routes (could be multiple) for each test molecule, and count the number of best routes in total for each method. We find that in terms of total costs, Retro</em> produces $4 \times$ more best routes than the second best method. Even for the length metric, which is not the objective Retro* is optmizing for, it still achieves about the same performance as the best method.</p>
<p>As a demonstration for Retro*'s ability to find high-quality routes, we illustrate a sample solution in Figure 3-mid, where each node represents a molecule. The target molecule corresponds to the root node, and the building blocks are in yellow. The numbers on the edges indicates the likelihoods of successfully producing the corresponding reactions in realworld. The expert route provided shares the exactly the same first reaction and the same right branch with the route found by our algorithm. However, the left branch (Figure 3-right) is much longer and less probable than the corresponding part of the solution route, as shown in the dotted box region in Figure 3-mid. Please refer to Appendix C for more sample solution routes and search tree visualizations.</p>
<h2>6. Conclusion</h2>
<p>In this work, we propose Retro<em>, a learning-based retrosynthetic planning algorithm for efficiently finding high-quality routes. Retro</em> is able to utilize previous planning experience to bias the search on unseen molecules towards promising directions. We also propose a systematic approach for creating a retrosynthesis dataset from publicly available reaction datasets and novel metrics for evaluating solution routes without involving human experts. Experiments on realworld benchmark dataset demonstrate our algorithm's significant improvement over existing methods on both planning efficiency and solution quality.</p>
<h2>Acknowledgements</h2>
<p>We thank Junhong Liu, Wei Yang and Yong Liu for helpful discussions. This work is supported in part by NSF grants CDS\&amp;E-1900017 D3SC, CCF-1836936 FMitF, IIS1841351, CAREER IIS-1350983, CNS-1704701, ONR MURI grant to L.S.</p>
<h2>References</h2>
<p>Allis, L. V., van der Meulen, M., and Van Den Herik, H. J. Proof-number search. Artificial Intelligence, 66(1):91124, 1994.</p>
<p>Chen, B., Dai, B., Lin, Q., Ye, G., Liu, H., and Song, L. Learning to plan in high dimensions via neural exploration-exploitation trees. In International Conference on Learning Representations, 2020.</p>
<p>Coley, C. W., Rogers, L., Green, W. H., and Jensen, K. F. Computer-assisted retrosynthesis based on molecular similarity. ACS Central Science, 3(12):1237-1245, 2017.</p>
<p>Dai, H., Li, C., Coley, C., Dai, B., and Song, L. Retrosynthesis prediction with conditional graph logic network. In Advances in Neural Information Processing Systems, pp. 8870-8880, 2019.</p>
<p>Erol, K. Hierarchical task network planning: formalization, analysis, and implementation. PhD thesis, 1996.</p>
<p>Guez, A., Weber, T., Antonoglou, I., Simonyan, K., Vinyals, O., Wierstra, D., Munos, R., and Silver, D. Learning to search with MCTSnets. arXiv preprint arXiv:1802.04697, 2018.</p>
<p>Hart, P. E., Nilsson, N. J., and Raphael, B. A formal basis for the heuristic determination of minimum cost paths. IEEE transactions on Systems Science and Cybernetics, 4(2):100-107, 1968.</p>
<p>Karpov, P., Godin, G., and Tetko, I. A transformer model for retrosynthesis. 2019.</p>
<p>Kishimoto, A., Buesser, B., Chen, B., and Botea, A. Depthfirst proof-number search with heuristic edge cost and application to chemical synthesis planning. In Advances in Neural Information Processing Systems, pp. 7224-7234, 2019.</p>
<p>Kocsis, L. and Szepesvári, C. Bandit based Monte-Carlo planning. In European conference on machine learning, pp. 282-293. Springer, 2006.</p>
<p>Liu, B., Ramsundar, B., Kawthekar, P., Shi, J., Gomes, J., Luu Nguyen, Q., Ho, S., Sloane, J., Wender, P., and Pande, V. Retrosynthetic reaction prediction using neural sequence-to-sequence models. ACS Central Science, 3 (10):1103-1113, 2017.</p>
<p>Rogers, D. and Hahn, M. Extended-connectivity fingerprints. Journal of chemical information and modeling, 50 (5):742-754, 2010.</p>
<p>Schreck, J. S., Coley, C. W., and Bishop, K. J. Learning retrosynthetic planning through simulated experience. $A C S$ Central Science.</p>
<p>Segler, M., Preuß, M., and Waller, M. P. Towards" alphachem": Chemical synthesis planning with tree search and deep neural network policies. arXiv preprint arXiv:1702.00020, 2017.</p>
<p>Segler, M. H. and Waller, M. P. Neural-symbolic machine learning for retrosynthesis and reaction prediction. Chemistry-A European Journal, 23(25):5966-5971, 2017.</p>
<p>Segler, M. H., Preuss, M., and Waller, M. P. Planning chemical syntheses with deep neural networks and symbolic ai. Nature, 555(7698):604, 2018.</p>
<p>Silver, D., Huang, A., Maddison, C. J., Guez, A., Sifre, L., Van Den Driessche, G., Schrittwieser, J., Antonoglou, I., Panneershelvam, V., Lanctot, M., et al. Mastering the game of GO with deep neural networks and tree search. nature, 529(7587):484, 2016.</p>
<p>Silver, D., Schrittwieser, J., Simonyan, K., Antonoglou, I., Huang, A., Guez, A., Hubert, T., Baker, L., Lai, M., Bolton, A., et al. Mastering the game of GO without human knowledge. Nature, 550(7676):354-359, 2017.</p>
<p>Yang, K. and Deng, J. Learning to prove theorems via interacting with proof assistants. arXiv preprint arXiv:1905.09381, 2019.</p>
<h1>A. Implementation details</h1>
<p><img alt="img-4.jpeg" src="img-4.jpeg" /></p>
<p>Figure 5. Illustration for the update process. Three phases correspond to line 1-8, line 11-16, and line 17-21 in Algorithm 2.
In this section we describe the algorithm details in the update phase of Retro*. The goal of the update phase is to compute the up-to-date $V_{t}(m \mid T)$ for every molecule node $m \in \mathcal{F}(T)$. To implement efficient update, we need to cache $V_{t}(m \mid T)$ for all $m \in \mathcal{V}^{m}(T)$. Note that from Eq (8), we can observe the fact that sibling molecule nodes have the same $V_{t}(m \mid T)$, i.e. $V_{t}\left(m_{a} \mid T\right)=V_{t}\left(m_{b} \mid T\right)$ if $p r\left(m_{a} \mid T\right)=p r\left(m_{b} \mid T\right)$. Therefore instead of storing the value of $V_{t}(m \mid T)$ in every molecule node $m$, we store the value in their common parent via defining $V_{t}(R \mid T)=V_{t}(m \mid T)$ if $R=p r(m \mid T)$ for every reaction node $R \in \mathcal{V}^{r}(T)$.
In our implementation, we cache $V_{t}(R \mid T)$ for all reaction nodes $R \in \mathcal{V}^{r}(T)$ and cache $r n(v \mid T)$ for all nodes $v \in \mathcal{V}(T)$. Caching values in this way would allow us to visit each related node only once for minimal update.</p>
<div class="codehilite"><pre><span></span><code><span class="nt">Algorithm</span><span class="w"> </span><span class="nt">2</span><span class="o">:</span><span class="w"> </span><span class="nt">Update</span><span class="w"> </span><span class="err">\</span><span class="o">(</span><span class="err">\</span><span class="nt">left</span><span class="o">(</span><span class="nt">m_</span><span class="p">{</span><span class="err">\text</span><span class="w"> </span><span class="err">{next</span><span class="w"> </span><span class="p">}</span><span class="err">}</span><span class="o">,</span><span class="err">\</span><span class="nt">left</span><span class="err">\</span><span class="p">{</span><span class="err">R_{i</span><span class="p">}</span><span class="o">,</span><span class="w"> </span><span class="err">\</span><span class="nt">mathcal</span><span class="p">{</span><span class="err">S</span><span class="p">}</span><span class="nt">_</span><span class="p">{</span><span class="err">i</span><span class="p">}</span><span class="o">,</span><span class="w"> </span><span class="nt">c</span><span class="err">\</span><span class="nt">left</span><span class="o">(</span><span class="nt">R_</span><span class="p">{</span><span class="err">i</span><span class="p">}</span><span class="err">\</span><span class="nt">right</span><span class="o">)</span><span class="err">\</span><span class="nt">right</span><span class="err">\}</span><span class="nt">_</span><span class="p">{</span><span class="err">i=1</span><span class="p">}</span><span class="o">^</span><span class="p">{</span><span class="err">k</span><span class="p">}</span><span class="err">\</span><span class="nt">right</span><span class="o">)^</span><span class="p">{</span><span class="err">5</span><span class="p">}</span><span class="err">\</span><span class="o">)</span>
<span class="nt">for</span><span class="w"> </span><span class="err">\</span><span class="o">(</span><span class="nt">i</span><span class="w"> </span><span class="err">\</span><span class="nt">leftarrow</span><span class="w"> </span><span class="nt">1</span><span class="err">\</span><span class="o">)</span><span class="w"> </span><span class="nt">to</span><span class="w"> </span><span class="err">\</span><span class="o">(</span><span class="nt">k</span><span class="err">\</span><span class="o">)</span><span class="w"> </span><span class="nt">do</span>
<span class="w">    </span><span class="nt">for</span><span class="w"> </span><span class="err">\</span><span class="o">(</span><span class="nt">m</span><span class="w"> </span><span class="err">\</span><span class="nt">in</span><span class="w"> </span><span class="err">\</span><span class="nt">mathcal</span><span class="p">{</span><span class="err">S</span><span class="p">}</span><span class="nt">_</span><span class="p">{</span><span class="err">i</span><span class="p">}</span><span class="err">\</span><span class="o">)</span><span class="w"> </span><span class="nt">do</span>
<span class="w">        </span><span class="err">\</span><span class="o">(</span><span class="nt">r</span><span class="w"> </span><span class="nt">n</span><span class="o">(</span><span class="nt">m</span><span class="o">)</span><span class="w"> </span><span class="err">\</span><span class="nt">leftarrow</span><span class="w"> </span><span class="nt">V_</span><span class="p">{</span><span class="err">m</span><span class="p">}</span><span class="err">\</span><span class="o">)</span>
<span class="w">        </span><span class="err">\</span><span class="o">(</span><span class="nt">r</span><span class="w"> </span><span class="nt">n</span><span class="err">\</span><span class="nt">left</span><span class="o">(</span><span class="nt">R_</span><span class="p">{</span><span class="err">i</span><span class="p">}</span><span class="err">\</span><span class="nt">right</span><span class="o">)</span><span class="w"> </span><span class="err">\</span><span class="nt">leftarrow</span><span class="w"> </span><span class="nt">c</span><span class="err">\</span><span class="nt">left</span><span class="o">(</span><span class="nt">R_</span><span class="p">{</span><span class="err">i</span><span class="p">}</span><span class="err">\</span><span class="nt">right</span><span class="o">)+</span><span class="err">\</span><span class="nt">sum_</span><span class="p">{</span><span class="err">m</span><span class="w"> </span><span class="err">\in</span><span class="w"> </span><span class="err">\mathcal{S</span><span class="p">}</span><span class="nt">_</span><span class="p">{</span><span class="err">i</span><span class="p">}</span><span class="err">}</span><span class="w"> </span><span class="nt">r</span><span class="w"> </span><span class="nt">n</span><span class="o">(</span><span class="nt">m</span><span class="o">)</span><span class="err">\</span><span class="o">)</span>
<span class="w">        </span><span class="err">\</span><span class="o">(</span><span class="nt">V_</span><span class="p">{</span><span class="err">t</span><span class="p">}</span><span class="err">\</span><span class="nt">left</span><span class="o">(</span><span class="nt">R_</span><span class="p">{</span><span class="err">i</span><span class="p">}</span><span class="err">\</span><span class="nt">right</span><span class="o">)</span><span class="w"> </span><span class="err">\</span><span class="nt">leftarrow</span><span class="w"> </span><span class="nt">V_</span><span class="p">{</span><span class="err">t</span><span class="p">}</span><span class="err">\</span><span class="nt">left</span><span class="o">(</span><span class="nt">p</span><span class="w"> </span><span class="nt">r</span><span class="err">\</span><span class="nt">left</span><span class="o">(</span><span class="nt">m_</span><span class="p">{</span><span class="err">\text</span><span class="w"> </span><span class="err">{next</span><span class="w"> </span><span class="p">}</span><span class="err">}\</span><span class="nt">right</span><span class="o">)</span><span class="err">\</span><span class="nt">right</span><span class="o">)</span><span class="nt">-r</span><span class="w"> </span><span class="nt">n</span><span class="err">\</span><span class="nt">left</span><span class="o">(</span><span class="nt">m_</span><span class="p">{</span><span class="err">\text</span><span class="w"> </span><span class="err">{next</span><span class="w"> </span><span class="p">}</span><span class="err">}\</span><span class="nt">right</span><span class="o">)+</span><span class="nt">r</span><span class="w"> </span><span class="nt">n</span><span class="err">\</span><span class="nt">left</span><span class="o">(</span><span class="nt">R_</span><span class="p">{</span><span class="err">i</span><span class="p">}</span><span class="err">\</span><span class="nt">right</span><span class="o">)</span><span class="err">\</span><span class="o">)</span>
<span class="w">    </span><span class="err">\</span><span class="o">(</span><span class="err">\</span><span class="nt">operatorname</span><span class="p">{</span><span class="err">new</span><span class="p">}</span><span class="w"> </span><span class="err">\</span><span class="nt">cdot</span><span class="w"> </span><span class="nt">r</span><span class="w"> </span><span class="nt">n</span><span class="w"> </span><span class="err">\</span><span class="nt">leftarrow</span><span class="w"> </span><span class="err">\</span><span class="nt">min</span><span class="w"> </span><span class="nt">_</span><span class="p">{</span><span class="err">i</span><span class="w"> </span><span class="err">\in\{1,2,</span><span class="w"> </span><span class="err">\cdots,</span><span class="w"> </span><span class="err">k\</span><span class="p">}</span><span class="err">}</span><span class="w"> </span><span class="nt">r</span><span class="w"> </span><span class="nt">n</span><span class="err">\</span><span class="nt">left</span><span class="o">(</span><span class="nt">R_</span><span class="p">{</span><span class="err">i</span><span class="p">}</span><span class="err">\</span><span class="nt">right</span><span class="o">)</span><span class="err">\</span><span class="o">);</span>
<span class="w">    </span><span class="nt">delta</span><span class="w"> </span><span class="err">\</span><span class="o">(</span><span class="err">\</span><span class="nt">leftarrow</span><span class="err">\</span><span class="o">)</span><span class="w"> </span><span class="nt">new_rn-rn</span><span class="w"> </span><span class="err">\</span><span class="o">(</span><span class="err">\</span><span class="nt">left</span><span class="o">(</span><span class="nt">m_</span><span class="p">{</span><span class="err">\text</span><span class="w"> </span><span class="err">{next</span><span class="w"> </span><span class="p">}</span><span class="err">}\</span><span class="nt">right</span><span class="o">)</span><span class="err">\</span><span class="o">);</span>
<span class="w">    </span><span class="err">\</span><span class="o">(</span><span class="nt">r</span><span class="w"> </span><span class="nt">n</span><span class="err">\</span><span class="nt">left</span><span class="o">(</span><span class="nt">m_</span><span class="p">{</span><span class="err">\text</span><span class="w"> </span><span class="err">{next</span><span class="w"> </span><span class="p">}</span><span class="err">}\</span><span class="nt">right</span><span class="o">)</span><span class="w"> </span><span class="err">\</span><span class="nt">leftarrow</span><span class="err">\</span><span class="o">)</span><span class="w"> </span><span class="nt">new_rn</span><span class="o">;</span>
<span class="w">    </span><span class="err">\</span><span class="o">(</span><span class="nt">m_</span><span class="p">{</span><span class="err">\text</span><span class="w"> </span><span class="err">{current</span><span class="w"> </span><span class="p">}</span><span class="err">}</span><span class="w"> </span><span class="err">\</span><span class="nt">leftarrow</span><span class="w"> </span><span class="nt">m_</span><span class="p">{</span><span class="err">\text</span><span class="w"> </span><span class="err">{next</span><span class="w"> </span><span class="p">}</span><span class="err">}\</span><span class="o">);</span>
<span class="w">    </span><span class="nt">while</span><span class="w"> </span><span class="nt">delta</span><span class="w"> </span><span class="err">\</span><span class="o">(</span><span class="err">\</span><span class="nt">neq</span><span class="w"> </span><span class="nt">0</span><span class="err">\</span><span class="o">)</span><span class="w"> </span><span class="nt">and</span><span class="w"> </span><span class="err">\</span><span class="o">(</span><span class="nt">m_</span><span class="p">{</span><span class="err">\text</span><span class="w"> </span><span class="err">{current</span><span class="w"> </span><span class="p">}</span><span class="err">}\</span><span class="o">)</span><span class="w"> </span><span class="nt">is</span><span class="w"> </span><span class="nt">not</span><span class="w"> </span><span class="nt">root</span><span class="w"> </span><span class="nt">do</span>
<span class="w">        </span><span class="err">\</span><span class="o">(</span><span class="nt">R_</span><span class="p">{</span><span class="err">\text</span><span class="w"> </span><span class="err">{current</span><span class="w"> </span><span class="p">}</span><span class="err">}</span><span class="w"> </span><span class="err">\</span><span class="nt">leftarrow</span><span class="w"> </span><span class="nt">p</span><span class="w"> </span><span class="nt">r</span><span class="err">\</span><span class="nt">left</span><span class="o">(</span><span class="nt">m_</span><span class="p">{</span><span class="err">\text</span><span class="w"> </span><span class="err">{current</span><span class="w"> </span><span class="p">}</span><span class="err">}\</span><span class="nt">right</span><span class="o">)</span><span class="err">\</span><span class="o">);</span>
<span class="w">        </span><span class="err">\</span><span class="o">(</span><span class="nt">r</span><span class="w"> </span><span class="nt">n</span><span class="err">\</span><span class="nt">left</span><span class="o">(</span><span class="nt">R_</span><span class="p">{</span><span class="err">\text</span><span class="w"> </span><span class="err">{current</span><span class="w"> </span><span class="p">}</span><span class="err">}\</span><span class="nt">right</span><span class="o">)</span><span class="w"> </span><span class="err">\</span><span class="nt">leftarrow</span><span class="w"> </span><span class="nt">r</span><span class="w"> </span><span class="nt">n</span><span class="err">\</span><span class="nt">left</span><span class="o">(</span><span class="nt">R_</span><span class="p">{</span><span class="err">\text</span><span class="w"> </span><span class="err">{current</span><span class="w"> </span><span class="p">}</span><span class="err">}\</span><span class="nt">right</span><span class="o">)+</span><span class="err">\</span><span class="o">)</span><span class="w"> </span><span class="nt">delta</span><span class="o">;</span>
<span class="w">        </span><span class="err">\</span><span class="o">(</span><span class="nt">V_</span><span class="p">{</span><span class="err">t</span><span class="p">}</span><span class="err">\</span><span class="nt">left</span><span class="o">(</span><span class="nt">R_</span><span class="p">{</span><span class="err">\text</span><span class="w"> </span><span class="err">{current</span><span class="w"> </span><span class="p">}</span><span class="err">}\</span><span class="nt">right</span><span class="o">)</span><span class="w"> </span><span class="err">\</span><span class="nt">leftarrow</span><span class="w"> </span><span class="nt">V_</span><span class="p">{</span><span class="err">t</span><span class="p">}</span><span class="err">\</span><span class="nt">left</span><span class="o">(</span><span class="nt">R_</span><span class="p">{</span><span class="err">\text</span><span class="w"> </span><span class="err">{current</span><span class="w"> </span><span class="p">}</span><span class="err">}\</span><span class="nt">right</span><span class="o">)+</span><span class="err">\</span><span class="o">)</span><span class="w"> </span><span class="nt">delta</span><span class="o">;</span>
<span class="w">        </span><span class="nt">for</span><span class="w"> </span><span class="err">\</span><span class="o">(</span><span class="nt">m</span><span class="w"> </span><span class="err">\</span><span class="nt">in</span><span class="w"> </span><span class="err">\</span><span class="nt">operatorname</span><span class="p">{</span><span class="err">ch</span><span class="p">}</span><span class="err">\</span><span class="nt">left</span><span class="o">(</span><span class="nt">R_</span><span class="p">{</span><span class="err">\text</span><span class="w"> </span><span class="err">{current</span><span class="w"> </span><span class="p">}</span><span class="err">}\</span><span class="nt">right</span><span class="o">)</span><span class="err">\</span><span class="o">)</span><span class="w"> </span><span class="nt">do</span>
<span class="w">            </span><span class="nt">if</span><span class="w"> </span><span class="err">\</span><span class="o">(</span><span class="nt">m</span><span class="err">\</span><span class="o">)</span><span class="w"> </span><span class="nt">is</span><span class="w"> </span><span class="nt">not</span><span class="w"> </span><span class="err">\</span><span class="o">(</span><span class="nt">m_</span><span class="p">{</span><span class="err">\text</span><span class="w"> </span><span class="err">{current</span><span class="w"> </span><span class="p">}</span><span class="err">}\</span><span class="o">)</span><span class="w"> </span><span class="nt">then</span>
<span class="w">                </span><span class="nt">UpdateSibling</span><span class="w"> </span><span class="err">\</span><span class="o">((</span><span class="nt">m</span><span class="err">\</span><span class="o">),</span><span class="w"> </span><span class="nt">delta</span><span class="w"> </span><span class="err">\</span><span class="o">()</span><span class="err">\</span><span class="o">);</span>
<span class="w">        </span><span class="err">\</span><span class="o">(</span><span class="nt">m_</span><span class="p">{</span><span class="err">\text</span><span class="w"> </span><span class="err">{current</span><span class="w"> </span><span class="p">}</span><span class="err">}</span><span class="w"> </span><span class="err">\</span><span class="nt">leftarrow</span><span class="w"> </span><span class="nt">p</span><span class="w"> </span><span class="nt">r</span><span class="err">\</span><span class="nt">left</span><span class="o">(</span><span class="nt">R_</span><span class="p">{</span><span class="err">\text</span><span class="w"> </span><span class="err">{current</span><span class="w"> </span><span class="p">}</span><span class="err">}\</span><span class="nt">right</span><span class="o">)</span><span class="err">\</span><span class="o">);</span>
<span class="w">        </span><span class="nt">delta</span><span class="w"> </span><span class="err">\</span><span class="o">(=</span><span class="nt">0</span><span class="err">\</span><span class="o">);</span>
<span class="w">        </span><span class="nt">if</span><span class="w"> </span><span class="err">\</span><span class="o">(</span><span class="nt">r</span><span class="w"> </span><span class="nt">n</span><span class="err">\</span><span class="nt">left</span><span class="o">(</span><span class="nt">R_</span><span class="p">{</span><span class="err">\text</span><span class="w"> </span><span class="err">{current</span><span class="w"> </span><span class="p">}</span><span class="err">}\</span><span class="nt">right</span><span class="o">)&lt;</span><span class="nt">r</span><span class="w"> </span><span class="nt">n</span><span class="err">\</span><span class="nt">left</span><span class="o">(</span><span class="nt">m_</span><span class="p">{</span><span class="err">\text</span><span class="w"> </span><span class="err">{current</span><span class="w"> </span><span class="p">}</span><span class="err">}\</span><span class="nt">right</span><span class="o">)</span><span class="err">\</span><span class="o">)</span><span class="w"> </span><span class="nt">then</span>
<span class="w">            </span><span class="nt">delta</span><span class="w"> </span><span class="err">\</span><span class="o">(</span><span class="err">\</span><span class="nt">leftarrow</span><span class="w"> </span><span class="nt">r</span><span class="w"> </span><span class="nt">n</span><span class="err">\</span><span class="nt">left</span><span class="o">(</span><span class="nt">R_</span><span class="p">{</span><span class="err">\text</span><span class="w"> </span><span class="err">{current</span><span class="w"> </span><span class="p">}</span><span class="err">}\</span><span class="nt">right</span><span class="o">)</span><span class="nt">-r</span><span class="w"> </span><span class="nt">n</span><span class="err">\</span><span class="nt">left</span><span class="o">(</span><span class="nt">m_</span><span class="p">{</span><span class="err">\text</span><span class="w"> </span><span class="err">{current</span><span class="w"> </span><span class="p">}</span><span class="err">}\</span><span class="nt">right</span><span class="o">)</span><span class="err">\</span><span class="o">);</span>
<span class="w">            </span><span class="err">\</span><span class="o">(</span><span class="nt">r</span><span class="w"> </span><span class="nt">n</span><span class="err">\</span><span class="nt">left</span><span class="o">(</span><span class="nt">m_</span><span class="p">{</span><span class="err">\text</span><span class="w"> </span><span class="err">{current</span><span class="w"> </span><span class="p">}</span><span class="err">}\</span><span class="nt">right</span><span class="o">)</span><span class="w"> </span><span class="err">\</span><span class="nt">leftarrow</span><span class="w"> </span><span class="nt">r</span><span class="w"> </span><span class="nt">n</span><span class="err">\</span><span class="nt">left</span><span class="o">(</span><span class="nt">R_</span><span class="p">{</span><span class="err">\text</span><span class="w"> </span><span class="err">{current</span><span class="w"> </span><span class="p">}</span><span class="err">}\</span><span class="nt">right</span><span class="o">)</span><span class="err">\</span><span class="o">);</span>
</code></pre></div>

<p>The update function is summarized in Algorithm 2 and illustrated in Figure 5, which takes in the expanded node $m_{\text {next }}$ and the expansion result $\left{R_{i}, \mathcal{S}<em i="i">{i}, c\left(R</em>$, and performs updates to affected nodes. We first compute the values for new}\right)\right}_{i=1}^{k</p>
<p><sup id="fnref4:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>reactions according to Eq (7) and (8) in line 1-8. Then we update the ancestor nodes of $m_{\text {next }}$ in a bottom-up fashion in line 9-21. We also update the molecule nodes in the sibling sub-trees in line 16 and Algorithm 3.</p>
<div class="codehilite"><pre><span></span><code><span class="nt">Algorithm</span><span class="w"> </span><span class="nt">3</span><span class="o">:</span><span class="w"> </span><span class="nt">UpdateSibling</span><span class="w"> </span><span class="err">\</span><span class="o">((</span><span class="nt">m</span><span class="o">,</span><span class="w"> </span><span class="err">\</span><span class="nt">operatorname</span><span class="p">{</span><span class="err">delta</span><span class="p">}</span><span class="o">)</span><span class="err">\</span><span class="o">)</span>
<span class="err">\</span><span class="o">(</span><span class="nt">1</span><span class="w"> </span><span class="nt">r</span><span class="w"> </span><span class="nt">n</span><span class="o">(</span><span class="nt">m</span><span class="w"> </span><span class="err">\</span><span class="nt">mid</span><span class="w"> </span><span class="nt">T</span><span class="o">)</span><span class="w"> </span><span class="err">\</span><span class="nt">leftarrow</span><span class="w"> </span><span class="nt">r</span><span class="w"> </span><span class="nt">n</span><span class="o">(</span><span class="nt">m</span><span class="w"> </span><span class="err">\</span><span class="nt">mid</span><span class="w"> </span><span class="nt">T</span><span class="o">)+</span><span class="err">\</span><span class="nt">operatorname</span><span class="p">{</span><span class="err">delta</span><span class="p">}</span><span class="err">\</span><span class="o">);</span>
<span class="nt">2</span><span class="w"> </span><span class="nt">for</span><span class="w"> </span><span class="err">\</span><span class="o">(</span><span class="nt">R</span><span class="w"> </span><span class="err">\</span><span class="nt">in</span><span class="w"> </span><span class="nt">c</span><span class="w"> </span><span class="nt">h</span><span class="o">(</span><span class="nt">m</span><span class="w"> </span><span class="err">\</span><span class="nt">mid</span><span class="w"> </span><span class="nt">T</span><span class="o">)</span><span class="err">\</span><span class="o">)</span><span class="w"> </span><span class="nt">do</span>
<span class="nt">3</span><span class="w"> </span><span class="nt">for</span><span class="w"> </span><span class="err">\</span><span class="o">(</span><span class="nt">m</span><span class="o">^</span><span class="p">{</span><span class="err">\prime</span><span class="p">}</span><span class="w"> </span><span class="err">\</span><span class="nt">in</span><span class="w"> </span><span class="nt">c</span><span class="w"> </span><span class="nt">h</span><span class="o">(</span><span class="nt">R</span><span class="w"> </span><span class="err">\</span><span class="nt">mid</span><span class="w"> </span><span class="nt">T</span><span class="o">)</span><span class="err">\</span><span class="o">)</span><span class="w"> </span><span class="nt">do</span>
<span class="nt">4</span><span class="w"> </span><span class="err">\</span><span class="o">(</span><span class="err">\</span><span class="nt">quad</span><span class="err">\</span><span class="o">)</span><span class="w"> </span><span class="nt">UpdateSibling</span><span class="w"> </span><span class="err">\</span><span class="o">(</span><span class="err">\</span><span class="nt">left</span><span class="o">(</span><span class="nt">m</span><span class="o">^</span><span class="p">{</span><span class="err">\prime</span><span class="p">}</span><span class="err">\</span><span class="nt">right</span><span class="o">.</span><span class="err">\</span><span class="o">),</span><span class="w"> </span><span class="nt">delta</span><span class="w"> </span><span class="err">\</span><span class="o">()</span><span class="err">\</span><span class="o">);</span>
</code></pre></div>

<p>Our implementation visits a node only when necessary. When updating along the ancestor path, it immediately stops when the influence of the expansion vanishes (line 10). When updating a single node, we use a $O(1)$ delta update by leveraging the relations derived from Eq (7) and (8), avoiding a direct computation which may require $O(k)$ or $O(\operatorname{depth}(T))$ summations.</p>
<h1>B. Guarantees on finding the optimal solution</h1>
<p>Since Retro<em> is a variant of the A</em> algorithm, we can leverage existing results to prove the theoretical guarantees for Retro<em>. In this section, we first state the assumptions we make, and then prove the admissibility (Theorem 1) of Retro</em>.</p>
<p>The theoretical results in this paper build upon the assumption that we can access $\hat{V}<em m="m">{m}$, which is a lowerbound for $V</em>$.}$ for all molecules $m$. Note that this is a weak assumption, since we know 0 is a universal lowerbound for $V_{m</p>
<p>As we describe in Eq (6), $V_{t}(m \mid T)$ can be decomposed into $g_{t}(m \mid T)$ and $h_{t}(m \mid T)$, where $g_{t}(m \mid T)$ is the exact cost of the partial route through $m$ which is already in the tree, and $h_{t}(m \mid T)$ is the future costs for frontier nodes in the route which is a summation of a series of $V_{m} \mathrm{~s}$. In practice we use $\hat{V}<em t="t">{m}$ in the summation, and arrive at $\hat{h}</em>(m \mid T)$, i.e. the following lemma.}(m \mid T)$, which is a lowerbound of $h_{t</p>
<p>Lemma 2 Assuming $V_{m}$ or its lowerbound is known for all encountered molecules $m$, then the approximated future costs $\hat{h}<em t="t">{t}(m \mid T)$ in Retro* is a lowerbound of true $h</em>(m \mid T)$.</p>
<p>We re-state the admissibility result (Theorem 1) in the main text and prove it with existing results in A* literature.</p>
<p>Theorem 1 (Admissibility) Assuming $V_{m}$ or its lowerbound is known for all encountered molecules $m$, Algorithm 1 is guaranteed to return an optimal solution, if the halting condition is changed to "the total costs of a found route is no larger than $\operatorname{argmin}<em t="t">{m \in \mathcal{F}(T)} V</em>(m)$ ".</p>
<p>Proof Combine Lemma 2 and Theorem 1 in the original A* paper (Hart et al., 1968).</p>
<h2>C. Sample search trees and solution routes</h2>
<p>In this section, we present two examples of the solution routes and the corresponding search trees for target molecule $A$ and $B$ produced by Retro*.</p>
<p>Solution route for target molecule $A / B$ is illustrated in the top/bottom sub-figure of Figure 6, where a set of edges pointing from the same product molecule to reactant molecules represents an one-step chemical reaction. Molecules on the leaf nodes are all available.</p>
<p>The search trees for molecule $A$ and $B$ are illustrated in Figure 7 and Figure 8. We use reactangular boxes to represent molecules. Yellow/grey/blue boxes indicate available/unexpanded/solved molecules. Reactangular arrows are used to represent reactions. The numbers on the edges pointing from a molecule to a reaction are the probabilities produced by the one-step model. Due to space limit, we only present the minimal tree which leads to a solution.</p>
<p><img alt="img-5.jpeg" src="img-5.jpeg" /></p>
<p>Figure 6. Top/bottom: solution route produced by Retro* for molecule $A / B$. Edges point from the same product molecule to the reactant molecules represent an one-step chemical reaction.</p>
<h1>D. Retro* for hierarchical task planning</h1>
<p>As a general planning algorithm, Retro* can be applied to other machine learning problems as well, including theorem proving (Yang \&amp; Deng, 2019) and hierarchical task planning (Erol, 1996) (or HTP), etc. Below, we conduct a synthetic experiment on HTP to demonstrate the idea. In the experiment, we are trying to search for a plan to complete a target task. The tasks (OR nodes) can be completed with different methods, and each method (AND nodes) requires a sequence of subtasks to be completed. Furthermore, each method is associated with a nonnegative cost. The goal is to find a plan with minimum total cost to realize the target task by decomposing it recursively until all the leaf task nodes represent primitive tasks that we know how to execute directly. As an example, to travel from home in city $A$ to hotel in city $B$, we can take either flight, train or ship, each with its own cost. For each method, we have subtasks such as home $\rightarrow$ airport $A$, flight $(A \rightarrow B)$, and airport $B \rightarrow$ hotel. These subtasks can be further realized by several methods.</p>
<p>As usual, we want to find a plan with small cost in limited time which is measured by the number of expansions of task nodes. We use the optimal halting condition as stated in theorem 1. We compare our algorithms against DFPN-E, the best performing baseline. The results are summarized in Table 2 and 3.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Time Limit</th>
<th style="text-align: center;">15</th>
<th style="text-align: center;">20</th>
<th style="text-align: center;">25</th>
<th style="text-align: center;">30</th>
<th style="text-align: center;">35</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Retro*</td>
<td style="text-align: center;">.67</td>
<td style="text-align: center;">.91</td>
<td style="text-align: center;">.96</td>
<td style="text-align: center;">.98</td>
<td style="text-align: center;">1.</td>
</tr>
<tr>
<td style="text-align: left;">Retro*-0</td>
<td style="text-align: center;">.50</td>
<td style="text-align: center;">.86</td>
<td style="text-align: center;">.95</td>
<td style="text-align: center;">.98</td>
<td style="text-align: center;">.99</td>
</tr>
<tr>
<td style="text-align: left;">DFPN-E</td>
<td style="text-align: center;">.02</td>
<td style="text-align: center;">.33</td>
<td style="text-align: center;">.74</td>
<td style="text-align: center;">.93</td>
<td style="text-align: center;">.97</td>
</tr>
</tbody>
</table>
<p>Table 2. Success rate (higher is better) vs time limit.</p>
<p>As we can see, in terms of success rate, Retro<em> is slightly better than Retro</em>-0, and both of them are significantly better than DFPN-E. In terms of solution quality, we compute the approximation ratio ( $=$ solution cost $/$ ground truth best solution cost)</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Alg</th>
<th style="text-align: left;">Retro*</th>
<th style="text-align: left;">Retro*-0</th>
<th style="text-align: left;">DFPN-E</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Avg. AR</td>
<td style="text-align: left;">1</td>
<td style="text-align: left;">1</td>
<td style="text-align: left;">1.5</td>
</tr>
<tr>
<td style="text-align: left;">Max. AR</td>
<td style="text-align: left;">1</td>
<td style="text-align: left;">1</td>
<td style="text-align: left;">3.9</td>
</tr>
</tbody>
</table>
<p>Table 3. AR = Approximation ratio (lower is better), time limit=35.
for every solution, and verify the theoretical guarantee in theorem 1 on finding the best solution.</p>
<h1>E. Related Works</h1>
<p>Reinforcement learning algorithms (without planning) have also been considered for the retrosynthesis problem. Schreck et al. leverages self-play experience to fit a value function and uses policy iteration for learning an expansion policy. It is possible to combine it with a planning algorithm to achieve better performance in practice.</p>
<p>Learning to search from previous planning experiences has been well studied and applied to Go (Silver et al., 2016; 2017), Sokoban (Guez et al., 2018) and path planning (Chen et al., 2020). Existing methods cannot be directly applied to the retrosynthesis problem since the search space is more complicated, and the traditional representation where a node corresponds to a state is highly inefficient, as we mentioned in the discussion on MCTS in previous sections.</p>
<p><img alt="img-6.jpeg" src="img-6.jpeg" /></p>
<p>Figure 7. Search tree produced by Retro* for molecule $A$. Reactangular boxes/arrows represent molecules/reactions. Yellow/grey/blue indicate available/unexpanded/solved molecules. Numbers on the edges are the probabilities produced by the one-step model.</p>
<p><img alt="img-7.jpeg" src="img-7.jpeg" /></p>
<p>Figure 8. Search tree produced by Retro* for molecule $B$. Reactangular boxes/arrows represent molecules/reactions. Yellow/grey/blue indicate available/unexpanded/solved molecules. Numbers on the edges are the probabilities produced by the one-step model.</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>${ }^{5}$ For clarity, we omit the condition on $T$ in the notations.&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref3:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref4:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
<li id="fn:1">
<p>${ }^{2}$ For simplicity we follow the common practice to ignore the reagents and other chemical reaction conditions.&#160;<a class="footnote-backref" href="#fnref:1" title="Jump back to footnote 2 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>