<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-9217 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-9217</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-9217</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-162.html">extraction-schema-162</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <p><strong>Paper ID:</strong> paper-250113586</p>
                <p><strong>Paper Title:</strong> <a href="https://arxiv.org/pdf/2206.14384v1.pdf" target="_blank">Framing Algorithmic Recourse for Anomaly Detection</a></p>
                <p><strong>Paper Abstract:</strong> The problem of algorithmic recourse has been explored for supervised machine learning models, to provide more interpretable, transparent and robust outcomes from decision support systems. An unexplored area is that of algorithmic recourse for anomaly detection, specifically for tabular data with only discrete feature values. Here the problem is to present a set of counterfactuals that are deemed normal by the underlying anomaly detection model so that applications can utilize this information for explanation purposes or to recommend countermeasures. We present an approach -- Context preserving Algorithmic Recourse for Anomalies in Tabular data (CARAT), that is effective, scalable, and agnostic to the underlying anomaly detection model. CARAT uses a transformer based encoder-decoder model to explain an anomaly by finding features with low likelihood. Subsequently semantically coherent counterfactuals are generated by modifying the highlighted features, using the overall context of features in the anomalous instance(s). Extensive experiments help demonstrate the efficacy of CARAT.</p>
                <p><strong>Cost:</strong> 0.012</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e9217.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e9217.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>CARAT (Explainer)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Context preserving Algorithmic Recourse for Anomalies in Tabular data (Explainer component)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A Transformer-based encoder-decoder explainer trained in a masked-language-model-style on rows of categorical tabular data to predict per-entity likelihoods conditioned on the other entities; used to identify low-likelihood (out-of-context) entities for anomaly explanation and to drive generation of semantically coherent counterfactuals.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Transformer-based encoder-decoder (pretrained row encoder + decoder-R + decoder-P)</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>Transformer (encoder-decoder, MLM-style pretraining; encoder yields contextual embeddings, decoder-P predicts per-entity likelihoods)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>tabular data with strictly categorical attributes (rows treated as sequences/tuples of entities)</td>
                        </tr>
                        <tr>
                            <td><strong>data_domain</strong></td>
                            <td>shipping / bill-of-lading records (Panjiva datasets)</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>categorical co-occurrence anomalies — entities out-of-context (unexpected co-occurrence / outlier categorical combinations)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Pretrain an encoder+decoder-R with a reconstruction objective similar to Masked Language Modeling (≈20% masked, ≈20% random replacements) to learn contextual entity embeddings; freeze encoder; train decoder-P (uses first-layer entity embedding concatenated with positional encoding and the encoder's contextual embedding combined via a bilinear layer then domain-specific dense layers) to predict likelihood (sigmoid) that an entity is correct in its record (binary cross-entropy). Anomalous entities are those with low predicted likelihood; candidate replacements are found by semantic similarity from a DistMult KGE on an HIN with domain-specific metapaths; form combinatorial candidate counterfactuals and rank them by a separate anomaly detection model (MEAD or APE) to choose least-anomalous K.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_methods</strong></td>
                            <td>Replace-m (exhaustive replacement), FIMAP (adversarial perturbation proxy classifier), RCEAA (autoencoder-based optimization), Xformer-R (explainer-only baseline), MEAD and APE (anomaly detection models used to rank counterfactuals)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Feature Accuracy, Heterogeneity, Coherence, Sparsity-Index, Conditional Correctness; also computational time and stability across underlying AD models</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>CARAT obtained the best overall normalized mean score across metrics (Table 2f normalized mean = 0.9183). Feature Accuracy ≈ 0.98 on several datasets (e.g., Dataset-1: 0.9822 ± 0.0509; Dataset-2: 0.9813 ± 0.0583). Conditional Correctness typically ≈ 0.97 on several datasets (e.g., Dataset-1 0.9774 ± 0.0631). Coherence and sparsity scores show CARAT produced semantically consistent and relatively sparse counterfactuals compared to baselines; CARAT is computationally efficient compared to exhaustive Replace-m and optimization-based RCEAA.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td>CARAT outperforms baselines overall: higher Feature Accuracy and Coherence than Replace-m, FIMAP, RCEAA, and Xformer-R; achieves good Sparsity comparable to Xformer-R and better than FIMAP and RCEAA; superior normalized aggregate score (0.9183) vs. baselines (example: FIMAP 0.2410, RCEAA 0.1657, Xformer-R 0.6752). CARAT is also much faster and more scalable than Replace-m and RCEAA.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Not an anomaly detector itself — depends on a black-box anomaly detection model M (MEAD or APE) for final ranking; assumes a clean training set for M; does not account for application-specific costs, feasibility, or actionability of suggested changes; evaluated only on categorical high-cardinality tabular shipping data (may not generalize without adaptation); model size and resource requirements not specified; potential ethical risk if used adversarially.</td>
                        </tr>
                        <tr>
                            <td><strong>unique_insights</strong></td>
                            <td>Treating a table row as a 'sentence' and using Transformer MLM-style pretraining captures pairwise and higher-order co-occurrence patterns among categorical entities enabling per-entity likelihood scoring; combining such contextual likelihoods with HIN-based KGE (DistMult) plus metapaths yields semantically coherent counterfactual replacements; decoupling explanation (Transformer likelihoods) from anomaly scoring (MEAD/APE) allows model-agnostic recourse generation with competitive computational efficiency and stability across underlying AD models.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Framing Algorithmic Recourse for Anomaly Detection', 'publication_date_yy_mm': '2022-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9217.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e9217.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Xformer-R (baseline)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Xformer-R (explainer-only baseline)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A baseline variant that uses the Transformer explainer to identify low-likelihood entities, then generates counterfactuals by uniformly sampling replacement values from the corresponding domain (no semantic KGE-based selection).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Transformer-based explainer (same pretrained encoder + decoder-P architecture as CARAT)</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>Transformer (encoder with decoder-P to predict per-entity likelihood)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>tabular categorical rows</td>
                        </tr>
                        <tr>
                            <td><strong>data_domain</strong></td>
                            <td>shipping / bill-of-lading records (Panjiva datasets)</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>out-of-context categorical co-occurrence anomalies</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Identify domains/entities with low likelihood using the Transformer explainer, then replace those entity values by sampling uniformly from that domain to produce candidate counterfactuals; rank candidates using the anomaly detection model.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_methods</strong></td>
                            <td>Compared against CARAT, Replace-m, FIMAP, RCEAA, and used MEAD/APE as the anomaly scoring model</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Same as CARAT: Feature Accuracy, Heterogeneity, Coherence, Sparsity-Index, Conditional Correctness</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>Xformer-R attains good sparsity similar to CARAT but lower coherence and somewhat lower feature-accuracy; aggregate normalized performance lower than CARAT (see Table 2f: Xformer-R normalized mean ≈ 0.6752 vs CARAT 0.9183). Example Feature Accuracy: Dataset-1 0.9803 ± 0.0527 (close to CARAT) but coherence and heterogeneity metrics lag.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td>Performs better than naive baselines (Replace-m in some metrics) but worse than CARAT overall because uniform sampling of replacements ignores semantic similarity (leading to lower coherence); shows that explainer's identification of low-likelihood entities is effective but replacement strategy matters.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Uniform sampling for replacements yields less semantically coherent counterfactuals; lower coherence than KGE-based selection; still depends on an external anomaly detector for ranking; does not incorporate metapath/HIN semantics.</td>
                        </tr>
                        <tr>
                            <td><strong>unique_insights</strong></td>
                            <td>Demonstrates that the Transformer explainer alone is effective at pinpointing low-likelihood entities (high feature-accuracy), but the mechanism for selecting replacement values strongly affects the plausibility/coherence of generated counterfactuals.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Framing Algorithmic Recourse for Anomaly Detection', 'publication_date_yy_mm': '2022-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9217.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e9217.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>BERT / TabTransformer (mentioned)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>BERT; TabTransformer: referenced language-model architectures for contextual embeddings</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>BERT and TabTransformer are transformer-based contextual embedding models cited in related work as examples of language-model-style architectures applied to sequences and tabular/contextual embedding tasks; they are mentioned for motivation but not used in experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>BERT; TabTransformer</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>Transformer-based language/modeling architectures</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>text / tabular contextual embeddings (general mention)</td>
                        </tr>
                        <tr>
                            <td><strong>data_domain</strong></td>
                            <td>general (text for BERT; tabular for TabTransformer); cited for architecture relevance</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>not directly applied in this paper (mentioned as general-purpose contextual encoders)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Cited as motivations for using Transformer architectures and masked-language-model-style pretraining for capturing contextual representations; no direct application or fine-tuning for anomaly detection in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_methods</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td>Mentioned as related work motivating the architectural choice; not empirically compared in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>No limitations specific to anomaly detection are reported here since these models are only mentioned in related work; the paper notes that tabular ordering is arbitrary so Transformer ordering choices must be addressed (they use domain positional encodings).</td>
                        </tr>
                        <tr>
                            <td><strong>unique_insights</strong></td>
                            <td>Authors leverage masked-LM-like pretraining ideas (inspired by language models such as BERT) for categorical tabular rows; they emphasize positional domain encodings since rows lack natural sequential ordering.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Framing Algorithmic Recourse for Anomaly Detection', 'publication_date_yy_mm': '2022-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Entity embedding-based anomaly detection for heterogeneous categorical events <em>(Rating: 2)</em></li>
                <li>Reliable Counterfactual Explanations for Autoencoder Based Anomalies <em>(Rating: 2)</em></li>
                <li>Tabtransformer: Tabular data modeling using contextual embeddings <em>(Rating: 2)</em></li>
                <li>BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-9217",
    "paper_id": "paper-250113586",
    "extraction_schema_id": "extraction-schema-162",
    "extracted_data": [
        {
            "name_short": "CARAT (Explainer)",
            "name_full": "Context preserving Algorithmic Recourse for Anomalies in Tabular data (Explainer component)",
            "brief_description": "A Transformer-based encoder-decoder explainer trained in a masked-language-model-style on rows of categorical tabular data to predict per-entity likelihoods conditioned on the other entities; used to identify low-likelihood (out-of-context) entities for anomaly explanation and to drive generation of semantically coherent counterfactuals.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "Transformer-based encoder-decoder (pretrained row encoder + decoder-R + decoder-P)",
            "model_type": "Transformer (encoder-decoder, MLM-style pretraining; encoder yields contextual embeddings, decoder-P predicts per-entity likelihoods)",
            "model_size": null,
            "data_type": "tabular data with strictly categorical attributes (rows treated as sequences/tuples of entities)",
            "data_domain": "shipping / bill-of-lading records (Panjiva datasets)",
            "anomaly_type": "categorical co-occurrence anomalies — entities out-of-context (unexpected co-occurrence / outlier categorical combinations)",
            "method_description": "Pretrain an encoder+decoder-R with a reconstruction objective similar to Masked Language Modeling (≈20% masked, ≈20% random replacements) to learn contextual entity embeddings; freeze encoder; train decoder-P (uses first-layer entity embedding concatenated with positional encoding and the encoder's contextual embedding combined via a bilinear layer then domain-specific dense layers) to predict likelihood (sigmoid) that an entity is correct in its record (binary cross-entropy). Anomalous entities are those with low predicted likelihood; candidate replacements are found by semantic similarity from a DistMult KGE on an HIN with domain-specific metapaths; form combinatorial candidate counterfactuals and rank them by a separate anomaly detection model (MEAD or APE) to choose least-anomalous K.",
            "baseline_methods": "Replace-m (exhaustive replacement), FIMAP (adversarial perturbation proxy classifier), RCEAA (autoencoder-based optimization), Xformer-R (explainer-only baseline), MEAD and APE (anomaly detection models used to rank counterfactuals)",
            "performance_metrics": "Feature Accuracy, Heterogeneity, Coherence, Sparsity-Index, Conditional Correctness; also computational time and stability across underlying AD models",
            "performance_results": "CARAT obtained the best overall normalized mean score across metrics (Table 2f normalized mean = 0.9183). Feature Accuracy ≈ 0.98 on several datasets (e.g., Dataset-1: 0.9822 ± 0.0509; Dataset-2: 0.9813 ± 0.0583). Conditional Correctness typically ≈ 0.97 on several datasets (e.g., Dataset-1 0.9774 ± 0.0631). Coherence and sparsity scores show CARAT produced semantically consistent and relatively sparse counterfactuals compared to baselines; CARAT is computationally efficient compared to exhaustive Replace-m and optimization-based RCEAA.",
            "comparison_to_baseline": "CARAT outperforms baselines overall: higher Feature Accuracy and Coherence than Replace-m, FIMAP, RCEAA, and Xformer-R; achieves good Sparsity comparable to Xformer-R and better than FIMAP and RCEAA; superior normalized aggregate score (0.9183) vs. baselines (example: FIMAP 0.2410, RCEAA 0.1657, Xformer-R 0.6752). CARAT is also much faster and more scalable than Replace-m and RCEAA.",
            "limitations_or_failure_cases": "Not an anomaly detector itself — depends on a black-box anomaly detection model M (MEAD or APE) for final ranking; assumes a clean training set for M; does not account for application-specific costs, feasibility, or actionability of suggested changes; evaluated only on categorical high-cardinality tabular shipping data (may not generalize without adaptation); model size and resource requirements not specified; potential ethical risk if used adversarially.",
            "unique_insights": "Treating a table row as a 'sentence' and using Transformer MLM-style pretraining captures pairwise and higher-order co-occurrence patterns among categorical entities enabling per-entity likelihood scoring; combining such contextual likelihoods with HIN-based KGE (DistMult) plus metapaths yields semantically coherent counterfactual replacements; decoupling explanation (Transformer likelihoods) from anomaly scoring (MEAD/APE) allows model-agnostic recourse generation with competitive computational efficiency and stability across underlying AD models.",
            "uuid": "e9217.0",
            "source_info": {
                "paper_title": "Framing Algorithmic Recourse for Anomaly Detection",
                "publication_date_yy_mm": "2022-06"
            }
        },
        {
            "name_short": "Xformer-R (baseline)",
            "name_full": "Xformer-R (explainer-only baseline)",
            "brief_description": "A baseline variant that uses the Transformer explainer to identify low-likelihood entities, then generates counterfactuals by uniformly sampling replacement values from the corresponding domain (no semantic KGE-based selection).",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "Transformer-based explainer (same pretrained encoder + decoder-P architecture as CARAT)",
            "model_type": "Transformer (encoder with decoder-P to predict per-entity likelihood)",
            "model_size": null,
            "data_type": "tabular categorical rows",
            "data_domain": "shipping / bill-of-lading records (Panjiva datasets)",
            "anomaly_type": "out-of-context categorical co-occurrence anomalies",
            "method_description": "Identify domains/entities with low likelihood using the Transformer explainer, then replace those entity values by sampling uniformly from that domain to produce candidate counterfactuals; rank candidates using the anomaly detection model.",
            "baseline_methods": "Compared against CARAT, Replace-m, FIMAP, RCEAA, and used MEAD/APE as the anomaly scoring model",
            "performance_metrics": "Same as CARAT: Feature Accuracy, Heterogeneity, Coherence, Sparsity-Index, Conditional Correctness",
            "performance_results": "Xformer-R attains good sparsity similar to CARAT but lower coherence and somewhat lower feature-accuracy; aggregate normalized performance lower than CARAT (see Table 2f: Xformer-R normalized mean ≈ 0.6752 vs CARAT 0.9183). Example Feature Accuracy: Dataset-1 0.9803 ± 0.0527 (close to CARAT) but coherence and heterogeneity metrics lag.",
            "comparison_to_baseline": "Performs better than naive baselines (Replace-m in some metrics) but worse than CARAT overall because uniform sampling of replacements ignores semantic similarity (leading to lower coherence); shows that explainer's identification of low-likelihood entities is effective but replacement strategy matters.",
            "limitations_or_failure_cases": "Uniform sampling for replacements yields less semantically coherent counterfactuals; lower coherence than KGE-based selection; still depends on an external anomaly detector for ranking; does not incorporate metapath/HIN semantics.",
            "unique_insights": "Demonstrates that the Transformer explainer alone is effective at pinpointing low-likelihood entities (high feature-accuracy), but the mechanism for selecting replacement values strongly affects the plausibility/coherence of generated counterfactuals.",
            "uuid": "e9217.1",
            "source_info": {
                "paper_title": "Framing Algorithmic Recourse for Anomaly Detection",
                "publication_date_yy_mm": "2022-06"
            }
        },
        {
            "name_short": "BERT / TabTransformer (mentioned)",
            "name_full": "BERT; TabTransformer: referenced language-model architectures for contextual embeddings",
            "brief_description": "BERT and TabTransformer are transformer-based contextual embedding models cited in related work as examples of language-model-style architectures applied to sequences and tabular/contextual embedding tasks; they are mentioned for motivation but not used in experiments.",
            "citation_title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding.",
            "mention_or_use": "mention",
            "model_name": "BERT; TabTransformer",
            "model_type": "Transformer-based language/modeling architectures",
            "model_size": null,
            "data_type": "text / tabular contextual embeddings (general mention)",
            "data_domain": "general (text for BERT; tabular for TabTransformer); cited for architecture relevance",
            "anomaly_type": "not directly applied in this paper (mentioned as general-purpose contextual encoders)",
            "method_description": "Cited as motivations for using Transformer architectures and masked-language-model-style pretraining for capturing contextual representations; no direct application or fine-tuning for anomaly detection in this paper.",
            "baseline_methods": "",
            "performance_metrics": "",
            "performance_results": "",
            "comparison_to_baseline": "Mentioned as related work motivating the architectural choice; not empirically compared in this paper.",
            "limitations_or_failure_cases": "No limitations specific to anomaly detection are reported here since these models are only mentioned in related work; the paper notes that tabular ordering is arbitrary so Transformer ordering choices must be addressed (they use domain positional encodings).",
            "unique_insights": "Authors leverage masked-LM-like pretraining ideas (inspired by language models such as BERT) for categorical tabular rows; they emphasize positional domain encodings since rows lack natural sequential ordering.",
            "uuid": "e9217.2",
            "source_info": {
                "paper_title": "Framing Algorithmic Recourse for Anomaly Detection",
                "publication_date_yy_mm": "2022-06"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Entity embedding-based anomaly detection for heterogeneous categorical events",
            "rating": 2,
            "sanitized_title": "entity_embeddingbased_anomaly_detection_for_heterogeneous_categorical_events"
        },
        {
            "paper_title": "Reliable Counterfactual Explanations for Autoencoder Based Anomalies",
            "rating": 2,
            "sanitized_title": "reliable_counterfactual_explanations_for_autoencoder_based_anomalies"
        },
        {
            "paper_title": "Tabtransformer: Tabular data modeling using contextual embeddings",
            "rating": 2,
            "sanitized_title": "tabtransformer_tabular_data_modeling_using_contextual_embeddings"
        },
        {
            "paper_title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding.",
            "rating": 1,
            "sanitized_title": "bert_pretraining_of_deep_bidirectional_transformers_for_language_understanding"
        }
    ],
    "cost": 0.011997499999999998,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Framing Algorithmic Recourse for Anomaly Detection
29 Jun 2022</p>
<p>Debanjan Datta ddatta@vt.edu 
Virginia Tech Arlington
VirginiaUnited States Feng Chen</p>
<p>University of Texas
Dallas DallasTexasUnited States Naren Ramakrishnan</p>
<p>Virginia Tech Arlington
VirginiaUnited States</p>
<p>Framing Algorithmic Recourse for Anomaly Detection
29 Jun 20224DE3D28D6BC5647692E70B55CFF4F09710.1145/3534678.3539344arXiv:2206.14384v1[cs.LG]Anomaly DetectionAlgorithmic RecourseDeep Learning
The problem of algorithmic recourse has been explored for supervised machine learning models, to provide more interpretable, transparent and robust outcomes from decision support systems.An unexplored area is that of algorithmic recourse for anomaly detection, specifically for tabular data with only discrete feature values.Here the problem is to present a set of counterfactuals that are deemed normal by the underlying anomaly detection model so that applications can utilize this information for explanation purposes or to recommend countermeasures.We present an approach-Context preserving Algorithmic Recourse for Anomalies in Tabular data (CARAT ), that is effective, scalable, and agnostic to the underlying anomaly detection model.CARAT uses a transformer based encoder-decoder model to explain an anomaly by finding features with low likelihood.Subsequently semantically coherent counterfactuals are generated by modifying the highlighted features, using the overall context of features in the anomalous instance(s).Extensive experiments help demonstrate the efficacy of CARAT.</p>
<p>INTRODUCTION</p>
<p>Algorithmic recourse can be defined as a a set of actions or changes that can change the outcome for a data instance with respect to a machine learning model, typically from an unfavorable outcome to a favorable one [21].This is an important and challenging task with practical applicability in domains such as healthcare, hiring, insurance, and commerce that incorporate machine learning models into decision support systems [23,35].Algorithmic recourse is closely related to explainability, specifically counterfactual explanations that are important to improve fairness, transparency, and trust in output of machine learning (ML) models.Indeed the most cited and intuitive explanation of algorithmic recourse presents an example how to change input features of bank loan application decided by a black-box ML algorithm to obtain a favorable outcome [24].</p>
<p>Although the primary focus of algorithmic recourse has been in supervised learning contexts [30], specifically classification based scenarios, it is also applicable in other scenarios.In this work, we address the research of how to frame algorithmic recourse for outcomes of unsupervised anomaly detection.Specifically, we seek to obtain a set of actions to modify the feature values of a data instance deemed anomalous by a black-box anomaly detection model such that it is no longer anomalous.A motivating example would be the case of a shipment transaction that is flagged as suspicious or illegal by a monitoring system employing anomaly detection, and our exploring what needs to be modified in this transaction to no longer merit that outcome.An entity such as a trading company might seek to address its future shipment patterns, by adjusting routes, products or suppliers to avoid getting flagged as potentially fraudulent -thus motivating the problem of algorithmic recourse for anomaly detection.</p>
<p>Algorithmic recourse for anomaly detection has some factors that differentiates it from the classification based scenario due to the underlying ML model w.r.t. which one tries to achieve a different but favorable outcome.While classification models are supervised, anomaly detection models are mostly unsupervised, and archetypes of anomalies are difficult to determine and are application scenario dependant.Prior works consider tabular data for algorithmic recourse in the context of classification [23,36], and use comparatively simpler datasets where features are mostly real-valued.We explore the scenario where features are strictly categorical with high dimensionality (cardinality), such as found in real world data from commerce, communication and shipping [4,14].Concepts such as proximity in the context of counterfactuals are simpler to define for real-valued data.Moreover, metrics used in classification specific algorithmic recourse do not directly translate to the scenario of anomaly detection.Our key contributions in this work are: (i) A novel formulation for the unexplored problem of algorithmic recourse for unsupervised anomaly detection.(ii) A novel approach CARAT to generate counterfactuals for anomalies in tabular data with categorical features.CARAT is demonstrated to be effective, scalable and agnostic to the underlying anomaly detection model.(iii) A new set of metrics that can effectively quantify the quality of the generated counterfactuals w.r.t.multiple objectives.(iv) Empirical results on multiple real world shipment datasets along with a case study highlighting the practical utility of our approach.</p>
<p>PRELIMINARIES</p>
<p>Tabular data with strictly categorical attributes can be formally represented in terms of domains and entities [14].A domain or attribute or categorical feature is defined as a set of elements sharing a common property, e.g.Port.A domain consists of a set of entities which are the set of possible values for the categorical variable, e.g.Port: { Baltimore, New York, . . .}. Context [14] is defined as the reference group of entities with which an entity occurs, implying an entity can be present in multiple contexts.A data instance (record) is anomalous if it contains unexpected co-occurrence among two or more of its entities [13,14,18].</p>
<p>Definition (Anomalous Record).An anomalous record is a record where certain domains have entity values that are not consistent with the remaining entity values, termed as the context, with respect to the expected data distribution.</p>
<p>Explanation for a model typically refers to an attempt to convey the internal state or logic of an algorithm that leads to a decision [43].Closely related to the idea of explanations are counterfactuals.Counterfactuals are hypothetical examples that demonstrate to an user how a different and desired prediction can be obtained.Algorithmic recourse has been defined as an actionable set of changes that can be made to change the prediction of a system with respect to a data instance from an unfavourable one to a desirable one [21].The idea is to change one or more of the feature values of the input in an feasible manner in order to produce a favorable outcome.Algorithmic recourse has been explored in the context of mostly classification problems, with a generalized binary outcome scenario.Algorithmic recourse for anomaly detection is an important yet mostly unexplored problem.In this work, the hypothetical instances that are the result of algorithmic recourse on a data instance are referred to as counterfactuals or recourse candidates.It is important to note that while counterfactual explanations provide explanations through contrasting examples, algorithmic recourse refers to the set of actions that provides the desired outcome.</p>
<p>While nominal points are assumed to be generated from an underlying data distribution D, anomalies can be assumed to be generated from a different distribution D ′ .It can be hypothesized that an anomaly x  ∼ D ′ , is generated from some x  ∼ D through some transformation function set F , such that x  = F (x  ) ∼ D ′ .A simplifying view of F can be a process of feature value perturbation or corruption.Therefore, we can also hypothesize that there exists some arbitrary function set G, such that G(x  ) ∼ D and possibly G(x  ) ≠ x  -which is emulated through algorithmic recourse.</p>
<p>Definition (Algorithmic Recourse for Anomaly Detection).Algorithmic recourse for anomaly detection can be defined as a set of actionable changes on an anomalous data instance, such that it is no longer considered an anomaly with respect to the underlying anomaly detection model.Specifically, we consider the research question that given a row of tabular data, with strictly categorical values, which is deemed anomalous by an anomaly detection model M  -how can we generate a set of hypothetical records such which would be deemed normal by M  .In this setting, without loss of generality we consider M  to be (i) trained using a training set which is assumed to be clean [8,14], (ii) a likelihood based model that produces real-valued scores, (iii) a queriable black box model Problem Description.Given data instance x  which is deemed anomalous by a given anomaly detection model M  , the objective is to generate a set of counterfactuals    such that x   ∈    is not an anomaly according to M  .</p>
<p>Since in the case of unsupervised anomaly detection an application or dataset specific threshold is often used which is difficult to determine, we can relax the definition of recourse to a obtain a set of counterfactuals  such that x   ∈    are ranked lower by M  in terms of anomaly score.There are multiple objectives that require optimization to obtain counterfactuals that satisfy different criterion [22] such as sparsity, diversity, prolixity [26], proximity to the anomalous record, low cost to the end user, along with feasibility, actionability and non-discriminatory nature which depend on application scenario.Since we address a general scenario without apriori application specific knowledge, some of these problem specific objectives such as user specific cost or feasibility are not applicable.We consider the key criterion such as validity, diversity and sparsity and discuss them on evaluation metrics in Section 5.</p>
<p>RELATED WORK</p>
<p>In this section, we discuss the prior literature that explores the concepts of algorithmic recourse, counterfactuals and anomaly explanation, which are relevant in this discourse.</p>
<p>Explainability in machine learning models has gained burgeoning research focus over the last decade due to the need for building trust and achieving transparency in decision support systems that often employ black-box models.Post-hoc explanations through feature importance has been proposed to explain prediction of classifiers.LIME [37] presents an approach to obtaining explanations through locally approximating a model in the neighborhood of of a prediction of a prediction.DeepLIFT [39] proposed a method to decompose the prediction of a neural network by recursively calculating the contributions by individual neurons.SHAP [27]present a unified framework that assigns each feature an additive importance measure for a particular prediction, based on Shapley Values.Inter-pretML [32] presents an unified framework for Ml interpretability.</p>
<p>There has been recent work on explaining outcome for anomaly detection models [2,28,47].ACE [48] proposes an approach for explaining anomalies in cybersecurity datasets.While some some anomaly detection methods such as LODI [11] and LOGP [12] provide feature importance to explain anomalies by design, most methods employ a post-hoc explanation approach.DIFFI [5] provides explanations for outputs from an Isolation Forest.Explanation through gradient based approaches have been proposed in anomaly detection based methods on neural networks [1,25,31].</p>
<p>Karimi et al. [23] presents a comprehensive survey on algorithmic recourse.Ustun et al. [41] introduced the notion of actionable recourse, that ensures that the counterfactuals are obtained through appropriate feature value modification.DiCE [30] presents an a framework for generating and evaluating a diverse set of counterfactuals based on determinantal point processes.Neural network model based approaches for generating counterfactuals have also been proposed [7,29,34].Causal reasoning has also been explored towards algorithmic recourse [9,22,24,35].Approaches for recourse based on heuristics, specifically using genetic algorithms have also been explored [3,10,38].To our knowledge, only one method RCEAA [17] has been proposed towards recourse in anomaly detection based on autoencoders with real valued inputs.(b) Architecture of Decoder-P, which takes both the embeddings and the contextual representation of entities from the encoder, and predicts likelihood of each entity in the record (Section 4.1.2) Figure 1: Architecture of the Explainer model in CARAT, comprising of the encoder and decoder-P, which captures likelihood of each entity in the input record.</p>
<p>ALGORITHMIC RECOURSE THROUGH MODELING CONTEXT</p>
<p>Algorithmic recourse consists of two steps: (i) Understanding what is causing a data instance to be an anomaly, (ii) How to define a set of actions to modify the feature values in order to remedy the unfavorable outcome.We propose CARAT: Context preserving Algorithmic Recourse for Anomalies in Tabular Data that decomposes the task into these two sequential logical steps and address them.CARAT comprises of a model based approach to identify the presence of entities that causes the record to be anomalous, and an algorithm to modify those feature values in the record for recourse.</p>
<p>Explainer Model</p>
<p>Given a record or data instance with categorical features, the tuple of entities is anomalous when one or more of the entities are out-of-context with respect to the remaining entities [13] with unexpected co-occurrence patterns.We use a Transformer [42] based architecture to jointly model the context of the entities of records.</p>
<p>Transformers have been extensively utilized in other applications on text, image and tabular data [19].A record can be considered as a sequence of entities, without a predefined ordering of domains or any semantic interpretation of the relative ordering.Transformer based architectures are appropriate for tabular data with categorical features since (i) they can handle large cardinality values for each category and are scalable (ii) can provide contextual representations of entities (iii) can model context with a prespecified ordering of domains and do not consider any relative ordering among the domains (categories).We adopt an encoder-decoder architecture, similar to language models [15] with the objective to predict the likelihood of each entity in a given record with possible corruptions.The predicted likelihood for each entity is conditioned on the context-implicitly capturing the pair-wise and higher order co-occurrence patterns among entities.</p>
<p>4.1.1Pretrained Row Encoder.The encoder has a transformer based architecture and consists of multiple layers.Sequential architectures are not effective for rows of tabular data where the relative ordering of entities (and domains) do not have any semantic interpretation.To handle domains with large number of entities, a  parallel domain specific embedding layers are used with same dimensionality.To inform the model which domain an entity embedding vector belongs to, we utilize positional encoding [15] vectors which is concatenated to each of the entity embedding vectors.The tuple of vectors is then passed to the subsequent transformer block comprising of multiple layers of transformers.</p>
<p>To train the encoder such that it learns contextual representation for each entity in a record, we require a corresponding decoder and training objective which we design as follows.We refer to this decoder as decoder-R, which is used for pretraining the encoder and not in the final objective.Decoder-R comprises of multiple fully connected layers and is trained to reconstruct data.In order to aid the network to retain information and reconstruct it accurately, the contextual entity embeddings from the encoder layer are augmented with positional vectors through concatenation, after the first fully connected layer.Note that both the encoder and decoder-R utilize positional encoding to indicate domain and help the model reconstruct the entity for a given domain using the contextual embedding.The remainder of the decoder-R consists of  parallel dense layers with GELU activation, with the last layer being softmax to obtain the index of the entity for a specific domain.Note that while the first transformation layer is shared for entity embedding of all domains, the latter layers are domain specific.The encoder and decoder-R are jointly trained, using a reconstruction based objective, similar to Masked Language Model where we randomly perturb or remove entities from records and train the model to predict the correct one from the partial context.The trained encoder captures the shallow embedding in the first layer as well as the contextual representation of entities in the record.</p>
<p>Entity Likelihood Prediction Model.</p>
<p>The decoder-P is designed to predict the likelihood of each entity in a record as output-using the outputs from the pretrained encoder as it's input.The input to decoder-P consists of (i) The embedding representation for the
E 3 E 4 E 1</p>
<p>Metapath schema</p>
<p>Anomaly</p>
<p>Conterfactual  ℎ entity   , obtained from the first embedding layer of the encoder (  0 ∈   ) (ii) The contextual representation of the entity   , obtained from the last layer of the encoder,   .Domain specific positional encoding vector (  ∈   ) is concatenated with   0 to obtain   ∈  2 .We want to capture the semantic coherence and interaction between   , and the contextual representation of the entity   .To accomplish this we use a Bilinear layer.The output of this Bilinear layer is fed to a dense network with multiple hidden layers, and finally a sigmoid activation function to obtain a likelihood of whether an entity should occur in the given record.We utilize a simple 2-layered architecture with ReLU activation for this domain specific dense layer.Binary cross-entropy loss is used to train decoder-P, keeping the weights of the pretrained encoder fixed.The training of decoder-R differs from decoder-P due to the divergent objective.We generate labelled samples from the training data, where we perturb samples with a probability 1 − .For  fraction of samples, the model is given unchanged records from the training set to enable it to recognize expected patterns and predict higher likelihood scores for co-occurring entities.For the remaining samples, we randomly perturb one or more of its entities and task the decoder to recognize which of the entities have been perturbed.It is important to note that the objective of the explainer model is not anomaly detection, but to predict the likelihoods of individual entities in a record.
A 1 E 3 E4 E 1 E 3 A 1 E 1 E 3 E4 E 1 B 2</p>
<p>Generating Counterfactuals</p>
<p>Records in tabular data with categorical features can be considered as tuple of entities, with data specific inherent relationships between the domains (attributes).For instance in the case of shipment records, products being shipped are closely related to the company trading them and their origin.Many real-life applications involve tabular data which can be represented as a heterogeneous graph or Heterogeneous Information Network (HIN).A HIN [40] is formally defined as a graph G = ( , ) with a object type mapping function  :  → A and edge type mapping function  :  → R.Here  ∈  are the nodes representing entities,  () ∈ A are the domains,  ∈  are the edges representing co-occurrence between entities and  () ∈ R. A metapath [40] or metapath schema is an abstract path defined on the graph network schema of a heterogeneous network that describes a composite relation R = 
∈ {𝑑 𝑚𝑜𝑑 }) for ∀𝑑 𝑖 ∈ {𝑑 𝑚𝑜𝑑 } do x 𝑐 𝑓 ← Replace 𝑒 𝑎 𝑖 ∈ 𝑑 𝑖 in x 𝑎 with 𝑐 𝑖 ∈ 𝐶 𝑖 ; 𝐶𝐹 ← 𝐶𝐹 ∪ x 𝑐 𝑓 Score x 𝑐 𝑓 ∈ 𝐶𝐹 using M 𝐴𝐷 ; 𝐶𝐹 ← Least K anomalous records in 𝐶𝐹 ;
nodes of type  1 ,  2 . . . +1 , capturing relationships between entities of different domains.There can exist multiple metapaths, and we consider R and thus the metapaths to be symmetric in our problem setting.Metapaths have been utilized in similarity search in complex data, and to find patterns through capturing relevant entity relationships [4].Recent approaches on knowledge graph embeddings (KGE) [44] have demonstrated their effectiveness in capturing the semantic relationships between objects of different types in knowledge graphs which are HINs.Many approaches for KGE consider symmetric relationships as in our case, and is more generally applicable.We choose one such model DistMult [46] to obtain KGE for the entities in our data.DistMult uses both node and edge embeddings to predict semantically similar nodes, since it models relationships between entities in form of &lt;   , ,   &gt;.</p>
<p>In generating counterfactuals for an anomalous record, we intend to replace the entity   (or entities) which is predicted to have low likelihood by the explainer model, given the context comprising of the other entities in the record.The intuition is to replace such entities with other entities (of the corresponding domain) which are semantically similar to the other entities in the record.Let x  be the anomalous record and let entity    in domain   be selected for replacement.In this task, we utilize the associated HIN constructed from the data, along with the set of metapaths  = { 1 ,  2 . . .  } that are defined using domain knowledge.Here metapath   is of the form {  ,   . . .  }.Thus, candidates to replace    are selected using the metapaths that contain   .Let us consider one such metapath   such that   ∈   , with relations of (  ,   ) and (  ,   ).Let the respective entities in x  for   and   be    and    .In a generated counterfactual x   , the entity     that replaces    should ideally be semantically similar to    and    .KGE can be effectively used for this task.This idea is described in Figure 2. We find  nearest entities to    and    , belonging to domain   .Note that it is possible that   or   is null based on the schema of   .We replace the entities in the domains with low likelihood with all combinations of the candidate replacements for the respective domains to obtain the set of candidate counterfactuals, of which  least anomalous are chosen.The steps are summarized in Algorithm 1.</p>
<p>EVALUATION METRICS</p>
<p>Evaluation metrics are crucial to understanding the performance of counterfactual generation methods, more so due to the fact that generated counterfactuals have multiple objectives and associated trade-offs.We discuss some of the metrics proposed in prior literature, and their limitations in the current problem setting.Further, we propose a set of new metrics that are more appropriate.</p>
<p>Existing Metrics for Counterfactuals</p>
<p>Recourse Correctness or validity [30] captures the ratio of counterfactuals that are accurate in terms obtaining the desired outcome from the blackbox prediction model.For unsupervised anomaly detection since M  provides a real valued likelihood (or anomaly score), a direct prediction (decision value) is unavailable.Recourse Coverage [36] refers to quantification of the criterion that the algorithmic recourse provided covers as many instances as possible.Distance [9,23] or proximity measures the mean feature-wise distance between the original data instance and the set of recourse candidates.Distance is often calculated separately for categorical and continuous attributes.For continuous attributes   norms [16] or their combinations are used whereas for categorical(discrete) variables overlap measure [6] 1(  =   ) has been used.With purely categorical attributes, this measure however fails to convey any information other than merely how many of the attributes are different in the counterfactual.</p>
<p>Cost [9,22] refers to the cost incurred in changing a particular feature value in a recourse candidate.Prior works have utilized   norms to quantify this criteria, for real-valued features.In our problem scenario, this metric is directly not applicable without any external real-world constraints which can help quantify the difference in cost in changing   to   vs.   .Diversity [30] refers to the feature-wise distances between the set of recourse candidates.Diversity encourages sufficient variation among the set of recourse candidates so that it increases the chance of finding a feasible solution.However, it has been noted that in certain cases diversity as an objective correlates poorly with user cost [45].Sparsity [30] refers to the number of features that are different in the recourse candidates, with respect to the original data instance.</p>
<p>Proposed Metrics</p>
<p>We propose a new set of metrics based on previously defined metrics, which are more suited to our problem setting.</p>
<p>Sparsity-Index: Sparsity is an important objective along with diversity that encourages minimal change is made to a data instance in terms of features.To capture this notion, we define Sparsity Index for tabular data with categorical features.Let x  be the anomalous record, and   be the  ℎ domain or feature.
𝑆𝑝𝑎𝑟𝑠𝑖𝑡𝑦 𝐼𝑛𝑑𝑒𝑥 = 1 |𝑌 | Σ x∈𝑌 1 1 + Σ 𝑑 𝑗 1(𝑥 𝑗 ≠ 𝑥 𝑎 𝑗 )(1)
The values of Sparsity Index ∈ [0.5, 1), with the low value corresponding to modification of all feature values and the maximum value corresponding to none.</p>
<p>Coherence: We define coherence as measure to quantify the consistency of the counterfactuals similar to density consistency [23].Let D  be the set of domains which are modified in x  to obtain a counterfactual x   , D  be the remaining domains.Let   be the entity in x   for domain .Coherence measures the mean probability of co-occurrence of the entities   ∈   with   ∈   .Maximizing coherence implies    in x  is replaced with a candidate entity     in x   which has a high probability of co-occurrence given the context of other entities of   in x  , and leads to plausible counterfactuals.
𝑐𝑜ℎ𝑒𝑟𝑒𝑛𝑐𝑒 = Σ 𝑒 𝑖 ∈𝐷 𝑝 1 |D 𝑟 | Σ 𝑒 𝑗 ∈D 𝑟 𝑃 (𝑒 𝑖 , 𝑒 𝑗 )(2)
Conditional Correctness: This metric quantifies the validity of the counterfactuals, conditional upon the underlying anomaly detection model M  which has a scoring function  M ().Let D  be a set of randomly chosen data instances from the training and testing set.Let x  be the anomalous record and let the rank of x  in x  ∩ D  be  , sorted by  M () with appropriate order.Without loss of generalization, we can assume a higher score indicates a more normal or nominal data instance and a low score indicates anomalousness.For  ∈  , where Y is the set of counterfactuals, conditional correctness can be defined as
𝐶𝐶 = 1 |𝑌 | Σ 𝑥 ∈𝑌 1(𝑅𝑎𝑛𝑘 (𝑥) − 𝑟 &gt; 0) (3)
This implies that  is ranked lower in terms of being an anomaly, since higher ranked data instances are more anomalous.Ranking is a more suitable approach to designing a metric than utilizing thresholds which are data and application dependant an is difficult to determine.The relative ordering of records are important in this setting, since test instances are sorted based on  M ().</p>
<p>Feature Accuracy: The concept of anomaly in tabular data with categorical variables has been described as one or more attributes being out of context with respect to the others, as discussed in Section 2. Therefore, it is important to accurately measure how well can a model identify which of the domain values should be modified in x  , and relates to the explanation aspect of algorithmic recourse.This requires having a Gold Standard (ground truth) knowledge where we know which domain values (features) have been corrupted and the entities for those domains are out of context.Let  be the set of domains (features) with  domains.Let q() be a binary valued function that has value 1 if the domain value is changed in counterfactual x   from x  (  ∈ x  →   ∈ x   ) is an actual cause of the anomaly or if a domain value remains unchanged if it was not a cause of the anomaly.Heterogeneity: Although diversity is an important objective for recourse candidates, existing diversity metrics like Count Diversity [30] are inadequate.A trivial random modification of all feature values will maximize such metrics for our setting with strictly categorical features, where distance between discrete feature values is computed using overlap measure.Two factors are important here: (i) the variation among the entities that are proposed to replace original entity in x  and (ii) the correct domain's value is modified or not.We require the Gold Standard (ground truth) to determine whether the counterfactual modifies the a correct domain's value.In our experiments, use of synthetic anomalies enables calculation of this metric.Between any two pair of recourse candidates, heterogeneity encourages dissimilarity while taking into account if both the pair of counterfactuals modify the correct domain's value.Let  be the number of domains,  be the size of the set of counterfactuals  , and 1(q) be 1 if the correct domain has been modified.
𝐹𝐴 = 1 |𝑌 | Σ x 𝑐 𝑓 1 𝑚 Σ 𝑗 ∈𝑑𝑜𝑚 1(q(𝑟 𝑗 → 𝑥 𝑗 ) = 1)(4)𝐻 = 1 𝐾 2 𝑚 Σ 𝐾−1 𝑖=1 Σ 𝐾 𝑗=𝑖+1 Σ 𝑚 𝑙=1 𝑤 𝑙 𝑖 𝑗 1(𝑥 𝑙 𝑖 ≠ 𝑥 𝑙 𝑗 ) 𝑤 𝑙 𝑖 𝑗 = 1(q(𝑟 𝑙 → 𝑥 𝑙 𝑖 ) = 1) * 1(q(𝑟 𝑙 → 𝑥 𝑙 𝑗 ) = 1)(5)</p>
<p>EMPIRICAL EVALUATION</p>
<p>The key objective here is to obtain counterfactuals for for anomalies in tabular data with categorical features.We consider MEAD [14] and APE [8] as the base anomaly detection models suited to categorical tabular data.For our comparative evaluation against baselines we use MEAD.For an objective and quantifiable analysis of the performance of our approach with possible alternatives, we perform extensive experiments to capture the varied desiderata in terms of the metrics defined in Section 5.2.Further, we analyze the computational cost as well as the stability of the proposed approach.</p>
<p>Datasets</p>
<p>The datasets used in for the experimental and evaluation setup are real world proprietary datasets of shipping records obtained from Panjiva Inc [33].Specifically we use 5 datasets with no overlap, constructed from a larger corpus of records.We consider records of a time period as the training set and subsequent time as the test set.We fix the test set size to 5000.The dataset details are described in Table 1.The training set of each dataset is used to train the AD model as well as the KGE model.Since we do not have ground truth data of anomalies, we use synthetic anomalies generated from the test set of each dataset following prior work [8], and allows us to analyze the results using the ground truth knowledge of what caused the record to be an anomaly.</p>
<p>Competing Baseline Methods</p>
<p>The area of algorithmic recourse specifically for anomaly detection is unexplored, and to the best of our knowledge only one prior work RCEAA [17] exists on this.Prior work on algorithmic recourse deals with classification scenarios and they are not directly applicable to our setting.Moreover, as previously noted, most prior work deals with real valued or mixed valued data where the cardinality of categorical variables are significantly lower.Also, most prior approaches convert discrete variables to binary vectors through one-hot encoding and treat them as real valued vectors.We choose the following baselines for comparison: Replace-m: This approach generates an initial candidate set of all possible records by replacing the entity values in  domains simultaneously, using all possible combinations.The records in this candidate set are scored by the given anomaly detection model, and  top scored (least anomalous) records are considered as set of counterfactuals.We set  = 1 due to computational limitations.</p>
<p>FIMAP [7]: FIMAP is a model based approach for generating counterfactuals through adverserial perturbations using a perturbation network, for a classification setting with known labels.To train the proxy classifier, a set of synthetic anomalies (assigned label  = 0) and normal instances (assigned label  = 1).The perturbation network, which generates counterfactuals, is trained by providing synthetic anomalies and passing the perturbed data instance to the pretrained proxy classifier, to obtain the desired label ( = 1).</p>
<p>RCEAA [17]: RCEAA uses an optimization based objective to exactly calculate a set of  counterfactuals.Since the optimization requires real valued inputs, we adopt real-value relaxation on the one-hot encoded discrete representation of x  and use softthreshold approach to obtain discrete outputs.</p>
<p>Xformer-R: This method utilizes the explainer model to identify entities in an anomaly with low likelihood.Counterfactuals are generated by replacing the entity in the identified domains x  with entity values that are sampled uniformly from the domain.</p>
<p>Results</p>
<p>We present the results for the metrics discussed in Section 5.2.For conditional correctness, we sample a set of records containing both known synthetic anomalies and normal data instances.It is important to note that no single metric quantifies the different desiderata of the generated counterfactuals.Beginning with feature accuracy, which is reported in Table 2a we see the approaches based on Transformer based explainer (Xformer-R and CARAT ) have significantly better performance compared to the others.This demonstrates that the explainer can effectively identify entities in records which do not conform to expected co-occurrence patterns.For heterogeneity, the results are presented in Table 2b, while CARAT performs well, but FIMAP has somewhat better performance.This can be explained by the fact that counterfactuals generated by FIMAP modify most of the entity values-which violates the sparsity objective.Next we consider coherence, which that captures how semantically similar the replaced entities are to the remaining ones in the counterfactuals generated.As reported in Table 2c, we find CARAT performs significantly better.This implies the generated counterfactuals are consistent with the underlying data distribution.Considering sparsity, FIMAP and RECEAA have significantly lower values as shown Dataset-1 0.0012 ± 0.0005 0.0000 ± 0.0000 0.0002 ± 0.0001 0.0004 ± 0.0003 0.0025 ± 0.0022 Dataset-2 0.0008 ± 0.0004 0.0000 ± 0.0000 0.0002 ± 0.0001 0.0003 ± 0.0002 0.0020 ± 0.0018 Dataset-3 0.0013 ± 0.0006 0.0000 ± 0.0000 0.0002 ± 0.0001 0.0004 ± 0.0003 0.0030 ± 0.0028 Dataset-4 0.0003 ± 0.0004 0.0000 ± 0.0000 0.0001 ± 0.0001 0.0007 ± 0.0012 0.0018 ± 0.0027 Dataset-5 0.0007 ± 0.0007 0.0000 ± 0.0001 0.0005 ± 0.0005 0.0011 ± 0.0014 0.0037 ± 0.0047 CARAT shows competitive performance here, better than other baselines.Since no single metric comprehensively captures the requisite objectives that we are trying to maximize in generating counterfactuals-we summarize the model performances across all the metrics.For each approach, we first obtain the average of the
(</p>
<p>Time (in seconds)</p>
<p>Replace-m FIMAP RCEAA Xformer-R CARAT values across all datasets and then normalize them.Then we perform an unweighted average across all of these normalized metrics values to find a single performance value.The results are reported in Table 2f, which shows CARAT has a significant overall advantage.</p>
<p>Method</p>
<p>Stability</p>
<p>The process of algorithmic recourse is inherently dependant on the underlying anomaly detection model which finds the anomalous data instances.Thus it is important to understand the variation in performance of our proposed approach in the context of the underlying AD model M  .Here M  is a black-box model, and assumed to perfectly capture the underlying data distribution to find data instances that are true anomalies.We choose two embedding based algorithms for tabular data with strictly categorical features as M  , APE [8] and MEAD [14].We apply APE and MEAD on test sets of each of the datasets, consider 1% of the lowest scored records as anomalies, and apply CARAT with the respective AD models on the corresponding anomalies.Comparison of the applicable metrics defined in Section 5.2 for the generated counterfactuals across multiple metrics are reported in Table 3.We observe that similar performance is obtained in both cases, demonstrating the stability of our proposed approach.</p>
<p>Computational Cost</p>
<p>One of the major challenges of generating recourse is the computational complexity.We consider the computational cost in the execution phase, after all applicable pretraining and set up has been completed.An approach with with exponential computational complexity would be simply infeasible in most practical scenarios.For instance the Replace-m approach outlined in Section 6.2, the complexity is  (Σ  1   ,  +1 .. + ), where  domains are chosen to be modified at most,   ,  +1 . . . + are the cardinalities of the   .RCEAA [17] also suffers from high computational cost, as shown in Figure 3.The major bottlenecks in such an optimization based approach are: (i) expensive loss function (ii) grid search for hyperparameters (iii) operations on a very high dimensional vector due to one-hot encoding.Our proposed approach is computationally efficient, since the explanation phase uses only a pretrained model with linear time complexity and the counterfactual generation phase that requires finding nearest neighbors is sped up using an indexing library [20].</p>
<p>Case Study of an Anomaly</p>
<p>We perform a short case study based on one of the anomalies detected from test set of Dataset-1.The detected anomaly and a set of counterfactuals are shown in Figure 4. Our explainer model finds that the entity in domain HS Code in the anomalous record x  has low likelihood of occurrence in its context.This is supported by the empirical data, as we find goods represented by the entity <HS Code:7211> was previously traded by the neither the consignee (buyer) nor the shipper.Additionally, <HS Code:7211> was not previously transported through the ports of lading and unlading in the record.Our explainer only presents a low score for this entity, and not the others in the record although their context, which contains <HS Code:7211>, is altered.This demonstrates that the model can accurately predict likelihood from partially correct contextual information-which is the case for anomalous records.Let us look at the counterfactuals, where <HS Code:7211> is modified to alternate values.<HS Code:7211> refers to products of iron or non-alloy steel.Firstly <HS Code:7210>, <HS Code:7225> and <HS Code:7219> refer to products very similar to <HS Code:7211>, specifically rolled or non-rolled steel or alloy products.<HS Code: 2818> and <HS Code:7304> are metal products as well.So the counterfactuals are essentially suggesting the buyer to obtain alternate products from the supplier (shipper).This can be explained based on the data, the particular type of goods <HS Code:7211> are generally not sourced from the given origin and the shipper evidenced by any similar prior occurrences.A practical explanation might relate to industrial production and proficiency patterns, since certain regions specialize in specific products.From prior records it is further observed that the consignee buys metal and alloy goods, such as with HS Codes 7210, 7323, 7304, 7225 and 7310.Thus CARAT provides meaningful counterfactuals for detected anomalies.</p>
<p>CONCLUSION AND FUTURE WORK</p>
<p>In this work we address the previously unexplored problem of algorithmic recourse for anomaly detection in tabular data with categorical features with high cardinality.We propose a novel deep learning based approach CARAT to find counterfactuals for detected anomalies.We also define a set of relevant metrics that can enable effective evaluation of counterfactuals in such a problem setting.The scalability and efficacy of our model in terms of the applicable metrics as well computational cost is demonstrated through extensive experiments.However the current research leads to further research questions.While we consider multiple objectives to optimize in the process of algorithmic recourse there are application scenario specific constraints that are not considered.One of the questions that has practical implications and requires domain knowledge is the actual cost incurred by the user.Another aspect is feasibility and actionability of counterfactuals, which are often dependant on extrinsic factors that need to explicitly considered and incorporated into the algorithmic recourse for anomalies.Thus there are multiple continuing research directions which are a natural progression of the problem we address in this work.</p>
<p>A DATASET BACKGROUND</p>
<p>The datasets used in the empirical evaluation are from shipping domain and are proprietary due to security and legal reasons.We discuss some of the attributes of this real world data and their interpretations.</p>
<p>HS Code or Harmonized Tariff Schedule Codes are globally standardized codes that define what type of goods are being transported.Carrier is the transporting entity that operates between ports.The ports of lading and unlading are the points where the cargo is laden onto the transporting vessel or vehicle and and unladen from it.We have received help of collaborating domain experts who deal with shipping data to help us understand the data characteristics and the relationships between attributes.The original data has many attributes which contain redundant information, and we select only meaningful attributes from the raw data.Also we remove rows with missing values and perform standard data cleaning to obtain our datasets.</p>
<p>The metapaths that describe these relationships are shown in Table 4.These are designed with the knowledge of the structure of supply chains that are captured in this Bill of Lading corpus.In pretraining the encoder with decoder-R, the training objective is similar to Masked Language Model but not identical.Specifically we replace approximately 20% of entities in each records to mask, and 20% of entities are perturbed by replacement with a randomly sample entity from the same domain.In the second phase of training the decoder-P,  -the fraction of records which are not changed is set to 0.3.</p>
<p>Both the pre-training phase of the encoder and the final explainer architecture are trained for 250 epochs with a batch size of 512 and learning rate of 0.0005.All optimization for our model and the baselines are performed using Adam.</p>
<p>B.2.4 CARAT KGE Details.</p>
<p>The knowledge graph embedding model adopted here is DistMult.We use an embedding size of 100.The training batch size used is 1024, and we train the model for 300 epochs.We use both the node and edge embeddings to find entities that are similar to a target entity.Since DistMult uses <head,rel,tail> format to calculate similarity, we perform nearest neighbor search for the tail entity using precomputed embedding of head nodes and relation type.</p>
<p>B.3 Empirical Evaluation Setup</p>
<p>We generate counterfactuals for synthetic anomalies.For each approach, we use a set of 400 anomalies and we generate 50 counterfactuals for each anomaly.We use the same set of anomalies for all approaches to perform a fair comparative evaluation.For RCEAA we are able generate counterfactuals for 40 anomalies, due to the excessively long execution time as explained in Section 6.5.</p>
<p>B.4 Additional Detail on Competing Baselines</p>
<p>For the baseline models, we adapt the models to the current problem setting in an appropriate manner.We utilize the hyperparameters provided in the original work and do not perform significant hyperparameter tuning for these approaches.Similarly, we do not perform significant hyperparameter tuning for our model to tune performance as well since the objective is to demonstrate the validity of our approach in a general setting.B.4.1 RCEAA.In our implementation of RCEAA [17], we adapt the original approach.Firstly, we replace the autoencoder based anomaly detection model with our likelihood based model.In the loss function, we use 10 ℎ percentile scores of training data as the threshold so that the generated counterfactuals have a low anomaly score (higher likelihood) according to our anomaly model.We set  to 2. Additionally in place of euclidean distance, we use cosine distance since the dimensionality of the vectors is high.In order to reduce the computational complexity due to grid search of hyperparameters, we set the upper and lower bounds of  1 and  2 to 0.25 and 0.75, and adopt step size of 0.25.The training epochs are increased from 15 mentioned in the paper, to 20.We report the results with the lowest optimization loss.B.4.2 FIMAP.For FIMAP, which is an approach for generating counterfactuals in a classification based setting, we adapt it to our problem setting appropriately.We adopt a more complex neural network architecture that follows that archetype proposed in the original work.Specifically, an embedding projection layer of dimensionality 32 is used for each categorical variable, whose output is concatenated and fed to a fully connected network for both proxy classifier network and perturbation network.The fully connected network for proxy classifier has size (256, 256]), following the original work that uses a 3 layered neural network.The fully connected network for perturbation model has size (256, 128, 128) and uses dropout of 0.2.The value of  in Gumbel softmax set to 0.5.We use 10000 data points to train the proxy classifier for each dataset, with samples from training set and synthetic anomalies.The batch size used is 512, and the networks are trained for 100 epochs, with early stopping.</p>
<p>C CODE AND DATA LINK</p>
<p>Please find the code for this work at : https://github.com/ddatta-DAC/Algorithmic_Recourse_AnomalyDetection</p>
<p>D ETHICAL IMPLICATIONS OF ALGORITHMIC RECOURSE FOR ANOMALY DETECTION</p>
<p>Since algorithmic recourse provides an approach towards generating counterfactuals that are not deemed anomalous by an anomaly detection model which may be part of a decision support system, it raises an obvious ethical question.Is algorithmic recourse adverserial to anomaly detection i.e. intended to help nefarious actors attempting to evade detection?That is not our motivation here.First, data and anomaly detection models are expected to be secured and adverserial agents would have no access to them in order to circumvent the detection process.Recourse for anomaly detection is intended to help the decision making process.It can enable organizations like enforcement agencies in our case study, that make use of anomaly detection systems to better handle false positive cases.Verified agents, whose transactions may be erroneously flagged, could be intimated of the issue and may be provided alternatives or countermeasures.The issue of false positives exist since it is not feasible to always incorporate the application specific notions of anomaly into anomaly detection models.This effectively aids the decision support system user as well the agents whose data is being assessed.In practical scenarios, systems that utilize algorithmic recourse do require transparency and human surveillance to ensure they are used as intended.There is a minimal risk, as in any system, that unscrupulous personnel who are insiders might utilize algorithmic recourse to provide alternatives to nefarious agents enabling them avoid detection.This however can be eliminated through correct operational and access protocols where such a system is deployed.</p>
<p>Figure 2 :
2
Figure 2: Finding counterfactuals through replacing a lower likelihood entity in a record with another entity based on semantic similarity with respect to the other entities.</p>
<p>Figure 3 :
3
Figure 3: Computational time of compared approaches.Our proposed approach CARAT shows a clear advantage.</p>
<p>Figure 4 :
4
Figure 4: Example of an detected anomaly (first row) and the generated counterfactuals using CARAT.</p>
<p>Decoder-P Concat Positional Embedding 01 Encoder Domain Embedding Layer Bilinear Layer
EncoderDecoder-REncoderEntity 1 Entity 2 Entity m Entity 1 Entity 2Concat Positional Embedding0 0 0 1 1 1Concat Positional EmbeddingSoftMax SoftMax SoftMaxPredicted Predicted Entity 2 Predicted Entity 1Input Row Entity m Entity 1 Entity 2Transformer Blocks0011FCNP(Entity 2) P(Entity 1) P(Entity m)Input RowDomain Embedding LayerN X Transformer Blocks With Multi-Headed Self-attentionFCN with GeLUEntity m12m(a) Architecture of the Encoder and the Decoder-R used in the firstphase of pretraining the Encoder to learn the representation the enti-ties and capture overall context of the record (Section 4.1.1).</p>
<p>1  2 . . .  between Algorithm 1: Counterfactual generation in CARAT Input : Anomalous record x  ; Explainer Model M  , Anomaly Detection model M  , Set of metapaths MP : { 1 ,  2 ..  }, K: No. of counterfactuals Output : Set of conterfactuals CF for x  {  } ← Set of domains   where M  :  (   ∈ x  ) &lt; 0.5 If {  } =  : {  } ←   where   ( (   ∈ x  )) ; //Ensure at least a single domain is modified for   ∈ {  } do   = {}; //Candidate entities to replace    for   ∈ MP do  = {} if   ∈   then  ←  (  ,   ), such that  ∩ {  } =   ←  ∪  for each   ∈  do  ←     ℎ for    ∈   ; //Find entities for   similar to other entities in x    =   ∪  ; //Update candidate entities  ← {} for combinations of (  ,  </p>
<p>Table 1 :
1
Details of the datasets used for evaluation.
DatasetSourceTotal entity countDomain CountTrain sizeDataset-1US Import6353838291Dataset-2US import6151835177Dataset-3US import7340843495Dataset-4 Colombia Export4008516758Dataset-5 Ecuador Export3198713956</p>
<p>Table 2 :
2
Comparison of performance of baselines and our approach for the adopted metrics.
(a) Feature AccuracyDatasetReplace-mFIMAPRCEAAXformer-RCARATDataset-10.8638 ± 0.0858 0.1897 ± 0.0615 0.2328 ± 0.0414 0.9803 ± 0.0527 0.9822 ± 0.0509Dataset-20.8581 ± 0.0930 0.1899 ± 0.0617 0.2585 ± 0.0488 0.9771 ± 0.0641 0.9813 ± 0.0583Dataset-30.8591 ± 0.0876 0.1898 ± 0.0615 0.2381 ± 0.0580 0.9769 ± 0.0633 0.9786 ± 0.0630Dataset-40.7167 ± 0.1152 0.2995 ± 0.0962 0.3094 ± 0.0988 0.9111 ± 0.1388 0.9164 ± 0.1370Dataset-50.5658 ± 0.1566 0.2181 ± 0.0698 0.2761 ± 0.0542 0.9577 ± 0.0855 0.9601 ± 0.0831(b) HeterogenityDatasetReplace-mFIMAPRCEAAXformer-RCARATDataset-10.3589 ± 0.3056 0.9737 ± 0.0261 0.6625 ± 0.1098 0.9693 ± 0.0821 0.9017 ± 0.1244Dataset-20.3728 ± 0.3273 0.9716 ± 0.0278 0.6646 ± 0.1499 0.9579 ± 0.1311 0.8930 ± 0.1522Dataset-30.3472 ± 0.3164 0.9737 ± 0.0262 0.6503 ± 0.1236 0.9662 ± 0.1016 0.8978 ± 0.1319Dataset-40.0634 ± 0.1216 0.9145 ± 0.0965 0.6863 ± 0.2824 0.8164 ± 0.2333 0.7805 ± 0.2264Dataset-50.1122 ± 0.2041 0.9570 ± 0.0441 0.6176 ± 0.1957 0.8879 ± 0.1957 0.8378 ± 0.2003(c) CoherenceDatasetReplace-mFIMAPRCEAAXformer-RCARAT</p>
<p>Summary (normalized mean) of all metrics across all datasets, for the baselines and our proposed approach CARAT.
d) Sparsity-IndexDatasetReplace-mFIMAPRCEAAXformer-RCARATDataset-10.8889 ± 0.0000 0.5015 ± 0.0010 0.5355 ± 0.0089 0.8389 ± 0.0524 0.8381 ± 0.0523Dataset-20.8889 ± 0.0000 0.5016 ± 0.0010 0.5391 ± 0.0089 0.8381 ± 0.0523 0.8572 ± 0.0463Dataset-30.8889 ± 0.0000 0.5015 ± 0.0010 0.5321 ± 0.0042 0.8366 ± 0.0532 0.8358 ± 0.0531Dataset-40.8750 ± 0.0000 0.5049 ± 0.0022 0.5445 ± 0.0052 0.7804 ± 0.0705 0.7825 ± 0.0678Dataset-50.8333 ± 0.0000 0.5027 ± 0.0014 0.5468 ± 0.0039 0.8305 ± 0.0586 0.8300 ± 0.0585(e) Conditional CorrectnessDatasetReplace-mFIMAPRCEAAXformer-RCARATDataset-11.0000 ± 0.0000 0.7404 ± 0.1388 0.6230 ± 0.1609 0.7389 ± 0.1947 0.9774 ± 0.0631Dataset-21.0000 ± 0.0000 0.6646 ± 0.1556 0.4990 ± 0.2092 0.7414 ± 0.2077 0.9733 ± 0.0800Dataset-31.0000 ± 0.0000 0.7544 ± 0.1342 0.6090 ± 0.1489 0.7634 ± 0.2061 0.9727 ± 0.0679Dataset-41.0000 ± 0.0000 0.3666 ± 0.2223 0.3770 ± 0.2712 0.5572 ± 0.2725 0.8411 ± 0.2429Dataset-51.0000 ± 0.0000 0.5122 ± 0.1867 0.4240 ± 0.1744 0.5858 ± 0.2708 0.8695 ± 0.2023(f) Replace-mFIMAPRCEAAXformer-RCARAT0.61500.24100.16570.67520.9183in Table 2d, since the counterfactuals have multiple feature valuesmodified from the given anomaly. Replace-m has a high sparsitysince a single entity is modified (m=1). Xformer-R and CARAT have
similar performance in terms of sparsity.Lastly, for conditional correctness reported in Table2ewe find Replace-m has perfect score due to performing exhaustive search for least anomalous records.</p>
<p>Table 3 :
3
Comparison of metrics for generated counterfactuals using different anomaly detection models with CARAT.±0.0362 0.8730 ±0.0391 0.7323 ±0.3012 0.7237 ±0.3283 0.0004 ±0.0004 0.0004 ±0.0004 Dataset-2 0.8870 ±0.0178 0.8695 ±0.0404 0.6624 ±0.3003 0.6853 ±0.3473 0.0003 ±0.0003 0.0004 ±0.0004 Dataset-3 0.8810 ±0.0370 0.8753 ±0.0416 0.7517 ±0.2462 0.6326 ±0.3721 0.0002 ±0.0002 0.0003 ±0.0003 Dataset-4 0.8415 ±0.0058 0.8194 ±0.0517 0.6422 ±0.2703 0.5414 ±0.3877 0.0004 ±0.0003 0.0003 ±0.0004 Dataset-5 0.8720 ±0.0238 0.8654 ±0.0355 0.7694 ±0.2150 0.4601 ±0.3657 0.0009 ±0.0008 0.0015 ±0.0014
Sparsity IndexConditional Corr.CoherenceDatasetAPEMEADAPEMEADAPEMEADDataset-1 0.8764 0 10002000300040005000</p>
<p>Table 4 :
4
Metapaths for the datasets belonging to the three data sources, viz.US Import, Colombia Export and Ecuador Export.Schema of the metapaths describing the relationships between attributes of the data for US Import Shipment Origin ↔ HS Code ↔Port Of Lading Shipment Destination ↔ HS Code ↔ Port Of Unlading Port Of Lading ↔ HS Code ↔ Carrier HS Code ↔ Carrier ↔Port Of Unlading Shipper ↔ Shipment Origin ↔ Port Of Lading Consignee ↔ Shipment Destination↔Port Of Unlading Consignee ↔ Carrier ↔ Shipment Destination Shipper ↔ Carrier ↔ Shipment Origin Consignee ↔ Carrier ↔ Port Of Unlading Shipper ↔ Carrier ↔ Port Of Lading (b) Schema of the metapaths describing the relationships between attributes of the data for exports from Colombia.Shipper ↔ Shipment Origin ↔ HS Code Consignee ↔ Shipment Destination ↔ HS Code Shipment Destination ↔ HS Code ↔ Shipment Origin Shipper ↔ HS Code ↔ Consignee (c) Schema of the metapaths describing the relationships between attributes of the data for exports from Ecuador.We provide the implementation details to faithfully reproduce the results obtained.All implementation is done in Python 3.9, and uses standard libraries such as Numpy, Pandas and scikit-learn.For optimization and neural network based models, PyTorch (version 1.10) is used.All data preprocessing, training and evaluation presented in this work are performed on a 40-core machine, with a single GPU and distributed training required.To train our Knowledge Graph Embedding model, we use the library StellarGraph, which provides an implementation of DistMult.Anomaly Detection Model.Anomaly detection for tabular data with strictly categorical features, especially where the attributes have high dimensionality (cardinality) is a challenging task.We choose Multi-relational Embedding based Anomaly Detection [14] as the base anomaly detection model for our experiments.MEAD uses an additive model based on shallow embedding, where the likelihood of a record is a function of the magnitude of transformed sum of the entity embeddings.We use an embedding size of 32 for anomaly detection models our experiments.
Shipment Destination,Goods Shipped,Port Of UnladingShipper ↔ Goods Shipped ↔ Shipment OriginGoods Shipped ↔ Carrier ↔ Port Of UnladingConsignee ↔ Shipment Destination ↔ Port Of UnladingConsignee ↔ Carrier ↔ Shipment DestinationShipper ↔ Carrier ↔ Shipment OriginConsignee ↔ Carrier ↔ Port Of Unlading
[8,14]2.2 Synthetic Anomalies.Synthetic anomalies are generated using the approach followed in prior works[8,14].For each record, randomly one or more feature values are perturbed i.e. replaced with a random but valid feature value for the categorical attribute.</p>
<p>ACKNOWLEDGMENTSThis work was supported in part by US NSF grants CCF-1918770, NRT DGE-1545362, and OAC-1835660 to NR, and IIS-1954376 and IIS-1815696 to FC.
Toward explainable deep neural network based anomaly detection. Kasun Amarasinghe, Kevin Kenney, Milos Manic, 2018. 2018IEEE11</p>
<p>Explaining anomalies detected by autoencoders using Shapley Additive Explanations. Liat Antwarg, Ronnie Mindlin Miller, Bracha Shapira, Lior Rokach, Expert Systems with Applications. 1861157362021. 2021</p>
<p>Plausible counterfactuals: Auditing deep learning classifiers with realistic adversarial examples. Alejandro Barredo, -Arrieta , Javier Del, Ser , 2020. 2020IEEE</p>
<p>Collective fraud detection capturing inter-transaction dependency. Bokai Cao, KDD 2017 Workshop on Anomaly Detection in Finance. PMLR2018</p>
<p>Mattia Carletti, Matteo Terzi, Gian Antonio Susto, arXiv:2007.11117Interpretable Anomaly Detection with DIFFI: Depth-based Isolation Forest Feature Importance. 2020. 2020arXiv preprint</p>
<p>Similarity Measures for Categorical Data-A Comparative Study. Varun Chandola, Shyam Boriah, Vipin Kumar, 2007. 2007</p>
<p>FIMAP: Feature Importance by Minimal Adversarial Perturbation. Matt Chapman-Rounds, AAAI. 202135</p>
<p>Entity embedding-based anomaly detection for heterogeneous categorical events. Ting Chen, IJCAI. 2016</p>
<p>Riccardo Crupi, Counterfactual Explanations as Interventions in Latent Space. arXiv e-prints (2021). 20212106</p>
<p>Multi-objective counterfactual explanations. Susanne Dandl, International Conference on Parallel Problem Solving from Nature. Springer2020</p>
<p>Local outlier detection with interpretation. Xuan Hong, Dang , ECML PKDD. Springer2013</p>
<p>Discriminative features for identifying and interpreting outliers. Xuan Hong, Dang , IEEE ICDE. IEEE2014. 2014</p>
<p>Detecting anomalous records in categorical datasets. Kaustav Das, Jeff Schneider, 13th ACM SIGKDD. 2007</p>
<p>Detecting Suspicious Timber Trades. Debanjan Datta, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence202034</p>
<p>BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. Jacob Devlin, NAACL. ACL2019</p>
<p>Explanations based on the missing: Towards contrastive explanations with pertinent negatives. Amit Dhurandhar, NeurIPS. 312018. 2018</p>
<p>Reliable Counterfactual Explanations for Autoencoder Based Anomalies. Swastik Haldar, 8th ACM IKDD CODS and 26th COMAD. 2021</p>
<p>An embedding approach to anomaly detection. Renjun Hu, C Charu, Shuai Aggarwal, Jinpeng Ma, Huai, ICDE. 2016</p>
<p>Tabtransformer: Tabular data modeling using contextual embeddings. Xin Huang, arXiv:2012.066782020. 2020arXiv preprint</p>
<p>Billion-scale similarity search with gpus. Jeff Johnson, Matthijs Douze, Hervé Jégou, IEEE Transactions on Big Data. 72019. 2019</p>
<p>Towards realistic individual recourse and actionable explanations in black-box decision making systems. Shalmali Joshi, arXiv:1907.096152019. 2019arXiv preprint</p>
<p>Model-agnostic counterfactual explanations for consequential decisions. Amir-Hossein Karimi, AISTATS. PMLR2020</p>
<p>A survey of algorithmic recourse: definitions, formulations, solutions, and prospects. CoRR abs. Amir-Hossein Karimi, 2020. 2010. 20204050</p>
<p>Algorithmic recourse: from counterfactual explanations to interventions. Amir-Hossein, Bernhard Karimi, Isabel Schölkopf, Valera, ACM FaccT. 2021</p>
<p>Towards explaining anomalies: a deep Taylor decomposition of one-class models. Jacob Kauffmann, Pattern Recognition. 1011071982020. 2020</p>
<p>Good counterfactuals and where to find them: A case-based technique for generating counterfactuals for explainable AI (XAI). T Mark, Barry Keane, Smyth, International Conference on Case-Based Reasoning. Springer2020</p>
<p>A Unified Approach to Interpreting Model Predictions. M Scott, Su-In Lundberg, Lee, 2017. 201730</p>
<p>Explaining anomalies in groups with characterizing subspace rules. Meghanath Macha, Leman Akoglu, 2018. 2018. 201832</p>
<p>Preserving causal constraints in counterfactual explanations for machine learning classifiers. Divyat Mahajan, arXiv:1912.032772019. 2019arXiv preprint</p>
<p>Explaining machine learning classifiers through diverse counterfactual explanations. Ramaravind K Mothilal, ACM FAT. 2020. 2020</p>
<p>Gee: A gradient-based explainable variational autoencoder for network anomaly detection. Phong Quoc, Nguyen, IEEE CNS. 2019. 2019</p>
<p>Interpretml: A unified framework for machine learning interpretability. Harsha Nori, arXiv:1909.092232019. 2019arXiv preprint</p>
<p>Panjiva, Panjiva Trade Data. 2019</p>
<p>Learning model-agnostic counterfactual explanations for tabular data. Martin Pawelczyk, The Web Conference. 2020. 2020</p>
<p>Causal inference and counterfactual prediction in machine learning for actionable healthcare. Mattia Prosperi, NMI. 272020. 2020</p>
<p>Kaivalya Rawal, Himabindu Lakkaraju, Beyond Individualized Recourse: Interpretable and Interactive Summaries of Actionable Recourses. 2020. 2020</p>
<p>Explaining the predictions of any classifier. Marco Tulio Ribeiro, Sameer Singh, Carlos Guestrin, 22nd ACM SIGKDD. 2016Why should i trust you?</p>
<p>Certifai: Counterfactual explanations for robustness, transparency, interpretability, and fairness of artificial intelligence models. Shubham Sharma, Jette Henderson, Joydeep Ghosh, arXiv:1905.078572019. 2019arXiv preprint</p>
<p>Learning important features through propagating activation differences. Avanti Shrikumar, Peyton Greenside, Anshul Kundaje, International conference on machine learning. PMLR2017</p>
<p>Pathsim: Meta path-based top-k similarity search in heterogeneous information networks. Yizhou Sun, Proceedings of the VLDB Endowment. the VLDB Endowment2011. 20114</p>
<p>Actionable recourse in linear classification. Berk Ustun, Alexander Spangher, Yang Liu, ACM FAT. 2019</p>
<p>Attention is all you need. Ashish Vaswani, NeurIPS. 2017</p>
<p>Counterfactual explanations without opening the black box: Automated decisions and the GDPR. Sandra Wachter, Harv. JL &amp; Tech. 318412017. 2017</p>
<p>Knowledge graph embedding: A survey of approaches and applications. Quan Wang, IEEE TKDE. 122017. 2017</p>
<p>Prateek Yadav, arXiv:2111.01235Low-Cost Algorithmic Recourse for Users With Uncertain Cost Functions. 2021. 2021arXiv preprint</p>
<p>Embedding entities and relations for learning and inference in knowledge bases. Bishan Yang, 2014ICLR</p>
<p>Anomaly explanation: A review. Véronne Yepmo, Grégory Smits, Olivier Pivert, Data &amp; Knowledge Engineering. 1371019462022. 2022</p>
<p>ACE-an anomaly contribution explainer for cybersecurity applications. Xiao Zhang, IEEE Big Data. IEEE. 2019. 2019. 1991-2000</p>            </div>
        </div>

    </div>
</body>
</html>