<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-2390 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-2390</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-2390</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-65.html">extraction-schema-65</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of multi-agent AI systems that coordinate to perform scientific research tasks, including details about their coordination mechanisms, communication protocols, feedback mechanisms, agent specializations, and performance results.</div>
                <p><strong>Paper ID:</strong> paper-221377377</p>
                <p><strong>Paper Title:</strong> <a href="https://arxiv.org/pdf/2008.04793v2.pdf" target="_blank">On Multiple Intelligences and Learning Styles for Artificial Intelligence Systems: Future Research Trends in AI with a Human Face?</a></p>
                <p><strong>Paper Abstract:</strong> This article discusses recent trends and concepts in developing new kinds of artificial intelligence (AI) systems which relate to complex facets and different types of human intelligence, especially social, emotional, attentional and ethical intelligence, which to date have been under-discussed. We describe various aspects of multiple human intelligence and learning styles, which may impact on a variety of AI problem domains. Using the concept of multiple intelligence rather than a single type of intelligence, we categorize and provide working definitions of various AI depending on their cognitive skills or capacities. Future AI systems will be able not only to communicate with human actors and each other, but also to efficiently exchange knowledge with abilities of cooperation, collaboration and even co-creating something new and valuable and have meta-learning capacities. Multi-agent systems such as these can be used to solve problems that would be difficult to solve by any individual intelligent agent.</p>
                <p><strong>Cost:</strong> 0.012</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e2390.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e2390.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of multi-agent AI systems that coordinate to perform scientific research tasks, including details about their coordination mechanisms, communication protocols, feedback mechanisms, agent specializations, and performance results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>AI-SQ multi-system</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>AI with Social Intelligence (AI-SQ) multi-system</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A conceptual multi-agent AI system archetype that emphasizes social abilities (communication, coordination, cooperation, collaboration, co-creative collaboration) enabling agents to exchange information and knowledge, align on shared goals, and jointly perform complex tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>AI-SQ multi-system (AI with Social Intelligence)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>A conceptual multi-agent architecture in which individual agents (software modules or robots) possess social intelligence enabling them to communicate, coordinate, cooperate, collaborate, and co-create. The paper frames AI-SQ as a superset of emotional intelligence (EQ) and defines social interaction skills (5C): Communication, Coordination, Cooperation, Collaboration and Co-creative collaboration. Agents may be DNN modules, intelligent robots or other AI sub-systems that exchange data, information and knowledge and support each other's goals or a shared goal.</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_agents</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>agent_specializations</strong></td>
                            <td>Not explicitly enumerated. The paper describes agents generically as AI sub-systems (e.g., DNNs, robots) that can adopt roles per need: communicators (exchange information), coordinators (align action sequencing and responsibility allocation), cooperators (share relevant information/resources to support individual goals), collaborators (share knowledge to pursue a common goal), and co-creators (drive innovation via exploration and feedback). Specific dedicated roles (e.g., idea-generation vs evaluation) are not specified in the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>research_phases_covered</strong></td>
                            <td>Conceptually covers ideation/knowledge exchange, coordinated task execution, joint problem solving, and iterative improvement (co-creative prototyping/testing); does not detail explicit literature review or experimental-execution pipelines.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_mechanism</strong></td>
                            <td>Described conceptually: can be centralized or decentralized depending on implementation; paper defines coordination as alignment/harmony or sequenced plan (delineating who does what, when, within what duration). No concrete implementation (e.g., centralized controller, consensus algorithm) is specified in the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>communication_protocol</strong></td>
                            <td>Not specified in technical detail. Paper only states agents 'communicate and exchange data and information' and 'exchange knowledge' (format/structure unspecified). No explicit message formats, serialization, or language/protocols are given.</td>
                        </tr>
                        <tr>
                            <td><strong>feedback_mechanism</strong></td>
                            <td>Conceptual iterative feedback loops are described for co-creative intelligence: prototyping, testing, exchange of ideas via feedback, and adaptation for further improvements. Also mentions self-assessment/self-awareness capabilities where agents evaluate their own performance and robustness (self-assessment under noise/incomplete data).</td>
                        </tr>
                        <tr>
                            <td><strong>communication_frequency</strong></td>
                            <td>Unspecified; described at a conceptual level (could be continuous, on-demand, or at phase transitions) but the paper does not provide frequency or scheduling details.</td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>General complex tasks and problem domains where multi-agent coordination is required (the paper suggests applicability across domains including robotics, ensemble DNN tasks, and broadly 'scientific' and complex problem solving), but no concrete scientific-research application with experiments is presented.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>coordination_benefits</strong></td>
                            <td>Conceptual benefits described: ability to solve problems difficult for any single agent, improved learning efficiency by leveraging multiple intelligences and learning styles, better decision making, capacity for co-creation and innovation, robustness through social-awareness and self-management. No quantitative benefits or empirical results are reported in the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_challenges</strong></td>
                            <td>Discussed challenges (conceptual): need for conflict management when working in groups, limitations in current AI (lack of self-awareness, self-management, social-awareness), potential coordination failures, and the practical difficulty of implementing complex EQ/SQ/MQ abilities. Communication/overhead or concrete failure modes are not empirically evaluated.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_studies</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>optimal_configurations</strong></td>
                            <td>No empirical optimal configurations are given. The paper suggests promising components for higher performance (e.g., ensemble learning, attention mechanisms, meta-learning, integration of multiple intelligences such as EQ+SQ), but stops short of specific configuration recommendations backed by experimental evidence.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'On Multiple Intelligences and Learning Styles for Artificial Intelligence Systems: Future Research Trends in AI with a Human Face?', 'publication_date_yy_mm': '2020-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2390.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e2390.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of multi-agent AI systems that coordinate to perform scientific research tasks, including details about their coordination mechanisms, communication protocols, feedback mechanisms, agent specializations, and performance results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Ensemble-DNN cooperative</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Ensemble of Deep Neural Networks with cooperative/collaborative multi-agent behavior</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A referenced conceptual system where an ensemble of DNNs not only aggregates outputs but also communicates and cooperates/collaborates to perform joint complex tasks in an optimized way.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Ensemble DNN multi-agent system</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>The paper describes ensembles of deep neural networks as a form of multi-agent system in which individual DNN agents can exchange information and potentially knowledge to cooperate or collaborate on a shared task; ensembles may be enhanced with attention mechanisms and meta-learning to select inputs/features and improve robustness.</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_agents</strong></td>
                            <td>variable</td>
                        </tr>
                        <tr>
                            <td><strong>agent_specializations</strong></td>
                            <td>Not concretely specified. Implicit specializations include: individual DNN models trained on sub-tasks or modalities (e.g., visual vs audio), attention modules that select feature subsets, and a coordinating ensemble mechanism to fuse outputs or decide responsibility. The paper does not list explicit named roles.</td>
                        </tr>
                        <tr>
                            <td><strong>research_phases_covered</strong></td>
                            <td>Training (learning), inference/execution, and conceptual iterative refinement (via ensemble updates); no explicit mention of literature review or experimental evaluation phases.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_mechanism</strong></td>
                            <td>Implied mechanisms include ensemble aggregation and attention-based selection among agents; coordination is described conceptually (agents cooperate/collaborate to perform joint tasks), but specific orchestration (e.g., voting, parameter sharing, centralized aggregator) is not specified.</td>
                        </tr>
                        <tr>
                            <td><strong>communication_protocol</strong></td>
                            <td>Not specified. The paper mentions exchange of information/knowledge between DNN agents but gives no details about message formats or channels (e.g., shared memory, message passing).</td>
                        </tr>
                        <tr>
                            <td><strong>feedback_mechanism</strong></td>
                            <td>Not detailed; implied mechanisms include iterative learning updates across ensemble members, attention-guided selection, and metalearning to adapt model coordination over episodes.</td>
                        </tr>
                        <tr>
                            <td><strong>communication_frequency</strong></td>
                            <td>Unspecified.</td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>Joint complex tasks amenable to ensembles (e.g., multimodal perception like audiovisual speech recognition; general pattern recognition and decision tasks), but no concrete scientific-research application experiments are provided.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>coordination_benefits</strong></td>
                            <td>Conceptual benefits: improved robustness to noise/incomplete data via multimodal integration (neural binding), better performance through attention and ensemble methods, and the ability to leverage multiple modalities/intelligences. No quantitative results are presented in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_challenges</strong></td>
                            <td>Not empirically evaluated in the paper; conceptual issues include management of heterogenous models, alignment of subtask responsibilities, and design of effective ensemble cooperation protocols.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_studies</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>optimal_configurations</strong></td>
                            <td>No empirical guidance provided. The paper highlights attention mechanisms, ensemble learning, and metalearning as promising ingredients for effective ensembles.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'On Multiple Intelligences and Learning Styles for Artificial Intelligence Systems: Future Research Trends in AI with a Human Face?', 'publication_date_yy_mm': '2020-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2390.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e2390.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of multi-agent AI systems that coordinate to perform scientific research tasks, including details about their coordination mechanisms, communication protocols, feedback mechanisms, agent specializations, and performance results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>MA-RL mentions</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Multi-Agent Reinforcement Learning algorithms (as mentioned)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>The paper references a set of multi-agent reinforcement learning (MARL) algorithms (e.g., MAIS, Coordinated Multi-Agent DQN, MAF, COMA, MADDPG) as important techniques for multi-agent systems and notes their relevance for multi-agent learning and partially observable settings.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Collection of multi-agent RL algorithms referenced in Fig.19</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>This entry groups the MARL algorithms explicitly listed in the paper's Figure 19 as being important for multi-agent learning: Multi-Agent Importance Sampling (MAIS), Coordinated Multi-Agent DQN, Multi-Agent Fingerprints (MAF), Counterfactual Multi-Agent Policy Gradient (COMAPG / COMA-like methods), Multi-Agent DDPG (MADDPG), and related MARL approaches for POMDPs and multi-agent settings. The paper cites these as state-of-the-art algorithm classes relevant to MA systems but provides no implementation details within this work.</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_agents</strong></td>
                            <td>variable</td>
                        </tr>
                        <tr>
                            <td><strong>agent_specializations</strong></td>
                            <td>Not specified in the paper; algorithms are general methods for coordinating multiple learning agents rather than specifying particular specialized agent roles.</td>
                        </tr>
                        <tr>
                            <td><strong>research_phases_covered</strong></td>
                            <td>Learning (policy learning), coordination during execution (decentralized actors/centralized training is discussed as a class in the MARL literature referenced), but no explicit coverage of other research phases in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_mechanism</strong></td>
                            <td>Not detailed in this paper beyond naming algorithm families; the paper groups MA RL algorithms (including coordinated DQN and centralized-training/multi-agent critic approaches) as relevant but does not describe specific coordination protocols.</td>
                        </tr>
                        <tr>
                            <td><strong>communication_protocol</strong></td>
                            <td>Not specified in this paper. MARL algorithms are mentioned at the taxonomy level; communication/interaction channels used by those algorithms are not described here.</td>
                        </tr>
                        <tr>
                            <td><strong>feedback_mechanism</strong></td>
                            <td>Not detailed here. The paper references MARL literature where feedback mechanisms (e.g., centralized critic, counterfactual advantage baselines) exist, but this paper itself does not report those mechanisms or results.</td>
                        </tr>
                        <tr>
                            <td><strong>communication_frequency</strong></td>
                            <td>Unspecified.</td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>General multi-agent learning tasks; the paper highlights MARL as important for partially observable and multi-agent problems but gives no explicit experimental domain within this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>coordination_benefits</strong></td>
                            <td>Paper claims MARL algorithms are 'important and perspective' for AI multi-systems with multiple intelligences, implying benefits for coordinated learning and handling of non-stationarity in multi-agent environments, but provides no quantitative evidence.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_challenges</strong></td>
                            <td>Not detailed in this paper beyond general mentions of the complexity of multi-agent learning (e.g., non-stationarity) and the challenges addressed in the referenced MARL literature.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_studies</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>optimal_configurations</strong></td>
                            <td>No configurations or hyperparameter recommendations are provided in this paper; only a taxonomy and pointers to MARL algorithm families are given.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'On Multiple Intelligences and Learning Styles for Artificial Intelligence Systems: Future Research Trends in AI with a Human Face?', 'publication_date_yy_mm': '2020-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Deep reinforcement learning for multi agent systems: A review of challenges, solutions, and applications <em>(Rating: 2)</em></li>
                <li>A survey of learning in multi agent environments: Dealing with non-stationarity <em>(Rating: 2)</em></li>
                <li>A survey on transfer learning for multi agent reinforcement learning systems <em>(Rating: 2)</em></li>
                <li>Amplifying the social intelligence of teams through human swarming <em>(Rating: 1)</em></li>
                <li>Enabling robotic social intelligence by engineering human social-cognitive mechanisms <em>(Rating: 1)</em></li>
                <li>Socially emotional brain-inspired cognitive architecture framework for artificial intelligence <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-2390",
    "paper_id": "paper-221377377",
    "extraction_schema_id": "extraction-schema-65",
    "extracted_data": [
        {
            "name_short": "AI-SQ multi-system",
            "name_full": "AI with Social Intelligence (AI-SQ) multi-system",
            "brief_description": "A conceptual multi-agent AI system archetype that emphasizes social abilities (communication, coordination, cooperation, collaboration, co-creative collaboration) enabling agents to exchange information and knowledge, align on shared goals, and jointly perform complex tasks.",
            "citation_title": "here",
            "mention_or_use": "mention",
            "system_name": "AI-SQ multi-system (AI with Social Intelligence)",
            "system_description": "A conceptual multi-agent architecture in which individual agents (software modules or robots) possess social intelligence enabling them to communicate, coordinate, cooperate, collaborate, and co-create. The paper frames AI-SQ as a superset of emotional intelligence (EQ) and defines social interaction skills (5C): Communication, Coordination, Cooperation, Collaboration and Co-creative collaboration. Agents may be DNN modules, intelligent robots or other AI sub-systems that exchange data, information and knowledge and support each other's goals or a shared goal.",
            "number_of_agents": null,
            "agent_specializations": "Not explicitly enumerated. The paper describes agents generically as AI sub-systems (e.g., DNNs, robots) that can adopt roles per need: communicators (exchange information), coordinators (align action sequencing and responsibility allocation), cooperators (share relevant information/resources to support individual goals), collaborators (share knowledge to pursue a common goal), and co-creators (drive innovation via exploration and feedback). Specific dedicated roles (e.g., idea-generation vs evaluation) are not specified in the paper.",
            "research_phases_covered": "Conceptually covers ideation/knowledge exchange, coordinated task execution, joint problem solving, and iterative improvement (co-creative prototyping/testing); does not detail explicit literature review or experimental-execution pipelines.",
            "coordination_mechanism": "Described conceptually: can be centralized or decentralized depending on implementation; paper defines coordination as alignment/harmony or sequenced plan (delineating who does what, when, within what duration). No concrete implementation (e.g., centralized controller, consensus algorithm) is specified in the paper.",
            "communication_protocol": "Not specified in technical detail. Paper only states agents 'communicate and exchange data and information' and 'exchange knowledge' (format/structure unspecified). No explicit message formats, serialization, or language/protocols are given.",
            "feedback_mechanism": "Conceptual iterative feedback loops are described for co-creative intelligence: prototyping, testing, exchange of ideas via feedback, and adaptation for further improvements. Also mentions self-assessment/self-awareness capabilities where agents evaluate their own performance and robustness (self-assessment under noise/incomplete data).",
            "communication_frequency": "Unspecified; described at a conceptual level (could be continuous, on-demand, or at phase transitions) but the paper does not provide frequency or scheduling details.",
            "task_domain": "General complex tasks and problem domains where multi-agent coordination is required (the paper suggests applicability across domains including robotics, ensemble DNN tasks, and broadly 'scientific' and complex problem solving), but no concrete scientific-research application with experiments is presented.",
            "performance_metrics": null,
            "baseline_comparison": null,
            "coordination_benefits": "Conceptual benefits described: ability to solve problems difficult for any single agent, improved learning efficiency by leveraging multiple intelligences and learning styles, better decision making, capacity for co-creation and innovation, robustness through social-awareness and self-management. No quantitative benefits or empirical results are reported in the paper.",
            "coordination_challenges": "Discussed challenges (conceptual): need for conflict management when working in groups, limitations in current AI (lack of self-awareness, self-management, social-awareness), potential coordination failures, and the practical difficulty of implementing complex EQ/SQ/MQ abilities. Communication/overhead or concrete failure modes are not empirically evaluated.",
            "ablation_studies": null,
            "optimal_configurations": "No empirical optimal configurations are given. The paper suggests promising components for higher performance (e.g., ensemble learning, attention mechanisms, meta-learning, integration of multiple intelligences such as EQ+SQ), but stops short of specific configuration recommendations backed by experimental evidence.",
            "uuid": "e2390.0",
            "source_info": {
                "paper_title": "On Multiple Intelligences and Learning Styles for Artificial Intelligence Systems: Future Research Trends in AI with a Human Face?",
                "publication_date_yy_mm": "2020-08"
            }
        },
        {
            "name_short": "Ensemble-DNN cooperative",
            "name_full": "Ensemble of Deep Neural Networks with cooperative/collaborative multi-agent behavior",
            "brief_description": "A referenced conceptual system where an ensemble of DNNs not only aggregates outputs but also communicates and cooperates/collaborates to perform joint complex tasks in an optimized way.",
            "citation_title": "here",
            "mention_or_use": "mention",
            "system_name": "Ensemble DNN multi-agent system",
            "system_description": "The paper describes ensembles of deep neural networks as a form of multi-agent system in which individual DNN agents can exchange information and potentially knowledge to cooperate or collaborate on a shared task; ensembles may be enhanced with attention mechanisms and meta-learning to select inputs/features and improve robustness.",
            "number_of_agents": "variable",
            "agent_specializations": "Not concretely specified. Implicit specializations include: individual DNN models trained on sub-tasks or modalities (e.g., visual vs audio), attention modules that select feature subsets, and a coordinating ensemble mechanism to fuse outputs or decide responsibility. The paper does not list explicit named roles.",
            "research_phases_covered": "Training (learning), inference/execution, and conceptual iterative refinement (via ensemble updates); no explicit mention of literature review or experimental evaluation phases.",
            "coordination_mechanism": "Implied mechanisms include ensemble aggregation and attention-based selection among agents; coordination is described conceptually (agents cooperate/collaborate to perform joint tasks), but specific orchestration (e.g., voting, parameter sharing, centralized aggregator) is not specified.",
            "communication_protocol": "Not specified. The paper mentions exchange of information/knowledge between DNN agents but gives no details about message formats or channels (e.g., shared memory, message passing).",
            "feedback_mechanism": "Not detailed; implied mechanisms include iterative learning updates across ensemble members, attention-guided selection, and metalearning to adapt model coordination over episodes.",
            "communication_frequency": "Unspecified.",
            "task_domain": "Joint complex tasks amenable to ensembles (e.g., multimodal perception like audiovisual speech recognition; general pattern recognition and decision tasks), but no concrete scientific-research application experiments are provided.",
            "performance_metrics": null,
            "baseline_comparison": null,
            "coordination_benefits": "Conceptual benefits: improved robustness to noise/incomplete data via multimodal integration (neural binding), better performance through attention and ensemble methods, and the ability to leverage multiple modalities/intelligences. No quantitative results are presented in this paper.",
            "coordination_challenges": "Not empirically evaluated in the paper; conceptual issues include management of heterogenous models, alignment of subtask responsibilities, and design of effective ensemble cooperation protocols.",
            "ablation_studies": null,
            "optimal_configurations": "No empirical guidance provided. The paper highlights attention mechanisms, ensemble learning, and metalearning as promising ingredients for effective ensembles.",
            "uuid": "e2390.1",
            "source_info": {
                "paper_title": "On Multiple Intelligences and Learning Styles for Artificial Intelligence Systems: Future Research Trends in AI with a Human Face?",
                "publication_date_yy_mm": "2020-08"
            }
        },
        {
            "name_short": "MA-RL mentions",
            "name_full": "Multi-Agent Reinforcement Learning algorithms (as mentioned)",
            "brief_description": "The paper references a set of multi-agent reinforcement learning (MARL) algorithms (e.g., MAIS, Coordinated Multi-Agent DQN, MAF, COMA, MADDPG) as important techniques for multi-agent systems and notes their relevance for multi-agent learning and partially observable settings.",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_name": "Collection of multi-agent RL algorithms referenced in Fig.19",
            "system_description": "This entry groups the MARL algorithms explicitly listed in the paper's Figure 19 as being important for multi-agent learning: Multi-Agent Importance Sampling (MAIS), Coordinated Multi-Agent DQN, Multi-Agent Fingerprints (MAF), Counterfactual Multi-Agent Policy Gradient (COMAPG / COMA-like methods), Multi-Agent DDPG (MADDPG), and related MARL approaches for POMDPs and multi-agent settings. The paper cites these as state-of-the-art algorithm classes relevant to MA systems but provides no implementation details within this work.",
            "number_of_agents": "variable",
            "agent_specializations": "Not specified in the paper; algorithms are general methods for coordinating multiple learning agents rather than specifying particular specialized agent roles.",
            "research_phases_covered": "Learning (policy learning), coordination during execution (decentralized actors/centralized training is discussed as a class in the MARL literature referenced), but no explicit coverage of other research phases in this paper.",
            "coordination_mechanism": "Not detailed in this paper beyond naming algorithm families; the paper groups MA RL algorithms (including coordinated DQN and centralized-training/multi-agent critic approaches) as relevant but does not describe specific coordination protocols.",
            "communication_protocol": "Not specified in this paper. MARL algorithms are mentioned at the taxonomy level; communication/interaction channels used by those algorithms are not described here.",
            "feedback_mechanism": "Not detailed here. The paper references MARL literature where feedback mechanisms (e.g., centralized critic, counterfactual advantage baselines) exist, but this paper itself does not report those mechanisms or results.",
            "communication_frequency": "Unspecified.",
            "task_domain": "General multi-agent learning tasks; the paper highlights MARL as important for partially observable and multi-agent problems but gives no explicit experimental domain within this paper.",
            "performance_metrics": null,
            "baseline_comparison": null,
            "coordination_benefits": "Paper claims MARL algorithms are 'important and perspective' for AI multi-systems with multiple intelligences, implying benefits for coordinated learning and handling of non-stationarity in multi-agent environments, but provides no quantitative evidence.",
            "coordination_challenges": "Not detailed in this paper beyond general mentions of the complexity of multi-agent learning (e.g., non-stationarity) and the challenges addressed in the referenced MARL literature.",
            "ablation_studies": null,
            "optimal_configurations": "No configurations or hyperparameter recommendations are provided in this paper; only a taxonomy and pointers to MARL algorithm families are given.",
            "uuid": "e2390.2",
            "source_info": {
                "paper_title": "On Multiple Intelligences and Learning Styles for Artificial Intelligence Systems: Future Research Trends in AI with a Human Face?",
                "publication_date_yy_mm": "2020-08"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Deep reinforcement learning for multi agent systems: A review of challenges, solutions, and applications",
            "rating": 2,
            "sanitized_title": "deep_reinforcement_learning_for_multi_agent_systems_a_review_of_challenges_solutions_and_applications"
        },
        {
            "paper_title": "A survey of learning in multi agent environments: Dealing with non-stationarity",
            "rating": 2,
            "sanitized_title": "a_survey_of_learning_in_multi_agent_environments_dealing_with_nonstationarity"
        },
        {
            "paper_title": "A survey on transfer learning for multi agent reinforcement learning systems",
            "rating": 2,
            "sanitized_title": "a_survey_on_transfer_learning_for_multi_agent_reinforcement_learning_systems"
        },
        {
            "paper_title": "Amplifying the social intelligence of teams through human swarming",
            "rating": 1,
            "sanitized_title": "amplifying_the_social_intelligence_of_teams_through_human_swarming"
        },
        {
            "paper_title": "Enabling robotic social intelligence by engineering human social-cognitive mechanisms",
            "rating": 1,
            "sanitized_title": "enabling_robotic_social_intelligence_by_engineering_human_socialcognitive_mechanisms"
        },
        {
            "paper_title": "Socially emotional brain-inspired cognitive architecture framework for artificial intelligence",
            "rating": 1,
            "sanitized_title": "socially_emotional_braininspired_cognitive_architecture_framework_for_artificial_intelligence"
        }
    ],
    "cost": 0.012233999999999998,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>On Multiple Intelligences and Learning Styles for Artificial Intelligence Systems: Future Research Trends in AI with a Human Face?</p>
<p>Andrzej Cichocki 
Systems Research Institute
Skolkovo Institute of Science and Technology (Skoltech)
MoscowRussia</p>
<p>Polish Academy of Science
WarsawPoland</p>
<p>On Multiple Intelligences and Learning Styles for Artificial Intelligence Systems: Future Research Trends in AI with a Human Face?
267685A6EF580B4454EEB7AE894557F9Artificial Intelligencemultiple intelligenceslearning stylesphysical intelligenceemotional intelligencesocial intelligenceattentional intelligencemoral-ethical intelligenceresponsible decision makingcreativitycognitive functionsmeta-learning of AI systems
This article discusses some future trends and concepts in developing new generation of artificial intelligence (AI) systems which relate to complex facets and different types of human intelligence, especially social, emotional, attentional and ethical intelligence.We describe various aspects of multiple human intelligences and learning styles, which may impact on a variety of AI problem domains.Using the concept of "multiple intelligences" rather than a single type of intelligence, we categorize and provide working definitions of various AI depending on their cognitive skills or capacities.Future AI systems will be able not only to communicate with human users and each other, but also to efficiently exchange knowledge with abilities of cooperation, collaboration and even co-creating something new and valuable and have metalearning capacities.Multi-agent systems such as these can be used to solve problems that would be difficult to solve by any individual intelligent agent.</p>
<p>Introduction</p>
<p>Both human intelligence, as defined by innate, biological intelligence, as well as artificial intelligence (AI), commonly defined as machine intelligence, have been hot topics in a wide spectrum of scientific literature [see e.g., [1][2][3][4][5][6][7][8][9][10][11][12][13]50].In this paper, we explore how multiple aspects of human intelligence and various learning styles may further inspire or promote the development of new kinds of improved intelligent multiagent systems.We also seek to provide an introduction on how different AI-systems can be categorized and ranked depending on their cognitive skills and learning styles.</p>
<p>Progress and even breakthroughs in AI have typically demonstrated that AI systems have the ability to perform often very well, at solving specific problems or tasks such recognition, classification, ranking, prediction, clustering, segmentation, playing games, like Go/Jeopardy, and even creation of artwork, like music or paintings [see e.g., 5,14,15,[52][53][54][55].However, as AI systems evolve and expand, it is increasingly clear that their full potential lies beyond merely solving well-defined problems or performing tasks within preset parameters.Rather, many AI systems of the future will interact with other AI sub-systems (like smart robots or multi-agents) alongside human users to solve dynamically changing and complex problems.For this type of interaction to take place, multi-agent systems must have the ability to continuously learn, review, and evolve their interaction strategies during ongoing communication.In other words, research in AI may go far beyond a single mental-intellectual or logicalmathematical intelligence, towards the concept of multiple intelligences.We refer to this phenomenon as "AI with multiple intelligences" as until now most AI methods and approaches are based on one single type of intelligence and perform only one specific task or a set of a few closely related tasks, without fully exploring and implementing sophisticated cognitive skills, emotional-social intelligence (ESI), and responsible group decision making.</p>
<p>In this paper, we mostly consider AI systems which are, in general, in a form of a multiagent system (MAS), e.g., some kind of smart humanoid robots or computerized systems composed of multiple interacting agents (see Figure 1).This is closely related to the concept of Distributed Artificial Intelligence (DAI), which is an important subfield of AI research, dedicated to the development of distributed solutions for specific problems [14, 15, 21, and 22].</p>
<p>Fig. 1 Multi-agents can not only communicate and exchange data and information, but may have also ability to coordinate, cooperate and/or collaborate and exchange knowledge.</p>
<p>AI as Multidisciplinary Research</p>
<p>AI is grounded in, advanced by research from multiple disciplines, inspired, and driven by Human Cognitive Science, Systems Neuroscience and the Computational Sciences (see Figure 2).</p>
<p>Particularly, human cognitive science and systems neuroscience play key roles in the development of new AI concepts and smart/intelligent systems.In fact, AI research spans the intersection of many fields including human brain science, computer science and applied mathematics [5][6][7].That being said, human cognitive science is a highly interdisciplinary area in itself, exploring ideas and methods from biology, psychology, philosophy, and linguistics.Fundamental human cognitive processes are related to higher-level functions of the human brain and encompass language, imagination, perception, and planning [7,14,19,41,57,58].Cognitive skills (functions, abilities or capacities) allow us to receive, select, store, transform, develop and retrieve information and knowledge that we have received from external stimuli.A better understanding of such cognitive functions and processes in the human brain would allow us to implement them in future generations of AI systems more effectively and extend their flexibilities and applications (see Section 9).</p>
<p>AI Subdomains: Current Key Applications</p>
<p>In recent years, AI research has made tremendous progress which has already found applications in many fields, from computer vision (CV) (e.g., machine vision, robot vision) and pattern recognition (classification, clustering), to areas like robotics and intelligent agents (R/IA), Natural Language Processing (NLP) (natural language generation (NLG), natural language understanding (NLU), machine translation, sentiment analysis, information retrieval and extraction), Speech Recognition and Synthesis (SR/S), Planning, Scheduling and Optimization (PSO), Knowledge Representation and Reasoning (KRR) and Expert Systems (ES) (Figure 3).Currently, Machine Learning (ML) and its subdomains -Deep Learning (DL) and Artificial Neural Networks (ANN) -play a key role for AI research.Many researchers consider ML to be an important subdomain of AI.However, in our opinion, not all ML algorithms and methods, and not even all ANN, can be classified as part of AI since not all methods in machine learning mimic human intelligence.The same is true for all other domains, like expert systems, NLP or data mining (see Figure 3)</p>
<p>Multiple Intelligences</p>
<p>In Figure 4, we illustrate six vital multiple human intelligences: Physical intelligence (PQ), mental-intellectual intelligence (verbal-logical-mathematical, or IQ), emotional and social intelligence (referred to as EQ and SQ), creative Intelligence (CQ) and moral and ethical intelligence (MQ) (see e.g., [33,[38][39][40][41][42][43]51]).</p>
<p> Physical Intelligence or Physical Quotient PQ, also known as bodilykinesthetic intelligence, is an intelligence derived or learned through physical, tactile and practical learning such as sports, dance or craftsmanship.Physical intelligence is an important aspect of personal effectiveness and physical performance.</p>
<p> Mental/intellectual Intelligence aka Intelligence Quotient -IQ is the mental ability involved in language, mathematical analytical skills, logical reasoning, perceiving relationships and analogies, calculating, data interpretation, verbal abilities, visual and spatial reasoning, classification, and pattern detection and recognition. Emotional intelligence (Emotional Quotient --EQ) is the ability to perceive, assess, generate, understand and control emotions.EQ also involves the regulation of emotions to promote further emotional and intellectual growth.The concept of EQ was conceptualized and investigated by Michael Beldoch and later popularized by Daniel Goleman, among others [35,36]. Social Intelligence (Social Quotient --SQ), is, roughly speaking, the capacity to understand other humans and to act both rationally and emotionally in relation with others.SQ is important particularly when forming social bonds and when working within a team.This type of ability does not necessarily need to be limited to humans, but could also potentially describe the intelligence of a network of intelligent multi-agents, which need to perform complex tasks or solve specific problems jointly, while resolving the various conflicts, which may arise from working within a group.</p>
<p> Moral and Ethical Intelligence (aka MQ) is defined according to Lennick and Kiel [33] as "the mental capacity to determine how universal human principles should be applied to our personal values, goals, and actions".Usually, being morally and ethically intelligent means not only just assessing what is right and what is wrong, but also having the courage to do what is right and prevent both oneself and others from doing the wrong things [32][33][34].</p>
<p>As regards Social Intelligence -SQ, in particular, this was first conceptualized by psychologist Edward Thorndike (see e.g., [37]), but was later reinvented, extended and popularized by many psychologists, especially Howard Gardner [8,9] and Daniel Goleman [36].Gardner proposed and investigated eight human multiple intelligences, out, of which the two most important ones are: intrapersonal intelligence and interpersonal intelligence, which correspond to EQ and SQ intelligences in the above schema (see Figures 4 and 6   According to the theory of multiple intelligences proposed by Gardner, at least eight different types of intelligence exist: Logical-mathematical (reasoning, number smart), Visual-spatial (picture smart), Verbal-linguistic (word smart), Musical-rhythmic and harmonic (sound smart), Bodily-kinesthetic (body smart), Naturalistic (nature smart), Intrapersonal (self-smart), and Interpersonal (social smart) [8,9].Most humans have all of these intelligences, but not all of them are developed in all of us equally or sufficiently well, therefore we often do not use them effectively.A person with only one or two intelligences, which are well developed, may have difficulties to function in the world: such is the case, for example, of many people with Autism Spectrum Disorder (ASD).</p>
<p>Howard Gardner defined an intelligence as "the ability to find and solve problems and create products of value in one's own culture".Pei Wang [3,4] defined intelligence as "the capacity of an information-processing system to adapt to its environment while operating with insufficient knowledge and resources."</p>
<p>Gardner's theory of multiple intelligences has come under some criticism from researchers in education, psychology and philosophy [10,[39][40][41][42].These critics argue that Gardner's definitions of multiple intelligences are too broad and mostly represent what could be called talents, abilities, preferences or personality traits.Others, meanwhile, argue that his definition was not broad enough, as he did not include spiritual intelligence in his list (encompassing concepts such as love, generosity, openness, courage, self-discipline, forgiveness, compassion, detachment, sense of purpose).However, this was mainly due to the challenges of codifying quantifiable scientific criteria for this type of intelligence, which Gardner rigorously investigated.We do however; note that spiritual intelligence is considered by some researchers as the most sophisticated form of human intelligence since it is related to the formation of higher meanings and human values.Even if some of multiple intelligences could be controversial or do not exist for humans [1,7], we believe that they are very useful not only to categorize but also to develop new AI systems.</p>
<p>Why, then, is multiple intelligence theory so interesting and important in AI research and development?First of all, it allows AI systems to learn a variety of different tasks and solve different, or even unrelated sub-problems at once.Moreover, possessing multiple intelligences can draw multi-agents back into a specific learning style, which may be most appropriate to the task at hand.Furthermore, through using their different intelligences together, multi-agents can direct their attention to more specific tasks and problems and this may help to increase their efficiency of learning, and consequently their performance and/or better decision making [23][24][25][26].</p>
<p>AI systems can be classified according to their functionality and ability (see for details</p>
<p>Learning Styles and Machine Learning (ML) Algorithms</p>
<p>The main difference between multiple intelligences and perceptual learning styles is that multiple intelligences represents different intellectual and cognitive abilities, while corresponding perceptual (sensory) learning styles are the different ways in which a human or an intelligent agent approaches and learns a specific ability to solve problems or execute desired tasks depending on available sensory data.The Sensory Learning Style, also known as the VAK, uses the three main sensory receivers: Visual, Auditory, and Kinesthetic (see Figure 6 (a)).</p>
<p>Multiple intelligences can be learned -or at least improved and enhanced -via systematic and continuous learning using suitable sensory/training data and appropriate social interactions.It should be noted that certain learning styles can help to build social skills in multi-agents, that is to learn and to develop some knowledge and experience who and what is around them and how properly communicate and interact socially in order to do some tasks/actions or to make responsible decisions.Moreover, by learning from different modality of data, we can improve considerably the performance.For example, by integration of audio data with visual data (lips movements) speech recognition can be dramatically improved in noisy environment (mechanism that called neural binding in the neuroscientific literature) [56].Some of the multiple intelligences have already been explored in commercial AI systems.For example, the BAIDU AI Composer is now used to compose creative music inspired by artistic paintings.Just to mention a few others, the AIVA (Artificial Intelligence Virtual Artist) system has a musical intelligence with the ability to compose original music for films (recognized by SACAM), the Intelligent Atlas robot developed by Boston Dynamics possesses impressive bodily-kinesthetic (physical) intelligence, and DeepMind's AlphaGo, which employs a Monte Carlo tree search combined with reinforcement learning algorithm, possesses sophisticated logicalmathematical intelligence to play, almost perfectly, a complex game Go.However, as of now, none of these AI systems can perform two or more quite different cognitive tasks.</p>
<p>In current AI systems, we extensively use six basic ways of learning: Supervised learning, unsupervised learning, semi-supervised learning, reinforcement learning, ensemble learning and deep learning (see Figure 7).Particularly, important and useful for our concepts and models are: Ensemble learning, deep learning algorithms, and deep reinforcement learning [15,20,21] (see  in Appendix for more details).</p>
<p>AI Systems with Multiple Intelligences</p>
<p>We now provide a new categorization and working definitions of AI systems (multiagents) depending on their abilities, flexibility and level/type of intelligence as follows (see also Figure 8).</p>
<p>AI with Physical Intelligence abilities (AI-PQ</p>
<p>) is an AI system implemented not only in software but also physically in hardware (e.g., as an electronic neuromorphic chip), which can perform specific tasks on-line or in near real-time with the ability to demonstrate good physical efficiency, that is: low power consumption, high speed, low latency, robustness and resilience to changing conditions and environmental conditions (like temperature, pressure or humidity).Such an AI system should have also the ability to control and automatically optimize power consumption depending on tasks and preferences.</p>
<p>AI with mental or intellectual abilities (AI-IQ</p>
<p>) is a computerized AI system, which can perform some logical, mathematical, analytical, and/or verbal tasks with the abilities of analytical skills, logical reasoning, pattern recognition (the ability to relate or recognize multiple patterns or events) and/or the ability to store and retrieve information.</p>
<p>AI with Emotional Intelligence abilities (AI-EQ</p>
<p>) is an AI system, which possess selfawareness, self-assessment, self-regulation (or self-management).In other words, AI-EQ has the capacity to evaluate/assess its own performance.It also should have reliability and robustness of performance for specific tasks, for example robustness in respect to noisy, corrupted and incomplete data sets (i.e., efficient treatment/ processing of incomplete data).The AI-EQ should also have the ability to selfassessment of own performance depending on the noise level or incompleteness of sensory data sets.</p>
<p>Remark: It should be noted that our AI-EQ should not be confused with Emotional AI.Emotional AI systems refer to technologies that use affective computing and AI methods to sense, detect and classify human emotions and behaviors.Affective computing, in general, is the study and development of AI systems and devices that can recognize, interpret, process, and simulate human affects.However, affective computing aims mostly to enable AI systems to understand the emotional states expressed by human subjects (see e.g., [30,31]).</p>
<p>It should be noted that in this paper, we consider a more general scenario, where AI-EQ is defined as an AI system, which possesses its own selfawareness, self-assessment and self-management (self-regulation).</p>
<p>AI with Social Intelligence abilities (AI-SQ</p>
<p>) is an AI system, which has the ability to interact and communicate with human and/or other AI sub-systems (e.g., Deep Neural Networks (DNNs), intelligent robots, multi-agents) and exchange information and knowledge and support each other.Moreover, such AI-SQ has ability to coordinate, cooperate and even collaborate with other AI sub-systems (intelligent agents).For example, for ensemble of DNNs which have ability to not only communicate but also cooperate and/or collaborate to perform joint complex tasks in an optimized way.</p>
<p>AI with Computational Creativity (AI-CQ</p>
<p>) is an AI system that has the capacity to both generate and evaluate novel outputs, including images, music or videos, which would, if produced by a human, be considered creative and to have value and purpose, or conform to common sense (see also Figures 9 (a) and (b)).</p>
<p>Remark: Computational creativity (also known as artificial creativity, creative computing or creative computation) is a closely related multidisciplinary endeavor that can be considered as the intersection of the fields of artificial intelligence, cognitive psychology, philosophy, and the arts [43-46, 57, 58].</p>
<p>AI with Ethical and Moral Intelligence (AI-MQ</p>
<p>) is defined as an AI system which has the ability not only to judge its own actions and actions of others (whether agents or humans) from the point of view of ethics, but also have executive power to make responsible decisions to prevent "wrong" doing.In other words, AI-MQ should have some kind of self-awareness and executive power not only to judge or asses what is "right" and "wrong" but also should have ability to take action to do what is right.AI-MQ intelligence would be most challenging to implement from of all intelligences which we discuss in this paper though, if possible, perhaps the most valuable for humanity.</p>
<p>Remark: While ethics and morals both relate to "right" and "wrong" behaviors and are therefore often used interchangeably, we do differentiate between them in a substantial way: While morality is something normative but usually personal, ethics is the standard of "right and wrong" which is established by a certain community, culture, or social setting (e.g., codes of conduct in workplaces).In other words, ethics refers to rules provided by an external source, whereas morals refer to an individual's own principles regarding what is "right" and "wrong" [32][33][34].</p>
<p>In all our working definitions, we assume that "Insufficient Knowledge and Resources" are the typical working conditions for any real intelligent systems, along with the ability to adapt (according to the definition of intelligence by Pei Wang, see above) [3,4].Furthermore, an advanced AI system may additionally have a metalearning (learning to learn) capability to improve gradually the learning algorithm itself, given the experience of multiple learning episodes [4,47].It is interesting to note that, for example high AI-PQ is necessary for agile robotic and manufacturing systems, while AI-IQ intelligence is needed in all problem solving systems.</p>
<p>AI with Social Intelligence (AI-SQ)</p>
<p>The main attribute, or characteristic, of AI-SQ are social interactions, which can be represented and realized through: Communication, coordination, cooperation, collaboration and co-creative collaboration skills -5C skills (see for detail Figure 10).[2,11,23,35,44,45 ].</p>
<p>Remark: Although words such as coordination, cooperation and collaboration are often used interchangeably in the context of social interactions and effective teamwork, we must note substantial differences among them. Using these words interchangeably poses a risk of confusion, as well as diluting their meaning and diminishing the potential for designing desired learning styles by AI researchers and developers</p>
<p>Therefore, we provide here a categorization of AI-SQ and working definitions of AI-SQ depending on their interaction levels and performed tasks:</p>
<p>A. AI with communication ability provides an efficient way for exchange of information and data between intelligent agents.</p>
<p>B. By AI with coordination ability, we understand the ability of multi-agents to maintain some harmony and/or alignment among individual agents efforts toward accomplishment of specific common goals.Coordination can also be understood as a sequenced plan of actions to be performed by intelligent agents, by delineating who will do what, when, and within what time duration.</p>
<p>C. AI with cooperation intelligence is a network of multi-agents or physical smart robots, where each individual agent/robot exchanges relevant information and resources in support of each other's goals, rather than a shared common goal.</p>
<p>It is interesting to note that in the case of cooperation, the result will be created by individual/independent agent/robot efforts, rather than through a collective team effort.In such a case, sub-tasks for each individual agent/robot are separated, but with a well-understood and defined global task for a network of multi-agents.</p>
<p>D. AI with collaboration intelligence is characterized by the ability of multiagents to exchange not only information but also knowledge and to work together and/or with humans to produce or create something in support of a shared task.In general, collaboration is the action of working together with someone to produce or create something.Intelligent agents should share a common goal or principle to contribute jointly to perform a specific task.</p>
<p>E. AI with co-creative intelligence is a network of multi-agents, which has the ability to work together to produce something new, innovative and even unexpected, which has value and purpose and follows common sense.Such co-creative intelligence can be achieved by knowledge/expertise, experience, curiosity, exploration, flexibility, a strong motivation, prototyping, testing and exchange of ideas via feedback, and adaptation for further improvements (see Figures 9 and 10).</p>
<p>Remark: Creative solutions or ideas can be produced in several ways: (1) Novel (nontrivial, unexpected) combinations of familiar ideas;</p>
<p>(2) Nonlinear or multilinear transformation of original data sets into higher dimensional spaces, so that new structures can be generated, which could not have arisen before; (3) Generation of novel ideas by the exploration of structured conceptual spaces.Furthermore, in the creative process and learning, one or more of the following may be involved depending on the circumstances: Synthesis, revolution, reapplication, evolution, and changing direction [44,45].</p>
<p>AI with Emotional and Social Intelligence</p>
<p>Social intelligence (SQ) can be considered an extension or a superset of emotional intelligence (EQ) since it is a much broader concept than emotional intelligence.In fact, in the psychology both intelligences are often integrated as EQ &amp; SQ or briefly as ESI (emotional-social intelligence) [13,14,16,19,38,42].</p>
<p>AI with Emotional and Social Intelligence is referred to here as (AI with EQ+SQ with five fundamental abilities of an intelligent multi-agent: self-awareness, selfmanagement, social awareness, social (interaction) and responsible decision making skills.These skills would allow an AI multi-system with EQ &amp; SQ not only to understand, but also to manage and perform self-regulation and social interactions (see for detail in Figure 11).</p>
<p>Self-awareness of AI with EQ+SQ multi-system (multi-agent) can be interpreted, as its ability to evaluate or asses its own behaviors (i.e., outputs, actions, decisions), strengths and weaknesses across various situations, i.e., assess its own performance, reliability and potential limitations in performing specific tasks in different scenarios, e.g., when sensor data sets are corrupted by noise or outliers.</p>
<p>Social-awareness is the capacity of understanding and assessing of behaviors, or performance and/or reliability and robustness of interconnected and interacted multiagents or human users, in respect to environmental changes, quality of input/output data, and/or the changing of desired tasks.Self-management is characterized as the capacity of planning and self-controlling one's own actions dependent of external changes, self-adaptability to various conditions and flexibility to a changing environment, resilience and robustness to noise and/or outliers or corrupted sensory signals/data sets and the ability to identify potential problems in order to make a responsible choice from among the possible options.</p>
<p>Responsible (ethical) decision making is characterized by the capacity to generate alternative solutions and apply criteria which allow an intelligent agent to choose the ethical solutions or decisions, i.e. the ability to plan and act ethically and responsibly (see Figure 12).By ethical principles and solutions, we usually understand: value of humans, avoiding harm, solidarity, justice, and social responsibility for common good [12].Finally, Social interaction skills of AI with EQ+SQ can be expressed, first all, by the abilities of communication, cooperation, collaboration, or more advanced, co-creative collaboration skills with smooth and efficient interactions and teamwork.However, other important cognitive skills should be also taken here into account when looking at this type of intelligence, such as assertiveness, tolerance to the limitations of others, the ability to avoid or mitigate conflicted actions or solutions (i.e., efficient conflict management), and also the ability to learn from others and teach others [13][14][15][16][17][18][19].</p>
<p>Attentional Intelligence</p>
<p>There are several vital cognitive abilities for AI, encompassing different aspects of intellectual functions and processes, including perception (visual, auditory, tactile), attention (attending specific information and ignoring other), responsible inhibition (ability to suppress inappropriate responses), inference (i.e., a conclusion or idea reached on the basis of evidence and reasoning and/or the process of reaching such a conclusion), the formation of knowledge, pattern recognition, episodic memory (association of events with place and time), short-term and long-term memory, judgment and evaluation, reasoning and computation, planning, strategic problem solving, continual meta learning, responsible decision making, comprehension and generation of language (see Figure 13 for detail).</p>
<p>Fig. 13 The eight core cognitive skills important for future AI systems.</p>
<p>In this battery of important cognitive abilities and skills as regards AI, complex attentions, continual meta learning and self-adaptation to the surrounding environment are the ones which will play key roles [7,14,15].Attention in AI can be interpreted as a neural attention mechanism which, for example, equips, an ensemble of deep neural networks with the ability to focus and perform a smart selection on a subset of their inputs (or features) [24][25][26][27][28][29].For example, an AI system with attention will have the ability to automatically select specific inputs or a specific subset of stimuli or input data (e.g., some specific patches of images or specific frequency of audio signals), in order to solve a problem more efficiently and/or more robustly with respect to noise or outliers.</p>
<p>Drawing on research in cognitive science, we can say that humans have at least four main types of attention used in our daily lives: Selective attention, divided attention, sustained attention, and executive attention.All these "attentions" can principally be implemented and employed in AI systems [24][25][26][27][28][29].Selective attention is the ability to focus or concentrate on a task even when some distractions are present (e.g., noise, outliers, changing environmental conditions) (see e.g., [28] and Figure 14 for more detail).</p>
<p>Fig. 14 Components of attentional intelligence: Alertness is a state of being ready to react immediately to a specific stimulus, while attention mechanism is principally focus on a certain specific part of information or stimuli or training data sets, when processing a large amount of raw information.Spatial Attention is a form of visual attention that involves directing attention to a location in 2D or 3D space, while Temporal Attention is a special case of attention (e.g., visual attention) that involves directing attention to specific instants of time.</p>
<p>The essence of temporal attention is to flexibly focus in time to recognize temporal e.g., rhythmic patterns Attention Switching task is paradigm requiring AI system to switch between performing multiple different individual tasks.It can be interpreted as a perceptual cognitive function that involves the ability to unconsciously shift attention between one task and another.Divided attention is a type of simultaneous focus that allows to process different information sources and efficiently perform multiple tasks simultaneously, while Executive Attention, refers to ability to control responses, particularly in conflict situations where several responses are possible.Interference Suppression is mechanism to ignore some salient perceptual information in a bivalent task while attending to the less salient conflicting information.On the other hand, Inhibition involves the ability to avoid further processing of stimuli or information, which could or should be ignored.Supervisory Attentional control is a higher level cognitive mechanism active in non-routine or novel situations; it requires conscious control in response to specific environmental stimuli and uses flexible strategies to solve a variety of difficult conflicted problems.Meta Attention or Meta focus consists of regulation of attention and knowledge of attention (i.e., noticing where AI-system focus is directed and self--awareness of employing specific strategies so that it keeps its attention focused on the task at hand.Meta Memory is awareness of memory strategies that work best for AI system.Meta Perception or Meta Sensing means noticing what AI system is sensing/measuring or "feeling", and finally, the most sophisticated Meta Cognition involves of selfawareness of the strategy an AI system is using to learn to perform specific tasks and evaluating whether this strategy is sufficiently effective.</p>
<p>Selective attention occurs when the awareness -whether that is visual, auditory, or tactile-is channeled onto something specific or focused on relevant targets.Divided attention occurs when mental focus is directed towards multiple tasks or ideas at once.Sustained attention is the ability to attend to a task continuously for an extended period.Executive attention refers to our ability to regulate responses or decisions, particularly in situations of conflict or when one receives confusing and contradictory stimuli.When utilizing their executive attention in such a conflict setting, a human being or an AI system should have the ability to regulate their responses accordingly where several non-consistent responses are possible (see Figure 14).In general, Attention can be considered as focused self-awareness and it is attracted to selected range of features of specific stimuli like images, sounds, and words.Attentional Intelligence (AI-AQ) (see Figure 14 for detail) is closely associated with the efficient processing of information and knowledge and it plays a key role in the human intelligence.</p>
<p>Conclusions and Discussion</p>
<p>There are various definitions of human and AI intelligences and creativities that have been developed and built up over years of discussion and disputing, rewording and reworking, among psychologists, philosophers, neuroscientists, cognitive and computer scientists [4,7].There are, inevitably, issues with the working definitions of various intelligences -discussed in this paper, some arguably pedantic, some disputable or controversial and some need to be refined.</p>
<p>Since AI research is inspired by human intelligence, we believe that multiple intelligences and corresponding learning styles will play an important role in the research, development and evaluation of a new generation of distributed general AI systems.Furthermore, in many specific applications of AI, for example, in biomedical applications, an extremely vast diversity of knowledge and cognitive skills is required, and therefore many different forms of cognitive skills and/or intelligences could be potentially useful.</p>
<p>Although current state-of-the-arts AI systems already exploit and mimic some human intelligences, still, emotional, social, attentional and moral-ethical intelligences are not implemented to their full potential.For example, current AI systems have the ability, to some extent, to detect and recognize human emotions, but so far, they do not possess self-awareness, self-management, self-assessment, social-awareness and social skills to interact with other agents efficiently.Furthermore, current AI systems still have quite limited cognitive skills in other domains and are not yet able to perform intelligent and responsible decision making.</p>
<p>Since emotional-social intelligence, attentional intelligence and moral-ethical intelligence related to responsible decision making are the essence of human relationships and are essential for effective teamwork and social co-existence, we expect more research and development in AI systems which will have the ability to meaningfully interact with users socially, understand their behaviors and abilities, and even understand (to some extent) theory of human minds, including complex cognitive tasks, emotions and human social interactions.</p>
<p>In this paper, we attempted to categorize various AI systems depending on their abilities, learning styles and learning algorithms.</p>
<p>The essential purpose of such categorizations of AI systems (and corresponding working definitions) is attempt to make them, as much as possible, useful, inspiring and insightful, due to the following reasons [4]: a) They explain what kind of features or components should each specific AI system have and they have some explanatory power, which may lead to progress not just in AI but also in systems neuroscience.b) They not only categorize AI systems, but can also allow us to measure their degree of intelligence.If there are different kinds of intelligences, we need some taxonomy for identifying the kind of intelligence possessed by a system (if any), and quantitatively comparing it to that of other AI systems.</p>
<p>c) They could be some kind of guide to measure the progress and/or to demonstrate some potential in the development of new generation of AI systems.Here, a key point is to measure the cognitive skills, flexibility and meta-level learning capability, rather than the concrete problem-solving capability.</p>
<p>d) Furthermore, they allows us to formulate explicitly or implicitly new challenging sub-problems in AI, according to the motto of "a problem well-stated is half solved".</p>
<p>Furthermore, it is interesting to note that many features, especially self-control, selfawareness, social emotions, attention, responsible decision making, ethicalawareness, and moral-ethical responsibilities, of the proposed AI with PQ, IQ, EQ, SQ, CQ, AQ and MQ intelligences are associated with the big five personality traits of humans: Openness (tendency to creativity, curiosity and imagination), Conscientiousness (tendency to being diligent, responsible and self-aware), Extraversion (tendency towards sociability, assertiveness and emotional expressiveness), Agreeableness (tendency towards being collaborative and trustworthy) and Emotional Stability (tendency towards to have reliable and stable behaviors and emotions, self-regulation, resilience) [40][41][42].</p>
<p>However, it is neither necessary nor practically useful to attempt to develop and design current AI systems, which would be able to simulate or mimic exactly all human, multiple intelligences; this is also neither feasible nor realistic.Rather, it is desirable and expected that AI systems would have complementary and/or augmented intelligences to existing human multiple intelligences.This concept is related to the recently introduced AI augmented intelligence, where AI works together with humans to enhance cognitive performance, including learning, decision making and forming new experiences.Intelligent augmentation will use and integrate human multiple intelligences, together with more advanced cognitive skills and computational technologies, but with the main objective, not of replacing humans, but rather of assisting them and enhancing their capacities.For example, an AI multi-agent with emotional-social intelligence would be able to analyze social cues and human interactions so as to enhance human team collaboration.Another example could be AI agents who collaborate with human game players in E-sports to complete customdesigned missions.[20,15,21] ) and references therein for more details).</p>
<p>Fig. 2
2
Fig. 2 AI as multidisciplinary research of three areas: Cognitive Science, Systems Neuroscience, and the Computational Sciences.On the other hand, AI methods allow us to better understand systems neuroscience and human cognitive science and even develop new computational and mathematical tools.</p>
<p>Fig. 3
3
Fig.3Core areas related to AI: AI can be considered as a wide collection of different technologies, rather one independent field.Not all methods used in machine learning (ML) belong to AI.</p>
<p>(b)).</p>
<p>Fig. 4
4
Fig. 4 Human multiple intelligences, that are, in general, strongly correlated and mutually dependent.</p>
<p>Figure 5 (Fig. 5
55
Fig. 5 Types (classification) of AI and future trends in development of general AI: (a) based on functionality, (b) based on capability.</p>
<p>Fig. 6 (
6
Fig. 6 (a) Three main human perceptual (sensory) learning styles and (b) eight different learning styles and their corresponding multiple intelligences, as formulated by Gardner.</p>
<p>Fig. 7
7
Fig. 7 Basic description and features of six fundamental learning approaches used in ML and AI systems.</p>
<p>Fig. 8
8
Fig. 8 Categorization of AI (multi-agents) with the six intelligences: Physical intelligence (PQ), Intellectual intelligence (IQ), Emotional intelligence (EQ), Social intelligence (SQ), Creative intelligence (CQ) and Moral-Ethical intelligence (MQ).</p>
<p>Fig. 9 (
9
Fig. 9 (a) Components of creative intelligence, (b) creative intelligence process.</p>
<p>Fig. 10
10
Fig. 10 AI-SQ multi-system (multi-agent) with five social capabilities to interact (5C social skills): Communication, Coordination, Cooperation, Collaboration and Co-creative collaboration.</p>
<p>Fig. 11
11
Fig. 11 Conceptual graph illustrating AI with EQ+SQ or AI with ESI (Emotional-Social Intelligences) with the advanced cognitive functions: Self-awareness, social (external) awareness, interaction (social) skills and self-management abilities.Such advanced AI has both autonomous and social features.</p>
<p>Fig. 12
12
Fig. 12 Responsible-ethical decision making process.</p>
<p>Fig. 15
15
Fig. 15 Basic supervised (a) and unsupervised (b) learning algorithms used in machine learning.</p>
<p>Fig. 16
16
Fig. 16 Basic ensemble learning algorithms.</p>
<p>Fig. 17
17
Fig. 17 Basic reinforcement learning algorithms.</p>
<p>Fig. 18
18
Fig. 18 Basic deep leaning models and learning algorithms (meaning of abbreviations: ResNet-Residual Network or Residual CNN, LSTM -Long Short-Term Memory and GRU -Gated Recurrent Unit which are special cases of RNNs).</p>
<p>Fig. 19
19
Fig. 19 Categorization of deep reinforcement learning algorithms.Each category consists of a number of specific algorithms (see e.g., [20]): Stochastic Policy Gradient (SPG): REINFORCE, Soft Actor-Critic (SAC), Asynchronous Advantage Actor-Critic (A3C); Simple Policy Gradients algorithms (SmpPG): REINFORCE, SAC, A3C, Deep Deterministic Policy Gradient (DDPG), Distributed Distributional Deep Deterministic Policy Gradients (D4PG), and Twin Delayed Deep Deterministic (TD3); Deep Q-Networks: DQN, Double Deep Q Network (DDQN), DDQN with Duel Architecture and DDQN with Proportional Prioritization; Actor-Critic (AC): SAC, A3C, Deep Deterministic Policy Gradient (DDPG), D4PG, TD3, Trust Region Policy Optimization (TRPO) and Proximal Policy Optimization (PPO); Monte Carlo (MC): REINFORCE, PPO and TRPO; Natural Policy Gradient (NPG): TRPO, PPO, Actor-Critic using Kronecker-Factored Trust Region (ACKTR) and Actor-Critic with Experience Replay (ACER); Deterministic Policy Gradient (DPG): DDPG, D4PG and TD3; Q-Prop (hybrid of MC &amp; AC).Finally, the most important and perspective for our AI multi-systems with multiple intelligences are two class of sophisticated RL algorithms: Partially Observable Markov Decision Process (POMDP): Deep Belief Q-network (DBQN), Deep Recurrent Q-network (DRQN), Recurrent Deterministic Policy Gradients (RDPG), and Multi-Agent (MA) learning: Multi-Agent Importance Sampling (MAIS), Coordinated Multi-Agent DQN, Multi-Agent Fingerprints (MAF), Counterfactual Multi-Agent Policy Gradient (COMAPG) and Multi-Agent DDPG (MADDPG) (see[20,15,21] ) and references therein for more details).</p>
<p> Andrzej Cichocki</p>
<p>The neuroscience of intelligence: Empirical support for the theory of multiple intelligences?. C B Shearer, J M Karanian, Trends in Neuroscience and Education. 20176</p>
<p>Hybrid-augmented intelligence: Collaboration and cognition. N N Zheng, Z Y Liu, P J Ren, Y Q Ma, S T Chen, S Y Yu, J R Xue, B D Chen, F Y Wang, Frontiers of Information Technology &amp; Electronic Engineering. 1822017</p>
<p>On defining Artificial Intelligence. P Wang, Journal of Artificial General Intelligence. 1022019</p>
<p>On Defining Artificial Intelligence"-Commentaries and Author's Response. D Monett, C W Lewis, K R Thrisson, Journal of Artificial General Intelligence. 1122020Introduction to the JAGI Special Issue</p>
<p>The unreasonable effectiveness of deep learning in artificial intelligence. T J Sejnowski, 2020Proceedings of the National Academy of Sciences</p>
<p>A deep learning framework for neuroscience. B A Richards, T P Lillicrap, P Beaudoin, Y Bengio, R Bogacz, A Christensen, C Clopath, R P Costa, A De Berker, S Ganguli, C J Gillon, Nature Neuroscience. 22112019</p>
<p>One intelligence or many? Alternative approaches to cognitive abilities. H S Paik, 1998. July2920</p>
<p>Intelligence Reframed: Multiple Intelligences for the 21st Century. H E Gardner, 2000Hachette UK</p>
<p>The science of multiple intelligences theory: A response to Lynn Waterhouse. H Gardner, S Moran, Educational Psychologist. 4142006</p>
<p>L S Almeida, M D Prieto, A I Ferreira, M R Bermejo, M Ferrando, C Ferrndiz, Intelligence assessment: Gardner multiple intelligence theory as an alternative. 201020</p>
<p>Artificial intelligence and communication: A humanmachine communication research agenda. A L Guzman, S C Lewis, New Media &amp; Society. 2212020</p>
<p>Artificial intelligence and the future of work: Human-AI symbiosis in organizational decision making. M H Jarrahi, Business Horizons. 6142018</p>
<p>. W S Bainbridge, E E Brent, K M Carley, D R Heise, M W Macy, B Markovsky, J Skvoretz, Artificial social intelligence. Annual Review of Sociology. 1994</p>
<p>Enabling robotic social intelligence by engineering human social-cognitive mechanisms. T J Wiltshire, S F Warta, D Barber, S M Fiore, Cognitive Systems Research. 432017</p>
<p>A survey on transfer learning for multi agent reinforcement learning systems. F L Da Silva, A H R Costa, Journal of Artificial Intelligence Research. 642019</p>
<p>Amplifying the social intelligence of teams through human swarming. L Rosenberg, G Willcox, D Askay, L Metcalf, E Harris, 2018 First IEEE International Conference on Artificial Intelligence for Industries (AI4I). 2018</p>
<p>Deep learning for AI. Y Bengio, I Goodfellow, A Courville, 2020Invited talk at AAAI</p>
<p>A solution to the hyper complex, cross domain reality of artificial intelligence: The hierarchy of AI. A Kear, S L Folkes, International Journal of Advanced Computer Science and Applications. 1132020</p>
<p>Socially emotional brain-inspired cognitive architecture framework for artificial intelligence. A V Samsonovich, Cognitive Systems Research. 602020</p>
<p>Deep reinforcement learning for autonomous internet of things: Model, applications and challenges. L Lei, Y Tan, K Zheng, S Liu, K Zhang, X Shen, 2020IEEE Communications Surveys &amp; Tutorialsin print</p>
<p>Deep reinforcement learning for multi agent systems: A review of challenges, solutions, and applications. T T Nguyen, N D Nguyen, S Nahavandi, IEEE Transactions on Cybernetics. 2020in print</p>
<p>P Hernandez-Leal, M Kaisers, T Baarslag, E M De Cote, arXiv:1707.09183A survey of learning in multi agent environments: Dealing with non-stationarity. 2017arXiv preprint</p>
<p>Multi-attention recurrent network for human communication comprehension. A Zadeh, P P Liang, S Poria, P Vij, E Cambria, L P Morency, Thirty-Second AAAI Conference on Artificial Intelligence. 2018</p>
<p>Semi-supervised classification using attention-based regularization on coarse-resolution data. G Nayak, R Ghosh, X Jia, V Mithafi, V Kumar, Proceedings of the 2020 SIAM International Conference on Data Mining. the 2020 SIAM International Conference on Data Mining2020</p>
<p>An attentive survey of attention models. S Chaudhari, G Polatkan, R Ramanath, V Mithal, arXiv:1904.028742019arXiv preprint</p>
<p>Attention, please! a critical review of neural attention models in natural language processing. A Galassi, M Lippi, P Torroni, arXiv:1902.021812019arXiv preprint</p>
<p>Understanding and improving deep learning-based rolling bearing fault diagnosis with attention mechanism. X Li, W Zhang, Q Ding, Signal Processing. 1612019</p>
<p>The structure of the relationship between attention and intelligence. K Schweizer, H Moosbrugger, F Goldhammer, Intelligence. 3362005</p>
<p>Toward distinguishing the different types of attention using EEG signals. L Pillette, A Cichocki, B N'kaoua, F Lotte, 2018</p>
<p>Emotionmeter: A multimodal framework for recognizing human emotions. W L Zheng, W Liu, Y Lu, B L Lu, A Cichocki, IEEE Transactions on Cybernetics. 4932018</p>
<p>Individual classification of emotions using EEG. S Valenzi, T Islam, P Jurica, A Cichocki, Journal of Biomedical Science and Engineering. 2014. 2014</p>
<p>The global landscape of AI ethics guidelines. A Jobin, M Lenca, E Vayena, Nature Machine Intelligence. 192019</p>
<p>Moral Intelligence: Enhancing Business Performance and Leadership Success. D Lennick, F Kiel, 2007Pearson Prentice Hall</p>
<p>Can artificial intelligences be moral agents?. B Broek, B Janik, New Ideas in Psychology. 542019</p>
<p>The Communication of Emotional Meaning. M Beldoch, J R Davitz, 1964McGraw-Hill</p>
<p>D Goleman, Emotional Intelligence. Bantam2006</p>
<p>R J Sternberg, R Kosti, Social Intelligence and Nonverbal Communication. Palgrave Macmillan2020</p>
<p>Social computing: From social informatics to social intelligence. F Y Wang, K M Carley, D Zeng, W Mao, IEEE Intelligent Systems. 2222007</p>
<p>Multiple intelligences, the Mozart effect, and emotional intelligence: A critical review. L Waterhouse, Educational Psychologist. 4142006</p>
<p>Zooming in on the attentional foundations of the Big Five. V Swift, K E Wilson, J B Peterson, Personality and Individual Differences. 1641100002020</p>
<p>Prefrontal cognitive ability, intelligence, Big Five personality, and the prediction of advanced academic and workplace performance. D M Higgins, J B Peterson, R O Pihl, A G Lee, Journal of Personality and Social Psychology. 9322982007</p>
<p>Beyond individual intelligence tests: Application of Cattell-Horn-Carroll Theory. J M Caemmerer, T Z Keith, M R Reynolds, Intelligence. 791014332020</p>
<p>Abandoning objectives: Evolution through the search for novelty alone. J Lehman, K O Stanley, Evolutionary Computation. 1922011</p>
<p>Open questions in creating safe open-ended AI: Tensions between control and creativity. A Ecoffet, J Clune, J Lehman, Artificial Life Conference Proceedings. Cambridge, MAMIT Press2020One Rogers Street</p>
<p>Creativity and artificial intelligence. M A Boden, Artificial Intelligence. 1031-21998</p>
<p>Building machines that learn and think like people. B M Lake, T D Ullman, J B Tenenbaum, S J Gershman, Behavioral and Brain Sciences. 402017</p>
<p>T Hospedales, A Antoniou, P Micaelli, A Storkey, arXiv:2004.05439Meta-learning in neural networks: A survey. 2020arXiv preprint</p>
<p>The machine with a human face: From artificial intelligence to artificial sentience. S Lavelle, International Conference on Advanced Information Systems Engineering. ChamSpringer2020. June</p>
<p>A deep learning framework for neuroscience. B A Richards, T P Lillicrap, P Beaudoin, Y Bengio, R Bogacz, A Christensen, C J Gillon, Nature Neuroscience. 22112019</p>
<p>Artificial Intelligence: Distinguishing between types &amp; definitions. R Martinez, Nevada Law Journal. 19392019</p>
<p>Why AI will never surpass human intelligence. B Y Bartholomew, Journal of Consciousness Exploration &amp; Research. 1132020</p>
<p>I Goodfellow, Y Bengio, A Courville, Deep Learning. CambridgeMIT Press20161</p>
<p>Block Hankel tensor ARIMA for multiple short time series forecasting. Q Shi, J Yin, J Cai, A Cichocki, T Yokota, L Chen, J Zeng, AAAI. 2020</p>
<p>T Yokota, H Hontani, Q Zhao, A Cichocki, arXiv:1908.02995Manifold modeling in embedded space: A perspective for interpreting Deep Image Prior. 2019arXiv preprint</p>
<p>Tensor decompositions for feature extraction and classification of high dimensional datasets. Nonlinear Theory and its Applications. A H Phan, A Cichocki, IEICE. 112010</p>
<p>The effects of audiovisual inputs on solving the cocktail party problem in the human brain: An fMRI study. Y Li, F Wang, Y Chen, A Cichocki, T Sejnowski, Cerebral Cortex. 28102018</p>
<p>Intuition, insight, imagination and creativity. W Duch, IEEE Computational Intelligence Magazine. 232007</p>
<p>Cognitive architectures: Where do we go from here?. W Duch, R J Oentaryo, M Pasquier, In Agi. 1712008, March</p>            </div>
        </div>

    </div>
</body>
</html>