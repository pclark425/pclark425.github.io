<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-9406 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-9406</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-9406</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-162.html">extraction-schema-162</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <p><strong>Paper ID:</strong> paper-471d97bf60adbdc0931c1cb278486dd9cd37fe51</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/471d97bf60adbdc0931c1cb278486dd9cd37fe51" target="_blank">Detecting Errors within a Corpus using Anomaly Detection</a></p>
                <p><strong>Paper Venue:</strong> Applied Natural Language Processing Conference</p>
                <p><strong>Paper TL;DR:</strong> This work presents a method for automatically detecting errors in a manually marked corpus using anomaly detection, and presents the results of applying this method to the tagged portion of the Penn Treebank corpus.</p>
                <p><strong>Cost:</strong> 0.008</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e9406.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e9406.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Sparse Markov Transducer</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Sparse Markov Transducer (variable-order conditional probabilistic transducer with wildcards)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A probabilistic, variable-order conditional model that estimates P(tag | context) using a weighted mixture of n-gram style conditional models (trigram, bigrams, unigrams) including wildcarded contexts and context-dependent weights, with pseudo-count smoothing and priors emphasizing the current word.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Sparse Markov Transducer</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>variable-order Markov transducer / conditional probabilistic transducer (not a neural transformer)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>categorical sequence records (token-level records: current tag, current word, previous tag, next tag)</td>
                        </tr>
                        <tr>
                            <td><strong>data_domain</strong></td>
                            <td>Part-of-speech tagged natural language text (Penn Treebank, Wall Street Journal articles)</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>annotation errors / outliers in tagged sequences (mistagged tokens)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Train a conditional probability model P_M over records using sparse Markov transducers (weighted mixture of context-dependent n-gram models including wildcarded contexts). Assume anomalies come from a uniform/alternate distribution P_A; compute log-likelihood under a mixture model D=(1-λ)M+λA. For each record, compute the log-likelihood difference if the record is moved from M to A; rank records by this score, iteratively remove declared anomalies and efficiently reestimate the model to find further anomalies. Suggested replacement tag = most likely tag under P_M for that context.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_methods</strong></td>
                            <td>Compared primarily to an alternative probability model used in the paper (Naive Bayes). Related methods mentioned in background: fixed-order Markov models, maximum entropy taggers, boosting for tagging (as related work) but not used as baselines in experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Human-evaluated corpus error rate among flagged anomalies (precision of anomalies), counts of anomalies detected, fraction of system-suggested corrections that match human-corrected tag (correction accuracy). Reported metrics: number of anomalies detected; corpus error rate (percentage of flagged anomalies judged to be true tagging errors) in ranked buckets.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>Sparse Markov transducer experiments detected 7,055 anomalies over the full Penn Treebank. Human evaluation (on ranked anomalies): among 400 sampled anomalies (100 from each 1000-ranked bucket within the first 4000), 158 judged corpus errors, 202 system errors, 40 unsure -> overall corpus error rate 44% (ignoring 'unsure'); top 1-1000 bucket had 69% corpus error rate; 1001-2000: 40%; 2001-3000: 20%; 3001-4000: 45%. Of the 158 corpus errors, in 145 cases the system's suggested tag would have corrected the error (≈91% correction accuracy if auto-applied).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td>Compared with the Naive Bayes probability model within the same anomaly-detection framework: the two modeling methods produced somewhat different anomaly sets but only slight differences; sparse Markov transducer produced more anomalies (7055) than Naive Bayes (6213). Human verification was performed only on sparse Markov transducer output, so quantitative superiority is not conclusively established in the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>The method depends critically on the quality of the normal-model P_M; fails to detect errors that do not present as low-likelihood under P_M (e.g., errors in infrequent contexts or inherently ambiguous contexts). Inconsistencies across annotators (systematic, non-rare annotation differences) will not be detected because they become part of the majority distribution. Sensitivity to chosen priors, smoothing (pseudo-counts), and which contextual features are used.</td>
                        </tr>
                        <tr>
                            <td><strong>unique_insights</strong></td>
                            <td>Variable-order, sparse-context conditional models that include wildcard contexts and priors emphasizing the current word provide a practical way to model contextual likelihoods for anomaly detection in tagged sequences; ranking by the likelihood-difference score yields much higher precision in top-ranked anomalies (e.g., 69% precision in top 1,000). Using the model's highest-likelihood tag suggestion can correct the majority of detected corpus errors (≈91% of judged errors had the system's suggested tag as the correct fix).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Detecting Errors within a Corpus using Anomaly Detection', 'publication_date_yy_mm': '2000-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9406.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e9406.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Naive Bayes (POS anomaly detection)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Naive Bayes conditional probability model for P(tag | word, prev_tag, next_tag)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A simple generative model estimating P(T_i | W_i, T_{i-1}, T_{i+1}) under the conditional independence (Naive Bayes) assumption: P(W|T) * P(T_{i-1}|T) * P(T_{i+1}|T) * P(T), normalized; used as P_M within the same mixture/anomaly-detection framework.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Naive Bayes (POS conditional model)</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>generative Naive Bayes classifier (conditional independence model)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>categorical sequence records (token-level: current word and neighboring tags)</td>
                        </tr>
                        <tr>
                            <td><strong>data_domain</strong></td>
                            <td>Part-of-speech tagged natural language text (Penn Treebank, Wall Street Journal)</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>annotation errors / outliers in tagged sequences (mistagged tokens)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Estimate P_M by computing P(T_i | W_i, T_{i-1}, T_{i+1}) via Naive Bayes: assume conditional independence so P(T|context) ∝ P(W|T) * P(T_{i-1}|T) * P(T_{i+1}|T) * P(T). Use this as the majority-model in the mixture D=(1-λ)M+λA, compute per-record log-likelihood-difference if moved to anomalous distribution P_A, rank records and iteratively remove anomalies.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_methods</strong></td>
                            <td>Compared primarily to the sparse Markov transducer model within the paper. Related prior work mentioned (maximum entropy tagger, Markov models, boosting) are cited but not used as experimental baselines.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Number of anomalies flagged; human-evaluated corpus error rate among flagged anomalies (precision).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>Naive Bayes experiments flagged 6,213 anomalies over the corpus. The paper reports that anomalies from Naive Bayes and sparse Markov transducer differed only slightly; human verification was focused on the sparse Markov transducer output, so no detailed human-evaluated precision numbers are reported specifically for Naive Bayes.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td>Naive Bayes produced a comparable but somewhat smaller set of anomalies (6,213) than the sparse Markov transducer (7,055); differences were reported as small, but no direct human-judged precision comparison is provided in the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>As with the general method: limited by lack of contextual modeling (naive independence assumptions reduce modeling power), leading to missed anomalies in contexts where dependencies matter; lower modeling fidelity can reduce anomaly-detection precision. Same high-level limitations: infrequent/ambiguous contexts, annotator inconsistencies, and sensitivity to model estimation choices.</td>
                        </tr>
                        <tr>
                            <td><strong>unique_insights</strong></td>
                            <td>A simple Naive Bayes conditional model can serve as a viable P_M within a likelihood-based anomaly detection framework for corpus cleaning, flagging thousands of candidate errors with performance broadly comparable to a more sophisticated sparse Markov transducer; this suggests that even relatively simple probabilistic models can be useful for semi-automatic corpus error detection.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Detecting Errors within a Corpus using Anomaly Detection', 'publication_date_yy_mm': '2000-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Anomaly detection over noisy data using learned probability distributions <em>(Rating: 2)</em></li>
                <li>Adaptive mixtures of probabilistic transducers <em>(Rating: 2)</em></li>
                <li>An efficient extension to mixture techniques for prediction and decision trees <em>(Rating: 2)</em></li>
                <li>Sequence matching and learning in anomaly detection for computer security <em>(Rating: 2)</em></li>
                <li>Detecting intrusions using system calls: alternative data models <em>(Rating: 1)</em></li>
                <li>Outliers in Statistical Data <em>(Rating: 1)</em></li>
                <li>A maximum entropy model part-of-speech tagger <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-9406",
    "paper_id": "paper-471d97bf60adbdc0931c1cb278486dd9cd37fe51",
    "extraction_schema_id": "extraction-schema-162",
    "extracted_data": [
        {
            "name_short": "Sparse Markov Transducer",
            "name_full": "Sparse Markov Transducer (variable-order conditional probabilistic transducer with wildcards)",
            "brief_description": "A probabilistic, variable-order conditional model that estimates P(tag | context) using a weighted mixture of n-gram style conditional models (trigram, bigrams, unigrams) including wildcarded contexts and context-dependent weights, with pseudo-count smoothing and priors emphasizing the current word.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "Sparse Markov Transducer",
            "model_type": "variable-order Markov transducer / conditional probabilistic transducer (not a neural transformer)",
            "model_size": null,
            "data_type": "categorical sequence records (token-level records: current tag, current word, previous tag, next tag)",
            "data_domain": "Part-of-speech tagged natural language text (Penn Treebank, Wall Street Journal articles)",
            "anomaly_type": "annotation errors / outliers in tagged sequences (mistagged tokens)",
            "method_description": "Train a conditional probability model P_M over records using sparse Markov transducers (weighted mixture of context-dependent n-gram models including wildcarded contexts). Assume anomalies come from a uniform/alternate distribution P_A; compute log-likelihood under a mixture model D=(1-λ)M+λA. For each record, compute the log-likelihood difference if the record is moved from M to A; rank records by this score, iteratively remove declared anomalies and efficiently reestimate the model to find further anomalies. Suggested replacement tag = most likely tag under P_M for that context.",
            "baseline_methods": "Compared primarily to an alternative probability model used in the paper (Naive Bayes). Related methods mentioned in background: fixed-order Markov models, maximum entropy taggers, boosting for tagging (as related work) but not used as baselines in experiments.",
            "performance_metrics": "Human-evaluated corpus error rate among flagged anomalies (precision of anomalies), counts of anomalies detected, fraction of system-suggested corrections that match human-corrected tag (correction accuracy). Reported metrics: number of anomalies detected; corpus error rate (percentage of flagged anomalies judged to be true tagging errors) in ranked buckets.",
            "performance_results": "Sparse Markov transducer experiments detected 7,055 anomalies over the full Penn Treebank. Human evaluation (on ranked anomalies): among 400 sampled anomalies (100 from each 1000-ranked bucket within the first 4000), 158 judged corpus errors, 202 system errors, 40 unsure -&gt; overall corpus error rate 44% (ignoring 'unsure'); top 1-1000 bucket had 69% corpus error rate; 1001-2000: 40%; 2001-3000: 20%; 3001-4000: 45%. Of the 158 corpus errors, in 145 cases the system's suggested tag would have corrected the error (≈91% correction accuracy if auto-applied).",
            "comparison_to_baseline": "Compared with the Naive Bayes probability model within the same anomaly-detection framework: the two modeling methods produced somewhat different anomaly sets but only slight differences; sparse Markov transducer produced more anomalies (7055) than Naive Bayes (6213). Human verification was performed only on sparse Markov transducer output, so quantitative superiority is not conclusively established in the paper.",
            "limitations_or_failure_cases": "The method depends critically on the quality of the normal-model P_M; fails to detect errors that do not present as low-likelihood under P_M (e.g., errors in infrequent contexts or inherently ambiguous contexts). Inconsistencies across annotators (systematic, non-rare annotation differences) will not be detected because they become part of the majority distribution. Sensitivity to chosen priors, smoothing (pseudo-counts), and which contextual features are used.",
            "unique_insights": "Variable-order, sparse-context conditional models that include wildcard contexts and priors emphasizing the current word provide a practical way to model contextual likelihoods for anomaly detection in tagged sequences; ranking by the likelihood-difference score yields much higher precision in top-ranked anomalies (e.g., 69% precision in top 1,000). Using the model's highest-likelihood tag suggestion can correct the majority of detected corpus errors (≈91% of judged errors had the system's suggested tag as the correct fix).",
            "uuid": "e9406.0",
            "source_info": {
                "paper_title": "Detecting Errors within a Corpus using Anomaly Detection",
                "publication_date_yy_mm": "2000-04"
            }
        },
        {
            "name_short": "Naive Bayes (POS anomaly detection)",
            "name_full": "Naive Bayes conditional probability model for P(tag | word, prev_tag, next_tag)",
            "brief_description": "A simple generative model estimating P(T_i | W_i, T_{i-1}, T_{i+1}) under the conditional independence (Naive Bayes) assumption: P(W|T) * P(T_{i-1}|T) * P(T_{i+1}|T) * P(T), normalized; used as P_M within the same mixture/anomaly-detection framework.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "Naive Bayes (POS conditional model)",
            "model_type": "generative Naive Bayes classifier (conditional independence model)",
            "model_size": null,
            "data_type": "categorical sequence records (token-level: current word and neighboring tags)",
            "data_domain": "Part-of-speech tagged natural language text (Penn Treebank, Wall Street Journal)",
            "anomaly_type": "annotation errors / outliers in tagged sequences (mistagged tokens)",
            "method_description": "Estimate P_M by computing P(T_i | W_i, T_{i-1}, T_{i+1}) via Naive Bayes: assume conditional independence so P(T|context) ∝ P(W|T) * P(T_{i-1}|T) * P(T_{i+1}|T) * P(T). Use this as the majority-model in the mixture D=(1-λ)M+λA, compute per-record log-likelihood-difference if moved to anomalous distribution P_A, rank records and iteratively remove anomalies.",
            "baseline_methods": "Compared primarily to the sparse Markov transducer model within the paper. Related prior work mentioned (maximum entropy tagger, Markov models, boosting) are cited but not used as experimental baselines.",
            "performance_metrics": "Number of anomalies flagged; human-evaluated corpus error rate among flagged anomalies (precision).",
            "performance_results": "Naive Bayes experiments flagged 6,213 anomalies over the corpus. The paper reports that anomalies from Naive Bayes and sparse Markov transducer differed only slightly; human verification was focused on the sparse Markov transducer output, so no detailed human-evaluated precision numbers are reported specifically for Naive Bayes.",
            "comparison_to_baseline": "Naive Bayes produced a comparable but somewhat smaller set of anomalies (6,213) than the sparse Markov transducer (7,055); differences were reported as small, but no direct human-judged precision comparison is provided in the paper.",
            "limitations_or_failure_cases": "As with the general method: limited by lack of contextual modeling (naive independence assumptions reduce modeling power), leading to missed anomalies in contexts where dependencies matter; lower modeling fidelity can reduce anomaly-detection precision. Same high-level limitations: infrequent/ambiguous contexts, annotator inconsistencies, and sensitivity to model estimation choices.",
            "unique_insights": "A simple Naive Bayes conditional model can serve as a viable P_M within a likelihood-based anomaly detection framework for corpus cleaning, flagging thousands of candidate errors with performance broadly comparable to a more sophisticated sparse Markov transducer; this suggests that even relatively simple probabilistic models can be useful for semi-automatic corpus error detection.",
            "uuid": "e9406.1",
            "source_info": {
                "paper_title": "Detecting Errors within a Corpus using Anomaly Detection",
                "publication_date_yy_mm": "2000-04"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Anomaly detection over noisy data using learned probability distributions",
            "rating": 2
        },
        {
            "paper_title": "Adaptive mixtures of probabilistic transducers",
            "rating": 2
        },
        {
            "paper_title": "An efficient extension to mixture techniques for prediction and decision trees",
            "rating": 2
        },
        {
            "paper_title": "Sequence matching and learning in anomaly detection for computer security",
            "rating": 2
        },
        {
            "paper_title": "Detecting intrusions using system calls: alternative data models",
            "rating": 1
        },
        {
            "paper_title": "Outliers in Statistical Data",
            "rating": 1
        },
        {
            "paper_title": "A maximum entropy model part-of-speech tagger",
            "rating": 1
        }
    ],
    "cost": 0.00823925,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>Detecting Errors within a Corpus using Anomaly Detection</h1>
<p>Eleazar Eskin<br>Department of Computer Science<br>Columbia University<br>eeskin@cs.columbia.edu</p>
<h4>Abstract</h4>
<p>We present a method for automatically detecting errors in a manually marked corpus using anomaly detection. Anomaly detection is a method for determining which elements of a large data set do not conform to the whole. This method fits a probability distribution over the data and applies a statistical test to detect anomalous elements. In the corpus error detection problem, anomalous elements are typically marking errors. We present the results of applying this method to the tagged portion of the Penn Treebank corpus.</p>
<h2>1 Introduction</h2>
<p>Manually marking corpora is a time consuming and expensive process. The process is subject to human error by the experts doing the marking. Unfortunately, many natural language processing methods are sensitive to these errors. In order to ensure accuracy in a corpus, typically several experts pass over the corpus to ensure consistency. For large corpora this can be a tremendous expense.</p>
<p>In this paper, we propose a method for automatically detecting errors in a marked corpus using an anomaly detection technique. This technique detects anomalies or elements which do not fit in with the rest of the corpus. When applied to marked corpora, the anomalies tend to be errors in the markings of the corpus.</p>
<p>To detect the anomalies, we first compute a probability distribution over the entire corpus. Then we apply a statistical test which identifies which elements are anomalies. In this case the anomalies are the elements with very low likelihood. These elements are marked as errors and are thrown out of the corpus. The model is recomputed on the remaining elements. At conclusion, we are left with two data sets: one the
normal elements and the second the detected anomalous elements.</p>
<p>We evaluate this method over the part of speech tagged portion of the Penn Treebank corpus (Marcus et al., 1993). In one experiment, our method detected 1000 anomalies within a data set of 1.25 million tagged elements. Human judges evaluated the results of the application of this method and verified that $69 \%$ of identified anomalies are in fact tagging errors. In another experiment, our method detected 4000 anomalies of which $44 \%$ are tagging errors.</p>
<h3>1.1 Related Work</h3>
<p>The tagged portion of the Penn Treebank has been extensively utilized for construction and evaluation of taggers. This includes transformation-based tagging (Brill, 1994; Brill and Wu, 1998). Weischedel et al. (1993) applied Markov Models to tagging. Abney et al. (1999) applied boosting to part of speech tagging. Adwait Ratnaparkhi (1996) estimates a probability distribution for tagging using a maximum entropy approach.</p>
<p>Regarding error detection in corpora, Ratnaparkhi (1996) discusses inconsistencies in the Penn Treebank and relates them to interannotator differences in tagging style. Abney, Schapire and Singer (1999) discuss how to use boosting for cleaning data.</p>
<p>Much related work to the anomaly detection problem stems from the field of statistics in the study of outliers. This work examines detecting and dealing with outliers in univariate data, multivariate data, and structured data where the probability distribution over the data is given a priori. Statistics gives a set of discordancy tests which can be applied to any given element in the dataset to determine whether it is an outlier. A survey of outliers in statistics is</p>
<p>given in Barnett and Lewis (1994).
Anomaly detection is extensively used within the field of computer security specifically in intrusion detection (Denning, 1987). Typically anomaly detection methods are applied to detect attacks by comparing the activity during an attack to the activity under normal use (Lane and Brodley, 1997; Warrender et al., 1999). The method used in this paper is based on a method for anomaly detection which detects anomalies in noisy data (Eskin, 2000).</p>
<p>The sparse Markov transducer probability modeling method is an extension of adaptive mixtures of probabilistic transducers (Singer, 1997; Pereira and Singer, 1999). Naive Bayes learning, which is used to estimate probabilities in this paper, is described in (Mitchell, 1997).</p>
<h2>2 Anomaly Detection</h2>
<p>More formally, anomaly detection is the process of determining when an element of data is an outlier. Given a set of training data without a probability distribution, we want to construct an automatic method for detecting anomalies. We are interested in detecting anomalies for two main reasons. One, we are interested in modeling the data and the anomalies can contaminate the model. And two, the anomalies themselves can be of interest as they may show rarely occurring events. For the purposes of this work, we are most interested in identifying mistagged elements, i.e. the second case.</p>
<p>In order to motivate a method for detecting anomalies, we must first make assumptions about how the anomalies occur in the data. We use a "mixture model" for explaining the presence of anomalies, one of several popular models in statistics for explaining outliers (Barnett and Lewis, 1994). In the mixture model, there are two probability distributions which generate the data. An element $x_{i}$ is either generated from the majority distribution or with (small) probability $\lambda$ from an alternate (anomalous) distribution. Our distribution for the data, $\mathbf{D}$, is then:</p>
<p>$$
\mathbf{D}=(1-\lambda) \mathbf{M}+\lambda \mathbf{A}
$$</p>
<p>where $\mathbf{M}$ is the majority distribution, and $\mathbf{A}$ is the anomalous distribution. The mixture framework for explaining anomalies is independent of the properties of the distributions $\mathbf{M}$ and $\mathbf{A}$. In other words, no assumptions about
the nature of the probability distributions are necessary. The specific probability distributions, $\mathbf{M}$ and $\mathbf{A}$, are chosen based on prior knowledge of the problem. Typically $\mathbf{M}$ is a structured distribution which is estimated over the data using a machine learning technique, while $\mathbf{A}$ is a uniform (random) distribution representing elements which do not fit into $\mathbf{M}$.</p>
<p>In the corpus error detection problem, we are assuming that for each tag in the corpus with probability $(1-\lambda)$ the human annotator markes the corpus with the correct tag and with probability $\lambda$ the human annotator makes an error. In the case of an error, we assume that the tag is chosen at random.</p>
<h3>2.1 Detection of Anomalies</h3>
<p>Detecting anomalies, in this framework, is equivalent to determining which elements were generated by the distribution $\mathbf{A}$ and which elements were generated by distribution M. Elements generated by $\mathbf{A}$ are anomalies, while elements generated by $\mathbf{M}$ are not. In our case, we have probability distributions associated with the distributions $\mathbf{M}$ and $\mathbf{A}, P_{M}$ and $P_{A}$ respectively.</p>
<p>The algorithm partitions the data into two sets, the normal elements $M$ and the anomalies $A$. For each element, we make a determination of whether it is an anomaly and should be included in $A$ or a majority element in which it should be included in $M$. We measure the likelihood of the distribution under both cases to make this determination.</p>
<p>The likelihood, $L$, of distribution $\mathbf{D}$ with probability function $P$ over elements $x_{1}, \ldots, x_{N}$ is defined as follows:
$L(\mathbf{D})=\prod_{i=1}^{N} P_{D}\left(x_{i}\right)=$
$\left((1-\lambda)^{|M|} \prod_{x_{i} \in M} P_{M}\left(x_{i}\right)\right)\left(\lambda^{|A|} \prod_{x_{j} \in A} P_{A}\left(x_{j}\right)\right)$
Since the product of small numbers is difficult to compute, we instead compute the log likelihood, $L L$. The log likelihood for our case is:</p>
<p>$$
\begin{aligned}
L L(\mathbf{D})=|M| &amp; \log (1-\lambda)+\sum_{x_{i} \in M} \log \left(P_{M}\left(x_{i}\right)\right) \
&amp; +|A| \log \lambda+\sum_{x_{j} \in A} \log \left(P_{A}\left(x_{j}\right)\right)
\end{aligned}
$$</p>
<p>In order to determine which elements are anomalies, we use a general principal for determining outliers in multivariate data (Barnett, 1979). We measure how likely each element $x_{i}$ is an outlier by comparing the difference between the log likelihood of the distribution if the element is removed from the majority distribution and included in the anomalous distribution. If this difference is sufficiently large, we declare the element an anomaly.</p>
<p>Specifically what this difference should be depends on the probability distributions and prior knowledge of the problem such as the rate of the anomalies, $\lambda$.</p>
<h2>3 Methodology</h2>
<h3>3.1 Corpus</h3>
<p>The corpus we use is the Penn Treebank tagged corpus. The corpus contains approximately 1.25 million manually tagged words from Wall Street Journal articles. For each word, a record is generated containing the following elements:</p>
<ol>
<li>The tag of the current word $T_{i}$.</li>
<li>The current word $W_{i}$.</li>
<li>The previous tag $T_{i-1}$.</li>
<li>The next tag $T_{i+1}$.</li>
</ol>
<p>Over records containing these 4 elements, we compute our probability distributions.</p>
<h3>3.2 Probability Modeling Methods</h3>
<p>The anomaly detection framework is independent of specific probability distributions. Different probability distributions have different properties. Since the anomaly detection framework does not depend on a specific probability distribution, we can choose the probability distribution to best model the data based on our intuitions about the problem.</p>
<p>To illustrate this, we perform two sets of experiments, each using a different probability distribution modeling method. The first set of experiments uses sparse Markov transducers as the probability modeling method, while the second uses a simple naive Bayes method.</p>
<h3>3.3 Sparse Markov Transducers</h3>
<p>Sparse Markov transducers compute probabilistic mappings over sparse data. A Markov transducer is defined to be a probability distribution
conditional on a finite set of inputs. A Markov transducer of order $L$ is the conditional probability distribution of the form:</p>
<p>$$
P\left(Y_{i} \mid X_{t} X_{t-1} X_{t-2} X_{t-3} \ldots X_{t-(L-1)}\right)
$$</p>
<p>where $X_{k}$ are random variables over the input alphabet $\Sigma_{\text {in }}$ and $Y_{k}$ is a random variable over the output alphabet $\Sigma_{\text {out }}$. This probability distribution stochastically defines a mapping of strings over the input alphabet into the output alphabet. The mapping is conditional on the $L$ previous input symbols.</p>
<p>In the case of sparse data, the probability distribution is conditioned on only some of the inputs. We use sparse Markov transducers to model these type of distributions. A sparse Markov transducer is a conditional probability of the form:</p>
<p>$$
P\left(Y_{i} \mid \phi^{n_{1}} X_{t_{1}} \phi^{n_{2}} X_{t_{2}} \ldots \phi^{n_{k}} X_{t_{k}}\right)
$$</p>
<p>where $\phi$ represents a wild card symbol and $t_{i}=t-\sum_{j=1}^{i} n_{j}-(i-1)$. The goal of the sparse Markov transducer estimation algorithm is to estimate a conditional probability of this form based upon a set of inputs and their corresponding outputs. However, the task is complicated due to the lack of knowledge a priori of which inputs the probability distribution is conditional on.</p>
<p>Intuitively, a fixed order Markov Chain of order $L$ is equivalent to a $n$-gram with $n=L$. In a variable order Markov Chain, the value of $n$ changes depending on the context. For example, some elements in the data may use a bigram, while others may use a trigram. The sparse Markov transducer uses a weighted sum of $n$-grams for different values of $n$ and these weights depend on the context. In addition the weighted sum is over not only $n$-grams, but also $n$-grams with wild cards such as a trigram where only the first and last element is conditioned on.</p>
<p>In this case we are looking at the input sequence of the current word, $W_{t}$, the previous tag, $T_{t-1}$, and the next tag, $T_{t+1}$. The output is the set of all possible tags. The models that are in the weighted sum are the trigram, $W_{t} T_{t-1} T_{t+1}$; the bigrams $W_{t} T_{t-1}, W_{t} T_{t+1}$ and $T_{t-1} T_{t+1}$; and the unigrams $W_{t}, T_{t-1}$ and $T_{t+1}$. The specific weights of each model depends on the context or the actual values of $W_{t}, T_{t-1}$, and $T_{t+1}$.</p>
<p>Sparse Markov transducers depend on a set of prior probabilities that incorporate prior knowledge about the importance of various elements in the input sequence. These prior probabilities are set based on the problem. For this problem, we use the priors to encode the information that the current word, $W_{t}$, is very important in determining the part of speech.</p>
<p>Each model in the weighted sum uses a pseudo-count predictor. This predictor computes the probability of an output (tag) by the number of times that a specific output was seen in a given context. In order to avoid probabilities of 0 , we assume that we have seen each output at least once in every context. In fact, these predictors can be any probability distribution which can also depend on what works best for the task.</p>
<h3>3.4 Naive Bayes</h3>
<p>The probability distribution for the tags was also estimated using a straight forward naive Bayes approach.</p>
<p>We are interested in the probability of a tag, given the current word, the previous tag, and the next tag, or the probability distribution $P\left(T_{i} \mid W_{i}, T_{i-1}, T_{i+1}\right)$ which using Bayes Rule is equivalent to:</p>
<p>$$
\begin{aligned}
&amp; P\left(T_{i} \mid W_{i}, T_{i-1}, T_{i+1}\right)= \
&amp; \frac{P\left(W_{i}, T_{i-1}, T_{i+1} \mid T_{i}\right) * P\left(T_{i}\right)}{P\left(W_{i}, T_{i-1}, T_{i+1}\right)}
\end{aligned}
$$</p>
<p>If we make the Naive Bayes independence assumption and we assume that the denominator is constant for all values this reduces to:</p>
<p>$$
\begin{aligned}
&amp; P\left(T_{i} \mid W_{i}, T_{i-1}, T_{i+1}\right)= \
&amp; \frac{P\left(W_{i} \mid T_{i}\right) * P\left(T_{i-1} \mid T_{i}\right) * P\left(T_{i+1} \mid T_{i}\right) * P\left(T_{i}\right)}{C}
\end{aligned}
$$</p>
<p>where $C$ is a normalization constant in order to have the probabilities sum to 1 . Each of the values on the right side of the equation can easily be computed over the data estimating a probability distribution.</p>
<h3>3.5 Computing Probability Distributions</h3>
<p>Each probability distribution was trained over each record giving a model over the entire data. The probability model is then used to determine whether or not an element is an anomaly
by applying the test in equation (3). Typically this can be done in an efficient manner because the approach does not require reestimating the model over the entire data set. If an element is designated as an anomaly, we remove it from the set of normal elements and efficiently reestimate the probability distribution to obtain more anomalous elements.</p>
<h2>4 Results/Evaluation</h2>
<p>The method was applied to the Penn Treebank corpus and a set of anomalies were generated. These anomalies were evaluated by human judges to determine if they are in fact tagging errors in the corpus. The human judges were natural language processing researchers (not the author) familiar with the Penn Treebank markings.</p>
<p>In the experiments involving the sparse Markov transducers, after applying the method, 7055 anomalies were detected. In the experiments involving the naive Bayes learning method, 6213 anomalies were detected.</p>
<p>Sample output from the system is shown in figure 1. The error is shown in the context marked with !!!. The likelihood of the tag is also given which is extremely low for the errors. The system also outputs a suggested tag and its likelihood which is the tag with the highest likelihood for that context. As we can see, these errors are clearly annotation errors.</p>
<p>Since the anomalies detected from the two probability modeling methods differed only slightly, we performed human judge verification of the errors over only the results of the sparse Markov transducer experiments.</p>
<p>The anomalies were ordered based on their likelihood. Using this ranking, the set of anomalies were broken up into sets of 1000 records. We examined the first 4000 elements by randomly selecting 100 elements out of each 1000 .</p>
<p>Human judges were presented with the system output for four sets of 100 anomalies. The judges were asked to choose among three options for each example:</p>
<ol>
<li>Corpus Error - The tag in the corpus sentence is incorrect.</li>
<li>Unsure - The judge is unsure whether or not the corpus tag is correct.</li>
</ol>
<p>Error 0.000035: Its/PRP\$ fast-food/NN restaurants/NNS -/: including/VBG Denny/NNP 's/POS ,/, Hardee/NNP 's/POS ,/, Quincy/NNP 's/POS and/CC El/NNP Pollo/NNP Loco/NNP (// "/" !!!the/NN!!! only/JJ significant/JJ fast-food/NN chain/NN to/TO specialize/VB in/IN char-broiled/JJ chicken/NN "/" )/) -/: are/VBP stable/JJ ,/, recession-resistant/JJ and/CC growing/VBG ./. Suggested Tag: DT ( 0.998262 )</p>
<p>Error 0.019231: Not/RB even/RB Jack/NNP Lemmon/NNP 's/POS expert/JJ doddering/JJ !!!makes/NNS!!! this/DT trip/NN worth/NN taking/VBG ./. Suggested Tag: VBZ ( 0.724359 )</p>
<p>Error 0.014286: It/PRP also/RB underscores/VBZ the/DT difficult/JJ task/NN ahead/RB as/IN !!!Coors/NNS!!! attempts/VBZ to/TO purchase/VB Stroh/NNP Brewery/NNP Co./NNP and/CC fight/VB off/RP increasingly/RB tough/JJ competition/NN from/IN Anheuser-Busch/NNP Cos/NNP ./. Suggested Tag: NNP ( 0.414286 )</p>
<p>Figure 1: Sample output of anomalies in Penn Treebank corpus. The errors are marked with !!!.
3. System Error - The tag in the corpus sentence is correct and the system incorrectly marked it as an error.</p>
<p>The "unsure" choice was allowed because of the inherent subtleties in differentiating between types of tags such as "VB vs. VBP" or "VBD vs. VBN".</p>
<p>Over the 400 examples evaluated, 158 were corpus errors, 202 were system errors and the judges were unsure in 40 of the cases. The corpus error rate was computed by throwing out the unsure cases and computing:</p>
<p>$$
\begin{aligned}
&amp; \text { Corpus error rate }= \
&amp; \frac{\text { Corpus Errors }}{\text { System Errors }+ \text { Corpus Errors }}
\end{aligned}
$$</p>
<p>The total corpus error rate over the 400 manually checked examples was was $44 \%$. As can be seen, many of the anomalies are in fact errors in the corpus.</p>
<p>For each error, we asked the human judge to determine if the correct tag is the systems suggested tag. Out of the total 158 corpus errors, the systems correct tag would have corrected the error in 145 cases.</p>
<p>Since the verified examples were random, we can assume that $91 \%$ of corpus errors would be automatically corrected if the system would replace the suspect tag with the suggested tag. Ignoring the "unsure" elements for the purposes
of this analysis, if we attempted to automatically correct the first 1000 examples where the error rate was $69 \%$, this method would have led to a reduction of the total number of errors in the corpus by 245 .</p>
<h2>5 Conclusion</h2>
<p>This paper presents a fully automatic method for detecting errors in corpora using anomaly detection techniques. As shown, the anomalies detected in the Penn Treebank corpus tend to be tagging errors.</p>
<p>This method has some inherent limitations because not all errors in the corpus would manifest themselves as anomalies. In infrequent contexts or ambiguous situations, the method may not have enough information to detect an error. In addition, if there are inconsistencies between annotators, the method would not detect the errors because the errors would be manifested over a significant portion of the corpus.</p>
<p>Although this paper presents a fully automatic method for error detection in corpora, this method can also be used as a semiautomatic method for correcting errors. The method can guide an annotator to the elements which are most likely errors. The method can greatly reduce the number of elements that an annotator needs to examine.</p>
<p>Future work in this area involves modeling the corpora with other probability distributions.</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Anomaly Rank</th>
<th style="text-align: center;">Corpus Errors</th>
<th style="text-align: center;">System Error</th>
<th style="text-align: center;">Unsure</th>
<th style="text-align: center;">Corpus Error Rate</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">$1-1000$</td>
<td style="text-align: center;">63</td>
<td style="text-align: center;">28</td>
<td style="text-align: center;">9</td>
<td style="text-align: center;">$69 \%$</td>
</tr>
<tr>
<td style="text-align: center;">$1001-2000$</td>
<td style="text-align: center;">36</td>
<td style="text-align: center;">54</td>
<td style="text-align: center;">10</td>
<td style="text-align: center;">$40 \%$</td>
</tr>
<tr>
<td style="text-align: center;">$2001-3000$</td>
<td style="text-align: center;">18</td>
<td style="text-align: center;">70</td>
<td style="text-align: center;">12</td>
<td style="text-align: center;">$20 \%$</td>
</tr>
<tr>
<td style="text-align: center;">$3001-4000$</td>
<td style="text-align: center;">41</td>
<td style="text-align: center;">50</td>
<td style="text-align: center;">9</td>
<td style="text-align: center;">$45 \%$</td>
</tr>
<tr>
<td style="text-align: center;">Totals</td>
<td style="text-align: center;">158</td>
<td style="text-align: center;">202</td>
<td style="text-align: center;">40</td>
<td style="text-align: center;">$44 \%$</td>
</tr>
</tbody>
</table>
<p>Table 1: Results of error detection experiments on the tagged portion of the Penn Treebank</p>
<p>The method is very sensitive to the effectiveness of the probability model in modeling the normal elements. Extensions to the probability distributions presented here such as adding information about endings of words or using more features could increase the accuracy of the probability distribution and the overall performance of the anomaly detection system. Other future work involves applying this method to other marked corpora.</p>
<h2>References</h2>
<p>Steve Abney, Robert E. Schapire, and Yoram Singer. 1999. Boosting applied to tagging and PP attachment. In Proceedings of the Joint SIGDAT Conference on Empirical Methods in Natural Language Processing Conference and Very Large Corpora.
V. Barnett and T. Lewis. 1994. Outliers in Statistical Data. John Wiley and Sons.
V. Barnett. 1979. Some outlier tests for multivariate samples. South African Statist, 13:2952.</p>
<p>Eric Brill and Jun Wu. 1998. Classifier combination for improved lexical disambiguation. In Proceedings of COLING-ACL.
Eric Brill. 1994. Some advances in transformation-based part of speech tagging. In Proceedings of the Twelfth National Conference on Artificial Intelligence, pages 722-727.
D.E. Denning. 1987. An intrusion detection model. IEEE Transactions on Software Engineering, SE-13:222-232.
Eleazar Eskin. 2000. Anomaly detection over noisy data using learned probability distributions. In Proceedings of the Seventeenth International Conference on Machine Learning (ICML-2000) (to appear).
T. Lane and C. E. Brodley. 1997. Sequence matching and learning in anomaly detection
for computer security. In AAAI Workshop: AI Approaches to Fraud Detection and Risk Management, pages 43-49. AAAI Press.
Mitchell Marcus, Beatrice Santorini, and Mary Ann Marcinkiewicz. 1993. Building a large annotated corpus of english: The Penn Treebank. Computational Linguistics, 19(2):313-330.
Tom Mitchell. 1997. Machine Learning. McGraw Hill.
Fernando Pereira and Yoram Singer. 1999. An efficient extension to mixture techniques for prediction and decision trees. Machine Learning, 36(3):183-199.
Adwait Ratnaparkhi. 1996. A maximum entropy model part-of-speech tagger. In Proceedings of the Empirical Methods in Natural Language Processing Conference.
Yoram Singer. 1997. Adaptive mixtures of probalistic transducers. Neural Computation, 9(8):1711-1733.
Christina Warrender, Stephanie Forrest, and Barak Pearlmutter. 1999. Detecting intrusions using system calls: alternative data models. In 1999 IEEE Symposium on Security and Privacy, pages 133-145. IEEE Computer Society.
Ralph Weischedel, Marie Meteer, Richard Schwartz, Lance Ramshaw, and Jeff Palmucci. 1993. Coping with ambiguity and unknown words through probabilistic models. Computational Linguistics, 19(2):359-382.</p>            </div>
        </div>

    </div>
</body>
</html>