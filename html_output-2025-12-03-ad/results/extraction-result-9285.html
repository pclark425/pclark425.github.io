<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-9285 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-9285</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-9285</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-162.html">extraction-schema-162</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <p><strong>Paper ID:</strong> paper-267320333</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2401.17052v2.pdf" target="_blank">Retrieval Augmented Deep Anomaly Detection for Tabular Data</a></p>
                <p><strong>Paper Abstract:</strong> Deep learning for tabular data has garnered increasing attention in recent years, yet employing deep models for structured data remains challenging. While these models excel with unstructured data, their efficacy with structured data has been limited. Recent research has introduced retrieval-augmented models to address this gap, demonstrating promising results in supervised tasks such as classification and regression. In this work, we investigate using retrieval-augmented models for anomaly detection on tabular data. We propose a reconstruction-based approach in which a transformer model learns to reconstruct masked features ofnormal samples. We test the effectiveness of KNN-based and attention-based modules to select relevant samples to help in the reconstruction process of the target sample. Our experiments on a benchmark of 31 tabular datasets reveal that augmenting this reconstruction-based anomaly detection (AD) method with sample-sample dependencies via retrieval modules significantly boosts performance. The present work supports the idea that retrieval module are useful to augment any deep AD method to enhance anomaly detection on tabular data. Our code to reproduce the experiments is made available on GitHub.</p>
                <p><strong>Cost:</strong> 0.019</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e9285.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e9285.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Transformer (vanilla)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Mask-reconstruction Transformer for Tabular Anomaly Detection</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A transformer encoder trained in a mask-reconstruction (feature-masking) objective on normal-only tabular data; attends only to feature-feature dependencies and produces anomaly scores from reconstruction error.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Transformer (custom small transformer)</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>transformer encoder (self-attention)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>hidden_dim ∈ {8,16,32}; 2 or 4 encoder layers; 4 attention heads (dataset-dependent)</td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>tabular data (mixed numerical and categorical features; per-feature embeddings)</td>
                        </tr>
                        <tr>
                            <td><strong>data_domain</strong></td>
                            <td>benchmark of 31 tabular datasets (ODDS multidimensional point datasets, Arrhythmia, Thyroid, fraud, campaign, backdoor) and a synthetic 3D dataset</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>general outliers including dependency anomalies, global anomalies, local anomalies, clustered/group anomalies</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Reconstruction-based anomaly detection: randomly mask features during training and train transformer to predict masked features from unmasked ones; anomaly score is average reconstruction error over a deterministic mask bank at inference.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_methods</strong></td>
                            <td>Compared against non-deep methods (Isolation Forest, KNN, RRCF, COPOD, PIDForest) and deep/self-supervised AD methods (GOAD, DROCC, NeuTraL-AD, contrastive [30], NPT-AD, Mask-KNN).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>F1-score, AUROC (reported as mean across datasets and per-dataset splits)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>Average F1-score = 56.2; Average AUROC = 83.4 (reported in Table 1). Per-dataset metrics reported in Tables 8/9.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td>Serves as main parametric baseline; retrieval-augmented variants (notably attention-bsim) significantly outperform this vanilla transformer on average (F1 and AUROC gains reported). Performance relative to classical baselines varies by dataset.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Because it only models feature-feature dependencies, it struggles to detect anomalies that are local relative to the sample neighborhood (local anomalies/type 1 in synthetic test). Performance depends on mask design; no sample-sample information leads to blind spots for some anomaly types.</td>
                        </tr>
                        <tr>
                            <td><strong>unique_insights</strong></td>
                            <td>Transformer-only mask reconstruction reliably detects anomalies that violate learned inter-feature relations (dependency anomalies) but fails on anomalies that require sample-sample context; combining sample-sample retrieval with feature modeling is necessary for consistent performance across anomaly types.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Retrieval Augmented Deep Anomaly Detection for Tabular Data', 'publication_date_yy_mm': '2024-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9285.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e9285.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Transformer + attention-bsim</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Transformer with attention-bsim external retrieval module</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A retrieval-augmented transformer that, after encoding, retrieves helper samples using a distance-based attention score (L2 between W_K-transformed embeddings) and aggregates helper representations to improve masked-feature reconstruction and anomaly detection.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Transformer + attention-bsim retrieval module</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>transformer encoder + attention-based external retrieval (distance-based attention)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>hidden_dim ∈ {8,16,32}; 2 or 4 encoder layers; 4 attention heads (same transformer backbone as vanilla)</td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>tabular data (mixed numerical and categorical features)</td>
                        </tr>
                        <tr>
                            <td><strong>data_domain</strong></td>
                            <td>same 31-tabular-dataset benchmark and synthetic 3D experiment</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>improves detection for local anomalies (sample-sample dependent) and dependency anomalies (feature-feature), i.e., both local and dependency anomaly types</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Post-encoder retrieval: flatten encoder outputs; compute S(z,x) = -||W_K(h_z) - W_K(h_x)||^2 to select helpers H (or use full C with attention weights); value V(z,x) = W_V(h_x); aggregate helpers into sample embedding hz <- (1-λ)hz + λ * (1/k) Σ V(z,x); train on mask-reconstruction objective; anomaly score is average reconstruction error across deterministic mask bank.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_methods</strong></td>
                            <td>Compared to vanilla transformer, Transformer+KNN, Transformer+v-attention, Transformer+att-bsim-bval, Mask-KNN, and classical baselines listed above.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>F1-score, AUROC; per-dataset and average reported.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>Average F1-score = 58.6 (vs vanilla 56.2), Average AUROC = 84.4 (vs vanilla 83.4). On the synthetic 3D experiment (Table 3): Normal detection 94.6% (±0.5), Type-1 anomalies 88.0% (±0.8), Type-2 anomalies 100.0% (±0.0). Best-performing retrieval variant in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td>Significantly outperforms the vanilla transformer on average (reported +4.3% relative F1 improvement) and is the best retrieval-augmented variant tested; outperforms KNN- and vanilla-attention retrieval in these reconstruction-based AD experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Non-parametric retrieval increases memory and inference complexity (scales with training set when helpers = C); performance sensitive to hyperparameters k (number of helpers) and λ (aggregation weight); some datasets require tuning (optimal k often moderate 25–50); not all retrieval modules help and attention-bsim-bval performed worse here; placement of retrieval matters (post-encoder best).</td>
                        </tr>
                        <tr>
                            <td><strong>unique_insights</strong></td>
                            <td>Combining sample-sample retrieval (attention-bsim) with feature-feature transformer representations enables detection of both local and dependency anomalies; deterministic mask bank at inference is better than random in most cases; moderate helper counts and post-encoder retrieval location yield best results.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Retrieval Augmented Deep Anomaly Detection for Tabular Data', 'publication_date_yy_mm': '2024-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9285.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e9285.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Transformer + KNN</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Transformer augmented with KNN-based external retrieval</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Retrieval-augmented transformer using a simple k-nearest-neighbors selection in embedding space (L2 distance) where retrieved helper values are the helper embeddings themselves and are aggregated into the target embedding.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Transformer + KNN retrieval module</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>transformer encoder + KNN (non-parametric) retrieval</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>hidden_dim ∈ {8,16,32}; 2 or 4 layers; 4 attention heads</td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>tabular data (mixed numerical/categorical)</td>
                        </tr>
                        <tr>
                            <td><strong>data_domain</strong></td>
                            <td>31-tabular-dataset benchmark and synthetic test</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>helps detect anomalies that require sample-sample context (local anomalies)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Post-encoder: compute S(z,x) = -||h_z - h_x||; select top-k nearest helpers; V(z,x) = h_x; aggregate helpers into target via hz <- (1-λ)hz + λ*(1/k)Σ h_x; train with mask-reconstruction objective.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_methods</strong></td>
                            <td>Compared to vanilla transformer and attention-based retrieval modules; also conceptually related to Mask-KNN baseline.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>F1-score, AUROC</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>Average F1-score ≈ 56.1, AUROC ≈ 83.1 (Table 1). Performance similar to vanilla transformer on average; benefits vary by dataset.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td>Did not provide consistent improvement over vanilla transformer across the benchmark and was outperformed by attention-bsim.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Choice of k affects results; simple L2-based nearest neighbors may be insufficient compared to learned attention scoring; limited by capacity to incorporate feature-feature interactions beyond embeddings.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Retrieval Augmented Deep Anomaly Detection for Tabular Data', 'publication_date_yy_mm': '2024-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9285.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e9285.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Transformer + v-attention</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Transformer with vanilla (dot-product) attention-based retrieval</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Retrieval-augmented transformer using a learned dot-product attention (W_Q(h_z)^T W_K(h_x)) to score and retrieve helper samples for aggregation.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Transformer + v-attention retrieval</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>transformer encoder + learned dot-product attention retrieval</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>hidden_dim ∈ {8,16,32}; 2 or 4 layers; 4 attention heads</td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>tabular (mixed)</td>
                        </tr>
                        <tr>
                            <td><strong>data_domain</strong></td>
                            <td>same benchmark</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>aimed at capturing sample-sample correlations; intended to help local anomalies</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Post-encoder: compute S(z,x) = W_Q(h_z)^T W_K(h_x); V(z,x) = W_V(h_x); use attention weights to aggregate and feed to final layer; training is mask-reconstruction.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_methods</strong></td>
                            <td>Compared to KNN-based retrieval and attention-bsim variants.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>F1-score, AUROC</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>Average F1 ≈ 55.7, AUROC ≈ 83.1 (Table 1); did not improve over vanilla transformer on average in these experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td>Underperformed attention-bsim and was comparable to the vanilla transformer; authors note that v-attention (similar to ABD used in NPTs) did not yield the best results here.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Vanilla attention between datapoints (v-attention) did not consistently translate to better AD performance in the mask-reconstruction setup used; may require different design or pretraining.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Retrieval Augmented Deep Anomaly Detection for Tabular Data', 'publication_date_yy_mm': '2024-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9285.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e9285.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>attention-bsim-bval</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Attention-bsim with modified (bval) value function</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Distance-based attention score like attention-bsim but with a parametric, non-linear value function T(W_K(h_z)-W_K(h_x)) (small MLP) used to compute helper representations before aggregation.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Transformer + attention-bsim-bval</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>transformer encoder + distance-based attention + learned value MLP</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>hidden_dim ∈ {8,16,32}; 2 or 4 layers; 4 attention heads</td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>tabular mixed features</td>
                        </tr>
                        <tr>
                            <td><strong>data_domain</strong></td>
                            <td>benchmark of 31 tabular datasets</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>intended to capture nuanced sample-sample relations and contextual differences</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Compute S(z,x) = -||W_K(h_z) - W_K(h_x)||^2; V(z,x) = T(W_K(h_z)-W_K(h_x)) where T is Linear->Dropout->ReLU->Linear; aggregate into hz and train with mask-reconstruction.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_methods</strong></td>
                            <td>Compared to other retrieval modules and vanilla transformer.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>F1-score, AUROC</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>Average F1 ≈ 53.9, AUROC ≈ 82.1 (Table 1). In this work, it performed worse than attention-bsim and vanilla transformer.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td>Contrary to prior supervised-tabular work where this module variant performed well, in reconstruction-based AD it performed worse; indicates that retrieval/value design effects are task dependent.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>More complex value function did not help in the unsupervised mask-reconstruction AD setup; may be because no labels are available to shape the parametric value transform.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Retrieval Augmented Deep Anomaly Detection for Tabular Data', 'publication_date_yy_mm': '2024-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9285.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e9285.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Mask-KNN</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Mask-KNN (KNN imputation for masked reconstruction)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A non-parametric reconstruction method (from prior work) that imputes masked features using k-nearest-neighbors and scores anomalies by reconstruction error; used as a baseline and conceptual ablation of sample-sample-only approaches.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Beyond Individual Input for Deep Anomaly Detection on Tabular Data</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Mask-KNN</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>non-parametric KNN imputation</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>tabular data</td>
                        </tr>
                        <tr>
                            <td><strong>data_domain</strong></td>
                            <td>benchmark datasets and the synthetic 3D experiment</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>local anomalies and sample-sample dependent outliers</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Impute masked features using the k nearest neighbors (in feature space or embedding space) without learning a parametric model; anomaly score is reconstruction error averaged over mask bank.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_methods</strong></td>
                            <td>Used as a baseline to represent methods relying primarily on sample-sample dependencies (KNN-based AD).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>F1-score, AUROC; per-class shares in synthetic test</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>Synthetic 3D experiment (Table 3): Normal 93.0% (±0.4), Type-1 anomalies 100.0% (±0.0), Type-2 anomalies 77.3% (±4.4). On benchmark average varied per dataset (reported in Tables).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td>Mask-KNN excelled at detecting type-1 (local) anomalies but performed much worse at type-2 (dependency) anomalies; complementary failure modes to transformer-only model.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Only leverages sample-sample relations; fails when anomalies differ only in feature-feature relations (dependency anomalies); performance sensitive to neighbor count k and dataset structure.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Retrieval Augmented Deep Anomaly Detection for Tabular Data', 'publication_date_yy_mm': '2024-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9285.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e9285.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>NPT-AD (mentioned)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>NPT-AD (Anomaly detection using Non-Parametric Transformers / Attention Between Datapoints)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Referenced prior work that uses Attention Between Datapoints (ABD) in Neural Process Transformer (NPT) style models to leverage inter-sample relations for tabular tasks; cited as a strong AD approach in the literature.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Beyond Individual Input for Deep Anomaly Detection on Tabular Data</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>NPT-AD</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>transformer with Attention Between Datapoints (multi-head self-attention across samples)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>tabular data</td>
                        </tr>
                        <tr>
                            <td><strong>data_domain</strong></td>
                            <td>tabular anomaly detection benchmarks</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>general AD (leverages inter-sample relations; suitable for local anomalies)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Uses standard multi-head self-attention across datapoints (ABD) to allow interactions between samples during training/inference; reported strong performance in prior work.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_methods</strong></td>
                            <td>Referenced as a strong deep baseline alongside GOAD, DROCC, etc.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Not reported in detail in this paper (metrics are in original NPT-AD publication).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>Mentioned as high-performing in prior literature; authors note ABD (v-attention-like) differs from attention-bsim and may benefit from modification.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td>This paper's experiments indicate that v-attention-like mechanisms (ABD-style) did not beat attention-bsim in the present reconstruction-based AD setup; authors suggest exploring ABD modifications for AD.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Not evaluated directly in this paper; discussion notes that standard ABD (v-attention) did not outperform the best retrieval module here, suggesting task-dependent behavior.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Retrieval Augmented Deep Anomaly Detection for Tabular Data', 'publication_date_yy_mm': '2024-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Beyond Individual Input for Deep Anomaly Detection on Tabular Data <em>(Rating: 2)</em></li>
                <li>Self-Attention Between Datapoints: Going Beyond Individual Input-Output Pairs in Deep Learning <em>(Rating: 2)</em></li>
                <li>Retrieval-Augmented Diffusion Models <em>(Rating: 1)</em></li>
                <li>TabR: Tabular Deep Learning Meets Nearest Neighbors in 2023 <em>(Rating: 1)</em></li>
                <li>Unsupervised Cross-Task Generalization via Retrieval Augmentation <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-9285",
    "paper_id": "paper-267320333",
    "extraction_schema_id": "extraction-schema-162",
    "extracted_data": [
        {
            "name_short": "Transformer (vanilla)",
            "name_full": "Mask-reconstruction Transformer for Tabular Anomaly Detection",
            "brief_description": "A transformer encoder trained in a mask-reconstruction (feature-masking) objective on normal-only tabular data; attends only to feature-feature dependencies and produces anomaly scores from reconstruction error.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "Transformer (custom small transformer)",
            "model_type": "transformer encoder (self-attention)",
            "model_size": "hidden_dim ∈ {8,16,32}; 2 or 4 encoder layers; 4 attention heads (dataset-dependent)",
            "data_type": "tabular data (mixed numerical and categorical features; per-feature embeddings)",
            "data_domain": "benchmark of 31 tabular datasets (ODDS multidimensional point datasets, Arrhythmia, Thyroid, fraud, campaign, backdoor) and a synthetic 3D dataset",
            "anomaly_type": "general outliers including dependency anomalies, global anomalies, local anomalies, clustered/group anomalies",
            "method_description": "Reconstruction-based anomaly detection: randomly mask features during training and train transformer to predict masked features from unmasked ones; anomaly score is average reconstruction error over a deterministic mask bank at inference.",
            "baseline_methods": "Compared against non-deep methods (Isolation Forest, KNN, RRCF, COPOD, PIDForest) and deep/self-supervised AD methods (GOAD, DROCC, NeuTraL-AD, contrastive [30], NPT-AD, Mask-KNN).",
            "performance_metrics": "F1-score, AUROC (reported as mean across datasets and per-dataset splits)",
            "performance_results": "Average F1-score = 56.2; Average AUROC = 83.4 (reported in Table 1). Per-dataset metrics reported in Tables 8/9.",
            "comparison_to_baseline": "Serves as main parametric baseline; retrieval-augmented variants (notably attention-bsim) significantly outperform this vanilla transformer on average (F1 and AUROC gains reported). Performance relative to classical baselines varies by dataset.",
            "limitations_or_failure_cases": "Because it only models feature-feature dependencies, it struggles to detect anomalies that are local relative to the sample neighborhood (local anomalies/type 1 in synthetic test). Performance depends on mask design; no sample-sample information leads to blind spots for some anomaly types.",
            "unique_insights": "Transformer-only mask reconstruction reliably detects anomalies that violate learned inter-feature relations (dependency anomalies) but fails on anomalies that require sample-sample context; combining sample-sample retrieval with feature modeling is necessary for consistent performance across anomaly types.",
            "uuid": "e9285.0",
            "source_info": {
                "paper_title": "Retrieval Augmented Deep Anomaly Detection for Tabular Data",
                "publication_date_yy_mm": "2024-10"
            }
        },
        {
            "name_short": "Transformer + attention-bsim",
            "name_full": "Transformer with attention-bsim external retrieval module",
            "brief_description": "A retrieval-augmented transformer that, after encoding, retrieves helper samples using a distance-based attention score (L2 between W_K-transformed embeddings) and aggregates helper representations to improve masked-feature reconstruction and anomaly detection.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "Transformer + attention-bsim retrieval module",
            "model_type": "transformer encoder + attention-based external retrieval (distance-based attention)",
            "model_size": "hidden_dim ∈ {8,16,32}; 2 or 4 encoder layers; 4 attention heads (same transformer backbone as vanilla)",
            "data_type": "tabular data (mixed numerical and categorical features)",
            "data_domain": "same 31-tabular-dataset benchmark and synthetic 3D experiment",
            "anomaly_type": "improves detection for local anomalies (sample-sample dependent) and dependency anomalies (feature-feature), i.e., both local and dependency anomaly types",
            "method_description": "Post-encoder retrieval: flatten encoder outputs; compute S(z,x) = -||W_K(h_z) - W_K(h_x)||^2 to select helpers H (or use full C with attention weights); value V(z,x) = W_V(h_x); aggregate helpers into sample embedding hz &lt;- (1-λ)hz + λ * (1/k) Σ V(z,x); train on mask-reconstruction objective; anomaly score is average reconstruction error across deterministic mask bank.",
            "baseline_methods": "Compared to vanilla transformer, Transformer+KNN, Transformer+v-attention, Transformer+att-bsim-bval, Mask-KNN, and classical baselines listed above.",
            "performance_metrics": "F1-score, AUROC; per-dataset and average reported.",
            "performance_results": "Average F1-score = 58.6 (vs vanilla 56.2), Average AUROC = 84.4 (vs vanilla 83.4). On the synthetic 3D experiment (Table 3): Normal detection 94.6% (±0.5), Type-1 anomalies 88.0% (±0.8), Type-2 anomalies 100.0% (±0.0). Best-performing retrieval variant in this paper.",
            "comparison_to_baseline": "Significantly outperforms the vanilla transformer on average (reported +4.3% relative F1 improvement) and is the best retrieval-augmented variant tested; outperforms KNN- and vanilla-attention retrieval in these reconstruction-based AD experiments.",
            "limitations_or_failure_cases": "Non-parametric retrieval increases memory and inference complexity (scales with training set when helpers = C); performance sensitive to hyperparameters k (number of helpers) and λ (aggregation weight); some datasets require tuning (optimal k often moderate 25–50); not all retrieval modules help and attention-bsim-bval performed worse here; placement of retrieval matters (post-encoder best).",
            "unique_insights": "Combining sample-sample retrieval (attention-bsim) with feature-feature transformer representations enables detection of both local and dependency anomalies; deterministic mask bank at inference is better than random in most cases; moderate helper counts and post-encoder retrieval location yield best results.",
            "uuid": "e9285.1",
            "source_info": {
                "paper_title": "Retrieval Augmented Deep Anomaly Detection for Tabular Data",
                "publication_date_yy_mm": "2024-10"
            }
        },
        {
            "name_short": "Transformer + KNN",
            "name_full": "Transformer augmented with KNN-based external retrieval",
            "brief_description": "Retrieval-augmented transformer using a simple k-nearest-neighbors selection in embedding space (L2 distance) where retrieved helper values are the helper embeddings themselves and are aggregated into the target embedding.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "Transformer + KNN retrieval module",
            "model_type": "transformer encoder + KNN (non-parametric) retrieval",
            "model_size": "hidden_dim ∈ {8,16,32}; 2 or 4 layers; 4 attention heads",
            "data_type": "tabular data (mixed numerical/categorical)",
            "data_domain": "31-tabular-dataset benchmark and synthetic test",
            "anomaly_type": "helps detect anomalies that require sample-sample context (local anomalies)",
            "method_description": "Post-encoder: compute S(z,x) = -||h_z - h_x||; select top-k nearest helpers; V(z,x) = h_x; aggregate helpers into target via hz &lt;- (1-λ)hz + λ*(1/k)Σ h_x; train with mask-reconstruction objective.",
            "baseline_methods": "Compared to vanilla transformer and attention-based retrieval modules; also conceptually related to Mask-KNN baseline.",
            "performance_metrics": "F1-score, AUROC",
            "performance_results": "Average F1-score ≈ 56.1, AUROC ≈ 83.1 (Table 1). Performance similar to vanilla transformer on average; benefits vary by dataset.",
            "comparison_to_baseline": "Did not provide consistent improvement over vanilla transformer across the benchmark and was outperformed by attention-bsim.",
            "limitations_or_failure_cases": "Choice of k affects results; simple L2-based nearest neighbors may be insufficient compared to learned attention scoring; limited by capacity to incorporate feature-feature interactions beyond embeddings.",
            "uuid": "e9285.2",
            "source_info": {
                "paper_title": "Retrieval Augmented Deep Anomaly Detection for Tabular Data",
                "publication_date_yy_mm": "2024-10"
            }
        },
        {
            "name_short": "Transformer + v-attention",
            "name_full": "Transformer with vanilla (dot-product) attention-based retrieval",
            "brief_description": "Retrieval-augmented transformer using a learned dot-product attention (W_Q(h_z)^T W_K(h_x)) to score and retrieve helper samples for aggregation.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "Transformer + v-attention retrieval",
            "model_type": "transformer encoder + learned dot-product attention retrieval",
            "model_size": "hidden_dim ∈ {8,16,32}; 2 or 4 layers; 4 attention heads",
            "data_type": "tabular (mixed)",
            "data_domain": "same benchmark",
            "anomaly_type": "aimed at capturing sample-sample correlations; intended to help local anomalies",
            "method_description": "Post-encoder: compute S(z,x) = W_Q(h_z)^T W_K(h_x); V(z,x) = W_V(h_x); use attention weights to aggregate and feed to final layer; training is mask-reconstruction.",
            "baseline_methods": "Compared to KNN-based retrieval and attention-bsim variants.",
            "performance_metrics": "F1-score, AUROC",
            "performance_results": "Average F1 ≈ 55.7, AUROC ≈ 83.1 (Table 1); did not improve over vanilla transformer on average in these experiments.",
            "comparison_to_baseline": "Underperformed attention-bsim and was comparable to the vanilla transformer; authors note that v-attention (similar to ABD used in NPTs) did not yield the best results here.",
            "limitations_or_failure_cases": "Vanilla attention between datapoints (v-attention) did not consistently translate to better AD performance in the mask-reconstruction setup used; may require different design or pretraining.",
            "uuid": "e9285.3",
            "source_info": {
                "paper_title": "Retrieval Augmented Deep Anomaly Detection for Tabular Data",
                "publication_date_yy_mm": "2024-10"
            }
        },
        {
            "name_short": "attention-bsim-bval",
            "name_full": "Attention-bsim with modified (bval) value function",
            "brief_description": "Distance-based attention score like attention-bsim but with a parametric, non-linear value function T(W_K(h_z)-W_K(h_x)) (small MLP) used to compute helper representations before aggregation.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "Transformer + attention-bsim-bval",
            "model_type": "transformer encoder + distance-based attention + learned value MLP",
            "model_size": "hidden_dim ∈ {8,16,32}; 2 or 4 layers; 4 attention heads",
            "data_type": "tabular mixed features",
            "data_domain": "benchmark of 31 tabular datasets",
            "anomaly_type": "intended to capture nuanced sample-sample relations and contextual differences",
            "method_description": "Compute S(z,x) = -||W_K(h_z) - W_K(h_x)||^2; V(z,x) = T(W_K(h_z)-W_K(h_x)) where T is Linear-&gt;Dropout-&gt;ReLU-&gt;Linear; aggregate into hz and train with mask-reconstruction.",
            "baseline_methods": "Compared to other retrieval modules and vanilla transformer.",
            "performance_metrics": "F1-score, AUROC",
            "performance_results": "Average F1 ≈ 53.9, AUROC ≈ 82.1 (Table 1). In this work, it performed worse than attention-bsim and vanilla transformer.",
            "comparison_to_baseline": "Contrary to prior supervised-tabular work where this module variant performed well, in reconstruction-based AD it performed worse; indicates that retrieval/value design effects are task dependent.",
            "limitations_or_failure_cases": "More complex value function did not help in the unsupervised mask-reconstruction AD setup; may be because no labels are available to shape the parametric value transform.",
            "uuid": "e9285.4",
            "source_info": {
                "paper_title": "Retrieval Augmented Deep Anomaly Detection for Tabular Data",
                "publication_date_yy_mm": "2024-10"
            }
        },
        {
            "name_short": "Mask-KNN",
            "name_full": "Mask-KNN (KNN imputation for masked reconstruction)",
            "brief_description": "A non-parametric reconstruction method (from prior work) that imputes masked features using k-nearest-neighbors and scores anomalies by reconstruction error; used as a baseline and conceptual ablation of sample-sample-only approaches.",
            "citation_title": "Beyond Individual Input for Deep Anomaly Detection on Tabular Data",
            "mention_or_use": "use",
            "model_name": "Mask-KNN",
            "model_type": "non-parametric KNN imputation",
            "model_size": null,
            "data_type": "tabular data",
            "data_domain": "benchmark datasets and the synthetic 3D experiment",
            "anomaly_type": "local anomalies and sample-sample dependent outliers",
            "method_description": "Impute masked features using the k nearest neighbors (in feature space or embedding space) without learning a parametric model; anomaly score is reconstruction error averaged over mask bank.",
            "baseline_methods": "Used as a baseline to represent methods relying primarily on sample-sample dependencies (KNN-based AD).",
            "performance_metrics": "F1-score, AUROC; per-class shares in synthetic test",
            "performance_results": "Synthetic 3D experiment (Table 3): Normal 93.0% (±0.4), Type-1 anomalies 100.0% (±0.0), Type-2 anomalies 77.3% (±4.4). On benchmark average varied per dataset (reported in Tables).",
            "comparison_to_baseline": "Mask-KNN excelled at detecting type-1 (local) anomalies but performed much worse at type-2 (dependency) anomalies; complementary failure modes to transformer-only model.",
            "limitations_or_failure_cases": "Only leverages sample-sample relations; fails when anomalies differ only in feature-feature relations (dependency anomalies); performance sensitive to neighbor count k and dataset structure.",
            "uuid": "e9285.5",
            "source_info": {
                "paper_title": "Retrieval Augmented Deep Anomaly Detection for Tabular Data",
                "publication_date_yy_mm": "2024-10"
            }
        },
        {
            "name_short": "NPT-AD (mentioned)",
            "name_full": "NPT-AD (Anomaly detection using Non-Parametric Transformers / Attention Between Datapoints)",
            "brief_description": "Referenced prior work that uses Attention Between Datapoints (ABD) in Neural Process Transformer (NPT) style models to leverage inter-sample relations for tabular tasks; cited as a strong AD approach in the literature.",
            "citation_title": "Beyond Individual Input for Deep Anomaly Detection on Tabular Data",
            "mention_or_use": "mention",
            "model_name": "NPT-AD",
            "model_type": "transformer with Attention Between Datapoints (multi-head self-attention across samples)",
            "model_size": null,
            "data_type": "tabular data",
            "data_domain": "tabular anomaly detection benchmarks",
            "anomaly_type": "general AD (leverages inter-sample relations; suitable for local anomalies)",
            "method_description": "Uses standard multi-head self-attention across datapoints (ABD) to allow interactions between samples during training/inference; reported strong performance in prior work.",
            "baseline_methods": "Referenced as a strong deep baseline alongside GOAD, DROCC, etc.",
            "performance_metrics": "Not reported in detail in this paper (metrics are in original NPT-AD publication).",
            "performance_results": "Mentioned as high-performing in prior literature; authors note ABD (v-attention-like) differs from attention-bsim and may benefit from modification.",
            "comparison_to_baseline": "This paper's experiments indicate that v-attention-like mechanisms (ABD-style) did not beat attention-bsim in the present reconstruction-based AD setup; authors suggest exploring ABD modifications for AD.",
            "limitations_or_failure_cases": "Not evaluated directly in this paper; discussion notes that standard ABD (v-attention) did not outperform the best retrieval module here, suggesting task-dependent behavior.",
            "uuid": "e9285.6",
            "source_info": {
                "paper_title": "Retrieval Augmented Deep Anomaly Detection for Tabular Data",
                "publication_date_yy_mm": "2024-10"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Beyond Individual Input for Deep Anomaly Detection on Tabular Data",
            "rating": 2,
            "sanitized_title": "beyond_individual_input_for_deep_anomaly_detection_on_tabular_data"
        },
        {
            "paper_title": "Self-Attention Between Datapoints: Going Beyond Individual Input-Output Pairs in Deep Learning",
            "rating": 2,
            "sanitized_title": "selfattention_between_datapoints_going_beyond_individual_inputoutput_pairs_in_deep_learning"
        },
        {
            "paper_title": "Retrieval-Augmented Diffusion Models",
            "rating": 1,
            "sanitized_title": "retrievalaugmented_diffusion_models"
        },
        {
            "paper_title": "TabR: Tabular Deep Learning Meets Nearest Neighbors in 2023",
            "rating": 1,
            "sanitized_title": "tabr_tabular_deep_learning_meets_nearest_neighbors_in_2023"
        },
        {
            "paper_title": "Unsupervised Cross-Task Generalization via Retrieval Augmentation",
            "rating": 1,
            "sanitized_title": "unsupervised_crosstask_generalization_via_retrieval_augmentation"
        }
    ],
    "cost": 0.018883,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Retrieval Augmented Deep Anomaly Detection for Tabular Data
22 Jul 2024</p>
<p>Hugo Thimonier hugo.thimonier@lisn.fr 
Fabrice Popineau fabrice.popineau@lisn.fr 
Arpad Rimmel arpad.rimmel@lisn.fr 
Bich-Liên 2024 Doan bich-lien.doan@lisn.fr 
Retrieval </p>
<p>Laboratoire Interdisciplinaire des Sciences du Numérique
Université Paris-Saclay
CNRS
Gif-sur-YvetteCentraleSupélecFrance</p>
<p>Laboratoire Interdisciplinaire des Sciences du Numérique
Université Paris-Saclay
CNRS
Gif-sur-YvetteCentraleSupélecFrance Arpad Rimmel</p>
<p>Laboratoire Interdisciplinaire des Sciences du Numérique
Université Paris-Saclay
CNRS
Gif-sur-Yvette, Bich-Liên DoanCentraleSupélecFrance</p>
<p>Laboratoire Interdisciplinaire des Sciences du Numérique
Université Paris-Saclay
CNRS
Gif-sur-YvetteCentraleSupélecFrance</p>
<p>14 pagesNew YorkNYUSA</p>
<p>CIKM '24
October 21-252024BoiseIDUSA</p>
<p>Retrieval Augmented Deep Anomaly Detection for Tabular Data
22 Jul 20248ABA717133730A8B879135C679A4FA5210.1145/3627673.3679559arXiv:2401.17052v2[cs.LG]Anomaly DetectionTabular DataDeep Learning
Deep learning for tabular data has garnered increasing attention in recent years, yet employing deep models for structured data remains challenging.While these models excel with unstructured data, their efficacy with structured data has been limited.Recent research has introduced retrieval-augmented models to address this gap, demonstrating promising results in supervised tasks such as classification and regression.In this work, we investigate using retrieval-augmented models for anomaly detection on tabular data.We propose a reconstruction-based approach in which a transformer model learns to reconstruct masked features of normal samples.We test the effectiveness of KNN-based and attention-based modules to select relevant samples to help in the reconstruction process of the target sample.Our experiments on a benchmark of 31 tabular datasets reveal that augmenting this reconstruction-based anomaly detection (AD) method with sample-sample dependencies via retrieval modules significantly boosts performance.The present work supports the idea that retrieval module are useful to augment any deep AD method to enhance anomaly detection on tabular data.Our code to reproduce the experiments is made available on GitHub.CCS CONCEPTS• Security and privacy → Intrusion/anomaly detection and malware mitigation; • Computing methodologies → Semi-supervised learning settings; Neural networks.</p>
<p>INTRODUCTION</p>
<p>Semi-supervised anomaly detection (AD) consists in learning to characterize a normal distribution using a dataset only composed of samples belonging to the normal 1 class, in order to identify in a separate dataset the samples that do not belong to this normal distribution, namely anomalies.This class of algorithms is often used when the imbalance between classes is too severe, causing standard supervised approaches to fail [39].Examples of such applications are cyber intrusion detection [2], fraud detection on credit card payment [15,35], or tumor detection on images [37].On the contrary, unsupervised anomaly detection refers to identifying anomalies in a dataset without using labeled training data.These algorithms aim to discover patterns or structures in the data and flag instances that deviate significantly from these patterns.The application of such an approach usually includes detecting mislabeled samples or removing outliers from a dataset that may hinder a model's training process.</p>
<p>While deep learning methods have become ubiquitous and are widely used in the industry for various tasks on unstructured data, relying on deep models for tabular data remains challenging.Indeed, Grinsztajn et al. [11] discuss how the inherent characteristics of tabular data make this type of data challenging to handle by standard deep models.Hence, recent research on deep learning for structured data [1,9,17,29,32] has been oriented towards proposing novel training frameworks, regularization techniques or architectures tailored for tabular data.Similarly, general AD methods appear to struggle with tabular data, while the best-performing AD algorithms on tabular data involve accounting for the particular structure of this data type.For instance, [3,22,30,34] put forward self-supervised anomaly detection algorithms targeted for tabular data that significantly outperform general methods on most tested datasets.</p>
<p>In particular, recent research has emphasized the pivotal role of combining feature-feature and samples-sample dependencies in fostering deep learning model's performance on tabular data [9,17,32].Following these recent findings, we investigate the benefits of including external retrieval modules to leverage sample-sample dependencies to augment existing AD methods.External retrieval modules can be considered instrumental as they can augment any existing model that may only rely on feature-feature dependencies.In contrast, models that rely on internal retrieval mechanisms are bound to some inductive biases and cannot be used to learn all possible tasks that may be relevant for anomaly detection.</p>
<p>Leveraging both types of dependencies is critical to detect all types of anomalies effectively and can increase consistency across datasets, as we empirically show in section 5.1.Han et al. [13] categorize anomalies in tabular data into 4 families of anomalies which require different types of dependencies to be correctly identified.First, dependency anomalies explicitly refers to samples that do not follow the dependency structure that normal data follow require feature-feature dependencies to be efficiently identified.Second, global anomalies refer to unusual data points that deviate significantly from the norm.Relying on both dependencies should improve a model's capacity to detect these anomalies.Third, local anomalies that refer to the anomalies that are deviant from their local neighborhood can only be identified by relying on samplesample dependencies.Finally, clustered anomalies, also known as group anomalies, are composed of anomalies that exhibit similar characteristics.This type of anomaly requires feature-feature dependencies to be identified.</p>
<p>We test the relevance of external modules by employing transformers [36] in a mask-reconstruction framework to construct an anomaly score as it was proven to offer strong anomaly detection performance [34].We implement several external retrieval methods to augment the vanilla transformer and evaluate the performance of each approach on an extensive benchmark of tabular datasets.</p>
<p>We empirically show that the tested approaches incorporating retrieval modules to account for the sample-sample relations outperform the vanilla transformer that only attends to feature-feature dependencies.Furthermore, we propose an empirical experiment to account for the pertinence of combining dependencies, showing that detecting some types of anomalies can require a particular type of dependency.</p>
<p>The present work offers the following contributions:</p>
<p>• We propose an extensive evaluation of retrieval-based methods for AD on tabular data.• We empirically show that augmenting existing AD methods with a retrieval module to leverage sample-sample dependencies can help improve detection performance.• We compare our approach to existing methods found in the literature and observe that our method obtains competitive performance metrics.• We provide an explanation as to why combining dependencies leads to better identification of anomalies in tabular data.</p>
<p>RELATED WORKS</p>
<p>Ruff et al. [25] discuss how anomaly detection bears several denominations that more or less designate the same class of algorithms: anomaly detection, novelty detection, and outlier detection.The literature comprises 4 main classes of anomaly detection algorithms: density estimation, one-class classification, reconstruction-based, and self-supervised algorithms.</p>
<p>Density estimation.It is often seen as the most direct approach to detecting anomalies in a dataset.The density estimation approach consists in estimating the normal distribution and flagging low probability samples under this distribution as an anomaly.Existing methods include using Copula as the COPOD method proposed in [18], Local Outlier Factor (LOF) [5], Energy-based models [41] flow-based models [20].</p>
<p>Reconstruction-based methods.Other anomaly detection methods focus on learning to reconstruct samples belonging to the normal distribution.In inference, the capacity of the model to reconstruct an unseen sample is used as a measure of anomalousness.The more capable a model is to reconstruct a sample, the more likely the sample is to belong to the normal distribution seen in training.Such approach include methods involving autoencoders [6,16], diffusion models [38,42], GANs [27] or attention-based models [34].</p>
<p>One-Class Classification.One-class classification describes the task of identifying anomalies without directly estimating the normal density.This class of algorithm involves discriminative models that directly estimate a decision boundary.In [26,28,33], the authors propose algorithms that estimate the support of the normal distribution, either in the original data space or in a latent space.During inference, one flags the samples outside the estimated support as anomalies.Other one-class classification methods include tree-based approaches such as isolation forest (IForest) [21], extended isolation forest [14], RRCF [12] and PIDForest [8].Other methods include approaches to augment existing one-class classification methods with a classifier by generating synthetic anomalies during training, such as DROCC [10].</p>
<p>Self-Supervised Approaches.Given the recent successes of selfsupervision for many tasks, researchers have also investigated using self-supervised methods for anomaly detection.[3] and [22] propose transformation based anomaly detection methods for tabular data.The former relies on a classifier's capacity to identify which transformation was applied to a sample to measure anomalousness, while the latter relies on a contrastive approach.Similarly, [30] also proposes a contrastive approach to flag anomalies by learning feature-feature relation for normal samples.Parallel to this line of work, [24,31] have focused on proposing self-supervised approaches for representation learning tailored for anomaly detection.</p>
<p>Retrieval modules.Retrieval modules have gained attention in recent years in many fields of machine learning.For instance, [4] introduces a retrieval module to foster the scalability and efficiency of diffusion models.Parallel to that, [19] introduced retrieval for cross-task generalization of large language models, and [7] introduced it to enhance prompt learning.Finally, retrieval methods have been increasingly used to increase the performance of deep models for tabular data.For instance, [17] and [32] introduced internal retrieval modules in deep architecture for supervised tasks on tabular data, while [34] relied on internal retrieval modules for anomaly detection.Finally, [9] investigated using external retrieval modules to augment an MLP for supervised tasks on tabular data.
z Masked test sample Σ + h z z Reconst. test sample          x 1 x 2 . . . x 𝑛                   h x 1 h x 2 . . . h x 𝑛          Candidate samples
In-Embedding</p>
<p>In-Embedding</p>
<p>METHOD 3.1 Learning Objective</p>
<p>Let D  = {x  ∈ R  }  =1 represent the training set composed of  normal samples with  features.The standard approach to anomaly detection involves learning some function   : R  → Z by minimizing a loss function L. The chosen loss function and the space Z will vary according to the class of the considered anomaly detection algorithm.Nevertheless, the overall aim of L is to characterize the distribution of the samples in the training set as precisely as possible.Depending on the chosen AD algorithm, the obtained representation   (x) of sample x can be used directly or indirectly to compute an anomaly score.</p>
<p>Formally, the training objective can be summarized as follows min
𝜃 ∈Θ ∑︁ x∈ D 𝑡𝑟𝑎𝑖𝑛 L (x, 𝜙 𝜃 (x)),(1)
where L (x,   (x)) will vary according to the chosen task.For a reconstruction-based method, Z can be the original data space and L can be the squared ℓ 2 -norm of the difference between the original sample x and its reconstructed counterpart, L (x,
𝜙 𝜃 (x)) = ∥x − 𝜙 𝜃 (x) ∥ 2 .
Introducing an external retrieval module permits keeping the original objective unchanged while augmenting   with samplesample dependencies through non-parametric mechanisms.The model involves non-parametric relations as it leverages the entire training dataset to make its prediction.Hence, the model can conjointly attend to feature-feature and sample-sample interactions to optimize its objective.</p>
<p>Formally, instead of minimizing the loss as described in eq. ( 1), the parameters  of the function   are optimized to minimize the loss function as follows min
𝜃 ∈Θ ∑︁ x∈ D 𝑡𝑟𝑎𝑖𝑛 L (x, 𝜙 𝜃 (x; D 𝑡𝑟𝑎𝑖𝑛 )) .(2)
Nevertheless, not all approaches to AD may benefit from such non-parametric mechanisms.Some pretext tasks involving samplesample dependencies may lead to degenerate solutions, e.g.approaches based on contrastive learning such as the approaches of [22] or [30].However, reconstruction-based AD methods appear as a natural class of algorithms that may benefit from these non-parametric mechanisms.</p>
<p>Mask Reconstruction.In the mask reconstruction context, we empirically investigate the pertinence of external retrieval modules, as detailed in section 3.2.Our approach includes stochastic masking which consists in masking each entry in a sample vector x ∈ R  with probability   while setting as the objective task the prediction of the masked-out features from the unmasked features.Formally, we sample m ∈ R  a binary mask vector taking value 1 when the corresponding entry in x is masked, 0 otherwise.This mask m is then used to construct x  , x  ∈ R  representing respectively the masked and unmasked entries of sample x. x  , x  are obtained as follows,
x 𝑚 = m ⊙ x x 𝑜 = (1 𝑑 − m) ⊙ x,(3)
where 1  is the -dimensional unit vector.</p>
<p>A model   : R  × {0, 1}  → R  is trained to reconstruct the mask features x  from its unmasked counterpart x  and the mask vector m.By construction,   (x  ; m) only has non-zero values for corresponding masked features in m.</p>
<p>In the present work, we evaluate the benefit of replacing the traditional reconstruction learning objective defined as min
𝜃 ∈Θ ∑︁ x∈ D 𝑡𝑟𝑎𝑖𝑛 𝑑 (x 𝑚 , 𝜙 𝜃 (x 𝑜 ; m)),(4)
where  (., .) is a distance measure; with its equivalent augmented with a retrieval module as follows min
𝜃 ∈Θ ∑︁ x∈ D 𝑡𝑟𝑎𝑖𝑛 𝑑 x 𝑚 , 𝜙 𝜃 x 𝑜 ; m, D 𝑜 𝑡𝑟𝑎𝑖𝑛 , (5) (a) F1-score (↑) (b) Rank (↓)
Figure 2: For each of the 31 datasets on which models were evaluated, we report the average F1-score over 20 runs for 20 different seeds.We refer readers to Thimonier et al. [34] for details on the obtained metrics and the hyperparameters used for each method.For both figures, the model displayed on the far left is the worst-performing model for the chosen metric, and the one on the far right is the best-performing model.We also highlight the metric of the best-performing model in bold.</p>
<p>where
D 𝑜 𝑡𝑟𝑎𝑖𝑛 = {x 𝑜 𝑖 ∈ R 𝑑 } 𝑛 𝑖=1 .
In inference, D   is replaced by D  in which none of the features of the training samples are masked.</p>
<p>Retrieval methods</p>
<p>Let z denote the sample of interest for which we wish to reconstruct its masked features z  given its observed counterpart z  .Let C denote the candidate samples from the training set from which  helpers are to be retrieved, and H the retrieved helpers, H ⊆ C.</p>
<p>We consider several external retrieval modules that rely on similarity measures to identify relevant samples to augment the encoded representation of the sample of interest z.It involves placing a retrieval module after the transformer encoder and before the output layer, as shown in figure 1.We investigate in section 5 the impact of modifying the location of the retrieval module and consider placing it before the encoder as an alternative.For each method, the retrieval module consists in selecting the top- elements that maximize a similarity measure S(•, •) and use a value function to obtain representations of the chosen samples V (•, •) to be aggregated with sample z.KNN-based module.First, we consider a simple method that identifies the  most relevant samples in C using a KNN approach.Formally, the similarity and value functions are defined as follows
S(z, x) = −∥h z − h x ∥ V (z, x) = h x ,(6)
where h x and h z denote the representations of respectively sample x and z and ∥.∥ is the ℓ 2 -norm.</p>
<p>Attention-based modules.Second, we consider attention mechanisms to select H .We consider three types of attention inspired by those proposed in [9].First, the vanilla attention (later referred to as v-attention), where the score and value function used to select the retrieved samples are defined as
S(z, x) = 𝑊 𝑄 (h z ) ⊤ 𝑊 𝐾 (h 𝑥 ) V (z, x) = 𝑊 𝑉 (h x ).(7)
where   ,  and   are learned parameters.Second, we also consider another type of attention module, later referred to as attention-bsim, which involves replacing the score function defined in eq. ( 7) as follows
S(z, x) = − ∥𝑊 𝐾 (h z ) − 𝑊 𝐾 (h x ) ∥ 2 V (z, x) = 𝑊 𝑉 (h x ).(8)
Third, we consider attention-bsim-bval a modification of the value function in eq. ( 8) as
S(z, x) = − ∥𝑊 𝐾 (h z ) − 𝑊 𝐾 (h x ) ∥ 2 V (z, x) = 𝑇 (𝑊 𝐾 (h z ) − 𝑊 𝐾 (h x )),(9)
where
𝑇 (•) = LinearWithtoutBias • Dropout • ReLU • Linear(•).
Aggregation.The retrieval modules necessitate aggregating the obtained retrieved representations V (z, x) with the representation of the sample of interest z.We aggregate the value of the selected top- helpers, to be fed to the final layer
hz = (1 − 𝜆) • h z + 𝜆 • 1 𝑘 ∑︁ 𝑥 ∈ H V (z, x). (10)
where  ∈ [0, 1) is a hyperparameter.</p>
<p>Anomaly score</p>
<p>We construct an anomaly score to assess whether a test sample belongs to the normal distribution or should be considered an anomaly.As a reconstruction-based method, our anomaly score is directly obtained from the optimized loss during training: the better the trained model reconstructs a sample, the more likely the sample is to be normal.Indeed, since the model has exclusively seen normal samples during training, it should be less able to reconstruct anomalies correctly since they stem from a different distribution.On the contrary, unseen normal samples should be well reconstructed.We rely on the squared ℓ 2 -norm of the difference between the reconstructed sample and the original sample for numerical features, while we use the cross-entropy loss function for categorical features.We rely on a mask bank composed of  -dimensional masks to construct the anomaly score.We apply each mask to each validation sample and reconstruct the masked features to compute the reconstruction error for each mask.Thus, each validation sample is masked and reconstructed  times.The anomaly score is constructed as the average reconstruction error over the  masks.To construct the mask bank, we fix the maximum of features to be masked simultaneously  and and construct  =  =1   masks.Choosing deterministic masks instead of random masks to create the mask bank used for inference is beneficial for two reasons.First, since the model will reconstruct all features at least once, it increases the likelihood of identifying different types of anomalies.Indeed, anomalies that deviate from the normal distribution due to a single feature would only be identified if the corresponding mask hiding this feature would be included.Second, this approach ensures that all samples are masked identically to build the anomaly score.We investigate the impact of constructing a random mask bank instead of a deterministic mask bank in section 5.5.We use the whole unmasked training set2 C = D  to predict the masked features of each sample for each of the  masked vectors and construct the anomaly score for a validation sample z as AD-Score(z;
D 𝑡𝑟𝑎𝑖𝑛 ) = 1 𝑚 𝑚 ∑︁ 𝑘=1 L (z (𝑘 ) ; D 𝑡𝑟𝑎𝑖𝑛 ),(11)
where L (z ( ) ; D  ) designates the loss for the sample z with mask .</p>
<p>Training pipeline</p>
<p>Let x ∈ X ⊆ R  be a sample with  features, which can be either numerical or categorical.Let  designate the hidden dimension of the transformer.The training pipeline consists of the following steps:</p>
<p>Masking.We sample from a Bernoulli distribution with probability   whether each of the  features is masked.mask = ( 1 , . . .,   ), where   ∼ B (1,   ) ∀ ∈ [1, ..., ] and   = 1 if feature  is masked.</p>
<p>Encoding.For numerical features, we normalize to obtain 0 mean and unit variance, while we use one-hot encoding for categorical features.At this point, each feature  for  ∈ [1, 2, ..., ] has an  dimensional representation,  (x  ) ∈ R   , where   = 1 for numerical features and for categorical features   corresponds to its cardinality.We then mask each feature according to the sampled mask vector and concatenate each feature representation with the corresponding mask indicator function.Hence, each feature  has an (  + 1)-dimensional representation
((1 − 𝑚 𝑗 ) • 𝑒𝑛𝑐𝑜𝑑𝑒𝑑 (x 𝑗 ), 𝑚 𝑗 ) ∈ R 𝑒 𝑗 +1 ,
where x  is the -th features of sample x.</p>
<p>In-Embedding.We pass each of the features encoded representations of sample x through learned linear layers Linear(  + 1, ).We also learn -dimensional index and feature-type embeddings as proposed in [17].Both are added to the embedded representation of sample x.The obtained embedded representation is thus of dimension  ×  ℎ x = (ℎ 1</p>
<p>x , ℎ 2 x , . . ., ℎ  x ) ∈ R  × , and ℎ</p>
<p>𝑗</p>
<p>x ∈ R  corresponds to the embedded representation of feature  of sample x.</p>
<p>Transformer Encoder.The embedded representation obtained from the previous step is then passed through a transformer encoder.The output of the transformer h x is of dimension  × .</p>
<p>Out-Embedding.The output of the transformer, h x ∈ R  × is then used to compute an estimation of the original -dimensional vector.To obtain the estimated feature , we take the -th -dimensional representation which is output by the transformer encoder, ℎ x  ∈ R  , and pass it through a linear layer Linear(,   ), where   is 1 for numerical features and the cardinality for categorical features.</p>
<p>External Retrieval Modules.During training, for a batch B composed of  samples, for each sample x ∈ B, the entire batch serves as the candidates C. In inference, a random subsample of the training set is used as C.Both for training and inference, when possible memory-wise, we use as B and C the entire training set.As input, the retrieval module receives a R  × representation for each sample.Operations described in eq. ( 6), ( 7), ( 8) and ( 9) are performed on the flattened representations of samples x, h x   ∈ R  • .After selecting H ⊆ C, each sample is transformed back to its original dimension to allow aggregation as described in eq.(10).</p>
<p>EXPERIMENTS</p>
<p>Datasets.We experiment on an extensive benchmark of tabular datasets following previous work [30,34].The benchmark is comprised of two datasets widely used in the anomaly detection literature, namely Arrhythmia and Thyroid, a second group of datasets, the "Multi-dimensional point datasets", obtained from the Outlier Detection DataSets (ODDS)3 containing 28 datasets.We also include three real-world datasets from [13]: fraud, campaign, and backdoor.We display each dataset's characteristics in table 7 in appendix A.1.</p>
<p>Experimental Settings.Following previous work in the AD literature, [3,44], we construct the training set with a random subsample of the normal samples representing 50% of the normal samples, we concatenate the 50% remaining with the entire set of anomalies to constitute the validation set.Similarly, we fix the decision threshold for the AD score such that the number of predicted anomalies equals the number of existing anomalies.</p>
<p>To evaluate to which extent sample-sample dependencies are relevant for anomaly detection, we compare models that attend to relations between samples to the vanilla transformer model.We compare the different methods discussed using the F1-score (↑) and AUROC (↑) metrics following the literature.For each dataset, we report an average over 20 runs for 20 different seeds; we display the detailed results for all five transformer-based methods in tables 8 and 9 in appendix B.1 and report in Table 1 the average F1 and AUROC.</p>
<p>We considered three regimes for the transformer dimensions depending on the dataset size.The transformer encoder comprises 2 or 4 layers with 4 attention heads and hidden dimension  ∈ {8, 16, 32} for smaller to larger datasets.We train the transformer with a mask probability   set to 0.25 or 0.15 and rely on the LAMB optimizer [40] with  = (0.9, 0.999) and also included a Lookahead [43] wrapper with slow update rate  = 0.5 and  = 6 steps between updates.We also include a dropout regularization with  = 0.1 for attention weights and hidden layers.We ensure that during training, all samples from a batch are not masked simultaneously so that the retrieval module receives encoded representations of unmasked samples as it will in the inference stage.We considered the same transformer architecture and hyperparameters for the same dataset for each considered approach.For external retrieval modules, we chose for simplicity  = 0.5 for aggregation as detailed in eq. ( 10).We study in section 5.3 the effect of varying the value of  on the model's performance.For the KNN module, we set  = 5 as the cardinality of H since KNN-based anomaly detection methods [23] with  = 5 have shown strong anomaly detection performance [30].In contrast, for the attention modules, we set H = C and use the attention weights to compute a weighted mean to be aggregated as in eq. ( 10).We further discuss the choice of  in section 5.2.Finally, depending on the dataset, we trained the model until the loss stopped improving for 50 or 100 consecutive epochs.Each experiment in the present work can be replicated using the code made available on github 4 .</p>
<p>Results.As reported in Table 1, we observe that not all retrieval modules induce a significant boost in anomaly detection performance.We observe that only the transformer augmented by the attention-bsim module performs significantly better than the vanilla transformer.Indeed, augmenting the vanilla transformer with the retrieval module detailed in eq. ( 8) allows to increase the average F1-score by 4.3% and AUROC by 1.2%.This result is all the more interesting since it contradicts the results obtained for the supervised classification and regression tasks investigated in previous work [9] where the module that obtains the best performance is attention-bsim-bval.However, let us mention that the attention-bsim-bval module involved in our work is not identical to the one put forward in [9] as it does not involve any label.</p>
<p>For completeness, we compare the different architectures proposed in the present work to existing methods in the literature.We rely on the experiments conducted in [30,34] for the metrics of the competing methods.We display in figure 2 the comparison to existing methods.We compare our methods to recent deep methods, namely GOAD [3], DROCC [10], NeuTraL-AD [22], the contrastive approach proposed in [30] and NPT-AD [34].We also compare to classical non-deep methods such as Isolation Forest [21], KNN [23], RRCF [12], COPOD [18] and PIDForest [8].We refer the reader to [34] for the detail on the F1-score per dataset for other methods than those shown in Tables 8 and 9 in appendix B.1.</p>
<p>DISCUSSION</p>
<p>Why combine dependencies?</p>
<p>To account for the fact that the retrieval-augmented transformer outperforms the vanilla transformer, we hypothesize that different types of anomalies require different dependencies to identify them.In this section, we provide a simple example to demonstrate this statement.Consider a simple three dimensional data space, x = ( 1 ,  2 ,  3 ) ∈ R 3 , in which the relation between the features of normal sample are defined as follows,
𝑥 2 = 𝛼 1 + 𝛽 1 𝑥 1 + 𝜀 𝑥 3 = 𝛼 2 + 𝛽 2 𝑥 2 2 + 𝜀, (12)
where  is some white noise and ( 1 ,  2 ,  1 ,  2 ) ∈ R 2 are scalars.</p>
<p>Let us consider two types of anomalies as shown in Figure 3. First anomalies of type 1, in which the relations between features are identical to the ones given in eq. ( 12) but in a different subspace.Now consider type 2 anomalies, for which the values of the generating feature  1 are in the same subspace as normal samples, the relation between  1 and  2 is the same, but the parameters of the relation between  2 and  3 differ.Type 1 (resp.2) anomalies are akin to local anomalies (resp.dependency anomalies) discussed in [13].</p>
<p>To test our hypothesis, we compare the retrieval augmented transformer to the vanilla transformer and Mask-KNN, a reconstructionbased technique introduced in [34], that relies on KNN imputation to reconstruct masked features.Mask-KNN (resp.the transformer) can be considered approximately equivalent to the retrieval augmented transformer without considering the feature-feature dependencies (resp.the sample-sample dependencies).</p>
<p>In the present framework, models only leveraging inter-feature relations, such as the vanilla transformer, may have limited capacities to identify anomalies if they satisfy the same relations as given in eq. ( 12) but in a different subspace, i.e., anomalies of type 1.Similarly, a model that only relies on inter-sample relations, e.g., Mask-KNN, would struggle to correctly identify anomalies of type 2 as they lie in a subspace close to normal samples.Synthetic Dataset.We effectively test this hypothesis by constructing a synthetic three-dimensional dataset where the features of normal samples satisfy the relations described in eq.(12).We also construct two types of anomalies where type 1 anomalies follow the same inter-feature relation normal samples but with values in a non-overlapping interval as those of the normal class.Type 2 anomalies are constructed to be close to the normal population but with inter-feature relation differing from eq. ( 12).This synthetic dataset is displayed in figure 3. The normal population comprises 1000 samples, and we generate 200 anomalies for each type.We use half of the normal samples to train models and use the rest merged with the anomalies as the validation set.We compare the capacity of Mask-KNN, the vanilla transformer, and the retrieval-augmented transformer to identify anomalies and display the obtained results in Table 3.We consider the same mask bank, {(1, 0, 0), (0, 1, 0), (0, 0, 1)}, for all three approaches.We use the same strategy for selecting the decision threshold as detailed in section 4. See appendix B.2 for more details on the experimental setting.</p>
<p>Results.We observe in Table 3 that the vanilla transformer struggles to detect type 1 anomalies in comparison with other methods, as they explicitly require inter-sample dependencies to be identified.Nevertheless, it correctly identifies 91.4% of normal samples on average and perfectly detects type 2 anomalies.Conversely, Mask-KNN obtains significantly lower performance than competing methods Normal Sample Anomaly (type 1) Anomaly (type 2)</p>
<p>Figure 3: Anomalies of type 1 ( ) require inter-sample dependencies to be correctly identified with high probability.Anomalies of type 2 ( ) on the other hand require interfeature dependencies to be correctly identified.</p>
<p>for type 2 anomalies while correctly identifying type 1 anomalies and normal samples.Notice how both methods cannot correctly identify anomalies from one of the two anomaly types despite using a perfectly separable dataset.On the contrary, the retrieval augmented transformer can better identify both types of anomalies as it can leverage inter-sample and inter-feature dependencies.This experiment provides information as to why combining dependencies for anomaly detection is relevant: it allows the detection of most anomaly types while other approaches are confined to some anomaly categories.</p>
<p>Analysis of the effect of the number of helpers 𝑘 on the performance</p>
<p>Note that we randomly selected a subset of the dataset from the benchmark for the ablation studies conducted hereafter.We use this subset of datasets in each experiment for computational reasons and to avoid cherry-picking the hyperparameters.We investigate the impact of varying , the number of helpers, for both the transformer augmented by attention-bsim and the KNN module since they are the two best-performing retrieval-augmented models.We keep hyperparameters constant and only make  vary between runs.We report in Table 2 the obtained results for both architectures for values of  ∈ {0, 5, 25, 50, 200, 500, −1}, where −1 implies that H = C.</p>
<p>A noticeable trend is that both architectures obtain the best results with moderate numbers of helper, i.e.  ∈ {25, 50}, and have worse performance for smaller values of .This observation suggests that performance displayed in tables 1,8, and 9 could be improved for optimized values of .</p>
<p>Analysis of the effect of the value of 𝜆</p>
<p>We analyze the performance variation for the best-performing external retrieval module, namely transformer+attention-bsim, for varying values of .We compute the average F1-score over 10 runs for each value of  in {0.1, 0.2, . . ., 0.7} while keeping the same hyperparameters.We report the results in Table 5.</p>
<p>We observe a slight variation of the average metric across the datasets when setting lambda values from 0.1 to 0.7.The maximum value is obtained for 0.5, but the difference with other values of  is non-significant.Nevertheless, we observe significant differences between the obtained results for isolated datasets for different values of .This observation supports the idea that an optimal value of  exists for each dataset, which may differ between datasets.</p>
<p>Location of the retrieval module</p>
<p>We investigate the impact of the retrieval module's location on the retrieval-augmented models' performance.To do so, we focus on the transformer+attention-bsim model since it has shown to be the best-performing retrieval-based method.We compare three different architectures:</p>
<p>• (post-enc, post-enc) for post-encoder location and postencoder aggregation: the architecture detailed in figure 1, • (post-emb, post-enc), the architecture in which the retrieval module is located after the embedding layer, but the aggregation is still located after the encoder, • (post-emb, post-emb) the architecture where both retrieval and aggregation are located after the embedding layer.</p>
<p>We do not report the results for the cardio dataset since it failed to converge for the (post-emb, post-enc) and (post-emb, post-emb) architectures and output NaN values in inference.We used the same hyperparameters for all three architectures.For (post-emb, post-enc) and (post-emb, post-emb) architectures we report the average over 10 runs.We display the results in Table 4.</p>
<p>We observe that the (post-enc, post-enc) architecture obtains the highest mean and lowest mean standard deviation over the tested datasets by a sizable margin.The transformer encoder's expressiveness allows for better representations of a data sample than the embedding layer and may account for such results.Indeed, this shows that the retrieval modules that receive the embedded representation as inputs are less able to select the relevant sample to foster mask reconstruction and anomaly detection performance.Moreover, since the encoder and retrieval modules are trained conjointly, the retrieval module can help the encoder converge to a state that favors sample representations that allow relevant clusters to be formed.</p>
<p>Random mask bank</p>
<p>We also investigate the impact of constructing a random mask bank for inference instead of selecting a deterministic mask bank as discussed in section 3.3.We construct for inference a random mask bank composed of the same number of masks as for the deterministic mask bank and use the same probability   as used to train the model.We compare the performance of the transformer model+attention-bsim based on the F1-score for the two set-ups and display the results in Table 6.We observe that the deterministic mask bank detects anomalies better on most tested datasets.When computing the anomaly score with the deterministic mask bank, the model obtains an average F1-score of 76.6 over the 7 datasets, while with the random mask bank, the model obtains 65.4.Moreover, as expected, we also observed a significantly larger standard deviation between runs.We might expect the standard deviation to decrease as the number of masks increases, which would induce significant computational overhead.</p>
<p>LIMITATIONS AND CONCLUSION</p>
<p>Limitations.As with most non-parametric models that leverage the training set in inference, our retrieval-augmented models display a higher complexity than parametric approaches.These approaches can scale well for datasets with a reasonable number of features ; however, for large values of , these models incur a high memory cost.</p>
<p>Conclusion.</p>
<p>In this work, we have proposed an extensive investigation into external retrieval to augment reconstruction-based anomaly detection methods for tabular data.We have shown that augmenting existing AD methods using attention-based retrieval modules can help foster performance by allowing the model to attend to sample-sample dependencies.Indeed, our experiments involving an extensive benchmark of tabular datasets demonstrate the effectiveness of retrieval-based approaches since the architecture involving the attention-bsim module surpasses the vanilla transformer by a significant margin.We also provide a first explanation as to why combining both types of dependencies can be critical to obtaining consistent performance across datasets: different types of anomalies require different types of dependencies to be efficiently detected.</p>
<p>Future Work.Overall, our work showed that the best-performing attention-based retrieval mechanism relies on other forms of attention than vanilla attention.Parallel to that, models like NPT-AD have shown strong performance for anomaly detection on tabular data and rely on standard multi-head self-attention through the Attention Between Datapoints (ABD) mechanism, close to the v-attention module, to leverage inter-sample relations.Our findings may invite further research on modifying the ABD mechanism involved in NPTs to improve their AD performance.Finally, the use of external retrieval modules proved effective for the task of anomaly detection using mask reconstruction.The proposed external retrieval module could also be easily added to existing deep-AD methods to test whether they may prove relevant for other pretext tasks for anomaly detection on tabular data.</p>
<p>A DATASETS CHARACTERISTICS AND EXPERIMENTAL SETTINGS A.1 Dataset characteristics</p>
<p>In Table 7, we display the main characteristics of the datasets involved in our experiments.</p>
<p>Figure 1 :
1
Figure 1: Forward pass for sample z, see section 3.4 for more detail on training procedure.In the case of no retrieval module, the prediction for a sample z consists of the upper part of the figure with  = 0.</p>
<p>Table 1 :
1
Comparison of transformer-based methods.We observe that the external retrieval module attention-bsim significantly improves the AD performance of the vanilla transformer by 4.3% regarding the F1-Score and 1.2% for the AUROC.
Transformer +KNN +v-att. +att-bsim +att-bsim-bvalF1-Score (↑)56.256.155.758.653.9AUROC (↑)83.483.183.184.482.1</p>
<p>Table 2 :
2
Comparison of the F1-score (↑) of transformer+attention-bsim across values of .Here −1 stands for H = C.Some values are N/A either because it is not relevant to compute or when there are not enough samples in the training set for the selected value of .
𝑘052550200500−1transformer+attention-bsimAbalone42.5±7.8 53.0±6.4 54.9±5.4 55.0±5.4 52.0±5.6 54.0±6.5 53.0±5.7Satellite65.6±3.3 71.5±2.4 71.3±1.3 71.2±1.6 70.8±1.8 71.2±1.7 71.9±1.5Lympho88.3±7.6 91.7±8.3 93.3±8.2 91.7±8.3N/AN/A90.0±8.1Satimage89.0±4.1 88.8±3.8 88.4±3.8 89.4±4.2 88.8±4.3 89.1±4.3 93.2±1.7Thyroid55.5±4.8 56.9±5.3 55.9±5.2 56.3±5.2 56.4±5.2 55.9±5.6 55.8±6.3Cardio81.0±4.1 81.2±1.6 81.9±1.4 81.9±1.4 81.9±1.4 81.9±1.4 80.6±2.4Ionosphere 88.1±2.8 89.4±5.0 90.2±4.5 89.8±4.3N/AN/A91.7±2.1mean70.376.176.676.570.070.476.6mean std4.94.74.34.33.73.94.0</p>
<p>Table 3 :
3
Share (%) of each class correctly identified (↑).Average over 5 data splits.The Table should be read as follows: On average, the transformer correctly classified 78.5% of type 1 anomalies as anomalies.
NormalAnomaliesAnomalies(type 1)(type 2)Mask-KNN 93.0% (±0.4) 100.0%(±0.0) 77.3%(±4.4)Transformer 91.4% (±1.4) 78.5%(±1.0) 100.0%(±0.0)+att-bsim 94.6% (±0.5) 88.0%(±0.8) 100.0%(±0.0)</p>
<p>Table 4 :
4
Comparison of the performance of the transformer + attention-bsim model for different retrieval module architecture based on the F1-score (↑).
Retrievalpost-enc post-emb post-embAggregation post-enc post-enc post-embAbalone53.0±5.747.0±7.630.5±14Satellite71.9±1.560.5±0.965.1±2.3Lympho90.0±8.191.6±8.384.2±11.1Satimage93.2±1.750.8±17.0 65.9±15.3Thyroid55.8±6.355.2±5.958.1±5.0Ionosphere91.7±2.188.2±1.491.3±2.0mean75.965.665.9mean std4.26.98.3</p>
<p>Table 5 :
5
Comparison of transformer+attention-bsim across values of  based on the F1-Score (↑).
𝜆00.10.20.30.40.50.60.7Abalone 42.5 44.34747.3 46.55346.5 45.8Satellite 65.6727272.57371.9 73.5 73.4Lympho 88.3 90.8 90.8 91.7 92.59091.790Satim.8994.5 94.6 94.1 94.1 93.2 93.8 94.1Thyroid 55.5 57.2 57.4 56.6 56.6 55.8 57.1 57.3Cardio 68.8 80.9 80.6 80.9 80.9 80.9 80.9 80.7Ionosp. 88.1 90.3 92.1 92.2 91.2 91.7 92.3 91.7mean71.1 75.7 76.4 76.5 76.4 76.6 76.5 76.1</p>
<p>Table 6 :
6
Comparison of the performance of the transformer + attention-bsim model based on the F1-Score (↑) for two mask bank set-ups.The same model was used for inference in both set-ups.We report an average over 10 different splits of the data.
Mask bank random deterministicAbalone43.0±14.953.0±5.7Satellite58.4±5.571.9±1.5Lympho86.7±8.590.0±8.1Satimage47.7±20.593.2±1.7Thyroid55.6±6.155.8±6.3Cardio81.3±1.680.6±2.4Ionosphere 85.2±4.391.7±2.1mean65.476.6mean std8.84.0</p>
<p>Table 7 :
7
Datasets characteristics
Dataset𝑛𝑑OutliersWine1291310 (7.7%)Lympho148186 (4.1%)Glass21499 (4.2%)Vertebral240630 (12.5%)WBC2783021 (5.6%)Ecoli33679 (2.6%)Ionosphere35133126 (36%)Arrhythmia45227466 (15%)BreastW6839239 (35%)Pima7688268 (35%)Vowels14561250 (3.4%)Letter Recognition160032100 (6.25%)Cardio183121176 (9.6%)Seismic258411170 (6.5%)Musk306216697 (3.2%)Speech368640061 (1.65%)Thyroid3772693 (2.5%)Abalone4177929 (0.69%)Optdigits521664150 (3%)Satimage-258033671 (1.2%)Satellite6435362036 (32%)Pendigits687016156 (2.27%)Annthyroid72006534 (7.42%)Mnist7603100700 (9.2%)Mammography111836260 (2.32%)Shuttle4909793511 (7%)Mulcross262144426214 (10%)ForestCover286048 102747 (0.9%)Campaign4118862 4640 (11.3%)Fraud284807 29492 (0.17%)Backdoor95329 196 2329 (2.44%)</p>
<p>Table 8 :
8
Anomaly detection F1-score (↑).We perform 5% T-test to test whether the difference between the highest metrics for each dataset is statistically significant.
MethodTransformer+KNN+v-att. +att-bsim +att-bsim-bvalWine23.5±7.924.9±5.926.5±7.329.0±7.727.0±5.6Lympho88.3±7.689.2±7.988.3±9.390.0±8.189.1±7.9Glass14.4±6.112.8±3.912.2±3.312.8±3.911.1±0.1Verteb.12.3±5.215.7±2.812.7±4.114.3±2.613.5±5.1Wbc66.4±3.265.2±4.066.2±5.265.5±4.467.9±4.2Ecoli75.0±9.975.6±7.5 75.6±9.773.8±8.075.0±9.7Ionosph.88.1±2.885.7±3.486.0±4.791.7±2.179.3±1.6Arrhyth.59.8±2.260.3±2.260.2±2.761.2±2.161.1±2.8Breastw96.7±0.396.7±0.396.8±0.396.7±0.396.7±0.3Pima65.6±2.064.7±3.164.0±3.364.3±2.467.0±1.5Vowels28.7±8.040.0±10.0 49.1±11.144.5±10.558.0±11.2Letter41.5±6.232.9±11.8 41.8±11.5 43.7±10.328.5±7.1Cardio68.8±2.865.6±3.662.8±6.967.7±3.768.3±4.5Seismic19.1±5.717.4±5.519.5±6.316.7±5.517.5±5.4Musk100±0.0100±0.0100±0.0100±0.0100±0.0Speech6.8±1.96.3±1.45.7±1.75.9±1.55.9±1.7Thyroid55.5±4.855.5±4.956.0±5.955.8±6.355.3±6.6Abalone42.5±7.842.5±9.549.8±6.553.0±5.743.2±9.1Optdig.61.1±4.770.7±16.5 51.5±7.662.6±6.522.8±5Satimage289.0±4.186.8±0.490.7±2.693.2±1.764.2±7.2Satellite65.6±3.358.6±2.957.3±3.071.9±1.553.7±3.3Pendig.35.4±10.952.1±9.0 39.0±14.553.4±9.834.2±12.2Annthyr.29.9±1.530.4±1.9 30.3±1.530.3±1.630.5±1.4Mnist56.7±5.764.2±3.761.7±1.061.6±1.056.7±1.9Mammo.17.4±2.217.3±2.415.5±2.517.2±3.017.7±2.7Shuttle85.3±9.890.8±2.9 67.7±13.787.8±3.795.6±1.8Mullcr.100±0.0100±0.0100±0.0100±0.0100±0.0Forest21.3±3.118.6±4.621.0±5.924.9±6.511.1±4.1Camp.47.0±1.948.5±2.143.3±2.349.7±1.249.1±1.1Fraud53.4±4.456.4±2, 156.3±2.157.1±2.155.2±1.8Backd.85.8±0.686.1± 0.6 85.2± 0.785.3± 0.682.4± 1.3mean56.256.155.758.653.9mean std4.44.65.03.73.7</p>
<p>Table 9 :
9
Anomaly detection AUROC(↑).We perform 5% T-test to test whether the differences between the highest metrics for each dataset are statistically significant.
MethodTransformer+KNN+v-att. +att-bsim +att-bsim-bvalWine61.4±6.760.4±5.4 62.1±6.463.5±7.864.5±5.6Lympho99.5±0.499.6±0.4 99.6±0.599.7±0.399.7±0.3Glass61.2±7.061.2±5.0 62.1±7.059.3±6.959.1±5.8Vertebral44.8±5.246.7±4.1 45.3±7.145.4±3.745.4±4.7WBC95.0±1.194.3±1.5 94.3±1.694.2±1.195.5±1.6Ecoli84.8±1.684.8±1.8 85.2±2.787.4±1.885.4±2.3Ionosph.95.4±1.993.7±2.7 93.6±4.097.5±0.187.2±2.3Arrhyth.81.7±1.181.9±0.9 81.8±0.982.3±0.782.1±0.9Breastw99.6±0.199.6±0.1 99.6±0.199.6±0.199.6±0.1Pima67.2±2.466.0±3.8 65.4±3.865.8±2.968.7±1.4Vowels78.4±9.286.1±5.2 90.4±4.788.3±4.594.3±2.8Letter80.5±4.873.5±9.6 81.0±8.781.5±6.869.1±7.7Cardio93.5±1.392.0±1.7 89.9±4.293.3±1.793.7±1.3Seismic58.2±7.956.8±8.4 57.9±7.658.0±6.754.8±6.2Musk100±0.0100±0.0 100±0.0100±0.0100±0.0Speech47.2±0.747.3±0.8 47.3±0.847.3±0.847.0±0.5Thyroid93.8±1.293.8±1.2 93.6±5.993.7±1.593.6±1.8Abalone88.3±2.086.1±3.6 88.0±3.587.9±3.786.6±2.9Optdig.96.4±4.796.2±9.8 94.9±1.796.7±1.183.4±3.2Satimage99.7±0.199.5±0.2 99.6±0.299.8±0.196.8±1.9Satellite73.8±2.568.9±2.0 67.8±2.579.5±1.962.0±2.9Pendigits93.8±2.696.5±1.4 94.1±2.897.1±1.289.4±7.1Annthyr.65.4±1.466.0±1.7 66.2±1.366.2±1.666.0±1.1Mnist87.4±3.290.3±2.2 89.9±0.490.0±0.587.3±1.0Mammo.77.6±1.076.8±2.4 75.2±2.978.4±1.679.8±1.8Mullcross100±0.0100±0.0 100±0.0100±0.0100±0.0Shuttle97.2±2.298.1±0.5 90.2±6.197.7±0.998.9±0.3Forest95.1±0.894.5±0.7 95.0±1.095.4±0.992.7±0.7Campaign75.3±2.175.7±1.9 69.3±2.076.1±2.075.9±2.1Fraud94.7±0.495.1±0.4 95.2±0.495.8±0.494.7±0.4Backdoor95.1±0.295.2±0.3 94.5±0.294.7±0.191.7±0.3mean83.483.183.184.482.1mean std2.42.82.62.02.3
For large datasets, we resort to a random subsample of the training set for computational reasons.
http://odds.cs.stonybrook.edu/
https://github.com/hugothimonier/Retrieval-Augmented-Deep-Anomaly-Detection-for-Tabular-Data
ACKNOWLEDGMENTThis work was granted access to the HPC resources of IDRIS under the allocation 2023-101424 made by GENCI.This research publication is supported by the Chair "Artificial intelligence applied to credit card fraud detection and automated trading" led by Centrale-Supelec and sponsored by the LUSIS company.B.2 Synthetic dataset generation and experimental detail for section 5.1The synthetic three dimensional dataset was generated as follows.• Normal samples: We consider an interval of values [−2, 3] from which we uniformly sample the first feature  1 .We then sample  2 ,  3 following the relation given in eq. (12) with parameters, ( 1 ,  1 ) = (2, 3), ( 2 ,  2 ) = (4, 3) and  ∼ N (0, 1).• Anomalies (type 1): We consider an interval of values[3.3, 4]from which we uniformly sample the first feature  1 and keep the rest as for normal samples.• Anomalies (type 2): We consider an interval of values [1.5, 2.5] from which we uniformly sample the first feature  1 and sample  2 ,  3 following eq.(12) but with parameters ( 1 ,  1 ) = (−7.5,−1) and ( 2 ,  2 ) = (4, 3).The vanilla transformer and its augmented version were trained with the following hyperparameters:• Batch size: −1.• Patience: 100 epochs.• Learning rate (lr): 0.001.• Hidden dim (): 8.• Masking probability   : 0.15.• Number of attention heads: 2.• Number of layers of the encoder: 2.• Retrieval hyper-parameters:-Retrieval location: post-encoder -Retrieval aggregation location: post-encoder -: 0.5 -C = D  - (H ) = 500 For Mask-KNN, following[34]we set the number of neighbors to  = 5.
TabNet: Attentive Interpretable Tabular Learning. Ö Sercan, Tomas Arik, Pfister, 10.1609/aaai.v35i8.16826Thirty-Fifth AAAI Conference on Artificial Intelligence, AAAI 2021, Thirty-Third Conference on Innovative Applications of Artificial Intelligence, IAAI 2021, The Eleventh Symposium on Educational Advances in Artificial Intelligence, EAAI 2021, Virtual Event. AAAI Press2021. February 2-9, 2021</p>
<p>CNN-BiLSTM: A Hybrid Deep Learning Approach for Network Intrusion Detection System in Software-Defined Networking With Hybrid Feature Selection. Rachid Ben Said, Zakaria Sabir, Iman Askerzade, 10.1109/ACCESS.2023.3340142IEEE Access. 112023. 2023</p>
<p>Classification-Based Anomaly Detection for General Data. Liron Bergman, Yedid Hoshen, International Conference on Learning Representations. 2020</p>
<p>Retrieval-Augmented Diffusion Models. Andreas Blattmann, Robin Rombach, Kaan Oktay, Jonas Müller, Björn Ommer, Advances in Neural Information Processing Systems. S Koyejo, A Mohamed, D Agarwal, K Belgrave, A Cho, Oh, Curran Associates, Inc202235</p>
<p>LOF: Identifying Density-Based Local Outliers. Markus M Breunig, Hans-Peter Kriegel, Raymond T Ng, Jörg Sander, 10.1145/335191.335388SIGMOD Rec. 2922000. may 2000</p>
<p>Unsupervised Detection of Lesions in Brain MRI using constrained adversarial auto-encoders. Xiaoran Chen, Ender Konukoglu, Medical Imaging with Deep Learning. 2018</p>
<p>Decoupling Knowledge from Memorization: Retrieval-augmented Prompt Learning. Xiang Chen, Lei Li, Ningyu Zhang, Xiaozhuan Liang, Shumin Deng, Chuanqi Tan, Fei Huang, Luo Si, Huajun Chen, Advances in Neural Information Processing Systems. S Koyejo, A Mohamed, D Agarwal, K Belgrave, A Cho, Oh, Curran Associates, Inc202235</p>
<p>PIDForest: Anomaly Detection and Certification via Partial Identification. Parikshit Gopalan, Sharan Vatsal, Udi Wieder, Neural Information Processing Systems. 2019202766416</p>
<p>Akim Kotelnikov, and Artem Babenko. Yury Gorishniy, Ivan Rubachev, Nikolay Kartashev, Daniil Shlenskii, arXiv:2307.14338[cs.LG]TabR: Tabular Deep Learning Meets Nearest Neighbors in 2023. 2023</p>
<p>DROCC: Deep Robust One-Class Classification. Sachin Goyal, Aditi Raghunathan, Moksh Jain, Harsha Vardhan Simhadri, Prateek Jain, Proceedings of the 37th International Conference on Machine Learning (Proceedings of Machine Learning Research. Hal Daumé, Iii , Aarti Singh, the 37th International Conference on Machine Learning ( Machine Learning Research2020119</p>
<p>Why do tree-based models still outperform deep learning on typical tabular data?. Leo Grinsztajn, Edouard Oyallon, Gael Varoquaux, Thirty-sixth Conference on Neural Information Processing Systems Datasets and Benchmarks Track. 2022</p>
<p>Robust Random Cut Forest Based Anomaly Detection on Streams. Sudipto Guha, Nina Mishra, Gourav Roy, Okke Schrijvers, International Conference on Machine Learning. 2016</p>
<p>ADBench: Anomaly Detection Benchmark. Songqiao Han, Xiyang Hu, Hailiang Huang, Minqi Jiang, Yue Zhao, Thirty-sixth Conference on Neural Information Processing Systems Datasets and Benchmarks Track. 2022</p>
<p>Extended Isolation Forest. Sahand Hariri, Matias Carrasco Kind, Robert J Brunner, 10.1109/TKDE.2019.2947676IEEE Transactions on Knowledge and Data Engineering. 332021. 2021</p>
<p>Financial Fraud: A Review of Anomaly Detection Techniques and Recent Advances. Waleed Hilal, S Andrew Gadsden, John Yawney, 10.1016/j.eswa.2021.116429Expert Systems with Applications. 1931164292022. 2022</p>
<p>RaPP: Novelty Detection with Reconstruction along Projection Pathway. Hyun Ki, Sangwoo Kim, Yongsub Shim, Jongseob Lim, Jeongwoo Jeon, Byungchan Choi, Andre S Kim, Yoon, International Conference on Learning Representations. 2020</p>
<p>Self-Attention Between Datapoints: Going Beyond Individual Input-Output Pairs in Deep Learning. Jannik Kossen, Neil Band, Clare Lyle, Aidan Gomez, Tom Rainforth, Yarin Gal, Advances in Neural Information Processing Systems. Y Beygelzimer, P Dauphin, J Wortman Liang, Vaughan, 2021</p>
<p>COPOD: Copula-Based Outlier Detection. Zheng Li, Yue Zhao, Nicola Botta, Cezar Ionescu, Xiyang Hu, 10.1109/icdm50108.2020.001352020 IEEE International Conference on Data Mining (ICDM). IEEE. 2020</p>
<p>Unsupervised Cross-Task Generalization via Retrieval Augmentation. Kangmin Bill Yuchen Lin, Chris Tan, Beiwen Miller, Xiang Tian, Ren, Advances in Neural Information Processing Systems. S Koyejo, A Mohamed, D Agarwal, K Belgrave, A Cho, Oh, Curran Associates, Inc202235</p>
<p>Unsupervised Anomaly Detection by Robust Density Estimation. Boyang Liu, Pang-Ning Tan, Jiayu Zhou, 10.1609/aaai.v36i4.20328Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence2022. Jun. 202236</p>
<p>Isolation Forest. Tony Fei, Kai Ming Liu, Zhi-Hua Ting, Zhou, 10.1109/ICDM.2008.172008 Eighth IEEE International Conference on Data Mining. 2008</p>
<p>Neural Transformation Learning for Deep Anomaly Detection Beyond Images. Chen Qiu, Timo Pfrommer, Marius Kloft, Stephan Mandt, Maja Rudolph, Proceedings of the 38th International Conference on Machine Learning, ICML 2021. Marina Meila, Tong Zhang, the 38th International Conference on Machine Learning, ICML 2021PMLR2021. 18-24 July 2021139Virtual Event (Proceedings of Machine Learning Research</p>
<p>Efficient Algorithms for Mining Outliers from Large Data Sets. Sridhar Ramaswamy, Rajeev Rastogi, Kyuseok Shim, 10.1145/342009.335437Proceedings of the 2000 ACM SIGMOD International Conference on Management of Data. Weidong Chen, Jeffrey F Naughton, Philip A Bernstein, the 2000 ACM SIGMOD International Conference on Management of DataDallas, Texas, USAACM2000. May 16-18, 2000</p>
<p>Mean-Shifted Contrastive Loss for Anomaly Detection. Tal Reiss, Yedid Hoshen, 10.1609/aaai.v37i2.25309Proceedings of the Thirty-Seventh AAAI Conference on Artificial Intelligence and Thirty-Fifth Conference on Innovative Applications of Artificial Intelligence and Thirteenth Symposium on Educational Advances in Artificial Intelligence (AAAI'23/IAAI'23/EAAI'23). the Thirty-Seventh AAAI Conference on Artificial Intelligence and Thirty-Fifth Conference on Innovative Applications of Artificial Intelligence and Thirteenth Symposium on Educational Advances in Artificial Intelligence (AAAI'23/IAAI'23/EAAI'23)AAAI Press2023240</p>
<p>A Unifying Review of Deep and Shallow Anomaly Detection. Lukas Ruff, Jacob R Kauffmann, Robert A Vandermeulen, Grégoire Montavon, Wojciech Samek, Marius Kloft, Thomas G Dietterich, Klaus-Robert Müller, arXiv:2009.11732Proc. IEEE. 10952021. May 2021</p>
<p>Deep One-Class Classification. Lukas Ruff, Robert Vandermeulen, Nico Goernitz, Lucas Deecke, Ahmed Shoaib, Alexander Siddiqui, Emmanuel Binder, Marius Müller, Kloft, PMLR, 4393-4402Proceedings of the 35th International Conference on Machine Learning (Proceedings of Machine Learning Research. the 35th International Conference on Machine Learning ( Machine Learning Research201880</p>
<p>Unsupervised Anomaly Detection with Generative Adversarial Networks to Guide Marker Discovery. Thomas Schlegl, Philipp Seeböck, Sebastian M Waldstein, Ursula Schmidt-Erfurth, Georg Langs, Information Processing in Medical Imaging. Marc Niethammer, Martin Styner, Stephen Aylward, Hongtu Zhu, Ipek Oguz, Pew-Thian Yap, Dinggang Shen, ChamSpringer International Publishing2017</p>
<p>Support Vector Method for Novelty Detection. Bernhard Schölkopf, Robert Williamson, Alex Smola, John Shawe-Taylor, John Platt, Proceedings of the 12th International Conference on Neural Information Processing Systems. the 12th International Conference on Neural Information Processing SystemsDenver, CO; Cambridge, MA, USAMIT Press1999NIPS'99)</p>
<p>Anomaly Detection for Tabular Data with Internal Contrastive Learning. Ira Shavitt, Eran Segal, ; S Bengio, H Wallach, H Larochelle, K Grauman, N , International Conference on Learning Representations. R Cesa-Bianchi, Garnett, Tom Shenkar and Lior Wolf2018. 202231Advances in Neural Information Processing Systems</p>
<p>Learning and Evaluating Representations for Deep One-Class Classification. Kihyuk Sohn, Chun-Liang Li, Jinsung Yoon, Minho Jin, Tomas Pfister, International Conference on Learning Representations. 2021</p>
<p>SAINT: Improved Neural Networks for Tabular Data via Row Attention and Contrastive Pre-Training. Gowthami Somepalli, Micah Goldblum, Avi Schwarzschild, C Bayan Bruss, Tom Goldstein, arXiv:2106.013422021. 2021</p>
<p>Support Vector Data Description. David Tax, Robert Duin, 10.1023/B:MACH.0000008084.60811.49Machine Learning. 542004. 01 2004</p>
<p>Beyond Individual Input for Deep Anomaly Detection on Tabular Data. Hugo Thimonier, Fabrice Popineau, Arpad Rimmel, Bich-Liên Doan, Proceedings of the 41st International Conference on Machine Learning, ICML 2024. Proceedings of Machine Learning Research. the 41st International Conference on Machine Learning, ICML 2024Vienna, AustriaPMLR2024. 21-27 July 2024235</p>
<p>Hugo Thimonier, Fabrice Popineau, Arpad Rimmel, Fabrice Bich-Liên Doan, Daniel, arXiv:2312.13896[cs.LG]Comparative Evaluation of Anomaly Detection Methods for Fraud Detection in Online Credit Card Payments. 2023</p>
<p>Attention is All you Need. Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Ł Kaiser, Illia Polosukhin, Advances in Neural Information Processing Systems. I Guyon, U Von Luxburg, S Bengio, H Wallach, R Fergus, S Vishwanathan, R Garnett, Curran Associates, Inc201730</p>
<p>Anomaly detection for medical images based on a one-class classification. Qi Wei, Yinhao Ren, Rui Hou, Bibo Shi, Joseph Y Lo, Lawrence Carin, 10.1117/12.2293408International Society for Optics and Photonics, SPIE, 105751M. Nicholas Petrick, Kensaku Mori, 2018. 201810575In Medical Imaging</p>
<p>Diffusion Models for Medical Anomaly Detection. Julia Wolleb, Florentin Bieder, Robin Sandkühler, Philippe C Cattin, Medical Image Computing and Computer Assisted Intervention -MICCAI 2022. Linwei Wang, Qi Dou, P Thomas Fletcher, Stefanie Speidel, Shuo Li, Nature Switzerland, ChamSpringer2022</p>
<p>Classification of imbalanced data: a review. Sun Yanmin, Andrew Wong, Mohamed S Kamel, 10.1142/S0218001409007326International Journal of Pattern Recognition and Artificial Intelligence. 232011. 11 2011</p>
<p>Large Batch Optimization for Deep Learning: Training BERT in 76 minutes. Yang You, Jing Li, Sashank Reddi, Jonathan Hseu, Sanjiv Kumar, Srinadh Bhojanapalli, Xiaodan Song, James Demmel, Kurt Keutzer, Cho-Jui Hsieh, International Conference on Learning Representations. 2020</p>
<p>Deep Structured Energy Based Models for Anomaly Detection. Shuangfei Zhai, Yu Cheng, Weining Lu, Zhongfei Zhang, Proceedings of The 33rd International Conference on Machine Learning (Proceedings of Machine Learning Research. Maria , Florina Balcan, Kilian Q Weinberger, The 33rd International Conference on Machine Learning ( Machine Learning ResearchNew York, New York, USAPMLR201648</p>
<p>Hui Zhang, Zheng Wang, Zuxuan Wu, Yu-Gang Jiang, arXiv:2303.08730[cs.CV]Diffu-sionAD: Norm-guided One-step Denoising Diffusion for Anomaly Detection. 2023</p>
<p>Lookahead Optimizer: k steps forward, 1 step back. Michael Zhang, James Lucas, Jimmy Ba, Geoffrey E Hinton, Advances in Neural Information Processing Systems. H Wallach, H Larochelle, A Beygelzimer, F Alché-Buc, E Fox, R Garnett, Curran Associates, Inc201932</p>
<p>Deep Autoencoding Gaussian Mixture Model for Unsupervised Anomaly Detection. Bo Zong, Qi Song, Martin Renqiang Min, Wei Cheng, Cristian Lumezanu, Daeki Cho, Haifeng Chen, International Conference on Learning Representations. 2018</p>            </div>
        </div>

    </div>
</body>
</html>