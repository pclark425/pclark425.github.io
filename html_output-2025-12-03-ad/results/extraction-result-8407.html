<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-8407 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-8407</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-8407</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-150.html">extraction-schema-150</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve tasks, including details of the memory mechanism, tasks, comparative results, ablations, and key findings.</div>
                <p><strong>Paper ID:</strong> paper-2cbb8de53759e75411bc528518947a3094fbce3a</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/2cbb8de53759e75411bc528518947a3094fbce3a" target="_blank">Billion-Scale Similarity Search with GPUs</a></p>
                <p><strong>Paper Venue:</strong> IEEE Transactions on Big Data</p>
                <p><strong>Paper TL;DR:</strong> This paper proposes a novel design for an inline-formula that enables the construction of a high accuracy, brute-force, approximate and compressed-domain search based on product quantization, and applies it in different similarity search scenarios.</p>
                <p><strong>Paper Abstract:</strong> Similarity search finds application in database systems handling complex data such as images or videos, which are typically represented by high-dimensional features and require specific indexing structures. This paper tackles the problem of better utilizing GPUs for this task. While GPUs excel at data parallel tasks such as distance computation, prior approaches in this domain are bottlenecked by algorithms that expose less parallelism, such as <inline-formula><tex-math notation="LaTeX">$k$</tex-math><alternatives><mml:math><mml:mi>k</mml:mi></mml:math><inline-graphic xlink:href="johnson-ieq1-2921572.gif"/></alternatives></inline-formula>-min selection, or make poor use of the memory hierarchy. We propose a novel design for <inline-formula><tex-math notation="LaTeX">$k$</tex-math><alternatives><mml:math><mml:mi>k</mml:mi></mml:math><inline-graphic xlink:href="johnson-ieq2-2921572.gif"/></alternatives></inline-formula>-selection. We apply it in different similarity search scenarios, by optimizing brute-force, approximate and compressed-domain search based on product quantization. In all these setups, we outperform the state of the art by large margins. Our implementation operates at up to 55 percent of theoretical peak performance, enabling a nearest neighbor implementation that is 8.5 × faster than prior GPU state of the art. It enables the construction of a high accuracy <inline-formula><tex-math notation="LaTeX">$k$</tex-math><alternatives><mml:math><mml:mi>k</mml:mi></mml:math><inline-graphic xlink:href="johnson-ieq3-2921572.gif"/></alternatives></inline-formula>-NN graph on 95 million images from the <sc>Yfcc100M</sc> dataset in 35 minutes, and of a graph connecting 1 billion vectors in less than 12 hours on 4 Maxwell Titan X GPUs. We have open-sourced our approach for the sake of comparison and reproducibility.</p>
                <p><strong>Cost:</strong> 0.006</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <p class="empty-note">No extracted data.</p>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <p class="empty-note">No potentially relevant new papers extracted.</p>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-8407",
    "paper_id": "paper-2cbb8de53759e75411bc528518947a3094fbce3a",
    "extraction_schema_id": "extraction-schema-150",
    "extracted_data": [],
    "potentially_relevant_new_papers": [],
    "cost": 0.00582425,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>Billion-scale similarity search with GPUs</h1>
<p>Jeff Johnson<br>Facebook AI Research New York</p>
<p>Matthijs Douze<br>Facebook AI Research Paris</p>
<p>Hervé Jégou<br>Facebook AI Research<br>Paris</p>
<h2>ABSTRACT</h2>
<p>Similarity search finds application in specialized database systems handling complex data such as images or videos, which are typically represented by high-dimensional features and require specific indexing structures. This paper tackles the problem of better utilizing GPUs for this task. While GPUs excel at data-parallel tasks, prior approaches are bottlenecked by algorithms that expose less parallelism, such as $k$-min selection, or make poor use of the memory hierarchy.</p>
<p>We propose a design for $k$-selection that operates at up to $55 \%$ of theoretical peak performance, enabling a nearest neighbor implementation that is $8.5 \times$ faster than prior GPU state of the art. We apply it in different similarity search scenarios, by proposing optimized design for brute-force, approximate and compressed-domain search based on product quantization. In all these setups, we outperform the state of the art by large margins. Our implementation enables the construction of a high accuracy $k$-NN graph on 95 million images from the YFCC100M dataset in 35 minutes, and of a graph connecting 1 billion vectors in less than 12 hours on 4 Maxwell Titan X GPUs. We have open-sourced our approach ${ }^{1}$ for the sake of comparison and reproducibility.</p>
<h2>1. INTRODUCTION</h2>
<p>Images and videos constitute a new massive source of data for indexing and search. Extensive metadata for this content is often not available. Search and interpretation of this and other human-generated content, like text, is difficult and important. A variety of machine learning and deep learning algorithms are being used to interpret and classify these complex, real-world entities. Popular examples include the text representation known as word2vec [32], representations of images by convolutional neural networks [39, 19], and image descriptors for instance search [20]. Such representations or embeddings are usually real-valued, high-dimensional vectors of 50 to $1000+$ dimensions. Many of these vector representations can only effectively be produced on GPU systems,</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup>as the underlying processes either have high arithmetic complexity and/or high data bandwidth demands [28], or cannot be effectively partitioned without failing due to communication overhead or representation quality [38]. Once produced, their manipulation is itself arithmetically intensive. However, how to utilize GPU assets is not straightforward. More generally, how to exploit new heterogeneous architectures is a key subject for the database community [9].</p>
<p>In this context, searching by numerical similarity rather than via structured relations is more suitable. This could be to find the most similar content to a picture, or to find the vectors that have the highest response to a linear classifier on all vectors of a collection.</p>
<p>One of the most expensive operations to be performed on large collections is to compute a $k$-NN graph. It is a directed graph where each vector of the database is a node and each edge connects a node to its $k$ nearest neighbors. This is our flagship application. Note, state of the art methods like NN-Descent [15] have a large memory overhead on top of the dataset itself and cannot readily scale to the billion-sized databases we consider.</p>
<p>Such applications must deal with the curse of dimensionality [46], rendering both exhaustive search or exact indexing for non-exhaustive search impractical on billion-scale databases. This is why there is a large body of work on approximate search and/or graph construction. To handle huge datasets that do not fit in RAM, several approaches employ an internal compressed representation of the vectors using an encoding. This is especially convenient for memory-limited devices like GPUs. It turns out that accepting a minimal accuracy loss results in orders of magnitude of compression [21]. The most popular vector compression methods can be classified into either binary codes [18, 22], or quantization methods [25, 37]. Both have the desirable property that searching neighbors does not require reconstructing the vectors.</p>
<p>Our paper focuses on methods based on product quantization (PQ) codes, as these were shown to be more effective than binary codes [34]. In addition, binary codes incur important overheads for non-exhaustive search methods [35]. Several improvements were proposed after the original product quantization proposal known as IVFADC [25]; most are difficult to implement efficiently on GPU. For instance, the inverted multi-index [4], useful for high-speed/low-quality operating points, depends on a complicated "multi-sequence" algorithm. The optimized product quantization or OPQ [17] is a linear transformation on the input vectors that improves the accuracy of the product quantization; it can be applied</p>
<p>as a pre-processing. The SIMD-optimized IVFADC implementation from [2] operates only with sub-optimal parameters (few coarse quantization centroids). Many other methods, like LOPQ and the Polysemous codes [27, 16] are too complex to be implemented efficiently on GPUs.</p>
<p>There are many implementations of similarity search on GPUs, but mostly with binary codes [36], small datasets [44], or exhaustive search [14, 40, 41]. To the best of our knowledge, only the work by Wieschollek et al. [47] appears suitable for billion-scale datasets with quantization codes. This is the prior state of the art on GPUs, which we compare against in Section 6.4.</p>
<p>This paper makes the following contributions:</p>
<ul>
<li>a GPU $k$-selection algorithm, operating in fast register memory and flexible enough to be fusable with other kernels, for which we provide a complexity analysis;</li>
<li>a near-optimal algorithmic layout for exact and approximate $k$-nearest neighbor search on GPU;</li>
<li>a range of experiments that show that these improvements outperform previous art by a large margin on mid- to large-scale nearest-neighbor search tasks, in single or multi-GPU configurations.</li>
</ul>
<p>The paper is organized as follows. Section 2 introduces the context and notation. Section 3 reviews GPU architecture and discusses problems appearing when using it for similarity search. Section 4 introduces one of our main contributions, i.e., our k-selection method for GPUs, while Section 5 provides details regarding the algorithm computation layout. Finally, Section 6 provides extensive experiments for our approach, compares it to the state of the art, and shows concrete use cases for image collections.</p>
<h2>2. PROBLEM STATEMENT</h2>
<p>We are concerned with similarity search in vector collections. Given the query vector $x \in \mathbb{R}^{d}$ and the collection ${ }^{2}$ $\left[y_{i}\right]<em i="i">{i=0: \ell}\left(y</em>\right)$, we search:} \in \mathbb{R}^{d</p>
<p>$$
L=k \text {-argmin }<em i="i">{i=0: \ell}\left|x-y</em>
$$}\right|_{2</p>
<p>i.e., we search the $k$ nearest neighbors of $x$ in terms of L2 distance. The L2 distance is used most often, as it is optimized by design when learning several embeddings (e.g., [20]), due to its attractive linear algebra properties.</p>
<p>The lowest distances are collected by $k$-selection. For an array $\left[a_{i}\right]<em s__i="s_{i">{i=0: \ell}, k$-selection finds the $k$ lowest valued elements $\left[a</em>\right]}<em s__i="s_{i">{i=0: k}, a</em>\right]}} \leq a_{s_{i+1}}$, along with the indices $\left[s_{i<em i="i">{i=0: k}, 0 \leq$ $s</em>$ is not specified.}&lt;\ell$, of those elements from the input array. The $a_{i}$ will be 32-bit floating point values; the $s_{i}$ are 32 - or 64 -bit integers. Other comparators are sometimes desired; e.g., for cosine similarity we search for highest values. The order between equivalent keys $a_{s_{i}}=a_{s_{j}</p>
<p>Batching. Typically, searches are performed in batches of $n_{\mathrm{q}}$ query vectors $\left[x_{j}\right]<em _mathrm_q="\mathrm{q">{j=0: n</em> \geq k$.}}}\left(x_{j} \in \mathbb{R}^{d}\right)$ in parallel, which allows for more flexibility when executing on multiple CPU threads or on GPU. Batching for $k$-selection entails selecting $n_{\mathrm{q}} \times k$ elements and indices from $n_{\mathrm{q}}$ separate arrays, where each array is of a potentially different length $\ell_{i</p>
<p><sup id="fnref2:0"><a class="footnote-ref" href="#fn:0">1</a></sup>Exact search. The exact solution computes the full pairwise distance matrix $D=\left[\left|x_{j}-y_{i}\right|<em j="0:" n__mathrm_q="n_{\mathrm{q">{2}^{2}\right]</em>$. In practice, we use the decomposition}}, i=0: \ell} \in \mathbb{R}^{n_{\mathrm{q}} \times \ell</p>
<p>$$
\left|x_{j}-y_{i}\right|<em j="j">{2}^{2}=\left|x</em>\right\rangle
$$}\right|^{2}+\left|y_{i}\right|^{2}-2\left\langle x_{j}, y_{i</p>
<p>The two first terms can be precomputed in one pass over the matrices $X$ and $Y$ whose rows are the $\left[x_{j}\right]$ and $\left[y_{i}\right]$. The bottleneck is to evaluate $\left\langle x_{j}, y_{i}\right\rangle$, equivalent to the matrix multiplication $X Y^{\top}$. The $k$-nearest neighbors for each of the $n_{q}$ queries are $k$-selected along each row of $D$.
Compressed-domain search. From now on, we focus on approximate nearest-neighbor search. We consider, in particular, the IVFADC indexing structure [25]. The IVFADC index relies on two levels of quantization, and the database vectors are encoded. The database vector $y$ is approximated as:</p>
<p>$$
y \approx q(y)=q_{1}(y)+q_{2}\left(y-q_{1}(y)\right)
$$</p>
<p>where $q_{1}: \mathbb{R}^{d} \rightarrow \mathcal{C}<em 2="2">{1} \subset \mathbb{R}^{d}$ and $q</em>}: \mathbb{R}^{d} \rightarrow \mathcal{C<em 1="1">{2} \subset \mathbb{R}^{d}$ are quantizers; i.e., functions that output an element from a finite set. Since the sets are finite, $q(y)$ is encoded as the index of $q</em>(y)\right)$. The first-level quantizer is a coarse quantizer and the second level fine quantizer encodes the residual vector after the first level.}(y)$ and that of $q_{2}\left(y-q_{1</p>
<p>The Asymmetric Distance Computation (ADC) search method returns an approximate result:</p>
<p>$$
L_{\mathrm{ADC}}=k \text {-argmin }<em i="i">{i=0: \ell}\left|x-q\left(y</em>
$$}\right)\right|_{2</p>
<p>For IVFADC the search is not exhaustive. Vectors for which the distance is computed are pre-selected depending on the first-level quantizer $q_{1}$ :</p>
<p>$$
L_{\mathrm{IVF}}=\tau \text {-argmin }<em 1="1">{c \in \mathcal{C}</em>
$$}}|x-c|_{2</p>
<p>The multi-probe parameter $\tau$ is the number of coarse-level centroids we consider. The quantizer operates a nearestneighbor search with exact distances, in the set of reproduction values. Then, the IVFADC search computes</p>
<p>$$
L_{\mathrm{IVFADC}}=\underset{i=0: \ell \text { s.t. } q_{1}\left(y_{i}\right) \in L_{\mathrm{IVF}}}{\left|\left.k \arg \min <em 1="1">{q</em>
$$}\left(y_{i}\right) \in L_{\mathrm{IVF}}}\right| x-q\left(y_{i}\right)\right|_{2}</p>
<p>Hence, IVFADC relies on the same distance estimations as the two-step quantization of ADC , but computes them only on a subset of vectors.</p>
<p>The corresponding data structure, the inverted file, groups the vectors $y_{i}$ into $\left|\mathcal{C}<em 1="1">{1}\right|$ inverted lists $\mathcal{I}</em>}, \ldots, \mathcal{I<em 1="1">{\left|\mathcal{C}</em>$, and boils down to linearly scanning $\tau$ inverted lists.
The quantizers. The quantizers $q_{1}$ and $q_{2}$ have different properties. $q_{1}$ needs to have a relatively low number of reproduction values so that the number of inverted lists does not explode. We typically use $\left|C_{1}\right| \approx \sqrt{\ell}$, trained via $k$-means. For $q_{2}$, we can afford to spend more memory for a more extensive representation. The ID of the vector (a 4 - or 8 -byte integer) is also stored in the inverted lists, so it makes no sense to have shorter codes than that; i.e., $\log }\right|}$ with homogeneous $q_{1}\left(y_{i}\right)$. Therefore, the most memory-intensive operation is computing $L_{\text {IVFADC }<em 2="2">{2}\left|\mathcal{C}</em>\right|&gt;4 \times 8$.
Product quantizer. We use a product quantizer [25] for $q_{2}$, which provides a large number of reproduction values without increasing the processing cost. It interprets the vector $y$ as $b$ sub-vectors $y=\left[y^{0} \ldots y^{b-1}\right]$, where $b$ is an even divisor of</p>
<p>the dimension $d$. Each sub-vector is quantized with its own quantizer, yielding the tuple $\left(q^{0}\left(y^{0}\right), \ldots, q^{b-1}\left(y^{b-1}\right)\right)$. The sub-quantizers typically have 256 reproduction values, to fit in one byte. The quantization value of the product quantizer is then $q_{2}(y)=q^{0}\left(y^{0}\right)+256 \times q^{1}\left(y^{1}\right)+\ldots+256^{b-1} \times q^{b-1}$, which from a storage point of view is just the concatenation of the bytes produced by each sub-quantizer. Thus, the product quantizer generates $b$-byte codes with $\left|\mathcal{C}_{2}\right|=256^{b}$ reproduction values. The $k$-means dictionaries of the quantizers are small and quantization is computationally cheap.</p>
<h2>3. GPU: OVERVIEW AND K-SELECTION</h2>
<p>This section reviews salient details of Nvidia's generalpurpose GPU architecture and programming model [30]. We then focus on one of the less GPU-compliant parts involved in similarity search, namely the $k$-selection, and discuss the literature and challenges.</p>
<h3>3.1 Architecture</h3>
<p>GPU lanes and warps. The Nvidia GPU is a generalpurpose computer that executes instruction streams using a 32 -wide vector of CUDA threads (the warp); individual threads in the warp are referred to as lanes, with a lane ID from $0-31$. Despite the "thread" terminology, the best analogy to modern vectorized multicore CPUs is that each warp is a separate CPU hardware thread, as the warp shares an instruction counter. Warp lanes taking different execution paths results in warp divergence, reducing performance. Each lane has up to 25532 -bit registers in a shared register file. The CPU analogy is that there are up to 255 vector registers of width 32 , with warp lanes as SIMD vector lanes.</p>
<p>Collections of warps. A user-configurable collection of 1 to 32 warps comprises a block or a co-operative thread array (CTA). Each block has a high speed shared memory, up to 48 KiB in size. Individual CUDA threads have a blockrelative ID, called a thread id, which can be used to partition and assign work. Each block is run on a single core of the GPU called a streaming multiprocessor (SM). Each SM has functional units, including ALUs, memory load/store units, and various special instruction units. A GPU hides execution latencies by having many operations in flight on warps across all SMs. Each individual warp lane instruction throughput is low and latency is high, but the aggregate arithmetic throughput of all SMs together is $5-10 \times$ higher than typical CPUs.</p>
<p>Grids and kernels. Blocks are organized in a grid of blocks in a kernel. Each block is assigned a grid relative ID. The kernel is the unit of work (instruction stream with arguments) scheduled by the host CPU for the GPU to execute. After a block runs through to completion, new blocks can be scheduled. Blocks from different kernels can run concurrently. Ordering between kernels is controllable via ordering primitives such as streams and events.</p>
<p>Resources and occupancy. The number of blocks executing concurrently depends upon shared memory and register resources used by each block. Per-CUDA thread register usage is determined at compilation time, while shared memory usage can be chosen at runtime. This usage affects occupancy on the GPU. If a block demands all 48 KiB of shared memory for its private usage, or 128 registers per thread as
opposed to 32 , then only $1-2$ other blocks can run concurrently on the same SM, resulting in low occupancy. Under high occupancy more blocks will be present across all SMs, allowing more work to be in flight at once.</p>
<p>Memory types. Different blocks and kernels communicate through global memory, typically $4-32$ GB in size, with $5-$ $10 \times$ higher bandwidth than CPU main memory. Shared memory is analogous to CPU L1 cache in terms of speed. GPU register file memory is the highest bandwidth memory. In order to maintain the high number of instructions in flight on a GPU, a vast register file is also required: 14 MB in the latest Pascal P100, in contrast with a few tens of KB on CPU. A ratio of $250: 6.25: 1$ for register to shared to global memory aggregate cross-sectional bandwidth is typical on GPU, yielding $10-100$ s of TB/s for the register file [10].</p>
<h3>3.2 GPU register file usage</h3>
<p>Structured register data. Shared and register memory usage involves efficiency tradeoffs; they lower occupancy but can increase overall performance by retaining a larger working set in a faster memory. Making heavy use of registerresident data at the expense of occupancy or instead of shared memory is often profitable 43.</p>
<p>As the GPU register file is very large, storing structured data (not just temporary operands) is useful. A single lane can use its (scalar) registers to solve a local task, but with limited parallelism and storage. Instead, lanes in a GPU warp can instead exchange register data using the warp shuffle instruction, enabling warp-wide parallelism and storage.</p>
<p>Lane-stride register array. A common pattern to achieve this is a lane-stride register array. That is, given elements $\left[a_{i}\right]<em j="j">{i=0 ; \ell}$, each successive value is held in a register by neighboring lanes. The array is stored in $\ell / 32$ registers per lane, with $\ell$ a multiple of 32 . Lane $j$ stores $\left{a</em>\right}$.}, a_{32+j}, \ldots, a_{\ell-32+j}\right}$, while register $r$ holds $\left{a_{32 r}, a_{32 r+1}, \ldots, a_{32 r+31</p>
<p>For manipulating the $\left[a_{i}\right]$, the register in which $a_{i}$ is stored (i.e., $[i / 32]$ ) and $\ell$ must be known at assembly time, while the lane (i.e., $i \bmod 32$ ) can be runtime knowledge. A wide variety of access patterns (shift, any-to-any) are provided; we use the butterfly permutation [29] extensively.</p>
<h2>3.3 k-selection on CPU versus GPU</h2>
<p>$k$-selection algorithms, often for arbitrarily large $\ell$ and $k$, can be translated to a GPU, including radix selection and bucket selection [1], probabilistic selection [33], quickselect [14], and truncated sorts [40]. Their performance is dominated by multiple passes over the input in global memory. Sometimes for similarity search, the input distances are computed on-the-fly or stored only in small blocks, not in their entirety. The full, explicit array might be too large to fit into any memory, and its size could be unknown at the start of the processing, rendering algorithms that require multiple passes impractical. They suffer from other issues as well. Quickselect requires partitioning on a storage of size $\mathcal{O}(\ell)$, a data-dependent memory movement. This can result in excessive memory transactions, or requiring parallel prefix sums to determine write offsets, with synchronization overhead. Radix selection has no partitioning but multiple passes are still required.</p>
<p>Heap parallelism. In similarity search applications, one is usually interested only in a small number of results, $k&lt;$</p>
<p>1000 or so. In this regime, selection via max-heap is a typical choice on the CPU, but heaps do not expose much data parallelism (due to serial tree update) and cannot saturate SIMD execution units. The ad-heap [31] takes better advantage of parallelism available in heterogeneous systems, but still attempts to partition serial and parallel work between appropriate execution units. Despite the serial nature of heap update, for small $k$ the CPU can maintain all of its state in the L1 cache with little effort, and L1 cache latency and bandwidth remains a limiting factor. Other similarity search components, like PQ code manipulation, tend to have greater impact on CPU performance [2].</p>
<p>GPU heaps. Heaps can be similarly implemented on a GPU [7]. However, a straightforward GPU heap implementation suffers from high warp divergence and irregular, datadependent memory movement, since the path taken for each inserted element depends upon other values in the heap.</p>
<p>GPU parallel priority queues [24] improve over the serial heap update by allowing multiple concurrent updates, but they require a potential number of small sorts for each insert and data-dependent memory movement. Moreover, it uses multiple synchronization barriers through kernel launches in different streams, plus the additional latency of successive kernel launches and coordination with the CPU host.</p>
<p>Other more novel GPU algorithms are available for small $k$, namely the selection algorithm in the fgknn library [41]. This is a complex algorithm that may suffer from too many synchronization points, greater kernel launch overhead, usage of slower memories, excessive use of hierarchy, partitioning and buffering. However, we take inspiration from this particular algorithm through the use of parallel merges as seen in their merge queue structure.</p>
<h2>4. FAST K-SELECTION ON THE GPU</h2>
<p>For any CPU or GPU algorithm, either memory or arithmetic throughput should be the limiting factor as per the roofline performance model [48]. For input from global memory, $k$-selection cannot run faster than the time required to scan the input once at peak memory bandwidth. We aim to get as close to this limit as possible. Thus, we wish to perform a single pass over the input data (from global memory or produced on-the-fly, perhaps fused with a kernel that is generating the data).</p>
<p>We want to keep intermediate state in the fastest memory: the register file. The major disadvantage of register memory is that the indexing into the register file must be known at assembly time, which is a strong constraint on the algorithm.</p>
<h3>4.1 In-register sorting</h3>
<p>We use an in-register sorting primitive as a building block. Sorting networks are commonly used on SIMD architectures [13], as they exploit vector parallelism. They are easily implemented on the GPU, and we build sorting networks with lane-stride register arrays.</p>
<p>We use a variant of Batcher's bitonic sorting network [8], which is a set of parallel merges on an array of size $2^{k}$. Each merge takes $s$ arrays of length $t$ ( $s$ and $t$ a power of 2 ) to $s / 2$ arrays of length $2 t$, using $\log <em 2="2">{2}(t)$ parallel steps. A bitonic sort applies this merge recursively: to sort an array of length $\ell$, merge $\ell$ arrays of length 1 to $\ell / 2$ arrays of length 2 , to $\ell / 4$ arrays of length 4 , successively to 1 sorted array of length $\ell$, leading to $\frac{1}{2}\left(\log </em>(\ell)\right)$ parallel merge steps.}(\ell)^{2}+\log _{2</p>
<div class="codehilite"><pre><span></span><code><span class="nt">Algorithm</span><span class="w"> </span><span class="nt">1</span><span class="w"> </span><span class="nt">Odd-size</span><span class="w"> </span><span class="nt">merging</span><span class="w"> </span><span class="nt">network</span>
<span class="w">    </span><span class="nt">function</span><span class="w"> </span><span class="nt">MERGE-ODD</span><span class="w"> </span><span class="err">\</span><span class="o">(</span><span class="err">\</span><span class="nt">left</span><span class="o">(</span><span class="err">\</span><span class="nt">left</span><span class="cp">[</span><span class="nx">L_</span><span class="p">{</span><span class="nx">i</span><span class="p">}</span><span class="o">\</span><span class="nx">right</span><span class="cp">]</span><span class="nt">_</span><span class="p">{</span><span class="err">i=0:</span><span class="w"> </span><span class="err">\ell_{L</span><span class="p">}</span><span class="err">}</span><span class="o">,</span><span class="err">\</span><span class="nt">left</span><span class="cp">[</span><span class="nx">R_</span><span class="p">{</span><span class="nx">i</span><span class="p">}</span><span class="o">\</span><span class="nx">right</span><span class="cp">]</span><span class="nt">_</span><span class="p">{</span><span class="err">i=0:</span><span class="w"> </span><span class="err">\ell_{R</span><span class="p">}</span><span class="err">}\</span><span class="nt">right</span><span class="o">)</span><span class="err">\</span><span class="o">)</span>
<span class="w">        </span><span class="nt">parallel</span><span class="w"> </span><span class="nt">for</span><span class="w"> </span><span class="err">\</span><span class="o">(</span><span class="nt">i</span><span class="w"> </span><span class="err">\</span><span class="nt">leftarrow</span><span class="w"> </span><span class="nt">0</span><span class="o">:</span><span class="w"> </span><span class="err">\</span><span class="nt">min</span><span class="w"> </span><span class="err">\</span><span class="nt">left</span><span class="o">(</span><span class="err">\</span><span class="nt">ell_</span><span class="p">{</span><span class="err">L</span><span class="p">}</span><span class="o">,</span><span class="w"> </span><span class="err">\</span><span class="nt">ell_</span><span class="p">{</span><span class="err">R</span><span class="p">}</span><span class="err">\</span><span class="nt">right</span><span class="o">)</span><span class="err">\</span><span class="o">)</span><span class="w"> </span><span class="nt">do</span>
<span class="w">            </span><span class="err">\</span><span class="o">(</span><span class="err">\</span><span class="nt">triangleright</span><span class="err">\</span><span class="o">)</span><span class="w"> </span><span class="nt">inverted</span><span class="w"> </span><span class="nt">1st</span><span class="w"> </span><span class="nt">stage</span><span class="o">;</span><span class="w"> </span><span class="nt">inputs</span><span class="w"> </span><span class="nt">are</span><span class="w"> </span><span class="nt">already</span><span class="w"> </span><span class="nt">sorted</span>
<span class="w">            </span><span class="err">\</span><span class="o">(</span><span class="err">\</span><span class="nt">operatorname</span><span class="p">{</span><span class="err">COMPARE-SWAP</span><span class="p">}</span><span class="err">\</span><span class="nt">left</span><span class="o">(</span><span class="nt">L_</span><span class="p">{</span><span class="err">\ell_{L</span><span class="p">}</span><span class="nt">-i-1</span><span class="err">}</span><span class="o">,</span><span class="w"> </span><span class="nt">R_</span><span class="p">{</span><span class="err">i</span><span class="p">}</span><span class="err">\</span><span class="nt">right</span><span class="o">)</span><span class="err">\</span><span class="o">)</span>
<span class="w">        </span><span class="nt">end</span><span class="w"> </span><span class="nt">for</span>
<span class="w">        </span><span class="nt">parallel</span><span class="w"> </span><span class="nt">do</span>
<span class="w">            </span><span class="err">\</span><span class="o">(</span><span class="err">\</span><span class="nt">triangleright</span><span class="err">\</span><span class="o">)</span><span class="w"> </span><span class="nt">If</span><span class="w"> </span><span class="err">\</span><span class="o">(</span><span class="err">\</span><span class="nt">ell_</span><span class="p">{</span><span class="err">L</span><span class="p">}</span><span class="o">=</span><span class="err">\</span><span class="nt">ell_</span><span class="p">{</span><span class="err">R</span><span class="p">}</span><span class="err">\</span><span class="o">)</span><span class="w"> </span><span class="nt">and</span><span class="w"> </span><span class="nt">a</span><span class="w"> </span><span class="nt">power-of-2</span><span class="o">,</span><span class="w"> </span><span class="nt">these</span><span class="w"> </span><span class="nt">are</span><span class="w"> </span><span class="nt">equivalent</span>
<span class="w">            </span><span class="nt">MERGE-ODD-CONTINUE</span><span class="w"> </span><span class="err">\</span><span class="o">(</span><span class="err">\</span><span class="nt">left</span><span class="o">(</span><span class="err">\</span><span class="nt">left</span><span class="cp">[</span><span class="nx">L_</span><span class="p">{</span><span class="nx">i</span><span class="p">}</span><span class="o">\</span><span class="nx">right</span><span class="cp">]</span><span class="nt">_</span><span class="p">{</span><span class="err">i=0:</span><span class="w"> </span><span class="err">\ell_{L</span><span class="p">}</span><span class="err">}\</span><span class="nt">right</span><span class="o">.</span><span class="err">\</span><span class="o">),</span><span class="w"> </span><span class="nt">left</span><span class="w"> </span><span class="err">\</span><span class="o">()</span><span class="err">\</span><span class="o">)</span>
<span class="w">            </span><span class="nt">MERGE-ODD-CONTINUE</span><span class="w"> </span><span class="err">\</span><span class="o">(</span><span class="err">\</span><span class="nt">left</span><span class="o">(</span><span class="err">\</span><span class="nt">left</span><span class="cp">[</span><span class="nx">R_</span><span class="p">{</span><span class="nx">i</span><span class="p">}</span><span class="o">\</span><span class="nx">right</span><span class="cp">]</span><span class="nt">_</span><span class="p">{</span><span class="err">i=0:</span><span class="w"> </span><span class="err">\ell_{R</span><span class="p">}</span><span class="err">}\</span><span class="nt">right</span><span class="o">.</span><span class="err">\</span><span class="o">),</span><span class="w"> </span><span class="nt">right</span><span class="w"> </span><span class="err">\</span><span class="o">()</span><span class="err">\</span><span class="o">)</span>
<span class="w">        </span><span class="nt">end</span><span class="w"> </span><span class="nt">do</span>
<span class="w">    </span><span class="nt">end</span><span class="w"> </span><span class="nt">function</span>
<span class="w">    </span><span class="nt">function</span><span class="w"> </span><span class="nt">MERGE-ODD-CONTINUE</span><span class="w"> </span><span class="err">\</span><span class="o">(</span><span class="err">\</span><span class="nt">left</span><span class="o">(</span><span class="err">\</span><span class="nt">left</span><span class="cp">[</span><span class="nx">x_</span><span class="p">{</span><span class="nx">i</span><span class="p">}</span><span class="o">\</span><span class="nx">right</span><span class="cp">]</span><span class="nt">_</span><span class="p">{</span><span class="err">i=0:</span><span class="w"> </span><span class="err">\ell</span><span class="p">}</span><span class="o">,</span><span class="w"> </span><span class="nt">p</span><span class="err">\</span><span class="nt">right</span><span class="o">)</span><span class="err">\</span><span class="o">)</span>
<span class="w">        </span><span class="nt">if</span><span class="w"> </span><span class="err">\</span><span class="o">(</span><span class="err">\</span><span class="nt">ell</span><span class="o">&gt;</span><span class="nt">1</span><span class="err">\</span><span class="o">)</span><span class="w"> </span><span class="nt">then</span>
<span class="w">            </span><span class="err">\</span><span class="o">(</span><span class="nt">h</span><span class="w"> </span><span class="err">\</span><span class="nt">leftarrow</span><span class="w"> </span><span class="nt">2</span><span class="o">^</span><span class="p">{</span><span class="err">\left|\log</span><span class="w"> </span><span class="err">_{2</span><span class="p">}</span><span class="w"> </span><span class="err">\</span><span class="nt">ell</span><span class="err">\</span><span class="nt">right</span><span class="o">|</span><span class="nt">-1</span><span class="err">}</span><span class="w"> </span><span class="err">\</span><span class="nt">quad</span><span class="w"> </span><span class="err">\</span><span class="nt">triangleright</span><span class="err">\</span><span class="o">)</span><span class="w"> </span><span class="nt">largest</span><span class="w"> </span><span class="nt">power-of-</span><span class="w"> </span><span class="err">\</span><span class="o">(</span><span class="nt">2</span><span class="o">&lt;</span><span class="err">\</span><span class="nt">ell</span><span class="err">\</span><span class="o">)</span>
<span class="w">            </span><span class="nt">parallel</span><span class="w"> </span><span class="nt">for</span><span class="w"> </span><span class="err">\</span><span class="o">(</span><span class="nt">i</span><span class="w"> </span><span class="err">\</span><span class="nt">leftarrow</span><span class="w"> </span><span class="nt">0</span><span class="o">:</span><span class="w"> </span><span class="err">\</span><span class="nt">ell-h</span><span class="err">\</span><span class="o">)</span><span class="w"> </span><span class="nt">do</span>
<span class="w">                </span><span class="err">\</span><span class="o">(</span><span class="err">\</span><span class="nt">triangleright</span><span class="err">\</span><span class="o">)</span><span class="w"> </span><span class="nt">Implemented</span><span class="w"> </span><span class="nt">with</span><span class="w"> </span><span class="nt">warp</span><span class="w"> </span><span class="nt">shuffle</span><span class="w"> </span><span class="nt">butterfly</span>
<span class="w">            </span><span class="err">\</span><span class="o">(</span><span class="err">\</span><span class="nt">operatorname</span><span class="p">{</span><span class="err">COMPARE-SWAP</span><span class="p">}</span><span class="err">\</span><span class="nt">left</span><span class="o">(</span><span class="nt">x_</span><span class="p">{</span><span class="err">i</span><span class="p">}</span><span class="o">,</span><span class="w"> </span><span class="nt">x_</span><span class="p">{</span><span class="err">i+h</span><span class="p">}</span><span class="err">\</span><span class="nt">right</span><span class="o">)</span><span class="err">\</span><span class="o">)</span>
<span class="w">            </span><span class="nt">end</span><span class="w"> </span><span class="nt">for</span>
<span class="w">            </span><span class="nt">parallel</span><span class="w"> </span><span class="nt">do</span>
<span class="w">                </span><span class="nt">if</span><span class="w"> </span><span class="err">\</span><span class="o">(</span><span class="nt">p</span><span class="o">=</span><span class="err">\</span><span class="o">)</span><span class="w"> </span><span class="nt">left</span><span class="w"> </span><span class="nt">then</span><span class="w"> </span><span class="err">\</span><span class="o">(</span><span class="err">\</span><span class="nt">quad</span><span class="w"> </span><span class="err">\</span><span class="nt">triangleright</span><span class="err">\</span><span class="o">)</span><span class="w"> </span><span class="nt">left</span><span class="w"> </span><span class="nt">side</span><span class="w"> </span><span class="nt">recursion</span>
<span class="w">                    </span><span class="nt">MERGE-ODD-CONTINUE</span><span class="w"> </span><span class="err">\</span><span class="o">(</span><span class="err">\</span><span class="nt">left</span><span class="o">(</span><span class="err">\</span><span class="nt">left</span><span class="cp">[</span><span class="nx">x_</span><span class="p">{</span><span class="nx">i</span><span class="p">}</span><span class="o">\</span><span class="nx">right</span><span class="cp">]</span><span class="nt">_</span><span class="p">{</span><span class="err">i=0:</span><span class="w"> </span><span class="err">\ell-h</span><span class="p">}</span><span class="err">\</span><span class="nt">right</span><span class="o">.</span><span class="err">\</span><span class="o">),</span><span class="w"> </span><span class="nt">left</span><span class="w"> </span><span class="err">\</span><span class="o">()</span><span class="err">\</span><span class="o">)</span>
<span class="w">                    </span><span class="nt">MERGE-ODD-CONTINUE</span><span class="w"> </span><span class="err">\</span><span class="o">(</span><span class="err">\</span><span class="nt">left</span><span class="o">(</span><span class="err">\</span><span class="nt">left</span><span class="cp">[</span><span class="nx">x_</span><span class="p">{</span><span class="nx">i</span><span class="p">}</span><span class="o">\</span><span class="nx">right</span><span class="cp">]</span><span class="nt">_</span><span class="p">{</span><span class="err">i=\</span><span class="n">ell-h</span><span class="p">:</span><span class="w"> </span><span class="err">\</span><span class="n">ell</span><span class="p">}</span><span class="err">\</span><span class="nt">right</span><span class="o">.</span><span class="err">\</span><span class="o">),</span><span class="w"> </span><span class="nt">right</span><span class="w"> </span><span class="err">\</span><span class="o">()</span><span class="err">\</span><span class="o">)</span>
<span class="w">                </span><span class="nt">else</span><span class="w"> </span><span class="err">\</span><span class="o">(</span><span class="err">\</span><span class="nt">quad</span><span class="w"> </span><span class="err">\</span><span class="nt">triangleright</span><span class="err">\</span><span class="o">)</span><span class="w"> </span><span class="nt">right</span><span class="w"> </span><span class="nt">side</span><span class="w"> </span><span class="nt">recursion</span>
<span class="w">                    </span><span class="nt">MERGE-ODD-CONTINUE</span><span class="w"> </span><span class="err">\</span><span class="o">(</span><span class="err">\</span><span class="nt">left</span><span class="o">(</span><span class="err">\</span><span class="nt">left</span><span class="cp">[</span><span class="nx">x_</span><span class="p">{</span><span class="nx">i</span><span class="p">}</span><span class="o">\</span><span class="nx">right</span><span class="cp">]</span><span class="nt">_</span><span class="p">{</span><span class="err">i=0:</span><span class="w"> </span><span class="err">h</span><span class="p">}</span><span class="err">\</span><span class="nt">right</span><span class="o">.</span><span class="err">\</span><span class="o">),</span><span class="w"> </span><span class="nt">left</span><span class="w"> </span><span class="err">\</span><span class="o">()</span><span class="err">\</span><span class="o">)</span>
<span class="w">                    </span><span class="nt">MERGE-ODD-CONTINUE</span><span class="w"> </span><span class="err">\</span><span class="o">(</span><span class="err">\</span><span class="nt">left</span><span class="o">(</span><span class="err">\</span><span class="nt">left</span><span class="cp">[</span><span class="nx">x_</span><span class="p">{</span><span class="nx">i</span><span class="p">}</span><span class="o">\</span><span class="nx">right</span><span class="cp">]</span><span class="nt">_</span><span class="p">{</span><span class="err">i=</span><span class="n">h</span><span class="p">:</span><span class="w"> </span><span class="err">\</span><span class="n">ell</span><span class="p">}</span><span class="err">\</span><span class="nt">right</span><span class="o">.</span><span class="err">\</span><span class="o">),</span><span class="w"> </span><span class="nt">right</span><span class="w"> </span><span class="err">\</span><span class="o">()</span><span class="err">\</span><span class="o">)</span>
<span class="w">                </span><span class="nt">end</span><span class="w"> </span><span class="nt">if</span>
<span class="w">            </span><span class="nt">end</span><span class="w"> </span><span class="nt">do</span>
<span class="w">            </span><span class="nt">end</span><span class="w"> </span><span class="nt">if</span>
<span class="w">    </span><span class="nt">end</span><span class="w"> </span><span class="nt">function</span>
</code></pre></div>

<p>Odd-size merging and sorting networks. If some input data is already sorted, we can modify the network to avoid merging steps. We may also not have a full power-of-2 set of data, in which case we can efficiently shortcut to deal with the smaller size.</p>
<p>Algorithm 1 is an odd-sized merging network that merges already sorted left and right arrays, each of arbitrary length. While the bitonic network merges bitonic sequences, we start with monotonic sequences: sequences sorted monotonically. A bitonic merge is made monotonic by reversing the first comparator stage.</p>
<p>The odd size algorithm is derived by considering arrays to be padded to the next highest power-of-2 size with dummy
<img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Figure 1: Odd-size network merging arrays of sizes 5 and 3. Bullets indicate parallel compare/swap. Dashed lines are elided elements or comparisons.</p>
<p><img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Figure 2: Overview of WarpSelect. The input values stream in on the left, and the warp queue on the right holds the output result.</p>
<p>elements that are never swapped (the merge is monotonic) and are already properly positioned; any comparisons with dummy elements are elided. A left array is considered to be padded with dummy elements at the start; a right array has them at the end. A merge of two sorted arrays of length $\ell_L$ and $\ell_R$ to a sorted array of $\ell_L + \ell_R$ requires $\left\lceil \log_2(\max(\ell_L, \ell_R))\right\rceil + 1$ parallel steps. Figure 1 shows Algorithm 1's merging network for arrays of size 5 and 3, with 4 parallel steps.</p>
<p>The COMPARE-SWAP is implemented using warp shuffles on a lane-stride register array. Swaps with a stride a multiple of 32 occur directly within a lane as the lane holds both elements locally. Swaps of stride $\leq 16$ or a non-multiple of 32 occur with warp shuffles. In practice, used array lengths are multiples of 32 as they are held in lane-stride arrays.</p>
<div class="codehilite"><pre><span></span><code>Algorithm 2 Odd-size sorting network
    function SORT-ODD([x\_{i}]_{i=0:t})
        if \(\ell &gt; 1\) then
            parallel do
                SORT-ODD([x\_{i}]\_{i=0:[\ell/2]}
                SORT-ODD([x\_{i}]\_{i=[\ell/2]:t})
            end do
                MERGE-ODD([x\_{i}]\_{i=0:[\ell/2]}, [x\_{i}]\_{i=[\ell/2]:t})
            end if
    end function
</code></pre></div>

<p>Algorithm 2 extends the merge to a full sort. Assuming no structure present in the input data, $\frac{1}{2}(\left\lceil \log_2(\ell)\right\rceil^2 + \left\lceil \log_2(\ell)\right\rceil)$ parallel steps are required for sorting data of length $\ell$.</p>
<h3>4.2 WarpSelect</h3>
<p>Our k-selection implementation, WARPSELECT, maintains state entirely in registers, requires only a single pass over data and avoids cross-warp synchronization. It uses MERGE-ODD and SORT-ODD as primitives. Since the register file provides much more storage than shared memory, it supports k ≤ 1024. Each warp is dedicated to k-selection to a single one of the n arrays [a<sub>i</sub>]. If n is large enough, a single warp per each [a<sub>i</sub>] will result in full GPU occupancy. Large $\ell$ per warp is handled by recursive decomposition, if $\ell$ is known in advance.</p>
<p><strong>Overview.</strong> Our approach (Algorithm 3 and Figure 2) operates on values, with associated indices carried along (omitted from the description for simplicity). It selects the k least values that come from global memory, or from intermediate value registers if fused into another kernel providing the values. Let [a<sub>i</sub>]<sub>i=0:t</sub> be the sequence provided for selection.</p>
<p>The elements (on the left of Figure 2) are processed in groups of 32, the warp size. Lane j is responsible for processing {a<sub>j</sub>, a<sub>32+j</sub>, ...}; thus, if the elements come from global memory, the reads are contiguous and coalesced into a minimal number of memory transactions.</p>
<p><strong>Data structures.</strong> Each lane j maintains a small queue of t elements in registers, called the thread queues [T<sub>i</sub><sup>j</sup>]<sub>i=0:t</sub>, ordered from largest to smallest (T<sub>i</sub><sup>j</sup> ≥ T<sub>i+1</sub><sup>j</sup>). The choice of t is made relative to k, see Section 4.3. The thread queue is a first-level filter for new values coming in. If a new a<sub>32</sub><sup>i+j</sup> is greater than the largest key currently in the queue, T<sub>0</sub><sup>j</sup>, it is guaranteed that it won't be in the k smallest final results.</p>
<p>The warp shares a lane-stride register array of k smallest seen elements, [W<sub>i</sub>]<sub>i=0:k</sub>, called the warp queue. It is ordered from smallest to largest (W<sub>i</sub> ≤ W<sub>i+1</sub>); if the requested k is not a multiple of 32, we round it up. This is a second level data structure that will be used to maintain all of the k smallest warp-wide seen values. The thread and warp queues are initialized to maximum sentinel values, e.g., +∞.</p>
<p><strong>Update.</strong> The three invariants maintained are:</p>
<ul>
<li>all per-lane T<sub>0</sub><sup>j</sup> are not in the min-k</li>
<li>all per-lane T<sub>0</sub><sup>j</sup> are greater than all warp queue keys W<sub>i</sub></li>
<li>all a<sub>i</sub> seen so far in the min-k are contained in either some lane's thread queue ([T<sub>i</sub><sup>j</sup>]<sub>i=0:t,j=0:32</sub>), or in the warp queue.</li>
</ul>
<p>Lane j receives a new a<sub>32</sub><sup>i+j</sup> and attempts to insert it into its thread queue. If a<sub>32</sub><sup>i+j</sup> &gt; T<sub>0</sub><sup>j</sup>, then the new pair is by definition not in the k minimum, and can be rejected.</p>
<p>Otherwise, it is inserted into its proper sorted position in the thread queue, thus ejecting the old T<sub>0</sub><sup>j</sup>. All lanes complete doing this with their new received pair and their thread queue, but it is now possible that the second invariant have been violated. Using the warp ballot instruction, we determine if any lane has violated the second invariant. If not, we are free to continue processing new elements.</p>
<p><strong>Restoring the invariants.</strong> If any lane has its invariant violated, then the warp uses ODD-MERGE to merge and sort the thread and warp queues together. The new warp queue</p>
<div class="codehilite"><pre><span></span><code>Algorithm<span class="w"> </span>3<span class="w"> </span>WARPSELECT<span class="w"> </span>pseudocode<span class="w"> </span>for<span class="w"> </span>lane<span class="w"> </span>j
<span class="w">    </span>function<span class="w"> </span>WARPSELECT(a)
<span class="w">        </span>if<span class="w"> </span>a<span class="w"> </span><span class="nt">&lt; T</span><span class="err">&lt;sub</span><span class="nt">&gt;</span>0<span class="nt">&lt;/sub&gt;&lt;sup&gt;</span>j<span class="nt">&lt;/sup&gt;</span><span class="w"> </span>then
<span class="w">            </span>insert<span class="w"> </span>a<span class="w"> </span>into<span class="w"> </span>our<span class="w"> </span>[T<span class="nt">&lt;sub&gt;</span>i<span class="nt">&lt;/sub&gt;&lt;sup&gt;</span>j<span class="nt">&lt;/sup&gt;</span>]<span class="nt">&lt;sub&gt;</span>i=0:t<span class="nt">&lt;/sub&gt;</span>
<span class="w">        </span>end<span class="w"> </span>if
<span class="w">        </span>if<span class="w"> </span>WARP-BALLOT(T<span class="nt">&lt;sub&gt;</span>0<span class="nt">&lt;/sub&gt;&lt;sup&gt;</span>j<span class="nt">&lt;/sup&gt;</span><span class="w"> </span><span class="nt">&lt; W</span><span class="err">&lt;sub</span><span class="nt">&gt;</span>k-1<span class="nt">&lt;/sub&gt;</span>)<span class="w"> </span>then
<span class="w">             </span>\(\triangleright\)<span class="w"> </span>Reinterpret<span class="w"> </span>thread<span class="w"> </span>queues<span class="w"> </span>as<span class="w"> </span>lane-stride<span class="w"> </span>array
<span class="w">            </span>[\alpha\_i]<span class="nt">&lt;sub&gt;</span>i=0:32t<span class="nt">&lt;/sub&gt;</span><span class="w"> </span>\leftarrow<span class="w"> </span>CAST([T\_i<span class="nt">&lt;sub&gt;</span>i<span class="nt">&lt;/sub&gt;&lt;sup&gt;</span>j<span class="nt">&lt;/sup&gt;</span>]<span class="nt">&lt;sub&gt;</span>i=0:t,j=0:32<span class="nt">&lt;/sub&gt;</span>)
<span class="w">            </span>\(\triangleright\)<span class="w"> </span>concatenate<span class="w"> </span>and<span class="w"> </span>sort<span class="w"> </span>thread<span class="w"> </span>queues
<span class="w">            </span>SORT-ODD([\alpha\_i]<span class="nt">&lt;sub&gt;</span>i=0:32t<span class="nt">&lt;/sub&gt;</span>)
<span class="w">            </span>MERGE-ODD([W\_i]<span class="nt">&lt;sub&gt;</span>i=0:k<span class="nt">&lt;/sub&gt;</span>,<span class="w"> </span>[\alpha\_i]<span class="nt">&lt;sub&gt;</span>i=0:32t<span class="nt">&lt;/sub&gt;</span>)
<span class="w">            </span>\(\triangleright\)<span class="w"> </span>Reinterpret<span class="w"> </span>lane-stride<span class="w"> </span>array<span class="w"> </span>as<span class="w"> </span>thread<span class="w"> </span>queues
<span class="w">            </span>[T\_i<span class="nt">&lt;sub&gt;</span>i<span class="nt">&lt;/sub&gt;&lt;sup&gt;</span>j<span class="nt">&lt;/sup&gt;</span>]<span class="nt">&lt;sub&gt;</span>i=0:t,j=0:32<span class="nt">&lt;/sub&gt;</span><span class="w"> </span>\leftarrow<span class="w"> </span>CAST([\alpha\_i]<span class="nt">&lt;sub&gt;</span>i=0:32t<span class="nt">&lt;/sub&gt;</span>)
<span class="w">            </span>REVERSE-ARRAY([T\_i]<span class="nt">&lt;sub&gt;</span>i<span class="nt">&lt;/sub&gt;&lt;sup&gt;</span>j<span class="nt">&lt;/sup&gt;&lt;sub&gt;</span>i<span class="nt">&lt;/sub&gt;</span>)<span class="w"> </span>\(\triangleright\)<span class="w"> </span>Back<span class="w"> </span>in<span class="w"> </span>thread<span class="w"> </span>queue<span class="w"> </span>order,<span class="w"> </span>invariant<span class="w"> </span>restored
<span class="w">        </span>end<span class="w"> </span>if
<span class="w">    </span>end<span class="w"> </span>function

will<span class="w"> </span>be<span class="w"> </span>the<span class="w"> </span>min-k<span class="w"> </span>elements<span class="w"> </span>across<span class="w"> </span>the<span class="w"> </span>merged,<span class="w"> </span>sorted<span class="w"> </span>queues,<span class="w"> </span>and<span class="w"> </span>the<span class="w"> </span>new<span class="w"> </span>thread<span class="w"> </span>queues<span class="w"> </span>will<span class="w"> </span>be<span class="w"> </span>the<span class="w"> </span>remainder,<span class="w"> </span>from<span class="w"> </span>min$(k+1)$<span class="w"> </span>to<span class="w"> </span>min-<span class="w"> </span>$(k+32<span class="w"> </span>t+1)$.<span class="w"> </span>This<span class="w"> </span>restores<span class="w"> </span>the<span class="w"> </span>invariants<span class="w"> </span>and<span class="w"> </span>we<span class="w"> </span>are<span class="w"> </span>free<span class="w"> </span>to<span class="w"> </span>continue<span class="w"> </span>processing<span class="w"> </span>subsequent<span class="w"> </span>elements.

Since<span class="w"> </span>the<span class="w"> </span>thread<span class="w"> </span>and<span class="w"> </span>warp<span class="w"> </span>queues<span class="w"> </span>are<span class="w"> </span>already<span class="w"> </span>sorted,<span class="w"> </span>we<span class="w"> </span>merge<span class="w"> </span>the<span class="w"> </span>sorted<span class="w"> </span>warp<span class="w"> </span>queue<span class="w"> </span>of<span class="w"> </span>length<span class="w"> </span>$k$<span class="w"> </span>with<span class="w"> </span>32<span class="w"> </span>sorted<span class="w"> </span>arrays<span class="w"> </span>of<span class="w"> </span>length<span class="w"> </span>$t$.<span class="w"> </span>Supporting<span class="w"> </span>odd-sized<span class="w"> </span>merges<span class="w"> </span>is<span class="w"> </span>important<span class="w"> </span>because<span class="w"> </span>Batcher&#39;s<span class="w"> </span>formulation<span class="w"> </span>would<span class="w"> </span>require<span class="w"> </span>that<span class="w"> </span>$32<span class="w"> </span>t=k$<span class="w"> </span>and<span class="w"> </span>is<span class="w"> </span>a<span class="w"> </span>power-of-2;<span class="w"> </span>thus<span class="w"> </span>if<span class="w"> </span>$k=1024,<span class="w"> </span>t$<span class="w"> </span>must<span class="w"> </span>be<span class="w"> </span>32<span class="w"> </span>.<span class="w"> </span>We<span class="w"> </span>found<span class="w"> </span>that<span class="w"> </span>the<span class="w"> </span>optimal<span class="w"> </span>$t$<span class="w"> </span>is<span class="w"> </span>way<span class="w"> </span>smaller<span class="w"> </span>(see<span class="w"> </span>below).

Using<span class="w"> </span>ODD-MERGE<span class="w"> </span>to<span class="w"> </span>merge<span class="w"> </span>the<span class="w"> </span>32<span class="w"> </span>already<span class="w"> </span>sorted<span class="w"> </span>thread<span class="w"> </span>queues<span class="w"> </span>would<span class="w"> </span>require<span class="w"> </span>a<span class="w"> </span>struct-of-arrays<span class="w"> </span>to<span class="w"> </span>array-of-structs<span class="w"> </span>transposition<span class="w"> </span>in<span class="w"> </span>registers<span class="w"> </span>across<span class="w"> </span>the<span class="w"> </span>warp,<span class="w"> </span>since<span class="w"> </span>the<span class="w"> </span>$t$<span class="w"> </span>successive<span class="w"> </span>sorted<span class="w"> </span>values<span class="w"> </span>are<span class="w"> </span>held<span class="w"> </span>in<span class="w"> </span>different<span class="w"> </span>registers<span class="w"> </span>in<span class="w"> </span>the<span class="w"> </span>same<span class="w"> </span>lane<span class="w"> </span>rather<span class="w"> </span>than<span class="w"> </span>a<span class="w"> </span>lane-stride<span class="w"> </span>array.<span class="w"> </span>This<span class="w"> </span>is<span class="w"> </span>possible<span class="w"> </span>[12],<span class="w"> </span>but<span class="w"> </span>would<span class="w"> </span>use<span class="w"> </span>a<span class="w"> </span>comparable<span class="w"> </span>number<span class="w"> </span>of<span class="w"> </span>warp<span class="w"> </span>shuffles,<span class="w"> </span>so<span class="w"> </span>we<span class="w"> </span>just<span class="w"> </span>reinterpret<span class="w"> </span>the<span class="w"> </span>thread<span class="w"> </span>queue<span class="w"> </span>registers<span class="w"> </span>as<span class="w"> </span>an<span class="w"> </span>(unsorted)<span class="w"> </span>lane-stride<span class="w"> </span>array<span class="w"> </span>and<span class="w"> </span>sort<span class="w"> </span>from<span class="w"> </span>scratch.<span class="w"> </span>Significant<span class="w"> </span>speedup<span class="w"> </span>is<span class="w"> </span>realizable<span class="w"> </span>by<span class="w"> </span>using<span class="w"> </span>ODD-MERGE<span class="w"> </span>for<span class="w"> </span>the<span class="w"> </span>merge<span class="w"> </span>of<span class="w"> </span>the<span class="w"> </span>aggregate<span class="w"> </span>sorted<span class="w"> </span>thread<span class="w"> </span>queues<span class="w"> </span>with<span class="w"> </span>the<span class="w"> </span>warp<span class="w"> </span>queue.

Handling<span class="w"> </span>the<span class="w"> </span>remainder.<span class="w"> </span>If<span class="w"> </span>there<span class="w"> </span>are<span class="w"> </span>remainder<span class="w"> </span>elements<span class="w"> </span>because<span class="w"> </span>$\ell$<span class="w"> </span>is<span class="w"> </span>not<span class="w"> </span>a<span class="w"> </span>multiple<span class="w"> </span>of<span class="w"> </span>32<span class="w"> </span>,<span class="w"> </span>those<span class="w"> </span>are<span class="w"> </span>inserted<span class="w"> </span>into<span class="w"> </span>the<span class="w"> </span>thread<span class="w"> </span>queues<span class="w"> </span>for<span class="w"> </span>the<span class="w"> </span>lanes<span class="w"> </span>that<span class="w"> </span>have<span class="w"> </span>them,<span class="w"> </span>after<span class="w"> </span>which<span class="w"> </span>we<span class="w"> </span>proceed<span class="w"> </span>to<span class="w"> </span>the<span class="w"> </span>output<span class="w"> </span>stage.

Output.<span class="w"> </span>A<span class="w"> </span>final<span class="w"> </span>sort<span class="w"> </span>and<span class="w"> </span>merge<span class="w"> </span>is<span class="w"> </span>made<span class="w"> </span>of<span class="w"> </span>the<span class="w"> </span>thread<span class="w"> </span>and<span class="w"> </span>warp<span class="w"> </span>queues,<span class="w"> </span>after<span class="w"> </span>which<span class="w"> </span>the<span class="w"> </span>warp<span class="w"> </span>queue<span class="w"> </span>holds<span class="w"> </span>all<span class="w"> </span>min-k<span class="w"> </span>values.

###<span class="w"> </span>4.3<span class="w"> </span>Complexity<span class="w"> </span>and<span class="w"> </span>parameter<span class="w"> </span>selection

For<span class="w"> </span>each<span class="w"> </span>incoming<span class="w"> </span>group<span class="w"> </span>of<span class="w"> </span>32<span class="w"> </span>elements,<span class="w"> </span>WarpSelect<span class="w"> </span>can<span class="w"> </span>perform<span class="w"> </span>1,2<span class="w"> </span>or<span class="w"> </span>3<span class="w"> </span>constant-time<span class="w"> </span>operations,<span class="w"> </span>all<span class="w"> </span>happening<span class="w"> </span>in<span class="w"> </span>warp-wide<span class="w"> </span>parallel<span class="w"> </span>time:

1.<span class="w"> </span>read<span class="w"> </span>32<span class="w"> </span>elements,<span class="w"> </span>compare<span class="w"> </span>to<span class="w"> </span>all<span class="w"> </span>thread<span class="w"> </span>queue<span class="w"> </span>heads<span class="w"> </span>$T_{0}^{j}$,<span class="w"> </span>cost<span class="w"> </span>$C_{1}$,<span class="w"> </span>happens<span class="w"> </span>$N_{1}$<span class="w"> </span>times;
2.<span class="w"> </span>if<span class="w"> </span>$\exists<span class="w"> </span>j<span class="w"> </span>\in\{0,<span class="w"> </span>\ldots,<span class="w"> </span>31\},<span class="w"> </span>a_{32<span class="w"> </span>n+j}<span class="nt">&lt;T_</span><span class="err">{0}^{j}$,</span><span class="w"> </span><span class="err">perform</span><span class="w"> </span><span class="err">insertion</span><span class="w"> </span><span class="err">sort</span><span class="w"> </span><span class="err">on</span><span class="w"> </span><span class="err">those</span><span class="w"> </span><span class="err">specific</span><span class="w"> </span><span class="err">thread</span><span class="w"> </span><span class="err">queues,</span><span class="w"> </span><span class="err">cost</span><span class="w"> </span><span class="err">$C_{2}=\mathcal{O}(t)$,</span><span class="w"> </span><span class="err">happens</span><span class="w"> </span><span class="err">$N_{2}$</span><span class="w"> </span><span class="err">times;</span>
<span class="err">3.</span><span class="w"> </span><span class="err">if</span><span class="w"> </span><span class="err">$\exists</span><span class="w"> </span><span class="err">j,</span><span class="w"> </span><span class="err">T_{0}^{j}&lt;W_{k-1}$,</span><span class="w"> </span><span class="err">sort</span><span class="w"> </span><span class="err">and</span><span class="w"> </span><span class="err">merge</span><span class="w"> </span><span class="err">queues,</span><span class="w"> </span><span class="err">cost</span><span class="w"> </span><span class="err">$C_{3}=$</span><span class="w"> </span><span class="err">$\mathcal{O}\left(t</span><span class="w"> </span><span class="err">\log</span><span class="w"> </span><span class="err">(32</span><span class="w"> </span><span class="err">t)^{2}+k</span><span class="w"> </span><span class="err">\log</span><span class="w"> </span><span class="err">\left(\max</span><span class="w"> </span><span class="err">(k,</span><span class="w"> </span><span class="err">32</span><span class="w"> </span><span class="err">t)\right)\right)$,</span><span class="w"> </span><span class="err">happens</span><span class="w"> </span><span class="err">$N_{3}$</span><span class="w"> </span><span class="err">times.</span>

<span class="err">Thus,</span><span class="w"> </span><span class="err">the</span><span class="w"> </span><span class="err">total</span><span class="w"> </span><span class="err">cost</span><span class="w"> </span><span class="err">is</span><span class="w"> </span><span class="err">$N_{1}</span><span class="w"> </span><span class="err">C_{1}+N_{2}</span><span class="w"> </span><span class="err">C_{2}+N_{3}</span><span class="w"> </span><span class="err">C_{3}</span><span class="w"> </span><span class="err">.</span><span class="w"> </span><span class="err">N_{1}=\ell</span><span class="w"> </span><span class="err">/</span><span class="w"> </span><span class="err">32$,</span><span class="w"> </span><span class="err">and</span><span class="w"> </span><span class="err">on</span><span class="w"> </span><span class="err">random</span><span class="w"> </span><span class="err">data</span><span class="w"> </span><span class="err">drawn</span><span class="w"> </span><span class="err">independently,</span><span class="w"> </span><span class="err">$N_{2}=\mathcal{O}(k</span><span class="w"> </span><span class="err">\log</span><span class="w"> </span><span class="err">(\ell))$</span><span class="w"> </span><span class="err">and</span><span class="w"> </span><span class="err">$N_{3}=\mathcal{O}(k</span><span class="w"> </span><span class="err">\log</span><span class="w"> </span><span class="err">(\ell)</span><span class="w"> </span><span class="err">/</span><span class="w"> </span><span class="err">t)$,</span><span class="w"> </span><span class="err">see</span><span class="w"> </span><span class="err">the</span><span class="w"> </span><span class="err">Appendix</span><span class="w"> </span><span class="err">for</span><span class="w"> </span><span class="err">a</span><span class="w"> </span><span class="err">full</span><span class="w"> </span><span class="err">derivation.</span><span class="w"> </span><span class="err">Hence,</span><span class="w"> </span><span class="err">the</span><span class="w"> </span><span class="err">trade-off</span><span class="w"> </span><span class="err">is</span><span class="w"> </span><span class="err">to</span><span class="w"> </span><span class="err">balance</span><span class="w"> </span><span class="err">a</span><span class="w"> </span><span class="err">cost</span><span class="w"> </span><span class="err">in</span><span class="w"> </span><span class="err">$N_{2}</span><span class="w"> </span><span class="err">C_{2}$</span><span class="w"> </span><span class="err">and</span><span class="w"> </span><span class="err">one</span><span class="w"> </span><span class="err">in</span><span class="w"> </span><span class="err">$N_{3}</span><span class="w"> </span><span class="err">C_{3}$.</span><span class="w"> </span><span class="err">The</span><span class="w"> </span><span class="err">practical</span><span class="w"> </span><span class="err">choice</span><span class="w"> </span><span class="err">for</span><span class="w"> </span><span class="err">$t$</span><span class="w"> </span><span class="err">given</span><span class="w"> </span><span class="err">$k$</span><span class="w"> </span><span class="err">and</span><span class="w"> </span><span class="err">$\ell$</span><span class="w"> </span><span class="err">was</span><span class="w"> </span><span class="err">made</span><span class="w"> </span><span class="err">by</span><span class="w"> </span><span class="err">experiment</span><span class="w"> </span><span class="err">on</span><span class="w"> </span><span class="err">a</span><span class="w"> </span><span class="err">variety</span><span class="w"> </span><span class="err">of</span><span class="w"> </span><span class="err">$k$-NN</span><span class="w"> </span><span class="err">data.</span><span class="w"> </span><span class="err">For</span><span class="w"> </span><span class="err">$k</span><span class="w"> </span><span class="err">\leq</span><span class="w"> </span><span class="err">32$,</span><span class="w"> </span><span class="err">we</span><span class="w"> </span><span class="err">use</span><span class="w"> </span><span class="err">$</span><span class="na">t=</span><span class="s">2,</span><span class="w"> </span><span class="err">k</span><span class="w"> </span><span class="err">\leq</span><span class="w"> </span><span class="err">128$</span><span class="w"> </span><span class="err">uses</span><span class="w"> </span><span class="err">$</span><span class="na">t=</span><span class="s">3,</span><span class="w"> </span><span class="err">k</span><span class="w"> </span><span class="err">\leq</span><span class="w"> </span><span class="err">256$</span><span class="w"> </span><span class="err">uses</span><span class="w"> </span><span class="err">$</span><span class="na">t=</span><span class="s">4$,</span><span class="w"> </span><span class="err">and</span><span class="w"> </span><span class="err">$k</span><span class="w"> </span><span class="err">\leq</span><span class="w"> </span><span class="err">1024$</span><span class="w"> </span><span class="err">uses</span><span class="w"> </span><span class="err">$</span><span class="na">t=</span><span class="s">8$,</span><span class="w"> </span><span class="err">all</span><span class="w"> </span><span class="err">irrespective</span><span class="w"> </span><span class="err">of</span><span class="w"> </span><span class="err">$\ell$.</span>

<span class="err">##</span><span class="w"> </span><span class="err">5.</span><span class="w"> </span><span class="err">COMPUTATION</span><span class="w"> </span><span class="err">LAYOUT</span>

<span class="err">This</span><span class="w"> </span><span class="err">section</span><span class="w"> </span><span class="err">explains</span><span class="w"> </span><span class="err">how</span><span class="w"> </span><span class="err">IVFADC,</span><span class="w"> </span><span class="err">one</span><span class="w"> </span><span class="err">of</span><span class="w"> </span><span class="err">the</span><span class="w"> </span><span class="err">indexing</span><span class="w"> </span><span class="err">methods</span><span class="w"> </span><span class="err">originally</span><span class="w"> </span><span class="err">built</span><span class="w"> </span><span class="err">upon</span><span class="w"> </span><span class="err">product</span><span class="w"> </span><span class="err">quantization</span><span class="w"> </span><span class="err">[25],</span><span class="w"> </span><span class="err">is</span><span class="w"> </span><span class="err">implemented</span><span class="w"> </span><span class="err">efficiently.</span><span class="w"> </span><span class="err">Details</span><span class="w"> </span><span class="err">on</span><span class="w"> </span><span class="err">distance</span><span class="w"> </span><span class="err">computations</span><span class="w"> </span><span class="err">and</span><span class="w"> </span><span class="err">articulation</span><span class="w"> </span><span class="err">with</span><span class="w"> </span><span class="err">$k$-selection</span><span class="w"> </span><span class="err">are</span><span class="w"> </span><span class="err">the</span><span class="w"> </span><span class="err">key</span><span class="w"> </span><span class="err">to</span><span class="w"> </span><span class="err">understanding</span><span class="w"> </span><span class="err">why</span><span class="w"> </span><span class="err">this</span><span class="w"> </span><span class="err">method</span><span class="w"> </span><span class="err">can</span><span class="w"> </span><span class="err">outperform</span><span class="w"> </span><span class="err">more</span><span class="w"> </span><span class="err">recent</span><span class="w"> </span><span class="err">GPUcompliant</span><span class="w"> </span><span class="err">approximate</span><span class="w"> </span><span class="err">nearest</span><span class="w"> </span><span class="err">neighbor</span><span class="w"> </span><span class="err">strategies</span><span class="w"> </span><span class="err">[47].</span>

<span class="err">###</span><span class="w"> </span><span class="err">5.1</span><span class="w"> </span><span class="err">Exact</span><span class="w"> </span><span class="err">search</span>

<span class="err">We</span><span class="w"> </span><span class="err">briefly</span><span class="w"> </span><span class="err">come</span><span class="w"> </span><span class="err">back</span><span class="w"> </span><span class="err">to</span><span class="w"> </span><span class="err">the</span><span class="w"> </span><span class="err">exhaustive</span><span class="w"> </span><span class="err">search</span><span class="w"> </span><span class="err">method,</span><span class="w"> </span><span class="err">often</span><span class="w"> </span><span class="err">referred</span><span class="w"> </span><span class="err">to</span><span class="w"> </span><span class="err">as</span><span class="w"> </span><span class="err">exact</span><span class="w"> </span><span class="err">brute-force.</span><span class="w"> </span><span class="err">It</span><span class="w"> </span><span class="err">is</span><span class="w"> </span><span class="err">interesting</span><span class="w"> </span><span class="err">on</span><span class="w"> </span><span class="err">its</span><span class="w"> </span><span class="err">own</span><span class="w"> </span><span class="err">for</span><span class="w"> </span><span class="err">exact</span><span class="w"> </span><span class="err">nearest</span><span class="w"> </span><span class="err">neighbor</span><span class="w"> </span><span class="err">search</span><span class="w"> </span><span class="err">in</span><span class="w"> </span><span class="err">small</span><span class="w"> </span><span class="err">datasets.</span><span class="w"> </span><span class="err">It</span><span class="w"> </span><span class="err">is</span><span class="w"> </span><span class="err">also</span><span class="w"> </span><span class="err">a</span><span class="w"> </span><span class="err">component</span><span class="w"> </span><span class="err">of</span><span class="w"> </span><span class="err">many</span><span class="w"> </span><span class="err">indexes</span><span class="w"> </span><span class="err">in</span><span class="w"> </span><span class="err">the</span><span class="w"> </span><span class="err">literature.</span><span class="w"> </span><span class="err">In</span><span class="w"> </span><span class="err">our</span><span class="w"> </span><span class="err">case,</span><span class="w"> </span><span class="err">we</span><span class="w"> </span><span class="err">use</span><span class="w"> </span><span class="err">it</span><span class="w"> </span><span class="err">for</span><span class="w"> </span><span class="err">the</span><span class="w"> </span><span class="err">IVFADC</span><span class="w"> </span><span class="err">coarse</span><span class="w"> </span><span class="err">quantizer</span><span class="w"> </span><span class="err">$q_{1}$.</span>

<span class="err">As</span><span class="w"> </span><span class="err">stated</span><span class="w"> </span><span class="err">in</span><span class="w"> </span><span class="err">Section</span><span class="w"> </span><span class="err">2,</span><span class="w"> </span><span class="err">the</span><span class="w"> </span><span class="err">distance</span><span class="w"> </span><span class="err">computation</span><span class="w"> </span><span class="err">boils</span><span class="w"> </span><span class="err">down</span><span class="w"> </span><span class="err">to</span><span class="w"> </span><span class="err">a</span><span class="w"> </span><span class="err">matrix</span><span class="w"> </span><span class="err">multiplication.</span><span class="w"> </span><span class="err">We</span><span class="w"> </span><span class="err">use</span><span class="w"> </span><span class="err">optimized</span><span class="w"> </span><span class="err">GEMM</span><span class="w"> </span><span class="err">routines</span><span class="w"> </span><span class="err">in</span><span class="w"> </span><span class="err">the</span><span class="w"> </span><span class="err">cuBLAS</span><span class="w"> </span><span class="err">library</span><span class="w"> </span><span class="err">to</span><span class="w"> </span><span class="err">calculate</span><span class="w"> </span><span class="err">the</span><span class="w"> </span><span class="err">$-2\left\langle</span><span class="w"> </span><span class="err">x_{j},</span><span class="w"> </span><span class="err">y_{i}\right\rangle$</span><span class="w"> </span><span class="err">term</span><span class="w"> </span><span class="err">for</span><span class="w"> </span><span class="err">L2</span><span class="w"> </span><span class="err">distance,</span><span class="w"> </span><span class="err">resulting</span><span class="w"> </span><span class="err">in</span><span class="w"> </span><span class="err">a</span><span class="w"> </span><span class="err">partial</span><span class="w"> </span><span class="err">distance</span><span class="w"> </span><span class="err">matrix</span><span class="w"> </span><span class="err">$D^{\prime}$.</span><span class="w"> </span><span class="err">To</span><span class="w"> </span><span class="err">complete</span><span class="w"> </span><span class="err">the</span><span class="w"> </span><span class="err">distance</span><span class="w"> </span><span class="err">calculation,</span><span class="w"> </span><span class="err">we</span><span class="w"> </span><span class="err">use</span><span class="w"> </span><span class="err">a</span><span class="w"> </span><span class="err">fused</span><span class="w"> </span><span class="err">$k$-selection</span><span class="w"> </span><span class="err">kernel</span><span class="w"> </span><span class="err">that</span><span class="w"> </span><span class="err">adds</span><span class="w"> </span><span class="err">the</span><span class="w"> </span><span class="err">$\left\|y_{i}\right\|^{2}$</span><span class="w"> </span><span class="err">term</span><span class="w"> </span><span class="err">to</span><span class="w"> </span><span class="err">each</span><span class="w"> </span><span class="err">entry</span><span class="w"> </span><span class="err">of</span><span class="w"> </span><span class="err">the</span><span class="w"> </span><span class="err">distance</span><span class="w"> </span><span class="err">matrix</span><span class="w"> </span><span class="err">and</span><span class="w"> </span><span class="err">immediately</span><span class="w"> </span><span class="err">submits</span><span class="w"> </span><span class="err">the</span><span class="w"> </span><span class="err">value</span><span class="w"> </span><span class="err">to</span><span class="w"> </span><span class="err">$k$-selection</span><span class="w"> </span><span class="err">in</span><span class="w"> </span><span class="err">registers.</span><span class="w"> </span><span class="err">The</span><span class="w"> </span><span class="err">$\left\|x_{j}\right\|^{2}$</span><span class="w"> </span><span class="err">term</span><span class="w"> </span><span class="err">need</span><span class="w"> </span><span class="err">not</span><span class="w"> </span><span class="err">be</span><span class="w"> </span><span class="err">taken</span><span class="w"> </span><span class="err">into</span><span class="w"> </span><span class="err">account</span><span class="w"> </span><span class="err">before</span><span class="w"> </span><span class="err">$k$-selection.</span><span class="w"> </span><span class="err">Kernel</span><span class="w"> </span><span class="err">fusion</span><span class="w"> </span><span class="err">thus</span><span class="w"> </span><span class="err">allows</span><span class="w"> </span><span class="err">for</span><span class="w"> </span><span class="err">only</span><span class="w"> </span><span class="err">2</span><span class="w"> </span><span class="err">passes</span><span class="w"> </span><span class="err">(GEMM</span><span class="w"> </span><span class="err">write,</span><span class="w"> </span><span class="err">$k$-select</span><span class="w"> </span><span class="err">read)</span><span class="w"> </span><span class="err">over</span><span class="w"> </span><span class="err">$D^{\prime}$,</span><span class="w"> </span><span class="err">compared</span><span class="w"> </span><span class="err">to</span><span class="w"> </span><span class="err">other</span><span class="w"> </span><span class="err">implementations</span><span class="w"> </span><span class="err">that</span><span class="w"> </span><span class="err">may</span><span class="w"> </span><span class="err">require</span><span class="w"> </span><span class="err">3</span><span class="w"> </span><span class="err">or</span><span class="w"> </span><span class="err">more.</span><span class="w"> </span><span class="err">Row-wise</span><span class="w"> </span><span class="err">$k$-selection</span><span class="w"> </span><span class="err">is</span><span class="w"> </span><span class="err">likely</span><span class="w"> </span><span class="err">not</span><span class="w"> </span><span class="err">fusable</span><span class="w"> </span><span class="err">with</span><span class="w"> </span><span class="err">a</span><span class="w"> </span><span class="err">well-tuned</span><span class="w"> </span><span class="err">GEMM</span><span class="w"> </span><span class="err">kernel,</span><span class="w"> </span><span class="err">or</span><span class="w"> </span><span class="err">would</span><span class="w"> </span><span class="err">result</span><span class="w"> </span><span class="err">in</span><span class="w"> </span><span class="err">lower</span><span class="w"> </span><span class="err">overall</span><span class="w"> </span><span class="err">efficiency.</span>

<span class="err">As</span><span class="w"> </span><span class="err">$D^{\prime}$</span><span class="w"> </span><span class="err">does</span><span class="w"> </span><span class="err">not</span><span class="w"> </span><span class="err">fit</span><span class="w"> </span><span class="err">in</span><span class="w"> </span><span class="err">GPU</span><span class="w"> </span><span class="err">memory</span><span class="w"> </span><span class="err">for</span><span class="w"> </span><span class="err">realistic</span><span class="w"> </span><span class="err">problem</span><span class="w"> </span><span class="err">sizes,</span><span class="w"> </span><span class="err">the</span><span class="w"> </span><span class="err">problem</span><span class="w"> </span><span class="err">is</span><span class="w"> </span><span class="err">tiled</span><span class="w"> </span><span class="err">over</span><span class="w"> </span><span class="err">the</span><span class="w"> </span><span class="err">batch</span><span class="w"> </span><span class="err">of</span><span class="w"> </span><span class="err">queries,</span><span class="w"> </span><span class="err">with</span><span class="w"> </span><span class="err">$t_{q}</span><span class="w"> </span><span class="err">\leq</span><span class="w"> </span><span class="err">n_{q}$</span><span class="w"> </span><span class="err">queries</span><span class="w"> </span><span class="err">being</span><span class="w"> </span><span class="err">run</span><span class="w"> </span><span class="err">in</span><span class="w"> </span><span class="err">a</span><span class="w"> </span><span class="err">single</span><span class="w"> </span><span class="err">tile.</span><span class="w"> </span><span class="err">Each</span><span class="w"> </span><span class="err">of</span><span class="w"> </span><span class="err">the</span><span class="w"> </span><span class="err">$\left\lceil</span><span class="w"> </span><span class="err">n_{q}</span><span class="w"> </span><span class="err">/</span><span class="w"> </span><span class="err">t_{q}\right\rceil$</span><span class="w"> </span><span class="err">tiles</span><span class="w"> </span><span class="err">are</span><span class="w"> </span><span class="err">independent</span><span class="w"> </span><span class="err">problems,</span><span class="w"> </span><span class="err">but</span><span class="w"> </span><span class="err">we</span><span class="w"> </span><span class="err">run</span><span class="w"> </span><span class="err">two</span><span class="w"> </span><span class="err">in</span><span class="w"> </span><span class="err">parallel</span><span class="w"> </span><span class="err">on</span><span class="w"> </span><span class="err">different</span><span class="w"> </span><span class="err">streams</span><span class="w"> </span><span class="err">to</span><span class="w"> </span><span class="err">better</span><span class="w"> </span><span class="err">occupy</span><span class="w"> </span><span class="err">the</span><span class="w"> </span><span class="err">GPU,</span><span class="w"> </span><span class="err">so</span><span class="w"> </span><span class="err">the</span><span class="w"> </span><span class="err">effective</span><span class="w"> </span><span class="err">memory</span><span class="w"> </span><span class="err">requirement</span><span class="w"> </span><span class="err">of</span><span class="w"> </span><span class="err">$D$</span><span class="w"> </span><span class="err">is</span><span class="w"> </span><span class="err">$\mathcal{O}\left(2</span><span class="w"> </span><span class="err">\ell</span><span class="w"> </span><span class="err">t_{q}\right)$.</span><span class="w"> </span><span class="err">The</span><span class="w"> </span><span class="err">computation</span><span class="w"> </span><span class="err">can</span><span class="w"> </span><span class="err">similarly</span><span class="w"> </span><span class="err">be</span><span class="w"> </span><span class="err">tiled</span><span class="w"> </span><span class="err">over</span><span class="w"> </span><span class="err">$\ell$.</span><span class="w"> </span><span class="err">For</span><span class="w"> </span><span class="err">very</span><span class="w"> </span><span class="err">large</span><span class="w"> </span><span class="err">input</span><span class="w"> </span><span class="err">coming</span><span class="w"> </span><span class="err">from</span><span class="w"> </span><span class="err">the</span><span class="w"> </span><span class="err">CPU,</span><span class="w"> </span><span class="err">we</span><span class="w"> </span><span class="err">support</span><span class="w"> </span><span class="err">buffering</span><span class="w"> </span><span class="err">with</span><span class="w"> </span><span class="err">pinned</span><span class="w"> </span><span class="err">memory</span><span class="w"> </span><span class="err">to</span><span class="w"> </span><span class="err">overlap</span><span class="w"> </span><span class="err">CPU</span><span class="w"> </span><span class="err">to</span><span class="w"> </span><span class="err">GPU</span><span class="w"> </span><span class="err">copy</span><span class="w"> </span><span class="err">with</span><span class="w"> </span><span class="err">GPU</span><span class="w"> </span><span class="err">compute.</span>

<span class="err">###</span><span class="w"> </span><span class="err">5.2</span><span class="w"> </span><span class="err">IVFADC</span><span class="w"> </span><span class="err">indexing</span>

<span class="err">PQ</span><span class="w"> </span><span class="err">lookup</span><span class="w"> </span><span class="err">tables.</span><span class="w"> </span><span class="err">At</span><span class="w"> </span><span class="err">its</span><span class="w"> </span><span class="err">core,</span><span class="w"> </span><span class="err">the</span><span class="w"> </span><span class="err">IVFADC</span><span class="w"> </span><span class="err">requires</span><span class="w"> </span><span class="err">computing</span><span class="w"> </span><span class="err">the</span><span class="w"> </span><span class="err">distance</span><span class="w"> </span><span class="err">from</span><span class="w"> </span><span class="err">a</span><span class="w"> </span><span class="err">vector</span><span class="w"> </span><span class="err">to</span><span class="w"> </span><span class="err">a</span><span class="w"> </span><span class="err">set</span><span class="w"> </span><span class="err">of</span><span class="w"> </span><span class="err">product</span><span class="w"> </span><span class="err">quantization</span><span class="w"> </span><span class="err">reproduction</span><span class="w"> </span><span class="err">values.</span><span class="w"> </span><span class="err">By</span><span class="w"> </span><span class="err">developing</span><span class="w"> </span><span class="err">Equation</span><span class="w"> </span><span class="err">(6)</span><span class="w"> </span><span class="err">for</span><span class="w"> </span><span class="err">a</span><span class="w"> </span><span class="err">database</span><span class="w"> </span><span class="err">vector</span><span class="w"> </span><span class="err">$y$,</span><span class="w"> </span><span class="err">we</span><span class="w"> </span><span class="err">obtain:</span>

<span class="err">$$</span>
<span class="err">\|x-q(y)\|_{2}^{2}=\left\|x-q_{1}(y)-q_{2}\left(y-q_{1}(y)\right)\right\|_{2}^{2}</span>
<span class="err">$$</span>

<span class="err">If</span><span class="w"> </span><span class="err">we</span><span class="w"> </span><span class="err">decompose</span><span class="w"> </span><span class="err">the</span><span class="w"> </span><span class="err">residual</span><span class="w"> </span><span class="err">vectors</span><span class="w"> </span><span class="err">left</span><span class="w"> </span><span class="err">after</span><span class="w"> </span><span class="err">$q_{1}$</span><span class="w"> </span><span class="err">as:</span>

<span class="err">$$</span>
<span class="err">\begin{aligned}</span>
<span class="err">y-q_{1}(y)</span><span class="w"> </span><span class="err">&amp;</span><span class="w"> </span><span class="err">=\left[\overrightarrow{y^{1}}</span><span class="w"> </span><span class="err">\cdots</span><span class="w"> </span><span class="err">\overrightarrow{y^{k}}\right]</span><span class="w"> </span><span class="err">\text</span><span class="w"> </span><span class="err">{</span><span class="w"> </span><span class="err">and</span><span class="w"> </span><span class="err">}</span><span class="w"> </span><span class="err">\\</span>
<span class="err">x-q_{1}(y)</span><span class="w"> </span><span class="err">&amp;</span><span class="w"> </span><span class="err">=\left[\overrightarrow{x^{1}}</span><span class="w"> </span><span class="err">\cdots</span><span class="w"> </span><span class="err">\overrightarrow{x^{k}}\right]</span>
<span class="err">\end{aligned}</span>
<span class="err">$$</span>

<span class="err">then</span><span class="w"> </span><span class="err">the</span><span class="w"> </span><span class="err">distance</span><span class="w"> </span><span class="err">is</span><span class="w"> </span><span class="err">rewritten</span><span class="w"> </span><span class="err">as:</span>

<span class="err">$$</span>
<span class="err">\|x-q(y)\|_{2}^{2}=\left\|\widetilde{x^{1}}-q^{1}\left(\widetilde{y^{1}}\right)\right\|_{2}^{2}+\ldots+\left\|\widetilde{x^{k}}-q^{k}\left(\widetilde{y^{k}}\right)\right\|_{2}^{2}</span>
<span class="err">$$</span>

<span class="err">Each</span><span class="w"> </span><span class="err">quantizer</span><span class="w"> </span><span class="err">$q^{1},</span><span class="w"> </span><span class="err">\ldots,</span><span class="w"> </span><span class="err">q^{k}$</span><span class="w"> </span><span class="err">has</span><span class="w"> </span><span class="err">256</span><span class="w"> </span><span class="err">reproduction</span><span class="w"> </span><span class="err">values,</span><span class="w"> </span><span class="err">so</span><span class="w"> </span><span class="err">when</span><span class="w"> </span><span class="err">$x$</span><span class="w"> </span><span class="err">and</span><span class="w"> </span><span class="err">$q_{1}(y)$</span><span class="w"> </span><span class="err">are</span><span class="w"> </span><span class="err">known</span><span class="w"> </span><span class="err">all</span><span class="w"> </span><span class="err">distances</span><span class="w"> </span><span class="err">can</span><span class="w"> </span><span class="err">be</span><span class="w"> </span><span class="err">precomputed</span><span class="w"> </span><span class="err">and</span><span class="w"> </span><span class="err">stored</span><span class="w"> </span><span class="err">in</span><span class="w"> </span><span class="err">tables</span><span class="w"> </span><span class="err">$T_{1},</span><span class="w"> </span><span class="err">\ldots,</span><span class="w"> </span><span class="err">T_{b}$</span><span class="w"> </span><span class="err">each</span><span class="w"> </span><span class="err">of</span><span class="w"> </span><span class="err">size</span><span class="w"> </span><span class="err">256</span><span class="w"> </span><span class="err">[25].</span><span class="w"> </span><span class="err">Computing</span><span class="w"> </span><span class="err">the</span><span class="w"> </span><span class="err">sum</span><span class="w"> </span><span class="err">(10)</span><span class="w"> </span><span class="err">consists</span><span class="w"> </span><span class="err">of</span><span class="w"> </span><span class="err">$b$</span><span class="w"> </span><span class="err">look-ups</span><span class="w"> </span><span class="err">and</span><span class="w"> </span><span class="err">additions.</span><span class="w"> </span><span class="err">Comparing</span><span class="w"> </span><span class="err">the</span><span class="w"> </span><span class="err">cost</span><span class="w"> </span><span class="err">to</span><span class="w"> </span><span class="err">compute</span><span class="w"> </span><span class="err">$n$</span><span class="w"> </span><span class="err">distances:</span>

<span class="err">-</span><span class="w"> </span><span class="err">Explicit</span><span class="w"> </span><span class="err">computation:</span><span class="w"> </span><span class="err">$n</span><span class="w"> </span><span class="err">\times</span><span class="w"> </span><span class="err">d$</span><span class="w"> </span><span class="err">mutiply-adds;</span>
<span class="err">-</span><span class="w"> </span><span class="err">With</span><span class="w"> </span><span class="err">lookup</span><span class="w"> </span><span class="err">tables:</span><span class="w"> </span><span class="err">$256</span><span class="w"> </span><span class="err">\times</span><span class="w"> </span><span class="err">d$</span><span class="w"> </span><span class="err">multiply-adds</span><span class="w"> </span><span class="err">and</span><span class="w"> </span><span class="err">$n</span><span class="w"> </span><span class="err">\times</span><span class="w"> </span><span class="err">b$</span><span class="w"> </span><span class="err">lookup-adds.</span>

<span class="err">This</span><span class="w"> </span><span class="err">is</span><span class="w"> </span><span class="err">the</span><span class="w"> </span><span class="err">key</span><span class="w"> </span><span class="err">to</span><span class="w"> </span><span class="err">the</span><span class="w"> </span><span class="err">efficiency</span><span class="w"> </span><span class="err">of</span><span class="w"> </span><span class="err">the</span><span class="w"> </span><span class="err">product</span><span class="w"> </span><span class="err">quantizer.</span><span class="w"> </span><span class="err">In</span><span class="w"> </span><span class="err">our</span><span class="w"> </span><span class="err">GPU</span><span class="w"> </span><span class="err">implementation,</span><span class="w"> </span><span class="err">$b$</span><span class="w"> </span><span class="err">is</span><span class="w"> </span><span class="err">any</span><span class="w"> </span><span class="err">multiple</span><span class="w"> </span><span class="err">of</span><span class="w"> </span><span class="err">4</span><span class="w"> </span><span class="err">up</span><span class="w"> </span><span class="err">to</span><span class="w"> </span><span class="err">64.</span><span class="w"> </span><span class="err">The</span><span class="w"> </span><span class="err">codes</span><span class="w"> </span><span class="err">are</span><span class="w"> </span><span class="err">stored</span><span class="w"> </span><span class="err">as</span><span class="w"> </span><span class="err">sequential</span><span class="w"> </span><span class="err">groups</span><span class="w"> </span><span class="err">of</span><span class="w"> </span><span class="err">$b$</span><span class="w"> </span><span class="err">bytes</span><span class="w"> </span><span class="err">per</span><span class="w"> </span><span class="err">vector</span><span class="w"> </span><span class="err">within</span><span class="w"> </span><span class="err">lists.</span>

<span class="err">IVFADC</span><span class="w"> </span><span class="err">lookup</span><span class="w"> </span><span class="err">tables.</span><span class="w"> </span><span class="err">When</span><span class="w"> </span><span class="err">scanning</span><span class="w"> </span><span class="err">over</span><span class="w"> </span><span class="err">the</span><span class="w"> </span><span class="err">elements</span><span class="w"> </span><span class="err">of</span><span class="w"> </span><span class="err">the</span><span class="w"> </span><span class="err">inverted</span><span class="w"> </span><span class="err">list</span><span class="w"> </span><span class="err">$\mathcal{I}_{L}$</span><span class="w"> </span><span class="err">(where</span><span class="w"> </span><span class="err">by</span><span class="w"> </span><span class="err">definition</span><span class="w"> </span><span class="err">$q_{1}(y)$</span><span class="w"> </span><span class="err">is</span><span class="w"> </span><span class="err">constant),</span><span class="w"> </span><span class="err">the</span><span class="w"> </span><span class="err">look-up</span><span class="w"> </span><span class="err">table</span><span class="w"> </span><span class="err">method</span><span class="w"> </span><span class="err">can</span><span class="w"> </span><span class="err">be</span><span class="w"> </span><span class="err">applied,</span><span class="w"> </span><span class="err">as</span><span class="w"> </span><span class="err">the</span><span class="w"> </span><span class="err">query</span><span class="w"> </span><span class="err">$x$</span><span class="w"> </span><span class="err">and</span><span class="w"> </span><span class="err">$q_{1}(y)$</span><span class="w"> </span><span class="err">are</span><span class="w"> </span><span class="err">known.</span>

<span class="err">Moreover,</span><span class="w"> </span><span class="err">the</span><span class="w"> </span><span class="err">computation</span><span class="w"> </span><span class="err">of</span><span class="w"> </span><span class="err">the</span><span class="w"> </span><span class="err">tables</span><span class="w"> </span><span class="err">$T_{1}</span><span class="w"> </span><span class="err">\ldots</span><span class="w"> </span><span class="err">T_{b}$</span><span class="w"> </span><span class="err">is</span><span class="w"> </span><span class="err">further</span><span class="w"> </span><span class="err">optimized</span><span class="w"> </span><span class="err">[5].</span><span class="w"> </span><span class="err">The</span><span class="w"> </span><span class="err">expression</span><span class="w"> </span><span class="err">of</span><span class="w"> </span><span class="err">$\|x-q(y)\|_{2}^{2}$</span><span class="w"> </span><span class="err">in</span><span class="w"> </span><span class="err">Equation</span><span class="w"> </span><span class="err">(7)</span><span class="w"> </span><span class="err">can</span><span class="w"> </span><span class="err">be</span><span class="w"> </span><span class="err">decomposed</span><span class="w"> </span><span class="err">as:</span>

<span class="err">$$</span>
<span class="err">\underbrace{\left\|q_{2}(\ldots)\right\|_{2}^{2}+2\left\langle</span><span class="w"> </span><span class="err">q_{1}(y),</span><span class="w"> </span><span class="err">q_{2}(\ldots)\right\rangle}_{\text</span><span class="w"> </span><span class="err">{term</span><span class="w"> </span><span class="err">}</span><span class="w"> </span><span class="err">1}+\underbrace{\left\|x-q_{1}(y)\right\|_{2}^{2}}_{\text</span><span class="w"> </span><span class="err">{term</span><span class="w"> </span><span class="err">}</span><span class="w"> </span><span class="err">2}-2</span><span class="w"> </span><span class="err">\underbrace{\left\langle</span><span class="w"> </span><span class="err">x,</span><span class="w"> </span><span class="err">q_{2}(\ldots)\right\rangle}_{\text</span><span class="w"> </span><span class="err">{term</span><span class="w"> </span><span class="err">}</span><span class="w"> </span><span class="err">3}</span>
<span class="err">$$</span>

<span class="err">The</span><span class="w"> </span><span class="err">objective</span><span class="w"> </span><span class="err">is</span><span class="w"> </span><span class="err">to</span><span class="w"> </span><span class="err">minimize</span><span class="w"> </span><span class="err">inner</span><span class="w"> </span><span class="err">loop</span><span class="w"> </span><span class="err">computations.</span><span class="w"> </span><span class="err">The</span><span class="w"> </span><span class="err">computations</span><span class="w"> </span><span class="err">we</span><span class="w"> </span><span class="err">can</span><span class="w"> </span><span class="err">do</span><span class="w"> </span><span class="err">in</span><span class="w"> </span><span class="err">advance</span><span class="w"> </span><span class="err">and</span><span class="w"> </span><span class="err">store</span><span class="w"> </span><span class="err">in</span><span class="w"> </span><span class="err">lookup</span><span class="w"> </span><span class="err">tables</span><span class="w"> </span><span class="err">are</span><span class="w"> </span><span class="err">as</span><span class="w"> </span><span class="err">follows:</span>

<span class="err">-</span><span class="w"> </span><span class="err">Term</span><span class="w"> </span><span class="err">1</span><span class="w"> </span><span class="err">is</span><span class="w"> </span><span class="err">independent</span><span class="w"> </span><span class="err">of</span><span class="w"> </span><span class="err">the</span><span class="w"> </span><span class="err">query.</span><span class="w"> </span><span class="err">It</span><span class="w"> </span><span class="err">can</span><span class="w"> </span><span class="err">be</span><span class="w"> </span><span class="err">precomputed</span><span class="w"> </span><span class="err">from</span><span class="w"> </span><span class="err">the</span><span class="w"> </span><span class="err">quantizers,</span><span class="w"> </span><span class="err">and</span><span class="w"> </span><span class="err">stored</span><span class="w"> </span><span class="err">in</span><span class="w"> </span><span class="err">a</span><span class="w"> </span><span class="err">table</span><span class="w"> </span><span class="err">$\mathcal{T}$</span><span class="w"> </span><span class="err">of</span><span class="w"> </span><span class="err">size</span><span class="w"> </span><span class="err">$\left|\mathcal{C}_{1}\right|</span><span class="w"> </span><span class="err">\times</span><span class="w"> </span><span class="err">256</span><span class="w"> </span><span class="err">\times</span><span class="w"> </span><span class="err">b$;</span>
<span class="err">-</span><span class="w"> </span><span class="err">Term</span><span class="w"> </span><span class="err">2</span><span class="w"> </span><span class="err">is</span><span class="w"> </span><span class="err">the</span><span class="w"> </span><span class="err">distance</span><span class="w"> </span><span class="err">to</span><span class="w"> </span><span class="err">$q_{1}$</span><span class="w"> </span><span class="err">&#39;s</span><span class="w"> </span><span class="err">reproduction</span><span class="w"> </span><span class="err">value.</span><span class="w"> </span><span class="err">It</span><span class="w"> </span><span class="err">is</span><span class="w"> </span><span class="err">thus</span><span class="w"> </span><span class="err">a</span><span class="w"> </span><span class="err">by-product</span><span class="w"> </span><span class="err">of</span><span class="w"> </span><span class="err">the</span><span class="w"> </span><span class="err">first-level</span><span class="w"> </span><span class="err">quantizer</span><span class="w"> </span><span class="err">$q_{1}$;</span>
<span class="err">-</span><span class="w"> </span><span class="err">Term</span><span class="w"> </span><span class="err">3</span><span class="w"> </span><span class="err">can</span><span class="w"> </span><span class="err">be</span><span class="w"> </span><span class="err">computed</span><span class="w"> </span><span class="err">independently</span><span class="w"> </span><span class="err">of</span><span class="w"> </span><span class="err">the</span><span class="w"> </span><span class="err">inverted</span><span class="w"> </span><span class="err">list.</span><span class="w"> </span><span class="err">Its</span><span class="w"> </span><span class="err">computation</span><span class="w"> </span><span class="err">costs</span><span class="w"> </span><span class="err">$d</span><span class="w"> </span><span class="err">\times</span><span class="w"> </span><span class="err">256$</span><span class="w"> </span><span class="err">multiply-adds.</span>

<span class="err">This</span><span class="w"> </span><span class="err">decomposition</span><span class="w"> </span><span class="err">is</span><span class="w"> </span><span class="err">used</span><span class="w"> </span><span class="err">to</span><span class="w"> </span><span class="err">produce</span><span class="w"> </span><span class="err">the</span><span class="w"> </span><span class="err">lookup</span><span class="w"> </span><span class="err">tables</span><span class="w"> </span><span class="err">$T_{1}</span><span class="w"> </span><span class="err">\ldots</span><span class="w"> </span><span class="err">T_{b}$</span><span class="w"> </span><span class="err">used</span><span class="w"> </span><span class="err">during</span><span class="w"> </span><span class="err">the</span><span class="w"> </span><span class="err">scan</span><span class="w"> </span><span class="err">of</span><span class="w"> </span><span class="err">the</span><span class="w"> </span><span class="err">inverted</span><span class="w"> </span><span class="err">list.</span><span class="w"> </span><span class="err">For</span><span class="w"> </span><span class="err">a</span><span class="w"> </span><span class="err">single</span><span class="w"> </span><span class="err">query,</span><span class="w"> </span><span class="err">computing</span><span class="w"> </span><span class="err">the</span><span class="w"> </span><span class="err">$\tau</span><span class="w"> </span><span class="err">\times</span><span class="w"> </span><span class="err">b$</span><span class="w"> </span><span class="err">tables</span><span class="w"> </span><span class="err">from</span><span class="w"> </span><span class="err">scratch</span><span class="w"> </span><span class="err">costs</span><span class="w"> </span><span class="err">$\tau</span><span class="w"> </span><span class="err">\times</span><span class="w"> </span><span class="err">d</span><span class="w"> </span><span class="err">\times</span><span class="w"> </span><span class="err">256$</span><span class="w"> </span><span class="err">multiply-adds,</span><span class="w"> </span><span class="err">while</span><span class="w"> </span><span class="err">this</span><span class="w"> </span><span class="err">decomposition</span><span class="w"> </span><span class="err">costs</span><span class="w"> </span><span class="err">$256</span><span class="w"> </span><span class="err">\times</span><span class="w"> </span><span class="err">d$</span><span class="w"> </span><span class="err">multiply-adds</span><span class="w"> </span><span class="err">and</span><span class="w"> </span><span class="err">$\tau</span><span class="w"> </span><span class="err">\times</span><span class="w"> </span><span class="err">b</span><span class="w"> </span><span class="err">\times</span><span class="w"> </span><span class="err">256$</span><span class="w"> </span><span class="err">additions.</span><span class="w"> </span><span class="err">On</span><span class="w"> </span><span class="err">the</span><span class="w"> </span><span class="err">GPU,</span><span class="w"> </span><span class="err">the</span><span class="w"> </span><span class="err">memory</span><span class="w"> </span><span class="err">usage</span><span class="w"> </span><span class="err">of</span><span class="w"> </span><span class="err">$\mathcal{T}$</span><span class="w"> </span><span class="err">can</span><span class="w"> </span><span class="err">be</span><span class="w"> </span><span class="err">prohibitive,</span><span class="w"> </span><span class="err">so</span><span class="w"> </span><span class="err">we</span><span class="w"> </span><span class="err">enable</span><span class="w"> </span><span class="err">the</span><span class="w"> </span><span class="err">decomposition</span><span class="w"> </span><span class="err">only</span><span class="w"> </span><span class="err">when</span><span class="w"> </span><span class="err">memory</span><span class="w"> </span><span class="err">is</span><span class="w"> </span><span class="err">a</span><span class="w"> </span><span class="err">not</span><span class="w"> </span><span class="err">a</span><span class="w"> </span><span class="err">concern.</span>

<span class="err">###</span><span class="w"> </span><span class="err">5.3</span><span class="w"> </span><span class="err">GPU</span><span class="w"> </span><span class="err">implementation</span>

<span class="err">Algorithm</span><span class="w"> </span><span class="err">4</span><span class="w"> </span><span class="err">summarizes</span><span class="w"> </span><span class="err">the</span><span class="w"> </span><span class="err">process</span><span class="w"> </span><span class="err">as</span><span class="w"> </span><span class="err">one</span><span class="w"> </span><span class="err">would</span><span class="w"> </span><span class="err">implement</span><span class="w"> </span><span class="err">it</span><span class="w"> </span><span class="err">on</span><span class="w"> </span><span class="err">a</span><span class="w"> </span><span class="err">CPU.</span><span class="w"> </span><span class="err">The</span><span class="w"> </span><span class="err">inverted</span><span class="w"> </span><span class="err">lists</span><span class="w"> </span><span class="err">are</span><span class="w"> </span><span class="err">stored</span><span class="w"> </span><span class="err">as</span><span class="w"> </span><span class="err">two</span><span class="w"> </span><span class="err">separate</span><span class="w"> </span><span class="err">arrays,</span><span class="w"> </span><span class="err">for</span><span class="w"> </span><span class="err">PQ</span><span class="w"> </span><span class="err">codes</span><span class="w"> </span><span class="err">and</span><span class="w"> </span><span class="err">associated</span><span class="w"> </span><span class="err">IDs.</span><span class="w"> </span><span class="err">IDs</span><span class="w"> </span><span class="err">are</span><span class="w"> </span><span class="err">resolved</span><span class="w"> </span><span class="err">only</span><span class="w"> </span><span class="err">if</span><span class="w"> </span><span class="err">$k$-selection</span><span class="w"> </span><span class="err">determines</span><span class="w"> </span><span class="err">$k$-nearest</span><span class="w"> </span><span class="err">membership.</span><span class="w"> </span><span class="err">This</span><span class="w"> </span><span class="err">lookup</span><span class="w"> </span><span class="err">yields</span><span class="w"> </span><span class="err">a</span><span class="w"> </span><span class="err">few</span><span class="w"> </span><span class="err">sparse</span><span class="w"> </span><span class="err">memory</span><span class="w"> </span><span class="err">reads</span><span class="w"> </span><span class="err">in</span><span class="w"> </span><span class="err">a</span><span class="w"> </span><span class="err">large</span><span class="w"> </span><span class="err">array,</span><span class="w"> </span><span class="err">thus</span><span class="w"> </span><span class="err">the</span><span class="w"> </span><span class="err">IDs</span><span class="w"> </span><span class="err">can</span><span class="w"> </span><span class="err">optionally</span><span class="w"> </span><span class="err">be</span><span class="w"> </span><span class="err">stored</span><span class="w"> </span><span class="err">on</span><span class="w"> </span><span class="err">CPU</span><span class="w"> </span><span class="err">for</span><span class="w"> </span><span class="err">tiny</span><span class="w"> </span><span class="err">performance</span><span class="w"> </span><span class="err">cost.</span>

<span class="err">List</span><span class="w"> </span><span class="err">scanning.</span><span class="w"> </span><span class="err">A</span><span class="w"> </span><span class="err">kernel</span><span class="w"> </span><span class="err">is</span><span class="w"> </span><span class="err">responsible</span><span class="w"> </span><span class="err">for</span><span class="w"> </span><span class="err">scanning</span><span class="w"> </span><span class="err">the</span><span class="w"> </span><span class="err">$\tau$</span><span class="w"> </span><span class="err">closest</span><span class="w"> </span><span class="err">inverted</span><span class="w"> </span><span class="err">lists</span><span class="w"> </span><span class="err">for</span><span class="w"> </span><span class="err">each</span><span class="w"> </span><span class="err">query,</span><span class="w"> </span><span class="err">and</span><span class="w"> </span><span class="err">calculating</span><span class="w"> </span><span class="err">the</span><span class="w"> </span><span class="err">pervector</span><span class="w"> </span><span class="err">pair</span><span class="w"> </span><span class="err">distances</span><span class="w"> </span><span class="err">using</span><span class="w"> </span><span class="err">the</span><span class="w"> </span><span class="err">lookup</span><span class="w"> </span><span class="err">tables</span><span class="w"> </span><span class="err">$T_{i}$.</span><span class="w"> </span><span class="err">The</span><span class="w"> </span><span class="err">$T_{i}$</span><span class="w"> </span><span class="err">are</span><span class="w"> </span><span class="err">stored</span><span class="w"> </span><span class="err">in</span><span class="w"> </span><span class="err">shared</span><span class="w"> </span><span class="err">memory:</span><span class="w"> </span><span class="err">up</span><span class="w"> </span><span class="err">to</span><span class="w"> </span><span class="err">$n_{q}</span><span class="w"> </span><span class="err">\times</span><span class="w"> </span><span class="err">\tau</span><span class="w"> </span><span class="err">\times</span><span class="w"> </span><span class="err">\max</span><span class="w"> </span><span class="err">_{i}\left|\mathcal{I}_{i}\right|</span><span class="w"> </span><span class="err">\times</span><span class="w"> </span><span class="err">b$</span><span class="w"> </span><span class="err">lookups</span><span class="w"> </span><span class="err">are</span><span class="w"> </span><span class="err">required</span><span class="w"> </span><span class="err">for</span><span class="w"> </span><span class="err">a</span><span class="w"> </span><span class="err">query</span><span class="w"> </span><span class="err">set</span><span class="w"> </span><span class="err">(trillions</span><span class="w"> </span><span class="err">of</span><span class="w"> </span><span class="err">accesses</span><span class="w"> </span><span class="err">in</span><span class="w"> </span><span class="err">practice),</span><span class="w"> </span><span class="err">and</span><span class="w"> </span><span class="err">are</span><span class="w"> </span><span class="err">random</span><span class="w"> </span><span class="err">access.</span><span class="w"> </span><span class="err">This</span><span class="w"> </span><span class="err">limits</span><span class="w"> </span><span class="err">$b$</span><span class="w"> </span><span class="err">to</span><span class="w"> </span><span class="err">at</span><span class="w"> </span><span class="err">most</span><span class="w"> </span><span class="err">48</span><span class="w"> </span><span class="err">(32bit</span><span class="w"> </span><span class="err">floating</span><span class="w"> </span><span class="err">point)</span><span class="w"> </span><span class="err">or</span><span class="w"> </span><span class="err">96</span><span class="w"> </span><span class="err">(16-bit</span><span class="w"> </span><span class="err">floating</span><span class="w"> </span><span class="err">point)</span><span class="w"> </span><span class="err">with</span><span class="w"> </span><span class="err">current</span><span class="w"> </span><span class="err">architectures.</span><span class="w"> </span><span class="err">In</span><span class="w"> </span><span class="err">case</span><span class="w"> </span><span class="err">we</span><span class="w"> </span><span class="err">do</span><span class="w"> </span><span class="err">not</span><span class="w"> </span><span class="err">use</span><span class="w"> </span><span class="err">the</span><span class="w"> </span><span class="err">decomposition</span><span class="w"> </span><span class="err">of</span><span class="w"> </span><span class="err">Equation</span><span class="w"> </span><span class="err">(11),</span><span class="w"> </span><span class="err">the</span><span class="w"> </span><span class="err">$T_{i}$</span><span class="w"> </span><span class="err">are</span><span class="w"> </span><span class="err">calculated</span><span class="w"> </span><span class="err">by</span><span class="w"> </span><span class="err">a</span><span class="w"> </span><span class="err">separate</span><span class="w"> </span><span class="err">kernel</span><span class="w"> </span><span class="err">before</span><span class="w"> </span><span class="err">scanning.</span>

<span class="err">Multi-pass</span><span class="w"> </span><span class="err">kernels.</span><span class="w"> </span><span class="err">Each</span><span class="w"> </span><span class="err">$n_{q}</span><span class="w"> </span><span class="err">\times</span><span class="w"> </span><span class="err">\tau$</span><span class="w"> </span><span class="err">pairs</span><span class="w"> </span><span class="err">of</span><span class="w"> </span><span class="err">query</span><span class="w"> </span><span class="err">against</span><span class="w"> </span><span class="err">inverted</span><span class="w"> </span><span class="err">list</span><span class="w"> </span><span class="err">can</span><span class="w"> </span><span class="err">be</span><span class="w"> </span><span class="err">processed</span><span class="w"> </span><span class="err">independently.</span><span class="w"> </span><span class="err">At</span><span class="w"> </span><span class="err">one</span><span class="w"> </span><span class="err">extreme,</span><span class="w"> </span><span class="err">a</span><span class="w"> </span><span class="err">block</span><span class="w"> </span><span class="err">is</span><span class="w"> </span><span class="err">dedicated</span><span class="w"> </span><span class="err">to</span><span class="w"> </span><span class="err">each</span><span class="w"> </span><span class="err">of</span><span class="w"> </span><span class="err">these,</span><span class="w"> </span><span class="err">resulting</span><span class="w"> </span><span class="err">in</span><span class="w"> </span><span class="err">up</span><span class="w"> </span><span class="err">to</span><span class="w"> </span><span class="err">$n_{q}</span><span class="w"> </span><span class="err">\times</span><span class="w"> </span><span class="err">\tau</span><span class="w"> </span><span class="err">\times</span><span class="w"> </span><span class="err">\max</span><span class="w"> </span><span class="err">_{i}\left|\mathcal{I}_{i}\right|$</span><span class="w"> </span><span class="err">partial</span><span class="w"> </span><span class="err">results</span><span class="w"> </span><span class="err">being</span><span class="w"> </span><span class="err">written</span><span class="w"> </span><span class="err">back</span><span class="w"> </span><span class="err">to</span><span class="w"> </span><span class="err">global</span><span class="w"> </span><span class="err">memory,</span><span class="w"> </span><span class="err">which</span><span class="w"> </span><span class="err">is</span><span class="w"> </span><span class="err">then</span><span class="w"> </span><span class="err">$k$-selected</span><span class="w"> </span><span class="err">to</span><span class="w"> </span><span class="err">$n_{q}</span><span class="w"> </span><span class="err">\times</span><span class="w"> </span><span class="err">k$</span><span class="w"> </span><span class="err">final</span><span class="w"> </span><span class="err">results.</span><span class="w"> </span><span class="err">This</span><span class="w"> </span><span class="err">yields</span><span class="w"> </span><span class="err">high</span><span class="w"> </span><span class="err">parallelism</span><span class="w"> </span><span class="err">but</span><span class="w"> </span><span class="err">can</span><span class="w"> </span><span class="err">exceed</span><span class="w"> </span><span class="err">available</span><span class="w"> </span><span class="err">GPU</span><span class="w"> </span><span class="err">global</span><span class="w"> </span><span class="err">memory;</span><span class="w"> </span><span class="err">as</span><span class="w"> </span><span class="err">with</span><span class="w"> </span><span class="err">exact</span><span class="w"> </span><span class="err">search,</span><span class="w"> </span><span class="err">we</span><span class="w"> </span><span class="err">choose</span><span class="w"> </span><span class="err">a</span><span class="w"> </span><span class="err">tile</span><span class="w"> </span><span class="err">size</span><span class="w"> </span><span class="err">$t_{q}</span><span class="w"> </span><span class="err">\leq</span><span class="w"> </span><span class="err">n_{q}$</span><span class="w"> </span><span class="err">to</span><span class="w"> </span><span class="err">reduce</span><span class="w"> </span><span class="err">memory</span><span class="w"> </span><span class="err">consumption,</span><span class="w"> </span><span class="err">bounding</span><span class="w"> </span><span class="err">its</span><span class="w"> </span><span class="err">complexity</span><span class="w"> </span><span class="err">by</span><span class="w"> </span><span class="err">$\mathcal{O}\left(2</span><span class="w"> </span><span class="err">t_{q}</span><span class="w"> </span><span class="err">\tau</span><span class="w"> </span><span class="err">\max</span><span class="w"> </span><span class="err">_{i}\left|\mathcal{I}_{i}\right|\right)$</span><span class="w"> </span><span class="err">with</span><span class="w"> </span><span class="err">multi-streaming.</span>

<span class="err">A</span><span class="w"> </span><span class="err">single</span><span class="w"> </span><span class="err">warp</span><span class="w"> </span><span class="err">could</span><span class="w"> </span><span class="err">be</span><span class="w"> </span><span class="err">dedicated</span><span class="w"> </span><span class="err">to</span><span class="w"> </span><span class="err">$k$-selection</span><span class="w"> </span><span class="err">of</span><span class="w"> </span><span class="err">each</span><span class="w"> </span><span class="err">$t_{q}$</span><span class="w"> </span><span class="err">set</span><span class="w"> </span><span class="err">of</span><span class="w"> </span><span class="err">lists,</span><span class="w"> </span><span class="err">which</span><span class="w"> </span><span class="err">could</span><span class="w"> </span><span class="err">result</span><span class="w"> </span><span class="err">in</span><span class="w"> </span><span class="err">low</span><span class="w"> </span><span class="err">parallelism.</span><span class="w"> </span><span class="err">We</span><span class="w"> </span><span class="err">introduce</span><span class="w"> </span><span class="err">a</span><span class="w"> </span><span class="err">two-pass</span><span class="w"> </span><span class="err">$k$-selection,</span><span class="w"> </span><span class="err">reducing</span><span class="w"> </span><span class="err">$t_{q}</span><span class="w"> </span><span class="err">\times</span><span class="w"> </span><span class="err">\tau</span><span class="w"> </span><span class="err">\times</span><span class="w"> </span><span class="err">\max</span><span class="w"> </span><span class="err">_{i}\left|\mathcal{I}_{i}\right|$</span><span class="w"> </span><span class="err">to</span><span class="w"> </span><span class="err">$t_{q}</span><span class="w"> </span><span class="err">\times</span><span class="w"> </span><span class="err">f</span><span class="w"> </span><span class="err">\times</span><span class="w"> </span><span class="err">k$</span><span class="w"> </span><span class="err">partial</span><span class="w"> </span><span class="err">results</span><span class="w"> </span><span class="err">for</span><span class="w"> </span><span class="err">some</span><span class="w"> </span><span class="err">subdivision</span><span class="w"> </span><span class="err">factor</span><span class="w"> </span><span class="err">$f$.</span><span class="w"> </span><span class="err">This</span><span class="w"> </span><span class="err">is</span><span class="w"> </span><span class="err">reduced</span><span class="w"> </span><span class="err">again</span><span class="w"> </span><span class="err">via</span><span class="w"> </span><span class="err">$k$-selection</span><span class="w"> </span><span class="err">to</span><span class="w"> </span><span class="err">the</span><span class="w"> </span><span class="err">final</span><span class="w"> </span><span class="err">$t_{q}</span><span class="w"> </span><span class="err">\times</span><span class="w"> </span><span class="err">k$</span><span class="w"> </span><span class="err">results.</span>
<span class="err">Fused</span><span class="w"> </span><span class="err">kernel.</span><span class="w"> </span><span class="err">As</span><span class="w"> </span><span class="err">with</span><span class="w"> </span><span class="err">exact</span><span class="w"> </span><span class="err">search,</span><span class="w"> </span><span class="err">we</span><span class="w"> </span><span class="err">experimented</span><span class="w"> </span><span class="err">with</span><span class="w"> </span><span class="err">a</span><span class="w"> </span><span class="err">kernel</span><span class="w"> </span><span class="err">that</span><span class="w"> </span><span class="err">dedicates</span><span class="w"> </span><span class="err">a</span><span class="w"> </span><span class="err">single</span><span class="w"> </span><span class="err">block</span><span class="w"> </span><span class="err">to</span><span class="w"> </span><span class="err">scanning</span><span class="w"> </span><span class="err">all</span><span class="w"> </span><span class="err">$\tau$</span><span class="w"> </span><span class="err">lists</span>
<span class="err">for</span><span class="w"> </span><span class="err">a</span><span class="w"> </span><span class="err">single</span><span class="w"> </span><span class="err">query,</span><span class="w"> </span><span class="err">with</span><span class="w"> </span><span class="err">$k$-selection</span><span class="w"> </span><span class="err">fused</span><span class="w"> </span><span class="err">with</span><span class="w"> </span><span class="err">distance</span><span class="w"> </span><span class="err">computation.</span><span class="w"> </span><span class="err">This</span><span class="w"> </span><span class="err">is</span><span class="w"> </span><span class="err">possible</span><span class="w"> </span><span class="err">as</span><span class="w"> </span><span class="err">WarpSelect</span><span class="w"> </span><span class="err">does</span><span class="w"> </span><span class="err">not</span><span class="w"> </span><span class="err">fight</span><span class="w"> </span><span class="err">for</span><span class="w"> </span><span class="err">the</span><span class="w"> </span><span class="err">shared</span><span class="w"> </span><span class="err">memory</span><span class="w"> </span><span class="err">resource</span><span class="w"> </span><span class="err">which</span><span class="w"> </span><span class="err">is</span><span class="w"> </span><span class="err">severely</span><span class="w"> </span><span class="err">limited.</span><span class="w"> </span><span class="err">This</span><span class="w"> </span><span class="err">reduces</span><span class="w"> </span><span class="err">global</span><span class="w"> </span><span class="err">memory</span><span class="w"> </span><span class="err">write-back,</span><span class="w"> </span><span class="err">since</span><span class="w"> </span><span class="err">almost</span><span class="w"> </span><span class="err">all</span><span class="w"> </span><span class="err">intermediate</span><span class="w"> </span><span class="err">results</span><span class="w"> </span><span class="err">can</span><span class="w"> </span><span class="err">be</span><span class="w"> </span><span class="err">eliminated.</span><span class="w"> </span><span class="err">However,</span><span class="w"> </span><span class="err">unlike</span><span class="w"> </span><span class="err">$k$-selection</span><span class="w"> </span><span class="err">overhead</span><span class="w"> </span><span class="err">for</span><span class="w"> </span><span class="err">exact</span><span class="w"> </span><span class="err">computation,</span><span class="w"> </span><span class="err">a</span><span class="w"> </span><span class="err">significant</span><span class="w"> </span><span class="err">portion</span><span class="w"> </span><span class="err">of</span><span class="w"> </span><span class="err">the</span><span class="w"> </span><span class="err">runtime</span><span class="w"> </span><span class="err">is</span><span class="w"> </span><span class="err">the</span><span class="w"> </span><span class="err">gather</span><span class="w"> </span><span class="err">from</span><span class="w"> </span><span class="err">the</span><span class="w"> </span><span class="err">$T_{i}$</span><span class="w"> </span><span class="err">in</span><span class="w"> </span><span class="err">shared</span><span class="w"> </span><span class="err">memory</span><span class="w"> </span><span class="err">and</span><span class="w"> </span><span class="err">linear</span><span class="w"> </span><span class="err">scanning</span><span class="w"> </span><span class="err">of</span><span class="w"> </span><span class="err">the</span><span class="w"> </span><span class="err">$\mathcal{I}_{i}$</span><span class="w"> </span><span class="err">from</span><span class="w"> </span><span class="err">global</span><span class="w"> </span><span class="err">memory;</span><span class="w"> </span><span class="err">the</span><span class="w"> </span><span class="err">write-back</span><span class="w"> </span><span class="err">is</span><span class="w"> </span><span class="err">not</span><span class="w"> </span><span class="err">a</span><span class="w"> </span><span class="err">dominant</span><span class="w"> </span><span class="err">contributor.</span><span class="w"> </span><span class="err">Timing</span><span class="w"> </span><span class="err">for</span><span class="w"> </span><span class="err">the</span><span class="w"> </span><span class="err">fused</span><span class="w"> </span><span class="err">kernel</span><span class="w"> </span><span class="err">is</span><span class="w"> </span><span class="err">improved</span><span class="w"> </span><span class="err">by</span><span class="w"> </span><span class="err">at</span><span class="w"> </span><span class="err">most</span><span class="w"> </span><span class="err">$15</span><span class="w"> </span><span class="err">\%$,</span><span class="w"> </span><span class="err">and</span><span class="w"> </span><span class="err">for</span><span class="w"> </span><span class="err">some</span><span class="w"> </span><span class="err">problem</span><span class="w"> </span><span class="err">sizes</span><span class="w"> </span><span class="err">would</span><span class="w"> </span><span class="err">be</span><span class="w"> </span><span class="err">subject</span><span class="w"> </span><span class="err">to</span><span class="w"> </span><span class="err">lower</span><span class="w"> </span><span class="err">parallelism</span><span class="w"> </span><span class="err">and</span><span class="w"> </span><span class="err">worse</span><span class="w"> </span><span class="err">performance</span><span class="w"> </span><span class="err">without</span><span class="w"> </span><span class="err">subsequent</span><span class="w"> </span><span class="err">decomposition.</span><span class="w"> </span><span class="err">Therefore,</span><span class="w"> </span><span class="err">and</span><span class="w"> </span><span class="err">for</span><span class="w"> </span><span class="err">reasons</span><span class="w"> </span><span class="err">of</span><span class="w"> </span><span class="err">implementation</span><span class="w"> </span><span class="err">simplicity,</span><span class="w"> </span><span class="err">we</span><span class="w"> </span><span class="err">do</span><span class="w"> </span><span class="err">not</span><span class="w"> </span><span class="err">use</span><span class="w"> </span><span class="err">this</span><span class="w"> </span><span class="err">layout.</span>
</code></pre></div>

<p>Algorithm 4 IVFPQ batch search routine
    function IVFPQ-SEARCH (\left(\left[x_{1}, \ldots, x_{n_{\mathrm{q}}}\right], \mathcal{I}<em _left_mathcal_C="\left|\mathcal{C">{1}, \ldots, \mathcal{I}</em><em _mathrm_q="\mathrm{q">{1}\right|}\right))
    for (i \leftarrow 0: n</em>) do (\triangleright) batch quantization of Section 5.1
        (L_{\mathrm{IVF}}^{i} \leftarrow \tau \cdot \operatorname{argmin}}<em 1="1">{c \in \mathcal{C}</em>|x-c|}<em _mathrm_q="\mathrm{q">{2})
    end for
    for (i \leftarrow 0: n</em>) do
        (L \leftarrow[] \quad \triangleright) distance table
        Compute term 3 (see Section 5.2)
        for (L) in (L_{\mathrm{IVF}}^{i}) do (\triangleright \tau) loops
            Compute distance tables (T_{1}, \ldots, T_{b})
            for (j) in (\mathcal{I}}<em i="i">{L}) do
                (\triangleright) distance estimation, Equation (10)
            (d \leftarrow\left|x</em>\right)\right|}-q\left(y_{j<em i="i">{2}^{2})
            Append ((d, L, j)) to (L)
            end for
            end for
            (R</em>)-select smallest distances (d) from (L)
        end for
        return R
    end function
```} \leftarrow \mathrm{k</p>
<h3>5.4 Multi-GPU parallelism</h3>
<p>Modern servers can support several GPUs. We employ this capability for both compute power and memory.</p>
<p>Replication. If an index instance fits in the memory of a single GPU, it can be replicated across $\mathcal{R}$ different GPUs. To query $n_{\mathrm{q}}$ vectors, each replica handles a fraction $n_{\mathrm{q}} / \mathcal{R}$ of the queries, joining the results back together on a single GPU or in CPU memory. Replication has near linear speedup, except for a potential loss in efficiency for small $n_{\mathrm{q}}$.</p>
<p>Sharding. If an index instance does not fit in the memory of a single GPU, an index can be sharded across $\mathcal{S}$ different GPUs. For adding $\ell$ vectors, each shard receives $\ell / \mathcal{S}$ of the vectors, and for query, each shard handles the full query set $n_{\mathrm{q}}$, joining the partial results (an additional round of $k$ selection is still required) on a single GPU or in CPU memory. For a given index size $\ell$, sharding will yield a speedup (sharding has a query of $n_{\mathrm{q}}$ against $\ell / \mathcal{S}$ versus replication with a query of $n_{\mathrm{q}} / \mathcal{R}$ against $\ell$ ), but is usually less than pure replication due to fixed overhead and cost of subsequent $k$-selection.</p>
<p>Replication and sharding can be used together ( $\mathcal{S}$ shards, each with $\mathcal{R}$ replicas for $\mathcal{S} \times \mathcal{R}$ GPUs in total). Sharding or replication are both fairly trivial, and the same principle can be used to distribute an index across multiple machines.</p>
<p><img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>Figure 3: Runtimes for different k-selection methods, as a function of array length ℓ. Simultaneous arrays processed are nq = 10000. k = 100 for full lines, k = 1000 for dashed lines.</p>
<h2>6. EXPERIMENTS &amp; APPLICATIONS</h2>
<p>This section compares our GPU k-selection and nearest-neighbor approach to existing libraries. Unless stated otherwise, experiments are carried out on a 2×2.8GHz Intel Xeon E5-2680v2 with 4 Maxwell Titan X GPUs on CUDA 8.0.</p>
<h3>6.1 k-selection performance</h3>
<p>We compare against two other GPU small k-selection implementations: the row-based Merge Queue with Buffered Search and Hierarchical Partition extracted from the fgknn library of Tang et al. [41] and Truncated Bitonic Sort (TBiS) from Sismanis et al. [40]. Both were extracted from their respective exact search libraries.</p>
<p>We evaluate k-selection for k = 100 and 1000 of each row from a row-major matrix nq × ℓ of random 32-bit floating point values on a single Titan X. The batch size nq is fixed at 10000, and the array lengths ℓ vary from 1000 to 128000. Inputs and outputs to the problem remain resident in GPU memory, with the output being of size nq × k, with corresponding indices. Thus, the input problem sizes range from 40 MB (ℓ = 1000) to 5.12 GB (ℓ = 128k). TBiS requires large auxiliary storage, and is limited to ℓ ≤ 48000 in our tests.</p>
<p>Figure 3 shows our relative performance against TBiS and fgknn. It also includes the peak possible performance given by the memory bandwidth limit of the Titan X. The relative performance of WARPSELECT over fgknn increases for larger k; even TBiS starts to outperform fgknn for larger ℓ at k = 1000. We look especially at the largest ℓ = 128000. WARPSELECT is 1.62× faster at k = 100, 2.01× at k = 1000. Performance against peak possible drops off for all implementations at larger k. WARPSELECT operates at 55% of peak at k = 100 but only 16% of peak at k = 1000. This is due to additional overhead associated with bigger thread queues and merge/sort networks for large k.</p>
<p><strong>Differences from fgknn.</strong> WARPSELECT is influenced by fgknn, but has several improvements: all state is maintained in registers (no shared memory), no inter-warp synchronization or buffering is used, no "hierarchical partition", the k-selection can be fused into other kernels, and it uses odd-size networks for efficient merging and sorting.</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
<th># centroids</th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>method</td>
<td># GPUs</td>
<td>256</td>
<td>4096</td>
</tr>
<tr>
<td>BIDMach [11]</td>
<td>1</td>
<td>320 s</td>
<td>735 s</td>
</tr>
<tr>
<td>Ours</td>
<td>1</td>
<td>140 s</td>
<td>316 s</td>
</tr>
<tr>
<td>Ours</td>
<td>4</td>
<td>84 s</td>
<td>100 s</td>
</tr>
</tbody>
</table>
<p>Table 1: MNIST8m k-means performance</p>
<h3>6.2 k-means clustering</h3>
<p>The exact search method with k = 1 can be used by a k-means clustering method in the assignment stage, to assign nq training vectors to |C_{1}| centroids. Despite the fact that it does not use the IVFADC and k = 1 selection is trivial (a parallel reduction is used for the k = 1 case, not WARPSELECT), k-means is a good benchmark for the clustering used to train the quantizer q_{1}.</p>
<p>We apply the algorithm on MNIST8m images. The 8.1M images are graylevel digits in 28x28 pixels, linearized to vectors of 784-d. We compare this k-means implementation to the GPU k-means of BIDMach [11], which was shown to be more efficient than several distributed k-means implementations that require dozens of machines^{3}. Both algorithms were run for 20 iterations. Table 1 shows that our implementation is more than 2× faster, although both are built upon cuBLAS. Our implementation receives some benefit from the k-selection fusion into L2 distance computation. For multi-GPU execution via replicas, the speedup is close to linear for large enough problems (3.16× for 4 GPUs with 4096 centroids). Note that this benchmark is somewhat unrealistic, as one would typically sub-sample the dataset randomly when so few centroids are requested.</p>
<p><strong>Large scale.</strong> We can also compare to [3], an approximate CPU method that clusters 10^{8} 128-d vectors to 85k centroids. Their clustering method runs in 46 minutes, but requires 56 minutes (at least) of pre-processing to encode the vectors. Our method performs exact k-means on 4 GPUs in 52 minutes without any pre-processing.</p>
<h3>6.3 Exact nearest neighbor search</h3>
<p>We consider a classical dataset used to evaluate nearest neighbor search: SIFT1M [25]. Its characteristic sizes are ℓ = 10^{6}, d = 128, nq = 10^{4}. Computing the partial distance matrix D^{i} costs nq × ℓ × d = 1.28 Tflop, which runs in less than one second on current GPUs. Figure 4 shows the cost of the distance computations against the cost of our tiling of the GEMM for the −2⟨x_{j}, y_{i}⟩ term of Equation 2 and the peak possible k-selection performance on the distance matrix of size nq × ℓ, which additionally accounts for reading the tiled result matrix D^{i} at peak memory bandwidth.</p>
<p>In addition to our method from Section 5, we include times from the two GPU libraries evaluated for k-selection performance in Section 6.1. We make several observations:</p>
<ul>
<li>for k-selection, the naive algorithm that sorts the full result array for each query using thrust::sort_by_key is more than 10× slower than the comparison methods;</li>
<li>L2 distance and k-selection cost is dominant for all but our method, which has 85 % of the peak possible performance, assuming GEMM usage and our tiling</li>
</ul>
<p>^{3}BIDMach numbers from https://github.com/BIDData/BIDMach/wiki/Benchmarks#KMeans</p>
<p><img alt="img-3.jpeg" src="img-3.jpeg" /></p>
<p>Figure 4: Exact search k-NN time for the SIFT1M dataset with varying k on 1 Titan X GPU.</p>
<p>of the partial distance matrix $D^{\prime}$ on top of GEMM is close to optimal. The cuBLAS GEMM itself has low efficiency for small reduction sizes (d = 128);</p>
<ul>
<li>Our fused L2/k-selection kernel is important. Our same exact algorithm without fusion (requiring an additional pass through $D^{\prime}$) is at least 25% slower.</li>
</ul>
<p>Efficient k-selection is even more important in situations where approximate methods are used to compute distances, because the relative cost of k-selection with respect to distance computation increases.</p>
<h3>6.4 Billion-scale approximate search</h3>
<p>There are few studies on GPU-based approximate nearest-neighbor search on large datasets (ℓ ≥ 10<sup>6</sup>). We report a few comparison points here on index search, using standard datasets and evaluation protocol in this field.</p>
<p><strong>SIFT1M.</strong> For the sake of completeness, we first compare our GPU search speed on SIFT1M with the implementation of Wieschollek et al. [47]. They obtain a nearest neighbor recall at 1 (fraction of queries where the true nearest neighbor is in the top 1 result) of R@1 = 0.51, and R@100 = 0.86 in 0.02 ms per query on a Titan X. For the same time budget, our implementation obtains R@1 = 0.80 and R@100 = 0.95.</p>
<p><strong>SIFT1B.</strong> We compare again with Wieschollek et al., on the SIFT1B dataset [26] of 1 billion SIFT image features at n<sub>q</sub> = 10<sup>4</sup>. We compare the search performance in terms of same memory usage for similar accuracy (more accurate methods may involve greater search time or memory usage). On a single GPU, with m = 8 bytes per vector, R@10 = 0.376 in 17.7 µs per query vector, versus their reported R@10 = 0.35 in 150 µs per query vector. Thus, our implementation is more accurate at a speed 8.5× faster.</p>
<p><strong>DEEP1B.</strong> We also experimented on the DEEP1B dataset [6] of ℓ=1 billion CNN representations for images at n<sub>q</sub> = 10<sup>4</sup>. The paper that introduces the dataset reports CPU results (1 thread): R@1 = 0.45 in 20 ms search time per vector. We use a PQ encoding of m = 20, with d = 80 via OPQ [17], and |C<sub>1</sub>| = 2<sup>18</sup>, which uses a comparable dataset storage as the original paper (20 GB). This requires multiple GPUs as it is too large for a single GPU's global memory, so we consider 4 GPUs with S = 2, R = 2. We obtain a R@1 = 0.4517 in 0.0133 ms per vector. While the hardware platforms are</p>
<p><img alt="img-4.jpeg" src="img-4.jpeg" /></p>
<p>Figure 5: Speed/accuracy trade-off of brute-force 10-NN graph construction for the YFCC100M and DEEP1B datasets.</p>
<p>different, it shows that making searches on GPUs is a game-changer in terms of speed achievable on a single machine.</p>
<h3>6.5 The k-NN graph</h3>
<p>An example usage of our similarity search method is to construct a k-nearest neighbor graph of a dataset via brute force (all vectors queried against the entire index).</p>
<p><strong>Experimental setup.</strong> We evaluate the trade-off between speed, precision, and memory on two datasets: 95 million images from the YFCC100M dataset [42] and DEEP1B. For YFCC100M, we compute CNN descriptors as the one-before-last layer of a ResNet [23], reduced to d = 128 with PCA.</p>
<p>The evaluation measures the trade-off between:</p>
<ul>
<li><strong>Speed:</strong> How much time it takes to build the IVFADC index from scratch and construct the whole k-NN graph (k = 10) by searching nearest neighbors for all vectors in the dataset. Thus, this is an end-to-end test that includes indexing as well as search time;</li>
<li><strong>Quality:</strong> We sample 10,000 images for which we compute the exact nearest neighbors. Our accuracy measure is the fraction of 10 found nearest neighbors that are within the ground-truth 10 nearest neighbors.</li>
</ul>
<p>For YFCC100M, we use a coarse quantizer (2<sup>16</sup> centroids), and consider m = 16, 32, and 64 byte PQ encodings for each vector. For DEEP1B, we pre-process the vectors to d = 120 via OPQ, use |C<sub>1</sub>| = 2<sup>18</sup> and consider m = 20, 40. For a given encoding, we vary τ from 1 to 256, to obtain trade-offs between efficiency and quality, as seen in Figure 5.</p>
<p><img alt="img-5.jpeg" src="img-5.jpeg" /></p>
<p>Figure 6: Path in the k-NN graph of 95 million images from YFCC100M. The first and the last image are given; the algorithm computes the smoothest path between them.</p>
<p><strong>Discussion.</strong> For YFCC100M we used S = 1, R = 4. An accuracy of more than 0.8 is obtained in 35 minutes. For DEEP1B, a lower-quality graph can be built in 6 hours, with higher quality in about half a day. We also experimented with more GPUs by doubling the replica set, using 8 Maxwell M40s (the M40 is roughly equivalent in performance to the Titan X). Performance is improved sublinearly (∼ 1.6× for m = 20, ∼ 1.7× for m = 40).</p>
<p>For comparison, the largest k-NN graph construction we are aware of used a dataset comprising 36.5 million 384-d vectors, which took a cluster of 128 CPU servers 108.7 hours of compute [45], using NN-Descent [15]. Note that NN-Descent could also build or refine the k-NN graph for the datasets we consider, but it has a large memory overhead over the graph storage, which is already 80 GB for DEEP1B. Moreover it requires random access across all vectors (384 GB for DEEP1B).</p>
<p>The largest GPU k-NN graph construction we found is a brute-force construction using exact search with GEMM, of a dataset of 20 million 15,000-d vectors, which took a cluster of 32 Tesla C2050 GPUs 10 days [14]. Assuming computation scales with GEMM cost for the distance matrix, this approach for DEEP1B would take an impractical 200 days of computation time on their cluster.</p>
<h3>6.6 Using the k-NN graph</h3>
<p>When a k-NN graph has been constructed for an image dataset, we can find paths in the graph between any two images, provided there is a single connected component (this is the case). For example, we can search the shortest path between two images of flowers, by propagating neighbors from a starting image to a destination image. Denoting by S and D the source and destination images, and d<sub>ij</sub> the distance between nodes, we search the path P = {p<sub>1</sub>, ..., p<sub>n</sub>} with p<sub>1</sub> = S and p<sub>n</sub> = D such that</p>
<p>$$\min_{P} \max_{i=1..n} d_{p_{i}_{p_{i+1}}}, \tag{12}$$</p>
<p>i.e., we want to favor smooth transitions. An example result is shown in Figure 6 from YFCC100M<sup>4</sup>. It was obtained after 20 seconds of propagation in a k-NN graph with k = 15 neighbors. Since there are many flower images in the dataset, the transitions are smooth.</p>
<h3>7. CONCLUSION</h3>
<p>The arithmetic throughput and memory bandwidth of GPUs are well into the teraflops and hundreds of gigabytes per second. However, implementing algorithms that approach these performance levels is complex and counterintuitive. In this paper, we presented the algorithmic structure of similarity search methods that achieves near-optimal performance on GPUs.</p>
<p>This work enables applications that needed complex approximate algorithms before. For example, the approaches presented here make it possible to do exact k-means clustering or to compute the k-NN graph with simple brute-force approaches in less time than a CPU (or a cluster of them) would take to do this approximately.</p>
<p>GPU hardware is now very common on scientific workstations, due to their popularity for machine learning algorithms. We believe that our work further demonstrates their interest for database applications. Along with this work, we are publishing a carefully engineered implementation of this paper's algorithms, so that these GPUs can now also be used for efficient similarity search.</p>
<h3>8. REFERENCES</h3>
<ul>
<li>[1] T. Alabi, J. D. Blanchard, B. Gordon, and R. Steinbach. Fast k-selection algorithms for graphics processing units. <em>ACM Journal of Experimental Algorithmics</em>, 17:4.2:4.1–4.2:4.29, October 2012.</li>
<li>[2] F. André, A.-M. Kermarrec, and N. L. Scouarnec. Cache locality is not enough: High-performance nearest neighbor search with product quantization fast scan. In <em>Proc. International Conference on Very Large DataBases</em>, pages 288–299, 2015.</li>
<li>[3] Y. Avrithis, Y. Kalantidis, E. Anagnostopoulos, and I. Z. Emiris. Web-scale image clustering revisited. In <em>Proc. International Conference on Computer Vision</em>, pages 1502–1510, 2015.</li>
<li>[4] A. Babenko and V. Lempitsky. The inverted multi-index. In <em>Proc. IEEE Conference on Computer Vision and Pattern Recognition</em>, pages 3069–3076, June 2012.</li>
<li>[5] A. Babenko and V. Lempitsky. Improving bilayer product quantization for billion-scale approximate nearest neighbors in high dimensions. <em>arXiv preprint arXiv:1404.1831</em>, 2014.</li>
<li>[6] A. Babenko and V. Lempitsky. Efficient indexing of billion-scale datasets of deep descriptors. In <em>Proc. IEEE Conference on Computer Vision and Pattern Recognition</em>, pages 2055–2063, June 2016.</li>
<li>[7] R. Barrientos, J. Gómez, C. Tenllado, M. Prieto, and M. Marín. knn query processing in metric spaces using GPUs. In <em>International European Conference on Parallel and Distributed Computing</em>, volume 6852 of <em>Lecture Notes</em></li>
</ul>
<p><sup>4</sup>The mapping from vectors to images is not available for DEEP1B</p>
<p>in Computer Science, pages 380-392, Bordeaux, France, September 2011. Springer.
[8] K. E. Batcher. Sorting networks and their applications. In Proc. Spring Joint Computer Conference, AFIPS '68 (Spring), pages 307-314, New York, NY, USA, 1968. ACM.
[9] P. Boncz, W. Lehner, and T. Neumann. Special issue: Modern hardware. The VLDB Journal, 25(5):623-624, 2016.
[10] J. Canny, D. L. W. Hall, and D. Klein. A multi-teraflop constituency parser using GPUs. In Proc. Empirical Methods on Natural Language Processing, pages 1898-1907. ACL, 2013.
[11] J. Canny and H. Zhao. Bidmach: Large-scale learning with zero memory allocation. In BigLearn workshop, NIPS, 2013.
[12] B. Catanzaro, A. Keller, and M. Garland. A decomposition for in-place matrix transposition. In Proc. ACM Symposium on Principles and Practice of Parallel Programming, PPoPP '14, pages 193-206, 2014.
[13] J. Chhugani, A. D. Nguyen, V. W. Lee, W. Macy, M. Hagog, Y.-K. Chen, A. Baransi, S. Kumar, and P. Dubey. Efficient implementation of sorting on multi-core simd cpu architecture. Proc. VLDB Endow., 1(2):1313-1324, August 2008.
[14] A. Dashti. Efficient computation of k-nearest neighbor graphs for large high-dimensional data sets on gpu clusters. Master's thesis, University of Wisconsin Milwaukee, August 2013.
[15] W. Dong, M. Charikar, and K. Li. Efficient k-nearest neighbor graph construction for generic similarity measures. In WWW: Proceeding of the International Conference on World Wide Web, pages 577-586, March 2011.
[16] M. Douze, H. Jégou, and F. Perronnin. Polysemous codes. In Proc. European Conference on Computer Vision, pages 785-801. Springer, October 2016.
[17] T. Ge, K. He, Q. Ke, and J. Sun. Optimized product quantization. IEEE Trans. PAMI, 36(4):744-755, 2014.
[18] Y. Gong and S. Lazebnik. Iterative quantization: A procrustean approach to learning binary codes. In Proc. IEEE Conference on Computer Vision and Pattern Recognition, pages 817-824, June 2011.
[19] Y. Gong, L. Wang, R. Guo, and S. Lazebnik. Multi-scale orderless pooling of deep convolutional activation features. In Proc. European Conference on Computer Vision, pages 392-407, 2014.
[20] A. Gordo, J. Almazan, J. Revaud, and D. Larlus. Deep image retrieval: Learning global representations for image search. In Proc. European Conference on Computer Vision, pages 241-257, 2016.
[21] S. Han, H. Mao, and W. J. Dally. Deep compression: Compressing deep neural networks with pruning, trained quantization and huffman coding. arXiv preprint arXiv:1510.00149, 2015.
[22] K. He, F. Wen, and J. Sun. K-means hashing: An affinity-preserving quantization method for learning binary compact codes. In Proc. IEEE Conference on Computer Vision and Pattern Recognition, pages 2938-2945, June 2013.
[23] K. He, X. Zhang, S. Ren, and J. Sun. Deep residual learning for image recognition. In Proc. IEEE Conference on Computer Vision and Pattern Recognition, pages $770-778$, June 2016.
[24] X. He, D. Agarwal, and S. K. Prasad. Design and implementation of a parallel priority queue on many-core architectures. IEEE International Conference on High Performance Computing, pages 1-10, 2012.
[25] H. Jégou, M. Douze, and C. Schmid. Product quantization for nearest neighbor search. IEEE Trans. PAMI, 33(1):117-128, January 2011.
[26] H. Jégou, R. Tavenard, M. Douze, and L. Amsaleg. Searching in one billion vectors: re-rank with source coding. In International Conference on Acoustics, Speech,
and Signal Processing, pages 861-864, May 2011.
[27] Y. Kalantidis and Y. Avrithis. Locally optimized product quantization for approximate nearest neighbor search. In Proc. IEEE Conference on Computer Vision and Pattern Recognition, pages 2329-2336, June 2014.
[28] A. Krizhevsky, I. Sutskever, and G. E. Hinton. Imagenet classification with deep convolutional neural networks. In Advances in Neural Information Processing Systems, pages 1097-1105, 2012.
[29] F. T. Leighton. Introduction to Parallel Algorithms and Architectures: Array, Trees, Hypercubes. Morgan Kaufmann Publishers Inc., San Francisco, CA, USA, 1992.
[30] E. Lindholm, J. Nickolls, S. Oberman, and J. Montrym. NVIDIA Tesla: a unified graphics and computing architecture. IEEE Micro, 28(2):39-55, March 2008.
[31] W. Liu and B. Vinter. Ad-heap: An efficient heap data structure for asymmetric multicore processors. In Proc. of Workshop on General Purpose Processing Using GPUs, pages 54:54-54:63. ACM, 2014.
[32] T. Mikolov, I. Sutskever, K. Chen, G. S. Corrado, and J. Dean. Distributed representations of words and phrases and their compositionality. In Advances in Neural Information Processing Systems, pages 3111-3119, 2013.
[33] L. Monroe, J. Wendelberger, and S. Michalak. Randomized selection on the GPU. In Proc. ACM Symposium on High Performance Graphics, pages 89-98, 2011.
[34] M. Norouzi and D. Fleet. Cartesian k-means. In Proc. IEEE Conference on Computer Vision and Pattern Recognition, pages 3017-3024, June 2013.
[35] M. Norouzi, A. Punjani, and D. J. Fleet. Fast search in Hamming space with multi-index hashing. In Proc. IEEE Conference on Computer Vision and Pattern Recognition, pages 3108-3115, 2012.
[36] J. Pan and D. Manocha. Fast GPU-based locality sensitive hashing for k-nearest neighbor computation. In Proc. ACM International Conference on Advances in Geographic Information Systems, pages 211-220, 2011.
[37] L. Paulevé, H. Jégou, and L. Amsaleg. Locality sensitive hashing: a comparison of hash function types and querying mechanisms. Pattern recognition letters, 31(11):1348-1358, August 2010.
[38] O. Shamir. Fundamental limits of online and distributed algorithms for statistical learning and estimation. In Advances in Neural Information Processing Systems, pages $163-171,2014$.
[39] A. Sharif Razavian, H. Azizpour, J. Sullivan, and S. Carlsson. CNN features off-the-shelf: an astounding baseline for recognition. In CVPR workshops, pages $512-519,2014$.
[40] N. Sismanis, N. Pitsianis, and X. Sun. Parallel search of k-nearest neighbors with synchronous operations. In IEEE High Performance Extreme Computing Conference, pages $1-6,2012$.
[41] X. Tang, Z. Huang, D. M. Eyers, S. Mills, and M. Guo. Efficient selection algorithm for fast k-nn search on GPUs. In IEEE International Parallel \&amp; Distributed Processing Symposium, pages 397-406, 2015.
[42] B. Thomee, D. A. Shamma, G. Friedland, B. Elizalde, K. Ni, D. Poland, D. Borth, and L.-J. Li. YFCC100M: The new data in multimedia research. Communications of the ACM, 59(2):64-73, January 2016.
[43] V. Volkov and J. W. Demmel. Benchmarking GPUs to tune dense linear algebra. In Proc. ACM/IEEE Conference on Supercomputing, pages 31:1-31:11, 2008.
[44] A. Wakatani and A. Murakami. GPGPU implementation of nearest neighbor search with product quantization. In IEEE International Symposium on Parallel and Distributed Processing with Applications, pages 248-253, 2014.
[45] T. Wurashina, K. Aoyama, H. Sawada, and T. Hattori. Efficient k-nearest neighbor graph construction using mapreduce for large-scale data sets. IEICE Transactions,</p>
<p>97-D(12):3142-3154, 2014.
[46] R. Weber, H.-J. Schek, and S. Blott. A quantitative analysis and performance study for similarity-search methods in high-dimensional spaces. In Proc. International Conference on Very Large DataBases, pages 194-205, 1998.
[47] P. Wieschollek, O. Wang, A. Sorkine-Hornung, and H. P. A. Lensch. Efficient large-scale approximate nearest neighbor search on the GPU. In Proc. IEEE Conference on Computer Vision and Pattern Recognition, pages 2027-2035, June 2016.
[48] S. Williams, A. Waterman, and D. Patterson. Roofline: An insightful visual performance model for multicore architectures. Communications of the ACM, 52(4):65-76, April 2009.</p>
<h2>Appendix: Complexity analysis of WarpSelect</h2>
<p>We derive the average number of times updates are triggered in WarpSelect, for use in Section 4.3.</p>
<p>Let the input to $k$-selection be a sequence $\left{a_{1}, a_{2}, \ldots, a_{\ell}\right}$ (1-based indexing), a randomly chosen permutation of a set of distinct elements. Elements are read sequentially in $c$ groups of size $w$ (the warp; in our case, $w=32$ ); assume $\ell$ is a multiple of $w$, so $c=\ell / w$. Recall that $t$ is the thread queue length. We call elements prior to or at position $n$ in the min- $k$ seen so far the successive min-k (at $n$ ). The likelihood that $a_{n}$ is in the successive min- $k$ at $n$ is:</p>
<p>$$
\alpha(n, k):= \begin{cases}1 &amp; \text { if } n \leq k \ k / n &amp; \text { if } n&gt;k\end{cases}
$$</p>
<p>as each $a_{n}, n&gt;k$ has a $k / n$ chance as all permutations are equally likely, and all elements in the first $k$ qualify.
Counting the insertion sorts. In a given lane, an insertion sort is triggered if the incoming value is in the successive min- $k+t$ values, but the lane has "seen" only $w c_{0}+\left(c-c_{0}\right)$ values, where $c_{0}$ is the previous won warp ballot. The probability of this happening is:</p>
<p>$$
\alpha\left(w c_{0}+\left(c-c_{0}\right), k+t\right) \approx \frac{k+t}{w c} \text { for } c&gt;k
$$</p>
<p>The approximation considers that the thread queue has seen all the $w c$ values, not just those assigned to its lane. The probability of any lane triggering an insertion sort is then:</p>
<p>$$
1-\left(1-\frac{k+t}{w c}\right)^{w} \approx \frac{k+t}{c}
$$</p>
<p>Here the approximation is a first-order Taylor expansion. Summing up the probabilities over $c$ gives an expected number of insertions of $N_{2} \approx(k+t) \log (c)=\mathcal{O}(k \log (\ell / w))$.
Counting full sorts. We seek $N_{3}=\pi(\ell, k, t, w)$, the expected number of full sorts required for WarpSelect.
Single lane. For now, we assume $w=1$, so $c=\ell$. Let $\gamma(\ell, m, k)$ be the probability that in an sequence $\left{a_{1}, \ldots, a_{\ell}\right}$, exactly $m$ of the elements as encountered by a sequential scanner $(w=1)$ are in the successive min- $k$. Given $m$, there are $\binom{\ell}{m}$ places where these successive min- $k$ elements can occur. It is given by a recurrence relation:</p>
<p>$$
\gamma(\ell, m, k):= \begin{cases}1 &amp; \ell=0 \text { and } m=0 \ 0 &amp; \ell=0 \text { and } m&gt;0 \ 0 &amp; \ell&gt;0 \text { and } m=0 \ (\gamma(\ell-1, m-1, k) \cdot \alpha(\ell, k)+ &amp; \ \gamma(\ell-1, m, k) \cdot(1-\alpha(\ell, k))) &amp; \text { otherwise. }\end{cases}
$$</p>
<p>The last case is the probability of: there is a $\ell-1$ sequence with $m-1$ successive min- $k$ elements preceding us, and the current element is in the successive min- $k$, or the current element is not in the successive min- $k, m$ ones are before us. We can then develop a recurrence relationship for $\pi(\ell, k, t, 1)$. Note that</p>
<p>$$
\delta(\ell, b, k, t):=\sum_{m=b t}^{\min ((b t+\max (0, t-1)), \ell)} \gamma(\ell, m, k)
$$</p>
<p>for $b$ where $0 \leq b t \leq \ell$ is the fraction of all sequences of length $\ell$ that will force $b$ sorts of data by winning the thread queue ballot, as there have to be $b t$ to $(b t+\max (0, t-1))$ elements in the successive min- $k$ for these sorts to happen (as the min- $k$ elements will overflow the thread queues). There are at most $\lfloor\ell / t\rfloor$ won ballots that can occur, as it takes $t$ separate sequential current min- $k$ seen elements to win the ballot. $\pi(\ell, k, t, 1)$ is thus the expectation of this over all possible $b$ :</p>
<p>$$
\pi(\ell, k, t, 1)=\sum_{b=1}^{\lfloor\ell / t\rfloor} b \cdot \delta(\ell, b, k, t)
$$</p>
<p>This can be computed by dynamic programming. Analytically, note that for $t=1, k=1, \pi(\ell, 1,1,1)$ is the harmonic number $H_{\ell}=1+\frac{1}{2}+\frac{1}{3}+\ldots+\frac{1}{2}$, which converges to $\ln (\ell)+\gamma$ (the Euler-Mascheroni constant $\gamma$ ) as $\ell \rightarrow \infty$.</p>
<p>For $t=1, k&gt;1, \ell&gt;k, \pi(\ell, k, 1,1)=k+k\left(H_{\ell}-H_{k}\right)$ or $\mathcal{O}(k \log (\ell))$, as the first $k$ elements are in the successive min- $k$, and the expectation for the rest is $\frac{k}{k+1}+\frac{k}{k+2}+\ldots+\frac{k}{\ell}$.</p>
<p>For $t&gt;1, k&gt;1, \ell&gt;k$, note that there are some number $D, k \leq D \leq \ell$ of successive min- $k$ determinations $D$ made for each possible $\left{a_{1}, \ldots, a_{\ell}\right}$. The number of won ballots for each case is by definition $\lfloor D / t\rfloor$, as the thread queue must fill up $t$ times. Thus, $\pi(\ell, k, t, 1)=\mathcal{O}(k \log (\ell) / t)$.
Multiple lanes. The $w&gt;1$ case is complicated by the fact that there are joint probabilities to consider (if more than one of the $w$ workers triggers a sort for a given group, only one sort takes place). However, the likelihood can be bounded. Let $\pi^{\prime}(\ell, k, t, w)$ be the expected won ballots assuming no mutual interference between the $w$ workers for winning ballots (i.e., we win $b$ ballots if there are $b \leq w$ workers that independently win a ballot at a single step), but with the shared min- $k$ set after each sort from the joint sequence. Assume that $k \geq w$. Then:</p>
<p>$$
\begin{aligned}
\pi^{\prime}(\ell, k, 1, w) &amp; \leq w\left(\left\lceil\frac{k}{w}\right\rceil+\sum_{i=1}^{\lceil\ell / w\rceil-\lceil k / w\rceil} \frac{k}{w(\lceil k / w\rceil+i)}\right) \
&amp; \leq w \pi(\lceil\ell / w\rceil, k, 1,1)=\mathcal{O}(w k \log (\ell / w))
\end{aligned}
$$</p>
<p>where the likelihood of the $w$ workers seeing a successive min- $k$ element has an upper bound of that of the first worker at each step. As before, the number of won ballots is scaled by $t$, so $\pi^{\prime}(\ell, k, t, w)=\mathcal{O}(w k \log (\ell / w) / t)$. Mutual interference can only reduce the number of ballots, so we obtain the same upper bound for $\pi(\ell, k, t, w)$.</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>${ }^{2}$ To avoid clutter in 0 -based indexing, we use the array notation $0: \ell$ to denote the range ${0, \ldots, \ell-1}$ inclusive.&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>