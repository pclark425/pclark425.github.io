<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-1240 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-1240</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-1240</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-28.html">extraction-schema-28</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of navigation in text-based games or text worlds, including graph-topology features of the environments (such as diameter, clustering coefficient, dead-ends, door constraints, connectivity), exploration efficiency metrics, and how these relate to agent performance and policy structure.</div>
                <p><strong>Paper ID:</strong> paper-268510406</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2403.09971v3.pdf" target="_blank">Advancing Object Goal Navigation Through LLM-enhanced Object Affinities Transfer</a></p>
                <p><strong>Paper Abstract:</strong> Object-goal navigation requires mobile robots to efficiently locate targets with visual and spatial information, yet existing methods struggle with generalization in unseen environments. Heuristic approaches with naive metrics fail in complex layouts, while graph-based and learning-based methods suffer from environmental biases and limited generalization. Although Large Language Models (LLMs) as planners or agents offer a rich knowledge base, they are cost-inefficient and lack targeted historical experience. To address these challenges, we propose the LLM-enhanced Object Affinities Transfer (LOAT) framework, integrating LLM-derived semantics with learning-based approaches to leverage experiential object affinities for better generalization in unseen settings. LOAT employs a dual-module strategy: one module accesses LLMs'vast knowledge, and the other applies learned object semantic relationships, dynamically fusing these sources based on context. Evaluations in AI2-THOR and Habitat simulators show significant improvements in navigation success and efficiency, and real-world deployment demonstrates the zero-shot ability of LOAT to enhance object-goal navigation systems.</p>
                <p><strong>Cost:</strong> 0.012</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e1240.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e1240.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of navigation in text-based games or text worlds, including graph-topology features of the environments (such as diameter, clustering coefficient, dead-ends, door constraints, connectivity), exploration efficiency metrics, and how these relate to agent performance and policy structure.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>AI2-THOR (SAVN-NAV)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>AI2-THOR simulator (SAVN-NAV benchmark)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A simulated indoor household environment used for embodied object-goal navigation; SAVN-NAV is a benchmark sampled from AI2-THOR for navigation evaluation with randomized starts and target items.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>AI2-THOR (SAVN-NAV)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Household indoor simulator (photorealistic rooms/kitchens/bedrooms) used for object-goal navigation tasks with randomized start positions and target objects.</td>
                        </tr>
                        <tr>
                            <td><strong>graph_diameter</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>clustering_coefficient</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>dead_ends_present</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>dead_ends_count</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>door_constraints_present</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>door_constraints_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>graph_connectivity</strong></td>
                            <td>Topological (hierarchical object-to-zone) graphs are used for some policies (e.g., HOZ): nodes represent zones/areas or sets of objects; connectivity is a sparse topological graph over areas (hierarchical), not fully connected.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>HOZ w/ LOAT (graph-based) / A3C (policy)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Graph-based policy using a hierarchical object-to-zone topological graph (HOZ); node embeddings aggregate pre-trained text embeddings of objects in the node; A3C is used as the downstream RL policy. LOAT provides node-wise affinity activations by averaging object affinities per node.</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_efficiency_metric</strong></td>
                            <td>SPL (Success weighted by Path Length), PLWSR (Path Length-Weighted Success Rate), SR (Success Rate)</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_efficiency_value</strong></td>
                            <td>HOZ baseline SPL 38.80 (units: %), SR 72.20 (%); HOZ w/ LOAT SPL 39.56 (%), SR 73.12 (%) (reported in Table II for SAVN-NAV).</td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td>HOZ baseline SR 72.20%; HOZ w/ LOAT SR 73.12% (Table II).</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_policy_type</strong></td>
                            <td>Graph-based/topological policies with node-level semantic activation (hierarchical graph) perform well in these benchmarks; LOAT-enhanced graph policies slightly outperform plain graph policies.</td>
                        </tr>
                        <tr>
                            <td><strong>topology_performance_relationship</strong></td>
                            <td>Paper reports that applying affinity-based node activations on topological graphs (averaging object affinities per node) improves node prioritization leading to modest gains in SPL and SR; no explicit numeric dependence given on standard graph-topology metrics (diameter, clustering coefficient).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_across_topologies</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>topology_comparison_results</strong></td>
                            <td>The paper compares map-based and graph-based policies and shows LOAT improves both; for SAVN-NAV specifically, HOZ with LOAT slightly improves SPL and SR versus HOZ baseline (about +0.76 SPL and +0.92 percentage points SR). No systematic comparison across different graph topologies (e.g., differing diameters or clustering) is provided.</td>
                        </tr>
                        <tr>
                            <td><strong>policy_structure_findings</strong></td>
                            <td>Graph-based policies benefit from node-wise activation using averaged object affinities (Equation 6–7). The LOAT dynamic fusion (guidance ratio γ) modulates reliance on semantic LLM priors vs experiential affinities depending on temporal context; RNN hidden states or trajectory history used to compute γ, implying memory/context encodings are important for weighting semantic vs learned priors.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Advancing Object Goal Navigation Through LLM-enhanced Object Affinities Transfer', 'publication_date_yy_mm': '2024-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1240.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e1240.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of navigation in text-based games or text worlds, including graph-topology features of the environments (such as diameter, clustering coefficient, dead-ends, door constraints, connectivity), exploration efficiency metrics, and how these relate to agent performance and policy structure.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Habitat ObjectNav</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Habitat simulator (ObjectGoal Navigation benchmark)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A large-scale embodied AI platform with photorealistic indoor scenes used for point- or object-goal navigation; benchmarked here with ObjectNav tasks and SPL/SR metrics.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Habitat (ObjectNav)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Photorealistic indoor environments (reconstructed 3D scenes) for object-goal navigation (find an object category in unseen scenes).</td>
                        </tr>
                        <tr>
                            <td><strong>graph_diameter</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>clustering_coefficient</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>dead_ends_present</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>dead_ends_count</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>door_constraints_present</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>door_constraints_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>graph_connectivity</strong></td>
                            <td>When used, policies can employ metric maps or implicit graph/topological structures; the paper integrates LOAT with a PEANUT-inspired map-based policy and reports improvements. Connectivity specifics (average degree, tree vs mesh) are not provided.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>PEANUT w/ LOAT (map-based) / DD-PPO / PEANUT</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>PEANUT-inspired map-based navigation model that predicts navigation priors to unseen targets; LOAT supplies per-category affinity channel activations on semantic maps (scales semantic map channels by A_Fc). DD-PPO is a strong baseline trained at scale.</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_efficiency_metric</strong></td>
                            <td>SPL (Success weighted by Path Length), SR (Success Rate)</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_efficiency_value</strong></td>
                            <td>DD-PPO SPL 0.20, SR 0.52; PEANUT SPL 0.30, SR 0.55; PEANUT w/ LOAT SPL 0.32, SR 0.63 (values reported in paper).</td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td>PEANUT w/ LOAT SR 0.63 (63%), PEANUT SR 0.55 (55%), DD-PPO SR 0.52 (52%).</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_policy_type</strong></td>
                            <td>Map-based policies augmented with semantic affinity activations (channel-wise scaling of semantic map) improve exploration efficiency; dynamic fusion that leverages LLM priors helps in novel scenes.</td>
                        </tr>
                        <tr>
                            <td><strong>topology_performance_relationship</strong></td>
                            <td>The paper indicates that enhancing semantic maps via LOAT's affinity scores improves path efficiency (SPL) and success (SR), but does not tie these gains to explicit graph-topology measures (e.g., diameter). The relationship reported is between semantic/affinity guidance and improved exploration efficiency rather than classical graph-theoretic measures.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_across_topologies</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>topology_comparison_results</strong></td>
                            <td>Comparison is primarily between map-based (PEANUT) and other baselines (DD-PPO); LOAT improves map-based PEANUT (SPL +0.02, SR +0.08). No experiments vary intrinsic graph topology metrics systematically.</td>
                        </tr>
                        <tr>
                            <td><strong>policy_structure_findings</strong></td>
                            <td>Map-based policies benefit from channel-wise scaling of semantic maps by LOAT affinities (Equation 5). Dynamic fusion uses temporal/context embeddings to tune reliance on LLM priors vs experiential affinities, implying policies that can incorporate temporal context (memory) better leverage LOAT.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Advancing Object Goal Navigation Through LLM-enhanced Object Affinities Transfer', 'publication_date_yy_mm': '2024-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1240.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e1240.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of navigation in text-based games or text worlds, including graph-topology features of the environments (such as diameter, clustering coefficient, dead-ends, door constraints, connectivity), exploration efficiency metrics, and how these relate to agent performance and policy structure.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ALFRED (AI2-THOR tasks)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>ALFRED benchmark (tasks in AI2-THOR for instruction following and object manipulation/navigation)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A dataset/benchmark of instruction-following household tasks in AI2-THOR combining navigation and interaction; used here to test LOAT-P (ULOAT-enhanced Prompter/FILM) for semantic map activation and object finding.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>ALFRED (AI2-THOR)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Household instruction-following benchmark (combined navigation + manipulation) built on AI2-THOR scenes; emphasizes realistic multi-step tasks with object search and interaction.</td>
                        </tr>
                        <tr>
                            <td><strong>graph_diameter</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>clustering_coefficient</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>dead_ends_present</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>dead_ends_count</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>door_constraints_present</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>door_constraints_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>graph_connectivity</strong></td>
                            <td>Primarily treated with map-based semantic maps; no explicit graph-topology metrics are provided. LOAT is applied to semantic map channels to bias search.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>LOAT-P (Prompter / FILM enhanced with LOAT), FILM, Prompter</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>LOAT-P augments existing instruction-following/navigation architectures (FILM, Prompter) by scaling semantic map channels using LOAT affinities and replacing segmentation with DINO for robust detection; downstream policies remain unchanged in architecture.</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_efficiency_metric</strong></td>
                            <td>SR (Success Rate), GFR (Goal Found Rate), PLW metrics (path-length-weighted variants)</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_efficiency_value</strong></td>
                            <td>LOAT-P reported as top-performing on ALFRED; specific examples: Prompter valid-seen SR 51.04% -> Prompter w/ LOAT 53.47% (Table IV); FILM valid-seen SR 20.10% -> FILM w/ LOAT 22.78% (Table IV).</td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td>Prompter w/ LOAT valid-seen SR 53.47% (vs Prompter 51.04%); FILM w/ LOAT valid-seen SR 22.78% (vs FILM 20.10%).</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_policy_type</strong></td>
                            <td>Map-based instruction-following policies improved by semantic affinity priors; models that can ingest channel-wise semantic activations (map-based) benefit from LOAT.</td>
                        </tr>
                        <tr>
                            <td><strong>topology_performance_relationship</strong></td>
                            <td>Improvements are reported when semantic map channels are biased by affinities, leading to better goal-finding (GFR) and SR; the paper does not report relationships to formal graph-topology metrics (diameter/clustering) in ALFRED.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_across_topologies</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>topology_comparison_results</strong></td>
                            <td>Paper compares baseline FILM/Prompter to LOAT-augmented variants showing consistent gains across methods (e.g., +~2 percentage points SR for FILM, +~2.4 for Prompter on valid-seen), but does not evaluate different topological graph structures explicitly.</td>
                        </tr>
                        <tr>
                            <td><strong>policy_structure_findings</strong></td>
                            <td>Integrating LOAT as a preprocessing activation on semantic maps improves performance without changing downstream policy loss or architecture; suggests that providing semantic priors (via affinities) to map-based policies is effective for search efficiency and object discovery.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Advancing Object Goal Navigation Through LLM-enhanced Object Affinities Transfer', 'publication_date_yy_mm': '2024-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Hierarchical object-to-zone graph for object navigation <em>(Rating: 2)</em></li>
                <li>Learning object relation graph and tentative policy for visual navigation <em>(Rating: 2)</em></li>
                <li>Visual semantic navigation using scene priors <em>(Rating: 2)</em></li>
                <li>Esc: Exploration with soft commonsense constraints for zero-shot object navigation <em>(Rating: 2)</em></li>
                <li>Poni: Potential functions for object-goal navigation with interaction-free learning <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-1240",
    "paper_id": "paper-268510406",
    "extraction_schema_id": "extraction-schema-28",
    "extracted_data": [
        {
            "name_short": "AI2-THOR (SAVN-NAV)",
            "name_full": "AI2-THOR simulator (SAVN-NAV benchmark)",
            "brief_description": "A simulated indoor household environment used for embodied object-goal navigation; SAVN-NAV is a benchmark sampled from AI2-THOR for navigation evaluation with randomized starts and target items.",
            "citation_title": "here",
            "mention_or_use": "use",
            "environment_name": "AI2-THOR (SAVN-NAV)",
            "environment_description": "Household indoor simulator (photorealistic rooms/kitchens/bedrooms) used for object-goal navigation tasks with randomized start positions and target objects.",
            "graph_diameter": null,
            "clustering_coefficient": null,
            "dead_ends_present": null,
            "dead_ends_count": null,
            "door_constraints_present": null,
            "door_constraints_description": null,
            "graph_connectivity": "Topological (hierarchical object-to-zone) graphs are used for some policies (e.g., HOZ): nodes represent zones/areas or sets of objects; connectivity is a sparse topological graph over areas (hierarchical), not fully connected.",
            "environment_size": null,
            "agent_name": "HOZ w/ LOAT (graph-based) / A3C (policy)",
            "agent_description": "Graph-based policy using a hierarchical object-to-zone topological graph (HOZ); node embeddings aggregate pre-trained text embeddings of objects in the node; A3C is used as the downstream RL policy. LOAT provides node-wise affinity activations by averaging object affinities per node.",
            "exploration_efficiency_metric": "SPL (Success weighted by Path Length), PLWSR (Path Length-Weighted Success Rate), SR (Success Rate)",
            "exploration_efficiency_value": "HOZ baseline SPL 38.80 (units: %), SR 72.20 (%); HOZ w/ LOAT SPL 39.56 (%), SR 73.12 (%) (reported in Table II for SAVN-NAV).",
            "success_rate": "HOZ baseline SR 72.20%; HOZ w/ LOAT SR 73.12% (Table II).",
            "optimal_policy_type": "Graph-based/topological policies with node-level semantic activation (hierarchical graph) perform well in these benchmarks; LOAT-enhanced graph policies slightly outperform plain graph policies.",
            "topology_performance_relationship": "Paper reports that applying affinity-based node activations on topological graphs (averaging object affinities per node) improves node prioritization leading to modest gains in SPL and SR; no explicit numeric dependence given on standard graph-topology metrics (diameter, clustering coefficient).",
            "comparison_across_topologies": true,
            "topology_comparison_results": "The paper compares map-based and graph-based policies and shows LOAT improves both; for SAVN-NAV specifically, HOZ with LOAT slightly improves SPL and SR versus HOZ baseline (about +0.76 SPL and +0.92 percentage points SR). No systematic comparison across different graph topologies (e.g., differing diameters or clustering) is provided.",
            "policy_structure_findings": "Graph-based policies benefit from node-wise activation using averaged object affinities (Equation 6–7). The LOAT dynamic fusion (guidance ratio γ) modulates reliance on semantic LLM priors vs experiential affinities depending on temporal context; RNN hidden states or trajectory history used to compute γ, implying memory/context encodings are important for weighting semantic vs learned priors.",
            "uuid": "e1240.0",
            "source_info": {
                "paper_title": "Advancing Object Goal Navigation Through LLM-enhanced Object Affinities Transfer",
                "publication_date_yy_mm": "2024-03"
            }
        },
        {
            "name_short": "Habitat ObjectNav",
            "name_full": "Habitat simulator (ObjectGoal Navigation benchmark)",
            "brief_description": "A large-scale embodied AI platform with photorealistic indoor scenes used for point- or object-goal navigation; benchmarked here with ObjectNav tasks and SPL/SR metrics.",
            "citation_title": "here",
            "mention_or_use": "use",
            "environment_name": "Habitat (ObjectNav)",
            "environment_description": "Photorealistic indoor environments (reconstructed 3D scenes) for object-goal navigation (find an object category in unseen scenes).",
            "graph_diameter": null,
            "clustering_coefficient": null,
            "dead_ends_present": null,
            "dead_ends_count": null,
            "door_constraints_present": null,
            "door_constraints_description": null,
            "graph_connectivity": "When used, policies can employ metric maps or implicit graph/topological structures; the paper integrates LOAT with a PEANUT-inspired map-based policy and reports improvements. Connectivity specifics (average degree, tree vs mesh) are not provided.",
            "environment_size": null,
            "agent_name": "PEANUT w/ LOAT (map-based) / DD-PPO / PEANUT",
            "agent_description": "PEANUT-inspired map-based navigation model that predicts navigation priors to unseen targets; LOAT supplies per-category affinity channel activations on semantic maps (scales semantic map channels by A_Fc). DD-PPO is a strong baseline trained at scale.",
            "exploration_efficiency_metric": "SPL (Success weighted by Path Length), SR (Success Rate)",
            "exploration_efficiency_value": "DD-PPO SPL 0.20, SR 0.52; PEANUT SPL 0.30, SR 0.55; PEANUT w/ LOAT SPL 0.32, SR 0.63 (values reported in paper).",
            "success_rate": "PEANUT w/ LOAT SR 0.63 (63%), PEANUT SR 0.55 (55%), DD-PPO SR 0.52 (52%).",
            "optimal_policy_type": "Map-based policies augmented with semantic affinity activations (channel-wise scaling of semantic map) improve exploration efficiency; dynamic fusion that leverages LLM priors helps in novel scenes.",
            "topology_performance_relationship": "The paper indicates that enhancing semantic maps via LOAT's affinity scores improves path efficiency (SPL) and success (SR), but does not tie these gains to explicit graph-topology measures (e.g., diameter). The relationship reported is between semantic/affinity guidance and improved exploration efficiency rather than classical graph-theoretic measures.",
            "comparison_across_topologies": true,
            "topology_comparison_results": "Comparison is primarily between map-based (PEANUT) and other baselines (DD-PPO); LOAT improves map-based PEANUT (SPL +0.02, SR +0.08). No experiments vary intrinsic graph topology metrics systematically.",
            "policy_structure_findings": "Map-based policies benefit from channel-wise scaling of semantic maps by LOAT affinities (Equation 5). Dynamic fusion uses temporal/context embeddings to tune reliance on LLM priors vs experiential affinities, implying policies that can incorporate temporal context (memory) better leverage LOAT.",
            "uuid": "e1240.1",
            "source_info": {
                "paper_title": "Advancing Object Goal Navigation Through LLM-enhanced Object Affinities Transfer",
                "publication_date_yy_mm": "2024-03"
            }
        },
        {
            "name_short": "ALFRED (AI2-THOR tasks)",
            "name_full": "ALFRED benchmark (tasks in AI2-THOR for instruction following and object manipulation/navigation)",
            "brief_description": "A dataset/benchmark of instruction-following household tasks in AI2-THOR combining navigation and interaction; used here to test LOAT-P (ULOAT-enhanced Prompter/FILM) for semantic map activation and object finding.",
            "citation_title": "here",
            "mention_or_use": "use",
            "environment_name": "ALFRED (AI2-THOR)",
            "environment_description": "Household instruction-following benchmark (combined navigation + manipulation) built on AI2-THOR scenes; emphasizes realistic multi-step tasks with object search and interaction.",
            "graph_diameter": null,
            "clustering_coefficient": null,
            "dead_ends_present": null,
            "dead_ends_count": null,
            "door_constraints_present": null,
            "door_constraints_description": null,
            "graph_connectivity": "Primarily treated with map-based semantic maps; no explicit graph-topology metrics are provided. LOAT is applied to semantic map channels to bias search.",
            "environment_size": null,
            "agent_name": "LOAT-P (Prompter / FILM enhanced with LOAT), FILM, Prompter",
            "agent_description": "LOAT-P augments existing instruction-following/navigation architectures (FILM, Prompter) by scaling semantic map channels using LOAT affinities and replacing segmentation with DINO for robust detection; downstream policies remain unchanged in architecture.",
            "exploration_efficiency_metric": "SR (Success Rate), GFR (Goal Found Rate), PLW metrics (path-length-weighted variants)",
            "exploration_efficiency_value": "LOAT-P reported as top-performing on ALFRED; specific examples: Prompter valid-seen SR 51.04% -&gt; Prompter w/ LOAT 53.47% (Table IV); FILM valid-seen SR 20.10% -&gt; FILM w/ LOAT 22.78% (Table IV).",
            "success_rate": "Prompter w/ LOAT valid-seen SR 53.47% (vs Prompter 51.04%); FILM w/ LOAT valid-seen SR 22.78% (vs FILM 20.10%).",
            "optimal_policy_type": "Map-based instruction-following policies improved by semantic affinity priors; models that can ingest channel-wise semantic activations (map-based) benefit from LOAT.",
            "topology_performance_relationship": "Improvements are reported when semantic map channels are biased by affinities, leading to better goal-finding (GFR) and SR; the paper does not report relationships to formal graph-topology metrics (diameter/clustering) in ALFRED.",
            "comparison_across_topologies": true,
            "topology_comparison_results": "Paper compares baseline FILM/Prompter to LOAT-augmented variants showing consistent gains across methods (e.g., +~2 percentage points SR for FILM, +~2.4 for Prompter on valid-seen), but does not evaluate different topological graph structures explicitly.",
            "policy_structure_findings": "Integrating LOAT as a preprocessing activation on semantic maps improves performance without changing downstream policy loss or architecture; suggests that providing semantic priors (via affinities) to map-based policies is effective for search efficiency and object discovery.",
            "uuid": "e1240.2",
            "source_info": {
                "paper_title": "Advancing Object Goal Navigation Through LLM-enhanced Object Affinities Transfer",
                "publication_date_yy_mm": "2024-03"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Hierarchical object-to-zone graph for object navigation",
            "rating": 2,
            "sanitized_title": "hierarchical_objecttozone_graph_for_object_navigation"
        },
        {
            "paper_title": "Learning object relation graph and tentative policy for visual navigation",
            "rating": 2,
            "sanitized_title": "learning_object_relation_graph_and_tentative_policy_for_visual_navigation"
        },
        {
            "paper_title": "Visual semantic navigation using scene priors",
            "rating": 2,
            "sanitized_title": "visual_semantic_navigation_using_scene_priors"
        },
        {
            "paper_title": "Esc: Exploration with soft commonsense constraints for zero-shot object navigation",
            "rating": 2,
            "sanitized_title": "esc_exploration_with_soft_commonsense_constraints_for_zeroshot_object_navigation"
        },
        {
            "paper_title": "Poni: Potential functions for object-goal navigation with interaction-free learning",
            "rating": 1,
            "sanitized_title": "poni_potential_functions_for_objectgoal_navigation_with_interactionfree_learning"
        }
    ],
    "cost": 0.012036999999999999,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Advancing Object-Goal Navigation through LLM-enhanced Object Affinities Transfer
20 Jul 2025</p>
<p>Mengying Lin 
Institute of Automation
Chinese Academy of Sciences
BeijingChina</p>
<p>Georgia Institute of Technology
AtlantaUS</p>
<p>Shugao Liu 
Institute of Automation
Chinese Academy of Sciences
BeijingChina</p>
<p>Dingxi Zhang 
ETH Zurich
ZurichCH</p>
<p>Yaran Chen 
Institute of Automation
Chinese Academy of Sciences
BeijingChina</p>
<p>Xi'an Jiaotong-Liverpool University
SuzhouChina</p>
<p>Zhaoran Wang 
McCormick School of Engineering
Northwestern University</p>
<p>Haoran Li lihaoran2015@ia.ac.cn 
Institute of Automation
Chinese Academy of Sciences
BeijingChina</p>
<p>Dongbin Zhao 
Institute of Automation
Chinese Academy of Sciences
BeijingChina</p>
<p>Advancing Object-Goal Navigation through LLM-enhanced Object Affinities Transfer
20 Jul 202589F7CA08812AB1AC6F0288547732D279arXiv:2403.09971v3[cs.RO]
Object-goal navigation requires mobile robots to efficiently locate targets with visual and spatial information, yet existing methods struggle with generalization in unseen environments.Heuristic approaches with naive metrics fail in complex layouts, while graph-based and learning-based methods suffer from environmental biases and limited generalization.Although Large Language Models (LLMs) as planners or agents offer a rich knowledge base, they are cost-inefficient and lack targeted historical experience.To address these challenges, we propose the LLM-enhanced Object Affinities Transfer (LOAT) framework, integrating LLM-derived semantics with learning-based approaches to leverage experiential object affinities for better generalization in unseen settings.LOAT employs a dual-module strategy: one module accesses LLMs' vast knowledge, and the other applies learned object semantic relationships, dynamically fusing these sources based on context.Evaluations in AI2-THOR and Habitat simulators show significant improvements in navigation success and efficiency, and real-world deployment demonstrates the zero-shot ability of LOAT to enhance objectgoal navigation systems.</p>
<p>I. INTRODUCTION</p>
<p>Object navigation is a basic skill for the mobile robot, which enables the robot to navigate to a specified target object within a scene given category names.The objective is to find the object successfully and minimize the navigation path [1].Considering the trade-off between success rate and efficiency, how to leverage object semantic relationships in the household environment is an important direction for more efficient navigation.</p>
<p>Understanding object relationships is key to efficient navigation.Heuristic methods using non-training distance metrics like Euclidean distance [2] are simple but fail to reflect navigable path lengths in complex multi-room layouts.Graph-based methods construct learnable nodes and edges representing categories and correlations [3], yet struggle with generalization due to training biases and stationary structures that cannot handle unseen targets.</p>
<p>Learning-based methods using elaborate training data poorly generalize to new scenes or objects.Large language models (LLMs) and vision-language models (VLMs) offer richer contextual insights to enhance generalization [4], but inconsistent inference scores and variable object priorities with paraphrased prompts affect stability.Direct LLM/VLM applications as navigation agents (SayNav [5], NavGPT [6]) show strong generalization but require frequent, computationally intensive queries.While excelling in general reasoning, their broad knowledge may lack specificity for certain contexts like culturally specific household layouts, potentially causing suboptimal performance.</p>
<p>In this work, we propose the LLM-enhanced Object Affinities Transfer (LOAT) framework to improve generalization and navigation performance in novel environments.LOAT integrates LLM commonsense reasoning through a generalized affinities module with learned object relationships from an experiential affinities module.This combination leverages LLMs' diverse cultural knowledge while grounding it with experiential patterns, enhancing decision-making in complex household layouts.A dynamic fusion module balances these affinity sources based on temporal contexts.</p>
<p>Our main contributions are:</p>
<p>• We propose LOAT, a novel framework that enhances object-goal navigation efficiency by providing object affinity guidance to downstream navigation policies with minimal architectural modifications.• We design three core modules-experiential affinities, generalized affinities, and dynamic fusion-that significantly improve generalization for unseen objects through effective LLM-historical information integration.</p>
<p>• Extensive experiments across multiple simulators and real-world tasks demonstrate LOAT substantially improves navigation success rates and path efficiency with impressive generalization in novel scenarios.</p>
<p>II. RELATED WORK</p>
<p>A. Traditional Methods to Object-Goal Navigation</p>
<p>Object-goal navigation, a foundational area in Embodied AI, aims to enable agents to locate specific target objects in unseen environments.Traditional approaches fall into two categories: end-to-end learning-based methods that train agents directly through sensory inputs, and map-based methods that construct environmental representations to guide navigation.</p>
<p>1) End-to-End Learning-Based Methods: End-to-end learning methods have gained traction for training em-bodied navigation agents [7], focusing on maximizing reward functions that incentivize successful object discovery [8].Recent advancements introduce novel architectures enhancing navigation capabilities.Decision Transformer [9] employs sequence modeling to learn policies by conditioning on historical data, enabling adaptability across navigation tasks.MTVM [10] explicitly models historical observationinstruction interactions, crucial for understanding navigation trajectory progress.PoliFormer [11] represents a fully transformer-based agent integrating causal transformer decoders with long-term memory and reasoning capabilities, designed to scale with on-policy reinforcement learning training.</p>
<p>2) Map-Based Methods: Map-based methods fall into two categories: direct prediction and frontier-based exploration.</p>
<p>a) Direct Prediction: Direct prediction includes action prediction and waypoint prediction.Action prediction uses current observations and semantic maps to guide real-time agent movements, enabling responsive adaptation to environmental changes [12].Waypoint prediction trains models on map datasets to generate probabilistic maps indicating potential target locations, facilitating efficient path planning by directing agents toward high-probability areas [13]- [15].b) Frontier-based Exploration: This approach utilizes semantic data to define exploration boundaries through obstacle maps constructed from egocentric RGB-D images [16].By establishing a structured framework, frontier-based methods enhance agents' navigation capabilities, facilitating targeted exploration and improving overall navigation efficiency [17], [18].</p>
<p>B. Large Models-based Object Navigation</p>
<p>Incorporating large models into navigation systems follows three methodologies:</p>
<p>1) Object Relevance Scoring with Scripted Strategies: This approach leverages large models to evaluate object relevance using scripted search strategies like frontier-based methods [19], [20].ESC [4] employs LLMs for direct candidate scoring, while L3MVN [21] and Prompter [22] derive collocation probabilities from masked language models with prompts like "Something you find at [MASK] is [TARGET]," scoring candidates based on their placement in the "[MASK]" token.However, model sensitivity to language changes causes significant score variability with prompt modifications, affecting consistency of object relevance assessments.</p>
<p>2) High-Level Planning with Large Models: This method uses large models for strategic planning and task decomposition in long-horizon navigation [23].LLM-Planner [24] breaks down tasks and identifies key landmarks from instructions, establishing subgoals and initiating replanning upon failure.This strategy struggles in scenarios lacking explicit high-level instructions for targeting objects.</p>
<p>3) Navigation Agent: SayNav [5] and NavGPT [6] directly use language models as navigational agents, requiring frequent prompts at every step.While conceptually appeal-ing for dynamic adaptability, computational and time costs constrain practicality for wide-scale application.</p>
<p>III. METHODS</p>
<p>Rather than utilizing LLMs as high-level planners requiring complex alignment with low-level policies, our approach employs language-based priors in numerically interpretable formats for downstream models.LOAT converts semantic object relationships into continuous affinity scores directly integrated into existing navigation architectures.As shown in Fig. 1, the LOAT framework integrates LLM-derived insights with historical object affinity data to enhance semantic maps, bridging high-level semantic understanding with low-level policy execution.</p>
<p>The framework consists of three modules: the generalized affinities module captures broad semantic knowledge from LLMs and outputs relevance scores for each object category; the experiential affinities module leverages learned object relationships from training data; and the dynamic fusion module balances these sources based on contextual inputs.These numerical affinity scores directly inform node-wise or channel-wise activation based on map types, enriching semantic maps for informed navigation without requiring architectural changes to underlying policy networks.</p>
<p>A. Experiential Affinities Module</p>
<p>This module aims at extracting object affinities from training time.It employs a scaled dot-product similarity mechanism to determine the relevance of each environmental object to the target, leveraging pre-trained text embeddings.The set of objects in maps is represented as O = {o 1 , o 2 , ..., o M }, where M is the total category number in maps and o target is the target.The embedding for any object o i is obtained through a pre-trained text encoder as e(o i ), which converts object category names into fixed-dimensional vector representations.</p>
<p>To compute the affinity scores, we first transform the embeddings into queries Q and keys K i using learned linear transformations for the target and all other objects respectively:
Q = W q e(o target ), K i = W k e(o i ),(1)
where W q and W k are weight matrices for queries and keys, and K i represents the key vector for object o i .The experiential affinity score A Ei for each object o i is then calculated using the scaled dot-product similarity with softmax normalization:
A Ei = exp(Q • K T i / √ d k ) M j=1 exp(Q • K T j / √ d k ) ,(2)
where d k is the dimensionality of the key vectors, serving to scale the dot product such that it leads to more stable gradients, with K j being the key corresponding to the j th object in the environment.This formulation computes continuous similarity scores based on learnable transformations of pretrained embeddings, capturing statistical patterns observed during training.</p>
<p>LLM-enhanced Object Afinities Transfer</p>
<p>Feed in Downstream Policy
Generalized</p>
<p>Dynamic Fusion Module</p>
<p>Fig. 1.LOAT Framework.This framework processes the target and scene map categories to locate the target based on object affinities.Category information is passed to two main modules: the generalized affinities module, powered by LLMs, which assesses each object's relevance, and the experiential affinities module, which uses a pre-trained text tokenizer for historical object affinities.A dynamic fusion module balances these inputs using temporal state embeddings before applying the scores for node-wise or channel-wise activation to enhance downstream policy decision-making.</p>
<p>This mechanism effectively captures the semantic relationship between the target and every other object in the map by computing normalized similarity scores that prioritize objects based on their learned relevance to the target.The resultant affinity scores guide the module to emphasize features from objects more closely related to the target in training experiences, thus enhancing pattern recognition and facilitating more informed navigation decisions within known contexts.</p>
<p>B. Generalized Affinities Module</p>
<p>The generalized affinities module leverages semantic relations derived from LLMs to enhance focus on objects semantically related to a specified target.While LLMs could score object affinities directly, inconsistent inference scores and varied object priorities from prompting present challenges.Paraphrased prompts lead to unstable scoring, potentially undermining system reliability.To address this, we shift focus from specific scores to object relevance, ensuring consistent generalized knowledge.Therefore, we use LLM priors solely as identifiers of relevant objects rather than for exact scoring.</p>
<p>The semantic relevance of each object o i in the map to the target o target is determined by a binary value S(o i , o target ), indicated by a LLM.This setup ensures that all objects deemed semantically related to the target are assigned a nonzero attention weight and remain unaffected by the object affinities from training data.By employing this uniform attention mechanism, the module guarantees that the agent considers all potentially relevant objects, thus improving its adaptability and performance in unfamiliar settings.</p>
<p>The generalized attention weight A Gi for each object o i is calculated as:
A Gi = S(o i , o target ) M j=1 S(o j , o target ) .(3)
In contrast to Equ. ( 2), this formulation operates on discrete binary relevance judgments S(o i , o target ) ∈ {0, 1} from LLMs, where the function S indicates semantic relevance without considering similarity magnitudes.While Equ. ( 2) learns continuous affinity patterns from training data through learnable parameters W q and W k , Equ. (3) leverages fixed semantic knowledge from pre-trained language models, ensuring uniform attention distribution among all semantically relevant objects.The final output of the generalized affinities module is a normalized vector, which directs the agent's focus towards objects of interest specified by LLM for better generalization.</p>
<p>C. Dynamic Fusion Module</p>
<p>The dynamic fusion module synergizes the outputs from the generalized affinities module (A G ) and the experiential affinities module (A E ), finely tuning the balance between learned patterns and semantic guidance for optimal navigation performance.Specifically, it adjusts the contributions of A Gi and A Ei , the attention scores for an object o i from the respective modules, ensuring an adaptive final attention mechanism.</p>
<p>This adaptation is driven by the guidance ratio γ, which is dynamically modulated based on the temporal context H and, when available, additional environmental factors E.</p>
<p>In architectures utilizing RNNs to encode the current state, H includes the hidden states of the RNNs.For non-RNN architectures, H encompasses the agent's past trajectory and relevant environmental data, such as explored regions and observed layouts.E further enriches this context with external cues, aiding in the precise adjustment of γ.</p>
<p>The key idea involves extracting features that capture historical and environmental contexts, with processing tailored to the specific modality of each context as shown in Fig. 2. All available context features are concatenated and fed into the final MLP to obtain the dynamic rate γ.Building on this design, γ is dynamically adjusted according to the context: it decreases in familiar environments where experiential patterns are consistent, and increases in novel or complex settings where LLMs provide more effective navigational insights.This dynamic fusion of affinity scores enables the system to adaptively employ the most effective navigation strategy for the given scenario:
A Fi = γ • A Gi + (1 − γ) • A Ei .(4)
Through this mechanism, the dynamic fusion module ensures that the final affinity scores (A Fi ) for each object o i are flexibly adapted to the navigation task's specific needs.By leveraging both experiential patterns and semantic guidance, the module enhances the agent's ability to efficiently navigate across diverse environmental contexts, capitalizing on the strengths of both submodules.</p>
<p>D. Integration with Downstream Policy</p>
<p>The LOAT framework's affinity scores are systematically integrated into downstream policies to intensify the focus on objects pertinent to the navigation goal.This integration applies slightly different strategies for map-based and graphbased policies, optimizing the agent's navigational efficacy.</p>
<p>Map-based Policy: Let S m ∈ R HimesW ×C represent a multi-channel semantic map, where H and W are the spatial dimensions and C is the number of object categories.Each channel c ∈ {1, 2, ..., C} corresponds to a specific object category (e.g., "chair", "table", "door") and contains a 2D grid where each cell value indicates the presence or confidence of that object category at the corresponding spatial location.This representation is a classical grid-based semantic map enhanced with categorical channels, not a neural feature map.</p>
<p>The affinity score for each object category c, derived from the dynamic fusion in Equ.(4), is represented by A Fc ∈ R. The activation of channel c in response to the affinity is computed as:
Activation(c) = A Fc • S m [:, :, c],(5)
where S m [:, :, c] ∈ R HimesW denotes the entire 2D spatial channel for object category c, and the multiplication is element-wise across all spatial locations.This operation scales the entire channel by the corresponding affinity score, creating a search bias that emphasizes spatial regions containing objects deemed relevant to the target.</p>
<p>Graph-based Policy: For a topological graph G, with node N representing a distinct area or a set of objects, let A F N denote the averaged affinity scores for objects within node N , which is given by:
A F N = 1 |O N | oi∈O N A F oi ,(6)
where O N is the object set within node N and A F oi is the affinity score for object o i .Let E N denote the embedding for node N generated by the downstream graph-based policy.In typical graph-based navigation policies, the node embedding E N is constructed by aggregating the pre-trained text embeddings of all objects within the node:
Activation(N ) = E N • A F N = E N |O N | oi∈O N A F oi .(7)
This node-wise activation process highlights nodes with high relevance to the target, guiding the policy to prioritize exploration of these strategically important nodes.</p>
<p>Training LOAT with Downstream Policy: LOAT functions as a flexible plugin compatible with diverse downstream policies without modifying their original training loss functions.LOAT operates as a preprocessing module that enhances input features (semantic maps or node embeddings) rather than altering learning objectives, allowing downstream policies to continue optimizing their original loss using enhanced inputs.Downstream policies may employ imitation learning, reinforcement learning, or other methods.When integrated with LOAT, training becomes two-stage.First, the experimental affinity module is co-trained with the downstream policy.Second, the generalized affinity module and dynamic fusion layer are introduced while freezing weights of both the experimental affinity module and downstream policy, updating only the dynamic fusion layer parameters.</p>
<p>By employing these strategies, LOAT significantly refines decision-making process, enhancing adaptability and generalization across diverse environments.Through targeted activation within downstream policies, the approach leverages learned environmental patterns and generalized semantic insights from LLMs, creating a robust framework for focused navigation.</p>
<p>IV. EXPERIMENTS</p>
<p>A. Setup 1) Benchmarks and Metrics: We evaluate the proposed method across Habitat [25] and AI2-THOR [26] simulators, including three benchmarks emphasizing object-goal navigation: ALFRED [27], Habitat ObjectNav [28], and SAVN-NAV1 .To evaluate the methods, we use several key metrics: SR (Success Rate): Percentage of episodes where the agent successfully completes the task by reaching the target object.SPL (Success weighted by Path Length): Ratio of the 2) Implementation Details and Baselines: We utilize paraphrase-MiniLM-L6-v2 [34] to compute text embeddings for category names, producing 384-dimensional dense vectors.To assess object affinities, GPT-4 is introduced to store semantic scores for faster navigation.Two 2-layer MLPs with ReLU are employed to calculate the guidance ratio γ.</p>
<p>For ALFRED tasks, we enhance the FILM [13] system with LOAT for semantic map activation.We replace Mask R-CNN with a fine-tuned DINO [35] model for object segmentation because DINO provides more robust object detection in diverse indoor environments, which is essential for accurate semantic map construction that LOAT relies upon.Additionally, we adapt a Prompter-inspired [22] exploration strategy as it demonstrates superior performance in instruction-following tasks, ensuring fair comparison by using strong baseline components.These modifications are applied consistently across all compared methods to maintain experimental fairness.This enhanced system, called LOAT-P, offers an integrated solution for improved navigation and object interaction in AI2-THOR environments.</p>
<p>LOAT-P is compared to several established methods, including HLSM [30], which uses a spatial-semantic voxel map for environment modeling; FILM [13], known for its spatial memory and semantic search capabilities; LGS-RPA [31], which employs landmark-guided search; EPA [32], featuring neural-symbolic planning; Prompter [22], based on templatedriven planning; CAPEAM [33], which integrates spatial and state-change information; and LLM-Planner [24], a trainingfree approach leveraging large language models for few-shot planning.</p>
<p>We also evaluate the LOAT framework with a graph-based policy from the HOZ [3] system on the SAVN-NAV navigation tasks [29].The activated hierarchical graphs are then fed into an A3C [36] policy and trained with reinforcement learning.We compare the LOAT-enhanced HOZ with a naive A3C policy that utilizes a simple visual embedding layer, as well as other graph-centric methods like ORG [37] and SP [38], which establish object semantic relationships.</p>
<p>For Habitat ObjectNav tasks, we adapt a PEANUTinspired model [14], trained with the LOAT framework.For evaluating the LOAT-enhanced PEANUT, we benchmark it against PEANUT and DD-PPO [39] trained on 20,000 human demonstrations.I. LOAT-P achieves SOTA performance across all metrics, with a notable 10% increase in SR.While some improvements appear modest in absolute terms, they represent meaningful advances in object navigation where even small gains often require substantial algorithmic innovations.Notably, the SR discrepancy between familiar and unfamiliar environments is markedly reduced, showcasing LOAT's efficacy in applying generalized object affinities from LLMs in novel settings.</p>
<p>B. Results</p>
<p>ALFRED experiment results are shown in Table</p>
<p>Following [3], we employ SAVN-NAV navigation tasks [29] with random selection of agent's initial position and goal item, using five trials per scenario.Table II displays results for all targets and a subset with optimal path lengths above five steps.Integrating LOAT into the HOZ system improved both SPL and SR metrics, surpassing previously reproduced results and underscoring LOAT's effectiveness within graph-based policy.</p>
<p>Habitat ObjectNav validation results in Table III demonstrate significant performance enhancement from incorporating LOAT.The PEANUT w/ LOAT method exhibits notable improvements in both SPL and SR, suggesting that LOAT not only optimizes policy learning but also significantly boosts navigation capabilities in complex environments.</p>
<p>Method SPL SR</p>
<p>DD-PPO [39] 0.20 0.52 Habitat-Web [40] 0.22 0.55 ProcTHOR [41] 0.32 0.54 PIRLNav [42] 0.28 0.62 PEANUT [14] 0.30 0.55 PEANUT w/ LOAT 0.32 0.63 Comprehensive analysis across three benchmark evaluations reveals that LOAT excels in three key aspects:</p>
<p>1) Improves effectiveness and generalization of navigation systems.LOAT combines experienced object affinities with LLM semantic understanding, leading to higher success rates, reduced navigation pathways, and improved generalization to new environments.2) Compatible with current SOTA methods, LOAT enhances performance in various navigation contexts by working well with both graph-based and mapbased policies, improving performance regardless of the downstream policy mechanism.3) Offers targeted guidance for navigating towards small, hard-to-locate or unseen objects.By leveraging object affinities from both training experiences and LLM insights, it efficiently detects objects difficult to identify without context from relevant easier-to-find objects.For example, LOAT locates a "fork" by first identifying a nearby "dining table" or "kitchen counter" where forks commonly appear.</p>
<p>C. Ablation Studies 1) Impact of the LOAT Framework in ALFRED [27]: The LOAT-P system dramatically increased ALFRED's performance in previous experiments.To differentiate the impact of the LOAT framework from other improvements, such as advanced segmentation methods, LOAT is rigorously evaluated by integrating it into the Prompter [22] and FILM [13] on the ALFRED benchmark, respectively.Table IV shows enhancements across all measured metrics upon incorporating the LOAT framework.Notably, the improvement in GFR is a testament to LOAT's ability to significantly enhance the agent's proficiency in identifying target objects.This underscores the framework's effectiveness in augmenting navigational and object-identification capabilities with insights from both LLM-derived object affinities and training-time preferences, thereby contributing to the overall performance uplift.2) Impact of LOAT Submodules: The LOAT framework's integration of Generalized Affinities (G.A.) and Experiential Affinities (E.A.) modules enhances navigation and task execution, as shown in Table V.The G.A. module slightly improves success rates through general knowledge guidance, but shows limitations in complex scenarios without learned experience.The E.A. module improves outcomes in both short and long trials by applying specific past experiences.</p>
<p>Integration of both modules yields the highest performance improvements.While G.A. provides a broad knowledge base, E.A. extracts targeted knowledge from training, optimizing both general principles and specific experiences.Beyond this parallel integration of LLM commonsense and experiential object affinities, we also explore using LLM commonsense as a constraint.This comprehensive approach enables LOAT to navigate complex environments more effectively, demonstrating the importance of integrating diverse knowledge sources for advanced decision-making and problem-solving capabilities.Predicted Distribution for Out-of-domain Objects.In (a), models without the generalized affinities module may make less acceptable assumptions, such as linking a can opener with a bathtub basin.Using LLMderived knowledge, models in (b) make more accurate predictions, such as positioning can openers near cabinets or coffee tables.</p>
<p>Target Objects</p>
<p>Objects in Map</p>
<p>D. Evaluation on Out-of-Domain Objects</p>
<p>Since LOAT employs text embeddings instead of onehot encodings for task representation, we examine model performance on unseen targets without training.We assessed out-of-domain object recognition using 300 precollected semantic maps from AI2-THOR environments, predicting potential locations for unseen targets based on category names: "Umbrella", "HairDrier", "Scissors", "Toothbrush", "Comb", "Peach", "CanOpener", "Whisk", "Magazine", "Eyeglasses".The model identifies nearest objects in the map to these targets, applying a distance threshold of one-fifteenth of the map's total resolution.We focused on assessing semantic logic behind probability distributions to determine if predicted locations were plausible within domestic contexts.Fig. 3 shows that models relying solely on experience transfer may predict uniform distributions, resulting in semantically incongruous predictions (e.g.associating a can opener with a bathtub basin).LOAT-integrated models better incorporate commonsense reasoning from LLMs, producing logically coherent probability distributions (e.g.placing a can opener near cabinets or coffee tables) reflecting intuitive home placement expectations.</p>
<p>E. Navigation in Real Environments</p>
<p>We conduct real-world navigation tasks with the LoCoBot wx250s platform, powered by an Intel NUC Mini PC running ROS.The robot connects to an NVIDIA GeForce RTX 3060 laptop hosting the LOAT-P navigation system, while an Intel RealSense D455 camera captures RGB and depth images for environmental perception.The LOAT-P system was deployed in two laboratory-adapted scenes simulating household environments with distinct semantic divisions.It located five object categories-Apple, Book, Bowl, Cup, and Laptop-across three trials per scene from various initial positions.The system transitioned directly from simulation (trained on ALFRED dataset) to real-world applications without further training.</p>
<p>Results indicated successful location of all target objects, demonstrating LOAT's effective generalization to unseen environments.Visual examples, such as accurate bowl identification near the microwave, are shown in Fig. 4.These findings confirm the robustness and adaptability of LOAT-P navigation system in real-world scenarios.</p>
<p>V. CONCLUSIONS</p>
<p>In this paper, we propose the LOAT framework, a novel approach that integrates LLM-derived object semantics with historical experiential object affinities to enhance robotic navigation.LOAT significantly improves navigation in environments like AI2-THOR and Habitat across three benchmarks, demonstrating excellent navigation performance and generalization ability in unseen scenarios and targets.In addition, as a flexible plugin, it can be combined with different types of downstream policy, such as metric-mapbased and topological-graph-based policies.</p>
<p>While LOAT's performance can be influenced by the diversity of object categories in the underlying semantic map, extending LOAT's dual-module strategy to open vocabulary navigation is still challenging.Such an approach holds promise for expanding its adaptability to a broader range of environments and tasks, further advancing autonomous navigation capabilities.</p>
<p>Fig. 2 .
2
Fig.2.The Architecture of Dynamic Fusion Module.The input of the dynamic fusion module could be several environmental and temporal contexts, the encoders of which are dependent on their modalities.All of the flattened features will be further concatenated together before undergoing the final MLP and outputting the guidance rate.</p>
<p>Fig. 3.Predicted Distribution for Out-of-domain Objects.In (a), models without the generalized affinities module may make less acceptable assumptions, such as linking a can opener with a bathtub basin.Using LLMderived knowledge, models in (b) make more accurate predictions, such as positioning can openers near cabinets or coffee tables.</p>
<p>Fig. 4 .
4
Fig. 4. Real-world Navigation Examples.In real world experiments, model with LOAT is able to make reasonable predictions without extra training.</p>
<p>TABLE I COMPARISON
I
WITH THE STATE-OF-THE-ART METHODS IN ALFRED.Weights goal completion by the optimality of the path taken.GFR (Goal Found Rate): Measures the agent's ability to locate the target object based on high-level instructions, indicating navigation success apart from completion.
MethodTests SeenTests UnseenSRPLWSRGCPLWGCSRPLWSRGCPLWGCHLSM [30]29.948.7441.2114.5820.275.5530.319.99FILM [13]27.6711.2338.5115.0624.4610.5536.3714.30LGS-RPA [31]33.0116.6541.7124.4927.8012.9238.5520.01EPA [32]39.962.5644.143.4736.072.9239.543.91Prompter [22]49.3823.4755.9029.0642.6419.4959.5525.00CAPEAM [33]47.3619.0354.3823.7843.6917.6454.6622.76LLM-Planner [24] 18.20-26.77-16.42-23.37-LOAT-P (ours)56.0328.5965.3633.5454.2228.1263.8533.51shortest path to the actual path taken, adjusted for suc-cess to assess navigation efficiency. PLWSR (Path LengthWeighted Success Rate): Evaluates success while penalizinglonger paths, enhancing efficiency assessment. GC (GoalCompletion): Indicates whether the agent achieved the taskobjective. PLWGC (Path Length Weighted Goal Comple-tion):</p>
<p>TABLE II COMPARISON
II
IN SAVN-NAV NAVIGATION TASKS IN AI2-THOR.
MethodAllLong Trials (L ≥ 5)SPLSRSPLSRRandom1.733.560.070.27A3C <a href="baseline">36</a> 33.78 57.35 30.6545.77SP [38]37.01 62.16 34.1750.86ORG [37]38.42 66.38 36.2655.55HOZ [3]38.80 72.20 38.8364.05HOZ w/ LOAT39.56 73.12 39.6865.26</p>
<p>TABLE III RESULTS
III
IN HABITAT OBJECTNAV IN VAL SPLIT.</p>
<p>TABLE IV PERFORMANCE
IV
WITH/WITHOUT LOAT INTEGRATION IN ALFRED.
MethodValid SeenValid UnseenSRGFRSRGFRFILM [13]20.10 56.15 23.66 58.41FILM [13] w/ LOAT22.78 56.27 26.46 60.37Prompter [22]51.04 65.04 52.20 73.66Prompter [22] w/ LOAT 53.47 66.63 53.78 75.85</p>
<p>TABLE V COMPARATIVE
V
EVALUATION OF HOZ INCORPORATING LOAT FRAMEWORK VARIANTS, EXPERIENTIAL AFFINITIES (E.A.) AND GENERALIZED AFFINITIES (G.A.) MODULES.
MethodAll TrialsLong Trials (L ≥ 5)SPL (%) Success (%) SPL (%) Success (%)Baseline (HOZ) [29]38.8072.2038.8364.05w/ G.A. Module38.9472.4038.7864.05w/ E.A. Module39.0372.5139.0864.35w/ Full LOAT39.5673.1239.6865.26
A benchmark in AI2-THOR collected by Wortsman et. al[29], referred as SAVN-NAV
This work is partly supported by the National Natural Science Foundationof China (NSFC) under Grants No. 62173324, and in part by the CAS for Grand Challenges under Grant 104GJHZ2022013GC.
A survey of object goal navigation. J Sun, J Wu, Z Ji, Y.-K Lai, IEEE Transactions on Automation Science and Engineering. 222025</p>
<p>How to not train your dragon: Training-free embodied object goal navigation with semantic frontiers. J Chen, G Li, S Kumar, B Ghanem, F Yu, Robotics: Science and Systems XIX. K E Bekris, K Hauser, S L Herbert, J Yu, Daegu, Republic of KoreaJuly 10-14, 2023. 2023</p>
<p>Hierarchical object-to-zone graph for object navigation. S Zhang, X Song, Y Bai, W Li, Y Chu, S Jiang, Proceedings of the IEEE/CVF International Conference on Computer Vision. the IEEE/CVF International Conference on Computer Vision2021140</p>
<p>Esc: Exploration with soft commonsense constraints for zero-shot object navigation. K Zhou, K Zheng, C Pryor, Y Shen, H Jin, L Getoor, X E Wang, International Conference on Machine Learning. PMLR202342842</p>
<p>Saynav: Grounding large language models for dynamic planning to navigation in new environments. A Rajvanshi, K Sikka, X Lin, B Lee, H.-P Chiu, A Velasquez, Proceedings of the International Conference on Automated Planning and Scheduling. the International Conference on Automated Planning and Scheduling202434</p>
<p>Navgpt: Explicit reasoning in visionand-language navigation with large language models. G Zhou, Y Hong, Q Wu, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence202438</p>
<p>Mat: Morphological adaptive transformer for universal morphology policy learning. B Li, H Li, Y Zhu, D Zhao, IEEE Transactions on Cognitive and Developmental Systems. 1642024</p>
<p>Deep reinforcement learning-based automatic exploration for navigation in unknown environment. H Li, Q Zhang, D Zhao, IEEE Transactions on Neural Networks and Learning Systems. 3162020</p>
<p>Decision transformer: Reinforcement learning via sequence modeling. L Chen, K Lu, A Rajeswaran, K Lee, A Grover, M Laskin, P Abbeel, A Srinivas, I Mordatch, Advances in Neural Information Processing Systems. Curran Associates, Inc20213497</p>
<p>Multimodal transformer with variable-length memory for vision-and-language navigation. C Lin, Y Jiang, J Cai, L Qu, G Haffari, Z Yuan, Computer Vision -ECCV 2022. 2022</p>
<p>Poliformer: Scaling onpolicy rl with transformers results in masterful navigators. K.-H Zeng, Z Zhang, K Ehsani, R Hendrix, J Salvador, A Herrasti, R Girshick, A Kembhavi, L Weihs, Proceedings of the Conference on Robot Learning (CoRL). the Conference on Robot Learning (CoRL)2024</p>
<p>Think global, act local: Dual-scale graph transformer for vision-and-language navigation. S Chen, P.-L Guhur, M Tapaswi, C Schmid, I Laptev, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. the IEEE/CVF Conference on Computer Vision and Pattern Recognition2022547</p>
<p>FILM: following instructions in language with modular methods. S Y Min, D S Chaplot, P K Ravikumar, Y Bisk, R Salakhutdinov, International Conference on Learning Representations. 2022</p>
<p>Peanut: predicting and navigating to unseen targets. A J Zhai, S Wang, Proceedings of the IEEE/CVF International Conference on Computer Vision. the IEEE/CVF International Conference on Computer Vision2023935</p>
<p>Common sense language-guided exploration and hierarchical dense perception for instruction following embodied agents. Y Chen, X Zhang, Y Chen, D Zhao, Y Zhao, Z Zhao, P Hu, 2024 IEEE International Conference on Multimedia and Expo (ICME). 2024</p>
<p>A frontier-based approach for autonomous exploration. B Yamauchi, Proceedings 1997 IEEE International Symposium on Computational Intelligence in Robotics and Automation CIRA'97. 'Towards New Computational Principles for Robotics and Automation. 1997 IEEE International Symposium on Computational Intelligence in Robotics and Automation CIRA'97. 'Towards New Computational Principles for Robotics and Automation1997</p>
<p>Cows on pasture: Baselines and benchmarks for language-driven zero-shot object navigation. S Y Gadre, M Wortsman, G Ilharco, L Schmidt, S Song, 2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). 202323181</p>
<p>Poni: Potential functions for objectgoal navigation with interaction-free learning. S K Ramakrishnan, D S Chaplot, Z Al-Halah, J Malik, K Grauman, 2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). 202218878</p>
<p>Frontier based exploration for autonomous robot. A Topiwala, P Inani, A Kathpal, abs/1806.03581CoRR. 2018</p>
<p>Leaffordnav: Enhancing open-vocabulary mobile manipulation with llm-guided exploration and affordance-aware navigation. Y Chen, H Li, Y Chen, D Zhao, 2025 IEEE International Conference on Multimedia and Expo (ICME). 2025</p>
<p>L3mvn: Leveraging large language models for visual target navigation. B Yu, H Kasaei, M Cao, 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS). IEEE2023</p>
<p>Prompter: Utilizing large language model prompting for a data efficient embodied instruction following. Y Inoue, H Ohashi, abs/2211.03267CoRR. 2022</p>
<p>Robogpt: an llm-based long-term decision-making embodied agent for instruction following tasks. Y Chen, W Cui, Y Chen, M Tan, X Zhang, J Liu, H Li, D Zhao, H Wang, IEEE Transactions on Cognitive and Developmental Systems. 2025</p>
<p>Llm-planner: Few-shot grounded planning for embodied agents with large language models. C H Song, J Wu, C Washington, B M Sadler, W.-L Chao, Y Su, Proceedings of the IEEE/CVF International Conference on Computer Vision. the IEEE/CVF International Conference on Computer Vision2023</p>
<p>Habitat: A Platform for Embodied AI Research. M Savva, A Kadian, O Maksymets, Y Zhao, E Wijmans, B Jain, J Straub, J Liu, V Koltun, J Malik, D Parikh, D Batra, Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV). the IEEE/CVF International Conference on Computer Vision (ICCV)2019</p>
<p>E Kolve, R Mottaghi, W Han, E Vanderbilt, L Weihs, A Herrasti, D Gordon, Y Zhu, A Gupta, A Farhadi, AI2-THOR: An Interactive 3D Environment for Visual AI. 2017arXiv</p>
<p>Alfred: A benchmark for interpreting grounded instructions for everyday tasks. M Shridhar, J Thomason, D Gordon, Y Bisk, W Han, R Mottaghi, L Zettlemoyer, D Fox, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. the IEEE/CVF Conference on Computer Vision and Pattern Recognition202010749</p>
<p>Habitat challenge 2022. K Yadav, S K Ramakrishnan, A Gokaslan, O Maksymets, R Jain, R Ramrakhya, A X Chang, A Clegg, M Savva, E Undersander, D S Chaplot, D Batra, </p>
<p>Learning to learn how to learn: Self-adaptive visual navigation using meta-learning. M Wortsman, K Ehsani, M Rastegari, A Farhadi, R Mottaghi, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. the IEEE/CVF Conference on Computer Vision and Pattern Recognition2019</p>
<p>A persistent spatial semantic representation for high-level natural language instruction execution. V Blukis, C Paxton, D Fox, A Garg, Y Artzi, Conference on Robot Learning. PMLR2022</p>
<p>Following natural language instructions for household tasks with landmark guided search and reinforced pose adjustment. M Murray, M Cakmak, IEEE Robotics and Automation Letters. 732022</p>
<p>A planning based neural-symbolic approach for embodied instruction following. X Liu, H Palacios, C Muise, Interactions. 98172022</p>
<p>Context-aware planning and environment-aware memory for instruction following embodied agents. B Kim, J Kim, Y Kim, C Min, J Choi, Proceedings of the IEEE/CVF International Conference on Computer Vision. the IEEE/CVF International Conference on Computer Vision202310946</p>
<p>Sentence-bert: Sentence embeddings using siamese bert-networks. N Reimers, I Gurevych, Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing. the 2019 Conference on Empirical Methods in Natural Language ProcessingAssociation for Computational Linguistics112019</p>
<p>Emerging properties in self-supervised vision transformers. M Caron, H Touvron, I Misra, H Jégou, J Mairal, P Bojanowski, A Joulin, Proceedings of the IEEE/CVF International Conference on Computer Vision. the IEEE/CVF International Conference on Computer Vision2021</p>
<p>Asynchronous methods for deep reinforcement learning. V Mnih, A P Badia, M Mirza, A Graves, T P Lillicrap, T Harley, D Silver, K Kavukcuoglu, Proceedings of the International Conference on Machine Learning. the International Conference on Machine Learning2016</p>
<p>Learning object relation graph and tentative policy for visual navigation. H Du, X Yu, L Zheng, Computer Vision -ECCV 2020. A Vedaldi, H Bischof, T Brox, J.-M Frahm, ChamSpringer International Publishing2020</p>
<p>Visual semantic navigation using scene priors. W Yang, X Wang, A Farhadi, A Gupta, R Mottaghi, International Conference on Learning Representations. 2019</p>
<p>DD-PPO: learning near-perfect pointgoal navigators from 2.5 billion frames. E Wijmans, A Kadian, A Morcos, S Lee, I Essa, D Parikh, M Savva, D Batra, International Conference on Learning Representations. 2020</p>
<p>Habitatweb: Learning embodied object-search strategies from human demonstrations at scale. R Ramrakhya, E Undersander, D Batra, A Das, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. the IEEE/CVF Conference on Computer Vision and Pattern Recognition2022</p>
<p>Procthor: Largescale embodied ai using procedural generation. M Deitke, E Vanderbilt, A Herrasti, L Weihs, K Ehsani, J Salvador, W Han, E Kolve, A Kembhavi, R Mottaghi, Advances in Neural Information Processing Systems. 202235</p>
<p>Pirlnav: Pretraining with imitation and rl finetuning for objectnav. R Ramrakhya, D Batra, E Wijmans, A Das, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. the IEEE/CVF Conference on Computer Vision and Pattern Recognition2023906</p>            </div>
        </div>

    </div>
</body>
</html>