<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-8262 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-8262</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-8262</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-152.html">extraction-schema-152</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models use diverse or similar reasoning methods to solve reasoning problems, including details of the reasoning methods, whether multiple or single methods are used, the tasks or benchmarks, performance results, and any explicit comparisons or ablations between diverse and similar reasoning approaches.</div>
                <p><strong>Paper ID:</strong> paper-272911308</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2409.17972v2.pdf" target="_blank">BEATS: Optimizing LLM Mathematical Capabilities with BackVerify and Adaptive Disambiguate based Efficient Tree Search</a></p>
                <p><strong>Paper Abstract:</strong> Large Language Models (LLMs) have exhibited exceptional performance across a broad range of tasks and domains. However, they still encounter difficulties in solving mathematical problems due to the rigorous and logical nature of mathematics. Previous studies have employed techniques such as supervised fine-tuning (SFT), prompt engineering, and search-based methods to improve the mathematical problem-solving abilities of LLMs. Despite these efforts, their performance remains suboptimal and demands substantial computational resources. To address this issue, we propose a novel approach, BEATS, to enhance mathematical problem-solving abilities. Our method leverages newly designed prompts that guide the model to iteratively rewrite, advance by one step, and generate answers based on previous steps. Additionally, we introduce a new back-verification technique that uses LLMs to validate the correctness of the generated answers. Furthermore, we employ a pruning tree search to optimize search time while achieving strong performance. Notably, our method improves Qwen2-7b-Instruct's score from 36.94 to 61.52, outperforming GPT4's 42.5 on the MATH benchmark.</p>
                <p><strong>Cost:</strong> 0.014</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e8262.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e8262.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models use diverse or similar reasoning methods to solve reasoning problems, including details of the reasoning methods, whether multiple or single methods are used, the tasks or benchmarks, performance results, and any explicit comparisons or ablations between diverse and similar reasoning approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>BEATS</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>BEATS: Backverify and Adaptive Disambiguate based Efficient Tree Search</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A search-and-prompting method introduced in this paper that combines disambiguation, one-step incremental reasoning actions, a pruning tree search, and a back-verification stage to improve LLM mathematical problem solving at inference time.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>BEATS (method applied to multiple base LLMs)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>An inference-time algorithm (not a base LLM) that issues structured prompts to a base LLM to perform three action types (Disambiguation, One-Step-Forward, Give Final Answer), constructs a pruned tree of reasoning states, and then validates candidate leaf answers using back-verification by the same or another LLM.</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_methods</strong></td>
                            <td>['Disambiguation (question rewriting)', 'One-step incremental reasoning (step-by-step decomposition)', "Give final answer (terminal action that emits 'The answer is ...')", 'Pruned tree search (heuristic-constrained tree expansion, DFS for leaf collection)', 'Back-verification (resubmitting Q + candidate A to LLM to judge correctness)', 'Majority voting (used as baseline/comparison)', 'Comparison to BFS/DFS/MCTS search strategies (discussed)']</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_methods_description</strong></td>
                            <td>BEATS issues three action-specific prompts: Disambiguation rewrites ambiguous questions (allowed only as root successor), One-Step-Forward asks the model to advance the solution by a single logical step, and Give Final Answer asks for a conclusive answer. Nodes are expanded under pruning heuristics (e.g., limit number of One-Step actions τ, allow only one Disambiguation at root) to keep search tractable. After tree construction, leaf nodes ending with 'The answer is' are selected and validated by back-verification, where the candidate answer is concatenated with the original question and the LLM is asked to judge correctness; final decision uses majority over back-verification judgements.</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_diversity</strong></td>
                            <td>diverse</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_diversity_experimental_setup</strong></td>
                            <td>Ablation experiments remove Disambiguation and Back Verification modules separately to measure impact; comparisons are made conceptually and empirically between back-verification and majority voting, and between the paper's pruning-tree search and MCTS/BFS-style approaches described in prior work.</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>Mathematical reasoning benchmarks including MATH (competition-style math), GSM8K (grade-school math), SVAMP (math word problems), SimulEq (equation solving), NumGLUE (8 numerical reasoning tasks).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>Applying BEATS (with pruning tree + back-verification + prompts) produced large gains vs. baselines: e.g., on MATH BEATS raised Qwen2-7B-Instruct from 36.94 (baseline) to 61.52; on GSM8K BEATS with Qwen2 reached 83.02. For LLaMA3-8B-Instruct, BEATS w.o. BackVerify reached 35.17% (MATH) and 83.62% (GSM8K), and with BackVerify reached 42.93% (MATH) and 88.48% (GSM8K). BEATS also yields strong results on SVAMP, SimulEq and NumGLUE (examples: LLaMA+BEATS: SVAMP 88.7, SimulEq 78.4, NumGLUE 73.61 as reported).</td>
                        </tr>
                        <tr>
                            <td><strong>qualitative_findings</strong></td>
                            <td>Disambiguation reduces errors arising from ambiguous problem statements; back-verification discards incorrect candidate answers that majority voting would retain when LLMs reproduce same mistakes across branches; pruning-tree search enables controllable inference time while searching all leaves (contrast to MCTS which may not visit all leaves and may miss correct answers); LLaMA3 tends to generate many more tokens (longer reasoning traces) than Qwen2/Yi-1.5, reflecting different reasoning behavior and compute tradeoffs.</td>
                        </tr>
                        <tr>
                            <td><strong>explicit_comparison</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>key_claims_or_conclusions</strong></td>
                            <td>Diverse, structured reasoning actions (disambiguation + one-step decomposition + final-answer emission) combined with a pruned tree search and back-verification substantially improve mathematical problem solving at inference time; back-verification is more reliable than naive majority voting because LLMs can repeat the same mistake across multiple paths; pruning-tree search provides a controllable and effective alternative to MCTS.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'BEATS: Optimizing LLM Mathematical Capabilities with BackVerify and Adaptive Disambiguate based Efficient Tree Search', 'publication_date_yy_mm': '2024-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8262.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e8262.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models use diverse or similar reasoning methods to solve reasoning problems, including details of the reasoning methods, whether multiple or single methods are used, the tasks or benchmarks, performance results, and any explicit comparisons or ablations between diverse and similar reasoning approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Qwen2-7B-Instruct</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Qwen2 7B Instruct</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A 7B-parameter instruction-tuned Qwen family LLM used as a base model in experiments, evaluated under BEATS and baseline prompting/search methods.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Qwen2-7B-Instruct</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Instruction-tuned open foundation model in the Qwen series, size ~7B parameters as used in this paper's experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_methods</strong></td>
                            <td>['Chain-of-Thought style prompting (baseline references)', 'Hard voting / majority voting baseline (sampling multiple outputs)', 'Used within BEATS with Disambiguation / One-step / Final-answer prompts', 'Back-verification used as discriminator during verification stage']</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_methods_description</strong></td>
                            <td>As a base LLM Qwen2 was prompted using BEATS' three action prompts to generate stepwise reasoning and final answers; candidate answers were then back-verified by the LLM (Qwen2 used both as generator and discriminator in reported experiments). Baseline comparisons include zero-shot CoT and hard-voting where multiple sampled reasoning traces are aggregated by majority vote.</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_diversity</strong></td>
                            <td>both (when used with BEATS it engages multiple action types; as a baseline it can be used with single-style CoT or with voting-over-similar-samples)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_diversity_experimental_setup</strong></td>
                            <td>Paper reports baseline hard-voting/zero-shot CoT and BEATS experiments with and without back-verification and disambiguation; specifically reports Qwen2 baseline MATH score 36.94, BEATS (full) MATH 61.52; also compares BEATS w.o. BackVerify (57.28 on MATH as reported in tables).</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>MATH, GSM8K, SVAMP, SimulEq, NumGLUE</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>Baseline (hard-voting/zero-shot) MATH ~36.94; BEATS (full pipeline with back-verification) MATH 61.52 for Qwen2-7B-Instruct; GSM8K with BEATS: 83.02 (reported). BEATS w.o. BackVerify reported near 57.28 on MATH (table entries).</td>
                        </tr>
                        <tr>
                            <td><strong>qualitative_findings</strong></td>
                            <td>When used within BEATS, Qwen2 shows large absolute gains, indicating that applying diverse reasoning actions plus back-verification is effective across base models; back-verification reduces cases where the model repeats identical reasoning errors across different sampled paths.</td>
                        </tr>
                        <tr>
                            <td><strong>explicit_comparison</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>key_claims_or_conclusions</strong></td>
                            <td>BEATS yields especially large improvements for Qwen2-7B-Instruct (from ~36.94 to 61.52 on MATH), demonstrating that combining diverse reasoning actions and back-verification at inference can outperform both zero-shot baselines and some larger or closed-source models (paper claims outperforming GPT-4 on MATH in this reported number).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'BEATS: Optimizing LLM Mathematical Capabilities with BackVerify and Adaptive Disambiguate based Efficient Tree Search', 'publication_date_yy_mm': '2024-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8262.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e8262.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models use diverse or similar reasoning methods to solve reasoning problems, including details of the reasoning methods, whether multiple or single methods are used, the tasks or benchmarks, performance results, and any explicit comparisons or ablations between diverse and similar reasoning approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LLaMA3-8B-Instruct</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>LLaMA3 8B Instruct</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An 8B-parameter instruct-tuned variant of LLaMA3 used as a base model for BEATS experiments; exhibited longer reasoning traces (more tokens) in the paper's analysis.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>LLaMA3-8B-Instruct</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>An 8B-parameter instruction-tuned LLaMA3 family model used to evaluate BEATS; reported to produce more tokens (longer chains) than other evaluated base models.</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_methods</strong></td>
                            <td>['Chain-of-Thought prompting (baseline)', 'Used within BEATS: Disambiguation, One-step, Final Answer prompts', 'Pruned tree search + back-verification']</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_methods_description</strong></td>
                            <td>Applied BEATS prompts and search: disambiguation at root, iterative one-step reasoning expansions (capped per node), and terminal 'Give Final Answer' actions; final candidate answers validated via back-verification. Baselines include zero-shot CoT and search-based methods like ToT and ReST-MCTS*.</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_diversity</strong></td>
                            <td>both (as baseline LLaMA3 may produce long single-step CoT traces; with BEATS it participates in diverse action-based tree search)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_diversity_experimental_setup</strong></td>
                            <td>Ablation experiments removed Disambiguation and Back Verification to measure impact on LLaMA3 results; comparisons made to other search strategies (MCTS, BFS) and voting verification.</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>MATH, GSM8K, SVAMP, SimulEq, NumGLUE</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>LLaMA3-8B-Instruct + BEATS (w.o. BackVerify) achieved 35.17% on MATH and 83.62% on GSM8K; with BackVerify these increased to 42.93% (MATH) and 88.48% (GSM8K). On SVAMP, SimulEq and NumGLUE LLaMA3+BEATS also showed substantial improvements (examples reported: SVAMP 88.7, SimulEq 78.4, NumGLUE 73.61).</td>
                        </tr>
                        <tr>
                            <td><strong>qualitative_findings</strong></td>
                            <td>LLaMA3 tends to generate significantly more tokens / longer reasoning traces, which increases compute but may reflect different reasoning behavior; disambiguation module notably improves LLaMA3 performance (ablation shows meaningful drops when removed).</td>
                        </tr>
                        <tr>
                            <td><strong>explicit_comparison</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>key_claims_or_conclusions</strong></td>
                            <td>BEATS improves LLaMA3 performance significantly; disambiguation and back-verification modules are critical (their removal causes considerable accuracy drops), and pruning-tree search offers controllable inference compared to MCTS while preserving thorough leaf exploration.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'BEATS: Optimizing LLM Mathematical Capabilities with BackVerify and Adaptive Disambiguate based Efficient Tree Search', 'publication_date_yy_mm': '2024-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8262.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e8262.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models use diverse or similar reasoning methods to solve reasoning problems, including details of the reasoning methods, whether multiple or single methods are used, the tasks or benchmarks, performance results, and any explicit comparisons or ablations between diverse and similar reasoning approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Yi-1.5-6B-Chat</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Yi-1.5 6B Chat</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A ~6B-parameter conversational model (Yi family) evaluated with BEATS in the paper; used as another base model to test generality of the method.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Yi-1.5-6B-Chat</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>An instruction/chat-capable model of the Yi family (~6B parameters) used as a base LLM in experiments applying BEATS.</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_methods</strong></td>
                            <td>['Chain-of-Thought baseline prompting', 'Used within BEATS action prompts and pruned tree search', 'Back-verification for candidate validation']</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_methods_description</strong></td>
                            <td>Yi-1.5 was prompted in the same BEATS pipeline: Disambiguation at root (if needed), iterative one-step reasoning with capped expansions, final answer emission, and back-verification of candidate answers. Compared to baseline zero-shot/CoT results, BEATS yields large gains on several benchmarks.</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_diversity</strong></td>
                            <td>both (capable of single long CoT or multi-action tree search when used with BEATS)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_diversity_experimental_setup</strong></td>
                            <td>Paper reports BEATS results for Yi-1.5 with and without back-verification and includes ablation for disambiguation; Yi-1.5 results validate that BEATS generalizes across different model families and sizes.</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_benchmark</strong></td>
                            <td>MATH, GSM8K, SVAMP, SimulEq, NumGLUE</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>Reported in tables as improved performance with BEATS relative to baselines (paper reports BEATS (w.o. BackVerify) and BEATS full numbers for Yi-1.5 in Table 1 and 2; example table entries show BEATS variants for Yi-1.5 with substantial gains over zero-shot CoT baselines).</td>
                        </tr>
                        <tr>
                            <td><strong>qualitative_findings</strong></td>
                            <td>BEATS improvements hold across multiple base models including smaller (6B) models, showing that diverse reasoning actions plus back-verification are effective beyond a single backbone; ablations again show removal of disambiguation/back-verification hurts performance.</td>
                        </tr>
                        <tr>
                            <td><strong>explicit_comparison</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>key_claims_or_conclusions</strong></td>
                            <td>BEATS generalizes across base models including Yi-1.5-6B-Chat; diverse reasoning actions (disambiguation + one-step decomposition) and back-verification consistently increase accuracy compared to similar single-method baselines such as plain CoT or majority voting over sampled outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'BEATS: Optimizing LLM Mathematical Capabilities with BackVerify and Adaptive Disambiguate based Efficient Tree Search', 'publication_date_yy_mm': '2024-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Tree of Thoughts: Deliberate problem solving with large language models <em>(Rating: 2)</em></li>
                <li>ReST-MCTS*: LLM selftraining via process reward guided tree search <em>(Rating: 2)</em></li>
                <li>LiteSearch: Efficacious tree search for LLM <em>(Rating: 2)</em></li>
                <li>Self-Consistency improves LLM reasoning by aggregating diverse chains-of-thought <em>(Rating: 2)</em></li>
                <li>Chain-of-Thought prompting elicits reasoning in large language models <em>(Rating: 2)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-8262",
    "paper_id": "paper-272911308",
    "extraction_schema_id": "extraction-schema-152",
    "extracted_data": [
        {
            "name_short": "BEATS",
            "name_full": "BEATS: Backverify and Adaptive Disambiguate based Efficient Tree Search",
            "brief_description": "A search-and-prompting method introduced in this paper that combines disambiguation, one-step incremental reasoning actions, a pruning tree search, and a back-verification stage to improve LLM mathematical problem solving at inference time.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "BEATS (method applied to multiple base LLMs)",
            "model_description": "An inference-time algorithm (not a base LLM) that issues structured prompts to a base LLM to perform three action types (Disambiguation, One-Step-Forward, Give Final Answer), constructs a pruned tree of reasoning states, and then validates candidate leaf answers using back-verification by the same or another LLM.",
            "reasoning_methods": [
                "Disambiguation (question rewriting)",
                "One-step incremental reasoning (step-by-step decomposition)",
                "Give final answer (terminal action that emits 'The answer is ...')",
                "Pruned tree search (heuristic-constrained tree expansion, DFS for leaf collection)",
                "Back-verification (resubmitting Q + candidate A to LLM to judge correctness)",
                "Majority voting (used as baseline/comparison)",
                "Comparison to BFS/DFS/MCTS search strategies (discussed)"
            ],
            "reasoning_methods_description": "BEATS issues three action-specific prompts: Disambiguation rewrites ambiguous questions (allowed only as root successor), One-Step-Forward asks the model to advance the solution by a single logical step, and Give Final Answer asks for a conclusive answer. Nodes are expanded under pruning heuristics (e.g., limit number of One-Step actions τ, allow only one Disambiguation at root) to keep search tractable. After tree construction, leaf nodes ending with 'The answer is' are selected and validated by back-verification, where the candidate answer is concatenated with the original question and the LLM is asked to judge correctness; final decision uses majority over back-verification judgements.",
            "reasoning_diversity": "diverse",
            "reasoning_diversity_experimental_setup": "Ablation experiments remove Disambiguation and Back Verification modules separately to measure impact; comparisons are made conceptually and empirically between back-verification and majority voting, and between the paper's pruning-tree search and MCTS/BFS-style approaches described in prior work.",
            "task_or_benchmark": "Mathematical reasoning benchmarks including MATH (competition-style math), GSM8K (grade-school math), SVAMP (math word problems), SimulEq (equation solving), NumGLUE (8 numerical reasoning tasks).",
            "performance_results": "Applying BEATS (with pruning tree + back-verification + prompts) produced large gains vs. baselines: e.g., on MATH BEATS raised Qwen2-7B-Instruct from 36.94 (baseline) to 61.52; on GSM8K BEATS with Qwen2 reached 83.02. For LLaMA3-8B-Instruct, BEATS w.o. BackVerify reached 35.17% (MATH) and 83.62% (GSM8K), and with BackVerify reached 42.93% (MATH) and 88.48% (GSM8K). BEATS also yields strong results on SVAMP, SimulEq and NumGLUE (examples: LLaMA+BEATS: SVAMP 88.7, SimulEq 78.4, NumGLUE 73.61 as reported).",
            "qualitative_findings": "Disambiguation reduces errors arising from ambiguous problem statements; back-verification discards incorrect candidate answers that majority voting would retain when LLMs reproduce same mistakes across branches; pruning-tree search enables controllable inference time while searching all leaves (contrast to MCTS which may not visit all leaves and may miss correct answers); LLaMA3 tends to generate many more tokens (longer reasoning traces) than Qwen2/Yi-1.5, reflecting different reasoning behavior and compute tradeoffs.",
            "explicit_comparison": true,
            "key_claims_or_conclusions": "Diverse, structured reasoning actions (disambiguation + one-step decomposition + final-answer emission) combined with a pruned tree search and back-verification substantially improve mathematical problem solving at inference time; back-verification is more reliable than naive majority voting because LLMs can repeat the same mistake across multiple paths; pruning-tree search provides a controllable and effective alternative to MCTS.",
            "uuid": "e8262.0",
            "source_info": {
                "paper_title": "BEATS: Optimizing LLM Mathematical Capabilities with BackVerify and Adaptive Disambiguate based Efficient Tree Search",
                "publication_date_yy_mm": "2024-09"
            }
        },
        {
            "name_short": "Qwen2-7B-Instruct",
            "name_full": "Qwen2 7B Instruct",
            "brief_description": "A 7B-parameter instruction-tuned Qwen family LLM used as a base model in experiments, evaluated under BEATS and baseline prompting/search methods.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "Qwen2-7B-Instruct",
            "model_description": "Instruction-tuned open foundation model in the Qwen series, size ~7B parameters as used in this paper's experiments.",
            "reasoning_methods": [
                "Chain-of-Thought style prompting (baseline references)",
                "Hard voting / majority voting baseline (sampling multiple outputs)",
                "Used within BEATS with Disambiguation / One-step / Final-answer prompts",
                "Back-verification used as discriminator during verification stage"
            ],
            "reasoning_methods_description": "As a base LLM Qwen2 was prompted using BEATS' three action prompts to generate stepwise reasoning and final answers; candidate answers were then back-verified by the LLM (Qwen2 used both as generator and discriminator in reported experiments). Baseline comparisons include zero-shot CoT and hard-voting where multiple sampled reasoning traces are aggregated by majority vote.",
            "reasoning_diversity": "both (when used with BEATS it engages multiple action types; as a baseline it can be used with single-style CoT or with voting-over-similar-samples)",
            "reasoning_diversity_experimental_setup": "Paper reports baseline hard-voting/zero-shot CoT and BEATS experiments with and without back-verification and disambiguation; specifically reports Qwen2 baseline MATH score 36.94, BEATS (full) MATH 61.52; also compares BEATS w.o. BackVerify (57.28 on MATH as reported in tables).",
            "task_or_benchmark": "MATH, GSM8K, SVAMP, SimulEq, NumGLUE",
            "performance_results": "Baseline (hard-voting/zero-shot) MATH ~36.94; BEATS (full pipeline with back-verification) MATH 61.52 for Qwen2-7B-Instruct; GSM8K with BEATS: 83.02 (reported). BEATS w.o. BackVerify reported near 57.28 on MATH (table entries).",
            "qualitative_findings": "When used within BEATS, Qwen2 shows large absolute gains, indicating that applying diverse reasoning actions plus back-verification is effective across base models; back-verification reduces cases where the model repeats identical reasoning errors across different sampled paths.",
            "explicit_comparison": true,
            "key_claims_or_conclusions": "BEATS yields especially large improvements for Qwen2-7B-Instruct (from ~36.94 to 61.52 on MATH), demonstrating that combining diverse reasoning actions and back-verification at inference can outperform both zero-shot baselines and some larger or closed-source models (paper claims outperforming GPT-4 on MATH in this reported number).",
            "uuid": "e8262.1",
            "source_info": {
                "paper_title": "BEATS: Optimizing LLM Mathematical Capabilities with BackVerify and Adaptive Disambiguate based Efficient Tree Search",
                "publication_date_yy_mm": "2024-09"
            }
        },
        {
            "name_short": "LLaMA3-8B-Instruct",
            "name_full": "LLaMA3 8B Instruct",
            "brief_description": "An 8B-parameter instruct-tuned variant of LLaMA3 used as a base model for BEATS experiments; exhibited longer reasoning traces (more tokens) in the paper's analysis.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "LLaMA3-8B-Instruct",
            "model_description": "An 8B-parameter instruction-tuned LLaMA3 family model used to evaluate BEATS; reported to produce more tokens (longer chains) than other evaluated base models.",
            "reasoning_methods": [
                "Chain-of-Thought prompting (baseline)",
                "Used within BEATS: Disambiguation, One-step, Final Answer prompts",
                "Pruned tree search + back-verification"
            ],
            "reasoning_methods_description": "Applied BEATS prompts and search: disambiguation at root, iterative one-step reasoning expansions (capped per node), and terminal 'Give Final Answer' actions; final candidate answers validated via back-verification. Baselines include zero-shot CoT and search-based methods like ToT and ReST-MCTS*.",
            "reasoning_diversity": "both (as baseline LLaMA3 may produce long single-step CoT traces; with BEATS it participates in diverse action-based tree search)",
            "reasoning_diversity_experimental_setup": "Ablation experiments removed Disambiguation and Back Verification to measure impact on LLaMA3 results; comparisons made to other search strategies (MCTS, BFS) and voting verification.",
            "task_or_benchmark": "MATH, GSM8K, SVAMP, SimulEq, NumGLUE",
            "performance_results": "LLaMA3-8B-Instruct + BEATS (w.o. BackVerify) achieved 35.17% on MATH and 83.62% on GSM8K; with BackVerify these increased to 42.93% (MATH) and 88.48% (GSM8K). On SVAMP, SimulEq and NumGLUE LLaMA3+BEATS also showed substantial improvements (examples reported: SVAMP 88.7, SimulEq 78.4, NumGLUE 73.61).",
            "qualitative_findings": "LLaMA3 tends to generate significantly more tokens / longer reasoning traces, which increases compute but may reflect different reasoning behavior; disambiguation module notably improves LLaMA3 performance (ablation shows meaningful drops when removed).",
            "explicit_comparison": true,
            "key_claims_or_conclusions": "BEATS improves LLaMA3 performance significantly; disambiguation and back-verification modules are critical (their removal causes considerable accuracy drops), and pruning-tree search offers controllable inference compared to MCTS while preserving thorough leaf exploration.",
            "uuid": "e8262.2",
            "source_info": {
                "paper_title": "BEATS: Optimizing LLM Mathematical Capabilities with BackVerify and Adaptive Disambiguate based Efficient Tree Search",
                "publication_date_yy_mm": "2024-09"
            }
        },
        {
            "name_short": "Yi-1.5-6B-Chat",
            "name_full": "Yi-1.5 6B Chat",
            "brief_description": "A ~6B-parameter conversational model (Yi family) evaluated with BEATS in the paper; used as another base model to test generality of the method.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "Yi-1.5-6B-Chat",
            "model_description": "An instruction/chat-capable model of the Yi family (~6B parameters) used as a base LLM in experiments applying BEATS.",
            "reasoning_methods": [
                "Chain-of-Thought baseline prompting",
                "Used within BEATS action prompts and pruned tree search",
                "Back-verification for candidate validation"
            ],
            "reasoning_methods_description": "Yi-1.5 was prompted in the same BEATS pipeline: Disambiguation at root (if needed), iterative one-step reasoning with capped expansions, final answer emission, and back-verification of candidate answers. Compared to baseline zero-shot/CoT results, BEATS yields large gains on several benchmarks.",
            "reasoning_diversity": "both (capable of single long CoT or multi-action tree search when used with BEATS)",
            "reasoning_diversity_experimental_setup": "Paper reports BEATS results for Yi-1.5 with and without back-verification and includes ablation for disambiguation; Yi-1.5 results validate that BEATS generalizes across different model families and sizes.",
            "task_or_benchmark": "MATH, GSM8K, SVAMP, SimulEq, NumGLUE",
            "performance_results": "Reported in tables as improved performance with BEATS relative to baselines (paper reports BEATS (w.o. BackVerify) and BEATS full numbers for Yi-1.5 in Table 1 and 2; example table entries show BEATS variants for Yi-1.5 with substantial gains over zero-shot CoT baselines).",
            "qualitative_findings": "BEATS improvements hold across multiple base models including smaller (6B) models, showing that diverse reasoning actions plus back-verification are effective beyond a single backbone; ablations again show removal of disambiguation/back-verification hurts performance.",
            "explicit_comparison": true,
            "key_claims_or_conclusions": "BEATS generalizes across base models including Yi-1.5-6B-Chat; diverse reasoning actions (disambiguation + one-step decomposition) and back-verification consistently increase accuracy compared to similar single-method baselines such as plain CoT or majority voting over sampled outputs.",
            "uuid": "e8262.3",
            "source_info": {
                "paper_title": "BEATS: Optimizing LLM Mathematical Capabilities with BackVerify and Adaptive Disambiguate based Efficient Tree Search",
                "publication_date_yy_mm": "2024-09"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Tree of Thoughts: Deliberate problem solving with large language models",
            "rating": 2,
            "sanitized_title": "tree_of_thoughts_deliberate_problem_solving_with_large_language_models"
        },
        {
            "paper_title": "ReST-MCTS*: LLM selftraining via process reward guided tree search",
            "rating": 2,
            "sanitized_title": "restmcts_llm_selftraining_via_process_reward_guided_tree_search"
        },
        {
            "paper_title": "LiteSearch: Efficacious tree search for LLM",
            "rating": 2,
            "sanitized_title": "litesearch_efficacious_tree_search_for_llm"
        },
        {
            "paper_title": "Self-Consistency improves LLM reasoning by aggregating diverse chains-of-thought",
            "rating": 2,
            "sanitized_title": "selfconsistency_improves_llm_reasoning_by_aggregating_diverse_chainsofthought"
        },
        {
            "paper_title": "Chain-of-Thought prompting elicits reasoning in large language models",
            "rating": 2,
            "sanitized_title": "chainofthought_prompting_elicits_reasoning_in_large_language_models"
        }
    ],
    "cost": 0.01382925,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>BEATS: OPTIMIZING LLM MATHEMATICAL CAPA-BILITIES WITH BACKVERIFY AND ADAPTIVE DISAM-BIGUATE BASED EFFICIENT TREE SEARCH
29 Sep 2024</p>
<p>Linzhuang Sun sunlinzhuang21@mails.ucas.ac.cn 
University of Chinese Academy of Sciences ♡ Peking University ♣ Baichuan Inc. ♢ Shanghai AI Laboratory ♠</p>
<p>Hao Liang hao.liang@stu.pku.edu.cn 
University of Chinese Academy of Sciences ♡ Peking University ♣ Baichuan Inc. ♢ Shanghai AI Laboratory ♠</p>
<p>Jingxuan Wei♡ 
University of Chinese Academy of Sciences ♡ Peking University ♣ Baichuan Inc. ♢ Shanghai AI Laboratory ♠</p>
<p>Conghui He♠Bihui Yu♡ 
University of Chinese Academy of Sciences ♡ Peking University ♣ Baichuan Inc. ♢ Shanghai AI Laboratory ♠</p>
<p>Zenan Zhou 
University of Chinese Academy of Sciences ♡ Peking University ♣ Baichuan Inc. ♢ Shanghai AI Laboratory ♠</p>
<p>Wentao Zhang wentao.zhang@pku.edu.cn 
University of Chinese Academy of Sciences ♡ Peking University ♣ Baichuan Inc. ♢ Shanghai AI Laboratory ♠</p>
<p>BEATS: OPTIMIZING LLM MATHEMATICAL CAPA-BILITIES WITH BACKVERIFY AND ADAPTIVE DISAM-BIGUATE BASED EFFICIENT TREE SEARCH
29 Sep 2024A741A0568CAE64D340D8C98F7110C6E0arXiv:2409.17972v2[cs.CL]
Large Language Models (LLMs) have exhibited exceptional performance across a broad range of tasks and domains.However, they still encounter difficulties in solving mathematical problems due to the rigorous and logical nature of mathematics.Previous studies have employed techniques such as supervised fine-tuning (SFT), prompt engineering, and search-based methods to improve the mathematical problem-solving abilities of LLMs.Despite these efforts, their performance remains suboptimal and demands substantial computational resources.To address this issue, we propose a novel approach, BEATS, to enhance mathematical problem-solving abilities.Our method leverages newly designed prompts that guide the model to iteratively rewrite, advance by one step, and generate answers based on previous steps.Additionally, we employ a pruning tree search to optimize search time while achieving strong performance.Furthermore, we introduce a new back-verification technique that uses LLMs to validate the correctness of the generated answers.Notably, our method improves Qwen2-7b-Instruct's score from 36.94 to 61.52 (outperforming GPT-4's 42.5) on the MATH benchmark.The code is made available at https://github.com/Aurora-slz/BEATS</p>
<p>INTRODUCTION</p>
<p>LLMs have demonstrated exceptional performance across diverse tasks and domains (Touvron et al., 2023;meta llama, 2024;Bai et al., 2023a), excelling in zero-shot and few-shot scenarios.Recent advancements in scaling laws and fine-tuning have further enhanced their capabilities, enabling their application in complex real-world tasks such as natural language understanding and multimodal processing.</p>
<p>Among the various capabilities of LLMs, mathematical proficiency is crucial, as it reflects not only logical reasoning but also the model's capacity for structured problem-solving.Mastery of mathematical tasks necessitates precision, adherence to complex rules, and the application of algorithms, all of which are essential indicators of an LLM's overall reasoning and cognitive abilities.There are generally two approaches to enhance mathematical capability.The first set of methods trains LLMs to improve their mathematical skills.Models such as Mammoth (Yue et al., 2023;2024) and Internlm-math (Ying et al., 2024), along with DeepSeek (Shao et al., 2024), utilize vast amounts of data to develop robust mathematical models.The second set of methods employs tree search and self-correction techniques to enhance mathematical abilities.Techniques like ToT (Yao et al., 2024), RAP (Hao et al., 2023), ReST-MCTS* (Zhang et al., 2024), and LiteSearch (Wang et al., 2024) leverage tree structures and search methods such as BFS, DFS and Monte Carlo Tree Search (MCTS).However, both approaches still encounter suboptimal results.They face the following challenges: How many total meters does James run in a week if he runs 3 sprints, each of 60 meters, 3 times a week?</p>
<p>Figure 1: We provide a straightforward example to illustrate our BEATS method.First, we construct a tree search using three distinct actions.Next, we apply back verification to achieve the correct answer.</p>
<p>Suboptimal Prompts Self-improving models (Yao et al., 2024;Wang et al., 2024) typically address problems by either decomposing them into subproblems or rewriting them, followed by solving through methods CoT or Process of Thought (PoT).However, they tend to overlook the issue of ambiguous problem statements.As illustrated by the root node in Figure 1(a), vague expressions can mislead the LLM's understanding.</p>
<p>High Computational Cost Previous researches utilizing pre-training or SFT techniques (Yue et al., 2023;2024;Ying et al., 2024) often suffer from insufficient amounts of data and high computational costs.Search-based approaches enhance mathematical reasoning during the inference stage, thus avoiding the pressure of additional training.However, due to the vast search space, a naive search algorithm can lead to a significant increase in inference time (Yao et al., 2024).Although Wang et al. (2024) employs MCTS to compress the search space, which may result in the absent of correct answers.</p>
<p>Ineffective Verification Method When selecting among multiple candidate answers to a problem, previous works like Yao et al. (2024); Wang et al. (2024) typically employ voting-based verification methods.However, they overlook the fact that LLMs can make the same mistakes across multiple routes.</p>
<p>To address these challenges, we propose BEATS, a novel method for efficient search aimed at enhancing mathematical performance.Our method guides the model to answer problems instructed by clarified question, thereby avoiding ambiguities in problem statements.We meticulously design prompts that instruct the model to disambiguate, solve one step at a time, and directly generate answers based on preceding steps.Additionally, traditional verification methods in tree search, such as majority voting, may be unreliable, as LLMs can perpetuate the same mistakes across multiple branches.To overcome this, we introduce a back-verification technique that re-submits both the answer and the problem to the model for a judgment of correctness, leveraging the model's capabilities while reducing its reasoning difficulty.Furthermore, we employ a pruning tree search to optimize search time while achieving strong performance.It is worth noting that with our meticulously designed pruning tree, we can control search expenses; simultaneously, compared to MCTS, the pruning tree is able to search through every leaf node, ensuring promising performance, while MCTS is more likely to search based on prior experience.</p>
<p>The core contributions of this paper are summarized as follows:</p>
<p>• Meticulously Designed Prompt We developed three newly curated prompts designed to solve mathematical problems step-by-step, provide final answers, and, most importantly, avoiding ambiguities in problem statements.• Pruning Tree Search for Controllable Inference Time We implement a pruning strategy for the tree by imposing constraints on the search steps.Specifically, we restrict the rewriting of the question to once and terminate the tree construction when answer is achieved.</p>
<p>• New Effective Verification Method We propose a new back-verification method that resubmits both the answer and the problem to the model for a judgment of correctness, as shown in Figure 1.This approach enhances the performance of searching in LLMs compared to majority voting.• Strong Performance We achieved competitive results across several datasets, including MATH, GSM8K, SVAMP, SimulEq, and NumGLUE.Notably, the BEATS method, based on Qwen2-7B-Instruct, improved its performance on the MATH dataset from 36.94 to 61.52, significantly surpassing GPT-4's score of 42.5.</p>
<p>RELATED WORK</p>
<p>MATH LARGE LANGUAGE MODELS</p>
<p>LLMs have demonstrated significant capabilities across various tasks, including mathematical problem-solving, which is a critical skill for these models.However, learning to solve mathematical problems poses challenges for LLMs, often requiring large amounts of training data and substantial computational resources.In this paper, we review several state-of-the-art (SOTA) models specifically designed to tackle mathematical problems.</p>
<p>Llemma (Azerbayev et al., 2021) integrates both code and mathematical data to train models, resulting in strong performance.InternLM2 (Ying et al., 2024) utilizes a vast amount of math-related pre-training corpus to achieve high performance.Mammoth (Yue et al., 2023) collected Chain-of-Thought (CoT) data for fine-tuning language models and achieved impressive results.Mammoth2 (Yue et al., 2024) builds on Mammoth by collecting WebInstruct, one of the largest open-source math datasets, and uses it to fine-tune LLMs, resulting in SOTA performance.DeepSeek (Shao et al., 2024) employs preference-based mathematical data to perform an additional stage of reinforcement learning, achieving SOTA results.</p>
<p>In addition to models explicitly trained for mathematics, a few foundation models exhibit exceptional mathematical proficiency.Llama3 (Touvron et al., 2023) has shown remarkable performance in solving mathematical problems.Qwen2 (Bai et al., 2023b), another series of outstanding models, is one of the SOTA open-source models.Furthermore, closed-source models like Claude and GPT also demonstrate strong capabilities in mathematical problem solving.</p>
<p>PROMPT ENGINEERING FOR LARGE LANGUAGE MODELS</p>
<p>The effectiveness of large language models in various applications largely depends on the quality of the prompts used.There are already many designed prompts that can significantly enhance the performance of LLMs (Kojima et al., 2022;Wei et al., 2022;Yao et al., 2024;Besta et al., 2024;Yang et al., 2024;Wang et al., 2023a).However, these methods that rely on manual prompt engineering are far less scalable.In the field of mathematical logical reasoning for LLMs, the Chain of Thought and its derived strategies are widely popular due to their effectiveness.Zero-shot CoT (Kojima et al., 2022) is adding a simple sentence like "Let's think step by step" at the end of questions to assist LLMs in generating reasoning steps.Instead of Zero-shot CoT, Manual-Cot (Wei et al., 2022) provides reasoning steps as few shots.Self-Consistency further improves language models' reasoning performance by generating a diverse set of reasoning paths and choosing the most consistent answer in the final answer set.Tree of Thought (Yao et al., 2024) and GOT (Besta et al., 2024) extend the reasoning pathway from linear to non-linear data structures by leveraging multiple LLM queries to elicit different plausible reasoning paths (Yang et al., 2024).Buffer of Thought (BOT) (Yang et al., 2024) designs a series of thought-template for tasks, and for each problem, it retrieve a relevant thought-template to prompt LLMs.PS prompting (Wang et al., 2023a) improves COT by encouraging LLMs to devise a plan before attempting to solve a problem.In this paper, we employ meticulously designed prompts to enhance the model's mathematical capabilities.</p>
<p>REASONING IN LARGE LANGUAGE MODELS</p>
<p>The recently introduced GPT-o1 model has demonstrated outstanding performance in solving mathematical problems, primarily due to its integration of a novel reasoning module.Our proposed tree search methodology can be categorized as a mathematical reasoning technique.In this paper, we STEP: We have computed the sum of probabilities for  and  to be ⁄ 9 12. Next, to find the probability of the spinner landing on , we need to subtract this sum from the total probability space, which is 1
(or ⁄ 12 12). [𝑃(𝐶) = 1 -(𝑃(𝐴) + 𝑃(𝐵)) ] [𝑃(𝐶) = ⁄ 12 12 -⁄ 9 12] [𝑃(𝐶) = ⁄ 3 12]
The probability of the spinner landing on  is ⁄ 3 12.However, this fraction can be simplified.\n\nTo simplify, we divide both the numerator and the denominator by their greatest common divisor, which is 3:
[ 𝑃(𝐶) = ⁄ (3 ÷ 3) (12 ÷ 3) = ⁄ 1 4] The answer is ⁄ 1 4.
CLARIFIED QUESTION: In a board game spinner divided into three sections labeled ,  and , the probability of the spinner landing on section  is given as ⁄ 1 3, and the probability of landing on section  is ⁄ 5 12. …</p>
<p>METHOD</p>
<p>PROMPT DESIGN</p>
<p>We design three actions for the tree search, illustrated in Figure 7.The three options are: One Step Forward, Giving Final Answer, and Disambiguation.</p>
<p>One</p>
<p>Step Forward The prompt is summarized in Figure 7(a).It encourages the model to progress through the search tree by evaluating the next logical step based on the current context and information.Given that mathematical problems often require multi-step reasoning, splitting a problem into individual steps reduces the complexity of the LLM's response.By addressing each step sequentially, we enhance the likelihood of arriving at the correct answer, as the model can focus on one aspect of the problem at a time, thereby improving accuracy and clarity in reasoning.</p>
<p>Giving the Final Answer</p>
<p>The prompt is summarized in Figure 7(b), this option directs the model to provide a conclusive answer after considering all relevant information, ensuring clarity and precision in responses.At the appropriate moment, this prompt assists in summarizing the reasoning behind multi-step answers, allowing the model to draw a definitive conclusion.By integrating in-sights from each step, it helps ensure that the final answer accurately reflects the cumulative logic and reasoning process.</p>
<p>Disambiguation The prompt is illustrated in Figure 7(c).This prompt emphasizes reformulating the initial query to enhance clarity and specificity, thereby facilitating a more effective search process.This approach is necessary, as many problem descriptions are frequently ambiguous or unclear, leading to incorrect answers.For example, the query, Josh decides to try flipping a house.He buys a house for $80,000 and then invests $50,000 in repairs.This increased the value of the house by 150%.How much profit did he make?, can introduce ambiguity.By incorporating a step to rewrite questions, we aim to eliminate such ambiguities, ensuring that the model fully comprehends the problem before attempting to solve it.This helps prevent errors that result from misinterpretations of the initial query.</p>
<p>PRUNING TREE SEARCH</p>
<p>Algorithm 1: Pruning Tree Building Algorithm Input: Maximum depth D, question q, tree node u, action list A, one-step action limit τ , LLM generation function G, action counter Count Function BuildTree(u, d):
if d &lt; D then foreach a ∈ A do if (a = "Disambiguation") ∧ d &gt; 1 then continue; if a = "One Step Forward" ∧ Count(u, a) ≥ τ then continue; c ← new Node(); u.value ← G(LLM, u.prompt, a); c.prompt ← u.prompt ⊕ u.value; u.addChild(c);
if "the answer is" ∈ c.value then continue;</p>
<p>BuildTree(c, d + 1);</p>
<p>Output: BuildTree(root, 1)</p>
<p>In the constructed search tree τ , the root node represents the input question q, while the leaf nodes correspond to the deduced answers S. The intermediate nodes represent reasoning states that connect the root to the leaves, with edges between these nodes indicating the actions A taken during the reasoning process.</p>
<p>As shown in Figure 2 and Algorithm 1, a node in the tree is denoted by u d , where d indicates the depth of the node.For a given node u d , its ancestor nodes up to the root are denoted by the sequence u d−1 , ..., u 1 .Each node is associated with a prompt that concatenates the responses from previous rounds.These prompts, containing prior rounds of answers, are fed into the action module to generate further responses leading to the correct answer.
u d .prompt = d−1 i=1 u i .value(1)
Additionally, each node stores a value corresponding to the answer derived from both the preceding rounds' responses and the current action.The mathematical formulation is as follows:
u d .value = G(LLM, u d .prompt, a)(2)
We apply the following heuristic pruning rules during this process:</p>
<p>(1) Disambiguation actions are restricted to the immediate successors of the root node to ensure that clarifications or specifications are handled early.</p>
<p>Preprint</p>
<p>(2) One-step actions are limited to five occurrences within P i , preventing the inference path from becoming excessively long or repetitive.</p>
<p>(3) If a node's content ends with the phrase The answer is, the node is marked as a terminal state and added to the set of candidate answers S.This rule helps efficiently identify conclusive outcomes, ensuring the search process terminates once a definitive answer is found.</p>
<p>BACK-VERIFICATION</p>
<p>After constructing the tree, we apply a depth-first search (DFS) to identify the leaf nodes.From these, we select only those that contain the phrase The answer is as candidate answers for back verification.</p>
<p>For a candidate answer A, we concatenate it with the question Q for back verification using LLMs:
Correct = LLM (Q ⊕ A)(3)
Back verification involves leveraging both the answer and the question to allow the LLM to confirm the correctness of the answer.It is well-established that verifying an answer is typically easier than solving the original problem.Thus, we employ back verification to enhance the accuracy of validation.After the back-verification, we utilize majority voting based on the back-verification results.The impact of back verification is further examined in Section 4.3.problem-solving tasks, designed to evaluate models' performance on grade-school-level math problems.</p>
<p>EXPERIMENT</p>
<p>(2) MATH: The MATH dataset contains 5,000 test samples drawn from competition-style problems, covering a wide range of topics, including algebra, calculus, combinatorics, and geometry.</p>
<p>(3) SVAMP: The SVAMP dataset comprises 1,000 math word problems, each involving at most two mathematical expressions and one unknown variable.(4) SimulEq: The SimulEq dataset includes 514 test samples focused on solving equations, with an emphasis on algebraic manipulation and logical reasoning.(5) NumGLUE: The NumGLUE dataset includes 1,042 test problems encompassing 8 distinct tasks that involve various numerical reasoning challenges, such as arithmetic, quantitative reasoning in commonsense and domain-specific contexts, reading comprehension, and natural language inference.</p>
<p>Models To evaluate the effectiveness of our approach, we conducted experiments using three stateof-the-art (SOTA) models: LLaMA3-8B-Instruct, Yi-1.5-6B-Chat, and Qwen2-7B-Instruct.The primary experimental results are presented in Table 1 and Table 2, while a detailed analysis is provided in Section 4.2.</p>
<p>Baselines We consider three types of baseline models:</p>
<p>(1) Zero-Shot Models, which include Zero-Shot CoT and a hard-voting approach that first generates a set of candidate answers through multiple sampling and then determines the final answer by majority voting.</p>
<p>(2) Supervised Fine-Tuning Models, encompassing WizardMath (Luo et al., 2023), MuggleMath (Li et al., 2024b), MetaMath (Yu et al., 2023), LEMA-LLaMA (An et al., 2023), Code-Llama (Roziere et al., 2023), Platypus (Lee et al., 2023), MAmmoTH (Yue et al., 2023), Galactica (Taylor et al., 2022), Tulu (Wang et al., 2023b), and Guanaco (Dettmers et al., 2023).</p>
<p>(3) Search Algorithm-Based Models, including ToT (Yao et al., 2024), RAP (Hao et al., 2023), ReST-MCTS<em> (Zhang et al., 2024), LiteSearch (Wang et al., 2024), and Llama-2+M</em> (Kang et al., 2024).</p>
<p>Details In our experimental setup, we configured the tree depth to 7, with the disambiguation step allowed only as a direct successor to the root node.Node expansion was performed using the vLLM framework with the following parameters: temperature set to 0.8, top p set to 0.9, and max tokens set to 2048.During the BackVerify stage, Qwen2-7B-Instruct was used as the discriminator.For answer verification, we employed the same framework as MAmmoth.All experiments were conducted on a machine running Ubuntu 22.04, equipped with 8 NVIDIA H100 GPUs, a 120-core CPU, and 960 GB of memory.Since we know that ab = 0, the sum of the reciprocals will be: 1/a + 1/b = 7 / 0 However, dividing by zero is undefined in mathematics.Thus, there is no valid value for the sum of the reciprocals when ab = 0. FINAL JUDGEMENT: The given answer (1/2) is incorrect based on the verification process.</p>
<p>Verify the candidate answer: 1/2 ❎</p>
<p>We are asked to find the value of $\frac{1}{a} + \frac{1}{b}$.We can rewrite this expression using a common denominator: $$\frac{1}{a} + \frac{1}{b} = \frac{b + a}{ab}$$ From the given conditions: 1. $a + b = 7$ 2. $a^3 + b^3 = 42$ We need to find $ab$.We can use the identity for the sum of cubes to help us with this: $$a^3 + b^3 = (a + b)(a^2 -ab + b^2)$$ Given $a^3 + b^3 = 42$ and $a + b = 7$, we can substitute these values into the identity: $$42 = 7(a^2 -ab + b^2)$$ First, let's solve for $a^2 + b^2$: $$6 = a^2 -ab + b^2$$ Now, we need to find $ab$.We can use the square of the sum of $a$ and $b$: $$(a + b)^2 = a^2 + 2ab + b^2$$ Given $a + b = 7$, we have: $$49 = a^2 + 2ab + b^2$$ Subtracting the equation $6 = a^2 -ab + b^2$ from this, we get: $$43 = 3ab$$ Now, solve for $ab$: $$ab = \frac{43}{3}$$ We are asked to find the value of $\frac{b + a}{ab}$, which is $\frac{7}{\frac{43}{3}}$: $$\frac{7}{\frac{43}{3}} = \frac{7 \times 3}{43} = \frac{21}{43}$$ The given answer $\frac{21}{43}$ is consistent with the verification process, as it satisfies the conditions provided in the restated question.FINAL JUDGEMENT: The answer is correct based on the verification.</p>
<p>Question: If $a+b=7$ and $a^3+b^3=42$, what is the value of the sum $\dfrac{1}{a}+\dfrac{1}{b}$?Express your answer as a common fraction.</p>
<p>Verify the candidate answer: $\frac{21}{43}$ ✅</p>
<p>Back Verify Case</p>
<p>Figure 3: From this figure, we observe that models are more likely to deduce errors when using majority voting but can achieve the correct answer through back verification.</p>
<p>MAIN EXPERIMENT</p>
<p>The experimental results presented in Table 1 demonstrate the effectiveness of our proposed method across both the MATH and GSM8K benchmarks.Compared to Zero-Shot category, our model, even without the BackVerify step, significantly outperforms these baselines, achieving 35.17% on MATH and 83.62% on GSM8K using LLaMA-8B as the base model.In the Search category, iterative methods like ReST-MCTS* show improvement over time, with the second iteration yielding 34.28% on MATH.Our model, with the BackVerify mechanism enabled, outperforms these methods, reaching 42.93% on MATH and 88.48% on GSM8K with LLaMA-8B.Furthermore, when utilizing the Qwen-7B model, our approach reaches 61.52% on MATH and 83.02% on GSM8K, demonstrating its robustness across different base models.Notably, even without fine-tuning, our approach outperforms the SFT models across both MATH and GSM8K benchmarks.WizardMath and LEMA-LLaMA, both fine-tuned models based on LLaMA-7B, achieve 10.7% and 9.4% accuracy on MATH, respectively, while our method without BackVerify reaches 35.17%, far surpassing the SFT models.Similarly, on GSM8K, WizardMath achieves 54.9% and LEMA-LLaMA reaches 54.1%, whereas our model without BackVerify attains 83.62%, demonstrating a clear performance advantage.</p>
<p>Additional experiments on the SVAMP, SimulEq and NumGLUE datasets consistently prove the effectiveness of our method.On the SVAMP dataset, our model achieves a performance of 88.7 with LLaMA, compared to the best Zero-Shot result of 85.2 using Qwen and the best SFT result of 73.7 from MAmmoTH-Coder.On the SimulEq dataset, our method achieves a significant improvement with a score of 78.4 using LLaMA, outperforming all SFT models, where the highest score is 47.1 by MAmmoTH-Coder.Similarly, on the NumGLUE dataset, our method achieves 73.61, again outperforming both the Zero-Shot and SFT models.</p>
<p>Overall, we have two following observations: (1) Fine-tuning alone may not be sufficient to achieve optimal performance, and that the search-based methods integrated into our approach offer a more robust mechanism for reasoning across tasks.(2) When solving mathematical problems, the MCTS algorithm is not the only viable approach.A straightforward BFS search algorithm, combined with carefully designed long-step and short-step problem-solving prompts along with the BackVerify mechanism, can significantly enhance the model's mathematical capabilities.</p>
<p>Question Disambiguation</p>
<p>Original Question: James decides to run 3 sprints 3 times a week.He runs 60 meters each sprint.How many total meters does he run a week?</p>
<p>Clarified Question: How many total meters does James run in a week if he runs 3 sprints, each of 60 meters, 3 times a week?</p>
<p>Figure 4: From this figure, we observe that some questions may contain ambiguity, which can be resolved by using the disambiguation operation to generate a clarified version of the question.</p>
<p>ABLATION STUDY</p>
<p>To better understand the strong performance of our model, we conducted an ablation study to demonstrate the effectiveness of the disambiguation and back verification modules by systematically removing them.</p>
<p>Remove the Disambiguation Module To assess the impact of the disambiguation process, we conducted a series of comparative experiments using the MATH and GSM8K datasets with both the LLaMA3-8b-Instruct and Qwen2-7b-Instruct models.As shown in Table 3, removing the disambiguation component in BEATS resulted in a significant decrease in accuracy across all experiments, highlighting the critical role of the disambiguation process.Additionally, we evaluated the effectiveness of disambiguation through case studies.In Figure 4, the clarified question offers the following advantages: (1) The original phrasing, "3 sprints 3 times a week", is ambiguous, as it could imply that James runs three sprints three times a week or that each session consists of three sets of three sprints.In contrast, the clarified question explicitly states that James runs three sprints per session and completes these sessions three times per week, thereby minimizing potential misinterpretation.</p>
<p>(2) The clarified question concisely presents the key details, "3 sprints of 60 meters each, 3 times a week", in a structured format that enhances logical flow and comprehension.Remove the Back Verification Module In Table 1 and Table 2, we compare model variants with and without back verification across five benchmark datasets: MATH, GSM8K, SVAMP, SimulEq, and NumGLUE.The ablation study demonstrates that back verification consistently improves model performance, highlighting its robustness and effectiveness in enhancing the model's mathematical capabilities.Furthermore, as illustrated by the example in Figure 3, when presented with the candidate answers 1 2 and 21 43 , the LLM successfully discarded the incorrect solutions through back verification, ultimately selecting the correct answer.</p>
<p>Overall, the ablation study demonstrates the critical role of the disambiguation and back verification modules in enhancing model performance.Removing either led to a drop in accuracy, showing their effectiveness in clarifying ambiguous problem statements and filtering incorrect answers.Together, these components significantly improve the model's ability to solve mathematical problems.</p>
<p>CONCLUSION</p>
<p>In this paper, we introduced BEATS, a new method designed to enhance the mathematical problemsolving capabilities of LLMs.By addressing critical challenges such as suboptimal prompts, ineffective verification methods, and high computational costs, our approach offers a significant improvement in performance.The meticulously crafted prompts facilitate step-by-step reasoning, re-Preprint ducing ambiguities in problem statements and enabling the model to generate accurate answers.Our innovative back-verification technique enhances the reliability of results by ensuring that answers are thoroughly validated.Additionally, the pruning tree search strategy allows for controlled inference time while maintaining state-of-the-art performance.Through extensive experimentation, we demonstrated that BEATS notably outperforms existing methods, marking a solid foundation for advancing mathematical reasoning in LLMs.This work represents an excellent starting point, paving the way for future research to explore more effective verification methods and their applicability across a broader spectrum of complex problem domains.BEATS significantly improves the model's mathematical capabilities through designed pruning search algorithm, which processes multi-turn question inference.Figure 5 presents a comparison of the average number of tokens generated by different models-LLaMA3, Qwen2, and Yi-1.5-across five mathematical benchmarks: MATH, GSM8K, SVAMP, SimulEq, and NumGLUE.As shown in the figure, LLaMA3 consistently produces the highest number of tokens across all benchmarks, with a particularly large margin in the MATH dataset, where it exceeds 5,000 tokens on average.In contrast, Qwen2 and Yi-1.5 generate fewer tokens, with Yi-1.5 often producing the least across most datasets.This suggests that LLaMA3 might engage in more extensive reasoning processes but at the cost of higher computation, while Qwen2 and Yi-1.5 strike a balance between efficiency and performance.</p>
<p>B CANDIDATE ANSWER DISTRIBUTION</p>
<p>Figure 6 illustrates the distribution of candidate answer set sizes for individual test samples across five mathematical benchmarks (MATH, GSM8K, SVAMP, SimulEq, and NumGLUE) for three models: LLaMA3, Qwen2, and Yi-1.5.As shown in the figure, most test samples for all models tend to have larger candidate sets, with a clear peak at 12 candidates across all benchmarks.LLaMA3 consistently demonstrates larger candidate sets compared to Qwen2 and Yi-1.5, particularly in the MATH and GSM8K benchmarks, where the size of candidate sets reaches up to 12 for a substantial number of cases.</p>
<p>Please act as a professional math teacher.Your goal is to accurately clarify a math word problem by restating the question in a way that eliminates any potential ambiguity.To achieve the goal, you have two jobs.# Restate the Given Question clearly to avoid any ambiguity or confusion.# Ensure that all important details from the original question are preserved.</p>
<p>You have two principles to do this.# Ensure the clarified question is fully understandable and unambiguous.# Ensure that no information is lost from the original question.</p>
<p>C PROMPTS</p>
<p>Inspired by Li et al. (2024a), we utilized the prompts shown in Figure 7 to implement the BEATS algorithm.</p>
<p>Preprint</p>
<p>James decides to run 3 sprints 3 times a week.He runs 60 meters each sprint.How many total meters does he run a week?</p>
<p>spinner is divided into three parts labeled ,  and .The probability of the spinner landing on  is ⁄ 1 3 and the probability of the spinner landing on  is ⁄ 5 12.What is the probability of the spinner landing on ? Express your answer as a common fraction.STEP: First, let's find the sum of the probabilities of the spinner landing on A and B. This will give us a portion of the total probability space.[()+ () = ⁄ 1 3 + ⁄ 5 12 ] Now, let's compute this sum.[() + ()</p>
<p>Figure 2 :
2
Figure 2: Visualization of the search algorithm in BEATS.</p>
<p>If the sum of two numbers, a and b, is equal to 7 (i.e., a + b = 7), and the sum of their cubes is equal to 42 (i.e., a³ + b³ = 42), is the value of the sum of their reciprocals equal to 1/2?To verify, we can use the fact that a + b = 7 to express b as b = 7 -a.Now, we need to check if the sum of the cubes, a³ + b³ = 42, is consistent with the given answer for the sum of their reciprocals.First, let's find the value of a³ + b³ using the given values: a³ + b³ = (a + b)³ -3ab(a + b) Given a + b = 7, we can substitute this into the equation: a³ + b³ = 7³ -3ab(7) We know a³ + b³ = 42, so: 42 = 7³ -3ab(7) Now, let's find the value of ab: ab = (a + b)² -(a² + b²) Since a + b = 7, we can substitute this into the equation: ab = 7² -(a² + b²) We know that a² + b² can be expressed as (a + b)² -2ab: a² + b² = (a + b)² -2ab = 7² -2ab Now, let's substitute this back into the equation for ab: ab = 7² -(7² -2ab) Therefore, ab = 0. Now, let's find the value of 1/a + 1/b: 1/a + 1/b = (a + b) / (ab)</p>
<p>Preprint</p>
<p>Figure 6 :
6
Figure 6: Candidate answer set size.</p>
<p>Figure 5 :
5
Figure 5: Average tokens needed for solving different problems.</p>
<p>Given</p>
<p>Figure 7: Prompts used in BEATS.</p>
<p>Table 1 :
1
We compared our method with previous tree search, zero-shot, and SFT approaches on two commonly used benchmarks, i.e.GSM8K and MATH.Our model achieved SOTA performance on both benchmarks.
ModelBase Model Size MATH GSM8KChain-of-ThoughtLLaMA38B27.8050.27Chain-of-ThoughtYi-1.56B30.4264.47Zero-ShotChain-of-Thought Hard Voting@8 (Wang et al., 2024)Qwen2 LLaMA37B 8B36.94 30.0076.63 78.39Hard Voting@64 (Wang et al., 2024)LLaMA38B33.0083.24WizardMath (Luo et al., 2023)LLaMA27B10.7054.90SFTMuggleMath (Li et al., 2024b) MetaMath (Yu et al., 2023)LLaMA2 LLaMA27B 7B-19.8068.40 66.50LEMA-LLaMA (An et al., 2023)LLaMA27B9.4054.10ToT (Yao et al., 2024)LLaMA38B13.6069.07RAP (Hao et al., 2023)LLaMA38B18.8080.59ReST-MCTS<em>(1st iteration)LLaMA38B31.42-SearchReST-MCTS</em>(2st iteration) LiteSearch (Wang et al., 2024)LLaMA3 LLaMA38B 8B34.28 --82.30Llama-2+M<em> (BS@16) (Kang et al., 2024)LLaMA213B32.4066.30Llama-2+M</em> (LevinTS@16)LLaMA213B33.9068.80BEATS (w.o. BackVerify)LLaMA38B35.1783.62BEATSLLaMA38B42.9388.48SearchBEATS (w.o. BackVerify) BEATSYi-1.5 Yi-1.56B 6B42.01 51.2774.68 76.12BEATS (w.o. BackVerify)Qwen27B57.2881.50BEATSQwen27B61.5283.024.1 EXPERIMENT SETTINGS
DatasetsWe conduct experiments on five authoritative mathematical reasoning datasets: (1) GSM8K: The GSM8K dataset consists of 1,319 test samples and is widely used for arithmetic Preprint</p>
<p>Table 2 :
2
We compare our method with previous models on SVAMP, SimulEq, and NumGLUE benchmarks.Our method show significant improvement over these benchmarks.
ModelBase Model Size SVAMP SimulEq NumGLUEChain-of-ThoughtLLaMA38B53.9021.2027.35Zero-ShotChain-of-Thought Chain-of-ThoughtYi-1.5 Qwen26B 7B76.40 85.2034.63 32.6838.39 53.36Code-Llama (Roziere et al., 2023)-13B60.003.8027.60WizardMath (Luo et al., 2023)LLaMA213B51.9014.9036.10Platypus (Lee et al., 2023)LLaMA213B55.407.4042.30Platypus (Lee et al., 2023)LLaMA130B+51.7013.6040.50Platypus (Lee et al., 2023)LLaMA265B+51.8021.7048.10SFTOcra-Platypus (Lee et al., 2023) MAmmoTH (Yue et al., 2023)LLaMA2 LLaMA213B 13B56.80 72.407.90 43.2035.30 61.20MAmmoTH-Coder (Yue et al., 2023) Code-Llama 13B73.7047.1066.40Galactica (Taylor et al., 2022)GAL30B41.6013.2034.70Tulu (Wang et al., 2023b)LLaMA230B+59.0010.3043.40Guanaco (Dettmers et al., 2023)LLaMA265B+66.8020.2040.50BEATS (w.o. BackVerify)LLaMA38B80.6072.7666.99BEATSLLaMA38B88.7078.4073.61SearchBEATS (w.o. BackVerify) BEATSYi-1.5 Yi-1.56B 6B79.30 83.7034.72 34.8275.43 77.93BEATS (w.o. BackVerify)Qwen27B88.8035.2172.84BEATSQwen27B90.7036.1973.16</p>
<p>Table 3 :
3
We compare the performance with and without the disambiguation module.The results demonstrate the effectiveness of the disambiguation module.
DatasetModelSearchAccuracyMATHLLaMA3 Qwen2BEATS w.o. disambiguation 35.80 ↓ 7.13 42.93 BEATS 61.52 w.o. disambiguation 51.88 ↓ 9.64GSM8KLLaMA3 Qwen2BEATS w.o. disambiguation 74.83 ↓ 13.65 88.48 BEATS 83.02 w.o. disambiguation 76.88 ↓ 6.14</p>
<p>Shengnan An, Zexiong Ma, Zeqi Lin, Nanning Zheng, Jian-Guang Lou, Weizhu Chen, arXiv:2310.20689Learning from mistakes makes llm better reasoner. 2023arXiv preprint</p>
<p>Llemma: An open language model for mathematics. Zhangir Azerbayev, Hailey Schoelkopf, Keiran Paster, Stephen Santos, Albert Q Mcaleer, Jia Jiang, Stella Deng, Sean Biderman, Welleck, arXiv:2310.106312023. 2021arXiv preprint</p>
<p>Jinze Bai, Shuai Bai, Yunfei Chu, Zeyu Cui, Kai Dang, Xiaodong Deng, Yang Fan, Wenbin Ge, Yu Han, Fei Huang, Binyuan Hui, Luo Ji, Mei Li, Junyang Lin, Runji Lin, Dayiheng Liu, Gao Liu, Chengqiang Lu, Keming Lu, Jianxin Ma, Rui Men, Xingzhang Ren, Xuancheng Ren, Chuanqi Tan, Sinan Tan, Jianhong Tu, Peng Wang, Shijie Wang, Wei Wang, Shengguang Wu, Benfeng Xu, Jin Xu, An Yang, Hao Yang, Jian Yang, Shusheng Yang, Yang Yao, Bowen Yu, Hongyi Yuan, Zheng Yuan, Jianwei Zhang, Xingxuan Zhang, Yichang Zhang, Zhenru Zhang, Chang Zhou, Jingren Zhou, arXiv:2309.16609Xiaohuan Zhou, and Tianhang Zhu. Qwen technical report. 2023aarXiv preprint</p>
<p>. Jinze Bai, Shuai Bai, Yunfei Chu, Zeyu Cui, Kai Dang, Xiaodong Deng, Yang Fan, Wenbin Ge, Yu Han, Fei Huang, arXiv:2309.166092023bQwen technical report. arXiv preprint</p>
<p>Graph of thoughts: Solving elaborate problems with large language models. Maciej Besta, Nils Blach, Ales Kubicek, Robert Gerstenberger, Michal Podstawski, Lukas Gianinazzi, Joanna Gajda, Tomasz Lehmann, Hubert Niewiadomski, Piotr Nyczyk, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence202438</p>
<p>Alphamath almost zero: process supervision without process. Guoxin Chen, Minpeng Liao, Chengxi Li, Kai Fan, arXiv:2405.035532024aarXiv preprint</p>
<p>Step-level value preference optimization for mathematical reasoning. Guoxin Chen, Minpeng Liao, Chengxi Li, Kai Fan, arXiv:2406.108582024barXiv preprint</p>
<p>Qlora: efficient finetuning of quantized llms. Tim Dettmers, Artidoro Pagnoni, Ari Holtzman, Luke Zettlemoyer, arXiv:2305.143142023. 202352arXiv preprint</p>
<p>Shibo Hao, Yi Gu, Haodi Ma, Joshua Jiahua Hong, Zhen Wang, Daisy Zhe Wang, Zhiting Hu, arXiv:2305.14992Reasoning with language model is planning with world model. 2023arXiv preprint</p>
<p>Mindstar: Enhancing math reasoning in pre-trained llms at inference time. Jikun Kang, Xin Zhe Li, Xi Chen, Amirreza Kazemi, Boxing Chen, arXiv:2405.162652024arXiv preprint</p>
<p>Large language models are zero-shot reasoners. Takeshi Kojima, Shane Shixiang, Machel Gu, Yutaka Reid, Yusuke Matsuo, Iwasawa, Advances in neural information processing systems. 202235</p>
<p>Training language models to self-correct via reinforcement learning. Aviral Kumar, Vincent Zhuang, Rishabh Agarwal, Yi Su, John D Co-Reyes, Avi Singh, Kate Baumli, Shariq Iqbal, Colton Bishop, Rebecca Roelofs, arXiv:2409.129172024arXiv preprint</p>
<p>Platypus: Quick, cheap, and powerful refinement of llms. Cole J Ariel N Lee, Nataniel Hunter, Ruiz, arXiv:2308.073172023arXiv preprint</p>
<p>Chen Li, Weiqi Wang, Jingcheng Hu, Yixuan Wei, Nanning Zheng, Han Hu, Zheng Zhang, Houwen Peng, arXiv:2403.04706Common 7b language models already possess strong math capabilities. 2024aarXiv preprint</p>
<p>Mugglemath: Assessing the impact of query and response augmentation on math reasoning. Chengpeng Li, Zheng Yuan, Hongyi Yuan, Guanting Dong, Keming Lu, Jiancan Wu, Chuanqi Tan, Xiang Wang, Chang Zhou, Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics. Long Papers. the 62nd Annual Meeting of the Association for Computational Linguistics2024b1</p>
<p>Chain of thought empowers transformers to solve inherently serial problems. Zhiyuan Li, Hong Liu, Denny Zhou, Tengyu Ma, arXiv:2402.128752024carXiv preprint</p>
<p>Wizardmath: Empowering mathematical reasoning for large language models via reinforced evol-instruct. Preprint Haipeng Luo, Qingfeng Sun, Can Xu, Pu Zhao, Jianguang Lou, Chongyang Tao, Xiubo Geng, Qingwei Lin, Shifeng Chen, Dongmei Zhang, arXiv:2308.095832023. 2024arXiv preprintIntroducing Meta Llama 3: The most capable openly available LLM to date</p>
<p>Code llama: Open foundation models for code. Jonas Baptiste Roziere, Fabian Gehring, Sten Gloeckle, Itai Sootla, Gat, Ellen Xiaoqing, Yossi Tan, Jingyu Adi, Romain Liu, Tal Sauvestre, Remez, arXiv:2308.129502023arXiv preprint</p>
<p>Zhihong Shao, Peiyi Wang, Qihao Zhu, Runxin Xu, Junxiao Song, Mingchuan Zhang, Yu Li, Daya Wu, Guo, arXiv:2402.03300Deepseekmath: Pushing the limits of mathematical reasoning in open language models. 2024arXiv preprint</p>
<p>Guillem Ross Marcin Kardas, Thomas Cucurull, Anthony Scialom, Elvis Hartshorn, Andrew Saravia, Viktor Poulton, Robert Kerkez, Stojnic, arXiv:2211.09085Galactica: A large language model for science. 2022arXiv preprint</p>
<p>Thibaut Hugo Touvron, Gautier Lavril, Xavier Izacard, Marie-Anne Martinet, Timothée Lachaux, Baptiste Lacroix, Naman Rozière, Eric Goyal, Hambro, arXiv:2302.13971Faisal Azhar, et al. Llama: Open and efficient foundation language models. 2023arXiv preprint</p>
<p>Ante Wang, Linfeng Song, Ye Tian, Baolin Peng, Dian Yu, Haitao Mi, Jinsong Su, Dong Yu, arXiv:2407.00320Litesearch: Efficacious tree search for llm. 2024arXiv preprint</p>
<p>Plan-and-solve prompting: Improving zero-shot chain-of-thought reasoning by large language models. Lei Wang, Wanyu Xu, Yihuai Lan, Zhiqiang Hu, Yunshi Lan, Roy , Ka-Wei Lee, Ee-Peng Lim, arXiv:2305.040912023aarXiv preprint</p>
<p>How far can camels go? exploring the state of instruction tuning on open resources. Yizhong Wang, Hamish Ivison, Pradeep Dasigi, Jack Hessel, Tushar Khot, Khyathi Chandu, David Wadden, Kelsey Macmillan, Noah A Smith, Iz Beltagy, Advances in Neural Information Processing Systems. 2023b36</p>
<p>Chain-of-thought prompting elicits reasoning in large language models. Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Denny Quoc V Le, Zhou, Advances in neural information processing systems. 202235</p>
<p>Ling Yang, Zhaochen Yu, Tianjun Zhang, Shiyi Cao, Minkai Xu, Wentao Zhang, Joseph E Gonzalez, Bin Cui, arXiv:2406.04271Buffer of thoughts: Thought-augmented reasoning with large language models. 2024arXiv preprint</p>
<p>Tree of thoughts: Deliberate problem solving with large language models. Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Tom Griffiths, Yuan Cao, Karthik Narasimhan, Advances in Neural Information Processing Systems. 202436</p>
<p>Huaiyuan Ying, Shuo Zhang, Linyang Li, Zhejian Zhou, Yunfan Shao, Zhaoye Fei, Yichuan Ma, Jiawei Hong, Kuikun Liu, Ziyi Wang, arXiv:2402.06332Internlm-math: Open math large language models toward verifiable reasoning. 2024arXiv preprint</p>
<p>Longhui Yu, Weisen Jiang, Han Shi, Jincheng Yu, Zhengying Liu, Yu Zhang, James T Kwok, Zhenguo Li, Adrian Weller, Weiyang Liu, Metamath, arXiv:2309.12284Bootstrap your own mathematical questions for large language models. 2023arXiv preprint</p>
<p>Xiang Yue, Xingwei Qu, Ge Zhang, Yao Fu, Wenhao Huang, Huan Sun, Yu Su, Wenhu Chen, arXiv:2309.05653Mammoth: Building math generalist models through hybrid instruction tuning. 2023arXiv preprint</p>
<p>Xiang Yue, Tuney Zheng, Ge Zhang, Wenhu Chen, arXiv:2405.03548Mammoth2: Scaling instructions from the web. 2024arXiv preprint</p>
<p>Quiet-star: Language models can teach themselves to think before speaking. Eric Preprint, Georges Zelikman, Yijia Harik, Varuna Shao, Nick Jayasiri, Noah D Haber, Goodman, arXiv:2403.096292024arXiv preprint</p>
<p>Rest-mcts*: Llm selftraining via process reward guided tree search. Dan Zhang, Sining Zhoubian, Yisong Yue, Yuxiao Dong, Jie Tang, arXiv:2406.038162024arXiv preprint</p>            </div>
        </div>

    </div>
</body>
</html>