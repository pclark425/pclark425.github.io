<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-9818 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-9818</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-9818</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-167.html">extraction-schema-167</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLMs being used to distill or synthesize theories or knowledge from large numbers of scholarly papers, including details about the models, input corpora, methods, outputs, evaluations, strengths, and limitations.</div>
                <p><strong>Paper ID:</strong> paper-d46b60993f4a192ba1a6621592f777f0e156f13d</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/d46b60993f4a192ba1a6621592f777f0e156f13d" target="_blank">Are ChatGPT and large language models “the answer” to bringing us closer to systematic review automation?</a></p>
                <p><strong>Paper Venue:</strong> Systematic Reviews</p>
                <p><strong>Paper TL;DR:</strong> This commentary discusses ChatGPT and its perspectives on its utility to systematic reviews (SRs) through the appropriateness and applicability of its responses to SR related prompts and advises that great caution should be taken by non-content experts in using these tools.</p>
                <p><strong>Paper Abstract:</strong> In this commentary, we discuss ChatGPT and our perspectives on its utility to systematic reviews (SRs) through the appropriateness and applicability of its responses to SR related prompts. The advancement of artificial intelligence (AI)-assisted technologies leave many wondering about the current capabilities, limitations, and opportunities for integration AI into scientific endeavors. Large language models (LLM)—such as ChatGPT, designed by OpenAI—have recently gained widespread attention with their ability to respond to various prompts in a natural-sounding way. Systematic reviews (SRs) utilize secondary data and often require many months and substantial financial resources to complete, making them attractive grounds for developing AI-assistive technologies. On February 6, 2023, PICO Portal developers hosted a webinar to explore ChatGPT’s responses to tasks related to SR methodology. Our experience from exploring the responses of ChatGPT suggest that while ChatGPT and LLMs show some promise for aiding in SR-related tasks, the technology is in its infancy and needs much development for such applications. Furthermore, we advise that great caution should be taken by non-content experts in using these tools due to much of the output appearing, at a high level, to be valid, while much is erroneous and in need of active vetting.</p>
                <p><strong>Cost:</strong> 0.008</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e9818.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e9818.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLMs being used to distill or synthesize theories or knowledge from large numbers of scholarly papers, including details about the models, input corpora, methods, outputs, evaluations, strengths, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ChatGPT (GPT-3.5)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>ChatGPT (based on OpenAI's GPT-3.5)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A conversational large language model (LLM) from OpenAI trained to predict and generate natural language; used by the authors in a webinar to attempt systematic-review related tasks (question formulation, search drafting, code outline, and summarization of a small set of abstracts).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Are ChatGPT and large language models "the answer" to bringing us closer to systematic review automation?</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-3.5 (ChatGPT)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>A large pre-trained transformer language model optimized for dialogue; described as trained to predict language from large corpora of written text and adapted into ChatGPT for conversational interaction. The paper notes GPT-3.5 as the original basis for ChatGPT and characterizes LLMs as predicting likely continuations of text rather than performing retrieval of verifiable sources.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>input_corpus_description</strong></td>
                            <td>For model pretraining the paper reports GPT-3.5 was trained on ~570 GB of text (broad written-language corpora, unspecified composition). For the authors' experiments, ChatGPT was prompted interactively and given task-specific inputs including a set of three abstracts for summarization, individual systematic-review prompts (PICO/question drafting), and requests to draft PubMed search strategies and analysis code.</td>
                        </tr>
                        <tr>
                            <td><strong>input_corpus_size</strong></td>
                            <td>3</td>
                        </tr>
                        <tr>
                            <td><strong>topic_query_description</strong></td>
                            <td>Systematic review tasks: formulating structured review questions, creating eligibility criteria, screening titles, drafting PubMed search strategies, generating code outlines for meta-analysis (Python/R), and synthesizing/summarizing content from three abstracts.</td>
                        </tr>
                        <tr>
                            <td><strong>distillation_method</strong></td>
                            <td>Interactive prompting of ChatGPT in a webinar/demo setting (natural-language prompts requesting question formulation, eligibility criteria, search strategy, code outline, and summaries). No retrieval-augmented generation, external scholarly-database querying, or explicit multi-document aggregation pipeline was used; summarization of multiple studies was performed by prompting the model with the abstracts and asking for summaries.</td>
                        </tr>
                        <tr>
                            <td><strong>output_type</strong></td>
                            <td>Structured review question and eligibility criteria drafts, draft PubMed search strategy, code outline for meta-analysis, and narrative summaries of a small set of abstracts.</td>
                        </tr>
                        <tr>
                            <td><strong>output_example</strong></td>
                            <td>Authors report that ChatGPT 'identified and summarized relevant information from a set of three abstracts' and produced proposed eligibility criteria and an initial PubMed search strategy; however the search strategy 'fabricated controlled vocabulary' and summaries contained errors. (No verbatim output quoted in paper.)</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method</strong></td>
                            <td>Qualitative expert review by the paper authors and webinar attendees (reading chat transcripts and assessing appropriateness, verifiability, and usability); no quantitative metrics or gold-standard comparison reported.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_results</strong></td>
                            <td>Qualitative findings: ChatGPT performed some tasks reasonably as a starting point (question formulation, eligibility criteria, title screening), produced a usable-but-flawed initial search strategy (fabricated controlled vocabulary terms), generated code outlines with errors needing troubleshooting, and produced summaries of three abstracts with mistakes; overall judged promising but immature and requiring expert vetting.</td>
                        </tr>
                        <tr>
                            <td><strong>strengths</strong></td>
                            <td>Good at contextualizing prompts and producing human-readable draft artifacts quickly (structured questions, eligibility criteria, initial search drafts, code outlines, and narrative summaries); potential to speed initial stages and help non-experts get started; useful for writing/editing polish.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Does not provide verifiable references or perform real literature retrieval; prone to hallucination (fabricated controlled-vocabulary terms and unverifiable citations), non-deterministic outputs, coding errors, and factual mistakes in summaries; requires subject-matter/methodologic experts to vet outputs, undermining utility for non-experts.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_cases</strong></td>
                            <td>Fabricated controlled vocabulary in proposed PubMed search strategies, coding errors in generated meta-analysis code, factual errors in synthesized summaries of abstracts, and inability to produce verifiable source references when asked; overall outputs that appear plausible but are erroneous on closer inspection.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Are ChatGPT and large language models “the answer” to bringing us closer to systematic review automation?', 'publication_date_yy_mm': '2023-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9818.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e9818.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLMs being used to distill or synthesize theories or knowledge from large numbers of scholarly papers, including details about the models, input corpora, methods, outputs, evaluations, strengths, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GPT-4</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Generative Pre-trained Transformer 4 (GPT-4)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>The next-generation OpenAI LLM referenced by the authors; the paper notes limited/minor testing by the authors suggesting mild improvement on small-scale summarization but no clear additional benefit for systematic-review task completion.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Are ChatGPT and large language models "the answer" to bringing us closer to systematic review automation?</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-4</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>A more advanced OpenAI LLM released March 15, 2023; characterized in the paper as purportedly more powerful than GPT-3.5 and better at recognizing and producing language and contextual cues. The authors performed minor testing with similar prompts.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>input_corpus_description</strong></td>
                            <td>Not detailed in the paper; authors report only minor testing with similar small-scale summarization prompts (three abstracts). Pretraining corpus/composition not specified in the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>input_corpus_size</strong></td>
                            <td>3</td>
                        </tr>
                        <tr>
                            <td><strong>topic_query_description</strong></td>
                            <td>Same small-scale systematic-review related prompts used for ChatGPT (summarization of three abstracts); no large-scale synthesis experiments reported.</td>
                        </tr>
                        <tr>
                            <td><strong>distillation_method</strong></td>
                            <td>Minor ad-hoc prompting/testing analogous to the ChatGPT prompts used in the webinar; no formal distillation pipeline, retrieval augmentation, or systematic multi-paper synthesis method described.</td>
                        </tr>
                        <tr>
                            <td><strong>output_type</strong></td>
                            <td>Narrative summarization of the provided small set of abstracts; authors report 'mild improvement' in summarization quality.</td>
                        </tr>
                        <tr>
                            <td><strong>output_example</strong></td>
                            <td>Authors state 'some minor testing of GPT-4.0 with similar questions showed a mild improvement in the summarization of three abstracts' but provide no direct excerpt.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method</strong></td>
                            <td>Informal qualitative comparison by the authors of summarization outputs versus GPT-3.5/ChatGPT outputs; no formal metrics reported.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_results</strong></td>
                            <td>Mild qualitative improvement in summarizing three abstracts, but no observed additional improvements in other systematic-review task completions.</td>
                        </tr>
                        <tr>
                            <td><strong>strengths</strong></td>
                            <td>Reported by authors to have slightly better summarization performance on a very small test; generally described as improved language/context handling versus GPT-3.5.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Authors did not observe substantive gains for systematic-review task automation in their limited tests; same overarching limitations (need for expert vetting, non-determinism, lack of verifiable retrieval) apply; no large-scale synthesis tested.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_cases</strong></td>
                            <td>Not explicitly enumerated for GPT-4 in the paper beyond the persistence of errors and lack of reliable, verifiable outputs for SR tasks in limited testing.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Are ChatGPT and large language models “the answer” to bringing us closer to systematic review automation?', 'publication_date_yy_mm': '2023-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>ChatGPT: optimizing language models for dialogue <em>(Rating: 2)</em></li>
                <li>GPT-4 <em>(Rating: 2)</em></li>
                <li>Pretrained language models for biomedical and clinical tasks: understanding and extending the state-of-the-art <em>(Rating: 2)</em></li>
                <li>RobotReviewer - automating evidence synthesis <em>(Rating: 2)</em></li>
                <li>Performance of ChatGPT on USMLE: potential for AI-assisted medical education using large language models <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-9818",
    "paper_id": "paper-d46b60993f4a192ba1a6621592f777f0e156f13d",
    "extraction_schema_id": "extraction-schema-167",
    "extracted_data": [
        {
            "name_short": "ChatGPT (GPT-3.5)",
            "name_full": "ChatGPT (based on OpenAI's GPT-3.5)",
            "brief_description": "A conversational large language model (LLM) from OpenAI trained to predict and generate natural language; used by the authors in a webinar to attempt systematic-review related tasks (question formulation, search drafting, code outline, and summarization of a small set of abstracts).",
            "citation_title": "Are ChatGPT and large language models \"the answer\" to bringing us closer to systematic review automation?",
            "mention_or_use": "use",
            "model_name": "GPT-3.5 (ChatGPT)",
            "model_description": "A large pre-trained transformer language model optimized for dialogue; described as trained to predict language from large corpora of written text and adapted into ChatGPT for conversational interaction. The paper notes GPT-3.5 as the original basis for ChatGPT and characterizes LLMs as predicting likely continuations of text rather than performing retrieval of verifiable sources.",
            "model_size": null,
            "input_corpus_description": "For model pretraining the paper reports GPT-3.5 was trained on ~570 GB of text (broad written-language corpora, unspecified composition). For the authors' experiments, ChatGPT was prompted interactively and given task-specific inputs including a set of three abstracts for summarization, individual systematic-review prompts (PICO/question drafting), and requests to draft PubMed search strategies and analysis code.",
            "input_corpus_size": 3,
            "topic_query_description": "Systematic review tasks: formulating structured review questions, creating eligibility criteria, screening titles, drafting PubMed search strategies, generating code outlines for meta-analysis (Python/R), and synthesizing/summarizing content from three abstracts.",
            "distillation_method": "Interactive prompting of ChatGPT in a webinar/demo setting (natural-language prompts requesting question formulation, eligibility criteria, search strategy, code outline, and summaries). No retrieval-augmented generation, external scholarly-database querying, or explicit multi-document aggregation pipeline was used; summarization of multiple studies was performed by prompting the model with the abstracts and asking for summaries.",
            "output_type": "Structured review question and eligibility criteria drafts, draft PubMed search strategy, code outline for meta-analysis, and narrative summaries of a small set of abstracts.",
            "output_example": "Authors report that ChatGPT 'identified and summarized relevant information from a set of three abstracts' and produced proposed eligibility criteria and an initial PubMed search strategy; however the search strategy 'fabricated controlled vocabulary' and summaries contained errors. (No verbatim output quoted in paper.)",
            "evaluation_method": "Qualitative expert review by the paper authors and webinar attendees (reading chat transcripts and assessing appropriateness, verifiability, and usability); no quantitative metrics or gold-standard comparison reported.",
            "evaluation_results": "Qualitative findings: ChatGPT performed some tasks reasonably as a starting point (question formulation, eligibility criteria, title screening), produced a usable-but-flawed initial search strategy (fabricated controlled vocabulary terms), generated code outlines with errors needing troubleshooting, and produced summaries of three abstracts with mistakes; overall judged promising but immature and requiring expert vetting.",
            "strengths": "Good at contextualizing prompts and producing human-readable draft artifacts quickly (structured questions, eligibility criteria, initial search drafts, code outlines, and narrative summaries); potential to speed initial stages and help non-experts get started; useful for writing/editing polish.",
            "limitations": "Does not provide verifiable references or perform real literature retrieval; prone to hallucination (fabricated controlled-vocabulary terms and unverifiable citations), non-deterministic outputs, coding errors, and factual mistakes in summaries; requires subject-matter/methodologic experts to vet outputs, undermining utility for non-experts.",
            "failure_cases": "Fabricated controlled vocabulary in proposed PubMed search strategies, coding errors in generated meta-analysis code, factual errors in synthesized summaries of abstracts, and inability to produce verifiable source references when asked; overall outputs that appear plausible but are erroneous on closer inspection.",
            "uuid": "e9818.0",
            "source_info": {
                "paper_title": "Are ChatGPT and large language models “the answer” to bringing us closer to systematic review automation?",
                "publication_date_yy_mm": "2023-04"
            }
        },
        {
            "name_short": "GPT-4",
            "name_full": "Generative Pre-trained Transformer 4 (GPT-4)",
            "brief_description": "The next-generation OpenAI LLM referenced by the authors; the paper notes limited/minor testing by the authors suggesting mild improvement on small-scale summarization but no clear additional benefit for systematic-review task completion.",
            "citation_title": "Are ChatGPT and large language models \"the answer\" to bringing us closer to systematic review automation?",
            "mention_or_use": "mention",
            "model_name": "GPT-4",
            "model_description": "A more advanced OpenAI LLM released March 15, 2023; characterized in the paper as purportedly more powerful than GPT-3.5 and better at recognizing and producing language and contextual cues. The authors performed minor testing with similar prompts.",
            "model_size": null,
            "input_corpus_description": "Not detailed in the paper; authors report only minor testing with similar small-scale summarization prompts (three abstracts). Pretraining corpus/composition not specified in the paper.",
            "input_corpus_size": 3,
            "topic_query_description": "Same small-scale systematic-review related prompts used for ChatGPT (summarization of three abstracts); no large-scale synthesis experiments reported.",
            "distillation_method": "Minor ad-hoc prompting/testing analogous to the ChatGPT prompts used in the webinar; no formal distillation pipeline, retrieval augmentation, or systematic multi-paper synthesis method described.",
            "output_type": "Narrative summarization of the provided small set of abstracts; authors report 'mild improvement' in summarization quality.",
            "output_example": "Authors state 'some minor testing of GPT-4.0 with similar questions showed a mild improvement in the summarization of three abstracts' but provide no direct excerpt.",
            "evaluation_method": "Informal qualitative comparison by the authors of summarization outputs versus GPT-3.5/ChatGPT outputs; no formal metrics reported.",
            "evaluation_results": "Mild qualitative improvement in summarizing three abstracts, but no observed additional improvements in other systematic-review task completions.",
            "strengths": "Reported by authors to have slightly better summarization performance on a very small test; generally described as improved language/context handling versus GPT-3.5.",
            "limitations": "Authors did not observe substantive gains for systematic-review task automation in their limited tests; same overarching limitations (need for expert vetting, non-determinism, lack of verifiable retrieval) apply; no large-scale synthesis tested.",
            "failure_cases": "Not explicitly enumerated for GPT-4 in the paper beyond the persistence of errors and lack of reliable, verifiable outputs for SR tasks in limited testing.",
            "uuid": "e9818.1",
            "source_info": {
                "paper_title": "Are ChatGPT and large language models “the answer” to bringing us closer to systematic review automation?",
                "publication_date_yy_mm": "2023-04"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "ChatGPT: optimizing language models for dialogue",
            "rating": 2
        },
        {
            "paper_title": "GPT-4",
            "rating": 2
        },
        {
            "paper_title": "Pretrained language models for biomedical and clinical tasks: understanding and extending the state-of-the-art",
            "rating": 2
        },
        {
            "paper_title": "RobotReviewer - automating evidence synthesis",
            "rating": 2
        },
        {
            "paper_title": "Performance of ChatGPT on USMLE: potential for AI-assisted medical education using large language models",
            "rating": 1
        }
    ],
    "cost": 0.007752,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>Are ChatGPT and large language models "the answer" to bringing us closer to systematic review automation?</h1>
<p>Riaz Qureshi ${ }^{1,2^{*}}{ }^{\text {O }}$, Daniel Shaughnessy ${ }^{1}$, Kayden A. R. Gill ${ }^{2,3}$, Karen A. Robinson ${ }^{2,4}$, Tianjing $\mathrm{Li}^{1,2}$ and Eitan Agai ${ }^{2}$</p>
<h4>Abstract</h4>
<p>In this commentary, we discuss ChatGPT and our perspectives on its utility to systematic reviews (SRs) through the appropriateness and applicability of its responses to SR related prompts. The advancement of artificial intelligence (AI)-assisted technologies leave many wondering about the current capabilities, limitations, and opportunities for integration Al into scientific endeavors. Large language models (LLM)—such as ChatGPT, designed by OpenAI—have recently gained widespread attention with their ability to respond to various prompts in a natural-sounding way. Systematic reviews (SRs) utilize secondary data and often require many months and substantial financial resources to complete, making them attractive grounds for developing Al-assistive technologies. On February 6, 2023, PICO Portal developers hosted a webinar to explore ChatGPT's responses to tasks related to SR methodology. Our experience from exploring the responses of ChatGPT suggest that while ChatGPT and LLMs show some promise for aiding in SR-related tasks, the technology is in its infancy and needs much development for such applications. Furthermore, we advise that great caution should be taken by non-content experts in using these tools due to much of the output appearing, at a high level, to be valid, while much is erroneous and in need of active vetting.</p>
<p>Keywords Artificial intelligence, Large language models, Systematic review, Methodology</p>
<p>In this commentary, we discuss ChatGPT and our perspectives on its utility to systematic reviews through the appropriateness and applicability of its responses to systematic review tasks and prompts. ChatGPT is a large language model (LLM) and artificial intelligence (AI) system designed by OpenAI (https://openai.com/blog/ chatgpt/) to interact with people in a natural and conversational way [1]. Standard machine-learning (ML) algorithms are trained to provide responses or to make classifications or predictions given a specific input using</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup>large sets of data that have already been, or are actively, categorized by users [2, 3]. Likewise, LLMs are trained to predict language and writing based on large datasets of written language, thereby learning contextual clues and what might be expected or predicted following a set of words (i.e., a prompt) [3-5]. For example, OpenAI's GPT3.5 was trained on approximately 570 GB of text and is the original basis for ChatGPT [1, 6]. Depending on the prompt, LLMs can produce many different types of outputs. This has produced an explosion in the use of LLMs and ChatGPT, as well as creating controversy surrounding their applications [6].</p>
<p>Conducting a systematic review is a complex and arduous process that takes a great deal of expertise and time. It is not uncommon for reviews to take over 12 months to complete and require upwards of $\$ 100,000$ in effort when considering the time spent on searching (by information</p>
<p>specialists), screening, data extraction, analysis, interpretation, and writing by methodologists and content experts [7-9]. There are areas where ML and AI have already been introduced in the systematic review process with great success [10-13]. Given the recent attention around LLMs, like ChatGPT, and the resource burden of conducting a systematic review, we wanted to explore and critique the responses of ChatGPT to systematic review tasks. On February 6, 2023, developers of PICO Portal—an AI-assisted systematic review platform [10]—hosted a webinar to demonstrate a variety of tasks and elicit feedback on the ChatGPT output.</p>
<p>We "tested" ChatGPT by asking it to complete systematic-review tasks with a focus on tasks relevant to interpretation of language and not test whether ChatGPT could perform a task that is more data-specific, such as data extraction [14]. Other biomedical uses for LLMs have been suggested, including for data and text mining, particularly of clinical records, and aiding in medical education and clinical decision making [15, 16]. Our intent was to see whether this kind of language model could be used by someone who may wish to plan a systematic review, further develop a review question, or get help in drafting the search or analysis methods. A detailed description of our experience and a link to the webinar recording can be found in the SUPPLEMENT.</p>
<p>We found that ChatGPT could complete some systematic review tasks well, while others had clear room for improvement:</p>
<ul>
<li>In formulating a structured review question, creating eligibility criteria, and screening titles for relevance, ChatGPT's output suggested the interpretation and contextualization of the prompt was appropriate. We felt the proposed criteria and selected articles could serve as a starting point for refinement depending on the complexity of the question.</li>
<li>Having a ChatGPT generated PubMed search strategy, or an initial version, would be helpful to those who may not have access to an informationist in their resources. However, the proposed search strategy was unusable with multiple issues, including fabricating controlled vocabulary, that would not be apparent without expertise in search construction.</li>
<li>ChatGPT is able to produce code in various programming languages and was able to create an outline of code for conducting a meta-analysis in Python and R. However, as with the search strategy, there were coding errors that required troubleshooting from a user with methodologic expertise.</li>
<li>Synthesis and summary of multiple studies is a challenge but ultimately the most essential product of a systematic review. The time required to pick relevant information and create a summary is substantial, but there is potential for tools like ChatGPT to help begin these processes for reviewers. We found promise in the ability of the system to identify and summarize relevant information from a set of three abstracts. However, there were errors that suggest the technology is not yet ready for such a task.</li>
</ul>
<p>In its current form, ChatGPT presents as an "uncanny valley" in research and information sciences: from a distance, the output mimics and passes as authentic; however, on closer inspection, it becomes apparent that it is not expertly formed material based on a depth of understanding of the systematic review process. A particularly strong limitation of the system is the lack of referencing appropriate and verifiable sources when asked for factual information. When we asked for references, we could not verify what it presented to us. This is a common occurrence as LLMs are designed to build a response using predictions and not by looking through literature to find real sources [17]. Indeed, when asked where it finds information and to search bibliographic databases, ChatGPT responds only that it cannot conduct any real literature retrieval.</p>
<p>With the model's current capabilities, we anticipate that anyone attempting to use ChatGPT for providing verifiable and content/context-specific research will find that the recipient must have expertise in the subject matter. Unfortunately, this pre-requisite defeats the purpose of having an "intelligent" automation help with the tasks. It should be noted that other LLMs are being developed and entering the public domain, so ChatGPT may not perfectly reflect all LLMs. On March 15, 2023, GPT-4.0 was released for testing among OpenAI's paid subscribers [18]. This new model purports to be more powerful than GPT-3.5 and better at recognizing and producing language and contextual cues in writing [18]. It should be noted that some minor testing of GPT-4.0 with similar questions showed a mild improvement in the summarization of three abstracts, but no additional improvements in systematic review task completion as far as we could discern. Additionally, there may be other systematic review tasks and use cases that we have not conceived and may elicit a more trustworthy and usable response from ChatGPT or other such systems. Furthermore, for better or worse, since generating a response in an LLM is not deterministic, the response will not be identical each time the same question is asked. We expect that there will be further advancements in the capabilities of these systems.</p>
<p>We know that the broader scientific community has concerns with the use of LLMs in research, and from our experience, we believe the systematic review</p>
<p>community shares the same sentiments. Those in attendance during our demonstration posted many comments about ChatGPT and its application in education and research, primarily echoing concerns with the use of the technology and a large number of questions about its capabilities, limitations, internal processes, and output. Comments reflecting the uncertainty and hesitancy to use LLMs were also common, alongside the risks with non-expert use, as it was apparent that there was a requirement for content expertise in the various tasks. Many attendees posted links to resources and other tools to help perform the systematic review tasks we explored. There were also some comments on potential applications and areas for developing LLMs in the field of evidence syntheses and general positive and negative reactions from people about the utility of AI systems and LLMs in science. It is clear that discussion of the potential applications, challenges, and risks with integrating these technologies into the systematic review process need to happen and should take place in large, public forums. One group that is working towards addressing some of the questions and methodological issues such integration brings is the International Collaboration for the Automation of Systematic Reviews (ICASR) [19].</p>
<p>Despite the challenges with its use in systematic review tasks, ChatGPT was able to contextualize our questions and formulate responses that fit what we requested, which is encouraging for future development. In particular, we believe more attention should be given to accurately creating search strategies, as these utilize logic and rules (e.g., Boolean operators) and structured language in a way that should be more easily trainable than conversational language. Likewise, strengthening the ability of LLMs to take sections of text and identify relevant information for summary purposes could provide starting points for researchers or high-level summaries of results when time is limited (e.g., in a pandemic with hundreds of articles published daily that could contain relevant information to inform guidelines). Additionally, as the text writing and editing capabilities improve, the potential utility increases for these systems in polishing drafts of systematic reviews for authors who need help revising their writing [20].</p>
<p>In conclusion, we believe ChatGPT and other LLMs hold promise in being integrated into systematic reviews, but they are not yet able to be used with confidence in any way. We encourage others to attempt similar exploration and testing to understand the current limitations and capacity of ChatGPT and LLMs in the context of evidence synthesis.</p>
<h2>Supplementary Information</h2>
<p>The online version contains supplementary material available at https://doi. org/10.1186/s13643-023-02243-z.</p>
<p>Additional file 1: SUPPLEMENT. Detailed description of our experience and a link to the webinar recording.</p>
<p>We would like to thank the webinar attendees for their feedback and discussion of ChatGPT's responses to our prompts.</p>
<h2>Authors' contributions</h2>
<p>RQ and EA conceptualized the commentary and led the webinar discussed within. RQ drafted the manuscript. RQ, DS, and KG read the chat transcripts to identify themes. All authors critically revised the manuscript for content and approved the final version for publication.</p>
<h2>Funding</h2>
<p>Not applicable.</p>
<h2>Availability of data and materials</h2>
<p>Data sharing is not applicable to this article as no datasets were generated or analyzed during the current study.</p>
<h2>Declarations</h2>
<p>Ethics approval and consent to participate</p>
<p>Not applicable.</p>
<h2>Consent for publication</h2>
<p>Not applicable.</p>
<h2>Competing interests</h2>
<p>RQ, KG, TL, and KR provide consultative services to PICO Portal. EA is the founder and owner of PICO Portal. PICO Portal itself has no affiliation with ChatGPT. DS has no relevant interests.</p>
<p>Received: 21 March 2023 Accepted: 20 April 2023
Published online: 29 April 2023</p>
<h2>References</h2>
<ol>
<li>OpenAI. ChatGPT: optimizing language models for dialogue. OpenAI. Published 2023. Accessed 6 Feb 2023. https://openai.com/blog/chatgpt/.</li>
<li>Ray S. A quick review of machine learning algorithms. In: Proceedings of the International Conference on Machine Learning, Big Data, Cloud and Parallel Computing: Trends, Prespectives and Prospects, COMITCon 2019. IEEE; 2019:35-39.</li>
<li>Mahesh B. Machine learning algorithms - a review. Int J Sci Res. 2018;18(8):381-6. https://doi.org/10.21275/ART20203995.</li>
<li>Drenik G. Large language models will define artificial intelligence. Forbes. Published online 2023. https://www.forbes.com/sites/garydrenik/2023/ 01/11/large-language-models-will-define-artificial-intelligence/?sh= 698337a9b60f.</li>
<li>Wiggers K. The emerging types of language models and why they matter. TechCrunch. Published online 2022. https://techcrunch.com/2022/04/28/ the-emerging-types-of-language-models-and-why-they-matter/.</li>
<li>Shen Y, Heacock L, Elias J, Hentel K, Reig B, Shih G, Moy L. ChatGPT and other large language models are double-edged swords. Radiology. 2023;1. https://doi.org/10.1148/radiol.230163.</li>
<li>Michelson M, Reuter K. The significant cost of systematic reviews and meta-analyses: a call for greater involvement of machine learning to assess the promise of clinical trials. Contemp Clin Trials Commun. 2019;16:100443. https://doi.org/10.1016/j.conctc.2019.100443.</li>
<li>Borah R, Brown AW, Capers PL, Kaiser KA. Analysis of the time and workers needed to conduct systematic reviews of medical interventions using</li>
</ol>
<p>data from the PROSPERO registry. BMJ Open. 2017;7(2):e012545. https:// doi.org/10.1136/bmjopen-2016-012545.
9. Bullers K, Howard AM, Hanson A, Kearns WD, Orriola JJ, Polo RL, Sakmar KA. It takes longer than you think: librarian time spent on systematic review tasks. J Med Libr Assoc. 2018;106(2):198-207. https://doi.org/10. 5195/jmla.2018.323.
10. PICO Portal. Introducing PICO Portal. Published 2023. Accessed 10 Feb 2023. https://picoportal.org.
11. DistillerSR. DistillerSR smarter reviews: trusted evidence. DistillerSR. Published 2023. Accessed 10 Feb 2023. www.distillersr.com.
12. Covidence. Covidence - better systematic review management. Covidence. Published 2023. Accessed 10 Feb 2023. https://www.covidence. org/.
13. Rayyan. Rayyan - Intelligent Systematic Review. Faster Systematic Reviews. Published 2023. www.rayyan.ai.
14. RobotReviewer. RobotReviewer - automating evidence synthesis. RobotReviewer. Published 2023. www.robotreviewer.net.
15. Kung TH, Cheatham M, Medenilla A, Sillos C, De Leon L, Elepaño C, Madriaga M, Aggabao R, Diaz-Candido G, Maningo J, Tseng V. Performance of ChatGPT on USMLE: potential for AI-assisted medical education using large language models. PLoS Digit Heal. 2023;2(2):e0000198. https://doi.org/10.1371/journal.pdig. 0000198.
16. Lewis P, Ott M, Du J, Stoyanov V. Pretrained language models for biomedical and clinical tasks: understanding and extending the state-of-the-art. In: Proceedings Of the 3rd Clinical Natural Language Processing Workshop. 2020. p. 146-57. https://doi.org/10.18653/v1/2020.clinicalnlp-1.17.
17. Smerdon D. @dsmerdon. Twitter. Published 2023. Accessed 10 Feb 2023. https://twitter.com/dsmerdon/status/1618816703923912704?lang=en.
18. Chen R. GPT-4. OpenAI. Published 2023. Accessed 4 Mar 2023. https:// openai.com/research/gpt-4.
19. ICASR. International Collaboration for the Automation of Systematic Reviews. 2023. Accessed 4 Mar 2023. https://icasr.github.io/.
20. Staiman A. Guest Post - Academic Publishers Are Missing the Point on ChatGPT ChatGPT as Author. The Scholarly Kitchen. Published online March 2023. https://scholarlykitchen.sspnet.org/2023/03/31/guest-post-academic-publishers-are-missing-the-point-on-chatgpt/.</p>
<h1>Publisher's Note</h1>
<p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p>
<h2>Ready to submit your research? Choose BMC and benefit from:</h2>
<ul>
<li>fast, convenient online submission</li>
<li>thorough peer review by experienced researchers in your field</li>
<li>rapid publication on acceptance</li>
<li>support for research data, including large and complex data types</li>
<li>gold Open Access which fosters wider collaboration and increased citations</li>
<li>maximum visibility for your research: over 100M website views per year</li>
</ul>
<p>At BMC, research is always in progress.
Learn more biomedcentral.com/submissions</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>*Correspondence:</p>
<p>Riaz Qureshi
riaz.qureshi@cuanschutz.edu
${ }^{1}$ University of Colorado Anschutz Medical Campus, Aurora, CO, USA
${ }^{2}$ PICO Portal, New York, NY, USA
${ }^{3}$ University of Pittsburgh, Pittsburgh, PA, USA
${ }^{4}$ Johns Hopkins University, Baltimore, MD, USA&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>