<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-9291 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-9291</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-9291</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-162.html">extraction-schema-162</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <p><strong>Paper ID:</strong> paper-235337585</p>
                <p><strong>Paper Title:</strong> <a href="https://arxiv.org/pdf/2012.13972v1.pdf" target="_blank">Recompose Event Sequences vs. Predict Next Events: A Novel Anomaly Detection Approach for Discrete Event Logs</a></p>
                <p><strong>Paper Abstract:</strong> One of the most challenging problems in the field of intrusion detection is anomaly detection for discrete event logs. While most earlier work focused on applying unsupervised learning upon engineered features, most recent work has started to resolve this challenge by applying deep learning methodology to abstraction of discrete event entries. Inspired by natural language processing, LSTM-based anomaly detection models were proposed. They try to predict upcoming events, and raise an anomaly alert when a prediction fails to meet a certain criterion. However, such a predict-next-event methodology has a fundamental limitation: event predictions may not be able to fully exploit the distinctive characteristics of sequences. This limitation leads to high false positives (FPs). It is also critical to examine the structure of sequences and the bi-directional causality among individual events. To this end, we propose a new methodology: Recomposing event sequences as anomaly detection. We propose DabLog, a LSTM-based Deep Autoencoder-Based anomaly detection method for discrete event Logs. The fundamental difference is that, rather than predicting upcoming events, our approach determines whether a sequence is normal or abnormal by analyzing (encoding) and reconstructing (decoding) the given sequence. Our evaluation results show that our new methodology can significantly reduce the numbers of FPs, hence achieving a higher F1 score.</p>
                <p><strong>Cost:</strong> 0.018</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e9291.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e9291.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>DabLog</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Deep Autoencoder-Based anomaly detection method for discrete event Logs</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An LSTM-based sequence-reconstruction anomaly detector that treats each discrete event sequence as an atomic instance: it embeds events, encodes the full sequence with a stacked LSTM autoencoder, decodes to a reconstructed categorical distribution, classifies per-event logits, and applies a critic (rank- or threshold-based) to decide sequence-level anomalies.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>DabLog</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>LSTM autoencoder (stacked recurrent encoder-decoder)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>Encoder: 2 LSTM layers (64, 32 hidden units); Decoder: 2 LSTM layers (32, 64 hidden units); embedding dimension unspecified</td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>categorical discrete event sequences (time-sensitive sequential logs)</td>
                        </tr>
                        <tr>
                            <td><strong>data_domain</strong></td>
                            <td>system console logs (HDFS dataset used in experiments); also reported results on traffic logs in abstract</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>sequence-level anomalies including structural anomalies, rare/unseen events, and causality-violating sequences (time-sensitive anomalies)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Train an embedding layer for event keys; use a stacked LSTM encoder to produce a representation code and a stacked LSTM decoder to reconstruct the sequence (reverse order). Feed decoder logits to a softmax event classifier to obtain per-time-step categorical probabilities. A critic flags a sequence abnormal if any event's true key is not among top-N reconstructed probabilities or below a probability threshold; authors also propose future rank-distance (embedding-aware) double-thresholds.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_methods</strong></td>
                            <td>Predictor-based LSTM next-event models (re-implemented 'Baseline' similar to DeepLog/nLSALog), trivial frequency top-N heuristic, and conventional autoencoders for time-insensitive data (discussed in related work).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Precision, Recall, F1 score, False-positive rate, Accuracy, Area Under ROC (AUROC)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>On HDFS-derived key sets: K1 (101 keys) DabLog peak F1 = 97.18% at normalized rank threshold θ_N = 9%; DabLog (5K training) peak F1 = 95.20% at θ_N = 27%. K2 (304 keys) DabLog peak F1 = 94.15% at θ_N = 6%. Reported AUROC: K0 99.49%, K1 99.44%, K2 99.08%. Paper also reports (abstract) DabLog produced 1,790 fewer FPs and 1,982 more TPs than the predictor baseline on HDFS with 101 distinct events, and 2,419 fewer FPs with trade-off of 83 fewer TPs on traffic logs with 706 distinct events.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td>DabLog substantially outperforms predictor-based baseline in F1 and precision on the evaluated HDFS experiments (example: on K1, DabLog 97.18% F1 vs Baseline 87.32% F1 at their peaks), producing far fewer false positives while often producing more true positives; improvements are larger for larger vocabularies (more distinct event keys).</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Current critic options (rank-based or simple threshold) ignore embedding-neighborhood correlations and can misclassify near-tied probabilities; OOV (out-of-vocabulary) / unknown event keys are a problem because embedding is learned only for training keys; the rank-based critic's behavior depends on vocabulary size and training coverage (models trained with small training sets may artificially appear to perform well under coarse rank thresholds); requires datasets with reconstructable sequential relationships (some public security datasets lack low-level events and are unsuitable); computational cost of training embedding + LSTM autoencoder not extensively profiled.</td>
                        </tr>
                        <tr>
                            <td><strong>unique_insights</strong></td>
                            <td>Reconstructing entire discrete sequences (autoencoder) leverages bidirectional causality (past and future context) and sequence structure, avoiding the 'cold-start' guessing of next-event predictors and reducing both false positives and false negatives; training a dedicated event embedding is preferable to one-hot or off-the-shelf word embeddings for security logs; framing anomaly detection as sequence reconstruction + classification (embed-encode-decode-classify-critic) is a novel and effective alternative to next-event prediction for time-sensitive discrete logs.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Recompose Event Sequences vs. Predict Next Events: A Novel Anomaly Detection Approach for Discrete Event Logs', 'publication_date_yy_mm': '2021-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9291.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e9291.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Baseline (predictor)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Reimplemented predictor-based anomaly detection model (DeepLog-like)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A reimplementation representative of predictor-based LSTM anomaly detectors: uses an embedding layer, a two-layer stacked LSTM to predict the next event (single-event predictor), a softmax classifier and a rank-based critic (top-N) to mark anomalies when predictions do not include the true next event.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Baseline (predictor, DeepLog-like)</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>Stacked LSTM predictor (recurrent)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>2 LSTM layers with 64 hidden units each (as implemented in this paper's baseline)</td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>categorical discrete event sequences (time-sensitive logs), single-event prediction per sliding window</td>
                        </tr>
                        <tr>
                            <td><strong>data_domain</strong></td>
                            <td>system console logs (HDFS dataset used in experiments)</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>anomalous next-events (rare/unexpected events), but misses structure-level anomalies</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Embed sequence (learned embedding), feed prefix into stacked LSTM predictor to produce next-event softmax probabilities; mark the sequence anomalous if the true next event is not in top-N predicted keys (rank-based) or its probability is below a threshold.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_methods</strong></td>
                            <td>Compared against DabLog (LSTM autoencoder) and trivial frequency model in the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Precision, Recall, F1, FP rate, Accuracy, AUROC</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>On K1 (101 keys) Baseline peak F1 = 87.32% at θ_N = 10% (paper's reimplementation); Baseline (5K) peak F1 = 94.98% at θ_N = 31% for smaller training set; AUROC reported in Table III: Baseline 97.23% for K1 (and other values for other key sets). In specific case comparisons at K1 and θ_N=9% Baseline had many exclusive false positives (e.g., 2,215 exclusive FPs vs DabLog's 425 exclusive FPs).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td>n/a (this is the baseline).</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Fundamental limitation: predictors use only past context Pr(x_t | x_{<t}) and therefore cannot exploit bidirectional causality; they make forced guesses early in sequences (cold-start), causing many false positives for rare-but-normal events and false negatives for structurally abnormal sequences that require future context; top-N rank criteria used in prior work can be too coarse for larger vocabularies and lead to misleadingly high accuracy if vocab is small.</td>
                        </tr>
                        <tr>
                            <td><strong>unique_insights</strong></td>
                            <td>Predictor-based approaches are effectively detecting rare next-events but can conflate rarity with abnormality; their effectiveness falls when vocabulary size grows and when anomalies are structural rather than single-event deviations.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Recompose Event Sequences vs. Predict Next Events: A Novel Anomaly Detection Approach for Discrete Event Logs', 'publication_date_yy_mm': '2021-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9291.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e9291.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>DeepLog</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Deeplog: Anomaly detection and diagnosis from system logs through deep learning</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Prior work that inspired predictor-based anomaly detection for logs: uses a two-layer LSTM to predict next log keys from one-hot encoded events and flags anomalies when true next event not in top-N predictions.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Deeplog: Anomaly detection and diagnosis from system logs through deep learning</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>DeepLog</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>Stacked LSTM predictor</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>two-layer LSTM (exact hidden unit counts in original paper; in this paper DeepLog referenced as two-layer)</td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>categorical discrete event sequences (system logs)</td>
                        </tr>
                        <tr>
                            <td><strong>data_domain</strong></td>
                            <td>system console logs (HDFS cited in comparisons)</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>next-event anomalies / rare event detection</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Predict next log-key using a two-layer LSTM over one-hot encoded events; use top-N rank-based criterion on predicted softmax to label anomalies.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_methods</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>accuracy, top-N hit rates, (in literature) precision/recall</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>One-hot encoding causes dimension explosion for large vocabularies; top-N criterion can be overly coarse (previous work used top-9 out of 28 keys which covered almost entire distribution), and relying on past-only context leads to cold-start guessing and inability to detect structural anomalies.</td>
                        </tr>
                        <tr>
                            <td><strong>unique_insights</strong></td>
                            <td>Used as a motivating example in this paper to show limits of next-event predictors when vocabularies grow and when sequence structure matters.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Recompose Event Sequences vs. Predict Next Events: A Novel Anomaly Detection Approach for Discrete Event Logs', 'publication_date_yy_mm': '2021-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9291.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e9291.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>nLSALog</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>nLSALog: An anomaly detection framework for log sequence in security management</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A related predictor-based framework referenced by the paper that uses stacked LSTMs, embedding and self-attention to predict upcoming log events for anomaly detection.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>nlsalog: An anomaly detection framework for log sequence in security management</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>nLSALog</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>Stacked LSTM predictor with self-attention</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>n-layer stacked LSTM (exact configuration in original paper); uses embedding and self-attention components</td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>categorical discrete event sequences (system/security logs)</td>
                        </tr>
                        <tr>
                            <td><strong>data_domain</strong></td>
                            <td>system logs / security management contexts</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>next-event / sequence anomalies detected via prediction</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Embedding layer + stacked LSTM encoder with self-attention used to predict future event keys; anomalies detected when predictions deviate from true next events under top-N or threshold criterions.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_methods</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Shares conceptual limitations of predictor-based approaches highlighted in the paper: reliance on past-only context, top-N criteria sensitivity, and potential issues scaling to larger vocabularies.</td>
                        </tr>
                        <tr>
                            <td><strong>unique_insights</strong></td>
                            <td>Example of more complex predictor architectures (attention, deeper stacks) but still constrained by predictor methodology limits discussed in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Recompose Event Sequences vs. Predict Next Events: A Novel Anomaly Detection Approach for Discrete Event Logs', 'publication_date_yy_mm': '2021-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9291.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e9291.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LSTM autoencoder (generic)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>LSTM encoder-decoder autoencoder for sequence reconstruction</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>General architecture where a recurrent LSTM encoder compresses a variable-length sequence into a fixed-length code and an LSTM decoder reconstructs the sequence, used here for time-sensitive anomaly detection by measuring reconstruction mismatch.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>LSTM autoencoder</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>Encoder-decoder recurrent neural network (LSTM)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>stacked LSTM encoder/decoder; paper uses 2 layers each for DabLog (encoder 64/32, decoder 32/64)</td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>time-sensitive categorical sequences (discrete event logs)</td>
                        </tr>
                        <tr>
                            <td><strong>data_domain</strong></td>
                            <td>system logs (HDFS) and potentially other time-sensitive discrete event domains</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>sequence-reconstruction anomalies (poorly reconstructed sequences → anomalous), including rare/unseen events and structural anomalies</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Train autoencoder on normal sequences so it learns compact representations of normal sequence structure; at test time, reconstruct and compare reconstructed categorical distributions to true events via classifier+critic to decide anomalies.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_methods</strong></td>
                            <td>Standard autoencoders for time-insensitive data, predictor-based LSTM models (for comparison)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>reconstruction-based anomaly scores (here implemented as rank-based / thresholded classifier outputs), F1, precision, recall, AUROC</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>Used as core of DabLog; performance results reported under DabLog entries (e.g., F1 up to 97.18% on K1).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td>Sequence-reconstruction (autoencoder) produced better F1 and precision than predictor baselines for the evaluated HDFS experiments, especially with larger vocabularies.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Autoencoders must be forced (via limited hidden capacity and training only on normal data) to learn meaningful abstractions; unconditional decoding chosen here for autoencoder suitability but other variants exist; direct scalar reconstruction errors (RMS) are less suitable for discrete-key sequences, requiring classification+critic.</td>
                        </tr>
                        <tr>
                            <td><strong>unique_insights</strong></td>
                            <td>Applying LSTM autoencoders to time-sensitive discrete event logs (not just time-insensitive data) is effective when combined with an event classifier and a critic, enabling detection of structural anomalies that next-event predictors miss.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Recompose Event Sequences vs. Predict Next Events: A Novel Anomaly Detection Approach for Discrete Event Logs', 'publication_date_yy_mm': '2021-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Deeplog: Anomaly detection and diagnosis from system logs through deep learning <em>(Rating: 2)</em></li>
                <li>nlsalog: An anomaly detection framework for log sequence in security management <em>(Rating: 2)</em></li>
                <li>Recurrent neural network attention mechanisms for interpretable system log anomaly detection <em>(Rating: 2)</em></li>
                <li>Dream: Deep recursive attentive model for anomaly detection in kernel events <em>(Rating: 1)</em></li>
                <li>Hierarchical attentionbased anomaly detection model for embedded operating systems <em>(Rating: 1)</em></li>
                <li>Deeplog: Anomaly detection and diagnosis from system logs through deep learning <em>(Rating: 2)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-9291",
    "paper_id": "paper-235337585",
    "extraction_schema_id": "extraction-schema-162",
    "extracted_data": [
        {
            "name_short": "DabLog",
            "name_full": "Deep Autoencoder-Based anomaly detection method for discrete event Logs",
            "brief_description": "An LSTM-based sequence-reconstruction anomaly detector that treats each discrete event sequence as an atomic instance: it embeds events, encodes the full sequence with a stacked LSTM autoencoder, decodes to a reconstructed categorical distribution, classifies per-event logits, and applies a critic (rank- or threshold-based) to decide sequence-level anomalies.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "DabLog",
            "model_type": "LSTM autoencoder (stacked recurrent encoder-decoder)",
            "model_size": "Encoder: 2 LSTM layers (64, 32 hidden units); Decoder: 2 LSTM layers (32, 64 hidden units); embedding dimension unspecified",
            "data_type": "categorical discrete event sequences (time-sensitive sequential logs)",
            "data_domain": "system console logs (HDFS dataset used in experiments); also reported results on traffic logs in abstract",
            "anomaly_type": "sequence-level anomalies including structural anomalies, rare/unseen events, and causality-violating sequences (time-sensitive anomalies)",
            "method_description": "Train an embedding layer for event keys; use a stacked LSTM encoder to produce a representation code and a stacked LSTM decoder to reconstruct the sequence (reverse order). Feed decoder logits to a softmax event classifier to obtain per-time-step categorical probabilities. A critic flags a sequence abnormal if any event's true key is not among top-N reconstructed probabilities or below a probability threshold; authors also propose future rank-distance (embedding-aware) double-thresholds.",
            "baseline_methods": "Predictor-based LSTM next-event models (re-implemented 'Baseline' similar to DeepLog/nLSALog), trivial frequency top-N heuristic, and conventional autoencoders for time-insensitive data (discussed in related work).",
            "performance_metrics": "Precision, Recall, F1 score, False-positive rate, Accuracy, Area Under ROC (AUROC)",
            "performance_results": "On HDFS-derived key sets: K1 (101 keys) DabLog peak F1 = 97.18% at normalized rank threshold θ_N = 9%; DabLog (5K training) peak F1 = 95.20% at θ_N = 27%. K2 (304 keys) DabLog peak F1 = 94.15% at θ_N = 6%. Reported AUROC: K0 99.49%, K1 99.44%, K2 99.08%. Paper also reports (abstract) DabLog produced 1,790 fewer FPs and 1,982 more TPs than the predictor baseline on HDFS with 101 distinct events, and 2,419 fewer FPs with trade-off of 83 fewer TPs on traffic logs with 706 distinct events.",
            "comparison_to_baseline": "DabLog substantially outperforms predictor-based baseline in F1 and precision on the evaluated HDFS experiments (example: on K1, DabLog 97.18% F1 vs Baseline 87.32% F1 at their peaks), producing far fewer false positives while often producing more true positives; improvements are larger for larger vocabularies (more distinct event keys).",
            "limitations_or_failure_cases": "Current critic options (rank-based or simple threshold) ignore embedding-neighborhood correlations and can misclassify near-tied probabilities; OOV (out-of-vocabulary) / unknown event keys are a problem because embedding is learned only for training keys; the rank-based critic's behavior depends on vocabulary size and training coverage (models trained with small training sets may artificially appear to perform well under coarse rank thresholds); requires datasets with reconstructable sequential relationships (some public security datasets lack low-level events and are unsuitable); computational cost of training embedding + LSTM autoencoder not extensively profiled.",
            "unique_insights": "Reconstructing entire discrete sequences (autoencoder) leverages bidirectional causality (past and future context) and sequence structure, avoiding the 'cold-start' guessing of next-event predictors and reducing both false positives and false negatives; training a dedicated event embedding is preferable to one-hot or off-the-shelf word embeddings for security logs; framing anomaly detection as sequence reconstruction + classification (embed-encode-decode-classify-critic) is a novel and effective alternative to next-event prediction for time-sensitive discrete logs.",
            "uuid": "e9291.0",
            "source_info": {
                "paper_title": "Recompose Event Sequences vs. Predict Next Events: A Novel Anomaly Detection Approach for Discrete Event Logs",
                "publication_date_yy_mm": "2021-05"
            }
        },
        {
            "name_short": "Baseline (predictor)",
            "name_full": "Reimplemented predictor-based anomaly detection model (DeepLog-like)",
            "brief_description": "A reimplementation representative of predictor-based LSTM anomaly detectors: uses an embedding layer, a two-layer stacked LSTM to predict the next event (single-event predictor), a softmax classifier and a rank-based critic (top-N) to mark anomalies when predictions do not include the true next event.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "Baseline (predictor, DeepLog-like)",
            "model_type": "Stacked LSTM predictor (recurrent)",
            "model_size": "2 LSTM layers with 64 hidden units each (as implemented in this paper's baseline)",
            "data_type": "categorical discrete event sequences (time-sensitive logs), single-event prediction per sliding window",
            "data_domain": "system console logs (HDFS dataset used in experiments)",
            "anomaly_type": "anomalous next-events (rare/unexpected events), but misses structure-level anomalies",
            "method_description": "Embed sequence (learned embedding), feed prefix into stacked LSTM predictor to produce next-event softmax probabilities; mark the sequence anomalous if the true next event is not in top-N predicted keys (rank-based) or its probability is below a threshold.",
            "baseline_methods": "Compared against DabLog (LSTM autoencoder) and trivial frequency model in the paper.",
            "performance_metrics": "Precision, Recall, F1, FP rate, Accuracy, AUROC",
            "performance_results": "On K1 (101 keys) Baseline peak F1 = 87.32% at θ_N = 10% (paper's reimplementation); Baseline (5K) peak F1 = 94.98% at θ_N = 31% for smaller training set; AUROC reported in Table III: Baseline 97.23% for K1 (and other values for other key sets). In specific case comparisons at K1 and θ_N=9% Baseline had many exclusive false positives (e.g., 2,215 exclusive FPs vs DabLog's 425 exclusive FPs).",
            "comparison_to_baseline": "n/a (this is the baseline).",
            "limitations_or_failure_cases": "Fundamental limitation: predictors use only past context Pr(x_t | x_{&lt;t}) and therefore cannot exploit bidirectional causality; they make forced guesses early in sequences (cold-start), causing many false positives for rare-but-normal events and false negatives for structurally abnormal sequences that require future context; top-N rank criteria used in prior work can be too coarse for larger vocabularies and lead to misleadingly high accuracy if vocab is small.",
            "unique_insights": "Predictor-based approaches are effectively detecting rare next-events but can conflate rarity with abnormality; their effectiveness falls when vocabulary size grows and when anomalies are structural rather than single-event deviations.",
            "uuid": "e9291.1",
            "source_info": {
                "paper_title": "Recompose Event Sequences vs. Predict Next Events: A Novel Anomaly Detection Approach for Discrete Event Logs",
                "publication_date_yy_mm": "2021-05"
            }
        },
        {
            "name_short": "DeepLog",
            "name_full": "Deeplog: Anomaly detection and diagnosis from system logs through deep learning",
            "brief_description": "Prior work that inspired predictor-based anomaly detection for logs: uses a two-layer LSTM to predict next log keys from one-hot encoded events and flags anomalies when true next event not in top-N predictions.",
            "citation_title": "Deeplog: Anomaly detection and diagnosis from system logs through deep learning",
            "mention_or_use": "mention",
            "model_name": "DeepLog",
            "model_type": "Stacked LSTM predictor",
            "model_size": "two-layer LSTM (exact hidden unit counts in original paper; in this paper DeepLog referenced as two-layer)",
            "data_type": "categorical discrete event sequences (system logs)",
            "data_domain": "system console logs (HDFS cited in comparisons)",
            "anomaly_type": "next-event anomalies / rare event detection",
            "method_description": "Predict next log-key using a two-layer LSTM over one-hot encoded events; use top-N rank-based criterion on predicted softmax to label anomalies.",
            "baseline_methods": null,
            "performance_metrics": "accuracy, top-N hit rates, (in literature) precision/recall",
            "performance_results": null,
            "comparison_to_baseline": null,
            "limitations_or_failure_cases": "One-hot encoding causes dimension explosion for large vocabularies; top-N criterion can be overly coarse (previous work used top-9 out of 28 keys which covered almost entire distribution), and relying on past-only context leads to cold-start guessing and inability to detect structural anomalies.",
            "unique_insights": "Used as a motivating example in this paper to show limits of next-event predictors when vocabularies grow and when sequence structure matters.",
            "uuid": "e9291.2",
            "source_info": {
                "paper_title": "Recompose Event Sequences vs. Predict Next Events: A Novel Anomaly Detection Approach for Discrete Event Logs",
                "publication_date_yy_mm": "2021-05"
            }
        },
        {
            "name_short": "nLSALog",
            "name_full": "nLSALog: An anomaly detection framework for log sequence in security management",
            "brief_description": "A related predictor-based framework referenced by the paper that uses stacked LSTMs, embedding and self-attention to predict upcoming log events for anomaly detection.",
            "citation_title": "nlsalog: An anomaly detection framework for log sequence in security management",
            "mention_or_use": "mention",
            "model_name": "nLSALog",
            "model_type": "Stacked LSTM predictor with self-attention",
            "model_size": "n-layer stacked LSTM (exact configuration in original paper); uses embedding and self-attention components",
            "data_type": "categorical discrete event sequences (system/security logs)",
            "data_domain": "system logs / security management contexts",
            "anomaly_type": "next-event / sequence anomalies detected via prediction",
            "method_description": "Embedding layer + stacked LSTM encoder with self-attention used to predict future event keys; anomalies detected when predictions deviate from true next events under top-N or threshold criterions.",
            "baseline_methods": null,
            "performance_metrics": null,
            "performance_results": null,
            "comparison_to_baseline": null,
            "limitations_or_failure_cases": "Shares conceptual limitations of predictor-based approaches highlighted in the paper: reliance on past-only context, top-N criteria sensitivity, and potential issues scaling to larger vocabularies.",
            "unique_insights": "Example of more complex predictor architectures (attention, deeper stacks) but still constrained by predictor methodology limits discussed in this paper.",
            "uuid": "e9291.3",
            "source_info": {
                "paper_title": "Recompose Event Sequences vs. Predict Next Events: A Novel Anomaly Detection Approach for Discrete Event Logs",
                "publication_date_yy_mm": "2021-05"
            }
        },
        {
            "name_short": "LSTM autoencoder (generic)",
            "name_full": "LSTM encoder-decoder autoencoder for sequence reconstruction",
            "brief_description": "General architecture where a recurrent LSTM encoder compresses a variable-length sequence into a fixed-length code and an LSTM decoder reconstructs the sequence, used here for time-sensitive anomaly detection by measuring reconstruction mismatch.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "LSTM autoencoder",
            "model_type": "Encoder-decoder recurrent neural network (LSTM)",
            "model_size": "stacked LSTM encoder/decoder; paper uses 2 layers each for DabLog (encoder 64/32, decoder 32/64)",
            "data_type": "time-sensitive categorical sequences (discrete event logs)",
            "data_domain": "system logs (HDFS) and potentially other time-sensitive discrete event domains",
            "anomaly_type": "sequence-reconstruction anomalies (poorly reconstructed sequences → anomalous), including rare/unseen events and structural anomalies",
            "method_description": "Train autoencoder on normal sequences so it learns compact representations of normal sequence structure; at test time, reconstruct and compare reconstructed categorical distributions to true events via classifier+critic to decide anomalies.",
            "baseline_methods": "Standard autoencoders for time-insensitive data, predictor-based LSTM models (for comparison)",
            "performance_metrics": "reconstruction-based anomaly scores (here implemented as rank-based / thresholded classifier outputs), F1, precision, recall, AUROC",
            "performance_results": "Used as core of DabLog; performance results reported under DabLog entries (e.g., F1 up to 97.18% on K1).",
            "comparison_to_baseline": "Sequence-reconstruction (autoencoder) produced better F1 and precision than predictor baselines for the evaluated HDFS experiments, especially with larger vocabularies.",
            "limitations_or_failure_cases": "Autoencoders must be forced (via limited hidden capacity and training only on normal data) to learn meaningful abstractions; unconditional decoding chosen here for autoencoder suitability but other variants exist; direct scalar reconstruction errors (RMS) are less suitable for discrete-key sequences, requiring classification+critic.",
            "unique_insights": "Applying LSTM autoencoders to time-sensitive discrete event logs (not just time-insensitive data) is effective when combined with an event classifier and a critic, enabling detection of structural anomalies that next-event predictors miss.",
            "uuid": "e9291.4",
            "source_info": {
                "paper_title": "Recompose Event Sequences vs. Predict Next Events: A Novel Anomaly Detection Approach for Discrete Event Logs",
                "publication_date_yy_mm": "2021-05"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Deeplog: Anomaly detection and diagnosis from system logs through deep learning",
            "rating": 2,
            "sanitized_title": "deeplog_anomaly_detection_and_diagnosis_from_system_logs_through_deep_learning"
        },
        {
            "paper_title": "nlsalog: An anomaly detection framework for log sequence in security management",
            "rating": 2,
            "sanitized_title": "nlsalog_an_anomaly_detection_framework_for_log_sequence_in_security_management"
        },
        {
            "paper_title": "Recurrent neural network attention mechanisms for interpretable system log anomaly detection",
            "rating": 2,
            "sanitized_title": "recurrent_neural_network_attention_mechanisms_for_interpretable_system_log_anomaly_detection"
        },
        {
            "paper_title": "Dream: Deep recursive attentive model for anomaly detection in kernel events",
            "rating": 1,
            "sanitized_title": "dream_deep_recursive_attentive_model_for_anomaly_detection_in_kernel_events"
        },
        {
            "paper_title": "Hierarchical attentionbased anomaly detection model for embedded operating systems",
            "rating": 1,
            "sanitized_title": "hierarchical_attentionbased_anomaly_detection_model_for_embedded_operating_systems"
        },
        {
            "paper_title": "Deeplog: Anomaly detection and diagnosis from system logs through deep learning",
            "rating": 2,
            "sanitized_title": "deeplog_anomaly_detection_and_diagnosis_from_system_logs_through_deep_learning"
        }
    ],
    "cost": 0.0176445,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Recomposition vs. Prediction: A Novel Anomaly Detection for Discrete Events Based On Autoencoder</p>
<p>Lun-Pin Yuan 
Penn State University
Penn State University
Penn State University</p>
<p>Peng Liu pliu@ist.psu.edu 
Penn State University
Penn State University
Penn State University</p>
<p>Sencun Zhu 
Penn State University
Penn State University
Penn State University</p>
<p>Recomposition vs. Prediction: A Novel Anomaly Detection for Discrete Events Based On Autoencoder</p>
<p>One of the most challenging problems in the field of intrusion detection is anomaly detection for discrete event logs. While most earlier work focused on applying unsupervised learning upon engineered features, most recent work has started to resolve this challenge by applying deep learning methodology to abstraction of discrete event entries. Inspired by natural language processing, LSTM-based anomaly detection models were proposed. They try to predict upcoming events, and raise an anomaly alert when a prediction fails to meet a certain criterion. However, such a predict-next-event methodology has a fundamental limitation: event predictions may not be able to fully exploit the distinctive characteristics of sequences. This limitation leads to high false positives (FPs) and high false negatives (FNs). It is also critical to examine the structure of sequences and the bi-directional causality among individual events. To this end, we propose a new methodology: Recomposing event sequences as anomaly detection. We propose DabLog, a LSTM-based Deep Autoencoder-Based anomaly detection method for discrete event Logs. The fundamental difference is that, rather than predicting upcoming events, our approach determines whether a sequence is normal or abnormal by analyzing (encoding) and reconstructing (decoding) the given sequence. Our evaluation results show that our new methodology can significantly reduce the numbers of FPs and FNs, hence achieving a higher F1 score.</p>
<p>I. INTRODUCTION</p>
<p>One of the most challenging problems in the field of intrusion detection is anomaly detection for discrete event logs. Researchers have been trying to resolve this challenge for two decades, and most work have focused on applying unsupervised learning upon engineered features from normal data, assuming unforeseen anomalies do not follow the learned normal patterns (e.g., [27], [33], [25], [35], [29], [38], [3], [36], [31], [32]). Recently, solving this challenge with deep learning has gained a substantial amount of traction in the security community (e.g., [15], [6], [17], [16], [47]), partially due to the unique advantages of deep learning in natural language processing. Researchers have applied related languageprocessing methodologies to anomaly detection for discrete event logs by treating discrete events as words and logs as sentences, as if linguistic causality exists in the security logs. The main benefit of this approach over machine learning upon engineered features is that detail domain knowledge, complex feature extraction, and costly human interference are no longer required (e.g., [32], [48], [42], [30], [13]).</p>
<p>Inspired by natural language processing, Long Short Term Memory (LSTM) [24] based anomaly detection models (e.g., [15], [6], [17], [16], [47]) were proposed. These models try to predict upcoming log events, and they raise an anomaly alert when a prediction fails to meet a certain criterion. However, we found that the widely-adopted methodology "using an LSTM-based model in predicting next events" has a fundamental limitation: event predictions may not be able to fully exploit the distinctive characteristics of sequences. To be specific, event-prediction methodology assumes the distribution of an event is affected only by the prior events before it (e.g., when a model sees an open fileoperation, it can guess such open operation is followed by read operations); however, the distribution can also be affected by later events (e.g., when a model sees a read operation, it should examine whether it has seen any open operation) or no events whatsoever (e.g., an event may have nothing to do with the other events). Therefore, an anomaly detection method should also look deeper into the sequential structure and the bidirectional causality among events. Because of this limitation, the widely adopted methodology could lead to numerous false positives (FPs) and false negatives (FNs).</p>
<p>Examples why the methodology could lead to FPs and FNs are illustrated as follows. For FP example, consider a normal sequence of file operations [open A, read A, read A] and an upcoming event open B. By seeing just the first few operations, a predictor-based anomaly detection model may guess the upcoming event to be read A, because (1) it is one of the most frequent events that follow open A in the training dataset while open B is less frequent, and (2) the first few operations does not enclose prior knowledge which indicates B will be soon opened; consequently, the predictor-based model may wrongly report the sequence as abnormal, although in reality it is also normal but less common. The fundamental issue is that, when little necessary knowledge is available in a sequence (regardless of sequence length), predictor-based anomaly detection always has to make bold guesses. For FN example, consider an abnormal sequence of file operations [read A, read A, close A] and an upcoming event read A. If the predictor-based model does not examine whether there is any open A before the upcoming read A, it may consider this sequence normal, hence a false negative.</p>
<p>To address the fundamental limitation of not being able to fully exploit the distinctive characteristics of sequences, we propose a different methodology: using an LSTM autoencoder in recomposing sequences. Compared to the existing methodology, the fundamental difference is that our LSTM autoencoder determines whether a sequence is normal or abnormal by analyzing (encoding) and reconstructing (decoding) the given sequence rather than predicting upcoming individual events. The intuition is that an anomaly detection method should see a sequence as an atomic instance, and it should examine the structure of the sequence as well as the bidirectional causality among the events. Hence, our anomaly detection model can detect not only sequences that include unseen or rare events, but also structurally abnormal sequences. Note that, our model is more than a standard autoencoder which reconstructs input input vectors. To work with discrete events, our solution is designed as an embed-encode-decodeclassify-critic model.</p>
<p>In this work, we propose DabLog, a Deep Autoencoder-Based anomaly detection method for discrete event Logs. DabLog aims to provide an anomaly detection function AD : S → {normal, abnormal}. DabLog consists of four major components ( Figure 2): an embedding layer, a deep LSTM autoencoder, an event classifier, and an anomaly critic. Our evaluation results show that the new methodology can significantly reduce the number of FPs, while achieving a better F 1 score. Compared to our predictor-based baseline model, DabLog reports 1,790 less FPs but 1,982 more TPs in our evaluation upon HDFS console logs with 101 distinct events, and DabLog reports 2,419 less FPs with trade-off 83 less TPs in our evaluation upon traffic logs with 706 distinct events. Specifically, we make the following contributions.</p>
<p>1) Through in-depth FP and FN case studies, we discover a fundamental limitation of predictor-based models. We resolve this limitation by proposing a deep autoencoder-based anomaly detection method for discrete event logs. 2) We evaluate DabLog upon HDFS console-log dataset, and our results show that DabLog outperforms our reimplemented predictor-based baseline model in terms of F 1 score. DabLog achieves 97.18% F 1 scores in evaluation with 101 distinct events, while our baseline model achieves only 87.32% F 1 scores. 3) To the best of our knowledge, we are the first to show that autoencoders can effectively serve the purpose of detecting time-sensitive anomalies in discrete event logs with contexts that involves more distinct events, while the common practice is to apply predictors to time-sensitive data with fewer distinct events and to apply autoencoders to time-insensitive data.</p>
<p>The rest of this paper is organized as follows. Section II outlines related work in the anomaly detection literature. Section III introduces background knowledge to encoderdecoder networks. Section IV states our motivation and a motivating example. Section V details our DabLog design. Section VI shows our evaluation results and case studies. Section VII discusses a few limitations and future work. Lastly, Section VIII concludes this paper.</p>
<p>II. RELATED WORK</p>
<p>Most anomaly detection methods are zero-positive machine learning models that are trained by only normal (i.e., negative) data and then used in testing whether observation data is normal or abnormal, assuming unforeseen anomalies do not follow the learned normal patterns. For example, Kenaza et al. [27] integrated supports vector data description and clustering algorithms, and Liuq et al. [33] integrated Kprototype clustering and k-NN classification algorithms to detect anomalous data points, assuming anomalies are rare or accidental events. When prior domain knowledge is available for linking causal or dependency relations among subjects and objects and operations, graph-based anomaly detection methods (such as Elicit [35], Log2Vec [29], Oprea et al. [38]) could be powerful. When little prior domain knowledge is available, Principal Component Analysis (PCA) based anomaly detection methods (for example, Hu et al. [25] proposed an anomaly detection model for heterogeneous logs using singular value decomposition) could be powerful. Oppositions to zero-positive anomaly detection are semi-supervised or online learning anomaly detection, in which some anomalies will be available over time [14].</p>
<p>Autoencoder framework is another PCA approach that is widely used in anomaly detection. Briefly speaking, a typical autoencoder-based anomaly detection method learns how to reconstruct normal data, and it detects anomalies by checking whether the reconstruction error of a data point has exceeded a threshold. To detect anomalies, Zong et al. [50] proposed deep autoencoding Gaussian mixture models, Chiba et al. [11] proposed autoencoders with back propagation, Sakurada and Yairi [41] proposed autoencoders with nonlinear dimensionality reduction, Lu et al. proposed MC-AEN [34] which is an autoencoder which is constrained by embedding manifold learning, Nguyen et al. proposed GEE [37] which is a variational autoencoder with gradient-based anomaly explanation, Wang et al. proposed adVAE [44] which is a self-adversarial variational autoencoder with Gaussian anomaly prior assumption, Alam et al. proposed AutoPerf [3] which is an ensemble of autoencoders accompanied by K-mean clustering algorithm, Mirsky et al. proposed Kitsune [36] which is an ensemble of lightweight autoencoders, Liu et al. [31], [32] proposed an ensemble of autoencoders for multi-sourced heterogeneous logs, and Chalapathy et al. [9] and Zhou et al. [49] proposed robust autoencoders.</p>
<p>The above anomaly detection methods only work with time-insensitive data (i.e., each data point is independent of the other data points). To work with time-sensitive data (i.e., dependencies exist among data points), researchers have leveraged Long Short-Term Memory (LSTM) [24] in building anomaly detection models. LSTM has been widely used in learning sequences, and LSTM-based deep learning has been widely used to extract patterns from massive data. Since most cyber operations are sequential (e.g., as in timestamped audit logs), LSTM-based deep learning has great potential in serving anomaly detection applications. Inspired by natural language processing, Deeplog [15], Brown et al. [6], DReAM [17], HAbAD [16], and nLSALog [47] were proposed to build LSTM-based multi-class classifier in order to predict future log entries. We summarize these LSTM-based methods in the next section; for other anomaly detection methods, surveys and comparisons can be found in [4], [8], [18], [10], [7], [19], [22].</p>
<p>III. BACKGROUND KNOWLEDGE</p>
<p>To understand our approach, some background knowledge on Deep LSTM Encoder-Decoder Network is essential. Cho et al. [12] proposed an LSTM encoder-decoder network for statistical machine translation. Both encoder and decoder are recurrent networks. An encoder φ takes a variable-length input 
sequence X = [x 1 , x 2 , x 3 , . .
. , x T ] of length T and generates a brief fixed-length representation code (also commonly referred to as the representation or the code) of X, and the encoding operation is denoted as code = φ(X)). A decoder ψ then takes the representation code and generates a variable-length target sequence Y = [y 1 , y 2 , y 3 , . . . , y T ] of length T , and the decoding operation is denoted as Y = ψ(code) = (ψ • φ)(X). Depending on the application, X and Y may have different lengths. Srivastava et al. [43] summarized three types of LSTM encoder-decoder networks for unsupervised learning models. 1) Autoencoder: The goal of an autoencoder is to enclose into the representation code all needed to reconstruct the same sequence. An autoencoder takes an input sequence X = [x 1 , x 2 , x 3 , . . . , x T ] and tries to reconstruct the target sequenceŶ 1 = [x T , x T −1 , x T −2 , . . . , x 1 ]. Note that the target sequence is in the reverse order, as if the encoder recurrently encodes (pushes) x t into the representation code, whereas the decoder recurrently decodes (pops) x t from the code. 2) Predictor: The goal of a predictor is to predict future sequence based on what it has observed. The representation code plays the role of an internal hidden state. A predictor takes the input sequence X = [x 1 , x 2 , x 3 , . . . , x T ] and tries to predict the tar-
get sequenceŶ 2 = [x T +1 , x T +2 , x T +3 , . . . , x T +T ].
If T = 1, then it is a single-event predictor. 3) Composite: Merging the above two models, a composite model tries to reconstruct-
predictŶ 3 = [Ŷ 1 ,Ŷ 2 ].
Each LSTM encoder-decoder network listed above can be conditional or unconditional, depending on whether the truê y τ (condition) is provided to the decoder (as an additional input) when the decoder tries to decode y τ +1 . In an autoencoder, y τ = x T −τ +1 , whereas in a predictorŷ τ = x T +τ .</p>
<p>The time-sensitive anomaly detection models for discrete event logs, mentioned in Section II, are predictors. These predictors typically consider an upcoming event x T +τ normal if the probability Pr(x T +τ |x 1 , x 2 , . . . , x T +τ −1 ) is within a threshold (or alternatively x T +τ is within the top-N predic-tion); otherwise abnormal. Specifically, DeepLog [15] leverages a two-layer LSTM network that works on one-hot representation of log entries. Brown et al. [6] leverages bidirectional LSTM, word embedding, and five attention mechanisms. Both HAbAD [16] and DReAM [17] build an embed-encoderattention-decoder framework. nLSALog [47] leverages n-layer stacked LSTM, embedding layer, and self-attention mechanism. Some of the above models further incorporate an embedding layer (here embedding is a learned representation of log entries) in their encoders in order to include correlation among log entries, and some incorporate an attention layer (here attention is an aggregated state of hidden states from each time-step or each neuron) in their decoders in order to improve prediction accuracy.</p>
<p>Predictors and autocoders have been extensively studied for time-sensitive anomaly detection, and for time-insensitive anomaly detection, respectively. However, to our best knowledge, whether autoencoders can serve time-sensitive anomaly detection have not yet been investigated until this work. Conceptually, an LSTM autoencoder is essentially trying to learn the identity function of the input data distribution. Such identity function will definitely fail to fit every input data because, at high-level, there are only a fixed number of hidden units at each layer (in both encoder and decoder) and thus very unlikely they can learn everything needed for reconstruction. Moreover, hidden states (e.g., h i j and h i j in Figure 1) and representation codes are too small to enclose detail information of the input data. Based on these constraints, autoencoders are forced to learn more meaningful concepts and relationships inside the input data. Trained with only normal input, autoencoders can be used in detecting anomalies in case of poor reconstruction.</p>
<p>IV. MOTIVATION</p>
<p>We define an anomaly detection function for discrete events as AD : S → {normal, abnormal}, where a sequence of events S = [e t |1 ≤ t ≤ T ] ∈ S is essentially a set of relevant events (e.g., events of the same subject) sorted by timestamps (e.g., from past to present). Each discrete event e t is represented by a distinct event key k i ∈ K, which is a string template. Distinct event keys are referred to as logkey in DeepLog [15], log template in nLSALog [47], and discrete keys in Du et al. [14]'s work.</p>
<p>Among the aforementioned related work, we find DeepLog [15] and nLSALog [47] representative of predictorbased anomaly detection methods. They are similar predictors that predict only single upcoming event e T +1 for each slidingwindow subsequence s T = [e t |max(1, T −9) ≤ t ≤ T ], whose window size |s T | is at most ten (we refer this configuration to as seqlen = 10). They consider S anomalous if any prediction e T +1 ∈ S is not an instance of event key k j ∈ K in its top-9 predictions out of 28 event keys, or equivalently top-32% predictions. Both methods were evaluated upon the same HDFS dataset [46], [45] and seemed promising based on accuracy = (T P + T N )/(T P + F N + F P + T N ). .</p>
<p>Single-event prediction, however, is not an ideal solution for sequence-based anomaly detection AD : S → {normal, abnormal}. Typical anomaly detection methods are based on the variance of an instance, or equivalently the error from particular expectation of an instance. In our context, the instances are the sequences S ∈ S, and hence intuitively we should consider an individual sequence S as an atomic instance. Yet, by examining whether an individual event e T +1 ∈ S is in top-N expectation based on prior events, single-event prediction obviously considers the individual event e T +1 as an atomic instance. As such, it seems to us that single-event prediction is more like anomalous event detection, or somewhat rare event detection considering their configuration setup. The problem is twofold. On one hand, a rare event does not necessarily make the event itself or the sequence abnormal, and hence wrongly reporting rare events as abnormal will cause more FPs (a case study is provided below). On the other hand, the absence of abnormal events does not necessarily makes the sequence normal. That is, a sequence without abnormal events can still be structurally abnormal; therefore, not checking sequential structure may cause more FNs (a case study is provided in Section VI). Based on the above observations, it is important to examine the structure of a sequence (and even to reconstruct it) as well as its bidirectional causality, and in fact by doing so one can expect significantly less FPs and FNs (details are in Section VI).</p>
<p>A. Motivating Example: FP Case Study</p>
<p>We are particularly interested in how predictor-based approach can be applied to scenarios where finer grained prediction is required and more event keys are involved. As opposed to the criterion of top-32% predictions out of |K| = 28 keys, our criterion top-9% out of |K 1 | = 101 keys is more reasonable, and the reasons are detailed in the next subsection. We re-implement a predictor-based anomaly detection model (referred to as the Baseline model, details in Section VI), which is similar to that in DeepLog [15] and nLSALog [47]. By applying our Baseline model upon our re-crafted key set K 1 , we find many false positive cases. We use the following FP case (session ID: -3547984959929874282) to motivate our autoencoder-based anomaly detection.</p>
<p>This normal session has in total 25 events, and Baseline reports the fifth event e 5 as an abnormal event. The first four events are in the subsequence s 4 = [k 1 , k 2 , k 2 , k 2 ], and the fifth event is e 5 = k 3 , where k 1 = "allocatedBlock ...", k 2 = "Receiving block within the localhost", and k 3 = "Received block of size 20-30 MB from 10.250. * ". The first ten events are listed in Table I. To the Baseline model, e 5 = k 3 is abnormal because k 3 is not within the top-9% predictions for e 5 . Top-9% predictions include variants of k 4 = "addStoredBlock: blockMap updated ...", k 5 = "block terminating", and k 6 = "Received block of size 60-70 MB from 10.251. * ". We can easily tell that both k 3 and k 6 are variants of "Received block of size * from * ". In fact, the corresponding embedded vectors E(k 3 ) and E(k 6 ) are close to each other in the hyper-dimensional universe U, meaning that their concepts are similar in Baseline's point of view.</p>
<p>However, the fact that k 3 is not in top-9% but at top-63% causes this FP. The fundamental problem is that, without the pre-knowledge of the block size-interval information for this specific session, by seeing just s 4 = [k 1 , k 2 , k 2 , k 2 ], Baseline would rather guess "60-70 MB" as the block size, as it has learned through training that k 6 is a very frequent key (dominating 10.77% of the entire dataset), whereas k 3 is actually Received block of size 20-30 MB from 10.251. * an extremely rare event (only dominating 0.05%). This is similar to the cold-start problem in a recommendation system, where, not knowing personal preference, a recommendation system often recommends new users with most popular products among others. Here, a predictor-based anomaly detection method always has to make a few bold guesses at the beginning of any sequence for the lack of information, and this issue cannot be mitigated by providing more training data (details in Section VI). Manipulating sequence length (seqlen) cannot resolve this issue either. As long as the sequence does not include critical information, regardless of sequence length, here Baseline will always guess top predictions that may lead to FPs. It seems to us that, when knowledge is limited, Baseline is more like a detection model for extremely rare events rather than anomalies. Nevertheless, in this example, once Baseline knows the size from e 5 , it can correctly predict the following events e 6 , e 7 , and e 8 .</p>
<p>In contrast, an LSTM autoencoder-based anomaly detection can resolve this issue. Unlike predictors that make guesses for next events, our autoencoder-based anomaly detection model, called DabLog, first analyzes (encodes) the sequence, and then reconstructs (decodes) the sequence, as if the sequence is an atomic instance. By analyzing s 10 = [e 1 , e 2 , e 3 , . . . , e 10 ], DabLog already knows that the transmission is of size "20-30 MB", not "60-70 MB", even though k 3 is an extremely rare event. In fact, DabLog could not only correctly reconstruct s 10 with k 3 in e 5 's top-9% reconstructions, but also correctly reconstruct other subsequences from s 11 to s 15 , which also involve e 5 . Furthermore, it correctly reconstructed every subsequence from s 16 to s 25 . As a result, DabLog would not falsely report this session as abnormal. In fact, with configuration seqlen = 10 and top-9% rank-based criterion, DabLog reported 3,187 less FPs and 2,145 more TPs than Baseline upon K 1 .</p>
<p>B. Critical Issues about Criterion</p>
<p>Previous work [15], [47] detect anomalies by checking top-9 predictions out of 28 event keys. Yet, this criterion is problematic because of the following reasons.</p>
<p>First, top-9 (top-32%) is too high. By sorting the event keys by occurrence, we found that top-9 most frequent event keys in the dataset dominate 98.66% of the entire dataset (and top-10 keys dominate 99.64%). The coverage is so high that even a trivial model, that always blindly guess these top-9 event keys, can already achieve 85.58% accuracy and 14.33% FP rate; similarly, by predicting top-10, one can even achieve 99.16% accuracy and 0.35% FP rate. Furthermore, over 10 (out of 28) event keys defined in their work [15], [47] did not appear in normal sequences at all; therefore, their appearance in the testing phase made their models more easier to identify anomalous sequences. Apparently, we need a much more precise model that is able to predict a smaller set of candidate events; for example, a more reasonable choice could be top-3 events (dominating 42.37%), or equivalently around top-10% of |K|. Another reason for a more precise prediction (i.e., a smaller N in top-N prediction) is that, when we see anomalies, it would be easier to examine "what are normal" from just top-N keys to figure out "why anomalies are abnormal", just like our reasoning in the previous subsection. A trivial model that guesses top-3 predictions would only achieve 5.71% accuracy and 97.05% FP rate. Finally, in the context of anomaly detection where the number of negative samples (i.e., normal events) is significantly larger then the number of positive samples, F 1 score is more meaningful than accuracy, because we do not care about the dominating TNs. Instead, we care more about TPs, FPs, and FNs, and hence the accuracy metric seems misleading here (details in Section VI).</p>
<p>Second, the number of log keys |K| = 28 is too small. If we look at unique sequence patterns under configuration seqlen = 10, we have in total 28,961 patters, in which 13,056 are always normal, 11,099 are always abnormal, and 4,806 are non-deterministic. Regardless of implementation, any anomaly function AD : S → {normal, abnormal} that merely learns these 13,056 normal patterns and reports the other patterns abnormal would get reasonable results. The number of unique patterns is simply too small, and this is also the reason why these previous models needed only incredibly few training data (e.g., 4,855 normal block sessions). However, in practice, for some applications, the number of unique event keys can easily exceed a hundred, and the patterns of normal sequences can easily become unlearnable due to the scale. One may argue that the number of keys can be reduced by abstracting and aggregating multiple keys; however, key abstraction and aggregation may cause the loss of important information. When seeing anomalies, one may not know what what exactly happened due to lack of important information.</p>
<p>V. OUR DABLOG APPROACH</p>
<p>A. Overview</p>
<p>Based on the motivation and insights in Section IV, we propose DabLog, a Deep Autoencoder-Based anomaly detection method for discrete event Logs. DabLog is an unsupervised and offline machine-learning model. The fundamental differences between DabLog and the aforementioned predictorbased related work is that, DabLog determines whether S is abnormal by reconstructing S rather than predicting (or sometime guessing) upcoming individual events. The intuition is that, to avoid guessing, an anomaly detection method should see a sequence as an atomic instance, and it should examine the structure of the sequence as well as the bi-directional causality among the events. In the event of poor reconstruction, DabLog can detect not only sequences that include unseen or rare events, but also structurally abnormal sequences.</p>
<p>DabLog focuses on discrete events, which are essentially discrete-log representation derived from discrete log entries. Each log event e t is represented as a discrete event key k i (which is an abstraction string), and the key set is K = {k i |1 ≤<br />
i ≤ V },
where V is the number of unique discrete events (vocabulary size). Much work [48], [42], [30], [13] has been done for automatic discovery of unique discrete keys from security logs.</p>
<p>We make a Time-Sensitive Distribution Assumption: we assume that the value of the time-sensitive distribution D of an event e t at time t may depend on both the past and future events; that is, one can expect both past and future causal events e i and e j when observing an event e t , where i &lt; t &lt; j. For example, if e t is "deleting a remote object", then one can expect there is a past event e i like "ask to delete a remote object" and a future event e j like either "deleted an remote object" or "deletion error" (if such audit logs are available). We define the probability function of e t for t in i ≤ t ≤ j by Pr(e t |e i , e i+1 , . . . , e j ); this assumption is not applicable to predictors, whose probability mass functions are typically defined by only the past, that is Pr(x t |x t−1 , . . . , x 1 ).</p>
<p>In summary, DabLog aims to provide an anomaly detection function AD : S → {normal, abnormal}. DabLog consists of four major components ( Figure 2): an embedding layer, a deep LSTM autoencoder, an event classifier, and an anomaly critic. The workflow is stated as follows. Given a sequence S ∈ S, the embedding layer E embeds S into an embedded distribution X e , the autoencoder then analyzes (encodes) X e and reconstructs (decodes) the categorical logit distribution Y , the event classifier then transforms Y into categorical probability distribution P, and lastly the critic compares P with S and reports whether S is normal or abnormal.</p>
<p>B. Embedding Layer</p>
<p>Since our anomaly detection takes a sequence of discrete events S = [e t |1 ≤ t ≤ T ] as input, we need to embed discrete events e t ∈ K into a particular model-recognizable vector, where K = {k i |1 ≤ k ≤ V } is the set of discrete event keys of vocabulary size V = |K|. We denote an embedding function as E : S → X and the procedure as X e = E(S), where X e = [x t |1 ≤ t ≤ T ] ∈ X is an embedded distribution of S, and x t is the embedded vector of e t . There are three common embedding options adopted by prior work: (1) embedding with one-hot representation, (2) embedding using pre-trained natural linguistic packages, and (3) embedding by training an additional embedding layer along with the other layers.</p>
<p>We adopt the last option, because the other two options have major drawbacks. On one hand, one-hot representation,
in which x t = [v i |1 ≤ i ≤ V ]
where v i ∈ {0, 1} and i v i = 1, not only lacks the ability to embed the semantic or correlation features among keys, but also causes the model to suffer from dimension explosion when V is large (dimension explosion causes run-time inefficiency in machine learning). As a consequence, leveraging one-hot representation, DeepLog [15] does not work well on datasets with more keys (even the HDFS dataset), even though its accuracy has been improved by stacking two LSTM layers. On the other hand, while directly using pre-trained natural linguistic packages (e.g., Word2Vec and GloVe) seems convenient, it may not work well on security audit logs that lack natural linguistic properties [32]. The reasons include that (1) a JSON-formatted or CSV-formatted log may not demonstrate syntactic structure, (2) duplicate or redundant attributes may introduce unwanted noise, and (3) arbitrary abbreviated strings may not have a match in the existing packages.</p>
<p>Although the last option training an additional embedding layer is slower, the embedding function E can be well customized for the specific log dataset. That is, rather than no correlation (with one-hot representation) or syntactic correlation (using linguistic packages), the underlying correlation between discrete events k i ∈ K (for example, k 3 and k 6 in Table I) can be found by E.</p>
<p>In our approach, an embedding layer is instantiated by V and the size of output dimension δ, and then it holds a random matrix that maps e t = k i to x t , where x t is an embedded vector of size δ. This matrix is then trained by back propagation during its training phase along with the time-sensitive encoderdecoder network. In addition to event keys, we incorporate three special padding keys begin-of-sequence, end-of-sequence and unknown in our embedding layer. On one hand, the keys begin-of-sequence and end-of-sequence provide additional sequential characteristics to LSTM models, and we noticed a slight improvement for both autoencoders and predictors in detection results. On the other hand, the unknown key is used for improving computational performance. The problem of not using unknown key is that, the embedding function in prior work initiates untrained embedding vectors for all unknown events, and similarly the event classifier also initiates unused logit dimensions for unknown events. It is inefficient to train such a machine-learning model when unknown events unnecessarily use much resource.</p>
<p>C. Deep LSTM Autoencoder</p>
<p>Deep autoencoders have been used in time-insensitive anomaly detection. Conceptually, an autoencoder learns the identity function of the normal data and reconstructs normal data distribution; hence the input data leading to poor reconstruction is potentially abnormal. Since we are tackling time-sensitive discrete events instead of engineered features, our autoencoder is different from typical ones that reconstruct the input features. Rather, it tries to reconstruct the logit distribution of categorical events.</p>
<p>A typical autoencoder is trained by minimizing the function: φ, ψ = arg min φ,ψ X − (ψ • φ)(X) , where φ is an encoder, ψ is a decoder, X is the input distribution, and ψ • φ(X) is the target (reconstructed) distribution. To tackle time-sensitive discrete events, our autoencoder ( Figure 1) is trained by minimizing the function:
φ, ψ = arg min φ,ψ X − Y 2 = arg min φ,ψ rev(X e ) − (ψ • φ)(X e ) 2 = arg min φ,ψ (rev • E)(S) − (ψ • φ • E)(S) 2
where φ is a deep encoder, ψ is a deep decoder, and rev is a function that reverses a distribution matrix. The encoder φ maps an E-embedded matrix X e = E(S) into a representation code = φ(X e ), whereas the decoder ψ maps the code into a target distribution matrix Y = ψ(code). Hence, the reconstructed distribution through the embed-encode-decode procedure is denoted as Y = (ψ • φ • E)(S). The function rev is involved because Y is in the reverse order from X e due to LSTM's hidden state h t , which is explained below.</p>
<p>We build our encoder φ and decoder ψ by stacking vanilla Long Short-Term Memory (LSTM) [24] (variants are applicable as well [21], [26]). The advantage of using an recurrent LSTM network over traditional recurrent neural networks is that an LSTM unit calculates a hidden state that conceptually remembers past activities as well as long-term dependencies [5]. For presentation purpose, we denote the computation of hidden state h t by
h t = LSTM (x t , h t−1 )
That is, at each time-step t, an LSTM unit takes two inputs x t (the current data point) and h t−1 (previous hidden state), and it generates an output h t (current hidden state). Multiple LSTM layers each calculates its own hidden state, as illustrated in Figure 1. The representation code = φ(E(S)) is essentially the transferable hidden state h T at the last time-step T , and h T is calculated by applying LSTM function iteratively from t = 1 up until the last time-step t = T . We can conceptually think of this procedure as "pushing x t into a state stack h T "; hence, the conceptual procedure for decoder is "popping x t out from a state stack h T ". Therefore, the distribution X e and Y are in reverse order.</p>
<p>Our deep LSTM autoencoders are similar to traditional autoencoders that consist of deep encoders and deep decoders, except that our encoder φ and decoder ψ are implemented with stacked LSTMs (of at least two layers). The number of hidden units decreases (e.g., by half) layer-by-layer in φ, and increases (e.g., doubled) layer-by-layer in ψ. Some research work [39], [20], [23] have addressed the main benefit of stacking multiple LSTM layers over using a single layer: stacking hidden states potentially allows hidden states at each layer to reflect information at different timescale, and the final layer can gain benefits from learning or combining representations given by prior layers (hence better results).</p>
<p>Our autoencoder is unconditional, meaning that we do not provide a conditionŷ τ = e T −τ +1 to the decoder ψ when it is decoding y τ +1 for any y τ in Y = [y τ |1 ≤ τ ≤ T ]. This decision is made differently from some predictor-based anomaly detection methods [15], [16], [47], [6], [17] that either provide e T +k−1 to ψ when decoding e T +k or predict only e T +1 for any input sequence S = [e t |1 ≤ t ≤ T ]. Srivastava et al. [43] have shown that, although conditional decoders could provide slightly better results in predictors, unconditional decoders are more suitable for autoencoders. There are two reasons. First, autoencoders have only one expected output from any input sequence, which is the reconstruction of the input, whereas predictors could have multiple expected outputs (say S 1 and S 2 have the same prefix of length T but different suffices). While the condition acts as a hint about which suffix should be decoded in predictors, providing conditions serves no additional purpose in autoencoders. Second, usually there is strong short-term dependency among adjacent events, and hence it is not ideal to provide a condition that may cause the model to easily pick up short-term dependencies but omit long-term dependencies.</p>
<p>D. Event Classifier and Anomaly Critic</p>
<p>Since our goal is to provide an anomaly detection method AD : S → {normal, abnormal}, simply combining an embedding layer and a deep LSTM autoencoder will not accomplish our goal. Similar to prior predictor-based anomaly detection methods [15], [47], [6], [17], right after our deep autoencoder, we add an additional single-layer fully connected feed-forward network γ, which is activated by a softmax function. The last layer γ acts as a multi-class classifier that takes input Y (which is the reconstructed distribution from ψ) and generates a probabilistic matrix P
= [P τ |1 ≤ τ ≤ T ], where P τ = [p i |1 ≤ i ≤ V ]
and p i can be interpreted as the likelihood of the discrete event e t = e T −τ +1 being an instance of discrete event key k i (that is, γ is an event classifier). We explain why we need γ in the following paragraph. In order to train γ, one-hot representation of S is provided as true probabilistic matrix, denoted as X 1 = onehot(S) = [P t |1 ≤ t ≤ T ], wherê P t = [p i |1 ≤ i ≤ V ] andp i ∈ [0, 1] and ip i = 1. Similar to the embedding function E, we also include three additional special padding keys begin-of-sequence, end-of-sequence, and unknown in the onehot function. Note that X 1 and P are in reverse order, soP = rev(X 1 ). In our design, the multi-class classifier γ is trained by minimizing the categorical crossentropy loss function:
L(P, P) = T τ L(x T −τ +1 , P τ ), where L(x t , P τ ) = − V ip i × log(p i )
In summary, the overall embedder-encoder-decoderclassifier network tries to minimize the function:
E, φ, ψ, γ = arg min E,φ,ψ,γ (rev • onehot)(S) − (γ • ψ • φ • E)(S)
Unlike typical time-insensitive autoencoder-based anomaly detection methods, we do not directly use scalar reconstruction errors (e.g., root-mean-square error) as anomaly scores. The reason is that our problem-identifying time-sensitive anomaly = [ 1 , 2 , 3 , 4 , 5 , 6 , 7 , 8  Top-are normal keys abnormal Fig. 3: An example of the rank-based criterion by examining discrete events-is more like a language processing problem. We can view sequences S as sentences and events e t as words, and we care more about wording (e.g., "which words e t better fit in the current sentence S") rather than embedding (e.g., "which vector y τ better vectorize e t in the current sentence S"). As such, we need the event classifier γ as well as certain reasonable "wording options" that help us with finding "fitting words" and "unfitting words", or equivalently, normal events and abnormal events in S.</p>
<p>Rank-based criterion and threshold-based criterion are two common "wording options" adopted by previous predictorbased anomaly detection methods. Say a discrete event e t is an instance ofk i , a rank-based criterion will consider e t anomalous if p i is not in top-N prediction (e.g., N = V /10) in P τ , and a threshold-based criterion will consider e t anomalous if p i ∈ P τ is under a particular threshold θ P . In other words, discrete keys {k j |∀j s.t. p j ∈ arg top N (P τ )} and {k j |∀j s.t. p j &gt; θ P } are normal discrete keys. Our autoencoder-based anomaly detection adopts both thresholdbased and rank-based criteria, but for presentation purpose we demonstrate the rank-based criterion (Figure 3) in this paper in order to compare our work with prior predictor-based methods [15], [47]. However, both rank-based and threshold-based criteria have the same major drawback: they brutally divide P τ while omitting the correlation between the truek i and the supposedly normal keys; hence, besides the aforementioned two criteria, our anomaly detection has an option of a novel criterion, which is discussed in Section VII-B.</p>
<p>Similar to prior anomaly detection work [15], [47] that conducted experiments on the same dataset [46], [45], in which anomaly labels (e.g., normal or abnormal) are given at the sequence level, our anomaly detection model gives labels to sequences. We say a sequence S = [e t |1 ≤ t ≤ T ] is abnormal if any e t ∈ S is abnormal. With aforementioned criteria, our anomaly detection method AD : S → {normal, abnormal} is complete.</p>
<p>VI. EVALUATION</p>
<p>We motivate our evaluation with three questions: (1) how better is DabLog in comparison with a predictor-based baseline model, (2) how does having more keys impact the detection results, and (3) how does the fundamental difference make DabLog more advantageous. Similar to prior work [15], [47], we evaluate DabLog with the Hadoop File System (HDFS) console-log dataset released by Xu et al. [46]. We show that DabLog not only is capable of detecting system anomalies, but also outperforms our predictor-based re-implementation baseline model.</p>
<p>A. DabLog and Baseline Implementation</p>
<p>We implement both Baseline and DabLog models with 3K lines of Python 3.7.4 script, and we leverage deep-learning utilities from package Tensorflow 2.0.0.</p>
<p>Baseline Model Implementation: We re-implement an anomaly detection model which we believe is representative of predictor-based models (Figure 4). Similar to DeepLog [15] and nLSALog [47], the Baseline model has a two-layered LSTM network, a multi-class classifier, and a rank-based critic, except that unlike DeepLog it does not learn onehot representation, and unlike nLSALog it does not include a self-attention layer. The embedding layer is implemented with a tensorflow.keras.layers.Embedding layer, in which we also include three additional special padding keys begin-ofsequence, end-of-sequence, and unknown (we notice a slightly improvement for both models when including them). The twolayered LSTM network is implemented by stacking two tensorflow.keras.layers.LSTM layers, and each is activated by ReLU. Each LSTM layer is configured to have 64 hidden units just like the ones in DeepLog and nLSALog. Lastly, the event classifier layer is implemented with tensorflow.keras.layers.Dense, which is activated by the softmax function, just like the ones in DeepLog and nLSALog. In event classifier, we also include the three additional special padding keys.</p>
<p>Note that we do not reuse DeepLog's code for the following reason. The only difference between Baseline and DeepLog is that DeepLog uses one-hot representation, whereas Baseline (as well as nLSALog) uses an embedding layer. Since the performance difference has already been addressed in prior predictor-based work (e.g., [47], [6], [16], [17]) and in the research field of natural-language processing (e.g., [28]), we believe it is redundant to re-evaluate the original DeepLog implementation. Still, the other parameters (including the numbers of layers and the numbers of hidden units) used in Baseline are the same as in DeepLog and nLSALog.</p>
<p>DabLog Model Implementation: Our encoder and decoder are implemented by stacking two tensorflow.keras.layers.LSTM layers, and each is activated by ReLU. The encoder is configured to have 64 and 32 hidden units for its 1 st and the 2 nd layer respectively, and the decoder is configured to have 32 and 64 hidden units for its 1 st and the 2 nd layer respectively, as we follow the common practice that the representation code is a downgraded abstraction. The embedding layer and the event classifier are implemented in the same way as the ones in the Baseline model. In DabLog, the encoder network is connected with the decoder by tensorflow.keras.layers.RepeatVector, and the decoder network is connected with the classifier by tensorflow.keras.layers.TimeDistributed.</p>
<p>To train the DabLog and Baseline, Adam optimizer is used with accuracy metric in minimizing categorical cross-entropy. We use the same sequence-length configuration seqlen = 10. Sliding window is applied to longer sequences S that have lengths |S| &gt; seqlen.</p>
<p>B. Experiment Setup</p>
<p>The HDFS dataset [46] encloses over 11 million log entries from Hadoop map-reduce jobs that ran on 203 Amazon EC2 nodes across two days. Each log entry contains a block identifier, and each block can be understood as a concurrent thread (i.e., log entries that have the same block identifier are executed sequentially). The anomaly labels (i.e., normal or abnormal) are provided at the block level, and there are 558,223 normal blocks and 16,838 abnormal blocks. Xu et al. [45] addressed that the labels were given based on 680 unique event traces across all the data, and an event trace is labeled as normal if it contains all the events of a given pattern. 1) Dataset Engineering: As mentioned in Section IV, we think the number of event keys |K| = 28 is too small. To measure how well the related work can be applied to scenarios where more event keys are involved (note that we do not recraft keys for performance improvement-having more keys surely reduces the prediction performance), we re-crafted the event keys into three sets K 0 (new base), K 1 , and K 2 , so that we have 31, 101, and 304 keys, respectively. Since anomaly labels are given upon sequences (by block ID), it is safe to transform keys without modifying the original sequences (that is, anomaly labels are not impacted by our key transformation). The statistics of each key set under configuration seqlen = 10 is listed in Table II. These key sets are from the same source log, except that K 1 and K 2 discard less information by reattaching add-on strings; for example: There are three types of add-on strings. First, for two event keys that each involves a filepath, we attach one of the 32 filepath add-ons (e.g., "/user/root/randtxt/ temporary/ task * /part * " and "/mnt/hadoop/mapred/system/job * /job.jar") we got from manual analysis. Second, for two event keys that each involves a filesize, we attach one of the seven 10-MB interval add-ons (e.g., "0-10 MB" and "60-70 MB"). Third, for nine events that each involves an IP address, we attach add-ons from the following rules. 1) If an event key involves both a source IP address and a destination IP address, we check and attach add-ons that represent whether it is "within the localhost"; if not, we then check whether it is "within the subnet" or "between subnets" by the IP prefixes (e.g., 10.251.7 * ) 2) If an event key involves either a source IP address or a destination IP, we attach add-ons that represent directions and IP prefixes (e.g., "from 10.251.7 * ").</p>
<p>The IP-prefix granularity is different for K 1 and K 2 : for K 1 we use the first two decimal numbers (e.g., 10.251. * ), and for K 2 we use just one more decimal number (e.g., 10.251.7 * ). We split K 0 by attaching add-ons, but we also discard keys that have zero occurrence. Among these key sets, we think K 1 is the most representative. Note that one benefit of applying machine learning to discrete events is that, detail domain knowledge is no longer required. While our method of splitting event keys does not look perfect, we argue that, this method serves our purpose of evaluating the performance of DabLog and Baseline at different number of logkeys, as we do not intent to make them know any domain details. </p>
<p>Fig. 4: Baseline Predictor-Based Model</p>
<p>2) Training Datasets and Testing Datasets: In the context of anomaly detection, a model learns whatever it needs from partial normal dataset, and uses its knowledge to identify anomalies. DeepLog and nLSALog suggested that, upon |K| = 28, a training dataset which included only 4,855 normal sessions was large enough. Similarly, we train DabLog and the baseline model with 5,000 normal sessions, and we denote the resulting model as DabLog (5K) and Baseline (5K), respectively. However, since these 5K sessions cannot cover the majority of the normal patterns in experiments upon K 1 and K 2 , we also train DabLog and the baseline model with larger datasets, and we denote the resulting model as DabLog and Baseline. The training dataset for K 0 and K 1 consists of 200,000 normal sessions, and the training dataset for K 2 consists of 100,000 normal sessions. The number of sessions in dataset for K 2 is smaller due to the computational limitation within our experiment environment. The testing datasets for K 0 , K 1 , and K 2 each includes all 16,868 abnormal sessions. Beside abnormal sessions, the testing dataset for K 0 and K 1 include 200,000 normal sessions, and the testing dataset for K 2 include 100,000 normal sessions.</p>
<p>C. Anomaly Detection Results</p>
<p>To compare different models, we leverage the F 1 score metric, whose equations are listed below, where T P , F P , T N , and F N denote the numbers of true positives, false positives, true negatives, and false negatives, respectively. The higher the F 1 score, the better the model in providing good anomaly detection results. Previous work was evaluated by the accuracy metric. However, we believe the accuracy metric is misleading for imbalanced dataset, as a blind model that always returns normal for any sequences can achieve high accuracy due to the fact that T N F N .</p>
<p>Recall = TP Rate = T P T P + F N Precision = T P T P + F P F 1 Score = 2 × Precision × Recall Precision + Recall FP Rate = F P F P + T N Accuracy = T P + T N T P + T N + F P + F N Figure 5(a) depicts the F 1 score trends of different models upon the base key set K 0 . The X-axis represents the variable ranking threshold N in a normalized form θ N = N |K * | × 100%; for example, a data point at x = 31 represents the result of a model that examines top-31% reconstructions or predictions, or equivalently top-9 out of |K 0 | = 31 keys. The Y-axis represents the F 1 score of the models. In Figure 5(a), Baseline (5K) has its peak F 1 score 97.52% at θ N = 31%, which is similar to the ones reported in the previous work [15], [47]; hence, we believe Baseline (5K) and Baseline are representative models of predictor-based models. Besides DabLog and Baseline, we also include a trivial frequency model, which is mentioned in Section IV, for reference. This trivial frequency model reports anomalous sequences by checking whether a sequence includes any event that is not an instance of top-N most frequent keys. It has its peak F 1 score 85.00% at θ N = 29%.</p>
<p>To assess the performance of these models at larger numbers of discrete event keys, we test them against K 1 and K 2 . Figure 5(b) depicts the F 1 score trends of models upon K 1 . DabLog (5K) has its peak F 1 score at 95.20% at θ N = 27%, whereas Baseline (5K) has its peak F 1 Score 94.98% at θ N = 31%; by comparing the trends, we can see that DabLog (5K) has a higher peak and a wider plateau, and hence DabLog (5K) is more advantageous for critics where coarse-grained reconstruction, say N ≥ 30%, is used. Similarly, DabLog has its peak F 1 score 97.18% at θ N = 9%, whereas Baseline has its peak F 1 Score 87.32% at θ N = 10%; by comparing the trends again, we can see that DabLog is more advantageous for critics where fine-grained (i.e., more precise) reconstruction, say N ≤ 10, is used. On the other hand, Figure 5(c) shows a similar trends upon K 2 . DabLog has its peak F 1 score 94.15% at θ N = 6%, and Baseline also has its peak F 1 score at θ N = 6% but its score is only 80.47%. The above comparisons clearly shows DabLog and DabLog (5K) are more advantageous upon all key sets K 0 , K 1 , and K 2 .</p>
<p>Unlike traditional deep neural networks, DabLog and Baseline does not follow the common belief of "having more training data leads to better performance", because their last components (i.e., anomaly critics) are not based on learning, but based on the ranks of keys regardless of training size. This statement also applies to prior work [15], [47] that trained models with no more than 1% of the dataset. We can see in Figure 5(a), Figure 5(b), and Figure 5(c) that the models with 5K training data have higher F 1 plateaus; however, it does not mean that the less training data, the better the models perform. Rather, the less keys involved in training, the more keys have zero distribution (i.e., p i = 0) in reconstruction. Since keys k i with p i = 0 have the same escalated rank, the anomaly critics tend to report them normal (i.e., hit) when a moderately highthreshold rank is applied. Hence, the F 1 scores remain high until false-negative rises. This is an unaddressed issue of the rank-based approach in prior work [15], [47], and we believe To understand the trend of F 1 score in DabLog, we depict the trends of different metrics upon K 1 in Figure 5(d). Again, X-axis represents the normalized variable ranking threshold θ N , and Y-axis represents the scores. We can see that FPrate are constantly low, and precision are constantly high while F 1 score decreases with θ N . This is because when θ N increases, more and more events (hence more sequences) will be considered as normal. In the extreme case θ N = 100%, everything will be considered normal. In other words, the number of FNs increases with θ N . This in turn causes recall to decrease, and accordingly F 1 score decreases with θ N . Figure 5(e) further shows that DabLog has much higher precision than Baseline in different parameter settings. This result is significant because a higher precision means fewer false positive cases for security administrators to (manually) analyze. Figure 5(f) shows that while the recall of DabLog and Baseline both decreases with θ N , DabLog is more advantageous as its trend decreases slower. This supports one of our insights mentioned in Section IV: since Baseline cannot identify structurally abnormal sequences, it would have more FNs (a FN case study is provided in the following subsection).</p>
<p>Previous work [15], [47] was also evaluated by the area under Receiver Operating Characteristic (ROC) curve in a 2-D space, where the X-axis represents the FP-rate, and the Yaxis represents the TP-rate.  </p>
<p>D. Case Study</p>
<p>The above statements may seem too abstract and nonintuitive to understand why DabLog is more advantageous, so here we make more detailed comparisons under a fixed configuration. We motivate our case studies with this question: how does the fundamental difference make DabLog more advantageous? Upon K 1 and at θ N = 9%, DabLog and Baseline reported 14,768 common TPs, 627 common FPs, and 80 common FNs; however, DabLog also reported 1,986 exclusive TPs with trade-off 425 exclusive FPs, whereas Baseline reported 4 exclusive TPs but 2,215 exclusive FPs (recall that the testing dataset for K 1 has 200,000 normal sessions and 16,868 abnormal sessions). Upon K 2 and at θ N = 6%, DabLog and Baseline reported 14,555 common TPs, 1,089 common FPs, and 90 common FNs; however, DabLog also reported 2,169 exclusive TPs with trade-off 932 exclusive FPs, whereas Baseline reported 24 exclusive TPs but 4,119 exclusive FPs. In conclusion, DabLog provided more TPs and less FPs (or equivalently more TNs), and Baseline provided more FPs and less TPs (or equivalently more FNs). We conducted case studies upon K 1 and at θ N = 9%. One was detailed in Section IV: a normal session that DabLog reported normal, while Baseline reported it abnormal.</p>
<p>Here, we illustrate their difference through an oppo-  Table IV. These subsequences are considered abnormal because DabLog could not correctly reconstruct particularly the 21st event e 21 . That is, the key k 3 is not within the top-9% reconstructions for e 21 . Top-9% reconstructions include k 4 , variants of k 5 , variant of k 6 ="addStoredBlock: blockMap updated ...", and k 7 = "EXCEPTION: block is not valid ...". These event keys, except k 7 , are frequent keys each dominates over 0.1% of the dataset. Interestingly, here DabLog expects not only frequent keys, but also an extremely rare event key k 7 (which dominates 0.0017%) before k 5 . Since these expected keys in top-9% reconstructions for e 21 are related to exception, verification, or blockMap updates, we believe that the reconstruction distribution is derived for causality relationship with e 23 (which is related block transmission) rather than for e 19 (which is related to block deletion), even though DabLog knows a deletion is asked at e 19 as it has correctly reconstructed e 19 . Our interpretation is that, DabLog expects a cause at e 21 that leads to the exception at e 23 , and it is the absence of causality before e 23 making the sequence structurally abnormal.</p>
<p>In contrast, Baseline does not predict e 21 to be any of these keys after s 20 = [e 11 , . . . , e 20 ]. In other words, Baseline does not expect a cause at e 21 , because it cannot foresee e 23 = k 5 . With the fundamental limitation of unable to exploit bi-directional causality, Baseline is incapable of detecting such a structurally abnormal session. Therefore, we believe it is necessary for an anomaly detection methodology to see sequences as atomic instances and examine the bi-directional causality as well as the structure within a sequence. Single-direction anomaly detection like Baseline cannot identify structurally abnormal sequences.</p>
<p>VII. DISCUSSION AND FUTURE WORK</p>
<p>A. A More Comprehensive Embedding</p>
<p>Our DabLog approach learns the embedding function E by training an additional embedding layer along with the other layers. This approach has the drawback of handling unknown event keys that are not in the training data but in the testing data. If e * = k * is not in the training data, then x * = E(k * ) is an undefined vector; hence the model may wrongly judge sequences S * that includes k * . In the literature of natural language processing, this problem is also known as the out-ofvocabulary problem, and there are two common workaround options for it. One option is to substitute the designated "unknown" word for not only unknown words but also rare words, so that "unknown" is trained as if it is some known rare events. This option, however, is not applicable to security audit logs, because unknown events can be frequent and similar to known events (e.g., unknown event key "receiving 70-80 MB" is similar to known event key "receiving 60-70 MB"), and wrongly treating unknown events as rare events may cause FPs. The other option is to leverage a pre-trained Word2Vec embedding in building a new embedding model (e.g. Mimick embeding [40]). Inspired by the latter option, one of our future work is to build an Event2Vec embedding model E that can derive the embedding for k * by examining the words in k * . We will investigate how this new embedding can improve the results in our future work.</p>
<p>B. A Rank-Distance Double-Threshold Criterion</p>
<p>We presented DabLog's critic as a rank-based criterion in order to compare DabLog with existing work [15], [47]. However, both rank-based and threshold-based criteria have the same major drawback: they brutally divide the probabilistic distribution P τ into two parts (normal and abnormal), while omitting the correlation between the truek i and the other keys {k j }. The problem is that the critic may wrongly see a normal event key as abnormal, and vice versa. For example, let us consider a case in which |p i − p j | is very small, meaning that the corresponding keysk i and k j are almost equivalently anomalous to the model, stillk i could be abnormal and k j could be normal when the pivotal condition sits in between. Ifk i has certain strong correlation with another k J (e.g., neighbors in embedding universe U), then very likelyk i has the same anomaly label as k J . We believe both rankbased criterion and threshold-based criterion have limitation that cause FPs and FNs. Therefore, we are curious whether we can incorporate the embedding distance in a rank-based critic (we name the resulting criterion rank-distance doublethreshold criterion). Basically, in addition to checking top-N reconstructions, it also checks the labels of neighbors (within threshold radius) in U. We leave it as a future work. </p>
<p>C. Merging Models of Different Ideas</p>
<p>There are many different ideas on how to build an anomaly detection model, and each has its advantages. In hope of being more advantageous, one may want to merge different ideas by merging their anomaly results according to certain rules (e.g., intersection or union), and we refer to the resulting method as a hybrid model. From Table V, we can see that taking intersection benefits us by less FPs, and taking union benefits us by less FNs. Besides hybrid models, we can also consider building a composite model, which is an interconnected neural network resulted from merging the neural networks of different ideas (different sub-networks are trained simultaneously). We have many options for merging models, yet "which advantage (e.g., having less FPs or less FNs) is more preferable" is debatable. In practice, having less FPs is more preferable for offline learning models, as manual inspections are very expensive. In contrast, having less FNs is more preferable for online learning models that are capable of unlearning FPs [14]. Among these different options, although we believe that there is little space for improvement, their benefits are worth researching into in the future.</p>
<p>D. DabLog is beyond a Standard Autoencoder</p>
<p>We would like emphasize again that, although DabLog is based on the autoencoder methodology, DabLog is more than a standard autoencoder. Compared to the reconstruction problem for standard autoencoders, our problem-identifying time-sensitive anomaly by examining discrete events-is more like a language processing problem. We can view sequences S as sentences and events e t as words, and we care more about wording (e.g., "which words e t better fit in the current sentence S") rather than embedding (e.g., "which vector y τ better vectorize e t in the current sentence S"). As such, DabLog is designed as an embed-encode-decode-classify-critic model, so that it can help us with finding "fitting words" and "unfitting words", or equivalently, normal events and abnormal events in the sequential context of S. In contrast, typical time-insensitive autoencoder-based anomaly detection methods directly use scalar reconstruction errors (e.g., root-mean-square error) as anomaly scores.</p>
<p>E. More Reconstruction Methods and More Datasets</p>
<p>Although we show that reconstructing sequences is also an attractive methodology (besides predictor-based methods), autoencoders are not the only sequence-reconstruction solution. Combining predictor results from predictors of different directions can also achieve sequence reconstruction (i.e., with one for successor events and the other for predecessor events), though this approach may not be as accurate or efficient as the autoencoder-based approaches. Nevertheless, the performance difference of different sequence-reconstruction methods is worth researching into. We will also put more efforts in discovering and experimenting more datasets. In this paper we use the same HDFS dataset as used in the prior work for a convenient comparison; however, this dataset has little to do with cyberattacks or cyber threats. Although we are aware of some other threat-related datasets [2], [1], they are too abstract (either because low-level events are not included or because too much details are discarded for anonymity) to learn sequential relationships between events. As a consequence, their sequences are not reconstructable, unless domain knowledge is available for numeric feature extraction, as shown in Liu et.al [31], [32]'s work (but then the problem becomes numericfeature reconstruction and is no longer discrete-key sequence reconstruction). DabLog requires datasets that include relationships among low-level events (e.g., system-call events or Windows audit events with details). To be more attractive to the security community, our top priority in our future work is to find more (or engineer) labeled datasets for experiments.</p>
<p>VIII. CONCLUSION</p>
<p>With regard to anomaly detection approaches for discrete events, we address a fundamental limitation of the widely adopted predictor-based methodology through our in-depth case studies. We argue that recomposing sequences is also an attractive methodology, especially in real-world contexts where the need of detection with more keys cannot be well satisfied by predctor-based methodology. We propose DabLog and evaluate DabLog with the HDFS console-log dataset. Our results show that DabLog outperforms our predictor-based baseline model in terms of F 1 score. With reconstruction of sequential events, not only does DabLog have much fewer FPs, but also does DabLog improve awareness regarding what is normal in contexts that involves more keys.</p>
<p>Fig. 1: Deep LSTM Encoder-Decoder Network</p>
<p>Fig. 2 :
2DabLog Anomaly Detection Model</p>
<p>k i ∈ K 0 :"Received block" 1 st add-on :"of size 20-30 MB" 2 st add-on :"from 10.250. * " k j ∈ K 1 :"Received block of size 20-30 MB from 10.250. * "</p>
<p>(a) F 1 Fig. 5 :
15Scores upon |K 0 | = 31 Event Keys (b) F 1 Scores upon |K 1 | = 101 Event Keys (c) F 1 Scores upon |K 2 | = 304 Event Keys (d) DabLog's Metrics upon |K 1 | = 101 Event Keys (e) Precision upon Different Key Sets (f) Recall (TP Rate) upon Different Key Sets Metrics Comparison Among Different Models and Different Configurations (System-Log Dataset) that presenting results from DabLog (5K) and Baseline (5K) is misleading. Models should always be trained by sufficient data, or otherwise the models learn very little about the keys. Hence, we focus on results from DabLog and Baseline.</p>
<p>site case. DabLog reported an abnormal session (ID: -9134333392518302881) abnormal, while Baseline wrongly reported it normal. It has in total 34 events, and DabLog reported the subsequences s 23 , s 28 , s 29 , and s 30 abnormal, where s 23 = [e 14 , . . . , e 23 ] and s 30 = [e 21 , . . . , e 30 ]. The events are listed in</p>
<p>TABLE I :
IExample Sequential Discrete Eventse0 
¡begin of sequence¿ 
e1 
k1 
NameSystem.allocatedBlock /usr/root/... 
e2 
k2 
Receiving block within the localhost 
e3 
k2 
Receiving block within the localhost 
e4 
k2 
Receiving block within the localhost 
e5 
k3 
Received block of size 20-30 MB from 10.250. *<br />
e6 
blockMap updated: 10.251. *  added of size 20-30 MB 
e7 
blockMap updated: 10.251. *  added of size 20-30 MB 
e8 
blockMap updated: 10.250. *  added of size 20-30 MB 
e9 
PacketResponder 1 for block terminating 
e10 </p>
<p>TABLE II :
IIStatistics of Event Key Sets under seqlen = 10|K * | 
Normal 
Abnormal 
Undecidable 
Size 
Patterns 
Patterns 
Patterns </p>
<p>K0 
31 
13, 056 
11, 099 
4, 806 
K1 
101 
220, 912 
35, 662 
19, 925 
K2 
304 
1, 868, 327 
103, 863 
49, 856 </p>
<p>normal 
or 
abnormal 
= 1 </p>
<p>, 2 
, ⋯ , </p>
<p>+1 </p>
<p>= 1 </p>
<p>, 2 </p>
<p>, … 
Embedding </p>
<p>Layer </p>
<p>Dense </p>
<p>Layer </p>
<p>2-Layered </p>
<p>LSTM </p>
<p>Rank-Based </p>
<p>Critic </p>
<p>+1 </p>
<p>Table III lists the area under ROC</p>
<p>TABLE III :
IIIArea Under ROC CurveEvent Key Sets 
|K0| = 31 
|K1| = 101 
|K2| = 304 </p>
<p>DabLog 
99.49% 
99.44% 
99.08% 
DabLog (5K) 
99.47% 
99.34% 
98.98% 
BaseLine 
96.02% 
97.23% 
97.41% 
BaseLine (5K) 
99.42% 
99.29% 
98.23% </p>
<p>of different models in our evaluation. The area under ROC is 
useful when a model involves a variable threshold, as the curve 
depicts the expected trade-offs between TP-rate and FP-rate 
when tuning the variable threshold. However, in our evaluation, 
the curves are almost right-angle lines, and the areas under 
ROC curves are very high. That said, we can still see that 
DabLog and DabLog (5K) are more advantageous. </p>
<p>TABLE IV :
IVExample Sequential Discrete Events e14 Starting thread to transfer block e15 Receiving block within the localhost e16 blockMap updated: 10.251. * added of size 60-70 MB e17 Received block within the localhost e18 Transmitted block within the subnet e19 k1 ask 10.251. * to delete block(s) e20 k2 blockMap updated: 10.251. * added of size 60-70 MB e21 k3 Deleting block /mnt/hadoop/dfs/data/current/... Deleting block /mnt/hadoop/dfs/data/current/...e22 
k4 
Verification succeeded for block 
e23 
k5 
Got exception while serving block within the subnet 
e24 
Got exception while serving block within the subnet 
e25 
Verification succeeded for block 
e26 
delete block on 10.251. <em><br />
e27 
delete block on 10.251. </em><br />
e28 
delete block on 10.251. *<br />
e29 
ask 10.251. *  to delete block(s) 
e30 </p>
<p>TABLE V :
VExperiments upon K 1 and with θ N = 7.5%seqlen = 10 
seqlen = 30 
Intersection 
Union </p>
<p>TP 
16,367 
14,910 
14,630 
16,647 
FP 
2,424 
1,224 
1,059 
2,589 
TN 
197,576 
198,776 
198,941 
197,411 
FN 
471 
1,928 
2,208 
191 
FP Rate 
1.21% 
0.61% 
0.52% 
1.29% 
Recall 
97.20% 
88.54% 
86.88% 
98.86% 
Precision 
87.10% 
92.41% 
93.25% 
86.54% 
F1 Score 
91.87% 
90.44% 
89.95% 
92.29% </p>
<p>Advanced Reseach in Cyber Systems. Arcs data sets"Arcs data sets," Advanced Reseach in Cyber Systems. [Online].</p>
<p>Insider threat test dataset. Software Engineering Institute, Carnegie Mellon University"Insider threat test dataset," Software Engineering Institute, Carnegie Mellon University. [Online]. Available: https://resources.sei.cmu.edu/ library/asset-view.cfm?assetid=508099</p>
<p>A zero-positive learning approach for diagnosing software performance regressions. M Alam, J Gottschlich, N Tatbul, J Turek, T Mattson, A Muzahid, M. Alam, J. Gottschlich, N. Tatbul, J. Turek, T. Mattson, and A. Muza- hid, "A zero-positive learning approach for diagnosing software perfor- mance regressions," 2017.</p>
<p>Deep learning approaches for anomaly-based intrusion detection systems: A survey, taxonomy, and open issues. A Aldweesh, A Derhab, A Z Emam, Knowledge-Based Systems. 189105124A. Aldweesh, A. Derhab, and A. Z. Emam, "Deep learning approaches for anomaly-based intrusion detection systems: A survey, taxonomy, and open issues," Knowledge-Based Systems, vol. 189, p. 105124, 2020. [Online]. Available: http://www.sciencedirect.com/science/article/ pii/S0950705119304897</p>
<p>Learning long-term dependencies with gradient descent is difficult. Y Bengio, P Simard, P Frasconi, IEEE Transactions on Neural Networks. 52Y. Bengio, P. Simard, and P. Frasconi, "Learning long-term dependen- cies with gradient descent is difficult," IEEE Transactions on Neural Networks, vol. 5, no. 2, pp. 157-166, 1994.</p>
<p>Recurrent neural network attention mechanisms for interpretable system log anomaly detection. A Brown, A Tuor, B Hutchinson, N Nichols, 10.1145/3217871.3217872Proceedings of the First Workshop on Machine Learning for Computing Systems, ser. MLCS'18. the First Workshop on Machine Learning for Computing Systems, ser. MLCS'18New York, NY, USAAssociation for Computing MachineryA. Brown, A. Tuor, B. Hutchinson, and N. Nichols, "Recurrent neural network attention mechanisms for interpretable system log anomaly detection," in Proceedings of the First Workshop on Machine Learning for Computing Systems, ser. MLCS'18. New York, NY, USA: Association for Computing Machinery, 2018. [Online]. Available: https://doi.org/10.1145/3217871.3217872</p>
<p>A survey of data mining and machine learning methods for cyber security intrusion detection. A L Buczak, E Guven, IEEE Communications Surveys Tutorials. 182A. L. Buczak and E. Guven, "A survey of data mining and ma- chine learning methods for cyber security intrusion detection," IEEE Communications Surveys Tutorials, vol. 18, no. 2, pp. 1153-1176, Secondquarter 2016.</p>
<p>Deep learning for anomaly detection: A survey. R Chalapathy, S Chawla, CoRRR. Chalapathy and S. Chawla, "Deep learning for anomaly detection: A survey," CoRR, 2019.</p>
<p>Robust, deep and inductive anomaly detection. R Chalapathy, A K Menon, S Chawla, Machine Learning and Knowledge Discovery in Databases. M. Ceci, J. Hollmén, L. Todorovski, C. Vens, and S. DžeroskiSpringer International PublishingR. Chalapathy, A. K. Menon, and S. Chawla, "Robust, deep and inductive anomaly detection," in Machine Learning and Knowledge Discovery in Databases, M. Ceci, J. Hollmén, L. Todorovski, C. Vens, and S. Džeroski, Eds. Cham: Springer International Publishing, 2017, pp. 36-51.</p>
<p>Anomaly detection for discrete sequences: A survey. V Chandola, A Banerjee, V Kumar, IEEE Transactions on Knowledge and Data Engineering. 245V. Chandola, A. Banerjee, and V. Kumar, "Anomaly detection for discrete sequences: A survey," IEEE Transactions on Knowledge and Data Engineering, vol. 24, no. 5, pp. 823-839, May 2012.</p>
<p>A novel architecture combined with optimal parameters for back propagation neural networks applied to anomaly network intrusion detection. Z Chiba, N Abghour, K Moussaid, A E Omri, M Rida, Computers &amp; Security. 75Z. Chiba, N. Abghour, K. Moussaid, A. E. Omri, and M. Rida, "A novel architecture combined with optimal parameters for back propagation neural networks applied to anomaly network intrusion detection," Computers &amp; Security, vol. 75, pp. 36 -58, 2018. [Online]. Available: http://www.sciencedirect.com/science/article/pii/S0167404818300543</p>
<p>Learning phrase representations using RNN encoderdecoder for statistical machine translation. K Cho, B Van Merrienboer, Ç Gülçehre, F Bougares, H Schwenk, Y Bengio, abs/1406.1078CoRR. K. Cho, B. van Merrienboer, Ç . Gülçehre, F. Bougares, H. Schwenk, and Y. Bengio, "Learning phrase representations using RNN encoder- decoder for statistical machine translation," CoRR, vol. abs/1406.1078, 2014. [Online]. Available: http://arxiv.org/abs/1406.1078</p>
<p>Spell: Streaming parsing of system event logs. M Du, F Li, 2016 IEEE 16th International Conference on Data Mining (ICDM). M. Du and F. Li, "Spell: Streaming parsing of system event logs," in 2016 IEEE 16th International Conference on Data Mining (ICDM), 2016, pp. 859-864.</p>
<p>Lifelong anomaly detection through unlearning. M Du, Z Chen, C Liu, R Oak, D Song, 10.1145/3319535.3363226Proceedings of the 2019 ACM SIGSAC Conference on Computer and Communications Security, ser. CCS '19. the 2019 ACM SIGSAC Conference on Computer and Communications Security, ser. CCS '19New York, NY, USAAssociation for Computing MachineryM. Du, Z. Chen, C. Liu, R. Oak, and D. Song, "Lifelong anomaly detection through unlearning," in Proceedings of the 2019 ACM SIGSAC Conference on Computer and Communications Security, ser. CCS '19. New York, NY, USA: Association for Computing Machinery, 2019, p. 1283-1297. [Online]. Available: https://doi.org/10.1145/3319535.3363226</p>
<p>Deeplog: Anomaly detection and diagnosis from system logs through deep learning. M Du, F Li, G Zheng, V Srikumar, Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security, ser. CCS '17. the 2017 ACM SIGSAC Conference on Computer and Communications Security, ser. CCS '17New York, NY, USAACMM. Du, F. Li, G. Zheng, and V. Srikumar, "Deeplog: Anomaly detection and diagnosis from system logs through deep learning," in Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communica- tions Security, ser. CCS '17. New York, NY, USA: ACM, 2017, pp. 1285-1298.</p>
<p>Hierarchical attentionbased anomaly detection model for embedded operating systems. M O Ezeme, Q H Mahmoud, A Azim, 2018 IEEE 24th International Conference on Embedded and Real-Time Computing Systems and Applications (RTCSA). M. O. Ezeme, Q. H. Mahmoud, and A. Azim, "Hierarchical attention- based anomaly detection model for embedded operating systems," in 2018 IEEE 24th International Conference on Embedded and Real-Time Computing Systems and Applications (RTCSA), Aug 2018, pp. 225-231.</p>
<p>Dream: Deep recursive attentive model for anomaly detection in kernel events. O M Ezeme, Q H Mahmoud, A Azim, IEEE Access. 7O. M. Ezeme, Q. H. Mahmoud, and A. Azim, "Dream: Deep recursive attentive model for anomaly detection in kernel events," IEEE Access, vol. 7, pp. 18 860-18 870, 2019.</p>
<p>Quantitative comparison of unsupervised anomaly detection algorithms for intrusion detection. F Falcão, T Zoppi, C B V Silva, A Santos, B Fonseca, A Ceccarelli, A Bondavalli, 10.1145/3297280.3297314Proceedings of the 34th ACM/SIGAPP Symposium on Applied Computing, ser. SAC '19. the 34th ACM/SIGAPP Symposium on Applied Computing, ser. SAC '19New York, NY, USAAssociation for Computing MachineryF. Falcão, T. Zoppi, C. B. V. Silva, A. Santos, B. Fonseca, A. Ceccarelli, and A. Bondavalli, "Quantitative comparison of unsupervised anomaly detection algorithms for intrusion detection," in Proceedings of the 34th ACM/SIGAPP Symposium on Applied Computing, ser. SAC '19. New York, NY, USA: Association for Computing Machinery, 2019, p. 318-327. [Online]. Available: https://doi.org/10.1145/3297280.3297314</p>
<p>Execution anomaly detection in distributed systems through unstructured log analysis. Q Fu, J.-G Lou, Y Wang, J Li, International conference on Data Mining. full paperQ. Fu, J.-G. Lou, Y. Wang, and J. Li, "Execution anomaly detection in distributed systems through unstructured log analysis," in International conference on Data Mining (full paper).</p>
<p>. IEEE. IEEE, December 2009. [Online].</p>
<p>Speech recognition with deep recurrent neural networks. A Graves, A Rahman Mohamed, G Hinton, A. Graves, A. rahman Mohamed, and G. Hinton, "Speech recognition with deep recurrent neural networks," 2013.</p>
<p>LSTM: A search space odyssey. K Greff, R K Srivastava, J Koutník, B R Steunebrink, J Schmidhuber, abs/1503.04069CoRR. K. Greff, R. K. Srivastava, J. Koutník, B. R. Steunebrink, and J. Schmidhuber, "LSTM: A search space odyssey," CoRR, vol. abs/1503.04069, 2015. [Online]. Available: http://arxiv.org/abs/1503. 04069</p>
<p>Experience report: System log analysis for anomaly detection. S He, J Zhu, P He, M R Lyu, 2016 IEEE 27th International Symposium on Software Reliability Engineering (ISSRE). S. He, J. Zhu, P. He, and M. R. Lyu, "Experience report: System log analysis for anomaly detection," in 2016 IEEE 27th International Symposium on Software Reliability Engineering (ISSRE), Oct 2016, pp. 207-218.</p>
<p>Training and analysing deep recurrent neural networks. M Hermans, B Schrauwen, Advances in Neural Information Processing Systems. C. J. C. Burges, L. Bottou, M. Welling, Z. Ghahramani, and K. Q. WeinbergerCurran Associates, Inc26M. Hermans and B. Schrauwen, "Training and analysing deep recurrent neural networks," in Advances in Neural Information Processing Systems 26, C. J. C. Burges, L. Bottou, M. Welling, Z. Ghahramani, and K. Q. Weinberger, Eds. Curran Associates, Inc., 2013, pp. 190-198. [Online]. Available: http://papers.nips.cc/paper/ 5166-training-and-analysing-deep-recurrent-neural-networks.pdf</p>
<p>Long short-term memory. S Hochreiter, J Schmidhuber, 10.1162/neco.1997.9.8.1735Neural Computation. 98S. Hochreiter and J. Schmidhuber, "Long short-term memory," Neural Computation, vol. 9, no. 8, pp. 1735-1780, 1997. [Online]. Available: https://doi.org/10.1162/neco.1997.9.8.1735</p>
<p>Anomalous user activity detection in enterprise multi-source logs. Q Hu, B Tang, D Lin, 2017 IEEE International Conference on Data Mining Workshops (ICDMW). Q. Hu, B. Tang, and D. Lin, "Anomalous user activity detection in enterprise multi-source logs," in 2017 IEEE International Conference on Data Mining Workshops (ICDMW), Nov 2017, pp. 797-803.</p>
<p>An empirical exploration of recurrent network architectures. R Jozefowicz, W Zaremba, I Sutskever, International conference on machine learning. R. Jozefowicz, W. Zaremba, and I. Sutskever, "An empirical exploration of recurrent network architectures," in International conference on machine learning, 2015, pp. 2342-2350.</p>
<p>An efficient hybrid svdd/clustering approach for anomaly-based intrusion detection. T Kenaza, K Bennaceur, A Labed, 10.1145/3167132.3167180Proceedings of the 33rd Annual ACM Symposium on Applied Computing, ser. SAC '18. the 33rd Annual ACM Symposium on Applied Computing, ser. SAC '18New York, NY, USAAssociation for Computing MachineryT. Kenaza, K. Bennaceur, and A. Labed, "An efficient hybrid svdd/clustering approach for anomaly-based intrusion detection," in Proceedings of the 33rd Annual ACM Symposium on Applied Computing, ser. SAC '18. New York, NY, USA: Association for Computing Machinery, 2018, p. 435-443. [Online]. Available: https://doi.org/10.1145/3167132.3167180</p>
<p>Word Embedding for Understanding Natural Language: A Survey. Y Li, T Yang, Springer International PublishingChamY. Li and T. Yang, Word Embedding for Understanding Natural Lan- guage: A Survey. Cham: Springer International Publishing, 2018, pp. 83-104.</p>
<p>Log2vec: A heterogeneous graph embedding based approach for detecting cyber threats within enterprise. F Liu, Y Wen, D Zhang, X Jiang, X Xing, D Meng, Proceedings of the 2019 ACM SIGSAC Conference on Computer and Communications Security, ser. CCS '19. the 2019 ACM SIGSAC Conference on Computer and Communications Security, ser. CCS '19New York, NY, USAAssociation for Computing MachineryF. Liu, Y. Wen, D. Zhang, X. Jiang, X. Xing, and D. Meng, "Log2vec: A heterogeneous graph embedding based approach for detecting cyber threats within enterprise," in Proceedings of the 2019 ACM SIGSAC Conference on Computer and Communications Security, ser. CCS '19. New York, NY, USA: Association for Computing Machinery, 2019, p. 1777-1794.</p>
<p>Insider threat identification using the simultaneous neural learning of multi-source logs. L Liu, C Chen, J Zhang, O De Vel, Y Xiang, IEEE Access. 7L. Liu, C. Chen, J. Zhang, O. De Vel, and Y. Xiang, "Insider threat identification using the simultaneous neural learning of multi-source logs," IEEE Access, vol. 7, pp. 183 162-183 176, 2019.</p>
<p>Anomalybased insider threat detection using deep autoencoders. L Liu, O De, C Vel, J Chen, Y Zhang, Xiang, 2018 IEEE International Conference on Data Mining Workshops (ICDMW). L. Liu, O. De Vel, C. Chen, J. Zhang, and Y. Xiang, "Anomaly- based insider threat detection using deep autoencoders," in 2018 IEEE International Conference on Data Mining Workshops (ICDMW), Nov 2018, pp. 39-48.</p>
<p>Unsupervised insider detection through neural feature learning and model optimisation. L Liu, C Chen, J Zhang, O De Vel, Y Xiang, Network and System Security, J. K. Liu and X. HuangSpringer International PublishingL. Liu, C. Chen, J. Zhang, O. De Vel, and Y. Xiang, "Unsupervised insider detection through neural feature learning and model optimisa- tion," in Network and System Security, J. K. Liu and X. Huang, Eds. Cham: Springer International Publishing, 2019, pp. 18-36.</p>
<p>An integrated method for anomaly detection from massive system logs. Z Liu, T Qin, X Guan, H Jiang, C Wang, IEEE Access. 6611Z. Liu, T. Qin, X. Guan, H. Jiang, and C. Wang, "An integrated method for anomaly detection from massive system logs," IEEE Access, vol. 6, pp. 30 602-30 611, 2018.</p>
<p>Exploiting embedding manifold of autoencoders for hyperspectral anomaly detection. X Lu, W Zhang, J Huang, IEEE Transactions on Geoscience and Remote Sensing. 583X. Lu, W. Zhang, and J. Huang, "Exploiting embedding manifold of autoencoders for hyperspectral anomaly detection," IEEE Transactions on Geoscience and Remote Sensing, vol. 58, no. 3, pp. 1527-1537, March 2020.</p>
<p>Elicit: A system for detecting insiders who violate need-to-know. M A Maloof, G D Stephens, Proceedings of the 10th International Conference on Recent Advances in Intrusion Detection, ser. RAID'07. the 10th International Conference on Recent Advances in Intrusion Detection, ser. RAID'07Berlin, HeidelbergSpringer-VerlagM. A. Maloof and G. D. Stephens, "Elicit: A system for detecting insid- ers who violate need-to-know," in Proceedings of the 10th International Conference on Recent Advances in Intrusion Detection, ser. RAID'07. Berlin, Heidelberg: Springer-Verlag, 2007, p. 146-166.</p>
<p>Kitsune: An ensemble of autoencoders for online network intrusion detection. Y Mirsky, T Doitshman, Y Elovici, A Shabtai, Y. Mirsky, T. Doitshman, Y. Elovici, and A. Shabtai, "Kitsune: An ensemble of autoencoders for online network intrusion detection," 2018.</p>
<p>Gee: A gradient-based explainable variational autoencoder for network anomaly detection. Q P Nguyen, K W Lim, D M Divakaran, K H Low, M C Chan, 2019 IEEE Conference on Communications and Network Security (CNS). Q. P. Nguyen, K. W. Lim, D. M. Divakaran, K. H. Low, and M. C. Chan, "Gee: A gradient-based explainable variational autoencoder for network anomaly detection," in 2019 IEEE Conference on Communications and Network Security (CNS), June 2019, pp. 91-99.</p>
<p>Detection of earlystage enterprise infection by mining large-scale log data. A Oprea, Z Li, T Yen, S H Chin, S Alrwais, 2015 45th Annual IEEE/IFIP International Conference on Dependable Systems and Networks. A. Oprea, Z. Li, T. Yen, S. H. Chin, and S. Alrwais, "Detection of early- stage enterprise infection by mining large-scale log data," in 2015 45th Annual IEEE/IFIP International Conference on Dependable Systems and Networks, June 2015, pp. 45-56.</p>
<p>How to construct deep recurrent neural networks. R Pascanu, C Gulcehre, K Cho, Y Bengio, R. Pascanu, C. Gulcehre, K. Cho, and Y. Bengio, "How to construct deep recurrent neural networks," 2013.</p>
<p>Mimicking word embeddings using subword RNNs. Y Pinter, R Guthrie, J Eisenstein, Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing. the 2017 Conference on Empirical Methods in Natural Language ProcessingCopenhagen, DenmarkAssociation for Computational LinguisticsY. Pinter, R. Guthrie, and J. Eisenstein, "Mimicking word embeddings using subword RNNs," in Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing. Copenhagen, Denmark: Association for Computational Linguistics, Sep. 2017, pp. 102-112. [Online]. Available: https://www.aclweb.org/anthology/ D17-1010</p>
<p>Anomaly detection using autoencoders with nonlinear dimensionality reduction. M Sakurada, T Yairi, 10.1145/2689746.2689747Proceedings of the MLSDA 2014 2nd Workshop on Machine Learning for Sensory Data Analysis, ser. MLSDA'14. the MLSDA 2014 2nd Workshop on Machine Learning for Sensory Data Analysis, ser. MLSDA'14New York, NY, USAAssociation for Computing MachineryM. Sakurada and T. Yairi, "Anomaly detection using autoencoders with nonlinear dimensionality reduction," in Proceedings of the MLSDA 2014 2nd Workshop on Machine Learning for Sensory Data Analysis, ser. MLSDA'14. New York, NY, USA: Association for Computing Machinery, 2014, p. 4-11. [Online]. Available: https://doi.org/10.1145/2689746.2689747</p>
<p>A deep learning approach to network intrusion detection. N Shone, T N Ngoc, V D Phai, Q Shi, IEEE Transactions on Emerging Topics in Computational Intelligence. 21N. Shone, T. N. Ngoc, V. D. Phai, and Q. Shi, "A deep learning approach to network intrusion detection," IEEE Transactions on Emerging Topics in Computational Intelligence, vol. 2, no. 1, pp. 41-50, Feb 2018.</p>
<p>Unsupervised learning of video representations using lstms. N Srivastava, E Mansimov, R Salakhutdinov, abs/1502.04681CoRR. N. Srivastava, E. Mansimov, and R. Salakhutdinov, "Unsupervised learning of video representations using lstms," CoRR, vol. abs/1502.04681, 2015. [Online]. Available: http://arxiv.org/abs/1502. 04681</p>
<p>advae: A self-adversarial variational autoencoder with gaussian anomaly prior knowledge for anomaly detection. X Wang, Y Du, S Lin, P Cui, Y Shen, Y Yang, Knowledge-Based Systems. 190105187X. Wang, Y. Du, S. Lin, P. Cui, Y. Shen, and Y. Yang, "advae: A self-adversarial variational autoencoder with gaussian anomaly prior knowledge for anomaly detection," Knowledge- Based Systems, vol. 190, p. 105187, 2020. [Online]. Available: http://www.sciencedirect.com/science/article/pii/S0950705119305283</p>
<p>Online system problem detection by mining patterns of console logs. W Xu, L Huang, A Fox, D Patterson, M Jordan, 10.1109/ICDM.2009.19Proceedings of the 2009 Ninth IEEE International Conference on Data Mining, ser. ICDM '09. the 2009 Ninth IEEE International Conference on Data Mining, ser. ICDM '09USAIEEE Computer SocietyW. Xu, L. Huang, A. Fox, D. Patterson, and M. Jordan, "Online system problem detection by mining patterns of console logs," in Proceedings of the 2009 Ninth IEEE International Conference on Data Mining, ser. ICDM '09. USA: IEEE Computer Society, 2009, p. 588-597. [Online]. Available: https://doi.org/10.1109/ICDM.2009.19</p>
<p>Detecting large-scale system problems by mining console logs. W Xu, L Huang, A Fox, D Patterson, M I Jordan, 10.1145/1629575.1629587Proceedings of the ACM SIGOPS 22nd Symposium on Operating Systems Principles, ser. SOSP '09. the ACM SIGOPS 22nd Symposium on Operating Systems Principles, ser. SOSP '09New York, NY, USAAssociation for Computing MachineryW. Xu, L. Huang, A. Fox, D. Patterson, and M. I. Jordan, "Detecting large-scale system problems by mining console logs," in Proceedings of the ACM SIGOPS 22nd Symposium on Operating Systems Principles, ser. SOSP '09. New York, NY, USA: Association for Computing Machinery, 2009, p. 117-132. [Online]. Available: https://doi.org/10.1145/1629575.1629587</p>
<p>nlsalog: An anomaly detection framework for log sequence in security management. R Yang, D Qu, Y Gao, Y Qian, Y Tang, IEEE Access. 7R. Yang, D. Qu, Y. Gao, Y. Qian, and Y. Tang, "nlsalog: An anomaly detection framework for log sequence in security management," IEEE Access, vol. 7, pp. 181 152-181 164, 2019.</p>
<p>Autoencoder-based feature learning for cyber security applications. M Yousefi-Azar, V Varadharajan, L Hamey, U Tupakula, 2017 International Joint Conference on Neural Networks (IJCNN). M. Yousefi-Azar, V. Varadharajan, L. Hamey, and U. Tupakula, "Autoencoder-based feature learning for cyber security applications," in 2017 International Joint Conference on Neural Networks (IJCNN), May 2017, pp. 3854-3861.</p>
<p>Anomaly detection with robust deep autoencoders. C Zhou, R C Paffenroth, 10.1145/3097983.3098052Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, ser. KDD '17. the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, ser. KDD '17New York, NY, USAAssociation for Computing MachineryC. Zhou and R. C. Paffenroth, "Anomaly detection with robust deep autoencoders," in Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, ser. KDD '17. New York, NY, USA: Association for Computing Machinery, 2017, p. 665-674. [Online]. Available: https://doi.org/10.1145/3097983.3098052</p>
<p>Deep autoencoding gaussian mixture model for unsupervised anomaly detection. B Zong, Q Song, M R Min, W Cheng, C Lumezanu, D Cho, H Chen, International Conference on Learning Representations. B. Zong, Q. Song, M. R. Min, W. Cheng, C. Lumezanu, D. Cho, and H. Chen, "Deep autoencoding gaussian mixture model for unsupervised anomaly detection," in International Conference on Learning Representations, 2018. [Online]. Available: https: //openreview.net/forum?id=BJJLHbb0-</p>            </div>
        </div>

    </div>
</body>
</html>