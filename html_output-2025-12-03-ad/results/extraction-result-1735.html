<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-1735 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-1735</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-1735</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-31.html">extraction-schema-31</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of genetic/evolutionary algorithms that use crossover and mutation operations on code, programs, or literature to generate new solutions, with particular attention to measures of novelty, diversity, executability, and functionality.</div>
                <p><strong>Paper ID:</strong> paper-35a49bd6a958dcb1a088a061d031cbb1a587b186</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/35a49bd6a958dcb1a088a061d031cbb1a587b186" target="_blank">Effective mutation rate adaptation through group elite selection</a></p>
                <p><strong>Paper Venue:</strong> Annual Conference on Genetic and Evolutionary Computation</p>
                <p><strong>Paper TL;DR:</strong> The Group Elite Selection of Mutation Rates (GESMR) algorithm and its theoretical and empirical analysis demonstrate how self-adaptation can be harnessed to improve performance in several applications of evolutionary computation.</p>
                <p><strong>Paper Abstract:</strong> Evolutionary algorithms are sensitive to the mutation rate (MR); no single value of this parameter works well across domains. Self-adaptive MR approaches have been proposed but they tend to be brittle: Sometimes they decay the MR to zero, thus halting evolution. To make self-adaptive MR robust, this paper introduces the Group Elite Selection of Mutation Rates (GESMR) algorithm. GESMR co-evolves a population of solutions and a population of MRs, such that each MR is assigned to a group of solutions. The resulting best mutational change in the group, instead of average mutational change, is used for MR selection during evolution, thus avoiding the vanishing MR problem. With the same number of function evaluations and with almost no overhead, GESMR converges faster and to better solutions than previous approaches on a wide range of continuous test optimization problems. GESMR also scales well to high-dimensional neuroevolution for supervised image-classification tasks and for reinforcement learning control tasks. Remarkably, GESMR produces MRs that are optimal in the long-term, as demonstrated through a comprehensive look-ahead grid search. Thus, GESMR and its theoretical and empirical analysis demonstrate how self-adaptation can be harnessed to improve performance in several applications of evolutionary computation.</p>
                <p><strong>Cost:</strong> 0.015</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e1735.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e1735.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of genetic/evolutionary algorithms that use crossover and mutation operations on code, programs, or literature to generate new solutions, with particular attention to measures of novelty, diversity, executability, and functionality.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GESMR</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Group Elite Selection of Mutation Rates</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An adaptive mutation-rate genetic algorithm that co-evolves a population of scalar mutation rates (σ) and a population of candidate solutions, assigning each σ to a group of solutions and selecting mutation rates based on the best (group-elite) fitness change produced in that group to avoid vanishing mutation rates.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>GESMR</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>GESMR maintains two co-evolving populations: (1) N+1 candidate solutions (real-valued genotypes, including neural-network weight vectors for neuroevolution tasks) and (2) K positive scalar mutation rates σ_k. At each generation the non-elite solutions are partitioned into K groups (equal size) and each group is mutated using its assigned σ_k via Gaussian additive mutation x' = x + σ ε (ε ~ N(0,I)); after evaluating offspring, each σ_k is scored by the best change in objective (Δ_k = min_i f(x_i') - f(x_i) among that group). MRs are then evolved with truncation selection (one elite) and a multiplicative meta-mutation σ' = σ * τ^{ε} (ε ~ U(-1,1)), producing new σ population for next generation. No crossover operator is used in experiments (explicitly omitted to isolate mutation-rate effects). The algorithm's goal is to adapt σ for long-term improvement while avoiding the vanishing-mutation-rate problem common in self-adaptation.</td>
                        </tr>
                        <tr>
                            <td><strong>input_type</strong></td>
                            <td>real-valued solution vectors (continuous genotypes); neural network weight vectors in neuroevolution; controller parameter vectors in RL tasks</td>
                        </tr>
                        <tr>
                            <td><strong>crossover_operation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>mutation_operation</strong></td>
                            <td>Solution mutation: Gaussian additive mutation M(x;σ) = x + σ ε, with ε ~ N(0,I). Mutation-rate (meta-)mutation for σ: M_σ(σ;τ) = σ * τ^{ε} with ε ~ U(-1,1) (continuous uniform) and fixed meta-rate τ (e.g., τ=2 in experiments).</td>
                        </tr>
                        <tr>
                            <td><strong>uses_literature</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>uses_code</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_metric</strong></td>
                            <td>Outlier/objective Δ-based metric: Δ(x,σ) = f(M(x;σ)) - f(x). For an MR σ_k assigned to a group, MR worth is Δ_k = min_{i in group} Δ(x_i,σ_k) (the best/bottom-of-group change). GESMR selects σ to minimize this outlier statistic (the 'outlier objective').</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>executability_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>executability_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>diversity_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>diversity_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_executability_tradeoff</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>frontier_characterization</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_or_domain</strong></td>
                            <td>Continuous optimization benchmarks (Ackley, Griewank, Rastrigin, Rosenbrock, Sphere, Linear) across dimensions {2,10,100,1000}; neuroevolution for image classification (MNIST, Fashion-MNIST); neuroevolution for reinforcement-learning control (CartPole, Pendulum, Acrobot, MountainCar).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Compared against: OFMR (optimal fixed MR via grid search), LAMR-G (look-ahead MR via grid search every G generations), FMR (fixed MR), 1CMR (1/d), 15MR (1/5 success-rule heuristic), UCB/R (multi-armed bandit adaptive MR), SAMR (self-adaptive MR), GESMR-AVG (uses group mean Δ instead of min), GESMR-FIX (σs fixed), and CMA-ES (covariance matrix adaptation) as a separate comparator.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>GESMR selects mutation rates by maximizing the best mutation outcome within groups (min Δ), which provably avoids the vanishing-mutation-rate problem that afflicts self-adaptive MR (SAMR) in rugged landscapes. Empirically, GESMR converges faster and to better final objective values than most baselines across diverse continuous benchmarks and scales to high-dimensional neuroevolution and RL tasks; it also closely matches the long-term oracle (LAMR-100) mutation-rate trajectory (lowest mean-squared-error to LAMR-100 among non-oracle methods). The paper demonstrates that the mean objective (expected Δ) is minimized at σ→0 (leading SAMR to shrink σ), while the outlier objective (expected min Δ over group samples) is minimized at σ>0, explaining why GESMR maintains nonzero σ and better exploration. No crossover is used; novelty/diversity/executability as concepts are operationalized via Δ statistics and final elite fitness rather than explicit novelty/diversity or executability metrics.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Effective mutation rate adaptation through group elite selection', 'publication_date_yy_mm': '2022-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1735.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e1735.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of genetic/evolutionary algorithms that use crossover and mutation operations on code, programs, or literature to generate new solutions, with particular attention to measures of novelty, diversity, executability, and functionality.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>SAMR</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Self-Adaptive Mutation Rates (self-adaptation of MR)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A class of genetic-algorithm techniques that concatenate a mutation-rate parameter to each individual and evolve both genotype and attached σ end-to-end; σ is mutated by a meta-mutation operator and selected indirectly through selection on individual fitness.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Self-Adaptive Mutation Rates (SAMR)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Each individual is represented as a pair (x_i, σ_i); solution x_i is mutated using its own σ_i and σ_i itself is mutated by a meta-mutation (e.g., multiplicative mutation with meta-rate τ). Selection operates on the pairs so σ_i values are carried forward indirectly when associated x_i have high fitness. In this paper SAMR implementation used σs spaced logarithmically and the σ meta-mutation σ' = σ * τ^{ε} with τ=2; selection uses truncation with one elite. Experiments explicitly compare SAMR against GESMR and other baselines.</td>
                        </tr>
                        <tr>
                            <td><strong>input_type</strong></td>
                            <td>real-valued solution vectors; neural network weight vectors in neuroevolution; controller parameters in RL tasks</td>
                        </tr>
                        <tr>
                            <td><strong>crossover_operation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>mutation_operation</strong></td>
                            <td>Solution mutation: Gaussian additive mutation M(x;σ) = x + σ ε, ε ~ N(0,I). MR meta-mutation: multiplicative operator σ' = σ * τ^{ε}, ε ~ U(-1,1).</td>
                        </tr>
                        <tr>
                            <td><strong>uses_literature</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>uses_code</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_metric</strong></td>
                            <td>Implicit/indirect: SAMR optimizes for expected short-term fitness via selection on (x,σ) pairs; mathematically aligned with mean objective E[Δ] = E[f(M(x;σ)) - f(x)]. The paper links SAMR behavior to minimizing the mean Δ, which tends to favor σ→0 in rugged landscapes.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>executability_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>executability_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>diversity_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>diversity_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_executability_tradeoff</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>frontier_characterization</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_or_domain</strong></td>
                            <td>Same continuous benchmarks and neuroevolution/RL domains as used for evaluation in the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Compared against GESMR, OFMR, LAMR-G, 15MR, UCB/R, fixed MRs, CMA-ES, and ablations (GESMR-AVG, GESMR-FIX).</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>SAMR frequently suffers from the vanishing mutation-rate problem (VMRP) in rugged fitness landscapes because it effectively optimizes the mean Δ objective which is minimized by σ→0; as a result SAMR tends to converge prematurely to low σ and worse final fitness. SAMR can perform well only on smoother landscapes (e.g., Rosenbrock, Sphere) where small σ is appropriate.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Effective mutation rate adaptation through group elite selection', 'publication_date_yy_mm': '2022-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1735.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e1735.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of genetic/evolutionary algorithms that use crossover and mutation operations on code, programs, or literature to generate new solutions, with particular attention to measures of novelty, diversity, executability, and functionality.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>UCB/R</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>UCB-based adaptive mutation-rate with R arms (multi-armed bandit operator selection)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An adaptive MR technique that treats a discrete set of candidate mutation rates as arms in a multi-armed bandit and selects an MR each generation using an upper-confidence-bound (UCB) algorithm; reward is reported as the best (lowest) change in fitness produced that generation.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>UCB/R (multi-armed bandit MR selection)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Create R discrete MR arms sampled logarithmically across a range; at each generation select one arm via UCB, apply that MR to mutate solutions, and report reward equal to the best (minimum) Δ observed; UCB updates arm value estimates. Used as baseline in experiments (variants UCB/5, UCB/10).</td>
                        </tr>
                        <tr>
                            <td><strong>input_type</strong></td>
                            <td>real-valued solution vectors; neural network weight vectors</td>
                        </tr>
                        <tr>
                            <td><strong>crossover_operation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>mutation_operation</strong></td>
                            <td>Solution mutation uses the chosen MR (Gaussian additive mutation x' = x + σ ε). No MR meta-evolution; MR choices are from a fixed discrete set of arms.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_literature</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>uses_code</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_metric</strong></td>
                            <td>Bandit reward uses the best Δ in generation (an extreme-value reward), akin to selecting by outlier performance rather than mean.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>executability_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>executability_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>diversity_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>diversity_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_executability_tradeoff</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>frontier_characterization</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_or_domain</strong></td>
                            <td>Used as baseline on the continuous optimization benchmarks and high-dimensional neuroevolution tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Compared directly against GESMR, SAMR, 15MR, fixed MRs, and oracle methods in the experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>UCB-based selection can be limited by the discrete and quantized set of arms and fails to match continuous MR adaptation such as GESMR which can evolve σ arbitrarily; UCB approaches were outperformed by GESMR in many rugged/high-dimensional problems because arm discretization and independence assumptions limit expressiveness.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Effective mutation rate adaptation through group elite selection', 'publication_date_yy_mm': '2022-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1735.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e1735.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of genetic/evolutionary algorithms that use crossover and mutation operations on code, programs, or literature to generate new solutions, with particular attention to measures of novelty, diversity, executability, and functionality.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>15MR</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>1/5 Success Rule (15MR) adaptive mutation heuristic</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A heuristic rule that adapts the mutation rate by doubling it when the fraction of beneficial mutations exceeds 1/5 and halving it otherwise (the classic 1/5 success rule from evolution strategies).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>15MR (1/5 success-rule MR adaptation)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Start with an initial MR (e.g. 1e-2); each generation compute percentage of beneficial mutations (Δ<0). If >1/5, MR := 2*MR; else MR := MR/2. No per-individual σ; global MR updated heuristically. Used as a strong baseline in experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>input_type</strong></td>
                            <td>real-valued solution vectors; neural network weight vectors</td>
                        </tr>
                        <tr>
                            <td><strong>crossover_operation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>mutation_operation</strong></td>
                            <td>Solution mutation: Gaussian additive mutation with current global MR σ; MR adaptation via multiplicative factor of two based on success fraction.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_literature</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>uses_code</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_metric</strong></td>
                            <td>Uses fraction of beneficial mutations (percentage with Δ<0) as the adaptation signal (target 1/5).</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>executability_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>executability_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>diversity_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>diversity_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_executability_tradeoff</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>frontier_characterization</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_or_domain</strong></td>
                            <td>Test optimization functions, neuroevolution (MNIST/Fashion-MNIST) and RL control tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Compared against GESMR, SAMR, UCB/R, fixed MR baselines, and oracle methods.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>15MR is a simple heuristic that performed very well on some domains (notably MNIST neuroevolution in this paper), sometimes outperforming GESMR, suggesting that domain-specific heuristics can be competitive; however, it is ad-hoc and may not generalize across landscapes.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Effective mutation rate adaptation through group elite selection', 'publication_date_yy_mm': '2022-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1735.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e1735.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of genetic/evolutionary algorithms that use crossover and mutation operations on code, programs, or literature to generate new solutions, with particular attention to measures of novelty, diversity, executability, and functionality.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>CMA-ES</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Covariance Matrix Adaptation Evolution Strategy</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A state-of-the-art evolution strategy that adapts a full covariance matrix of the search distribution to control search step-sizes and correlations, rather than a single scalar mutation rate.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>CMA-ES</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Maintains a multivariate Gaussian search distribution with mean and covariance; updates the covariance matrix and step-size to shape search according to successful steps; effective but requires quadratic memory/time in genotype dimensionality, limiting scalability to very high-dimensional neuroevolution problems.</td>
                        </tr>
                        <tr>
                            <td><strong>input_type</strong></td>
                            <td>real-valued solution vectors</td>
                        </tr>
                        <tr>
                            <td><strong>crossover_operation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>mutation_operation</strong></td>
                            <td>Samples offspring from multivariate Gaussian with learned covariance and step-size; no simple scalar σ per individual (covariance generalizes MR).</td>
                        </tr>
                        <tr>
                            <td><strong>uses_literature</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>uses_code</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>executability_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>executability_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>diversity_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>diversity_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_executability_tradeoff</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>frontier_characterization</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_or_domain</strong></td>
                            <td>Compared as a strong optimizer baseline on continuous test functions (100-D problems) given the same computational budget.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Compared against GESMR in experiments; GESMR outperformed CMA-ES on several challenging high-dimensional problems within the same time budget.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Although CMA-ES is powerful, its quadratic resource cost limits the number of generations for a fixed budget; GESMR completed far more generations and outperformed CMA-ES on several 100-D tasks under equal runtime constraints.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Effective mutation rate adaptation through group elite selection', 'publication_date_yy_mm': '2022-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Self-Adaptation in Genetic Algorithms <em>(Rating: 2)</em></li>
                <li>Extreme Value Based Adaptive Operator Selection <em>(Rating: 2)</em></li>
                <li>Natural selection fails to optimize mutation rates for long-term adaptation on rugged fitness landscapes <em>(Rating: 2)</em></li>
                <li>The CMA Evolution Strategy: A Tutorial <em>(Rating: 1)</em></li>
                <li>Use of statistical outlier detection method in adaptive evolutionary algorithms <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-1735",
    "paper_id": "paper-35a49bd6a958dcb1a088a061d031cbb1a587b186",
    "extraction_schema_id": "extraction-schema-31",
    "extracted_data": [
        {
            "name_short": "GESMR",
            "name_full": "Group Elite Selection of Mutation Rates",
            "brief_description": "An adaptive mutation-rate genetic algorithm that co-evolves a population of scalar mutation rates (σ) and a population of candidate solutions, assigning each σ to a group of solutions and selecting mutation rates based on the best (group-elite) fitness change produced in that group to avoid vanishing mutation rates.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "GESMR",
            "system_description": "GESMR maintains two co-evolving populations: (1) N+1 candidate solutions (real-valued genotypes, including neural-network weight vectors for neuroevolution tasks) and (2) K positive scalar mutation rates σ_k. At each generation the non-elite solutions are partitioned into K groups (equal size) and each group is mutated using its assigned σ_k via Gaussian additive mutation x' = x + σ ε (ε ~ N(0,I)); after evaluating offspring, each σ_k is scored by the best change in objective (Δ_k = min_i f(x_i') - f(x_i) among that group). MRs are then evolved with truncation selection (one elite) and a multiplicative meta-mutation σ' = σ * τ^{ε} (ε ~ U(-1,1)), producing new σ population for next generation. No crossover operator is used in experiments (explicitly omitted to isolate mutation-rate effects). The algorithm's goal is to adapt σ for long-term improvement while avoiding the vanishing-mutation-rate problem common in self-adaptation.",
            "input_type": "real-valued solution vectors (continuous genotypes); neural network weight vectors in neuroevolution; controller parameter vectors in RL tasks",
            "crossover_operation": null,
            "mutation_operation": "Solution mutation: Gaussian additive mutation M(x;σ) = x + σ ε, with ε ~ N(0,I). Mutation-rate (meta-)mutation for σ: M_σ(σ;τ) = σ * τ^{ε} with ε ~ U(-1,1) (continuous uniform) and fixed meta-rate τ (e.g., τ=2 in experiments).",
            "uses_literature": false,
            "uses_code": false,
            "novelty_metric": "Outlier/objective Δ-based metric: Δ(x,σ) = f(M(x;σ)) - f(x). For an MR σ_k assigned to a group, MR worth is Δ_k = min_{i in group} Δ(x_i,σ_k) (the best/bottom-of-group change). GESMR selects σ to minimize this outlier statistic (the 'outlier objective').",
            "novelty_results": null,
            "executability_metric": null,
            "executability_results": null,
            "diversity_metric": null,
            "diversity_results": null,
            "novelty_executability_tradeoff": null,
            "frontier_characterization": null,
            "benchmark_or_domain": "Continuous optimization benchmarks (Ackley, Griewank, Rastrigin, Rosenbrock, Sphere, Linear) across dimensions {2,10,100,1000}; neuroevolution for image classification (MNIST, Fashion-MNIST); neuroevolution for reinforcement-learning control (CartPole, Pendulum, Acrobot, MountainCar).",
            "comparison_baseline": "Compared against: OFMR (optimal fixed MR via grid search), LAMR-G (look-ahead MR via grid search every G generations), FMR (fixed MR), 1CMR (1/d), 15MR (1/5 success-rule heuristic), UCB/R (multi-armed bandit adaptive MR), SAMR (self-adaptive MR), GESMR-AVG (uses group mean Δ instead of min), GESMR-FIX (σs fixed), and CMA-ES (covariance matrix adaptation) as a separate comparator.",
            "key_findings": "GESMR selects mutation rates by maximizing the best mutation outcome within groups (min Δ), which provably avoids the vanishing-mutation-rate problem that afflicts self-adaptive MR (SAMR) in rugged landscapes. Empirically, GESMR converges faster and to better final objective values than most baselines across diverse continuous benchmarks and scales to high-dimensional neuroevolution and RL tasks; it also closely matches the long-term oracle (LAMR-100) mutation-rate trajectory (lowest mean-squared-error to LAMR-100 among non-oracle methods). The paper demonstrates that the mean objective (expected Δ) is minimized at σ→0 (leading SAMR to shrink σ), while the outlier objective (expected min Δ over group samples) is minimized at σ&gt;0, explaining why GESMR maintains nonzero σ and better exploration. No crossover is used; novelty/diversity/executability as concepts are operationalized via Δ statistics and final elite fitness rather than explicit novelty/diversity or executability metrics.",
            "uuid": "e1735.0",
            "source_info": {
                "paper_title": "Effective mutation rate adaptation through group elite selection",
                "publication_date_yy_mm": "2022-04"
            }
        },
        {
            "name_short": "SAMR",
            "name_full": "Self-Adaptive Mutation Rates (self-adaptation of MR)",
            "brief_description": "A class of genetic-algorithm techniques that concatenate a mutation-rate parameter to each individual and evolve both genotype and attached σ end-to-end; σ is mutated by a meta-mutation operator and selected indirectly through selection on individual fitness.",
            "citation_title": "",
            "mention_or_use": "use",
            "system_name": "Self-Adaptive Mutation Rates (SAMR)",
            "system_description": "Each individual is represented as a pair (x_i, σ_i); solution x_i is mutated using its own σ_i and σ_i itself is mutated by a meta-mutation (e.g., multiplicative mutation with meta-rate τ). Selection operates on the pairs so σ_i values are carried forward indirectly when associated x_i have high fitness. In this paper SAMR implementation used σs spaced logarithmically and the σ meta-mutation σ' = σ * τ^{ε} with τ=2; selection uses truncation with one elite. Experiments explicitly compare SAMR against GESMR and other baselines.",
            "input_type": "real-valued solution vectors; neural network weight vectors in neuroevolution; controller parameters in RL tasks",
            "crossover_operation": null,
            "mutation_operation": "Solution mutation: Gaussian additive mutation M(x;σ) = x + σ ε, ε ~ N(0,I). MR meta-mutation: multiplicative operator σ' = σ * τ^{ε}, ε ~ U(-1,1).",
            "uses_literature": false,
            "uses_code": false,
            "novelty_metric": "Implicit/indirect: SAMR optimizes for expected short-term fitness via selection on (x,σ) pairs; mathematically aligned with mean objective E[Δ] = E[f(M(x;σ)) - f(x)]. The paper links SAMR behavior to minimizing the mean Δ, which tends to favor σ→0 in rugged landscapes.",
            "novelty_results": null,
            "executability_metric": null,
            "executability_results": null,
            "diversity_metric": null,
            "diversity_results": null,
            "novelty_executability_tradeoff": null,
            "frontier_characterization": null,
            "benchmark_or_domain": "Same continuous benchmarks and neuroevolution/RL domains as used for evaluation in the paper.",
            "comparison_baseline": "Compared against GESMR, OFMR, LAMR-G, 15MR, UCB/R, fixed MRs, CMA-ES, and ablations (GESMR-AVG, GESMR-FIX).",
            "key_findings": "SAMR frequently suffers from the vanishing mutation-rate problem (VMRP) in rugged fitness landscapes because it effectively optimizes the mean Δ objective which is minimized by σ→0; as a result SAMR tends to converge prematurely to low σ and worse final fitness. SAMR can perform well only on smoother landscapes (e.g., Rosenbrock, Sphere) where small σ is appropriate.",
            "uuid": "e1735.1",
            "source_info": {
                "paper_title": "Effective mutation rate adaptation through group elite selection",
                "publication_date_yy_mm": "2022-04"
            }
        },
        {
            "name_short": "UCB/R",
            "name_full": "UCB-based adaptive mutation-rate with R arms (multi-armed bandit operator selection)",
            "brief_description": "An adaptive MR technique that treats a discrete set of candidate mutation rates as arms in a multi-armed bandit and selects an MR each generation using an upper-confidence-bound (UCB) algorithm; reward is reported as the best (lowest) change in fitness produced that generation.",
            "citation_title": "",
            "mention_or_use": "use",
            "system_name": "UCB/R (multi-armed bandit MR selection)",
            "system_description": "Create R discrete MR arms sampled logarithmically across a range; at each generation select one arm via UCB, apply that MR to mutate solutions, and report reward equal to the best (minimum) Δ observed; UCB updates arm value estimates. Used as baseline in experiments (variants UCB/5, UCB/10).",
            "input_type": "real-valued solution vectors; neural network weight vectors",
            "crossover_operation": null,
            "mutation_operation": "Solution mutation uses the chosen MR (Gaussian additive mutation x' = x + σ ε). No MR meta-evolution; MR choices are from a fixed discrete set of arms.",
            "uses_literature": false,
            "uses_code": false,
            "novelty_metric": "Bandit reward uses the best Δ in generation (an extreme-value reward), akin to selecting by outlier performance rather than mean.",
            "novelty_results": null,
            "executability_metric": null,
            "executability_results": null,
            "diversity_metric": null,
            "diversity_results": null,
            "novelty_executability_tradeoff": null,
            "frontier_characterization": null,
            "benchmark_or_domain": "Used as baseline on the continuous optimization benchmarks and high-dimensional neuroevolution tasks.",
            "comparison_baseline": "Compared directly against GESMR, SAMR, 15MR, fixed MRs, and oracle methods in the experiments.",
            "key_findings": "UCB-based selection can be limited by the discrete and quantized set of arms and fails to match continuous MR adaptation such as GESMR which can evolve σ arbitrarily; UCB approaches were outperformed by GESMR in many rugged/high-dimensional problems because arm discretization and independence assumptions limit expressiveness.",
            "uuid": "e1735.2",
            "source_info": {
                "paper_title": "Effective mutation rate adaptation through group elite selection",
                "publication_date_yy_mm": "2022-04"
            }
        },
        {
            "name_short": "15MR",
            "name_full": "1/5 Success Rule (15MR) adaptive mutation heuristic",
            "brief_description": "A heuristic rule that adapts the mutation rate by doubling it when the fraction of beneficial mutations exceeds 1/5 and halving it otherwise (the classic 1/5 success rule from evolution strategies).",
            "citation_title": "",
            "mention_or_use": "use",
            "system_name": "15MR (1/5 success-rule MR adaptation)",
            "system_description": "Start with an initial MR (e.g. 1e-2); each generation compute percentage of beneficial mutations (Δ&lt;0). If &gt;1/5, MR := 2*MR; else MR := MR/2. No per-individual σ; global MR updated heuristically. Used as a strong baseline in experiments.",
            "input_type": "real-valued solution vectors; neural network weight vectors",
            "crossover_operation": null,
            "mutation_operation": "Solution mutation: Gaussian additive mutation with current global MR σ; MR adaptation via multiplicative factor of two based on success fraction.",
            "uses_literature": false,
            "uses_code": false,
            "novelty_metric": "Uses fraction of beneficial mutations (percentage with Δ&lt;0) as the adaptation signal (target 1/5).",
            "novelty_results": null,
            "executability_metric": null,
            "executability_results": null,
            "diversity_metric": null,
            "diversity_results": null,
            "novelty_executability_tradeoff": null,
            "frontier_characterization": null,
            "benchmark_or_domain": "Test optimization functions, neuroevolution (MNIST/Fashion-MNIST) and RL control tasks.",
            "comparison_baseline": "Compared against GESMR, SAMR, UCB/R, fixed MR baselines, and oracle methods.",
            "key_findings": "15MR is a simple heuristic that performed very well on some domains (notably MNIST neuroevolution in this paper), sometimes outperforming GESMR, suggesting that domain-specific heuristics can be competitive; however, it is ad-hoc and may not generalize across landscapes.",
            "uuid": "e1735.3",
            "source_info": {
                "paper_title": "Effective mutation rate adaptation through group elite selection",
                "publication_date_yy_mm": "2022-04"
            }
        },
        {
            "name_short": "CMA-ES",
            "name_full": "Covariance Matrix Adaptation Evolution Strategy",
            "brief_description": "A state-of-the-art evolution strategy that adapts a full covariance matrix of the search distribution to control search step-sizes and correlations, rather than a single scalar mutation rate.",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_name": "CMA-ES",
            "system_description": "Maintains a multivariate Gaussian search distribution with mean and covariance; updates the covariance matrix and step-size to shape search according to successful steps; effective but requires quadratic memory/time in genotype dimensionality, limiting scalability to very high-dimensional neuroevolution problems.",
            "input_type": "real-valued solution vectors",
            "crossover_operation": null,
            "mutation_operation": "Samples offspring from multivariate Gaussian with learned covariance and step-size; no simple scalar σ per individual (covariance generalizes MR).",
            "uses_literature": false,
            "uses_code": false,
            "novelty_metric": null,
            "novelty_results": null,
            "executability_metric": null,
            "executability_results": null,
            "diversity_metric": null,
            "diversity_results": null,
            "novelty_executability_tradeoff": null,
            "frontier_characterization": null,
            "benchmark_or_domain": "Compared as a strong optimizer baseline on continuous test functions (100-D problems) given the same computational budget.",
            "comparison_baseline": "Compared against GESMR in experiments; GESMR outperformed CMA-ES on several challenging high-dimensional problems within the same time budget.",
            "key_findings": "Although CMA-ES is powerful, its quadratic resource cost limits the number of generations for a fixed budget; GESMR completed far more generations and outperformed CMA-ES on several 100-D tasks under equal runtime constraints.",
            "uuid": "e1735.4",
            "source_info": {
                "paper_title": "Effective mutation rate adaptation through group elite selection",
                "publication_date_yy_mm": "2022-04"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Self-Adaptation in Genetic Algorithms",
            "rating": 2
        },
        {
            "paper_title": "Extreme Value Based Adaptive Operator Selection",
            "rating": 2
        },
        {
            "paper_title": "Natural selection fails to optimize mutation rates for long-term adaptation on rugged fitness landscapes",
            "rating": 2
        },
        {
            "paper_title": "The CMA Evolution Strategy: A Tutorial",
            "rating": 1
        },
        {
            "paper_title": "Use of statistical outlier detection method in adaptive evolutionary algorithms",
            "rating": 1
        }
    ],
    "cost": 0.014603,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>Effective Mutation Rate Adaptation through Group Elite Selection</h1>
<p>Akarsh Kumar<br>The University of Texas at Austin<br>Austin, Texas, USA<br>akarshkumar0101@gmail.com<br>Risto Miikkulainen<br>The University of Texas at Austin<br>and Cognizant AI Labs<br>Austin, Texas, USA<br>risto@cs.utexas.edu</p>
<h2>ABSTRACT</h2>
<p>Evolutionary algorithms are sensitive to the mutation rate (MR); no single value of this parameter works well across domains. Selfadaptive MR approaches have been proposed but they tend to be brittle: Sometimes they decay the MR to zero, thus halting evolution. To make self-adaptive MR robust, this paper introduces the Group Elite Selection of Mutation Rates (GESMR) algorithm. GESMR co-evolves a population of solutions and a population of MRs, such that each MR is assigned to a group of solutions. The resulting best mutational change in the group, instead of average mutational change, is used for MR selection during evolution, thus avoiding the vanishing MR problem. With the same number of function evaluations and with almost no overhead, GESMR converges faster and to better solutions than previous approaches on a wide range of continuous test optimization problems. GESMR also scales well to high-dimensional neuroevolution for supervised image-classification tasks and for reinforcement learning control tasks. Remarkably, GESMR produces MRs that are optimal in the long-term, as demonstrated through a comprehensive look-ahead grid search. Thus, GESMR and its theoretical and empirical analysis demonstrate how self-adaptation can be harnessed to improve performance in several applications of evolutionary computation.</p>
<h2>CCS CONCEPTS</h2>
<ul>
<li>Computing methodologies $\rightarrow$ Genetic algorithms.</li>
</ul>
<h2>KEYWORDS</h2>
<p>Genetic algorithms, neuroevolution, adaptation/self-adaptation, mutation operators, parameter control</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<h2>Bo Liu</h2>
<p>The University of Texas at Austin
Austin, Texas, USA
bliu@cs.utexas.edu</p>
<h2>Peter Stone</h2>
<p>The University of Texas at Austin and Sony AI
Austin, Texas, USA
pstone@cs.utexas.edu</p>
<h2>ACM Reference Format:</h2>
<p>Akarsh Kumar, Bo Liu, Risto Miikkulainen, and Peter Stone. 2022. Effective Mutation Rate Adaptation through Group Elite Selection . In GECCO-2022: Genetic and Evolutionary Computation Conference, July 7-13, 2022, Boston, MA. ACM, New York, NY, USA, 14 pages. https://doi.org/10.1145/1122445. 1122456</p>
<h2>1 INTRODUCTION</h2>
<p>Biological evolution has produced an incredible diversity of life that is seen everywhere. In this process, the solutions and the mechanisms co-evolve end-to-end, including the mutation rate [MR; 24]. Self-adaptation of MRs (SAMR) is a technique common in the literature of genetic algorithms (GA) that encapsulates this idea of end-to-end evolution of the MR along with the individuals [2, 8, 25, 33]. The idea is to assign each individual its own MR, creating a pair. The pairs are then evolved end-to-end using the assigned MR for mutating the individual and a "meta" MR for mutating the assigned MR.</p>
<p>However, this approach often runs into the problem that the MRs produced decay to zero, causing evolution to stop at a suboptimal value. If instead the MR were fixed at some moderate value, evolution would continue and find a better function value [7, 12, 29]. This premature convergence can be attributed to the fact that most mutations hurt the fitness of an individual [7], and thus an effective way for an individual to preserve its fitness into the next generation is to have no mutation. Thus, SAMR ignores the long-term goal of evolution to explore the fitness landscape and find better solutions in future generations [7].</p>
<p>To counteract this effect, this paper proposes a novel GA based on supportive co-evolution [13] of solutions and MRs, entitled Group Elite Selection of Mutation Rates (GESMR). After assigning each MR to a group of solutions, the solutions are evolved using that MR, and the MRs are evolved according to the best change in function value from the MR's solution group, defined as the "group elite". By targeting the MR that produces the best change in function value, given many mutation samples, GESMR can mitigate the vanishing MR problem. Additionally, GESMR is straightforward to implement and requires no more function evaluations than a fixed MR GA, and thus can be applied to a wide range of GA problems.</p>
<p>In prior work, a related approach using the idea of group elites was formulated as a multi-armed bandit problem and applied to</p>
<p>entire genetic operators in an ad-hoc manner [11, 38]. In contrast, this paper demonstrates that the approach is most effective when focused on MRs, and it also makes it possible to understand this result both empirically and theoretically.</p>
<p>Evaluation of GESMR is performed on common benchmark test optimization problems from the GA literature. To show that the method scales well to harder problems, it is also evaluated on neuroevolution for image classification in the MNIST/Fashion-MNIST domain and on reinforcement learning for control in the CartPole, Pendulum, Acrobot, and MountainCar domains. For comparison, results of several adaptive MR algorithms including an oracle optimal fixed MR, an oracle look-ahead MR (that uses foresight to determine MR), self-adaptive MR, the multi-armed bandit method [11], and some common heuristic methods [28] are also reported.</p>
<p>GESMR outperforms other algorithms in most tasks. Even when SAMR prematurely converges, like in problems with especially rugged fitness landscapes [7], GESMR does not. As a matter of fact, GESMR performs as well as the oracle look-ahead MR in function value and even matches the MR to the empirically estimated longterm optimal MR. To explain why, the statistical distribution of the change in function value for a spectrum of MRs for different function landscapes is empirically analyzed and visualized. This analysis shows that SAMR is minimizing an MR objective whose optimal MR is zero in rugged landscapes, while GESMR is minimizing an objective whose optimal MR is nonzero.</p>
<h2>2 RELATED WORK</h2>
<p>Research on mutation rates (MRs) is one of the most studied subfields of genetic algorithms [1, 3, 10, 17-19].</p>
<p>Fixed MRs: Lots of theoretical and empirical work has been done on finding the optimal fixed MR for specific problems [4, 15], finding heuristics like the MR should be proportional to $1 / L$ where $L$ is the length of the genotype [9, 26]. Evolutionary bilevel optimization tries to find the optimal evolutionary parameters, including MR, by running an inner evolution with an outer loop searching over parameters [21, 32]. However, it is commonly known that the optimal MR is constantly changing during evolution [27].</p>
<p>Deterministic MRs: Deterministic MRs are common but these are ad hoc functions to change the MR as a function of the number of generations, and may not generalize to unseen problems with different landscapes [1].</p>
<p>Adaptive MRs: Adaptive MRs are also common [9, 27, 31, 34, 37] but these rely on another ad hoc system to determine how to alter the MR given feedback from the evolution. A common technique is to maintain a MR that produces mutations of which only one-fifth are beneficial [18, 28], by increasing MR when the percentage of successful mutations is greater than $1 / 5$ (and vice versa). Although this technique is based on empirical findings, it is ad-hoc, does not generalize to different landscapes, requires a hardcoded threshold, and has been shown to lead to premature convergence when elitism is employed [29].</p>
<p>Self-Adaptive MRs: Perhaps the most promising and evolutionarily plausible class of adapting MRs is that of self-adapting MRs
$[1,2,14,19,37]$. This technique concatenates an MR to each individual and evolves the MRs and individuals in one end-to-end evolutionary process. However, many previous works have shown this process to be brittle and lead to premature convergence of evolution as the MRs decay and vanish [7, 12, 25, 29]. In the instances where self-adapting MRs succeed, the authors attribute the cause to be from a relatively smooth fitness landscape [7, 12], or high selection pressure [23]. The cause of general premature convergence in rugged landscapes is attributed to the fact that most mutations are deleterious, causing self-adaptation to prefer solutions that mutate less and preserve the fitness of each individual [7, 12]. Clune et al. [7] mention that, in this way, evolution is short-sighted: it cannot adapt MRs to be optimal for the long-term, only optimizing for short-term performance.</p>
<p>Outlier-Based MRs: Some works have proposed looking at the best mutation produced by a certain mutation operator to judge the quality of the operator [11, 38], with the motivation that an operator that produces infrequent large fitness gains is preferred to one that produces frequent small fitness gains. However, these works model the operator selection as a multi-armed bandit problem. This technique is not only unnatural to evolution, it is also limited by the expressiveness of the arms used and assumes independent arms, thus failing to capture the continuous spectrum that the MR exists in.</p>
<p>CMA-ES:. One of the most successful forms of adapting the spread of a population during an evolutionary search is with Covariance Matrix Adaptation Evolution Strategy (CMA-ES) [16]. It relies on maintaining a covariance matrix, which requires quadratic time and space in the solution vector length. Thus, CMA-ES does not scale to larger problems like deep neuroevolution with millions of parameters [35]. In contrast, GESMR and GAs in general are linear wrt. solution length.</p>
<h2>3 METHOD</h2>
<p>This section first provides the formal problem definition, a discussion of the general class of genetic algorithms, and then briefly describes a previous adaptive mutation rate (MR) method and its associated vanishing MR problem. Finally this section proposes the Group Elite Selection of Mutation Rates (GESMR) algorithm that addresses this problem with better performance and almost no extra overhead.</p>
<h3>3.1 Problem Formulation</h3>
<p>Consider the general optimization problem where the goal is to find the best decision variable $x^{*} \in \mathbb{R}^{d}$ that minimizes a target function $f$ (e.g. the negative fitness function in the genetic algorithm literature). The objective is therefore</p>
<p>$$
\underset{x \in \mathbb{R}^{d}}{\arg \min } f(x)
$$</p>
<h3>3.2 Genetic Algorithms and the Mutation Rate</h3>
<p>A genetic algorithm (GA) evolves a population of $N+1$ candidate solutions/individuals $x_{0}, \ldots, x_{N}$ over time that progressively minimize the objective in Eq. 1. At each evolution time step $t$, the current population is $\left{x_{t}^{(t)}\right}_{t=0}^{N}$.</p>
<p><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Figure 1: Comparison of GESMR against a fixed MR GA and SAMR. Fixed MR GA only evolves the solution with a given MR. SAMR evolves pairs of solutions and MRs. GESMR co-evolves a population of solutions and a population of MRs separately. Each MR is assigned a group and the MRs are evolved using the best function value gain in the MR's corresponding group.</p>
<p>To produce the next generation, a GA consists of 1) selection of individuals, 2) mutation of individuals, and 3) crossover of individuals.</p>
<p>The common truncation selection method with one elite is used in this paper. Truncation selection creates a new set of $N+1$ solutions by keeping the single best "elite" solution from the population (known as elitism) and uniformly sampling the rest of the $N$ solutions from the top $\eta_{x}$ portion of the population with replacement (better solution has lower $f(x)$ value) [35].</p>
<p>Since it is a common way to mutate a continuous genotype $x$ [35], the Gaussian mutation operator $M: \mathbb{R}^{d} \rightarrow \mathbb{R}^{d}$ is used, which produces $x^{\prime}$ with</p>
<p>$$
x^{\prime} \sim M(x ; \sigma) \triangleq x+\sigma \epsilon, \text { and } \epsilon \sim \mathcal{N}(0, I)
$$</p>
<p>where $\mathcal{N}(0, I)$ denotes a standard multi-variate normal distribution in $\mathbb{R}^{d} . \sigma \in \mathbb{R}_{\geq 0}$ represents the mutation rate (MR), which constrains how different $x^{\prime}$ could be from $x$.</p>
<p>Crossover is used to mix information between solutions, essentially allowing traits to be transferred to another solution. For the sake of simplicity and to isolate the mutation operator, which is the main focus of this work, no crossover operator is used since crossover is not a necessary mechanism in GAs [35].</p>
<p>For conventional GA algorithms, a fixed MR is chosen a priori based on the user's preference or prior knowledge. Clearly, a too small $\sigma$ will slow down evolution and a too large $\sigma$ will tend towards random search, a tuned $\sigma$ is needed. It has also been shown that the optimal $\sigma$ changes over the course of evolution, e.g. a small $\sigma$ is often needed to "fine tune" the solutions at the end of evolution [6]. As a result, the adaptive MR field studies how to dynamically adapt this $\sigma$ for faster learning and better convergence. Among previous adaptive MR methods, a well-known and commonly used method is the self-adaptation of MR (SAMR) [1, 2, 14, 19, 37]. This method attaches to each solution $x_{i}$ its own MR, $\sigma_{i}$. These pairs $\left{\left(x_{i}, \sigma_{i}\right)\right}$ are then evolved, by selection on the pairs and mutating the $x_{i}$ using $\sigma_{i}$ and mutating $\sigma_{i}$ using an external fixed meta MR $\tau$.</p>
<p>In practice, a well-known drawback of SAMR is that the MRs produced could prematurely converge to zero over time [7, 12,</p>
<p>Algorithm 1 One step of GESMR
Input: current solutions $\left{x_{i}^{(t)}\right}<em k="k">{i=0}^{N}$, current mutation rates $\left{\sigma</em>\right}}^{(t)<em x="x">{k=1}^{K}$, the selection rates $\eta</em>$, and the meta mutation rate, $\tau$.
Output: next generation of solutions $\left{x_{i}^{(t+1)}\right}}, \eta_{\sigma<em k="k">{i=0}^{N}$ and mutation rates $\left{\sigma</em>\right}}^{(t+1)<em i="i">{k=1}^{K}$.
1: // 1. Evolve the solutions
2: $\left{\tilde{x}</em>\right}}^{(t)<em i="i">{i=0}^{N} \leftarrow \operatorname{sort}\left{x</em>\right}}^{(t)<em i="i">{i=0}^{N}$ with ascending $f\left(\tilde{x}</em>\right)$
3: Generate $\left{\tilde{x}}^{(t)<em i="0">{i}^{(t)}\right}</em>$ according to Eq. 3 (Selection)
4: Generate $\left{x_{i}^{(t+1)}\right}}^{N<em k="k">{i=0}^{N}$ according to Eq. 4(Mutation)
5: // 2. Evolve the mutation rates
6: Calculate $\Delta</em>$ according to Eq. 5 (MR worth)
7: $\left{\hat{\sigma}}^{(t)<em k="1">{k}^{(t)}\right}</em>\right}}^{K} \leftarrow \operatorname{sort}\left{\sigma_{k}^{(t)<em k="k">{k=1}^{K}$ with ascending $\Delta</em>$
8: Generate $\left{\hat{\sigma}}^{(t)<em k="1">{k}^{(t)}\right}</em>$ according to Eq. 6 (Selection)
9: Generate $\left{\sigma_{k}^{(t+1)}\right}}^{K<em i="i">{k=1}^{K}$ according to Eq. 7(Mutation)
10: return $\left{x</em>\right}}^{(t+1)<em j="j">{i=1}^{N}$ and $\left{\sigma</em>$
29], which is referred to here as the vanishing mutation rate problem (VMRP). One might try to simply clip the MR to a lower bound, but a single lower bound that maintains exploration early on while still allowing for fine tuning later may not exist [6]. Therefore, there exists a need for a better adaptive MR strategy.}^{(t+1)}\right}_{j=1}^{K</p>
<h3>3.3 Group Elite Selection of Mutation Rates</h3>
<p>This section presents Group Elite Selection of Mutation Rates (GESMR), to adapt MRs on the fly, along with empirical evidence that GESMR mitigates the VMRP and outperforms previous adaptive MR methods. For visualization of GESMR, refer to Fig. 1.</p>
<p>GESMR keeps a set of $K$ positive scalar MRs $\left{\sigma_{k}\right}_{k=1}^{K}$, where $N \equiv 0(\bmod K)$, and co-evolves them with the $N+1$ candidate solutions, so that the $\sigma$ s do not decay to zero.</p>
<p>At each optimization step $t$, the current population, $\left{x_{i}^{(t)}\right}<em i="i">{i=0}^{N}$ is first sorted in ascending order of $f\left(x</em>}^{(t)}\right)$, giving $\left{\hat{x<em i="0">{i}^{(t)}\right}</em>}^{N}$. Truncation selection with one elite is applied to get the next generation parents, $\left{\hat{x<em i="0">{i}^{(t)}\right}</em>$, with}^{N</p>
<p>$$
\hat{x}<em 0="0">{i}^{(t)}= \begin{cases}\hat{x}</em>}^{(t)} &amp; i=0 \ \sim \mathcal{U}\left{\hat{x<em m-1="m-1">{0}^{(t)}, \ldots, \hat{x}</em>
$$}^{(t)}\right} &amp; i=1, \ldots, N\end{cases</p>
<p>and $m=\eta_{x} N$ (number of solutions for parent selection).
Then, the non-elite solutions, $\left{\hat{x}<em i="1">{i}^{(t)}\right}</em>}^{N}$ are split into $K$ groups of equal size (i.e. each group has $N / K$ solutions) and each group is assigned a different $\sigma_{k}$. Without loss of generality, $\sigma_{k}$ corresponds to $\left{\hat{x<em K="K" N="N" _="/" k="k">{(k-1) N / K+1}^{(t)}, \ldots,\left{\hat{x}</em>}^{(t)}\right}\right.$. To form the next generation, each $\hat{x<em k="k">{i}^{(t)}$ is then mutated according to its corresponding $\sigma</em>$, while the elite is unaltered:</p>
<p>$$
x_{i}^{(t+1)}= \begin{cases}\hat{x}<em i="i">{0}^{(t)} &amp; i=0 \ \sim M\left(\hat{x}</em>
$$}^{(t)} ; \sigma_{\lfloor i K / N\rfloor}\right) &amp; i=1, \ldots, N\end{cases</p>
<p>After the next generation of $\left{x_{i}^{(t+1)}\right}<em k="k">{i=0}^{N}$ are found, GESMR evolves the MRs, $\left{\sigma</em>$ using another separate but similar GA with one elite, truncation selection, and a different mutation operator.}\right}_{k=1}^{K</p>
<p>For each $\sigma_{k}$, its negative fitness is calculated by considering the best change in function value it has produced:</p>
<p>$$
\Delta_{k}^{(t)} \triangleq \Delta\left(\sigma_{k}^{(t)}\right)=\min <em i="i">{i=(k-1) N / K+1}\left(f\left(x</em>\right)\right)
$$}^{(t+1)}\right)-f\left(\hat{x}_{i}^{(t)</p>
<p>First the MR population is sorted by this $\Delta_{k}^{(t)}$, producing $\left{\hat{\sigma}<em k="k">{k=1}^{K}\right}$. Truncation selection with one elite is applied to get the next generation parent MRs $\left{\sigma</em>$ with}\right}_{k=1}^{K</p>
<p>$$
\hat{\sigma}<em 1="1">{k}^{(t)}= \begin{cases}\hat{\sigma}</em>}^{(t)} &amp; k=1 \ \sim \mathcal{U}\left{\hat{\sigma<em l="l">{1}^{(t)}, \ldots, \hat{\sigma}</em>
$$}^{(t)}\right} &amp; k=2, \ldots, K\end{cases</p>
<p>and $l=\eta_{\sigma} K$ (number of MRs for parent selection). The mutation operator associated with the $\sigma$ s is</p>
<p>$$
\sigma^{\prime} \sim M_{\sigma}(\sigma ; \tau) \triangleq \sigma \tau^{\epsilon} \text { and } \epsilon \sim \mathcal{U}(-1,1)
$$</p>
<p>where $\mathcal{U}(-1,1)$ represents a continuous uniform distribution on $\mathbb{R}$ and $\tau$ represents a fixed meta mutation rate.</p>
<p>The next generation of MRs is produced by mutating the parent MRs, while the elite parent is unaltered:</p>
<p>$$
\sigma_{i}^{(t+1)}= \begin{cases}\hat{\sigma}<em _sigma="\sigma">{1}^{(t)} &amp; i=1 \ \sim M</em>
$$}\left(\hat{\sigma}_{i}^{(t)} ; \tau\right) &amp; i=2, \ldots, K\end{cases</p>
<p>One full step of GESMR is described in Alg. 1.
The performance of GESMR depends on the number of groups, $K$. When $K=1$, GESMR recovers the fixed-MR method. When $K=N$, each solution aside from the elite is assigned a different MR, a method reminiscent of the SAMR method. The experiment section shows that in practice the optimal $K$ lies between 1 and $N$, and uncovers a heuristic on how to choose such a $K$.</p>
<h2>4 EXPERIMENT</h2>
<p>The experiments in this section are designed to answer the following questions:
(1) How does GESMR compare to other methods in terms of the quality of function values found and how quickly it converges to those values?
(2) Does SAMR suffer from the Vanishing Mutation Rate Problem (VMRP)? Does GESMR solve this problem, and can it produce MRs that are optimal in a long-term sense?
(3) What parts of GESMR are vital to its success?
(4) Why is GESMR more successful than SAMR?
(5) What is the optimal group size in GESMR and how much does this parameter matter?
(6) Does GESMR generalize to the high-dimensional loss landscapes of neuroevolution?
(7) Does GESMR generalize to neuroevolution for reinforcement learning control tasks?</p>
<h3>4.1 Comparison Algorithms</h3>
<p>For comparison, the following MR selection and adaptation algorithms are evaluated in various optimization problems:</p>
<ul>
<li>${ }^{\dagger}$ OFMR: Optimal fixed MR found with a grid search;</li>
<li>${ }^{\dagger}$ LAMR-G: MR determined at every $G$ generations by "looking ahead," that is, by running a grid search multiple times and picking the MR that produces the best elite in another evolution run (initialized with the current population and run for $G$ generations);</li>
<li>FMR: A fixed MR of $\sigma=0.01$;</li>
<li>1CMR A fixed MR of $\sigma=1 / d[26]$;</li>
<li>15MR: MR is doubled if the percentage of beneficial mutations is above $1 / 5$ in the current generation and cut in half if not [28];</li>
<li>UCB/R: The adaptive MR method proposed by Fialho et al. [11], implemented with a multi-armed bandit with $R$ arms (each corresponding to a different MR), and sampling an arm every generation using the upper confidence bound algorithm [11];</li>
<li>SAMR: Self-adaptation of MR, where each solution is assigned its own MR and evolved end-to-end;</li>
<li>GESMR: The method of Algorithm 1;</li>
<li>GESMR-AVG: The method of Algorithm 1 with the min in Eq. 5 replaced with the mean;</li>
<li>GESMR-FIX: The method of Algorithm 1 with the MRs fixed to the initial population and not evolved further.</li>
</ul>
<p>Details for the parameters of these algorithms are provided in Appendix A. The †represents that the algorithm is an oracle using foresight (looking ahead of the current evolution step) to determine the MR and should not be compared against directly. Note that LAMR- $G$ specifically uses foresight to determine the best MR for the next $G$ generations. With sufficiently large $G$, its MRs thus serve as an empirical estimate of the optimal long-term MRs at any point during evolution.</p>
<p><img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Figure 2: Elite function value and average mutation rate (MR) over generations of evolution by different adaptive MR methods, applied to four test optimization problems. Notice GESMR outperforms other methods in function value and is able to match its MR to the one from LAMR-100.</p>
<h3>4.2 Test Optimization Functions</h3>
<p>All algorithms are evaluated on common test functions: Ackley, Griewank, Rastrigin, Rosenbrock, Sphere, and Linear [36]. Definitions of these test functions are provided in Appendix B.1. Each function is evaluated for dimension $d \in{2,10,100,1000}$, with the initial population sampled from $\mathcal{N}(\mathbf{0}, \mathbf{I})$ and $\mathcal{N}\left(\mathbf{0}, 10^{2} \mathbf{I}\right)$ (referenced in table as std with values 1 and 10). These functions were chosen because they are common in the GA literature and they span a diverse range of ruggedness for function landscapes [22]. All results are averaged over five seeds.</p>
<p>Fig. 2 shows selected runs from this experiment, displaying the elite function value and the average MR over generations. The full list of final elite function values are reported in Table 1 in Appendix B.2, serving as a statistic on how good the final solution is. The full list of average elite function values over all evolution iterations are reported in Table 2 in Appendix B.2, serving as a statistic on how quickly the algorithm converges to a good solution. Mean squared error between the log MR of an algorithm and the log MR of LAMR-100 (averaged over generations) are reported in Table 3 in Appendix B.2, serving as a statistic on how close to optimal the MRs are. Additionally, all of the tables bold the statistically significant results which are computed by a t-test.</p>
<p>To answer Question 1, GESMR outperforms other methods, excluding the oracles, in almost all domains both in terms of the final function value and in terms of quickness of convergence to good values.</p>
<p>To answer Question 2, SAMR only succeeds and matches the performance of LAMR when the function landscape is relatively nonrugged, like in the Rosenbrock and Sphere functions. In the rugged functions, SAMR consistently produces MRs that are sub-optimal and smaller than those produced by even OFMR, and thus also lags behind in elite function value during evolution. Thus, SAMR struggles with the VMRP, as shown in previous work [7, 25, 29]. However, GESMR overcomes this phenomenon and surprisingly consistently matches its average MR to the long-term optimal MR produced by LAMR-100 (i.e. red and black lines match in Fig. 2, and GESMR has consistently the lowest error in Table 3 in Appendix B.2).</p>
<p>The limitations of of all methods except 15MR, SAMR, and GESMR can be seen in the linear test function. The optimal MR for this case is $\sigma \rightarrow \infty$, but other methods are unable to approximate this result because they limit themselves to an upper bound (ex. UCB- $R$ is limited by the largest MR in its arms). On the other hand, GESMR quickly keeps scaling up the MR until reaching a very large MR. GESMR is also arbitrarily precise, fine tuning MRs with an evolutionary process. In contrast, UCB- $R$ and the grid search methods constrain the MRs to a quantized range.</p>
<p>To answer Question 3, GESMR-AVG and GESMR-FIX were run as an ablation of GESMR, with the results shown in Fig. 2 and Tables 1, 2, 3 in Appendix B.2. GESMR outperforms both of them, suggesting that the use of the best mutation statistic and the evolution of MRs are both vital to its success.</p>
<h3>4.3 Empirical Analysis of GESMR vs. SAMR</h3>
<p>To answer Question 4, two objectives for $\sigma$ are defined based on a change of function value, and these objectives are shown to be related to the GESMR-AVG, GESMR, and SAMR methods. These objectives are then analyzed empirically (in this section) and theoretically (in Section 4.4 to explain the behavior of the algorithms.</p>
<p>Consider the change in function value of a mutation given a solution and an MR:</p>
<p>$$
\Delta(x, \sigma) \sim f(M(x ; \sigma))-f(x)
$$</p>
<p>For simplicity, this variable will be denoted as $\Delta$. Let $\left{\Delta_{q}\right}_{q=1}^{N / K}$ represent independently and identically distributed instances of $\Delta$ where $q$ indexes an individual within its group. To minimize $f(x)$ in evolution, a $\sigma$ must be chosen to minimize $\Delta(x, \sigma)$ in some capacity (denoted as an "MR objective"). Consider two MR objectives</p>
<ul>
<li>mean objective, $\sigma_{\mu}^{*}=\arg \min <em _epsilon="\epsilon" x_="x,">{\sigma} \mathbb{E}</em>[\Delta(x, \sigma)]$ and</li>
<li>outlier objective, $\sigma_{\min }^{*}=\arg \min <em _epsilon="\epsilon" x_="x,">{\sigma} \mathbb{E}</em>\left[\min <em q="q">{q} \Delta</em>(x, \sigma)\right]$.</li>
</ul>
<p>The expectations in the objectives are over $x$ sampled from the current population and the noise in the mutation operator, $\epsilon$. For simplicity, these objectives are denoted as $\arg \min <em _sigma="\sigma">{\sigma} \mathbb{E}[\Delta]$ and $\arg \min </em>\left[\min } \mathbb{E<em q="q">{q} \Delta</em> s$ that produce non-deleterious mutations over generations consistently. This mechanism is intuitively associated with the mean objective.}\right]$, respectively. The mean objective corresponds to the algorithm GESMR-AVG, which selects $\sigma$ s directly to minimize a sample average of $\Delta$. The outlier objective corresponds to the algorithm GESMR, which selects $\sigma$ s directly to minimize the best (lowest-value) sample of $\left{\Delta_{q}\right}$. SAMR does not select $\sigma$ s directly, but rather selects $\left(x_{i}, \sigma_{i}\right)$ pairs to minimize $f\left(x_{i}\right)$. However, because $x_{i}$ is produced using the parent of $\sigma_{i}$, SAMR also selects pairs $\left(x_{i}, \sigma_{i}\right)$ indirectly based on $\sigma_{i</p>
<p><img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>Figure 3: Visualization of mutations and the distribution of the change in function value from the mutations, $\Delta(x, \sigma)$ (defined in Eq. 8), for nine labeled mutation rates, $\sigma$, at one point, $x$, on the 2-D Ackley function. The left plots show an image representation of the 2-D function landscape where lighter colors are higher values and annotates the original solution and some mutated solutions. The right plots show the empirical histogram of $\Delta(x, \sigma)$ and annotates the mean and minimum samples of this histogram. Only moderate $\sigma \mathrm{s}$ are able to mutate to the global minimum.
<img alt="img-3.jpeg" src="img-3.jpeg" /></p>
<p>Figure 4: A representation of $\sigma$ versus $\Delta(x, \sigma)$ (defined in Eq. 8) colored by the empirical probability density function, $p_{\Delta}(\delta ; \sigma)$ and the respective log distribution for the 2-D Ackley function. Many samples of $\Delta(x, \sigma)$ are generated from $x \sim \mathcal{N}(0, I)$, and a logarithmic range of $\sigma \mathrm{s}$, and put into bins of a $\sigma-\Delta$ grid, colored by the number of samples the bin has. Annotated are the $\sigma$ versus $\mathbb{E}[\Delta ; \sigma]$ (mean of $\Delta \mathrm{s}$ ) and $\mathbb{E}\left[\min <em q="q">{q} \Delta</em>^{} ; \sigma\right]$ (min of $\Delta \mathrm{s}$ ) curves, and the $\sigma \mathrm{s}$ that minimize them. Importantly, notice that $\sigma_{\mu<em>}=0$ and $\sigma_{\min }^{</em>}&gt;0$.</p>
<p>To analyze general function landscapes outside of evolution, $x$ is either fixed to a point or sampled from a distribution, and many more samples for $\left{\Delta_{q}\right}$ are used. Fig. 3 shows a histogram of samples from $\Delta$ and visualizes their respective mutations across values of $\sigma$ for a single $x$ in the Ackley 2-D function, highlighting that the best mutation comes from a $\sigma$ that is not too small and not too large. Fig. 4 represents this same information, but sampling $x \sim \mathcal{N}(0, I)$, for a continuous range of $\sigma$ as a visualization of the probability density function (PDF), $p_{\Delta}(\delta ; \sigma)$. The sigma versus the mean objective and the outlier objective curves as well as their optimal $\sigma$ solutions, $\sigma_{\mu}^{<em>}$ and $\sigma_{\min }^{</em>}$ are shown over the PDF. Fig. 5 displays this same plot for several other test optimization problems.</p>
<p>As Fig. 5 shows $\mathbb{E}[\Delta]$ often increases monotonically with $\sigma$. As a result, the optimal MR tends to go to zero, i.e. $\sigma_{\mu}^{*} \rightarrow 0$. Interestingly,
<img alt="img-4.jpeg" src="img-4.jpeg" /></p>
<p>Figure 5: A representation of the $\sigma$ versus $\Delta(x, \sigma)$ (defined in Eq. 8) colored by the empirical probability density function $p_{\Delta}(\delta ; \sigma)$, and the respective log distribution for several different test optimization functions of different dimensionality. Many samples of $\Delta(x, \sigma)$ are generated from $x \sim \mathcal{N}(0, I)$ and a logarithmic range of $\sigma \mathrm{s}$ and put into bins of a $\sigma$ versus $\Delta$ 2-D grid, colored by the number of samples the bin has. Annotated are the $\sigma$ versus $\mathbb{E}[\Delta ; \sigma]$ (mean of $\Delta \mathrm{s}$ ), $\mathbb{E}\left[\min <em q="q">{q} \Delta</em>\left[\max } ; \sigma\right]$ (min of $\Delta \mathrm{s}$ ), and $\mathbb{E<em q="q">{q} \Delta</em>^{} ; \sigma\right]$ (max of $\Delta \mathrm{s}$ ) curves, and the optimal $\sigma$ that minimizes the first two curves. All curves show that $\sigma_{\mu<em>} \rightarrow 0$ and $\sigma_{\min }^{</em>}&gt;0$.
$\mathbb{E}\left[\min <em q="q">{q} \Delta</em>^{}\right]$ is zero for $\sigma=0$, and decreases monotonically as $\sigma$ increases until $\sigma=\sigma_{\min <em>}$, and then increases monotonically with $\sigma$, leading to $\sigma_{\min }^{</em>} \neq 0$. These behaviors hold true for all landscapes tested, except for the non-rugged linear landscape.</p>
<p>These results answer Question 4 by showing empirically that GESMR targets higher MRs than SAMR in many problems, demonstrating that it has the capacity to mitigate the VMRP. Theoretical analysis of GESMR and SAMR further grounds this empirical finding to prove that GESMR will always avoid a fully vanishing MR.</p>
<h3>4.4 Theoretical Analysis of GESMR vs. SAMR</h3>
<p>In this section, the behavior of the mean and outlier MR objectives are analyzed as $\sigma \rightarrow 0$ and $\sigma \rightarrow \infty$ during evolution. The current population of $x$ is assumed to be already partially optimized, i.e., better than those of random search (which is the initialization). Partial</p>
<p>optimization also means that the evolution has not yet converged, and thus the gradient of the function at the solutions, $\nabla f(x)$, is nonzero.</p>
<p>Assume $\sigma \rightarrow \infty$, fully and randomly exploring the solution space without exploiting the current solutions. Then, $\mathbb{E}[\Delta]=\mathbb{E}<em x="x">{x^{\prime}}\left[f\left(x^{\prime}\right)\right]-\mathbb{E}</em>\left[\min }[f(x)]$ (first expectation is over all mutants, $x^{\prime}$ ) becomes a constant only based on the function landscape and the distribution of $x . \mathbb{E<em q="q">{q} \Delta</em>\left[\min }\right]$ becomes, by definition, random search of the function landscape. Since $x$ is already partially optimized, random search must yield a strictly worse expected solution than $x$. So, $\mathbb{E}[\Delta]&gt;\mathbb{E<em q="q">{q} \Delta</em>\right]&gt;0$, and thus both MR objectives are positive.</p>
<p>Assume $\sigma=0$ (i.e. no mutation), fully exploiting the current solution without exploring the solution space. Then, both MR objectives vanish as $\mathbb{E}[\Delta]=\mathbb{E}\left[\min <em q="q">{q} \Delta</em>\right]=0$.</p>
<p>The most interesting case is when $\sigma$ is small but not zero, i.e. $0&lt;\sigma&lt;\sigma_{c}$. For a sufficiently small $\sigma_{c}$ the function landscape can be approximated as linear with $f(M(x ; \sigma)) \approx f(x)+\sigma \epsilon^{T} \nabla f(x)$. Then, $\Delta(x, \sigma)=f(M(x ; \sigma))-f(x)=\sigma \epsilon^{T} \nabla f(x)$. Since $\epsilon \sim \mathcal{N}(0, I)$, it follows that $\Delta(x, \sigma) \sim \mathcal{N}\left(0, \sigma^{2}|\nabla f(x)|^{2}\right)$, which leads to $\mathbb{E}[\Delta]=0$. A further useful constraint is provided by Theorem 1:</p>
<p>Theorem 1. Let $Z_{\sigma}^{(1)}, \ldots, Z_{\sigma}^{(q)} \sim$ iid $\mathcal{N}\left(0, \sigma^{2}\right)$.
If $Y_{\sigma}=\min \left(Z_{\sigma}^{(1)}, \ldots, Z_{\sigma}^{(q)}\right)$, then $\mathbb{E}\left[Y_{\sigma}\right]=\sigma \mathbb{E}\left[Y_{\sigma=1}\right]$ with $\mathbb{E}\left[Y_{\sigma=1}\right]&lt;0$.</p>
<p>Proof. By definition, $f_{z}(z)=\phi(z / \sigma)$ and $F_{z}(z)=\Phi(z / \sigma)$. Then, $P\left(Y_{\sigma} \leq y\right)=1-P\left(Y_{\sigma} \geq y\right)=1-P\left(Z_{\sigma}^{(1)} \geq y, \ldots, Z_{\sigma}^{(q)} \geq y\right)$</p>
<p>$$
\begin{aligned}
&amp; =1-(1-\Phi(y / \sigma))^{q} \
f_{Y_{\sigma}}(y) &amp; =\frac{1}{\sigma} q(1-\Phi(y / \sigma))^{q-1} \phi(y / \sigma) \
\mathbb{E}\left[Y_{\sigma}\right] &amp; =\int_{y} \frac{y}{\sigma} q(1-\Phi(y / \sigma))^{q-1} \phi(y / \sigma) \
&amp; =\sigma \int_{y} y q(1-\Phi(y))^{q-1} \phi(y) \
&amp; =\sigma \mathbb{E}\left[Y_{\sigma=1}\right]
\end{aligned}
$$</p>
<p>In addition, $\mathbb{E}\left[Y_{\sigma=1}\right]&lt;0$ because $Y_{\sigma=1}$ is the minimum of $q&gt;1$ zero-mean standard normal random variables.</p>
<p>By Theorem 1, $\mathbb{E}\left[\min <em q="q">{q} \Delta</em>\right] \propto \sigma|\nabla f(x)|&lt;0$. Thus, in this range of $\sigma$, the outlier objective decreases linearly as $\sigma$ increases, while the mean objective still vanishes.</p>
<p>Using these three cases, consider the MR objectives as $\sigma$ varies from 0 to $\infty . \mathbb{E}[\Delta]$ starts at 0 and takes a theoretically unknown (but empirically monotonic) path to a positive value. $\mathbb{E}\left[\min <em q="q">{q} \Delta</em>^{}\right]$ starts at 0 , decreases to below 0 until a certain $\sigma_{c}$, then takes a theoretically unknown (but empirically monotonic) path to a positive value. This theoretical analysis guarantees that $\sigma_{\min <em>}&gt;0$, a condition that cannot be put on $\sigma_{p}^{</em>}$.</p>
<p>Thus, this section and Section 4.3 empirically and theoretically answer Question 4, i.e. explain why GESMR-AVG and SAMR often suffer from the VMRP in rugged landscapes, and how GESMR overcomes this limitation. In short, GESMR-AVG and SAMR assume that $\sigma$ produce non-deleterious mutations consistently, whereas most mutations are actually deleterious [7]. This condition is possible only if $\sigma \rightarrow 0$, which GESMR incorporates into the algorithm itself.
<img alt="img-5.jpeg" src="img-5.jpeg" /></p>
<p>Figure 6: Elite final function value of GESMR versus the number of groups, $K$, as the population size, $N$ increases in the Ackley 100-D function. As $N \rightarrow \infty$, the optimal $K \rightarrow$ $N^{3 / 4}$, suggesting $K$ does not need tuning.
<img alt="img-6.jpeg" src="img-6.jpeg" /></p>
<p>Figure 7: Elite function value and average mutation rate (for different mutation rate control strategies) versus generations of neuroevolution applied to image classification in MNIST and Fashion-MNIST. GESMR outperforms most methods except 15MR, which appears to be an especially good fit for this problem.</p>
<h3>4.5 Ablation on the Group Size Parameter</h3>
<p>To answer Question 5, and to evaluate the optimal number of groups, $K$, evolution was run on the Ackley, Griewank, Rosenbrock, and Sphere functions with $d=100$ and $K$ equal to all factors of $N$ for various values of $N$. It turns out that if the number of groups is too small, i.e. $K \rightarrow 1$, or too big, i.e. $K \rightarrow N$, the performance drops very fast (Fig. 6). In general, $K=\sqrt{N}$ is a reasonable value, but as $N \rightarrow \infty$, the optimal $K \rightarrow N^{3 / 4}$. This finding suggests that the number-of-groups hyperparameter can be set according to $N$ and does not need tuning.</p>
<h3>4.6 Neuroevolution for Image Classification</h3>
<p>To answer Question 6, the algorithms were run on the high dimensional loss landscapes of neuroevolution for image classification with the common MNIST and Fashion-MNIST datasets [20, 39]. The</p>
<p>details of the datasets, the NN architecture evolved, and the experimental setup are provided in Appendix C. Each algorithm was run independently five times and the mean loss and the standard error measured.</p>
<p>GESMR outperforms all other methods, including FMR and SAMR, but does not beat 15MR (Fig. 7). Presumably, 15MR's hyperparameter of $1 / 5$ is especially suited to the MNIST loss landscapes but might have trouble generalizing to other problems, like the test optimization problems and the reinforcement learning control problems.</p>
<h3>4.7 Neuroevolution for Reinforcement Learning</h3>
<p>Reinforcement learning (RL) tasks are amenable to the neuroevolution approach because the approach tolerates long time-horizon rewards well [30, 35]. To answer Question 7, the algorithms were evaluated on four common RL control tasks: CartPole, Pendulum, Acrobot, and MountainCar [5]. In all these tasks, a controller maps the robot's input observations to either continuous or discrete actions to maximize a cumulative reward. The details of these environments, the neural architecture evolved, and the experimental setup are provided in the Appendix D. Each algorithm was run independently five times and the mean and standard error of performance was measured.</p>
<p>The results are shown in Fig. 9 in the Appendix D. GESMR generally outperformed other methods including the baseline fixed MR and SAMR. Presumably, GESMR fails in MountainCar because the reward signal is very sparse (zero rewards provide no way to appropriately select for MRs).</p>
<h3>4.8 Comparison against CMA-ES</h3>
<p>CMA-ES is not a pure adaptive MR GA method: It stores a covariance matrix to control the spread of the population, rather than storing a single MR [16]. This matrix grows quadratically with the solution vector length. However, CMA-ES still provides an interesting comparison given a fixed computational budget. Fig. 8 shows that GESMR outperforms CMA-ES significantly in four of the most challenging test optimization problems, even though CMA-ES uses much more memory (quadratic in the solution space). Thus, not only does GESMR scale to higher dimensional problems, it also outperforms CMA-ES when both are given the same running time.</p>
<h2>5 CONCLUSION</h2>
<p>In this paper, a novel and simple adaptive mutation rate (MR) method, group elite selection mutation rate (GESMR), was proposed to mitigate the vanishing mutation rate problem (VMRP), along with empirical analysis that grounds its success over selfadaptation of mutation rates (SAMR). Comprehensive experiment results showed that GESMR outperforms previous adaptive MR methods in final value and convergence speed. GESMR also consistently matches its MRs to the empirically estimated long-term optimal MR. Thus, this work provides the next step in designing self-adaptive machine learning algorithms.
<img alt="img-7.jpeg" src="img-7.jpeg" /></p>
<p>Figure 8: Elite final function values of GESMR and CMA-ES on four challenging problems in the 100-D solution space with a fixed computational budget. Whereas CMA-ES is only able to complete 50 generations, GESMR is completes approximately 1000, resulting in an order of magnitude better values.</p>
<h2>REFERENCES</h2>
<p>[1] Aldeida Aleti and Irene Moser. 2016. A Systematic Literature Review of Adaptive Parameter Control Methods for Evolutionary Algorithms. ACM Comput. Surv. 49, 3 (Oct. 2016), 1-35.
[2] Thomas Bäck. 1992. Self-Adaptation in Genetic Algorithms. In Proceedings of the First European Conference on Artificial Life. Citeseer.
[3] Thomas Bäck and Martin Schütz. 1996. Intelligent mutation rate control in canonical genetic algorithms. In Foundations of Intelligent Systems. Springer Berlin Heidelberg, 158-167.
[4] Südtje Böttcher, Benjamin Doerr, and Frank Neumann. 2010. Optimal Fixed and Adaptive Mutation Rates for the LeadingOnes Problem. In Parallel Problem Solving from Nature, PPSN XI. Springer Berlin Heidelberg, 1-10.
[5] Greg Brockman, Vicki Cheung, Ludwig Pettersson, Jonas Schneider, John Schulman, Jie Tang, and Wojciech Zaremba. 2016. OpenAI Gym. (June 2016). arXiv:1606.01540 [cs.LG]
[6] J Cervantes and C R Stephens. 2009. Limitations of Existing Mutation Rate Heuristics and How a Rank GA Overcomes Them. IEEE Trans. Evol. Comput. 13, 2 (April 2009), 369-397.
[7] Jeff Chane, Dusan Misevic, Charles Ofria, Richard E Lenski, Santiago F Elena, and Rafael Sanjuán. 2008. Natural selection fails to optimize mutation rates for long-term adaptation on rugged fitness landscapes. PLoS Comput. Biol. 4, 9 (Sept. 2008), e1000187.
[8] Duc-Cuong Dang and Per Kristian Lehre. 2016. Self-adaptation of Mutation Rates in Non-elitist Populations. In Parallel Problem Solving from Nature - PPSN XIV. Springer International Publishing, 803-813.
[9] Benjamin Doerr, Carola Doerr, and Johannes Lengler. 2019. Self-adjusting mutation rates with provably optimal success rules. In Proceedings of the Genetic and Evolutionary Computation Conference (Prague, Czech Republic) (GECCO '19). Association for Computing Machinery, New York, NY, USA, 1479-1487.
[10] A E Eiben, R Hinterding, and Z Michalewicz. 1999. Parameter control in evolutionary algorithms. IEEE Trans. Evol. Comput. 3, 2 (July 1999), 124-141.
[11] Álvaro Fialho, Luis Da Costa, Marc Schoenauer, and Michèle Sebag. 2008. Extreme Value Based Adaptive Operator Selection. In Parallel Problem Solving from Nature - PPSN X, 10th International Conference Dortmund, Germany, September 13-17, 2008, Proceedings, Vol. 5199. unknown, 175-184.</p>
<p>[12] M R Glickman and K Sycara. 2000. Reasons for premature convergence of selfadapting mutation rates. In Proceedings of the 2000 Congress on Evolutionary Computation. CEC00 (Cat. No.00TH8512), Vol. 1. ieeexplore.ieee.org, 62-69 vol.1.
[13] Brian W Goldman and Daniel R Tauritz. 2012. Supportive coevolution. In Proceedings of the 14th annual conference companion on Genetic and evolutionary computation (Philadelphia, Pennsylvania, USA) (GECCO '12). Association for Computing Machinery, New York, NY, USA, 59-66.
[14] Jonatan Gomez. 2004. Self Adaptation of Operator Rates in Evolutionary Algorithms. In Genetic and Evolutionary Computation - GECCO 2004. Springer Berlin Heidelberg, 1162-1173.
[15] R N Greenwell, J E Angus, and M Finck. 1995. Optimal mutation probability for genetic algorithms. Math. Comput. Model. 21, 8 (April 1995), 1-11.
[16] Nikolaus Hansen. 2016. The CMA Evolution Strategy: A Tutorial. (April 2016). arXiv:1604.00772 [cs.LG]
[17] Ahmad Hassanat, Khalid Almohammadi, Esra'a Alkafaween, Eman Abunawas, Awni Hammouri, and V B Surya Prasath. 2019. Choosing Mutation and Crossover Ratios for Genetic Algorithms-A Review with a New Dynamic Approach. Information 10, 12 (Dec. 2019), 390.
[18] Giorgos Karafotias, Mark Hoogendoorn, and A E Eiben. 2015. Parameter Control in Evolutionary Algorithms: Trends and Challenges. IEEE Trans. Evol. Comput. 19, 2 (April 2015), 167-187.
[19] Oliver Kramer. 2010. Evolutionary self-adaptation: a survey of operators and strategy parameters. Evol. Intell. 3, 2 (Aug. 2010), 51-65.
[20] Y LeCun. 1998. The MNIST database of handwritten digits. http://yann. lecun. com/exdb/mnist/ (1998).
[21] Jason Zhi Liang and Risto Miikkulainen. 2015. Evolutionary Bilevel Optimization for Complex Control Tasks. In Proceedings of the 2015 Annual Conference on Genetic and Evolutionary Computation (Madrid, Spain) (GECCO' 15). Association for Computing Machinery, New York, NY, USA, 871-878.
[22] Katherine M Malan and Andries P Engelbrecht. 2009. Quantifying ruggedness of continuous landscapes using entropy. In 2009 IEEE Congress on Evolutionary Computation. 1440-1447.
[23] Michael Kurtis Maschek. 2010. Intelligent mutation rate control in an economic application of genetic algorithms. Comput. Econ. 35, 1 (Jan. 2010), 25-49.
[24] D Metzgar and C Wills. 2000. Evidence for the adaptive evolution of mutation rates. Cell 101, 6 (June 2000), 581-584.
[25] Silja Meyer-Nieberg and Hans-Georg Beyer. 2007. Self-Adaptation in Evolutionary Algorithms. In Parameter Setting in Evolutionary Algorithms, Fernando G Lobo, Claudio F Lima, and Zbigniew Michalewicz (Eds.). Springer Berlin Heidelberg, Berlin, Heidelberg, 47-75.
[26] Gabriela Ochoa. 2002. Setting the mutation rate: Scope and limitations of the 1/L heuristic. In Proceedings of the 4th Annual Conference on Genetic and Evolutionary Computation. maths.stir.ac.uk, 495-502.
[27] Lalit M Patnaik and Srinivas Mandavilli. 1986. Adaptation in Genetic Algorithms. In Genetic Algorithms for Pattern Recognition. CRC Press, 45-64.
[28] I Rechenberg. 1978. Evolutionsstrategien. In Simulationsmethoden in der Medizin und Biologie. Springer Berlin Heidelberg, 83-114.
[29] G Rudolph. 2001. Self-adaptive mutations may lead to premature convergence. IEEE Trans. Evol. Comput. 5, 4 (2001), 410-414.
[30] Tim Salimans, Jonathan Ho, Xi Chen, Snymon Sidor, and Ilya Sutskever. 2017. Evolution Strategies as a Scalable Alternative to Reinforcement Learning. (March 2017). arXiv:1703.03864 [stat.ML]
[31] Mike Sewell, Jagath Samarabandu, Ranga Rodrigo, and Kenneth McIsaac. 2006. The rank-scaled mutation rate for genetic algorithms. Int. J. Inform. Technol. 3, 1 (2006), 32-36.
[32] Ankur Sinha, Pekka Malo, and Kalyanmoy Deb. 2018. A Review on Bilevel Optimization: From Classical to Evolutionary Approaches and Applications. IEEE Trans. Evol. Comput. 22, 2 (April 2018), 276-295.
[33] J Smith and T C Fogarty. 1996. Self adaptation of mutation rates in a steady state genetic algorithm. In Proceedings of IEEE International Conference on Evolutionary Computation. ieeexplore.ieee.org, 318-325.
[34] M Srinivas and L M Patnaik. 1994. Adaptive probabilities of crossover and mutation in genetic algorithms. IEEE Trans. Syst. Man Cybern. 24, 4 (April 1994), $656-667$.
[35] Felipe Petroski Such, Vashisht Madhavan, Edoardo Conti, Joel Lehman, Kenneth O Stanley, and Jeff Clune. 2017. Deep Neuroevolution: Genetic Algorithms Are a Competitive Alternative for Training Deep Neural Networks for Reinforcement Learning. (Dec. 2017). arXiv:1712.06567 [cs.NE]
[36] Sonja Surjanovic and Derek Bingham. 2013. Optimization Test Functions and Datasets. https://www.sfu.ca/ ssurjano/optimization.html. Accessed: 2021-9-6.
[37] D Thierens. 2002. Adaptive mutation rate control schemes in genetic algorithms. In Proceedings of the 2002 Congress on Evolutionary Computation. CEC'02 (Cat. No.02TH8600), Vol. 1. ieeexplore.ieee.org, 980-985 vol.1.
[38] James M Whitacre, Tuan Q Pham, and Ruhul A Sarker. 2009. Use of statistical outlier detection method in adaptive evolutionary algorithms. (July 2009). arXiv:0907.0595 [cs.NE]
[39] Han Xiao, Kashif Rasul, and Roland Vollgraf. 2017. Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms. (Aug. 2017).</p>
<h2>A GENERAL EXPERIMENT SETUP</h2>
<p>All algorithms for all experiments (except the group size ablation experiment) are run with a population size of $N+1=101$. The test optimization problems are run for $T \in{100,300,1000,2500}$ generations with problem dimensionality $d \in{2,30,100,1000}$, respectively. The Linear function is always only run for $T=100$ generations. The MNIST/Fashion-MNIST experiments are run for $T=1000$ generations. All reinforcement learning experiments are run for $T=100$ generations.</p>
<p>OFMR finds the optimal fixed MR using a grid search over a logarithmic range of ten MRs ranging from $1 \times 10^{-3}$ to 1 . For each MR in the grid search, an entire evolution is run to evaluate it. The MR whose evolution provides the best final elite function value is picked as the optimal fixed MR, and another fixed MR evolution is run with this MR value.</p>
<p>LAMR- $G$ changes the MR every $G$ generations, and picks the MR according to a grid search over a logarithmic range of 10 MRs ranging from $1 \times 10^{-3}$ to 1 . For each MR in the grid search, the current population is used to initialize another evolution run that ooks ahead for $G$ generations. The MR whose evolution provides the best final elite is used for the next $G$ generations in the main evolution run. In this way, LAMR- $G$ is able to adapt MRs for the long-term by directly looking ahead $G$ generations and picking an that MR performs the best.</p>
<p>FMR sets the MR to a fixed $1 \times 10^{-2}$, as is commonly done when the user is left to define an MR.</p>
<p>1CMR sets the MR to a fixed $1 / d$ where $d$ is the dimensionality of the solution space [26]. The goal is to search carefully in problems with high dimensionality and explore more in problems with low dimensionality.</p>
<p>15MR starts with the MR equal to $1 \times 10^{-2}$ and adapts MRs based on the percentage of beneficial mutations in the current generation (i.e. those that result in a negative function value change) If the percentage is greater than $1 / 5$, the MR is doubled, else it is cut in half. This factor of two is chosen to match the meta-MRs in SAMR and GESMR in order to compare adaptability fairly between methods.</p>
<p>UCB $/ R$ creates a multi-armed bandit problem with $R$ arms corresponding to MRs that are spaced logarithmically between $1 \times 10^{-3}$ and 1 . The upper confidence bound (UCB) algorithm is utilized to solve the problem. At each generation, an MR is sampled from UCB; the reward that is reported back is the best (lowest) change in function value from mutations for the current generation.</p>
<p>With SAMR, solutions are paired up with MRs spaced logarithmically between $1 \times 10^{-3}$ and $1 \times 10^{3}$. The solutions are mutated according to their assigned MR and the MRs are mutated with the same equation as with GESMR, using the meta-MR $\tau=2$.</p>
<p>With GESMR, the population of MRs are initialized by spacing them logarithmically between $1 \times 10^{-3}$ and $1 \times 10^{3}$. They are mutated using the meta-MR $\tau=2$.</p>
<h2>B DETAILS OF THE FUNCTION OPTIMIZATION EXPERIMENT</h2>
<p>Detailed definitions of the test functions are given in this Appendix, followed by detailed results.</p>
<h2>B. 1 Test Function Definitions</h2>
<h2>Ackley:</h2>
<p>$$
\begin{aligned}
f(x)= &amp; -a \exp \left(-b \sqrt{\frac{1}{d} \sum_{i=1}^{d} x_{i}^{2}}\right) \
&amp; -\exp \left(\frac{1}{d} \sum_{i=1}^{d} \cos \left(c x_{i}\right)\right)+a+\exp (1)
\end{aligned}
$$</p>
<p>with $a=20, b=0.2, c=2 \pi$.</p>
<h2>Griewank:</h2>
<p>$$
f(x)=\sum_{i=1}^{d} \frac{x_{i}^{2}}{4000}-\prod_{i=1}^{d} \cos \left(\frac{x_{i}}{\sqrt{i}}\right)+1
$$</p>
<h2>Rastrigin:</h2>
<p>$$
f(x)=10 d+\sum_{i=1}^{d}\left[x_{i}^{2}-10 \cos \left(2 \pi x_{i}\right)\right]
$$</p>
<h2>Rosenbrock:</h2>
<p>$$
f(x)=\sum_{i=1}^{d-1}\left[100\left(x_{i+1}-x_{i}^{2}\right)^{2}+\left(x_{i}-1\right)^{2}\right]
$$</p>
<p>Sphere:</p>
<p>$$
f(x)=\sum_{i=1}^{d} x_{i}^{2}
$$</p>
<p>Linear:</p>
<p>$$
f(x)=\sum_{i=1}^{d} x_{i}
$$</p>
<h2>B. 2 Function Optimization Results</h2>
<p>The full results of the test optimization functions are shown in Tables 1, 2, 3. Table 1 summarizes the final elite function value achieved by each algorithm in all the test function optimization runs. Table 2 summarizes the average elite function value over generations from each algorithm in all the test function optimization runs. Table 3 summarizes the mean squared error between the average $\log$ MR of a given algorithm with the $\log$ MR of LAMR-100 (the oracle long-term MR). These result show that GESMR outperforms other methods in the high dimensional and rugged function landscapes. GESMR also produces MRs that match the oracle long-term optimal MR, showing that GESMR empirically produces MRs suited for the long-term. GESMR also scales well to the high dimensions of neuroevolution.</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
<th></th>
<th></th>
<th></th>
<th></th>
<th></th>
<th></th>
<th></th>
<th></th>
<th></th>
<th></th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th></th>
<th></th>
<th></th>
<th></th>
<th></th>
<th></th>
<th></th>
<th></th>
<th></th>
<th></th>
<th></th>
<th></th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th style="text-align: center;"></th>
<th style="text-align: center;">Dies</th>
<th style="text-align: center;">Std</th>
<th style="text-align: center;">${ }^{\dagger}$ OFMR</th>
<th style="text-align: center;">${ }^{\dagger}$ LAMR-100</th>
<th style="text-align: center;">FMR</th>
<th style="text-align: center;">1CMR</th>
<th style="text-align: center;">15MR</th>
<th style="text-align: center;">UCB/5</th>
<th style="text-align: center;">UCB/10</th>
<th style="text-align: center;">SAMR</th>
<th style="text-align: center;">GESMR</th>
<th style="text-align: center;">GESMR-AVG</th>
<th style="text-align: center;">GESMR-FIX</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">$\begin{aligned} &amp; \text { ㄷ } \ &amp; \text { ㄷ } \ &amp; \text { ㄷ } \ &amp; \text { ㄷ } \ &amp; \text { ㄷ } \ &amp; 0 \end{aligned}$</td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0.2</td>
<td style="text-align: center;">0.0</td>
<td style="text-align: center;">${ }^{*} 5.3$</td>
<td style="text-align: center;">38.6</td>
<td style="text-align: center;">29.0</td>
<td style="text-align: center;">31.5</td>
<td style="text-align: center;">44.2</td>
<td style="text-align: center;">44.8</td>
<td style="text-align: center;">15.5</td>
<td style="text-align: center;">65.1</td>
<td style="text-align: center;">47.3</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">10</td>
<td style="text-align: center;">0.7</td>
<td style="text-align: center;">0.0</td>
<td style="text-align: center;">${ }^{*} 1.4$</td>
<td style="text-align: center;">9.5</td>
<td style="text-align: center;">20.0</td>
<td style="text-align: center;">13.7</td>
<td style="text-align: center;">12.0</td>
<td style="text-align: center;">61.0</td>
<td style="text-align: center;">10.2</td>
<td style="text-align: center;">95.3</td>
<td style="text-align: center;">14.0</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">30</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">4.1</td>
<td style="text-align: center;">0.0</td>
<td style="text-align: center;">2.3</td>
<td style="text-align: center;">1.9</td>
<td style="text-align: center;">1.9</td>
<td style="text-align: center;">9.9</td>
<td style="text-align: center;">8.6</td>
<td style="text-align: center;">4.4</td>
<td style="text-align: center;">1.2</td>
<td style="text-align: center;">14.2</td>
<td style="text-align: center;">16.3</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">100</td>
<td style="text-align: center;">1.1</td>
<td style="text-align: center;">0.0</td>
<td style="text-align: center;">8.3</td>
<td style="text-align: center;">3.2</td>
<td style="text-align: center;">2.3</td>
<td style="text-align: center;">7.0</td>
<td style="text-align: center;">6.3</td>
<td style="text-align: center;">12.6</td>
<td style="text-align: center;">1.4</td>
<td style="text-align: center;">29.4</td>
<td style="text-align: center;">4.5</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">1.1</td>
<td style="text-align: center;">9.4</td>
<td style="text-align: center;">0.0</td>
<td style="text-align: center;">3.2</td>
<td style="text-align: center;">3.2</td>
<td style="text-align: center;">4.8</td>
<td style="text-align: center;">9.9</td>
<td style="text-align: center;">12.7</td>
<td style="text-align: center;">1.4</td>
<td style="text-align: center;">0.9</td>
<td style="text-align: center;">29.1</td>
<td style="text-align: center;">34.1</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">10</td>
<td style="text-align: center;">7.1</td>
<td style="text-align: center;">0.0</td>
<td style="text-align: center;">6.0</td>
<td style="text-align: center;">6.0</td>
<td style="text-align: center;">5.7</td>
<td style="text-align: center;">9.0</td>
<td style="text-align: center;">8.5</td>
<td style="text-align: center;">13.9</td>
<td style="text-align: center;">${ }^{*} 0.4$</td>
<td style="text-align: center;">77.1</td>
<td style="text-align: center;">14.7</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">1000</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0.5</td>
<td style="text-align: center;">0.0</td>
<td style="text-align: center;">1.0</td>
<td style="text-align: center;">3.0</td>
<td style="text-align: center;">0.5</td>
<td style="text-align: center;">3.2</td>
<td style="text-align: center;">4.1</td>
<td style="text-align: center;">0.7</td>
<td style="text-align: center;">${ }^{*} 0.2$</td>
<td style="text-align: center;">105.4</td>
<td style="text-align: center;">28.7</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">10</td>
<td style="text-align: center;">11.7</td>
<td style="text-align: center;">0.0</td>
<td style="text-align: center;">3.1</td>
<td style="text-align: center;">9.0</td>
<td style="text-align: center;">14.5</td>
<td style="text-align: center;">16.5</td>
<td style="text-align: center;">11.7</td>
<td style="text-align: center;">5.1</td>
<td style="text-align: center;">3.0</td>
<td style="text-align: center;">89.9</td>
<td style="text-align: center;">23.1</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0.0</td>
<td style="text-align: center;">0.0</td>
<td style="text-align: center;">5.3</td>
<td style="text-align: center;">38.6</td>
<td style="text-align: center;">58.5</td>
<td style="text-align: center;">17.3</td>
<td style="text-align: center;">16.4</td>
<td style="text-align: center;">16.0</td>
<td style="text-align: center;">20.3</td>
<td style="text-align: center;">15.5</td>
<td style="text-align: center;">47.6</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">10</td>
<td style="text-align: center;">0.5</td>
<td style="text-align: center;">0.0</td>
<td style="text-align: center;">7.9</td>
<td style="text-align: center;">2.8</td>
<td style="text-align: center;">8.1</td>
<td style="text-align: center;">9.5</td>
<td style="text-align: center;">7.9</td>
<td style="text-align: center;">76.5</td>
<td style="text-align: center;">5.1</td>
<td style="text-align: center;">76.0</td>
<td style="text-align: center;">5.0</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">30</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1.2</td>
<td style="text-align: center;">0.0</td>
<td style="text-align: center;">1.3</td>
<td style="text-align: center;">1.7</td>
<td style="text-align: center;">3.1</td>
<td style="text-align: center;">7.9</td>
<td style="text-align: center;">7.7</td>
<td style="text-align: center;">0.8</td>
<td style="text-align: center;">0.6</td>
<td style="text-align: center;">8.4</td>
<td style="text-align: center;">18.6</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">100</td>
<td style="text-align: center;">1.1</td>
<td style="text-align: center;">2.2</td>
<td style="text-align: center;">0.0</td>
<td style="text-align: center;">6.9</td>
<td style="text-align: center;">2.8</td>
<td style="text-align: center;">4.1</td>
<td style="text-align: center;">8.6</td>
<td style="text-align: center;">7.7</td>
<td style="text-align: center;">0.9</td>
<td style="text-align: center;">${ }^{*} 0.5$</td>
<td style="text-align: center;">8.8</td>
<td style="text-align: center;">6.8</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">100</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">1.9</td>
<td style="text-align: center;">0.0</td>
<td style="text-align: center;">1.5</td>
<td style="text-align: center;">1.5</td>
<td style="text-align: center;">0.8</td>
<td style="text-align: center;">8.9</td>
<td style="text-align: center;">8.1</td>
<td style="text-align: center;">0.7</td>
<td style="text-align: center;">${ }^{*} 0.2$</td>
<td style="text-align: center;">9.0</td>
<td style="text-align: center;">23.1</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">10</td>
<td style="text-align: center;">2.6</td>
<td style="text-align: center;">0.0</td>
<td style="text-align: center;">5.6</td>
<td style="text-align: center;">5.6</td>
<td style="text-align: center;">0.9</td>
<td style="text-align: center;">7.8</td>
<td style="text-align: center;">8.0</td>
<td style="text-align: center;">0.7</td>
<td style="text-align: center;">${ }^{*} 0.2$</td>
<td style="text-align: center;">6.3</td>
<td style="text-align: center;">10.2</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">1000</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0.3</td>
<td style="text-align: center;">0.0</td>
<td style="text-align: center;">0.4</td>
<td style="text-align: center;">7.4</td>
<td style="text-align: center;">0.4</td>
<td style="text-align: center;">4.2</td>
<td style="text-align: center;">3.7</td>
<td style="text-align: center;">1.0</td>
<td style="text-align: center;">0.2</td>
<td style="text-align: center;">37.1</td>
<td style="text-align: center;">18.0</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">10</td>
<td style="text-align: center;">0.4</td>
<td style="text-align: center;">0.0</td>
<td style="text-align: center;">8.0</td>
<td style="text-align: center;">26.0</td>
<td style="text-align: center;">0.5</td>
<td style="text-align: center;">7.7</td>
<td style="text-align: center;">7.3</td>
<td style="text-align: center;">0.7</td>
<td style="text-align: center;">${ }^{*} 0.2$</td>
<td style="text-align: center;">151.9</td>
<td style="text-align: center;">5.7</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0.0</td>
<td style="text-align: center;">0.0</td>
<td style="text-align: center;">${ }^{*} 5.3$</td>
<td style="text-align: center;">38.6</td>
<td style="text-align: center;">39.7</td>
<td style="text-align: center;">30.1</td>
<td style="text-align: center;">44.2</td>
<td style="text-align: center;">21.9</td>
<td style="text-align: center;">12.6</td>
<td style="text-align: center;">25.4</td>
<td style="text-align: center;">47.5</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">10</td>
<td style="text-align: center;">0.8</td>
<td style="text-align: center;">0.0</td>
<td style="text-align: center;">9.7</td>
<td style="text-align: center;">0.9</td>
<td style="text-align: center;">11.7</td>
<td style="text-align: center;">3.2</td>
<td style="text-align: center;">3.1</td>
<td style="text-align: center;">80.6</td>
<td style="text-align: center;">6.0</td>
<td style="text-align: center;">99.4</td>
<td style="text-align: center;">2.6</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">30</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">2.1</td>
<td style="text-align: center;">0.0</td>
<td style="text-align: center;">2.4</td>
<td style="text-align: center;">6.0</td>
<td style="text-align: center;">2.8</td>
<td style="text-align: center;">22.1</td>
<td style="text-align: center;">24.4</td>
<td style="text-align: center;">1.4</td>
<td style="text-align: center;">1.2</td>
<td style="text-align: center;">7.0</td>
<td style="text-align: center;">31.9</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">100</td>
<td style="text-align: center;">1.1</td>
<td style="text-align: center;">1.6</td>
<td style="text-align: center;">0.0</td>
<td style="text-align: center;">3.1</td>
<td style="text-align: center;">3.1</td>
<td style="text-align: center;">0.9</td>
<td style="text-align: center;">22.5</td>
<td style="text-align: center;">22.0</td>
<td style="text-align: center;">1.6</td>
<td style="text-align: center;">0.8</td>
<td style="text-align: center;">6.9</td>
<td style="text-align: center;">36.5</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">100</td>
<td style="text-align: center;">1.1</td>
<td style="text-align: center;">15.8</td>
<td style="text-align: center;">0.0</td>
<td style="text-align: center;">5.8</td>
<td style="text-align: center;">5.8</td>
<td style="text-align: center;">25.6</td>
<td style="text-align: center;">28.0</td>
<td style="text-align: center;">23.2</td>
<td style="text-align: center;">4.0</td>
<td style="text-align: center;">${ }^{*} 0.9$</td>
<td style="text-align: center;">27.4</td>
<td style="text-align: center;">27.9</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">1000</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0.4</td>
<td style="text-align: center;">0.0</td>
<td style="text-align: center;">1.1</td>
<td style="text-align: center;">2.6</td>
<td style="text-align: center;">0.5</td>
<td style="text-align: center;">3.3</td>
<td style="text-align: center;">18.5</td>
<td style="text-align: center;">0.7</td>
<td style="text-align: center;">0.2</td>
<td style="text-align: center;">32.4</td>
<td style="text-align: center;">29.9</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">10</td>
<td style="text-align: center;">6.1</td>
<td style="text-align: center;">0.0</td>
<td style="text-align: center;">5.4</td>
<td style="text-align: center;">17.2</td>
<td style="text-align: center;">8.4</td>
<td style="text-align: center;">13.6</td>
<td style="text-align: center;">10.0</td>
<td style="text-align: center;">9.5</td>
<td style="text-align: center;">${ }^{*} 2.9$</td>
<td style="text-align: center;">118.7</td>
<td style="text-align: center;">13.5</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0.5</td>
<td style="text-align: center;">0.0</td>
<td style="text-align: center;">1.9</td>
<td style="text-align: center;">19.6</td>
<td style="text-align: center;">19.8</td>
<td style="text-align: center;">10.2</td>
<td style="text-align: center;">24.0</td>
<td style="text-align: center;">5.7</td>
<td style="text-align: center;">12.2</td>
<td style="text-align: center;">36.4</td>
<td style="text-align: center;">25.8</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">10</td>
<td style="text-align: center;">1.6</td>
<td style="text-align: center;">0.0</td>
<td style="text-align: center;">8.8</td>
<td style="text-align: center;">3.7</td>
<td style="text-align: center;">16.3</td>
<td style="text-align: center;">7.9</td>
<td style="text-align: center;">10.5</td>
<td style="text-align: center;">19.2</td>
<td style="text-align: center;">12.6</td>
<td style="text-align: center;">54.5</td>
<td style="text-align: center;">6.0</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">30</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">2.2</td>
<td style="text-align: center;">0.0</td>
<td style="text-align: center;">2.0</td>
<td style="text-align: center;">2.5</td>
<td style="text-align: center;">2.3</td>
<td style="text-align: center;">12.7</td>
<td style="text-align: center;">17.1</td>
<td style="text-align: center;">1.0</td>
<td style="text-align: center;">0.6</td>
<td style="text-align: center;">10.0</td>
<td style="text-align: center;">19.3</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">100</td>
<td style="text-align: center;">1.5</td>
<td style="text-align: center;">0.0</td>
<td style="text-align: center;">8.2</td>
<td style="text-align: center;">3.3</td>
<td style="text-align: center;">2.5</td>
<td style="text-align: center;">5.5</td>
<td style="text-align: center;">4.7</td>
<td style="text-align: center;">1.3</td>
<td style="text-align: center;">0.8</td>
<td style="text-align: center;">10.3</td>
<td style="text-align: center;">5.3</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">100</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">2.3</td>
<td style="text-align: center;">0.0</td>
<td style="text-align: center;">1.8</td>
<td style="text-align: center;">1.8</td>
<td style="text-align: center;">0.8</td>
<td style="text-align: center;">3.2</td>
<td style="text-align: center;">13.8</td>
<td style="text-align: center;">0.8</td>
<td style="text-align: center;">0.5</td>
<td style="text-align: center;">8.5</td>
<td style="text-align: center;">23.5</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">100</td>
<td style="text-align: center;">10</td>
<td style="text-align: center;">2.2</td>
<td style="text-align: center;">0.0</td>
<td style="text-align: center;">5.5</td>
<td style="text-align: center;">5.5</td>
<td style="text-align: center;">0.9</td>
<td style="text-align: center;">9.3</td>
<td style="text-align: center;">4.2</td>
<td style="text-align: center;">0.7</td>
<td style="text-align: center;">${ }^{*} 0.3$</td>
<td style="text-align: center;">10.5</td>
<td style="text-align: center;">9.4</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">1000</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0.5</td>
<td style="text-align: center;">0.0</td>
<td style="text-align: center;">0.4</td>
<td style="text-align: center;">7.2</td>
<td style="text-align: center;">0.4</td>
<td style="text-align: center;">1.0</td>
<td style="text-align: center;">0.9</td>
<td style="text-align: center;">0.7</td>
<td style="text-align: center;">0.2</td>
<td style="text-align: center;">35.0</td>
<td style="text-align: center;">18.6</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">10</td>
<td style="text-align: center;">0.4</td>
<td style="text-align: center;">0.0</td>
<td style="text-align: center;">7.6</td>
<td style="text-align: center;">25.3</td>
<td style="text-align: center;">0.4</td>
<td style="text-align: center;">2.5</td>
<td style="text-align: center;">1.5</td>
<td style="text-align: center;">0.8</td>
<td style="text-align: center;">${ }^{*} 0.2$</td>
<td style="text-align: center;">15.0</td>
<td style="text-align: center;">3.8</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0.5</td>
<td style="text-align: center;">0.0</td>
<td style="text-align: center;">${ }^{*} 4.1$</td>
<td style="text-align: center;">35.0</td>
<td style="text-align: center;">35.9</td>
<td style="text-align: center;">31.1</td>
<td style="text-align: center;">17.8</td>
<td style="text-align: center;">65.9</td>
<td style="text-align: center;">11.0</td>
<td style="text-align: center;">205.5</td>
<td style="text-align: center;">43.3</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">10</td>
<td style="text-align: center;">0.4</td>
<td style="text-align: center;">0.0</td>
<td style="text-align: center;">${ }^{*} 0.4$</td>
<td style="text-align: center;">12.1</td>
<td style="text-align: center;">19.0</td>
<td style="text-align: center;">14.0</td>
<td style="text-align: center;">7.9</td>
<td style="text-align: center;">53.7</td>
<td style="text-align: center;">9.7</td>
<td style="text-align: center;">106.2</td>
<td style="text-align: center;">17.2</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">30</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">3.0</td>
<td style="text-align: center;">0.0</td>
<td style="text-align: center;">2.2</td>
<td style="text-align: center;">4.0</td>
<td style="text-align: center;">2.6</td>
<td style="text-align: center;">7.0</td>
<td style="text-align: center;">15.7</td>
<td style="text-align: center;">0.6</td>
<td style="text-align: center;">0.7</td>
<td style="text-align: center;">8.8</td>
<td style="text-align: center;">24.6</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">100</td>
<td style="text-align: center;">1.5</td>
<td style="text-align: center;">0.0</td>
<td style="text-align: center;">6.8</td>
<td style="text-align: center;">3.0</td>
<td style="text-align: center;">2.1</td>
<td style="text-align: center;">8.0</td>
<td style="text-align: center;">6.9</td>
<td style="text-align: center;">1.0</td>
<td style="text-align: center;">0.7</td>
<td style="text-align: center;">10.2</td>
<td style="text-align: center;">7.7</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">100</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">3.2</td>
<td style="text-align: center;">0.0</td>
<td style="text-align: center;">3.2</td>
<td style="text-align: center;">3.2</td>
<td style="text-align: center;">1.2</td>
<td style="text-align: center;">2.5</td>
<td style="text-align: center;">4.7</td>
<td style="text-align: center;">0.6</td>
<td style="text-align: center;">${ }^{*} 0.5$</td>
<td style="text-align: center;">7.2</td>
<td style="text-align: center;">30.8</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">10</td>
<td style="text-align: center;">10</td>
<td style="text-align: center;">4.8</td>
<td style="text-align: center;">0.0</td>
<td style="text-align: center;">5.7</td>
<td style="text-align: center;">5.7</td>
<td style="text-align: center;">1.5</td>
<td style="text-align: center;">14.6</td>
<td style="text-align: center;">5.5</td>
<td style="text-align: center;">0.6</td>
<td style="text-align: center;">0.5</td>
<td style="text-align: center;">7.5</td>
<td style="text-align: center;">14.4</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">1000</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0.4</td>
<td style="text-align: center;">0.0</td>
<td style="text-align: center;">0.5</td>
<td style="text-align: center;">7.9</td>
<td style="text-align: center;">0.4</td>
<td style="text-align: center;">1.0</td>
<td style="text-align: center;">1.0</td>
<td style="text-align: center;">0.7</td>
<td style="text-align: center;">0.2</td>
<td style="text-align: center;">54.6</td>
<td style="text-align: center;">17.4</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">10</td>
<td style="text-align: center;">0.4</td>
<td style="text-align: center;">0.0</td>
<td style="text-align: center;">8.1</td>
<td style="text-align: center;">26.2</td>
<td style="text-align: center;">0.4</td>
<td style="text-align: center;">3.5</td>
<td style="text-align: center;">1.8</td>
<td style="text-align: center;">0.7</td>
<td style="text-align: center;">0.2</td>
<td style="text-align: center;">61.1</td>
<td style="text-align: center;">3.6</td>
</tr>
</tbody>
</table>
<p>Table 3: A genetic algorithm's mean squared error $\log$ MR compared to empirical estimate of the long-term optimal $\log$ MR (the $\log$ MR from LAMR-100), on various functions and population initializations using different mutation rate control strategies. This metric quantifies how optimal (lower is better) the MRs produced are for the long-term. The results are averaged over 40 seeds. The best value is shown in bold. A statistical t-test is performed on the best method and if the resulting p-value is less than 0.05 versus all other methods, the result is considered significant and shown with an asterisk (*) in front of it. Methods marked with $\dagger$ are oracles for benchmark and are not compared against because they use foresight during evolution. GESMR consistently outperforms other methods, showing that GESMR is producing MRs optimal for the long-term. The Linear function is not shown because LAMR-100 is not able to produce the true optimal MR (goes to infinity), so comparisons to LAMR-100 in a Linear function does not make sense.</p>
<p><img alt="img-8.jpeg" src="img-8.jpeg" /></p>
<p>Figure 9: Elite function value and average mutation rate (MR) over generations of neuroevolution using different MR control strategies applied to the reinforcement learning control tasks of CartPole, Pendulum, Acrobot, and MountainCar. GESMR outperforms most other methods in CartPole, Pendulum, and Acrobot, but fails in MountainCar.</p>
<h2>C DETAILS OF THE IMAGE CLASSIFICATION EXPERIMENT</h2>
<p>MNIST and Fashion-MNIST are common image classification datasets of hand written digits and clothes, respectively [20, 39]. The inputs are $28 \times x 28$ grayscale images and the output is one of ten classification labels. Both datasets consists of 60,000 training images 10,000 evaluation images. For these problems, $f$ is the negative log-likelihood function (i.e. the cross-entropy loss) as is common in supervised learning.</p>
<p>The evolved neural-network architecture contains three $3 \times 3$ Conv2D layers with 10 channels, each one followed by a $2 \times 2$ MaxPooling layer and a ReLU nonlinearity. The resulting feature maps are collapsed into a vector and fed into a $10 \times 10$ Dense layer followed by a ReLU and another $10 \times 10$ Dense layer. after which they are fed into a Softmax function to output ten class probabilities.</p>
<h2>D DETAILS OF THE REINFORCEMENT LEARNING EXPERIMENT</h2>
<p>CartPole, Pendulum, Acrobot, and MountainCar are common reinforcement learning control tasks. In each of these tasks, the performance of a robot controller is evaluated in a simulated environment [5]. CartPole consists of balancing a single pole on a onedimensional cart for as long as possible or until 200 timesteps have passed, rewarded for how long the pole stays up. Pendulum consists of a robot trying to swing up a pendulum, rewarded for maintaining as much of an upward angle as possible. Acrobot consists of moving a joint with two links such that the bottom link swings to as high as possible. MountainCar consists of a car with a weak engine in valley between two hills; it must be moved back and forth between the hills to gain enough energy to reach the top of the target hill. In all environments, $f$ is the negative cumulative reward of an episode (averaged over five episodes).</p>
<p>The evolved neural-network architecture contains a dense layer to map the number of observations to 128 hidden neurons with a ReLU activation function, and another dense layer mapping the 128 neurons to the number of actions. If the action space is discrete, a Softmax function is applied to output action probabilities.</p>
<p>The detailed results are shown in Figure 9.</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. GECCO-2022, July 7-13, 2022, Boston, MA
(C) 2022 Association for Computing Machinery.</p>
<p>ACM ISBN 978-1-4503-XXXX-X/18/06... \$15.00
https://doi.org/10.1145/1122445.1122456&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>