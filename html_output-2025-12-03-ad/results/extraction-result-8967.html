<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-8967 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-8967</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-8967</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-158.html">extraction-schema-158</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods for representing or converting graphs into text for language model training, including details of the representation, the type of graph, the conversion process, downstream tasks, performance metrics, comparisons to other methods, and any reported advantages, disadvantages, or failure cases.</div>
                <p><strong>Paper ID:</strong> paper-764b371693860195c2c92991cad92419720e002c</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/764b371693860195c2c92991cad92419720e002c" target="_blank">Generating English from Abstract Meaning Representations</a></p>
                <p><strong>Paper Venue:</strong> International Conference on Natural Language Generation</p>
                <p><strong>Paper TL;DR:</strong> A method that learns to linearize tokens of AMR graphs into an English-like order is introduced, which reduces the amount of distortion in PBMT and increases generation quality.</p>
                <p><strong>Paper Abstract:</strong> We present a method for generating English sentences from Abstract Meaning Representation (AMR) graphs, exploiting a parallel corpus of AMRs and English sentences. We treat AMR-to-English generation as phrase-based machine translation (PBMT). We introduce a method that learns to linearize tokens of AMR graphs into an English-like order. Our linearization reduces the amount of distortion in PBMT and increases generation quality. We report a Bleu score of 26.8 on the standard AMR/English test set.</p>
                <p><strong>Cost:</strong> 0.01</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e8967.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e8967.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods for representing or converting graphs into text for language model training, including details of the representation, the type of graph, the conversion process, downstream tasks, performance metrics, comparisons to other methods, and any reported advantages, disadvantages, or failure cases.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>AMR linearization (general)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Abstract Meaning Representation linearization for PBMT</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Transform AMR graphs into ordered token strings that approximate English word order, producing string-to-string training data for phrase-based machine translation (Moses) to generate English from AMR.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>representation_name</strong></td>
                            <td>AMR linearization (string serialization)</td>
                        </tr>
                        <tr>
                            <td><strong>representation_description</strong></td>
                            <td>AMR graphs are serialized into token sequences by ordering a concept token (from :instance-of) and its outgoing role tokens into a permutation intended to place semantically-related tokens near their English surface positions; variables, quotes, and some roles/concepts are removed in a cleaning step to form final linearized AMR strings.</td>
                        </tr>
                        <tr>
                            <td><strong>graph_type</strong></td>
                            <td>Abstract Meaning Representation (AMR) directed acyclic graphs (semantic graphs)</td>
                        </tr>
                        <tr>
                            <td><strong>conversion_method</strong></td>
                            <td>Learned linearization that produces permutations of the concept and role tokens per node; variants include pre-order DFS, memorized majority ordering of sibling-role sets, and a classifier-based reordering learned from token alignments; followed by cleaning (remove variables, sense tags, certain roles/concepts) and specialized realization for names/dates/numbers.</td>
                        </tr>
                        <tr>
                            <td><strong>downstream_task</strong></td>
                            <td>Surface realization / text generation: AMR-to-English generation using phrase-based machine translation</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Best end-to-end single-reference case-insensitive BLEU (1..4 grams): Dev BLEU 27.2, Test BLEU 26.9 (using classifier linearization + cleaning + name/number/date realizers). Phrase table: 1.2M phrase pairs; 5-gram language model trained on 1.7B Gigaword tokens. Alignment-crossings (development) after linearization reported in Table 2 (see specialized methods).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_others</strong></td>
                            <td>Compared directly within paper: classifier linearization > majority method > pre-order DFS in BLEU and in reducing alignment crossings; compared to Flanigan et al. (2016) tree-transducer approach, the best system outperforms by +4.9 BLEU on test (26.9 vs 22.0).</td>
                        </tr>
                        <tr>
                            <td><strong>advantages</strong></td>
                            <td>Provides string inputs compatible with strong existing PBMT toolkits (Moses); learned linearization reduces alignment crossings and improves locality, leading to substantial BLEU gains; practical pipeline with cleaning and special-case realizers yields a strong baseline.</td>
                        </tr>
                        <tr>
                            <td><strong>disadvantages</strong></td>
                            <td>Relies on discarding or simplifying AMR structure (many roles/concepts removed) which can lose semantic detail; converting a graph to a single string can still leave non-local dependencies and information loss compared to graph-aware methods.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_cases</strong></td>
                            <td>AMR abstractions that omit time/number/voice require insertion heuristics or separate realizers; some differences persist between system output and gold (example provided), indicating imperfect realization of arguments and function words; no systematic per-construction failure rates beyond alignment/lexical errors reported.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Generating English from Abstract Meaning Representations', 'publication_date_yy_mm': '2016-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8967.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e8967.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods for representing or converting graphs into text for language model training, including details of the representation, the type of graph, the conversion process, downstream tasks, performance metrics, comparisons to other methods, and any reported advantages, disadvantages, or failure cases.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Pre-order DFS</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Pre-order depth-first traversal linearization</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Baseline linearization that serializes AMR by a simple pre-order depth-first traversal of the graph, ignoring learned ordering cues.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>representation_name</strong></td>
                            <td>Pre-order DFS linearization</td>
                        </tr>
                        <tr>
                            <td><strong>representation_description</strong></td>
                            <td>Per-node, visit concept and its children in standard pre-order DFS sequence (concept via :instance-of first, then outgoing edges in graph-defined order), yielding a serialized AMR token string.</td>
                        </tr>
                        <tr>
                            <td><strong>graph_type</strong></td>
                            <td>AMR graphs</td>
                        </tr>
                        <tr>
                            <td><strong>conversion_method</strong></td>
                            <td>Deterministic pre-order depth-first traversal (no learned permutation), producing token sequence including concept and role tokens.</td>
                        </tr>
                        <tr>
                            <td><strong>downstream_task</strong></td>
                            <td>AMR-to-English generation via PBMT</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Dev BLEU 17.7, Test BLEU 16.6 (baseline). Alignment crossings on dev: total 46671, adjacent crossings 7409 (as reported in Table 2).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_others</strong></td>
                            <td>Underperforms the Majority and Classifier linearization methods: Majority and Classifier substantially reduce alignment crossings and increase BLEU (+~9 BLEU to 25.6/26.9 respectively on test with further cleaning/realizers).</td>
                        </tr>
                        <tr>
                            <td><strong>advantages</strong></td>
                            <td>Simple, deterministic, no training required; preserves subtree adjacency that reflects AMR locality.</td>
                        </tr>
                        <tr>
                            <td><strong>disadvantages</strong></td>
                            <td>Creates many alignment crossings relative to learned orderings, resulting in worse PBMT performance; does not attempt to match English ordering.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_cases</strong></td>
                            <td>High number of alignment crossings leads to poor PBMT phrase alignment and low BLEU; produces lower-quality generation without further cleaning and specialized realizers.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Generating English from Abstract Meaning Representations', 'publication_date_yy_mm': '2016-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8967.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e8967.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods for representing or converting graphs into text for language model training, including details of the representation, the type of graph, the conversion process, downstream tasks, performance metrics, comparisons to other methods, and any reported advantages, disadvantages, or failure cases.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Majority Method</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Majority-order linearization</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Memorize the most common sibling-edge ordering observed in aligned training data for each role set; fall back to human-annotated AMR order if unseen.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>representation_name</strong></td>
                            <td>Majority-order linearization</td>
                        </tr>
                        <tr>
                            <td><strong>representation_description</strong></td>
                            <td>For each set of sibling roles at a node, the method stores and uses the most frequent permutation observed in the aligned training corpus; unseen role-sets use the original AMR ordering (with :instance-of first).</td>
                        </tr>
                        <tr>
                            <td><strong>graph_type</strong></td>
                            <td>AMR graphs</td>
                        </tr>
                        <tr>
                            <td><strong>conversion_method</strong></td>
                            <td>Lookup-based permutation: extract sibling-edge sets from training alignments, memorize sorted order (by median alignment positions), and apply memorized ordering when linearizing dev/test AMRs.</td>
                        </tr>
                        <tr>
                            <td><strong>downstream_task</strong></td>
                            <td>AMR-to-English generation via PBMT</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Dev BLEU 26.5, Test BLEU 25.6 (including cleaning and special realizers). Alignment crossings on dev: total 33772 (reported as 33772 (72%)), adjacent crossings 4850 (reported as 4850 (65%)) as shown in Table 2.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_others</strong></td>
                            <td>Outperforms Pre-order DFS by a large margin (+~9 BLEU on test when combined with cleaning/realizers); slightly underperforms the classifier method (Classifier: Dev 27.2 / Test 26.9).</td>
                        </tr>
                        <tr>
                            <td><strong>advantages</strong></td>
                            <td>Simple, data-driven, substantially reduces alignment crossings and improves BLEU without complex modeling; easy to implement and effective.</td>
                        </tr>
                        <tr>
                            <td><strong>disadvantages</strong></td>
                            <td>Cannot generalize to unseen role-sets beyond memorized permutations; falls back to AMR order which may be suboptimal.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_cases</strong></td>
                            <td>When a sibling-role set is not observed in training, fallback ordering may produce suboptimal token order and higher alignment crossings; lacks fine-grained decisions like dropping :instance-of when appropriate.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Generating English from Abstract Meaning Representations', 'publication_date_yy_mm': '2016-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8967.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e8967.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods for representing or converting graphs into text for language model training, including details of the representation, the type of graph, the conversion process, downstream tasks, performance metrics, comparisons to other methods, and any reported advantages, disadvantages, or failure cases.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Classifier Method</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Classifier-based linearization (three binary classifiers)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A learned linearization that decomposes ordering into three binary classification tasks (drop :instance-of, position relative to :instance-of, pairwise ordering) trained on token-aligned AMR/English data to reduce alignment crossings and improve locality.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>representation_name</strong></td>
                            <td>Classifier-based linearization</td>
                        </tr>
                        <tr>
                            <td><strong>representation_description</strong></td>
                            <td>Breaks linearization into (1) deciding whether to drop the :instance-of concept, (2) deciding for each edge whether it appears before the :instance-of, and (3) pairwise ordering decisions between edges; uses maximum entropy classifiers with features built from concept and role tokens and pair combinations, then composes pairwise probabilities into a left-leaning score to produce an ordering.</td>
                        </tr>
                        <tr>
                            <td><strong>graph_type</strong></td>
                            <td>AMR graphs</td>
                        </tr>
                        <tr>
                            <td><strong>conversion_method</strong></td>
                            <td>Train three MaxEnt binary classifiers on aligned training data: classifier (1) predicts dropping :instance-of using features k, c, (c,r_i), PropBank/special keyword flags; classifier (2) predicts whether r_i appears before :instance-of with features r_i,(c,r_i),(r_i,r_j); classifier (3) predicts r_i before r_j with features (c,r_i,r_j). Use classifier outputs to partition edges and produce final permutation via recursive left-leaning scoring.</td>
                        </tr>
                        <tr>
                            <td><strong>downstream_task</strong></td>
                            <td>AMR-to-English generation via PBMT</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Dev BLEU 27.2, Test BLEU 26.9 (including cleaning and name/number/date realizers). Alignment crossings on dev: total 35603 (reported as 35603 (76%)), adjacent crossings 4015 (reported as 4015 (54%)). Concept-dropping stats: 97% of concepts dropped by classifier are unaligned; classifier correctly drops 87% of unaligned concepts.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_others</strong></td>
                            <td>Outperforms Majority Method and Pre-order DFS in BLEU and reduces adjacent alignment crossings more than Majority Method, improving locality; best overall in paper and outperforms prior tree-transducer approach of Flanigan et al. (2016) by +4.9 BLEU on test.</td>
                        </tr>
                        <tr>
                            <td><strong>advantages</strong></td>
                            <td>Learns ordering decisions capable of dropping unexpressed concepts and producing more English-like token order; reduces adjacent alignment crossings strongly and yields best BLEU performance in experiments; quantitative concept dropping accuracy reported.</td>
                        </tr>
                        <tr>
                            <td><strong>disadvantages</strong></td>
                            <td>Requires training with aligned AMR/English data and multiple classifiers; pairwise classifier approach is more complex than memorization and may be sensitive to feature design and data sparsity.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_cases</strong></td>
                            <td>Not all dropped/kept decisions are perfect (classifier correctly drops 87% of unaligned concepts, so 13% of unaligned concepts are incorrectly kept); some residual alignment crossings remain and some generated sentences diverge from gold (example provided), indicating imperfect ordering and realization in some cases.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Generating English from Abstract Meaning Representations', 'publication_date_yy_mm': '2016-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8967.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e8967.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of methods for representing or converting graphs into text for language model training, including details of the representation, the type of graph, the conversion process, downstream tasks, performance metrics, comparisons to other methods, and any reported advantages, disadvantages, or failure cases.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Cleaning & special realizers</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>AMR cleaning and specialized name/number/date realizers</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Post-linearization steps that remove variables, sense tags and low-value roles/concepts, and insert specialized realizations for names, numbers, and dates to improve generation quality.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>representation_name</strong></td>
                            <td>Cleaned linearized AMR + specialized realizers</td>
                        </tr>
                        <tr>
                            <td><strong>representation_description</strong></td>
                            <td>After linearization, remove variable names, quote marks, sense tags, *-quantity/*-entity concepts and specific roles (:op*, :snt*, :arg0/1/2, :name, :quant, :unit, :value, :year, :domain-of), and augment training data by applying realization components for names, numbers, and dates found in dev/test to improve model exposure to these surface forms.</td>
                        </tr>
                        <tr>
                            <td><strong>graph_type</strong></td>
                            <td>AMR graphs (post-linearization string form)</td>
                        </tr>
                        <tr>
                            <td><strong>conversion_method</strong></td>
                            <td>Apply rule-based cleaning to linearized AMR strings (strip/deleting tokens and roles listed above); apply specialized generators for names/dates/numbers and add their outputs to the training data.</td>
                        </tr>
                        <tr>
                            <td><strong>downstream_task</strong></td>
                            <td>AMR-to-English generation via PBMT</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Incremental BLEU improvements reported: Pre-order DFS baseline 16.6 test; adding cleaning raises DFS to 21.0 test (1a), adding name/number/date realizers further raises to 22.5 test (1b). When combined with Majority/Classifier methods, yields best scores (Majority: test 25.6; Classifier: test 26.9).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_others</strong></td>
                            <td>Cleaning and specialized realizers provide large improvements over raw linearization (see 1 -> 1a -> 1b rows in Table 3); they are complementary to ordering methods (Majority and Classifier).</td>
                        </tr>
                        <tr>
                            <td><strong>advantages</strong></td>
                            <td>Significantly improves BLEU by normalizing input and handling special surface realizations; reduces noise for PBMT training and decoding.</td>
                        </tr>
                        <tr>
                            <td><strong>disadvantages</strong></td>
                            <td>Removes many AMR annotations and roles (potential semantic information loss); reliance on specialized components means separate engineering for different entity types.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_cases</strong></td>
                            <td>Removing roles/concepts may discard information needed for faithful surface realization in some cases; specialized realizers may not generalize to unseen entity formats.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Generating English from Abstract Meaning Representations', 'publication_date_yy_mm': '2016-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Generation from abstract meaning representation using tree transducers <em>(Rating: 2)</em></li>
                <li>Aligning English strings with Abstract Meaning Representation graphs <em>(Rating: 2)</em></li>
                <li>Abstract Meaning Representation for sembanking <em>(Rating: 2)</em></li>
                <li>Source-side classifier preordering for machine translation <em>(Rating: 2)</em></li>
                <li>Generation that exploits corpus-based statistical knowledge <em>(Rating: 1)</em></li>
                <li>Phrase-based statistical language generation using graphical models and active learning <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-8967",
    "paper_id": "paper-764b371693860195c2c92991cad92419720e002c",
    "extraction_schema_id": "extraction-schema-158",
    "extracted_data": [
        {
            "name_short": "AMR linearization (general)",
            "name_full": "Abstract Meaning Representation linearization for PBMT",
            "brief_description": "Transform AMR graphs into ordered token strings that approximate English word order, producing string-to-string training data for phrase-based machine translation (Moses) to generate English from AMR.",
            "citation_title": "here",
            "mention_or_use": "use",
            "representation_name": "AMR linearization (string serialization)",
            "representation_description": "AMR graphs are serialized into token sequences by ordering a concept token (from :instance-of) and its outgoing role tokens into a permutation intended to place semantically-related tokens near their English surface positions; variables, quotes, and some roles/concepts are removed in a cleaning step to form final linearized AMR strings.",
            "graph_type": "Abstract Meaning Representation (AMR) directed acyclic graphs (semantic graphs)",
            "conversion_method": "Learned linearization that produces permutations of the concept and role tokens per node; variants include pre-order DFS, memorized majority ordering of sibling-role sets, and a classifier-based reordering learned from token alignments; followed by cleaning (remove variables, sense tags, certain roles/concepts) and specialized realization for names/dates/numbers.",
            "downstream_task": "Surface realization / text generation: AMR-to-English generation using phrase-based machine translation",
            "performance_metrics": "Best end-to-end single-reference case-insensitive BLEU (1..4 grams): Dev BLEU 27.2, Test BLEU 26.9 (using classifier linearization + cleaning + name/number/date realizers). Phrase table: 1.2M phrase pairs; 5-gram language model trained on 1.7B Gigaword tokens. Alignment-crossings (development) after linearization reported in Table 2 (see specialized methods).",
            "comparison_to_others": "Compared directly within paper: classifier linearization &gt; majority method &gt; pre-order DFS in BLEU and in reducing alignment crossings; compared to Flanigan et al. (2016) tree-transducer approach, the best system outperforms by +4.9 BLEU on test (26.9 vs 22.0).",
            "advantages": "Provides string inputs compatible with strong existing PBMT toolkits (Moses); learned linearization reduces alignment crossings and improves locality, leading to substantial BLEU gains; practical pipeline with cleaning and special-case realizers yields a strong baseline.",
            "disadvantages": "Relies on discarding or simplifying AMR structure (many roles/concepts removed) which can lose semantic detail; converting a graph to a single string can still leave non-local dependencies and information loss compared to graph-aware methods.",
            "failure_cases": "AMR abstractions that omit time/number/voice require insertion heuristics or separate realizers; some differences persist between system output and gold (example provided), indicating imperfect realization of arguments and function words; no systematic per-construction failure rates beyond alignment/lexical errors reported.",
            "uuid": "e8967.0",
            "source_info": {
                "paper_title": "Generating English from Abstract Meaning Representations",
                "publication_date_yy_mm": "2016-09"
            }
        },
        {
            "name_short": "Pre-order DFS",
            "name_full": "Pre-order depth-first traversal linearization",
            "brief_description": "Baseline linearization that serializes AMR by a simple pre-order depth-first traversal of the graph, ignoring learned ordering cues.",
            "citation_title": "here",
            "mention_or_use": "use",
            "representation_name": "Pre-order DFS linearization",
            "representation_description": "Per-node, visit concept and its children in standard pre-order DFS sequence (concept via :instance-of first, then outgoing edges in graph-defined order), yielding a serialized AMR token string.",
            "graph_type": "AMR graphs",
            "conversion_method": "Deterministic pre-order depth-first traversal (no learned permutation), producing token sequence including concept and role tokens.",
            "downstream_task": "AMR-to-English generation via PBMT",
            "performance_metrics": "Dev BLEU 17.7, Test BLEU 16.6 (baseline). Alignment crossings on dev: total 46671, adjacent crossings 7409 (as reported in Table 2).",
            "comparison_to_others": "Underperforms the Majority and Classifier linearization methods: Majority and Classifier substantially reduce alignment crossings and increase BLEU (+~9 BLEU to 25.6/26.9 respectively on test with further cleaning/realizers).",
            "advantages": "Simple, deterministic, no training required; preserves subtree adjacency that reflects AMR locality.",
            "disadvantages": "Creates many alignment crossings relative to learned orderings, resulting in worse PBMT performance; does not attempt to match English ordering.",
            "failure_cases": "High number of alignment crossings leads to poor PBMT phrase alignment and low BLEU; produces lower-quality generation without further cleaning and specialized realizers.",
            "uuid": "e8967.1",
            "source_info": {
                "paper_title": "Generating English from Abstract Meaning Representations",
                "publication_date_yy_mm": "2016-09"
            }
        },
        {
            "name_short": "Majority Method",
            "name_full": "Majority-order linearization",
            "brief_description": "Memorize the most common sibling-edge ordering observed in aligned training data for each role set; fall back to human-annotated AMR order if unseen.",
            "citation_title": "here",
            "mention_or_use": "use",
            "representation_name": "Majority-order linearization",
            "representation_description": "For each set of sibling roles at a node, the method stores and uses the most frequent permutation observed in the aligned training corpus; unseen role-sets use the original AMR ordering (with :instance-of first).",
            "graph_type": "AMR graphs",
            "conversion_method": "Lookup-based permutation: extract sibling-edge sets from training alignments, memorize sorted order (by median alignment positions), and apply memorized ordering when linearizing dev/test AMRs.",
            "downstream_task": "AMR-to-English generation via PBMT",
            "performance_metrics": "Dev BLEU 26.5, Test BLEU 25.6 (including cleaning and special realizers). Alignment crossings on dev: total 33772 (reported as 33772 (72%)), adjacent crossings 4850 (reported as 4850 (65%)) as shown in Table 2.",
            "comparison_to_others": "Outperforms Pre-order DFS by a large margin (+~9 BLEU on test when combined with cleaning/realizers); slightly underperforms the classifier method (Classifier: Dev 27.2 / Test 26.9).",
            "advantages": "Simple, data-driven, substantially reduces alignment crossings and improves BLEU without complex modeling; easy to implement and effective.",
            "disadvantages": "Cannot generalize to unseen role-sets beyond memorized permutations; falls back to AMR order which may be suboptimal.",
            "failure_cases": "When a sibling-role set is not observed in training, fallback ordering may produce suboptimal token order and higher alignment crossings; lacks fine-grained decisions like dropping :instance-of when appropriate.",
            "uuid": "e8967.2",
            "source_info": {
                "paper_title": "Generating English from Abstract Meaning Representations",
                "publication_date_yy_mm": "2016-09"
            }
        },
        {
            "name_short": "Classifier Method",
            "name_full": "Classifier-based linearization (three binary classifiers)",
            "brief_description": "A learned linearization that decomposes ordering into three binary classification tasks (drop :instance-of, position relative to :instance-of, pairwise ordering) trained on token-aligned AMR/English data to reduce alignment crossings and improve locality.",
            "citation_title": "here",
            "mention_or_use": "use",
            "representation_name": "Classifier-based linearization",
            "representation_description": "Breaks linearization into (1) deciding whether to drop the :instance-of concept, (2) deciding for each edge whether it appears before the :instance-of, and (3) pairwise ordering decisions between edges; uses maximum entropy classifiers with features built from concept and role tokens and pair combinations, then composes pairwise probabilities into a left-leaning score to produce an ordering.",
            "graph_type": "AMR graphs",
            "conversion_method": "Train three MaxEnt binary classifiers on aligned training data: classifier (1) predicts dropping :instance-of using features k, c, (c,r_i), PropBank/special keyword flags; classifier (2) predicts whether r_i appears before :instance-of with features r_i,(c,r_i),(r_i,r_j); classifier (3) predicts r_i before r_j with features (c,r_i,r_j). Use classifier outputs to partition edges and produce final permutation via recursive left-leaning scoring.",
            "downstream_task": "AMR-to-English generation via PBMT",
            "performance_metrics": "Dev BLEU 27.2, Test BLEU 26.9 (including cleaning and name/number/date realizers). Alignment crossings on dev: total 35603 (reported as 35603 (76%)), adjacent crossings 4015 (reported as 4015 (54%)). Concept-dropping stats: 97% of concepts dropped by classifier are unaligned; classifier correctly drops 87% of unaligned concepts.",
            "comparison_to_others": "Outperforms Majority Method and Pre-order DFS in BLEU and reduces adjacent alignment crossings more than Majority Method, improving locality; best overall in paper and outperforms prior tree-transducer approach of Flanigan et al. (2016) by +4.9 BLEU on test.",
            "advantages": "Learns ordering decisions capable of dropping unexpressed concepts and producing more English-like token order; reduces adjacent alignment crossings strongly and yields best BLEU performance in experiments; quantitative concept dropping accuracy reported.",
            "disadvantages": "Requires training with aligned AMR/English data and multiple classifiers; pairwise classifier approach is more complex than memorization and may be sensitive to feature design and data sparsity.",
            "failure_cases": "Not all dropped/kept decisions are perfect (classifier correctly drops 87% of unaligned concepts, so 13% of unaligned concepts are incorrectly kept); some residual alignment crossings remain and some generated sentences diverge from gold (example provided), indicating imperfect ordering and realization in some cases.",
            "uuid": "e8967.3",
            "source_info": {
                "paper_title": "Generating English from Abstract Meaning Representations",
                "publication_date_yy_mm": "2016-09"
            }
        },
        {
            "name_short": "Cleaning & special realizers",
            "name_full": "AMR cleaning and specialized name/number/date realizers",
            "brief_description": "Post-linearization steps that remove variables, sense tags and low-value roles/concepts, and insert specialized realizations for names, numbers, and dates to improve generation quality.",
            "citation_title": "here",
            "mention_or_use": "use",
            "representation_name": "Cleaned linearized AMR + specialized realizers",
            "representation_description": "After linearization, remove variable names, quote marks, sense tags, *-quantity/*-entity concepts and specific roles (:op*, :snt*, :arg0/1/2, :name, :quant, :unit, :value, :year, :domain-of), and augment training data by applying realization components for names, numbers, and dates found in dev/test to improve model exposure to these surface forms.",
            "graph_type": "AMR graphs (post-linearization string form)",
            "conversion_method": "Apply rule-based cleaning to linearized AMR strings (strip/deleting tokens and roles listed above); apply specialized generators for names/dates/numbers and add their outputs to the training data.",
            "downstream_task": "AMR-to-English generation via PBMT",
            "performance_metrics": "Incremental BLEU improvements reported: Pre-order DFS baseline 16.6 test; adding cleaning raises DFS to 21.0 test (1a), adding name/number/date realizers further raises to 22.5 test (1b). When combined with Majority/Classifier methods, yields best scores (Majority: test 25.6; Classifier: test 26.9).",
            "comparison_to_others": "Cleaning and specialized realizers provide large improvements over raw linearization (see 1 -&gt; 1a -&gt; 1b rows in Table 3); they are complementary to ordering methods (Majority and Classifier).",
            "advantages": "Significantly improves BLEU by normalizing input and handling special surface realizations; reduces noise for PBMT training and decoding.",
            "disadvantages": "Removes many AMR annotations and roles (potential semantic information loss); reliance on specialized components means separate engineering for different entity types.",
            "failure_cases": "Removing roles/concepts may discard information needed for faithful surface realization in some cases; specialized realizers may not generalize to unseen entity formats.",
            "uuid": "e8967.4",
            "source_info": {
                "paper_title": "Generating English from Abstract Meaning Representations",
                "publication_date_yy_mm": "2016-09"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Generation from abstract meaning representation using tree transducers",
            "rating": 2
        },
        {
            "paper_title": "Aligning English strings with Abstract Meaning Representation graphs",
            "rating": 2
        },
        {
            "paper_title": "Abstract Meaning Representation for sembanking",
            "rating": 2
        },
        {
            "paper_title": "Source-side classifier preordering for machine translation",
            "rating": 2
        },
        {
            "paper_title": "Generation that exploits corpus-based statistical knowledge",
            "rating": 1
        },
        {
            "paper_title": "Phrase-based statistical language generation using graphical models and active learning",
            "rating": 1
        }
    ],
    "cost": 0.00979975,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>Generating English from Abstract Meaning Representations</h1>
<p>Nima Pourdamghani , Kevin Knight , Ulf Hermjakob<br>Information Sciences Institute<br>Department of Computer Science<br>University of Southern California<br>{damghani,knight,ulf}@isi.edu</p>
<h4>Abstract</h4>
<p>We present a method for generating English sentences from Abstract Meaning Representation (AMR) graphs, exploiting a parallel corpus of AMRs and English sentences. We treat AMR-to-English generation as phrase-based machine translation (PBMT). We introduce a method that learns to linearize tokens of AMR graphs into an English-like order. Our linearization reduces the amount of distortion in PBMT and increases generation quality. We report a Bleu score of 26.8 on the standard AMR/English test set.</p>
<h2>1 Introduction</h2>
<p>Banarescu et al. (2013) introduce Abstract Meaning Representation (AMR) graphs to represent sentence level semantics. Human annotators have created a dataset of more than 10,000 AMR/English string pairs.</p>
<p>AMRs are directed acyclic graphs, where leaves are labeled with concepts, internal nodes are labeled with variables representing instances of those concepts, and edges are labeled with roles that relate pairs of concepts. For instance, the sentence The boy wants to go is represented as:</p>
<div class="codehilite"><pre><span></span><code><span class="p">(</span><span class="n">w</span><span class="w"> </span><span class="err">:</span><span class="n">instance</span><span class="o">-</span><span class="k">of</span><span class="w"> </span><span class="n">want</span><span class="o">-</span><span class="mi">01</span>
<span class="w">    </span><span class="err">:</span><span class="n">arg0</span><span class="w"> </span><span class="p">(</span><span class="n">b</span><span class="w"> </span><span class="err">:</span><span class="n">instance</span><span class="o">-</span><span class="k">of</span><span class="w"> </span><span class="n">boy</span><span class="p">)</span>
<span class="w">    </span><span class="err">:</span><span class="n">arg1</span><span class="w"> </span><span class="p">(</span><span class="n">g</span><span class="w"> </span><span class="err">:</span><span class="n">instance</span><span class="o">-</span><span class="k">of</span><span class="w"> </span><span class="k">go</span><span class="o">-</span><span class="mi">01</span>
<span class="w">        </span><span class="err">:</span><span class="n">arg0</span><span class="w"> </span><span class="n">b</span><span class="p">))</span>
</code></pre></div>

<p>Colons discriminate roles from concepts. In this paper, :instance-of is our way of writing the slash $(/)$ found in the AMR corpus.</p>
<p>Because AMR and English are highly cognate, the AMR-to-English generation problem might seem similar to previous natural language generation (NLG) problems such as bag generation (Brown et al., 1990), restoring order to unordered dependency trees (Guo et al., 2011) or generation from logical form (Corston-Oliver et al., 2002). However, AMR's deeper logic provides a serious challenge for English realization. AMR also abstracts away details of time, number, and voice, which must be inserted.</p>
<p>Langkilde and Knight (1998) introduced Nitrogen, which used a precursor of AMR for generating English. Recently, Flanigan et al. (2016) presented the first trained AMR-to-English generator. They generate spanning trees from AMR graphs and apply tree-to-string transducers to the trees to generate English.</p>
<p>We attack AMR-to-English generation using the tools of phrase-based machine translation (PBMT). PBMT has already been applied to natural language generation from simple semantic structures (Mairesse et al., 2010), but deep semantic representations such as AMR are more challenging to deal with. PBMT expects strings for its source and target languages, so we cannot work with AMR graphs as input. Therefore, we develop a method that learns to linearize AMR graphs into AMR strings. Our linearization strives to put AMR tokens roughly into English word order, making the transformation to English easier.</p>
<p>It may seem surprising that we ignore much of the structure of AMR, but we follow string-based statistical MT, which ignored much of the structure of</p>
<p><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Figure 1: AMR-to-English generation pipeline.
language but nonetheless provided a strong baseline.
Figure 1 shows our pipeline for generating English from AMR. Our contributions are:</p>
<ol>
<li>We present a strong baseline method for AMR-to-English generation.</li>
<li>We introduce a method that learns to linearize AMR tokens into an order resembling English.</li>
<li>We obtain a Bleu score of 26.8 on the standard AMR/English test set, which is 4.9 points higher than previous work.</li>
</ol>
<h2>2 Method</h2>
<p>Given a set of AMR/English pairs, divided into train, development, and test sets, we follow these steps:
Construct token-level alignments: We use the method proposed in (Pourdamghani et al., 2014) to construct alignments between AMR and English tokens in the training set.
Extend training data: We use special realization components for names, dates, and numbers found in the dev/test sets, adding their results to the training corpus.
Linearize AMR graphs: We learn to convert AMR graphs into AMR strings in a way that linearized AMR tokens have an English-like order (Section 3). Clean AMR strings: We remove variables, quote marks, and sense tags from linearized AMRs. We also remove <em>-quantity and </em>-entity concepts, plus these roles: :op<em>, :snt</em>, :arg0, :arg1, :arg2, :name, :quant, :unit, :value, :year, :domain-of.
Phrase-Based Machine Translation: We use Moses (Koehn et al., 2007) to train and tune a PBMT system on string/string training data. We then use this system to produce English realizations from linearized development and test AMRs.</p>
<h2>3 Linearization</h2>
<p>When we linearize AMR, we would like-at a minimum-for semantically-related tokens to stay close together. A straightforward, pre-order depth first search (DFS) accomplishes this (Pourdamghani et al., 2014). For instance, linearizing</p>
<div class="codehilite"><pre><span></span><code><span class="p">(</span><span class="n">w</span><span class="w"> </span><span class="err">:</span><span class="n">instance</span><span class="o">-</span><span class="k">of</span><span class="w"> </span><span class="n">want</span><span class="o">-</span><span class="mi">01</span>
<span class="w">    </span><span class="err">:</span><span class="n">arg0</span><span class="w"> </span><span class="p">(</span><span class="n">b</span><span class="w"> </span><span class="err">:</span><span class="n">instance</span><span class="o">-</span><span class="k">of</span><span class="w"> </span><span class="n">boy</span><span class="p">)</span>
<span class="w">    </span><span class="err">:</span><span class="n">arg1</span><span class="w"> </span><span class="p">(</span><span class="n">g</span><span class="w"> </span><span class="err">:</span><span class="n">instance</span><span class="o">-</span><span class="k">of</span><span class="w"> </span><span class="k">go</span><span class="o">-</span><span class="mi">01</span>
<span class="w">        </span><span class="err">:</span><span class="n">arg0</span><span class="w"> </span><span class="n">b</span><span class="p">))</span>
</code></pre></div>

<p>yields " $w$ :instance-of want-01 :arg0 $b$ :instance-of boy :arg1 $g$ :instance-of go-01 :arg0 $b$ ".</p>
<p>Of course, we are free to visit AMR sister nodes in any order. For instance, if we visit sisters in order (:arg0, :instance-of, :arg1), we get this string instead: " $w$ :arg0 $b$ :instance-of boy :instance-of want-01 :arg1 $g$ :instance-of go-01 :arg0 $b$ ", which more resembles English word order.</p>
<p>We therefore induce an ordering function that takes any set of edge labels as input and produces a permutation of those labels. We call this the linearization function.</p>
<p>The input to this function is a sequence consisting of the concept under the :instance-of edge (e.g., want-01) followed by the other edges sorted alphabetically (e.g., :arg0 :arg1). The output is a permutation of the input (e.g., $(2,1,3)$ ).</p>
<p>Because :instance-of concepts often have no equivalent in English, e.g.:</p>
<div class="codehilite"><pre><span></span><code><span class="p">(</span><span class="n">n</span><span class="w"> </span><span class="o">:</span><span class="n">instance</span><span class="o">-</span><span class="kr">of</span><span class="w"> </span><span class="n">name</span>
<span class="w">    </span><span class="o">:</span><span class="n">op1</span><span class="w"> </span><span class="s">&quot;Pierre&quot;</span><span class="w"> </span><span class="o">-&gt;</span><span class="w"> </span><span class="n">Pierre</span><span class="w"> </span><span class="n">Vinken</span>
<span class="w">    </span><span class="o">:</span><span class="n">op2</span><span class="w"> </span><span class="s">&quot;Vinken&quot;</span><span class="p">)</span>
</code></pre></div>

<p>we additionally allow the first component of the output to be " -1 ", indicating deletion.</p>
<p>Our linearization function therefore has the following form:</p>
<p>$$
p:\left{c, r_{1}, r_{2}, \ldots, r_{k-1}\right} \rightarrow\left(\pi_{1}, \pi_{2}, \ldots, \pi_{k}\right)
$$</p>
<p>where $c$ is a concept token, $r_{i}$ are role tokens, $\pi_{i&gt;1} \in$ ${1,2, \ldots, k}$ and $\pi_{1} \in{-1,1,2, \ldots, k}$.</p>
<p>Here are sample input/output pairs for the linearization function:</p>
<div class="codehilite"><pre><span></span><code><span class="p">(</span><span class="n">want</span><span class="o">-</span><span class="mo">01</span><span class="p">,</span><span class="w"> </span><span class="o">:</span><span class="n">arg0</span><span class="p">,</span><span class="w"> </span><span class="o">:</span><span class="n">arg1</span><span class="p">)</span><span class="w"> </span><span class="o">-&gt;</span><span class="w"> </span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">3</span><span class="p">)</span>
<span class="p">(</span><span class="n">name</span><span class="p">,</span><span class="w"> </span><span class="o">:</span><span class="n">op1</span><span class="p">,</span><span class="w"> </span><span class="o">:</span><span class="n">op2</span><span class="p">)</span><span class="w"> </span><span class="o">-&gt;</span><span class="w"> </span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">2</span><span class="p">)</span>
<span class="p">(</span><span class="kr">and</span><span class="p">,</span><span class="w"> </span><span class="o">:</span><span class="n">op1</span><span class="p">,</span><span class="w"> </span><span class="o">:</span><span class="n">op2</span><span class="p">)</span><span class="w"> </span><span class="o">-&gt;</span><span class="w"> </span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">3</span><span class="p">)</span>
<span class="p">(</span><span class="n">area</span><span class="o">-</span><span class="n">quantity</span><span class="p">,</span><span class="w"> </span><span class="o">:</span><span class="n">quant</span><span class="p">,</span><span class="w"> </span><span class="o">:</span><span class="n">unit</span><span class="p">)</span><span class="w"> </span><span class="o">-&gt;</span><span class="w"> </span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">2</span><span class="p">)</span>
<span class="p">(</span><span class="n">win</span><span class="o">-</span><span class="mo">01</span><span class="p">,</span><span class="w"> </span><span class="o">:</span><span class="n">arg0</span><span class="p">,</span><span class="w"> </span><span class="o">:</span><span class="n">arg1</span><span class="p">,</span><span class="w"> </span><span class="o">:</span><span class="n">time</span><span class="p">)</span><span class="w"> </span><span class="o">-&gt;</span><span class="w"> </span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">3</span><span class="p">,</span><span class="w"> </span><span class="mi">4</span><span class="p">)</span>
</code></pre></div>

<p>Our overall objective is to minimize the number of crossings in the alignment links after linearization. We use our token-aligned AMR/English data to produce training examples for the function (1). We assign each outgoing AMR edge a position equal to the median of the alignment points of all tokens in its subtree, including the edge itself. We assign -1 to an edge if none of its subtree tokens are aligned. Then we extract all sets of sibling edges in the AMR graph, and sort them based on these numbers. We use these sorted sets to create training instances.</p>
<p>We now describe three linearization methods.</p>
<h3>3.1 Pre-order DFS</h3>
<p>This baseline method linearizes AMR by simple preorder traversal, ignoring the data just described.</p>
<h3>3.2 Majority Method</h3>
<p>The majority method memorizes the most common order for each role set in the data. If no match is found, we use the ordering given in the original, human-annotated AMR, with the :instance-of edge first.</p>
<h3>3.3 Classifier Method</h3>
<p>The classifier method breaks the problem into learning three binary classifiers over inputs of the form $\left(c, r_{1}, r_{2}, \ldots, r_{k-1}\right):$</p>
<ol>
<li>
<p>Should the :instance-of edge be dropped?</p>
</li>
<li>
<p>Features: $k, c,\left(c, r_{i}\right)$, whether $c$ is a Propbank frameset, and whether $c$ is a "special keyword" as defined by Banarescu et al. (2013).</p>
</li>
<li>
<p>Should edge $r_{i}$ appear before :instance-of?</p>
</li>
<li>
<p>Features: $r_{i},\left(c, r_{i}\right),\left(r_{i}, r_{j}\right)$ for all $j \neq i$</p>
</li>
<li>
<p>Should edge $r_{i}$ appear before $r_{j}$ ?</p>
</li>
<li>
<p>Features: $\left(c, r_{i}, r_{j}\right)$</p>
</li>
</ol>
<p>We use the toolkit of Zhang (2004) to learn a maximum entropy classifier for each task.</p>
<table>
<thead>
<tr>
<th style="text-align: left;"></th>
<th style="text-align: right;">AMR/English pairs</th>
<th style="text-align: right;">English word tokens</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Train</td>
<td style="text-align: right;">10,313</td>
<td style="text-align: right;">218,021</td>
</tr>
<tr>
<td style="text-align: left;">Dev</td>
<td style="text-align: right;">1,368</td>
<td style="text-align: right;">29,848</td>
</tr>
<tr>
<td style="text-align: left;">Test</td>
<td style="text-align: right;">1,371</td>
<td style="text-align: right;">30,263</td>
</tr>
</tbody>
</table>
<p>Table 1: Data for AMR-to-English generation.</p>
<p>After training, for a given input query, we consult the first classifier on whether or not to drop the :instance-of edge.</p>
<p>If we drop this edge, we consider the rest of the edges as one group; otherwise, we divide them into two groups each appearing on one side of the :instance-of edge, using the second classifier.</p>
<p>Next, we order the edges within each group. Let $\mathrm{P}\left(r_{i}&lt;r_{j}\right)$ be the probability-according to the third classifier-that $r_{i}$ precedes $r_{j}$. For each edge $r_{i}$, we assign it a "left-leaning" score, which is the product of all $\mathrm{P}\left(r_{i}&lt;r_{j}\right)$, for all $j \neq i$. We remove the edge with the highest left-leaning score. We then recursively process the remaining edges in the group.</p>
<p>We were inspired by Lerner and Petrov (2013) to break the problem down this way. Because their dependencies are ordered, while our AMRs edges are not, we defined a different set of features and classifiers.</p>
<h2>4 Experiments</h2>
<p>We use AMR/English data from the AMR 1.0 corpus, ${ }^{1}$ along with the provided train/development/test split (Table 1).</p>
<p>We implement the method of Pourdamghani et al. (2014) to construct alignments for the training set. We train the linearization function introduced in Section 3 on the aligned training set and use it to re-linearize that training set, maintaining the alignment links. This gives us aligned string-to-string training data for PBMT. We use the same trained linearization function to linearize development and test AMRs.</p>
<p>To measure the quality of linearization, we make calculations on the development set, using alignments to references (these alignments are used only for this experiment, and not for decoding).</p>
<p>A good linearization function should: (a) reduce the number of crossings in the alignment links, and (b) correctly identify concepts to be dropped.</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<table>
<thead>
<tr>
<th style="text-align: left;"></th>
<th style="text-align: center;">Crossings</th>
<th style="text-align: center;">Adj. crossings</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Pre-order DFS</td>
<td style="text-align: center;">46671</td>
<td style="text-align: center;">7409</td>
</tr>
<tr>
<td style="text-align: left;">Majority Method</td>
<td style="text-align: center;">$33772(72 \%)$</td>
<td style="text-align: center;">$4850(65 \%)$</td>
</tr>
<tr>
<td style="text-align: left;">Classifier Method</td>
<td style="text-align: center;">$35603(76 \%)$</td>
<td style="text-align: center;">$4015(54 \%)$</td>
</tr>
</tbody>
</table>
<p>Table 2: Total alignment crossings, and crossings between adjacent links after linearizing development AMRs with different methods. Numbers in parentheses show the reduction compared to Pre-order DFS.</p>
<table>
<thead>
<tr>
<th style="text-align: left;"></th>
<th style="text-align: center;">Dev Bleu</th>
<th style="text-align: center;">Test Bleu</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">1: Pre-order DFS</td>
<td style="text-align: center;">17.7</td>
<td style="text-align: center;">16.6</td>
</tr>
<tr>
<td style="text-align: left;">1a: $1+$ clean AMRs</td>
<td style="text-align: center;">21.6</td>
<td style="text-align: center;">21.0</td>
</tr>
<tr>
<td style="text-align: left;">1b: 1a + name/number/date</td>
<td style="text-align: center;">23.5</td>
<td style="text-align: center;">22.5</td>
</tr>
<tr>
<td style="text-align: left;">2: Majority Method</td>
<td style="text-align: center;">26.5</td>
<td style="text-align: center;">25.6</td>
</tr>
<tr>
<td style="text-align: left;">3: Classifier Method</td>
<td style="text-align: center;">27.2</td>
<td style="text-align: center;">26.9</td>
</tr>
<tr>
<td style="text-align: left;">Flanigan et al. (2016)</td>
<td style="text-align: center;">22.7</td>
<td style="text-align: center;">22.0</td>
</tr>
</tbody>
</table>
<p>Table 3: Results for AMR-to-English generation on development and test data. Experiments 2 and 3 include cleaning AMRs and name/number/date translations. Bleu scores are singlereference, case insensitive, ${1 . .4}$-grams.</p>
<p>Table 2 shows the total number of crossings and number of crossings between adjacent alignment links after linearizing development AMRs with the three methods introduced in Section 3. Both advanced methods highly reduce the number of crossings. The Classifier Method reduces the number of adjacent crossings much more than the Majority Method, helping to enhance locality. End-to-end experiments (Table 3) show that the Classifier Method outperforms the Majority Method in improving Bleu score.</p>
<p>With respect to concept dropping, $97 \%$ of the concepts dropped by the Classifier Method are in fact not aligned, and the method correctly drops $87 \%$ of the unaligned concepts.</p>
<p>Next, we use the Moses (Koehn et al., 2007) system for our PBMT implementation. Phrase extraction, limited to maximum phrase length 9 , yields 1.2 m phrase pairs. We use a 5 -gram language model trained on 1.7 b tokens of Gigaword English. We use MERT for tuning, and we decode linearized AMRs into English with a maximum stack size of 1000.</p>
<p>Table 3 shows our results. We find that better linearization methods lead to better Bleu scores. The Majority Method outperforms Pre-order DFS by 3.1 Bleu on test data, and the Classifier Method adds another 1.2 Bleu. We also find that steps of cleaning
and specialized name/number/date generators significantly improve Bleu. Compared to (Flanigan et al., 2016) our best system achives 4.5 Bleu points improvement on dev and 4.9 points improvement on test data.</p>
<p>Here is a small-sized input/output example from the automatic AMR-to-English generation system:</p>
<h2>Input AMR:</h2>
<div class="codehilite"><pre><span></span><code>(s / state-01
    :arg0 (p / person
        :name (n / name :opl &quot;fan&quot;))
    :arg1 (c / concern-01
        :arg1 (c3 / commission)
        :arg2 (t / term
            :mod (i / invest-01
                :arg2 (c2 / country
                    :name (n3/name :op1 &quot;taiwan&quot;))
            :time (f / future)))
    :manner (p2 / primary)))
</code></pre></div>

<p>Linearized, Cleaned AMR: fan state commission :manner primary concern invest taiwan :time future term
System Output: fans who have stated that the commission is primarily concerned with the terms of the investment in taiwan in the future .
Gold English: fan stated the commission is primarily concerned with the term of future investment in taiwan .</p>
<h2>5 Conclusion</h2>
<p>We introduce a method for learning to generate English from AMR. We use phrase-based machine translation technology and carry out experiments to compare different AMR linearization methods. We show that our method outperforms prior work by a large margin. We consider our results to form a strong baseline for future work.</p>
<h2>References</h2>
<p>Laura Banarescu, Claire Bonial, Shu Cai, Madalina Georgescu, Kira Griffitt, Ulf Hermjakob, Kevin Knight, Philipp Koehn, Martha Palmer, and Nathan Schneider. 2013. Abstract Meaning Representation for sembanking. In Proc. ACL Linguistic Annotation Workshop (LAW).
Peter F. Brown, John Cocke, Stephen A. Della Pietra, Vincent J. Della Pietra, Fredrick Jelinek, John D. Laf-</p>
<p>ferty, Robert L. Mercer, and Paul S. Roossin. 1990. A statistical approach to machine translation. Computational linguistics, 16(2):79-85.
Simon Corston-Oliver, Michael Gamon, Eric Ringger, and Robert Moore. 2002. An overview of Amalgam: A machine-learned generation module. In Proc. INLG.
Jeffrey Flanigan, Chris Dyer, Noah A. Smith, and Jaime Carbonell. 2016. Generation from abstract meaning representation using tree transducers. In Proc. NAACL.
Yuqing Guo, Haifeng Wang, and Josef Van Genabith. 2011. Dependency-based n-gram models for general purpose sentence realisation. Natural Language Engineering, 17(4):455-483.
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris Callison-Burch, Marcello Federico, Nicola Bertoldi, Brooke Cowan, Wade Shen, Christine Moran, Richard Zens, et al. 2007. Moses: Open source toolkit for statistical machine translation. In Proc. ACL Poster and Demonstration Sessions.
Irene Langkilde and Kevin Knight. 1998. Generation that exploits corpus-based statistical knowledge. In Proc. ACL.
Uri Lerner and Slav Petrov. 2013. Source-side classifier preordering for machine translation. In Proc. EMNLP.
Franois Mairesse, Milica Gai, Filip Jurek, Simon Keizer, Blaise Thomson, Kai Yu, and Steve Young. 2010. Phrase-based statistical language generation using graphical models and active learning. In Proc. ACL.
Nima Pourdamghani, Yang Gao, Ulf Hermjakob, and Kevin Knight. 2014. Aligning English strings with Abstract Meaning Representation graphs. In Proc. EMNLP.
Le Zhang. 2004. Maximum entropy modeling toolkit for Python and C++. http://bit.ly/1DGnb2p.</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>${ }^{1}$ LDC Catalog number 2014T12.&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>