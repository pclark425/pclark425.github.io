<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-1318 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-1318</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-1318</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-29.html">extraction-schema-29</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of simulators used for training models or agents on scientific reasoning tasks (especially in thermodynamics, circuits, or biology), including details about simulator fidelity levels and transfer performance to real-world or different contexts.</div>
                <p><strong>Paper ID:</strong> paper-211075982</p>
                <p><strong>Paper Title:</strong> <a href="https://arxiv.org/pdf/2002.04495v1.pdf" target="_blank">On transfer learning of neural networks using bi-fidelity data for uncertainty propagation</a></p>
                <p><strong>Paper Abstract:</strong> Due to their high degree of expressiveness, neural networks have recently been used as surrogate models for mapping inputs of an engineering system to outputs of interest. Once trained, neural networks are computationally inexpensive to evaluate and remove the need for repeated evaluations of computationally expensive models in uncertainty quantification applications. However, given the highly parameterized construction of neural networks, especially deep neural networks, accurate training often requires large amounts of simulation data that may not be available in the case of computationally expensive systems. In this paper, to alleviate this issue for uncertainty propagation, we explore the application of transfer learning techniques using training data generated from both high- and low-fidelity models. We explore two strategies for coupling these two datasets during the training procedure, namely, the standard transfer learning and the bi-fidelity weighted learning. In the former approach, a neural network model mapping the inputs to the outputs of interest is trained based on the low-fidelity data. The high-fidelity data is then used to adapt the parameters of the upper layer(s) of the low-fidelity network, or train a simpler neural network to map the output of the low-fidelity network to that of the high-fidelity model. In the latter approach, the entire low-fidelity network parameters are updated using data generated via a Gaussian process model trained with a small high-fidelity dataset. The parameter updates are performed via a variant of stochastic gradient descent with learning rates given by the Gaussian process model. Using three numerical examples, we illustrate the utility of these bi-fidelity transfer learning methods where we focus on accuracy improvement achieved by transfer learning over standard training approaches.</p>
                <p><strong>Cost:</strong> 0.018</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e1318.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e1318.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of simulators used for training models or agents on scientific reasoning tasks (especially in thermodynamics, circuits, or biology), including details about simulator fidelity levels and transfer performance to real-world or different contexts.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>CompositeBeam (FEniCS / Euler-Bernoulli)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Composite beam high-fidelity finite-element model (FEniCS) and low-fidelity Euler-Bernoulli beam model</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>High-fidelity finite-element simulation of a cantilever composite beam (implemented in FEniCS) is used as the HF data source; a closed-form Euler-Bernoulli analytic model (ignoring circular holes and using homogenized cross-section) is used as the cheap LF model. These two fidelities are used to train and adapt neural-network surrogates for predicting maximum tip deflection under uncertain material and load parameters.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>ON TRANSFER LEARNING OF NEURAL NETWORKS USING BI-FIDELITY DATA FOR UNCERTAINTY PROPAGATION</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>simulator_name</strong></td>
                            <td>FEniCS finite-element high-fidelity model; Euler-Bernoulli analytic low-fidelity model</td>
                        </tr>
                        <tr>
                            <td><strong>simulator_description</strong></td>
                            <td>High-fidelity: 2D/3D finite-element structural simulation implemented in FEniCS with a refined mesh resolving geometric holes and stress distribution. Low-fidelity: closed-form Euler-Bernoulli beam solution for a homogenized cross-section that ignores circular holes and higher-order effects.</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>mechanics / structural mechanics</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_level</strong></td>
                            <td>High-fidelity: finite-element solver resolving geometry and detailed stress/deflection (mesh shown in paper). Low-fidelity: analytic Euler-Bernoulli model that only accounts for bending of a homogenized cross-section (much lower fidelity).</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_characteristics</strong></td>
                            <td>High-fidelity includes geometric detail (circular holes), spatial discretization via FEM and the resulting detailed stress/deflection field. Low-fidelity ignores holes and heterogeneity; uncertainty enters only as a multiplicative factor in the closed-form solution; no geometric detail or local effects are modeled.</td>
                        </tr>
                        <tr>
                            <td><strong>model_or_agent_name</strong></td>
                            <td>Feed-forward neural network (FNN) and Residual network (ResNet) student surrogates</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Supervised neural-network surrogates: FNNs (two hidden layers tested, ELU activation) and ResNet variants; training via Adam SGD. Transfer-learning variants: BFTL-1 (fine-tune top layers), BFTL-2 (shallow mapper from LF output to HF), BFWL (GP teacher generating synthetic HF-corrected labels to re-train student).</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task</strong></td>
                            <td>Predict the scalar QoI: maximum vertical deflection at the free end of the cantilever beam under uncertain load and material moduli.</td>
                        </tr>
                        <tr>
                            <td><strong>training_performance</strong></td>
                            <td>Standard (HF-only) training with N_h=30: FNN mean validation RMSE ≈ 6.01×10^-3; ResNet (HF-only) ≈ 2.17×10^-3. Bi-fidelity settings used N_l=250 LF and N_h=20 HF for transfer experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_target</strong></td>
                            <td>Transfer/adapt LF-trained neural network to predict high-fidelity QoI (HF finite-element outputs); validation on independent HF dataset.</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_performance</strong></td>
                            <td>Bi-fidelity best method (BFWL) reduced error by >order-of-magnitude: FNN + BFWL mean validation RMSE ≈ 4.55×10^-4; ResNet + BFWL ≈ 5.66×10^-4 (with N_l=250, N_h=20). BFTL-1 and BFTL-2 gave intermediate improvements (e.g., FNN BFTL-1 ≈ 4.04×10^-3, BFTL-2 ≈ 3.42×10^-3).</td>
                        </tr>
                        <tr>
                            <td><strong>compares_fidelity_levels</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_comparison_results</strong></td>
                            <td>Comparisons across LF-only, HF-only, and mixed (bi-fidelity) training show: LF-only poor; HF-only decent; transfer learning (especially BFWL which leverages GP uncertainty) provided the largest reduction in validation RMSE. ResNet architecture improved HF-only performance, but BFWL still yielded the best results when combining LF and small HF datasets. Co-kriging was compared and the FNN surrogate outperformed co-kriging in this example.</td>
                        </tr>
                        <tr>
                            <td><strong>minimal_fidelity_discussion</strong></td>
                            <td>No explicit quantitative 'minimum fidelity' threshold is given. Authors note the LF model can be much cheaper but must be sufficiently related to HF to avoid negative transfer; they discuss negative transfer when datasets are considerably dissimilar but do not specify minimal required features.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_cases</strong></td>
                            <td>The paper warns of negative transfer when LF and HF are very dissimilar. For this example, partial-adaptation transfer (BFTL variants) provided improvements but were sometimes no better than ResNet HF-only training; adding more HF data eventually reduces the relative advantage of transfer methods.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'On transfer learning of neural networks using bi-fidelity data for uncertainty propagation', 'publication_date_yy_mm': '2020-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1318.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e1318.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of simulators used for training models or agents on scientific reasoning tasks (especially in thermodynamics, circuits, or biology), including details about simulator fidelity levels and transfer performance to real-world or different contexts.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LiIonBattery (finite-difference coarse/fine)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Lithium-ion battery porous-electrode finite-difference high-fidelity model (314 nodes) and coarse finite-difference low-fidelity model (50 nodes)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A multi-physics porous-electrode LIB model (based on Hadigol et al.) is solved with fine and coarse finite-difference meshes: the high-fidelity model uses 314 nodes (fine spatial resolution) while the low-fidelity uses a coarse 50-node mesh (≈7× faster). These are used as HF/LF sources for training neural-network surrogates to predict the spatial mean liquid-phase concentration at a specified time under 17 uncertain parameters.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>ON TRANSFER LEARNING OF NEURAL NETWORKS USING BI-FIDELITY DATA FOR UNCERTAINTY PROPAGATION</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>simulator_name</strong></td>
                            <td>Custom finite-difference LIB simulator (Hadigol et al. model) — fine (314 nodes) HF and coarse (50 nodes) LF</td>
                        </tr>
                        <tr>
                            <td><strong>simulator_description</strong></td>
                            <td>High-fidelity: finite-difference solution of porous-electrode (Newman) battery model with 314 spatial nodes capturing detailed diffusion/reaction dynamics. Low-fidelity: coarsened spatial discretization (50 nodes) approximating same equations with lower resolution and reduced computational cost (~7× faster).</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>electrochemistry / battery modeling</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_level</strong></td>
                            <td>High-fidelity: detailed finite-difference discretization capturing spatial gradients and multi-physics coupling. Low-fidelity: coarse spatial discretization that under-resolves spatial features and dynamics, trading accuracy for speed.</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_characteristics</strong></td>
                            <td>HF includes fine spatial resolution of liquid-phase concentration, reaction-diffusion coupling, and porous-electrode physics. LF reduces node count (50 nodes), so spatial gradients and local effects are smoothed; computational speed-up ≈ 7× but with reduced accuracy.</td>
                        </tr>
                        <tr>
                            <td><strong>model_or_agent_name</strong></td>
                            <td>Feed-forward neural network (FNN) and ResNet student surrogates</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Two-hidden-layer FNNs (and ResNet variants) trained by Adam; transfer methods BFTL-1, BFTL-2, and BFWL (GP teacher with rational-quadratic kernel) tested. Inputs are 17 uncertain physical parameters; output is scalar QoI (spatial mean concentration at t=2000 s).</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task</strong></td>
                            <td>Predict the spatial mean liquid-phase concentration at a given time (t = 2000 s) across uncertain battery parameters (17-dimensional input).</td>
                        </tr>
                        <tr>
                            <td><strong>training_performance</strong></td>
                            <td>Standard HF-only training with N_h=40: FNN mean validation RMSE ≈ 9.38×10^-2 (Table 7). Transfer experiments used N_l=140 LF and N_h=20 HF.</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_target</strong></td>
                            <td>Transfer LF-trained student network to predict HF QoI (fine discretization outputs) using a small HF dataset to adapt the network.</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_performance</strong></td>
                            <td>In transfer experiments (N_l=140, N_h=20), BFWL achieved mean validation RMSE ≈ 6.56×10^-3 (Table 7) for FNN (substantial reduction compared to HF-only standard). Other transfer variants (BFTL-1, BFTL-2) also reduced errors (e.g., BFTL-1 ≈ 7.75×10^-3, BFTL-2 ≈ 8.10×10^-3 in Table 7).</td>
                        </tr>
                        <tr>
                            <td><strong>compares_fidelity_levels</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_comparison_results</strong></td>
                            <td>All three transfer-learning approaches reduced mean validation error relative to HF-only standard training. BFWL (GP-based fidelity-weighting) produced the smallest mean RMSE in the reported initialization experiment. ResNet did not substantially change the benefit gained from transfer learning in this example.</td>
                        </tr>
                        <tr>
                            <td><strong>minimal_fidelity_discussion</strong></td>
                            <td>No explicit minimum fidelity claim; authors note the coarse model runs 7× faster and can produce useful LF data for transfer, but do not quantify minimum required LF accuracy. They again caution that too-large dissimilarity can cause negative transfer.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_cases</strong></td>
                            <td>No explicit catastrophic failure reported; however, performance gains vary and in some dataset-selection experiments BFWL did not uniformly outperform other methods (sensitivity to data splits and initialization observed).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'On transfer learning of neural networks using bi-fidelity data for uncertainty propagation', 'publication_date_yy_mm': '2020-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1318.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e1318.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of simulators used for training models or agents on scientific reasoning tasks (especially in thermodynamics, circuits, or biology), including details about simulator fidelity levels and transfer performance to real-world or different contexts.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>AirfoilFlow (PHASTA Coarse/Fine RANS)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Airfoil flow simulations using PHASTA RANS solver with Spalart–Allmaras turbulence closure — fine RANS (≈241k elements) and coarse RANS (≈9k elements)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>RANS simulations (PHASTA) for flow around a parameterized NACA airfoil are run at two mesh fidelities: a fine RANS mesh that resolves boundary layers and shear layers (≈241k elements) and a coarse RANS mesh that under-resolves boundary layers and shear and is computationally ≈498× cheaper; these HF/LF outputs are used to train NN surrogates predicting pressure coefficient distribution on the airfoil surface.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>ON TRANSFER LEARNING OF NEURAL NETWORKS USING BI-FIDELITY DATA FOR UNCERTAINTY PROPAGATION</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>simulator_name</strong></td>
                            <td>PHASTA RANS solver (Spalart–Allmaras closure) — fine-grid RANS (241k elems) and coarse-grid RANS (9k elems); Euler mesh also referenced</td>
                        </tr>
                        <tr>
                            <td><strong>simulator_description</strong></td>
                            <td>Fine RANS: refined mesh conforming to boundary-layer/grid-independence checks (y+min < 1), resolves shear layer downstream of trailing edge, surface spacing refined near leading/trailing edges. Coarse RANS: coarser mesh with first y+ ≫ 1 (does not resolve boundary layer), coarser surface spacing, does not resolve shear layers, but is far cheaper computationally. PHASTA is the RANS solver used.</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>fluid dynamics / computational aerodynamics</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_level</strong></td>
                            <td>High-fidelity: grid-independent RANS with resolved boundary layers and shear, physically accurate Cp predictions. Low-fidelity: coarse RANS under-resolves boundary layer and shear, lacks wall modeling and cannot produce physically accurate solution but is ~498× cheaper.</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_characteristics</strong></td>
                            <td>Fine RANS resolves wall effects and shear; coarse RANS: first grid point at 0.01 m (large y+), no wall model, does not resolve shear layer downstream of trailing edge, coarse surface spacing (0.1c except curvature-refined regions).</td>
                        </tr>
                        <tr>
                            <td><strong>model_or_agent_name</strong></td>
                            <td>Feed-forward neural network (FNN) and ResNet surrogates</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>FNN with four hidden layers (50 neurons each, ELU) and ResNet variants; models trained to predict Cp at 153 surface grid points; transfer methods BFTL-1, BFTL-2, BFWL (GP teacher using Matern kernel) applied with N_l=200 LF and N_h=100 HF in experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task</strong></td>
                            <td>Predict surface pressure coefficient (Cp) distribution at 153 surface points for parameterized airfoil geometry and angle-of-attack under uncertainty.</td>
                        </tr>
                        <tr>
                            <td><strong>training_performance</strong></td>
                            <td>HF-only standard training with N_h=100: FNN mean validation RMSE ≈ 3.0076×10^-1; ResNet ≈ 2.9170×10^-1 (Table 11).</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_target</strong></td>
                            <td>Transfer LF-trained surrogates to HF Cp prediction (validation against HF data).</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_performance</strong></td>
                            <td>Bi-fidelity methods: BFWL yielded mean validation RMSE ≈ 3.2402×10^-2 (about an order-of-magnitude improvement over HF-only FNN). BFTL-2 gave moderate improvement (≈1.4896×10^-1). Coarse LF alone is physically inaccurate but useful when combined via BFWL.</td>
                        </tr>
                        <tr>
                            <td><strong>compares_fidelity_levels</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_comparison_results</strong></td>
                            <td>Coarse RANS LF is physically inaccurate by itself (cannot resolve wall/shear), leading to poor HF predictions if used naively. However, BFWL (GP-based teacher weighting) substantially improved HF prediction accuracy (order-of-magnitude RMSE reduction). BFTL variants gave limited improvement; ResNet architecture did not substantially help in the bi-fidelity context for this problem.</td>
                        </tr>
                        <tr>
                            <td><strong>minimal_fidelity_discussion</strong></td>
                            <td>Authors explicitly note the coarse LF mesh 'does not enable a physically accurate solution' (missing wall effects and shear-layer resolution). There is no strict minimal fidelity quantified, but the results indicate that even LF models that miss key physical features can still be useful when combined with small HF datasets via fidelity-weighted transfer (BFWL).</td>
                        </tr>
                        <tr>
                            <td><strong>failure_cases</strong></td>
                            <td>The coarse RANS LF failed to produce physically accurate solutions alone; some transfer methods (BFTL variants) did not yield substantial improvements, and standard HF-only training produced large errors; the authors emphasize potential for negative transfer when LF and HF are too dissimilar.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'On transfer learning of neural networks using bi-fidelity data for uncertainty propagation', 'publication_date_yy_mm': '2020-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Predicting the output from a complex computer code when fast approximations are available <em>(Rating: 2)</em></li>
                <li>Survey of multifidelity methods in uncertainty propagation, inference, and optimization <em>(Rating: 2)</em></li>
                <li>On uncertainty quantification of lithium-ion batteries: Application to an LiC6/LiCoO2 cell <em>(Rating: 2)</em></li>
                <li>Grid convergence for turbulent flows <em>(Rating: 2)</em></li>
                <li>Bi-fidelity approximation for uncertainty quantification and sensitivity analysis of irradiated particle-laden turbulence <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-1318",
    "paper_id": "paper-211075982",
    "extraction_schema_id": "extraction-schema-29",
    "extracted_data": [
        {
            "name_short": "CompositeBeam (FEniCS / Euler-Bernoulli)",
            "name_full": "Composite beam high-fidelity finite-element model (FEniCS) and low-fidelity Euler-Bernoulli beam model",
            "brief_description": "High-fidelity finite-element simulation of a cantilever composite beam (implemented in FEniCS) is used as the HF data source; a closed-form Euler-Bernoulli analytic model (ignoring circular holes and using homogenized cross-section) is used as the cheap LF model. These two fidelities are used to train and adapt neural-network surrogates for predicting maximum tip deflection under uncertain material and load parameters.",
            "citation_title": "ON TRANSFER LEARNING OF NEURAL NETWORKS USING BI-FIDELITY DATA FOR UNCERTAINTY PROPAGATION",
            "mention_or_use": "use",
            "simulator_name": "FEniCS finite-element high-fidelity model; Euler-Bernoulli analytic low-fidelity model",
            "simulator_description": "High-fidelity: 2D/3D finite-element structural simulation implemented in FEniCS with a refined mesh resolving geometric holes and stress distribution. Low-fidelity: closed-form Euler-Bernoulli beam solution for a homogenized cross-section that ignores circular holes and higher-order effects.",
            "scientific_domain": "mechanics / structural mechanics",
            "fidelity_level": "High-fidelity: finite-element solver resolving geometry and detailed stress/deflection (mesh shown in paper). Low-fidelity: analytic Euler-Bernoulli model that only accounts for bending of a homogenized cross-section (much lower fidelity).",
            "fidelity_characteristics": "High-fidelity includes geometric detail (circular holes), spatial discretization via FEM and the resulting detailed stress/deflection field. Low-fidelity ignores holes and heterogeneity; uncertainty enters only as a multiplicative factor in the closed-form solution; no geometric detail or local effects are modeled.",
            "model_or_agent_name": "Feed-forward neural network (FNN) and Residual network (ResNet) student surrogates",
            "model_description": "Supervised neural-network surrogates: FNNs (two hidden layers tested, ELU activation) and ResNet variants; training via Adam SGD. Transfer-learning variants: BFTL-1 (fine-tune top layers), BFTL-2 (shallow mapper from LF output to HF), BFWL (GP teacher generating synthetic HF-corrected labels to re-train student).",
            "reasoning_task": "Predict the scalar QoI: maximum vertical deflection at the free end of the cantilever beam under uncertain load and material moduli.",
            "training_performance": "Standard (HF-only) training with N_h=30: FNN mean validation RMSE ≈ 6.01×10^-3; ResNet (HF-only) ≈ 2.17×10^-3. Bi-fidelity settings used N_l=250 LF and N_h=20 HF for transfer experiments.",
            "transfer_target": "Transfer/adapt LF-trained neural network to predict high-fidelity QoI (HF finite-element outputs); validation on independent HF dataset.",
            "transfer_performance": "Bi-fidelity best method (BFWL) reduced error by &gt;order-of-magnitude: FNN + BFWL mean validation RMSE ≈ 4.55×10^-4; ResNet + BFWL ≈ 5.66×10^-4 (with N_l=250, N_h=20). BFTL-1 and BFTL-2 gave intermediate improvements (e.g., FNN BFTL-1 ≈ 4.04×10^-3, BFTL-2 ≈ 3.42×10^-3).",
            "compares_fidelity_levels": true,
            "fidelity_comparison_results": "Comparisons across LF-only, HF-only, and mixed (bi-fidelity) training show: LF-only poor; HF-only decent; transfer learning (especially BFWL which leverages GP uncertainty) provided the largest reduction in validation RMSE. ResNet architecture improved HF-only performance, but BFWL still yielded the best results when combining LF and small HF datasets. Co-kriging was compared and the FNN surrogate outperformed co-kriging in this example.",
            "minimal_fidelity_discussion": "No explicit quantitative 'minimum fidelity' threshold is given. Authors note the LF model can be much cheaper but must be sufficiently related to HF to avoid negative transfer; they discuss negative transfer when datasets are considerably dissimilar but do not specify minimal required features.",
            "failure_cases": "The paper warns of negative transfer when LF and HF are very dissimilar. For this example, partial-adaptation transfer (BFTL variants) provided improvements but were sometimes no better than ResNet HF-only training; adding more HF data eventually reduces the relative advantage of transfer methods.",
            "uuid": "e1318.0",
            "source_info": {
                "paper_title": "On transfer learning of neural networks using bi-fidelity data for uncertainty propagation",
                "publication_date_yy_mm": "2020-02"
            }
        },
        {
            "name_short": "LiIonBattery (finite-difference coarse/fine)",
            "name_full": "Lithium-ion battery porous-electrode finite-difference high-fidelity model (314 nodes) and coarse finite-difference low-fidelity model (50 nodes)",
            "brief_description": "A multi-physics porous-electrode LIB model (based on Hadigol et al.) is solved with fine and coarse finite-difference meshes: the high-fidelity model uses 314 nodes (fine spatial resolution) while the low-fidelity uses a coarse 50-node mesh (≈7× faster). These are used as HF/LF sources for training neural-network surrogates to predict the spatial mean liquid-phase concentration at a specified time under 17 uncertain parameters.",
            "citation_title": "ON TRANSFER LEARNING OF NEURAL NETWORKS USING BI-FIDELITY DATA FOR UNCERTAINTY PROPAGATION",
            "mention_or_use": "use",
            "simulator_name": "Custom finite-difference LIB simulator (Hadigol et al. model) — fine (314 nodes) HF and coarse (50 nodes) LF",
            "simulator_description": "High-fidelity: finite-difference solution of porous-electrode (Newman) battery model with 314 spatial nodes capturing detailed diffusion/reaction dynamics. Low-fidelity: coarsened spatial discretization (50 nodes) approximating same equations with lower resolution and reduced computational cost (~7× faster).",
            "scientific_domain": "electrochemistry / battery modeling",
            "fidelity_level": "High-fidelity: detailed finite-difference discretization capturing spatial gradients and multi-physics coupling. Low-fidelity: coarse spatial discretization that under-resolves spatial features and dynamics, trading accuracy for speed.",
            "fidelity_characteristics": "HF includes fine spatial resolution of liquid-phase concentration, reaction-diffusion coupling, and porous-electrode physics. LF reduces node count (50 nodes), so spatial gradients and local effects are smoothed; computational speed-up ≈ 7× but with reduced accuracy.",
            "model_or_agent_name": "Feed-forward neural network (FNN) and ResNet student surrogates",
            "model_description": "Two-hidden-layer FNNs (and ResNet variants) trained by Adam; transfer methods BFTL-1, BFTL-2, and BFWL (GP teacher with rational-quadratic kernel) tested. Inputs are 17 uncertain physical parameters; output is scalar QoI (spatial mean concentration at t=2000 s).",
            "reasoning_task": "Predict the spatial mean liquid-phase concentration at a given time (t = 2000 s) across uncertain battery parameters (17-dimensional input).",
            "training_performance": "Standard HF-only training with N_h=40: FNN mean validation RMSE ≈ 9.38×10^-2 (Table 7). Transfer experiments used N_l=140 LF and N_h=20 HF.",
            "transfer_target": "Transfer LF-trained student network to predict HF QoI (fine discretization outputs) using a small HF dataset to adapt the network.",
            "transfer_performance": "In transfer experiments (N_l=140, N_h=20), BFWL achieved mean validation RMSE ≈ 6.56×10^-3 (Table 7) for FNN (substantial reduction compared to HF-only standard). Other transfer variants (BFTL-1, BFTL-2) also reduced errors (e.g., BFTL-1 ≈ 7.75×10^-3, BFTL-2 ≈ 8.10×10^-3 in Table 7).",
            "compares_fidelity_levels": true,
            "fidelity_comparison_results": "All three transfer-learning approaches reduced mean validation error relative to HF-only standard training. BFWL (GP-based fidelity-weighting) produced the smallest mean RMSE in the reported initialization experiment. ResNet did not substantially change the benefit gained from transfer learning in this example.",
            "minimal_fidelity_discussion": "No explicit minimum fidelity claim; authors note the coarse model runs 7× faster and can produce useful LF data for transfer, but do not quantify minimum required LF accuracy. They again caution that too-large dissimilarity can cause negative transfer.",
            "failure_cases": "No explicit catastrophic failure reported; however, performance gains vary and in some dataset-selection experiments BFWL did not uniformly outperform other methods (sensitivity to data splits and initialization observed).",
            "uuid": "e1318.1",
            "source_info": {
                "paper_title": "On transfer learning of neural networks using bi-fidelity data for uncertainty propagation",
                "publication_date_yy_mm": "2020-02"
            }
        },
        {
            "name_short": "AirfoilFlow (PHASTA Coarse/Fine RANS)",
            "name_full": "Airfoil flow simulations using PHASTA RANS solver with Spalart–Allmaras turbulence closure — fine RANS (≈241k elements) and coarse RANS (≈9k elements)",
            "brief_description": "RANS simulations (PHASTA) for flow around a parameterized NACA airfoil are run at two mesh fidelities: a fine RANS mesh that resolves boundary layers and shear layers (≈241k elements) and a coarse RANS mesh that under-resolves boundary layers and shear and is computationally ≈498× cheaper; these HF/LF outputs are used to train NN surrogates predicting pressure coefficient distribution on the airfoil surface.",
            "citation_title": "ON TRANSFER LEARNING OF NEURAL NETWORKS USING BI-FIDELITY DATA FOR UNCERTAINTY PROPAGATION",
            "mention_or_use": "use",
            "simulator_name": "PHASTA RANS solver (Spalart–Allmaras closure) — fine-grid RANS (241k elems) and coarse-grid RANS (9k elems); Euler mesh also referenced",
            "simulator_description": "Fine RANS: refined mesh conforming to boundary-layer/grid-independence checks (y+min &lt; 1), resolves shear layer downstream of trailing edge, surface spacing refined near leading/trailing edges. Coarse RANS: coarser mesh with first y+ ≫ 1 (does not resolve boundary layer), coarser surface spacing, does not resolve shear layers, but is far cheaper computationally. PHASTA is the RANS solver used.",
            "scientific_domain": "fluid dynamics / computational aerodynamics",
            "fidelity_level": "High-fidelity: grid-independent RANS with resolved boundary layers and shear, physically accurate Cp predictions. Low-fidelity: coarse RANS under-resolves boundary layer and shear, lacks wall modeling and cannot produce physically accurate solution but is ~498× cheaper.",
            "fidelity_characteristics": "Fine RANS resolves wall effects and shear; coarse RANS: first grid point at 0.01 m (large y+), no wall model, does not resolve shear layer downstream of trailing edge, coarse surface spacing (0.1c except curvature-refined regions).",
            "model_or_agent_name": "Feed-forward neural network (FNN) and ResNet surrogates",
            "model_description": "FNN with four hidden layers (50 neurons each, ELU) and ResNet variants; models trained to predict Cp at 153 surface grid points; transfer methods BFTL-1, BFTL-2, BFWL (GP teacher using Matern kernel) applied with N_l=200 LF and N_h=100 HF in experiments.",
            "reasoning_task": "Predict surface pressure coefficient (Cp) distribution at 153 surface points for parameterized airfoil geometry and angle-of-attack under uncertainty.",
            "training_performance": "HF-only standard training with N_h=100: FNN mean validation RMSE ≈ 3.0076×10^-1; ResNet ≈ 2.9170×10^-1 (Table 11).",
            "transfer_target": "Transfer LF-trained surrogates to HF Cp prediction (validation against HF data).",
            "transfer_performance": "Bi-fidelity methods: BFWL yielded mean validation RMSE ≈ 3.2402×10^-2 (about an order-of-magnitude improvement over HF-only FNN). BFTL-2 gave moderate improvement (≈1.4896×10^-1). Coarse LF alone is physically inaccurate but useful when combined via BFWL.",
            "compares_fidelity_levels": true,
            "fidelity_comparison_results": "Coarse RANS LF is physically inaccurate by itself (cannot resolve wall/shear), leading to poor HF predictions if used naively. However, BFWL (GP-based teacher weighting) substantially improved HF prediction accuracy (order-of-magnitude RMSE reduction). BFTL variants gave limited improvement; ResNet architecture did not substantially help in the bi-fidelity context for this problem.",
            "minimal_fidelity_discussion": "Authors explicitly note the coarse LF mesh 'does not enable a physically accurate solution' (missing wall effects and shear-layer resolution). There is no strict minimal fidelity quantified, but the results indicate that even LF models that miss key physical features can still be useful when combined with small HF datasets via fidelity-weighted transfer (BFWL).",
            "failure_cases": "The coarse RANS LF failed to produce physically accurate solutions alone; some transfer methods (BFTL variants) did not yield substantial improvements, and standard HF-only training produced large errors; the authors emphasize potential for negative transfer when LF and HF are too dissimilar.",
            "uuid": "e1318.2",
            "source_info": {
                "paper_title": "On transfer learning of neural networks using bi-fidelity data for uncertainty propagation",
                "publication_date_yy_mm": "2020-02"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Predicting the output from a complex computer code when fast approximations are available",
            "rating": 2,
            "sanitized_title": "predicting_the_output_from_a_complex_computer_code_when_fast_approximations_are_available"
        },
        {
            "paper_title": "Survey of multifidelity methods in uncertainty propagation, inference, and optimization",
            "rating": 2,
            "sanitized_title": "survey_of_multifidelity_methods_in_uncertainty_propagation_inference_and_optimization"
        },
        {
            "paper_title": "On uncertainty quantification of lithium-ion batteries: Application to an LiC6/LiCoO2 cell",
            "rating": 2,
            "sanitized_title": "on_uncertainty_quantification_of_lithiumion_batteries_application_to_an_lic6licoo2_cell"
        },
        {
            "paper_title": "Grid convergence for turbulent flows",
            "rating": 2,
            "sanitized_title": "grid_convergence_for_turbulent_flows"
        },
        {
            "paper_title": "Bi-fidelity approximation for uncertainty quantification and sensitivity analysis of irradiated particle-laden turbulence",
            "rating": 1,
            "sanitized_title": "bifidelity_approximation_for_uncertainty_quantification_and_sensitivity_analysis_of_irradiated_particleladen_turbulence"
        }
    ],
    "cost": 0.0176305,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>ON TRANSFER LEARNING OF NEURAL NETWORKS USING BI-FIDELITY DATA FOR UNCERTAINTY PROPAGATION
2019</p>
<p>Subhayan De 
University of Colorado
80309BoulderCO</p>
<p>Jolene Britton 
University of California
92521RiversideCA</p>
<p>Matthew Reynolds 
National Renewable Energy Laboratory
80401GoldenCO</p>
<p>University of Colorado
80309, EBoulderCO</p>
<p>Ryan Skinner 
University of Colorado
80309BoulderCO</p>
<p>Kenneth Jansen 
University of Colorado
80309BoulderCO</p>
<p>Alireza Doostan doostan@colorado.edu 
University of Colorado
80309BoulderCO</p>
<p>Alireza Doostan 
ON TRANSFER LEARNING OF NEURAL NETWORKS USING BI-FIDELITY DATA FOR UNCERTAINTY PROPAGATION</p>
<p>International Journal for Uncertainty Quantification
x(x2019Original Manuscript Submitted: mm/dd/yyyy; Final Draft Received: mm/dd/yyyy*Address all correspondence to:Neural networkTransfer learningGaussian process regressionUncertainty propagationScientific machine learning
Due to their high degree of expressiveness, neural networks have recently been used as surrogate models for mapping inputs of an engineering system to outputs of interest. Once trained, neural networks are computationally inexpensive to evaluate and remove the need for repeated evaluations of computationally expensive models in uncertainty quantification applications. However, given the highly parameterized construction of neural networks, especially deep neural networks, accurate training often requires large amounts of simulation data that may not be available in the case of computationally expensive systems. In this paper, to alleviate this issue for uncertainty propagation, we explore the application of transfer learning techniques using training data generated from both high-and low-fidelity models. We explore two strategies for coupling these two datasets during the training procedure, namely, the standard transfer learning and the bi-fidelity weighted learning. In the former approach, a neural network model mapping the inputs to the outputs of interest is trained based on the low-fidelity data. The high-fidelity data is then used to adapt the parameters of the upper layer(s) of the low-fidelity network, or train a simpler neural network to map the output of the low-fidelity network to that of the high-fidelity model. In the latter approach, the entire low-fidelity network parameters are updated using data generated via a Gaussian process model trained with a small high-fidelity dataset. The parameter updates are performed via a variant of stochastic gradient descent with learning rates given by the Gaussian process model. Using three numerical examples, we illustrate the utility of these bi-fidelity transfer learning methods where we focus on accuracy improvement achieved by transfer learning over standard training approaches.</p>
<p>INTRODUCTION</p>
<p>Neural networks build on imitating the biological neurons and are useful for learning nonlinear and complex functions [1,2]. With the recent advances in computing resources and software, it is now possible to train large neural networks that accurately describe the response of physical systems. Building surrogate models for mechanics problems using neural networks offers several distinct benefits. In particular, the past few years have seen a proliferation of open source software tools for building and training neural networks. Examples of widely used software packages include Tensorflow [3], Theano [4], Caffe [5], and PyTorch [6]. These tools supply users with efficient software abstractions for building and training neural networks, resulting in accelerated workflows that produce expressive surrogate models in a small amount of time. Furthermore, these software packages enjoy large user community support outside of applications in science and engineering. Another benefit of building surrogate models using neural networks is the ability to leverage specialized hardware architectures that enable faster training of models. For example, the software packages listed above all contain some consideration toward training neural networks using GPUs. More importantly, large investments in high performance computing resources specifically tailored for artificial intelligence (AI) applications are becoming more commonplace. For example, at the time of publication of this article, the first two exascale computers planned for delivery to the Department of Energy will include some degree of optimization for AI applications [7,8]. Also, the current top two spots on the Top500 list [9] are occupied by high-performance computing systems built by IBM that include NVIDIA Volta GV100 GPUs. Finally, neural networks have the potential to have a high level of expressiveness. The composite function model has been shown to have a universal approximation property given the use of differentiable activation functions and a single layer with a large number of neurons [10][11][12][13].</p>
<p>Despite the above said benefits of using neural networks as surrogate models, there are some limitations. One such limitation is the lack of clarity involving the application of physical constraints or symmetries of the models. This limitation is well-known and is currently an area of focus in the Scientific Machine Learning (SciML) community [14]. However, the most limiting drawback of using neural networks as surrogate models is perhaps the substantial-at times prohibitive for scientific applications-data requirements for training neural networks. Datasets for scientific and engineering applications are often limited in size due to the costs associated with the physical experiments or the computational complexity of high-fidelity simulations. A potential cure for this lack of data volume is the integration of data from models or experiments of different fidelities into the neural network training process.</p>
<p>Multiple models in computational mechanics are often available to describe a physical phenomenon (e.g., turbulence) [15,16]. Among them, some models, known as the high-fidelity models, require more computational resources but provide higher levels of accuracy. These models can be used to generate accurate data for training neural networks. However, it may be computationally expensive or even infeasible to do so, even when running in parallel. On the other hand, models with generally low levels of accuracy often (not always) require small computational budget and can be used to generate a large dataset. These models are denoted as low-fidelity models. As an example, a coarse finite element discretization of a differential equations may give rise to a low-fidelity model as compared to a fine discretization of the same problem that achieves a desired accuracy. Other instances of low-fidelity models include reduced order models [17][18][19] or regression models [20][21][22].</p>
<p>In a multi-fidelity approach, the availability of these different fidelities of models are exploited [15,16] to achieve a high level of accuracy in the response prediction. In this approach, the smaller computational cost of the low-fidelity models are utilized and a smaller number of high-fidelity model evaluations are used to correct the error introduced through using many low-fidelity model evaluations. Related to the topic of this study, multi-fidelity methods have also shown to lead to effective uncertainty quantification strategies. In [23], a Bayesian model with the sequential Monte Carlo algorithm is implemented to establish a relation between inaccurate low-fidelity models and high-fidelity models. Li and Xiu [24], Li et al. [25], and Peherstorfer et al. [26] used a combination of low-and high-fidelity models to evaluate probability of failure. Additive and multiplicative corrections of low-fidelity models via small number of high-fidelity samples have been developed for Gaussian process regression [27][28][29][30] (a.k.a. co-kriging) and polynomial chaos expansions [31][32][33]. A different class of methods rely on low-fidelity data to generate a low-rank approximation of high-fidelity quantities of interest, see, e.g., [34][35][36][37][38][39][40][41] In the domain of neural networks, transfer learning [42,43] attempts to use the knowledge gained from solving one problem to solve another related problem, where accurate or labeled data may be missing or limited. For example, when labeled data for two related but different classification or regression tasks are available, knowledge gained from training a neural network for one of the problems can be used to help training for the other one. This scenario is known as the inductive transfer learning [42]. Similarly, in another scenario, transfer learning can be implemented for two unrelated tasks. This application of transfer learning is known as transductive transfer learning. These different types of transfer learning have seen many applications in machine learning domain, including text classification [44], image classification [45], natural language processing [46], and face recognition [47]. Alongside, there are applications of transfer learning in tuning global climate models [48], disease prediction [49], genome biology [50] and so on. For a detailed list of applications we refer the interested reader to [43] and the references therein. Apart form these standard transfer learning scenarios, fidelity-weighted learning [51,52] is an example of machines-teaching-machines or learning using privileged information paradigms [53][54][55], and can be thought of a transfer learning scenario. In this case, a neural network, named as the student, is trained using easily available poorly labeled data. On the other hand, a Gaussian process is constructed using high-quality labeled data and known as the teacher. The teacher's knowledge is then used to fine-tune the student network. Dehghani et al. [52] showed that in presence of large enough high-quality dataset the teacher can be used to improve the performance of the student network.</p>
<p>Generally speaking, transfer learning is demonstrated to provide the following advantages over standard learning, [42,56]: (i) smaller initial training error, (ii) faster convergence of the optimization scheme used for training, and (iii) similar (or smaller) validation error using smaller datasets. In this work, we are particularly interested in the last advantage as in many scientific applications, training datasets are of limited size. However, we note that depending on the required accuracy and the availability of high-fidelity data, this advantage may diminish when a sufficient number of high fidelity samples are used in the training of the standard neural network. Therefore, the primary utility of transfer learning techniques is in scenarios where limited high-fidelity data is available (see Fig. 1). In addition, when the two dataset used in transfer learning are considerably dissimilar, transfer learning may lead to less accurate predictions, a phenomenon referred to as negative transfer [57][58][59] and depicted in Fig. 1 1: When the number of high-fidelity data is not adequate, the goal of transfer learning (TL) is to provide a means for robust and accurate neural network training, especially in small sample size regimes. As transfer learning relies on similar or approximate datasets (here of lower fidelity), the resulting network may lead to less accurate surrogates as compared to when the network is trained based only on large high-fidelity datasets. This so-called transfer learning disadvantage may not be necessarily eliminated by adding more high-fidelity samples.</p>
<p>In the present study, we examine the utility of transfer learning in building neural network surrogates using a combination of low-and high-fidelity data. As the low-fidelity models can be simulated relatively cheaply, this allows access to a large quantity of training data without significant computational expense. Since the majority of the training data may be of lesser quality, we must couple the two types of data in a manner that the bi-fidelity predictions are still as accurate as possible. To this end, we use two transfer learning techniques, namely, the inductive transfer learning and the fidelity-weighted learning to efficiently train a neural network for uncertainty propagation. We use three numerical examples to show the usefulness of this approach. In the first example, bending of a composite beam with multiple circular holes on its web is considered, where the material properties and external load are uncertain. The low-fidelity model uses the Euler-Bernoulli beam equation whereas the high-fidelity model uses a finite element model. The second example considers a non-linear, multi-scale, multi-physics, Lithium ion battery model with 17 uncertain parameters, where the low-and high-fidelity models are, respectively, based on a coarse and fine discretization of the spatial domain. The final example involves turbulent flow around an airfoil with parametric geometry and inflow angle-of-attack. The low-fidelity model solves the Reynolds averaged Navier-Stokes (RANS) equations using 9,000 elements in the finite element discretization whereas the high-fidelity model uses 241,000 elements. These three numerical examples show that the transfer learning approach can be efficiently used to train neural networks for uncertainty propagation in the presence of limited, high-fidelity training data. Before proceeding, we remark that the techniques proposed in this paper specifically address the inclusion of bi-fidelity datasets into the neural network training process for developing surrogate models. The purpose of this work is not to claim the superiority of neural networks as surrogate models over other representations, e.g., polynomial expansions or Gaussian processes. Comparing the performance of neural network surrogates with those based on well-established techniques in the literature is important, but beyond the scope of this work.</p>
<p>The rest of this paper is organized as follows. In Section 2, we briefly discuss the components of a neural network and its training procedure. Following that, different aspects of transfer learning and fidelity-weighted learning for neural networks are introduced and the considered algorithms for using training bi-fidelity data are presented. In Section 3, three numerical examples are used to illustrate the efficacy of the two transfer learning techniques. Finally, we conclude the paper and mention future research directions.</p>
<p>METHODOLOGY</p>
<p>In this section, after briefly introducing uncertainty propagation through a system and the working principles of neural networks, transfer learning methods using bi-fidelity training data are discussed.</p>
<p>Uncertainty Propagation</p>
<p>Models, often in the form of partial differential equations, are used ubiquitously in order to describe the behavior of a physical system. The system's response or the quantity of interest (QoI) y -here for simplicity assumed a scalar -is often affected by the presence of uncertainty in its inputs x ∈ R d describing, for instance, loading, boundary conditions, material properties, or the structure of the model itself. An instance of the utility of models is to relate the QoI y to its inputs x, i.e.,
y = M(x).(1)
The task of uncertainty propagation is to quantify the uncertainty in y given the description of uncertainty in x. In probabilistic methods, the inputs x are random variables with prescribed probability distributions. As such, the QoI y is also a random variable and the goal of uncertainty propagation is to compute the statistics of y, e.g., mean and variance, or probability distribution function. One approach to uncertainty propagation, known as surrogate modeling, is to find an approximation to the map M, denoted by M, from samples of x and y. Once M is constructed, the statistics of y or the sensitivity of y to the components of x are estimated by simulating M -instead of M -which does not require evaluation of M. When M is expensive to simulate, building an accurate surrogate M becomes computationally intensive, and an active area of research is to minimize the number of evaluations of M with little loss of accuracy for such a construction. In the present work, we rely on neural networks as a means to generate M and, as motivated in Section 1, bi-fidelity strategies to reduce the cost of building M. We next provide a brief introduction to neural networks and their training.</p>
<p>Neural Network Surrogates</p>
<p>An artificial neural network, or simply neural network, mimics the behavior of neuron cells that process biological information. The recent advances in computing power have enabled the training of large neural networks to learn relationships formalized by (1) assuming sufficient training data is available. The most commonly used neural network is known as the feed-forward neural network (FNN) or multilayer perceptron (MLP) [2]. An FNN consists of a sequence of connected layers, including an input layer, one or more hidden layers, and an output layer (see Fig. 2). Each of these hidden layers have multiple neurons which perform an affine transformation of output from the previous layer. Then an often nonlinear activation function is applied resulting in the neuron's output. Mathematically, a neural network features a composite map between the inputs x and the output y given by
y ≈ M x; {W i } H i=0 , {β i } H i=0 := W 0 φ H (. . . φ 2 (W 2 (φ 1 (W 1 x + β 1 ) + β 2 ) . . . ) + β 0 ,(2)
where H is the number of hidden layers;
{W i } H i=1 and {β i } H i=1
are, respectively, the unknown weight matrices and bias vectors for the ith hidden layer; W 0 and β 0 are -with a slight abuse of notation -the unknown weight vector and scalar bias for the output layer, respectively; and φ i (·) are (vector-valued) activation functions for the ith hidden layer. The goal of training the FNN model M, or neural networks in general, is to determine the weights and biases
{W i } H i=0 ,{β i } H i=0
, so that M is close to M in some sense.</p>
<p>x 1
x 2 .
. . In another popular neural network architecture, dubbed residual network (ResNet), the output of a layer is directly added to the output of a subsequent layer, e.g.,
y i = φ i (W i y i−1 + β i ) + y i−1 ,(3)
where here y i−1 and y i are the outputs of the (i − 1)th and ith layers, respectively. Stated differently, the ith layer models the residual between the (i − 1)th and ith hidden layers [60], hence the name ResNet. Note that if y i and y i−1 have different dimensions, a short-cut mapping as described in [60] is needed. An illustration of the ResNet is shown in Fig. 3.</p>
<p>Activation Functions</p>
<p>There are many choices available for the activation function φ i (·) in (2). A common choice is the rectified linear unit (ReLU), where the output is given by
φ ReLU (z) = max(0, z),(4)
for an input z. Figure 4 shows the plot of an ReLU function and its derivative. Note that the derivative of the output vanishes for z &lt; 0. This creates difficulty during the training using gradient descent (see Section 2.2.2) for negative inputs and is known as the dying ReLU problem. To avoid this, we also investigate the use of another activation function, namely, exponential linear unit or ELU. In this case, the output is given by etc. However, they are not discussed in this paper as we found the ELU function to produce the best results for the numerical examples of Section 3. 
φ ELU (z) = z for z &gt; 0, α(e z − 1) for z ≤ 0,(5)</p>
<p>Training a neural network</p>
<p>The goal of training a neural network is to estimate the vector of parameters p := {W i , β i } H i=0 of the network by minimizing a cost (or loss) function. Among different training procedures, e.g., supervised, unsupervised, or reinforcement learning [2], here we use the supervised learning with labeled training samples D := {(x i , y i )} N i=1 of the inputs of the QoI, where y i := M(x i ). In this paper, we choose the mean square error (MSE) as the cost function J, i.e.,
J := 1 N N i=1 J i := 1 N N i=1 y i − M(x i ; p) 2 .(6)
We remark that a regularization term can be added to the cost function.</p>
<p>To minimize J, a standard stochastic gradient descent (SGD) algorithm updates the parameters at kth optimization step as follows
p k+1 ← p k − η k ∂J i k ∂p k ,(7)
where η k is the learning rate at kth iteration, i k is selected uniformly at random from {1, . . . , N }, and the derivative ∂Ji k ∂p k is calculated using back propagation [2,61]. We, however, use an improved variant of SGD, namely, the Adaptive Moment Estimation (Adam) algorithm [62,63]. Adam leverages past gradient information to retard the descent along large gradients. This information is stored in the momentum vector m and squared gradient vector v as
m k = b m m k−1 + (1 − b m ) ∂J i k ∂p k ; m k = m k 1 − b k m ; v k = b v v k−1 + (1 − b v ) ∂J i k ∂p k 2 ; v k = v k 1 − b k v ,(8)
where ∂J i k ∂p k 2 is performed element-wise, and b m and b v are parameters with default values 0.9 and 0.999, respectively. In (8), m k and v k are the unbiased momentum and squared gradient vectors, respectively. The gradient descent step is applied next as follows
p k+1 = p k − η k m k √ v k + ,(9)
where the above update is performed element-wise and is a small number to avoid division by zero. We use this algorithm to train the neural networks of this study. An illustration of the steps of this algorithm is shown in Algorithm 1.</p>
<p>Remark. The universal approximation theorem [10][11][12] states that FFNs with at least one hidden layer and large enough number of neurons, and differentiable activation functions, can approximate any continuous function on a compact support. Recently, Hanin [64] has derived expressions for the minimum number of hidden layers and neurons per layer required to represent a function within a prescribed error when ReLU activation functions are used. Despite these theoretical guarantees, the training algorithms might not be able to find the optimal values of the network Network: M(·; p 0 );
Given: {η k } Nmax k=1 , b m , b v , and ; Initialize p 1 = p 0 ; Initialize m 0 = 0; Initialize v 0 = 0; for k = 1, 2, . . . , N max do Draw i k uniformly at random from {1, . . . , N tr }; Compute ∂Ji k ∂p k ; Set m k ← b m m k−1 + (1 − b m ) ∂Ji k ∂p k ; Set v k ← b v v k−1 + (1 − b v ) ∂Ji k ∂p k 2 (element-wise); Set m k ← m k /(1 − b k m ); Set v k ← v k /(1 − b k v ); Set p k+1 ← p k − η k m k √ v k + (element-wise); end Trained network: M(·; p Nmax );
parameters to achieve a desired accuracy. In practice, with small number of hidden layers, a large number of neurons per hidden layer might be needed. Additionally, often more than one layer with a small number of neurons per layer are used. In the numerical examples of this manuscript, we use a maximum of 50 neurons per layer. A new hidden layer is added to the network if the validation error is reduced with the added layer.</p>
<p>Transfer Learning with Bi-fidelity Data</p>
<p>Transfer learning for neural networks starts from a network that has already been trained with data from a similar classification or regression problem. This scenario, also known as the inductive transfer learning, is directly applicable to the training of neural networks for uncertainty propagation using bi-fidelity data. In more detail, we first train a network using the low-fidelity training dataset
D l = {(x l,i , y l,i )} N l i=1
to generate a surrogate model of the QoI given by the low-fidelity model. We subsequently adapt this network based on the (smaller) high-fidelity training dataset
D h = {(x h,i , y h,i )} N h i=1 .
Notice that we assume both low-and high-fidelity models have the same inputs x, and that x l,i and x h,i are samples of x used in the low-and high-fidelity simulations. The network adaptation may be performed in multiple ways. One approach is to fix both the architecture and parameters of the low-fidelity network and train (via high-fidelity data) a network with a smaller architecture (hence fewer parameters) that maps the output of the low-fidelity network to the high-fidelity QoI. This approach parallels the bi-fidelity Gaussian process regression (or co-kriging) technique of [27,28] and relies on the assumption that the map between the low-and high-fidelity QoI is simpler to learn than the one between the model inputs and the QoI. Another approach is to fix the architecture of the low-fidelity network and only update the network parameters p associated with the entire network or the last few hidden layers using the high-fidelity data, see, e.g., [42,51] and the references therein. As we shall explain below, both approaches are pursued in this work.</p>
<p>Bi-fidelity Transfer Learning with Partial Network Adaptation/Extension (BFTL)</p>
<p>Here, we consider two versions of transfer learning focusing on partial adaption or extension of the low-fidelity network. In the first approach, referred to as BFTL-1, we only update the parameters of the low-fidelity network associated with the upper layers using the high-fidelity data. This modification is done by running additional (Adam) optimization steps -in a manner similar to (9) -until convergence. In our second approach, denoted as BFTL-2, a shallow network is trained to map the output of the low-fidelity network to the high-fidelity QoI. Notice the second network is kept shallow as only a smaller high-fidelity dataset is available for training. Unlike in the first approach, here the architecture and parameters of the low-fidelity network are fixed. Figure 6 shows the two networks used for the second approach above, where y l and y h are the outputs of the low-fidelity network and the high-fidelity model, respectively. We note that neither BFTL-1 nor BFTL-2 does require
x 1 x 2 . . . x d−1 x d y l{x h,i } N h i=1 ⊆ {x l,i } N l i=1
, thus making the transfer learning applicable to scenarios where (independent) training data from each model is available.</p>
<p>Bi-Fidelity Weighted (Transfer) Learning (BFWL)</p>
<p>Following the work of [51,52], our third approach to bi-fidelity transfer learning focuses on adapting the entire low-fidelity network parameters using a synthetic dataset generated via the high-fidelity data and an adjustment of the optimization's learning rate depending on the fidelity of the synthetic data. The method is based on the concept of learning using privileged information proposed in [54,55], which relies on the idea that an intelligent teacher can help educating the students. Fidelity-weighted learning (FWL), an algorithm from this paradigm, was proposed in [51,52] to train neural networks for classification in the presence of training data with labels of different quality. In such instances, a neural network, known as the student network, is trained using the weakly or poorly labeled training data. A Gaussian process teacher is trained using the strongly labeled training data, which is then used to fine-tune the parameters of the student network by generating a synthetic dataset with the associated prediction confidence. See APPENDIX A for more details about training a Gaussian process. A key feature of this approach is that the prediction confidence of each synthetic data entry is used to weight (or adjust) the learning rate parameter of the optimization algorithm. Since we use bi-fidelity datasets D h and D l within the fidelity-weighted learning technique, we name the procedure as bi-fidelity weighted learning (BFWL). The steps of BFWL are as follows:</p>
<p>(1) Stage I training: A student neural network M s (x; p) is trained using the low-fidelity dataset D l . The network architecture can be chosen based on standard metrics, e.g., validation/test errors, using the relatively larger low-fidelity dataset.</p>
<p>(2) Teacher construction: The teacher, a Gaussian process y ∼ GP(µ, k) with mean function µ(x) := µ( y(x)) and covariance function κ(x, x ) := κ( y(x), y(x )) is trained using the high-fidelity dataset D h . Here, y denotes the 
D l = {(x l,i , y l,i )} N l i=1 (Adam) Stage I training (Adam) Stage II training D b := {(x b,i , µ(x b,i ))} N l +N h i=1 Teacher, GP D h = {x h,i , y h,i } N h i=1 µ(·), Σ(·)
Prediction error FIG. 7: Schematic of the fidelity weighted transfer learning, [51,52], using a bi-fidelity dataset (BFWL). The student network is trained using the low-fidelity dataset D l (Stage I) and is then updated using the soft bi-fidelity dataset D b (Stage II). A GP model is trained using the high-fidelity data D h and employed to generate D b . The posterior variance of the soft dataset is used to adjust the learning rate of the Stage II optimization solver to adapt the student network parameters using D b .</p>
<p>GP approximation to y.</p>
<p>(3) Soft bi-fidelity dataset generation:
Let {x b,i } N l +N h i=1 := {x l,i } N l i=1 {x h,i } N h i=1
be the concatenation of the lowand high-fidelity inputs. Using the GP teacher, the so-called soft bi-fidelity dataset
D b := {(x b,i , µ(x b,i ))} N l +N h i=1
is generated next. Associated with each µ(x b,i ), the GP also provides a posterior variance Σ(x b,i ) := κ(x b,i , x b,i ) which will be employed in training the bi-fidelity network as explained next.</p>
<p>(4) Stage II training: To fine-tune the student network M s (x; p) with help from the teacher, the parameters p are adapted using the Adam update (9) but with a weighted learning rate η k ,
p k+1 = p k − η k m k √ v k + ,(10)
where at the kth iteration, η k is given by
η k = η k exp[−βΣ(x b,i k )].(11)
Notice that η k accounts for the fidelity of each soft data entry via its estimated variance provided by the teacher. In (11), the data index i k is selected uniformly at random from {1, . . . , N l + N h } and is used to evaluate m k and v k in (10); see also (8). Additionally, in (11), β is a positive parameter that dictates our trust in the teacher and, similarly as in (9), η k is the learning rate at iteration k.</p>
<p>A number of remarks regarding the BFWL algorithm above are worthwhile mentioning. First, the utility of the GP model is due to its ability to provide an estimate of the variance of the teacher's prediction of the QoI corresponding to the low-fidelity inputs {x l,i }. This is in turn used to weight the learning rate in (11). Other types of models, e.g., Bayesian variable regression [65] with polynomial basis, may be used as long as the uncertainty associated with the teacher's predictions can be quantified. Secondly, the Stage II updates (10) are started from those of the learned student network in Stage I training, hence a warm start for the Stage II training. Third, for larger values of β in (11), the parameters of the student network are less affected by the stage II updates. A detailed investigation of the effect of β, however, is beyond the scope of the current paper. Last but not least, we remark that the stage II training resemblances closely the variance reduced gradient descent algorithms, e.g., SVRG [66] and BF-SVRG [67]. As an example, a control variate constructed from the low-fidelity dataset D l for the gradients can be constructed to produce a variance reduced gradient estimate. However, the application of this variance reduction approach to the examples of Section 3 did not show notable improvements in the validation error as compared to that of the standard training using only high-fidelity dataset. Therefore, the results from such an approach is included in Section 3. A schematic illustrating the steps of the BFWL algorithm is shown in Fig. 7, in which the third column shows that the performance of the student network M s improves after the network parameter adaption in Stage II.</p>
<p>NUMERICAL EXAMPLES</p>
<p>The numerical examples presented in this section are implemented using PyTorch [6] for modeling neural networks and Scikit-learn [68] for Gaussian processes. In this section, we apply the bi-fidelity methods of Section 2.3 for the training of neural networks for three scientific problems from different domains, namely, structural mechanics, electrochemistry and transport, and fluid mechanics. We compare the results to neural networks trained using only the high-fidelity dataset. For comparison, we use a separate high-fidelity dataset
D v := {(x v i , y v h,i )} N v i=1
for validation and define the validation error as the normalized root mean square error (RMSE)
RMSE = Nv i=1 y v h,i − M(x v i ) 2 Nv i=1 y v h,i 2 .(12)</p>
<p>Example I: Deflection of a Composite Beam</p>
<p>A cantilever beam with composite cross-section and hollow web is used for the first example as shown in Fig. 8. The dimensions of the beam are as follows: the length L = 50 m; the width w = 1 m; the radius of the circular holes r = 1.5 m; and the heights of different parts of the web h 1 = h 2 = 0.1 m, and h 3 = 5 m. The externally distributed load q and the elastic moduli E 1 , E 2 , and E 3 of the three materials constituting the beam cross-section are assumed to be independent random variables uniformly distributed, as specified in Table 1. Thus, the input x = (q, E 1 , E 2 , E 3 ). The QoI y is the maximum vertical displacement (at the free end of the beam). A finite element model for the beam is implemented using FEniCS [69] and used as the high-fidelity model. The mesh for this high-fidelity model is shown in Fig. 9. For the low-fidelity model, the deflection of the beam u l (x) is given by the Euler-Bernoulli beam theory while ignoring the circular holes,
EI d 4 u l (x) dx 4 = −q, subject to u l (0) = 0; du l (0) dx = 0; d 3 u l (L) dx 3 = 0; d 4 u l (L) dx 4 = 0,(13)
where E and I are the Young's modulus and the moment of inertia of an equivalent cross-section consisting of a single (homogenized) material. The solution of (13) can be written as
u l (x) = − qL 4 24EI x L 4 − 4 x L 3 + 6 x L 2 .(14)
Note that for the low-fidelity model, the effect of the uncertainty is only through a multiplicative factor in (14). However, this is not the case for the high-fidelity model.  For values near 0, the student is heavily influenced by the teacher's predictions and the finepredicts values near to the teacher's predictions. On the other hand, for large values of , the st is own predictions more heavily. If the noise level is low, then the ⌘ values corresponding to t still near to 1, so the FWL method reduces to the TL method, see Figure ??. However, if the high, the ⌘ values corresponding to the HF data are lower, so the FWL method reduces to t ned predictions, see Figure ??. see that the HF only model performs the best, which is expected when using so many tr . The bi-fidelity methods both perform more highly than the LF only model. Tests changing ratio of LF to HF data and their errors &gt;&gt; attery Example Problem Description sider a Lithium-Ion battery (LIB) for our third test case. A LIB is made up of an anode, ca r, electrolyte, and positive and negative current collectors, see Figure 12. The anode is a p e and the cathode is a negative electrode, they both store lithium. The separator "blocks th ons inside a battery" and the electrolyte is a conductor that moves positively charges lithium e anode to the cathode (and vice versa) through the separator. harge occurs when the electrolyte moves the ions from the anode to the cathode. The loss of ele node is known as oxidation and the gain of electrons in the cathode is known as reduction. nt creates a charge at the positive current collector, the current flows through a powered devic   turns to the negative current collector. When the battery is being charged, the movement of </p>
<p>Results</p>
<p>We use a neural network that consists of two hidden layers with 15 neurons each and ELU activation function with α = 1 based on a preliminary investigation, where we monitored the validation error as we increased the number of neurons per layer (see Fig. 10). Note that we similarly choose our networks for the other two examples in this paper. We train the FNN and ResNet networks with N h = 30 high-fidelity samples. For validation, we use N v = 50 samples and the error defined in (12) to assess the network performance. Next, we use different transfer learning techniques with N l = 250 and N h = 20, respectively, low-and high-fidelity samples randomly generated based on the distribution of the inputs. Note that the cost of generating the training data from the low-fidelity model is negligible compared to the high-fidelity model in this example. For the BFTL-2 approach, we add a third hidden layer consisting of 20 neurons to model the relation between y l and y h . For the BFWL method, we use an additive combination of radial basis kernel with length scale of 1 and white noise kernel with small noise level bounds (10 −3 , 10 −5 ) to train the Gaussian process teacher. The learning rates used with different methods are listed in Table 2. Tables 3 and 4 show the mean validation RMSEs obtained from different learning methods. To illustrate the variability of the trained network with respect to the choice of the initial parameters p, Fig. 11 shows the histograms of the validation RMSEs for 30 independent, random initializations of the network parameters but with fixed training and validation datasets. Note that if the training algorithms were able to reach the same (global) optimum, then the histograms in Fig. 11 would show single bars. However, this is not the case as the cost function here is non-linear and non-convex, and may feature multiple local minima.     validation RMSE reduces from 6.01 × 10 −3 to 2.17 × 10 −3 using the ResNet architecture (see Table 3). Similarly, as reported in Table 4, the mean validation RMSE with fixed initial parameters reduces from 5.41 × 10 −3 to 1.50 × 10 −3 . Second and third columns of Fig. 11 and 12 show that BFTL-1 and BFTL-2 improve the performance of the neural network compared to an FNN but they do not provide significant advantage over the ResNet architecture with standard training (first column second row of Figs 11 and 12). For example, according to Table 3, the mean validation RMSEs of BFTL-1 and BFTL-2 using FNN are 4.04 × 10 −3 and 3.43 × 10 −3 , respectively, and using ResNet are 3.39 × 10 −3 and 1.95 × 10 −3 , respectively. Similarly, in Table 4, the mean validation RMSEs of BFTL-1 and BFTL-2 using FNN are 2.66 × 10 −3 and 4.57 × 10 −3 , respectively, and using ResNet are 3.38 × 10 −3 and 4.29 × 10 −3 , respectively. This shows that the ResNet architecture alone improves the performance in this example by modeling the residual in the second hidden layer. However, when used in conjunction with transfer learning techniques, modeling of residuals for the low-fidelity data does not play any role in BFTL-1. Similarly, in BFTL-2, we model a relation between the low-and high-fidelity data using an extra shallow layer. As a result, more accurate modeling of the residual for the low-fidelity dataset does not remain relevant anymore. The fourth columns of Figs. 11 and 12 show that the BFWL method with both FNN and ResNet architectures performs best among all the transfer learning methods and is able to considerably reduce the error as compared to the standard training. In Fig. 11, the BFWL with FNN and ResNet gives mean validation RMSEs 4.55 × 10 −4 and 5.66 × 10 −4 , respectively (see Table 3). In Fig. 12, the mean validation RMSEs are 4.99 × 10 −4 and 7.38 × 10 −4 , respectively (see Table 4). Hence, in this example, the use of uncertainty information learned from a handful of the high-fidelity data using a Gaussian process teacher provides useful information to further improve the neural network's performance compared to other transfer learning techniques. ResNet architecture does not provide notable advantage within the BFWL approach. We also evaluate the BFTL-1 approach with three hidden layers (15 neurons each) in this example. During the training with D h , we only train the parameters of the third hidden layer. This is to some extent similar to the BFTL-2    Fig. 14 shows a typical scenario, where we use N l = 250 and increase N h gradually. As the number of high-fidelity data points is increased the validation RMSE is decreased gradually similar to Fig. 1. As in the BFWL approach we rely on a Gaussian process model, a natural question is how BFWL (or FNN) compared with co-kriging (a bi-fidelity Gaussian process model). Fig. 15 shows a comparison between FNN and co-kriging for 30 different training/validation datasets to show that in this example the FNN outperforms the co-kriging method. The description of the co-kriging approach used here is presented in APPENDIX B.
FNN Standard D h 10 −4 BFTL-1 D l 4 × 10 −4 D h 10 −4 BFTL-2 D l 10 −3 D h 10 −4 BFWL ( M s ) D l 10 −3 D h 2 × 10 −4 (β = −0.25) ResNet Standard D h 10 −1 BFTL-1 D l 4 × 10 −4 D h 10 −4 BFTL-2 D l 10 −3 D h 10 −4 BFWL ( M s ) D l 10 −3 D h 2 × 10 −4 (β = −0.25)</p>
<p>Example II: Lithium-ion Battery</p>
<p>We consider a Lithium-ion battery (LIB) model for our second example. An LIB is made up of an anode, a cathode, a separator, an electrolyte, and positive and negative current collectors; see Fig. 16. The separator acts as a barrier between the positive electrode (anode) and the negative electrode (cathode). During the discharge of the battery, lithium ions in the anode particles diffuse to the particle surface and oxidize into positively charged lithium ions Li + and   electrons. The Li + ions travel from the anode to the cathode via the electrolyte (liquid phase) using diffusion and migration, and reduce to lithium at the surface of the cathode particles before diffusing into them. During charging, the opposite happens. For the numerical example of this section, we employ the LIB model of Hadigol et al. [70], which relies on the porous electrode theory of Newman in [71]. The interested reader is referred to [70] for a detailed description of the governing equations, model parameters, and solution strategy. In this example, we use the spatial mean of the liquid phase concentration at time t = 2000 s as the QoI. A finite difference mesh with 314 nodes is used to generate the high-fidelity dataset and a coarse mesh with 50 nodes for the low-fidelity dataset. The coarse model runs 7 times faster than the fine one. We chose 17 parameters from [70] to use as the input uncertain parameters x. Table 5 shows the probability distributions of these parameters inferred from the LiC 6 /LiCoO 2 cell literature; see [70] for more details. For the interest of completeness, we also describe these parameters briefly in APPENDIX C.<br />
BFTL-1 D l 4 × 10 −4 D h 10 −4 BFTL-2 D l 4 × 10 −4 D h 8 × 10 −3 BFWL ( M s ) D l 4 × 10 −4 D h 10 −4 (β = 0.01) ResNet Standard D h 4 × 10 −1 BFTL-1 D l 4 × 10 −4 D h 10 −4 BFTL-2 D l 4 × 10 −4 D h 4 × 10 −3 BFWL ( M s ) D l 4 × 10 −4 D h 4 × 10 −3 (β = 0.01)</p>
<p>Results</p>
<p>We first use an FNN with two hidden layers and 50 neurons each using ELU activation functions with α = 1. We train this network with N h = 40 high-fidelity samples. For the ResNet architecture, we add the output of the first hidden layer to the input of second hidden layer and use the ReLU activation functions for the second hidden layer.</p>
<p>The transfer learning methodologies are implemented with the FNN and ResNet architectures using N l = 140 and N h = 20 low-and high-fidelity samples, respectively. The Gaussian process teacher in BFWL uses a rational quadratic kernel with length scale bounds (20, 21) (see APPENDIX A). The learning rates used with different methods are listed  in Table 6. Tables 7 and 8 show the mean validation RMSEs obtained from different methods for 30 independent random initializations of the network (with fixed training samples) and 30 random replications of the training/validation datasets (fixed network initialization), respectively. The samples used in the latter tests we selected randomly from  the same pool of samples. Figs. 17 and 18 show the corresponding histograms. As suggested by Tables 7 and 8, the three transfer learning techniques are able to reduce the mean validation error relative to the standard learning. These tables suggest also that using transfer learning the mean validation error does not change considerably when using ResNet instead of an FNN architecture. This shows that modeling the residual becomes less relevant as we use transfer learning. With standard learning, the ResNet architecture though provides smaller mean validation RMSEs compared to FNN, as illustrated in the first columns of Figs. 17 and 18.</p>
<p>Example III: Flow around a NACA Airfoil</p>
<p>In our last example, we consider flow around NACA 4412 airfoil at Re = 1.52 × 10 6 and low angle-of-attacks (AoA) as also studied in [41]. The airfoil has chord-length 1.0 m and is placed in a fluid domain of stream-wise length L = 999 m (x-direction), vertical height H = 998 m (y-direction), and span-wise width W = 2 m (z-direction). This domain is shown in Fig. 19 along with the boundary conditions specified following the work of Diskin et al. [72]. The fluid enters the domain along the red line and exits at the blue lines in Fig. 19. The boundaries at ±y and ±z directions are assumed to be inviscid and impenetrable. Further, no-slip boundary conditions on the airfoil surface are considered.</p>
<p>To study the effect of the geometry variations, the maximum camber m, location of the maximum camber p, maximum thickness as a fraction of the chord length t are assumed to be parameters. In addition the AoA α is also assumed to be a parameter. These parameters are modeled by uniform random variables and are specified in Table 9. Here, the QoI is the coefficient of pressure C p on the surface of the airfoil at a set of 153 grid points (every 5th surface grid point in the high-fidelity mesh shown in Fig. 20b).</p>
<p>We use the mesh shown in Fig. 20a with 9,000 elements for the low-fidelity model to solve the Reynolds averaged Navier-Stokes (RANS) equations using PHASTA [73]. We employ Spalart-Allmaras (SA) turbulence closure model [74,75] in these simulations. The high-fidelity model uses a RANS simulation with SA closure and a mesh shown in Fig. 20b. This mesh is refined quadratically from near the airfoil to the boundaries and consists of 241,000 elements. In the low-fidelity model, we do not resolve the shear layer downstream of the trailing edge in contrast to the high-fidelity model. The low-fidelity mesh is also unable to capture any wall effects and hence cannot produce a reasonably accurate solution. However, the computational cost of the low-fidelity model is 498 times smaller than that of the high-fidelity model. The interested readers is referred to [41] for more details of the airfoil model and its implementation. enters the domain from the 180 , radius 499 m, circular-arc face. A NACA 0012 airfoil of chord-length 1.0 m sits in the middle of the domain; its leading edge is coincident with the origin. The airfoil has no-slip boundary conditions applied for RANS, and slip-wall boundary conditions for Euler. Fluid exits the domain on the three outflow faces, one located at x = 500 m, and the others on top and bottom angled at 3 to the x-axis. The ±y and ±z walls are inviscid and impenetrable, as we seek a two-dimensional solution.</p>
<p>II.B. Mesh Generation</p>
<p>For all runs, we begin by meshing the fluid volume described above, surrounding a standard NACA 0012 airfoil at zero angle of attack. A unique mesh is constructed for each model we consider in the bi-fidelity context: grid-independent RANS (Fine RANS), coarse-grid RANS with under-resolved boundary layers (Coarse RANS), and Euler flow (Euler). Meshes are shown in Figure 3, and their main characteristics are described below. Discussion of typical run-times and resource consumption is left to Section II.C.</p>
<p>All meshes are created by extruding the surface mesh on the +z-face in the z-direction, through the domain, and then tetrahedronizing the resulting one-element-thick volume mesh. Because geometric variation is central to this study, all meshes capture airfoil curvature reasonably well within cost constraints.</p>
<p>The Fine RANS mesh is constructed using the results of Diskin et. al. 24 as a reference. The surface mesh size varies quadratically from 0.0496c at the middle of the airfoil to 0.0004c at the leading and trailing edges, where c is the chord length. The boundary layer has a stretching ratio of 1.25, and its first point o↵ the wall is 5e-6 m away. This yields y + min &lt; 1 in all turbulent regions of the flow. Accordingly, the mesh conforms to Spalart's 25 guidelines. Furthermore, reasonable grid-independence of the Fine RANS mesh has been confirmed through successive surface, wake, and near-field refinement to be within 0.15% of truth based on our quantity of interest, C p . This mesh contains ⇠241k elements, and enables accurate solution of the RANS equations for moderate cost.</p>
<p>The Coarse RANS mesh di↵ers from its fine counterpart in three ways. First, the Coarse RANS mesh makes no attempt to resolve the shear layer downstream of the trailing edge, whereas the fine mesh does. Second, instead of fully resolving the boundary layer, the coarse mesh has a first point o↵ the wall at 0.01 m (y + min ⇠ 4 ⇥ 10 4 ) with the same stretching ratio. The coarse mesh's first y + is already well past the defect layer of a turbulent BL, and therefore has no hope of accurately capturing wall e↵ects since it does not apply a wall model. Third, in contrast to the Fine RANS surface mesh spacing, the coarse mesh maintains a surface spacing of 0.1c except where curvature refinement brings it relatively quickly to 0.004c. This mesh does not enable a physically accurate solution, but it contains only ⇠9k elements and consumes few computational resources.</p>
<p>Finally, the Euler mesh is essentially the same as the Fine RANS mesh, but removes boundary layers The schematic of the computational domain and the initial NACA 0012 airfoil used in Example III (adapted from [41]). We deform the mesh to map into NACA 4412 airfoil. Here, u is the inflow velocity and ν T is the kinematic turbulence viscosity. , t = 0.1 s followed by t = 0.01 s. Runs continue until negligible solution change is iterations according to aerodynamic force data, visualization of flow fields, and observing nce scalar) absolute errors. Meeting this criterion typically requires between 30 and 120 ing on the mesh and physical model. NACA 0012 flow solution acts as the starting point in PHASTA for each new combination meters we want to test. This means the simulations' start-up transient can be skipped  </p>
<p>Results</p>
<p>Four hidden layers with 50 neurons each and ELU activation functions is used for an FNN that is trained using N h = 100 high-fidelity samples for each of the 153 grid points. For validation, we use N v = 100 samples not used in the training. The ResNet architecture is implemented with the output from the first hidden layer added to the input of the fourth hidden layer. For the bi-fidelity trainings, we use N l = 200 low-fidelity samples along with N h = 100 high-fidelity samples. In BFTL-2, we add another hidden layer of 50 neurons to model the relation between y l and y h . In the BFWL approach, we first train the network using N l = 200 low-fidelity samples and use N h = 100 high-fidelity samples to train the Gaussian process teacher with a Matern kernel (generalization of the RBF kernel) with length scale parameter ρ = 1.0 and ν = 2.5 (see APPENDIX A). Table 10 shows the learning rates used in different learning methods.  The histograms of the validation RMSEs for all 153 grid points using different learning methods are shown in Fig. 21. Table 11 shows the mean validation RMSEs obtained using different learning techiniques. From this table, the mean error using the FNN is 3.01 × 10 −1 when trained only using the high-fidelity data. This does not improve significantly using the ResNet architecture (mean validation RMSE only becomes 2.9170 × 10 −1 ). Similar mean validation RMSEs have been observed for other combinations of the residual skip connections which we do not reported here. Due to these relatively large errors, we do not implement different transfer learning algorithms with the ResNet architecture. Among different transfer learning methods, the BFTL-2 approach slightly improves the validation errors as shown in Fig. 21 and Table 11. On the other hand, the mean validation RMSE using the BFWL approach is 3.2402 × 10 −2 , which shows an order of magnitude improvement compared to all other learning methods. This again shows the usefulness of a Gaussian teacher and the weighted learning rate in fine-tuning the low-fidelity student network. 
BFTL-1 D l 10 −4 D h 10 −4 BFTL-2 D l 4 × 10 −4 D h 10 −3 BFWL ( M s ) D l 10 −4 D h 10 −4 (β = 0.25) ResNet Standard D h 4 × 10 −4</p>
<p>CONCLUSIONS</p>
<p>Recently, there has been an increased interest in using neural networks for modeling uncertainty propagation through complex engineering systems. With computational resources specifically built for training these networks, it has become more relevant to exploit the expressiveness of neural networks for UQ. However, for large-scale engineering and scientific applications the main obstacle in training such networks is generating large datasets either using high-fidelity models or costly experimental setups. With the goal of reducing the amount of required data for training, transfer learning employs an already trained network for similar applications and adapts it to the application at hand.</p>
<p>In this paper, we study the utility of transfer learning using bi-fidelity data, where we train the network using low-fidelity data and adapt it using a smaller high-fidelity dataset. In our first implementation (BFTL-1), the uppermost hidden layer of a network trained using the low-fidelity dataset is fine-tuned using the high-fidelity dataset. In a second approach (BFTL-2), we add a shallow network to model the map between the QoI estimated by the low-fidelity and its high-fidelity counterpart. In our third implementation (BFWL), we modify the parameters of the low-fidelity neural network with synthetic data (with the associated uncertainty) generated via a high-fidelity trained Gaussian process. We explore these transfer learning techniques using three numerical examples. The first numerical example from structural mechanics shows that transfer learning reduces the validation error, especially as compared to the standard feed-forward network. The largest reduction -more than an order of magnitude -is achieved by BFWL. A similar observation is made from the second example on a Lithium ion battery model involving non-linear, multi-scale, and multi-physics phenomena subject to high-dimensional uncertainty. In the third example involving an airfoil with parameterized geometry and inflow angle-of-attack, we again observe the efficacy of BFWL, while the first two approaches lead to accuracies similar to that of the standard training. From these examples, we observe BFWL performs the best among the considered transfer learning strategies and leads to considerable error improvements over standard training. Additionally, the reduction in the error achieved by the transfer learning techniques depends on the architecture of the network, here feed-forward and residual (ResNet) networks.</p>
<p>We expect transfer learning to be an important tool for understanding complex physics and the effects of uncertainty in the near future. Initial works, such as the techniques communicated in this paper, show promise producing accurate surrogate models capable of rapidly generating higher-fidelity samples. However, there is still a lot of work required for these tools to reach the level of maturity present in other widely-used multi-fidelity techniques discussed in Section 1.</p>
<p>ACKNOWLEDGMENT</p>
<p>This work was authored in part by the National Renewable Energy Laboratory, operated by Alliance for Sustainable Energy, LLC, for the U.S. Department of Energy (DOE) under Contract No. DE-AC36-08GO28308. This material is based upon work supported by NSF grants CMMI-1454601 and OAC-1740330, as well as the DARPA grant HR0011-17-2-0022. The views expressed in the article do not necessarily represent the views of the DOE or the U.S. Government. The U.S. Government retains and the publisher, by accepting the article for publication, acknowledges that the U.S. Government retains a nonexclusive, paid-up, irrevocable, worldwide license to publish or reproduce the published form of this work, or allow others to do so, for U.S. Government purposes.</p>
<p>APPENDIX A. GAUSSIAN PROCESS REGRESSION OR KRIGING</p>
<p>A zero-mean Gaussian process f (x) ∼ GP 0, κ(x, x ) with covariance function κ(x, x ) can be written in terms of the following Gaussian distribution [20] f
(x) f (x ) ∼ N 0, κ(x, x) κ(x, x ) κ(x , x) κ(x , x ) . (A.1)
In the presence of independent zero-mean Gaussian noise ε with variance σ 2 n and measured data y = (y 1 , . . . , y N ), where
y i = f (x i ) + ε i , (A.2)
the joint probability density for prediction at x become
y f (x ) ∼ N 0, K + σ 2 n I k f k T f κ f f . (A.3)
Here, I is the identity matrix, K is the N × N covariance matrix associated with the inputs X := {x i } N i=1 such that K(i, j) = κ(x i , x j ), and k f is the N × 1 covariance vector between all the inputs X and x , i.e., k f (i) = κ(x i , x ), and κ f f = κ(x , x ). Hence, the posterior density of f (x ) is given by
f (x ) y ∼ N f , σ 2 f , (A.4)
wheref = k T f K + σ 2 n I −1 y and σ 2 f = κ f f − k T f K + σ 2 n I −1 k f . Note that many choices are available for the covariance function, e.g., radial basis kernel κ(x, x ; α, σ) = α 2 exp − x−x 2 2σ 2 , rational quadratic kernel κ(x, x ; α, ρ, σ) = α 2 exp 1 + x−x 2 2ρσ 2 −ρ , Matern kernel κ(x, x ; α, ρ, ν) =
α 2 2 1−ν Γ(ν) √ 2ν x−x ρ ν B ν √ 2ν x−x ρ
, white noise kernel κ(x, x ; α) = α 2 δ x,x , etc., where α, ρ, σ, and ν are hyperparameters; Γ(·) is the Gamma function; B ν (·) is the modified Bessel function of the second kind; and δ ·,· is the Kronecker delta function. These hyperparameters of the covariance function and the noise variance σ 2 n (collectively referred to as θ) are inferred using the measurement data by maximizing the likelihood or minimizing the following negative log-likelihood − log p(y|θ) = 1 2 y T K + σ 2 n I −1 y + 1 2 log|K + σ 2 n I| + N 2 log(2π).</p>
<p>(A.5)</p>
<p>APPENDIX B. MULTI-FIDELITY GAUSSIAN PROCESS REGRESSION OR CO-KRIGING</p>
<p>Using the low-fidelity dataset D l = {x l,i , y l,i } N l i=1 and a (smaller) high-fidelity dataset D h = {x h,i , y h,i } N h i=1 , cokriging [27,28] build the following multiplicative-additive relation between the low-and high-fidelity models, f h (x) = ρf l (x) + f corr (x).</p>
<p>(B.1)</p>
<p>Here, f l (x) ∼ GP(0, κ l (x, x )) is the Gaussian process approximation of the low-fidelity data (here for simplicity assumed to be of zero mean). The additive correction term f corr (x) ∼ GP(0, κ corr (x, x )) is also a Gaussian process independent of f l (x), and ρ is a multiplicative scaling factor (but can also be a function of x). Following (B.1), f h (x) is also a zero-mean Gaussian process with covariance function ρ 2 κ l (x, x ) + κ corr (x, x ). Furthermore, we assume y h = (y h,1 , . . . , y h,N ) and y l = (y l,1 , . . . , y l,N ) are generated in a manner similar to (A.2) from their respective models and with independent, zero-mean additive Gaussian noises with variances σ 2 h and σ 2 l , respectively. Hence, the joint probability density for the prediction at x becomes
   y h y l f (x )    ∼ N   0,   K hh K hl k hf K lh K ll k lf k f h k f l κ f f     , (B.2)
where K hh (i, j) = ρ 2 κ l (x h,i , x h,j ) + κ corr (x h,i , x h,i ) + σ 2 h δ i,j , K hl (i, j) = ρκ l (x h,i , x l,j ), k hf (i) = ρ 2 κ l (x h,i , x ) + κ corr (x h,i , x ), K ll (i, j) = κ l (x l,i , x j,l ) + σ 2 l δ i,j , k lf (i) = ρκ l (x l,i , x ), and κ f f = ρ 2 κ l (x , x ) + κ corr (x , x ), K lh = K T lh , k f h = k T hf , and k f l = k T lf . The predictive density of f (x ) is given by
f (x ) y l , y h ∼ N f , σ 2 f , (B.3) wheref = k hf k lf T K hh K hl K lh K ll −1 y h y l and σ 2 f = κ f f − k hf k lf T K hh K hl K lh K ll −1 k hf k lf .
The hyperparameters θ of the covariance functions and the noise variances are inferred using the measurement data by maximizing the likelihood or minimizing the following negative log-likelihood − log p(y h , y l |θ) = 1 2 y h y l T K hh K hl K lh K ll −1 y h y l + 1 2 log K hh K hl K lh K ll + N l + N h 2 log(2π).</p>
<p>(B.4)</p>
<p>APPENDIX C. UNCERTAIN PARAMETERS IN EXAMPLE II</p>
<p>The 17 uncertain parameters used in Section 3.2 are described below in brief.</p>
<p>• Porosity, : Porosity is defined as the ratio of the voids to the total volume. In a Li-ion battery, we have a , c , and s -porosity in the anode, cathode, and separator, respectively. The power generated by the battery is directly proportional but the capacity of the battery is inversely proportional to the porosity.</p>
<p>• Bruggeman coefficient, b: The relation between the tortuosity and the porosity is given by the Bruggeman relation,
τ = (1−b) , (C.1)
where tortuosity τ is a geometric parameter of the electrodes that affects the effective transport properties and b is the Bruggeman coefficient. Here, we have three Bruggeman coefficients, b a , b c , and b s , for the anode, cathode, and separator, respectively.</p>
<p>• Solid diffusion coefficient, D s : These coefficients, D s,a and D s,c , determine the diffusivity of the ions from the cathode and anode, respectively.</p>
<p>• Solid conductivity, σ: The flow of the current through the anode and cathode is characterized by the conductivities σ a and σ c , respectively.</p>
<p>• Reaction rate, k: The rate of the chemical reaction in the anode and cathode are described by the reaction rates k a and k c , respectively.</p>
<p>• Component length, L: The length of the anode, cathode, and separator -L a , L c , and L s , respectively -are assumed to be uncertain in Example II in Section 3.2.</p>
<p>• Salt diffusion coefficient, D: The friction between the salt ions (formed during the polarization) and the solvent can adversely affect the battery power. Hence, a larger value of salt diffusion coefficient D is preferred.</p>
<p>• Li + transference number, t 0 + : This number denotes the amount of current carried through the Li + ions.</p>
<p>FIG. 2 :
2Feed-forward neural network (FNN) architecture with two hidden layers.</p>
<p>FIG. 3 :
3Residual neural network (ResNet) architecture with two hidden layers. The curved arrows illustrate skip connections for adding the output of a layer directly to that of another layer.</p>
<p>FIG. 4 :
4Rectified linear unit (ReLU) and its derivative.</p>
<p>FIG. 5 :
5Exponential linear unit (ELU) and its derivative.</p>
<p>FIG. 6 :
6Schematic of the network in the bi-fidelity transfer learning approach BFTL-2 introduced in Section 2.3.1. The output of the low-fidelity network is mapped to that of the high-fidelity model via a shallow network trained using only high-fidelity data.</p>
<p>Figure 6 Figure 7 :
67Schematic of cantilever beam and it's cross section. Courtesy of[6].</p>
<p>9 FIG. 8 :
98The composite beam used in Example I (adapted from[39]). The dimensions are as follows: L = 50 m, r = 1.5 m, h 1 = h 2 = 0.1 m, and h 3 = 5 m. The elastic moduli E 1 , E 2 , E 3 , and the external load q are assumed uncertain.</p>
<p>Figure 8 :
8Finite element mesh of the high fidelity model. Courtesy of [6]. 9: 15 HF samples and 200 LF samples. 10 rounds. 1 hidden layer with 5 neurons, 0.01 initial le moid activation function, 15 pretraining epochs, 35 finetuning epochs.</p>
<p>FIG. 9 :
9The composite beam is solved in FEniCS and used as the high-fidelity model with the mesh shown here.</p>
<p>FIG. 10 :
10Fig. 12displays the same quantity for a fixed choice of network initial parameters but with 30 random selection of the training (N l = 250 and N h = 20) and validation (N v = 50) datasets from the same pool of samples.FromFigs. 11 and 12, it can be noticed that ResNet provides smaller validation errors. In particular, the mean For a feed-forward neural network with two hidden layers the number of neurons (kept same for these two layers) is selected based on the smallest validation RMSE. The validation errors are displaced here for Example I.</p>
<p>FIG. 11 :
11Histograms of the validation error RMSE for Example I using different learning approaches to train the neural network for 30 random initialization of the network. The first column shows the validation RMSEs using standard learning techniques for two different architectures using N h = 20 high-fidelity samples. The rest of the columns show the validation RMSEs for different transfer learning strategies implemented herein using N h = 20 high-fidelity and N l = 250 low-fidelity samples.</p>
<p>FIG. 12 :
12Histograms of the log of validation RMSEs for Example I using different learning approaches to train the neural network for 30 different validation datasets. The first column shows the validation RMSEs using standard learning techniques for two different architectures using N h = 20 high-fidelity sample. The rest of the columns show the validation RMSEs for different transfer learning strategies implemented herein using N h = 20 high-fidelity and N l = 250 low-fidelity samples.</p>
<p>FIG. 13 :
13Comparison of histograms of validation RMSEs for BFTL-1 with two and three hidden layers (15 neurons in each) for Example I.</p>
<p>FIG. 14 :
14As more high-fidelity data are used the validation RMSE using different learning techniques reduces in Example I. scenario, where a third layer is added to model the relation between y l and y h . However, the BFTL-1 with three hidden layers does not show any drastic improvement in the validation RMSE; seeFig. 13.</p>
<p>FIG. 15 :
15Comparison of co-kriging (see APPENDIX B) and a feed-forward neural network for Example I.</p>
<p>Figure 12 :
12Schematic of a Lithium-Ion battery. Courtesy of[4].</p>
<p>Figure 13 :
1325 HF samples and 430 LF samples. 5 rounds. 1 hidden layer with 15 neurons, 0.0001 initial FIG. 16: The schematic of a Lithium-ion battery used in Example II (adapted from [70]).</p>
<p>FIG. 17 :
17Histograms of validation RMSEs for Example II using different learning approaches for 30 random initializations of the network. The first column shows the validation RMSEs using standard learning technique for two different architectures and N h = 40 high-fidelity samples. The rest of the columns show the validation RMSEs for different transfer learning strategies implemented herein using N h = 20 high-fidelity and N l = 140 low-fidelity samples.</p>
<p>FIG. 18 :
18Histograms of the log of validation RMSEs for Example II using different learning approaches for 30 different validation datasets. The first column shows the validation RMSEs using standard learning techniques for two different architectures and N h = 40 high-fidelity samples. The rest of the columns show the validation RMSEs for different transfer learning strategies implemented using N h = 20 high-fidelity and N l = 140 low-fidelity samples.</p>
<p>Figure 1 .
1symmetric about x-axis, not shown) Wing no-slip, zero ⌫T Schematic of computational domain with RANS boundary conditions.3 of 11 American Institute of Aeronautics and Astronautics Downloaded by UNIVERSITY OF COLORADO on June 11, 2019 | http://arc.aiaa.org | DOI: 10.2514/6.2017-3260 FIG. 19:</p>
<p>re 3 .
3Meshes used for RANS, Coarse RANS, and Euler, from left to right.</p>
<p>Figure 3 .
3Meshes High-fidelity mesh FIG. 20: Meshes used for (a) low-fidelity model and (b) high-fidelity model in Example III for the NACA 0012 airfoil. They are then deformed to map into the NACA 4412 airfoil. Figure is adapted from [41].</p>
<p>FIG. 21 :
21Histograms of the validation RMSEs in the estimation of Cp for Example III using different learning approaches for 153 grid points along the surface of the airfoil. The first two histograms show the errors using the standard learning techniques for two different architectures and N h = 100 high-fidelity samples. The rest of the histograms show validation RMSEs for different transfer learning strategies implemented using N h = 100 high-fidelity and N l = 200 low-fidelity samples.</p>
<p>.Equivalent number of high-fidelity samples </p>
<p>Prediction Error </p>
<p>Without TL 
With TL 
Negative TL </p>
<p>TL advantage 
TL advantage </p>
<p>TL disadvantage </p>
<p>Crossover </p>
<p>FIG. </p>
<p>S. De, J. Britton, M. Reynolds, R. Skinner, K. Jansen, &amp; A. Doostan Student, M s</p>
<p>TABLE 1 :
1The uncertain parameters in Example I and their corresponding probability distributions. Note that U[a, b] denotes a uniform distribution between a and b.Parameter 
Unit Distribution 
Distributed load, q kN/m 
U[9, 11] 
Elastic modulus E 1 MPa 
U[0.9, 1.1] 
Elastic modulus E 2 MPa 
U[0.9, 1.1] 
Elastic modulus E 3 
kPa 
U[9, 11] </p>
<p>TABLE 2 :
2The learning rates used with different learning methods in Example I.Architecture 
Method 
Dataset 
Learning rate, η k </p>
<p>TABLE 3 :
3The mean validation RMSEs obtained using different learning methods and 30 different initializations of the network in Example I.Architecture Method 
Mean validation 
RMSE </p>
<p>FNN </p>
<p>Standard 6.0055 × 10 −3 
BFTL-1 
4.0435 × 10 −3 
BFTL-2 
3.4245 × 10 −3 
BFWL 
4.5453 × 10 −4 </p>
<p>ResNet </p>
<p>Standard 2.1694 × 10 −3 
BFTL-1 
3.3929 × 10 −3 
BFTL-2 
1.9507 × 10 −3 
BFWL 
5.6579 × 10 −4 </p>
<p>TABLE 4 :
4The mean validation RMSEs obtained using different learning methods and 30 random replications of training/validation datasets in Example I.Architecture Method 
Mean validation 
RMSE </p>
<p>FNN </p>
<p>Standard 5.4115 × 10 −3 
BFTL-1 
2.6621 × 10 −3 
BFTL-2 
4.5706 × 10 −3 
BFWL 
4.9860 × 10 −4 </p>
<p>ResNet </p>
<p>Standard 1.5013 × 10 −3 
BFTL-1 
3.3807 × 10 −3 
BFTL-2 
4.2873 × 10 −3 
BFWL 
7.3800 × 10 −4 </p>
<p>TABLE 5 :
5The uncertain parameters used in Example II and their distributions from[70]. A brief description of these parameters is given in APPENDIX C. Note that U[a, b] denotes a uniform distribution between a and b.Component Parameter 
Unit 
Distribution </p>
<p>Anode </p>
<h2>Porosity, a</h2>
<p>U[0.46, 0.51] 
Bruggeman coeff., b a 
-
U[3.8, 4.2] 
Solid diffusion coeff., D s,a 
m 2 /s 
U[3.51, 4.29] × 10 −14 
Conductivity, σ a 
S/m 
U[90, 110] 
Reaction rate, k a 
m 4 ·mol·s U[4.52, 5.53] × 10 −11 
Length, L a 
µm 
U[77, 83] </p>
<p>Cathode </p>
<h2>Porosity, c</h2>
<p>U[0.36, 0.41] 
Bruggeman coeff., b c 
-
U[3.8, 4.2] 
Solid diffusion coeff., D s,c 
m 2 /s 
U[0.90, 1.10] × 10 −14 
Conductivity, σ c 
S/m 
U[90, 110] 
Reaction rate, k c 
m 4 ·mol·s U[2.10, 2.56] × 10 −11 
Length, L c 
µm 
U[85, 91] </p>
<p>Separator </p>
<h2>Porosity, s</h2>
<p>U[0.63, 0.81] 
Bruggeman coeff., b a 
-
U[3.2, 4.8] 
Length, L a 
µm 
U[22, 28] 
Li + transference number, t 0 </p>
<ul>
<li></li>
</ul>
<p>-
U[0.345, 0.381] 
Salt diffusion coefficient, D 
m 2 /s 
U[6.75, 8.25] × 10 −10 </p>
<p>TABLE 6 :
6The learning rates used with different learning methods in Example II.Architecture 
Method 
Dataset 
Learning rate, η k </p>
<p>FNN </p>
<p>Standard 
D h 
10 −4 </p>
<p>TABLE 7 :
7The mean validation RMSEs obtained using different learning methods and 30 different initializations of the network in Example II.Architecture Method 
Mean validation 
RMSE </p>
<p>FNN </p>
<p>Standard 9.3767 × 10 −2 
BFTL-1 
7.7482 × 10 −3 
BFTL-2 
8.1033 × 10 −3 
BFWL 
6.5568 × 10 −3 </p>
<p>ResNet </p>
<p>Standard 1.1171 × 10 −2 
BFTL-1 
6.9649 × 10 −3 
BFTL-2 
6.5039 × 10 −3 
BFWL 
7.0899 × 10 −3 </p>
<p>TABLE 8 :
8The mean validation RMSEs obtained using different learning methods and 30 random selections of training/validation datasets in Example II.Architecture Method 
Mean validation 
RMSE </p>
<p>FNN </p>
<p>Standard 9.1903 × 10 −2 
BFTL-1 
1.7079 × 10 −2 
BFTL-2 
9.0712 × 10 −3 
BFWL 
1.3826 × 10 −2 </p>
<p>ResNet </p>
<p>Standard 3.9497 × 10 −2 
BFTL-1 
8.5282 × 10 −3 
BFTL-2 
9.2004 × 10 −3 
BFWL 
7.6422 × 10 −3 </p>
<p>TABLE 9 :
9The uncertain parameters in Example III and their corresponding probability distributions. Note that U[a, b] denotes a uniform distribution between a and b.Parameter 
Distribution 
Maximum camber, m 
U[0.032, 0.048] 
Location of maximum camber, p 
U[0.32, 0.48] 
Maximum thickness, t max 
U[0.096, 0.144] 
Angle of attack, α 
U[0 • , 6 • ] </p>
<p>TABLE 10 :
10The learning rates used with different learning methods in Example III.Architecture 
Method 
Dataset 
Learning rate, η k </p>
<p>FNN </p>
<p>Standard 
D h 
4 × 10 −4 </p>
<p>TABLE 11 :
11The mean validation RMSEs obtained using different learning methods in Example III.Architecture Method 
Mean validation 
RMSE </p>
<p>FNN </p>
<p>Standard 3.0076 × 10 −1 
BFTL-1 
3.1631 × 10 −1 
BFTL-2 
1.4896 × 10 −1 
BFWL 
3.2402 × 10 −2 
ResNet 
Standard 2.9170 × 10 −1 </p>
<p>S. De, J. Britton, M. Reynolds, R. Skinner, K. Jansen, &amp; A. Doostan</p>
<p>An introduction to neural networks. K Gurney, CRC pressGurney, K., An introduction to neural networks, CRC press, 2014.</p>
<p>Deep learning. I Goodfellow, Y Bengio, A Courville, MIT pressGoodfellow, I., Bengio, Y., and Courville, A., Deep learning, MIT press, 2016.</p>
<p>Tensorflow: A system for large-scale machine learning. M Abadi, P Barham, J Chen, Z Chen, A Davis, J Dean, M Devin, S Ghemawat, G Irving, M Isard, M Kudlur, J Levenberg, R Monga, S Moore, D Murray, B Steiner, P Tucker, V Vasudevan, P Warden, M Wicke, Y Yu, X Zheng, 12th USENIX Symposium on Operating Systems Design and Implementation (OSDI 16). Abadi, M., Barham, P., Chen, J., Chen, Z., Davis, A., Dean, J., Devin, M., Ghemawat, S., Irving, G., Isard, M., Kudlur, M., Levenberg, J., Monga, R., Moore, S., Murray, D., Steiner, B., Tucker, P., Vasudevan, V., Warden, P., Wicke, M., Yu, Y., and Zheng, X., Tensorflow: A system for large-scale machine learning, In 12th USENIX Symposium on Operating Systems Design and Implementation (OSDI 16), pp. 265-283, 2016.</p>
<p>Theano: a CPU and GPU math expression compiler. J Bergstra, O Breuleux, F Bastien, P Lamblin, R Pascanu, G Desjardins, J Turian, D Warde-Farley, Y Bengio, Proceedings of the Python for scientific computing conference (SciPy). the Python for scientific computing conference (SciPy)Austin, TX4Bergstra, J., Breuleux, O., Bastien, F., Lamblin, P., Pascanu, R., Desjardins, G., Turian, J., Warde-Farley, D., and Bengio, Y., Theano: a CPU and GPU math expression compiler, In Proceedings of the Python for scientific computing conference (SciPy), Vol. 4. Austin, TX, 2010.</p>
<p>Y Jia, E Shelhamer, J Donahue, S Karayev, J Long, R Girshick, S Guadarrama, Darrell , T Caffe, arXiv:1408.5093Convolutional architecture for fast feature embedding. arXiv preprintJia, Y., Shelhamer, E., Donahue, J., Karayev, S., Long, J., Girshick, R., Guadarrama, S., and Darrell, T., Caffe: Convolutional architecture for fast feature embedding, arXiv preprint arXiv:1408.5093, 2014.</p>
<p>Automatic differentiation in PyTorch. A Paszke, S Gross, S Chintala, G Chanan, E Yang, Z Devito, Z Lin, A Desmaison, L Antiga, A Lerer, NIPS 2017 Autodiff Workshop: The Future of Gradient-based Machine Learning Software and Techniques. Long Beach, CA, USAPaszke, A., Gross, S., Chintala, S., Chanan, G., Yang, E., DeVito, Z., Lin, Z., Desmaison, A., Antiga, L., and Lerer, A., Automatic differentiation in PyTorch, In NIPS 2017 Autodiff Workshop: The Future of Gradient-based Machine Learning Software and Techniques, Long Beach, CA, USA, 2017.</p>
<p>. Top500 List, TOP500 LIST . https://www.top500.org/lists/2019/06/. Accessed: 20th Aug, 2019.</p>
<p>Approximation by superpositions of a sigmoidal function. G Cybenko, Mathematics of Control, Signals and Systems. 24Cybenko, G., Approximation by superpositions of a sigmoidal function, Mathematics of Control, Signals and Systems, 2(4):303-314, 1989.</p>
<p>Multilayer feedforward networks are universal approximators. K Hornik, M Stinchcombe, H White, Neural Networks. 25Hornik, K., Stinchcombe, M., and White, H., Multilayer feedforward networks are universal approximators, Neural Networks, 2(5):359-366, 1989.</p>
<p>Universal approximation of an unknown mapping and its derivatives using multilayer feedforward networks. K Hornik, M Stinchcombe, H White, Neural Networks. 35Hornik, K., Stinchcombe, M., and White, H., Universal approximation of an unknown mapping and its derivatives using multilayer feedforward networks, Neural Networks, 3(5):551-560, 1990.</p>
<p>Deep relu networks and high-order finite element methods. J A Opschoor, P Petersen, C Schwab, SAM, ETH ZürichOpschoor, J.A., Petersen, P., and Schwab, C., Deep relu networks and high-order finite element methods, SAM, ETH Zürich, 2019.</p>
<p>N Baker, F Alexander, T Bremer, A Hagberg, Y Kevrekidis, H Najm, M Parashar, A Patra, J Sethian, S Wild, Workshop report on basic research needs for scientific machine learning: Core technologies for artificial intelligence. Washington, DCTech. Rep.United StatesBaker, N., Alexander, F., Bremer, T., Hagberg, A., Kevrekidis, Y., Najm, H., Parashar, M., Patra, A., Sethian, J., Wild, S., , Workshop report on basic research needs for scientific machine learning: Core technologies for artificial intelligence, Tech. Rep., USDOE Office of Science (SC), Washington, DC (United States), 2019.</p>
<p>M G Fernández-Godino, C Park, N H Kim, R T Haftka, arXiv:1609.07196Review of multi-fidelity models. arXiv preprintFernández-Godino, M.G., Park, C., Kim, N.H., and Haftka, R.T., Review of multi-fidelity models, arXiv preprint arXiv:1609.07196, 2016.</p>
<p>Survey of multifidelity methods in uncertainty propagation, inference, and optimization. B Peherstorfer, K Willcox, M Gunzburger, SIAM Review. 603Peherstorfer, B., Willcox, K., and Gunzburger, M., Survey of multifidelity methods in uncertainty propagation, inference, and optimization, SIAM Review, 60(3):550-591, 2018.</p>
<p>Turbulence and the dynamics of coherent structures Part I: coherent structures. L Sirovich, Quarterly of Applied Mathematics. 453Sirovich, L., Turbulence and the dynamics of coherent structures Part I: coherent structures, Quarterly of Applied Mathematics, 45(3):561-571, 1987.</p>
<p>The proper orthogonal decomposition in the analysis of turbulent flows. G Berkooz, P Holmes, J L Lumley, Annual Review of Fluid Mechanics. 251Berkooz, G., Holmes, P., and Lumley, J.L., The proper orthogonal decomposition in the analysis of turbulent flows, Annual Review of Fluid Mechanics, 25(1):539-575, 1993.</p>
<p>A survey of projection-based model reduction methods for parametric dynamical systems. P Benner, S Gugercin, K Willcox, SIAM Review. 574Benner, P., Gugercin, S., and Willcox, K., A survey of projection-based model reduction methods for parametric dynamical systems, SIAM Review, 57(4):483-531, 2015.</p>
<p>Gaussian processes in machine learning. C E Rasmussen, Advanced lectures on machine learning. SpringerRasmussen, C.E. Gaussian processes in machine learning. In Advanced lectures on machine learning, pp. 63-71. Springer, 2004.</p>
<p>Use of kriging models to approximate deterministic computer models. J D Martin, T W Simpson, AIAA Journal. 434Martin, J.D. and Simpson, T.W., Use of kriging models to approximate deterministic computer models, AIAA Journal, 43(4):853-863, 2005.</p>
<p>Recent advances in surrogate-based optimization. A I Forrester, A J Keane, Progress in Aerospace Sciences. 451-3Forrester, A.I. and Keane, A.J., Recent advances in surrogate-based optimization, Progress in Aerospace Sciences, 45(1-3):50- 79, 2009.</p>
<p>Accurate uncertainty quantification using inaccurate computational models. P S Koutsourelakis, SIAM Journal on Scientific Computing. 315Koutsourelakis, P.S., Accurate uncertainty quantification using inaccurate computational models, SIAM Journal on Scientific Computing, 31(5):3274-3300, 2009.</p>
<p>Evaluation of failure probability via surrogate models. J Li, D Xiu, Journal of Computational Physics. 22923Li, J. and Xiu, D., Evaluation of failure probability via surrogate models, Journal of Computational Physics, 229(23):8966-8980, 2010.</p>
<p>An efficient surrogate-based method for computing rare failure probability. J Li, J Li, D Xiu, Journal of Computational Physics. 23024Li, J., Li, J., and Xiu, D., An efficient surrogate-based method for computing rare failure probability, Journal of Computational Physics, 230(24):8683-8697, 2011.</p>
<p>Combining multiple surrogate models to accelerate failure probability estimation with expensive high-fidelity models. B Peherstorfer, B Kramer, K Willcox, Journal of Computational Physics. 341Peherstorfer, B., Kramer, B., and Willcox, K., Combining multiple surrogate models to accelerate failure probability estimation with expensive high-fidelity models, Journal of Computational Physics, 341:61-75, 2017.</p>
<p>Predicting the output from a complex computer code when fast approximations are available. M Kennedy, A O&apos;hagan, Biometrika. 871Kennedy, M. and O'Hagan, A., Predicting the output from a complex computer code when fast approximations are available, Biometrika, 87(1):1-13, 2000.</p>
<p>Building surrogate models based on detailed and approximate simulations. Z Qian, C Seepersad, V Joseph, J K Allen, C Wu, Journal of Mechanical Design. 1284Qian, Z., Seepersad, C., Joseph, V., Allen, J.K., and Wu, C., Building surrogate models based on detailed and approximate simulations, Journal of Mechanical Design, 128(4):668-677, 2006.</p>
<p>Parameter tuning for a multi-fidelity dynamical model of the magnetosphere. W Kleiber, S R Sain, M J Heaton, M Wiltberger, C S Reese, D Bingham, The Annals of Applied Statistics. 7Kleiber, W., Sain, S.R., Heaton, M.J., Wiltberger, M., Reese, C.S., Bingham, D., , Parameter tuning for a multi-fidelity dynamical model of the magnetosphere, The Annals of Applied Statistics, 7:1286-1310, 2013.</p>
<p>Recursive co-kriging model for design of computer experiments with multiple levels of fidelity. Le Gratiet, L Garnier, J , International Journal for Uncertainty Quantification. 4Le Gratiet, L. and Garnier, J., Recursive co-kriging model for design of computer experiments with multiple levels of fidelity, International Journal for Uncertainty Quantification, 4:365-386, 2014.</p>
<p>Recent advances in non-intrusive polynomial chaos and stochastic collocation methods for uncertainty analysis and Volume x, Issue x. M Eldred, Eldred, M., Recent advances in non-intrusive polynomial chaos and stochastic collocation methods for uncertainty analysis and Volume x, Issue x, 2019</p>
<p>S De, J Britton, M Reynolds, R Skinner, K Jansen, &amp; A Doostan Design, 50th AIAA/ASME/ASCE/AHS/ASC Structures, Structural Dynamics, and Materials Conference 17th AIAA/ASME/AHS Adaptive Structures Conference. 2274S. De, J. Britton, M. Reynolds, R. Skinner, K. Jansen, &amp; A. Doostan design, In 50th AIAA/ASME/ASCE/AHS/ASC Structures, Structural Dynamics, and Materials Conference 17th AIAA/ASME/AHS Adaptive Structures Conference, p. 2274.</p>
<p>Multifidelity uncertainty quantification using non-intrusive polynomial chaos and stochastic collocation. L W T Ng, M Eldred, 53rd AIAA/ASME/ASCE/AHS/ASC Structures, Structural Dynamics and Materials Conference 20th AIAA/ASME/AHS Adaptive Structures Conference 14th AIAA. 1852Ng, L.W.T. and Eldred, M., Multifidelity uncertainty quantification using non-intrusive polynomial chaos and stochastic collo- cation, In 53rd AIAA/ASME/ASCE/AHS/ASC Structures, Structural Dynamics and Materials Conference 20th AIAA/ASME/AHS Adaptive Structures Conference 14th AIAA, p. 1852, 2012.</p>
<p>Multi-fidelity methods in aerodynamic robust optimization. A S Padron, J J Alonso, M S Eldred, 18th AIAA Non-Deterministic Approaches Conference. 680Padron, A.S., Alonso, J.J., and Eldred, M.S., Multi-fidelity methods in aerodynamic robust optimization, In 18th AIAA Non-Deterministic Approaches Conference, p. 0680, 2016.</p>
<p>Stochastic model reduction for chaos representations. A Doostan, R Ghanem, J Red-Horse, Computer Methods in Applied Mechanics and Engineering. 196Doostan, A., Ghanem, R., and Red-Horse, J., Stochastic model reduction for chaos representations, Computer Methods in Applied Mechanics and Engineering, 196(37-40):3951-3966, 2007.</p>
<p>Efficient solution of stochastic systems: Application to the embankment dam problem. R Ghanem, G Saad, A Doostan, Structural Safety. 293Ghanem, R., Saad, G., and Doostan, A., Efficient solution of stochastic systems: Application to the embankment dam problem, Structural Safety, 29(3):238-251, 2007.</p>
<p>A stochastic collocation algorithm with multifidelity models. A Narayan, C Gittelson, D Xiu, SIAM Journal on Scientific Computing. 362Narayan, A., Gittelson, C., and Xiu, D., A stochastic collocation algorithm with multifidelity models, SIAM Journal on Scientific Computing, 36(2):A495-A521, 2014.</p>
<p>Computational aspects of stochastic collocation with multifidelity models. X Zhu, A Narayan, D Xiu, SIAM/ASA Journal on Uncertainty Quantification. 21Zhu, X., Narayan, A., and Xiu, D., Computational aspects of stochastic collocation with multifidelity models, SIAM/ASA Journal on Uncertainty Quantification, 2(1):444-463, 2014.</p>
<p>A bi-fidelity approach for uncertainty quantification of heat transfer in a rectangular ribbed channel. A Doostan, G Geraci, G Iaccarino, ASME Turbo Expo 2016: Turbomachinery Technical Conference and Exposition. American Society of Mechanical EngineersDoostan, A., Geraci, G., and Iaccarino, G., A bi-fidelity approach for uncertainty quantification of heat transfer in a rectangular ribbed channel, In ASME Turbo Expo 2016: Turbomachinery Technical Conference and Exposition, pp. V02CT45A031- V02CT45A031. American Society of Mechanical Engineers, 2016.</p>
<p>Practical error bounds for a non-intrusive bi-fidelity approach to parametric/stochastic model reduction. J Hampton, H R Fairbanks, A Narayan, A Doostan, Journal of Computational Physics. 368Hampton, J., Fairbanks, H.R., Narayan, A., and Doostan, A., Practical error bounds for a non-intrusive bi-fidelity approach to parametric/stochastic model reduction, Journal of Computational Physics, 368:315-332, 2018.</p>
<p>Bi-fidelity approximation for uncertainty quantification and sensitivity analysis of irradiated particle-laden turbulence. H R Fairbanks, L Jofre, G Geraci, G Iaccarino, A Doostan, arXiv:1808.05742arXiv preprintFairbanks, H.R., Jofre, L., Geraci, G., Iaccarino, G., and Doostan, A., Bi-fidelity approximation for uncertainty quantification and sensitivity analysis of irradiated particle-laden turbulence, arXiv preprint arXiv:1808.05742, 2018.</p>
<p>Reduced-basis multifidelity approach for efficient parametric study of NACA airfoils. R W Skinner, A Doostan, E L Peters, J A Evans, K E Jansen, AIAA Journal. Skinner, R.W., Doostan, A., Peters, E.L., Evans, J.A., and Jansen, K.E., Reduced-basis multifidelity approach for efficient parametric study of NACA airfoils, AIAA Journal, pp. 1-11, 2019.</p>
<p>A survey on transfer learning. S J Pan, Q Yang, IEEE Transactions on Knowledge and Data Engineering. 2210Pan, S.J. and Yang, Q., A survey on transfer learning, IEEE Transactions on Knowledge and Data Engineering, 22(10):1345- 1359, 2010.</p>
<p>A survey of transfer learning. K Weiss, T M Khoshgoftaar, Wang , D , Journal of Big Data. 319Weiss, K., Khoshgoftaar, T.M., and Wang, D., A survey of transfer learning, Journal of Big Data, 3(1):9, 2016.</p>
<p>Cross-domain co-extraction of sentiment and topic lexicons. F Li, S J Pan, O Jin, Q Yang, X Zhu, Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers. the 50th Annual Meeting of the Association for Computational Linguistics: Long PapersAssociation for Computational Linguistics1Li, F., Pan, S.J., Jin, O., Yang, Q., and Zhu, X., Cross-domain co-extraction of sentiment and topic lexicons, In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers-Volume 1, pp. 410-419. Association for Computational Linguistics, 2012.</p>
<p>Heterogeneous transfer learning for image classification. Y Zhu, Y Chen, Z Lu, S J Pan, G R Xue, Y Yu, Yang , Q , Twenty-Fifth AAAI Conference on Artificial Intelligence. Zhu, Y., Chen, Y., Lu, Z., Pan, S.J., Xue, G.R., Yu, Y., and Yang, Q., Heterogeneous transfer learning for image classification, In Twenty-Fifth AAAI Conference on Artificial Intelligence, 2011.</p>
<p>A unified architecture for natural language processing: Deep neural networks with multitask learning. R Collobert, J Weston, Proceedings of the 25th International Conference on Machine Learning. the 25th International Conference on Machine LearningACMCollobert, R. and Weston, J., A unified architecture for natural language processing: Deep neural networks with multitask learning, In Proceedings of the 25th International Conference on Machine Learning, pp. 160-167. ACM, 2008.</p>
<p>Domain adaptation for face recognition: Targetize source domain bridged by common subspace. M Kan, J Wu, S Shan, Chen , X , International Journal of Computer Vision. 1091-2Kan, M., Wu, J., Shan, S., and Chen, X., Domain adaptation for face recognition: Targetize source domain bridged by common subspace, International Journal of Computer Vision, 109(1-2):94-109, 2014.</p>
<p>Transfer learning used to analyze the dynamic evolution of the dust aerosol. Y Ma, W Gong, Mao , F , Journal of Quantitative Spectroscopy and Radiative Transfer. 153Ma, Y., Gong, W., and Mao, F., Transfer learning used to analyze the dynamic evolution of the dust aerosol, Journal of Quantitative Spectroscopy and Radiative Transfer, 153:119-130, 2015.</p>
<p>Knowledge transfer via classification rules using functional mapping for integrative modeling of gene expression data. H A Ogoe, S Visweswaran, X Lu, V Gopalakrishnan, BMC bioinformatics. 161226Ogoe, H.A., Visweswaran, S., Lu, X., and Gopalakrishnan, V., Knowledge transfer via classification rules using functional mapping for integrative modeling of gene expression data, BMC bioinformatics, 16(1):226, 2015.</p>
<p>Multitask learning in computational biology. C Widmer, G Rätsch, Proceedings of ICML Workshop on Unsupervised and Transfer Learning. ICML Workshop on Unsupervised and Transfer LearningWidmer, C. and Rätsch, G., Multitask learning in computational biology, In Proceedings of ICML Workshop on Unsupervised and Transfer Learning, pp. 207-216, 2012.</p>
<p>Neural ranking models with weak supervision. M Dehghani, H Zamani, A Severyn, J Kamps, W B Croft, Proceedings of the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval. the 40th International ACM SIGIR Conference on Research and Development in Information RetrievalACMDehghani, M., Zamani, H., Severyn, A., Kamps, J., and Croft, W.B., Neural ranking models with weak supervision, In Proceedings of the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval, pp. 65-74. ACM, 2017.</p>
<p>Fidelity-weighted learning. M Dehghani, A Mehrjou, S Gouws, J Kamps, B Schölkopf, International Conference on Learning Representations. Dehghani, M., Mehrjou, A., Gouws, S., Kamps, J., and Schölkopf, B., Fidelity-weighted learning, In International Conference on Learning Representations (ICLR 2018). OpenReview. net, 2018.</p>
<p>A fast learning algorithm for deep belief nets. G E Hinton, S Osindero, Y W Teh, International Journal for Uncertainty Quantification. 187Neural ComputationHinton, G.E., Osindero, S., and Teh, Y.W., A fast learning algorithm for deep belief nets, Neural Computation, 18(7):1527-1554, International Journal for Uncertainty Quantification</p>
<p>A new learning paradigm: Learning using privileged information. V Vapnik, A Vashist, Neural Networks. 225-6Vapnik, V. and Vashist, A., A new learning paradigm: Learning using privileged information, Neural Networks, 22(5-6):544-557, 2009.</p>
<p>Learning using privileged information: Similarity control and knowledge transfer. V Vapnik, R Izmailov, Journal of Machine Learning Research. 162Vapnik, V. and Izmailov, R., Learning using privileged information: Similarity control and knowledge transfer., Journal of Machine Learning Research, 16(2023-2049):2, 2015.</p>
<p>Transfer learning. L Torrey, J Shavlik, Handbook of research on machine learning applications and trends: algorithms, methods, and techniques. IGI GlobalTorrey, L. and Shavlik, J. Transfer learning. In Handbook of research on machine learning applications and trends: algorithms, methods, and techniques, pp. 242-264. IGI Global, 2010.</p>
<p>To transfer or not to transfer. M T Rosenstein, Z Marx, L P Kaelbling, T G Dietterich, NIPS 2005 workshop on transfer learning. 8983Rosenstein, M.T., Marx, Z., Kaelbling, L.P., and Dietterich, T.G., To transfer or not to transfer, In NIPS 2005 workshop on transfer learning, Vol. 898, p. 3, 2005.</p>
<p>On handling negative transfer and imbalanced distributions in multiple source transfer learning, Statistical Analysis and Data Mining. L Ge, J Gao, H Ngo, K Li, A Zhang, The ASA Data Science Journal. 74Ge, L., Gao, J., Ngo, H., Li, K., and Zhang, A., On handling negative transfer and imbalanced distributions in multiple source transfer learning, Statistical Analysis and Data Mining: The ASA Data Science Journal, 7(4):254-271, 2014.</p>
<p>Characterizing and avoiding negative transfer. Z Wang, Z Dai, B Póczos, J Carbonell, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. the IEEE Conference on Computer Vision and Pattern RecognitionWang, Z., Dai, Z., Póczos, B., and Carbonell, J., Characterizing and avoiding negative transfer, In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 11293-11302, 2019.</p>
<p>Deep residual learning for image recognition. K He, X Zhang, S Ren, J Sun, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. the IEEE Conference on Computer Vision and Pattern RecognitionHe, K., Zhang, X., Ren, S., and Sun, J., Deep residual learning for image recognition, In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 770-778, 2016.</p>
<p>Deep learning: An introduction for applied mathematicians. C F Higham, D J Higham, arXiv:1801.05894arXiv preprintHigham, C.F. and Higham, D.J., Deep learning: An introduction for applied mathematicians, arXiv preprint arXiv:1801.05894, 2018.</p>
<p>Adam: A method for stochastic optimization. D Kingma, J Ba, arXiv:1412.6980arXiv preprintKingma, D. and Ba, J., Adam: A method for stochastic optimization, arXiv preprint arXiv:1412.6980, 2014.</p>
<p>Topology optimization under uncertainty using a stochastic gradient-based approach. S De, J Hampton, K Maute, A Doostan, arXiv:1902.04562arXiv preprintDe, S., Hampton, J., Maute, K., and Doostan, A., Topology optimization under uncertainty using a stochastic gradient-based approach, arXiv preprint arXiv:1902.04562, 2019.</p>
<p>Universal function approximation by deep neural nets with bounded width and ReLU activations. B Hanin, arXiv:1708.02691arXiv preprintHanin, B., Universal function approximation by deep neural nets with bounded width and ReLU activations, arXiv preprint arXiv:1708.02691, 2017.</p>
<p>Bayesian variable selection in linear regression. T J Mitchell, J J Beauchamp, Journal of the American Statistical Association. 83404Mitchell, T.J. and Beauchamp, J.J., Bayesian variable selection in linear regression, Journal of the American Statistical Association, 83(404):1023-1032, 1988.</p>
<p>Accelerating stochastic gradient descent using predictive variance reduction. R Johnson, T Zhang, Advances in Neural Information Processing Systems. Johnson, R. and Zhang, T., Accelerating stochastic gradient descent using predictive variance reduction, In Advances in Neural Information Processing Systems, pp. 315-323, 2013.</p>
<p>Bi-fidelity stochastic gradient descent for structural optimization under uncertainty. S De, K Maute, A Doostan, arXiv:1911.10420arXiv preprintDe, S., Maute, K., and Doostan, A., Bi-fidelity stochastic gradient descent for structural optimization under uncertainty, arXiv preprint arXiv:1911.10420, 2019.</p>
<p>Scikit-learn: Machine learning in Python. F Pedregosa, G Varoquaux, A Gramfort, V Michel, B Thirion, O Grisel, M Blondel, P Prettenhofer, R Weiss, V Dubourg, Journal of Machine Learning Research. 12Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel, O., Blondel, M., Prettenhofer, P., Weiss, R., Dubourg, V., , Scikit-learn: Machine learning in Python, Journal of Machine Learning Research, 12:2825-2830, 2011.</p>
<p>Automated Solution of Differential Equations by the Finite Element Method. A Logg, K A Mardal, G N Wells, SpringerLogg, A., Mardal, K.A., and Wells, G.N., Automated Solution of Differential Equations by the Finite Element Method, Springer, 2012.</p>
<p>On uncertainty quantification of lithium-ion batteries: Application to an LiC 6 /LiCoO 2 cell. M Hadigol, K Maute, A Doostan, Journal of Power Sources. 300Hadigol, M., Maute, K., and Doostan, A., On uncertainty quantification of lithium-ion batteries: Application to an LiC 6 /LiCoO 2 cell, Journal of Power Sources, 300:507-524, 2015.</p>
<p>Porous-electrode theory with battery applications. J Newman, W Tiedemann, AIChE Journal. 211Newman, J. and Tiedemann, W., Porous-electrode theory with battery applications, AIChE Journal, 21(1):25-41, 1975.</p>
<p>Grid convergence for turbulent flows. B Diskin, J Thomas, C L Rumsey, A Schwöppe, 53rd AIAA Aerospace Sciences Meeting. 1746Diskin, B., Thomas, J., Rumsey, C.L., and Schwöppe, A., Grid convergence for turbulent flows, In 53rd AIAA Aerospace Sciences Meeting, p. 1746, 2015.</p>
<p>A stabilized finite element method for the incompressible Navier-Stokes equations using a hierarchical basis. C H Whiting, K E Jansen, International Journal for Numerical Methods in Fluids. 351Whiting, C.H. and Jansen, K.E., A stabilized finite element method for the incompressible Navier-Stokes equations using a hierarchical basis, International Journal for Numerical Methods in Fluids, 35(1):93-116, 2001.</p>            </div>
        </div>

    </div>
</body>
</html>