<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-6518 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-6518</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-6518</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-129.html">extraction-schema-129</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' reasoning methods, the diversity or similarity of reasoning styles, the tasks or benchmarks used to evaluate them, performance results, and any direct comparisons between diverse and similar reasoning approaches.</div>
                <p><strong>Paper ID:</strong> paper-274763018</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2412.09906v1.pdf" target="_blank">Enhancing the Reasoning Capabilities of Small Language Models via Solution Guidance Fine-Tuning</a></p>
                <p><strong>Paper Abstract:</strong> Large language models (LLMs) have demonstrated remarkable performance across a wide range of tasks. Advances in prompt engineering and fine-tuning techniques have further enhanced their ability to address complex reasoning challenges. However, these advanced capabilities are often exclusive to models exceeding 100 billion parameters. Although Chain-of-Thought (CoT) fine-tuning methods have been explored for smaller models (under 10 billion parameters), they typically depend on extensive CoT training data, which can introduce inconsistencies and limit effectiveness in low-data settings. To overcome these limitations, this paper introduce a new reasoning strategy Solution Guidance (SG) and a plug-and-play training paradigm Solution-Guidance Fine-Tuning (SGFT) for enhancing the reasoning capabilities of small language models. SG focuses on problem understanding and decomposition at the semantic and logical levels, rather than specific computations, which can effectively improve the SLMs' generalization and reasoning abilities. With only a small amount of SG training data, SGFT can fine-tune a SLM to produce accurate problem-solving guidances, which can then be flexibly fed to any SLM as prompts, enabling it to generate correct answers directly. Experimental results demonstrate that our method significantly improves the performance of SLMs on various reasoning tasks, enhancing both their practicality and efficiency within resource-constrained environments.</p>
                <p><strong>Cost:</strong> 0.015</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e6518.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e6518.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' reasoning methods, the diversity or similarity of reasoning styles, the tasks or benchmarks used to evaluate them, performance results, and any direct comparisons between diverse and similar reasoning approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>SG</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Solution Guidance</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A high-level problem-understanding and decomposition reasoning strategy that produces stepwise solution objectives (no calculations) to guide another model to compute the final answer; introduced in this paper to reduce noise and data needs compared to CoT.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_name</strong></td>
                            <td>Solution Guidance (SG)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_type</strong></td>
                            <td>sequential / decomposition</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_style_diversity</strong></td>
                            <td>single style</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>GSM8K, SVAMP, MultiArith, StrategyQA, CommonsenseQA</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Mathematical word problems and commonsense reasoning (provide stepwise solution objectives without calculations to guide answer generation).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>accuracy</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_target_method</strong></td>
                            <td>Chain-of-Thought (CoT)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_difference</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>analysis_notes</strong></td>
                            <td>SG focuses on semantic/logical decomposition rather than per-step calculations, reducing cascading error propagation and excessive explanatory text typical of CoT; it is designed for low-data fine-tuning and for collaborative inference where one model generates SG and another produces the final answer. The paper notes SG is currently single-path (homogeneous) and that multi-path/diverse SG generation could be explored in future work.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_study_present</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Enhancing the Reasoning Capabilities of Small Language Models via Solution Guidance Fine-Tuning', 'publication_date_yy_mm': '2024-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6518.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e6518.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' reasoning methods, the diversity or similarity of reasoning styles, the tasks or benchmarks used to evaluate them, performance results, and any direct comparisons between diverse and similar reasoning approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>CoT</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Chain-of-Thought reasoning</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Step-by-step reasoning traces that include intermediate calculations and explanations; used as a baseline and prior art for improving model reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_name</strong></td>
                            <td>Chain-of-Thought (CoT)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_type</strong></td>
                            <td>sequential / stepwise</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_style_diversity</strong></td>
                            <td>single style</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>GSM8K, SVAMP, MultiArith, StrategyQA, CommonsenseQA</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Mathematical and commonsense reasoning using multi-step chains with intermediate calculations.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>accuracy</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_target_method</strong></td>
                            <td>Solution Guidance (SG)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_difference</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>analysis_notes</strong></td>
                            <td>Paper describes limitations of CoT for small language models: requires large CoT datasets, prone to cascading error propagation from intermediate calculations, can reduce general capabilities by producing unnecessary reasoning chains; CoT fine-tuning used as principal baseline.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_study_present</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Enhancing the Reasoning Capabilities of Small Language Models via Solution Guidance Fine-Tuning', 'publication_date_yy_mm': '2024-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6518.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e6518.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' reasoning methods, the diversity or similarity of reasoning styles, the tasks or benchmarks used to evaluate them, performance results, and any direct comparisons between diverse and similar reasoning approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ChatGLM3-6B_zero-shot</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>ChatGLM3-6B (instruction-tuned) zero-shot baseline</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Instruction-tuned ChatGLM3-6B evaluated zero-shot on reasoning benchmarks as a baseline.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Enhancing the Reasoning Capabilities of Small Language Models via Solution Guidance Fine-Tuning</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>ChatGLM3-6B-Instruct</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>6B</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_name</strong></td>
                            <td>zero-shot instruction (no CoT/SG fine-tuning)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_type</strong></td>
                            <td>single-pass</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_style_diversity</strong></td>
                            <td>single style</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>GSM8K</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Grade-school arithmetic / math word problems (GSM8K in-distribution).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>accuracy</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>27.4</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_target_method</strong></td>
                            <td>ChatGLM3-6B_CoT</td>
                        </tr>
                        <tr>
                            <td><strong>performance_difference</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>analysis_notes</strong></td>
                            <td>Serves as base instruction-tuned small model performance; authors compare improvements from CoT fine-tuning and SGFT against this baseline.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_study_present</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Enhancing the Reasoning Capabilities of Small Language Models via Solution Guidance Fine-Tuning', 'publication_date_yy_mm': '2024-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6518.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e6518.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' reasoning methods, the diversity or similarity of reasoning styles, the tasks or benchmarks used to evaluate them, performance results, and any direct comparisons between diverse and similar reasoning approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ChatGLM3-6B_CoT</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>ChatGLM3-6B fine-tuned with Chain-of-Thought</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>ChatGLM3-6B fine-tuned using large CoT training data (CoT fine-tuning baseline).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Enhancing the Reasoning Capabilities of Small Language Models via Solution Guidance Fine-Tuning</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>ChatGLM3-6B-Instruct (CoT fine-tuned)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>6B</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_name</strong></td>
                            <td>Chain-of-Thought fine-tuning</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_type</strong></td>
                            <td>sequential / stepwise</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_style_diversity</strong></td>
                            <td>single style</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>GSM8K</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Grade-school arithmetic / math word problems.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>accuracy</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>34.4</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_target_method</strong></td>
                            <td>ChatGLM3-6B zero-shot baseline</td>
                        </tr>
                        <tr>
                            <td><strong>performance_difference</strong></td>
                            <td>7.0</td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>analysis_notes</strong></td>
                            <td>CoT fine-tuning improves over zero-shot baseline but requires much more training data; authors report CoT-finetuned small models can still suffer from error propagation and need many CoT samples (they used a 30k CoT baseline in comparisons).</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_study_present</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Enhancing the Reasoning Capabilities of Small Language Models via Solution Guidance Fine-Tuning', 'publication_date_yy_mm': '2024-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6518.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e6518.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' reasoning methods, the diversity or similarity of reasoning styles, the tasks or benchmarks used to evaluate them, performance results, and any direct comparisons between diverse and similar reasoning approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ChatGLM3-6B_SG+ChatGLM3-6B</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>SG-guided collaborative inference: ChatGLM3-6B (SG) + ChatGLM3-6B (response)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Using a ChatGLM3-6B model fine-tuned with SG to generate solution guidance and the same (untuned) ChatGLM3-6B model to produce final answers; evaluated on GSM8K.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Enhancing the Reasoning Capabilities of Small Language Models via Solution Guidance Fine-Tuning</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>ChatGLM3-6B-Instruct (SG fine-tuned) + ChatGLM3-6B-Instruct (response)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>6B</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_name</strong></td>
                            <td>Solution Guidance (SG) + collaborative inference</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_type</strong></td>
                            <td>sequential / decomposition with collaborative pipeline</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_style_diversity</strong></td>
                            <td>single style</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>GSM8K</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Grade-school arithmetic / math word problems; guidance model outputs steps (no calculations) which response model uses to compute answer.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>accuracy</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>43.7</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_target_method</strong></td>
                            <td>ChatGLM3-6B_CoT</td>
                        </tr>
                        <tr>
                            <td><strong>performance_difference</strong></td>
                            <td>9.3</td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>analysis_notes</strong></td>
                            <td>SG collaborative inference significantly outperforms CoT-fine-tuned ChatGLM3-6B on GSM8K (43.7 vs 34.4). Authors attribute gains to reduced noise/error propagation, division of labor (guidance vs computation), and much lower SG training-data requirements.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_study_present</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Enhancing the Reasoning Capabilities of Small Language Models via Solution Guidance Fine-Tuning', 'publication_date_yy_mm': '2024-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6518.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e6518.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' reasoning methods, the diversity or similarity of reasoning styles, the tasks or benchmarks used to evaluate them, performance results, and any direct comparisons between diverse and similar reasoning approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Qwen2-7B_zero-shot</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Qwen2-7B-Instruct zero-shot baseline</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Qwen2-7B instruction-tuned small model evaluated zero-shot on reasoning benchmarks.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Enhancing the Reasoning Capabilities of Small Language Models via Solution Guidance Fine-Tuning</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>qwen2-7B-Instruct</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>7B</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_name</strong></td>
                            <td>zero-shot instruction (no CoT/SG fine-tuning)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_type</strong></td>
                            <td>single-pass</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_style_diversity</strong></td>
                            <td>single style</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>GSM8K</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Grade-school arithmetic problems.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>accuracy</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>23.6</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_target_method</strong></td>
                            <td>Qwen2-7B_CoT</td>
                        </tr>
                        <tr>
                            <td><strong>performance_difference</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>analysis_notes</strong></td>
                            <td>Baseline performance for the Qwen family; used to measure benefits from CoT and SG approaches.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_study_present</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Enhancing the Reasoning Capabilities of Small Language Models via Solution Guidance Fine-Tuning', 'publication_date_yy_mm': '2024-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6518.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e6518.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' reasoning methods, the diversity or similarity of reasoning styles, the tasks or benchmarks used to evaluate them, performance results, and any direct comparisons between diverse and similar reasoning approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Qwen2-7B_SG+ChatGLM3-6B</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Qwen2-7B (SG fine-tuned) guiding ChatGLM3-6B (response)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Cross-model collaborative inference where Qwen2-7B fine-tuned with SG generates guidance and ChatGLM3-6B (untuned) produces final answers; reported as one of the strongest GSM8K results in the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Enhancing the Reasoning Capabilities of Small Language Models via Solution Guidance Fine-Tuning</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>qwen2-7B-Instruct (SG fine-tuned) + ChatGLM3-6B-Instruct (response)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>7B (guide) + 6B (responder)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_name</strong></td>
                            <td>Solution Guidance (SG) with cross-model collaborative inference</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_type</strong></td>
                            <td>sequential / decomposition with collaborative pipeline</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_style_diversity</strong></td>
                            <td>single style</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>GSM8K</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Grade-school arithmetic using guidance from one SLM and computation by another SLM.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>accuracy</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>48.3</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_target_method</strong></td>
                            <td>Qwen2-7B_CoT</td>
                        </tr>
                        <tr>
                            <td><strong>performance_difference</strong></td>
                            <td>17.1</td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>analysis_notes</strong></td>
                            <td>Cross-model SG guidance notably outperforms CoT fine-tuning on the same student model (reported Qwen2-7B_CoT = 31.2) and also outperforms single-model SG setups; authors highlight that SG requires far less training data (~3.3% of CoT data) while giving superior accuracy.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_study_present</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Enhancing the Reasoning Capabilities of Small Language Models via Solution Guidance Fine-Tuning', 'publication_date_yy_mm': '2024-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6518.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e6518.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' reasoning methods, the diversity or similarity of reasoning styles, the tasks or benchmarks used to evaluate them, performance results, and any direct comparisons between diverse and similar reasoning approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Llama2-7B_SG+Llama2-7B</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Llama2-7B SG-guided self-collaboration</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Llama2-7B fine-tuned with SG to generate guidance, used together with an untuned Llama2-7B responder to answer GSM8K problems.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Enhancing the Reasoning Capabilities of Small Language Models via Solution Guidance Fine-Tuning</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>llama2-7B-chat (SG fine-tuned + untuned responder)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>7B</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_name</strong></td>
                            <td>Solution Guidance (SG) + collaborative inference</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_type</strong></td>
                            <td>sequential / decomposition with collaborative pipeline</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_style_diversity</strong></td>
                            <td>single style</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>GSM8K</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Mathematical word problems (GSM8K).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>accuracy</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>28.6</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_target_method</strong></td>
                            <td>Llama2-7B_CoT</td>
                        </tr>
                        <tr>
                            <td><strong>performance_difference</strong></td>
                            <td>6.8</td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>analysis_notes</strong></td>
                            <td>SG improves Llama2-7B performance over CoT-finetuned Llama2-7B (28.6 vs 21.8 on GSM8K); authors emphasize SG's robustness on smaller SLMs and its lower data requirements compared to CoT.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_study_present</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Enhancing the Reasoning Capabilities of Small Language Models via Solution Guidance Fine-Tuning', 'publication_date_yy_mm': '2024-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Chain of thought prompting elicits reasoning in large language models <em>(Rating: 2)</em></li>
                <li>Large language models are reasoning teachers <em>(Rating: 2)</em></li>
                <li>Lisa: Layerwise importance sampling for memory-efficient large language model fine-tuning <em>(Rating: 2)</em></li>
                <li>Specializing smaller language models towards multi-step reasoning <em>(Rating: 2)</em></li>
                <li>Training verifiers to solve math word problems <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-6518",
    "paper_id": "paper-274763018",
    "extraction_schema_id": "extraction-schema-129",
    "extracted_data": [
        {
            "name_short": "SG",
            "name_full": "Solution Guidance",
            "brief_description": "A high-level problem-understanding and decomposition reasoning strategy that produces stepwise solution objectives (no calculations) to guide another model to compute the final answer; introduced in this paper to reduce noise and data needs compared to CoT.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "",
            "model_size": "",
            "reasoning_method_name": "Solution Guidance (SG)",
            "reasoning_method_type": "sequential / decomposition",
            "reasoning_style_diversity": "single style",
            "benchmark_name": "GSM8K, SVAMP, MultiArith, StrategyQA, CommonsenseQA",
            "task_description": "Mathematical word problems and commonsense reasoning (provide stepwise solution objectives without calculations to guide answer generation).",
            "performance_metric": "accuracy",
            "performance_value": null,
            "comparison_target_method": "Chain-of-Thought (CoT)",
            "performance_difference": null,
            "statistical_significance": null,
            "analysis_notes": "SG focuses on semantic/logical decomposition rather than per-step calculations, reducing cascading error propagation and excessive explanatory text typical of CoT; it is designed for low-data fine-tuning and for collaborative inference where one model generates SG and another produces the final answer. The paper notes SG is currently single-path (homogeneous) and that multi-path/diverse SG generation could be explored in future work.",
            "ablation_study_present": true,
            "uuid": "e6518.0",
            "source_info": {
                "paper_title": "Enhancing the Reasoning Capabilities of Small Language Models via Solution Guidance Fine-Tuning",
                "publication_date_yy_mm": "2024-12"
            }
        },
        {
            "name_short": "CoT",
            "name_full": "Chain-of-Thought reasoning",
            "brief_description": "Step-by-step reasoning traces that include intermediate calculations and explanations; used as a baseline and prior art for improving model reasoning.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "",
            "model_size": "",
            "reasoning_method_name": "Chain-of-Thought (CoT)",
            "reasoning_method_type": "sequential / stepwise",
            "reasoning_style_diversity": "single style",
            "benchmark_name": "GSM8K, SVAMP, MultiArith, StrategyQA, CommonsenseQA",
            "task_description": "Mathematical and commonsense reasoning using multi-step chains with intermediate calculations.",
            "performance_metric": "accuracy",
            "performance_value": null,
            "comparison_target_method": "Solution Guidance (SG)",
            "performance_difference": null,
            "statistical_significance": null,
            "analysis_notes": "Paper describes limitations of CoT for small language models: requires large CoT datasets, prone to cascading error propagation from intermediate calculations, can reduce general capabilities by producing unnecessary reasoning chains; CoT fine-tuning used as principal baseline.",
            "ablation_study_present": true,
            "uuid": "e6518.1",
            "source_info": {
                "paper_title": "Enhancing the Reasoning Capabilities of Small Language Models via Solution Guidance Fine-Tuning",
                "publication_date_yy_mm": "2024-12"
            }
        },
        {
            "name_short": "ChatGLM3-6B_zero-shot",
            "name_full": "ChatGLM3-6B (instruction-tuned) zero-shot baseline",
            "brief_description": "Instruction-tuned ChatGLM3-6B evaluated zero-shot on reasoning benchmarks as a baseline.",
            "citation_title": "Enhancing the Reasoning Capabilities of Small Language Models via Solution Guidance Fine-Tuning",
            "mention_or_use": "use",
            "model_name": "ChatGLM3-6B-Instruct",
            "model_size": "6B",
            "reasoning_method_name": "zero-shot instruction (no CoT/SG fine-tuning)",
            "reasoning_method_type": "single-pass",
            "reasoning_style_diversity": "single style",
            "benchmark_name": "GSM8K",
            "task_description": "Grade-school arithmetic / math word problems (GSM8K in-distribution).",
            "performance_metric": "accuracy",
            "performance_value": 27.4,
            "comparison_target_method": "ChatGLM3-6B_CoT",
            "performance_difference": null,
            "statistical_significance": false,
            "analysis_notes": "Serves as base instruction-tuned small model performance; authors compare improvements from CoT fine-tuning and SGFT against this baseline.",
            "ablation_study_present": true,
            "uuid": "e6518.2",
            "source_info": {
                "paper_title": "Enhancing the Reasoning Capabilities of Small Language Models via Solution Guidance Fine-Tuning",
                "publication_date_yy_mm": "2024-12"
            }
        },
        {
            "name_short": "ChatGLM3-6B_CoT",
            "name_full": "ChatGLM3-6B fine-tuned with Chain-of-Thought",
            "brief_description": "ChatGLM3-6B fine-tuned using large CoT training data (CoT fine-tuning baseline).",
            "citation_title": "Enhancing the Reasoning Capabilities of Small Language Models via Solution Guidance Fine-Tuning",
            "mention_or_use": "use",
            "model_name": "ChatGLM3-6B-Instruct (CoT fine-tuned)",
            "model_size": "6B",
            "reasoning_method_name": "Chain-of-Thought fine-tuning",
            "reasoning_method_type": "sequential / stepwise",
            "reasoning_style_diversity": "single style",
            "benchmark_name": "GSM8K",
            "task_description": "Grade-school arithmetic / math word problems.",
            "performance_metric": "accuracy",
            "performance_value": 34.4,
            "comparison_target_method": "ChatGLM3-6B zero-shot baseline",
            "performance_difference": 7.0,
            "statistical_significance": false,
            "analysis_notes": "CoT fine-tuning improves over zero-shot baseline but requires much more training data; authors report CoT-finetuned small models can still suffer from error propagation and need many CoT samples (they used a 30k CoT baseline in comparisons).",
            "ablation_study_present": true,
            "uuid": "e6518.3",
            "source_info": {
                "paper_title": "Enhancing the Reasoning Capabilities of Small Language Models via Solution Guidance Fine-Tuning",
                "publication_date_yy_mm": "2024-12"
            }
        },
        {
            "name_short": "ChatGLM3-6B_SG+ChatGLM3-6B",
            "name_full": "SG-guided collaborative inference: ChatGLM3-6B (SG) + ChatGLM3-6B (response)",
            "brief_description": "Using a ChatGLM3-6B model fine-tuned with SG to generate solution guidance and the same (untuned) ChatGLM3-6B model to produce final answers; evaluated on GSM8K.",
            "citation_title": "Enhancing the Reasoning Capabilities of Small Language Models via Solution Guidance Fine-Tuning",
            "mention_or_use": "use",
            "model_name": "ChatGLM3-6B-Instruct (SG fine-tuned) + ChatGLM3-6B-Instruct (response)",
            "model_size": "6B",
            "reasoning_method_name": "Solution Guidance (SG) + collaborative inference",
            "reasoning_method_type": "sequential / decomposition with collaborative pipeline",
            "reasoning_style_diversity": "single style",
            "benchmark_name": "GSM8K",
            "task_description": "Grade-school arithmetic / math word problems; guidance model outputs steps (no calculations) which response model uses to compute answer.",
            "performance_metric": "accuracy",
            "performance_value": 43.7,
            "comparison_target_method": "ChatGLM3-6B_CoT",
            "performance_difference": 9.3,
            "statistical_significance": false,
            "analysis_notes": "SG collaborative inference significantly outperforms CoT-fine-tuned ChatGLM3-6B on GSM8K (43.7 vs 34.4). Authors attribute gains to reduced noise/error propagation, division of labor (guidance vs computation), and much lower SG training-data requirements.",
            "ablation_study_present": true,
            "uuid": "e6518.4",
            "source_info": {
                "paper_title": "Enhancing the Reasoning Capabilities of Small Language Models via Solution Guidance Fine-Tuning",
                "publication_date_yy_mm": "2024-12"
            }
        },
        {
            "name_short": "Qwen2-7B_zero-shot",
            "name_full": "Qwen2-7B-Instruct zero-shot baseline",
            "brief_description": "Qwen2-7B instruction-tuned small model evaluated zero-shot on reasoning benchmarks.",
            "citation_title": "Enhancing the Reasoning Capabilities of Small Language Models via Solution Guidance Fine-Tuning",
            "mention_or_use": "use",
            "model_name": "qwen2-7B-Instruct",
            "model_size": "7B",
            "reasoning_method_name": "zero-shot instruction (no CoT/SG fine-tuning)",
            "reasoning_method_type": "single-pass",
            "reasoning_style_diversity": "single style",
            "benchmark_name": "GSM8K",
            "task_description": "Grade-school arithmetic problems.",
            "performance_metric": "accuracy",
            "performance_value": 23.6,
            "comparison_target_method": "Qwen2-7B_CoT",
            "performance_difference": null,
            "statistical_significance": false,
            "analysis_notes": "Baseline performance for the Qwen family; used to measure benefits from CoT and SG approaches.",
            "ablation_study_present": true,
            "uuid": "e6518.5",
            "source_info": {
                "paper_title": "Enhancing the Reasoning Capabilities of Small Language Models via Solution Guidance Fine-Tuning",
                "publication_date_yy_mm": "2024-12"
            }
        },
        {
            "name_short": "Qwen2-7B_SG+ChatGLM3-6B",
            "name_full": "Qwen2-7B (SG fine-tuned) guiding ChatGLM3-6B (response)",
            "brief_description": "Cross-model collaborative inference where Qwen2-7B fine-tuned with SG generates guidance and ChatGLM3-6B (untuned) produces final answers; reported as one of the strongest GSM8K results in the paper.",
            "citation_title": "Enhancing the Reasoning Capabilities of Small Language Models via Solution Guidance Fine-Tuning",
            "mention_or_use": "use",
            "model_name": "qwen2-7B-Instruct (SG fine-tuned) + ChatGLM3-6B-Instruct (response)",
            "model_size": "7B (guide) + 6B (responder)",
            "reasoning_method_name": "Solution Guidance (SG) with cross-model collaborative inference",
            "reasoning_method_type": "sequential / decomposition with collaborative pipeline",
            "reasoning_style_diversity": "single style",
            "benchmark_name": "GSM8K",
            "task_description": "Grade-school arithmetic using guidance from one SLM and computation by another SLM.",
            "performance_metric": "accuracy",
            "performance_value": 48.3,
            "comparison_target_method": "Qwen2-7B_CoT",
            "performance_difference": 17.1,
            "statistical_significance": false,
            "analysis_notes": "Cross-model SG guidance notably outperforms CoT fine-tuning on the same student model (reported Qwen2-7B_CoT = 31.2) and also outperforms single-model SG setups; authors highlight that SG requires far less training data (~3.3% of CoT data) while giving superior accuracy.",
            "ablation_study_present": true,
            "uuid": "e6518.6",
            "source_info": {
                "paper_title": "Enhancing the Reasoning Capabilities of Small Language Models via Solution Guidance Fine-Tuning",
                "publication_date_yy_mm": "2024-12"
            }
        },
        {
            "name_short": "Llama2-7B_SG+Llama2-7B",
            "name_full": "Llama2-7B SG-guided self-collaboration",
            "brief_description": "Llama2-7B fine-tuned with SG to generate guidance, used together with an untuned Llama2-7B responder to answer GSM8K problems.",
            "citation_title": "Enhancing the Reasoning Capabilities of Small Language Models via Solution Guidance Fine-Tuning",
            "mention_or_use": "use",
            "model_name": "llama2-7B-chat (SG fine-tuned + untuned responder)",
            "model_size": "7B",
            "reasoning_method_name": "Solution Guidance (SG) + collaborative inference",
            "reasoning_method_type": "sequential / decomposition with collaborative pipeline",
            "reasoning_style_diversity": "single style",
            "benchmark_name": "GSM8K",
            "task_description": "Mathematical word problems (GSM8K).",
            "performance_metric": "accuracy",
            "performance_value": 28.6,
            "comparison_target_method": "Llama2-7B_CoT",
            "performance_difference": 6.8,
            "statistical_significance": false,
            "analysis_notes": "SG improves Llama2-7B performance over CoT-finetuned Llama2-7B (28.6 vs 21.8 on GSM8K); authors emphasize SG's robustness on smaller SLMs and its lower data requirements compared to CoT.",
            "ablation_study_present": true,
            "uuid": "e6518.7",
            "source_info": {
                "paper_title": "Enhancing the Reasoning Capabilities of Small Language Models via Solution Guidance Fine-Tuning",
                "publication_date_yy_mm": "2024-12"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Chain of thought prompting elicits reasoning in large language models",
            "rating": 2,
            "sanitized_title": "chain_of_thought_prompting_elicits_reasoning_in_large_language_models"
        },
        {
            "paper_title": "Large language models are reasoning teachers",
            "rating": 2,
            "sanitized_title": "large_language_models_are_reasoning_teachers"
        },
        {
            "paper_title": "Lisa: Layerwise importance sampling for memory-efficient large language model fine-tuning",
            "rating": 2,
            "sanitized_title": "lisa_layerwise_importance_sampling_for_memoryefficient_large_language_model_finetuning"
        },
        {
            "paper_title": "Specializing smaller language models towards multi-step reasoning",
            "rating": 2,
            "sanitized_title": "specializing_smaller_language_models_towards_multistep_reasoning"
        },
        {
            "paper_title": "Training verifiers to solve math word problems",
            "rating": 1,
            "sanitized_title": "training_verifiers_to_solve_math_word_problems"
        }
    ],
    "cost": 0.0147905,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Enhancing the Reasoning Capabilities of Small Language Models via Solution Guidance Fine-Tuning
13 Dec 2024</p>
<p>Jing Bi 
School of Software Engineering
Beijing Jiaotong University
BeijingChina</p>
<p>Yuting Wu 
School of Software Engineering
Beijing Jiaotong University
BeijingChina</p>
<p>Weiwei Xing wwxing@bjtu.edu.cn 
School of Software Engineering
Beijing Jiaotong University
BeijingChina</p>
<p>Zhenjie Wei 
School of Software Engineering
Beijing Jiaotong University
BeijingChina</p>
<p>Enhancing the Reasoning Capabilities of Small Language Models via Solution Guidance Fine-Tuning
13 Dec 20246E68A1A63C0511A2C0FD74BA14E8893BarXiv:2412.09906v1[cs.CL]
Large language models (LLMs) have demonstrated remarkable performance across a wide range of tasks.Advances in prompt engineering and fine-tuning techniques have further enhanced their ability to address complex reasoning challenges.However, these advanced capabilities are often exclusive to models exceeding 100 billion parameters.Although Chain-of-Thought (CoT) fine-tuning methods have been explored for smaller models (under 10 billion parameters), they typically depend on extensive CoT training data, which can introduce inconsistencies and limit effectiveness in low-data settings.To overcome these limitations, this paper introduce a new reasoning strategy Solution Guidance (SG) and a plug-and-play training paradigm Solution-Guidance Fine-Tuning (SGFT) for enhancing the reasoning capabilities of small language models.SG focuses on problem understanding and decomposition at the semantic and logical levels, rather than specific computations, which can effectively improve the SLMs' generalization and reasoning abilities.With only a small amount of SG training data, SGFT can fine-tune a SLM to produce accurate problem-solving guidances, which can then be flexibly fed to any SLM as prompts, enabling it to generate correct answers directly.Experimental results demonstrate that our method significantly improves the performance of SLMs on various reasoning tasks, enhancing both their practicality and efficiency within resource-constrained environments. 1</p>
<p>Introduction</p>
<p>As large language models (LLMs) continue to expand in scale, they demonstrate remarkable proficiency in tasks such as language generation, translation, question answering, and so on.Moreover, they are increasingly being recognized for their potential in addressing more complex challenges, such as reasoning (Yang et al., 2022) and mathematical problem-solving (Mishra et al., 2022).The application of LLMs to reasoning tasks has garnered significant academic interest (Qiao et al., 2022), particularly in the domain of mathematics, where reasoning tasks present substantial challenges (Lu et al., 2022).As one of the representative techniques for enhancing the reasoning capabilities of LLMs, Chain-of-Thought (CoT) reasoning (Wei et al., 2022;Kojima et al., 2022) enables LLMs to deduce answers step-by-step rather than directly providing an answer, thereby producing more accurate and reliable results.However, directly applying CoT reasoning to small language models (SLMs) with fewer than 10 billion parameters has proven to be considerably less effective (Ho et al., 2022).Lanham et al. (2023) propose that CoT prompting only performs effectively under specific scenarios and model scales.</p>
<p>Further, the techniques of CoT fine-tuning have been proposed for SLMs (Ho et al., 2022).This kind of methods involves fine-tuning SLMs using CoT data, allowing them to reason through intermediate steps before reaching a conclusion.However, CoT follows a completely independent process for each problem, integrating both logical reasoning and computation.Due to insufficient fitting with a small amount of data during model training, a large amount of CoT training data is required.Acquiring and annotating such data is labor-intensive (Li et al., 2022), and the logical and grammatical consistency of the data, which depends on manual annotation, are not always assured.</p>
<p>Additionally, existing CoT involves problemsolving steps and a final answer.Each step contains specific explanations and calculations, and the outcome of the current step directly influences the logical generation of the next.This cascading effect causes multiple steps of explanations and calculations to accumulate, leading to error propa- gation and often generating excessive text, which introduces noise and ultimately affects the accuracy of the final answer.For example, when using CoT reasoning to solve the math problem in Figure 1, an unnecessary step was incorrectly generated during the reasoning process: In total, Kate's friends eat 36+24=60 pizza slices, which led to miscalculating the number of cheese pizzas and pepperoni pizzas in the subsequent steps, ultimately resulting in an incorrect final answer.This issue is particularly pronounced in SLMs.Moreover, language models trained with a large amount of CoT data may experience a decline in their equally important general capabilities (Fu et al., 2023).When faced with common-sense or simple questions, the model may fabricate non-existent reasoning chains, unnecessarily complicating the problem and providing incorrect answers.</p>
<p>To address the above issues of existing CoT techniques, we propose a new training paradigm, Solution-Guidance Fine-Tuning (SGFT), to improve the reasoning capabilities of small language models.Different from existing CoT, we present a new reasoning strategy Solution Guidance (SG), which only expects the SLMs to generate problemsolving guidance without calculations or extra explanations.SG focuses on problem understanding and decomposition at the semantic and logical levels, rather than specific computations.With only a small amount of SG training data, SGFT can effectively fine-tune a SLM to generate accurate problem-solving guidances.Then, we only need to use the generated solution guidances as input prompts for another SLM, which can produce the correct answers without additional training.</p>
<p>To verify the effectiveness of our method,</p>
<p>we conducted experiments on multiple reasoning benchmark datasets.The results demonstrate that, compared to traditional CoT fine-tuning applied directly to SLMs, our method significantly enhances performance in mathematical and common-sense reasoning tasks while preserving the original capabilities of SLMs.Additionally, since our approach requires significantly less training data, it is more practical and efficient for real-world applications.</p>
<p>Our key technical contributions are as follows:</p>
<p> We introduce a new reasoning strategy Solution Guidance (SG) for small language models (SLMs), which focuses on problem understanding rather than specific calculations.SG can effectively reduce data generation costs and significantly improve the reasoning capabilities of SLMs.</p>
<p> We propose a plug-and-play fine-tuning paradigm, named SGFT, for enhancing the reasoning capabilities of SLMs.Using only a small amount of SG training data, SGFT can fine-tune a SLM to generate accurate problemsolving guidances.These guidances can then be flexibly used as input prompts for any SLM, allowing it to directly produce correct answers.</p>
<p> Experiments on multiple reasoning benchmarks datasets demonstrate that our method significantly improve the reasoning capabilities of various SLMs.Our approach can be implemented on a single consumer-grade GPU, and achieve better performance with only 3% of the training data required by CoT fine-tuning.</p>
<p>Related Work</p>
<p>Chain-of-Thought Reasoning.In prompt engineering, Chain-of-Thought (CoT) (Wei et al., 2022) has shown excellent performance in reasoning tasks for large models.The method of automatically generating CoT prompts (Zhang et al., 2022) uses similarity-based retrieval methods, improving the performance of large language models in zero-shot reasoning tasks.Diao et al. (2023) combine active prompting with CoT, incorporating uncertainty measures and self-consistency methods to enhance the accuracy and consistency of reasoning.Turpin et al. (2023) believe that the chain of thought explanation is sometimes unreasonable.Wang et al. (2023) introduce the knowledge chain prompting method, which boosts the reasoning abilities of language models, and proposed a post-validation mechanism to ensure the accuracy of the reasoning chain.Wang et al. (2022) propose to replace greedy decoding with self-consistency, which further improves the effectiveness of CoT.Analyzing incorrect answers in-depth (Zhong et al., 2024), by adjusting the CoT for erroneous cases, encourages large language models to better understand the problems and utilize critical information for improved reasoning.Chae et al. (2024) decompose the reasoning process of language modeling into two steps Think-and-Execute improves the reasoning.Thought-of-Tree (ToT) (Yao et al., 2023) builds on the Chain of Thought approach for more complex planning of tasks.</p>
<p>Distillation of Reasoning Ability.Small models have much smaller internal mapping space compared to large models.Despite this, small models still possess certain reasoning abilities (Fu et al., 2023).Our focus is on leveraging these abilities to solve complex problems.Ho et al. (2022) first propose using large-scale language models (such as GPT-3 175B) as teacher models, generating CoT to fine-tune smaller student models.This approach significantly reduces the model size requirements and greatly enhances the performance of small models on complex reasoning tasks.Subsequent work has further refined the CoT fine-tuning method for small models (Magister et al., 2022).Li et al. (2022) propose a multi-task learning framework to enable small models to acquire reasoning abilities and generate explanations.Fu et al. (2023) specialize the training of small models, enhancing multi-step mathematical reasoning tasks.Researchers (Choi and Ahn, 2024) demonstrate that fine-tuned small models can achieve results comparable to large language models in specific domains.This has significant implications for resource optimization in practical applications.Article (Zhu et al., 2023) provide a summary of quantization, distillation, and other methods applied to large language models.</p>
<p>Method</p>
<p>As Figure 2 shows, our approach consists of the following steps: solution guidance generation, solution-guidance fine-tuning, and collaborative inference of SLMs based on SG.Specifically, GPT-4o is employed as the teacher model to assist in solution guidance generation.With the generated SG data, we fine-tune a SLM to break down complex problems into a series of manageable solution steps.Then, the generated solution guidances, as well as the original question, are passed to another SLM to generate the final answer without extra training.</p>
<p>Solution Guidance Generation</p>
<p>In fine-tuning large language models, the quality and structure of training data are critical.While traditional data such as CoT has proven effective for many tasks, it still presents certain limitations.This chapter introduces a new type of training data SG, and the method for its generation.Using GPT-4 as the teacher model, we generate data that differs from traditional CoT.We will examine the principles, implementation details, and advantages of this approach in terms of reducing noise and improving data quality.</p>
<p>Data Paradigm Setup.First, we randomly selected a subset of 2,000 questions from the GSM8K training set, referred to as Q = {q i } N , and the corresponding Solution Guidance for these questions, denoted as
d i , D = {d i } N forming the set SG. Therefore, G = {(q i , d i )} N is a datasets contain- ing N training instances.
We conducted a detailed error analysis of CoT method, found that incorrect answers mainly stem from inaccurate solution objectives, calculation errors, and logical flaws.To address these, we experimented and identified that correct step decomposition and sequencing are crucial for high-quality LM responses.Based on this, we defined SG's structure, which contains step-bystep solution objectives and their sequence.Then, we prompted GPT-4o to generate more SG training data based on this structure.Our goal is to identify one or more recurring patterns across different questions.Rather than meticulously analyzing and solving each question individually, we extract commonalities in mathematical reasoning problems to derive general solution steps.The fine-tuned model is then used to analyze each question specifically.For example, a typical pattern might be: "Step 1: Identify the primary problem, Step 2: Determine the necessary operations on specific values, Step 3: ...".The fine-tuning task focuses on learning this process, with the procedural patterns also originating from GPT-4.</p>
<p>Generation SG Data from LLM.The Solution Guidance (SG) we introduce is a novel concept.For Prompts for finetuning on SLM prompt_iv: Please generate a step-by-step solution for the following problem with no calculations.You don't need to solve it, just output the steps in 2 to 6 steps.prompt_v: Please generate a step-by-step solution for the following problem with no calculations.You don't need to solve it, just output the steps in 2 to 6 steps.Examples for the SG data are as follows :
[Q1+SG1]...[Q3+SG3]
Table 1: The table presents the prompts used in different stages.We employed prompt_i and prompt_ii to generate individual pieces of data from GPT-4o.Subsequently, we used prompt_iii to generate SG data in batches.Prompt_iv and prompt_v were selected as the prompts for adopting the context strategy and the few-shot approach during fine-tuning.the questions in the training set, we form a set of questions Q = {q i } M , and input each question into GPT-4o, prompting it to output the process of solving the problem.At this point, GPT-4o outputs M processes e i , and answers a i (in our experiments, we used M = 7).After verifying the correctness of the answers, we denote E = {(q i , e i , a i )} M .Table 1 presents the prompts that we utilized, we employed prompt_i and prompt_ii to obtain the original SG.</p>
<p>We then examine whether these processes e i , exhibit any consistency or regularity and summarize the patterns identified.Based on the responses, we outline the problem-solving pattern as follows: "1.Identify the total requirements and known information; 2. Solve step-by-step, setting intermediate goals and calculating their values; 3. Summarize all intermediate results and perform unit conversions; 4. Arrive at the final answer and verify it."Subsequently, we used prompt_iii in the Table 1 to generate the SG for question q i based on this pattern as d i .Examples of the data are shown in the Table 2, resulting in G = {(q i , d i )} N as the training data.</p>
<p>It is evident that our SG differs from the original CoT approach.While CoT emphasizes a step-bystep solution, including specific calculations for each problem, SG offers higher-level guidance.SG focuses on providing a framework for problemsolving rather than detailing the exact computational process.</p>
<p>Data Cleaning.In the generated datasets, we manually replaced some instances involving specific numerical calculations to ensure that the datasets focuses on problem understanding and textual logical reasoning.We also removed data related to pure mathematical calculations, as numerical computation is not the capability we aim to generalize.</p>
<p>Question Solution Guidance</p>
<p>Bailey starts with a certain amount of money.Then she receives a weekly allowance of $5 for 8,00 weeks.At the end of the 8,00 weeks, if she has a total of $100,how much money did Bailey start with?</p>
<p>Step 1: Calculate the total amount of allowance Bailey receives in 8 weeks.</p>
<p>Step 2: Calculate the amount of money Bailey started with.</p>
<p>A classroom has a whiteboard which is shared between the 4 teachers who take turns using the classroom.Each teacher has 2 lessons per day and uses the whiteboard in each lesson.If the whiteboard is cleaned 3 times per lesson, how many times is the whiteboard cleaned in a day?</p>
<p>Step 1: Calculate the total number of lessons in a day.</p>
<p>Step 2: Calculate the total number of times the whiteboard is cleaned in a day.</p>
<p>An interior design firm offers installation for $129.00.It includes hanging 4 mirrors, 2 shelves, 1 chandelier, and 10 pictures.They will install additional items for an extra $15.00 per item.Angela has 6 mirrors and 2 chandeliers and 20 pictures that she needs installed/hung.How much will this cost her?</p>
<p>Step 1: Determine the base installation cost.</p>
<p>Step 2: Determine the number of items included in the base installation service.</p>
<p>Step 3: Calculate the number of additional items Angela needs installed.</p>
<p>Step 4: Calculate the cost for the additional items.</p>
<p>Step 5: Calculate Angela's total cost.</p>
<p>Solution-Guidance Fine-Tuning (SGFT)</p>
<p>After acquiring the SG data, we focus on transferring the data generation capability to smaller models.We explore fine-tuning strategies and analyze the effects of incorporating contextual information, as well as zero-shot and few-shot examples, on model performance.Notably, our fine-tuning approaches and reasoning tasks can be executed on consumer-grade GPUs.</p>
<p>Fine-Tuning Method Based on LISA.Recent work by Pan et al. (2024) revealed that LoRA's (Hu et al., 2021) fine-tuning primarily targets the lowest and highest layers of large language models (LLMs), specifically the embedding and linear head layers.Building on this insight, the LISA method was proposed, which significantly reduces GPU memory consumption by selectively freezing certain layers using layer-wise importance sampling during training.For a 7B model, LISA demonstrates a training speed approximately 1.5 times faster than LoRA.</p>
<p>LISA employs a regularization loss function based on the AdamW optimizer, ensuring training stability while effectively leveraging the layer-wise importance sampling strategy.The objective function optimized by LISA includes a regularization term and is formulated as follows:
f reg (w) = f (w) + 1 2 w T Sw(1)
In this context, S is a finite positive semi-definite diagonal matrix, and w represents the model parameters.This regularization term helps control the model's complexity and prevents overfitting.LISA has the following convergence guarantee during optimization, where f * reg represents the optimal value of f reg :
1 T T t=1 f reg (w t )  f * reg  O 1  T(2)
To optimize fine-tuning efficiency and balance computational resources, we adopted this advanced fine-tuning method.By adjusting only a small number of parameters, this approach enables effective fine-tuning even with limited computational resources.</p>
<p>Improvements in Fine-Tuning Based on Prompt Engineering.Our experiments demonstrated that incorporating context during fine-tuning significantly influenced the model's behavior.For example, when fine-tuning without contextual prompts using only the data G = {(q i , d i )} N , the model unexpectedly generated specific numerical calculations and final answers, despite this not being the intended output at that stage.By introducing contextual prompt_iv or prompt_v in the Table 1, the training data was modified to G  = {( prompt + q i , d i )} N , leading the model to generate problem-solving steps rather than final answers.These findings were validated through our experimental results.</p>
<p>We conducted a series of experiments to assess the impact of different contexts on model performance.Specifically, we tested various contextual configurations (Dong et al., 2023)</p>
<p>Collaborative Inference of Small Models</p>
<p>After fine-tuning the smaller model, our approach enables the model to generate solution guidance rather than directly solving problems.Its role is to parse each input problem and generate the corresponding SG, which is then inputted, along with the original problem, into a response model.This response model can be any generalized language model; In our case, we chose a model with fewer than 10B parameters that had not been fine-tuned for specific tasks, such as a base or chat small model.By leveraging the synergy between our Model_SG and the language model, we significantly improved accuracy on mathematical and common-sense reasoning datasets compared to the original model.This division of labor allows the models to retain their general capabilities while efficiently addressing complex reasoning tasks.In our experiments, we compared the performance of an untuned small model serving as the guidance model with a single fine-tuned model responsible for both guidance and answer generation.The results confirmed that our approach, which separates these tasks, is more effective overall.</p>
<p>Our model can be fine-tuned and deployed using a single consumer-grade GPU, yielding superior results compared to traditional Chain-of-Thought (CoT) fine-tuning.This opens up new possibilities for researchers to explore the potential of small language models, even when working with constrained computational resources.</p>
<p>Experiments</p>
<p>Experimental Setup</p>
<p>Training Data: Following the method outlined by Brown et al. (2020), we randomly selected 7 questions from the GSM8K training set.Using the prompting procedure detailed in the previous, we tasked GPT-4o with generating problem-solving guidance (SG).We then input these 7 questions into GPT-4o to obtain their corresponding SG.Afterward, both the original questions and their SG were fed back into GPT-4o to generate the final answers.Once the answers were verified for accuracy, these 7 questions and their SG were used as few-shot examples for the large model.Then we randomly selected 1000, 2000, and 3000 questions from the GSM8K training set, instructing the large model to generate SG for each.This process provided the necessary training data.We then used the format of original questions plus SG to generate the final answers.Any data with incorrect answers was removed to ensure the training datasets maintained a high level of accuracy.Inference Tasks: For mathematical application problems, we used GSM8K (Cobbe et al., 2021), SVAMP (Patel et al., 2021), and MultiArith (Roy and Roth, 2016).For commonsense reasoning questions, we used CommonsenseQA (Talmor et al., 2019) and StrategyQA (Geva et al., 2021).These datasets are commonly employed to assess the reasoning capabilities of LLMs.Our evaluation metric is the accuracy on each dataset.Notably, GSM8K represents an in-distribution dataset, while the remaining datasets are out-of-distribution, providing a more diverse test of the model's generalization abilities.</p>
<p>Language Models: From the perspective of model distillation, we used GPT-4o as the teacher model.The student models included qwen2-7B-Instruct (Chu et al., 2024), chatglm3-6B-Instruct (Zeng et al., 2024), and llama2-7B-chat (Touvron Table 4: We compared the effects of different finetuning strategies across three datasets, using the following variables: no context, context with zero samples, and context with 3 samples.SG* refers to the model fine-tuned using SG as the guide model, with the original version of the same model serving as the response model.</p>
<p>et al., 2023).To maintain consistent outputs, the temperature was set to 0 for all models.We performed cross-model inference, using different models to generate SG and final answers.For baselines, we compared with the zero-shot outputs of each instruction-tuned small model.</p>
<p>Main Results</p>
<p>As shown in Table 3, the collaborative inference method for small models improves their ability to solve complex mathematical reasoning tasks.</p>
<p>Across various mathematical and textual reasoning datasets, our approach significantly boosts accuracy.Traditional CoT fine-tuning requires large datasets and tends to focus too narrowly on individual problems, limiting its ability to generalize problem-solving patterns.In contrast, our method uses one model for high-level guidance-understanding the problem and providing strategies-while the other model generates answers based on this guidance.This division of tasks creates an efficient problem-solving process while preserving the general capabilities often lost in fine-tuning.</p>
<p>Traditional CoT methods and our approach differ in the scale of training data.As shown in Figure 3, under the same fine-tuning strategy, our method requires only 3.3% of the data used by CoT to achieve superior performance.This greatly reduces the computational cost for fine-tuning and lowers the barrier for practical application.We compared performance across datasets with 1,000 to 3,000 Question: The cheese pizza is cut into 12 slices and the pepperoni pizza is cut into 8 slices.If Kate's 6 friends each eat 6 cheese pizza slices and 4 pepperoni pizza slices, how many pizza pies does she need to buy? Correct answer: 6 CoT Answer: If Kate's 6 friends each eat 6 cheese pizza slices, then they eat a total of 6 x 6 = 36 cheese pizza slices.If Kate's 6 friends each eat 4 pepperoni pizza slices, then they eat a total of 4 x 6 = 24 pepperoni pizza slices.In total, Kate's friends eat 36 + 24 = 60 pizza slices.Since each pizza pie is cut into 12 slices for cheese pizza and 8 slices for pepperoni pizza, Kate needs to buy 60 / 12 = 5 cheese pizza pies.She also needs to buy 60 /8=7 pepperoni pizza pies.Therefore, Kate needs to buy a total of 5 + 7 = 12 pizza pies.The answer is: 12 Ours Solution Guidance(SG):</p>
<p>Step 1: Calculate the total number of cheese pizza slices needed per person.</p>
<p>Step 2: Calculate the total number of pepperoni pizza slices needed per person.</p>
<p>Step 3: Calculate the total number of cheese pizzas needed.</p>
<p>Step 4: Calculate the total number of pepperoni pizzas needed.</p>
<p>Step 5: Sum up the total number of pizzas needed.Answer:</p>
<p>Step 1: Calculate the total number of cheese pizza slices needed per person.Kate's 6 friends each eat 6 cheese pizza slices, so the total number of cheese pizza slices needed is 6 friends * 6 slices/friend = 36 slices.</p>
<p>Step 2: Calculate the total number of pepperoni pizza slices needed per person.Kate's 6 friends each eat 4 pepperoni pizza slices, so the total number of pepperoni pizza slices needed is 6 friends * 4 slices/friend= 24 slices.</p>
<p>Step 3: Calculate the total number of cheese pizzas needed.Since each cheese pizza has 12 slices, the total number of cheese pizzas needed is 36 slices / 12 slices/pizza = 3 pizzas.</p>
<p>Step 4: Calculate the total number of pepperoni pizzas needed.Since each pepperoni pizza has 8 slices, the total number of pepperoni pizzas needed is 24 slices / 8 slices/pizza = 3 pizzas.</p>
<p>Step 5: Sum up the total number of pizzas needed.The total number of pizzas is 3 cheese pizzas + 3 pepperoni pizzas = 6 pizzas.The answer is: 6 training examples, noting that accuracy improved with more data.This suggests that our approach has greater potential than traditional CoT methods.</p>
<p>Ablation Study</p>
<p>In this section, we conducted a detailed ablation study to evaluate the effectiveness of finetuning models using SG.Consistently following our method, the first model generates SG, while the second model provides the answers.We tested four strategies: (1) Two untrained models directly for collaborative inference.(2) One untrained model for guidance and a CoT-fine-tuned model for answering.(3) One SG-fine-tuned model for guidance and a untrained model for answering.(4) One SG-fine-tuned model for guidance and a CoT-finetuned model for answering.</p>
<p>As shown in Figure 4, the optimal setup was using an SG-fine-tuned model for guidance and an untrained model for answering.The results suggest that SG-trained models offer better Solution Guidance, leading to more accurate answers from the response model.However, when the CoT model served as the response model, its performance was worse compared to the original model.</p>
<p>Comparison among In-context Learning</p>
<p>and Few-shot / Zero-shot Learning</p>
<p>We further explore the effects of in-context (with prompt_iv in the Table 1), zero-shot, and few-shot examples (3-shot, with prompt_v in the Table 1)</p>
<p>during fine-tuning on the performance of SG small model collaborative inference.</p>
<p>In Table 4, we found that when using our method for fine-tuning, the model's performance was consistently worse with the zero-shot no-context strategy compared to training with context.Training with context yielded better results, and increasing the number of examples further improved performance.However, due to equipment and time constraints, we limited our experiments to a maximum of 3-shot examples.The experimental results indicate that the context plus few-shot strategy is the most effective.</p>
<p>Case Study</p>
<p>Table 5 presents a test case from the GSM8K dataset where the traditional CoT approach causes the model to generate language logic and perform calculations simultaneously.This results in a misunderstanding of the problem, leading to computational errors and an incorrect answer.In contrast, our method first generates a solution plan (SG) for the problem and then performs calculations based on this plan.This structured approach allows the model to focus on distinct tasks, improving problem logic and ultimately producing a more accurate answer.</p>
<p>Table 6 shows Our method is also effective in common-sense reasoning problems.SG forms a complete problem-solving path, which includes analyzing the purpose of the problem, the differences Question: Where is there a telephone book in almost every room ?A). at hotel; B). house; C). library; D). bedsit; (E).closet; Correct answer: A Ours Solution Guidance(SG):</p>
<p>Step 1: Analyze the question to understand the context and identify the key concept, which is "a place where a telephone book is commonly found in almost every room."</p>
<p>Step 2: Examine the provided choices (hotel, house, library, bedsit, closet) and consider the relevance of each option to the key concept.</p>
<p>Step 3: Evaluate each option based on common knowledge about the presence of telephone books in different types of rooms.</p>
<p>Step 4: Determine the best answer based on the evaluation and reasoning.Answer:</p>
<p>Step 1: The question is asking where one would commonly find a telephone book in almost every room.The key concept here is the widespread availability of a telephone book within a certain type of space.</p>
<p>Step 2: Let's examine the choices: A) At hotel: Hotels often provide guests with a telephone book in each room for convenience.B) House: Telephone books are not typically found in every room of a house, but rather in a common area such as a room or kitchen.C) Library: Libraries do not have telephone books in every room, as they are typically found in reference sections or at the information desk.D) Bedsit: A bedsit, which is a single room that serves as both a bedroom and a sitting room, might have a telephone book, but this is not a guarantee in every bedsit.E) Closet: A closet is not a place where one would expect to find a telephone book.</p>
<p>Step 3: Based on common knowledge, hotels are known to provide a telephone book in each room as part of their hospitality services.Houses and libraries do not have telephone books in every room, and closets are not places where telephone books are stored.Bedsits, while they could have a telephone book, do not guarantee one in every room.</p>
<p>Step 4: The best answer, considering the widespread availability of telephone books in hotels, is A) At hotel.The answer is: A among various options, and evaluating each option.Based on the guidance of the SG, the model can obtain the final answer.</p>
<p>Conclusion</p>
<p>This paper proposes a new plug-and-play training paradigm Solution-Guidance Fine-Tuning (SGFT) for improving the reasoning capabilities of small language models, without relying on large amounts of Chain-of-Thought (CoT) training data.Experimental results demonstrate that the proposed approach significantly enhances SLMs' performance in mathematical and common-sense reasoning tasks while maintaining their general capabilities.A new reasoning strategy Solution Guidance (SG) is introduced, which emphasizes problem understanding and decomposition, reducing noise from calculation steps in traditional CoT data.Experiments show that using 1,000 pieces of SG data outperform 30,000 pieces of CoT data.</p>
<p>Limitations</p>
<p>In our work, we aimed to enhance the model's reasoning capabilities while preserving its original abilities, so we chose not to focus on smaller-scale models.Some researchers have found that even smaller models, when fine-tuned, can develop certain mathematical reasoning abilities.Future work could explore using smaller models (&lt;3B) as guidance models.We also observed that many studies employ diverse path reasoning, which can effectively improve answer accuracy.Applying this to our method would involve generating multiple SG for each question, then selecting the final answer based on the most consistent output across all SG.However, given our current computational limitations, we plan to explore these methods further in future work.</p>
<p>Figure 1 :
1
Figure 1: A wrong case of existing CoT reasoning.</p>
<p>Figure 2 :
2
Figure 2: The figure illustrates the complete architecture of our approach.In this diagram, SLM denotes the Small Language Model, LLM represents the Large Language Model, and SG (Solution Guidance) refers to the data schema introduced in our method.</p>
<p>Figure 3 :
3
Figure 3: Relationship between the amount of training data required by the CoT method and our method and the accuracy on the GSM8K data set, with the x-axis representing the amount of data and the y-axis representing the accuracy.</p>
<p>Figure 4 :
4
Figure 4: Comparison of the accuracy of four strategies for collaborative reasoning with small models, M represents an original model, M_CoT represents a model fine-tuned with CoT, and M_SG represents a model finetuned with SG.Test results on the GSM8K dataset.</p>
<p>Table 2 :
2
Examples of training data paradigms in our approach.</p>
<p>Table 3 :
3
, ranging from short to long contexts, and observed that appropriate context settings significantly improved task We conducted accuracy comparisons across five datasets related to reasoning, using the original SLM version as a baseline.We compared the performance of the original model, the Fine-tune-CoT method (fine-tuned with 30,000 CoT samples), and our method (fine-tuned with 3,000 SG samples).Additionally, we evaluated the models across different smaller-scale versions.All experiments in the comparison table utilized zero-shot prompting.
ModelGSM8K SVAMP MultiArith StrategyQA CommonsenseQAChatGLM3-6B27.440.853.862.358.1ChatGLM3-6B_CoT34.447.562.169.564.9ChatGLM3-6B_SG+ChatGLM3-6B43.751.267.472.769.8Qwen2-7B23.632.450.264.159.2Qwen2-7B_CoT31.237.257.270.364.4Qwen2-7B_SG+Qwen2-7B39.445.761.472.368.7Llama2-7B13.338.048.356.452.9Llama2-7B_CoT21.843.452.660.657.3Llama2-7B_SG+Llama2-7B28.647.857.464.862.1Llama2-7B_SG+ChatGLM3-6B38.146.661.969.464.3Llama2-7B_SG+Qwen2-7B35.443.858.266.262.7ChatGLM3-6B_SG+Llama2-7B39.647.964.771.768.2ChatGLM3-6B_SG+Qwen2-7B40.250.365.470.267.4Qwen2-7B_SG+Llama2-7B42.749.167.873.669.3Qwen2-7B_SG+ChatGLM3-6B48.357.872.979.875.7
completion.In addition, we examined the effects of zero-shot and few-shot examples.Zero-shot tasks were performed without any examples, whereas few-shot tasks included a limited number of examples.Our training data combined task context with sample examples, and the results showed that few-shot examples consistently led to better model performance than zero-shot examples.Due to hardware constraints, the maximum number of examples was limited to three.</p>
<p>Table 5 :
5
A test example where CoT fine-tuning method provides an incorrect answer.Our models generated SG and replied with the correct answer based on the SG.</p>
<p>Table 6 :
6
A test example from CommonsenseQA.</p>
<p>Code and data available at https://github.com/ BiJings/SGFT.
AcknowledgementsThis work is supported by the National Natural Science Foundation of China under Grant 62406022.
Language models are few-shot learners. Tom B Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M Ziegler, Jeff Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, ArXiv, abs/2005.14165Ilya Sutskever, and Dario Amodei. Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford2020Ma teusz Litwin</p>
<p>Language models as compilers: Simulating pseudocode execution improves algorithmic reasoning in language models. Hyungjoo Chae, Yeonghyeon Kim, Seungone Kim, Kai Tzu Iunn, Beong Ong, Moohyeon Woo Kwak, Seonghwan Kim, Taeyoon Kim, Jiwan Kwon, Youngjae Chung, Jinyoung Yu, Yeo, ArXiv, abs/2404.025752024</p>
<p>Can only llms do reasoning?: Potential of small language models in task planning. Gawon Choi, Hyemin Ahn, ArXiv, abs/2404.038912024</p>
<p>Yunfei Chu, Jin Xu, Qian Yang, Haojie Wei, Xipin Wei, Zhifang Guo, Yichong Leng, Yuanjun Lv, Jinzheng He, Junyang Lin, Chang Zhou, Jingren Zhou, ArXiv, abs/2407.10759Qwen2-audio technical report. 2024</p>
<p>Training verifiers to solve math word problems. Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, Christopher Hesse, John Schulman, ArXiv, abs/2110.141682021</p>
<p>Active prompting with chainof-thought for large language models. Shizhe Diao, Pengcheng Wang, Yong Lin, Xiang Liu, Tong Zhang, Annual Meeting of the Association for Computational Linguistics. 2023</p>
<p>A survey for in-context learning. Qingxiu Dong, Lei Li, Damai Dai, Ce Zheng, Zhiyong Wu, Baobao Chang, Xu Sun, Jingjing Xu, Lei Li, Zhifang Sui, ArXiv, abs/2301.002342023</p>
<p>Specializing smaller language models towards multi-step reasoning. Yao Fu, Hao-Chun, Litu Peng, Ashish Ou, Tushar Sabharwal, Khot, ArXiv, abs/2301.127262023</p>
<p>Did aristotle use a laptop? a question answering benchmark with implicit reasoning strategies. Mor Geva, Daniel Khashabi, Elad Segal, Tushar Khot, Dan Roth, Jonathan Berant, Transactions of the Association for Computational Linguistics. 92021</p>
<p>Large language models are reasoning teachers. Namgyu Ho, Laura Schmid, Se-Young Yun, Annual Meeting of the Association for Computational Linguistics. 2022</p>
<p>Lora: Low-rank adaptation of large language models. J Edward Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Weizhu Chen, ArXiv, abs/2106.096852021</p>
<p>Large language models are zero-shot reasoners. Takeshi Kojima, Shane Shixiang, Machel Gu, Yutaka Reid, Yusuke Matsuo, Iwasawa, ArXiv, abs/2205.119162022</p>
<p>Measuring faithfulness in chainof-thought reasoning. Tamera Lanham, Anna Chen, Ansh Radhakrishnan, Benoit Steiner, Carson E Denison, Danny Hernandez, Dustin Li, Esin Durmus, Evan Hubinger, John Kernion, Kamil, Karina E Lukovsiut, Newton Nguyen, Nicholas Cheng, Nicholas Joseph, Oliver Schiefer, Robin Rausch, Sam Larson, Sandipan Mccandlish, Saurav Kundu, Shannon Kadavath, Tom Yang, Timothy D Henighan, Timothy Maxwell, Tristan Telleen-Lawton, Zac Hume, Jared Hatfield-Dodds, Janina Kaplan, Sam Brauner, Ethan Bowman, Perez, ArXiv, abs/2307.137022023</p>
<p>Explanations from large language models make small reasoners better. Shiyang Li, Jianshu Chen, Yelong Shen, Zhiyu Chen, Xinlu Zhang, Zekun Li, Hong Wang, Jingu Qian, Baolin Peng, Yi Mao, Wenhu Chen, Xifeng Yan, ArXiv, abs/2210.067262022</p>
<p>A survey of deep learning for mathematical reasoning. Pan Lu, Liang Qiu, Wenhao Yu, Sean Welleck, Kai-Wei Chang, ArXiv, abs/2212.105352022</p>
<p>Teaching small language models to reason. Lucie Charlotte Magister, Jonathan Mallinson, Jakub Adamek, Eric Malmi, Aliaksei Severyn, ArXiv, abs/2212.084102022</p>
<p>Lila: A unified benchmark for mathematical reasoning. Swaroop Mishra, Matthew Finlayson, Pan Lu, Leonard Tang, Sean Welleck, Chitta Baral, Tanmay Rajpurohit, Oyvind Tafjord, Ashish Sabharwal, Peter Clark, A Kalyan, ArXiv, abs/2210.175172022</p>
<p>Lisa: Layerwise importance sampling for memory-efficient large language model fine-tuning. Rui Pan, Xiang Liu, Shizhe Diao, Renjie Pi, Jipeng Zhang, Chi Han, Tong Zhang, ArXiv, abs/2403.179192024</p>
<p>Are nlp models really able to solve simple math word problems?. Arkil Patel, S Bhattamishra, Navin Goyal, North American Chapter. the Association for Computational Linguistics. 2021</p>
<p>Reasoning with language model prompting: A survey. Shuofei Qiao, Yixin Ou, Ningyu Zhang, Xiang Chen, Yunzhi Yao, Shumin Deng, Chuanqi Tan, Fei Huang, Huajun Chen, ArXiv, abs/2212.095972022</p>
<p>Solving general arithmetic word problems. Subhro Roy, Dan Roth, ArXiv, abs/1608.014132016</p>
<p>Commonsenseqa: A question answering challenge targeting commonsense knowledge. Alon Talmor, Jonathan Herzig, Nicholas Lourie, Jonathan Berant, ArXiv, abs/1811.009372019</p>
<p>Hugo Touvron, Louis Martin, Kevin R Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, Daniel M Bikel, Lukas Blecher, Cantn Cristian, Moya Ferrer, Guillem Chen, David Cucurull, Jude Esiobu, Jeremy Fernandes, Wenyin Fu, Brian Fu, Cynthia Fuller, Vedanuj Gao, Naman Goswami, Anthony S Goyal, Saghar Hartshorn, Rui Hosseini, Hakan Hou, Marcin Inan, Viktor Kardas, Madian Kerkez, Isabel M Khabsa, A V Kloumann, Punit Korenev, Marie-Anne Singh Koura, Thibaut Lachaux, Jenya Lavril, Diana Lee, Yinghai Liskovich, Yuning Lu, Xavier Mao, Todor Martinet, Pushkar Mihaylov, Igor Mishra, Yixin Molybog, Andrew Nie, Jeremy Poulton, Rashi Reizenstein, Kalyan Rungta, Alan Saladi, Ruan Schelten, Eric Michael Silva, R Smith, Xia Subramanian, Binh Tan, Ross Tang, Adina Taylor, Jian Williams, Puxin Xiang Kuan, Zhengxu Xu, Iliyan Yan, Zarov, ArXiv, abs/2307.09288Yuchen Zhang, Angela Fan. Melanie Kambadur, Sharan Narang; Robert Stojnic, Sergey EdunovAurelien Rodriguezand Thomas Scialom. 2023. Llama 2: Open foundation and fine-tuned chat models</p>
<p>Language models don't always say what they think: Unfaithful explanations in chain-ofthought prompting. Miles Turpin, Julian Michael, Ethan Perez, Sam Bowman, ArXiv, abs/2305.043882023</p>
<p>Boosting language models reasoning with chain-of-knowledge prompting. J Wang, Qiushi Sun, Nuo Chen, Xiang , Lorraine Li, Ming Gao, ArXiv, abs/2306.064272023</p>
<p>Selfconsistency improves chain of thought reasoning in language models. Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Huai Hsin, Chi , Denny Zhou, ArXiv, abs/2203.111712022</p>
<p>Chain of thought prompting elicits reasoning in large language models. Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Ed Huai Hsin Chi, F Xia, Quoc Le, Denny Zhou, ArXiv, abs/2201.119032022</p>
<p>Language models as inductive reasoners. Zonglin Yang, Li Dong, Xinya Du, E Hao Cheng, Xiaodong Cambria, Jianfeng Liu, Furu Gao, Wei, ArXiv, abs/2212.109232022</p>
<p>Tree of thoughts: Deliberate problem solving with large language models. Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Thomas L Griffiths, Yuan Cao, Karthik Narasimhan, ArXiv, abs/2305.106012023</p>
<p>Team Glm, Aohan Zeng, Bin Xu, Bowen Wang, Chenhui Zhang, Da Yin, Diego Rojas, Guanyu Feng, Hanlin Zhao, Hanyu Lai, Hao Yu, Hongning Wang, Jiadai Sun, Jiajie Zhang, Jiale Cheng, Jiayi Gui, Jie Tang, Jing Zhang, Juanzi Li, Lei Zhao, Lindong Wu, Lucen Zhong, Ming Yue Liu, Minlie Huang, Peng Zhang, Qinkai Zheng, Rui Lu, Shuaiqi Duan, Shudan Zhang, Shulin Cao, Shuxun Yang, Weng Lam Tam, Wenyi Zhao, Xiao Liu, Xiaoyu Xia, Xiaohan Zhang, Xiaotao Gu, Xin Lv, Xinghan Liu, Xinyi Liu, Xinyue Yang, Xixuan Song, Xunkai Zhang, Yi An, Yifan Xu, Yilin Niu, Yuantao Yang, Yueyan Li, Yushi Bai, Yuxiao Dong, Zehan Qi, Zhaoyu Wang, Zhenyi Yang, Zhengxiao Du, ArXiv, abs/2406.12793Zhen-Ping Hou, and Zihan Wang. 2024. Chatglm: A family of large language models from glm-130b to glm-4 all tools. </p>
<p>Automatic chain of thought prompting in large language models. Zhuosheng Zhang, Aston Zhang, Mu Li, Alexander J Smola, ArXiv, abs/2210.034932022</p>
<p>Achieving &gt;97% on gsm8k: Deeply understanding the problems makes llms better reasoners. Qihuang Zhong, Kang Wang, Ziyang Xu, Juhua Liu, Liang Ding, Bo Du, Dacheng Tao, ArXiv, abs/2404.149632024</p>
<p>A survey on model compression for large language models. Xunyu Zhu, Jian Li, Yong Liu, Can Ma, Weiping Wang, ArXiv, abs/2308.076332023</p>            </div>
        </div>

    </div>
</body>
</html>