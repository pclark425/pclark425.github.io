<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-7679 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-7679</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-7679</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-143.html">extraction-schema-143</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how large language models are used to distill quantitative laws, equations, or functional relationships from collections of scholarly papers, including details of the models, prompting or fine‑tuning approaches, input corpora, extraction methods, types of laws, representation formats, evaluation datasets, metrics, baseline comparisons, validation procedures, and reported performance or limitations.</div>
                <p><strong>Paper ID:</strong> paper-260887174</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2308.06374v1.pdf" target="_blank">Large Language Models and Knowledge Graphs: Opportunities and Challenges</a></p>
                <p><strong>Paper Abstract:</strong> Large Language Models (LLMs) have taken Knowledge Representation -- and the world -- by storm. This inflection point marks a shift from explicit knowledge representation to a renewed focus on the hybrid representation of both explicit knowledge and parametric knowledge. In this position paper, we will discuss some of the common debate points within the community on LLMs (parametric knowledge) and Knowledge Graphs (explicit knowledge) and speculate on opportunities and visions that the renewed focus brings, as well as related research topics and challenges.</p>
                <p><strong>Cost:</strong> 0.012</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <p class="empty-note">No extracted data.</p>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Symbolic knowledge distillation: from general language models to commonsense models <em>(Rating: 2)</em></li>
                <li>LM-KBC: Knowledge base construction from pre-trained language models <em>(Rating: 2)</em></li>
                <li>How can we know what language models know? <em>(Rating: 1)</em></li>
                <li>COMET: Commonsense transformers for automatic knowledge graph construction <em>(Rating: 1)</em></li>
                <li>Knowledgeable or educated guess? revisiting language models as knowledge bases <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-7679",
    "paper_id": "paper-260887174",
    "extraction_schema_id": "extraction-schema-143",
    "extracted_data": [],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Symbolic knowledge distillation: from general language models to commonsense models",
            "rating": 2,
            "sanitized_title": "symbolic_knowledge_distillation_from_general_language_models_to_commonsense_models"
        },
        {
            "paper_title": "LM-KBC: Knowledge base construction from pre-trained language models",
            "rating": 2,
            "sanitized_title": "lmkbc_knowledge_base_construction_from_pretrained_language_models"
        },
        {
            "paper_title": "How can we know what language models know?",
            "rating": 1,
            "sanitized_title": "how_can_we_know_what_language_models_know"
        },
        {
            "paper_title": "COMET: Commonsense transformers for automatic knowledge graph construction",
            "rating": 1,
            "sanitized_title": "comet_commonsense_transformers_for_automatic_knowledge_graph_construction"
        },
        {
            "paper_title": "Knowledgeable or educated guess? revisiting language models as knowledge bases",
            "rating": 1,
            "sanitized_title": "knowledgeable_or_educated_guess_revisiting_language_models_as_knowledge_bases"
        }
    ],
    "cost": 0.011610249999999999,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Large Language Models and Knowledge Graphs: Opportunities and Challenges
11 Aug 2023</p>
<p>Jeff Z Pan 
The University of Edinburgh
United Kingdom</p>
<p>Edinburgh Research Centre
CSI
Huawei Technologies UKUnited Kingdom</p>
<p>Simon Razniewski 
Bosch Center for AI
Germany</p>
<p>Edinburgh Research Centre
CSI
Huawei Technologies UKUnited Kingdom</p>
<p>Jan-Christoph Kalo 
Vrije Universiteit Amsterdam
The Netherlands</p>
<p>Edinburgh Research Centre
CSI
Huawei Technologies UKUnited Kingdom</p>
<p>Sneha Singhania 
Max Planck Institute for Informatics
Germany</p>
<p>Edinburgh Research Centre
CSI
Huawei Technologies UKUnited Kingdom</p>
<p>Jiaoyan Chen 
The University of Manchester &amp; University of Oxford
United Kingdom</p>
<p>Edinburgh Research Centre
CSI
Huawei Technologies UKUnited Kingdom</p>
<p>Stefan Dietze 
GESIS -Leibniz Institute for the Social Sciences &amp; Heinrich-Heine-Universität Düsseldorf
Germany</p>
<p>Edinburgh Research Centre
CSI
Huawei Technologies UKUnited Kingdom</p>
<p>Hajira Jabeen 
GESIS -Leibniz Institute for the Social Sciences
Germany</p>
<p>Edinburgh Research Centre
CSI
Huawei Technologies UKUnited Kingdom</p>
<p>Janna Omeliyanenko 
University of Würzburg
Germany</p>
<p>Wen Zhang 
Zhejiang University
China</p>
<p>Edinburgh Research Centre
CSI
Huawei Technologies UKUnited Kingdom</p>
<p>Matteo Lissandrini 
Aalborg University
Denmark</p>
<p>Edinburgh Research Centre
CSI
Huawei Technologies UKUnited Kingdom</p>
<p>Russa Biswas 
Hasso-Plattner Institute
Germany</p>
<p>Edinburgh Research Centre
CSI
Huawei Technologies UKUnited Kingdom</p>
<p>Gerard De Melo 
Hasso-Plattner Institute
Germany</p>
<p>Edinburgh Research Centre
CSI
Huawei Technologies UKUnited Kingdom</p>
<p>Angela Bonifati 
Lyon</p>
<p>Edinburgh Research Centre
CSI
Huawei Technologies UKUnited Kingdom</p>
<p>Edlira Vakaj 
University
France</p>
<p>Edinburgh Research Centre
CSI
Huawei Technologies UKUnited Kingdom</p>
<p>Mauro Dragoni Fondazione 
Birmingham City University
United Kingdom</p>
<p>ItalyBruno Kessler 
Birmingham City University
United Kingdom</p>
<p>Damien Graux 
Birmingham City University
United Kingdom</p>
<p>Edinburgh Research Centre
CSI
Huawei Technologies UKUnited Kingdom</p>
<p>Mauro Dragoni 
Edinburgh Research Centre
CSI
Huawei Technologies UKUnited Kingdom</p>
<p>Large Language Models and Knowledge Graphs: Opportunities and Challenges
11 Aug 2023A745B859D818EE2D70E20052E76DE46810.1234/0000000.00000000arXiv:2308.06374v1[cs.AI]Received Date of submission Accepted Date of acceptance Published Date of publishing Editor Editor NamePhrases Large Language ModelPre-trained Language ModelKnowledge GraphOntologyRetrieval Augmented Language Models Digital Object Identifier 10.1234/0000000.00000000
Large Language Models (LLMs) have taken Knowledge Representation-and the world-by storm.This inflection point marks a shift from explicit knowledge representation to a renewed focus on the hybrid representation of both explicit knowledge and parametric knowledge.In this position paper, we will discuss some of the common debate points within the community on LLMs (parametric knowledge) and Knowledge Graphs (explicit knowledge) and speculate on opportunities and visions that the renewed focus brings, as well as related research topics and challenges.</p>
<p>Introduction</p>
<p>Large Language Models (LLMs) have taken Knowledge Representation (KR)-and the worldby storm, as they have demonstrated human-level performance on a vast spectrum of natural language tasks, including some tasks requiring human knowledge.Following this, people are gradually starting to accept the possibility of having knowledge represented in the parameters of some language models.The arrival of LLMs announces the era of Knowledge Computing, in which the notion of reasoning within KR is broadened to many computation tasks based on various knowledge representations.This is a big step for the field of Knowledge Representation.For a long time, people focused on explicit knowledge, such as those embedded in texts, sometimes also known as unstructured data, and those in a structured form, such as in databases and knowledge graphs (KGs) [123].Historically, for a long time, humans used texts to pass down their knowledge from one generation to another, until around the 1960s, when researchers started to study knowledge representation for better natural language understanding and developed early systems, such as ELIZA [180] at the MIT.In the early 2000s, the Knowledge Representation and the Semantic Web communities worked together to standardize the widely used knowledge representation languages, such as RDF [121] and OWL [55], at web scale, using which the large-scale knowledge bases are then more widely known as KGs [123], due to their helpful graph structures, enabling the both logical reasoning and graph-based learning.</p>
<p>This inflection point, with the arrival of LLMs, marks a paradigm shift from explicit knowledge representation to a renewed focus on the hybrid representation of both explicit knowledge and parametric knowledge.As a popular approach for explicit knowledge representation, KGs are now widely investigated for the combination with Transformer-based LLMs, including pre-trained masked language models (PLMs) like BERT [39] and RoBERTa [104], and more recent generative LLMs like the GPT series [23] and LLaMA [165].Some works use LLMs to augment KGs for, e.g., knowledge extraction, KG construction, and refinement, while others use KGs to augment LLMs for, e.g., training and prompt learning, or knowledge augmentation.In this paper, considering both directions, LLMs for KGs and KGs for LLMs, we present a better understanding of the shift from explicit knowledge representation to a renewed focus on the hybrid representation of both explicit knowledge and parametric knowledge.</p>
<p>A related survey paper [204] presents a comprehensive review of using LLMs for KG construction and reasoning, while our work provides a more in-depth view of the inflection point, considering not only relational KGs but also KGs with ontologies as schemas, as well as other dimensions of structured knowledge, including tabular data [183] and numerical values [122].Other works on the intersection of LLMs and KGs have a minor overlap with the topics covered in our paper; e.g., on studies using LLMs as KGs [5], on using KGs to augment LLMs [185], or on comparing GPT-4 with ChatGPT and SOTA fine-tuning methods on three knowledge-related tasks-entity, relation and event extraction, link prediction, and KG question answering [204].Overall, none of these papers look into the implications of the inflection point with concrete applications.To this end, this paper summarises the common debate points within the community, introduces the state-of-the-art for a comprehensive set of topics where KGs and LLMs are integrated, and further presents opportunities and challenges.</p>
<p>Common Debate Points within the Community</p>
<p>The usage of parametric and explicit knowledge together is a topic of debate in the Knowledge Computing community, with proponents and skeptics offering different perspectives.Below are some summaries of common points of contention.Knowledge Representation and Reasoning: KGs offer a structured representation of knowledge with explicit relationships, enabling reasoning and inference [110].Critics argue that parametric knowledge in LLMs relies on statistical patterns rather than true understanding and reasoning [13].Proponents of LLMs like ChatGPT, highlight their ability to generalize from large-scale text corpora, capturing a range of information, and excellent language understanding capabilities.On the one hand, LLMs could generate plausible but incorrect or nonsensical responses, such as hallucinations, due to a lack of explicit knowledge representation [193].There are also doubts on whether LLMs have the ability to learn directional entailments [96] or infer subsumption between concepts [61].On the other hand, KGs can be costly to build.While LLMs can be expensive to train too, they can be readily usable to support many downstream applications, bringing AI from the backstage to centre stage.Thus parametric knowledge is not the (only) destination for LLMs.To sum up, in comparison to the classic trade-off between expressiveness and decidability in Knowledge Representation, here we have the trade-off between precision and recall considering using explicit and parametric knowledge in Knowledge Computing tasks.</p>
<p>High Precision Methods: The success of KGs can largely be attributed to their ability to provide factual information about entities with high accuracy.For instance, YAGO [154] asserts an accuracy rate exceeding 95%.Similarly, Google necessitates high accuracy in its KG for operational use, e.g., the semi-automatical construction method of Knowledge Vault was not utilized in production, partly due to its inability to reach the desired 99% accuracy in their benchmark [179].Along this line of thought, many LLM-based methodologies for KG completion fail to reach these high-performance levels, as exemplified by the performance of BERT in [97,167], and GPT-3, equipped with hundreds of billions of parameters [4].This calls for novel high precision methods for KG construction based on LLMs.</p>
<p>Numerical Values: It is widely recognized that LLMs grapple with handling numerical values.Even straightforward arithmetic tasks can be a struggle for LMs, as highlighted in a study by .This shortcoming also extends to KG completion tasks [78].Multiple LLMs have been evaluated on their ability to complete KGs using numerical facts from Wikidata [169], such as individuals' birth and death years.However, none of the tested models accurately predicted even a single year.This raises questions about the capability of current LLMs to correctly memorize numbers during pre-training in a way that enables them for subsequent use in KG completion.While LLMs like PaLM [153] demonstrate some proficiency in dealing with numbers, more commonly used smaller models seem ill-equipped for this task.The complexity escalates when considering the intricacies of metrics and diverse numbering formats and types.Currently, modifying LLMs to handle numerical values remains unresolved, making their utilization for numerical KG completion seem far from practical.</p>
<p>Long-tail Knowledge: One of the key research questions on LLMs for the Knowledge Computing community (and beyond) is how much knowledge LLMs remember [107].Investigations indicate that LLMs' performance significantly deteriorates when dealing with random Wikidata facts, specifically those associated with long-tail entities, in comparison to popular entities, as T G D K</p>
<p>42:4</p>
<p>LLMs and KGs: Opportunities and Challenges evidenced in the PopQA dataset [107] and other datasets [133,167].This effect can be traced back to a causal relationship between the frequency of an entity's appearance in the pre-training corpus and the LLMs' capacity for memorization [44].Even sizable LLMs face difficulties when trying to retain information about long-tail entities [80].KGs inherently present an advantage over LLMs through their provision of knowledge about long-tail entities [78, 167] and thus can further help improve the recall for Knowledge Computing tasks.</p>
<p>Bias, Fairness and Beyond: Critics argue that LLMs can perpetuate and amplify biases present in the training data, leading to biased outputs.LLMs may generate biased or prejudiced responses if the training data contains stereotypes or discriminatory information [113,91].On the other hand, proponents argue that bias is not inherent to LLMs but reflects societal biases embedded in the data.They emphasize the importance of addressing bias in the training data and developing mitigation techniques [144,134,140].A survey [16] argued that "bias" in Natural Language Processing (NLP) systems took various conceptualizations without being critically engaged by practitioners.KGs are also used in a plethora of downstream tasks, and social biases engraved in KG embeddings get propagated [56,87].Specifically, ontology creation, which generally comprises manual rules factored by opinions, motivations, and personal choices, is a source of bias [73,43].Also, automated pipelines for KG construction exhibit gender bias [109].There are other similar concerns of LLMs beyond bias and fairness, including (but not limited to) copyright violation and misinformation.In general, due to the implicit nature of parametric knowledge, it is less straight forward to forget such toxic information from LLMs, compared to explicit knowledge.</p>
<p>Explainability and Interpretability: KGs are often preferred in scenarios where explainability and interpretability are crucial [28], as they explicitly represent relationships between entities and provide a structured knowledge representation.Skeptics of LLMs argue that these models lack transparency and interpretability, making it difficult to understand how they arrive at their answers or recommendations.Proponents of LLMs acknowledge the challenge of explainability but argue that recent research efforts [8,72] are improving LLM's interpretability through techniques like attention mechanisms, model introspection.Some also argue that Chain-of-Thoughts (CoT) [177] can also improve the explainability of LLMs, although question decomposition and precisely answering sub-questions with LLMs are still far from being solved.Attribution evaluation and augmentation of LLMs with e.g., source paragraphs and sentences is another recent research topic for improving their explainability in question answering [17].</p>
<p>Opportunities and Visions</p>
<p>One of the key questions this paper needs to answer is, now with the emergence of parametric knowledge, what new opportunities do we have?Here are some of our thoughts on such new opportunities with the arrival of parametric knowledge and its potential integration with explicit knowledge.</p>
<p>Instant access to huge text corpora:</p>
<p>As mentioned in the Introduction, for a long time, human beings passed down their knowledge in texts.Thus, a lot of knowledge these days are in textual form.Using LLMs gives access to extremely large text corpora at high speed, and recently even on consumer hardware [65].This allows AI developers to avoid getting bogged down in previously critical challenges around data gathering, preparation, storage, and querying at scale.It also helps to reduce previously critical dependencies on the field of information retrieval.2. Richer knowledge for many subtasks: Although the most prominent capabilities of LLMs, question answering and dialogue, are still under critical scrutiny, it should not be overlooked</p>
<p>42:5</p>
<p>that LLMs have significantly advanced and simplified many traditional tasks of the knowledge engineering pipeline.Out-of-the-box, with fine-tuning on a few examples, or via few-shot prompting, LLMs have advanced many tasks such as dependency and structured parsing, entity recognition, and relation extraction.And just as errors propagate along a pipeline, so do improvements, thus enabling KG construction at unprecedented scale and quality.Furthermore, LLMs are readily usable for many downstream tasks beyond knowledge engineering.By injecting explicit, and in particular structured, knowledge into LLMs, such as through retrieval augmented methods, one can make explicit knowledge more readily usable for such wide range of downstream tasks, further realising the vision of 'Knowledge is power'.3.Even more advanced language understanding: LLMs alone already significantly advanced the "understanding" of natural language, as evidenced by tasks like textual entailment, summarization, paraphrase detection and generation, etc.These capabilities are critical to making knowledge engineering robust to linguistic variance, typographic errors, redundancy, and other features of human-written, web-scraped, and other noisy forms of text.Now with potential novel approaches to combining parametric knowledge with explicit knowledge, it is possible to have even more advanced language understanding, not only for textual entailments, but also for other NLP tasks, such as summarization and consistent generation.4. Compression entails consolidation: An important step in traditional knowledge engineering is the consolidation and aggregation of conflicting and concurring pieces of information, requiring often elaborate methods for consolidating observations from sentences, patterns, and constraints [149].In LLM training, an aggregation occurs automatically.Although this step is not entirely understood, it brings the potential for outsourcing a major challenge in knowledge engineering.</p>
<p>With the above new opportunities brought by the combination of parametric and explicit knowledge, our vision is two-folded:</p>
<p>In Explicit-Knowledge-First use cases, our vision is that LLMs will enable, advance, and simplify crucial steps in the knowledge engineering pipeline so much as to enable KGs at unprecedented scale, quality, and utility.</p>
<p>In Parametric-Knowledge-First use cases, our vision is that KGs will improve, ground, and verify LLM generations so as to significantly increase reliability and trust in LLM usage.</p>
<p>Both visions are neither alternatives, nor does one build upon the other.Instead, we believe that classes of use cases will continue to exist side-by-side, some of which favor Explicit-Knowledge-First (scrutable) approaches, some of which favor Parametric-Knowledge-First (blackbox) approaches, with either of these having significant potential for benefiting from synergies of the two directions.</p>
<p>struggle when the content is diverse and heterogeneous in structure.However, LLMs are powerful NLP models trained on a broad spectrum of information sources, making them well-suited for knowledge extraction tasks.This section presents work that uses LLMs for knowledge extraction from various sources.</p>
<p>Entity Resolution and Matching</p>
<p>Entity resolution (also known as entity matching, entity linking or entity alignment) is the process of linking pieces of information occurring in multiple heterogeneous datasets and referring to the same world entity [46,50,126].Past research has focused on developing the methodologies and similarity measures among entities represented by flat structured data.However, entity resolution for semi-structured data for KGs is a fairly recent topic with significantly less attention.Approaches for entity alignment can be split into general vs embedding-based categories.</p>
<p>General approaches, such as CG-MuAlign [203] which employs Graph Neural Networks (GNNs) to perform multi-type entity alignment, leverages the neighborhood information and generalizes to unlabeled types, and REA [129] which tackles the multi-lingual entity alignment problem by combining adversarial training with GNNs to cope with the problem of noisy labeled data provided as input.</p>
<p>Embedding-based entity alignment methods for KGs reduces the symbolic similarities between graph entities to a vector space in order to flatten the heterogeneity of graph components and facilitate reasoning [156].Specifically, a total of 23 representative embedding alignment approaches are cross-compared in terms of performance but also are shown to require significant supervision in the labeling phase.Therefore, unsupervised methods and methods that cope with large-scale KGs are highly desirable in future research investigations.</p>
<p>LLMs are used in entity resolution and linking for KGs in multiple ways [7].First, LLMs can help with labeling training data, which is typically a resource-intensive and time-consuming step, hindering the performance of entity alignment for KGs.Similar to how [146] employs Generative Adversarial Networks (GANs) to reduce the effort of labeling data, we argue that LLMs can provide labeled samples of KGs and control the performances of the aforementioned embedding-based approaches.Also, LLMs can help build solid corpora of entity matching rules, modulo the fact that a declarative formalism with a logical language L is defined in the graph setting.Training data for this logical language should be provided as input to LLMs, similarly to SQL statements that are readily available for consumption in text corpora.However, prompt engineering is needed in order to produce meaningful rule corpora for real-world large-scale KGs, such as DBpedia [9] and Wikidata [169].Entity matching rule logs can be envisioned for these real-world large-scale KGs in a similar fashion as query logs for these KGs [18,19].</p>
<p>Concluding, entity alignment and matching are necessary pre-processing steps for full-fledged knowledge reasoning.The combination of general entity linking approaches with embeddingbased ones, as well as the leveraging of LLM-driven rule and labeled data construction, can lead to better integration of LLMs with knowledge reasoning [66].The latter integration of LLMs and knowledge reasoning can also boost performance, thus enabling the interpretability and explainability of the model's output and filling the gap between symbolic and statistical AI.</p>
<p>Knowledge Extraction from Tabular Data</p>
<p>Extracting knowledge from tabular data like databases, Web tables and CSV files is a common way for KG construction.For tables whose semantics (meta information) are already known, heuristic rules can be defined and used to transform their data into KG facts.However, realworld tables often have unclear semantics with important meta information, such as table name and column header, not clearly defined.Meanwhile, the original data usually need to be retrieved, explored, integrated and curated, before expected knowledge can be extracted.In recent years, Transformer-based LMs have been investigated for processing tables especially their textual contents.They can be applied to Representing and utilizing none textual tabular data: A table often contains not only long and short text but also data of other types like numbers and dates.There are still few works that consider these data.Extracting tabular knowledge: LLMs are mostly applied to process and understand tables but rarely applied to the final step of knowledge extraction.OntoGPT [25], which extracts instances from texts to populate an ontology using ChatGPT is known, but there are no counterparts for tables.Beyond instances, extracting relational facts is more challenging.</p>
<p>Knowledge Extraction from Text</p>
<p>Knowledge extraction from text generally entails automatic extraction of entities and associated relations, with traditional pipelines processing vast amounts of sentences and documents.This process enables the transformation of raw text into actionable knowledge, facilitating various applications such as information retrieval, recommendation systems, and KG construction.The language understanding capabilities of LLMs have enhanced this process.</p>
<p>For example, (1) Named Entity Recognition (NER) and Entity Linking, as mentioned in Section 4.1.1,involve identifying and categorizing named entities (such as persons, organizations, and locations) in text and linking (more in Section 4.2.1)them to KGs. (2) Relation extraction focuses on identifying and classifying relationships between entities, with LLMs that leverage zeroshot and few-shot in-context learning techniques [178,93].(3) Event extraction aims to detect and classify events mentioned in the text, including their participants and attributes [170,194].(4) Semantic Role Labeling (SRL) involves identifying the roles played by entities in a sentence, such as the subject, object and predicate [148,199].</p>
<p>These approaches allow LLMs to extract information from text without needing a large amount of explicit training on specific domains, thereby improving their versatility and adaptability.</p>
<p>T G D K</p>
<p>42:8</p>
<p>LLMs and KGs: Opportunities and Challenges</p>
<p>Moreover, LLMs have demonstrated proficiency in extracting knowledge from languages other than English, including low-resource languages, paving the way for cross-lingual knowledge extraction and enabling the utilization of LLMs in diverse linguistic contexts [89].</p>
<p>Furthermore, prompting LLMs has introduced new paradigms and possibilities in the field of NLP.LLMs can generate high-quality synthetic data, which can then be used to fine-tune smaller task-specific models.This approach, known as synthetic data generation, addresses the challenge of limited training data availability and enhances the performance of models [77,163].Additionally, instruction tuning has emerged as a powerful technique where LLMs are trained on datasets described by explicit instructions, enabling more precise control and customization of their behavior for specific tasks [178,174].Also, for constructing domain-specific KGs, the stakes are higher, and hence scrutinizing the generated text (by experts) is necessary.However, it is still a step forward since human annotation is less expensive than human text generation.</p>
<p>Apart from the obvious substantial computational resource requirements for training and utilizing these LLM, there are various challenges, including the ones presented in Section 2.More specifically, the following future directions are still possible:</p>
<p>Efficient extraction from very long documents.Current LLMs are incapable of processing very long documents like novels in one shot.In this regard, modeling long-range dependencies and performing corpus-level information extraction can be further improved.</p>
<p>High-coverage information extraction.</p>
<p>Almost all extraction pipelines focus on high precision.However, high recall is ignored or under-explored [152].Building knowledge extractors with high precision and high recall will result in a great leap toward building lifelong information extractors.</p>
<p>LLMs for KGs: Knowledge Graph Construction</p>
<p>We highlight the important role that LLMs play in improving KG construction, focusing on current trends, issues, and unanswered questions in this field.We start by discussing link prediction, which is a way to generate new facts given an existing KG.Next, we look at inductive link prediction, a method that predicts triples for unseen relationships.Our focus then shifts to a more recent method where triples is directly extracted from the parametric knowledge of an LLM.</p>
<p>As a conclusion of this section, we discuss the challenges of LLM-based methods for KG construction.These involve issues with long-tail entities, numerical values, and also the precision of these methods.</p>
<p>Link Prediction</p>
<p>Link prediction is about predicting a missing element of a triple given the other two elements.It includes head entity prediction (?, r, t), relation prediction (h, ?, t), and tail prediction (h, r, ?).</p>
<p>KG link prediction methods have mostly been studied for static snapshots of a KG.Many approaches, in fact, assume a training phase in which the current state of the KG is used to learn embeddings and other model parameters.Subsequently, many such models can only operate on entities for which an embedding was learned in the training phase.This leaves them incapable of predicting links for any previously unseen entities, such as newly added people or products.Inductive link prediction (ILP), in contrast, focuses on techniques that can predict links to new entities not originally contained in a KG.Furthermore, existing KG embeddingbased KG completion approaches frequently fail to leverage textual information and other literal information [54].</p>
<p>To overcome these challenges, current research focuses on incorporating textual information available in the KGs to improve the KG embeddings, boost performance in downstream tasks, and to support ILP.The latent representation is learned from textual information using a variety of encoding models such as linear models, convolutional models, recurrent neural models, and LLMs and studied in [105,124].In this work, we focus only on LLM-based methods.</p>
<p>The LLM encoder BERT [39] is used in Pretrain-KGE [197] to generate initial entity embeddings from entity descriptions and relations.These embeddings are then fed into KG embedding models to generate final embeddings.MADLINK [14] uses SBERT to generate embeddings from entity descriptions, together with the entity embeddings obtained from structural information.KEPLER [175] offers a unified approach for KG embedding and pre-trained language representation, embedding text-enhanced knowledge and factual knowledge into LLMs.Nayyeri et al. [114] use LLMs to produce representations at word, sentence, and document levels, merging them with graph structure embeddings.Huang et al. [69] propose a model that combines LLMs with other modalities, such as vision, to generate a multi-model embedding space.CoDEx [3] uses a novel loss function driven by LLMs that helps KG embedding models estimate the likelihood of triples based on textual information.While these approaches can leverage the structural information contained in the graph, KG embeddings can not be directly used to predict unknown entities in the ILP setting.To still predict entities within ILP, existing works that combine text embeddings and traditional KG embeddings use only the text embeddings in the ILP setting [106] or apply similarity based heuristics to generate KG embeddings for unseen entities [171].</p>
<p>Instead of considering the graph structure, another line of research directly leverages LLMs for KG Completion.For example, KG-BERT [187] represents a triple as an ordered sequence of head text, including surface form, descriptions, and attributes, relation text, tail text separated with special tokens.KG-BERT [187] optimizes the BERT model on KGs, followed by KG-GPT2 [15] that fine-tunes GPT-2 model.MTL-KGC [84] enhances the effectiveness of KG-BERT by combining prediction and relevance ranking tasks.PKGC evaluates triple validity by translating it into natural language sentences, while LLMs process these sentences for binary classification.Masked Language Model (MLM) is introduced to encode KG text, with MEMKGC [32] predicting masked entities using the MEM classification model.Open world KGC [33] expands MEMKGC with modules Entity Description Prediction (EDP) and Incomplete Triple Prediction (ITP), focusing on predicting entities with given textual descriptions.StAR [172] uses Siamesestyle textual encoders for text and a scoring module, while SimKGC [173] leverages a Siamese textual encoder.LP-BERT [94] is a hybrid KG completion method that combines MLM encoding for pre-training with LLM and separated encoding for fine-tuning, using a contrastive learning strategy.Also, LLMs such as GPT-3 and GPT-4 have the in-context learning capability which could adapt to new tasks through careful prompt design without fine-tuning the model parameters.Since LLMs are directly capable of predicting entities that are not yet contained in the KG, many works using direct LLM approaches also evaluate their models in the ILP setting [32,33,36,172,173,175,192].</p>
<p>Beyond the described approaches that construct and leverage embeddings for link prediction, LLMs may also be directly used in a prompting setting to find suitable links between entities, with existing methods described in detail in the following Section 4.2.2.As with the previous approaches that purely use LLMs, prompt-based approaches are directly applicable for ILP and are commonly evaluated in this setting [20,74,133,150,200].</p>
<p>Challenges and Opportunities: LLMs make it significantly easier to jointly utilize structural and text information for link prediction, while there are still challenges:</p>
<p>The generative language model which uses a decoder-only or encoder-decoder architecture cannot ensure that the generated result is already included in the KG.Also, one entity may have multiple natural language names.Thus it is hard to judge the correctness of the generated results from LLMs.</p>
<p>T G D K</p>
<p>Current link prediction models are mostly evaluated on ranking metrics, such as Hit@k and Mean Reciprocal Rank, which requires methods to give a ranked list of candidates.Considering that the number of candidate entities might be huge (e.g., over ten thousand), framing each candidate as an sample requires too many times of predictions and LLMs can not be efficiently evaluated due to its large scales (e.g., over 100 billion parameters) and high computation cost.</p>
<p>The key research question of link prediction is how well a method could learn to infer new triples based on existing ones.LLMs are trained based on a massive corpus that might overlap with KGs such as Wikidata [169].Thus it is not easy to distinguish whether the LLM completes the prediction by utilizing its memory or reasoning over existing facts.LLMs provide several benefits for ILP as demonstrated by the many existing approaches, but their application also has certain drawbacks.Since ILP entities may occur that are not contained within the underlying KG, the task is inherently reliant on auxiliary information.When leveraging LLMs for ILP, many studies focus on improving the extraction of knowledge from LLMs through prompt engineering, which is, by itself, a current popular research area that may directly benefit the domain.While prompting provides promising results, it requires well-designed strategies for predicting multi-token entities and out-of-vocabulary tokens.Further, if required knowledge is not captured by the LLM, e.g., when querying novel concepts that emerged after LLM pre-training, schemes to incorporate further knowledge into the LLM are required.Meanwhile, as feature selection, finding a suitable prompt also needs much searching with many experiments, which is costly especially for those recent commercial LLMs like GPT-4.Alternative methods rely on available high-quality textual descriptions of unknown entities.These methods inherit the limitations of classical link prediction, in that they require one-vs-all comparisons against all entity candidates during inference, which may become computationally prohibitive for large KGs.As such, efficient strategies for obtaining predictions may provide a promising research direction.Further, the combination of these methods with classical link prediction models has already shown strong performance and may be further explored to incorporate structural information into LLM-driven approaches.Though challenges exist, opportunities lie in designing efficient and effective link prediction methods combining LLMs preserving the efficiency of traditional methods and robustness of language models.</p>
<p>LLMs for KGs: Triple Extraction from LLMs</p>
<p>Traditionally, retrieval and reasoning of relational knowledge have both relied on symbolic knowledge bases [51], that often are constructed using supervised extraction techniques applied to unstructured corpora, e.g.Web archives [190,164].More recently, self-supervised LLMs have been investigated for their ability to directly retrieve relational knowledge [202] from their parameters, e.g. through question answering, prompting through the use of cloze-style questions [62, 143] or statement scoring [157].In this context, the ability of LLMs to retrieve, infer and generalize relational knowledge is seen as a crucial indicator of their capacity to understand and interpret natural language.Even though a range of terms are used in that context, e.g.fact or knowledge retrieval as well as knowledge inference, we refer to the task of accessing relational knowledge from LLM parameters as knowledge retrieval.</p>
<p>Benchmarks and Baselines: LAMA is the first benchmark dataset to evaluate knowledge retrieval in LLMs [132].Related works show that knowledge retrieval through prompts is inconsistent with regard to paraphrasing [45,62], with some types of information guiding LLMs towards more correct answers [24, 131, 31], while other are harmful to their performance [125,83].</p>
<p>LLMs struggle to retrieve knowledge from low-frequency phenomena [141] and [70] argue that LLMs fail to express large varieties of knowledge when prompted for it in a zero-shot manner.With respect to the interpretation, reliability and generalisability of knowledge retrieval, several studies [21, 24] investigate whether LLMs actually learn transferable generalisations or only exploit incidental shortcuts in the data.[24] explore biases in three different knowledge retrieval paradigms, namely prompt-based retrieval, case-based analogy, context-based inference, finding that decent performance of existing knowledge retrieval baselines tends to be driven by biased prompts that overfit to artefacts in the data, guide the LLM towards correct entity types or unintentionally leak correct answers or additional constraints applicable to the correct answer.In a similar context, [42] discuss the shortcut learning behaviour arising due to skewed training datasets, the model, or the fine-tuning process.[145] demonstrate an intriguing similarity between human cognitive biases and those exhibited by LLMs.Using insights from psychology, they analyse the learning and decision-making processes of black-box models to reveal their biases towards right-and-wrong for decision-making.Therefore, rigorous assessment of existing benchmark datasets is necessary for generalizable insights about knowledge retrieval and inference performance, and to facilitate efficient, unbiased knowledge retrieval from LLMs.</p>
<p>Prompt Engineering for Triple Extraction: Cao et al. [24] propose three paradigms for factual knowledge extraction from LLMs: prompt-based, case-based, and context-based.Results suggest the prompt-based retrieval is biased towards prompt structure.Prompt engineering [10] aims to create prompts that efficiently elicit desired responses from LLMs for a specific task.However, a limited number of manually created prompts only reveal a portion of the model's encoded knowledge [74], as the response can be influenced by the phrasing of the question.Thus, prompt engineering is a crucial part of knowledge retrieval from LLMs.LPAQA [74] uses an automated mining-based and paraphrasing-based method to generate diverse high-quality prompts, as well as ensemble methods to combine answers from different prompts.Automatic Prompt Engineer [202] uses LLM models like InstructGPT [119] and instruction induction [64] to generate instruction candidates which are then improved by proposing semantically similar instruction variants to achieve human-level performance.Zhou et al. [202] investigate the ability of LLMs, such as GPT-3, to generate high-quality prompts for a variety of tasks.Initial experiments on the role of syntax in knowledge retrieval [98] find a strong dependency on prompt structure and knowledge retrieval performance.</p>
<p>To summarise, prior works have shown that relational knowledge is captured by LLMs to T G D K 42:12 LLMs and KGs: Opportunities and Challenges a certain extent.However, there is still insufficient understanding of how performance differs across different kinds of knowledge or relations, for instance, commonsense knowledge compared to entity-centric encyclopedic facts or transversal versus hierarchical relations.In addition, several studies raise questions about LLMs capacity to infer knowledge beyond already-seen statements.</p>
<p>Challenges and Opportunities:</p>
<p>Entity Disambiguation: Entity disambiguation is essential for KG construction to ensure unique identification of entities and to maintain consistency across the graph.However, when extracting facts from LLMs, entity disambiguation presents several challenges, since LLMs only operate on word token level.Hence, polysemy and homonymy make it difficult to determine the correct entity when a term has multiple meanings or is spelled the same as others but has different meanings.Also, the need to resolve co-references, where the same entity is mentioned in various ways within a text, further complicates the process.Moreover, the same piece of text can refer to different entities depending on the context, making it a significant challenge to correctly identify and classify the entities.Entities that were not present in the training data or are less common in general can be particularly hard to disambiguate.This can be a frequent issue with newer, less well-known, or very domain-specific entities.These complexities lead to major challenges that need to be addressed: enhancing disambiguation techniques to better handle long-tail entities; developing methods to better understand and utilize context in entity disambiguation; and improving co-reference resolution in a way that it can be effectively incorporated into KG construction.</p>
<p>Long-tail Entities: Existing LLMs still manifest a low level of precision on long-tail entities.Models may begin to generate incorrect information when they fail to memorize the right facts.The answers provided by these models often lack consistency.Incorrect correlations drawn from the pre-training corpus can lead to various biases in KG completion.Whether retrieval-augmented models serve as a viable solution to this problem remains uncertain, as does the potential necessity to adapt pre-training and fine-tuning processes to enhance model robustness in handling long-tail entities.</p>
<p>High-Precision: LLMs face challenges in achieving high-precision predictions when performing knowledge extraction [167].A potential strategy to derive high-precision KGs from LLMs is to focus on model calibration.However, there are pressing challenges that remain unsolved.How can LLM training be adapted to prioritize high-precision learning?Can LLMs be used for validation purposes?These questions form the crux of the ongoing exploration in this field.</p>
<p>Provenance: Extracting factual knowledge directly from LLMs does not provide provenance, the origin and credibility of the information, which presents multiple issues.Without provenance, verifying the accuracy of information becomes challenging, potentially leading to the spread of misinformation.Additionally, bias detection is hindered, as the lack of source information makes it difficult to account for potential biases in the data used for training.</p>
<p>Provenance also provides critical context, without which, information can be misunderstood or misapplied.Lastly, the absence of source information compromises model transparency, making it hard to evaluate the accountability of the LLMs.</p>
<p>LLMs for KGs: Ontological Schema Construction</p>
<p>A KG is often equipped with an ontological schema (including rules, constraints and ontologies) for ensuring quality, enabling easier knowledge access, supporting reasoning, etc.Meanwhile, an independent ontology, which usually represents conceptual knowledge sometimes with logics, can also be regarded as a KG.In this part, we introduce topics that LLMs are applied to learn ontological schemas and to manage ontologies.</p>
<p>Constraint and Rule Mining from KGs</p>
<p>The existing KGs are mostly obtained from large-scale data extraction pipelines, which are notoriously brittle and can introduce errors and inconsistencies in these graphs [40,137].Moreover, a KG is never considered complete since the closed world assumption does not hold [40, 128], i.e., it is not possible to conclude that a missing fact is false unless it contradicts another existing fact.Instead, we usually consider that in a KG it holds the open-world assumption, that is a missing fact is simply considered as unknown.</p>
<p>Practical applications impose high demands in terms of (semi-)automatic methods for data quality assessment and validation [85, 136, 2].Since KGs contain huge amounts of data, it is not feasible to manually inspect and correct their errors.Therefore, a common approach is to instantiate rules and constraints that can be automatically enforced.These constraints express dependencies and conditions that the KG needs to satisfy at all times and that should not be violated by the introduction of new facts or their deletion.In KGs, rules and constraints can take the form of Graph Functional Dependencies [48], declarative first-order logic rules [52], or validating shapes [85,135].Once a set of rules or constraints are instantiated, the next step is to either identify which entities or facts in the KG violate any of them, or employ them to delete erroneous information, or, finally, to employ them to deduce any missing information [49,138].</p>
<p>▶ Example 1.The following rules could apply for a subset of a graph describing people and their relationships:
r 1 : hasParent(x, y) ⇒ hasChild(y, x); r 2 : hasParent(x, y) ⇒ ∃v 1 , v 2 ∈N | hasBirthYear(x, v 1 ) ∧ hasBirthYear(y, v 2 ); r 3 : hasChild(x, y)∧hasBirthYear(x, v 1 )∧hasBirthYear(y, v 2 ) ⇒ v 1 &lt; v 2 ;
Where r 1 states that hasChild is the inverse equivalent relation of hasParent, r 2 states that for each person in the KGs for which we know the parent-child relationship we should know the birth year, and r 3 states that if y is a child of x then x should be born before y.</p>
<p>Nonetheless, a fundamental challenge is how to generate such rules and constraints.Specifying them manually is prohibitively difficult and expensive [2, 136].On the one hand, the domain experts, who know the semantics for the dataset at hand, may not have the skill set or the background necessary to formally express those rules.Even when skilled, domain experts would require a substantial amount of manual work to exhaustively materialize a complete list of such rules [137].Therefore, in the past decade, we have witnessed an increased interest in methods that can (semi-) automatically extract rules and constrains [137,196].In all those cases, the data in the KG is exploited as a silver standard [128].That is, while the data are not perfect, we can still assume it is at least of reasonable quality.This approach works for rules that can find frequent positive examples.The challenge arises for rules that need to govern entities and facts that are rare, and for negative rules that need to prohibit some facts from appearing.To handle these cases, contextual information can be exploited.In this context, LLMs bring a number of important opportunities: Consider, for example, a rule where the relationships hasParent has been used, an LLM can be interrogated to identify whether hasParent between two entities refers more likely to the semantic meaning of being biologically descended or being owned or controlled.LLMs can be used to filter out candidate constraints, e.g., given their ability to mimic simple common sense reasoning, rules can be translated in the form of questions to the LLM, e.g., "if X is child of Y is it true that the birth year of Y comes always before the birth year of X?".Thus, an LLM can be used in support or replacement of a human annotator towards generated rules.</p>
<p>One of the most promising abilities of LLMs is parsing long texts.In companies and organizations, documents exist that contain reference governing information, e.g., procedures, regulations, and specifications.Here we see an untapped opportunity in parsing these documents in relation to the entities and predicates in the KG to extract constraints.Yet, the challenge arises in the fact that the LLM needs to use the correct vocabulary of entities and relations and the correct rule syntax.Recent advancements in program synthesis show a possible way to the challenge.</p>
<p>Finally, an even more fundamental challenge is that of transcending the usage of LLMs for NLP alone, and using them directly on large sets of facts within a KG.We can think of this setting as a special kind of multi-modal LLMs, where the KG is a specific modality.This brings to the question of whether it is possible to train LLMs to treat the task of rule generation as, for example, a summarization task.This would require then the ability to perform both inductive and abductive reasoning and treat rules as summaries from the set of facts in the KG.A Rule Mining Case with ChatGPT Let's have a look at the following real example asking ChatGPT to generate rules.▶ Example 2. We ask ChatGPT "Please list three rules that could help to infer one person's father.And output it in a first-order rule form."The following is the output we get: "Certainly!Here are three rules expressed in first-order logic form that could help infer a person's father:</p>
<p>Rule 1: ∀x, y (child(x, y) ∧ male(y) → father(y, x)) This rule states that for all individuals x and y, if there exists a 'child' relationship between x and y and y is male, then y is the father of x.</p>
<p>Rule 2: ∀x, y (biologicalChild(x, y) → father(y, x)) This rule states that for all individuals x and y, if there exists a 'biologicalChild' relationship between x and y, then y is the father of x.</p>
<p>Rule 3: ∀x, y (fatherOf(y, x) → father(y, x)) This rule states that for all individuals x and y, if there exists a 'fatherOf' relationship between y and x, then y is the father of x.</p>
<p>These rules, expressed in first-order logic, demonstrate how the relationships between individuals can be used to infer the father of a person within a KG."</p>
<p>From the above example, we can see that ChatGPT gives three rules that can possibly infer the father relationship.Rule 1 is correct which is consistent with the definition of father; Rule 2 is a rule with high probability; and Rule 3 is also correct since father and fatherOf are inverse relations.This demonstrates LLMs have rule knowledge and could express it in a formal form following instruction, thus they could serve as experts for automatic rule construction.To this end, however, we need to align the rules from the LLM to the existing knowledge in the KG, and feed the LLM about the existing knowledge and the context of the KG.Both are consistent with discussion about the company and family examples.</p>
<p>Ontology Refinement</p>
<p>Ontology refinement includes quite a few topics like knowledge completion (e.g., subsumption prediction, complex concept learning and new concept placement), erroneous knowledge detection and repair (e.g., inconsistency checking) and knowledge canonicalization (e.g., entity renaming).Besides formally represented knowledge, real-world ontologies, such as the widely used medical ontology SNOMED CT1 and food ontology FoodOn2 , also include a lot of meta information defined by different annotation properties for usability, such as entity labels, synonyms and natural language definition.Taking the concept obo:FOODON_00002809 in FoodOn as an example, it has not only formal knowledge such as named super concepts and logical restrictions, but also labels and synonyms (e.g., "edamame"), definitions (e.g., "Edamame is a preparation of immature soybean ..."), comments and so on.These meta information, especially the natural language text, further motivates people to use LLMs for ontology refinement.</p>
<p>For a refinement task, usually there are quite a few existing examples in the original ontology.Therefore, a straightforward solution, which has been adopted by most current methods, is finetuning a Pre-trained Language Model such as BERT together with an attached classifier.One typical method is BERTSubs [26] which is to predict the subsumption relationship between two named concepts, or between one named concept and one complex concept.It concatenates the corresponding texts of the two candidate concepts with special tokens as the input of a model composed of a pre-trained BERT and a logistic regression classifier, and fine-tunes the model with the existing subsumptions in the target ontology.For a named concept, the text could be either its name (label or synonym), or its name in combination with a textual description of its surrounding concepts; while for a complex concept, the text is its description (a.k.a.verbalisation).Another typical work is [101] which fine-tunes BERT and predicts the position to place in SNOMED CT for a new concept.Note that there are also some language model-based methods in taxonomy curation, such as [147] which fine-tunes BERT for taxonomy edge completion and GenTaxo [191] which fine-tunes a BERT variant named SciBERT for predicting positions that need new concepts.They can be directly applied or easily extended to refine an ontology's concept hierarchies.</p>
<p>Exploiting LLMs is a promising direction for ontology refinement, but it still needs much effort before they become practical tools.DeepOnto [59], which is a Python-based package that can support quite a few ontology engineering tasks, has already included some tools for ontology refinement and alignment using LLMs, but more development is needed to make it more accessible and to support generative LLMs like LLaMA and GPT-4.One obvious challenge is that those very recent generative LLMs have been rarely explored for ontology engineering.However, we think the following two research challenges are more fundamental:</p>
<p>Exploiting the graph structure and logics of an ontology together with its text.Currently LLM fine-tuning-based methods can well utilize the text of individual entities, but their other formal semantics are often ignored or not effectively incorporated.Besides finetuning with samples constructed by some templates, more LLM techniques such as prompt learning and instruction tuning could be considered.Combing symbolic reasoning with LLM inference.Symbolic reasoning, such as consistency checking in OWL ontologies, can still play a role to e.g., validate the knowledge inferred by LLMs.One aspect to incorporate symbolic reasoning is constructing samples for LLM fine-tuning and extracting prompts for LLM inference, while another aspect is the synergized framework [204] where LLM inference and symbolic reasoning work iteratively.</p>
<p>Ontology Alignment</p>
<p>The content of one single ontology is often incomplete and many real-world applications rely on cross-domain knowledge.Ontology alignment (a.k.a.ontology matching), which is to identify cross-ontology mappings between entities that have an equivalent, subsumption or membership relationship, thus becomes especially important for knowledge integration.The entity can be a concept (class), an individual (instance) or a property.Traditional systems (e.g., LogMap [75]) heavily rely on lexical matching and optionally use symbolic reasoning to remove mappings that lead to logical conflicts; while some recent methods combine these techniques with machine learning techniques like feature engineering, semantic embedding and distant supervision for better performance (e.g., LogMap-ML [27]).Especially, when the ontologies have a large ratio of assertions (large ABoxes) and the task is to discover equivalent individuals, ontology alignment is very close to the KG entity alignment task that has been widely investigated in recent years using KG embeddings [198].As in ontology refinement, exploiting the textual information by applying LLMs is a promising direction for augmenting ontology alignment.</p>
<p>The study of LLM application in ontology alignment is similar to ontology refinement.Pretrained language models such as BERT have been applied via fine-tuning [115,58].BERTMap [58] is a typical system that has achieved state-of-the-art performance in many biomedical ontology alignment benchmarks.It fine-tunes a pre-trained LM with synonym pairs extracted from the original ontologies and the potentially given mappings, and combines the predicted concept equivalence scores with lexical matching scores and reasoning for the mappings.Those recent LLMs like GPT-4 have not been applied in ontology alignment, as far as we know, and the two fundamental research challenges mentioned in ontology refinement are applicable in ontology alignment.Besides, ontology alignment has another critical challenge:</p>
<p>Evaluating LLM-based ontology alignment systems.Novel evaluation protocols with new metrics are needed to fairly and efficiently compare LLM-based systems even with incomplete ground truth mappings [60].Meanwhile, the semantics from the textual meta information and the LLM may be inconsistent with formal semantics defined in ontologies, and thus it is sometimes hard to determine whether a mapping by an LLM-based system is true or not.</p>
<p>KGs for LLMs: Training and Accessing LLMs</p>
<p>In Sections 4.1 to 4.3, we discussed on three different aspects on using LLMs for KGs.In this section, we look into the other direction, i.e., using KGs for LLMs.There are a few dimensions here.Firstly, KGs can be used as training data for LLMs.Secondly, triples in KGs can be used for prompt construction.Last but not least, KGs can be used as external knowledge in retrieval augmented language models.</p>
<p>KGs for (Pre-)Training Language Models</p>
<p>KGs usually contain information extracted from highly trusted sources, post-processed, and vetted by human evaluations.Information from KGs has been integrated into the pre-training corpus since natural language text alone can lead to limited information coverage [187,130,1,184].</p>
<p>Using factual knowledge from KGs to pre-train LLMs has also infused structured knowledge [112].This integration of KGs with LLMs, along with efficient prompts, has made it convenient to inject world knowledge and incorporate new evolving information into language models [41].Additionally, knowledge expressed in high-resource language KBs has been transferred into LMs tuned for low-resource languages [201,100].Furthermore, grounding knowledge from KGs to pre-train LMs has shown improvements in performance on generation and QA tasks [30,142,120].In another approach, [166] proposed an interpretable neuro-symbolic KB, where the memory consists of vector representations of entities and relations from an existing KB.These representations are augmented to an LM during pretraining and fine-tuning, enabling the model to excel in knowledge-intensive QA tasks.</p>
<p>KGs for Prompt Construction</p>
<p>The attention received by the integration of KGs and LLMs has grown recently.On the one hand, there is the explored direction of prompting LLMs for collecting and distilling knowledge in order to make it available to the end-users.On the other hand, there is the less explored research direction where KGs are used in synergy with prompts in order to enhance LLMs with capabilities making them more effective and, at the same time, trustworthy.A number of studies have leveraged KGs to enrich and fine-tune prompt creation resulting in a significant increase in prompt quantity, quality, and diversity compared to manual approaches.KGs have been employed in single and in multi-turn scaffolding prompts at scale, powered by numerous traversal paths over KGs with low authoring cost while considering the meaningful learning patterns [90].Other studies have investigated how incorporating explicit knowledge from external sources like KGs can help prompt engineering, especially by giving additional contexts (e.g., attributes, Khop neighbors) of the entities in order to help the LLMs to generate better predictions [22].Approaches like KnowPrompt [31] use KGs to incorporate semantic and prior knowledge among relation labels into prompt-tuning for relation extraction, enhancing the prompt construction process and optimizing their representation with structured constraints.Certain studies have utilized LLMs and prompts in the task of reasoning over KGs [34], e.g., LARK uses entities and relations in queries to find pertinent sub-graph contexts within abstract KGs, and then, performs chain reasoning over these contexts using LLM prompts of decomposed logical queries outperforming previous state-of-the-art approaches by a significant margin.</p>
<p>Challenges and Opportunities:</p>
<p>The current research in the field of KG utilization for prompt creation predominantly centers around LLMs, which are considered to have relatively lower efficacy compared to LLMs.LLMs present significant potential for advancing prompt creation methodologies in conjunction with KGs.We may summarize this perspective within the following four challenges: C1: KGs can be employed to automatically extract and represent relevant knowledge to generate context-aware writing prompts.Analyze and understand the relationships between different writing prompts, enabling the generation of prompts that build upon each other.C2: KGs can be combined with LLMs to facilitate the interactive and dynamic generation of prompts, adapting to user feedback and preferences in real time.Furthermore, the use of KGs in prompt creation has opened up possibilities for explainability and interpretability.Since KGs provide a transparent representation of knowledge, the prompts generated from KGs can be easily traced back to their underlying sources.C3: KGs can integrate into prompts the definitions of guards exploited during the generative task.Such guards may lead to enhancing the trustworthiness of the information generated by LLMs and make them more compliant with specific domain-wise or context-wise constraints.C4: KGs can create prompts that ask questions (e.g., inferring missing relations in an incomplete KG) that trigger KG complex reasoning capabilities and intermediate reasoning steps.</p>
<p>The integration of KGs within the prompt construction activities will allow us to answer the following preparatory set of research questions.For each research question, we provide a link to T G D K 42:18 LLMs and KGs: Opportunities and Challenges the challenges mentioned above, aiming to identify appropriate research pathways.RQ1: How can KGs be integrated into existing prompts to enhance the effectiveness (including relevance, non-biased, and privacy-preserving) of the information extracted from LLMs? −→ C1, C2, C3.RQ2: How can KGs be exploited to drive the generative capabilities of LLMs in order to properly address the whole ethical constraints of AI-based solutions?−→ C2, C3.RQ3: What are the optimal approaches to generate KGs-based prompts that enhance reasoning capabilities?−→ C4.Also, in the following three scenarios, the community would benefit from tackling the abovementioned challenges and research questions.</p>
<p>KGs for Hallucination Detection in LLMs:</p>
<p>The reliability of LLMs is greatly affected by the hallucination problem, where they generate inaccurate information.Despite attempts to address it, the issue of hallucination is likely to persist in the realm of LLMs for the foreseeable future.To aid in the detection of hallucinations, KGs-based prompting aims to offer reliable information that can serve as a foundation.By combining LLMs and KGs, researchers can develop a comprehensive prompt-based fact-checking model that can identify hallucinations in various domains.</p>
<p>KGs for Editing Knowledge in LLMs:</p>
<p>LLMs possess the ability to store extensive realworld knowledge, but they struggle to exploit prompts to update their internal knowledge to reflect real-world changes.KGs-based prompts offer a potential solution for modifying knowledge in LLMs, but they are restricted to handling basic tuple-based knowledge in KGs.Indeed, even if the entire LLM undergoes re-training, the knowledge presented through prompts would likely be assimilated within the vast network structure of the LLM.</p>
<p>KGs for Black-box LLMs Knowledge Injection: While pre-training and knowledge edit-</p>
<p>ing methods can bring LLMs up to date with the latest information, they require access to the internal structures and parameters of LLMs.However, many cutting-edge large LLMs only offer APIs that allow users and developers to interact with them, keeping their internal workings hidden from the public.Consequently, traditional KG injection techniques that involve modifying LLM structures with additional knowledge fusion modules cannot be employed.One potential solution is to convert various types of knowledge into different text prompts.However, it remains an area of ongoing research to determine if these prompts can effectively adapt to new LLMs.Additionally, the approach of using KGs-based prompts is constrained by the length of input tokens accepted by LLMs.Therefore, the question of how to enable effective knowledge injection for black-box LLMs still remains unanswered.</p>
<p>Retrieval Augmented Methods</p>
<p>There are a few of reasons that retrieval augmented methods are necessary for LLMs to obtain external knowledge.One reason is to address the problem of knowledge cutoff, i.e., LLMs are not aware of the events that happened after their training.Also, although parametric knowledge would increase when the size of parameters increases, training LLMs is expensive; e.g., GPT-3 (175B parameters) costs $4.6 million to train, and PaLM (540B parameters) costs $17 million.In fact, research suggests that the obtained knowledge from such training is mainly about popular entities [107].Furthermore, for domain specific applications, there might be some significant knowledge that is not yet in LLMs, including private and business critical knowledge that cannot be put into LLMs.</p>
<p>One idea to deal with the above lack of (updated) knowledge is to edit the knowledge in LLMs.A obvious strategy is to retrain and fine-tune the model based on the modified data.However, apart from being costly, retraining cannot guarantee that erroneous data will be corrected.Another Strategy is to develop hyper-network to learn a parameter shift for the base model.De Cao et al. [37] trained a hyper-network, KnowledgeEditor, to modify a fact and used Kullback-Leibler (KL) divergence-constrained optimization to alleviate the side effect on other data/knowledge that should not be changed.However, this method does not perform well when editing multiple edits, as it uses the same strategy to process multiple edits and ignore the relation between different edit gradients, resulting in a "zero-sum" phenomenon, where the inter-gradient conflict will inevitably cause some data modifications to fail.Han et al. [57] design explicit and implicit multi-editor models to learn diverse editing strategies in terms of dynamic structure and dynamic parameters respectively, allowing to deal with the conflict data in an efficient end-to-end manner.</p>
<p>However, the above Knowledge Editing methods are not yet scalable, people started to introduce retrieve-generate architectures for building retrieval augmented generation models.These methods are mainly using unstructured passages as external knowledge.RAG [92] outperforms DPR [82] by marginalizing the retrieval step to train the generator and retriever jointly with the supervision of the label answer.FiD [71] encodes the concatenation of the passages retrieved by pre-trained DPR and the original question separately, and then fuses them with concatenation to the decoder.It is expected that structured knowledge will be the main source of external knowledge, as passages often contain noise.Knowledge Graphs can be used directly as external knowledge.They can also be used to enhance passage-based methods [189].</p>
<p>Retrieval augmentation is a very promising direction.There are a few pressing challenges:</p>
<p>Unifying Knowledge Editing and Retrieval Augmentation: KGs can be used for editing knowledge in LLMs, while at the same time, KGs can also be used as external knowledge to assist LLMs in retrieval augmented methods.In fact, knowledge editing and retrieval augmentation is getting very close.For example, Mitchel et al. [111] proposed a Retrieval-Augmented Counterfactual Model (SERAC), which stores edits in an explicit memory for knowledge editing over LLMs.</p>
<p>Semi-parametric LLMs: This direction is highly related to the topic of this position paper.</p>
<p>The idea is to make use of explicit knowledge to augment LLMs.One of the key issue is to integrate different explicit knowledge [158], including unstructured ones, such as passages, and structured ones, such as KGs and databases, for augmenting LLMs.Support of Complex Reasoning: Can we go beyond simply retrieving explicit knowledge by enabling reasoning through retrieval augmented methods?BehnamGhader et al. [11] demonstrated with their experimental results that the similarity metric used by the retrievers is generally insufficient for reasoning tasks.Furthermore, LLMs do not take the complicated relations between statements into account, thus leading to to poor reasoning performance.</p>
<p>Applications</p>
<p>The integration of KGs and LLMs in a unified approach holds significant potential, as their combination mutually enhances and complements each other in a valuable manner.For instance, KGs provide very accurate and explicit knowledge, which is crucial for some applications i.e. healthcare, whereas LLMs have been criticized for their lack of factual knowledge leading to hallucinations and inaccurate facts.secondly, LLMs lack explainability instead, KGs given their symbolic reasoning ability, are able to generate interpretable results.On the other hand, KGs are difficult to construct from unstructured text and suffer from incompleteness therefore, LLMs T G D K 42:20 LLMs and KGs: Opportunities and Challenges could be utilized in addressing these challenges by text processing.Various applications have adopted this methodology of combining LLMs with KGs, such as healthcare assistants3 , question answering systems [188] or ChatBots, and sustainability, among others.</p>
<p>Commonsense Knowledge</p>
<p>The majority of KGs capture facts of the sort one might encounter in an encyclopedia or in a relational database.However, commonsense knowledge is another important form of world knowledge for AI systems.For instance, we may wish for a KG to not only capture that the Congo rainforest lies in Central Africa, but also that tropical rainforests have significant rainfall and lush green vegetation.ConceptNet is the most well-known commonsense knowledge graph, developed using manual crowdsourcing along with automated refinement techniques [102].However, crowdsourcing is very labor-intensive and costly, so alternative means of harvesting such knowledge have long been sought.</p>
<p>Commonsense Knowledge from LLMs:</p>
<p>The first study to investigate extracting knowledge from a language model to the best of our knowledge was indeed one that targeted commonsense knowledge [159].The authors mined commonsense triples such as hasProperty (apples, green) from the Google Web 1T n-gram data as well as from Microsoft's Web-scale smoothed language models [67].This was later extended into a large-scale commonsense knowledge graph Recently, [181] shows how common-sense triples could be extracted from an LLM and use through distillation to transfer knowledge into a smaller LM, outperfoming the larger one.Overall, finetuned LLMs are found to outperform off-the-shelf LLMs, while also benefitting from the advances of the latter.</p>
<p>Challenges and Opportunities: Commonsense knowledge, in particular, is genuinely openended, such that it depends on a number of considerations whether it makes sense to attempt to materialize relevant knowledge beforehand or rather invoke a (possibly slow) LLM on the fly.Commonsense knowledge may also differ substantially between different cultures [116].This also leads to the question of what kinds of biases are acceptable.Finally, a long-term challenge is how to capture knowledge that is not easily expressed in language, e.g., how a robot ought to grasp different kinds of objects.</p>
<p>Digital Build Environment</p>
<p>In the domain of Build Environment, where it is vital to design and construct in a safe and sustainable way, a number of regulations and guidelines need to be met.Automated Compliance Code Checking has bloomed to support this, but still, in the past, it was quite challenging to interpret regulations and execute rules in 3D models automatically due to the ambiguity of the text, and the need for extensive expert knowledge for interpretation.Many applications now in this area have combined LLMs + KGs in addressing these challenges by following an LLMs enhanced KG approach [204].LLMs interpret the text in the regulations and enhance a KG of rules, which are further serialized using dome Domain Specific Language [195,176].Interrogating 3D models modeled as graphs using the Linked Building Data approach is another challenge for the domain as it requires skill sets in query languages like SPARQL.LLMs are helping in understanding human language written questions and converting those into relevant query languages by bringing a new way of how domain experts interact and interrogate 3D models and their various forms.An example of this is AI Speckle4 .</p>
<p>Digital Healthcare</p>
<p>The Digital Healthcare sector holds immense potential for various possibilities concerning the adoption of LLMs, including the automation of clinical documentation, the synthesis of patient histories, and the identification of potential candidates for clinical trials.Although these advancements are remarkable, it is crucial to recognize the potential risks associated with employing LLMs in healthcare.Indeed, Digital Healthcare is one of the most critical application domains for the adoption of LLMs.The needs of the major stakeholders (i.e., physicians, healthcare providers, and policymakers) row against the paradigm behind the creation of LLMs.In particular, the two major significant risks related to the model's accuracy and the privacy concerns stemming from its usage.</p>
<p>Accuracy.Some demonstrations of LLMs have showcased impressive capabilities.Nevertheless, there have also been documented instances where LLMs have made mistakes or exhibited erratic behavior.In the Digital Healthcare sector, where patient safety is of utmost importance, it is crucial for healthcare organizations to comprehend the potential risks associated with LLM usage.When utilized to diagnose hypothetical patient cases, LLMs have exhibited accuracy at a level comparable to that of a third-or fourth-year medical student, albeit not reaching a professional's proficiency.Despite this high level of performance, LLMs have also been known to generate false information, invent sources, commit logical errors, and provide answers that are inappropriate or unethical.The integration of KGs would definitely enhance the capabilities of LLMs given the possibility of injecting domain-specific knowledge able to mitigate the issues mentioned above.Avoiding hallucinations and preserving ethics are definitely the two major aspects to which LLMs+KG may contribute in a significant manner.</p>
<p>Privacy.One major concern with LLMs is that employing any third-party application necessitates the transmission of data to that party.When data, including protected health information (PHI), is managed by a covered entity like a hospital, it becomes subject to the regulations of the jurisdiction where the entity is located (e.g., GDPR).Furthermore, by sending PHI to additional third parties, organizations lose control over how that data will be handled.For instance, healthcare organizations are unable to determine the exact storage location of their data, whether it will be mixed with data from other organizations and utilized to train future language models, or what security measures are in place to safeguard the data.Healthcare organizations employing LLMs must recognize that their data are potentially more susceptible to breaches or misuse.The role of preserving private information may be played by KGs through the modeling of axioms defining which data may be shared and with who and how personal knowledge may be anonymized in order to be transmitted to possible external systems.</p>
<p>An alternative approach, prioritizing privacy, involves running an open-source LLM within the infrastructure of a healthcare organization.This way, it would be possible to directly work on the parameters of LLMs given the possibility of having control of the injected knowledge and, at the same time, ensuring that data are never shared with a third party.However, these open-source models are currently not as advanced or extensively trained as the more popular commercial systems (e.g., ChatGPT).Additionally, the effort to create the knowledge resources to inject and the expertise required to program and maintain an open-source LLM may not be readily available to many healthcare organizations.</p>
<p>The two risks described above lead to likewise challenges that must be tackled in order to make a significant step toward the adoption of these models within the clinical practice.</p>
<p>Domain Specific Content Search</p>
<p>Recently we have witnessed the success of models like  in a multitude of NLP applications that involve multiple modalities and domain specific adaptations.While LLMs are often treated as generative models, they can be easily adopted in search and reasoning tasks in many tools and pipelines5 .Nonetheless, as seen in the past all these specialized domains can better benefit from the inclusion of symbolic knowledge in machine methods [6].Here we focus on two distinct applications: (1) semantic image and video search and (2) technical document understanding.</p>
<p>Recently, many methods, primarily based on deep learning models such as CLIP [139] and BLIP2 [95], achieved state-of-the-art performance on image retrieval tasks.These multi-modal models jointly learn vector embeddings for images and text, such that the embedding of the image should be close to that of the text that describes that image.Nonetheless, we have also seen increased interest in obtaining a more symbolic representation of the contents of an image [127,88].Datasets like Visual Genome [88] annotate images with scene graphs.A scene graph is a small KG that describes, with a structured formal graphical representation, the contents of an image in terms of objects (people, animals, items) as nodes connected via pairwise relationships (e.g., actions or positioning relationships) as edges.Therefore, Multimodal LLM can be trained to reason and exploit this additional representation offering an advanced ability to understand the contents of an image (or a video).Importantly, a scene graph node and edge can be annotated (grounded) with features and positions from the image (e.g., relative size).This can be exploited in applications like image and video search and question answering.When entities in a scene graph are connected to a background taxonomy or KG, then questions that require forms of abstraction and computation, e.g., What is the genus of the largest animal in the picture?What is the average price of the car in the picture?Retrieve images depicting kids wearing vegan friendly items of clothing in the catalog.</p>
<p>On the other hand, the digitalization of domain specific documents, e.g., especially contracts, is enabling in-depth applications of machine intelligence to help humans more effectively perform time-consuming tasks.Among these, contract review costs humans substantial time, money, and attention (many law firms spend approximately 50% of their time reviewing contracts, costing hundreds of thousands of dollars) [63].The Contract Understanding Atticus Dataset (CUAD) is a new dataset for legal contract review [63].CUAD was created with legal experts and consisted of over 13,000 annotations.Recent advancements in generic pre-trained language models showed their power in some text-understanding tasks [182,186].Therefore, we have seen different domain specific applications of NLP and LLM methods [182,186].Yet, they do not have access to all relevant knowledge and are ill-suited for certain calculations [81].This can be solved by exploiting external domain specific symbolic information, e.g., domain specific knowledge graphs [117, 99], and by adding symbolic and reasoning capabilities to the LLMs [81].This promising direction will lead to extending current state-of-the-art neuro-symbolic methods to combine the advantages of a graph representation when extracting symbolic knowledge from complex documents, the ability to understand long-form unstructured texts of LLMs, and the good properties of domain-specific code synthesis of LLMs to address advanced retrieval and question answering use-cases, e.g., How many weeks are left before the expiration of this contract?What are the conflicts between this liability clause and previous contracts my company signed?What is the risk of side-effects of this treatment for a patient with this given health record? Get the average yearly yield and spread for competitor companies of ACorp and their recent acquisitions in the EU market.</p>
<p>Outlook</p>
<p>In conclusion, the recent advances on large language models (LLMs) mark an important inflection point for knowledge graph (KG) research.While important questions on the ability to combine their strengths remain open, these offer exciting opportunities for future research.</p>
<p>ability to extract contextual information from input text; information extraction from contextual data used during training; automatic generation of new rules via inductive reasoning; T G D K understanding vocabulary in context, allowing to reconcile rules with synonyms and polysemy; providing explanations of rules or generating candidate validating or counterfactual examples.</p>
<p>[161] that covered a range of different relations and became a part of the WebChild KG [160].As both crowdsourcing and information extraction from text are likely to lead to incomplete knowledge, a key challenge is how to generalize beyond what has been collected.The WebBrain project explored neural knowledge graph completion [29] for better generalization.COMET, short for COMmonsEnse Transformer [20], and the improved COMET-ATOMIC 2020 [70], used existing data to fine-tune Transformer-based models.This line of work considers the original ConceptNet relations as well as reasoning-related knowledge pertaining to events, causes, and effects, e.g., what goals might have motivated a person A to leave an event without person B.</p>
<p>Transforming table contents into sequences: A</p>
<p>table or a table element with its structured context needs to be transformed into a sequence before it can be fed into LLMs.Different transformation methods are required for different LLM utilization scenarios, such as fine-tuning LLMs, LLM inference with prompts, and instruction tuning of LLMs.
table vector representation as a foundation of other predictiontasks [168]. TURL [38] is a typical method of table representation learning that uses BERT [39]and has been applied in several tasks such as cell filling, column type annotation, and relationextraction. Similarly, RPT [162] uses BERT and GPT to pre-train a table representation model.Starmie [47] transforms columns into sequences using a template and fine-tunes BERT with acontrast learning framework using unionable and not unionable column pairs as samples.Among all the table processing tasks, semantic table annotation which matches table data toKG components (e.g., table column to KG class, table cell to KG entity, inter-column relationshipto KG property) can be directly applied to extract knowledge for KG construction and popula-tion [103, 76]. There have been several attempts that use LLMs for these tasks. Doduo [155]serializes a table into a sequence of tokens and trains BERT for predicting column types and inter-column relationships. Korini et al. [86] prompts ChatGPT to annotate semantic column types.When task-specific samples for demonstration are minimal or absent, ChatGPT achieves similarperformance RoBERTa model. Although some attention has been given to utilizing LLMs fortabular data processing and KG construction, there is still much room for investigation, especiallytowards the following challenges:</p>
<p>Zhong et al. [200]propose that the models' accuracy may be from memorizing training data, not actually inferring knowledge.Similar to LAMA, the experiments on a more recent probing workKAMEL [78]confirm that LLMs are still far from the knowledge access capabilities of symbolic knowledge bases.The Knowledge Memorization, Identification and Reasoning test work KMIR [53] reveals that while LLMs struggle to robustly recall facts, their capacity to retain information is determined more by the number of parameters than the training methods, and while model compression can help preserve the memorization performance, it reduces the ability to identify and reason about the information in LLMs from transformer-based language models.Linzbach et al. [98] also present similar findings.LLMs are known to struggle with more complex reasoning tasks [68, 61].Branco et al. [21] explore generalisability of common-sense reasoning capabilities and the impact of shortcuts in training data.LLMs may exhibit various types of biases; representation of the majority viewpoint being a common issue due to distributions prevalent within pretraining data [12], neglecting disagreements among multiple viewpoints (e.g. by majority voting) [35].Prior works investigate individual factors (such as frequency) or LLM biases in other tasks [108], as well as knowledge retrieval [200].
Biases in Triple Extraction Evaluation:</p>
<p>The community is already rapidly adapting their research focus, with novel forums like the KBC-LM workshop[79]and the LM-KBC challenge[151]arising, and resources massively shifting towards hybrid approaches to knowledge extraction, consolidation, and usage.We give out the following recommendations:1.Don't throw out the KG with the paradigm shift: For a range of reliability or safety-critical applications, structured knowledge remains indispensible, and we have outlined many ways in which KGs and LLMs can fertilize each other.KGs are here to stay, do not just ditch them out of fashion.2.Murder your (pipeline) darlings: LLMs have substantially advanced many tasks in the KG and ontology construction pipeline, and even made some tasks obsolete.Take critical care in examining even the most established pipeline components, and compare them continuously with the LLM-based state of the art.3.Stay curious, stay critical:LLMs are arguably the most impressive artifact of AI research of the past years.Nonetheless, there exist a magnitude of exaggerated claims and expectations in the public as well as in the research literature, and one should retain a healthy dose of critical reflection.In particular, a fundamental fix to the so-called problem of hallucinations is not in sight.Data spuriousness in deep learning of commonsense reasoning.In EMNLP, pages 1504-1521, November 2021.22Ryan Brate, Minh-Hoang Dang, Fabian Hoppe, Yuan He, Albert Meroño-Peñuela, and Vijay Sadashivaiah.Improving language model predictions via prompts enriched with knowledge graphs.In DL4KG, 2022.23Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al.Language models are fewshot learners.neurIPS, 33:1877-1901, 2020.24Boxi Cao, Hongyu Lin, Xianpei Han, Le Sun, Lingyong Yan, Meng Liao, Tong Xue, and Jin Xu.Knowledgeable or educated guess?revisiting language models as knowledge bases.In ACL, pages 1860-1874, August 2021.25J Harry Caufield, Harshad Hegde, Vincent Emonet, Nomi L Harris, Marcin P Joachimiak, Nicolas Matentzoglu, HyeongSik Kim, Sierra AT Moxon, Justin T Reese, Melissa A Haendel, et al.Structured prompt interrogation and recursive extraction of semantics (spires): A method for populating knowledge bases using zero-shot learning.arXiv, 2023.26Jiaoyan Chen, Yuan He, Yuxia Geng, Ernesto Jiménez-Ruiz, Hang Dong, and Ian Horrocks.Contextual semantic embeddings for ontology subsumption prediction.WWW, pages 1-23, 2023.27Jiaoyan Chen, Ernesto Jiménez-Ruiz, Ian Horrocks, Denvar Antonyrajah, Ali Hadian, and Jaehun Lee.Augmenting ontology alignment by semantic embedding and distant supervision.In ESWC, pages 392-408, 2021.28Jiaoyan Chen, Freddy Lecue, Jeff Z. Pan, Ian Horrocks, and Huajun Chen.Knowledge-based Transfer Learning Explanation.In KR, pages 349-358, 2018.29Jiaqiang Chen, Niket Tandon, Charles Darwis Hariman, and Gerard de Melo.WebBrain: Joint neural learning of large-scale commonsense knowledge.In ISWC, pages 102-118, 2016.30Wenhu Chen, Yu Su, Xifeng Yan, and William Yang Wang.Kgpt: Knowledge-grounded pretraining for data-to-text generation.In EMNLP, 2020.31Xiang Chen, Ningyu Zhang, Xin Xie, Shumin Deng, Yunzhi Yao, Chuanqi Tan, Fei Huang, Luo Si, and Huajun Chen.Knowprompt: Knowledgeaware prompt-tuning with synergistic optimization for relation extraction.In WWW, pages 2778-2788, 2022.64Or Honovich, Uri Shaham, Samuel R Bowman, et al.Instruction induction: From few examples to natural language task descriptions.arXiv, 2022.65Edward J Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, and Weizhu Chen.Lora: Low-rank adaptation of large language models.ICLR, 2021.66Ziniu Hu, Yichong Xu, Wenhao Yu, Shuohang Wang, Ziyi Yang, Chenguang Zhu, Kai-Wei Chang, and Yizhou Sun.Empowering language models with knowledge graph reasoning for question answering.In New Frontiers in Graph Learning, 2022.67Jian Huang, Jianfeng Gao, Jiangbo Miao, Xiaolong Li, Kuansan Wang, Fritz Behr, and C. Lee Giles.Exploring web scale language models for search query processing.In WWW, page 451-460, 2010.68Jie Huang and Kevin Chen-Chuan Chang.Towards reasoning in large language models: A survey.Findings of ACL, 2023.69Ningyuan Huang, Yash R Deshpande, Yibo Liu, Houda Alberts, Kyunghyun Cho, Clara Vania, and Iacer Calixto.Endowing language models with multimodal knowledge graph representations.arXiv, 2022.70Jena D. Hwang, Chandra Bhagavatula, Ronan Le Bras, Jeff Da, Keisuke Sakaguchi, Antoine Bosselut, and Yejin Choi.Comet-atomic 2020: On symbolic and neural commonsense knowledge graphs.In AAAI, 2021.71Gautier Izacard and Edouard Grave.Leveraging passage retrieval with generative models for open domain question answering.In EACL, 2021.72Sarthak Jain and Byron C. Wallace.Attention is not explanation.In NAACL, 2019.73Krzysztof Janowicz, Bo Yan, Blake Regalia, Rui Zhu, and Gengchen Mai.Debiasing knowledge graphs: Why female presidents are not like female popes.In International Workshop on the Semantic Web, 2018.74Zhengbao Jiang, Frank F Xu, Jun Araki, et al.How can we know what language models know?TACL, 8:423-438, 2020.75Ernesto Jiménez-Ruiz and Bernardo Cuenca Grau.Logmap: Logic-based and scalable ontology matching.In ISWC, pages 273-288, 2011.76Ernesto Jiménez-Ruiz, Oktie Hassanzadeh, Vasilis Efthymiou, Jiaoyan Chen, and Kavitha Srinivas.Semtab 2019: Resources to benchmark tabular data to knowledge graph matching systems.In ESWC, pages 514-530, 2020.77Martin Josifoski, Marija Sakota, Maxime Peyrard, and Robert West.Exploiting asymmetry for synthetic training data generation: Synthie and the case of information extraction.ArXiv, 2023.78Jan-Christoph Kalo and Leandra Fichtel.Kamel: Knowledge analysis with multitoken entities in language models.In AKBC, 2022.79Jan-Christoph Kalo, Simon Razniewski, Sneha Singhania, and Jeff Z. Pan.LM-KBC: Knowledge base construction from pre-trained language models.ISWC Challenges, 2023.80Nikhil Kandpal, Haikang Deng, Adam Roberts, Eric Wallace, and Colin Raffel.Large language models struggle to learn long-tail knowledge, 2023.81Ehud Karpas, Omri Abend, Yonatan Belinkov, Barak Lenz, Opher Lieber, Nir Ratner, Yoav Shoham, Hofit Bata, Yoav Levine, Kevin Leyton-Brown, et al.Mrkl systems: A modular, neurosymbolic architecture that combines large language models, external knowledge sources and discrete reasoning.arXiv, 2022.82Vladimir Karpukhin, Barlas Oguz, Sewon Min, Patrick Lewis, Ledell Wu, Sergey Edunov, Danqi Chen, and Wen tau Yih.Dense passage retrieval for open-domain question answering.In EMNLP, page 6769-6781, 2020.83Nora Kassner and Hinrich Schütze.Negated and misprimed probes for pretrained language models: Birds can talk, but cannot fly.In ACL, 2020.84Bosung Kim, Taesuk Hong, Youngjoong Ko, and Jungyun Seo.Multi-task learning for knowledge graph completion with pre-trained language models.In COLING, pages 1737-1743, 2020.85Holger Knublauch and Dimitris Kontokostas.Shapes constraint language (shacl).W3C Candidate Recommendation, 11(8), 2017.86Keti Korini and Christian Bizer.Column type annotation using chatgpt.arXiv, 2023.87Angelie Kraft and Ricardo Usbeck.The lifecycle of "facts": A survey of social bias in knowledge graphs.In AACL, 2022.88Ranjay Krishna, Yuke Zhu, Oliver Groth, Justin Johnson, Kenji Hata, Joshua Kravitz, Stephanie Chen, Yannis Kalantidis, Li-Jia Li, David A Shamma, et al.Visual genome: Connecting language and vision using crowdsourced dense image annotations.IJCV, 123:32-73, 2017.89Viet Dac Lai, Nghia Trung Ngo, Amir Pouran Ben Veyseh, Hieu Man, Franck Dernoncourt, Trung Bui, and Thien Huu Nguyen.Chatgpt beyond english: Towards a comprehensive evaluation of large language models in multilingual learning.ArXiv, 2023.90Yoonjoo Lee, John Joon Young Chung, Tae Soo Kim, Jean Y. Song, and Juho Kim.Promptiverse: Scalable generation of scaffolding prompts through human-ai hybrid knowledge graph annotation.In CHI, 2022.91Alina Leidinger and Richard A. Rogers.Which stereotypes are moderated and under-moderated in search engine autocompletion?FAT, 2023.92Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich Küttler, Mike Lewis, Wen-tau Yih, Tim Rocktäschel, Sebastian Riedel, and Douwe Kiela.Retrieval-augmented generation for knowledgeintensive nlp tasks.In neurIPS, volume 33, 2020.93Bo Li, Gexiang Fang, Yang Yang, Quansen Wang, Wei Ye, Wen Zhao, and Shikun Zhang.Evaluating chatgpt's information extraction capabilities: An assessment of performance, explainability, calibration, and faithfulness.ArXiv, 2023.94Da Li, Ming Yi, and Yukai He.Lp-bert: Multi-task pre-training knowledge graph bert for link prediction.arXiv, 2022.95Junnan Li, Dongxu Li, Silvio Savarese, and Steven Hoi. Blip-2: Bootstrapping language-image pretraining with frozen image encoders and large language models.In arXiv, 2023.
Krieken, and Thiviyan Thanapalasingam. Prompt-18Angela Bonifati, Wim Martens, and Thomasing as probing: Using language models for know-Timm. Navigating the maze of wikidata query logs.ledge base construction. LM-KBC, 2022.In WWW, pages 127-138, 2019.5Badr AlKhamissi, Millicent Li, Asli Celikyilmaz,19Angela Bonifati, Wim Martens, and ThomasMona Diab, and Marjan Ghazvininejad. A reviewTimm. An analytical study of large SPARQLon language models as knowledge bases. arXiv,query logs. VLDB J., 29(2-3):655-679, 2020.2022.20Antoine Bosselut, Hannah Rashkin, Maarten Sap,6Mona Alshahrani, Mohammad Asif Khan, OmarChaitanya Malaviya, Asli Celikyilmaz, and YejinMaddouri, Akira R Kinjo, Núria Queralt-Choi. COMET: Commonsense transformers forRosinach, and Robert Hoehndorf. Neuro-symbolicautomatic knowledge graph construction. In ACL,representation learning on biological knowledgepages 4762-4779, 2019.graphs.Bioinformatics, 33(17):2723-2730, 0421Ruben Branco, António Branco, João An-2017.tónio Rodrigues, et al. Shortcutted commonsense:7Sihem Amer-Yahia, Angela Bonifati, Lei Chen,Guoliang Li, Kyuseok Shim, Jianliang Xu, andXiaochun Yang. From large language models todatabases and back: A discussion on research andeducation. DASFAA, abs/2306.01388, 2023.8Alejandro Barredo Arrieta,Natalia DíazRodríguez, Javier Del Ser, Adrien Bennetot,Siham Tabik, A. Barbado, Salvador García, SergioGil-Lopez, Daniel Molina, Richard Benjamins,Raja Chatila, and Francisco Herrera. Explainableartificial intelligence (XAI): Concepts, taxonomies,opportunities and challenges toward responsibleai. Information Fusion, 2020.9Sören Auer, Christian Bizer, Georgi Kobilarov,Jens Lehmann, Richard Cyganiak, and ZacharyIves. Dbpedia: A nucleus for a web of open data.In The semantic web, pages 722-735, 2007.10Stephen H Bach, Victor Sanh, Zheng-Xin Yong,Albert Webson, Colin Raffel, Nihal V Nayak, Ab-heesht Sharma, Taewoon Kim, M Saiful Bari,Thibault Fevry, et al. Promptsource: An integ-rated development environment and repository fornatural language prompts. ACL, 2022.11Parishad BehnamGhader, Santiago Miret, andSiva Reddy. Can retriever-augmented languagemodels reason? the blame game between the re-triever and the language model. In arXiv, 2022.12Emily M Bender, Timnit Gebru, AngelinaMcMillan-Major, et al.On the dangers ofstochastic parrots: Can language models be toobig? In FAT, pages 610-623, 2021.13Emily M. Bender and Alexander Koller. Climbingtowards NLU: On meaning, form, and understand-ing in the age of data. In ACL, 2020.14Russa Biswas, Harald Sack, and Mehwish Alam.Madlink: Attentive multihop and entity descrip-tions for link prediction in knowledge graphs. SWJ,pages 1-24, 2022.15Russa Biswas, Radina Sofronova, Mehwish Alam,and Harald Sack. Contextual language models forknowledge graph completion. In MLSMKG, 2021.16Su Lin Blodgett, Solon Barocas, Hal Daum'e, andHanna M. Wallach. Language (technology) ispower: A critical survey of "bias" in nlp. ACL,2020.17Bernd Bohnet, Vinh Q Tran, Pat Verga, RoeeAharoni, Daniel Andor, Livio Baldini Soares,Jacob Eisenstein, Kuzman Ganchev, JonathanHerzig, Kai Hui, et al.Attributed questionanswering: Evaluation and modeling for attrib-uted large language models.arXiv preprintarXiv:2212.08037, 2022.
https://www.snomed.org/
https://foodon.org/ T G D K
https://neo4j.com/blog/doctor-ai-a-voice-chatbot-for-healthcare-powered-by-neo4j-and-aws/
https://speckle.systems/blog/ai-powered-conversations-with-speckle/ T G D K
E.g., https://haystack.deepset.ai/
. The past is over, let's begin the new journey: The advances triggered by LLMs have uprooted the field in an unprecedented manner, and enable to enter the field with significant shortcuts. There is no better time to start anew in fields related to Knowledge Computing, than now. Although the direction of the present transformation is widely open, as researchers continue to explore the potentials and challenges of hybrid approaches, we can expect to see new breakthroughs in the representation and processing of knowledge, with far-reaching implications for fields ranging from Knowledge Computing to NLP, AI, and beyond.
96Tianyi Li, Mohammad Javad Hosseini, Sabine Weber, and Mark Steedman.Language models are poor learners of directional inference.In Findings in EMNLP, 2022.97Tianyi Li, Wenyu Huang, Nikos Papasarantopoulos, Pavlos Vougiouklis, and Jeff Z. Pan.askspecific pre-training and prompt decomposition for knowledge graph population with language models.In LM-KBC, 2022.98Stephan Linzbach, Tim Tressel, Laura Kallmeyer, Stefan Dietze, and Hajira Jabeen.Decoding prompt syntax: Analysing its impact on knowledge retrieval in large language models.In NLP4KGC,2023
Knowledge graph based synthetic corpus generation for knowledge-enhanced language model pretraining. Heming Agarwal, Siamak Ge, Shakeri, NAACL. June 2021</p>
<p>Language model guided knowledge graph embeddings. Viet-Phi Ahmadi, Vamsi Huynh, Stefano Meduri, Paolo Ortona, Papotti, J. Data and Information Quality. 3Mirza Mohtashim Alam, Md Rashad Al Hasan Rony, Mojtaba Nayyeri, Karishma Mohiuddin, MST Mahfuja Akter, Sahar Vahdati, and Jens Lehmann122may 2020. 2022IEEE Access</p>
<p>Knowledge graph extension with a pre-trained language model via unified learning method. Knowledge-Based Systems. Selene Báez Alivanistos, Michael Santamaría, Jan-Christoph Cochez, Emile Kalo, Daesik Van 32bonggeun Choi, Youngjoong Jang, Ko, 34Nurendra Choudhary and Chandan K Reddy. Complex logical reasoning over knowledge graphs using large language models. 2021. 2023. 20239110245arXivMem-kgc: Masked entity model for knowledge graph completion with pre-trained language model</p>
<p>Dealing with disagreements: Looking beyond the majority vote in subjective annotations. Mostafazadeh Davani, Mark Díaz, Vinodkumar Prabhakaran, TACL. 102022</p>
<p>Inductive Entity Representations from Text via Link Prediction. Michael Daza, Paul Cochez, Groth, WWW. 2021</p>
<p>Editing factual knowledge in language models. De Cao, Wilker Aziz, Ivan Titov, Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing. the 2021 Conference on Empirical Methods in Natural Language ProcessingDominican RepublicAssociation for Computational LinguisticsNovember 2021Online and Punta Cana</p>
<p>Turl: Table understanding through representation learning. Huan Deng, Alyssa Sun, You Lees, Cong Wu, Yu, ACM SIGMOD Record. 5112022</p>
<p>Bert: Pre-training of deep bidirectional transformers for language understanding. Ming-Wei Devlin, Kenton Chang, Kristina Lee, Toutanova, 2019NAACL</p>
<p>From data fusion to knowledge fusion. Luna Dong, Evgeniy Gabrilovich, Geremy Heitz, Wilko Horn, Kevin Murphy, Shaohua Sun, Wei Zhang, jun 2014VLDB7</p>
<p>Knowledge prompts: Injecting world knowledge into language models through soft prompts. Zhe Nogueira Dos Santos, Daniel Matthew Dong, John Cer, Siamak Nham, Jianmo Shakeri, Yun-Hsuan Ni, Sung, 2022ArXiv</p>
<p>Shortcut learning of large language models in natural language understanding: A survey. Fengxiang Du, Na He, Zou, 2022arXiv</p>
<p>Understanding gender bias in knowledge base embeddings. Qi Du, Yuanbin Zheng, Man Wu, Yan Lan, Meirong Yang, Ma, ACL. 2022</p>
<p>Measuring causal effects of data statistics on language model's 'factual' predictions. Nora Elazar, Shauli Kassner, Amir Ravfogel, Abhilasha Feder, Marius Ravichander, Yonatan Mosbach, Hinrich Belinkov, Yoav Schütze, Goldberg, 2023arXiv</p>
<p>Measuring and improving consistency in pretrained language models. Nora Elazar, Shauli Kassner, Abhilasha Ravfogel, Eduard Ravichander, Hinrich Hovy, Yoav Schütze, Goldberg, TACL. 92021</p>
<p>Duplicate record detection: A survey. K Elmagarmid, G Panagiotis, Vassilios S Ipeirotis, Verykios, TKDE. 1912007</p>
<p>Semantics-aware dataset discovery from data lakes with contextualized column-based representation learning. Jin Fan, Yuliang Wang, Dan Li, Renée Zhang, Miller, 2023VLDB</p>
<p>Discovering graph functional dependencies. Chunming Fan, Xueli Hu, Ping Liu, Lu, TODS. 4532020</p>
<p>Deducing certain fixes to graphs. Ping Fan, Chao Lu, Jingren Tian, Zhou, VDLB. 1272019</p>
<p>A theory for record linkage. P Fellegi, A B Sunter, Journal of the American Statistical Association. 641969</p>
<p>Improving entity retrieval on structured data. Ujwal Fetahu, Stefan Gadiraju, Dietze, ISWC. 2015</p>
<p>Amie: Association rule mining under incomplete evidence in ontological knowledge bases. Antonio Galárraga, Christina Teflioudi, Katja Hose, Fabian Suchanek, WWW, WWW '13. 2013</p>
<p>Kmir: A benchmark for evaluating knowledge memorization, identification and reasoning abilities of language models. Yantao Gao, Lei Jia, Chengzhen Li, Zhicheng Fu, Hao Dou, Xinyu Jiang, Lei Zhang, Zhao Chen, Cao, 2022</p>
<p>A survey on knowledge graph embeddings with literals: Which model links better literal-ly? Semantic Web. Asefa Gesese, Russa Biswas, Mehwish Alam, Harald Sack, 202112</p>
<p>OWL 2: The next step for OWL. Cuenca Grau, Ian Horrocks, Boris Motik, Bijan Parsia, F Peter, Ulrike Patel-Schneider, Sattler, J. Web Semant. 642008</p>
<p>Knowledge graphs and their role in the knowledge engineering of the 21st century (dagstuhl seminar 22372). Elena Groth, Bontas Paslaru, Marieke Simperl, Denny Van Erp, Vrandecic, Dagstuhl Reports. 122022</p>
<p>A Divide and Conquer Framework for Knowledge Editing. Ru Han, Xiaoli Li, Jeff Z Li, Pan, 2023Knowledge Based Systems</p>
<p>Bertmap: a bert-based ontology alignment system. Jiaoyan He, Denvar Chen, Ian Antonyrajah, Horrocks, AAAI. 202236</p>
<p>DeepOnto: A Python package for ontology engineering with deep learning. Jiaoyan He, Hang Chen, Ian Dong, Carlo Horrocks, Taehun Allocca, Brahmananda Kim, Sapkota, arXiv:2307.030672023arXiv preprint</p>
<p>Machine learning-friendly biomedical datasets for equivalence and subsumption ontology matching. Jiaoyan He, Hang Chen, Ernesto Dong, Ali Jiménez-Ruiz, Ian Hadian, Horrocks, ISWC. 2022</p>
<p>Language models as knowledge bases: On entity representations, storage capacity, and paraphrased queries. Jiaoyan He, Ernesto Chen, Hang Jiménez-Ruiz, Ian Dong, Horrocks, Findings of ACL, 2023. 62Benjamin Heinzerling and Kentaro Inui. 2021EACL</p>
<p>Cuad: An expert-annotated nlp dataset for legal contract review. Collin Hendrycks, Anya Burns, Spencer Chen, Ball, 20211</p>
<p>Pre-training is (almost) all you need: An application to commonsense reasoning. Nicola Tamborrino, Baptiste Pellicano, Pannier, Proceedings of the 7th ACM international conference on Web search and data mining. the 7th ACM international conference on Web search and data miningGerard de Melo2023. 2010. 20145803ACL, 2020. 158Wang-Chiew Tan</p>
<p>Deriving a Web-scale common sense fact database. Gerard Tandon, Gerhard De Melo, Weikum, AAAI. 2011</p>
<p>Rpt: relational pre-trained transformer is almost all you need towards democratizing data preparation. Ju Tang, Fangyi Fan, Jianhong Li, Xiaoyong Tu, Guoliang Du, Sam Li, Mourad Madden, Ouzzani, 2021VLDB</p>
<p>Does synthetic data generation of llms help clinical text mining?. Xiaotian Tang, Xiaoqian Han, Xia Jiang, Hu, 2023ArXiv</p>
<p>Inferring missing categorical information in noisy and sparse web markup. Elena Tempelmeier, Stefan Demidova, Dietze, 2018WWW</p>
<p>Thibaut Touvron, Gautier Lavril, Xavier Izacard, Marie-Anne Martinet, Timothée Lachaux, Baptiste Lacroix, Naman Rozière, Eric Goyal, Hambro, Faisal Azhar, et al. Llama: Open and efficient foundation language models. 2023arXiv</p>
<p>Facts as experts: Adaptable and interpretable neural memory over symbolic knowledge. Haitian Verga, Livio Sun, Baldini Soares, 2021NAACL</p>
<p>Evaluating language models for knowledge base completion. Sneha Veseli, Simon Singhania, Gerhard Razniewski, Weikum, ESWC. 2023</p>
<p>Towards foundation models for relational databases. Benjamin Vogel, Carsten Hilprecht, Binnig, vision paper</p>
<p>Wikidata: A free collaborative knowledgebase. TRL@NeurIPS2022, 2023. 169Denny Vrandečić and Markus Krötzsch. sep 201457</p>
<p>Entity, relation, and event extraction with contextualized span representations. Ulme Wadden, Yi Wennberg, Hannaneh Luan, Hajishirzi, Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP). the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)Hong Kong, ChinaAssociation for Computational LinguisticsNovember 2019</p>
<p>Inductive learning on commonsense knowledge graph completion. Guangtao Wang, Jing Wang, Jiaxuan Huang, Jure You, C.-C. Jay Leskovec, Kuo, Joint Conference on Neural Networks. 2021</p>
<p>Structure-augmented text representation learning for efficient knowledge graph completion. Tao Wang, Guodong Shen, Tianyi Long, Ying Zhou, Yi Wang, Chang, WWW. 2021</p>
<p>SimKGC: Simple Contrastive Knowledge Graph Completion with Pre-trained Language Models. Wei Wang, Zhuoyu Zhao, Jingming Wei, Liu, ACL. May 2022</p>
<p>Instructuie: Multi-task instruction tuning for unified information extraction. Wei Wang, Can Zhou, Han Zu, Tianze Xia, Yuan Chen, Rui Zhang, Junjie Zheng, Qi Ye, Tao Zhang, Jihua Gui, J Kang, Siyuan Yang, Chunsai Li, Du, 2023ArXiv</p>
<p>176Xiyu Wang and Nora El-Gohary. Deep learningbased relation extraction and knowledge graphbased representation of construction safety requirements. Tianyu Wang, Zhaocheng Gao, Zhengyan Zhu, Zhiyuan Zhang, Juanzi Liu, Jian Li, Tang, TACL. 9104696March 2021. 2023KEPLER: A Unified Model for Knowledge Embedding and Pre-trained Language Representation. Automation in Construction</p>
<p>Chain of thought prompting elicits reasoning in large language models. Xuezhi Wei, Dale Wang, Maarten Schuurmans, Ed Bosma, F Huai Hsin Chi, Quoc Xia, Denny Le, Zhou, ArXiv, abs/2201.119032022</p>
<p>Zero-shot information extraction via chatting with chatgpt. Xingyu Wei, Ning Cui, Xiaobin Cheng, Xin Wang, Shen Zhang, Pengjun Huang, Jinan Xie, Yufeng Xu, Meishan Chen, Yong Zhang, Wenjuan Jiang, Han, 2023ArXiv</p>
<p>Machine Knowledge: Creation and Curation of Comprehensive Knowledge Bases. Luna Weikum, Simon Dong, Fabian M Razniewski, Suchanek, FnT2021</p>
<p>Eliza-a computer program for the study of natural language communication between man and machine. Weizenbaum, Communications of the ACM. 1966</p>
<p>Chandra West, Jack Bhagavatula, Jena D Hessel, Liwei Hwang, Ronan Jiang, Ximing Le Bras, Sean Lu, Yejin Welleck, Choi, arXiv:2110.07178Symbolic knowledge distillation: from general language models to commonsense models. 2021arXiv preprint</p>
<p>Ozan Wu, Steven Irsoy, Vadim Lu, Mark Dabravolski, Sebastian Dredze, Prabhanjan Gehrmann, David Kambadur, Gideon Rosenberg, Mann, Bloomberggpt: A large language model for finance. 2023arXiv</p>
<p>Ontology-based data access: A survey. Diego Xiao, Roman Calvanese, Domenico Kontchakov, Antonella Lembo, Riccardo Poggi, Michael Rosati, Zakharyaschev, IJCAI. 2018</p>
<p>. Mahdi Xu, Devamanyu Namazifar, Aishwarya Hazarika, Yang Padmakumar, Liu, Z Dilek, </p>
<p>Kilm: Knowledge injection into encoder-decoder language models. Hakkani-Tür, ArXiv. 2023</p>
<p>Chatgpt is not enough: Enhancing large language models with knowledge graphs for fact-aware language modeling. Hongyang Yang, Zhao Chen, Xiao Li, Xindong Ding, Wu, 2023arXiv</p>
<p>A large language model for electronic health records. Aokun Yang, Nima Chen, Pournejatian, Chang Hoo, Kaleb E Shin, Christopher Smith, Colin Parisien, Cheryl Compas, Anthony B Martin, Mona G Costa, Ying Flores, Tanja Zhang, Christopher A Magoc, Gloria Harle, Duane A Lipori, William R Mitchell, Elizabeth A Hogan, Jiang Shenkman, Yonghui Bian, Wu, Digital Medicine. 511942022</p>
<p>Kgbert: Bert for knowledge graph completion. Chengsheng Yao, Yuan Mao, Luo, arXiv2019</p>
<p>Qa-gnn: Reasoning with language models and knowledge graphs for question answering. Hongyu Yasunaga, Antoine Ren, Percy Bosselut, Jure Liang, Leskovec, 2021NAACL</p>
<p>Kg-fid: Infusing knowledge graph in fusion-in-decoder for opendomain question answering. Chenguang Yu, Yuwei Zhu, Wenhao Fang, Shuohang Yu, Yichong Wang, Xiang Xu, Yiming Ren, Michael Yang, Zeng, ACL. 2022</p>
<p>Knowmore -knowledge base augmentation with structured web markup. Ujwal Yu, Besnik Gadiraju, Oliver Fetahu, Dominique Lehmberg, Stefan Ritze, Dietze, Semantic Web. 1012019</p>
<p>Enhancing taxonomy completion with concept generation via fusing relational representations. Jinfeng Zeng, Wenhao Lin, Jane Yu, Meng Cleland-Huang, Jiang, KDD. 2021</p>
<p>Inductive relation prediction by bert. Zhiyu Zha, Xifeng Chen, Yan, AAAI. 202236</p>
<p>Coffee: A contrastive oracle-free framework for event extraction. Chenshuang Zhang, Sheng Zhang, Yu Zheng, Chenghao Qiao, Mengchun Li, Sumit Zhang, Chu Kumar Dam, Ye Myaet Thwal, Le Luang Lin Tun, Donguk Huy, Sung-Ho Kim, Lik-Hang Bae, Yang Lee, Heng Yang, In-So Tao Shen, Choong-Seon Kweon, Hong, ArXiv, abs/2303.14452A complete survey on generative ai (aigc): Is chatgpt from gpt-4 to gpt-5 all you need? ArXiv, 2023. 194Meiru Zhang, Yixuan Su, Zaiqiao Meng, Zihao Fu, and Nigel Collier. 2023195Ruichuan Zhang and Nora El-Gohary</p>
<p>Transformer-based approach for automated context-aware ifc-regulation semantic information alignment. Automation in Construction. 2023145</p>
<p>Jiaoyan Zhang, Juan Chen, Zezhong Li, Jeff Z Xu, Huajun Pan, Chen, Knowledge graph reasoning with logics and embeddings: survey and perspective. 2022arXiv</p>
<p>Pretrain-kge: Learning knowledge representation from pretrained language models. Xiaoqian Zhang, Yi Liu, Qi Zhang, Xu Su, Bin Sun, He, EMNLP Findings. 2020</p>
<p>An industry evaluation of embedding-based entity alignment. Hualuo Zhang, Jiaoyan Liu, Xi Chen, Bo Chen, Yuejia Liu, Yefeng Xiang, Zheng, COLING. 2020</p>
<p>A frustratingly easy approach for entity and relation extraction. Danqi Zhong, Chen, Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language TechnologiesAssociation for Computational Linguistics199Zexuan. June 2021</p>
<p>Factual probing is [mask]: Learning vs. learning to recall. Dan Zhong, Danqi Friedman, Chen, NAACL. 2021</p>
<p>Prix-lm: Pretraining for multilingual knowledge base construction. Fangyu Zhou, Ivan Liu, Nigel Vulic, Muhao Collier, Chen, ACL. 2021</p>
<p>Large language models are human-level prompt engineers. Andrei Ioan Zhou, Ziwen Muresanu, Keiran Han, Silviu Paster, Harris Pitis, Jimmy Chan, Ba, arXiv2023</p>
<p>Collective multi-type entity alignment between knowledge graphs. Hao Zhu, Bunyamin Wei, Da Sisman, Christos Zheng, Xin Faloutsos, Jiawei Luna Dong, Han, WWW. 2020</p>
<p>Xiaohan Zhu, Jing Wang, Shuofei Chen, Yixin Qiao, Yunzhi Ou, Shumin Yao, Huajun Deng, Ningyu Chen, Zhang, Llms for knowledge graph construction and reasoning: Recent capabilities and future opportunities. 2023arXiv</p>            </div>
        </div>

    </div>
</body>
</html>