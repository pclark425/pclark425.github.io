<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-6883 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-6883</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-6883</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-132.html">extraction-schema-132</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how large language models are used to synthesize novel chemical compounds for specific applications, including model details, generation methods, target applications, chemical representations, evaluation metrics, constraints, integration with external tools, datasets, reported performance, experimental validation, and reported challenges or limitations.</div>
                <p><strong>Paper ID:</strong> paper-281526344</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2407.15141v2.pdf" target="_blank">Text-Augmented Multimodal LLMs for Chemical Reaction Condition Recommendation</a></p>
                <p><strong>Paper Abstract:</strong> Identifying reaction conditions that are broadly applicable across diverse substrates is a longstanding challenge in chemical and pharmaceutical research. While many methods are available to generate conditions with acceptable performance, a universal approach for reliably discovering effective conditions during reaction exploration is rare. Consequently, current reaction optimization processes are often labor-intensive, time-consuming, and costly, relying heavily on trial-and-error experimentation. Nowadays, large language models (LLMs) are capable of tackling chemistry-related problems, such as molecule design and chemical reasoning tasks. Here, we report the design, implementation and application of Chemma-RC, a text-augmented multimodal LLM to identify effective conditions through task-specific dialogue and condition generation. Chemma-RC learns a unified representation of chemical reactions by aligning multiple modalities-including text corpus, reaction SMILES, and reaction graphs-within a shared embedding module. Performance benchmarking on datasets showed high precision in identifying optimal conditions, with up to 17% improvement over the current state-of-the-art methods. A palladium-catalysed imidazole C-H arylation reaction was investigated experimentally to evaluate the functionalities of the Chemma-RC in practice. Our findings suggest that Chemma-RC holds significant potential to accelerate high-throughput condition screening in chemical synthesis.</p>
                <p><strong>Cost:</strong> 0.026</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e6883.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e6883.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how large language models are used to synthesize novel chemical compounds for specific applications, including model details, generation methods, target applications, chemical representations, evaluation metrics, constraints, integration with external tools, datasets, reported performance, experimental validation, and reported challenges or limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Chemma-RC</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Chemma-RC (Text-Augmented Multimodal LLM for Reaction Condition Prediction)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A text-augmented multimodal autoregressive LLM that aligns SMILES, reaction graphs, and retrieved text corpus into a shared embedding space to generate reaction conditions (solvents, reagents, catalysts) as SMILES/tokens; trained by supervised multimodal fine-tuning followed by a ranking-enhancement post-fine-tuning stage.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Chemma-RC</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>text-augmented multimodal decoder-only LLM (LLM backbone integrated with domain encoders and projection modules); autoregressive next-token generator with post-fine-tuning ranking module</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>Backbone: LLaMA-2-7b (32-layer, ~7B); trainable adapters via LoRA ~0.3B parameters</td>
                        </tr>
                        <tr>
                            <td><strong>training_data_description</strong></td>
                            <td>Multimodal data: reaction SMILES encoded by Parrot-like reaction encoder, reaction graphs encoded by R-GCN, retrieved text corpus paragraphs (~190 tokens average) from patents/literature; datasets: USPTO-Condition and USPTO_500MT_Condition for SFT, and HTE ORD ligand data for ranking post-fine-tuning.</td>
                        </tr>
                        <tr>
                            <td><strong>generation_method</strong></td>
                            <td>Direct autoregressive generation of text and chemical tokens (generates SMILES for reagents/solvents/catalysts) after projecting graph/SMILES embeddings into LLM token space; two-stage training: multimodal supervised fine-tuning (next-token prediction + contrastive alignment) then Ranking Enhancement with Feedback (REF) using HTE yield-ranked candidates; LoRA parameter-efficient fine-tuning; cross-modal contrastive (InfoNCE) alignment; Perceiver projection modules for modality alignment.</td>
                        </tr>
                        <tr>
                            <td><strong>chemical_representation</strong></td>
                            <td>Reaction SMILES, reaction graphs (molecular graphs), learned reaction/graph tokens, and retrieved textual corpus; outputs produced as SMILES strings (reagents/solvents/catalysts) and natural language tokens.</td>
                        </tr>
                        <tr>
                            <td><strong>target_application</strong></td>
                            <td>Reaction condition prediction (solvents, reagents, catalysts) for organic synthesis; selection of high-yield ligands in high-throughput experimentation (HTE) contexts (e.g., Pd-catalysed imidazole C–H arylation ligand selection).</td>
                        </tr>
                        <tr>
                            <td><strong>constraints_used</strong></td>
                            <td>Ranking stage uses HTE yield-ordered candidate lists as supervision (learns to prefer higher-yield conditions); in HTE ligand selection experiments other conditions (base, solvent) were fixed by experimental design; no explicit synthetic-accessibility, toxicity, or patentability filters reported.</td>
                        </tr>
                        <tr>
                            <td><strong>integration_with_external_tools</strong></td>
                            <td>Retrieval system for finding similar corpus from literature/patents; Perceiver projection modules to map non-text embeddings into LLM token space; used GPT-4 to generate diverse question-prompt templates for instruction dataset construction; Parrot reaction encoder and R-GCN graph encoder are integrated but frozen during SFT; LoRA used for efficient fine-tuning.</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_used</strong></td>
                            <td>USPTO-Condition (≈546k train), USPTO_500MT_Condition (≈88k train), curated ORD HTE dataset for Pd-catalysed imidazole C–H arylation ligand evaluation; retrieved patent/literature paragraphs paired per reaction for corpus augmentation.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td>Top-k exact match accuracy (top-1, top-3, top-10, top-15), partial match accuracy (per-condition matching), top-1 exact match on concatenated condition strings, precision, recall, and HTE-specific top-1/top-50% ligand-selection metrics.</td>
                        </tr>
                        <tr>
                            <td><strong>reported_results</strong></td>
                            <td>USPTO-Condition (top-1): catalyst 92.7% ; solvent 1 54.6% ; solvent 2 81.8% ; reagent1 53.4% ; reagent2 78.7% (Table 1). USPTO_500MT_Condition (zero-shot): top-1 exact 25.9%, partial accuracy 69.7%, recall 67.9%, precision 79.3% (Table 2). Out-of-distribution (time-split average top-1): ~69.6% (Table 4). HTE Pd C–H arylation ligand selection: top-1 accuracy 93.7% vs baseline 38.1% (Zhao et al.) reported (Figure 4 / main text). Reported improvements over previous best (TextReact etc.) up to ~7% absolute on some tasks and overall improvements up to 17% over prior SOTA in benchmarking claim.</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_validation</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>challenges_or_limitations</strong></td>
                            <td>Paper-reported limitations include: (1) inherent one-to-many mapping of substrates→many valid conditions making optimal selection hard; (2) alignment across vastly different modality scales (atom-level graphs to corpus-level text) is challenging; (3) adding graph modality increases computational cost while providing limited aggregate gains (but helpful on very large/more complex substrates); (4) data sparsity and long-tail distributions (power-law) reduce performance for rare conditions; (5) safety and feasibility of generated conditions must be ensured before autonomous execution; (6) LLMs pretrained on text alone struggle with SMILES-sensitive tasks absent modality alignment.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Text-Augmented Multimodal LLMs for Chemical Reaction Condition Recommendation', 'publication_date_yy_mm': '2024-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6883.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e6883.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how large language models are used to synthesize novel chemical compounds for specific applications, including model details, generation methods, target applications, chemical representations, evaluation metrics, constraints, integration with external tools, datasets, reported performance, experimental validation, and reported challenges or limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LLaMA-2</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>LLaMA-2 (used as LLM backbone)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A general-purpose decoder-only LLM used as the text-decoder backbone for Chemma-RC; integrated with projection layers and fine-tuned (via LoRA) to accept multimodal latent tokens for reaction condition generation.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Llama 2: Open Foundation and Fine-Tuned Chat Models.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>LLaMA-2-7b (32-layer used in experiments)</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>decoder-only LLM backbone (fine-tuned with adapters/LoRA within a multimodal framework)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>7B parameters (LLaMA-2-7b variant used)</td>
                        </tr>
                        <tr>
                            <td><strong>training_data_description</strong></td>
                            <td>Not detailed in this paper (pretrained general text foundation model referenced); used as off-the-shelf LLM backbone and further trained with multimodal instruction Q&A constructed from reaction SMILES, graphs, and retrieved corpus.</td>
                        </tr>
                        <tr>
                            <td><strong>generation_method</strong></td>
                            <td>Autoregressive next-token decoding for combined natural language and chemical token outputs; fine-tuned with LoRA during SFT stage.</td>
                        </tr>
                        <tr>
                            <td><strong>chemical_representation</strong></td>
                            <td>Operates on textual tokens; receives projected latent tokens from SMILES and graph encoders (via Perceiver) concatenated with text queries/corpus.</td>
                        </tr>
                        <tr>
                            <td><strong>target_application</strong></td>
                            <td>Backbone for generating reaction conditions and reagent/ligand SMILES in Chemma-RC.</td>
                        </tr>
                        <tr>
                            <td><strong>constraints_used</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>integration_with_external_tools</strong></td>
                            <td>Connected to Perceiver projection modules for modality alignment, LoRA for parameter-efficient fine-tuning, and frozen Parrot/R-GCN encoders providing embeddings.</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_used</strong></td>
                            <td>Fine-tuned on multimodal instruction datasets constructed from USPTO-Condition, USPTO_500MT_Condition and retrieved corpus; exact pretraining corpora not specified in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reported_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>experimental_validation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>challenges_or_limitations</strong></td>
                            <td>General-purpose LLMs (text-only pretraining) struggle on SMILES-sensitive tasks unless augmented/aligned with domain-specific representations; requires projection/alignment modules to consume graph/SMILES embeddings effectively.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Text-Augmented Multimodal LLMs for Chemical Reaction Condition Recommendation', 'publication_date_yy_mm': '2024-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6883.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e6883.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how large language models are used to synthesize novel chemical compounds for specific applications, including model details, generation methods, target applications, chemical representations, evaluation metrics, constraints, integration with external tools, datasets, reported performance, experimental validation, and reported challenges or limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Perceiver</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Perceiver (latent-query projection module)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A transformer-based projection module used in Chemma-RC to map graph and SMILES embeddings into a shared latent token space compatible with the LLM; found to outperform MLP and reprogramming projection variants for modality alignment in this work.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Perceiver: General Perception with Iterative Attention.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Perceiver projection modules (two independent Perceiver variants used for SMILES and graph)</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>transformer-based projection / alignment module (not a generative LLM)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>Not specified in paper</td>
                        </tr>
                        <tr>
                            <td><strong>training_data_description</strong></td>
                            <td>Trained as part of Chemma-RC modality alignment on paired (SMILES, graph, text) reaction examples from USPTO datasets during SFT using contrastive InfoNCE loss.</td>
                        </tr>
                        <tr>
                            <td><strong>generation_method</strong></td>
                            <td>Not generative for molecules; used to produce latent tokens from continuous embeddings to feed into LLM for downstream generation.</td>
                        </tr>
                        <tr>
                            <td><strong>chemical_representation</strong></td>
                            <td>Takes as input SMILES and graph embeddings (from Parrot/R-GCN) and outputs latent tokens aligned to text token space.</td>
                        </tr>
                        <tr>
                            <td><strong>target_application</strong></td>
                            <td>Cross-modal representation alignment for reaction condition generation.</td>
                        </tr>
                        <tr>
                            <td><strong>constraints_used</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>integration_with_external_tools</strong></td>
                            <td>Integrated inside Chemma-RC pipeline between encoders (Parrot/R-GCN) and LLaMA-2; used jointly with contrastive InfoNCE alignment losses.</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_used</strong></td>
                            <td>USPTO-Condition and USPTO_500MT_Condition used during the alignment training.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td>Ablation comparing projection modules: Perceiver achieved best performance (average gain ≈7.1% over reprogramming) — example: solvent1 top-1 54.6% (Perceiver) vs 51.1% (MLP) and 52.8% (Reprogramming) (Table 5).</td>
                        </tr>
                        <tr>
                            <td><strong>reported_results</strong></td>
                            <td>Perceiver projection achieved top-1 solvent1 accuracy 54.6% and overall best aggregated Top-k accuracies reported in Table 5.</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_validation</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>challenges_or_limitations</strong></td>
                            <td>Adds modeling complexity and compute; projection and alignment require careful contrastive training to avoid modality bias; no other explicit limitations reported beyond compute cost.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Text-Augmented Multimodal LLMs for Chemical Reaction Condition Recommendation', 'publication_date_yy_mm': '2024-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6883.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e6883.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how large language models are used to synthesize novel chemical compounds for specific applications, including model details, generation methods, target applications, chemical representations, evaluation metrics, constraints, integration with external tools, datasets, reported performance, experimental validation, and reported challenges or limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Parrot (reaction encoder)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Parrot (reaction SMILES encoder / attention-based reaction encoder)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A reaction encoder used to produce SMILES-based reaction embeddings for Chemma-RC; Parrot is an attention-based model for encoding reaction SMILES used as frozen encoder in experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Parrot reaction encoder</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>attention-based sequence encoder for reaction SMILES (used as frozen encoder)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>training_data_description</strong></td>
                            <td>Pretrained reaction representation model (details not given in this paper; cited as Wang et al.), used to extract SMILES embeddings for Chemma-RC training.</td>
                        </tr>
                        <tr>
                            <td><strong>generation_method</strong></td>
                            <td>Not a generative model here; provides embeddings that are projected into LLM token space.</td>
                        </tr>
                        <tr>
                            <td><strong>chemical_representation</strong></td>
                            <td>SMILES-based reaction representation (sequence input).</td>
                        </tr>
                        <tr>
                            <td><strong>target_application</strong></td>
                            <td>Provide SMILES embeddings for downstream reaction condition generation.</td>
                        </tr>
                        <tr>
                            <td><strong>constraints_used</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>integration_with_external_tools</strong></td>
                            <td>Frozen within Chemma-RC; outputs passed through Perceiver projection into LLaMA-2 token space.</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_used</strong></td>
                            <td>Parrot pretrained outside this work (paper cites Wang et al. for Parrot); Chemma-RC training used USPTO datasets to pair Parrot embeddings with corpus/graph embeddings.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reported_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>experimental_validation</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>challenges_or_limitations</strong></td>
                            <td>SMILES-based encoders can miss some nuances (e.g., atom permutations) and sometimes provide similar information to graph encoders; adding graph encoder still helps for very large/complex substrates.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Text-Augmented Multimodal LLMs for Chemical Reaction Condition Recommendation', 'publication_date_yy_mm': '2024-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6883.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e6883.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how large language models are used to synthesize novel chemical compounds for specific applications, including model details, generation methods, target applications, chemical representations, evaluation metrics, constraints, integration with external tools, datasets, reported performance, experimental validation, and reported challenges or limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>R-GCN</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Relational Graph Convolutional Network (R-GCN) graph encoder</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A graph-based molecular encoder used to produce graph embeddings of reactions in Chemma-RC, providing atom-level structural information complementary to SMILES encodings.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Modeling relational data with graph convolutional networks.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>R-GCN (graph convolutional network)</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>graph neural network encoder for molecular graphs (frozen during Chemma-RC SFT)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>training_data_description</strong></td>
                            <td>Pretrained graph model from literature (cited), used to encode molecular graphs for Chemma-RC alignment.</td>
                        </tr>
                        <tr>
                            <td><strong>generation_method</strong></td>
                            <td>Not generative; provides graph embeddings that are projected into LLM token space.</td>
                        </tr>
                        <tr>
                            <td><strong>chemical_representation</strong></td>
                            <td>Molecular graphs (atom/bond relational structure).</td>
                        </tr>
                        <tr>
                            <td><strong>target_application</strong></td>
                            <td>Provide graph-level features to improve condition prediction for complex substrates.</td>
                        </tr>
                        <tr>
                            <td><strong>constraints_used</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>integration_with_external_tools</strong></td>
                            <td>Outputs passed to Perceiver projection modules and then to LLaMA-2; frozen during SFT.</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_used</strong></td>
                            <td>Same USPTO datasets used for pairing graph embeddings with SMILES and corpus during alignment training.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reported_results</strong></td>
                            <td>Including graph modality with SMILES+corpus yielded incremental improvements for some condition types and provided notable benefits for very large/complex substrates (discussed in ablation and Figure 7/Table 3).</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_validation</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>challenges_or_limitations</strong></td>
                            <td>Graph modality increases computational cost; aggregate gains are smaller vs adding textual corpus, but critical for large/complex molecules.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Text-Augmented Multimodal LLMs for Chemical Reaction Condition Recommendation', 'publication_date_yy_mm': '2024-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6883.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e6883.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how large language models are used to synthesize novel chemical compounds for specific applications, including model details, generation methods, target applications, chemical representations, evaluation metrics, constraints, integration with external tools, datasets, reported performance, experimental validation, and reported challenges or limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GPT-4 (used for prompts & cited)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Generative Pre-trained Transformer 4 (GPT-4 / GPT-4o)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>State-of-the-art general-purpose multimodal LLMs cited as examples of LMMs applied in chemistry; in this work GPT-4 was leveraged to generate diverse question-prompt templates for instruction dataset construction, and GPT-4/GPT-4o are used as baseline comparisons in evaluation.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Gpt-4 technical report.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-4 / GPT-4o</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>general-purpose multimodal LLM (decoder-only style)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>training_data_description</strong></td>
                            <td>Not specified here (pretrained on broad web-scale corpora per original GPT-4 report); used only for prompt/template generation and baseline evaluation in experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>generation_method</strong></td>
                            <td>Few-shot / zero-shot prompting (used as baseline); GPT-4 used to synthesize Q&A prompt templates for instruction datasets.</td>
                        </tr>
                        <tr>
                            <td><strong>chemical_representation</strong></td>
                            <td>Textual tokens; can process SMILES as text but lacks specialized SMILES encoders unless augmented.</td>
                        </tr>
                        <tr>
                            <td><strong>target_application</strong></td>
                            <td>Prompt/template generation for instruction data; baseline for condition prediction comparisons; cited use-cases include molecule design and experiment planning in related work.</td>
                        </tr>
                        <tr>
                            <td><strong>constraints_used</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>integration_with_external_tools</strong></td>
                            <td>In other cited works GPT-4 is used as an agent integrated with tools; in this paper GPT-4 used to generate prompts and evaluated as baseline via API.</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_used</strong></td>
                            <td>Evaluated zero-/one-/five-shot on USPTO_500MT_Condition (Table 2) as baseline.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td>Top-1 exact accuracy and partial accuracy reported for baselines in Table 2.</td>
                        </tr>
                        <tr>
                            <td><strong>reported_results</strong></td>
                            <td>GPT-4o (zero-shot) reported top-1 exact ~1.0% and partial acc ~13.0% on USPTO_500MT_Condition (Table 2).</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_validation</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>challenges_or_limitations</strong></td>
                            <td>Poor performance on SMILES/sequence-sensitive reaction condition generation compared to domain-specific models; general-purpose LLMs often underperform on tasks requiring precise molecule-string handling.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Text-Augmented Multimodal LLMs for Chemical Reaction Condition Recommendation', 'publication_date_yy_mm': '2024-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6883.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e6883.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how large language models are used to synthesize novel chemical compounds for specific applications, including model details, generation methods, target applications, chemical representations, evaluation metrics, constraints, integration with external tools, datasets, reported performance, experimental validation, and reported challenges or limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ChemDFM</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>ChemDFM (Large chemical domain LLM)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A domain-specific large multimodal LLM for chemistry trained on a large chemical corpus; used as a baseline comparison in this work and reported to have limited zero-shot performance on reaction condition generation tasks compared to Chemma-RC.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Developing ChemDFM as a large language foundation model for chemistry.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>ChemDFM</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>large chemical-domain LLM (general-purpose chemical foundation model)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>Trained on ~34B chemical text tokens (paper notes), fine-tuned with ~2.7M instructions (reference in text).</td>
                        </tr>
                        <tr>
                            <td><strong>training_data_description</strong></td>
                            <td>Chemical literature and textbooks totalling ~34B tokens; instruction fine-tuning with chemical instructions (per cited description).</td>
                        </tr>
                        <tr>
                            <td><strong>generation_method</strong></td>
                            <td>Autoregressive LLM generation; evaluated in zero-/one-/few-shot settings for condition generation.</td>
                        </tr>
                        <tr>
                            <td><strong>chemical_representation</strong></td>
                            <td>Textual chemical strings and literature-derived content; not specialized multimodal alignment of graphs/SMILES as in Chemma-RC (per paper discussion).</td>
                        </tr>
                        <tr>
                            <td><strong>target_application</strong></td>
                            <td>General chemical tasks; evaluated for reagent/condition generation as baseline.</td>
                        </tr>
                        <tr>
                            <td><strong>constraints_used</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>integration_with_external_tools</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>dataset_used</strong></td>
                            <td>Evaluated on USPTO_500MT_Condition dataset (Table 2) as baseline.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td>Top-1 exact accuracy, partial accuracy, recall, precision on USPTO_500MT_Condition.</td>
                        </tr>
                        <tr>
                            <td><strong>reported_results</strong></td>
                            <td>ChemDFM (zero-shot) top-1 exact ~3.0% and partial accuracy ~38.0% on USPTO_500MT_Condition (Table 2).</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_validation</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>challenges_or_limitations</strong></td>
                            <td>Despite large chemical pretraining, showed low zero-shot accuracy on structured condition generation tasks; lacks explicit multimodal alignment (SMILES+graph+corpus) used by Chemma-RC which limited performance here.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Text-Augmented Multimodal LLMs for Chemical Reaction Condition Recommendation', 'publication_date_yy_mm': '2024-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6883.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e6883.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how large language models are used to synthesize novel chemical compounds for specific applications, including model details, generation methods, target applications, chemical representations, evaluation metrics, constraints, integration with external tools, datasets, reported performance, experimental validation, and reported challenges or limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>TextReact</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>TextReact (Predictive Chemistry Augmented with Text Retrieval)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A prior method that augments SMILES-based reaction representations with retrieved textual corpus from literature to improve reaction condition prediction; used as a baseline and ablation point in this work.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Predictive Chemistry Augmented with Text Retrieval.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>TextReact (retrieval-augmented SMILES transformer)</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>SMILES-based transformer augmented with retrieved textual corpus (retrieval-augmented model)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>training_data_description</strong></td>
                            <td>SMILES reaction data paired with retrieved relevant corpus entries from literature; evaluated on USPTO-Condition.</td>
                        </tr>
                        <tr>
                            <td><strong>generation_method</strong></td>
                            <td>Transformer-based sequence-to-sequence prediction using SMILES + retrieved corpus context.</td>
                        </tr>
                        <tr>
                            <td><strong>chemical_representation</strong></td>
                            <td>SMILES plus retrieved textual corpus paragraphs.</td>
                        </tr>
                        <tr>
                            <td><strong>target_application</strong></td>
                            <td>Reaction condition prediction (baseline comparison).</td>
                        </tr>
                        <tr>
                            <td><strong>constraints_used</strong></td>
                            <td>Original TextReact uses gold texts in some settings; in this paper TextReact variants excluding gold texts (TextReact(gr)) were used to avoid label leakage.</td>
                        </tr>
                        <tr>
                            <td><strong>integration_with_external_tools</strong></td>
                            <td>Retrieval pipeline to fetch similar corpus paragraphs from literature/patents (same retrieval approach used by Chemma-RC for corpus augmentation).</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_used</strong></td>
                            <td>USPTO-Condition (TextReact variants compared in Table 1 and Table 4).</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td>Top-k accuracy (top-1 etc.) and out-of-distribution time-split evaluation.</td>
                        </tr>
                        <tr>
                            <td><strong>reported_results</strong></td>
                            <td>TextReact (no-gold-text variant) top-1 averaged lower than Chemma-RC; e.g., Chemma-RC reported ≈7% absolute improvement over TextReact on aggregate metrics (Table 1 / Table 4 comparisons). Specific numbers in Table 1 show TextReact variant top-1 solvent1 ~51.7% vs Chemma-RC 54.6%.</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_validation</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>challenges_or_limitations</strong></td>
                            <td>Relies on retrieval quality; using gold corpus in evaluation can cause label leakage—careful retrieval required to avoid information leak; still outperformed by multimodal alignment approach in Chemma-RC.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Text-Augmented Multimodal LLMs for Chemical Reaction Condition Recommendation', 'publication_date_yy_mm': '2024-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6883.8">
                <h3 class="extraction-instance">Extracted Data Instance 8 (e6883.8)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how large language models are used to synthesize novel chemical compounds for specific applications, including model details, generation methods, target applications, chemical representations, evaluation metrics, constraints, integration with external tools, datasets, reported performance, experimental validation, and reported challenges or limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Boiko et al. GPT-4 agent</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>GPT-4 driven scientific agent system (Boiko et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Cited prior work that used GPT-4 driven agents to plan and perform complex experiments to accelerate reaction condition screening and experimental automation in chemistry (related work illustrating LLM agents for lab automation).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Autonomous chemical research with large language models.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-4 driven scientific agent system</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>tool-using LLM agent that plans and orchestrates experimental procedures</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>training_data_description</strong></td>
                            <td>Not detailed in this paper (cited as related work).</td>
                        </tr>
                        <tr>
                            <td><strong>generation_method</strong></td>
                            <td>LLM agent planning and tool orchestration (per cited work); not used directly in Chemma-RC experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>chemical_representation</strong></td>
                            <td>Textual instructions and integration with experimental automation tools (per cited work).</td>
                        </tr>
                        <tr>
                            <td><strong>target_application</strong></td>
                            <td>Automated experiment planning and execution, accelerating reaction condition screening in wet-lab settings (as cited).</td>
                        </tr>
                        <tr>
                            <td><strong>constraints_used</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>integration_with_external_tools</strong></td>
                            <td>Tool-using agent setups integrating lab automation hardware and software (per cited work, not used here).</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_used</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reported_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>experimental_validation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>challenges_or_limitations</strong></td>
                            <td>Paper cites such agent systems as promising but mentions safety/feasibility concerns when deploying LLM-generated conditions in autonomous synthesis platforms.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Text-Augmented Multimodal LLMs for Chemical Reaction Condition Recommendation', 'publication_date_yy_mm': '2024-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6883.9">
                <h3 class="extraction-instance">Extracted Data Instance 9 (e6883.9)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how large language models are used to synthesize novel chemical compounds for specific applications, including model details, generation methods, target applications, chemical representations, evaluation metrics, constraints, integration with external tools, datasets, reported performance, experimental validation, and reported challenges or limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ChemCrow</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>ChemCrow (LLM augmented with chem-expert tools)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Cited system that augments LLMs with chemistry-specific tools designed by domain experts to enable chemical task automation and assistive workflows; mentioned in related work as an approach for chemistry agents.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Augmenting large language models with chemistry tools.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>ChemCrow (LLM + chemistry toolset)</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>tool-using LLM agent augmented by domain tools</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>training_data_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>generation_method</strong></td>
                            <td>LLM augmented by external tool calls for chemistry-specific operations (per cited work, not used in Chemma-RC experiments).</td>
                        </tr>
                        <tr>
                            <td><strong>chemical_representation</strong></td>
                            <td>Textual plus tool-structured data; not detailed in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>target_application</strong></td>
                            <td>Chemical workflows and experimental assistance; exploration of conditions and experimental planning (cited in related work).</td>
                        </tr>
                        <tr>
                            <td><strong>constraints_used</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>integration_with_external_tools</strong></td>
                            <td>Chem-expert-designed tools (per cited work), not integrated in Chemma-RC pipeline.</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_used</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reported_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>experimental_validation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>challenges_or_limitations</strong></td>
                            <td>Mentioned as promising direction; general concerns about precise SMILES handling and safety when used in autonomous contexts apply.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Text-Augmented Multimodal LLMs for Chemical Reaction Condition Recommendation', 'publication_date_yy_mm': '2024-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6883.10">
                <h3 class="extraction-instance">Extracted Data Instance 10 (e6883.10)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how large language models are used to synthesize novel chemical compounds for specific applications, including model details, generation methods, target applications, chemical representations, evaluation metrics, constraints, integration with external tools, datasets, reported performance, experimental validation, and reported challenges or limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Reagent Transformer</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Reagent Transformer (SMILES-based transformer for reagent prediction)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A domain-specific SMILES/transformer based model for reagent prediction used as a baseline in this paper's evaluations.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Reagent Transformer</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>SMILES-based sequence model (Transformer) for reagent prediction</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>training_data_description</strong></td>
                            <td>Trained on reaction/regent prediction datasets per original work (not detailed here).</td>
                        </tr>
                        <tr>
                            <td><strong>generation_method</strong></td>
                            <td>Sequence-to-sequence generation of reagent SMILES/strings from reaction SMILES.</td>
                        </tr>
                        <tr>
                            <td><strong>chemical_representation</strong></td>
                            <td>SMILES</td>
                        </tr>
                        <tr>
                            <td><strong>target_application</strong></td>
                            <td>Reagent/condition prediction (baseline comparison on USPTO_500MT_Condition).</td>
                        </tr>
                        <tr>
                            <td><strong>constraints_used</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>integration_with_external_tools</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>dataset_used</strong></td>
                            <td>Evaluated on USPTO_500MT_Condition (Table 2 baseline).</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td>Top-1 exact acc, partial acc, recall, precision reported in Table 2 for comparison.</td>
                        </tr>
                        <tr>
                            <td><strong>reported_results</strong></td>
                            <td>Reagent Transformer top-1 exact ~17.5% and partial acc ~27.5% on USPTO_500MT_Condition (Table 2).</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_validation</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>challenges_or_limitations</strong></td>
                            <td>Lower performance than Chemma-RC in concatenated-unstructured condition generation tasks; SMILES-only approach can lack broader semantic context from textual corpus.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Text-Augmented Multimodal LLMs for Chemical Reaction Condition Recommendation', 'publication_date_yy_mm': '2024-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6883.11">
                <h3 class="extraction-instance">Extracted Data Instance 11 (e6883.11)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how large language models are used to synthesize novel chemical compounds for specific applications, including model details, generation methods, target applications, chemical representations, evaluation metrics, constraints, integration with external tools, datasets, reported performance, experimental validation, and reported challenges or limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Reaction GCNN</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Reaction GCNN (graph-convolutional neural network ranking model)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A graph-convolution neural network based ranking model for predicting condition sets cited and reproduced as a baseline in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Reaction GCNN</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>graph-convolutional neural network ranking model</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>training_data_description</strong></td>
                            <td>Trained on reaction-condition datasets per original work; used here as a baseline (reproduced).</td>
                        </tr>
                        <tr>
                            <td><strong>generation_method</strong></td>
                            <td>Predicts condition sets as labels/ranking (not generative SMILES output in this paper).</td>
                        </tr>
                        <tr>
                            <td><strong>chemical_representation</strong></td>
                            <td>Molecular graphs</td>
                        </tr>
                        <tr>
                            <td><strong>target_application</strong></td>
                            <td>Condition set prediction / ranking (baseline on USPTO_500MT_Condition).</td>
                        </tr>
                        <tr>
                            <td><strong>constraints_used</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>integration_with_external_tools</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>dataset_used</strong></td>
                            <td>USPTO_500MT_Condition (Table 2 baseline).</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td>Top-1 exact accuracy, partial accuracy, recall, precision (Table 2).</td>
                        </tr>
                        <tr>
                            <td><strong>reported_results</strong></td>
                            <td>Reaction GCNN top-1 exact ~16.1% and partial acc ~27.5% on USPTO_500MT_Condition (Table 2).</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_validation</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>challenges_or_limitations</strong></td>
                            <td>Baseline ranking approach lags behind Chemma-RC's multimodal LLM with ranking-enhancement for HTE-like tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Text-Augmented Multimodal LLMs for Chemical Reaction Condition Recommendation', 'publication_date_yy_mm': '2024-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Autonomous chemical research with large language models. <em>(Rating: 2)</em></li>
                <li>Augmenting large language models with chemistry tools. <em>(Rating: 2)</em></li>
                <li>Predictive Chemistry Augmented with Text Retrieval. <em>(Rating: 2)</em></li>
                <li>Developing ChemDFM as a large language foundation model for chemistry. <em>(Rating: 2)</em></li>
                <li>Perceiver: General Perception with Iterative Attention. <em>(Rating: 2)</em></li>
                <li>Llama 2: Open Foundation and Fine-Tuned Chat Models. <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-6883",
    "paper_id": "paper-281526344",
    "extraction_schema_id": "extraction-schema-132",
    "extracted_data": [
        {
            "name_short": "Chemma-RC",
            "name_full": "Chemma-RC (Text-Augmented Multimodal LLM for Reaction Condition Prediction)",
            "brief_description": "A text-augmented multimodal autoregressive LLM that aligns SMILES, reaction graphs, and retrieved text corpus into a shared embedding space to generate reaction conditions (solvents, reagents, catalysts) as SMILES/tokens; trained by supervised multimodal fine-tuning followed by a ranking-enhancement post-fine-tuning stage.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "Chemma-RC",
            "model_type": "text-augmented multimodal decoder-only LLM (LLM backbone integrated with domain encoders and projection modules); autoregressive next-token generator with post-fine-tuning ranking module",
            "model_size": "Backbone: LLaMA-2-7b (32-layer, ~7B); trainable adapters via LoRA ~0.3B parameters",
            "training_data_description": "Multimodal data: reaction SMILES encoded by Parrot-like reaction encoder, reaction graphs encoded by R-GCN, retrieved text corpus paragraphs (~190 tokens average) from patents/literature; datasets: USPTO-Condition and USPTO_500MT_Condition for SFT, and HTE ORD ligand data for ranking post-fine-tuning.",
            "generation_method": "Direct autoregressive generation of text and chemical tokens (generates SMILES for reagents/solvents/catalysts) after projecting graph/SMILES embeddings into LLM token space; two-stage training: multimodal supervised fine-tuning (next-token prediction + contrastive alignment) then Ranking Enhancement with Feedback (REF) using HTE yield-ranked candidates; LoRA parameter-efficient fine-tuning; cross-modal contrastive (InfoNCE) alignment; Perceiver projection modules for modality alignment.",
            "chemical_representation": "Reaction SMILES, reaction graphs (molecular graphs), learned reaction/graph tokens, and retrieved textual corpus; outputs produced as SMILES strings (reagents/solvents/catalysts) and natural language tokens.",
            "target_application": "Reaction condition prediction (solvents, reagents, catalysts) for organic synthesis; selection of high-yield ligands in high-throughput experimentation (HTE) contexts (e.g., Pd-catalysed imidazole C–H arylation ligand selection).",
            "constraints_used": "Ranking stage uses HTE yield-ordered candidate lists as supervision (learns to prefer higher-yield conditions); in HTE ligand selection experiments other conditions (base, solvent) were fixed by experimental design; no explicit synthetic-accessibility, toxicity, or patentability filters reported.",
            "integration_with_external_tools": "Retrieval system for finding similar corpus from literature/patents; Perceiver projection modules to map non-text embeddings into LLM token space; used GPT-4 to generate diverse question-prompt templates for instruction dataset construction; Parrot reaction encoder and R-GCN graph encoder are integrated but frozen during SFT; LoRA used for efficient fine-tuning.",
            "dataset_used": "USPTO-Condition (≈546k train), USPTO_500MT_Condition (≈88k train), curated ORD HTE dataset for Pd-catalysed imidazole C–H arylation ligand evaluation; retrieved patent/literature paragraphs paired per reaction for corpus augmentation.",
            "evaluation_metrics": "Top-k exact match accuracy (top-1, top-3, top-10, top-15), partial match accuracy (per-condition matching), top-1 exact match on concatenated condition strings, precision, recall, and HTE-specific top-1/top-50% ligand-selection metrics.",
            "reported_results": "USPTO-Condition (top-1): catalyst 92.7% ; solvent 1 54.6% ; solvent 2 81.8% ; reagent1 53.4% ; reagent2 78.7% (Table 1). USPTO_500MT_Condition (zero-shot): top-1 exact 25.9%, partial accuracy 69.7%, recall 67.9%, precision 79.3% (Table 2). Out-of-distribution (time-split average top-1): ~69.6% (Table 4). HTE Pd C–H arylation ligand selection: top-1 accuracy 93.7% vs baseline 38.1% (Zhao et al.) reported (Figure 4 / main text). Reported improvements over previous best (TextReact etc.) up to ~7% absolute on some tasks and overall improvements up to 17% over prior SOTA in benchmarking claim.",
            "experimental_validation": false,
            "challenges_or_limitations": "Paper-reported limitations include: (1) inherent one-to-many mapping of substrates→many valid conditions making optimal selection hard; (2) alignment across vastly different modality scales (atom-level graphs to corpus-level text) is challenging; (3) adding graph modality increases computational cost while providing limited aggregate gains (but helpful on very large/more complex substrates); (4) data sparsity and long-tail distributions (power-law) reduce performance for rare conditions; (5) safety and feasibility of generated conditions must be ensured before autonomous execution; (6) LLMs pretrained on text alone struggle with SMILES-sensitive tasks absent modality alignment.",
            "uuid": "e6883.0",
            "source_info": {
                "paper_title": "Text-Augmented Multimodal LLMs for Chemical Reaction Condition Recommendation",
                "publication_date_yy_mm": "2024-07"
            }
        },
        {
            "name_short": "LLaMA-2",
            "name_full": "LLaMA-2 (used as LLM backbone)",
            "brief_description": "A general-purpose decoder-only LLM used as the text-decoder backbone for Chemma-RC; integrated with projection layers and fine-tuned (via LoRA) to accept multimodal latent tokens for reaction condition generation.",
            "citation_title": "Llama 2: Open Foundation and Fine-Tuned Chat Models.",
            "mention_or_use": "use",
            "model_name": "LLaMA-2-7b (32-layer used in experiments)",
            "model_type": "decoder-only LLM backbone (fine-tuned with adapters/LoRA within a multimodal framework)",
            "model_size": "7B parameters (LLaMA-2-7b variant used)",
            "training_data_description": "Not detailed in this paper (pretrained general text foundation model referenced); used as off-the-shelf LLM backbone and further trained with multimodal instruction Q&A constructed from reaction SMILES, graphs, and retrieved corpus.",
            "generation_method": "Autoregressive next-token decoding for combined natural language and chemical token outputs; fine-tuned with LoRA during SFT stage.",
            "chemical_representation": "Operates on textual tokens; receives projected latent tokens from SMILES and graph encoders (via Perceiver) concatenated with text queries/corpus.",
            "target_application": "Backbone for generating reaction conditions and reagent/ligand SMILES in Chemma-RC.",
            "constraints_used": null,
            "integration_with_external_tools": "Connected to Perceiver projection modules for modality alignment, LoRA for parameter-efficient fine-tuning, and frozen Parrot/R-GCN encoders providing embeddings.",
            "dataset_used": "Fine-tuned on multimodal instruction datasets constructed from USPTO-Condition, USPTO_500MT_Condition and retrieved corpus; exact pretraining corpora not specified in this paper.",
            "evaluation_metrics": null,
            "reported_results": null,
            "experimental_validation": null,
            "challenges_or_limitations": "General-purpose LLMs (text-only pretraining) struggle on SMILES-sensitive tasks unless augmented/aligned with domain-specific representations; requires projection/alignment modules to consume graph/SMILES embeddings effectively.",
            "uuid": "e6883.1",
            "source_info": {
                "paper_title": "Text-Augmented Multimodal LLMs for Chemical Reaction Condition Recommendation",
                "publication_date_yy_mm": "2024-07"
            }
        },
        {
            "name_short": "Perceiver",
            "name_full": "Perceiver (latent-query projection module)",
            "brief_description": "A transformer-based projection module used in Chemma-RC to map graph and SMILES embeddings into a shared latent token space compatible with the LLM; found to outperform MLP and reprogramming projection variants for modality alignment in this work.",
            "citation_title": "Perceiver: General Perception with Iterative Attention.",
            "mention_or_use": "use",
            "model_name": "Perceiver projection modules (two independent Perceiver variants used for SMILES and graph)",
            "model_type": "transformer-based projection / alignment module (not a generative LLM)",
            "model_size": "Not specified in paper",
            "training_data_description": "Trained as part of Chemma-RC modality alignment on paired (SMILES, graph, text) reaction examples from USPTO datasets during SFT using contrastive InfoNCE loss.",
            "generation_method": "Not generative for molecules; used to produce latent tokens from continuous embeddings to feed into LLM for downstream generation.",
            "chemical_representation": "Takes as input SMILES and graph embeddings (from Parrot/R-GCN) and outputs latent tokens aligned to text token space.",
            "target_application": "Cross-modal representation alignment for reaction condition generation.",
            "constraints_used": null,
            "integration_with_external_tools": "Integrated inside Chemma-RC pipeline between encoders (Parrot/R-GCN) and LLaMA-2; used jointly with contrastive InfoNCE alignment losses.",
            "dataset_used": "USPTO-Condition and USPTO_500MT_Condition used during the alignment training.",
            "evaluation_metrics": "Ablation comparing projection modules: Perceiver achieved best performance (average gain ≈7.1% over reprogramming) — example: solvent1 top-1 54.6% (Perceiver) vs 51.1% (MLP) and 52.8% (Reprogramming) (Table 5).",
            "reported_results": "Perceiver projection achieved top-1 solvent1 accuracy 54.6% and overall best aggregated Top-k accuracies reported in Table 5.",
            "experimental_validation": false,
            "challenges_or_limitations": "Adds modeling complexity and compute; projection and alignment require careful contrastive training to avoid modality bias; no other explicit limitations reported beyond compute cost.",
            "uuid": "e6883.2",
            "source_info": {
                "paper_title": "Text-Augmented Multimodal LLMs for Chemical Reaction Condition Recommendation",
                "publication_date_yy_mm": "2024-07"
            }
        },
        {
            "name_short": "Parrot (reaction encoder)",
            "name_full": "Parrot (reaction SMILES encoder / attention-based reaction encoder)",
            "brief_description": "A reaction encoder used to produce SMILES-based reaction embeddings for Chemma-RC; Parrot is an attention-based model for encoding reaction SMILES used as frozen encoder in experiments.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "Parrot reaction encoder",
            "model_type": "attention-based sequence encoder for reaction SMILES (used as frozen encoder)",
            "model_size": null,
            "training_data_description": "Pretrained reaction representation model (details not given in this paper; cited as Wang et al.), used to extract SMILES embeddings for Chemma-RC training.",
            "generation_method": "Not a generative model here; provides embeddings that are projected into LLM token space.",
            "chemical_representation": "SMILES-based reaction representation (sequence input).",
            "target_application": "Provide SMILES embeddings for downstream reaction condition generation.",
            "constraints_used": null,
            "integration_with_external_tools": "Frozen within Chemma-RC; outputs passed through Perceiver projection into LLaMA-2 token space.",
            "dataset_used": "Parrot pretrained outside this work (paper cites Wang et al. for Parrot); Chemma-RC training used USPTO datasets to pair Parrot embeddings with corpus/graph embeddings.",
            "evaluation_metrics": null,
            "reported_results": null,
            "experimental_validation": false,
            "challenges_or_limitations": "SMILES-based encoders can miss some nuances (e.g., atom permutations) and sometimes provide similar information to graph encoders; adding graph encoder still helps for very large/complex substrates.",
            "uuid": "e6883.3",
            "source_info": {
                "paper_title": "Text-Augmented Multimodal LLMs for Chemical Reaction Condition Recommendation",
                "publication_date_yy_mm": "2024-07"
            }
        },
        {
            "name_short": "R-GCN",
            "name_full": "Relational Graph Convolutional Network (R-GCN) graph encoder",
            "brief_description": "A graph-based molecular encoder used to produce graph embeddings of reactions in Chemma-RC, providing atom-level structural information complementary to SMILES encodings.",
            "citation_title": "Modeling relational data with graph convolutional networks.",
            "mention_or_use": "use",
            "model_name": "R-GCN (graph convolutional network)",
            "model_type": "graph neural network encoder for molecular graphs (frozen during Chemma-RC SFT)",
            "model_size": null,
            "training_data_description": "Pretrained graph model from literature (cited), used to encode molecular graphs for Chemma-RC alignment.",
            "generation_method": "Not generative; provides graph embeddings that are projected into LLM token space.",
            "chemical_representation": "Molecular graphs (atom/bond relational structure).",
            "target_application": "Provide graph-level features to improve condition prediction for complex substrates.",
            "constraints_used": null,
            "integration_with_external_tools": "Outputs passed to Perceiver projection modules and then to LLaMA-2; frozen during SFT.",
            "dataset_used": "Same USPTO datasets used for pairing graph embeddings with SMILES and corpus during alignment training.",
            "evaluation_metrics": null,
            "reported_results": "Including graph modality with SMILES+corpus yielded incremental improvements for some condition types and provided notable benefits for very large/complex substrates (discussed in ablation and Figure 7/Table 3).",
            "experimental_validation": false,
            "challenges_or_limitations": "Graph modality increases computational cost; aggregate gains are smaller vs adding textual corpus, but critical for large/complex molecules.",
            "uuid": "e6883.4",
            "source_info": {
                "paper_title": "Text-Augmented Multimodal LLMs for Chemical Reaction Condition Recommendation",
                "publication_date_yy_mm": "2024-07"
            }
        },
        {
            "name_short": "GPT-4 (used for prompts & cited)",
            "name_full": "Generative Pre-trained Transformer 4 (GPT-4 / GPT-4o)",
            "brief_description": "State-of-the-art general-purpose multimodal LLMs cited as examples of LMMs applied in chemistry; in this work GPT-4 was leveraged to generate diverse question-prompt templates for instruction dataset construction, and GPT-4/GPT-4o are used as baseline comparisons in evaluation.",
            "citation_title": "Gpt-4 technical report.",
            "mention_or_use": "use",
            "model_name": "GPT-4 / GPT-4o",
            "model_type": "general-purpose multimodal LLM (decoder-only style)",
            "model_size": null,
            "training_data_description": "Not specified here (pretrained on broad web-scale corpora per original GPT-4 report); used only for prompt/template generation and baseline evaluation in experiments.",
            "generation_method": "Few-shot / zero-shot prompting (used as baseline); GPT-4 used to synthesize Q&A prompt templates for instruction datasets.",
            "chemical_representation": "Textual tokens; can process SMILES as text but lacks specialized SMILES encoders unless augmented.",
            "target_application": "Prompt/template generation for instruction data; baseline for condition prediction comparisons; cited use-cases include molecule design and experiment planning in related work.",
            "constraints_used": null,
            "integration_with_external_tools": "In other cited works GPT-4 is used as an agent integrated with tools; in this paper GPT-4 used to generate prompts and evaluated as baseline via API.",
            "dataset_used": "Evaluated zero-/one-/five-shot on USPTO_500MT_Condition (Table 2) as baseline.",
            "evaluation_metrics": "Top-1 exact accuracy and partial accuracy reported for baselines in Table 2.",
            "reported_results": "GPT-4o (zero-shot) reported top-1 exact ~1.0% and partial acc ~13.0% on USPTO_500MT_Condition (Table 2).",
            "experimental_validation": false,
            "challenges_or_limitations": "Poor performance on SMILES/sequence-sensitive reaction condition generation compared to domain-specific models; general-purpose LLMs often underperform on tasks requiring precise molecule-string handling.",
            "uuid": "e6883.5",
            "source_info": {
                "paper_title": "Text-Augmented Multimodal LLMs for Chemical Reaction Condition Recommendation",
                "publication_date_yy_mm": "2024-07"
            }
        },
        {
            "name_short": "ChemDFM",
            "name_full": "ChemDFM (Large chemical domain LLM)",
            "brief_description": "A domain-specific large multimodal LLM for chemistry trained on a large chemical corpus; used as a baseline comparison in this work and reported to have limited zero-shot performance on reaction condition generation tasks compared to Chemma-RC.",
            "citation_title": "Developing ChemDFM as a large language foundation model for chemistry.",
            "mention_or_use": "use",
            "model_name": "ChemDFM",
            "model_type": "large chemical-domain LLM (general-purpose chemical foundation model)",
            "model_size": "Trained on ~34B chemical text tokens (paper notes), fine-tuned with ~2.7M instructions (reference in text).",
            "training_data_description": "Chemical literature and textbooks totalling ~34B tokens; instruction fine-tuning with chemical instructions (per cited description).",
            "generation_method": "Autoregressive LLM generation; evaluated in zero-/one-/few-shot settings for condition generation.",
            "chemical_representation": "Textual chemical strings and literature-derived content; not specialized multimodal alignment of graphs/SMILES as in Chemma-RC (per paper discussion).",
            "target_application": "General chemical tasks; evaluated for reagent/condition generation as baseline.",
            "constraints_used": null,
            "integration_with_external_tools": null,
            "dataset_used": "Evaluated on USPTO_500MT_Condition dataset (Table 2) as baseline.",
            "evaluation_metrics": "Top-1 exact accuracy, partial accuracy, recall, precision on USPTO_500MT_Condition.",
            "reported_results": "ChemDFM (zero-shot) top-1 exact ~3.0% and partial accuracy ~38.0% on USPTO_500MT_Condition (Table 2).",
            "experimental_validation": false,
            "challenges_or_limitations": "Despite large chemical pretraining, showed low zero-shot accuracy on structured condition generation tasks; lacks explicit multimodal alignment (SMILES+graph+corpus) used by Chemma-RC which limited performance here.",
            "uuid": "e6883.6",
            "source_info": {
                "paper_title": "Text-Augmented Multimodal LLMs for Chemical Reaction Condition Recommendation",
                "publication_date_yy_mm": "2024-07"
            }
        },
        {
            "name_short": "TextReact",
            "name_full": "TextReact (Predictive Chemistry Augmented with Text Retrieval)",
            "brief_description": "A prior method that augments SMILES-based reaction representations with retrieved textual corpus from literature to improve reaction condition prediction; used as a baseline and ablation point in this work.",
            "citation_title": "Predictive Chemistry Augmented with Text Retrieval.",
            "mention_or_use": "use",
            "model_name": "TextReact (retrieval-augmented SMILES transformer)",
            "model_type": "SMILES-based transformer augmented with retrieved textual corpus (retrieval-augmented model)",
            "model_size": null,
            "training_data_description": "SMILES reaction data paired with retrieved relevant corpus entries from literature; evaluated on USPTO-Condition.",
            "generation_method": "Transformer-based sequence-to-sequence prediction using SMILES + retrieved corpus context.",
            "chemical_representation": "SMILES plus retrieved textual corpus paragraphs.",
            "target_application": "Reaction condition prediction (baseline comparison).",
            "constraints_used": "Original TextReact uses gold texts in some settings; in this paper TextReact variants excluding gold texts (TextReact(gr)) were used to avoid label leakage.",
            "integration_with_external_tools": "Retrieval pipeline to fetch similar corpus paragraphs from literature/patents (same retrieval approach used by Chemma-RC for corpus augmentation).",
            "dataset_used": "USPTO-Condition (TextReact variants compared in Table 1 and Table 4).",
            "evaluation_metrics": "Top-k accuracy (top-1 etc.) and out-of-distribution time-split evaluation.",
            "reported_results": "TextReact (no-gold-text variant) top-1 averaged lower than Chemma-RC; e.g., Chemma-RC reported ≈7% absolute improvement over TextReact on aggregate metrics (Table 1 / Table 4 comparisons). Specific numbers in Table 1 show TextReact variant top-1 solvent1 ~51.7% vs Chemma-RC 54.6%.",
            "experimental_validation": false,
            "challenges_or_limitations": "Relies on retrieval quality; using gold corpus in evaluation can cause label leakage—careful retrieval required to avoid information leak; still outperformed by multimodal alignment approach in Chemma-RC.",
            "uuid": "e6883.7",
            "source_info": {
                "paper_title": "Text-Augmented Multimodal LLMs for Chemical Reaction Condition Recommendation",
                "publication_date_yy_mm": "2024-07"
            }
        },
        {
            "name_short": "Boiko et al. GPT-4 agent",
            "name_full": "GPT-4 driven scientific agent system (Boiko et al.)",
            "brief_description": "Cited prior work that used GPT-4 driven agents to plan and perform complex experiments to accelerate reaction condition screening and experimental automation in chemistry (related work illustrating LLM agents for lab automation).",
            "citation_title": "Autonomous chemical research with large language models.",
            "mention_or_use": "mention",
            "model_name": "GPT-4 driven scientific agent system",
            "model_type": "tool-using LLM agent that plans and orchestrates experimental procedures",
            "model_size": null,
            "training_data_description": "Not detailed in this paper (cited as related work).",
            "generation_method": "LLM agent planning and tool orchestration (per cited work); not used directly in Chemma-RC experiments.",
            "chemical_representation": "Textual instructions and integration with experimental automation tools (per cited work).",
            "target_application": "Automated experiment planning and execution, accelerating reaction condition screening in wet-lab settings (as cited).",
            "constraints_used": null,
            "integration_with_external_tools": "Tool-using agent setups integrating lab automation hardware and software (per cited work, not used here).",
            "dataset_used": null,
            "evaluation_metrics": null,
            "reported_results": null,
            "experimental_validation": null,
            "challenges_or_limitations": "Paper cites such agent systems as promising but mentions safety/feasibility concerns when deploying LLM-generated conditions in autonomous synthesis platforms.",
            "uuid": "e6883.8",
            "source_info": {
                "paper_title": "Text-Augmented Multimodal LLMs for Chemical Reaction Condition Recommendation",
                "publication_date_yy_mm": "2024-07"
            }
        },
        {
            "name_short": "ChemCrow",
            "name_full": "ChemCrow (LLM augmented with chem-expert tools)",
            "brief_description": "Cited system that augments LLMs with chemistry-specific tools designed by domain experts to enable chemical task automation and assistive workflows; mentioned in related work as an approach for chemistry agents.",
            "citation_title": "Augmenting large language models with chemistry tools.",
            "mention_or_use": "mention",
            "model_name": "ChemCrow (LLM + chemistry toolset)",
            "model_type": "tool-using LLM agent augmented by domain tools",
            "model_size": null,
            "training_data_description": null,
            "generation_method": "LLM augmented by external tool calls for chemistry-specific operations (per cited work, not used in Chemma-RC experiments).",
            "chemical_representation": "Textual plus tool-structured data; not detailed in this paper.",
            "target_application": "Chemical workflows and experimental assistance; exploration of conditions and experimental planning (cited in related work).",
            "constraints_used": null,
            "integration_with_external_tools": "Chem-expert-designed tools (per cited work), not integrated in Chemma-RC pipeline.",
            "dataset_used": null,
            "evaluation_metrics": null,
            "reported_results": null,
            "experimental_validation": null,
            "challenges_or_limitations": "Mentioned as promising direction; general concerns about precise SMILES handling and safety when used in autonomous contexts apply.",
            "uuid": "e6883.9",
            "source_info": {
                "paper_title": "Text-Augmented Multimodal LLMs for Chemical Reaction Condition Recommendation",
                "publication_date_yy_mm": "2024-07"
            }
        },
        {
            "name_short": "Reagent Transformer",
            "name_full": "Reagent Transformer (SMILES-based transformer for reagent prediction)",
            "brief_description": "A domain-specific SMILES/transformer based model for reagent prediction used as a baseline in this paper's evaluations.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "Reagent Transformer",
            "model_type": "SMILES-based sequence model (Transformer) for reagent prediction",
            "model_size": null,
            "training_data_description": "Trained on reaction/regent prediction datasets per original work (not detailed here).",
            "generation_method": "Sequence-to-sequence generation of reagent SMILES/strings from reaction SMILES.",
            "chemical_representation": "SMILES",
            "target_application": "Reagent/condition prediction (baseline comparison on USPTO_500MT_Condition).",
            "constraints_used": null,
            "integration_with_external_tools": null,
            "dataset_used": "Evaluated on USPTO_500MT_Condition (Table 2 baseline).",
            "evaluation_metrics": "Top-1 exact acc, partial acc, recall, precision reported in Table 2 for comparison.",
            "reported_results": "Reagent Transformer top-1 exact ~17.5% and partial acc ~27.5% on USPTO_500MT_Condition (Table 2).",
            "experimental_validation": false,
            "challenges_or_limitations": "Lower performance than Chemma-RC in concatenated-unstructured condition generation tasks; SMILES-only approach can lack broader semantic context from textual corpus.",
            "uuid": "e6883.10",
            "source_info": {
                "paper_title": "Text-Augmented Multimodal LLMs for Chemical Reaction Condition Recommendation",
                "publication_date_yy_mm": "2024-07"
            }
        },
        {
            "name_short": "Reaction GCNN",
            "name_full": "Reaction GCNN (graph-convolutional neural network ranking model)",
            "brief_description": "A graph-convolution neural network based ranking model for predicting condition sets cited and reproduced as a baseline in this paper.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "Reaction GCNN",
            "model_type": "graph-convolutional neural network ranking model",
            "model_size": null,
            "training_data_description": "Trained on reaction-condition datasets per original work; used here as a baseline (reproduced).",
            "generation_method": "Predicts condition sets as labels/ranking (not generative SMILES output in this paper).",
            "chemical_representation": "Molecular graphs",
            "target_application": "Condition set prediction / ranking (baseline on USPTO_500MT_Condition).",
            "constraints_used": null,
            "integration_with_external_tools": null,
            "dataset_used": "USPTO_500MT_Condition (Table 2 baseline).",
            "evaluation_metrics": "Top-1 exact accuracy, partial accuracy, recall, precision (Table 2).",
            "reported_results": "Reaction GCNN top-1 exact ~16.1% and partial acc ~27.5% on USPTO_500MT_Condition (Table 2).",
            "experimental_validation": false,
            "challenges_or_limitations": "Baseline ranking approach lags behind Chemma-RC's multimodal LLM with ranking-enhancement for HTE-like tasks.",
            "uuid": "e6883.11",
            "source_info": {
                "paper_title": "Text-Augmented Multimodal LLMs for Chemical Reaction Condition Recommendation",
                "publication_date_yy_mm": "2024-07"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Autonomous chemical research with large language models.",
            "rating": 2,
            "sanitized_title": "autonomous_chemical_research_with_large_language_models"
        },
        {
            "paper_title": "Augmenting large language models with chemistry tools.",
            "rating": 2,
            "sanitized_title": "augmenting_large_language_models_with_chemistry_tools"
        },
        {
            "paper_title": "Predictive Chemistry Augmented with Text Retrieval.",
            "rating": 2,
            "sanitized_title": "predictive_chemistry_augmented_with_text_retrieval"
        },
        {
            "paper_title": "Developing ChemDFM as a large language foundation model for chemistry.",
            "rating": 2,
            "sanitized_title": "developing_chemdfm_as_a_large_language_foundation_model_for_chemistry"
        },
        {
            "paper_title": "Perceiver: General Perception with Iterative Attention.",
            "rating": 2,
            "sanitized_title": "perceiver_general_perception_with_iterative_attention"
        },
        {
            "paper_title": "Llama 2: Open Foundation and Fine-Tuned Chat Models.",
            "rating": 1,
            "sanitized_title": "llama_2_open_foundation_and_finetuned_chat_models"
        }
    ],
    "cost": 0.025579249999999998,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Text-Augmented Multimodal LLMs for Chemical Reaction Condition Prediction
25 Sep 2025</p>
<p>Yu Zhang 
MoE Key Laboratory of Artificial Intelligence
AI Institute
Shanghai Jiao Tong University</p>
<p>Ruijie Yu 
Kaipeng Zeng 
MoE Key Laboratory of Artificial Intelligence
AI Institute
Shanghai Jiao Tong University</p>
<p>Ding Li 
MoE Key Laboratory of Artificial Intelligence
AI Institute
Shanghai Jiao Tong University</p>
<p>Feng Zhu 
MoE Key Laboratory of Artificial Intelligence
AI Institute
Shanghai Jiao Tong University</p>
<p>Frontiers Science Center for Transformative Molecules (FSCTM)
Shanghai Jiao Tong University</p>
<p>Xiaokang Yang 
MoE Key Laboratory of Artificial Intelligence
AI Institute
Shanghai Jiao Tong University</p>
<p>Yaohui Jin 
MoE Key Laboratory of Artificial Intelligence
AI Institute
Shanghai Jiao Tong University</p>
<p>Yanyan Xu yanyanxu@sjtu.edu.cn 
MoE Key Laboratory of Artificial Intelligence
AI Institute
Shanghai Jiao Tong University</p>
<p>Text-Augmented Multimodal LLMs for Chemical Reaction Condition Prediction
25 Sep 202523F06603C638B0484C4E157E4D564C84arXiv:2407.15141v2[cs.AI]Text-augmentedMultimodal LLMChemical reaction condition prediction
Identifying reaction conditions that are broadly applicable across diverse substrates is a longstanding challenge in chemical and pharmaceutical research.While many methods are available to generate conditions with acceptable performance, a universal approach for reliably discovering effective conditions during reaction exploration is rare.Consequently, current reaction optimization processes are often labor-intensive, time-consuming, and costly, relying heavily on trial-and-error experimentation.Nowadays, large language models (LLMs) are capable of tackling chemistry-related problems, such as molecule design and chemical reasoning tasks.Here, we report the design, implementation and application of Chemma-RC, a text-augmented multimodal LLM to identify effective conditions through task-specific dialogue and condition generation.Chemma-RC learns a unified representation of chemical reactions by aligning multiple modalities-including text corpus, reaction SMILES, and reaction graphs-within a shared embedding module.Performance benchmarking on datasets showed high precision in identifying optimal conditions, with up to 17% improvement over the current state-of-the-art methods.A palladium-catalysed imidazole C-H arylation reaction was investigated experimentally to evaluate the functionalities of the Chemma-RC in practice.Our findings suggest that Chemma-RC holds significant potential to accelerate highthroughput condition screening in chemical synthesis.CCS Concepts• Applied computing → Chemistry; • Computing methodologies → Artificial intelligence.</p>
<p>Introduction</p>
<p>Chemical synthesis is a crucial step for the discovery of transformative molecules in multiple fields, including drug design, materials, renewable energy, etc.In chemical synthesis, reaction conditions are usually optimized to maximize the yield of each target molecule and to be applicable to a wide variety of substrates [37,38].Despite synthetic methods have achieved significant advancements over the past few decades, discovering effective reaction conditions from the vast substrates still relies on the trial-and-error experimental efforts [4].While automated platforms have increased the efficiency of reaction optimization and reduced exploration costs, challenges in exploring reaction conditions still hinder the adoption of new methodologies in synthetic chemistry.Additionally, optimization is often necessary for different target substrates, and pharmaceutically relevant molecules with high structural complexity may not be compatible with existing conditions.Recently, chemists have focused on designing reliable computer-aided synthesis planning (CASP) tools to facilitate condition screening [11,28,36].Transformer-based models built upon SMILES or reaction graphs have demonstrated strong effectiveness in addressing various chemical tasks [3,14,35].However, practical prediction for reaction conditions is more complex than what can be achieved by using graph methods alone.Therefore, a universal approach to discover effective conditions is still rare [27,32].In summary, to realize efficient synthesis in chemistry, there is an urgent need to facilitate high-efficiency reaction condition prediction.</p>
<p>Nowadays, the emergence of generative large language models (LLMs) or large multimodal models (LMMs), typified by GPT-4 and GPT-4o [1], has sparked significant interest in the field of AI for chemistry [2,6,7,16,25].The prediction and design of reaction conditions necessitate LLMs to be controllable for generating molecular structures that satisfy the substrates and synthesizability requirements.These requirements can be articulated as questions for LLM input, as illustrated in Figure 1A.Answering these questions demands a comprehensive understanding of chemical reactions and the relationship between substrates and conditions.However, sequence-based LLMs struggle with this because they are pre-trained or fine-tuned solely on texts.Notably, even in comparatively easier tasks related to molecules, such as captioning and understanding, the best LLMs perform worse than the domain-specific model, like GraphQA, an effective graph-based method in the design of molecules [15].As we investigate that there are various types of data in the field of chemistry, including simplified molecular-input line-entry system (SMILES) [44], reaction graphs, and a textual corpus of reaction [33], which encompasses the descriptions of reaction processes and reaction mechanisms.Among several data modalities, chemical large multimodal models (LMMs) are essential, with LLMs handling text generation and domain-specific models managing reaction representations [22].However, under the paradigm of LMMs, there are still two important challenges in chemical reaction prediction.First, the inherently 'one-to-many' nature of chemical reactions, where a single substrate may correspond to multiple valid reaction conditions, makes it difficult for LMMs to identify optimal reaction conditions.Second, multiple scales of different modalities of data, from atom-level structures to high-level corpora texts [30], render conventional cross-modal alignment methods ineffective.Addressing these challenges is essential for building chemical LMMs capable of advancing reaction prediction and optimization.Thus, we propose the multimodal LLM, Chemma-RC, for reaction condition prediction.As shown in Figure 1, Chemma-RC integrates LLMs and the other chemical domain-specific models within a multi-modal auto-regressive framework.It predicts the next token across both word and chemical space, enabling the direct generation of reaction conditions.In summary, we think Chemma-RC can be a potential solution due to the following advantages: (i) foundational LLMs can learn relationships between molecules and reactions, thereby acquiring chemical knowledge akin to the learning process of chemists; (ii) via learning the joint representation of chemical reactions from different modalities-graphs, reaction SMILES, and corpus, LLMs might be better equipped to capture the underlying chemical semantics of reactions, thereby improving the accuracy of reaction condition prediction.</p>
<p>The contributions of this work are summarized as follows:</p>
<p>(1) we first design a multimodal LLM, Chemma-RC, to jointly learn a unified reaction representation from SMILES, graphs, and corpus for condition prediction; (2) We design a post-fine-tuning strategy that integrates a ranking enhancement with feedback module to facilitate the generation of optimal conditions; (3) We design a cross-modality contrastive learning strategy to achieve unified and semantically representations across different modalities.</p>
<p>Through evaluation on benchmark datasets, Chemma-RC exhibits strong generalization capabilities on out-of-domain (OOD) and high-throughput experimentation (HTE) datasets.</p>
<p>Related Work</p>
<p>Since the emergence of DeepSeek [21], GPT-4 series [1], LLMs have become foundational models in addressing text-based challenges.The influence of these models is increasingly evident in the fields of chemistry [17], biology, and materials science, where they are being applied to complex molecular studies [13].In the field of chemistry,  [45,46].Further, in the study of organic synthesis, reaction conditions are usually designed and optimized to maximize the yield of each target molecule or minimize the cost of the reaction process [37,38].High-throughput condition screening, as an important tool in synthesizing molecules, exerts an important influence on chemical synthesis.For decades, chemists have focused on building reliable and convenient computer-aided synthesis planning (CASP) tools to facilitate chemical synthesis [28].[12,35], which were applied in forward prediction and reaction condition prediction tasks [3,35].Wang et al. reported the application of reinforcement learning models to identify generally applicable conditions [41].Chemical reaction condition prediction tasks aim to identify catalysts, reagents, solvents, or other conditions for a specific reaction.The exploration of a suitable condition is crucial in synthetic chemistry, as it dictates the expected outcomes, including reaction yields and rates [34].Gao et al. developed a neural network model to predict the chemical context as well as the temperature for any particular organic reaction [14]; Maser et al. proposed a machine-learned ranking model to predict the set of conditions used in a reaction as a binary vector [26]; Wang et al. proposed Parrot, a powerful and interpretable transformer-based model for the prediction of reaction condition [42]; In the meantime, in order to enhance the representation of reactions, Qian et al. [30] designed TextReact, which introduced relevant corpus retrieved from literature to enhance the molecular representation of the reaction based on SMILES.Nevertheless, these methods rely on manual feature selection by experts' knowledge and lack a general prediction model with powerful reaction representation.</p>
<p>Nowadays, the emergence of generative pre-trained transformerbased large language models (LLMs), typified by GPT-4, has triggered keen interest in leveraging such techniques to tackle chemistry challenges [2,6].Several works focus on chemical agents for the exploration of chemical conditions.Boiko et al. [7] proposed a GPT-4 driven scientific agent system to plan and perform complex experiments, which accelerates reaction condition screening and experimental automation in chemistry; Bran et al. developed ChemCrow, which augmented LLMs with chem-expert-designed tools [25]; However, for tasks demanding a precise understanding of molecular SMILES representation, such as reaction prediction, and retrosynthesis, LLMs exhibited a less competitive performance than traditional machine learning baselines [16].Partially, the reason is that, without an in-depth understanding of the SMILES strings and the reaction process that transforms reactants into products, it will be difficult for LLMs to generate accurate responses.</p>
<p>Methods</p>
<p>Problem Setup</p>
<p>For a task of reaction condition prediction, we define these symbols for following clarification: (1) reaction SMILES input , reaction SMILES representation encoded by encoder   , and reaction tokens  ; (2) graph representation of a reaction   and graph tokens ; (3) text corpus of similar reactions  , and text tokens  ; (4) reaction conditions  , which includes the catalyst, solvent, and reagent.We define F as a condition prediction function, then we obtain:
𝑌 = F (𝑋, 𝐺,𝑇 )(1)</p>
<p>Model Structure</p>
<p>An overview of Chemma-RC is illustrated in Figure 1.Chemma-RC responds to task-specific questions constructed by instruction prompts such as "which solvents would you recommend?", and generate answers as reaction conditions prediction.Firstly, it learns a unified reaction representation from SMILES, graphs, and corpus.Subsequently, the tunable modality alignment transforms the graph and SMILES embeddings into language tokens compatible with the  LLM space.Finally, Chemma-RC generates the SMILES of reagents, solvents, and catalysts as predicted results.</p>
<p>To formalize this, let  = { 1 ,  2 , . . .,   } be a sequence of word tokens (denoted as <Corpus> in Figure 2) of length  from the vocabulary W, reaction tokens <Reaction>  = { 1 ,  2 , . . .,   } of length , and graph tokens <Graph>  = { 1 ,  2 , . . .,   } of length , LLMs parameterized by  decompose the joint distribution as   ( ) =  =1   (  |  &lt; ), where  &lt; represents the tokens preceding the -th position.These learnable reaction and graph tokens, along with text tokens, are then input into the LLM to predict chemical reaction conditions, as shown in the equation 2:
L LM = ∑︁ 𝑖 − log 𝑝 𝜃 (𝑤 𝑖 | 𝑊 &lt;𝑖 , 𝑋, 𝐺)(2)</p>
<p>Modality Alignment</p>
<p>In Figure 1B, we introduce an alignment module designed to facilitate cross-modal representation learning among three distinct modalities.This module leverages latent tokens derived from graph and SMILES embeddings, aligning them with corresponding textbased tokens.To achieve this alignment, we utilize two transformerbased Perceiver modules [19], which project the graph and SMILES representations into a shared semantic space compatible with LLMs.Although these Perceiver modules share an identical architecture, they are parameterized independently.The pseudo-code for the modality projection process is detailed in Appendix C.</p>
<p>To optimize this alignment, we adopt a contrastive learning loss approach.Specifically, an InfoNCE loss, described in equation 3, is designed to minimize the embedding distance between the textual modality and its corresponding graph and SMILES representations for the same reaction (L text-graph and L text-SMILES ).Simultaneously, it maximizes the distance between graph and SMILES representations of different reactions (L graph-SMILES ).This dual application of the InfoNCE loss effectively aligns text-graph and text-SMILES pairs from the same reaction while contrasting graph-SMILES pairs from different reactions.
L text-graph = − 1 2 E x𝑔,x𝑡 log exp 𝐸 (x 𝑔 , x 𝑡 ) exp 𝐸 (x 𝑔 , x 𝑡 ) + x 𝑡 ′ ≠x𝑡 exp 𝐸 (x 𝑔 , x 𝑡 ′ ) + log exp 𝐸 (x 𝑔 , x 𝑡 ) exp 𝐸 (x 𝑔 , x 𝑡 ) + x 𝑔 ′ ≠x𝑔 exp 𝐸 (x 𝑔 ′ , x 𝑡 )(3)
where x t and x g form the text-graph pair for each reaction, and x  ′ and x  ′ are the negative samples randomly sampled from the noise distribution, which we use the empirical data distribution. (•) is the dot product function on the jointly learned space, that is,  x g , x t =  g •  g x g ,  t •  t (x t ) , where • is the function composition.</p>
<p>The final alignment loss for the module can be computed as a weighted sum of all contrastive pairs presented in Equation 4, with each term calculated using the InfoNCE loss presented in Equation 3.
L align = 1 3 L text-graph + L text-SMILES + L graph-SMILES(4)
We propose a two-stage training strategy for Chemma-RC, consisting of supervised fine-tuning (SFT) followed by post fine-tuning, as detailed in Section 3.5.Therefore, for the first training stage, the final loss for training Chemma-RC is the integration of next token prediction loss (L LM ) and alignment loss (L align ), which is illustrated in equation 5:
L final = L LM + L align (5)
3.4 Ranking Enhancement with Feedback (REF)</p>
<p>Given our focus on the practical applications in synthetic chemistry, we also want to underscore the significance of accurately identifying reaction conditions that lead to high-yield outcomes.</p>
<p>Large chemical models such as ChemDFM [46] commonly use top 50% accuracy to evaluate ligand prediction performance.This metric is well-suited for high-throughput experimentation (HTE) datasets, where the top-ranked half of ligands generally correspond to satisfactory reaction outcomes.However, when models trained under this paradigm are transferred to literature-based datasets for one-shot condition prediction, they often fail to generate suitable reaction conditions that lead to high yields.</p>
<p>To address this, as depicted in Figure 1C, we design the ranking enhancement module with feedback.This component is the second stage phase of training, as the detailed training process is discussed in Section 3.5.It learns the preferences among condition candidates, thereby enabling the model to predict conditions that are optimized for each specific target substrate.Specifically, it provides a prediction score not only for the ground truth preference condition but also for a set of candidates.During post-fine-tuning, we utilize High-Throughput Experimentation (HTE) data for training, which are predefined and sorted according to their yields of reaction outcomes.The objective of this fine-tuning is to learn a ranking function that assigns higher prediction scores to condition candidates of higher performance.We employ a ranking loss that penalizes the model when it fails to rank high-yield candidates above lower-yield ones.The ranking loss is defined as follows:
L Ranking = 𝑛−1 ∑︁ 𝑖=1 max (0, Δ 𝑖 − score (𝐶 𝑖 ) + score (𝐶 𝑖+1 ))(6)
where L Ranking is the ranking loss,  is the number of candidates, Δ  is the allowed margin between the scores of the -th candidate   and the ( + 1)-th candidate  +1 , and score(  ) is the model's prediction score for the -th candidate.The loss function encourages the model to learn that the score of the -th candidate should be at least Δ  higher than the score of the ( + 1)-th candidate.If the predictions do not meet this criterion, the loss is non-zero and the model is penalized.</p>
<p>End-to-End Model Fine-tuning</p>
<p>Supervised Fine-Tuning (SFT): we employ multimodal SFT to integrate the base LLM with other modules in Chemma-RC.In this process, we freeze the parameters of the reaction and graph encoders depicted in Figure 1A, and focus on fine-tuning the parameters of the LLM, denoted as  in Equation 2, as well as the projection layers for the query tokens  and .The projection layers for the graph and reaction encoders are designed to share the same architecture, although they are parameterized independently.The optimization can be performed end-to-end using Equation 2. This fine-tuning stage aligns the LLM with domain-specific models.</p>
<p>To preserve the generality of the base LLM, and improve training efficiency, we utilize parameter-efficient LoRA for SFT.</p>
<p>Ranking Enhancement with Feedback (REF):</p>
<p>The REF stage is the second phase of training, following the initial SFT stage.In this phase, we focus exclusively on optimizing the ranking loss, while keeping the parameters fine-tuned during SFT frozen.This approach allows the ranking enhancement module to learn preferences among different reaction condition candidates, improving the model's ability to predict high-yield outcomes for specific target substrates.</p>
<p>Construction of Multimodal Instruction Datasets</p>
<p>Instruction prompt datasets refer to format structured or unstructured data as natural language instructions so that LLMs can respond properly [31,43].Here, we introduce a tailored format of instruction-style prompts to facilitate multimodal SFT, shown in  To be specific, given a reaction, we retrieve a relevant corpus-a paragraph containing contextual information that closely resembles the reaction-and populate the <Corpus> placeholder with this data.Next, the reaction is converted into its corresponding SMILES format, and inserted into the specific token placeholder <Reaction SMILES>.Finally, we introduce two additional token placeholders, <Reaction> and <Graph>, for reaction SMILES and graph representations, respectively.To enhance the diversity of the dataset, we further leverage GPT-4 to generate a wide range of question prompts.These prompts are based on predefined templates, examples of which are provided in Table 8.</p>
<p>Experiments and Results</p>
<p>Data</p>
<p>We evaluate on two benchmark datasets, USPTO-Condition and USPTO_500MT_Condition, respectively.The details of data description are presented in Appendix A and Table 6.The visualization of data distribution is depicted in Figure 5.As shown in Table 6, the reaction conditions in the USPTO-Condition dataset are divided into five distinct categories, such as solvent 1, reagent 1, etc, and presented in a fixed order, which results in a more structured prediction task.In contrast, all reaction conditions in USPTO_500MT_Condition dataset are a single dot-concatenated string, posing a greater challenge due to the need to generate an unstructured sequence with correct formatting and semantics.</p>
<p>Experiment Setup</p>
<p>In our work, the reaction encoder is implemented based on Wang et al. [42].A pre-trained graph model proposed by [33] encodes the molecules in the reaction.We utilize LLaMA-2 [39] as a text decoder.Each reaction has a corresponding similar corpus, a paragraph describing a chemical reaction with an average length of 190 tokens.During the training process, we freeze the weight parameters of GCN and the reaction encoder.The modality alignment and part layers of LLaMA-2 are trainable.We utilize parameter-efficient LoRA for SFT, and the trainable parameters constitute approximately 0.3 billion out of the total 7 billion parameters.The multimodal SFT process is conducted with a batch size of 16 for fewer than 6 epochs over 48 hours, utilizing a GPU configuration of 2 × 48 GB NVIDIA A6000 GPUs.Inference is performed on a single 80 GB NVIDIA A800 GPU.Detailed training configuration is shown in Appendix B.</p>
<p>Performance Comparison</p>
<p>We conduct a systematic evaluation to demonstrate Chemma-RC's superior performance for reaction condition prediction.Compared baseline methods include rxnfp LSTM [14], Reaction GCNN [26], TextReact [30], and Reagent Transformer [3].The detailed introduction of these methods is presented in Appendix D.</p>
<p>For the USPTO-Condition dataset, we calculate top- accuracy with a strict matching policy.All SMILES from the prediction results are canonicalized to ensure consistent comparison.As depicted in Table 1, TextReact  refers that we utilize similar text [30] paired with the corresponding reaction for training.To avoid label leak issues, we do not use gold text mentioned in his work for training or testing.Thanks to the work of Qian et al., we retrieve the most semantically relevant corpus entries from literature or patents for each reaction.These retrieved corpus are integrated with reactions to construct Q&amp;A instruction datasets for multimodal SFT.</p>
<p>The overall performance is summarized in the Table 1.From the results, we can see that Chemma-RC consistently outperforms the baselines across all categories and accuracy levels, yielding a significant improvement of 7% over TextReact.Specifically, Chemma-RC achieves superior performance compared to other methods, attaining top-1 accuracy of 54.6% for solvent 1 and 81.8% for solvent 2 prediction, respectively.We also observe that the observed performance disparity across condition types-such as the significantly higher accuracy for catalyst prediction (92.7%) compared to solvent 1 prediction (54.6%).It can be attributed to the inherent distributional differences within the dataset.Specifically, the statistical results in Table 7 illustrate that the number of distinct catalyst types present in the training data is relatively limited, which leads to the highly consistent usage across reactions.In contrast, the solvent category, particularly solvent 1, exhibits much greater chemical diversity, with a larger number of unique solvents and more varied usage contexts.This increased diversity results in a more challenging prediction task, leading to lower model performance in this category.</p>
<p>For the USPTO_500MT_Condition dataset, all reaction conditions are a single dot-concatenated string, annotated as reagents.All reaction conditions must be generated in a single inference pass and then canonicalized to ensure consistency for evaluation and comparison.In Table 2, we report two metrics, including top-1 accuracy and partial accuracy.Different from the complete match accuracy that requires an exact match between the predicted and ground-truth conditions, the partial match accuracy focuses more on evaluating whether individual components (e.g., solvent, reagent, or catalyst) are correctly predicted, even if the full sequence is not perfectly matched.Relative enhanced performance is visualized in Appendix Figure 9. Notably, Chemma-RC significantly outperforms other LLMs and domain-specific chemical models [3,22] in Table 2.In the zero-shot setting, Chemma-RC achieves a top-1 accuracy of 25.9%, which is significantly higher than the best-performing general-purpose model, ChemDFM [45], at 2.0%.Further, we investigate the distribution of condition numbers combinations in test set, and report both top-1 exact match accuracy and partial accuracy in Table 11.We find that exact match accuracy, as well as precision and recall, increases with the frequency of specific condition number combinations in the dataset, irrespective of the type or quantity of reagents involved.Specifically, for three-condition combinations, which occur 3,258 times in the test set, Chemma-RC achieves a higher partial accuracy of 85.6%, compared to 56.91% in the onecondition scenario with 1,622 occurrences.Furthermore, we select several challenging reactions for detailed discussion, with results presented in Table 10.Our model, Chemma-RC, demonstrates robust performance in predicting complex chemical reactions, such as ring cleavage, achieving an exact match accuracy of 66.13% across six different condition combinations.In summary, despite singlecondition samples being simpler in structure, the limited occurrence provides fewer learning signals, which can negatively impact generalization.Conversely, frequent multi-condition examples offer richer and more consistent patterns, leading to better model performance, especially in partial accuracy.</p>
<p>Ablation Study</p>
<p>4.4.1 Model structure.Here, we conduct an ablation study to examine the inherent effect of different modalities on the performance of Chemma-RC.Specifically, we evaluate the performance under the different combinations of mono-domain, including SMILES, graph, and corpus, on the USPTO-Condition dataset.The results are reported in Table 3, and the heatmap visualization illustrating the relative performance improvements contributed by different modalities is presented in Figure 3.The results clearly indicate that different mono-domain inputs contribute unevenly to overall performance.For the prediction of solvent 1, which emerges as the most challenging condition type (in Table 1), the model enhanced with SMILES modality (first row) outperforms the models trained solely on graph-based modality (second row) and corpus data (third row), achieving 21.8% and 23.0% higher top-1 accuracy, respectively.</p>
<p>Subsequently, we investigate how chemical mono-domain data combination affects model performance compared to individual types of data (fourth row to sixth row).By incorporating a corpus   into the model already trained with SMILES representations, we achieve a 16.9% improvement in solvent 1 top-1 prediction accuracy.However, integrating graph representations into the SMILES-based model results in a 5.0% improvement in solvent 1 top-1 accuracy.The limited performance gain observed in this setting can be attributed to the inherent similarity between the graph modality and the SMILES representation.Since both modalities encode comparable structural information about the molecule, the removal of one does not significantly impact the model's overall performance.In contrast, the incorporation of textual modality, which introduces complementary semantic and contextual information, has a more substantial effect on representation quality and prediction accuracy.Although the advantages of incorporating graph modality may not be immediately apparent from aggregated performance metrics, we assert its critical importance for this task.In the context of challenging reactions with substrates comprising over 100 atoms, the integration of graph modality has been observed to significantly enhance condition prediction performance, which can be seen in Figure 7.</p>
<p>We hypothesize that this improvement arises because the graph modality enables the model to discern subtle differences between complex substrates-nuances that are not adequately captured by SMILES representations alone-thereby facilitating a more accurate prediction of reaction conditions.Therefore, the integration of graph modalities into predictive models will become essential for the actual applications of organic chemistry.</p>
<p>Out-of-distribution evaluation.</p>
<p>Here, we evaluate the generalization performance of Chemma-RC.We conduct two out-ofdistribution (OOD) experiments for evaluation.Firstly, inspired by the work proposed by Qian et al., [30], we also evaluate the out-ofdistribution (OOD) performance of Chemma-RC across different dataset splitting strategies on the USPTO-Condition dataset.Secondly, we employ Chemma-RC trained on the USPTO_500MT _Condition to test on the USPTO-Condition.Results are presented in Table 9 and Table 4.We consider both random split (RS) and time-based split (TS) to further assess the model's robustness and generalization ability.Random split (RS) setup follows the original data split of the USPTO-Condition dataset.The second setup-time split is more challenging [9,14], where the dataset is partitioned based on the publication year of patents.We train the model with historical data from older patents and test its performance on the data from newer patents.This temporal division introduces a substantial domain shift, as the difference between reactions in new patents and previous ones.</p>
<p>In Table 4, we calculate the average accuracy of all different types of conditions, and report average top-1, top-3, top-10, and top-15 accuracy metrics.TextReact (gr) refers to the TextReact model without retrieving gold texts for testing.The results demonstrate that while baseline method such as ChemBERTa [8] achieves moderate success, they fall short in capturing the full complexity of condition prediction.In contrast, Chemma-RC significantly outperforms all baseline methods across both RS and TS settings.Notably, despite being trained only on historical data, Chemma-RC achieves a top-1 (TS) accuracy of 69.6%.Further, the results of cross-dataset evaluation are presented in Appendix D.1 Table 9.This substantial improvement highlights Chemma-RC's superior ability to leverage multi-modal information and its robustness across different data distributions.As we discussed before, we designed a ranking function that assigns higher scores to condition candidates associated with better experimental performance.</p>
<p>C-H arylation reaction</p>
<p>Here, we curate a Pd-catalysed imidazole C-H arylation [37] HTE reaction data from ORD [9] to evaluate the effectiveness of this module.The objective is to identify ligands that maximize reaction yield, under the constraint that all other conditions, including bases and solvents, remain fixed within a predefined reaction space.</p>
<p>Compared with the top-50% metric proposed in [16], we aim to predict the ligands with the highest yields.In Figure 4, the box plot illustrates the yield distribution under different base-solventligand combination of conditions; the box marked in green is the ligand generated by our proposed Chemma-RC.For example, in the left top panel, under the combination of CsOAc and DMAc, Chemma-RC identifies the XPhos ligand.We further evaluate the model proposed by Zhao et al.'s work [45], which yields a top-1 accuracy of 38.1% for ligand selection.In comparison, Chemma-RC achieves a significantly higher accuracy of 93.7%, representing an improvement of 58.7%.All results are presented in Appendix Figure 10.In summary, Chemma-RC is capable of generating optimal conditions due to post-fine-tuning by the ranking enhancement module.We hope this technology has the potential to accelerate high-throughput reaction condition screening in the future.</p>
<p>Modality alignment.</p>
<p>In Chemma-RC, the modality alignment module utilizes the Perceiver projection module [19] to extract latent tokens from both graph and SMILES representations and subsequently aligns these tokens into a text-related language space, as illustrated in Figure 1.Here, we investigate the impact of different projection modules on modality alignment, a component that plays a crucial role in the performance of LMMs.Specifically, we introduce three projection methods for modality alignment, including Perceiver [19], Reprogramming [20], and MLP for comparison.</p>
<p>As depicted in Table 5, the Perceiver module achieves significant gains in the prediction of all condition categories.Compared to reprogramming, it achieves the highest accuracy in all predicted condition categories with an average performance gain of 7.1%.Specifically, for the solvent 1 prediction, a challenging task, the Perceiver module achieves a top-1 accuracy of 54.6%, clearly outperforming both MLP (51.1%) and Reprogramming (52.8%).This performance demonstrates the Perceiver's robustness and effectiveness in capturing complex cross-modal relationships, making it a strong candidate for accurate and reliable reaction condition prediction.</p>
<p>Conclusion and Limitations</p>
<p>In this paper, we present a multimodal LLM, a.k.a.Chemma-RC, for chemical reaction condition prediction.Trained with Q&amp;A instruction datasets along with text-augmented corpus, graph, and SMILES representation, Chemma-RC effectively answers questions about reaction conditions.Even though the integration of the graph modality increases computational cost while offering limited performance gains in the current task, we believe it holds promise for more complex reaction scenarios.We plan to further explore crossmodal alignments, where graph-based contributions are expected to play a more significant role.In the future, ensuring the safety and feasibility of generated reaction conditions is critical, especially when deploying the model in autonomous synthesis platforms.Second, the trade-off between computational efficiency and predictive performance warrants further investigation, particularly for scaling the model to broader chemical domains or real-time applications.To obtain a comprehensive understanding of data distribution, we perform an in-depth data analysis on the USPTO-Condition and USPTO_500MT_Condition datasets.</p>
<p>First, we calculate the non-empty count and non-empty proportion of each condition type.On the USPTO-Condition dataset, catalyst, reagent 2 and solvent 2 condition types exhibit a high extent of sparsity, with non-empty entries occurring in less than 30% of reactions, as shown in Table 7.It indicates that some reactions do not require multiple reagents and solvents, and the corresponding condition labels are therefore assigned as None.On the USPTO_500MT_Condition dataset, since reaction conditions are represented as a single dot-concatenated string, all reactions are associated with non-empty condition labels.Second, we explore the inner distribution characteristics across the two dataset, as illustrated in Figure 6.Reaction conditions exhibit a high degree of diversity and imbalance in both datasets.In Figure 6(F), we confirm that the occurrence frequency of reagents in the datasets follow a power-law distribution.The power-law distributions demonstrate the long-tail characteristics and a small number of categories account for the majority of the whole dataset.Such phenomenon is in light with the distribution of words in natural language, indicating that there is potential for tackling chemical tasks with natural language models.Table 8: Question templates generated by GPT-4.</p>
<p>Task Description</p>
<p>Solvent prediction</p>
<p>Could you suggest potential solvents that could have been used in the given chemical reaction, taking into consideration their polarity and compatibility with the reactants?</p>
<p>Reagent prediction</p>
<p>Please suggest some possible reagents that could have been used in the following chemical reaction.</p>
<p>Catalyst prediction</p>
<p>Considering the chemical reaction in question, which catalysts could be effective?</p>
<p>Condition prediction (all) Given the current chemical reaction, what would be the appropriate conditions to consider?</p>
<p>B Training Settings</p>
<p>Within the model framework, Chemma-RC takes the 32-layer LLaMA-2-7b as the LLM backbone.For the reaction representation, we introduce Parrot [42] to encode the reaction SMILES.For the graphbased reaction representation, we leverage R-GCN [33].For the text-based reaction representation, we retrieve the corresponding similar corpus and utilize LLaMA-2 as a text decoder.During the training process, the weight parameters of the graph and reaction encoders are frozen, while the modality alignment and part layers of LLaMA-2 are trainable.We utilize parameter-efficient LoRA for SFT, and the trainable parameters constitute approximately 0.3 billion out of the total 7 billion parameters.The multimodal SFT process is conducted with a batch size of 16 for fewer than 6 epochs over 48 hours, utilizing a GPU configuration of 2 × 48 GB NVIDIA A6000 GPUs.Inference is performed on a single 80 GB NVIDIA A800 GPU.</p>
<p>C Details of Modality Alignment</p>
<p>For the reaction condition prediction task, the representation of the reaction is extracted by encoders, and the text representation is tokenized by LLMs.However, fusing two types of representation introduces inductive biases issues [5,19].To effectively fuse representations from multiple modalities, we propose the use of a projection module, the Perceiver [19], for modality alignment (Figure 1).This module employs latent queries to align graph and SMILES tokens with text-related tokens, such as question prompts and a text-augmented corpus.We show the pseudo-code for modality projection in Algorithm.1.</p>
<p>D Model Performance</p>
<p>A chemical reaction can be represented as the transformation of a sequence of characters (reactants, conditions) into another sequence (products), with compounds connected by special characters, such as '&gt;&gt;'.This structure makes sequence-to-sequence models, such as the Transformer, well-suited for predictive modeling of reaction representation [18,35].However, existing SMILES-based Transformer models for reaction representation encounter limitations in various aspects, particularly with respect to atom permutations and the interpretability of reaction mechanisms.Consequently, our proposed Chemma-RC fuses data from diverse sources including corpus, SMILES and graphs of molecules to present a comprehensive view of the reaction.We assess the performance of our proposed Chemma-RC and the aforementioned baseline methods for reaction condition prediction.The top- reaction condition prediction accuracy on USPTO-Condition and USPTO_500MT_Condition datasets are presented in Table 1 and Table 2, respectively.We introduce several comparative baseline methods.</p>
<p>(1) rxnfp LSTM [14].This method introduces a reaction representation based on Morgan fingerprints, defined as the difference between the fingerprint vectors of the products and the reactants.We report reproduced results from Wang et al. [42] in Table 1, and results from Qian et al. [30] in Table 4. (2) Parrot [42].This method leverages a powerful attentionbased model architecture to encode the reaction.We report (5) ChemDFM [46].It is a pioneering LLM for chemistry trained on 34B tokens from chemical literature and textbooks, and fine-tuned using 2.7M instructions.We download the opensourced ChemDFM weights and evaluate model performance under zero-shot, one-shot and five-shot settings.We report our evaluation result in Table 2. (6) Reagent Transformer [3].This method leverages Molecular Transformer [35] to tackle the task of reagent prediction.We reproduce the model with the training settings reported in the paper and evaluate model performance on the USPTO_500MT_Condition dataset in Table 2. (7) Reaction GCNN [26].This method proposes a machine-learned ranking model to predict the condition set.We reproduce the model with the training settings reported in the paper and evaluate model performance in the USPTO_500MT_Condition dataset on in Table 2. (8) nach0 [22].This method is a multi-domain and multi-task encoder-decoder LLM pre-trained on unlabeled text from scientific literature, patents, and molecule strings to incorporate a range of chemical and linguistic knowledge.In Table 2, we report evaluation results from the paper.</p>
<p>(9) TextReact [30] variants: rxnfp retrieval, Transformer, Chem-BERTa, TextReact(gr).rxnfp retrieval takes the conditions of the most similar reactions in the training set as the prediction.Transformer uses the same architecture as the Tex-tReact predictor.ChemBERTa is same as the Transformer baseline except that the encoder is pretrained on external SMILES data.TextReact(gr) removes the gold corpus in the evaluation process.In Table 4, we report model performance from Qian et al. [30].</p>
<p>D.1 Generalization Performance</p>
<p>In order to validate the out-of-domain performance of Chemma-RC, we employ Chemma-RC trained on the USPTO_500MT_Condition to test on the USPTO-Condition.The evaluation strategy includes three specific training conditions: reagents, catalysts, and solvents.We adopt a metric of partial matched accuracy to illustrate the generalization capability of Chemma-RC.Different from the complete matched accuracy that requires perfect matching between predictions and labels, the partial matched accuracy is more suitable to test the generalization capacity, which focuses more on whether the predicted results match a substitutable part of the ground truth.Chemma-RC can successfully distinguish reagents from the combination of all conditions in a reaction.Additionally, training Chemma-RC on USPTO-Condition, a larger chemical reaction dataset, further enhances its ability to akin chemical knowledge.</p>
<p>D.2 Case Study</p>
<p>In this section, we select four cross-coupling reactions from USPO-Condition datasets for performance validation.We visualize the predicted results in Figure 7.As depicted in Figure 7, the reaction centers and leaving groups are highlighted in different colors.For C-N cross-coupling reactions (the first and the third row), Chemma-RC can predict all conditions precisely.For C-C bond formation and Formylation reactions (the second and the fourth row), Chemma-RC fails to predict Ethyl Acetate (the second case) and THF (the fourth case).The reason why Chemma-RC is less effective for these reactions is that the data volume of C-C bond formation reactions in the USPTO-Condition dataset is only 5%, as shown in Figure 5.This limited representation constrains the model's ability to learn the patterns associated with C-C bond formation reactions.Consequently, Chemma-RC lacks sufficient training examples to capture and generalize the underlying reaction mechanisms accurately.The scarcity of diverse and representative data hampers its effectiveness, leading to a lower precision in predicting these types of reactions.</p>
<p>Further, we visualize the predicted results on OOD datasets in Figure 8.We select two reaction cases for analysis.In case 1, Toluene is not predicted by Chemma-RC.In case 2, 1,4-Dioxane and 1-(diphenylphosphaneyl)cyclopenta-2,4-dien-1-ide are predicted.However, it is confirmed that Toluene and 1,4-Dioxane are common solvents, and 1-(diphenylphosphaneyl)cyclopenta-2,4-dien-1-ide is frequently used as a ligand.Therefore, we do not categorize these as failed cases because the model successfully predicts all the reagents in the labels and avoids predicting other conditions.</p>
<p>E Reproducibility Statement</p>
<p>To ensure the reproducibility of our work, we have used datasets which have been published in [24,42], and the data links are as follows: USPTO_500MT_Condition and USPTO-Condition.Additionally, the code base for Chemma-RC is available as an anonymous repository for continuous development: https://anonymous.4open.science/r/Chemma-RC-submission-5600/.In case 2, 1,4-Dioxane and 1-(diphenylphosphaneyl)cyclopenta-2,4-dien-1-ide were predicted.However, it is confirmed that Toluene and 1,4-Dioxane are common solvents, and 1-(diphenylphosphaneyl)cyclopenta-2,4-dien-1-ide is frequently used as a ligand.Therefore, we do not categorize these as failed cases because the model successfully predicts all the reagents in the labels and avoids predicting other conditions.</p>
<p><Graph>, <Reaction>, <Corpus>, considering the characteristics of this chemical reaction, which solvents would you advise as e ective?Reaction-graph contrastive loss (d) Reaction-text and graph-text constrative loss Ranking enhancement with feedback</p>
<p>Figure 1 :
1
Figure 1: Architecture of Chemma-RC.It processes task-specific questions and generates answers via a two-stage training framework: multimodal supervised fine-tuning followed by post-fine-tuning.</p>
<p>Figure 2 .
2
In contrast to standard prompts used in common SFT in Figure 2(a), we incorporate additional textual indicators and modalityspecific tokens (Figure 2(b)) to represent multimodal chemical data.CC(C)O.O=C(n1ccnc1)nccnc1&gt;&gt;CC(C)OC(=O)n1ccnc1 predict the the reagent for this reaction, reaction SMILES is as follows: <Reaction SMILES>.(b) Multimodal instruction Q&amp;A Text Human: Given a reaction text description: <Corpus>, reaction embedding <Reaction>, graph embedding: <Graph>, and the reaction SMILES: <Reaction SMILES>.Please predict the reagent for this reaction.)O.O=C(n1ccnc1)nccnc1&gt;&gt;CC(C)OC(=O)n1ccnc1</p>
<p>Figure 2 :
2
Figure 2: Construction of multimodal instruction datasets.(a) Traditional instruction prompts for supervised fine-tuning; (b) Our proposed text-augmented multimodal instruction Q&amp;A datasets.</p>
<p>Figure 3 :
3
Figure 3: Heatmap visualization of performance enhancements of Chemma-RC on the USPTO-Condition dataset.</p>
<p>Figure 4 :
4
Figure 4: Performance evaluation for identifying optimal ligand on C-H arylation reaction.</p>
<p>Algorithm 1
1
Pseudo code for modality projection.# B: batch size; C: channel size; n: content shape # M: query length; N: shape of flatten reaction tokens; # text_q: text query in shape (B, M, C) # react_embed: reaction embedding in shape (B, N, C) # word_embed: word embedding in shape (B, vocab_size, C) # Key part 1: map transformer-based reaction feature word_embed = self.word_proj(word_embed)word_embed = word_embed.repeat(react_embed.size()[0], 1, 1) react_embed = torch.cat([react_embed,word_embed], dim=1) smiles_react_tokens = linear_layer(react_embed) # to make 128 tokens # Key part 2: map graph-based reaction features graph_embed = self.word_proj(graph_embed)graph_react_tokens = linear_layer(graph_embed) # to make 3 tokens # Key part 3: reaction_tokens = torch.cat([smiles_react_tokens,graph_react_tokens], dim=1) # Key part 4: modality projection reaction_tokens_from_smiles = self.perceiver_proj_smiles(smiles_react_tokens) reaction_tokens_from_graphs = self.perceiver_proj_graphs(graph_react_tokens) # concat token final_token = torch.cat([reaction_tokens_from_smiles,reaction_tokens_from_graphs, text_q], dim=1)</p>
<p>EthylFirstFigure 7 :
7
Figure7: Visualization of generated conditions on four reactions.We select four Suzuki-Miyaura cross-coupling reactions to present the performance of condition prediction.The reaction centers and leaving groups are highlighted in different colors.</p>
<p>1 Sulfonylation 11 Conference' 17 , 1 -Figure 8 :
1111718
Figure8: Visualization of recommended conditions on two reactions.In case 1, Toluene was not predicted by Chemma-RC.In case 2, 1,4-Dioxane and 1-(diphenylphosphaneyl)cyclopenta-2,4-dien-1-ide were predicted.However, it is confirmed that Toluene and 1,4-Dioxane are common solvents, and 1-(diphenylphosphaneyl)cyclopenta-2,4-dien-1-ide is frequently used as a ligand.Therefore, we do not categorize these as failed cases because the model successfully predicts all the reagents in the labels and avoids predicting other conditions.</p>
<p>Figure 9 :
9
Figure 9: The visualization of relative performance enhancement.(A) relative performance enhancement on the USPTO-Condition dataset.(B) Performance evaluation for three baseline methods: Parrot (red), TextReact (green), and Chemma-RC (blue) on USPTO_500MT_Condition datasets.</p>
<p>Figure 10 :
10
Figure 10: Performance evaluation of ligand generation.</p>
<p>Table 1 :
1
Accuracy results for reaction condition prediction on USPTO-Condition dataset.The best performance is in bold.
Top-𝑘 Accuracy (%)ModelCatalystSolvent 1Solvent 2Reagent 1Reagent 2135135135135135rxnfp LSTM92.2 92.2 92.250.2 66.4 70.681.3 83.7 84.649.7 66.0 74.076.2 84.1 86.6Parrot92.4 92.4 92.449.3 67.7 72.380.7 84.2 85.149.6 67.3 75.776.5 84.1 87.2TextReact 𝑠92.4 95.3 96.351.7 65.5 71.779.8 87.7 89.851.9 68.7 75.175.8 86.7 89.7Chemma-RC92.7 98.6 99.254.6 76.4 84.881.8 94.8 97.653.4 75.8 83.978.7 93.2 96.2</p>
<p>Table 2 :
2
Comparison of model performance on USPTO_500MT_Condition dataset between general-purpose LLMs and domainspecific chemical models, respectively.General-purpose LLMs are tested under three settings: zero-shot, one-shot, and five-shot.Error analysis is reported, and the best results are in bold font.
MethodTop-1 exact acc. (%)Partial acc. (%)Recall (%)Precision (%)General-purpose LLMs, 100 examples are randomly sampled for evaluationZero-shot performanceDeepSeek-V20.0 ± 0.01915.1 ± 0.01817.4 ± 0.01817.9 ± 0.034GPT-4o1.0 ± 0.01213.0 ± 0.0107.6 ± 0.03412.1 ± 0.038LLaMA3-70B0.0 ± 0.0007.0 ± 0.01011.4 ± 0.0249.1 ± 0.024ChemDFM3.0 ± 0.02938.0 ± 0.02419.6 ± 0.01226.5 ± 0.028One-shot performanceDeepSeek-V20.0 ± 0.01915.1 ± 0.01817.4 ± 0.01817.9 ± 0.034GPT-4o1.0 ± 0.01213.0 ± 0.0107.6 ± 0.03412.1 ± 0.038LLaMA3-70B0.0 ± 0.0007.0 ± 0.01011.4 ± 0.0249.1 ± 0.024ChemDFM3.0 ± 0.02938.0 ± 0.02419.6 ± 0.01226.5 ± 0.028Five-shot performanceDeepSeek-V21.3 ± 0.01415.8 ± 0.05917.2 ± 0.01825.3 ± 0.050GPT-4o0.0 ± 0.03915.3 ± 0.0796.2 ± 0.0369.8 ± 0.020LLaMA3-70B1.0 ± 0.01028.0 ± 0.01314.1 ± 0.02411.9 ± 0.024ChemDFM1.0 ± 0.01721.0 ± 0.07011.1 ± 0.03814.4 ± 0.073Domain-specific chemical models, all samples in test sets are selected for evaluationReagent Transformer17.527.531.635.6Reaction GCNN16.127.533.040.2Parrot13.825.331.437.9nach013.1---Chemma-RC (zero-shot)25.969.767.979.3</p>
<p>Table 3 :
3
Performance evaluation of Chemma-RC under different combinations of mono-domain data on the USPTO-Condition Dataset.
Top-𝑘 Accuracy (%)SMILES Graph CorpusCatalystSolvent 1Solvent 2Reagent 1Reagent 2135135135135135✓✗✗90.3 97.5 98.737.1 64.5 75.780.8 92.9 96.837.1 63.5 74.773.7 89.9 94.1✗✓✗87.1 93.3 95.515.3 40.5 58.280.7 91.9 95.534.6 56.8 67.575.4 86.6 90.6✗✗✓87.1 87.4 87.814.1 26.1 44.980.7 88.19226.0 32.1 37.375.1 76.6 77.9✓✗✓92.6 98.5 99.354.0 76.0 84.481.8 94.7 97.652.8 75.4 83.378.6 93.1 96.1✓✓✗91.3 98.1 99.142.1 68.8 79.480.1 93.5 97.145.2 70.4 79.976.7 91.4 95.1✓✓✓92.7 98.6 99.254.6 76.4 84.881.8 94.8 97.653.4 75.8 83.978.7 93.2 96.2</p>
<p>Table 4 :
4
Evaluation performance under different data split strategies for reaction condition prediction.RS: random split; TS: time split.
Random splitTime splitTop-1 Top-3 Top-10 Top-15Top-1 Top-3 Top-10 Top-15rxnfp LSTM20.530.741.745.315.226.240.745.4rxnfp retrieval27.237.547.951.17.815.227.331.5Transformer30.043.856.760.518.731.847.652.7ChemBERTa30.344.758.062.018.731.947.652.8TextReact(gr)47.259.965.071.436.350.456.263.8Chemma-RC72.387.892.496.569.686.791.796.2</p>
<p>Table 5 :
5
Performance evaluation of Chemma-RC under different Modality alignments, the best performance are in bold.
ProjectionTop-𝑘 Accuracy (%)LayerCatalystSolvent 1Solvent 2Reagent 1Reagent 2135135135135135MLP90.9 97.8 98.951.1 73.3 82.281.1 93.9 97.147.4 71.0 79.977.0 91.7 95.2Reprogramming92.1 98.3 99.152.8 75.1 83.781.3 94.3 97.450.2 73.5 81.977.7 92.5 95.7Perceiver92.7 98.6 99.254.6 76.4 84.881.8 94.8 97.653.4 75.8 83.978.7 93.2 96.2
4.4.3Ranking enhancement with feedback.</p>
<p>Table 6 :
6
Data description of USPTO-Condition and USPTO_500MT_Condition datasets.
DatasetSample of conditionsPrediction type Training Validation TestingUSPTO-Condition[Zn],C1CCOC1,O,CO,[Cl-].[NH4+]classification546,72868,34168,341USPTO_500MT_ConditionCO.[Na+].CC(=O)O.[BH3-]CNgeneration88,4109,77810,828</p>
<p>Table 7 :
7
Sparsity analysis of the USPTO-Condition dataset.
Non-emptycatalystsolvent 1solvent 2reagent 1reagent 2Count89,756673,634130,326504,169170,752Density13%99%19%74%25%</p>
<p>Table 9 :
9
The top-1 partial matched accuracy of Chemma-RC under OOD setting.
Evaluation strategy (train → test)Accuracy (%)USPTO_500MT_Condition → USPTO-Condition (reagent)67.1USPTO_500MT_Condition → USPTO-Condition (catalyst)89.9USPTO_500MT_Condition → USPTO-Condition (solvent)58.1</p>
<p>Table 10 :
10
Performance evaluation of Chemma-RC on specific reaction types on USPTO-Condition dataset.
Reaction SMARTSReaction NameExact Match (%)Part Match (%)Recall (%)More complex reaction types</p>
<p>Table 11 :
11
Performance comparison across different numbers of reaction conditions on USPTO_500MT_Condition dataset.Condition numbers Frequency Exact acc (%) Partial acc (%) Recall (%) Precision (%)
1162233.1756.9156.5834.242402632.6678.7160.1054.713325819.0085.6056.4663.684132620.8189.2257.4370.56544020.9191.5957.8373.20615627.5691.0360.7777.25
Conference'17, July 2017, Washington, DC, USA Zhang et al.
Appendix A Data DescriptionWe introduce two large benchmark datasets, USPTO-Condition and USPTO_500MT_Condition to evaluate model performance on recommending reaction conditions.The USPTO-Condition dataset, curated by Wang et al.[42], is commonly used in previous works[30,42].It comprises about 700,000 reaction data derived from the public USPTO data[23], with heteroatom alkylation and arylation reactions accounting for the majority, as shown in Figure5(left).Each reaction entry consists of reaction reactants, products, and conditions in canonical SMILES format.As shown in Table6, the reaction conditions are categorized into five distinct types, including catalyst, solvent 1, solvent 2, reagent 1, and reagent 2, and are presented in a consistent order, which facilitates a more structured prediction task.We follow the data split strategy proposed by Wang[42], which randomly divides reactions into training, validation, and testing sets with a ratio of 8:1:1, and detailed statistics are presented in Table6.Furthermore, in section 4.4.2, for a fair comparison, we evaluate model performance under the time-based data split (TS) strategy proposed by Qian[30], where the reactions collected before 2015 are categorized as the training set, reactions from 2015 as validation, and reactions 2016 as testing.The USPTO_500MT_Condition dataset, introduced by Lu et al.[24], collects about 110,000 reactions with the top-500 common reaction types sourced from the USPTO-MIT dataset[9], and reactions with the top-100 reaction types constitute 59% of the dataset, as illustrated in Figure5(right).Each entry in the USPTO_500MT_Condition dataset comprises reactants, products, and conditions.Notably, as shown in Table6, all reaction conditions in USPTO_500MT_Condition dataset are concatenated using dots and collectively labeled as reagents, which results in an unstructured sequence generation task.We perform data cleaning on the USPTO_500MT_Condition dataset to ensure consistency and quality.Specifically, we canonicalize all molecular SMILES representations and remove reactions with more than six reagents.Following the data splitting strategy proposed by Lu[24], the dataset is randomly divided into training, validation, and test sets in an 8:1:1 ratio.Detailed statistics are reported in Table6.evaluation results from Wang et al.[42]in Table1.Further, we follow the training setting in the paper, and test Parrot's performance on the USPTO_500MT_Condition dataset in Table2. (3) TextReact[30].This method introduces relevant corpus retrieved from literature to enhance the molecular representation of the reaction based on SMILES.For a fair comparison, we exclude the gold texts paired with each chemical input during both training and evaluation.Our reproduced results are reported in Table1, where we referred as TextReact_s.(4) DeepSeek-V2[21], GPT-4o[1], LLaMA3-70B[39].They are general-purpose generative large language models pretrained on massive corpora of diverse text data, which sparked significant interest in the field of AI for chemistry.In Table2, we utilize Ollama and OpenAI API to evaluate model performance under three settings: zero-shot, one-shot and fiveshot.USPTO-Condition
Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, arXiv:2303.08774Shyamal Anadkat, et al. 2023. Gpt-4 technical report. 2023arXiv preprint</p>
<p>. Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, arXiv:2303.087742023. 2023arXiv preprint</p>
<p>Reagent prediction with a molecular transformer improves reaction data quality. Mikhail Andronov, Varvara Voinarovska, Natalia Andronova, Michael Wand, Djork-Arné Clevert, Jürgen Schmidhuber, Chemical Science. 142023. 2023</p>
<p>Closed-loop optimization of general reaction conditions for heteroaryl Suzuki-Miyaura coupling. Vandana Nicholas H Angello, Wiktor Rathore, Agnieszka Beker, Wołos, Rafał Edward R Jira, Tony C Roszak, Charles M Wu, Alán Schroeder, Bartosz A Aspuru-Guzik, Grzybowski, Science. 3782022. 2022</p>
<p>Tadas Baltrušaitis, Chaitanya Ahuja, Louis-Philippe Morency, Multimodal Machine Learning: A Survey and Taxonomy. IEEE transactions on pattern analysis and machine intelligence. 2018. 201841</p>
<p>Artificial Intelligence in Chemistry: Current Trends and Future Directions. Zachary J Baum, Xiang Yu, Philippe Y Ayala, Yanan Zhao, Steven P Watkins, Qiongqiong Zhou, Journal of Chemical Information and Modeling. 612021. 2021</p>
<p>Autonomous chemical research with large language models. Robert Daniil A Boiko, Ben Macknight, Gabe Kline, Gomes, Nature. 6242023. 2023</p>
<p>ChemBERTa: large-scale self-supervised pretraining for molecular property prediction. Seyone Chithrananda, Gabriel Grand, Bharath Ramsundar, arXiv:2010.098852020. 2020arXiv preprint</p>
<p>Prediction of Organic Reaction Outcomes Using Machine Learning. Regina Connor W Coley, Tommi S Barzilay, William H Jaakkola, Green, Klavs, Jensen, ACS central science. 32017. 2017</p>
<p>A graphconvolutional neural network model for the prediction of chemical reactivity. Wengong Connor W Coley, Luke Jin, Timothy F Rogers, Tommi S Jamison, William H Jaakkola, Regina Green, Klavs F Barzilay, Jensen, Chemical science. 102019. 2019</p>
<p>Computer-Assisted Design of Complex Organic Syntheses: Pathways for molecular synthesis can be devised with a computer and equipment for graphical communication. Elias James, Corey , W Todd Wipke, Science. 1661969. 1969</p>
<p>Exploring Chemical Reaction Space with Machine Learning Models: Representation and Feature Perspective. Yuheng Ding, Bo Qiang, Qixuan Chen, Yiqiao Liu, Liangren Zhang, Zhenming Liu, Journal of Chemical Information and Modeling. 2024. 2024</p>
<p>Mol-Instructions: A Large-Scale Biomolecular Instruction Dataset for Large Language Models. Yin Fang, Xiaozhuan Liang, Ningyu Zhang, Kangwei Liu, Rui Huang, Zhuo Chen, Xiaohui Fan, Huajun Chen, ICLR. OpenReview.net. 2024</p>
<p>Using Machine Learning To Predict Suitable Conditions for Organic Reactions. Hanyu Gao, Thomas J Struble, Connor W Coley, Yuran Wang, William H Green, Klavs, Jensen, ACS central science. 42018. 2018</p>
<p>Sample efficiency matters: a benchmark for practical molecular optimization. Wenhao Gao, Tianfan Fu, Jimeng Sun, Connor Coley, Advances in neural information processing systems. 352022. 2022</p>
<p>What can Large Language Models do in chemistry? A comprehensive benchmark on eight tasks. Taicheng Guo, Bozhao Nan, Zhenwen Liang, Zhichun Guo, Nitesh Chawla, Olaf Wiest, Xiangliang Zhang, Advances in Neural Information Processing Systems. 362023. 2023</p>
<p>Chemeval: a comprehensive multi-level chemical evaluation for large language models. Yuqing Huang, Rongyang Zhang, Xuesong He, Xuyang Zhi, Hao Wang, Xin Li, Feiyang Xu, Deguang Liu, Huadong Liang, Yi Li, arXiv:2409.139892024. 2024arXiv preprint</p>
<p>Chemformer: a pre-trained transformer for computational chemistry. Ross Irwin, Spyridon Dimitriadis, Jiazhen He, Esben Jannik Bjerrum, Machine Learning: Science and Technology. 3150222022. 2022</p>
<p>Perceiver: General Perception with Iterative Attention. Andrew Jaegle, Felix Gimeno, Andy Brock, Oriol Vinyals, Andrew Zisserman, Joao Carreira, International conference on machine learning. PMLR2021</p>
<p>Time-LLM: Time Series Forecasting by Reprogramming Large Language Models. Ming Jin, Shiyu Wang, Lintao Ma, Zhixuan Chu, James Y Zhang, Xiaoming Shi, Pin-Yu Chen, Yuxuan Liang, Yuan-Fang Li, Shirui Pan, Qingsong Wen, International Conference on Learning Representations (ICLR). 2024</p>
<p>Aixin Liu, Bei Feng, Bing Xue, Bingxuan Wang, Bochao Wu, Chengda Lu, Chenggang Zhao, Chengqi Deng, Chenyu Zhang, Chong Ruan, arXiv:2412.19437Deepseek-v3 technical report. 2024. 2024arXiv preprint</p>
<p>Alán Aspuru-Guzik, et al. 2024. nach0: Multimodal natural and chemical languages foundation model. Micha Livne, Zulfat Miftahutdinov, Elena Tutubalina, Maksim Kuznetsov, Daniil Polykovskiy, Annika Brundyn, Aastha Jhunjhunwala, Anthony Costa, Alex Aliper, Chemical Science. 152024</p>
<p>Extraction of chemical structures and reactions from the literature. Daniel Mark, Lowe , </p>
<p>Unified Deep Learning Model for Multitask Reaction Predictions with Explanation. Jieyu Lu, Yingkai Zhang, Journal of chemical information and modeling. 622022. 2022</p>
<p>Augmenting large language models with chemistry tools. Andres M Bran, Sam Cox, Oliver Schilter, Carlo Baldassari, Andrew D White, Philippe Schwaller, Nature Machine Intelligence. 2024. 2024</p>
<p>Multi-Label Classification Models for the Prediction of Cross-Coupling Reaction Conditions. Alexander Y Michael R Maser, Serim Cui, Travis J Ryou, Yisong Delano, Sarah E Yue, Reisman, Journal of Chemical Information and Modeling. 612021. 2021</p>
<p>A universal system for digitization and automatic execution of the chemical synthesis literature. M Hessam, Matthew Mehr, Artem I Craven, Graham Leonov, Leroy Keenan, Cronin, Science. 3702020. 2020</p>
<p>Computational planning of the synthesis of complex natural products. Barbara Mikulak-Klucznik, Patrycja Gołębiowska, Alison A Bayly, Oskar Popik, Tomasz Klucznik, Sara Szymkuć, Ewa P Gajewska, Piotr Dittwald, Olga Staszewska-Krajewska, Wiktor Beker, Nature. 5882020. 2020</p>
<p>Linking the Neural Machine Translation and the Prediction of Organic Chemistry Reactions. Juno Nam, Jurae Kim, arXiv:1612.095292016. 2016arXiv preprint</p>
<p>Predictive Chemistry Augmented with Text Retrieval. Yujie Qian, Zhening Li, Zhengkai Tu, Connor Coley, Regina Barzilay, 10.18653/v1/2023.emnlp-main.784Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing. Houda Bouamor, Juan Pino, Kalika Bali, the 2023 Conference on Empirical Methods in Natural Language ProcessingSingaporeAssociation for Computational Linguistics2023</p>
<p>Prompt Programming for Large Language Models: Beyond the Few-Shot Paradigm. Laria Reynolds, Kyle Mcdonell, Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems. 2021</p>
<p>Digitization and validation of a chemical synthesis literature database in the ChemPU. Simon Rohrbach, Mindaugas Šiaučiulis, Greig Chisholm, Petrisor-Alin Pirvan, Michael Saleeb, S Hessam M Mehr, Ekaterina Trushina, I Artem, Graham Leonov, Aamir Keenan, Khan, Science. 3772022. 2022</p>
<p>Modeling relational data with graph convolutional networks. Michael Schlichtkrull, Thomas N Kipf, Peter Bloem, Rianne Van Den, Ivan Berg, Max Titov, Welling, The semantic web: 15th international conference. Heraklion, Crete, GreeceSpringer2018. 2018. June 3-7, 2018</p>
<p>Tobias Schnitzer, Martin Schnurr, Andrew F Zahrt, Nader Sakhaee, Scott E Denmark, Helma Wennemers, Machine Learning to Develop Peptide Catalysts-Successes, Limitations, and Opportunities. ACS Central Science2024. 2024</p>
<p>Molecular Transformer: A Model for Uncertainty-Calibrated Chemical Reaction Prediction. Philippe Schwaller, Teodoro Laino, Théophile Gaudin, Peter Bolgar, Christopher A Hunter, Costas Bekas, Alpha A Lee, ACS central science. 52019. 2019</p>
<p>Mapping the Space of Chemical Reactions Using Attention-Based Neural Networks. Philippe Schwaller, Daniel Probst, Alain C Vaucher, H Vishnu, David Nair, Teodoro Kreutter, Jean-Louis Laino, Reymond, Nature machine intelligence. 32021. 2021</p>
<p>Bayesian reaction optimization as a tool for chemical synthesis. J Benjamin, Jason Shields, Jun Stevens, Marvin Li, Farhan Parasram, Jesus I Martinez Damani, Jacob M Alvarado, Ryan P Janey, Abigail G Adams, Doyle, Nature. 5902021. 2021</p>
<p>A Brief Introduction to Chemical Reaction Optimization. Alexander Connor J Taylor, Pomberger, Rachel Kobi C Felton, Magda Grainger, Thomas W Barecka, Richard A Chamberlain, Christopher N Bourne, Alexei A Johnson, Lapkin, Chemical Reviews. 1232023. 2023</p>
<p>Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, arXiv:2307.09288Shruti Bhosale, et al. 2023. Llama 2: Open Foundation and Fine-Tuned Chat Models. 2023arXiv preprint</p>
<p>Attention Is All You Need. Advances in neural information processing systems. Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, Illia Polosukhin, 2017. 201730</p>
<p>Identifying general reaction conditions by bandit optimization. Jason Y Wang, Jason M Stevens, Stavros K Kariofillis, Mai-Jan Tom, Dung L Golden, Jun Li, Jose E Tabora, Marvin Parasram, Benjamin J Shields, David N Primer, Nature. 6262024. 2024</p>
<p>Generic Interpretable Reaction Condition Predictions with Open Reaction Condition Datasets and Unsupervised Learning of Reaction Center. Xiaorui Wang, Chang-Yu Hsieh, Xiaodan Yin, Jike Wang, Yuquan Li, Yafeng Deng, Dejun Jiang, Zhenxing Wu, Hongyan Du, Hongming Chen, Research. 62312023. 2023</p>
<p>Self-Instruct: Aligning Language Models with Self-Generated Instructions. Yizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa Liu, Noah A Smith, Daniel Khashabi, Hannaneh Hajishirzi, 10.18653/v1/2023.acl-long.754Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics. Long Papers. Anna Rogers, Jordan Boyd-Graber, Naoaki Okazaki, the 61st Annual Meeting of the Association for Computational LinguisticsToronto, CanadaAssociation for Computational Linguistics20231</p>
<p>SMILES. 2. Algorithm for generation of unique SMILES notation. David Weininger, Arthur Weininger, Joseph L Weininger, Journal of chemical information and computer sciences. 291989. 1989</p>
<p>Zihan Zhao, Bo Chen, Jingpiao Li, Lu Chen, Liyang Wen, Pengyu Wang, Zichen Zhu, Danyang Zhang, Yansi Li, Zhongyang Dai, ChemDFM-X: towards large multimodal model for chemistry. 2024. 202467220109</p>
<p>Developing ChemDFM as a large language foundation model for chemistry. Zihan Zhao, Da Ma, Lu Chen, Liangtai Sun, Zihao Li, Yi Xia, Bo Chen, Hongshen Xu, Zichen Zhu, Su Zhu, Cell Reports Physical Science. 642025. 2025</p>            </div>
        </div>

    </div>
</body>
</html>