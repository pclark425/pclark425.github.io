<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-6390 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-6390</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-6390</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-126.html">extraction-schema-126</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models perform arithmetic, including model details, task details, prompting methods, performance results, and any analysis of internal mechanisms or failure modes.</div>
                <p><strong>Paper ID:</strong> paper-273023082</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2410.00151v2.pdf" target="_blank">Scheherazade : Evaluating Chain-of-Thought Math Reasoning in LLMs with Chain-of-Problems</a></p>
                <p><strong>Paper Abstract:</strong> Benchmarks are critical for measuring progress of math reasoning abilities of Large Language Models (LLMs). However, existing widely-used benchmarks such as GSM8K have been rendered less useful as multiple cutting-edge LLMs achieve over 94% accuracy. While harder benchmarks have been proposed, their creation is often manual and expensive. We present Scheherazade , an automated approach for producing challenging mathematical reasoning benchmarks by logically chaining mathematical reasoning problems. We propose two different chaining methods, forward chaining and backward chaining, which require reasoning forward and backward through the chain respectively. We apply Scheherazade on GSM8K to create GSM8K -Scheherazade and evaluate 3 frontier LLMs and OpenAI’s o1-preview on it. We show that while frontier models’ performance declines precipitously at only a few questions chained, a preliminary evaluation suggests o1-preview ’s performance persists up to 5 questions chained backwards. In addition, while all other models perform worse when problems are chained backwards, o1-preview performs better on backward-chained benchmarks. We will release the dataset and code publicly.</p>
                <p><strong>Cost:</strong> 0.012</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e6390.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e6390.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models perform arithmetic, including model details, task details, prompting methods, performance results, and any analysis of internal mechanisms or failure modes.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GPT-4o</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>GPT-4o</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A frontier OpenAI model evaluated in this paper for multi-step arithmetic/word-problem reasoning using chained-problem benchmarks (GSM8K-Scheherazade); shows near-perfect single-problem accuracy but rapid degradation as problems are chained.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Scheherazade: Evaluating Chain-of-Thought Math Reasoning in LLMs with Chain-of-Problems</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-4o</td>
                        </tr>
                        <tr>
                            <td><strong>model_family</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>training_data_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>GSM8K-Scheherazade (derived from GSM8K)</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>multi-step word problems / grade-school arithmetic reasoning (chained)</td>
                        </tr>
                        <tr>
                            <td><strong>problem_format</strong></td>
                            <td>natural-language chain-of-problems (if-then branching; forward and backward chaining)</td>
                        </tr>
                        <tr>
                            <td><strong>difficulty_level</strong></td>
                            <td>GSM8K-level per-component; overall harder due to chaining (chains of length 2–10 evaluated)</td>
                        </tr>
                        <tr>
                            <td><strong>prompting_method</strong></td>
                            <td>Evaluated for Chain-of-Thought (CoT) style multi-step reasoning; specific prompt templates not specified in paper</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>accuracy (fraction correct)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>Forward-chain accuracies (lengths 1..10): [0.971, 0.438, 0.365, 0.347, 0.333, 0.291, 0.253, 0.214, 0.195, 0.167]. Backward-chain accuracies (lengths 1..10, as reported elsewhere in the paper): [0.971, 0.932, 0.645, 0.393, 0.231, 0.147, 0.097, 0.080, 0.052, 0.001]. Summary: near-perfect at length=1, precipitous decline as chain length increases; no model (including GPT-4o) remains >50% beyond ~6 chained questions.</td>
                        </tr>
                        <tr>
                            <td><strong>internal_analysis</strong></td>
                            <td>No mechanistic interpretability (e.g., activation/attention probing or logit-lens) presented. Paper gives qualitative/manual error analysis only (see general discussion about models failing to follow backward CoT and omitting subquestions).</td>
                        </tr>
                        <tr>
                            <td><strong>failure_modes</strong></td>
                            <td>Rapid degradation with increasing chain length; worse performance on backward-chaining at longer lengths (though sometimes backward is stronger at short lengths); failures include omission of answering subproblems in the chain and inability to correctly propagate intermediate numeric conclusions across branches.</td>
                        </tr>
                        <tr>
                            <td><strong>scaling_trend</strong></td>
                            <td>Paper does not report architecture/size scaling for GPT-4o; observed trend: accuracy falls monotonically with chain length; backward-chain performance can be higher at short lengths but collapses faster than forward-chain, with forward overtaking around length ~6.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Scheherazade : Evaluating Chain-of-Thought Math Reasoning in LLMs with Chain-of-Problems', 'publication_date_yy_mm': '2024-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6390.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e6390.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models perform arithmetic, including model details, task details, prompting methods, performance results, and any analysis of internal mechanisms or failure modes.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>o1-preview</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>OpenAI o1-preview</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An OpenAI model variant evaluated preliminarily on backward-chained GSM8K-Scheherazade; shows substantially better robustness to backward chaining than other frontier models in the paper's limited evaluation.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Scheherazade: Evaluating Chain-of-Thought Math Reasoning in LLMs with Chain-of-Problems</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>o1-preview</td>
                        </tr>
                        <tr>
                            <td><strong>model_family</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>training_data_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>GSM8K-Scheherazade (backward chains; preliminary subset)</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>multi-step word problems / grade-school arithmetic reasoning (backward-chained)</td>
                        </tr>
                        <tr>
                            <td><strong>problem_format</strong></td>
                            <td>natural-language chain-of-problems (backward chaining); preliminary evaluation on 25 samples per chain length (lengths 1..7, also reported to length 8 for some results)</td>
                        </tr>
                        <tr>
                            <td><strong>difficulty_level</strong></td>
                            <td>GSM8K-level per-component; overall harder due to chaining (evaluated up to length 8 in limited sample set)</td>
                        </tr>
                        <tr>
                            <td><strong>prompting_method</strong></td>
                            <td>Evaluated for Chain-of-Thought reasoning; specific prompt or fine-tuning details not provided in paper</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>accuracy (fraction correct); also reported absolute counts on the small preliminary set</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>Preliminary backward-chain accuracies on 25-sample runs (lengths 1..8 as reported): [1.000, 0.880, 0.800, 0.800, 0.920, 0.520, 0.600, 0.562]. Example: at backward chain length 5 o1-preview solved 23/25 questions (92%). Overall, o1-preview retained high performance up to ~5 backward-chained questions, outperforming other evaluated models at those lengths.</td>
                        </tr>
                        <tr>
                            <td><strong>internal_analysis</strong></td>
                            <td>Limited manual error analysis: of 41 incorrect cases across evaluated lengths, o1-preview omitted answering every question in chain for 12 cases; omission rate higher for longest chains (4/10 for chains length ≥7). No deeper mechanistic probing performed.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_modes</strong></td>
                            <td>Omissions of subanswers within the chain (not answering every intermediate question), mistakes increase with chain length; some non-monotonic behaviour across chain lengths in the small sample (e.g., a spike at length 5 in the preliminary set).</td>
                        </tr>
                        <tr>
                            <td><strong>scaling_trend</strong></td>
                            <td>Paper provides only preliminary results for o1-preview (no size-sweep). Observed robustness relative to other models: much better retention of accuracy up to 4–5 backward-chained problems, then performance degrades; shows a qualitatively different trend (more robust on backward chaining) than other models evaluated.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Scheherazade : Evaluating Chain-of-Thought Math Reasoning in LLMs with Chain-of-Problems', 'publication_date_yy_mm': '2024-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6390.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e6390.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models perform arithmetic, including model details, task details, prompting methods, performance results, and any analysis of internal mechanisms or failure modes.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Llama 3.1 70B</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Meta Llama 3.1 70B</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A 70B-parameter Llama family model evaluated on chained GSM8K; achieves near-perfect single-problem accuracy but shows rapid drop with longer chains, performing worse than other frontier models at length >1.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Scheherazade: Evaluating Chain-of-Thought Math Reasoning in LLMs with Chain-of-Problems</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Llama 3.1 70B</td>
                        </tr>
                        <tr>
                            <td><strong>model_family</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>70B</td>
                        </tr>
                        <tr>
                            <td><strong>training_data_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>GSM8K-Scheherazade (forward and backward chains)</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>multi-step word problems / grade-school arithmetic reasoning (chained)</td>
                        </tr>
                        <tr>
                            <td><strong>problem_format</strong></td>
                            <td>natural-language chain-of-problems (if-then branching; forward and backward chaining)</td>
                        </tr>
                        <tr>
                            <td><strong>difficulty_level</strong></td>
                            <td>GSM8K-level per-component; overall harder due to chaining (chains of length 2–10 evaluated)</td>
                        </tr>
                        <tr>
                            <td><strong>prompting_method</strong></td>
                            <td>Assessed for Chain-of-Thought reasoning; specific prompt details not provided</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>accuracy (fraction correct)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>Forward-chain accuracies (lengths 1..10): [0.971, 0.268, 0.187, 0.124, 0.067, 0.044, 0.015, 0.011, 0.007, 0.005]. Backward-chain accuracies (lengths 1..10 as reported elsewhere): [0.971, 0.477, 0.265, 0.113, 0.064, 0.035, 0.015, 0.014, 0.002, 0.001]. Summary: strong at single-problem (length=1) but collapses quickly when chained.</td>
                        </tr>
                        <tr>
                            <td><strong>internal_analysis</strong></td>
                            <td>No internal mechanistic analysis provided in paper; only aggregate accuracy trajectories and qualitative remarks.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_modes</strong></td>
                            <td>Severe degradation with increasing chain length; worse-than-frontier performance at length >1; backward chains can be slightly better at very short lengths but collapse rapidly.</td>
                        </tr>
                        <tr>
                            <td><strong>scaling_trend</strong></td>
                            <td>Only single model size (70B) reported; observed performance drops sharply with chain length — no evidence in paper of emergent robustness from this size for chained problems.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Scheherazade : Evaluating Chain-of-Thought Math Reasoning in LLMs with Chain-of-Problems', 'publication_date_yy_mm': '2024-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6390.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e6390.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models perform arithmetic, including model details, task details, prompting methods, performance results, and any analysis of internal mechanisms or failure modes.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Claude 3.5 Sonnet</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Anthropic Claude 3.5 Sonnet</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An Anthropic frontier model evaluated on the chained GSM8K dataset; near-perfect on single problems but accuracy falls quickly with chain length, with backward chaining initially easier for short chains but deteriorating steeply.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Scheherazade: Evaluating Chain-of-Thought Math Reasoning in LLMs with Chain-of-Problems</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Claude 3.5 Sonnet</td>
                        </tr>
                        <tr>
                            <td><strong>model_family</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>training_data_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>GSM8K-Scheherazade (forward and backward chains)</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>multi-step word problems / grade-school arithmetic reasoning (chained)</td>
                        </tr>
                        <tr>
                            <td><strong>problem_format</strong></td>
                            <td>natural-language chain-of-problems (if-then branching; forward and backward chaining)</td>
                        </tr>
                        <tr>
                            <td><strong>difficulty_level</strong></td>
                            <td>GSM8K-level per-component; overall made harder via chaining (chains length 2–10 evaluated)</td>
                        </tr>
                        <tr>
                            <td><strong>prompting_method</strong></td>
                            <td>Evaluated for Chain-of-Thought reasoning; prompt specifics not described</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>accuracy (fraction correct)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>Forward-chain accuracies (lengths 1..10): [0.986, 0.280, 0.302, 0.274, 0.240, 0.236, 0.197, 0.177, 0.173, 0.156]. Backward-chain accuracies (lengths 1..10): [0.986, 0.879, 0.599, 0.319, 0.179, 0.102, 0.074, 0.056, 0.045, 0.032]. Summary: near-perfect at length=1; better on short backward chains but declines rapidly with chain length.</td>
                        </tr>
                        <tr>
                            <td><strong>internal_analysis</strong></td>
                            <td>No mechanistic probes; only aggregate accuracy trajectories and qualitative discussion (paper hypothesizes backward chaining is harder because it reverses typical CoT direction).</td>
                        </tr>
                        <tr>
                            <td><strong>failure_modes</strong></td>
                            <td>Rapid accuracy decline with chain length; relative advantage on very short backward chains but worse performance at longer backward chains compared to forward chains beyond certain lengths; general failure to correctly propagate intermediate results through nested conditionals.</td>
                        </tr>
                        <tr>
                            <td><strong>scaling_trend</strong></td>
                            <td>Paper does not present size-sweep for Claude; observed trend: accuracy falls rapidly with increasing chain length; backward-chain advantage at short lengths is transient.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Scheherazade : Evaluating Chain-of-Thought Math Reasoning in LLMs with Chain-of-Problems', 'publication_date_yy_mm': '2024-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Learning to reason with llms (openai o1) <em>(Rating: 2)</em></li>
                <li>A careful examination of large language model performance on grade school arithmetic <em>(Rating: 2)</em></li>
                <li>Premise order matters in reasoning with large language models <em>(Rating: 2)</em></li>
                <li>Training verifiers to solve math word problems <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-6390",
    "paper_id": "paper-273023082",
    "extraction_schema_id": "extraction-schema-126",
    "extracted_data": [
        {
            "name_short": "GPT-4o",
            "name_full": "GPT-4o",
            "brief_description": "A frontier OpenAI model evaluated in this paper for multi-step arithmetic/word-problem reasoning using chained-problem benchmarks (GSM8K-Scheherazade); shows near-perfect single-problem accuracy but rapid degradation as problems are chained.",
            "citation_title": "Scheherazade: Evaluating Chain-of-Thought Math Reasoning in LLMs with Chain-of-Problems",
            "mention_or_use": "use",
            "model_name": "GPT-4o",
            "model_family": null,
            "model_size": null,
            "training_data_description": null,
            "benchmark_name": "GSM8K-Scheherazade (derived from GSM8K)",
            "task_type": "multi-step word problems / grade-school arithmetic reasoning (chained)",
            "problem_format": "natural-language chain-of-problems (if-then branching; forward and backward chaining)",
            "difficulty_level": "GSM8K-level per-component; overall harder due to chaining (chains of length 2–10 evaluated)",
            "prompting_method": "Evaluated for Chain-of-Thought (CoT) style multi-step reasoning; specific prompt templates not specified in paper",
            "performance_metric": "accuracy (fraction correct)",
            "performance_value": "Forward-chain accuracies (lengths 1..10): [0.971, 0.438, 0.365, 0.347, 0.333, 0.291, 0.253, 0.214, 0.195, 0.167]. Backward-chain accuracies (lengths 1..10, as reported elsewhere in the paper): [0.971, 0.932, 0.645, 0.393, 0.231, 0.147, 0.097, 0.080, 0.052, 0.001]. Summary: near-perfect at length=1, precipitous decline as chain length increases; no model (including GPT-4o) remains &gt;50% beyond ~6 chained questions.",
            "internal_analysis": "No mechanistic interpretability (e.g., activation/attention probing or logit-lens) presented. Paper gives qualitative/manual error analysis only (see general discussion about models failing to follow backward CoT and omitting subquestions).",
            "failure_modes": "Rapid degradation with increasing chain length; worse performance on backward-chaining at longer lengths (though sometimes backward is stronger at short lengths); failures include omission of answering subproblems in the chain and inability to correctly propagate intermediate numeric conclusions across branches.",
            "scaling_trend": "Paper does not report architecture/size scaling for GPT-4o; observed trend: accuracy falls monotonically with chain length; backward-chain performance can be higher at short lengths but collapses faster than forward-chain, with forward overtaking around length ~6.",
            "uuid": "e6390.0",
            "source_info": {
                "paper_title": "Scheherazade : Evaluating Chain-of-Thought Math Reasoning in LLMs with Chain-of-Problems",
                "publication_date_yy_mm": "2024-09"
            }
        },
        {
            "name_short": "o1-preview",
            "name_full": "OpenAI o1-preview",
            "brief_description": "An OpenAI model variant evaluated preliminarily on backward-chained GSM8K-Scheherazade; shows substantially better robustness to backward chaining than other frontier models in the paper's limited evaluation.",
            "citation_title": "Scheherazade: Evaluating Chain-of-Thought Math Reasoning in LLMs with Chain-of-Problems",
            "mention_or_use": "use",
            "model_name": "o1-preview",
            "model_family": null,
            "model_size": null,
            "training_data_description": null,
            "benchmark_name": "GSM8K-Scheherazade (backward chains; preliminary subset)",
            "task_type": "multi-step word problems / grade-school arithmetic reasoning (backward-chained)",
            "problem_format": "natural-language chain-of-problems (backward chaining); preliminary evaluation on 25 samples per chain length (lengths 1..7, also reported to length 8 for some results)",
            "difficulty_level": "GSM8K-level per-component; overall harder due to chaining (evaluated up to length 8 in limited sample set)",
            "prompting_method": "Evaluated for Chain-of-Thought reasoning; specific prompt or fine-tuning details not provided in paper",
            "performance_metric": "accuracy (fraction correct); also reported absolute counts on the small preliminary set",
            "performance_value": "Preliminary backward-chain accuracies on 25-sample runs (lengths 1..8 as reported): [1.000, 0.880, 0.800, 0.800, 0.920, 0.520, 0.600, 0.562]. Example: at backward chain length 5 o1-preview solved 23/25 questions (92%). Overall, o1-preview retained high performance up to ~5 backward-chained questions, outperforming other evaluated models at those lengths.",
            "internal_analysis": "Limited manual error analysis: of 41 incorrect cases across evaluated lengths, o1-preview omitted answering every question in chain for 12 cases; omission rate higher for longest chains (4/10 for chains length ≥7). No deeper mechanistic probing performed.",
            "failure_modes": "Omissions of subanswers within the chain (not answering every intermediate question), mistakes increase with chain length; some non-monotonic behaviour across chain lengths in the small sample (e.g., a spike at length 5 in the preliminary set).",
            "scaling_trend": "Paper provides only preliminary results for o1-preview (no size-sweep). Observed robustness relative to other models: much better retention of accuracy up to 4–5 backward-chained problems, then performance degrades; shows a qualitatively different trend (more robust on backward chaining) than other models evaluated.",
            "uuid": "e6390.1",
            "source_info": {
                "paper_title": "Scheherazade : Evaluating Chain-of-Thought Math Reasoning in LLMs with Chain-of-Problems",
                "publication_date_yy_mm": "2024-09"
            }
        },
        {
            "name_short": "Llama 3.1 70B",
            "name_full": "Meta Llama 3.1 70B",
            "brief_description": "A 70B-parameter Llama family model evaluated on chained GSM8K; achieves near-perfect single-problem accuracy but shows rapid drop with longer chains, performing worse than other frontier models at length &gt;1.",
            "citation_title": "Scheherazade: Evaluating Chain-of-Thought Math Reasoning in LLMs with Chain-of-Problems",
            "mention_or_use": "use",
            "model_name": "Llama 3.1 70B",
            "model_family": null,
            "model_size": "70B",
            "training_data_description": null,
            "benchmark_name": "GSM8K-Scheherazade (forward and backward chains)",
            "task_type": "multi-step word problems / grade-school arithmetic reasoning (chained)",
            "problem_format": "natural-language chain-of-problems (if-then branching; forward and backward chaining)",
            "difficulty_level": "GSM8K-level per-component; overall harder due to chaining (chains of length 2–10 evaluated)",
            "prompting_method": "Assessed for Chain-of-Thought reasoning; specific prompt details not provided",
            "performance_metric": "accuracy (fraction correct)",
            "performance_value": "Forward-chain accuracies (lengths 1..10): [0.971, 0.268, 0.187, 0.124, 0.067, 0.044, 0.015, 0.011, 0.007, 0.005]. Backward-chain accuracies (lengths 1..10 as reported elsewhere): [0.971, 0.477, 0.265, 0.113, 0.064, 0.035, 0.015, 0.014, 0.002, 0.001]. Summary: strong at single-problem (length=1) but collapses quickly when chained.",
            "internal_analysis": "No internal mechanistic analysis provided in paper; only aggregate accuracy trajectories and qualitative remarks.",
            "failure_modes": "Severe degradation with increasing chain length; worse-than-frontier performance at length &gt;1; backward chains can be slightly better at very short lengths but collapse rapidly.",
            "scaling_trend": "Only single model size (70B) reported; observed performance drops sharply with chain length — no evidence in paper of emergent robustness from this size for chained problems.",
            "uuid": "e6390.2",
            "source_info": {
                "paper_title": "Scheherazade : Evaluating Chain-of-Thought Math Reasoning in LLMs with Chain-of-Problems",
                "publication_date_yy_mm": "2024-09"
            }
        },
        {
            "name_short": "Claude 3.5 Sonnet",
            "name_full": "Anthropic Claude 3.5 Sonnet",
            "brief_description": "An Anthropic frontier model evaluated on the chained GSM8K dataset; near-perfect on single problems but accuracy falls quickly with chain length, with backward chaining initially easier for short chains but deteriorating steeply.",
            "citation_title": "Scheherazade: Evaluating Chain-of-Thought Math Reasoning in LLMs with Chain-of-Problems",
            "mention_or_use": "use",
            "model_name": "Claude 3.5 Sonnet",
            "model_family": null,
            "model_size": null,
            "training_data_description": null,
            "benchmark_name": "GSM8K-Scheherazade (forward and backward chains)",
            "task_type": "multi-step word problems / grade-school arithmetic reasoning (chained)",
            "problem_format": "natural-language chain-of-problems (if-then branching; forward and backward chaining)",
            "difficulty_level": "GSM8K-level per-component; overall made harder via chaining (chains length 2–10 evaluated)",
            "prompting_method": "Evaluated for Chain-of-Thought reasoning; prompt specifics not described",
            "performance_metric": "accuracy (fraction correct)",
            "performance_value": "Forward-chain accuracies (lengths 1..10): [0.986, 0.280, 0.302, 0.274, 0.240, 0.236, 0.197, 0.177, 0.173, 0.156]. Backward-chain accuracies (lengths 1..10): [0.986, 0.879, 0.599, 0.319, 0.179, 0.102, 0.074, 0.056, 0.045, 0.032]. Summary: near-perfect at length=1; better on short backward chains but declines rapidly with chain length.",
            "internal_analysis": "No mechanistic probes; only aggregate accuracy trajectories and qualitative discussion (paper hypothesizes backward chaining is harder because it reverses typical CoT direction).",
            "failure_modes": "Rapid accuracy decline with chain length; relative advantage on very short backward chains but worse performance at longer backward chains compared to forward chains beyond certain lengths; general failure to correctly propagate intermediate results through nested conditionals.",
            "scaling_trend": "Paper does not present size-sweep for Claude; observed trend: accuracy falls rapidly with increasing chain length; backward-chain advantage at short lengths is transient.",
            "uuid": "e6390.3",
            "source_info": {
                "paper_title": "Scheherazade : Evaluating Chain-of-Thought Math Reasoning in LLMs with Chain-of-Problems",
                "publication_date_yy_mm": "2024-09"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Learning to reason with llms (openai o1)",
            "rating": 2,
            "sanitized_title": "learning_to_reason_with_llms_openai_o1"
        },
        {
            "paper_title": "A careful examination of large language model performance on grade school arithmetic",
            "rating": 2,
            "sanitized_title": "a_careful_examination_of_large_language_model_performance_on_grade_school_arithmetic"
        },
        {
            "paper_title": "Premise order matters in reasoning with large language models",
            "rating": 2,
            "sanitized_title": "premise_order_matters_in_reasoning_with_large_language_models"
        },
        {
            "paper_title": "Training verifiers to solve math word problems",
            "rating": 1,
            "sanitized_title": "training_verifiers_to_solve_math_word_problems"
        }
    ],
    "cost": 0.011731749999999999,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Scheherazade: Evaluating Chain-of-Thought Math Reasoning in LLMs with Chain-of-Problems</p>
<p>Stephen Miner 
Yale University</p>
<p>Yoshiki Takashima 
Yale University</p>
<p>Simeng Han 
Yale University</p>
<p>Ferhat Erata 
Yale University</p>
<p>Timos Antonopoulos 
Yale University</p>
<p>Ruzica Piskac 
Yale University</p>
<p>Scott J Shapiro 
Yale University</p>
<p>Scheherazade: Evaluating Chain-of-Thought Math Reasoning in LLMs with Chain-of-Problems
CF3A8E0D991A2304235C8EDE3E3C67A9
Benchmarks are critical for measuring progress of math reasoning abilities of Large Language Models (LLMs).However, existing widely-used benchmarks such as GSM8K have been rendered less useful as multiple cutting-edge LLMs achieve over 94% accuracy.While harder benchmarks have been proposed, their creation is often manual and expensive.We present Scheherazade, an automated approach for producing challenging mathematical reasoning benchmarks by logically chaining mathematical reasoning problems.We propose two different chaining methods, forward chaining and backward chaining, which require reasoning forward and backward through the chain respectively.We apply Scheherazade on GSM8K to create GSM8K-Scheherazade and evaluate 3 frontier LLMs and OpenAI's o1-preview on it.We show that while frontier models' performance declines precipitously at only a few questions chained, a preliminary evaluation suggests o1-preview's performance persists up to 5 questions chained backwards.In addition, while all other models perform worse when problems are chained backwards, o1-preview performs better on backward-chained benchmarks.Our data and code are available at https://github.com/YoshikiTakashima/scheherazadecode-data.</p>
<p>Introduction</p>
<p>"No problem can be solved from the same level of consciousness that created it."-Albert Einstein Benchmarks are the crux of evaluating LLM reasoning capablities.Ranging from grade-school math problems to advanced math olympiads and beyond, they enable measurement and apples-to-apples comparisons of LLMs that are black-box, proprietary, or often both.These benchmarks play a pivotal role in both development of LLMs and claims made about their capabilities [1][2][3].</p>
<p>Yet the current benchmark ecosystem is becoming unsustainable as the math reasoning capabilities of LLMs improve rapidly [4,[1][2][3].In addition, existing benchmarks are widely used for training and finetuning LLMs, leading to serious data contamination issues [5,6].GSM8K in particular have been rendered less useful as multiple advanced LLMs surpass 94% accuracy and competitive performance has been achieved on math [4, 1-3, 7, 8].Despite the rapid consumption and depreciation of benchmarks, novel, high-quality benchmark sets are limited, and generating new data often involves costly manual labeling.While synthetic benchmark creation methods have been proposed, their scope is limited.Existing approaches shuffle sentences [9], leverage templates [10,11] and mutate constants [12], limiting the complexity and diversity of the generated benchmarks.</p>
<p>We introduce Scheherazade, a technique for logically chaining multiple existing benchmarks together to create larger benchmark problems that test Chain-of-Thought (CoT) mathematical and logical reasoning abilities of models.We illustrate our approach with the following simple example: consider the statement, "If it rains, I will wear a raincoat."Now, if we modify the statement, for example, to "If 2+3 = 5 and it rains, I will wear a raincoat,' we, as humans, can immediately see that this statement is equivalent to the previous one.However, we could easily add more and more such statements to create a chain of expressions.Such a chain may sound highly artificial to us, but we would still be able to reason by ignoring all the irrelevant statements.In this paper, we show that such chains are a great way to test the reasoning capacities of existing LLMs.</p>
<p>Our approach chains benchmarks so that necessary information to solve the next question is derived by solving the previous question in the logical chain.Our tool leverages conditional branches and randomness to ensure the LLM cannot simply memorize the format.We propose two methods of syntactically chaining questions, forward chaining and backward chaining.In forward chaining, problems are connected using implication such that the resulting chained problem can be solved in the order it is written.In contrast, backward chaining requires that problems earlier in the chain require information from all problems later in the chain in order to be solvable.While logically equivalent, backward chaining forces the model under test to look backwards at every question.Both techniques generalize to chains of any length and ordering of their component problems.</p>
<p>We benchmark the mathematical reasoning abilities of four frontier models, OpenAI o1, GPT-4o, Meta Llama 3.1 70B, and Anthropic Claude 3.5 Sonnet, using a benchmark set created by applying Scheherazade to GSM8K and report our findings in Section 3. Running the models on our benchmark shows that, despite high reported scores on original GSM8K problems, the performance declines rapidly to less than half of the original GSM8K performance when multiple problems are chained together.No model performs above 50% at 6 questions chained or above 30% at 10 questions chained.A preliminary evaluation with OpenAI o1-preview shows it outperforms current frontier models at longer questions.At backward chain length of 5, o1-preview solves 23 out of 25 questions while no other model performs above 50%.</p>
<p>Approach</p>
<p>At the heart of our technique is chaining problems together.We introduce two techniques to create n-length chains of GSM8K problems, where n is the number of problems used in the chain.These problems are chained together to create a single, composite problem.The problems we create contain branching paths and use randomness to prevent the LLM from simply being able to memorize which path through the branches is the correct one.The first technique is forward chaining.In forward chaining, problems are chained together such that the resulting chain of problems can be solved in the order it is written.The other technique, backward chaining, requires that at any problem in the chain, information from a future problem is necessary to solve the current problem.Both of these techniques can generalize to any chain length, and the problems can be chained in any order.</p>
<p>To explain how we chain problems, we first introduce some notation.For a math reasoning question Q, let Q 1 be the first logical premise of Q.For example, if Q = "Alice has 3 apples.Bob has 2 apples.How many apples do Alice and Bob have in total?", then Q 1 = "Alice has 3 apples."We use Q p to denote the remaining premises of the problem, in our example Q p = "Bob has 2 apples.",but there could be many sentences in Q p or possible no sentences.We let Q q be the question or statement asking for the solution to the problem.In our example, Q q = "How many apples do Alice and Bob have in total?".Q c denotes the conclusion of the problem, written in natural language.For example, Q c = "Alice and Bob have 3 apples in total."We additionally use Q ′ c and Q ′ 1 for each question, a wrong conclusion and an alternate first premise respectively.</p>
<p>We chain problems together in two ways, forward chaining and backward chaining.At any point in the chain, to chain two problems together we create a branching "if then else" statement.For forward chaining, take n = 2 as an example, and let A and B be the two problems.Forward chaining A and B results in one of the following, selected at random:
A 1 + A p + (A c =⇒ B 1 ∧ ¬A c =⇒ B ′ 1 ) + B p + B q A 1 + A p + (A ′ c =⇒ B ′ 1 ∧ ¬A ′ c =⇒ B 1 ) + B p + B q
Here, the + symbol is string concatenation, and
A c =⇒ B 1 ∧ ¬A c =⇒ B ′ 1 denotes "If: [A c ] is true, then: [B 1 ] is true, otherwise: [B ′ 1 ] is true." Importantly, for any question Q, Q ′ 1 has the property that Q ′ 1 ⇏ Q c ,
meaning if the wrong branch is taken, the corresponding premise of that branch will lead to an incorrect conclusion.Figure 1 shows how forward chaining generalizes, and provides two example problems.</p>
<p>Backward chaining also branches in a similar way, but unlike forward chaining, backward chaining requires information from future problems in order to solve the current problem in the chain.For example, the result of backward chaining problems A and B results in one of the following, selected at random:
(B c =⇒ A 1 ∧ ¬B c =⇒ A ′ 1 ) + A p + B 1 + B p + A q (B ′ c =⇒ A ′ 1 ∧ ¬B ′ c =⇒ A 1 ) + A p + B 1 + B p + A q Notice that
in order to get the first premise of A, problem B must be solved.However, the premises of problem B do not appear until after problem A. Importantly, notice that in backward chaining the final question is A q , meaning all intermediate questions must be solved in order to solve the final question.Backward chaining also generalizes to any length.For the sake of showing the generalization simply, if we remove the randomness then backward chaining generalizes as follows:
(Q2 c =⇒ Q1 1 ∧¬Q2 c =⇒ Q1 ′ 1 )+Q1 p +(Q3 c =⇒ Q2 1 ∧¬Q3 c =⇒ Q2 ′ 1 )+Q2 p +...+Q1 q
This generalization shows that as the chain length increases, the reasoning required to solve the problem becomes increasingly nested.That is, information from Q2 is required to determine the first premise of Q1, information from Q3 is required to determine the first premise of Q2, and so on.In our results, we will show that LLMs struggle with this kind of reasoning, performing much better on forward reasoning than on backward reasoning.</p>
<p>Evaluation</p>
<p>Using our Scheherazade over GSM8K, we create GSM8K-Scheherazade, where we generate 1,000 examples for a chain of 2-10 and included both forward and backward chaining methods, resulting in a total of 18,000 new examples.We evaluate 4 state-of-the-art LLMs: OpenAI's GPT-4o (Aug.6th 2024), o1-preview, Anthropic Claude 3.5 Sonnet, and Meta Llama 3.1 70B.For all models except o1-preview, we run this evaluation on the entire GSM8K-Scheherazade.Because access to o1-preview is limited, we run a preliminary evaluation of 25 samples at chain lengths 1 to 7 for backwards chaining only.These lengths are picked because o1-preview's accuracy declines most dramatically over these lengths.</p>
<p>Table 1: Raw accuracy numbers up to length 10. o1-preview is run up to length 8. Despite near-perfect performance by frontier models at length 1 (original GSM8K problems), the performance rapidly declines.gpt-4o 0.971 0.932 0.645 0.393 0.231 0.147 0.097 0.080 0.052 0.001 Llama3.1 70B 0.971 0.477 0.265 0.113 0.064 0.035 0.015 0.014 0.002 0.001 o1-preview 1.000 0.880 0.800 0.800 0.920 0.520 0.600 0.562 -- The results of the evaluation are shown in and Table 1.For each chain length we give the raw accuracy numbers between 0 and 1.The top half provides accuracy numbers for forward chaining and lower half for backward chaining.Fig. 2 shows the performance normalized to accuracy on problems of length 1, which are identical to GSM8K problems.The horizontal axis denotes the number of chained questions, while the vertical axis represents normalized accuracy.</p>
<p>Looking at the raw accuracy presented in Table 1, we see that accuracy quickly declines for every model except o1-preview at 2 to 3 chains.In general, models other than o1-preview perform slightly better with backwards chaining with shorter questions but accuracy on backward-chained questions declines quicker than forward-chained questions, with the latter overtaking the former at around length 6.</p>
<p>Normalized to the original GSM8K performance in Fig. 2, we see that the accuracy declines rapidly for every model except o1-preview.With four problems chained, no model perform above 60% of the original GSM8K accuracy at length 8 and every model except o1-preview.Likewise, for every model other than o1-preview, the accuracy at longer lengths is worse with backward chaining.We posit the reason all models struggled with backward chaining is that backward chaining requires the LLMs to reason in reverse of traditional CoT.Manually analyzing the 41 questions o1-preview got incorrect, it did not answer every question in the chain for 12 of them.This ratio increases to 4 out of 10 for chains of length 7 and up, the longest chain we evaluated o1-preview on.</p>
<p>Conclusion and Future Work</p>
<p>The results of running GSM8K-Scheherazade on frontier models suggests several avenues for future work.First, it would be useful to run Scheherazade with benchmarks other than GSM8K.Other, more difficult math reasoning benchmarks exist, and Scheherazade may slow their depreciation.Second, logical operators other than if-then-else should be explored.It is possible to combine problems with conjunctions or disjunctions in addition to implications.When the benchmarks are numerical, numerical operators such as taking sums of solutions are also relevant.Third, given that o1-preview performs better with backward chaining, combining Scheherazade with more fine-grained reorderings of the questions remains to be explored.While we presented purely backward and purely forward chaining, hybrid combinations of both forward and backward chaining may allow us to figure out the scope of o1-preview's reasoning abilities.</p>
<p>Benchmarks are the foundation upon which the current language model ecosystem stands.Their rapidly eroding value is a cause for concern.We presented Scheherazade, a technique for generating new, larger benchmarks by logically chaining existing benchmarks.Using Scheherazade on GSM8K, we created a benchmark set that defeats existing frontier models and exposes surprising reasoning behavior in o1-preview, performing better at backward reasoning than forward.</p>
<p>Figure 1 :
1
Figure 1: Forward chaining generalization and example.</p>
<p>Forward</p>
<p>Claude 3.5 0.986 0.280 0.302 0.274 0.240 0.236 0.197 0.177 0.173 0.156 gpt-4o 0.971 0.438 0.365 0.347 0.333 0.291 0.253 0.214 0.195 0.167 Llama3.1 70B 0.971 0.268 0.187 0.124 0.067 0.044 0.015 0.011 0.007 0.005 Backward Claude 3.5 0.986 0.879 0.599 0.319 0.179 0.102 0.074 0.056 0.045 0.032</p>
<p>Figure 2 :
2
Figure 2: Accuracy of LLMs declines when the chains become longer.With the exception of o1-preview, LLMs find backward chains harder than forward chains at longer lengths.The *Agent solves L GSM8K question independently with the accuracy measured at L = 1.If the accuracy at L = 1 is a, then the agent is computed to perform at length L with accuracy a L .</p>
<p>Preprint. Under review.</p>
<p>Gpt-4 technical report. J Openai, Others Achiam, 2024</p>
<p>The llama 3 herd of models. A Dubey, A Jauhri, Others, 2024</p>
<p>Gemma: Open models based on gemini research and technology. G Team, T Mesnard, Others, 2024</p>
<p>Learning to reason with llms (openai o1). Openai, Sept. 2024</p>
<p>A careful examination of large language model performance on grade school arithmetic. H Zhang, J Da, D Lee, V Robinson, C Wu, W Song, T Zhao, P Raja, D Slack, Q Lyu, S Hendryx, R Kaplan, M Lunati, S Yue, 2024</p>
<p>On leakage of code generation evaluation datasets. A Matton, T Sherborne, D Aumiller, E Tommasone, M Alizadeh, J He, R Ma, M Voisin, E Gilsenan-Mcmahon, M Gallé, 2024</p>
<p>Training verifiers to solve math word problems. K Cobbe, V Kosaraju, M Bavarian, M Chen, H Jun, L Kaiser, M Plappert, J Tworek, J Hilton, R Nakano, C Hesse, J Schulman, 2110.14168, 2021CoRR</p>
<p>Measuring mathematical problem solving with the MATH dataset. D Hendrycks, C Burns, S Kadavath, A Arora, S Basart, E Tang, D Song, J Steinhardt, Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track. 2021</p>
<p>Premise order matters in reasoning with large language models. X Chen, R A Chi, X Wang, D Zhou, 2024</p>
<p>Training language models with syntactic data generation. Y Zhang, Y Luo, Y Yuan, A C , -C Yao, 2024</p>
<p>Synthesize step-by-step: Tools, templates and llms as data generators for reasoning-based chart vqa. Z Li, B Jasani, P Tang, S Ghadar, 2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Los Alamitos, CA, USAIEEE Computer Societyjun 2024</p>
<p>PAL: Program-aided language models. L Gao, A Madaan, S Zhou, U Alon, P Liu, Y Yang, J Callan, G Neubig, Proceedings of the 40th International Conference on Machine Learning. A Krause, E Brunskill, K Cho, B Engelhardt, S Sabato, J Scarlett, the 40th International Conference on Machine LearningPMLRJul 2023202Proceedings of Machine Learning Research</p>            </div>
        </div>

    </div>
</body>
</html>