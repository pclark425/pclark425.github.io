<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-5701 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-5701</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-5701</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-114.html">extraction-schema-114</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being used as text-based simulators in specific scientific subdomains, including details on the simulation tasks, reported accuracy, evaluation methods, and any factors identified as affecting the accuracy of these simulations.</div>
                <p><strong>Paper ID:</strong> paper-0f25d552eefd9649d080e2eda27482f7ba20a126</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/0f25d552eefd9649d080e2eda27482f7ba20a126" target="_blank">Mixture-of-Personas Language Models for Population Simulation</a></p>
                <p><strong>Paper Venue:</strong> Annual Meeting of the Association for Computational Linguistics</p>
                <p><strong>Paper TL;DR:</strong> Experiments for synthetic data generation show that MoP outperforms competing methods in alignment and diversity metrics, and is flexible, requires no model finetuning, and is transferable across base models.</p>
                <p><strong>Paper Abstract:</strong> Advances in Large Language Models (LLMs) paved the way for their emerging applications in various domains, such as human behavior simulations, where LLMs could augment human-generated data in social science research and machine learning model training. However, pretrained LLMs often fail to capture the behavioral diversity of target populations due to the inherent variability across individuals and groups. To address this, we propose \textit{Mixture of Personas} (MoP), a \textit{probabilistic} prompting method that aligns the LLM responses with the target population. MoP is a contextual mixture model, where each component is an LM agent characterized by a persona and an exemplar representing subpopulation behaviors. The persona and exemplar are randomly chosen according to the learned mixing weights to elicit diverse LLM responses during simulation. MoP is flexible, requires no model finetuning, and is transferable across base models. Experiments for synthetic data generation show that MoP outperforms competing methods in alignment and diversity metrics.</p>
                <p><strong>Cost:</strong> 0.016</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e5701.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e5701.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being used as text-based simulators in specific scientific subdomains, including details on the simulation tasks, reported accuracy, evaluation methods, and any factors identified as affecting the accuracy of these simulations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>MoP-Llama3-8B</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Mixture-of-Personas prompting with Llama3-8B-Instruct</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>This paper's primary experimental setup: an exemplar-based probabilistic prompting method (Mixture of Personas, MoP) applied to an instruction-tuned Llama3-8B model to simulate population-level text (news, movie/restaurant reviews) and to generate synthetic datasets for downstream classification.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Llama3-8B-Instruct</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Instruction-finetuned member of the Llama 3 family used as the fixed base LLM for all forward passes; kept frozen during MoP training while only gating networks are trained. Paper references Dubey et al. (2024) for Llama3.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>8B</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_subdomain</strong></td>
                            <td>Social science / behavioral simulation; NLP dataset synthesis (news topic classification, sentiment analysis)</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_task</strong></td>
                            <td>Text-based population simulation: generate news blurbs (AGNews) and movie/restaurant reviews (SST-2, IMDB, Yelp) representative of target population subgroups; create synthetic labeled datasets for downstream topic/sentiment classification.</td>
                        </tr>
                        <tr>
                            <td><strong>accuracy_metric</strong></td>
                            <td>Embedding-space alignment and diversity metrics: FID (Fréchet Inception Distance), MAUVE, KL Cosine (KL divergence of pairwise cosine-similarity histograms); downstream classifier F1 on golden test set.</td>
                        </tr>
                        <tr>
                            <td><strong>reported_accuracy</strong></td>
                            <td>Table 1 (MoP using Llama3-8B-Instruct): AGNews FID=0.951, MAUVE=0.871, KL Cosine=0.069; Yelp FID=0.948, MAUVE=0.826, KL Cosine=0.067; SST-2 FID=1.131, MAUVE=0.855, KL Cosine=0.319; IMDB FID=0.771, MAUVE=0.865, KL Cosine=0.039. Downstream classifier F1s (Table 2) trained on MoP synthetic data: AGNews F1=0.871, Yelp F1=0.867, SST-2 F1=0.845, IMDB F1=0.865. Averaged improvement over strongest baseline: ~58.8% FID improvement and ~27.9% MAUVE improvement.</td>
                        </tr>
                        <tr>
                            <td><strong>factors_affecting_accuracy</strong></td>
                            <td>Persona prompting quality and persona synthesis, use of exemplars (in-context examples), number of personas, number of exemplars, per-persona temperature (learnable τ), sparse gating/top-M selection, base model alignment to target distribution (pretrained biases), and whether the persona-exemplar pairings are learned or random.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_for_factors</strong></td>
                            <td>Ablation studies (Table 4) show removing exemplars drastically harms alignment/diversity (w/o exemplars: FID 3.694 vs MoP 0.951; MAUVE 0.552 vs 0.871), removing persona synthesizer degrades but less so (FID 1.674), and random personas degrade MAUVE/FID. Varying counts (Figure 4) shows more personas/exemplars generally help, with exemplar performance saturating around 2000. Per-persona learnable temperature τ is used and discussed as controlling diversity. Transfer experiments (Table 3) show base model choice affects metrics.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method</strong></td>
                            <td>Automated embedding-space evaluation: embed generated and golden texts with all-mpnet-base-v2, compute FID, MAUVE (500 clusters, scaling=1), and KL Cosine (histogram KL of pairwise cosine similarities). For downstream utility, train a DistilBERT classifier on 5,000 generated samples and evaluate F1 on the held-out golden test set. Generation volume: 5,000 synthetic responses per method; exemplar masking used during training to avoid predicting the same example.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Requires access to LLM output logits to train gating networks (limiting applicability to closed-source models without logit access); risk of biases from persona prompt construction; exemplars drawn from the same dataset risk overfitting without masking; performance depends on base-model prior alignment (e.g., Llama3 already closely aligned to Yelp, leaving less room for improvement).</td>
                        </tr>
                        <tr>
                            <td><strong>comparisons</strong></td>
                            <td>Compared against ZeroGen, AttrPrompt, ProGen, and PICLe (same Llama3 base). MoP substantially outperforms baselines on alignment/diversity metrics (Table 1). Also transferred MoP gating prompts to Gemma2-9B and Mistral-7B for cross-model comparison (Table 3).</td>
                        </tr>
                        <tr>
                            <td><strong>recommendations_or_best_practices</strong></td>
                            <td>Include exemplar-based prompting (exemplars are crucial); synthesize or curate personas (persona synthesizer improves alignment); use sparse top-M gating for scalability; learn per-persona temperature τ to control diversity; mask target examples during training to avoid trivial memorization; scale the number of personas and exemplars up to the point of saturation (≈2000 exemplars).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Mixture-of-Personas Language Models for Population Simulation', 'publication_date_yy_mm': '2025-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5701.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e5701.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being used as text-based simulators in specific scientific subdomains, including details on the simulation tasks, reported accuracy, evaluation methods, and any factors identified as affecting the accuracy of these simulations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>MoP->Gemma2-9B</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Mixture-of-Personas transferred to Gemma2-9B-Instruct</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Transfer evaluation: the MoP gating networks trained with Llama3-8B prompts were applied (plug-and-play) to Gemma2-9B-Instruct as the base LLM to simulate AGNews, showing that MoP transfers and can even improve alignment.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Gemma2-9B-Instruct</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Instruction-finetuned Gemma2 model (referenced Team et al. 2024); used as an alternative base LLM receiving the same persona+exemplar prompts and sampling configuration.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>9B</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_subdomain</strong></td>
                            <td>NLP dataset synthesis / population text simulation (news topic generation)</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_task</strong></td>
                            <td>Generate AGNews-style news blurbs under MoP prompting and gating learned on Llama3-8B.</td>
                        </tr>
                        <tr>
                            <td><strong>accuracy_metric</strong></td>
                            <td>FID, MAUVE, KL Cosine (embedding-based metrics using all-mpnet-base-v2).</td>
                        </tr>
                        <tr>
                            <td><strong>reported_accuracy</strong></td>
                            <td>Transfer results (Table 3): Gemma2-9B: FID=0.492, MAUVE=0.957, KL Cosine=0.006 (improves over the MoP-Llama3-8B baseline).</td>
                        </tr>
                        <tr>
                            <td><strong>factors_affecting_accuracy</strong></td>
                            <td>Base model architecture and pretraining/instruction-tuning differences (Gemma2's priors), compatibility of gating prompts with the new model, and sampling settings; demonstrates that transfer can improve or degrade performance depending on base model.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_for_factors</strong></td>
                            <td>Direct transfer experiment (Table 3) shows substantial improvement in embedding metrics when swapping Llama3-8B for Gemma2-9B while keeping MoP gating fixed, indicating base-model priors materially affect simulation alignment.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method</strong></td>
                            <td>Same embedding-space metrics (FID, MAUVE, KL Cosine) computed against the golden AGNews test set; using the pre-trained encoder all-mpnet-base-v2.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>No retraining of gating networks performed; success depends on instruction-tuned behavior of the target base model and logit compatibility; paper notes MoP needs logit access to train, which may be unavailable for closed-source models.</td>
                        </tr>
                        <tr>
                            <td><strong>comparisons</strong></td>
                            <td>Compared directly to MoP-Llama3-8B and MoP-Mistral-7B in Table 3; Gemma2-9B produced best metrics on AGNews among the three.</td>
                        </tr>
                        <tr>
                            <td><strong>recommendations_or_best_practices</strong></td>
                            <td>MoP gating learned on one model can often be applied to other instruction-tuned models, and practitioners should test multiple base models since some models (here Gemma2-9B) can yield better alignment.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Mixture-of-Personas Language Models for Population Simulation', 'publication_date_yy_mm': '2025-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5701.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e5701.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being used as text-based simulators in specific scientific subdomains, including details on the simulation tasks, reported accuracy, evaluation methods, and any factors identified as affecting the accuracy of these simulations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>MoP->Mistral-7B</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Mixture-of-Personas transferred to Mistral-v0.3-7B-Instruct</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Transfer evaluation of the MoP gating network applied to Mistral-7B-Instruct as an alternative base model for AGNews generation; shows comparable performance to the original Llama3-8B base in this task.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Mistral-v0.3-7B-Instruct</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Instruction-finetuned Mistral-7B variant (referenced Jiang et al. 2023); used as a base LLM to sample outputs under fixed MoP prompts/gating.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>7B</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_subdomain</strong></td>
                            <td>NLP dataset synthesis / population text simulation (news topic generation)</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_task</strong></td>
                            <td>Generate AGNews-style news blurbs under MoP prompting and gating learned on Llama3-8B.</td>
                        </tr>
                        <tr>
                            <td><strong>accuracy_metric</strong></td>
                            <td>FID, MAUVE, KL Cosine (embedding-space metrics).</td>
                        </tr>
                        <tr>
                            <td><strong>reported_accuracy</strong></td>
                            <td>Transfer results (Table 3): Mistral-7B: FID=0.923, MAUVE=0.869, KL Cosine=0.081 (close to MoP-Llama3-8B performance).</td>
                        </tr>
                        <tr>
                            <td><strong>factors_affecting_accuracy</strong></td>
                            <td>Base model priors and instruction-tuning differences; sampling and temperature settings; compatibility with MoP exemplar/persona prompts.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_for_factors</strong></td>
                            <td>Transfer table (Table 3) shows Mistral-7B yields metrics similar to Llama3-8B but behind Gemma2-9B, indicating model-specific priors influence alignment.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method</strong></td>
                            <td>Same embedding-space metrics (FID, MAUVE, KL Cosine) against AGNews golden test set using all-mpnet-base-v2 embeddings.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>As with other transfers, no retraining of gating networks; performance depends on how closely the model's generation prior matches the target distribution.</td>
                        </tr>
                        <tr>
                            <td><strong>comparisons</strong></td>
                            <td>Directly compared with MoP-Llama3-8B and MoP->Gemma2-9B (Table 3).</td>
                        </tr>
                        <tr>
                            <td><strong>recommendations_or_best_practices</strong></td>
                            <td>When deploying MoP, evaluate multiple candidate base models — smaller models (7B) can be competitive but priors vary; use model selection based on embedding-alignment metrics.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Mixture-of-Personas Language Models for Population Simulation', 'publication_date_yy_mm': '2025-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5701.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e5701.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being used as text-based simulators in specific scientific subdomains, including details on the simulation tasks, reported accuracy, evaluation methods, and any factors identified as affecting the accuracy of these simulations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GPT-4 (baselines)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>GPT-4 (used by baseline methods ZeroGen and AttrPrompt in referenced released datasets)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>GPT-4 outputs (from prior authors' released datasets) appear in baseline comparisons (ZeroGen and AttrPrompt variants using GPT-4) for synthetic data generation and provide reference metrics in Table 1.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-4</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Large instruction-capable model from OpenAI; paper uses previously released datasets/metrics from ZeroGen and AttrPrompt experiments run with GPT-4 (authors' released results), not new GPT-4 runs performed within this work.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>scientific_subdomain</strong></td>
                            <td>NLP dataset synthesis / population text simulation (news and reviews)</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_task</strong></td>
                            <td>Zero-shot or attribute-conditioned synthetic text generation used as baselines for comparison (news blurbs, reviews).</td>
                        </tr>
                        <tr>
                            <td><strong>accuracy_metric</strong></td>
                            <td>FID, MAUVE, KL Cosine (embedding-based metrics reported from released baseline datasets shown in Table 1).</td>
                        </tr>
                        <tr>
                            <td><strong>reported_accuracy</strong></td>
                            <td>Baseline entries labeled with * (from authors' released datasets): ZeroGen (GPT4)* — AGNews FID=3.248 MAUVE=0.553 KL=0.506; AttrPrompt (GPT4)* — AGNews FID=2.992 MAUVE=0.585 KL=0.399 (and analogous numbers for other datasets as shown in Table 1).</td>
                        </tr>
                        <tr>
                            <td><strong>factors_affecting_accuracy</strong></td>
                            <td>Prompt design (zero-shot vs attribute-augmented), lack of exemplar-based steering, temperature/default sampling, and the absence of population-level persona mixtures.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_for_factors</strong></td>
                            <td>Comparison of baseline GPT-4-based methods against MoP shows MoP's exemplar+persona mixture substantially improves embedding alignment/diversity metrics, implying exemplar-driven in-context steering and persona mixtures are effective interventions relative to those baselines.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method</strong></td>
                            <td>Same embedding-space metrics (FID, MAUVE, KL Cosine) computed by the authors when comparing methods (values sourced from released baseline results provided by prior authors).</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Baseline GPT-4 outputs (as used in prior works) exhibit larger FID and lower MAUVE compared to MoP-enhanced outputs, indicating potential lack of population-level diversity/alignment when not using hierarchical persona+exemplar prompting.</td>
                        </tr>
                        <tr>
                            <td><strong>comparisons</strong></td>
                            <td>Used as a baseline reference in Table 1 against MoP and other prompting methods (ZeroGen, AttrPrompt, ProGen, PICLe).</td>
                        </tr>
                        <tr>
                            <td><strong>recommendations_or_best_practices</strong></td>
                            <td>The paper's results suggest that augmenting vanilla-generation methods (including strong models like GPT-4) with exemplar-based persona mixtures can improve alignment to target population distributions; incorporate exemplar selection and persona mixtures rather than relying solely on attribute-randomized prompts or zero-shot prompts.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Mixture-of-Personas Language Models for Population Simulation', 'publication_date_yy_mm': '2025-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5701.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e5701.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being used as text-based simulators in specific scientific subdomains, including details on the simulation tasks, reported accuracy, evaluation methods, and any factors identified as affecting the accuracy of these simulations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LLMs-as-population-simulators (literature mentions)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Large Language Models used for human behavior / economic / political simulations (literature mentions)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>The paper cites and positions its work within prior uses of LLMs as simulators in social science (human behavior simulation), economics (simulated economic agents), and political science (analyzing electoral dynamics), indicating a growing trend of LLMs used as text-based simulators in these scientific subdomains.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>various LLMs (cited works)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Referenced works (e.g., Aher et al. 2023; Argyle et al. 2023; Horton 2023; Bisbee et al. 2023) apply LLMs to simulate human subjects, economic agents, and political opinion/text; specifics of architectures vary by cited study.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>scientific_subdomain</strong></td>
                            <td>Social science (human-subject simulation), Economics (economic agent modeling), Political science (electoral/political trend simulation)</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_task</strong></td>
                            <td>Simulate multiple humans for experimental replication, model economic agent decision-making, analyze political trends / generate synthetic survey/text data for study/scaling experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>accuracy_metric</strong></td>
                            <td>Not specified in detail in this paper; cited works use tasks and evaluations appropriate to their field (e.g., replication of human-subject study outcomes, statistical comparisons), but this paper does not enumerate their exact metrics.</td>
                        </tr>
                        <tr>
                            <td><strong>reported_accuracy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>factors_affecting_accuracy</strong></td>
                            <td>Paper highlights general factors from literature: LLM priors may not align with target populations, steering/steerability challenges, diversity collapse, and biases; motivating MoP design.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_for_factors</strong></td>
                            <td>High-level citations to prior work showing limitations in steerability and demographic alignment (e.g., Santurkar et al. 2023; Yu et al. 2024b) and motivating exemplar/persona mixture approach.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method</strong></td>
                            <td>This paper does not run those domain-specific experiments itself; it references those subdomains to motivate the population-simulation problem.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Cited literature documents LLMs' discrepancies across demographic groups, reduced diversity, biases, and insufficiency of simple prompt/persona strategies—motivating the MoP solution.</td>
                        </tr>
                        <tr>
                            <td><strong>comparisons</strong></td>
                            <td>Provided as contextual motivation rather than direct empirical comparison; MoP is proposed to address problems reported in these prior subdomain studies.</td>
                        </tr>
                        <tr>
                            <td><strong>recommendations_or_best_practices</strong></td>
                            <td>Paper recommends persona+exemplar hierarchical mixtures and in-context exemplar weighting as methods to better align LLM outputs with target population distributions in social science/economic/political simulation contexts.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Mixture-of-Personas Language Models for Population Simulation', 'publication_date_yy_mm': '2025-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Using large language models to simulate multiple humans and replicate human subject studies <em>(Rating: 2)</em></li>
                <li>Out of one, many: Using language models to simulate human samples <em>(Rating: 2)</em></li>
                <li>Large language models as simulated economic agents: What can we learn from homo silicus? <em>(Rating: 2)</em></li>
                <li>Synthetic replacements for human survey data? the perils of large language models <em>(Rating: 1)</em></li>
                <li>Whose opinions do language models reflect? <em>(Rating: 2)</em></li>
                <li>Large language model as attributed training data generator: A tale of diversity and bias <em>(Rating: 2)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-5701",
    "paper_id": "paper-0f25d552eefd9649d080e2eda27482f7ba20a126",
    "extraction_schema_id": "extraction-schema-114",
    "extracted_data": [
        {
            "name_short": "MoP-Llama3-8B",
            "name_full": "Mixture-of-Personas prompting with Llama3-8B-Instruct",
            "brief_description": "This paper's primary experimental setup: an exemplar-based probabilistic prompting method (Mixture of Personas, MoP) applied to an instruction-tuned Llama3-8B model to simulate population-level text (news, movie/restaurant reviews) and to generate synthetic datasets for downstream classification.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "Llama3-8B-Instruct",
            "model_description": "Instruction-finetuned member of the Llama 3 family used as the fixed base LLM for all forward passes; kept frozen during MoP training while only gating networks are trained. Paper references Dubey et al. (2024) for Llama3.",
            "model_size": "8B",
            "scientific_subdomain": "Social science / behavioral simulation; NLP dataset synthesis (news topic classification, sentiment analysis)",
            "simulation_task": "Text-based population simulation: generate news blurbs (AGNews) and movie/restaurant reviews (SST-2, IMDB, Yelp) representative of target population subgroups; create synthetic labeled datasets for downstream topic/sentiment classification.",
            "accuracy_metric": "Embedding-space alignment and diversity metrics: FID (Fréchet Inception Distance), MAUVE, KL Cosine (KL divergence of pairwise cosine-similarity histograms); downstream classifier F1 on golden test set.",
            "reported_accuracy": "Table 1 (MoP using Llama3-8B-Instruct): AGNews FID=0.951, MAUVE=0.871, KL Cosine=0.069; Yelp FID=0.948, MAUVE=0.826, KL Cosine=0.067; SST-2 FID=1.131, MAUVE=0.855, KL Cosine=0.319; IMDB FID=0.771, MAUVE=0.865, KL Cosine=0.039. Downstream classifier F1s (Table 2) trained on MoP synthetic data: AGNews F1=0.871, Yelp F1=0.867, SST-2 F1=0.845, IMDB F1=0.865. Averaged improvement over strongest baseline: ~58.8% FID improvement and ~27.9% MAUVE improvement.",
            "factors_affecting_accuracy": "Persona prompting quality and persona synthesis, use of exemplars (in-context examples), number of personas, number of exemplars, per-persona temperature (learnable τ), sparse gating/top-M selection, base model alignment to target distribution (pretrained biases), and whether the persona-exemplar pairings are learned or random.",
            "evidence_for_factors": "Ablation studies (Table 4) show removing exemplars drastically harms alignment/diversity (w/o exemplars: FID 3.694 vs MoP 0.951; MAUVE 0.552 vs 0.871), removing persona synthesizer degrades but less so (FID 1.674), and random personas degrade MAUVE/FID. Varying counts (Figure 4) shows more personas/exemplars generally help, with exemplar performance saturating around 2000. Per-persona learnable temperature τ is used and discussed as controlling diversity. Transfer experiments (Table 3) show base model choice affects metrics.",
            "evaluation_method": "Automated embedding-space evaluation: embed generated and golden texts with all-mpnet-base-v2, compute FID, MAUVE (500 clusters, scaling=1), and KL Cosine (histogram KL of pairwise cosine similarities). For downstream utility, train a DistilBERT classifier on 5,000 generated samples and evaluate F1 on the held-out golden test set. Generation volume: 5,000 synthetic responses per method; exemplar masking used during training to avoid predicting the same example.",
            "limitations_or_failure_cases": "Requires access to LLM output logits to train gating networks (limiting applicability to closed-source models without logit access); risk of biases from persona prompt construction; exemplars drawn from the same dataset risk overfitting without masking; performance depends on base-model prior alignment (e.g., Llama3 already closely aligned to Yelp, leaving less room for improvement).",
            "comparisons": "Compared against ZeroGen, AttrPrompt, ProGen, and PICLe (same Llama3 base). MoP substantially outperforms baselines on alignment/diversity metrics (Table 1). Also transferred MoP gating prompts to Gemma2-9B and Mistral-7B for cross-model comparison (Table 3).",
            "recommendations_or_best_practices": "Include exemplar-based prompting (exemplars are crucial); synthesize or curate personas (persona synthesizer improves alignment); use sparse top-M gating for scalability; learn per-persona temperature τ to control diversity; mask target examples during training to avoid trivial memorization; scale the number of personas and exemplars up to the point of saturation (≈2000 exemplars).",
            "uuid": "e5701.0",
            "source_info": {
                "paper_title": "Mixture-of-Personas Language Models for Population Simulation",
                "publication_date_yy_mm": "2025-04"
            }
        },
        {
            "name_short": "MoP-&gt;Gemma2-9B",
            "name_full": "Mixture-of-Personas transferred to Gemma2-9B-Instruct",
            "brief_description": "Transfer evaluation: the MoP gating networks trained with Llama3-8B prompts were applied (plug-and-play) to Gemma2-9B-Instruct as the base LLM to simulate AGNews, showing that MoP transfers and can even improve alignment.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "Gemma2-9B-Instruct",
            "model_description": "Instruction-finetuned Gemma2 model (referenced Team et al. 2024); used as an alternative base LLM receiving the same persona+exemplar prompts and sampling configuration.",
            "model_size": "9B",
            "scientific_subdomain": "NLP dataset synthesis / population text simulation (news topic generation)",
            "simulation_task": "Generate AGNews-style news blurbs under MoP prompting and gating learned on Llama3-8B.",
            "accuracy_metric": "FID, MAUVE, KL Cosine (embedding-based metrics using all-mpnet-base-v2).",
            "reported_accuracy": "Transfer results (Table 3): Gemma2-9B: FID=0.492, MAUVE=0.957, KL Cosine=0.006 (improves over the MoP-Llama3-8B baseline).",
            "factors_affecting_accuracy": "Base model architecture and pretraining/instruction-tuning differences (Gemma2's priors), compatibility of gating prompts with the new model, and sampling settings; demonstrates that transfer can improve or degrade performance depending on base model.",
            "evidence_for_factors": "Direct transfer experiment (Table 3) shows substantial improvement in embedding metrics when swapping Llama3-8B for Gemma2-9B while keeping MoP gating fixed, indicating base-model priors materially affect simulation alignment.",
            "evaluation_method": "Same embedding-space metrics (FID, MAUVE, KL Cosine) computed against the golden AGNews test set; using the pre-trained encoder all-mpnet-base-v2.",
            "limitations_or_failure_cases": "No retraining of gating networks performed; success depends on instruction-tuned behavior of the target base model and logit compatibility; paper notes MoP needs logit access to train, which may be unavailable for closed-source models.",
            "comparisons": "Compared directly to MoP-Llama3-8B and MoP-Mistral-7B in Table 3; Gemma2-9B produced best metrics on AGNews among the three.",
            "recommendations_or_best_practices": "MoP gating learned on one model can often be applied to other instruction-tuned models, and practitioners should test multiple base models since some models (here Gemma2-9B) can yield better alignment.",
            "uuid": "e5701.1",
            "source_info": {
                "paper_title": "Mixture-of-Personas Language Models for Population Simulation",
                "publication_date_yy_mm": "2025-04"
            }
        },
        {
            "name_short": "MoP-&gt;Mistral-7B",
            "name_full": "Mixture-of-Personas transferred to Mistral-v0.3-7B-Instruct",
            "brief_description": "Transfer evaluation of the MoP gating network applied to Mistral-7B-Instruct as an alternative base model for AGNews generation; shows comparable performance to the original Llama3-8B base in this task.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "Mistral-v0.3-7B-Instruct",
            "model_description": "Instruction-finetuned Mistral-7B variant (referenced Jiang et al. 2023); used as a base LLM to sample outputs under fixed MoP prompts/gating.",
            "model_size": "7B",
            "scientific_subdomain": "NLP dataset synthesis / population text simulation (news topic generation)",
            "simulation_task": "Generate AGNews-style news blurbs under MoP prompting and gating learned on Llama3-8B.",
            "accuracy_metric": "FID, MAUVE, KL Cosine (embedding-space metrics).",
            "reported_accuracy": "Transfer results (Table 3): Mistral-7B: FID=0.923, MAUVE=0.869, KL Cosine=0.081 (close to MoP-Llama3-8B performance).",
            "factors_affecting_accuracy": "Base model priors and instruction-tuning differences; sampling and temperature settings; compatibility with MoP exemplar/persona prompts.",
            "evidence_for_factors": "Transfer table (Table 3) shows Mistral-7B yields metrics similar to Llama3-8B but behind Gemma2-9B, indicating model-specific priors influence alignment.",
            "evaluation_method": "Same embedding-space metrics (FID, MAUVE, KL Cosine) against AGNews golden test set using all-mpnet-base-v2 embeddings.",
            "limitations_or_failure_cases": "As with other transfers, no retraining of gating networks; performance depends on how closely the model's generation prior matches the target distribution.",
            "comparisons": "Directly compared with MoP-Llama3-8B and MoP-&gt;Gemma2-9B (Table 3).",
            "recommendations_or_best_practices": "When deploying MoP, evaluate multiple candidate base models — smaller models (7B) can be competitive but priors vary; use model selection based on embedding-alignment metrics.",
            "uuid": "e5701.2",
            "source_info": {
                "paper_title": "Mixture-of-Personas Language Models for Population Simulation",
                "publication_date_yy_mm": "2025-04"
            }
        },
        {
            "name_short": "GPT-4 (baselines)",
            "name_full": "GPT-4 (used by baseline methods ZeroGen and AttrPrompt in referenced released datasets)",
            "brief_description": "GPT-4 outputs (from prior authors' released datasets) appear in baseline comparisons (ZeroGen and AttrPrompt variants using GPT-4) for synthetic data generation and provide reference metrics in Table 1.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "GPT-4",
            "model_description": "Large instruction-capable model from OpenAI; paper uses previously released datasets/metrics from ZeroGen and AttrPrompt experiments run with GPT-4 (authors' released results), not new GPT-4 runs performed within this work.",
            "model_size": null,
            "scientific_subdomain": "NLP dataset synthesis / population text simulation (news and reviews)",
            "simulation_task": "Zero-shot or attribute-conditioned synthetic text generation used as baselines for comparison (news blurbs, reviews).",
            "accuracy_metric": "FID, MAUVE, KL Cosine (embedding-based metrics reported from released baseline datasets shown in Table 1).",
            "reported_accuracy": "Baseline entries labeled with * (from authors' released datasets): ZeroGen (GPT4)* — AGNews FID=3.248 MAUVE=0.553 KL=0.506; AttrPrompt (GPT4)* — AGNews FID=2.992 MAUVE=0.585 KL=0.399 (and analogous numbers for other datasets as shown in Table 1).",
            "factors_affecting_accuracy": "Prompt design (zero-shot vs attribute-augmented), lack of exemplar-based steering, temperature/default sampling, and the absence of population-level persona mixtures.",
            "evidence_for_factors": "Comparison of baseline GPT-4-based methods against MoP shows MoP's exemplar+persona mixture substantially improves embedding alignment/diversity metrics, implying exemplar-driven in-context steering and persona mixtures are effective interventions relative to those baselines.",
            "evaluation_method": "Same embedding-space metrics (FID, MAUVE, KL Cosine) computed by the authors when comparing methods (values sourced from released baseline results provided by prior authors).",
            "limitations_or_failure_cases": "Baseline GPT-4 outputs (as used in prior works) exhibit larger FID and lower MAUVE compared to MoP-enhanced outputs, indicating potential lack of population-level diversity/alignment when not using hierarchical persona+exemplar prompting.",
            "comparisons": "Used as a baseline reference in Table 1 against MoP and other prompting methods (ZeroGen, AttrPrompt, ProGen, PICLe).",
            "recommendations_or_best_practices": "The paper's results suggest that augmenting vanilla-generation methods (including strong models like GPT-4) with exemplar-based persona mixtures can improve alignment to target population distributions; incorporate exemplar selection and persona mixtures rather than relying solely on attribute-randomized prompts or zero-shot prompts.",
            "uuid": "e5701.3",
            "source_info": {
                "paper_title": "Mixture-of-Personas Language Models for Population Simulation",
                "publication_date_yy_mm": "2025-04"
            }
        },
        {
            "name_short": "LLMs-as-population-simulators (literature mentions)",
            "name_full": "Large Language Models used for human behavior / economic / political simulations (literature mentions)",
            "brief_description": "The paper cites and positions its work within prior uses of LLMs as simulators in social science (human behavior simulation), economics (simulated economic agents), and political science (analyzing electoral dynamics), indicating a growing trend of LLMs used as text-based simulators in these scientific subdomains.",
            "citation_title": "",
            "mention_or_use": "mention",
            "model_name": "various LLMs (cited works)",
            "model_description": "Referenced works (e.g., Aher et al. 2023; Argyle et al. 2023; Horton 2023; Bisbee et al. 2023) apply LLMs to simulate human subjects, economic agents, and political opinion/text; specifics of architectures vary by cited study.",
            "model_size": null,
            "scientific_subdomain": "Social science (human-subject simulation), Economics (economic agent modeling), Political science (electoral/political trend simulation)",
            "simulation_task": "Simulate multiple humans for experimental replication, model economic agent decision-making, analyze political trends / generate synthetic survey/text data for study/scaling experiments.",
            "accuracy_metric": "Not specified in detail in this paper; cited works use tasks and evaluations appropriate to their field (e.g., replication of human-subject study outcomes, statistical comparisons), but this paper does not enumerate their exact metrics.",
            "reported_accuracy": null,
            "factors_affecting_accuracy": "Paper highlights general factors from literature: LLM priors may not align with target populations, steering/steerability challenges, diversity collapse, and biases; motivating MoP design.",
            "evidence_for_factors": "High-level citations to prior work showing limitations in steerability and demographic alignment (e.g., Santurkar et al. 2023; Yu et al. 2024b) and motivating exemplar/persona mixture approach.",
            "evaluation_method": "This paper does not run those domain-specific experiments itself; it references those subdomains to motivate the population-simulation problem.",
            "limitations_or_failure_cases": "Cited literature documents LLMs' discrepancies across demographic groups, reduced diversity, biases, and insufficiency of simple prompt/persona strategies—motivating the MoP solution.",
            "comparisons": "Provided as contextual motivation rather than direct empirical comparison; MoP is proposed to address problems reported in these prior subdomain studies.",
            "recommendations_or_best_practices": "Paper recommends persona+exemplar hierarchical mixtures and in-context exemplar weighting as methods to better align LLM outputs with target population distributions in social science/economic/political simulation contexts.",
            "uuid": "e5701.4",
            "source_info": {
                "paper_title": "Mixture-of-Personas Language Models for Population Simulation",
                "publication_date_yy_mm": "2025-04"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Using large language models to simulate multiple humans and replicate human subject studies",
            "rating": 2
        },
        {
            "paper_title": "Out of one, many: Using language models to simulate human samples",
            "rating": 2
        },
        {
            "paper_title": "Large language models as simulated economic agents: What can we learn from homo silicus?",
            "rating": 2
        },
        {
            "paper_title": "Synthetic replacements for human survey data? the perils of large language models",
            "rating": 1
        },
        {
            "paper_title": "Whose opinions do language models reflect?",
            "rating": 2
        },
        {
            "paper_title": "Large language model as attributed training data generator: A tale of diversity and bias",
            "rating": 2
        }
    ],
    "cost": 0.016097,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>Mixture-of-Personas Language Models for Population Simulation</h1>
<p>Ngoc Bui ${ }^{1}$, Hieu Trung Nguyen ${ }^{2}$, Shantanu Kumar ${ }^{1}$, Julian Theodore ${ }^{1}$, Weikang Qiu ${ }^{1}$, Viet Anh Nguyen ${ }^{2}$, Rex Ying ${ }^{1}$,<br>${ }^{1}$ Yale University, ${ }^{2}$ The Chinese University of Hong Kong,<br>{ngoc.bui, shantanu.kumar, jt2386, weikang.qiu, rex.ying}@yale.edu, {thnguyen, nguyen}@se.cuhk.edu.hk</p>
<h4>Abstract</h4>
<p>Advances in Large Language Models (LLMs) paved the way for their emerging applications in various domains, such as human behavior simulations, where LLMs could augment human-generated data in social science research and machine learning model training. However, pretrained LLMs often fail to capture the behavioral diversity of target populations due to the inherent variability across individuals and groups. To address this, we propose Mixture of Personas (MoP), a probabilistic prompting method that aligns the LLM responses with the target population. MoP is a contextual mixture model, where each component is an LM agent characterized by a persona and an exemplar representing subpopulation behaviors. The persona and exemplar are randomly chosen according to the learned mixing weights to elicit diverse LLM responses during simulation. MoP is flexible, requires no model finetuning, and is transferable across base models. Experiments for synthetic data generation show that MoP outperforms competing methods in alignment and diversity metrics.</p>
<h2>1 Introduction</h2>
<p>The impressive capability of Large Language Models (LLMs) to generate human-like output has enabled their application across various domains, where their responses can complement or substitute human-generated data, providing a scalable approach to address data limitations (Argyle et al., 2023). Prominent examples include simulating human behaviors in social science (Aher et al., 2023; Argyle et al., 2023), modeling economic agents and decision-making in economics (Horton, 2023), analyzing political trends and electoral dynamics in political science (Bisbee et al., 2023), or generating synthetic training data (Li et al., 2023b; Törnberg, 2023). Natural human responses in those applications often reflect diverse behaviors or preferences
<img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Figure 1: Sampling from foundational LLM agents frequently yields repetitive and generic responses. Meanwhile, prompting with personas can create more tailored, specific responses. The highlighted words in the figure correspond to the prompted personas.
of different personas shaped by demographic, cultural, and societal variations of the target population (Zhao et al., 2023). Modeling the distribution of those behaviors is crucial for generating realistic and contextually relevant outputs (Sorensen et al., 2024). A common approach to achieving tailored responses is to prompt LLMs with a persona that simulates a specific group's behavior, language, and preferences; see Figure 1. However, recent studies show that LLM's responses often lack diversity and exhibit significant biases (Yu et al., 2024b), and this downside persists even when LLMs are prompted with a persona (Santurkar et al., 2023).</p>
<p>Some efforts has been made toward improving the steerability LLMs, enabling them to produce outputs aligned with specific user intentions or personas. Approaches addressing steerability generally fall into two main categories: prompt engineering (Hwang et al., 2023; Chen et al., 2024) and fine-tuning using personalized datasets (Li et al., 2023a; Sun et al., 2024; Zhao et al., 2023; Choi and Li, 2024). Although these methods aim to capture the behaviors, preferences, and communication styles of particular user groups, both techniques encounter distinct challenges. Prompt engineering tailored for each user is both intricate</p>
<p>and resource-intensive. Meanwhile, learning-based methods require access to personal data, which is often scarce or expensive. The reliance on personal data also raises privacy concerns, restricting the practical applicability of these approaches.</p>
<p>Furthermore, diversity sampling remains a notable challenge in LLMs, especially when simulating responses representative of diverse populations. Current methods <em>Choi and Li (2024)</em> typically rely on a fixed, optimal selection of few-shot examples reused across multiple downstream tasks, complemented primarily by temperature scaling to enhance response diversity. However, relying solely on temperature scaling can be inadequate for generating semantically diverse outputs, frequently resulting in a trade-off between quality and diversity or causing outputs to collapse into semantically similar responses <em>Chang et al. (2023)</em>.
Proposed work. We address the steerability problem in LLMs, focusing on aligning model responses with the characteristics of a target population. To achieve this, we propose the Mixture of Persona (MoP), a probabilistic prompting framework that leverages persona descriptions and in-context exemplars to steer responses. MoP functions as a contextual mixture model comprising multiple LLM agents, each characterized by a persona prompt that is either user-defined or synthesized from observed target population responses. During response generation, personas are probabilistically selected based on mixing weights, enabling the model to produce customized and contextually relevant outputs.</p>
<p>Since the naive MoP approach described above may still be susceptible to biases and limited response diversity, we enhance it by incorporating in-context examples to better align LLM responses with population characteristics. These in-context exemplars are drawn anonymously from a representative pool of the target population, guided by learnable weights. Importantly, our method does not require direct associations between individual personas and specific examples, thus minimizing reliance on personal data. Instead, each exemplar’s influence on a persona is controlled through a secondary set of mixing weights, forming a two-level hierarchical mixture model. The first level manages persona selection, while the second level determines exemplar weighting. This hierarchical structure enables MoP to effectively represent the diversity and complexity inherent in population-level behaviors, simultaneously mitigating biases in LLM-generated responses.</p>
<p>We conduct extensive experiments to evaluate the effectiveness of MoP against existing prompting methods. Specifically, our experiments span two main scenarios: (1) simulating human-like opinions in tasks such as generating movie and restaurant reviews as well as news articles, and (2) creating synthetic data for downstream classification tasks. The results demonstrate that MoP significantly enhances alignment with target population responses, achieving a 58% improvement in FID scores and a 28% increase in MAUVE scores compared to the strongest baseline. Additionally, MoP generates more diverse responses, effectively capturing nuanced variations in population-level behavior without compromising response quality. We further demonstrate the transferability of MoP: a model trained on Llama3-8B-Instruct can directly generalize to other base models such as Gemma-9B-Instruct and Mistral-7B-Instruct in a plug-and-play fashion, eliminating the need for retraining.</p>
<h2>2 Problem Setting</h2>
<p>We consider the problem of simulating human behaviors or preferences at the population level using prior knowledge from pre-trained LLMs <em>Sorensen et al. (2024)</em>. Let $\mathcal{P}$ be a population composed of $K$ groups of interest. Each group $k \in{1, \ldots, K}$ can be characterized by a persona $g_{k}$ that reflects the traits and motivations driving the behaviors of individuals within that group. Let $\mathcal{D}=\left{\left(x_{i}, y_{i}\right)\right}<em i="i">{N}$ be a recorded data set from the population of interest $\mathcal{P}$. For synthetic data generation tasks such as movie review generation, $x</em>$ with different preferences.}$ could be an input context (e.g., movie title), and $y_{i}$ could be a human response (e.g., a movie review). Note that a given input $x$ could be associated with multiple, diverse responses $y$ produced by different individuals in the population $\mathcal{P</p>
<p>In real-world applications, the persona description $\left{g_{k}\right}<em k="k">{K}$ can be pre-defined by the users according to the task at hand or automatically synthesized from the record set $\mathcal{D}$. We will consider both variants in the experiments. It is worth noting further that, different from <em>Zhao et al. (2023)</em> and <em>Choi and Li (2024)</em>, we do not require access to preference or personal data generated by persona $g</em>\right)$ pairs); therefore, our setting could be considered as an 'unsupervised' setting of the steerability problem of LLMs.
Notations. In what follows, we use $p_{L M}(y \mid x)$ to}$ (e.g., $g_{k}-\left(x_{i}, y_{i</p>
<p><img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Figure 2: The generation pipeline for the Exemplar-based Mixture of Personas (MoP) operates as follows: Given a movie review <em>x</em>, MoP first samples a persona based on the learnable mixing weight <em>π</em>. Next, MoP selects an exemplar randomly from the observation pool according to the mixing weight Ω. The selected persona and exemplar are then concatenated with the input context to create a personalized prompt used to sample from a base LLM agent. The dashed block indicates the process of persona synthesis.</p>
<p>denote the probability density of the pre-trained LLM for an output <em>y</em> given the input <em>x</em> as a prompt and <em>pLM(y|g<sub>k</sub>, x)</em> to denote the probability given the concatenated input [<em>g<sub>k</sub>, x</em>], in that order.</p>
<h2>3 Methodology</h2>
<p>In this section, we propose the <em>Mixture of Personas</em> (MoP), a contextual mixture model of LM agents designed to simulate the diverse preferences of individuals within a target population P. In MoP, each agent is characterized by a persona prompt that encapsulates a specific subgroup's aggregated behaviors or preferences. Furthermore, the agent's responses are guided by an exemplar, randomly selected from the anonymous data set D based on a learnable mixing weight, making MoP a two-level hierarchical mixture of LLM agents. The overall pipeline is depicted in Figure 2. For clarity, we assume that the persona descriptions {<em>g<sub>k</sub></em>}<sub>K</sub> are pre-defined, postponing the discussion of persona synthesis to the end of this section.</p>
<h3>3.1 Mixture of Personas</h3>
<p>We propose modeling the population's responses as a mixture of responses generated by <em>K</em> constituent personas. Specifically, given an input context <em>x</em>, the probability of receiving a response <em>y</em> from the population P can be decomposed into group-based probabilities as</p>
<p>$$p(y|x) = \sum_{k=1}^{K} \pi_{k} p_{LM}(y|g_{k},x) \text{ with } \sum_{k} \pi_{k} = 1,\tag{1}$$</p>
<p>where <em>g<sub>k</sub></em> is a persona prompt representative for group characteristics <em>k</em> and <em>π<sub>k</sub></em> ∈ [0, 1] is the mixing weight specifying the group's propensity. Since population members may contribute differently to different input contexts<sup>1</sup>, we parametrize these mixing weights using a simple gating network that is conditionally dependent on the input context <em>x</em>, following Jordan and Jacobs (1994).</p>
<p>Specifically, we leverage a pre-trained sentence encoder to capture the semantics of the input context <em>x</em> and persona prompt <em>g<sub>k</sub></em></p>
<p>$$\mathbf{x} = \mathbf{W}_{x}h(x), \quad \mathbf{g}_{k} = \mathbf{W}_{g}h(g_{k}).\tag{2}$$</p>
<p>Here, <em>h</em>(·) ∈ ℝ<sup>d</sup><sup>r</sup> is a pre-trained sentence encoder and <strong>W</strong><sub><em>x</em></sub>, <strong>W</strong><sub><em>g</em></sub> ∈ ℝ<sup>d<sup>r</sup>×d</sup> are learnable parameters of the gating network. We now define the <em>persona gate</em> π based on the similarities between the input context and the persona prompts</p>
<p>$$\pi = \text{softmax}(\mathbf{x}^{\top}\mathbf{g}_{1}, \dots, \mathbf{x}^{\top}\mathbf{g}_{K}) \in [0, 1]^{K},\tag{3}$$</p>
<p>where the softmax normalizes the vector of <em>K</em> logits into probability mixing weights that determines the probability of selecting persona <em>g<sub>k</sub></em> given the input context <em>x</em>.</p>
<p>This persona prompt allows us to leverage abundant prior knowledge of LLMs to steer its responses toward the behaviors of the group <em>g<sub>k</sub></em> (Wang et al., 2023; Chen et al., 2024; Tseng et al., 2024). However, this direct prompting technique alone is often insufficient, as LLMs are generally pre-trained on massive, global datasets, which might not be aligned with our targeted group (Zhao et al., 2023). Additionally, it is known that relying solely on temperature scaling for LLM decoding may</p>
<p><sup>1</sup>For instance, in a movie review scenario, an art house or indie film may receive more reviews from critics than casual viewers, whereas an action movie might attract more reviews from casual viewers than critics.</p>
<p>not effectively generate semantically diverse responses (Chang et al., 2023). As a result, simulated responses tend to collapse into similar outputs. In the next section, we propose a method to address the above problems to elicit diverse responses from the pre-trained LLMs and align them to the group's preference using exemplars in the record set $\mathcal{D}$.</p>
<h3>3.2 Exemplar-based Mixture of Personas</h3>
<p>To address the aforementioned problem, we propose to combine the persona prompt with an exemplar, acting as historical data to guide the LLM agent and eliciting more diverse responses. Specifically, given an anonymous dataset $\mathcal{D}=$ $\left{\left(x_{i}, y_{i}\right)\right}<em L="L" M="M">{N}$, we model the distribution $p</em>\right)$ using another layer of the mixture model that aggregates the responses of the LLM agent $k$, augmented with varying exemplars
$p(y \mid x, \mathcal{D})=\sum_{k=1}^{K} \pi_{k} \sum_{j=1}^{N} \Omega_{k j} p_{L M}^{\gamma_{k}}\left(y \mid g_{k}, x_{j}, y_{j}, x\right)$,
where $\sum_{k} \pi=1$ and $\sum_{j} \Omega_{k j}=1 \forall k$.
Above, $\Omega_{k j}$ denotes the importance weight of the exemplar $\left(x_{j}, y_{j}\right)$ to the subpopulation $k$ and $p\left(y \mid g_{k}, x_{j}, y_{j}, x\right)$ represents the probability that an individual in group $k$ will respond to the context $x$ with $y$, given that they previously responded to context $x_{j}$ with $y_{j}$.}\left(\cdot \mid g_{k</p>
<p>Similar to the persona gate, we parameterize exemplar selection with a simple exemplar gate $\Omega$, which selects an exemplar based on the input context $x$ and the chosen persona $g_{k}$. Specifically, we define the exemplar gate $\Omega_{k}$ : corresponding to persona $k$ as follows:
$\Omega_{k:}=\operatorname{softmax}\left(\mathbf{x}^{\top} \mathbf{e}<em k="k">{1}+\mathbf{g}</em>}^{\top} \mathbf{e<em N="N">{1}, \ldots, \mathbf{x}^{\top} \mathbf{e}</em>}+\mathbf{g<em N="N">{k}^{\top} \mathbf{e}</em>\right)$,
where $\mathbf{e}<em e="e">{i}=\mathbf{W}</em>} h\left(e_{i}\right)$ is the embedding of the exemplar $i$. The input context $\mathbf{x}$ and persona prompt $\mathbf{g<em k="k">{k}$ are computed as defined in Eq. equation (2). Here, the utility of an exemplar explicitly depends on both input context $x$ and the persona prompt $g</em>$ for each persona to normalize LLM output logits, thereby controlling the diversity of responses for each persona. This parameter will be the temperature hyperparameter for the LLM's sampling algorithm during simulation. In summary, MoP is an instance of the two-level hierarchical mixture-of-experts model (Jordan and Jacobs, 1994), where each expert is an LLM agent prompted with a persona and an exemplar.}$. The softmax function is applied along each column of $\Omega$ to ensure that the mixing weights are summed to one, i.e., $\sum_{j} \Omega_{k j}=1$ for all $j$. Additionally, we add a learnable temperature parameter $\tau_{k</p>
<p>This prompting pipeline can be viewed as an in-context learning method for augmenting LLM instructions, a strategy widely applied across various LLM tasks (Brown, 2020). However, our method introduces two key differences from existing approaches. First, we operate in an unsupervised setting, where no explicit personal data pairs $\left{g_{k},\left(x_{i}, y_{i}\right)\right}$ are required. Instead, the relevance of exemplars to the persona $g_{k}$ is learned and controlled by the mixing weight $\Omega$. Second, while existing methods typically select a fixed, optimal set of few-shot examples to be reused across different instances in downstream tasks (Choi and Li, 2024), our approach randomly selects exemplars based on the weight $\Omega$, which enhances the diversity of simulated responses.</p>
<h3>3.3 Optimizing The Gating Networks</h3>
<p>We optimize the gating network to fit the population observation $\mathcal{D}$ by treating MoP learning as a maximum log-likelihood of the population observations $\mathcal{D}$. Let us denote $\theta$ as the gating network's learnable parameters. The log-likelihood of the observation $\mathcal{D}$ will be computed by
$\log (\theta ; \mathcal{D})=$
$\sum_{i}^{N} \log \left(\sum_{k}^{K} \sum_{j}^{N} \pi_{k} \Omega_{k j} p_{L M}^{\gamma_{k}}\left(y_{i} \mid g_{k}, x_{j}, y_{j}, x_{i}\right)\right)$.
The above computation requires $K \times N$ LLM forward passes to compute the log-likelihood estimate, which is prohibitively expensive, especially when $N$ and $K$ are large. To address this problem, we adopt a sparsely gating mechanism widely used in the mixture-of-experts (MoEs) literature (Shazeer et al., 2017). For any context $x$, we only estimate the log-probability of the pre-trained LLM for top$M$ pairs of persona and exemplars with the highest probability $\pi_{k} \Omega_{k j}$. This allows our training to scale up to thousands of exemplars and personas. Further, notice that we use the same observation set $\mathcal{D}$ as the exemplars for steering LLM output towards observations in $\mathcal{D}$. This can lead to over-optimization of the mixture model since, when estimating the loglikelihood $p\left(y_{i} \mid x_{i}, \mathcal{D}\right)$, the observation $\left(x_{i}, y_{i}\right)$ is already seen in the dataset $\mathcal{D}$ (Mallapragada et al.,</p>
<p>2010). To address this problem, we randomly mask the target example during training to avoid using the same exemplar to predict itself.</p>
<p>It is worth noting further that we exclusively train the gating network while keeping the pretrained LLM entirely fixed, requiring access only to the LLM’s output logits. As a result, our gating mechanism is transferable and can be applied to other pre-trained LLMs in a plug-and-play fashion without the need for retraining.</p>
<h3>3.4 Population Simulation</h3>
<p>Similar to other mixture models, our model admits an equivalent representation using the following generative process</p>
<p>$c|x$ $\sim \operatorname{Cat}(\pi) \quad \forall c \in[1, K],$
$h \mid c, x$ $\sim \operatorname{Cat}\left(\Omega_{k:}\right) \quad \forall h \in[1, N],$
$y \mid h, c, x$ $\sim p_{L M}^{\tau_{k}}\left(y \mid g_{c}, y_{h}, x\right)$,
where $c$ and $h$ are latent variables indicating the selected group and exemplar for the simulated records. To simulate responses from the population, we first sample $c$ and $h$ sequentially from two categorical distributions and then sample responses from the LLM agent using the corresponding persona and exemplar. This sampling process is memory and computation efficient because it does not incur an overhead by switching between different personalized models like existing finetuning approaches (Yu et al., 2024a).</p>
<h3>3.5 Persona Synthesis</h3>
<p>Although persona descriptions $\left{g_{k}\right}_{K}$ can be predefined by users depending on the task at hand, there are scenarios where it is preferable to synthesize personas directly from the given dataset $\mathcal{D}$. Given the assumption that no personal records are available, we utilize a pre-trained sentence encoder and LLM to cluster and generate the persona descriptions. Specifically, we first encode all records into a shared embedding space using the 'all-mpnet-basev2‘ sentence encoder and then apply the $K$-means algorithm to split the records set into $K$ clusters. For each cluster, we prompt a pre-trained LLM to summarize the records within the cluster, producing a persona description for the group. Details of the prompt used to generate persona descriptions can be found in Appendix D.</p>
<h2>4 Experiments</h2>
<p>In this section, we conduct extensive experiments to investigate the effectiveness of the proposed methods, aiming to answer the following three research questions:</p>
<p>RQ1: Can MoP steer the output of LLMs towards the population of interest?</p>
<p>RQ2: Can we utilize the MoP prompting technique to generate high-quality data for training ML models on task-specific applications?</p>
<p>RQ3: Can MoP be transferable to different pretrained LLMs in a plug-and-play manner?</p>
<p>To answer the above research questions, we conduct two main experiments: Steerability: We generate news articles and movie/restaurant reviews to demonstrate that a pre-trained LLM with MoP prompting can simulate the distribution of human-generated content while maintaining its diversity. Synthetic Data for Training ML Models: We show that adapting MoP prompting can create highquality training samples for classification tasks, such as topic or sentiment classification.</p>
<h3>4.1 Setup</h3>
<p>We describe the datasets, baselines, and metrics used throughout the experiment section.
Datasets. We employ four datasets that are commonly used in dataset generation literature (Yu et al., 2024b), including AGNews (Zhang et al., 2015), Yelp Reviews (Zhang et al., 2015), SST-2 (Stanford Sentiment Treebank) (Socher et al., 2013), and IMDB Reviews (Maas et al., 2011). AGNews includes news articles from AG News; each article belongs to one of four topics: 'world', 'sports', 'business', and 'technology'. Yelp is a restaurant review dataset while SST-2 and IMDB are movie review datasets; each review has a binary label indicating positive or negative review. Note that we use labels for testing purposes only. Each dataset includes two splits for training and testing. We train MoP on the training dataset and evaluate the synthetic data with the test set. Similar to (Yu et al., 2024b), we call the test set for testing a golden dataset. More details and statistics of the datasets are provided in Appendix B.</p>
<p>Baselines. We compare our method to prompting baselines in dataset generation literature: ZeroGen (Ye et al., 2022b), AttrPrompt (Yu et al.,</p>
<p>Table 1: Alignment and diversity of the generated datasets using our MoP with respect to the golden test set. The $<em>$ symbol indicates datasets obtained directly from the authors’ released datasets </em>Yu et al. (2024b)*.</p>
<p>| Method | AgNews | | | Yelp | | | SST-2 | | | IMDB | | |
| | FID$\downarrow$ | MAUVE$\uparrow$ | KL Cosine $\downarrow$ | FID$\downarrow$ | MAUVE$\uparrow$ | KL Cosine $\downarrow$ | FID$\downarrow$ | MAUVE$\uparrow$ | KL Cosine $\downarrow$ | FID$\downarrow$ | MAUVE$\uparrow$ | KL Cosine $\downarrow$ |
| ZeroGen (GPT4)<em> | 3.248 | 0.553 | 0.506 | 3.427 | 0.517 | 1.828 | 3.525 | 0.559 | 0.911 | 3.737 | 0.518 | 0.200 |
| AttrPrompt (GPT4)</em> | 2.992 | 0.585 | 0.399 | 2.599 | 0.570 | 0.428 | 4.133 | 0.550 | 1.834 | 2.477 | 0.566 | 0.789 |
| ZeroGen | 3.535 | 0.587 | 0.241 | 1.888 | 0.682 | 0.173 | 3.965 | 0.550 | 0.800 | 3.529 | 0.537 | 0.195 |
| PICLe | 2.200 | 0.740 | 0.490 | 1.769 | 0.702 | 0.265 | 3.531 | 0.562 | 3.180 | 2.870 | 0.609 | 1.459 |
| ProGen | 1.980 | 0.767 | 0.103 | 2.975 | 0.586 | 1.332 | 4.736 | 0.615 | 2.023 | 3.305 | 0.612 | 1.045 |
| AttrPrompt | 2.193 | 0.648 | 0.150 | 1.816 | 0.651 | 0.143 | 3.878 | 0.555 | 1.393 | 2.505 | 0.549 | 0.492 |
| MoP | 0.951 | 0.871 | 0.069 | 0.948 | 0.826 | 0.067 | 1.131 | 0.855 | 0.319 | 0.771 | 0.865 | 0.039 |
| Improvement (%) | 51.970 | 13.559 | 33.010 | 46.410 | 17.664 | 53.147 | 67.969 | 39.024 | 60.125 | 68.874 | 41.340 | 80.000 |</p>
<p>Table 2: Performance on downstream classification task using generated datasets to train a sentiment classifier (Yelp, SST-2, and IMDB) or news topic classifier (AgNews). F1 scores are calculated on the golden test set.</p>
<table>
<thead>
<tr>
<th></th>
<th>AgNews</th>
<th>Yelp</th>
<th>SST-2</th>
<th>IMDB</th>
</tr>
</thead>
<tbody>
<tr>
<td>Golden data</td>
<td>0.903</td>
<td>0.896</td>
<td>0.919</td>
<td>0.877</td>
</tr>
<tr>
<td>Zerogen</td>
<td>0.624</td>
<td>0.860</td>
<td>0.766</td>
<td>0.821</td>
</tr>
<tr>
<td>ProGen</td>
<td>0.722</td>
<td>0.843</td>
<td>0.785</td>
<td>0.810</td>
</tr>
<tr>
<td>PICLe</td>
<td>0.759</td>
<td>0.738</td>
<td>0.833</td>
<td>0.815</td>
</tr>
<tr>
<td>AttrPrompt</td>
<td>0.836</td>
<td>0.864</td>
<td>0.838</td>
<td>0.793</td>
</tr>
<tr>
<td>MoP</td>
<td>0.871</td>
<td>0.867</td>
<td>0.845</td>
<td>0.865</td>
</tr>
<tr>
<td>Improvement (%)</td>
<td>4.190</td>
<td>0.347</td>
<td>0.835</td>
<td>5.359</td>
</tr>
</tbody>
</table>
<p>2024b), ProGen <em>Ye et al. (2022a)</em> and steerability literature: PICLe <em>Choi and Li (2024)</em>. Here, ZeroGen is a simple zero-shot, context-dependent prompting method, and AttrPrompt is an attributerandomized prompting method to increase the diversity of synthesized samples. ProGen uses the influence function to weigh and choose synthesized samples as in-context examples. PCILe is an in-context prompting method to address the steerability problem of LLMs, where in-context examples are chosen according to the weight given by the logit difference between the persona-finetuned and the pretrained models. Appendix B provides more details of the baselines. In the following, we refer to MoP as our Exemplar-based Mixture of Personas described in Section 3.2.</p>
<p>Metrics. We follow <em>Pillutla et al. (2021)</em> and <em>Yu et al. (2024b)</em> to evaluate the alignment and diversity of the simulated data in the embedding space. Throughout, we use a pre-trained sentence encoder ‘all-mpnet-base-v2’ from <em>Song et al. (2020)</em> as a text encoder to map generated sentences into a common vector space. We then compute FID (Fréchet Inception Distance) <em>Heusel et al. (2017)</em> and MAUVE <em>Pillutla et al. (2021, 2023)</em> to evaluate the alignment between the simulated responses and the golden dataset. To evaluate the diversity of generated responses compared to the golden dataset, we report the KL-divergence of two histograms constructed by pairwise cosine similarity values of the generated responses and the golden dataset. We call this diversity metric KL Cosine. Note that MAUVE can also capture the diversity alignment to some extent <em>Pillutla et al. (2021)</em>. More details for the metrics are provided in Appendix B.</p>
<p>Implementation Details. For all experiments, we use the same Llama3-8B-Instruct <em>Dubey et al. (2024)</em> as the base model for our method and other baselines. For MoP implementation, we choose the number of personas to be 100 and randomly select 1,000 observations in the training dataset $\mathcal{D}$ as the set of exemplars. We then run $K$-Means and the persona synthesizer to extract 100 persona descriptions. After that, the personas and exemplars will be fixed during training and inference. Throughout, we use ‘all-mpnet-base-v2’ as the sentence encoder $h(\cdot)$ and set the hidden dimension for linear layers in the gating network as 128. During training, we choose top $M=4$ persona-examples pairs for each input context $x$ for LLM forwards. We initially set the temperature $\tau=0.6$ and let it be learnable during the training along with our gating networks. We use the default temperature $\tau=1$ for other baselines as discussed in <em>Yu et al. (2024b)</em> and <em>Ye et al. (2022b)</em>. Other generation hyperparameters of the base LLM model are set by default. For each method, we generate 5,000 synthetic responses and measure the evaluated metrics compared to the golden test set.</p>
<h3>4.2 Steerability (RQ1)</h3>
<p>Table 1 shows that MoP can significantly outperform other baseline prompting methods. Specifically, our method can outperform the best baseline by 58.8% in terms of FID and by 27.9% in terms of MAUVE, averaged over all datasets. This result demonstrates that MoP can effectively steer LLM’s</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>outputs to the target responses of the target population. Besides the improvement in alignment scores, KL Cosine metrics also indicate that our responses are more diverse than other baselines.</p>
<h3>4.3 Synthetic Data Generation (RQ2)</h3>
<p>We explore the two methods for leveraging the trained MoP in Section 4.2 to generate synthetic data tailored to task-specific classification tasks. One is applied for topic classification (Agnews) and the other is applied to sentiment classification tasks (Yelp, SST2, and IMDB).</p>
<p>For Agnews, we label the personas mined by the persona synthesizer and use it as the label for the sample generated by the chosen persona. We classify the persona description into four categories: world reporter, sports reporter, business reporter, and technology reporter. For completeness of the pipeline, we prompt pretrained LLM to do this simple task. The prompt is provided in Appendix D.</p>
<p>For the second method, we augment the input prompt with the following context for generating 2,500 positive reviews (similarly for negative):
"You watched the movie {title} and had positive impression. Please write a review for the movie:"</p>
<p>We train a DistilBERT model <em>Sanh (2019)</em> using 5,000 synthesized samples and evaluate its performance on the golden dataset, reporting the F1score in Table 2. Results show that the synthetic dataset generated by Llama3 with MoP prompting achieves up to a 2.68% improvement over the AttrPrompt baseline. The smaller performance gap observed with the Yelp dataset likely occurs because Llama3-8B-Instruct already aligns closely with the Yelp test distribution. This can be seen by the performance difference between ZeroGen and the golden training data is comparatively smaller than in other datasets, leaving less room for further improvement.</p>
<p>To further illustrate the advantage of MoP prompting, we plot the embedding space provided in Figure 3. The result indicates that our method better matches the diversity of the golden datasets compared to other baselines. Meanwhile, simulated responses of other baselines often collapse or cannot cover the diversity of the true responses.</p>
<h3>4.4 Transferability (RQ3)</h3>
<p>In this section, we evaluate the transferability of MoP to new model architectures. We use MoP trained on AGNews using Llama3-8B-Instruct as in Section 4.2; then, during the simulation, Table 3: Transferability of MoP on AGNews dataset. Note that we use instruction-finetuned version for all language models.</p>
<table>
<thead>
<tr>
<th style="text-align: center;"></th>
<th style="text-align: center;">FID $\downarrow$</th>
<th style="text-align: center;">MAUVE $\uparrow$</th>
<th style="text-align: center;">KL Cosine $\downarrow$</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">MoP Llama3-8B</td>
<td style="text-align: center;">0.951</td>
<td style="text-align: center;">0.871</td>
<td style="text-align: center;">0.069</td>
</tr>
<tr>
<td style="text-align: center;">$\rightarrow$ Gemma2-9B</td>
<td style="text-align: center;">0.492</td>
<td style="text-align: center;">0.957</td>
<td style="text-align: center;">0.006</td>
</tr>
<tr>
<td style="text-align: center;">$\rightarrow$ Mistral-7B</td>
<td style="text-align: center;">0.923</td>
<td style="text-align: center;">0.869</td>
<td style="text-align: center;">0.081</td>
</tr>
</tbody>
</table>
<p>we replace Llama3-8B-Instruct with Gemma2-9BInstruct <em>Team et al. (2024)</em> and Mistralv0.3-7BInstruct <em>Jiang et al. (2023)</em>. As reported in Table 3, MoP can be effectively transferred to other models and even enjoys the improvement over MoP with Llama3-8B-Instruct.</p>
<p>Table 4: Ablation study: MoP without exemplars or Persona Synthesizer.</p>
<table>
<thead>
<tr>
<th style="text-align: center;"></th>
<th style="text-align: center;">FID $\downarrow$</th>
<th style="text-align: center;">MAUVE $\uparrow$</th>
<th style="text-align: center;">KL Cosine $\downarrow$</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">MoP</td>
<td style="text-align: center;">0.951</td>
<td style="text-align: center;">0.871</td>
<td style="text-align: center;">0.069</td>
</tr>
<tr>
<td style="text-align: center;">w/o exemplars</td>
<td style="text-align: center;">3.694</td>
<td style="text-align: center;">0.552</td>
<td style="text-align: center;">0.560</td>
</tr>
<tr>
<td style="text-align: center;">w/o persona syn</td>
<td style="text-align: center;">1.674</td>
<td style="text-align: center;">0.807</td>
<td style="text-align: center;">0.174</td>
</tr>
<tr>
<td style="text-align: center;">w random personas</td>
<td style="text-align: center;">1.814</td>
<td style="text-align: center;">0.622</td>
<td style="text-align: center;">0.061</td>
</tr>
</tbody>
</table>
<h3>4.5 Ablation Studies</h3>
<p>We conduct extensive ablation studies to examine different variants of the proposed MoP methods. Unless otherwise specified, the experimental settings are consistent with those used in the steerability experiment described in Section 4.2.
Component Ablations. To investigate the effect of each component, we ablate exemplars and the persona synthesizer from MoP described in Section 3.2. For MoP without the persona synthesizer, we will use 100 predefined personas generated from GPT-4 without any context on the dataset. For MoP with random personas, we randomly select from 100 synthesized personas and exemplars are chosen heuristically based on the highest embedding similarity to the chosen persona embedding. The results in Table 4 indicate that prompting with exemplars is crucial to steer LLM responses toward the population of interest. Meanwhile, the persona synthesizer helps significantly improve the alignment score.
Ablation on Varying the Number of Personas and Exemplars. We investigate the impact of the number of personas and exemplars used for MoP. Specifically, we vary the number of personas in the range ${20,50,100,200}$ and the number of exemplars in the range ${100,200,1000,2000,5000}$. The result in Figure 4 shows that generally, more</p>
<p><img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>Figure 3: Diversity comparisons on Agnews of different prompting methods. The embeddings are computed using 'all-mpnet-base-v2'. The scatted points are synthesized samples with the colors indicating the corresponding labels. The circle lines indicate 2-std confidence ellipses of the golden test set. It can be seen that MoP offers synthesized samples that are diverse and aligned with the golden test set.</p>
<p><img alt="img-3.jpeg" src="img-3.jpeg" /></p>
<p>Figure 4: Mauve scores with varying the number of personas and number of examples.</p>
<p>fine-grained persona descriptions and more exemplars are typically helpful for MoP. However, the performance is saturated at 2000 exemplars.</p>
<p><strong>Mixing Personas in Single Query.</strong> In previous experiments, we randomly choose a single persona for inference. In this experiment, we explore the possibility of prompting LLMs with multiple personas in a single query. Note that, unlike the training, mixing personas is not a trivial problem if we want to maintain the black-box usage of LLM during inference. Thus, we prompt the pretrained LLM to synthesize a new persona description given <em>L</em> persona-exemplars sampled according to the mixing weights given by the gating network. The mixed persona will be used to construct a new prompt with <em>L</em> exemplars. The prompt is given in Appendix D. The results in Table 5 demonstrate that combining multiple personas can enhance the diversity of generated responses and, in certain cases (e.g., <em>L</em> = 2), improve alignment. However, using a larger number of personas (<em>L</em> = 4, 8) may negatively impact response alignment.</p>
<h3>5 Related Work</h3>
<p><strong>LLM Steerability.</strong> Recent work has explored understanding and directing the opinions of LLMs (Santurkar et al., 2023; Li et al., 2023a; Scherrer et al., 2024; Sorensen et al., 2024). For example, Santurkar et al. (2023) introduced OpinionQA to evaluate alignment with 60 U.S. demographic groups, revealing notable discrepancies. Scherrer et al. (2024) examined moral beliefs encoded in LLMs using moral scenario surveys. Methods to enhance LLM steerability include prompt engineering and finetuning (Feng et al., 2023; Kim and Yang, 2024; Zhao et al., 2023; Hwang et al., 2023; Simmons, 2022). Santurkar et al. (2023) designed prompts to target specific demographics. FERMI (Kim and Yang, 2024) uses personalized prompts and in-context examples for user-specific outputs, while GPO (Zhao et al., 2023) aligns LLMs with group opinion distributions through finetuning.</p>
<p><strong>Zeroshot Synthetic Data Generation.</strong> Generating synthetic datasets with LLMs has been widely studied (Zou et al., 2024; Gupta et al., 2023; Yu et al., 2024b; Gao et al., 2022; Ye et al., 2022a; Yu et al., 2023). Progen (Ye et al., 2022a) uses noise-robust influence functions to guide high-quality sample generation. FuseGen (Zou et al., 2024) builds on this by employing multiple LMs for generating synthetic samples but requires access to classifier models. In contrast, our MoP method avoids dependency on classifier families and multi-round processes, while also serving as a plugin to improve diversity in Progen's framework.</p>
<p><strong>Sampling Diversity.</strong> LLMs often exhibit low sampling diversity, leading to lexical redundancy even when feedback-tuned or persona-prompted (San-</p>
<p>turkar et al., 2023; Padmakumar and He, 2023). Padmakumar et al.(Padmakumar and He, 2023) found that InstructGPT reduced diversity compared to human-generated text. Efforts to balance quality and diversity, such as GAN-based approaches(Xu et al., 2018; Caccia et al., 2018), often fail to outperform LLMs (Holtzman et al., 2019). Techniques like temperature tuning (Hinton, 2015; Guo et al., 2017) and dynamic sampling (Zhang et al., 2024) aim to improve diversity, though recent work questions their efficacy (Peeperkorn et al., 2024; Renze and Guven, 2024). Diversity is critical in applications requiring human-representative outputs, such as synthetic data for testing social theories or scaling experimental research (Horton, 2023; Aher et al., 2023; Argyle et al., 2023). However, LLMs often fail to represent human behavior accurately, exhibiting biases and inconsistencies (Santurkar et al., 2023; Dorner et al., 2023; Aher et al., 2023). These limitations highlight challenges in modeling individual or group actions.</p>
<h2>6 Conclusion</h2>
<p>We introduced Mixture of Personas (MoP), a probabilistic prompting method designed to align LLMgenerated responses with a target population. Our experiments showed that exemplar-based variants of MoP significantly improve the alignment and diversity of synthetic data, leading to enhanced performance in downstream tasks. Furthermore, MoP is flexible and does not require fine-tuning of the base model, enabling seamless transferability across different models without retraining.</p>
<h2>7 Limitations</h2>
<p>While MoP is a prompting method and can be transferable to different models, MoP still needs access to LLM output logits to be trainable. This might be a constraint for an application of MoP to closedsource models such as ChatGPT, etc. However, this constraint is less restrictive compared to other finetuning baselines or requiring access to the persona datasets. Furthermore, as our study focuses on task scenarios where access to personal data is restricted due to privacy concerns, we recognize the potential trade-offs between protecting privacy and avoiding subjective labeling of users. By designing persona prompts without personal data, there is a risk of introducing biases inherent in the construction of these prompts, which may not fully represent user populations. Addressing this limitation will require
deeper investigations into the interplay between privacy and fairness, such as exploring techniques for bias mitigation within the probabilistic prompting framework. We leave this investigation for future work.</p>
<h2>References</h2>
<p>Gati V Aher, Rosa I Arriaga, and Adam Tauman Kalai. 2023. Using large language models to simulate multiple humans and replicate human subject studies. In International Conference on Machine Learning, pages 337-371. PMLR.</p>
<p>Lisa P Argyle, Ethan C Busby, Nancy Fulda, Joshua R Gubler, Christopher Rytting, and David Wingate. 2023. Out of one, many: Using language models to simulate human samples. Political Analysis, 31(3):337-351.</p>
<p>James Bisbee, Joshua D Clinton, Cassy Dorff, Brenton Kenkel, and Jennifer M Larson. 2023. Synthetic replacements for human survey data? the perils of large language models. Political Analysis, pages 116 .</p>
<p>Tom B Brown. 2020. Language models are few-shot learners. arXiv preprint arXiv:2005.14165.</p>
<p>Massimo Caccia, Lucas Caccia, William Fedus, Hugo Larochelle, Joelle Pineau, and Laurent Charlin. 2018. Language GANs falling short. arXiv preprint arXiv:1811.02549.</p>
<p>Chung-Ching Chang, David Reitter, Renat Aksitov, and Yun-Hsuan Sung. 2023. KI-divergence guided temperature sampling. arXiv preprint arXiv:2306.01286.</p>
<p>Jin Chen, Zheng Liu, Xu Huang, Chenwang Wu, Qi Liu, Gangwei Jiang, Yuanhao Pu, Yuxuan Lei, Xiaolong Chen, Xingmei Wang, et al. 2024. When large language models meet personalization: Perspectives of challenges and opportunities. World Wide Web, 27(4):42.</p>
<p>Hyeong Kyu Choi and Yixuan Li. 2024. PICLe: Eliciting diverse behaviors from large language models with persona in-context learning. In Forty-first International Conference on Machine Learning.</p>
<p>Florian E Dorner, Tom Sühr, Samira Samadi, and Augustin Kelava. 2023. Do personality tests generalize to large language models? arXiv preprint arXiv:2311.05297.</p>
<p>Abhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey, Abhishek Kadian, Ahmad Al-Dahle, Aiesha Letman, Akhil Mathur, Alan Schelten, Amy Yang, Angela Fan, et al. 2024. The llama 3 herd of models. arXiv preprint arXiv:2407.21783.</p>
<p>Shangbin Feng, Chan Young Park, Yuhan Liu, and Yulia Tsvetkov. 2023. From pretraining data to language models to downstream tasks: Tracking the trails of</p>
<p>political biases leading to unfair nlp models. arXiv preprint arXiv:2305.08283.</p>
<p>Jiahui Gao, Renjie Pi, Yong Lin, Hang Xu, Jiacheng Ye, Zhiyong Wu, Weizhong Zhang, Xiaodan Liang, Zhenguo Li, and Lingpeng Kong. 2022. Self-guided noise-free data generation for efficient zero-shot learning. arXiv preprint arXiv:2205.12679.</p>
<p>Chuan Guo, Geoff Pleiss, Yu Sun, and Kilian Q Weinberger. 2017. On calibration of modern neural networks. In International conference on machine learning, pages 1321-1330. PMLR.</p>
<p>Himanshu Gupta, Kevin Scaria, Ujjwala Anantheswaran, Shreyas Verma, Mihir Parmar, Saurabh Arjun Sawant, Swaroop Mishra, and Chitta Baral. 2023. Targen: Targeted data generation with large language models. arXiv preprint arXiv:2310.17876.</p>
<p>Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, and Sepp Hochreiter. 2017. Gans trained by a two time-scale update rule converge to a local nash equilibrium. Advances in neural information processing systems, 30.</p>
<p>Geoffrey Hinton. 2015. Distilling the knowledge in a neural network. arXiv preprint arXiv:1503.02531.</p>
<p>Ari Holtzman, Jan Buys, Li Du, Maxwell Forbes, and Yejin Choi. 2019. The curious case of neural text degeneration. arXiv preprint arXiv:1904.09751.</p>
<p>John J Horton. 2023. Large language models as simulated economic agents: What can we learn from homo silicus? Technical report, National Bureau of Economic Research.</p>
<p>EunJeong Hwang, Bodhisattwa Majumder, and Niket Tandon. 2023. Aligning language models to user opinions. In Findings of the Association for Computational Linguistics: EMNLP 2023, pages 59065919, Singapore. Association for Computational Linguistics.</p>
<p>AQ Jiang, A Sablayrolles, A Mensch, C Bamford, DS Chaplot, D de las Casas, F Bressand, G Lengyel, G Lample, L Saulnier, et al. 2023. Mistral 7b (2023). arXiv preprint arXiv:2310.06825.</p>
<p>Michael I Jordan and Robert A Jacobs. 1994. Hierarchical mixtures of experts and the em algorithm. Neural computation, 6(2):181-214.</p>
<p>Pratik Joshi, Sebastin Santy, Amar Budhiraja, Kalika Bali, and Monojit Choudhury. 2020. The state and fate of linguistic diversity and inclusion in the NLP world. arXiv preprint arXiv:2004.09095.</p>
<p>Jaehyung Kim and Yiming Yang. 2024. Few-shot personalization of llms with mis-aligned responses. arXiv preprint arXiv:2406.18678.</p>
<p>Junyi Li, Ninareh Mehrabi, Charith Peris, Palash Goyal, Kai-Wei Chang, Aram Galstyan, Richard Zemel, and Rahul Gupta. 2023a. On the steerability of large language models toward data-driven personas. arXiv preprint arXiv:2311.04978.</p>
<p>Zhuoyan Li, Hangxiao Zhu, Zhuoran Lu, and Ming Yin. 2023b. Synthetic data generation with large language models for text classification: Potential and limitations. arXiv preprint arXiv:2310.07849.</p>
<p>Andrew L. Maas, Raymond E. Daly, Peter T. Pham, Dan Huang, Andrew Y. Ng, and Christopher Potts. 2011. Learning word vectors for sentiment analysis. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, pages 142-150, Portland, Oregon, USA. Association for Computational Linguistics.</p>
<p>Pavan Kumar Mallapragada, Rong Jin, and Anil Jain. 2010. Non-parametric mixture models for clustering. In Joint IAPR International Workshops on Statistical Techniques in Pattern Recognition (SPR) and Structural and Syntactic Pattern Recognition (SSPR), pages 334-343. Springer.</p>
<p>Vishakh Padmakumar and He He. 2023. Does writing with language models reduce content diversity? arXiv preprint arXiv:2309.05196.</p>
<p>Max Peeperkorn, Tom Kouwenhoven, Dan Brown, and Anna Jordanous. 2024. Is temperature the creativity parameter of large language models? arXiv preprint arXiv:2405.00492.</p>
<p>Krishna Pillutla, Lang Liu, John Thickstun, Sean Welleck, Swabha Swayamdipta, Rowan Zellers, Sewoong Oh, Yejin Choi, and Zaid Harchaoui. 2023. Mauve scores for generative models: Theory and practice. Journal of Machine Learning Research, 24(356):1-92.</p>
<p>Krishna Pillutla, Swabha Swayamdipta, Rowan Zellers, John Thickstun, Sean Welleck, Yejin Choi, and Zaid Harchaoui. 2021. Mauve: Measuring the gap between neural text and human text using divergence frontiers. Advances in Neural Information Processing Systems, 34:4816-4828.</p>
<p>Matthew Renze and Erhan Guven. 2024. The effect of sampling temperature on problem solving in large language models. arXiv preprint arXiv:2402.05201.</p>
<p>V Sanh. 2019. Distilbert, a distilled version of bert: Smaller, faster, cheaper and lighter. arXiv preprint arXiv:1910.01108.</p>
<p>Shibani Santurkar, Esin Durmus, Faisal Ladhak, Cinoo Lee, Percy Liang, and Tatsunori Hashimoto. 2023. Whose opinions do language models reflect? In International Conference on Machine Learning, pages 29971-30004. PMLR.</p>
<p>Nino Scherrer, Claudia Shi, Amir Feder, and David Blei. 2024. Evaluating the moral beliefs encoded in llms. Advances in Neural Information Processing Systems, 36.</p>
<p>Noam Shazeer, Azalia Mirhoseini, Krzysztof Maziarz, Andy Davis, Quoc Le, Geoffrey Hinton, and Jeff Dean. 2017. Outrageously large neural networks: The sparsely-gated mixture-of-experts layer. arXiv preprint arXiv:1701.06538.</p>
<p>Gabriel Simmons. 2022. Moral mimicry: Large language models produce moral rationalizations tailored to political identity. arxiv. arXiv preprint arXiv:2209.12106.</p>
<p>Richard Socher, Alex Perelygin, Jean Wu, Jason Chuang, Christopher D. Manning, Andrew Ng, and Christopher Potts. 2013. Recursive deep models for semantic compositionality over a sentiment treebank. In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1631-1642, Seattle, Washington, USA. Association for Computational Linguistics.</p>
<p>Kaitao Song, Xu Tan, Tao Qin, Jianfeng Lu, and TieYan Liu. 2020. Mpnet: Masked and permuted pretraining for language understanding. Advances in neural information processing systems, 33:1685716867.</p>
<p>Taylor Sorensen, Jared Moore, Jillian Fisher, Mitchell Gordon, Niloofar Mireshghallah, Christopher Michael Rytting, Andre Ye, Liwei Jiang, Ximing Lu, Nouha Dziri, et al. 2024. A roadmap to pluralistic alignment. arXiv preprint arXiv:2402.05070.</p>
<p>Chenkai Sun, Ke Yang, Revanth Gangi Reddy, Yi R Fung, Hou Pong Chan, ChengXiang Zhai, and Heng Ji. 2024. Persona-db: Efficient large language model personalization for response prediction with collaborative data refinement. arXiv preprint arXiv:2402.11060.</p>
<p>Gemma Team, Morgane Riviere, Shreya Pathak, Pier Giuseppe Sessa, Cassidy Hardin, Surya Bhupatiraju, Léonard Hussenot, Thomas Mesnard, Bobak Shahriari, Alexandre Ramé, et al. 2024. Gemma 2: Improving open language models at a practical size. arXiv preprint arXiv:2408.00118.</p>
<p>Petter Törnberg. 2023. Chatgpt-4 outperforms experts and crowd workers in annotating political twitter messages with zero-shot learning. arXiv preprint arXiv:2304.06588.</p>
<p>Yu-Min Tseng, Yu-Chao Huang, Teng-Yun Hsiao, YuChing Hsu, Jia-Yin Foo, Chao-Wei Huang, and YunNung Chen. 2024. Two tales of persona in llms: A survey of role-playing and personalization. arXiv preprint arXiv:2406.01171.</p>
<p>Zhenhailong Wang, Shaoguang Mao, Wenshan Wu, Tao Ge, Furu Wei, and Heng Ji. 2023. Unleashing the
emergent cognitive synergy in large language models: A task-solving agent through multi-persona selfcollaboration. arXiv preprint arXiv:2307.05300.</p>
<p>Jingjing Xu, Xuancheng Ren, Junyang Lin, and Xu Sun. 2018. DP-GAN: diversity-promoting generative adversarial network for generating informative and diversified text. arXiv preprint arXiv:1802.01345.</p>
<p>Jiacheng Ye, Jiahui Gao, Jiangtao Feng, Zhiyong Wu, Tao Yu, and Lingpeng Kong. 2022a. Progen: Progressive zero-shot dataset generation via in-context feedback. arXiv preprint arXiv:2210.12329.</p>
<p>Jiacheng Ye, Jiahui Gao, Qintong Li, Hang Xu, Jiangtao Feng, Zhiyong Wu, Tao Yu, and Lingpeng Kong. 2022b. Zerogen: Efficient zero-shot learning via dataset generation. arXiv preprint arXiv:2202.07922.</p>
<p>Xiaoyan Yu, Tongxu Luo, Yifan Wei, Fangyu Lei, Yiming Huang, Peng Hao, and Liehuang Zhu. 2024a. Neeko: Leveraging dynamic lora for efficient multi-character role-playing agent. arXiv preprint arXiv:2402.13717.</p>
<p>Yue Yu, Yuchen Zhuang, Jieyu Zhang, Yu Meng, Alexander J Ratner, Ranjay Krishna, Jiaming Shen, and Chao Zhang. 2024b. Large language model as attributed training data generator: A tale of diversity and bias. Advances in Neural Information Processing Systems, 36.</p>
<p>Yue Yu, Yuchen Zhuang, Rongzhi Zhang, Yu Meng, Jiaming Shen, and Chao Zhang. 2023. Regen: Zeroshot text classification via training data generation with progressive dense retrieval. arXiv preprint arXiv:2305.10703.</p>
<p>Xiang Yue, Huseyin A Inan, Xuechen Li, Girish Kumar, Julia McAnallen, Hoda Shajari, Huan Sun, David Levitan, and Robert Sim. 2022. Synthetic text generation with differential privacy: A simple and practical recipe. arXiv preprint arXiv:2210.14348.</p>
<p>Shimao Zhang, Yu Bao, and Shujian Huang. 2024. EDT: Improving large language models' generation by entropy-based dynamic temperature sampling. arXiv preprint arXiv:2403.14541.</p>
<p>Xiang Zhang, Junbo Zhao, and Yann LeCun. 2015. Character-level convolutional networks for text classification. Advances in neural information processing systems, 28.</p>
<p>Siyan Zhao, John Dang, and Aditya Grover. 2023. Group preference optimization: Few-shot alignment of large language models. arXiv preprint arXiv:2310.11523.</p>
<p>Tianyuan Zou, Yang Liu, Peng Li, Jianqing Zhang, Jingjing Liu, and Ya-Qin Zhang. 2024. Fusegen: Plm fusion for data-generation based zero-shot learning. arXiv preprint arXiv:2406.12527.</p>
<h2>A Societal Impact</h2>
<p>While generating human-like datasets opens up many exciting possibilities for augmenting blind spots in data that may have otherwise led to limitations preventing a complete understanding of important information, synthetic data can still lack specific nuances, diversity, and edge cases present in human-derived data. This is especially prevalent in population sub-groups that remain underrepresented, causing a lack of labeled data in specific languages that affect the authenticity and coverage of over two billion individuals worldwide (Joshi et al., 2020). Our focus on augmenting human records instead of replacing them is notwithstanding the potential of synthetic data; it is imperative that we continue supporting data collection obtained directly from people in under-served communities and domains and, whenever possible, make those data freely available for empirical and experimental research. Beyond the behavioral science and data generation for training ML models, data generated using MoP could be leveraged across a broad range of applications, such as informaticsbased health claims, market intelligence and userpreference modeling, and free-form text writing - where the goal is not only to produce accurate or factually-correct answers but also to simulate a population of interest otherwise out of reach.</p>
<h2>B Additional Experiment Settings</h2>
<p>Datasets. Below are the detailed descriptions of four datasets used in this paper.</p>
<ul>
<li>AGNews (Zhang et al., 2015): This dataset contains 103600 news articles crawled from AG News. Each article is categorized into political news, sports news, business news, and technology news.</li>
<li>Yelp Reviews (Zhang et al., 2015): This dataset contains restaurant reviews from the Yelp platform. Each review is labeled with a positive or negative sentiment label. This popular dataset is used for sentiment analysis and opinion mining.</li>
<li>SST-2 (Stanford Sentiment Treebank) (Socher et al., 2013): The dataset consists of 11,855 individual sentences extracted from movie reviews to analyze the compositional effects of sentiment in language. Each sentence is annotated with a binary label indicating whether the review is positive or negative.</li>
<li>IMDB Reviews (Maas et al., 2011): The dataset consists of 50,000 movie reviews crawled from IMDB with 25,000 samples for positive classes and 25,000 samples for negative classes.</li>
</ul>
<p>Baselines. We provide descriptions for baselines used in our paper.</p>
<ul>
<li>ZeroGen (Ye et al., 2022b) generates synthetic samples by feeding simple class-conditioned prompts to language models. We reuse the same prompts described in (Yu et al., 2024b).</li>
<li>Attrprompt (Yu et al., 2024b) further increases the diversity of synthetic samples by utilizing a set of sample attributes generated by chat-GPT. For example, to generate synthetic examples for AgNews, Attrprompt also inputs randomized values for 'writing style' or 'location' to the prompt in addition to class information. We refer the readers to their papers for the full description of the used attributes for each dataset. In our experiment, we use the same attribute set released by the authors in their repository ${ }^{4}$.</li>
<li>ProGen (Ye et al., 2022a): proposes a framework for zero-shot dataset generation that iteratively improves the quality of synthetic datasets. It uses feedback from a task-specific model, guided by a noise-tolerant influence function, to identify high-quality samples and incorporate them as in-context examples for subsequent data generation.</li>
<li>PICLE (Choi and Li, 2024): is a framework designed to elicit specific target personas from large language models (LLMs) using an incontext learning (ICL) approach. It employs a novel likelihood-ratio-based selection mechanism to identify and prepend the most informative examples from a persona-specific pool, guiding the model to align with the desired persona. By leveraging Bayesian inference, PICLe modifies the LLM's output distribution to better reflect the target persona, achieving improved persona elicitation compared to baseline methods.</li>
</ul>
<p>Metrics. Measuring the alignment of the synthetic data with the golden dataset can be challenging due to the discrete nature of text sequences. We follow (Pillutla et al., 2021; Yu et al., 2024b) to</p>
<p><sup id="fnref2:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>evaluate the alignment and diversity of the simulated data in the embedding space. Throughout, we use a pre-trained sentence encoder 'all-mpnet-basev2' ${ }^{3}$ (Song et al., 2020) as a text encoder to map generated sentences into a common vector space. We then report three following metrics:</p>
<ul>
<li>FID (Fréchet Inception Distance) (Heusel et al., 2017) is a widely-used metric in computer vision literature to measure the fidelity of synthetic images with respect to real images. Following the approach in (Yue et al., 2022), we adapt FID for text generation. We first calculate the mean and covariance matrices of sentence embeddings for both the golden test set and synthetic datasets, then use the Fréchet distance to compute the FID between them.</li>
<li>The MAUVE metric (Pillutla et al., 2021, 2023) evaluates the similarity between two text distributions by comparing their divergence frontiers. It begins by embedding text into vectors and clustering them to create histograms of cluster assignments. A divergence curve is then constructed from these histograms, and the area under the curve quantifies the difference between the synthetic and golden data distributions. In our experiments, we use the original implementation of MAUVE ${ }^{6}$. As suggested by the authors, we set the number of clusters to 500 and the scaling parameter to 1 .</li>
<li>The Kullback-Leibler Cosine (KL Cosine) metric evaluates the divergence between the pairwise cosine similarity distributions of a method and the ground truth. First, the pairwise cosine similarities are computed for the method and the ground truth. Then, the Kullback-Leibler divergence between their normalized histograms is calculated as:</li>
</ul>
<p>$$
D_{K L}(P | Q)=\sum_{i} P(i) \log \frac{P(i)}{Q(i)}
$$</p>
<p>where $P(i)$ represents the histogram of pairwise cosine similarities for the method, and $Q(i)$ represents the histogram for the ground truth.</p>
<h2>C Additional ablation studies</h2>
<p>We conducted an additional experiment to evaluate whether our framework is sensitive to the format of</p>
<p><sup id="fnref3:0"><a class="footnote-ref" href="#fn:0">1</a></sup>Table 6: Train test split and the number of classes in each dataset.</p>
<table>
<thead>
<tr>
<th style="text-align: center;"></th>
<th style="text-align: center;">AgNews</th>
<th style="text-align: center;">Yelp</th>
<th style="text-align: center;">SST-2</th>
<th style="text-align: center;">IMDB</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">Train set</td>
<td style="text-align: center;">96000</td>
<td style="text-align: center;">141076</td>
<td style="text-align: center;">67349</td>
<td style="text-align: center;">14006</td>
</tr>
<tr>
<td style="text-align: center;">Test set</td>
<td style="text-align: center;">7600</td>
<td style="text-align: center;">35323</td>
<td style="text-align: center;">1821</td>
<td style="text-align: center;">14056</td>
</tr>
<tr>
<td style="text-align: center;">Number of classes</td>
<td style="text-align: center;">4</td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">2</td>
</tr>
</tbody>
</table>
<p>ICL prompts. Specifically, we modified the original ICL prompt ('You have written the following news blurb: [example]') to two alternative formats: ICL Template 1 and ICL Template 2. The results in the table below indicate that changes in the ICL format have minimal impact on performance in our setting.</p>
<p>ICL Template 1:
Example news blurb: [example]
ICL Template 2:
The following news blurb
is given as an example: [example]
These results suggest that our framework's performance is not overly sensitive to the specific format of ICL prompts.</p>
<p>Table 7: Comparison of metrics across different ICL prompts and templates.</p>
<table>
<thead>
<tr>
<th style="text-align: left;"></th>
<th style="text-align: center;">FID</th>
<th style="text-align: center;">Mauve</th>
<th style="text-align: center;">Cosine Similarity</th>
<th style="text-align: center;">KL Cosine</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Original ICL Prompt</td>
<td style="text-align: center;">0.951</td>
<td style="text-align: center;">0.871</td>
<td style="text-align: center;">0.108</td>
<td style="text-align: center;">0.069</td>
</tr>
<tr>
<td style="text-align: left;">ICL Template 1</td>
<td style="text-align: center;">0.955</td>
<td style="text-align: center;">0.883</td>
<td style="text-align: center;">0.110</td>
<td style="text-align: center;">0.074</td>
</tr>
<tr>
<td style="text-align: left;">ICL Template 2</td>
<td style="text-align: center;">0.955</td>
<td style="text-align: center;">0.881</td>
<td style="text-align: center;">0.108</td>
<td style="text-align: center;">0.069</td>
</tr>
</tbody>
</table>
<h2>D MoP Prompts</h2>
<p>In this section, we present the prompts used throughout our experiments.</p>
<ol>
<li>Synthesizing New Samples. The prompts in Fig. 5, Fig. 6, Fig. 7, and Fig. 8 are designed to synthesize new samples based on provided examples. These prompts guide the language model to generate new samples in line with the provided context and example, while maintaining consistency with the style and tone of the given input.</li>
<li>Generating new personas. We use the prompts in Fig. 9, Fig. 10, Fig. 11, and Fig. 12 to generate a new persona based on examples that reflect the characteristics of that persona.</li>
<li>Classifying personas. We use the prompts shown in Fig. 13 to classify a persona based</li>
</ol>
<p>on its description. The prompt provides a persona description of a reporter, and the task is to identify the reporter's specialization from four predefined categories: world news, sports news, business news, or sci/tech news.
4. Persona Mixing Prompt. The prompt in Fig. 14 is designed to synthesize a unified persona description by combining multiple persona descriptions with sample news blurbs written by the reporter. It integrates the thematic focus, stylistic tendencies, and primary interests from the inputs to generate a concise and cohesive profile of the reporter.</p>
<p>Figure 5: MoP Prompt for Agnews</p>
<div class="codehilite"><pre><span></span><code><span class="o">&lt;|</span><span class="n">begin_of_text</span><span class="o">|&gt;&lt;|</span><span class="n">start_header_id</span><span class="o">|&gt;</span><span class="n">system</span><span class="o">&lt;|</span><span class="n">end_header_id</span><span class="o">|&gt;</span><span class="err">\</span><span class="n">n</span><span class="err">\</span><span class="n">nYou</span><span class="w"> </span><span class="n">embody</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">persona</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">the</span>
<span class="w">    </span><span class="n">description</span><span class="w"> </span><span class="k">to</span><span class="w"> </span><span class="n">complete</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">tasks</span><span class="o">.&lt;|</span><span class="n">eot_id</span><span class="o">|&gt;&lt;|</span><span class="n">start_header_id</span><span class="o">|&gt;</span><span class="n">user</span><span class="o">&lt;|</span><span class="n">end_header_id</span><span class="o">|&gt;</span><span class="err">\</span><span class="n">n</span><span class="err">\</span><span class="n">n</span>
<span class="err">\</span><span class="n">n</span><span class="err">\</span><span class="n">nYou</span><span class="w"> </span><span class="n">have</span><span class="w"> </span><span class="n">written</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">following</span><span class="w"> </span><span class="n">news</span><span class="w"> </span><span class="n">blurb</span><span class="o">:</span><span class="w"> </span><span class="o">{</span><span class="n">example</span><span class="o">}</span>
<span class="err">\</span><span class="n">n</span><span class="err">\</span><span class="n">nPlease</span><span class="w"> </span><span class="n">write</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">short</span><span class="w"> </span><span class="n">news</span><span class="w"> </span><span class="n">blurb</span><span class="w"> </span><span class="n">similar</span><span class="w"> </span><span class="k">to</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">above</span><span class="w"> </span><span class="n">blurb</span><span class="o">.&lt;|</span><span class="n">eot_id</span><span class="o">|&gt;</span>
<span class="w">    </span><span class="o">&lt;|</span><span class="n">start_header_id</span><span class="o">|&gt;</span><span class="n">assistant</span><span class="o">&lt;|</span><span class="n">end_header_id</span><span class="o">|&gt;</span><span class="err">\</span><span class="n">n</span><span class="err">\</span><span class="n">n</span>
</code></pre></div>

<p>Figure 6: MoP Prompt for Yelp</p>
<div class="codehilite"><pre><span></span><code><span class="o">&lt;|</span><span class="n">begin_of_text</span><span class="o">|&gt;&lt;|</span><span class="n">start_header_id</span><span class="o">|&gt;</span><span class="n">system</span><span class="o">&lt;|</span><span class="n">end_header_id</span><span class="o">|&gt;</span><span class="err">\</span><span class="n">n</span><span class="err">\</span><span class="n">nYou</span><span class="w"> </span><span class="n">embody</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">persona</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">the</span>
<span class="w">    </span><span class="n">description</span><span class="w"> </span><span class="k">to</span><span class="w"> </span><span class="n">complete</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">tasks</span><span class="o">.&lt;|</span><span class="n">eot_id</span><span class="o">|&gt;&lt;|</span><span class="n">start_header_id</span><span class="o">|&gt;</span><span class="n">user</span><span class="o">&lt;|</span><span class="n">end_header_id</span><span class="o">|&gt;</span><span class="err">\</span><span class="n">n</span><span class="err">\</span><span class="n">n</span>
<span class="err">\</span><span class="n">n</span><span class="err">\</span><span class="n">nYour</span><span class="w"> </span><span class="n">review</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">restaurant</span><span class="w"> </span><span class="o">{</span><span class="n">context</span><span class="o">}:</span><span class="w"> </span><span class="o">{</span><span class="n">example</span><span class="o">}</span>
<span class="err">\</span><span class="n">n</span><span class="err">\</span><span class="n">nPlease</span><span class="w"> </span><span class="n">write</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">short</span><span class="w"> </span><span class="n">review</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">restaurant</span><span class="w"> </span><span class="o">{</span><span class="n">context</span><span class="o">},</span><span class="w"> </span><span class="n">similar</span><span class="w"> </span><span class="k">to</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">above</span><span class="w"> </span><span class="n">review</span><span class="o">:&lt;|</span><span class="n">eot_id</span><span class="o">|&gt;</span>
<span class="w">    </span><span class="o">&lt;|</span><span class="n">start_header_id</span><span class="o">|&gt;</span><span class="n">assistant</span><span class="o">&lt;|</span><span class="n">end_header_id</span><span class="o">|&gt;</span><span class="err">\</span><span class="n">n</span><span class="err">\</span><span class="n">n</span>
</code></pre></div>

<p>Figure 7: MoP Prompt for SST-2</p>
<div class="codehilite"><pre><span></span><code><span class="o">&lt;|</span><span class="n">begin_of_text</span><span class="o">|&gt;&lt;|</span><span class="n">start_header_id</span><span class="o">|&gt;</span><span class="n">system</span><span class="o">&lt;|</span><span class="n">end_header_id</span><span class="o">|&gt;</span><span class="err">\</span><span class="n">n</span><span class="err">\</span><span class="n">nYou</span><span class="w"> </span><span class="n">embody</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">persona</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">the</span>
<span class="w">    </span><span class="n">description</span><span class="w"> </span><span class="k">to</span><span class="w"> </span><span class="n">complete</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">tasks</span><span class="o">.&lt;|</span><span class="n">eot_id</span><span class="o">|&gt;&lt;|</span><span class="n">start_header_id</span><span class="o">|&gt;</span><span class="n">user</span><span class="o">&lt;|</span><span class="n">end_header_id</span><span class="o">|&gt;</span><span class="err">\</span><span class="n">n</span><span class="err">\</span><span class="n">n</span>
<span class="err">\</span><span class="n">n</span><span class="err">\</span><span class="n">nYou</span><span class="w"> </span><span class="n">have</span><span class="w"> </span><span class="n">written</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">following</span><span class="w"> </span><span class="n">review</span><span class="o">:</span><span class="w"> </span><span class="o">{</span><span class="n">example</span><span class="o">}</span>
<span class="err">\</span><span class="n">n</span><span class="err">\</span><span class="n">nPlease</span><span class="w"> </span><span class="n">write</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">review</span><span class="w"> </span><span class="n">sentence</span><span class="o">,</span><span class="w"> </span><span class="n">similar</span><span class="w"> </span><span class="k">to</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">above</span>
<span class="w">    </span><span class="n">review</span><span class="o">:&lt;|</span><span class="n">eot_id</span><span class="o">|&gt;&lt;|</span><span class="n">start_header_id</span><span class="o">|&gt;</span><span class="n">assistant</span><span class="o">&lt;|</span><span class="n">end_header_id</span><span class="o">|&gt;</span>
<span class="w">    </span><span class="err">\</span><span class="n">n</span><span class="err">\</span><span class="n">n</span><span class="o">&lt;|</span><span class="n">start_header_id</span><span class="o">|&gt;</span><span class="n">assistant</span><span class="o">&lt;|</span><span class="n">end_header_id</span><span class="o">|&gt;</span><span class="err">\</span><span class="n">n</span><span class="err">\</span><span class="n">n</span>
</code></pre></div>

<p>Figure 8: MoP Prompt for IMDB</p>
<div class="codehilite"><pre><span></span><code><span class="o">&lt;|</span><span class="n">begin_of_text</span><span class="o">|&gt;&lt;|</span><span class="n">start_header_id</span><span class="o">|&gt;</span><span class="n">system</span><span class="o">&lt;|</span><span class="n">end_header_id</span><span class="o">|&gt;</span><span class="err">\</span><span class="n">n</span><span class="err">\</span><span class="n">nYou</span><span class="w"> </span><span class="n">embody</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">persona</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">the</span>
<span class="w">    </span><span class="n">description</span><span class="w"> </span><span class="k">to</span><span class="w"> </span><span class="n">complete</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">tasks</span><span class="o">.&lt;|</span><span class="n">eot_id</span><span class="o">|&gt;&lt;|</span><span class="n">start_header_id</span><span class="o">|&gt;</span><span class="n">user</span><span class="o">&lt;|</span><span class="n">end_header_id</span><span class="o">|&gt;</span><span class="err">\</span><span class="n">n</span><span class="err">\</span><span class="n">n</span>
<span class="err">\</span><span class="n">n</span><span class="err">\</span><span class="n">nYou</span><span class="w"> </span><span class="n">have</span><span class="w"> </span><span class="n">written</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">following</span><span class="w"> </span><span class="n">review</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">movie</span><span class="w"> </span><span class="o">{</span><span class="n">context</span><span class="o">}:</span><span class="w"> </span><span class="o">{</span><span class="n">example</span><span class="o">}</span>
<span class="err">\</span><span class="n">n</span><span class="err">\</span><span class="n">nPlease</span><span class="w"> </span><span class="n">write</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">review</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">movie</span><span class="w"> </span><span class="o">{</span><span class="n">context</span><span class="o">},</span><span class="w"> </span><span class="n">similar</span><span class="w"> </span><span class="k">to</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">above</span>
<span class="w">    </span><span class="n">review</span><span class="o">:&lt;|</span><span class="n">eot_id</span><span class="o">|&gt;&lt;|</span><span class="n">start_header_id</span><span class="o">|&gt;</span><span class="n">assistant</span><span class="o">&lt;|</span><span class="n">end_header_id</span><span class="o">|&gt;</span><span class="err">\</span><span class="n">n</span><span class="err">\</span><span class="n">n</span>
</code></pre></div>

<p>Figure 9: MoP Prompt to generate persona for Agnews</p>
<div class="codehilite"><pre><span></span><code><span class="o">&lt;|</span><span class="n">begin_of_text</span><span class="o">|&gt;&lt;|</span><span class="n">start_header_id</span><span class="o">|&gt;</span><span class="n">system</span><span class="o">&lt;|</span><span class="n">end_header_id</span><span class="o">|&gt;</span>
<span class="n">You</span><span class="w"> </span><span class="n">are</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">helpful</span><span class="w"> </span><span class="n">AI</span><span class="w"> </span><span class="n">assistant</span><span class="o">&lt;|</span><span class="n">eot_id</span><span class="o">|&gt;&lt;|</span><span class="n">start_header_id</span><span class="o">|&gt;</span><span class="n">user</span><span class="o">&lt;|</span><span class="n">end_header_id</span><span class="o">|&gt;</span>
<span class="n">Given</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">list</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">news</span><span class="w"> </span><span class="n">blurbs</span><span class="w"> </span><span class="n">written</span><span class="w"> </span><span class="n">by</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">reporter</span><span class="p">,</span><span class="w"> </span><span class="n">construct</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">concise</span><span class="w"> </span><span class="n">persona</span><span class="w"> </span><span class="n">description</span><span class="w"> </span><span class="n">that</span>
<span class="w">    </span><span class="n">reflects</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">reporter</span><span class="s1">&#39;s primary focus, style, and thematic interests.</span>
<span class="n">Example</span><span class="w"> </span><span class="n">persona</span><span class="w"> </span><span class="n">descriptions</span><span class="p">:</span>
<span class="n">You</span><span class="w"> </span><span class="n">are</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">sports</span><span class="w"> </span><span class="n">reporter</span><span class="p">,</span><span class="w"> </span><span class="n">specializing</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">baseball</span><span class="w"> </span><span class="n">news</span><span class="p">,</span><span class="w"> </span><span class="n">with</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">focus</span><span class="w"> </span><span class="n">on</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">Major</span><span class="w"> </span><span class="n">League</span><span class="w"> </span><span class="n">Baseball</span>
<span class="w">    </span><span class="p">(</span><span class="n">MLB</span><span class="p">)</span><span class="w"> </span><span class="n">playoffs</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span><span class="n">postseason</span><span class="w"> </span><span class="n">games</span><span class="o">.</span>
<span class="n">List</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">news</span><span class="w"> </span><span class="n">blurbs</span><span class="p">:</span>
<span class="p">{</span><span class="n">examples</span><span class="p">}</span>
<span class="n">Generate</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">short</span><span class="w"> </span><span class="n">persona</span><span class="w"> </span><span class="n">description</span><span class="w"> </span><span class="n">that</span><span class="w"> </span><span class="n">synthesizes</span><span class="w"> </span><span class="n">their</span><span class="w"> </span><span class="n">focus</span><span class="p">,</span><span class="w"> </span><span class="n">preferences</span><span class="p">,</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span><span class="n">stylistic</span>
<span class="w">    </span><span class="n">tendencies</span><span class="w"> </span><span class="n">into</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">single</span><span class="w"> </span><span class="n">cohesive</span>
<span class="w">    </span><span class="n">statement</span><span class="o">.&lt;|</span><span class="n">eot_id</span><span class="o">|&gt;&lt;|</span><span class="n">start_header_id</span><span class="o">|&gt;</span><span class="n">assistant</span><span class="o">&lt;|</span><span class="n">end_header_id</span><span class="o">|&gt;</span>
</code></pre></div>

<p>The short persona is:</p>
<p>Figure 10: MoP Prompt to generate persona for Yelp</p>
<div class="codehilite"><pre><span></span><code><span class="err">&lt;</span>|begin_of_text|&gt;<span class="err">&lt;</span>/start_header_id|&gt;system<span class="err">&lt;</span>|end_header_id|&gt;
You<span class="w"> </span>are<span class="w"> </span>a<span class="w"> </span>helpful<span class="w"> </span>AI<span class="w"> </span>assistant<span class="err">&lt;</span>|eot_id|&gt;<span class="err">&lt;</span>/start_header_id|&gt;user<span class="err">&lt;</span>|end_header_id|&gt;
Given<span class="w"> </span>a<span class="w"> </span>list<span class="w"> </span>of<span class="w"> </span>restaurant<span class="w"> </span>review<span class="w"> </span>written<span class="w"> </span>by<span class="w"> </span>a<span class="w"> </span>customer,<span class="w"> </span>construct<span class="w"> </span>a<span class="w"> </span>concise<span class="w"> </span>persona<span class="w"> </span>description
<span class="w">    </span>that<span class="w"> </span>reflects<span class="w"> </span>the<span class="w"> </span>customer&#39;s<span class="w"> </span>preferences,<span class="w"> </span>writing<span class="w"> </span>style,<span class="w"> </span>and<span class="w"> </span>interests.
Examples<span class="w"> </span>of<span class="w"> </span>Persona<span class="w"> </span>Descriptions:
You<span class="w"> </span>are<span class="w"> </span>a<span class="w"> </span>food<span class="w"> </span>critic,<span class="w"> </span>specializing<span class="w"> </span>in<span class="w"> </span>fine<span class="w"> </span>dining<span class="w"> </span>and<span class="w"> </span>gourmet<span class="w"> </span>cuisine<span class="w"> </span>with<span class="w"> </span>a<span class="w"> </span>focus<span class="w"> </span>on<span class="w"> </span>presentation
<span class="w">    </span>and<span class="w"> </span>taste.
You<span class="w"> </span>are<span class="w"> </span>a<span class="w"> </span>casual<span class="w"> </span>diner<span class="w"> </span>who<span class="w"> </span>enjoys<span class="w"> </span>comfort<span class="w"> </span>food<span class="w"> </span>and<span class="w"> </span>writes<span class="w"> </span>personal<span class="w"> </span>and<span class="w"> </span>informal<span class="w"> </span>reviews.
List<span class="w"> </span>of<span class="w"> </span>reviews:
{examples}
Generate<span class="w"> </span>a<span class="w"> </span>short<span class="w"> </span>persona<span class="w"> </span>description<span class="w"> </span>that<span class="w"> </span>synthesizes<span class="w"> </span>their<span class="w"> </span>interests,<span class="w"> </span>preferences,<span class="w"> </span>and<span class="w"> </span>writing
<span class="w">    </span>stylistic<span class="w"> </span>tendencies<span class="w"> </span>into<span class="w"> </span>a<span class="w"> </span>single<span class="w"> </span>cohesive
<span class="w">    </span>statement.<span class="err">&lt;</span>|eot_id|&gt;<span class="err">&lt;</span>/start_header_id|&gt;assistant<span class="err">&lt;</span>|end_header_id|&gt;
The<span class="w"> </span>short<span class="w"> </span>persona<span class="w"> </span>is:
</code></pre></div>

<p>Figure 11: MoP Prompt to generate persona for SST-2</p>
<div class="codehilite"><pre><span></span><code><span class="err">&lt;</span>|begin_of_text|&gt;<span class="err">&lt;</span>/start_header_id|&gt;system<span class="err">&lt;</span>|end_header_id|&gt;
You<span class="w"> </span>are<span class="w"> </span>a<span class="w"> </span>helpful<span class="w"> </span>AI<span class="w"> </span>assistant<span class="err">&lt;</span>|eot_id|&gt;<span class="err">&lt;</span>/start_header_id|&gt;user<span class="err">&lt;</span>|end_header_id|&gt;
Given<span class="w"> </span>a<span class="w"> </span>list<span class="w"> </span>of<span class="w"> </span>movie<span class="w"> </span>review<span class="w"> </span>written<span class="w"> </span>by<span class="w"> </span>a<span class="w"> </span>viewer,<span class="w"> </span>construct<span class="w"> </span>a<span class="w"> </span>concise<span class="w"> </span>persona<span class="w"> </span>description<span class="w"> </span>that
<span class="w">    </span>reflects<span class="w"> </span>the<span class="w"> </span>review&#39;s<span class="w"> </span>preferences,<span class="w"> </span>writing<span class="w"> </span>style,<span class="w"> </span>and<span class="w"> </span>thematic<span class="w"> </span>interests.
Examples<span class="w"> </span>of<span class="w"> </span>Persona<span class="w"> </span>Descriptions:
You<span class="w"> </span>are<span class="w"> </span>a<span class="w"> </span>movie<span class="w"> </span>critic,<span class="w"> </span>specializing<span class="w"> </span>in<span class="w"> </span>horror<span class="w"> </span>movies<span class="w"> </span>and<span class="w"> </span>independent<span class="w"> </span>films<span class="w"> </span>with<span class="w"> </span>a<span class="w"> </span>focus<span class="w"> </span>on
<span class="w">    </span>cinematography<span class="w"> </span>and<span class="w"> </span>storytelling.
You<span class="w"> </span>are<span class="w"> </span>a<span class="w"> </span>casual<span class="w"> </span>viewer<span class="w"> </span>who<span class="w"> </span>enjoys<span class="w"> </span>action-packed<span class="w"> </span>films<span class="w"> </span>and<span class="w"> </span>writes<span class="w"> </span>personal<span class="w"> </span>and<span class="w"> </span>informal<span class="w"> </span>reviews.
List<span class="w"> </span>of<span class="w"> </span>reviews:
{examples}
Generate<span class="w"> </span>a<span class="w"> </span>short<span class="w"> </span>persona<span class="w"> </span>description<span class="w"> </span>that<span class="w"> </span>synthesizes<span class="w"> </span>their<span class="w"> </span>focus,<span class="w"> </span>preferences,<span class="w"> </span>and<span class="w"> </span>stylistic
<span class="w">    </span>tendencies<span class="w"> </span>into<span class="w"> </span>a<span class="w"> </span>single<span class="w"> </span>cohesive
<span class="w">    </span>statement.<span class="err">&lt;</span>|eot_id|&gt;<span class="err">&lt;</span>/start_header_id|&gt;assistant<span class="err">&lt;</span>|end_header_id|&gt;
The<span class="w"> </span>short<span class="w"> </span>persona<span class="w"> </span>is:
</code></pre></div>

<p>Figure 12: MoP Prompt to generate persona for IMDB</p>
<div class="codehilite"><pre><span></span><code><span class="o">&lt;|</span><span class="n">begin_of_text</span><span class="o">|&gt;&lt;|</span><span class="n">start_header_id</span><span class="o">|&gt;</span><span class="n">system</span><span class="o">&lt;|</span><span class="n">end_header_id</span><span class="o">|&gt;</span>
<span class="n">You</span><span class="w"> </span><span class="n">are</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">helpful</span><span class="w"> </span><span class="n">AI</span><span class="w"> </span><span class="n">assistant</span><span class="o">&lt;|</span><span class="n">eot_id</span><span class="o">|&gt;&lt;|</span><span class="n">start_header_id</span><span class="o">|&gt;</span><span class="n">user</span><span class="o">&lt;|</span><span class="n">end_header_id</span><span class="o">|&gt;</span>
<span class="n">Given</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">list</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">movie</span><span class="w"> </span><span class="n">review</span><span class="w"> </span><span class="n">written</span><span class="w"> </span><span class="n">by</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">viewer</span><span class="p">,</span><span class="w"> </span><span class="n">construct</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">concise</span><span class="w"> </span><span class="n">persona</span><span class="w"> </span><span class="n">description</span><span class="w"> </span><span class="n">that</span>
<span class="w">    </span><span class="n">reflects</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">review</span><span class="s1">&#39;s preferences, writing style, and thematic interests.</span>
<span class="n">Examples</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">Persona</span><span class="w"> </span><span class="n">Descriptions</span><span class="p">:</span>
<span class="n">You</span><span class="w"> </span><span class="n">are</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">movie</span><span class="w"> </span><span class="n">critic</span><span class="p">,</span><span class="w"> </span><span class="n">specializing</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">horror</span><span class="w"> </span><span class="n">movies</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span><span class="n">independent</span><span class="w"> </span><span class="n">films</span><span class="w"> </span><span class="n">with</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">focus</span><span class="w"> </span><span class="n">on</span>
<span class="w">    </span><span class="n">cinematography</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span><span class="n">storytelling</span><span class="o">.</span>
<span class="n">You</span><span class="w"> </span><span class="n">are</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">casual</span><span class="w"> </span><span class="n">viewer</span><span class="w"> </span><span class="n">who</span><span class="w"> </span><span class="n">enjoys</span><span class="w"> </span><span class="n">action</span><span class="o">-</span><span class="n">packed</span><span class="w"> </span><span class="n">films</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span><span class="n">writes</span><span class="w"> </span><span class="n">personal</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span><span class="n">informal</span><span class="w"> </span><span class="n">reviews</span><span class="o">.</span>
<span class="n">List</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">reviews</span><span class="p">:</span>
<span class="p">{</span><span class="n">examples</span><span class="p">}</span>
<span class="n">Generate</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">short</span><span class="w"> </span><span class="n">persona</span><span class="w"> </span><span class="n">description</span><span class="w"> </span><span class="n">that</span><span class="w"> </span><span class="n">synthesizes</span><span class="w"> </span><span class="n">their</span><span class="w"> </span><span class="n">focus</span><span class="p">,</span><span class="w"> </span><span class="n">preferences</span><span class="p">,</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span><span class="n">stylistic</span>
<span class="w">    </span><span class="n">tendencies</span><span class="w"> </span><span class="n">into</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">single</span><span class="w"> </span><span class="n">cohesive</span>
<span class="w">    </span><span class="n">statement</span><span class="o">.&lt;|</span><span class="n">eot_id</span><span class="o">|&gt;&lt;|</span><span class="n">start_header_id</span><span class="o">|&gt;</span><span class="n">assistant</span><span class="o">&lt;|</span><span class="n">end_header_id</span><span class="o">|&gt;</span>
<span class="n">The</span><span class="w"> </span><span class="n">short</span><span class="w"> </span><span class="n">persona</span><span class="w"> </span><span class="k">is</span><span class="p">:</span>
</code></pre></div>

<p>Figure 13: MoP Prompt to classify persona for AgNews</p>
<div class="codehilite"><pre><span></span><code><span class="o">&lt;|</span><span class="n">begin_of_text</span><span class="o">|&gt;&lt;|</span><span class="n">start_header_id</span><span class="o">|&gt;</span><span class="n">system</span><span class="o">&lt;|</span><span class="n">end_header_id</span><span class="o">|&gt;</span>
<span class="n">You</span><span class="w"> </span><span class="n">are</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">helpful</span><span class="w"> </span><span class="n">AI</span><span class="w"> </span><span class="n">assistant</span><span class="o">&lt;|</span><span class="n">eot_id</span><span class="o">|&gt;&lt;|</span><span class="n">start_header_id</span><span class="o">|&gt;</span><span class="n">user</span><span class="o">&lt;|</span><span class="n">end_header_id</span><span class="o">|&gt;</span>
<span class="n">Given</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">persona</span><span class="w"> </span><span class="n">description</span><span class="w"> </span><span class="k">of</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">reporter</span><span class="o">,</span><span class="w"> </span><span class="n">choose</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">specialization</span><span class="w"> </span><span class="k">of</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">personas</span><span class="o">:</span><span class="w"> </span><span class="n">world</span><span class="w"> </span><span class="n">news</span><span class="o">,</span>
<span class="w">    </span><span class="n">sports</span><span class="w"> </span><span class="n">news</span><span class="o">,</span><span class="w"> </span><span class="n">business</span><span class="w"> </span><span class="n">news</span><span class="o">,</span><span class="w"> </span><span class="n">sci</span><span class="o">/</span><span class="n">tech</span><span class="w"> </span><span class="n">news</span><span class="o">.</span>
<span class="n">Persona</span><span class="w"> </span><span class="n">description</span><span class="o">:</span><span class="w"> </span><span class="n">You</span><span class="w"> </span><span class="n">are</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">technology</span><span class="w"> </span><span class="n">reporter</span><span class="o">,</span><span class="w"> </span><span class="n">specializing</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">intersection</span><span class="w"> </span><span class="k">of</span><span class="w"> </span><span class="n">hardware</span><span class="w"> </span><span class="ow">and</span>
<span class="w">    </span><span class="n">software</span><span class="o">,</span><span class="w"> </span><span class="k">with</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">focus</span><span class="w"> </span><span class="n">on</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">PC</span><span class="w"> </span><span class="n">industry</span><span class="o">,</span><span class="w"> </span><span class="n">Linux</span><span class="o">,</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span><span class="n">major</span><span class="w"> </span><span class="n">tech</span><span class="w"> </span><span class="n">companies</span><span class="w"> </span><span class="n">like</span><span class="w"> </span><span class="n">Microsoft</span><span class="o">,</span>
<span class="w">    </span><span class="n">Apple</span><span class="o">,</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span><span class="nn">IBM</span><span class="p">.</span>
<span class="n">Options</span><span class="o">:</span>
<span class="nn">A</span><span class="p">.</span><span class="w"> </span><span class="n">world</span><span class="w"> </span><span class="n">news</span>
<span class="nn">B</span><span class="p">.</span><span class="w"> </span><span class="n">sports</span><span class="w"> </span><span class="n">news</span>
<span class="nn">C</span><span class="p">.</span><span class="w"> </span><span class="n">business</span><span class="w"> </span><span class="n">news</span>
<span class="nn">D</span><span class="p">.</span><span class="w"> </span><span class="n">sci</span><span class="o">/</span><span class="n">tech</span><span class="w"> </span><span class="n">news</span>
<span class="n">Answer</span><span class="o">:</span><span class="w"> </span><span class="n">D</span>
<span class="n">Persona</span><span class="w"> </span><span class="n">description</span><span class="o">:</span><span class="w"> </span><span class="o">{}</span>
<span class="n">Options</span><span class="o">:</span>
<span class="nn">A</span><span class="p">.</span><span class="w"> </span><span class="n">world</span><span class="w"> </span><span class="n">news</span>
<span class="nn">B</span><span class="p">.</span><span class="w"> </span><span class="n">sports</span><span class="w"> </span><span class="n">news</span>
<span class="nn">C</span><span class="p">.</span><span class="w"> </span><span class="n">business</span><span class="w"> </span><span class="n">news</span>
<span class="nn">D</span><span class="p">.</span><span class="w"> </span><span class="n">sci</span><span class="o">/</span><span class="n">tech</span><span class="w"> </span><span class="n">news</span>
<span class="n">Answer</span><span class="o">:</span><span class="w"> </span><span class="o">&lt;|</span><span class="n">eot_id</span><span class="o">|&gt;&lt;|</span><span class="n">start_header_id</span><span class="o">|&gt;</span><span class="n">assistant</span><span class="o">&lt;|</span><span class="n">end_header_id</span><span class="o">|&gt;</span>
</code></pre></div>

<p>Figure 14: MoP Prompt to mix personas for AgNews</p>
<div class="codehilite"><pre><span></span><code><span class="err">&lt;</span>|begin_of_text|&gt;<span class="err">&lt;</span>/start_header_id|&gt;system<span class="err">&lt;</span>|end_header_id|&gt;
You<span class="w"> </span>are<span class="w"> </span>a<span class="w"> </span>highly<span class="w"> </span>capable<span class="w"> </span>and<span class="w"> </span>insightful<span class="w"> </span>AI
<span class="w">    </span>assistant<span class="err">&lt;</span>|eot_id|&gt;<span class="err">&lt;</span>|start_header_id|&gt;user<span class="err">&lt;</span>|end_header_id|&gt;
Given<span class="w"> </span>a<span class="w"> </span>list<span class="w"> </span>of<span class="w"> </span>persona<span class="w"> </span>descriptions<span class="w"> </span>of<span class="w"> </span>a<span class="w"> </span>reporter<span class="w"> </span>and<span class="w"> </span>a<span class="w"> </span>list<span class="w"> </span>of<span class="w"> </span>news<span class="w"> </span>blurbs<span class="w"> </span>he/she<span class="w"> </span>has<span class="w"> </span>written,
<span class="w">    </span>construct<span class="w"> </span>a<span class="w"> </span>concise<span class="w"> </span>persona<span class="w"> </span>description<span class="w"> </span>that<span class="w"> </span>reflects<span class="w"> </span>the<span class="w"> </span>reporter&#39;s<span class="w"> </span>primary<span class="w"> </span>focus,<span class="w"> </span>style,<span class="w"> </span>and
<span class="w">    </span>thematic<span class="w"> </span>interests.
Example<span class="w"> </span>persona<span class="w"> </span>descriptions:
You<span class="w"> </span>are<span class="w"> </span>a<span class="w"> </span>sports<span class="w"> </span>reporter,<span class="w"> </span>specializing<span class="w"> </span>in<span class="w"> </span>baseball<span class="w"> </span>news,<span class="w"> </span>with<span class="w"> </span>a<span class="w"> </span>focus<span class="w"> </span>on<span class="w"> </span>the<span class="w"> </span>Major<span class="w"> </span>League<span class="w"> </span>Baseball
<span class="w">    </span>(MLB)<span class="w"> </span>playoffs<span class="w"> </span>and<span class="w"> </span>postseason<span class="w"> </span>games.
Inputs:
1.<span class="w"> </span>List<span class="w"> </span>of<span class="w"> </span>persona<span class="w"> </span>descriptions:<span class="w"> </span>A<span class="w"> </span>list<span class="w"> </span>of<span class="w"> </span>general<span class="w"> </span>persona<span class="w"> </span>characteristics<span class="w"> </span>previously<span class="w"> </span>associated
<span class="w">        </span>with<span class="w"> </span>the<span class="w"> </span>reporter.
2.<span class="w"> </span>List<span class="w"> </span>of<span class="w"> </span>news<span class="w"> </span>blurbs:<span class="w"> </span>A<span class="w"> </span>selection<span class="w"> </span>of<span class="w"> </span>sample<span class="w"> </span>news<span class="w"> </span>blurbs<span class="w"> </span>authored<span class="w"> </span>by<span class="w"> </span>the<span class="w"> </span>reporter,<span class="w"> </span>which<span class="w"> </span>reveal
<span class="w">        </span>their<span class="w"> </span>tone,<span class="w"> </span>thematic<span class="w"> </span>focus,<span class="w"> </span>and<span class="w"> </span>writing<span class="w"> </span>style.
Using<span class="w"> </span>the<span class="w"> </span>inputs,<span class="w"> </span>generate<span class="w"> </span>a<span class="w"> </span>short<span class="w"> </span>persona<span class="w"> </span>description<span class="w"> </span>that<span class="w"> </span>synthesizes<span class="w"> </span>their<span class="w"> </span>focus,<span class="w"> </span>preferences,
<span class="w">        </span>and<span class="w"> </span>stylistic<span class="w"> </span>tendencies<span class="w"> </span>into<span class="w"> </span>a<span class="w"> </span>single<span class="w"> </span>cohesive<span class="w"> </span>statement.
List<span class="w"> </span>of<span class="w"> </span>persona<span class="w"> </span>descriptions:
{personas}
List<span class="w"> </span>of<span class="w"> </span>news<span class="w"> </span>blurbs:
{examples}
Please<span class="w"> </span>provide<span class="w"> </span>the<span class="w"> </span>short<span class="w"> </span>persona<span class="w"> </span>description.<span class="err">&lt;</span>|eot_id|&gt;<span class="err">&lt;</span>|start_header_id|&gt;assistant<span class="err">&lt;</span>|end_header_id|&gt;
The<span class="w"> </span>short<span class="w"> </span>persona<span class="w"> </span>is:
</code></pre></div>

<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>${ }^{3}$ sentence-transformers/all-mpnet-base-v2
${ }^{6}$ https://krishnap25.github.io/mauve/&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref3:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>