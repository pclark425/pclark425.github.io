<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-2633 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-2633</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-2633</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-67.html">extraction-schema-67</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <p><strong>Paper ID:</strong> paper-6e4e90f5bb21d4770bbb4fae5ea655d5fd531872</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/6e4e90f5bb21d4770bbb4fae5ea655d5fd531872" target="_blank">Cost-effective materials discovery: Bayesian optimization across multiple information sources</a></p>
                <p><strong>Paper Venue:</strong> Materials Horizons</p>
                <p><strong>Paper TL;DR:</strong> Multi-information source Bayesian optimization and how it can be used to capture relevant information from cheap approximations to accelerate research in the materials sciences is studied.</p>
                <p><strong>Paper Abstract:</strong> Multi-information source Bayesian optimization and how it can be used to capture relevant information from cheap approximations to accelerate research in the materials sciences.</p>
                <p><strong>Cost:</strong> 0.023</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e2633.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e2633.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>PearsonKG</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>PearsonKG (csKG/PCM)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A multi-information-source Bayesian optimization algorithm combining a cost-sensitive Knowledge Gradient acquisition function with a Pearson-r based coregionalization surrogate (PCM) that requires no inter-source hyperparameters and prioritizes low-cost, informative evaluations.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>PearsonKG</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>PearsonKG pairs the cost-sensitive Knowledge Gradient (csKG) acquisition function with the Pearson-r Coregionalization Model (PCM) surrogate. PCM builds the inter-information-source coregionalization matrix from empirical Pearson correlation coefficients computed on data sampled at all information sources, removing the need to learn additional inter-source hyperparameters. csKG estimates the expected value of sampling a given (x, information source) pair and accounts for the sampling cost to choose the next query that maximizes expected improvement in the objective per unit cost. The combined system supports multi-information-source optimization (MISO) by selecting both which location x and which information source IS_i to sample next to efficiently attain a global optimum under a cost budget.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Computational materials science / global optimization problems (e.g., DFT geometry optimization, molecular optimization, combinatorial materials search)</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>Allocation is decided by the csKG acquisition function: at each step compute expected improvement (Knowledge Gradient) from sampling each candidate point x on each information source IS_i, divide/adjust by the estimated cost of that source, and pick the (x, IS_i) maximizing expected value per cost. The PCM surrogate provides posterior means and uncertainties across sources via a coregionalization matrix derived from Pearson-r coefficients (computed only on points sampled across all sources).</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td>Relative or absolute computational time / cost of a single evaluation on each information source (the paper uses explicit cost ratios, e.g., 1000:1, and CPU times in seconds for DFT levels to form cost estimates). Cumulative sampling cost (sum of per-evaluation costs) is tracked and used as the budget axis.</td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td>Knowledge Gradient (expected increase in the posterior estimate of the global optimum) evaluated per candidate (x, IS). The csKG variant incorporates cost-sensitivity (expected utility per unit cost).</td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td>Balancing arises from csKG: KG naturally trades exploration (sampling to reduce uncertainty where it could change the recommended optimum) and exploitation (sampling where the mean is already high), and csKG further biases selection by sampling cost—preferring cheaper samples when their expected contribution to KG per cost is high.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td>No explicit diversity diversification mechanism (e.g., penalized similarity or batch diversity) is described; diversity emerges implicitly from KG-driven exploration of uncertain regions and from sampling across multiple correlated sources.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td>Cumulative computational cost / wall-clock time budget (also implicit fixed-cost-per-evaluation budgeting and comparisons via cumulative cost to reach thresholds).</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td>The acquisition (csKG) directly incorporates per-source costs when ranking candidate queries, and performance is evaluated by the cumulative cost required to reach a predefined performance threshold (e.g., within X of global optimum). Initial hyperparameter training on multiple sources introduces an upfront cost which is accounted for in cumulative-cost comparisons.</td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td>Achievement of a performance threshold (e.g., reaching within 0.6 kcal/mol of lowest function evaluation for DFT geometry / reaching function value below a threshold for Rosenbrock). High-impact discoveries are operationalized as attaining the global optimum or a tight tolerance to it.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Reported metrics include mean cumulative cost to reach the threshold, standard deviation, and 99.9th-percentile cumulative cost. Example: In Rosenbrock benchmarks PearsonKG mean cost = 5 (in units scaled to expensive-source cost; Table 1), STD = 1, 99.9th%-tile = 5; In CO geometry optimization PearsonKG mean ~= 15 (time-scaled units), STD = 8, 99.9th%-tile = 38; In HOIP benchmark PearsonKG mean = 70 (time-scaled units) for Hybrid-1 vs GGA-1 case (see Tables 1-4).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Compared primarily to EGO (EI/GPR baseline) and to other MISO variants: misoKG (csKG/MGP) and MultiTaskKG (csKG/ICM).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>PearsonKG often outperforms EGO and other MISO variants: e.g., ~80% improvement over EGO on Rosenbrock in many settings; in CO geometry optimization, MISO methods (including PearsonKG) reduce mean cost by ~52% over EGO and give 71–76% improvement at the 99.9th percentile; PearsonKG frequently yields the best 99.9th-percentile robustness (Table 1-2).</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td>Reported efficiency gains include up to ~80% reduction in cumulative cost vs EGO on Rosenbrock benchmarks, ~52% mean cost reduction for CO geometry optimization, and up to ~76% improvement in 99.9th-percentile cost in certain DFT geometry cases (see Tables 1 and 2).</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td>The paper analyzes how source correlation and noise affect tradeoffs: high inter-source correlation and low noise favor MISO/PCM approaches (large efficiency gains); noisy or poorly correlated sources reduce or eliminate benefit, sometimes making traditional EGO preferable. It also discusses upfront hyperparameter training cost and how requiring intersection points across sources can create an initial cost offset.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td>Key recommendations: use csKG with PCM (PearsonKG) when alternative sources are well correlated with the target (so cheap samples reliably inform the expensive model) and when information sources share similar kernel hyperparameters; avoid MISO when sources are poorly correlated or highly noisy (EGO may be better). PCM reduces hyperparameter complexity and scales better because it generates coregionalization from empirical Pearson correlations, lowering risk of poor hyperparameter fits.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Cost-effective materials discovery: Bayesian optimization across multiple information sources', 'publication_date_yy_mm': '2020-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2633.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e2633.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>misoKG</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>misoKG (csKG/MGP)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A previously proposed multi-information-source Bayesian optimization instantiation combining the cost-sensitive Knowledge Gradient acquisition function with a multivariate Gaussian process (MGP) surrogate; designed to select costly vs cheap information sources to optimize objectives under budget constraints.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>misoKG</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>misoKG uses the csKG acquisition function with a multivariate Gaussian process regression (MGP) surrogate model. The MGP learns inter-source relationships via learned hyperparameters (which scale with the number of information sources) and provides posterior predictive means and uncertainties. csKG ranks candidate (x, IS) queries by expected value (Knowledge Gradient) adjusted for sampling cost, to select the next evaluation that maximizes expected improvement per cost.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>General multi-information-source optimization; applied here to benchmark optimization problems (Rosenbrock), molecular geometry optimization, and materials discovery tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>Select (x, IS) with highest cost-sensitive Knowledge Gradient using the MGP posterior; hyperparameters for inter-source covariance must be estimated (MLE/MAP) from multi-source training data which can require initial sampling across sources.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td>Per-evaluation computational cost expressed as relative cost ratios (e.g., 1000:1) or measured CPU time; cumulative cost tracked to measure efficiency.</td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td>Knowledge Gradient computed from the MGP posterior (expected one-step improvement in the estimated optimum), with a cost-sensitive modification (csKG) to incorporate per-source cost.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td>KG provides the exploration/exploitation tradeoff by valuing reductions in posterior uncertainty that might change the recommended optimum (exploration) vs sampling to improve high-mean areas (exploitation); cost weighting encourages cheaper informative samples.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td>No explicit diversity mechanism beyond the implicit exploratory behavior of KG and multiple sources; diversity of sampled hypotheses depends on KG uncertainty terms and the surrogate posterior.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td>Cumulative computational cost budget (time/cost per evaluation).</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td>csKG ranks queries by expected utility per unit cost; experiments and plots compare cumulative cost required to reach performance thresholds, and hyperparameter-training strategies are discussed (intersection vs costly-only training sets).</td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td>Thresholded attainment of global optimum or near-optimal objective value (same operationalization as other methods in the paper).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Mean cumulative cost, STD, and 99.9th-percentile cumulative cost to reach thresholds (see Tables 1-2). Example: in Rosenbrock tests misoKG mean cost reported as 13 (costly training) vs EGO 25 (Table 1); misoKG shows improvements but is generally outperformed by PearsonKG in robustness metrics.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>EGO (EI/GPR), PearsonKG (csKG/PCM), MultiTaskKG (csKG/ICM).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>misoKG outperforms EGO in many tested settings (e.g., Rosenbrock mean cost 13 vs EGO 25 under certain training), but is typically less robust than PCM-based PearsonKG due to larger hyperparameter complexity and sensitivity.</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td>Observed efficiency gains in experiments include reductions in mean cumulative cost vs EGO (e.g., from 25 to 13 in a Rosenbrock setup with costly-only hyperparameter training), though gains vary with source correlation and noise.</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td>Paper highlights that MGP requires a larger hyperparameter space which can make learning difficult (noisy landscape); thus misoKG benefits when hyperparameters can be well-trained (intersection training) but suffers when hyperparameter estimation is poor—tradeoffs between model expressiveness and hyperparameter learning complexity.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td>misoKG works well when inter-source relationships can be adequately learned and when sources are moderately correlated; however, due to hyperparameter scaling with number of sources, simpler coregionalization (PCM) or ICM may be preferable for scalability and robustness.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Cost-effective materials discovery: Bayesian optimization across multiple information sources', 'publication_date_yy_mm': '2020-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2633.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e2633.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>MultiTaskKG</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>MultiTaskKG (csKG/ICM)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A multi-information-source Bayesian optimization variant pairing csKG with the Intrinsic Coregionalization Model (ICM) surrogate to capture inter-source covariance with a compact parameterization for coregionalization.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>MultiTaskKG</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>MultiTaskKG uses csKG as the acquisition and ICM as the surrogate. ICM models the joint covariance as a Kronecker product K = K_s ⊗ K_x, where K_s (the coregionalization matrix) is parameterized via a low-rank factorization L L^T (or equivalent), adding at most m(m+1)/2 coregionalization parameters for m sources. csKG ranks (x, IS) queries by expected informational value adjusted for cost using the ICM posterior.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Multi-source Bayesian optimization for materials and computational chemistry problems (benchmarked on Rosenbrock, CO geometry, HOIP problems).</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>Select next (x, IS) via csKG computed on the ICM posterior that encodes inter-source covariance through learned coregionalization parameters; hyperparameters include kernel parameters and K_s factors, typically learned via MLE/MAP using data across sources.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td>Per-evaluation computational time/cost (relative ratios and cumulative cost used for performance evaluation).</td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td>Knowledge Gradient computed with the ICM surrogate's posterior mean and covariance; cost-sensitive KG used to incorporate sampling costs.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td>KG-driven tradeoff between reducing uncertainty (exploration) and sampling promising high-mean regions (exploitation), with cost weighting favoring informative cheap evaluations.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td>No explicit diversity enforcement; exploration arises from uncertainty modeled in the ICM posterior.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td>Cumulative computational cost (time) budget; experiments report cost-to-threshold.</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td>csKG ranks actions by expected utility per cost; ICM hyperparameters are trained on intersection or costly-only datasets which affects initial sampling cost and subsequent allocation.</td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td>Attainment of objective thresholds (e.g., within 0.6 kcal/mol of best energy) or reaching global optimum value in benchmark functions.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Mean cost, STD, and 99.9th-percentile cost. Example: in CO optimization MultiTaskKG mean = 15 (time-scaled units), STD = 9, 99.9th%-tile = 46; it outperforms EGO on mean and tail metrics in correlated-source cases.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>EGO (EI/GPR), misoKG (csKG/MGP), PearsonKG (csKG/PCM).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>MultiTaskKG performs substantially better than EGO when sources are well correlated (e.g., CO geometry), but is generally comparable to or slightly worse than PearsonKG which avoids extra inter-source hyperparameters.</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td>Reductions in mean and tail cumulative cost relative to EGO in well-correlated settings (e.g., ~52% mean cost reduction vs EGO in CO geometry optimization aggregated over MISO methods).</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td>ICM provides a compact coregionalization parameterization (fewer hyperparameters than full MGP) but still requires learning inter-source parameters; success depends on adequate training data across sources and on source correlation strength.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td>ICM-based MISO with csKG is effective when sources are correlated and when the number of inter-source parameters is manageable; users should ensure good training across sources and consider PCM when they wish to avoid learning additional inter-source hyperparameters.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Cost-effective materials discovery: Bayesian optimization across multiple information sources', 'publication_date_yy_mm': '2020-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2633.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e2633.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>csKG</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Cost-sensitive Knowledge Gradient (csKG)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An acquisition function extension of the Knowledge Gradient that explicitly incorporates per-evaluation cost to choose the next (x, information source) maximizing expected improvement per unit cost.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>csKG (cost-sensitive Knowledge Gradient)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>csKG computes the expected one-step improvement in the estimated global optimum (the Knowledge Gradient) for sampling a candidate (x, IS) based on the surrogate posterior, then adjusts/ranks candidates by their sampling cost (e.g., expected improvement per unit cost). csKG supports multi-information-source optimization by comparing different information sources with differing accuracies and costs and selecting the most cost-effective next evaluation.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Active learning and experimental design across heterogeneous information sources in computational materials science and general black-box optimization.</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>At each iteration, compute the expected value (KG) of sampling each candidate and information source and divide/weight by the source's cost to select the next sample that maximizes expected utility per cost; falls back to ordinary KG when no inter-source correlation is learned.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td>Per-evaluation cost measured as wall-clock computational time or a relative cost unit (e.g., cost ratios such as 1000:1), summed over queries to produce cumulative cost.</td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td>Knowledge Gradient — expected single-step increase in the posterior estimate of the optimum value, computed using the surrogate model's posterior mean and variance.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td>KG inherently balances exploration and exploitation by valuing potential changes to the recommended optimum due to uncertainty; csKG further biases towards cheaper sources that deliver good expected KG per cost, indirectly promoting cost-aware exploration.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td>No dedicated diversity module; diversity is a byproduct of selecting points with high expected KG which often correspond to uncertain regions.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td>Cumulative computational cost / evaluation budget.</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td>csKG explicitly factors sampling cost into acquisition ranking; performance is measured by cumulative cost to reach thresholds; initial multi-source training costs are accounted for in cumulative-cost analyses.</td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td>Same as other methods: reaching a specified performance threshold (e.g., global optimum or within X of it) is used to define success/breakthrough.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Used in combination with different surrogates; performance is reported as cumulative cost (mean, STD, tail percentiles) to reach thresholds across benchmarks.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Compared to EI (EGO) where KG is replaced by EI and to KG without cost-sensitivity.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>csKG-based MISO variants outperform EI/GPR (EGO) in many benchmark settings when cheap correlated sources exist, reducing cumulative cost to target; when sources are poorly correlated or noisy, csKG's advantage diminishes and it can default to KG-like behavior.</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td>Contributes to the reported efficiency gains of MISO methods: e.g., combined with PCM leads to up to ~80% reduction vs EGO in Rosenbrock tests, and ~52% mean reduction in CO geometry examples (these gains are attributable to cost-sensitivity and multi-source exploitation).</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td>The paper discusses how csKG's cost-aware ranking interacts with source correlation and surrogate hyperparameters: when surrogate hyperparameters are poorly estimated or sources correlate weakly, csKG's benefits shrink; csKG mitigates cost vs information tradeoffs by formalizing expected information per cost.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td>csKG is recommended when multiple information sources with different costs and correlations are available; it should be paired with surrogates that either reliably learn inter-source relations (MGP/ICM) or with PCM when robust empirical correlation estimates can be obtained to avoid complex hyperparameter learning.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Cost-effective materials discovery: Bayesian optimization across multiple information sources', 'publication_date_yy_mm': '2020-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2633.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e2633.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>PCM</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Pearson-r Coregionalization Model (PCM)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A surrogate-model coregionalization approach that builds the inter-information-source covariance matrix directly from empirical Pearson correlation coefficients, eliminating the need to learn inter-source hyperparameters.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Pearson-r Coregionalization Model (PCM)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>PCM constructs the coregionalization matrix K_s by computing Pearson-r correlation coefficients (ρ) between information-source outputs at points that were sampled across all sources, and placing those ρ values into K_s (diagonals set to 1). K_s is then combined with the input kernel K_x via Kronecker product (K = K_s ⊗ K_x) to produce a multi-source Gaussian-process prior without introducing extra inter-source hyperparameters. This reduces hyperparameter dimensionality and improves scalability and robustness when sources are well correlated.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Multi-information-source surrogate modeling for Bayesian optimization in materials science and computational chemistry.</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>Used as the surrogate within csKG-driven MISO; resource allocation (which source to sample) is determined by csKG using the PCM posterior (means and variances) which reflect inter-source correlations via empirically estimated ρ values.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td>Same per-evaluation cost measures used in MISO (wall-clock time, relative cost units); PCM itself reduces computational overhead by avoiding hyperparameter optimization for inter-source covariance.</td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td>The surrogate supplies posterior predictive variances and covariances used by KG/csKG to compute expected information gain (Knowledge Gradient).</td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td>Exploration/exploitation handled by csKG using PCM-derived posteriors; PCM's empirical correlations shape where uncertainty reduction on cheap sources transfers to the expensive source, affecting exploratory value.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td>No explicit diversity mechanisms; PCM indirectly affects diversity by modulating posterior covariance structure based on empirical inter-source correlations.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td>Cumulative computational cost (indirectly supported through its use with csKG).</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td>PCM reduces hyperparameter estimation cost and instability, lowering the upfront sampling/training cost needed to obtain reliable inter-source covariance estimates; used with csKG to select cost-effective queries.</td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td>Operationalized via attainment of optimization thresholds (same as other methods); PCM improves reliability to reach thresholds under cost constraints when sources are correlated.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>In benchmarks PCM (PearsonKG) yields lower mean and tail cumulative cost versus other surrogates. Example: Rosenbrock PearsonKG mean cost = 5, STD = 1 (intersection training), 99.9th%-tile = 5 (Table 1).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Compared to learned coregionalization approaches (ICM, MGP) and to single-source EGO (EI/GPR).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>PCM-based PearsonKG tends to outperform MGP and ICM variants in robustness (tail percentiles) and often in mean cumulative cost when information sources are well correlated, due to avoiding difficult inter-source hyperparameter learning.</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td>Contributes to the reported large efficiency gains (e.g., up to ~80% over EGO in Rosenbrock; significant reductions in worst-case tail costs compared to MGP/ICM).</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td>PCM trades off model flexibility for robustness and scalability: by using empirical correlations it reduces hyperparameter complexity (good when sufficient intersecting data exist and sources are well correlated) but may be less flexible if correlations vary across input space or if intersecting data are scarce.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td>PCM is recommended when information sources are globally well correlated and when practitioners wish to avoid expensive inter-source hyperparameter estimation; it is combined with csKG to make cost-aware allocation decisions that favor cheap informative evaluations.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Cost-effective materials discovery: Bayesian optimization across multiple information sources', 'publication_date_yy_mm': '2020-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2633.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e2633.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>EGO</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Efficient Global Optimization (EGO) — EI/GPR</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A standard single-source Bayesian optimization baseline that combines Expected Improvement (EI) acquisition with Gaussian Process Regression (GPR) surrogate modeling, commonly used for black-box expensive function optimization.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>EGO (EI/GPR)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>EGO uses a GPR surrogate trained on the expensive information source only and selects the next sampling point by maximizing the Expected Improvement acquisition function. It does not consider cheaper alternative information sources nor per-evaluation cost differences between sources.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>General black-box expensive function optimization (DFT geometry optimization, global optimization benchmarks).</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>Select the next x to evaluate on the single (expensive) information source by maximizing Expected Improvement; allocation is constrained to the expensive source only (no multi-source selection).</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td>Cumulative cost measured by summing costly evaluations (wall-clock time), since only expensive source is used.</td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td>Expected Improvement (EI) quantifying expected positive improvement over current best value; not directly cost-aware.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td>EI trades off exploration and exploitation by valuing points with either high predicted mean or high uncertainty, but without explicit cost-sensitivity or multi-source exploration.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td>No explicit diversity promotion beyond inherent EI-driven exploration.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td>Fixed cumulative cost/time implicitly via limit on number of expensive evaluations; comparisons measured by cumulative expensive-evaluation cost.</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td>EGO cannot choose cheaper sources; handling is simply to continue until budget exhausted or threshold reached, so it often incurs higher cumulative cost compared to csKG-based MISO when cheaper correlated sources exist.</td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td>Same threshold-based attainment (e.g., achieve value within tolerance of global optimum).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Baseline metrics reported include mean cumulative cost, STD, and 99.9th-percentile to reach thresholds. Example: Rosenbrock EGO mean = 25, STD = 21, 99.9th%-tile = 100 (Table 1); CO geometry EGO mean = 31, STD = 24, 99.9th%-tile = 156 (Table 2).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Acts as the baseline for comparisons; other MISO approaches are compared against EGO.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>MISO methods (csKG-based) outperform EGO in many scenarios with cheap correlated sources: e.g., ~80% improvement on Rosenbrock and ~52% average cost reduction on CO geometry; when sources are poorly correlated or noisy, EGO can match or outperform MISO variants.</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td>EGO is less efficient in multi-source settings; other methods report up to ~80% reductions in cumulative cost relative to EGO when multi-source, cost-aware sampling is exploited.</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td>EGO's lack of multi-source capability and cost-awareness leads to higher costs where cheaper correlated information exists; however, EGO can be preferable when no reliable cheaper sources exist or when inter-source correlations are weak/noisy.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td>EGO is the appropriate default when only the expensive single source is reliable or when alternative sources are poorly correlated/noisy; otherwise, cost-sensitive multi-source approaches are recommended.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Cost-effective materials discovery: Bayesian optimization across multiple information sources', 'publication_date_yy_mm': '2020-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2633.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e2633.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>MGP</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Multivariate Gaussian Process Regression (MGP)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A multivariate GP surrogate that models multiple information sources jointly by learning full inter-source covariance/hyperparameters, used previously in misoKG for MISO.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Multivariate Gaussian Process (MGP)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>MGP extends Gaussian process regression to vector-valued outputs (multiple information sources) by learning separate kernel hyperparameters per source and inter-source covariance structure; the number of hyperparameters grows with the number of sources, making training more challenging. In misoKG it provides predictive means and uncertainties across sources for csKG to evaluate expected information gain.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Multi-information-source surrogate modeling for Bayesian optimization in scientific computing and materials problems.</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>Used as the surrogate supplying posterior predictions to csKG which then ranks (x, IS) queries by expected KG per cost.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td>Per-evaluation computational time (used externally for csKG ranking); MGP increases model-training computational cost due to larger hyperparameter space.</td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td>Predictive variances and covariances from MGP are used to compute Knowledge Gradient.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td>KG/csKG on top of MGP balances exploration/exploitation; MGP's learned covariances determine how informative cheap-source samples are about expensive source.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td>No explicit diversity promotion beyond surrogate-modeled uncertainty.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td>Cumulative evaluation cost (implicitly handled by csKG when MGP used in misoKG).</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td>MGP itself does not handle budget constraints; csKG uses MGP outputs to handle cost-sensitive selection.</td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td>Same threshold-based metrics used elsewhere (cumulative cost to reach performance thresholds).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Reported as part of misoKG comparisons; MGP-based misoKG shows improvements vs EGO but is sensitive to hyperparameter training strategy (intersection vs costly-only). Example: misoKG mean costs vary from 5 to 13 in Rosenbrock scenarios depending on hyperparameter training (Table 1).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Compared to ICM and PCM surrogates under csKG as well as to single-source EGO.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>MGP can perform well when hyperparameters are well-trained (intersection training), but suffers when the hyperparameter landscape is large/noisy, making PCM or ICM preferable in some settings.</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td>Variable; can match other MISO gains when adequately trained but is less robust in high-dimensional hyperparameter scenarios.</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td>Paper highlights the tradeoff between representational flexibility (MGP can model complex inter-source structure) and the difficulty of learning many hyperparameters (risking poor performance and higher model-training cost).</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td>Use MGP when one can obtain sufficient intersecting data to reliably learn inter-source hyperparameters; otherwise prefer simpler coregionalization approaches (ICM) or empirical PCM.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Cost-effective materials discovery: Bayesian optimization across multiple information sources', 'publication_date_yy_mm': '2020-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2633.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e2633.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ICM</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Intrinsic Coregionalization Model (ICM)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A coregionalization surrogate model that represents inter-source covariance via a compact coregionalization matrix (K_s) factorized as L L^T and combined with an input kernel via Kronecker product to support multi-task Gaussian process modeling.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Intrinsic Coregionalization Model (ICM)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>ICM models multi-source covariance as K = K_s ⊗ K_x where K_s is a PSD coregionalization matrix (often parameterized as L L^T), capturing linear mixing of latent functions across sources. ICM introduces up to m(m+1)/2 inter-source parameters for m sources, offering a compromise between MGP flexibility and PCM simplicity.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Multi-task (multi-information-source) surrogate modeling for Bayesian optimization in materials and computational chemistry.</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>When used with csKG (MultiTaskKG), ICM provides multi-source posterior predictions that csKG uses to select cost-effective sampling across information sources.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td>Per-evaluation time/cost for each information source (as used by csKG); ICM itself incurs model training cost for fitting L factors.</td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td>Posterior predictive variance/covariance used by KG/csKG to compute expected information gain.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td>Exploration/exploitation balanced by csKG using ICM posterior; ICM's learned cross-source structure determines transferability of cheap-source information.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td>No explicit diversity module; exploration emerges from modeled uncertainties.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td>Cumulative computational cost/time (handled via csKG when used for allocation).</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td>csKG uses ICM outputs to make cost-aware selections; ICM reduces number of inter-source hyperparameters compared to full MGP but still requires fitting.</td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td>Same threshold-based metrics; ICM-based csKG methods improve attainment cost when sources correlate sufficiently.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Reported mean, STD, and tail cumulative cost metrics. Example: in CO geometry optimization MultiTaskKG (ICM) mean = 15, STD = 9, 99.9th%-tile = 46 (Table 2).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Compared against MGP, PCM, and single-source EGO.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>ICM often outperforms EGO in correlated-source settings and is competitive with PCM but can be outperformed by PCM particularly in tail robustness when PCM uses reliable empirical correlation estimates.</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td>Provides reductions in cost vs EGO in well-correlated cases (numerical reductions shown in Tables 1-4).</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td>ICM reduces hyperparameter scaling relative to full MGP but still requires learning coregionalization parameters; success depends on data sufficiency across sources and correlation strength.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td>ICM is a practical option when one prefers a parametric learned coregionalization (fewer parameters than MGP) but when empirical PCM is not applicable or when correlations vary spatially and require learned structure.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Cost-effective materials discovery: Bayesian optimization across multiple information sources', 'publication_date_yy_mm': '2020-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>A Tutorial on Bayesian Optimization <em>(Rating: 2)</em></li>
                <li>Kernels for Vector-Valued Functions: a Review <em>(Rating: 2)</em></li>
                <li>Multi-task Bayesian optimization <em>(Rating: 2)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-2633",
    "paper_id": "paper-6e4e90f5bb21d4770bbb4fae5ea655d5fd531872",
    "extraction_schema_id": "extraction-schema-67",
    "extracted_data": [
        {
            "name_short": "PearsonKG",
            "name_full": "PearsonKG (csKG/PCM)",
            "brief_description": "A multi-information-source Bayesian optimization algorithm combining a cost-sensitive Knowledge Gradient acquisition function with a Pearson-r based coregionalization surrogate (PCM) that requires no inter-source hyperparameters and prioritizes low-cost, informative evaluations.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "PearsonKG",
            "system_description": "PearsonKG pairs the cost-sensitive Knowledge Gradient (csKG) acquisition function with the Pearson-r Coregionalization Model (PCM) surrogate. PCM builds the inter-information-source coregionalization matrix from empirical Pearson correlation coefficients computed on data sampled at all information sources, removing the need to learn additional inter-source hyperparameters. csKG estimates the expected value of sampling a given (x, information source) pair and accounts for the sampling cost to choose the next query that maximizes expected improvement in the objective per unit cost. The combined system supports multi-information-source optimization (MISO) by selecting both which location x and which information source IS_i to sample next to efficiently attain a global optimum under a cost budget.",
            "application_domain": "Computational materials science / global optimization problems (e.g., DFT geometry optimization, molecular optimization, combinatorial materials search)",
            "resource_allocation_strategy": "Allocation is decided by the csKG acquisition function: at each step compute expected improvement (Knowledge Gradient) from sampling each candidate point x on each information source IS_i, divide/adjust by the estimated cost of that source, and pick the (x, IS_i) maximizing expected value per cost. The PCM surrogate provides posterior means and uncertainties across sources via a coregionalization matrix derived from Pearson-r coefficients (computed only on points sampled across all sources).",
            "computational_cost_metric": "Relative or absolute computational time / cost of a single evaluation on each information source (the paper uses explicit cost ratios, e.g., 1000:1, and CPU times in seconds for DFT levels to form cost estimates). Cumulative sampling cost (sum of per-evaluation costs) is tracked and used as the budget axis.",
            "information_gain_metric": "Knowledge Gradient (expected increase in the posterior estimate of the global optimum) evaluated per candidate (x, IS). The csKG variant incorporates cost-sensitivity (expected utility per unit cost).",
            "uses_information_gain": true,
            "exploration_exploitation_mechanism": "Balancing arises from csKG: KG naturally trades exploration (sampling to reduce uncertainty where it could change the recommended optimum) and exploitation (sampling where the mean is already high), and csKG further biases selection by sampling cost—preferring cheaper samples when their expected contribution to KG per cost is high.",
            "diversity_mechanism": "No explicit diversity diversification mechanism (e.g., penalized similarity or batch diversity) is described; diversity emerges implicitly from KG-driven exploration of uncertain regions and from sampling across multiple correlated sources.",
            "uses_diversity_promotion": false,
            "budget_constraint_type": "Cumulative computational cost / wall-clock time budget (also implicit fixed-cost-per-evaluation budgeting and comparisons via cumulative cost to reach thresholds).",
            "budget_constraint_handling": "The acquisition (csKG) directly incorporates per-source costs when ranking candidate queries, and performance is evaluated by the cumulative cost required to reach a predefined performance threshold (e.g., within X of global optimum). Initial hyperparameter training on multiple sources introduces an upfront cost which is accounted for in cumulative-cost comparisons.",
            "breakthrough_discovery_metric": "Achievement of a performance threshold (e.g., reaching within 0.6 kcal/mol of lowest function evaluation for DFT geometry / reaching function value below a threshold for Rosenbrock). High-impact discoveries are operationalized as attaining the global optimum or a tight tolerance to it.",
            "performance_metrics": "Reported metrics include mean cumulative cost to reach the threshold, standard deviation, and 99.9th-percentile cumulative cost. Example: In Rosenbrock benchmarks PearsonKG mean cost = 5 (in units scaled to expensive-source cost; Table 1), STD = 1, 99.9th%-tile = 5; In CO geometry optimization PearsonKG mean ~= 15 (time-scaled units), STD = 8, 99.9th%-tile = 38; In HOIP benchmark PearsonKG mean = 70 (time-scaled units) for Hybrid-1 vs GGA-1 case (see Tables 1-4).",
            "comparison_baseline": "Compared primarily to EGO (EI/GPR baseline) and to other MISO variants: misoKG (csKG/MGP) and MultiTaskKG (csKG/ICM).",
            "performance_vs_baseline": "PearsonKG often outperforms EGO and other MISO variants: e.g., ~80% improvement over EGO on Rosenbrock in many settings; in CO geometry optimization, MISO methods (including PearsonKG) reduce mean cost by ~52% over EGO and give 71–76% improvement at the 99.9th percentile; PearsonKG frequently yields the best 99.9th-percentile robustness (Table 1-2).",
            "efficiency_gain": "Reported efficiency gains include up to ~80% reduction in cumulative cost vs EGO on Rosenbrock benchmarks, ~52% mean cost reduction for CO geometry optimization, and up to ~76% improvement in 99.9th-percentile cost in certain DFT geometry cases (see Tables 1 and 2).",
            "tradeoff_analysis": "The paper analyzes how source correlation and noise affect tradeoffs: high inter-source correlation and low noise favor MISO/PCM approaches (large efficiency gains); noisy or poorly correlated sources reduce or eliminate benefit, sometimes making traditional EGO preferable. It also discusses upfront hyperparameter training cost and how requiring intersection points across sources can create an initial cost offset.",
            "optimal_allocation_findings": "Key recommendations: use csKG with PCM (PearsonKG) when alternative sources are well correlated with the target (so cheap samples reliably inform the expensive model) and when information sources share similar kernel hyperparameters; avoid MISO when sources are poorly correlated or highly noisy (EGO may be better). PCM reduces hyperparameter complexity and scales better because it generates coregionalization from empirical Pearson correlations, lowering risk of poor hyperparameter fits.",
            "uuid": "e2633.0",
            "source_info": {
                "paper_title": "Cost-effective materials discovery: Bayesian optimization across multiple information sources",
                "publication_date_yy_mm": "2020-08"
            }
        },
        {
            "name_short": "misoKG",
            "name_full": "misoKG (csKG/MGP)",
            "brief_description": "A previously proposed multi-information-source Bayesian optimization instantiation combining the cost-sensitive Knowledge Gradient acquisition function with a multivariate Gaussian process (MGP) surrogate; designed to select costly vs cheap information sources to optimize objectives under budget constraints.",
            "citation_title": "",
            "mention_or_use": "use",
            "system_name": "misoKG",
            "system_description": "misoKG uses the csKG acquisition function with a multivariate Gaussian process regression (MGP) surrogate model. The MGP learns inter-source relationships via learned hyperparameters (which scale with the number of information sources) and provides posterior predictive means and uncertainties. csKG ranks candidate (x, IS) queries by expected value (Knowledge Gradient) adjusted for sampling cost, to select the next evaluation that maximizes expected improvement per cost.",
            "application_domain": "General multi-information-source optimization; applied here to benchmark optimization problems (Rosenbrock), molecular geometry optimization, and materials discovery tasks.",
            "resource_allocation_strategy": "Select (x, IS) with highest cost-sensitive Knowledge Gradient using the MGP posterior; hyperparameters for inter-source covariance must be estimated (MLE/MAP) from multi-source training data which can require initial sampling across sources.",
            "computational_cost_metric": "Per-evaluation computational cost expressed as relative cost ratios (e.g., 1000:1) or measured CPU time; cumulative cost tracked to measure efficiency.",
            "information_gain_metric": "Knowledge Gradient computed from the MGP posterior (expected one-step improvement in the estimated optimum), with a cost-sensitive modification (csKG) to incorporate per-source cost.",
            "uses_information_gain": true,
            "exploration_exploitation_mechanism": "KG provides the exploration/exploitation tradeoff by valuing reductions in posterior uncertainty that might change the recommended optimum (exploration) vs sampling to improve high-mean areas (exploitation); cost weighting encourages cheaper informative samples.",
            "diversity_mechanism": "No explicit diversity mechanism beyond the implicit exploratory behavior of KG and multiple sources; diversity of sampled hypotheses depends on KG uncertainty terms and the surrogate posterior.",
            "uses_diversity_promotion": false,
            "budget_constraint_type": "Cumulative computational cost budget (time/cost per evaluation).",
            "budget_constraint_handling": "csKG ranks queries by expected utility per unit cost; experiments and plots compare cumulative cost required to reach performance thresholds, and hyperparameter-training strategies are discussed (intersection vs costly-only training sets).",
            "breakthrough_discovery_metric": "Thresholded attainment of global optimum or near-optimal objective value (same operationalization as other methods in the paper).",
            "performance_metrics": "Mean cumulative cost, STD, and 99.9th-percentile cumulative cost to reach thresholds (see Tables 1-2). Example: in Rosenbrock tests misoKG mean cost reported as 13 (costly training) vs EGO 25 (Table 1); misoKG shows improvements but is generally outperformed by PearsonKG in robustness metrics.",
            "comparison_baseline": "EGO (EI/GPR), PearsonKG (csKG/PCM), MultiTaskKG (csKG/ICM).",
            "performance_vs_baseline": "misoKG outperforms EGO in many tested settings (e.g., Rosenbrock mean cost 13 vs EGO 25 under certain training), but is typically less robust than PCM-based PearsonKG due to larger hyperparameter complexity and sensitivity.",
            "efficiency_gain": "Observed efficiency gains in experiments include reductions in mean cumulative cost vs EGO (e.g., from 25 to 13 in a Rosenbrock setup with costly-only hyperparameter training), though gains vary with source correlation and noise.",
            "tradeoff_analysis": "Paper highlights that MGP requires a larger hyperparameter space which can make learning difficult (noisy landscape); thus misoKG benefits when hyperparameters can be well-trained (intersection training) but suffers when hyperparameter estimation is poor—tradeoffs between model expressiveness and hyperparameter learning complexity.",
            "optimal_allocation_findings": "misoKG works well when inter-source relationships can be adequately learned and when sources are moderately correlated; however, due to hyperparameter scaling with number of sources, simpler coregionalization (PCM) or ICM may be preferable for scalability and robustness.",
            "uuid": "e2633.1",
            "source_info": {
                "paper_title": "Cost-effective materials discovery: Bayesian optimization across multiple information sources",
                "publication_date_yy_mm": "2020-08"
            }
        },
        {
            "name_short": "MultiTaskKG",
            "name_full": "MultiTaskKG (csKG/ICM)",
            "brief_description": "A multi-information-source Bayesian optimization variant pairing csKG with the Intrinsic Coregionalization Model (ICM) surrogate to capture inter-source covariance with a compact parameterization for coregionalization.",
            "citation_title": "",
            "mention_or_use": "use",
            "system_name": "MultiTaskKG",
            "system_description": "MultiTaskKG uses csKG as the acquisition and ICM as the surrogate. ICM models the joint covariance as a Kronecker product K = K_s ⊗ K_x, where K_s (the coregionalization matrix) is parameterized via a low-rank factorization L L^T (or equivalent), adding at most m(m+1)/2 coregionalization parameters for m sources. csKG ranks (x, IS) queries by expected informational value adjusted for cost using the ICM posterior.",
            "application_domain": "Multi-source Bayesian optimization for materials and computational chemistry problems (benchmarked on Rosenbrock, CO geometry, HOIP problems).",
            "resource_allocation_strategy": "Select next (x, IS) via csKG computed on the ICM posterior that encodes inter-source covariance through learned coregionalization parameters; hyperparameters include kernel parameters and K_s factors, typically learned via MLE/MAP using data across sources.",
            "computational_cost_metric": "Per-evaluation computational time/cost (relative ratios and cumulative cost used for performance evaluation).",
            "information_gain_metric": "Knowledge Gradient computed with the ICM surrogate's posterior mean and covariance; cost-sensitive KG used to incorporate sampling costs.",
            "uses_information_gain": true,
            "exploration_exploitation_mechanism": "KG-driven tradeoff between reducing uncertainty (exploration) and sampling promising high-mean regions (exploitation), with cost weighting favoring informative cheap evaluations.",
            "diversity_mechanism": "No explicit diversity enforcement; exploration arises from uncertainty modeled in the ICM posterior.",
            "uses_diversity_promotion": false,
            "budget_constraint_type": "Cumulative computational cost (time) budget; experiments report cost-to-threshold.",
            "budget_constraint_handling": "csKG ranks actions by expected utility per cost; ICM hyperparameters are trained on intersection or costly-only datasets which affects initial sampling cost and subsequent allocation.",
            "breakthrough_discovery_metric": "Attainment of objective thresholds (e.g., within 0.6 kcal/mol of best energy) or reaching global optimum value in benchmark functions.",
            "performance_metrics": "Mean cost, STD, and 99.9th-percentile cost. Example: in CO optimization MultiTaskKG mean = 15 (time-scaled units), STD = 9, 99.9th%-tile = 46; it outperforms EGO on mean and tail metrics in correlated-source cases.",
            "comparison_baseline": "EGO (EI/GPR), misoKG (csKG/MGP), PearsonKG (csKG/PCM).",
            "performance_vs_baseline": "MultiTaskKG performs substantially better than EGO when sources are well correlated (e.g., CO geometry), but is generally comparable to or slightly worse than PearsonKG which avoids extra inter-source hyperparameters.",
            "efficiency_gain": "Reductions in mean and tail cumulative cost relative to EGO in well-correlated settings (e.g., ~52% mean cost reduction vs EGO in CO geometry optimization aggregated over MISO methods).",
            "tradeoff_analysis": "ICM provides a compact coregionalization parameterization (fewer hyperparameters than full MGP) but still requires learning inter-source parameters; success depends on adequate training data across sources and on source correlation strength.",
            "optimal_allocation_findings": "ICM-based MISO with csKG is effective when sources are correlated and when the number of inter-source parameters is manageable; users should ensure good training across sources and consider PCM when they wish to avoid learning additional inter-source hyperparameters.",
            "uuid": "e2633.2",
            "source_info": {
                "paper_title": "Cost-effective materials discovery: Bayesian optimization across multiple information sources",
                "publication_date_yy_mm": "2020-08"
            }
        },
        {
            "name_short": "csKG",
            "name_full": "Cost-sensitive Knowledge Gradient (csKG)",
            "brief_description": "An acquisition function extension of the Knowledge Gradient that explicitly incorporates per-evaluation cost to choose the next (x, information source) maximizing expected improvement per unit cost.",
            "citation_title": "",
            "mention_or_use": "use",
            "system_name": "csKG (cost-sensitive Knowledge Gradient)",
            "system_description": "csKG computes the expected one-step improvement in the estimated global optimum (the Knowledge Gradient) for sampling a candidate (x, IS) based on the surrogate posterior, then adjusts/ranks candidates by their sampling cost (e.g., expected improvement per unit cost). csKG supports multi-information-source optimization by comparing different information sources with differing accuracies and costs and selecting the most cost-effective next evaluation.",
            "application_domain": "Active learning and experimental design across heterogeneous information sources in computational materials science and general black-box optimization.",
            "resource_allocation_strategy": "At each iteration, compute the expected value (KG) of sampling each candidate and information source and divide/weight by the source's cost to select the next sample that maximizes expected utility per cost; falls back to ordinary KG when no inter-source correlation is learned.",
            "computational_cost_metric": "Per-evaluation cost measured as wall-clock computational time or a relative cost unit (e.g., cost ratios such as 1000:1), summed over queries to produce cumulative cost.",
            "information_gain_metric": "Knowledge Gradient — expected single-step increase in the posterior estimate of the optimum value, computed using the surrogate model's posterior mean and variance.",
            "uses_information_gain": true,
            "exploration_exploitation_mechanism": "KG inherently balances exploration and exploitation by valuing potential changes to the recommended optimum due to uncertainty; csKG further biases towards cheaper sources that deliver good expected KG per cost, indirectly promoting cost-aware exploration.",
            "diversity_mechanism": "No dedicated diversity module; diversity is a byproduct of selecting points with high expected KG which often correspond to uncertain regions.",
            "uses_diversity_promotion": false,
            "budget_constraint_type": "Cumulative computational cost / evaluation budget.",
            "budget_constraint_handling": "csKG explicitly factors sampling cost into acquisition ranking; performance is measured by cumulative cost to reach thresholds; initial multi-source training costs are accounted for in cumulative-cost analyses.",
            "breakthrough_discovery_metric": "Same as other methods: reaching a specified performance threshold (e.g., global optimum or within X of it) is used to define success/breakthrough.",
            "performance_metrics": "Used in combination with different surrogates; performance is reported as cumulative cost (mean, STD, tail percentiles) to reach thresholds across benchmarks.",
            "comparison_baseline": "Compared to EI (EGO) where KG is replaced by EI and to KG without cost-sensitivity.",
            "performance_vs_baseline": "csKG-based MISO variants outperform EI/GPR (EGO) in many benchmark settings when cheap correlated sources exist, reducing cumulative cost to target; when sources are poorly correlated or noisy, csKG's advantage diminishes and it can default to KG-like behavior.",
            "efficiency_gain": "Contributes to the reported efficiency gains of MISO methods: e.g., combined with PCM leads to up to ~80% reduction vs EGO in Rosenbrock tests, and ~52% mean reduction in CO geometry examples (these gains are attributable to cost-sensitivity and multi-source exploitation).",
            "tradeoff_analysis": "The paper discusses how csKG's cost-aware ranking interacts with source correlation and surrogate hyperparameters: when surrogate hyperparameters are poorly estimated or sources correlate weakly, csKG's benefits shrink; csKG mitigates cost vs information tradeoffs by formalizing expected information per cost.",
            "optimal_allocation_findings": "csKG is recommended when multiple information sources with different costs and correlations are available; it should be paired with surrogates that either reliably learn inter-source relations (MGP/ICM) or with PCM when robust empirical correlation estimates can be obtained to avoid complex hyperparameter learning.",
            "uuid": "e2633.3",
            "source_info": {
                "paper_title": "Cost-effective materials discovery: Bayesian optimization across multiple information sources",
                "publication_date_yy_mm": "2020-08"
            }
        },
        {
            "name_short": "PCM",
            "name_full": "Pearson-r Coregionalization Model (PCM)",
            "brief_description": "A surrogate-model coregionalization approach that builds the inter-information-source covariance matrix directly from empirical Pearson correlation coefficients, eliminating the need to learn inter-source hyperparameters.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "Pearson-r Coregionalization Model (PCM)",
            "system_description": "PCM constructs the coregionalization matrix K_s by computing Pearson-r correlation coefficients (ρ) between information-source outputs at points that were sampled across all sources, and placing those ρ values into K_s (diagonals set to 1). K_s is then combined with the input kernel K_x via Kronecker product (K = K_s ⊗ K_x) to produce a multi-source Gaussian-process prior without introducing extra inter-source hyperparameters. This reduces hyperparameter dimensionality and improves scalability and robustness when sources are well correlated.",
            "application_domain": "Multi-information-source surrogate modeling for Bayesian optimization in materials science and computational chemistry.",
            "resource_allocation_strategy": "Used as the surrogate within csKG-driven MISO; resource allocation (which source to sample) is determined by csKG using the PCM posterior (means and variances) which reflect inter-source correlations via empirically estimated ρ values.",
            "computational_cost_metric": "Same per-evaluation cost measures used in MISO (wall-clock time, relative cost units); PCM itself reduces computational overhead by avoiding hyperparameter optimization for inter-source covariance.",
            "information_gain_metric": "The surrogate supplies posterior predictive variances and covariances used by KG/csKG to compute expected information gain (Knowledge Gradient).",
            "uses_information_gain": true,
            "exploration_exploitation_mechanism": "Exploration/exploitation handled by csKG using PCM-derived posteriors; PCM's empirical correlations shape where uncertainty reduction on cheap sources transfers to the expensive source, affecting exploratory value.",
            "diversity_mechanism": "No explicit diversity mechanisms; PCM indirectly affects diversity by modulating posterior covariance structure based on empirical inter-source correlations.",
            "uses_diversity_promotion": false,
            "budget_constraint_type": "Cumulative computational cost (indirectly supported through its use with csKG).",
            "budget_constraint_handling": "PCM reduces hyperparameter estimation cost and instability, lowering the upfront sampling/training cost needed to obtain reliable inter-source covariance estimates; used with csKG to select cost-effective queries.",
            "breakthrough_discovery_metric": "Operationalized via attainment of optimization thresholds (same as other methods); PCM improves reliability to reach thresholds under cost constraints when sources are correlated.",
            "performance_metrics": "In benchmarks PCM (PearsonKG) yields lower mean and tail cumulative cost versus other surrogates. Example: Rosenbrock PearsonKG mean cost = 5, STD = 1 (intersection training), 99.9th%-tile = 5 (Table 1).",
            "comparison_baseline": "Compared to learned coregionalization approaches (ICM, MGP) and to single-source EGO (EI/GPR).",
            "performance_vs_baseline": "PCM-based PearsonKG tends to outperform MGP and ICM variants in robustness (tail percentiles) and often in mean cumulative cost when information sources are well correlated, due to avoiding difficult inter-source hyperparameter learning.",
            "efficiency_gain": "Contributes to the reported large efficiency gains (e.g., up to ~80% over EGO in Rosenbrock; significant reductions in worst-case tail costs compared to MGP/ICM).",
            "tradeoff_analysis": "PCM trades off model flexibility for robustness and scalability: by using empirical correlations it reduces hyperparameter complexity (good when sufficient intersecting data exist and sources are well correlated) but may be less flexible if correlations vary across input space or if intersecting data are scarce.",
            "optimal_allocation_findings": "PCM is recommended when information sources are globally well correlated and when practitioners wish to avoid expensive inter-source hyperparameter estimation; it is combined with csKG to make cost-aware allocation decisions that favor cheap informative evaluations.",
            "uuid": "e2633.4",
            "source_info": {
                "paper_title": "Cost-effective materials discovery: Bayesian optimization across multiple information sources",
                "publication_date_yy_mm": "2020-08"
            }
        },
        {
            "name_short": "EGO",
            "name_full": "Efficient Global Optimization (EGO) — EI/GPR",
            "brief_description": "A standard single-source Bayesian optimization baseline that combines Expected Improvement (EI) acquisition with Gaussian Process Regression (GPR) surrogate modeling, commonly used for black-box expensive function optimization.",
            "citation_title": "",
            "mention_or_use": "use",
            "system_name": "EGO (EI/GPR)",
            "system_description": "EGO uses a GPR surrogate trained on the expensive information source only and selects the next sampling point by maximizing the Expected Improvement acquisition function. It does not consider cheaper alternative information sources nor per-evaluation cost differences between sources.",
            "application_domain": "General black-box expensive function optimization (DFT geometry optimization, global optimization benchmarks).",
            "resource_allocation_strategy": "Select the next x to evaluate on the single (expensive) information source by maximizing Expected Improvement; allocation is constrained to the expensive source only (no multi-source selection).",
            "computational_cost_metric": "Cumulative cost measured by summing costly evaluations (wall-clock time), since only expensive source is used.",
            "information_gain_metric": "Expected Improvement (EI) quantifying expected positive improvement over current best value; not directly cost-aware.",
            "uses_information_gain": true,
            "exploration_exploitation_mechanism": "EI trades off exploration and exploitation by valuing points with either high predicted mean or high uncertainty, but without explicit cost-sensitivity or multi-source exploration.",
            "diversity_mechanism": "No explicit diversity promotion beyond inherent EI-driven exploration.",
            "uses_diversity_promotion": false,
            "budget_constraint_type": "Fixed cumulative cost/time implicitly via limit on number of expensive evaluations; comparisons measured by cumulative expensive-evaluation cost.",
            "budget_constraint_handling": "EGO cannot choose cheaper sources; handling is simply to continue until budget exhausted or threshold reached, so it often incurs higher cumulative cost compared to csKG-based MISO when cheaper correlated sources exist.",
            "breakthrough_discovery_metric": "Same threshold-based attainment (e.g., achieve value within tolerance of global optimum).",
            "performance_metrics": "Baseline metrics reported include mean cumulative cost, STD, and 99.9th-percentile to reach thresholds. Example: Rosenbrock EGO mean = 25, STD = 21, 99.9th%-tile = 100 (Table 1); CO geometry EGO mean = 31, STD = 24, 99.9th%-tile = 156 (Table 2).",
            "comparison_baseline": "Acts as the baseline for comparisons; other MISO approaches are compared against EGO.",
            "performance_vs_baseline": "MISO methods (csKG-based) outperform EGO in many scenarios with cheap correlated sources: e.g., ~80% improvement on Rosenbrock and ~52% average cost reduction on CO geometry; when sources are poorly correlated or noisy, EGO can match or outperform MISO variants.",
            "efficiency_gain": "EGO is less efficient in multi-source settings; other methods report up to ~80% reductions in cumulative cost relative to EGO when multi-source, cost-aware sampling is exploited.",
            "tradeoff_analysis": "EGO's lack of multi-source capability and cost-awareness leads to higher costs where cheaper correlated information exists; however, EGO can be preferable when no reliable cheaper sources exist or when inter-source correlations are weak/noisy.",
            "optimal_allocation_findings": "EGO is the appropriate default when only the expensive single source is reliable or when alternative sources are poorly correlated/noisy; otherwise, cost-sensitive multi-source approaches are recommended.",
            "uuid": "e2633.5",
            "source_info": {
                "paper_title": "Cost-effective materials discovery: Bayesian optimization across multiple information sources",
                "publication_date_yy_mm": "2020-08"
            }
        },
        {
            "name_short": "MGP",
            "name_full": "Multivariate Gaussian Process Regression (MGP)",
            "brief_description": "A multivariate GP surrogate that models multiple information sources jointly by learning full inter-source covariance/hyperparameters, used previously in misoKG for MISO.",
            "citation_title": "",
            "mention_or_use": "use",
            "system_name": "Multivariate Gaussian Process (MGP)",
            "system_description": "MGP extends Gaussian process regression to vector-valued outputs (multiple information sources) by learning separate kernel hyperparameters per source and inter-source covariance structure; the number of hyperparameters grows with the number of sources, making training more challenging. In misoKG it provides predictive means and uncertainties across sources for csKG to evaluate expected information gain.",
            "application_domain": "Multi-information-source surrogate modeling for Bayesian optimization in scientific computing and materials problems.",
            "resource_allocation_strategy": "Used as the surrogate supplying posterior predictions to csKG which then ranks (x, IS) queries by expected KG per cost.",
            "computational_cost_metric": "Per-evaluation computational time (used externally for csKG ranking); MGP increases model-training computational cost due to larger hyperparameter space.",
            "information_gain_metric": "Predictive variances and covariances from MGP are used to compute Knowledge Gradient.",
            "uses_information_gain": true,
            "exploration_exploitation_mechanism": "KG/csKG on top of MGP balances exploration/exploitation; MGP's learned covariances determine how informative cheap-source samples are about expensive source.",
            "diversity_mechanism": "No explicit diversity promotion beyond surrogate-modeled uncertainty.",
            "uses_diversity_promotion": false,
            "budget_constraint_type": "Cumulative evaluation cost (implicitly handled by csKG when MGP used in misoKG).",
            "budget_constraint_handling": "MGP itself does not handle budget constraints; csKG uses MGP outputs to handle cost-sensitive selection.",
            "breakthrough_discovery_metric": "Same threshold-based metrics used elsewhere (cumulative cost to reach performance thresholds).",
            "performance_metrics": "Reported as part of misoKG comparisons; MGP-based misoKG shows improvements vs EGO but is sensitive to hyperparameter training strategy (intersection vs costly-only). Example: misoKG mean costs vary from 5 to 13 in Rosenbrock scenarios depending on hyperparameter training (Table 1).",
            "comparison_baseline": "Compared to ICM and PCM surrogates under csKG as well as to single-source EGO.",
            "performance_vs_baseline": "MGP can perform well when hyperparameters are well-trained (intersection training), but suffers when the hyperparameter landscape is large/noisy, making PCM or ICM preferable in some settings.",
            "efficiency_gain": "Variable; can match other MISO gains when adequately trained but is less robust in high-dimensional hyperparameter scenarios.",
            "tradeoff_analysis": "Paper highlights the tradeoff between representational flexibility (MGP can model complex inter-source structure) and the difficulty of learning many hyperparameters (risking poor performance and higher model-training cost).",
            "optimal_allocation_findings": "Use MGP when one can obtain sufficient intersecting data to reliably learn inter-source hyperparameters; otherwise prefer simpler coregionalization approaches (ICM) or empirical PCM.",
            "uuid": "e2633.6",
            "source_info": {
                "paper_title": "Cost-effective materials discovery: Bayesian optimization across multiple information sources",
                "publication_date_yy_mm": "2020-08"
            }
        },
        {
            "name_short": "ICM",
            "name_full": "Intrinsic Coregionalization Model (ICM)",
            "brief_description": "A coregionalization surrogate model that represents inter-source covariance via a compact coregionalization matrix (K_s) factorized as L L^T and combined with an input kernel via Kronecker product to support multi-task Gaussian process modeling.",
            "citation_title": "",
            "mention_or_use": "use",
            "system_name": "Intrinsic Coregionalization Model (ICM)",
            "system_description": "ICM models multi-source covariance as K = K_s ⊗ K_x where K_s is a PSD coregionalization matrix (often parameterized as L L^T), capturing linear mixing of latent functions across sources. ICM introduces up to m(m+1)/2 inter-source parameters for m sources, offering a compromise between MGP flexibility and PCM simplicity.",
            "application_domain": "Multi-task (multi-information-source) surrogate modeling for Bayesian optimization in materials and computational chemistry.",
            "resource_allocation_strategy": "When used with csKG (MultiTaskKG), ICM provides multi-source posterior predictions that csKG uses to select cost-effective sampling across information sources.",
            "computational_cost_metric": "Per-evaluation time/cost for each information source (as used by csKG); ICM itself incurs model training cost for fitting L factors.",
            "information_gain_metric": "Posterior predictive variance/covariance used by KG/csKG to compute expected information gain.",
            "uses_information_gain": true,
            "exploration_exploitation_mechanism": "Exploration/exploitation balanced by csKG using ICM posterior; ICM's learned cross-source structure determines transferability of cheap-source information.",
            "diversity_mechanism": "No explicit diversity module; exploration emerges from modeled uncertainties.",
            "uses_diversity_promotion": false,
            "budget_constraint_type": "Cumulative computational cost/time (handled via csKG when used for allocation).",
            "budget_constraint_handling": "csKG uses ICM outputs to make cost-aware selections; ICM reduces number of inter-source hyperparameters compared to full MGP but still requires fitting.",
            "breakthrough_discovery_metric": "Same threshold-based metrics; ICM-based csKG methods improve attainment cost when sources correlate sufficiently.",
            "performance_metrics": "Reported mean, STD, and tail cumulative cost metrics. Example: in CO geometry optimization MultiTaskKG (ICM) mean = 15, STD = 9, 99.9th%-tile = 46 (Table 2).",
            "comparison_baseline": "Compared against MGP, PCM, and single-source EGO.",
            "performance_vs_baseline": "ICM often outperforms EGO in correlated-source settings and is competitive with PCM but can be outperformed by PCM particularly in tail robustness when PCM uses reliable empirical correlation estimates.",
            "efficiency_gain": "Provides reductions in cost vs EGO in well-correlated cases (numerical reductions shown in Tables 1-4).",
            "tradeoff_analysis": "ICM reduces hyperparameter scaling relative to full MGP but still requires learning coregionalization parameters; success depends on data sufficiency across sources and correlation strength.",
            "optimal_allocation_findings": "ICM is a practical option when one prefers a parametric learned coregionalization (fewer parameters than MGP) but when empirical PCM is not applicable or when correlations vary spatially and require learned structure.",
            "uuid": "e2633.7",
            "source_info": {
                "paper_title": "Cost-effective materials discovery: Bayesian optimization across multiple information sources",
                "publication_date_yy_mm": "2020-08"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "A Tutorial on Bayesian Optimization",
            "rating": 2
        },
        {
            "paper_title": "Kernels for Vector-Valued Functions: a Review",
            "rating": 2
        },
        {
            "paper_title": "Multi-task Bayesian optimization",
            "rating": 2
        }
    ],
    "cost": 0.02335075,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>Materials Horizons</h1>
<h2>COMMUNICATION</h2>
<h2>(A) Check for updates</h2>
<p>Cite this: Mater, Horiz., 2020, 7, 2113</p>
<p>Received 13th January 2020, Accepted 26th March 2020</p>
<p>DOI: 10.1039/d0mh00062k
rsc.li/materials-horizons</p>
<p>Applications of Bayesian optimization to problems in the materials sciences have primarily focused on consideration of a single source of data, such as DFT, MD, or experiments. This work shows how it is possible to incorporate cost-effective sources of information with more accurate, but expensive, sources as a means to significantly accelerate materials discovery in the computational sciences. Specifically, we compare the performance of three surrogate models for multi-information source optimization (MISO) in combination with a cost-sensitive knowledge gradient approach for the acquisition function: a multivariate Gaussian process regression, a cokriging method exemplified by the intrinsic coregionalization model, and a new surrogate model we created, the Pearson-r coregionalization model. To demonstrate the effectiveness of this MISO approach to the study of commonly encountered materials science problems, we show MISO results for three test cases that outperform a standard efficient global optimization (EGO) algorithm: a challenging benchmark function (Rosenbrock), a molecular geometry optimization, and a binding energy maximization. We outline factors that affect the performance of combining different information sources, including one in which a standard EGO approach is preferable to MISO.</p>
<h2>1 Introduction</h2>
<p>At the forefront of materials sciences, there is a set of research topics that remain largely inaccessible, experimentally and computationally, due to their combinatorial complexity. As one topical example, the study of high entropy alloys has exploded into an almost insurmountable combinatorial problem. ${ }^{1}$ In the biological sciences, the large conformational space of protein</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<h2>Cost-effective materials discovery: Bayesian optimization across multiple information sources $\dagger$</h2>
<p>Henry C. Herbol, ${ }^{\star \star}$ Matthias Poloczek $\ddagger^{\text {b }}$ and Paulette Clancy ${ }^{\text {a }}$</p>
<h4>Abstract</h4>
<p>New concepts Bayesian optimization methods require an acquisition function (where to search next) and a surrogate model (mimicking the behavior of real systems). We create a novel algorithm that uses the only existing acquisition function capable of taking information from multiple sources (e.g., different experimental sources and/or simulation approaches) in conjunction with a new surrogate model that finds the optimal result meeting a pre-specified objective. Current surrogate models require many fitting parameters, restricting their applicability to less complex domains. Our new model minimizes the number of such hyperparameters and yet frequently performs far better than more complicated approaches. This opens the door to considering larger combinatorial problems than previously possible. We show that our new algorithm is successful at accelerating the search for optimal solutions of common materials science problems, like geometry optimization or optimal solvent choice. We identified that our multi-information source approach will work best in well-correlated systems. Noisy information sources make our approach only comparably effective to a standard EGO approach. Overall, this is an important new addition to existing Bayesian optimization tools, one that functions in decision-making more like our own brains, considering many pieces of information before deciding upon the best solution in the most effective manner.</p>
<p>folding has proven to be exceedingly difficult to tackle. ${ }^{2}$ In recent years, machine learning (ML) techniques have shown promise in their application to challenges in the physical and biological sciences, proving to be an effective means to tackle intractable compositional and/or high-dimensional problems. Several landmark studies are emerging, as evidenced by examples using "deep learning" approaches on protein folding such as AlphaFold, ${ }^{3}$ regression methods for transformation temperature predictions in shape change alloys, ${ }^{4}$ the use of a random forest approach to predict the thermoelectric properties of materials, ${ }^{5,6}$ the use of neural networks to predict molecular ${ }^{7}$ and atomic ${ }^{8}$ energies, and using Bayesian optimization to unravel the solution processing of the hybrid organic-inorganic perovskite (HOIP) combinatorial space. ${ }^{9}$ More nuanced applications have also arisen such as the use of deep transfer learning for materials property prediction, ${ }^{10}$ the necessity for multi-objective optimization in the case of</p>
<p>durable antifogging superomniphobic supertransmissive nanostructured glass development, ${ }^{11}$ the use of a support vector machine (SVM) to efficiently identify potential antimicrobial peptides, ${ }^{12}$ the development of a novel molecular reaction fingerprint for the study of redox reactions, ${ }^{13}$ the use of genetic algorithms to estimate parameters in large kinetic models, ${ }^{14}$ the use of a variety of these methods to explore the organic photovoltaic (OPV) space, ${ }^{15,16}$ the use of Gaussian process regression (GPR) to model quasar emission spectra for the detection of Ly $z$ absorbers, ${ }^{17}$ and a novel neural network design for encodingdecoding molecules to/from continuous space. ${ }^{18}$</p>
<p>Although such studies, and many others, are demonstrating the breadth of applicability of ML to materials sciences, they invariably use a single source of data/information, which we will designate as an information source ( $\mathcal{I S}$ ). It is clear that improvements in speed and cost could be made by learning information from a cost-effective source and limiting predictions from other, more expensive, sources. Ultimately, using multiple information sources could lead to more robust predictions of materials' choices and/or properties, not to mention the potential for lowering the cost (in time and resources) if a cheaper information source can be used in place of a more expensive one. For materials studies, information sources could be provided by experimental data, continuum modeling predictions, molecular dynamics (MD) simulations, quantum mechanically derived density functional theory (DFT) calculations, various ML models - neural networks (NN), Gaussian processes (GPs), random forests, etc. - or even an intuitive rule of thumb. Each information source has its own inherent accuracy and cost. In this paper, we will show how to use a combination of sources of information within a Bayesian optimization framework to significantly accelerate materials discovery for common, important calculations in the computational sciences.</p>
<p>Bayesian optimization, from a high-level point of view, involves the process of using Bayes rule to optimize a function. To understand why this is relevant, we must first contemplate the problem of optimizing a continuous, black-box, noisy function, $g(x)$. If we have no way of appreciating the function, our search is blind. However, what if we can devise a function, $f$, that, given our observations from $D=g(x)$, allows us to make more accurate predictions on $g(x)$ ? In essence, can we find $f(x \mid D) \sim g(x)$ ? If so, we can then use $f(x \mid D)$ to determine what candidate points $x$ we should sample to maximize (or minimize) $g(x)$. This can be accomplished using Bayes rule (eqn (1)).</p>
<p>$$
\begin{aligned}
P(f \mid D) &amp; =\frac{P(D \mid f) P(f)}{P(D)} \
\text { posterior } &amp; =\frac{\text { likelihood } \times \text { prior }}{\text { marginal likelihood }}
\end{aligned}
$$</p>
<p>In Bayesian optimization, we call this underlying model the surrogate model; it is frequently chosen to be a GPR. The choice of $x$ from our surrogate model to sample next (where "sample" means calling our black-box function) is determined by some suitable acquisition function. For a more in-depth background
<img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Fig. 1 Illustration depicting how one $\mathcal{I S}$ (shown as the top, more coarsely defined contour plot) can be used to learn about another more finely defined contour plot (shown as the bottom plot). Samples can be taken from either the coarse $\mathcal{I S}$ (green dots) or the fine $\mathcal{I S}$ (gold dots) source. If the $\mathcal{I S s}$ correlate well, samples taken on the top can be used to learn about the bottom, demonstrated here as transparent gold dots.
into Bayesian optimization, we direct the reader to a succinct review by Peter Frazier. ${ }^{19}$</p>
<p>One approach used to consider several information sources at a time is known as cokriging. ${ }^{20-22}$ This approach uses either spatial proximity (a cross-variogram) or correlation (crosscovariance) to define a matrix, called a coregionalization matrix, to interpolate one $\mathcal{I S}$ from data in another $\mathcal{I S} .{ }^{20,23}$ This is illustrated in Fig. 1, in which a prediction made from a coarse $\mathcal{I S}$ is used to glean information on a finer $\mathcal{I S}$. Kriging is perhaps best known as a geostatistics term for interpolation using a GP, while cokriging is simply the extension of this interpolation to multiple, highly correlated, data sets. ${ }^{20}$ Cokriging has been used to study a wide range of geological systems, from predicting surface temperatures from elevation ${ }^{24}$ to capturing the correlation of rainfall measurements from radar to standard rain gauges. ${ }^{25}$</p>
<p>In what follows, we will use an $\mathcal{I S}$ index number to denote the "accuracy" of the source (with accuracy being subjective and based on the user's viewpoint). We denote $\mathcal{I S}<em 1="1">{0}$ to be more accurate than $\mathcal{I S}</em>$, and so on.</p>
<p>An alternative approach to handling data from several information sources was recently published as a method employing multi-information source optimization with a Knowledge Gradient (misoKG). In that work, a cost-sensitive Knowledge Gradient (csKG) acquisition function was used with a standard multivariate Gaussian process regression (MGP) surrogate model. ${ }^{26}$ These two components, an acquisition function and a surrogate model, are the building blocks of an optimization algorithm. Hence, consideration of the choices of these two components will figure prominently in the discussions below. Multi-information source optimization (MISO) works by sampling in such a way that the cost is minimized, while the accuracy of the predicted (optimal) result is maximized. The underlying csKG</p>
<p>acquisition function allows for this by determining which point, and which source of information, to sample next. If the underlying GPR indicates no (or poor) correlation between the sources of information, then the model defaults to the well-known Knowledge Gradient (KG). At this point, we draw the reader's attention to the difference between MISO and multi-fidelity optimization: MISO can be seen as a generalization of multi-fidelity approaches from costeffective approximations to encompass any correlated source of information.</p>
<p>Each approach used here builds from an underlying Gaussian process, meaning that the code will need to learn empirical fitting parameters. These parameters, called hyperparameters, can vary depending on the choice of surrogate model. With more hyperparameters, it is possible to obtain a better regression; however, this comes at a cost. To fit hyperparameters, it is common to use an approach such as the Maximum Likelihood Estimation (MLE) or Maximum A Posteriori (MAP) estimation. ${ }^{19}$ The larger the hyperparameter space, the noisier the landscape, and the more difficult it becomes to adequately learn the hyperparameters. Assuming the same model for each information source, the number of hyperparameters in MGP scales linearly with the number of information sources. Coregionalization, on the other hand, will add at most $\frac{m(m+1)}{2}$ hyperparameters, being the components of a lower triangular matrix, where $m$ is the number of information sources. This provides a strong impetus to consider coregionalization as a surrogate model.</p>
<p>In this work, we present a "coregionalized csKG approach, using the csKG acquisition function with Bayesian optimization methods based on the intrinsic coregionalization model (ICM). ${ }^{27}$ Unlike the original multivariate Gaussian process regression (MGP) surrogate model, where the number of hyperparameters effectively scales with the number of information sources, we show it is possible to define the coregionalization matrix using significantly fewer hyperparameters. Further, we introduce an entirely new approach capable of generating the necessary coregionalization matrix, based on Pearson- $r$ correlation coefficients, ${ }^{28}$ which has the considerable advantage of removing the need for additional hyperparameters altogether. We call this surrogate model the Pearson- $r$ coregionalization model (PCM). As a "proof of concept," we apply a unique combination of the csKG acquisition function and the new PCM surrogate model to explore complex compositional landscapes involved in the solution processing of a novel class of solar cell materials, known as hybrid organic-inorganic perovskites (HOIPs), and other common computational materials applications.</p>
<h2>2 Nomenclature</h2>
<p>To merge the naming conventions between the ML and DFT communities, we present two approaches to identify the models used in this paper. Within the ML community, it is common practice to identify an acquisition function/surrogate model pair by a single name. This can be seen in the case of the commonly used efficient global optimization (EGO)
algorithm, ${ }^{29}$ which merges expected improvement (EI) with GPR (or, in the case of the original paper, this is referred to as "kriging"). Similarly, the misoKG algorithm uses a csKG acquisition function with an MGP surrogate model. To maintain this naming convention, we will then define "PearsonKG" to mean pairing the csKG acquisition function with the PCM surrogate model. In regards to the csKG with the ICM surrogate model, we note that a similar formulation exists with an alternative acquisition function: entropy search. This algorithm was dubbed multi-task Bayesian optimization (MTBO) ${ }^{30}$ and, as such, leads to our choice of its name as "MultiTaskKG."</p>
<p>This naming scheme has the benefit of recognizing an algorithm by name; however, it does not allow readers to easily parse the details of the constituent models. Within the DFT literature, the solution for naming the choices of functional and basis-set that define the overall approach is to list the two separated by a forward slash. In the spirit of the DFT naming convention, we express the specific names favored by the ML community by a combination of the underlying acquisition function and surrogate model. As a result, we identify the aforementioned combinations as follows:</p>
<ul>
<li>EGO $=$ EI/GPR</li>
<li>misoKG $=$ csKG/MGP</li>
<li>MultiTaskKG $=$ csKG/ICM</li>
<li>PearsonKG $=$ csKG/PCM</li>
</ul>
<p>Within this paper, we will refer to the algorithm name itself; however, we define the above in an effort to consolidate naming conventions within the ML and DFT literature. This extensible approach allows new researchers in the field to readily understand the taxonomy of algorithmic names in this area of machine learning.</p>
<h2>3 Results</h2>
<p>We benchmark three MISO surrogate models - PCM, ICM, and MGP - against a standard EGO approach using the Rosenbrock function as a first test case. ${ }^{31}$ The Rosenbrock function, with its long, narrow and very flat parabolic basin, is a difficult optimization problem that is commonly used for benchmark purposes. This test case also has probative value since it allows us to benchmark against the original misoKG paper by Poloczek et al. ${ }^{26}$ As a second test case, we study the effects of differing DFT functionals/basis sets as sources of information for the geometry optimization of carbon monoxide. Finally, we revisit the HOIP work ${ }^{9}$ and assess the benefits of using MISO approaches, in which different levels of theory within DFT are deployed as a set of information sources, as well as differing molecular systems.</p>
<p>Running a MISO approach does not guarantee that one information source will be sampled over another. As such, given that sampling from $\mathcal{I S}<em 1="1">{0}$ does not necessarily have the same cost as sampling from $\mathcal{I S}</em>}$, we end up with a heterogeneous data set where cost varies between replications. This can be conceptualized by considering two experiments in which we run a MISO approach using two sources, $\mathcal{I S<em 1="1">{0}$ and $\mathcal{I S}</em>$,</p>
<p>whose costs we estimate to be 1000 and 1 , respectively. If, on the first experiment, we sampled $\mathcal{I S}<em 1="1">{0} 4$ times and $\mathcal{I} S</em>$ model. The "best" model is identified as the model that achieves global maximization with the least cost.} 2$ times, versus on the second experiment where we sampled $\mathcal{I} S_{0} 6$ times, our 6th data point will be at a cumulative cost of either 4002 or 6000 , depending on the experiment. As we replicate our evaluations several times for statistical significance, it is no longer possible to simply "average across all replications." Thus, we must homogenize the sampling domain so as to average the value that first exceeds a given cost. We then plot the $x$ associated with the maximum (or minimum, depending on the problem) posterior mean of the $\mathcal{I} \mathcal{S}_{0</p>
<p>Hyperparameter optimization can be achieved in at least three different ways: (1) with data sampled across all $\mathcal{I S}$ (i.e., $x$, if $x$ is sampled for all $\mathcal{I} S_{i}$, mathematically shown as ${x \mid x \in \mathcal{I S}<em 0="0">{i} \forall i}}$ ), (2) with data sampled only within $\mathcal{I} \mathcal{S}</em>$. Additional benchmarks are shown in the ESI. $\dagger$ In this work, we learn the hyperparameters from the data we sampled
initially, and then keep them fixed for the remainder of the optimization. As such, we only concern ourselves with $\mathcal{I} S_{\text {Intersection }}$ and $\mathcal{I} S_{0}$.}$ - the most expensive information source - or (3) with all sampled data. In order, we will call these $\mathcal{I} S_{\text {Intersection }}, \mathcal{I} S_{\text {Costly }}$, and $\mathcal{I} S_{\text {Full }</p>
<p>Finally, as the Bayesian optimization is performed for a combinatorial problem, we discretize the domains we wish to optimize over. The larger the discretized domain, the more complex the problem, and the harder it is to find the global extrema. This class of problem is seen as "combinatorial optimization" for "large discrete domains." In the case of the Rosenbrock function, we illustrate below three different discretized domains as a way to illustrate the benefit of using MISO over that of using EGO, especially as the complexity of the problem increases.</p>
<h3>3.1 The Rosenbrock function</h3>
<p>Fig. 2 shows the results from a variety of MISO approaches in which $\mathcal{I} \mathcal{S}<em 1="1">{0}$ was the standard 2D Rosenbrock function (see eqn (5)), and a slightly noisier alternative was chosen as $\mathcal{I} \mathcal{S}</em>$ (in which the amplitude of the sine noise, $v$, was set to 0.1 ). To achieve better statistical significance, we ran 200 replications of each and plotted with $\pm 2$ standard error of the mean (SE).
<img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Fig. 2 A comparison of MISO approaches to a standard EGO approach to find the minimum of the Rosenbrock function (eqn (5)). In all cases, the three MISO approaches (misoKG, ${ }^{26}$ MultiTaskKG, and PearsonKG) significantly outperform EGO (shown in blue) by converging to the global minimum of -456.3 at the least cost. This improvement is even more noticeable for the larger discretized domains of 1000 and 500 samples, which constitute a more difficult optimization problem. This figure illustrates the advantage of a MISO approach when a well-correlated alternative information source is chosen. Shaded regions indicate two standard errors of the mean obtained from up to 200 replications.</p>
<p>The value of a MISO approach in all panels of Fig. 2 can clearly be seen in comparison to a more standard Bayesian optimization approach like EGO, which is shown as a control. Candidate $(x, y)$ data were sampled from $[-2,2]^{2}$ in increments of $0.016,0.008$, or 0.004 (for a sampled discrete domain size of 250,500 , or 1000 , respectively). This comparison of domain complexity is illustrated in Fig. 2a-c, where the superiority of MISO approaches becomes increasingly apparent. In contrast, Fig. 2d shows results from MISO approaches in which $\mathcal{I S}<em 1="1">{0}$ was the standard Rosenbrock function (see eqn (5)), but a significantly noisier alternative was chosen as $\mathcal{I S}</em>$ (in which the amplitude of the sine noise, $v$, was set to 10.0). Corresponding numerical results are shown in Table 1.</p>
<h3>3.2 DFT information sources for geometry optimization in CO</h3>
<p>We studied the ability of the same four statistical models to minimize the total energy of a carbon monoxide (CO) molecule. This effectively performs a geometry optimization, a common task using DFT, via Bayesian optimization. Information sources were taken as being either a single-point SCF calculation from a double-hybrid method, with a triple- $\zeta$ basis set (B2PLYP and Def2-TZVP), ${ }^{32,33}$ which is an accurate and expensive option, or a simple (inexpensive) Hartree-Fock approach with "three corrections" ${ }^{34}$ in which (1) a geometrical counterpoise correction to remove basis set superposition error, ${ }^{35-37}$ (2) the D3BJ dispersion correction, ${ }^{38}$ and (3) the MINIX basis set. ${ }^{39}$ Note that
these information sources correlate well, with a Pearson- $r$ correlation coefficient of 0.999 . As we will show, this strong correlation is an important consideration. The results are shown in Table 2, where the ICM and PCM surrogate models perform the best (i.e., have the lowest mean cost). What is more strikingly apparent though is the improvement to the 99.9th percentile, where PearsonKG shows a $76 \%$ improvement compared to that of EGO.</p>
<h3>3.3 Physical analytics pipeLine test case for HOIP materials</h3>
<p>A major difficulty associated with studying hybrid organicinorganic perovskites (HOIPs) computationally lies in the fact that (1) possible candidate materials differ in composition, (2) the compositional space represents a large combinatorial problem, and (3) no MD force field exists that is suitable to use in cost-effective simulations for HOIPs candidates. As a result, computational research on HOIPs formation and growth is currently restricted largely to expensive DFT calculations.</p>
<p>Our previous work ${ }^{9}$ showed the benefits of using Bayesian optimization to tame this complexity, and developed a probabilistic model for HOIP-solvent intermolecular binding energies. Here, we investigate the benefits of using multiple information source optimization approaches. The alternate $\mathcal{I S}$ in this case consist of data sources in which we varied (1) the number of solvents considered to be bound to the lead salt and (2) differing</p>
<p>Table 1 Benchmarking the performance of three MISO statistical models for the minimization of the Rosenbrock function. This table shows the significant advantage of using the PearsonKG approach over other MISO approaches, most readily apparent in the $99.9 \mathrm{th} \%$-tile. Values reported in this table indicate the cost taken to be below -455.3 , the lowest function evaluation across all methods (with the global minimum occurring at -456.3 ). All values in this table have been rounded to the nearest 1000 (the cost of $\mathcal{I S}_{0}$ ) and then scaled by 1000 to be more easily compared</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Algorithm</th>
<th style="text-align: left;">Acquisition function</th>
<th style="text-align: left;">Surrogate model</th>
<th style="text-align: left;">$\Theta$ training set</th>
<th style="text-align: center;">Mean</th>
<th style="text-align: center;">STD</th>
<th style="text-align: center;">$99.9 \mathrm{th} \%$-tile</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">EGO</td>
<td style="text-align: left;">EI</td>
<td style="text-align: left;">GPR</td>
<td style="text-align: left;">$\mathcal{I S}_{\text {Costly }}$</td>
<td style="text-align: center;">25</td>
<td style="text-align: center;">21</td>
<td style="text-align: center;">100</td>
</tr>
<tr>
<td style="text-align: left;">misoKG</td>
<td style="text-align: left;">csKG</td>
<td style="text-align: left;">MGP</td>
<td style="text-align: left;">$\mathcal{I S}_{\text {Costly }}$</td>
<td style="text-align: center;">13</td>
<td style="text-align: center;">13</td>
<td style="text-align: center;">81</td>
</tr>
<tr>
<td style="text-align: left;">MultiTaskKG</td>
<td style="text-align: left;">csKG</td>
<td style="text-align: left;">ICM</td>
<td style="text-align: left;">$\mathcal{I S}_{\text {Costly }}$</td>
<td style="text-align: center;">13</td>
<td style="text-align: center;">13</td>
<td style="text-align: center;">81</td>
</tr>
<tr>
<td style="text-align: left;">PearsonKG</td>
<td style="text-align: left;">csKG</td>
<td style="text-align: left;">PCM</td>
<td style="text-align: left;">$\mathcal{I S}_{\text {Costly }}$</td>
<td style="text-align: center;">5</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">5</td>
</tr>
<tr>
<td style="text-align: left;">misoKG</td>
<td style="text-align: left;">csKG</td>
<td style="text-align: left;">MGP</td>
<td style="text-align: left;">$\mathcal{I S}_{\text {Intersection }}$</td>
<td style="text-align: center;">5</td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">12</td>
</tr>
<tr>
<td style="text-align: left;">MultiTaskKG</td>
<td style="text-align: left;">csKG</td>
<td style="text-align: left;">ICM</td>
<td style="text-align: left;">$\mathcal{I S}_{\text {Intersection }}$</td>
<td style="text-align: center;">5</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">7</td>
</tr>
<tr>
<td style="text-align: left;">PearsonKG</td>
<td style="text-align: left;">csKG</td>
<td style="text-align: left;">PCM</td>
<td style="text-align: left;">$\mathcal{I S}_{\text {Intersection }}$</td>
<td style="text-align: center;">5</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">5</td>
</tr>
<tr>
<td style="text-align: left;">misoKG</td>
<td style="text-align: left;">csKG</td>
<td style="text-align: left;">MGP $^{a}$</td>
<td style="text-align: left;">$\mathcal{I S}_{\text {Intersection }}$</td>
<td style="text-align: center;">6</td>
<td style="text-align: center;">3</td>
<td style="text-align: center;">28</td>
</tr>
<tr>
<td style="text-align: left;">MultiTaskKG</td>
<td style="text-align: left;">csKG</td>
<td style="text-align: left;">ICM $^{a}$</td>
<td style="text-align: left;">$\mathcal{I S}_{\text {Intersection }}$</td>
<td style="text-align: center;">7</td>
<td style="text-align: center;">5</td>
<td style="text-align: center;">47</td>
</tr>
<tr>
<td style="text-align: left;">PearsonKG</td>
<td style="text-align: left;">csKG</td>
<td style="text-align: left;">PCM $^{a}$</td>
<td style="text-align: left;">$\mathcal{I S}_{\text {Intersection }}$</td>
<td style="text-align: center;">5</td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">16</td>
</tr>
</tbody>
</table>
<p>${ }^{a}$ Results using the same three statistical models, but for an extremely noisy Rosenbrock function.</p>
<p>Table 2 Benchmarking four statistical models to minimize the total energy of a CO molecule. Values indicate the cost taken to be within 0.6 kcal mol ${ }^{-1}$ of the lowest function evaluation across all methods. The cost ratio used was approximately 11.5 to 3.5 (based on average computational time, in seconds, for each single point DFT calculation with the respective levels of theory), and as such can be seen as the total time to geometry optimization. All values in this table have been rounded to the nearest 10 and then scaled by 10 so as to be more easily compared. It is clear that the PearsonKG and MultiTaskKG approaches converge to the ground state geometry in significantly less time than the "industry standard" EGO</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Algorithm</th>
<th style="text-align: left;">Acquisition function</th>
<th style="text-align: left;">Surrogate model</th>
<th style="text-align: left;">$\mathcal{I} \mathcal{S}_{0}$</th>
<th style="text-align: left;">$\mathcal{I} \mathcal{S}_{1}$</th>
<th style="text-align: center;">Mean</th>
<th style="text-align: center;">STD</th>
<th style="text-align: center;">$99.9 \mathrm{th} \%$-tile</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">EGO</td>
<td style="text-align: left;">EI</td>
<td style="text-align: left;">GPR</td>
<td style="text-align: left;">B2PLYP/def2-TZVP</td>
<td style="text-align: left;">-</td>
<td style="text-align: center;">31</td>
<td style="text-align: center;">24</td>
<td style="text-align: center;">156</td>
</tr>
<tr>
<td style="text-align: left;">misoKG</td>
<td style="text-align: left;">csKG</td>
<td style="text-align: left;">MGP</td>
<td style="text-align: left;">B2PLYP/def2-TZVP</td>
<td style="text-align: left;">HF-3c</td>
<td style="text-align: center;">28</td>
<td style="text-align: center;">18</td>
<td style="text-align: center;">87</td>
</tr>
<tr>
<td style="text-align: left;">MultiTaskKG</td>
<td style="text-align: left;">csKG</td>
<td style="text-align: left;">ICM</td>
<td style="text-align: left;">B2PLYP/def2-TZVP</td>
<td style="text-align: left;">HF-3c</td>
<td style="text-align: center;">15</td>
<td style="text-align: center;">9</td>
<td style="text-align: center;">46</td>
</tr>
<tr>
<td style="text-align: left;">PearsonKG</td>
<td style="text-align: left;">csKG</td>
<td style="text-align: left;">PCM</td>
<td style="text-align: left;">B2PLYP/def2-TZVP</td>
<td style="text-align: left;">HF-3c</td>
<td style="text-align: center;">15</td>
<td style="text-align: center;">8</td>
<td style="text-align: center;">38</td>
</tr>
</tbody>
</table>
<p><img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>Fig. 3 Comparison of the impact of different information sources for HOIP materials in the performance of MISO methods versus a standard EGO approach. The results show that EGO performs as well as, and at times better than, MISO methods in cases (Fig. 4b and c) where the information sources are poorly correlated. MISO methods fall back to EGO-like performance in such cases (with the exception of the x -offset due to the initial sampling).</p>
<p>DFT levels of theory (defined as differing functionals and basis sets), which can vary considerably in expense of calculation. As semi-empirical force fields for HOIPs become available in the future, these could also be used within a MISO approach.</p>
<p>Results of these tests are shown in Fig. 3. As the MISO surrogate models require an initial sampling from all the information sources prior to running the optimizer, this produces a systematic offset on the $x$-axis in Fig. 3a-c (and most readily observable in Fig. 3c) indicative of this additional training cost. In contrast, EGO starts optimizing sooner since its initial training is solely against the expensive $\mathcal{I} \mathcal{S}_{0}$. The largest benefits to using MISO approaches can be seen in Fig. 3a, in a test case in which the two information sources are both DFT functionals (inexpensive GGA and expensive hybrid approaches). In contrast, in Fig. 3b and c, the two different information sources concern information garnered from the number of solvent molecules bound to the lead salt (one solvent molecule vs. three solvent molecules in Fig. 3b, and three solvent molecules vs. five solvent molecules in Fig. 3c). Here, the advantage of using a MISO approach is far less apparent. The origin of this change is, we believe, a function of how noisy the energy landscape becomes as the
number of solvent molecules increases which, in turn, necessitates a growing importance of adequate sampling.</p>
<p>To assess the noise in the energy landscapes, we generate a cross-correlation table of possible HOIP-solvent information sources (Table 3). The various information sources are distinguished by the level of theory (GGA vs. hybrid) and the number of solvents ( 1,3 , or 5 ). The generalised gradient approximation (GGA) level of theory used was B97-D3 with a triple- $\zeta$ basis set; ${ }^{38,40}$ while the hybrid functional was PW6B95 with a triple- $\zeta$ basis set. ${ }^{33,41}$ The naming convention used was either GGA or hybrid followed by $N$, where $N$ was 1,3 , or 5 (signifying the number of solvents). Results for all the information sources are</p>
<p>Table 3 The cross-correlation matrix of all HOIP information sources. Correlation is calculated only on data that exists across both information sources</p>
<table>
<thead>
<tr>
<th style="text-align: left;"></th>
<th style="text-align: left;">Hybrid-1</th>
<th style="text-align: left;">GGA-1</th>
<th style="text-align: left;">GGA-3</th>
<th style="text-align: left;">GGA-5</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Hybrid-1</td>
<td style="text-align: left;">1.00</td>
<td style="text-align: left;">0.83</td>
<td style="text-align: left;">0.77</td>
<td style="text-align: left;">0.76</td>
</tr>
<tr>
<td style="text-align: left;">GGA-1</td>
<td style="text-align: left;">0.83</td>
<td style="text-align: left;">1.00</td>
<td style="text-align: left;">0.83</td>
<td style="text-align: left;">0.83</td>
</tr>
<tr>
<td style="text-align: left;">GGA-3</td>
<td style="text-align: left;">0.77</td>
<td style="text-align: left;">0.83</td>
<td style="text-align: left;">1.00</td>
<td style="text-align: left;">0.83</td>
</tr>
<tr>
<td style="text-align: left;">GGA-5</td>
<td style="text-align: left;">0.76</td>
<td style="text-align: left;">0.83</td>
<td style="text-align: left;">0.83</td>
<td style="text-align: left;">1.00</td>
</tr>
</tbody>
</table>
<p><img alt="img-3.jpeg" src="img-3.jpeg" /></p>
<p>Fig. 4 Comparison of all the HOIP information sources sorted such that the results using the cheap GGA-1 function is monotonically increasing. Data from GGA-1 and the expensive Hybrid-1 functional (where the "-1" indicates a single solvent) can be seen to correlate well. In contrast however, information sources that involved more solvents (GGA-3 and GGA-5 for 3 and 5 solvent molecules, respectively) show poor correlation. Color code as given in the inset.
plotted in Fig. 4. We find that GGA-1 correlates best with other $\mathcal{I S}$ (i.e., it consistently has a correlation factor over 0.8 ).</p>
<h2>4 Discussion</h2>
<p>As we explore the ability of machine learning to tackle grand challenges in computational materials science, it is natural to want to take advantage of information from a variety of sources and to combine them in such a way that we can make predictions of materials properties or optimal materials discovery in the most cost-effective way possible. In this paper, we use a newly proposed acquisition function, $\mathrm{csKG},{ }^{26}$ in concert with several surrogate models, including a new model proposed here, that can harness multiple information sources for costeffective predictions. This is the first application of a MISO approach to conduct common computational materials science calculations.</p>
<p>Our first study involved using the Rosenbrock function as a test of our optimization methods, since it is a challenging nonlinear, shallow-basin problem. The Rosenbrock benchmarks shown in Fig. 2 and Table 1 indicate: (1) the considerable benefits of using MISO approaches over a standard EGO approach; (2) the importance of adequate hyperparameter training in respective models; and (3) the benefits of the new PCM surrogate model, developed in this paper, over either a multivariate Gaussian process regression model (MGP) or an intrinsic coregionalization model (ICM).</p>
<p>For the Rosenbrock test, the improvement over EGO was $80 \%$ for each of the three MISO models we tested. In regards to hyperparameter optimization, we find that when the model includes hyperparameters that capture the interplay between information sources (as in the case of MGP and ICM), it is necessary to include data across all information sources to
adequately learn these parameters. The main improvement of our new model, PCM, over that of ICM and MGP can be seen in the results for the 99.9th percentile. This improvement also comes with the considerable advantage that we no longer need additional inter- $\mathcal{I S}$ hyperparameters in this approach. As Bayesian approaches are known to be capable of optimizing noisy functions, we find that when the information sources correlate well but are inherently noisy, MISO approaches continue to outperform EGO, with the PCM surrogate model remaining the best. Finally, looking at Fig. 2, when we consider a large combinatorial space for the optimization, the MISO models perform markedly better (over EGO) than when we consider a smaller combinatorial space.</p>
<p>Turning towards applications of this approach to computational materials sciences, our aim is to understand the effects of including different information sources on cost-effectiveness. Performing a geometry optimization of CO using Bayesian optimization is a prime example of a common computational chemistry calculation. Here, our information sources were different DFT functionals and basis sets. This is a representative real-life issue since these sources differ greatly in cost (certainly by over an order of magnitude). Finding that we have a close-to-unity Pearson correlation coefficient between these information sources, we anticipated that the various MISO methods would perform better than EGO. And, indeed, Table 2 shows that both the MISO surrogate models (ICM and PCM) outperform a standard EGO approach by, on average, $52 \%$ in cost. Further, in the case of the 99.9th percentile, MultiTaskKG and PearsonKG outperform EGO by $71 \%$ and $76 \%$, respectively. Commonly, local optimizers are used when performing DFT geometry optimizations; however, at times, the desire to find optimal molecular conformations/packing is desired instead. This is a global optimization problem which involves considerations of optimally packing molecules via translational and rotational changes, subsequently followed by a geometry optimization. This work shows that it is possible to use MISO methods to deploy cheap sources of information for this search space (such as Hartree-Fock) with more expensive/accurate functionals for the final calculations, greatly reducing the overall time required to find this optimal packing.</p>
<p>Finally, in a challenging application related to the selection of solar cell materials, hybrid organic-inorganic perovskites, we looked at the cost-effectiveness of combining different information sources within our PAL code base. For these perovskite materials, it becomes even more apparent that the reliability of the cheaper information sources, i.e., $\mathcal{I S}<em 0="0">{l&gt;0}$, to represent the most trusted source, $\mathcal{I} \mathcal{S}</em>$, comes under scrutiny. The results in Fig. 3a show a slight benefit in using PearsonKG, corroborated in Table 4 by the reduced mean cost to reach an optimal solution. However, this benefit is rapidly reduced as the information source changes to noisier alternatives. We find the nature of the information sources is an important factor when considering a MISO approach. This effect is clear in Fig. 4, which compares information sources that choose different ways to represent both the solvation of the lead salt and the level of DFT theory used. Choices like Hybrid-1 and GGA-1,</p>
<p>Table 4 Benchmarking MISO surrogate models (ICM and PCM) against EGO for the minimization of the HOIP objectives. Values reported in the table indicate the cost, taken to be within 0.6 kcal mol ${ }^{-1}$ of the lowest function evaluation across all methods. Lower cost indicates better performing models. All values in this table have been rounded to the nearest 10 and then scaled by 10 so as to be more easily compared</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Algorithm</th>
<th style="text-align: left;">Acquisition function</th>
<th style="text-align: left;">Surrogate model</th>
<th style="text-align: left;">$\mathcal{I S}_{0}$</th>
<th style="text-align: left;">$\mathcal{I} \mathcal{S}_{1}$</th>
<th style="text-align: left;">Mean</th>
<th style="text-align: left;">STD</th>
<th style="text-align: left;">99.9 th\%-tile</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">EGO</td>
<td style="text-align: left;">EI</td>
<td style="text-align: left;">GPR</td>
<td style="text-align: left;">Hybrid-1</td>
<td style="text-align: left;">-</td>
<td style="text-align: left;">80</td>
<td style="text-align: left;">30</td>
<td style="text-align: left;">198</td>
</tr>
<tr>
<td style="text-align: left;">MultiTaskKG</td>
<td style="text-align: left;">csKG</td>
<td style="text-align: left;">ICM</td>
<td style="text-align: left;">Hybrid-1</td>
<td style="text-align: left;">GGA-1</td>
<td style="text-align: left;">81</td>
<td style="text-align: left;">41</td>
<td style="text-align: left;">244</td>
</tr>
<tr>
<td style="text-align: left;">PearsonKG</td>
<td style="text-align: left;">csKG</td>
<td style="text-align: left;">PCM</td>
<td style="text-align: left;">Hybrid-1</td>
<td style="text-align: left;">GGA-1</td>
<td style="text-align: left;">70</td>
<td style="text-align: left;">35</td>
<td style="text-align: left;">216</td>
</tr>
<tr>
<td style="text-align: left;">EGO</td>
<td style="text-align: left;">EI</td>
<td style="text-align: left;">GPR</td>
<td style="text-align: left;">GGA-3</td>
<td style="text-align: left;">-</td>
<td style="text-align: left;">36</td>
<td style="text-align: left;">29</td>
<td style="text-align: left;">124</td>
</tr>
<tr>
<td style="text-align: left;">MultiTaskKG</td>
<td style="text-align: left;">csKG</td>
<td style="text-align: left;">ICM</td>
<td style="text-align: left;">GGA-3</td>
<td style="text-align: left;">GGA-1</td>
<td style="text-align: left;">33</td>
<td style="text-align: left;">32</td>
<td style="text-align: left;">187</td>
</tr>
<tr>
<td style="text-align: left;">PearsonKG</td>
<td style="text-align: left;">csKG</td>
<td style="text-align: left;">PCM</td>
<td style="text-align: left;">GGA-3</td>
<td style="text-align: left;">GGA-1</td>
<td style="text-align: left;">32</td>
<td style="text-align: left;">23</td>
<td style="text-align: left;">185</td>
</tr>
<tr>
<td style="text-align: left;">EGO</td>
<td style="text-align: left;">EI</td>
<td style="text-align: left;">GPR</td>
<td style="text-align: left;">GGA-5</td>
<td style="text-align: left;">-</td>
<td style="text-align: left;">70</td>
<td style="text-align: left;">59</td>
<td style="text-align: left;">300</td>
</tr>
<tr>
<td style="text-align: left;">MultiTaskKG</td>
<td style="text-align: left;">csKG</td>
<td style="text-align: left;">ICM</td>
<td style="text-align: left;">GGA-5</td>
<td style="text-align: left;">GGA-3</td>
<td style="text-align: left;">87</td>
<td style="text-align: left;">62</td>
<td style="text-align: left;">300</td>
</tr>
<tr>
<td style="text-align: left;">PearsonKG</td>
<td style="text-align: left;">csKG</td>
<td style="text-align: left;">PCM</td>
<td style="text-align: left;">GGA-5</td>
<td style="text-align: left;">GGA-3</td>
<td style="text-align: left;">105</td>
<td style="text-align: left;">70</td>
<td style="text-align: left;">300</td>
</tr>
</tbody>
</table>
<p>which share a common number of solvent molecules ( $=1$ ) model one another much better (i.e., are better correlated) than the alternatives (GGA-3 and GGA-5) in which the number of solvent molecules (and hence the inherent noise) varies. In the latter situation, we find no benefit to using a MISO approach (Fig. 3b and c).</p>
<p>In summary, we have developed a new surrogate model, PCM, and shown how it performs at least as well, and often better, than ICM (where ICM can be seen as the common "go to" model when it comes to coregionalization) for several archetypal test cases in the computational materials sciences. Importantly, the new PCM model does not involve any additional hyperparameters. Further, we show how the acquisition function, csKG, can be implemented in combination with these surrogate models. This combination opens the door for computational studies to incorporate any number of data streams of varying expense in a cost-effective way. This method allows the user to exploit the availability of less accurate, lower cost, alternative sources of information. We find that the best approach to take depends heavily on the correlation between information sources and the surrogate model that defines the potential. When an information source possesses the same GPR kernel $\left(K_{x}\right)$ with similar/identical hyperparameters, as in the Rosenbrock benchmark, CO geometry optimization, and the HOIP benchmark comparing Hybrid-1 versus GGA-1, using csKG with the PCM surrogate method converges significantly faster towards a global optimum. In cases where the hyperparameters differ greatly, as exemplified by GGA-5 versus GGA-3, the best course of action appears to reside in using a traditional EGO approach. Finally, we have discovered that, when it is desirable to maximize an objective with an expensive DFT functional, a MISO approach using the PCM surrogate model and a more costeffective functional can greatly reduce the total cost.</p>
<h2>5 Methods</h2>
<h3>5.1 The intrinsic coregionalization model</h3>
<p>There are many methods of coregionalization, several of which are outlined in a review article by Alvarez et al. ${ }^{42}$ The intrinsic coregionalization model (ICM) approach defines a coregionalization matrix $\left(K_{\mathrm{s}}\right)$ such that $K=K_{\mathrm{s}} \otimes K_{x}$ (where $\otimes$ is the Kronecker
product and $K_{x}$ is a user-defined kernel). ${ }^{42}$ The problem then arises how best to define $K_{\mathrm{s}}$. One method involves simply allowing $K_{\mathrm{s}}=I$, in which the hyperparameters of $K_{x}$, parameterized against all $\mathcal{I S}$, will capture the correlation between $\mathcal{I} \mathcal{S} .{ }^{43,44}$ Another method ensures a PSD matrix by having $K_{\mathrm{s}}=\operatorname{ES}^{T} S E$ in which $E$ is a diagonal matrix of scalars with dimension $M$ (the number of $\mathcal{I S}$ ), and $S$ is an upper triangular matrix. ${ }^{45}$ It should be noted that there exists an equivalent expression, $K_{\mathrm{s}}=E L L^{T} E$, in which $L$ is a lower triangular matrix. In general, the scalar matrix is not particularly common and, in most literature sources, we simply find that $K_{\mathrm{s}}$ is written as $L L^{T} .^{21}$</p>
<h3>5.2 The Pearson-r coregionalization model</h3>
<p>The Pearson-r coregionalization model (PCM) was developed based on the idea that the coregionalization matrix should capture the correlation between $\mathcal{I} \mathcal{S} .{ }^{22}$ From this, the coregionalization matrix was not learned, but dynamically generated from the Pearson-r correlation coefficients $(\rho)$ of sampled data. ${ }^{28}$ Specifically, each component of the coregionalization matrix was made using eqn (2), to which eqn (3) was calculated ( $\rho$ was only calculated for data that had been sampled at all $\mathcal{I S}$ using the python package, SciPy). ${ }^{46}$ This approach eradicates the need for additional hyperparameters (ontop of those in $K_{x}$ ), allowing for a more scalable model.</p>
<p>$$
\begin{gathered}
\rho=\frac{\sum\left(x-m_{x}\right)\left(y-m_{x}\right)}{\sqrt{\sum\left(x-m_{x}\right)^{2}\left(y-m_{y}\right)^{2}}} \
K_{\mathrm{s}}=\left[\begin{array}{ccccc}
1 &amp; \rho(0,1) &amp; \rho(0,2) &amp; \cdots &amp; \rho(0, M) \
\rho(1,0) &amp; 1 &amp; \rho(1,2) &amp; \cdots &amp; \rho(1, M) \
\vdots &amp; \cdots &amp; \ddots &amp; \cdots &amp; \vdots \
\vdots &amp; \cdots &amp; \cdots &amp; \ddots &amp; \vdots \
\rho(M, 0) &amp; \cdots &amp; \cdots &amp; \rho(M, M-1) &amp; 1
\end{array}\right]
\end{gathered}
$$</p>
<h3>51.3 Analytical model</h3>
<p>The Rosenbrock function, also known as the "banana function," is a well known, well studied and challenging test case for global</p>
<p>optimization. ${ }^{31}$ Further, a noisy alternate form has already been developed by Lam et al. ${ }^{47}$ As this function was used by Poloczek et al. ${ }^{26}$ to benchmark misoKG and MGP, we use it here to compare our new approach to Poloczek's misoKG. The function itself is shown in eqn (4), where $a, b, c \in \mathbb{R}$.</p>
<p>$$
f_{t}(x)=\left(a-x_{1}\right)^{2}+b\left(x_{2}-x_{1}^{2}\right)^{2}+c
$$</p>
<p>In order to use the Rosenbrock function with MISO surrogate models, we need several $\mathcal{I S}$. Accordingly, we define two $\mathcal{I S}$ as the Rosenbrock function, plus some additional varied term. The two $\mathcal{I S}$ used are shown in eqn (5):</p>
<p>$$
\begin{aligned}
\mathcal{I} \mathcal{S}<em c="c">{0} &amp; =-f</em>(x)+u \cdot \varepsilon \
\mathcal{I} \mathcal{S}<em c="c">{1} &amp; =-f</em>\right)
\end{aligned}
$$}(x)+v \cdot \sin \left(10 \cdot x_{1}+5 \cdot x_{2</p>
<p>We can replicate the work shown in Poloczek et al. ${ }^{26}$ by setting $a=1.0, b=100.0, c=-456.3, u=0, v=0.1$, and a cost ratio of 1000:1. The domain for $x \in \mathcal{D}$ is given by $\mathcal{D}_{i} \in \mathbb{R}^{2} \mid i&lt;N$ and bounded within the origin-centered-square of $[-2,2]^{2} . N$, the number of discrete points of our domain $\mathcal{D}$, was chosen to be either 250,500 , or 1000 , in order to capture the effects of the search-space on the models. To probe the limits of our model, we expanded upon this benchmark by considering a significantly noisier secondary information source and allowing $v=10.0$. Note that the global minimum of the Rosenbrock function (offset from 0 ) is set to $c$, in this case -456.3 .</p>
<h3>5.4 CO model</h3>
<p>In order to model the CO molecule using multiple $\mathcal{I S}$, a simple zero-mean, $\frac{5}{3}$ Matérn kernel was chosen. ${ }^{48}$ From this, the expensive source, $\mathcal{I} \mathcal{S}<em 1="1">{0}$, was chosen to be a double-hybrid approach using the B2PLYP functional ${ }^{32}$ and Def2-TZVP basis set. ${ }^{33}$ The cheaper source, $\mathcal{I} \mathcal{S}</em>$ Since CO consists of only two atoms, $x$ was taken as the interatomic distance (in $\AA$ ), bound between $[0.5,2.0]$, in intervals of $0.001 \AA$. Five random sampled points were taken to initially train hyperparameters.}$, was taken to be a corrected Hartree-Fock approach. ${ }^{34}$ All DFT calculations were performed using the Orca software. ${ }^{49</p>
<h3>5.5 HOIP model</h3>
<p>The probabilistic model for the HOIP system is the same as that outlined in Herbol et al. ${ }^{9}$ This is illustrated in eqn (6), with the mean given in eqn (7) and the covariance matrix in eqn (8).</p>
<p>$$
\begin{gathered}
V(x)=\sum_{i=1}^{n} \alpha_{i} x_{i}+\beta(x)+\zeta+f\left(x_{z}, x_{\rho}\right) \
\mu_{x}^{0}=\frac{n}{3} \mu_{x}+\mu_{\zeta} \
\Sigma_{x, x^{\prime}}^{0}=\operatorname{Cov}\left(V_{x}, V_{x^{\prime}}\right) \
=\sigma_{x}^{2}\left|x_{1: n}\right\rangle\left\langle x_{1: n}^{\prime}\right|+\sigma_{p}^{2} I_{m}+\sigma_{\zeta}^{2} J_{m}+\Sigma_{0}\left(S_{x}, S_{x^{\prime}}\right)
\end{gathered}
$$</p>
<p>For $\Sigma_{0}\left(S_{x}, S_{x^{\prime}}\right)$ we chose the well known $\frac{5}{3}$ Matérn kernel, which provides the covariance between measurements made at any two points. ${ }^{48}$</p>
<p>In the original PAL work, data points were generated to represent the intermolecular binding energy of three solvent molecules to a HOIP lead salt modeled using an ab initio GGA DFT functional. It would also be possible to generate DFT data corresponding to other situations in which a different number of solvent molecules was considered, given that a full shell surrounding the lead salt involves around 25 molecules. ${ }^{50}$ Moreover, we can use various choices of level of DFT theory which may differ significantly in accuracy and cost. Overall sampling of the solvents around the salt were performed using Packmol, ${ }^{51}$ LAMMPS, ${ }^{52}$ and the OPLS-AA force field. ${ }^{53}$ Final geometry optimizations and energy calculations were made using Orca. ${ }^{49}$</p>
<p>We define information sources, for example, as GGA-3, where N3 indicates the case in which three solvent molecules are considered to be bound to the lead salt, and R2 represents the level of theory indexed within the PAL codebase (the label " 2 " corresponding to the GGA functional B97-D3 with a triple- $\zeta$ basis set). Simply changing the number of solvents bound to the lead salt, or the level of theory used, will give rise to a different $\mathcal{I S}$ label. In that regard, we have explored the following information sources for benchmarking purposes:</p>
<ul>
<li>GGA-5 - intermolecular binding energy of five solvent molecules to a perovskite lead salt using the GGA functional B97-D3 (179 data points).</li>
<li>GGA-3 - intermolecular binding energy of three solvent molecules to a perovskite lead salt using the GGA functional B97-D3 (240 data points).</li>
<li>GGA-1 - intermolecular binding energy of one solvent molecule to a perovskite lead salt using the GGA functional B97-D3 (480 data points).</li>
<li>Hybrid-1 - intermolecular binding energy of one solvent molecule to a perovskite lead salt using the hybrid functional PW6B95 (480 data points).</li>
</ul>
<p>When using multiple information sources from among these options, we chose only those that exist across all $\mathcal{I S}$. Thus, when we used two information sources as a test case, labeling them $\mathcal{I} \mathcal{S}<em 1="1">{0}$ and $\mathcal{I} \mathcal{S}</em>}$, we chose Hybrid-1 and GGA-1, for which a total of 480 data points exist. However, when $\mathcal{I} \mathcal{S<em 1="1">{0}$ and $\mathcal{I} \mathcal{S}</em>$ are GGA-3 and GGA-1, respectively, only the 240 intersecting points in the data sets would be used.</p>
<h2>Data availability</h2>
<p>The code for this article and the results of the benchmarks are publicly available at: https://www.github.com/clancylab/PAL, https://www.github.com/clancylab/MISO_Paper, respectively.</p>
<h2>Author contributions</h2>
<p>H. C. H. implemented the code and benchmarks. M. P. proposed the idea of coregionalization, and H. C. H. proposed the idea of using a Pearson correlation. M. P. and P. C. advised and supervised the progress of the research. H. C. H., M. P., and P. C. wrote the manuscript.</p>
<h2>Conflicts of interest</h2>
<p>The authors declare no competing interests.</p>
<h2>Acknowledgements</h2>
<p>H. C. H., P. C. and M. P. were partially supported by NSF CMMI1536895. H. C. H. and P. C. were partially supported by funds from the Whiting School of Engineering at the Johns Hopkins University. The authors gratefully acknowledge extensive computing resources used in this work that was provided by the Maryland Advanced Research Computing Center (MARCC). MARCC was partially funded by the State of Maryland and is jointly managed by the Johns Hopkins University and the University of Maryland.</p>
<h2>References</h2>
<p>1 D. B. Miracle and O. N. Senkov, Acta Mater., 2017, 122, 448-511.
2 P. Crescenzi, D. Goldman, C. Papadimitriou, A. Piccolboni and M. Yannakakis, J. Comput. Biol., 1998, 5, 423-465.
3 R. Evans, J. Jumper, J. Kirkpatrick, L. Sifre, T. F. G. Green, C. Qin, A. Zidek, A. Nelson, A. Bridgland, H. Penedones, S. Petersen, K. Simonyan, S. Crossan, D. T. Jones, D. Silver, K. Kavukcuoglu, D. Hassabis and A. W. Senior, Thirteenth Critical Assessment of Techniques for Protein Structure Prediction, 2018.</p>
<p>4 D. Xue, D. Xue, R. Yuan, Y. Zhou, P. V. Balachandran, X. Ding, J. Sun and T. Lookman, Acta Mater., 2017, 125, 532-541.
5 T. D. Sparks, M. W. Gaultois, A. Oliynyk, J. Brgoch and B. Meredig, Scr. Mater., 2016, 111, 10-15.</p>
<p>6 M. W. Gaultois, A. O. Oliynyk, A. Mar, T. D. Sparks, G. J. Mulholland and B. Meredig, APL Mater., 2016, 4, 053213.
7 J. S. Smith, O. Isayev and A. E. Roitberg, Chem. Sci., 2017, 8, 3192-3203.
8 Y. Huang, J. Kang, W. A. Goddard and L.-W. Wang, Phys. Rev. B, 2019, 99, 064103.
9 H. C. Herbol, W. Hu, P. Frazier, P. Clancy and M. Poloczek, npj Comput. Mater., 2018, 4, 51.
10 D. Jha, K. Choudhary, F. Tavazza, W.-k. Liao, A. Choudhary, C. Campbell and A. Agrawal, Nat. Commun., 2019, 10, 5316.</p>
<p>11 S. Haghanifar, M. McCourt, B. Cheng, J. Wuenschell, P. Ohodnicki and P. W. Leu, Mater. Horiz., 2019, 6, 1632-1642.
12 M. W. Lee, E. Y. Lee, A. L. Ferguson and G. C. Wong, Curr. Opin. Colloid Interface Sci., 2018, 38, 204-213.
13 A. Jinich, B. Sanchez-Lengeling, H. Ren, R. Harman and A. Aspuru-Guzik, ACS Cent. Sci., 2019, 5, 1199-1210.</p>
<p>14 S. Katare, A. Bhan, J. M. Caruthers, W. N. Delgass and V. Venkatasubramanian, Comput. Chem. Eng., 2004, 28, 2569-2581.
15 W. Sun, Y. Zheng, K. Yang, Q. Zhang, A. A. Shah, Z. Wu, Y. Sun, L. Feng, D. Chen, Z. Xiao, S. Lu, Y. Li and K. Sun, Sci. Adv., 2019, 5(11), DOI: 10.1126/sciadv.aay4275.</p>
<p>16 W. Sun, M. Li, Y. Li, Z. Wu, Y. Sun, S. Lu, Z. Xiao, B. Zhao and K. Sun, Adv. Theory Simul., 2019, 2, 1800116.
17 R. Garnett, S. Ho, S. Bird and J. Schneider, Mon. Not. R. Astron. Soc., 2017, 472, 1850-1865.
18 R. Gómez-Bombarelli, J. N. Wei, D. Duvenaud, J. M. Hernández-Lobato, B. Sánchez-Lengeling, D. Sheberla, J. Aguilera-Iparraguirre, T. D. Hirzel, R. P. Adams and A. Aspuru-Guzik, Automatic Chemical Design Using a DataDriven Continuous Representation of Molecules, 2017.
19 P. I. Frazier, A Tutorial on Bayesian Optimization, 2018.
20 R. Webster and M. A. Oliver, Statistics in Practice, John Wiley \&amp; Sons, Ltd, 2007, pp. 219-242.
21 E. V. Bonilla, K. M. Chai and C. Williams, Advances in Neural Information Processing Systems 20, Curran Associates, Inc., 2008, pp. 153-160.
22 M. Alvarez and N. D. Lawrence, Advances in Neural Information Processing Systems 21, Curran Associates, Inc., 2009, pp. 57-64.
23 M. Goulard and M. Voltz, Math. Geol., 1992, 24, 269-286.
24 T. Ishida and S. Kawashima, Theor. Appl. Climatol., 1993, 47, 147-157.
25 W. F. Krajewski, J. Geophys. Res.: Atmos., 1987, 92, 9571-9580.
26 M. Poloczek, J. Wang and P. Frazier, Advances in Neural Information Processing Systems 30, NIPS, 2017, pp. 4288-4298.
27 P. Goovaerts, Geostatistics for Natural Resource Evaluation, Oxford University Press, 1997, ch. 4, vol. 42, pp. 75-116.
28 J. Benesty, J. Chen, Y. Huang and I. Cohen, Noise reduction in speech processing, Springer, 2009, pp. 1-4.
29 D. R. Jones, M. Schonlau and W. J. Welch, J. Global Optim., 1998, 13, 455-492.
30 K. Swersky, J. Snoek and R. P. Adams, Proceedings of the 26th International Conference on Neural Information Processing Systems - Volume 2, USA, 2013, pp. 2004-2012.
31 H. H. Rosenbrock, Comput. J., 1960, 3, 175-184.
32 S. Grimme, J. Chem. Phys., 2006, 124, 034108.
33 F. Weigend and R. Ahlrichs, Phys. Chem. Chem. Phys., 2005, 7, 3297-3305.
34 S. Grimme, J. Antony, S. Ehrlich and H. Krieg, J. Chem. Phys., 2010, 132, 154104.
35 H. Kruse and S. Grimme, J. Chem. Phys., 2012, 136, 154101.
36 J. G. Brandenburg, M. Alessio, B. Civalleri, M. F. Peintinger, T. Bredow and S. Grimme, J. Phys. Chem. A, 2013, 117, 9282-9292.
37 S. Grimme, J. G. Brandenburg, C. Bannwarth and A. Hansen, J. Chem. Phys., 2015, 143, 054107.</p>
<p>38 S. Grimme, S. Ehrlich and L. Goerigk, J. Comput. Chem., 2011, 32, 1456-1465.
39 R. Sure and S. Grimme, J. Comput. Chem., 2013, 34, 1672-1685.
40 S. Grimme, J. Comput. Chem., 2006, 27, 1787-1799.
41 Y. Zhao and D. G. Truhlar, J. Phys. Chem. A, 2005, 109, 5656-5667.
42 M. A. Alvarez, L. Rosasco and N. D. Lawrence, Kernels for Vector-Valued Functions: a Review, 2011.
43 N. D. Lawrence and J. C. Platt, Proceedings of the Twentyfirst International Conference on Machine Learning, New York, NY, USA, 2004, p. 65.</p>
<p>44 K. Yu, V. Tresp and A. Schwaighofer, Machine Learning: Proceedings of the 22nd International Conference (ICML 2005), 2005, pp. 1012-1019.</p>
<p>45 M. A. Osborne, S. J. Roberts, A. Rogers, S. D. Ramchurn and N. R. Jennings, 2008 International Conference on Information Processing in Sensor Networks (ipsn 2008), 2008.
46 P. Virtanen, R. Gommers, T. E. Oliphant, M. Haberland, T. Reddy, D. Cournapeau, E. Burovski, P. Peterson, W. Weckesser, J. Bright, S. J. van der Walt, M. Brett, J. Wilson, K. Jarrod Millman, N. Mayorov, A. R. J. Nelson, E. Jones, R. Kern, E. Larson, C. J. Carey, İ. Polat, Y. Feng, E. W. Moore, J. Vander Plas, D. Laxalde, J. Perktold, R. Cimrman, I. Henriksen, E. A. Quintero, C. R. Harris,
A. M. Archibald, A. H. Ribeiro, F. Pedregosa, P. van Mulbregt and SciPy 1.0 Contributors, Nat. Methods, 2020, 17, 261-272.
47 R. Lam, D. Allaire and K. Willcox, 2015.
48 B. Minasny and A. B. McBratney, Geoderma, 2005, 128, 192-207.
49 F. Neese, Wiley Interdiscip. Rev.: Comput. Mol. Sci., 2012, 2, 73-78.
50 B. A. Sorenson, S. S. Hong, H. C. Herbol and P. Clancy, Comput. Mater. Sci., 2019, 170, 109138.
51 L. Martínez, R. Andrade, E. G. Birgin and J. M. Martínez, J. Comput. Chem., 2009, 30, 2157-2164.</p>
<p>52 S. Plimpton, J. Comput. Phys., 1995, 117, 1-19.
53 W. L. Jorgensen, D. S. Maxwell and J. Tirado-Rives, J. Am. Chem. Soc., 1996, 118, 11225-11236.</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>${ }^{a}$ Department of Chemical and Biomolecular Engineering, Johns Hopkins University, Baltimore, MD 21218, USA. E-mail: hherbol@jhu.edu
${ }^{\text {b }}$ Uber AI, San Francisco, CA 94105, USA
$\dagger$ Electronic supplementary information (ESI) available. See DOI: 10.1039/ d0mh00062k
$\ddagger$ This work was done while author was affiliated with the University of Arizona in Tucson, AZ, USA.&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>