<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-3009 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-3009</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-3009</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-73.html">extraction-schema-73</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models perform arithmetic, including mechanisms, internal representations, interventions, and performance on arithmetic tasks.</div>
                <p><strong>Paper ID:</strong> paper-263835293</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2310.07075v3.pdf" target="_blank">Don’t Fine-Tune, Decode: Syntax Error-Free Tool Use via Constrained Decoding</a></p>
                <p><strong>Paper Abstract:</strong> Instruction-tuned large language models (LLMs) excel at many tasks but often fail to use external tools due to complicated and unfamiliar syntax constraints. While extensive fine-tuning and prompting can mitigate the issue, these approaches are expensive and hard to generalize. Furthermore, because syntax constraints are only learned implicitly during fine-tuning, models still make frequent syntax errors. Motivated by the fact that these constraints can be better satisfied explicitly with constrained decoding, we propose T OOL D EC , a decoding algorithm using finite state machines to force LLMs to follow tool syntax. Our experiments show that T OOL D EC eliminates all syntax errors, achieving significantly better performance on various base models and benchmarks. More surprisingly, when applied to generalist out-of-the-box LLMs such as Mistral-Instruct, T OOL D EC improves its accuracy in tool use from the initial 0% to an impressive 52%, matching the performance of specialized fine-tuned models such as ToolLLM. We release our code at https://github.com/chenhongqiao/tooldec .</p>
                <p><strong>Cost:</strong> 0.015</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e3009.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e3009.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models perform arithmetic, including mechanisms, internal representations, interventions, and performance on arithmetic tasks.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>TOOLDEC</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>TOOLDEC (Finite-State Machine Constrained Decoding)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A decoding-time intervention that constrains an LLM's token choices using a finite-state machine (FSM) derived from tool syntax (e.g., OpenAPI/JSON schema) so the model can only generate syntactically valid tool calls; also paired with prompt compression to remove syntax from prompts.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>arithmetic_task_type</strong></td>
                            <td>Used as the decoding intervention for arithmetic-as-tools tasks (FuncQA): problems requiring discrete arithmetic operations (multiply, power, lcm, etc.) called as tools; average ~2.78 tool calls per problem.</td>
                        </tr>
                        <tr>
                            <td><strong>reported_mechanism</strong></td>
                            <td>Enables correct arithmetic by forcing syntactically valid external tool invocations (i.e., the model issues calls to arithmetic operator tools rather than relying on internal numeric computation); enforces hard syntax constraints via an FSM that masks invalid next-token logits.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_for_mechanism</strong></td>
                            <td>Experimentally eliminates all syntax errors across evaluated models; when applied to FuncQA (numerical reasoning via arithmetic tools) it increases generalist LLM accuracy (paper reports LLaMA's FuncQA performance increases by ~2.2×). Token-masking during decoding shown in examples and pseudocode; ablation shows decoding-time constraints are far more effective than prompting syntactic constraints.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_against_mechanism</strong></td>
                            <td>No direct evidence provided that TOOLDEC changes internal numeric representations or reasoning strategies; improvements could be exclusively due to enabling correct tool invocation (the paper does not probe internal arithmetic computations).</td>
                        </tr>
                        <tr>
                            <td><strong>intervention_type</strong></td>
                            <td>Constrained decoding (FSM token masking) + prompt compression (remove syntactic detail from prompts).</td>
                        </tr>
                        <tr>
                            <td><strong>effect_of_intervention</strong></td>
                            <td>Eliminated syntax errors entirely for tool calls; substantially improved accuracy on tool-based arithmetic benchmarks (FuncQA) and other tool-use tasks; shortened per-tool prompt token counts (reported reductions of ~58% and ~69% on ToolEval subsets).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Eliminates syntax error rate to 0% for evaluated models on tool-call generation. On arithmetic benchmark FuncQA (68 problems, 0.1% numeric tolerance), application of TOOLDEC to generalist LLaMA yields a reported ~2.2× accuracy improvement (exact accuracy numbers not unambiguously provided in paper text). Average number of tool calls per FuncQA problem: 2.78. Prompt token reduction per tool: ~58% (I2-Category) and ~69% (I3-Instruction) on ToolEval.</td>
                        </tr>
                        <tr>
                            <td><strong>notable_failure_modes</strong></td>
                            <td>TOOLDEC only addresses syntactic correctness; semantic errors, wrong tool selection, incorrect arguments, or downstream numerical mistakes (incorrect computation by the tool or incorrect use of tool outputs) remain possible. The paper explicitly notes 'syntax error-free doesn't mean error-free.'</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_humans_or_symbolic</strong></td>
                            <td>TOOLDEC is positioned as enabling LLMs to use symbolic arithmetic tools (i.e., external calculators/operators); no direct head-to-head numerical accuracy comparison to humans or symbolic calculators is reported in the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Don’t Fine-Tune, Decode: Syntax Error-Free Tool Use via Constrained Decoding', 'publication_date_yy_mm': '2023-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3009.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e3009.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models perform arithmetic, including mechanisms, internal representations, interventions, and performance on arithmetic tasks.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>FuncQA (as used in paper)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>FuncQA (numerical reasoning benchmark using arithmetic operator tools)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A benchmark of 68 math problems where LLMs must produce numerical answers by invoking arithmetic operation tools (e.g., multiply, power, lcm); correctness judged with 0.1% tolerance and problems require on average 2.78 tool calls.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>FuncQA (Hao et al., 2023)</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>arithmetic_task_type</strong></td>
                            <td>Math word problems requiring use of primitive arithmetic operator tools (multiply, power, lcm, etc.); chained operations across multiple tool calls per problem (mean 2.78 calls).</td>
                        </tr>
                        <tr>
                            <td><strong>reported_mechanism</strong></td>
                            <td>Designed to require the model to call discrete arithmetic tools for computation rather than relying solely on the model's internal numeric computation; treats arithmetic operators as external tools accessible via API-like invocations.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_for_mechanism</strong></td>
                            <td>Benchmark design and evaluation use tools as the mechanism for computation; paper reports models using tool-calling (and that enabling correct calls via TOOLDEC improves performance).</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_against_mechanism</strong></td>
                            <td>Benchmark does not, by itself, reveal whether models sometimes compute internally instead of calling tools; the paper does not present probing to show internal arithmetic vs. tool usage per-se.</td>
                        </tr>
                        <tr>
                            <td><strong>intervention_type</strong></td>
                            <td>Evaluated with and without constrained decoding (TOOLDEC); also compared to prompting and fine-tuning approaches in paper ablations.</td>
                        </tr>
                        <tr>
                            <td><strong>effect_of_intervention</strong></td>
                            <td>Applying TOOLDEC to generalist LLMs increased FuncQA performance markedly (paper: LLaMA's performance increases by ~2.2× on FuncQA when using TOOLDEC).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>68 problems; correctness uses 0.1% numeric tolerance; average tool calls per problem = 2.78. Exact accuracy numbers per-model are provided in paper tables but not consistently unambiguous in the text; relative improvements (e.g., 2.2× for LLaMA) are reported.</td>
                        </tr>
                        <tr>
                            <td><strong>notable_failure_modes</strong></td>
                            <td>Syntax errors when generating tool calls prevent evaluation (many generalist models initially produced >90% syntax error rates on tool tasks, leading to effectively 0% accuracy). Even with syntax fixed, semantic mistakes in reasoning or wrong tool selection remain.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_humans_or_symbolic</strong></td>
                            <td>FuncQA is constructed to reward correct symbolic computation via tools; no explicit human baseline or calculator baseline is reported in this paper's discussion of FuncQA results.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Don’t Fine-Tune, Decode: Syntax Error-Free Tool Use via Constrained Decoding', 'publication_date_yy_mm': '2023-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3009.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e3009.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models perform arithmetic, including mechanisms, internal representations, interventions, and performance on arithmetic tasks.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LLaMA-7B</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>LLaMA-7B (generalist instruction-tuned LLM)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A 7B-parameter open foundation model instruction-tuned for general tasks; used in the paper as a generalist baseline for tool use and arithmetic-via-tools evaluation.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>LLaMA-7B</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Generalist 7B transformer model (LLaMA family), instruction-tuned; not fine-tuned specifically for tool use in the experiments reported.</td>
                        </tr>
                        <tr>
                            <td><strong>arithmetic_task_type</strong></td>
                            <td>Evaluated on FuncQA (math problems that require calling arithmetic operator tools), where problems require chained operator calls (average 2.78 calls).</td>
                        </tr>
                        <tr>
                            <td><strong>reported_mechanism</strong></td>
                            <td>Performs arithmetic in these experiments by generating tool calls (external operator invocations) when syntax permits; without correct tool-call syntax enforcement, LLaMA tends to fail (low baseline performance).</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_for_mechanism</strong></td>
                            <td>When decoding-time constraints (TOOLDEC) are applied to force syntactically valid tool calls, LLaMA's FuncQA performance improves substantially (reported ~2.2× improvement), indicating the primary failure mode was inability to generate valid tool calls rather than inability to solve the arithmetic when tools are available.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_against_mechanism</strong></td>
                            <td>No internal probing or representational analysis provided; the paper does not claim LLaMA performs internal symbolic arithmetic for these tasks and does not provide direct evidence about internal numeric representations.</td>
                        </tr>
                        <tr>
                            <td><strong>intervention_type</strong></td>
                            <td>Applied TOOLDEC (FSM-constrained decoding) and prompt compression; compared to prompting-based inclusion of syntax in-context.</td>
                        </tr>
                        <tr>
                            <td><strong>effect_of_intervention</strong></td>
                            <td>Marked accuracy increase on FuncQA (reportedly ~2.2×); eliminated syntax errors that previously caused near-zero pass rates on tool-using tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Paper reports relative improvements (2.2× on FuncQA) and that LLaMA with TOOLDEC achieves higher accuracy than its baseline; exact numeric accuracies are presented in paper tables but are not consistently unambiguous in the main text. Syntax error rate reduced from high (baseline unspecified for LLaMA) to 0% with TOOLDEC.</td>
                        </tr>
                        <tr>
                            <td><strong>notable_failure_modes</strong></td>
                            <td>Without constrained decoding, LLaMA (like other generalists) produces very high syntax error rates on tool calls, leading to failure on arithmetic-as-tool tasks; even with TOOLDEC, semantic/tool-selection errors can persist.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_humans_or_symbolic</strong></td>
                            <td>No direct comparison to human performance or exact symbolic calculators in this paper; the approach effectively delegates arithmetic correctness to symbolic tools.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Don’t Fine-Tune, Decode: Syntax Error-Free Tool Use via Constrained Decoding', 'publication_date_yy_mm': '2023-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3009.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e3009.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models perform arithmetic, including mechanisms, internal representations, interventions, and performance on arithmetic tasks.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Mistral-7B-Instruct</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Mistral-7B-Instruct (generalist instruction-tuned LLM)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A 7B-parameter instruction-tuned generalist LLM evaluated as an out-of-the-box model for tool use; initially produces very high syntax error rates when asked to call unfamiliar tools.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Mistral 7b</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Mistral-7B-Instruct</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Generalist 7B transformer model instruction-tuned (Mistral family); not fine-tuned for tool use in these experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>arithmetic_task_type</strong></td>
                            <td>Evaluated on tool-use benchmarks including FuncQA where arithmetic is performed via external operator tools.</td>
                        </tr>
                        <tr>
                            <td><strong>reported_mechanism</strong></td>
                            <td>Relies on generating tool-call text; fails primarily due to syntax errors when the syntax is unfamiliar, rather than necessarily failing on arithmetic reasoning per se.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_for_mechanism</strong></td>
                            <td>Mistral initially had >90% syntax error rates on ToolEval, resulting in 0% accuracy; when TOOLDEC constrained decoding was applied, Mistral's tool-use accuracy rose from 0% to as high as ~52% on some tool-use tasks (paper reports large absolute improvements), demonstrating that the inability to emit valid tool syntax (rather than arithmetic competence) was a primary failure mode.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_against_mechanism</strong></td>
                            <td>Paper does not probe internal arithmetic representations or whether Mistral can compute numbers internally; only shows that enabling correct external tool invocation drastically improves task success.</td>
                        </tr>
                        <tr>
                            <td><strong>intervention_type</strong></td>
                            <td>TOOLDEC (FSM-constrained decoding) + compressed prompts.</td>
                        </tr>
                        <tr>
                            <td><strong>effect_of_intervention</strong></td>
                            <td>Transformed near-zero baseline tool-use performance to substantial pass/win rates (e.g., paper states Mistral-Instruct improved from initial 0% to up to 52% accuracy on tool-use tasks in some settings). Eliminated syntax errors.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Reported: baseline 0% accuracy on some ToolEval subsets due to syntax errors; with TOOLDEC, accuracy rose to as high as 52% in the reported experiments; syntax error rate reduced from >90% to 0%.</td>
                        </tr>
                        <tr>
                            <td><strong>notable_failure_modes</strong></td>
                            <td>Before TOOLDEC: extremely high syntax error rate (>90%). After TOOLDEC: remaining errors are semantic (wrong tool selection, incorrect argument values) rather than syntactic.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_humans_or_symbolic</strong></td>
                            <td>No direct comparisons to human or symbolic calculator performance; TOOLDEC enables symbolic operators to be invoked so final numerical correctness depends on correct use of those tools.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Don’t Fine-Tune, Decode: Syntax Error-Free Tool Use via Constrained Decoding', 'publication_date_yy_mm': '2023-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3009.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e3009.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models perform arithmetic, including mechanisms, internal representations, interventions, and performance on arithmetic tasks.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ToolkenGPT (Tool tokens)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>ToolkenGPT (Llama-33B with learned tool tokens)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A specialist tool-use model that augments Llama-33B with an extra vocabulary of learned 'tool tokens' (toolkens) representing tool uses; tokens are learned so the frozen base model can signal tool invocation.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Toolkengpt</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>ToolkenGPT (Llama-33B with tool tokens)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Specialist Llama-33B model whose original weights are frozen and which learns additional tokens corresponding to tools; the model was fine-tuned to represent tool use compactly.</td>
                        </tr>
                        <tr>
                            <td><strong>arithmetic_task_type</strong></td>
                            <td>Evaluated on FuncQA (arithmetic-as-tools) and other tool-use benchmarks where arithmetic operations are exposed as callable tools or operators.</td>
                        </tr>
                        <tr>
                            <td><strong>reported_mechanism</strong></td>
                            <td>Performs arithmetic by emitting learned tool tokens that represent tool calls (a learned discrete representation for tools) rather than producing full tool-call syntax; still needs correct mapping from token to tool invocation at inference time.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_for_mechanism</strong></td>
                            <td>Paper references ToolkenGPT as a baseline specialist; TOOLDEC applied to generalist models can match or exceed ToolkenGPT performance, suggesting that explicit decoding constraints can substitute for learned tool-token representations. Paper's Table 1 shows ToolkenGPT baseline and small absolute improvements when TOOLDEC is applied.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_against_mechanism</strong></td>
                            <td>No internal probing in this paper showing whether ToolkenGPT computes internally vs. relying on the tool tokens; the paper notes ToolkenGPT requires learning representations for each tool (limiting generalization to unseen tools).</td>
                        </tr>
                        <tr>
                            <td><strong>intervention_type</strong></td>
                            <td>Compared specialist fine-tuning (tool tokens) vs. decoding-time FSM constraints; TOOLDEC is proposed as a complementary/alternative intervention.</td>
                        </tr>
                        <tr>
                            <td><strong>effect_of_intervention</strong></td>
                            <td>TOOLDEC applied to models (including specialists) reduces syntax errors and can improve accuracy; generalists + TOOLDEC can match or beat ToolkenGPT without fine-tuning. Paper reports modest numeric improvements for ToolkenGPT when TOOLDEC applied.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Table entries in paper indicate ToolkenGPT has non-zero FuncQA accuracy (single-digit to low double-digit percentages) and TOOLDEC yields improvements (specific numbers are present in tables but not unambiguously repeated in main text).</td>
                        </tr>
                        <tr>
                            <td><strong>notable_failure_modes</strong></td>
                            <td>Requires learned tokens for each tool and therefore needs fine-tuning to add new tools; still prone to syntax/format errors if not handled properly at inference.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_humans_or_symbolic</strong></td>
                            <td>No direct comparison; ToolkenGPT represents a learned interface to symbolic tools rather than invoking external calculators directly in raw text.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Don’t Fine-Tune, Decode: Syntax Error-Free Tool Use via Constrained Decoding', 'publication_date_yy_mm': '2023-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3009.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e3009.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models perform arithmetic, including mechanisms, internal representations, interventions, and performance on arithmetic tasks.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ChatGPT (baseline use)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>ChatGPT (used as a baseline with ReAct/DFSDT strategies)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A large instruct-capable conversational model used as a baseline in tool-use evaluations; used with ReAct and DFSDT planning strategies in experiments comparing model win/pass rates.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>ChatGPT</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Closed-source instruction-following conversational model (OpenAI); used as a baseline for tool-use benchmarks in the paper, tested with planning/acting strategies ReAct and DFSDT.</td>
                        </tr>
                        <tr>
                            <td><strong>arithmetic_task_type</strong></td>
                            <td>Used for tool-use comparisons that include arithmetic-as-tools tasks (e.g., FuncQA) and broader tool-call benchmarks (ToolEval); sometimes evaluated without external tools as well.</td>
                        </tr>
                        <tr>
                            <td><strong>reported_mechanism</strong></td>
                            <td>When used with tools, ChatGPT emits tool calls; however, even advanced models like ChatGPT sometimes make syntax errors on new tools, indicating the mechanism of tool use can fail at the syntactic generation step.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_for_mechanism</strong></td>
                            <td>Paper reports ChatGPT makes syntax errors in tool interactions (non-zero syntax error rates) and that specialist models or TOOLDEC can surpass or match ChatGPT performance in tool-use benchmarks.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_against_mechanism</strong></td>
                            <td>No internal representational evidence; the paper simply observes syntactic failures and uses constrained decoding to prevent them.</td>
                        </tr>
                        <tr>
                            <td><strong>intervention_type</strong></td>
                            <td>Compared baselines with and without constrained decoding (TOOLDEC) and with different planning strategies (ReAct, DFSDT).</td>
                        </tr>
                        <tr>
                            <td><strong>effect_of_intervention</strong></td>
                            <td>Applying TOOLDEC reduces syntax errors; in some tool-use settings TOOLDEC-enabled generalists match or exceed ChatGPT baseline performance (exact numeric comparisons in tables).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Paper reports ChatGPT win/pass rates in ToolEval and notes syntax error rates for ChatGPT are non-zero; exact numeric values are present in tables of the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>notable_failure_modes</strong></td>
                            <td>Produces syntax errors on unfamiliar tool formats; errors persist even in advanced models, motivating decoding-time interventions.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_humans_or_symbolic</strong></td>
                            <td>No explicit numeric comparison to humans or symbolic calculators presented in the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Don’t Fine-Tune, Decode: Syntax Error-Free Tool Use via Constrained Decoding', 'publication_date_yy_mm': '2023-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Facilitating large language models to master 16000+ real-world apis <em>(Rating: 2)</em></li>
                <li>Toolkengpt <em>(Rating: 2)</em></li>
                <li>Toolformer <em>(Rating: 2)</em></li>
                <li>Restgpt, Connecting large language models with real-world restful apis <em>(Rating: 1)</em></li>
                <li>Program of thoughts prompting: Disentangling computation from reasoning for numerical reasoning tasks <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-3009",
    "paper_id": "paper-263835293",
    "extraction_schema_id": "extraction-schema-73",
    "extracted_data": [
        {
            "name_short": "TOOLDEC",
            "name_full": "TOOLDEC (Finite-State Machine Constrained Decoding)",
            "brief_description": "A decoding-time intervention that constrains an LLM's token choices using a finite-state machine (FSM) derived from tool syntax (e.g., OpenAPI/JSON schema) so the model can only generate syntactically valid tool calls; also paired with prompt compression to remove syntax from prompts.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": null,
            "model_description": null,
            "arithmetic_task_type": "Used as the decoding intervention for arithmetic-as-tools tasks (FuncQA): problems requiring discrete arithmetic operations (multiply, power, lcm, etc.) called as tools; average ~2.78 tool calls per problem.",
            "reported_mechanism": "Enables correct arithmetic by forcing syntactically valid external tool invocations (i.e., the model issues calls to arithmetic operator tools rather than relying on internal numeric computation); enforces hard syntax constraints via an FSM that masks invalid next-token logits.",
            "evidence_for_mechanism": "Experimentally eliminates all syntax errors across evaluated models; when applied to FuncQA (numerical reasoning via arithmetic tools) it increases generalist LLM accuracy (paper reports LLaMA's FuncQA performance increases by ~2.2×). Token-masking during decoding shown in examples and pseudocode; ablation shows decoding-time constraints are far more effective than prompting syntactic constraints.",
            "evidence_against_mechanism": "No direct evidence provided that TOOLDEC changes internal numeric representations or reasoning strategies; improvements could be exclusively due to enabling correct tool invocation (the paper does not probe internal arithmetic computations).",
            "intervention_type": "Constrained decoding (FSM token masking) + prompt compression (remove syntactic detail from prompts).",
            "effect_of_intervention": "Eliminated syntax errors entirely for tool calls; substantially improved accuracy on tool-based arithmetic benchmarks (FuncQA) and other tool-use tasks; shortened per-tool prompt token counts (reported reductions of ~58% and ~69% on ToolEval subsets).",
            "performance_metrics": "Eliminates syntax error rate to 0% for evaluated models on tool-call generation. On arithmetic benchmark FuncQA (68 problems, 0.1% numeric tolerance), application of TOOLDEC to generalist LLaMA yields a reported ~2.2× accuracy improvement (exact accuracy numbers not unambiguously provided in paper text). Average number of tool calls per FuncQA problem: 2.78. Prompt token reduction per tool: ~58% (I2-Category) and ~69% (I3-Instruction) on ToolEval.",
            "notable_failure_modes": "TOOLDEC only addresses syntactic correctness; semantic errors, wrong tool selection, incorrect arguments, or downstream numerical mistakes (incorrect computation by the tool or incorrect use of tool outputs) remain possible. The paper explicitly notes 'syntax error-free doesn't mean error-free.'",
            "comparison_to_humans_or_symbolic": "TOOLDEC is positioned as enabling LLMs to use symbolic arithmetic tools (i.e., external calculators/operators); no direct head-to-head numerical accuracy comparison to humans or symbolic calculators is reported in the paper.",
            "uuid": "e3009.0",
            "source_info": {
                "paper_title": "Don’t Fine-Tune, Decode: Syntax Error-Free Tool Use via Constrained Decoding",
                "publication_date_yy_mm": "2023-10"
            }
        },
        {
            "name_short": "FuncQA (as used in paper)",
            "name_full": "FuncQA (numerical reasoning benchmark using arithmetic operator tools)",
            "brief_description": "A benchmark of 68 math problems where LLMs must produce numerical answers by invoking arithmetic operation tools (e.g., multiply, power, lcm); correctness judged with 0.1% tolerance and problems require on average 2.78 tool calls.",
            "citation_title": "FuncQA (Hao et al., 2023)",
            "mention_or_use": "use",
            "model_name": null,
            "model_description": null,
            "arithmetic_task_type": "Math word problems requiring use of primitive arithmetic operator tools (multiply, power, lcm, etc.); chained operations across multiple tool calls per problem (mean 2.78 calls).",
            "reported_mechanism": "Designed to require the model to call discrete arithmetic tools for computation rather than relying solely on the model's internal numeric computation; treats arithmetic operators as external tools accessible via API-like invocations.",
            "evidence_for_mechanism": "Benchmark design and evaluation use tools as the mechanism for computation; paper reports models using tool-calling (and that enabling correct calls via TOOLDEC improves performance).",
            "evidence_against_mechanism": "Benchmark does not, by itself, reveal whether models sometimes compute internally instead of calling tools; the paper does not present probing to show internal arithmetic vs. tool usage per-se.",
            "intervention_type": "Evaluated with and without constrained decoding (TOOLDEC); also compared to prompting and fine-tuning approaches in paper ablations.",
            "effect_of_intervention": "Applying TOOLDEC to generalist LLMs increased FuncQA performance markedly (paper: LLaMA's performance increases by ~2.2× on FuncQA when using TOOLDEC).",
            "performance_metrics": "68 problems; correctness uses 0.1% numeric tolerance; average tool calls per problem = 2.78. Exact accuracy numbers per-model are provided in paper tables but not consistently unambiguous in the text; relative improvements (e.g., 2.2× for LLaMA) are reported.",
            "notable_failure_modes": "Syntax errors when generating tool calls prevent evaluation (many generalist models initially produced &gt;90% syntax error rates on tool tasks, leading to effectively 0% accuracy). Even with syntax fixed, semantic mistakes in reasoning or wrong tool selection remain.",
            "comparison_to_humans_or_symbolic": "FuncQA is constructed to reward correct symbolic computation via tools; no explicit human baseline or calculator baseline is reported in this paper's discussion of FuncQA results.",
            "uuid": "e3009.1",
            "source_info": {
                "paper_title": "Don’t Fine-Tune, Decode: Syntax Error-Free Tool Use via Constrained Decoding",
                "publication_date_yy_mm": "2023-10"
            }
        },
        {
            "name_short": "LLaMA-7B",
            "name_full": "LLaMA-7B (generalist instruction-tuned LLM)",
            "brief_description": "A 7B-parameter open foundation model instruction-tuned for general tasks; used in the paper as a generalist baseline for tool use and arithmetic-via-tools evaluation.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "LLaMA-7B",
            "model_description": "Generalist 7B transformer model (LLaMA family), instruction-tuned; not fine-tuned specifically for tool use in the experiments reported.",
            "arithmetic_task_type": "Evaluated on FuncQA (math problems that require calling arithmetic operator tools), where problems require chained operator calls (average 2.78 calls).",
            "reported_mechanism": "Performs arithmetic in these experiments by generating tool calls (external operator invocations) when syntax permits; without correct tool-call syntax enforcement, LLaMA tends to fail (low baseline performance).",
            "evidence_for_mechanism": "When decoding-time constraints (TOOLDEC) are applied to force syntactically valid tool calls, LLaMA's FuncQA performance improves substantially (reported ~2.2× improvement), indicating the primary failure mode was inability to generate valid tool calls rather than inability to solve the arithmetic when tools are available.",
            "evidence_against_mechanism": "No internal probing or representational analysis provided; the paper does not claim LLaMA performs internal symbolic arithmetic for these tasks and does not provide direct evidence about internal numeric representations.",
            "intervention_type": "Applied TOOLDEC (FSM-constrained decoding) and prompt compression; compared to prompting-based inclusion of syntax in-context.",
            "effect_of_intervention": "Marked accuracy increase on FuncQA (reportedly ~2.2×); eliminated syntax errors that previously caused near-zero pass rates on tool-using tasks.",
            "performance_metrics": "Paper reports relative improvements (2.2× on FuncQA) and that LLaMA with TOOLDEC achieves higher accuracy than its baseline; exact numeric accuracies are presented in paper tables but are not consistently unambiguous in the main text. Syntax error rate reduced from high (baseline unspecified for LLaMA) to 0% with TOOLDEC.",
            "notable_failure_modes": "Without constrained decoding, LLaMA (like other generalists) produces very high syntax error rates on tool calls, leading to failure on arithmetic-as-tool tasks; even with TOOLDEC, semantic/tool-selection errors can persist.",
            "comparison_to_humans_or_symbolic": "No direct comparison to human performance or exact symbolic calculators in this paper; the approach effectively delegates arithmetic correctness to symbolic tools.",
            "uuid": "e3009.2",
            "source_info": {
                "paper_title": "Don’t Fine-Tune, Decode: Syntax Error-Free Tool Use via Constrained Decoding",
                "publication_date_yy_mm": "2023-10"
            }
        },
        {
            "name_short": "Mistral-7B-Instruct",
            "name_full": "Mistral-7B-Instruct (generalist instruction-tuned LLM)",
            "brief_description": "A 7B-parameter instruction-tuned generalist LLM evaluated as an out-of-the-box model for tool use; initially produces very high syntax error rates when asked to call unfamiliar tools.",
            "citation_title": "Mistral 7b",
            "mention_or_use": "use",
            "model_name": "Mistral-7B-Instruct",
            "model_description": "Generalist 7B transformer model instruction-tuned (Mistral family); not fine-tuned for tool use in these experiments.",
            "arithmetic_task_type": "Evaluated on tool-use benchmarks including FuncQA where arithmetic is performed via external operator tools.",
            "reported_mechanism": "Relies on generating tool-call text; fails primarily due to syntax errors when the syntax is unfamiliar, rather than necessarily failing on arithmetic reasoning per se.",
            "evidence_for_mechanism": "Mistral initially had &gt;90% syntax error rates on ToolEval, resulting in 0% accuracy; when TOOLDEC constrained decoding was applied, Mistral's tool-use accuracy rose from 0% to as high as ~52% on some tool-use tasks (paper reports large absolute improvements), demonstrating that the inability to emit valid tool syntax (rather than arithmetic competence) was a primary failure mode.",
            "evidence_against_mechanism": "Paper does not probe internal arithmetic representations or whether Mistral can compute numbers internally; only shows that enabling correct external tool invocation drastically improves task success.",
            "intervention_type": "TOOLDEC (FSM-constrained decoding) + compressed prompts.",
            "effect_of_intervention": "Transformed near-zero baseline tool-use performance to substantial pass/win rates (e.g., paper states Mistral-Instruct improved from initial 0% to up to 52% accuracy on tool-use tasks in some settings). Eliminated syntax errors.",
            "performance_metrics": "Reported: baseline 0% accuracy on some ToolEval subsets due to syntax errors; with TOOLDEC, accuracy rose to as high as 52% in the reported experiments; syntax error rate reduced from &gt;90% to 0%.",
            "notable_failure_modes": "Before TOOLDEC: extremely high syntax error rate (&gt;90%). After TOOLDEC: remaining errors are semantic (wrong tool selection, incorrect argument values) rather than syntactic.",
            "comparison_to_humans_or_symbolic": "No direct comparisons to human or symbolic calculator performance; TOOLDEC enables symbolic operators to be invoked so final numerical correctness depends on correct use of those tools.",
            "uuid": "e3009.3",
            "source_info": {
                "paper_title": "Don’t Fine-Tune, Decode: Syntax Error-Free Tool Use via Constrained Decoding",
                "publication_date_yy_mm": "2023-10"
            }
        },
        {
            "name_short": "ToolkenGPT (Tool tokens)",
            "name_full": "ToolkenGPT (Llama-33B with learned tool tokens)",
            "brief_description": "A specialist tool-use model that augments Llama-33B with an extra vocabulary of learned 'tool tokens' (toolkens) representing tool uses; tokens are learned so the frozen base model can signal tool invocation.",
            "citation_title": "Toolkengpt",
            "mention_or_use": "use",
            "model_name": "ToolkenGPT (Llama-33B with tool tokens)",
            "model_description": "Specialist Llama-33B model whose original weights are frozen and which learns additional tokens corresponding to tools; the model was fine-tuned to represent tool use compactly.",
            "arithmetic_task_type": "Evaluated on FuncQA (arithmetic-as-tools) and other tool-use benchmarks where arithmetic operations are exposed as callable tools or operators.",
            "reported_mechanism": "Performs arithmetic by emitting learned tool tokens that represent tool calls (a learned discrete representation for tools) rather than producing full tool-call syntax; still needs correct mapping from token to tool invocation at inference time.",
            "evidence_for_mechanism": "Paper references ToolkenGPT as a baseline specialist; TOOLDEC applied to generalist models can match or exceed ToolkenGPT performance, suggesting that explicit decoding constraints can substitute for learned tool-token representations. Paper's Table 1 shows ToolkenGPT baseline and small absolute improvements when TOOLDEC is applied.",
            "evidence_against_mechanism": "No internal probing in this paper showing whether ToolkenGPT computes internally vs. relying on the tool tokens; the paper notes ToolkenGPT requires learning representations for each tool (limiting generalization to unseen tools).",
            "intervention_type": "Compared specialist fine-tuning (tool tokens) vs. decoding-time FSM constraints; TOOLDEC is proposed as a complementary/alternative intervention.",
            "effect_of_intervention": "TOOLDEC applied to models (including specialists) reduces syntax errors and can improve accuracy; generalists + TOOLDEC can match or beat ToolkenGPT without fine-tuning. Paper reports modest numeric improvements for ToolkenGPT when TOOLDEC applied.",
            "performance_metrics": "Table entries in paper indicate ToolkenGPT has non-zero FuncQA accuracy (single-digit to low double-digit percentages) and TOOLDEC yields improvements (specific numbers are present in tables but not unambiguously repeated in main text).",
            "notable_failure_modes": "Requires learned tokens for each tool and therefore needs fine-tuning to add new tools; still prone to syntax/format errors if not handled properly at inference.",
            "comparison_to_humans_or_symbolic": "No direct comparison; ToolkenGPT represents a learned interface to symbolic tools rather than invoking external calculators directly in raw text.",
            "uuid": "e3009.4",
            "source_info": {
                "paper_title": "Don’t Fine-Tune, Decode: Syntax Error-Free Tool Use via Constrained Decoding",
                "publication_date_yy_mm": "2023-10"
            }
        },
        {
            "name_short": "ChatGPT (baseline use)",
            "name_full": "ChatGPT (used as a baseline with ReAct/DFSDT strategies)",
            "brief_description": "A large instruct-capable conversational model used as a baseline in tool-use evaluations; used with ReAct and DFSDT planning strategies in experiments comparing model win/pass rates.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "ChatGPT",
            "model_description": "Closed-source instruction-following conversational model (OpenAI); used as a baseline for tool-use benchmarks in the paper, tested with planning/acting strategies ReAct and DFSDT.",
            "arithmetic_task_type": "Used for tool-use comparisons that include arithmetic-as-tools tasks (e.g., FuncQA) and broader tool-call benchmarks (ToolEval); sometimes evaluated without external tools as well.",
            "reported_mechanism": "When used with tools, ChatGPT emits tool calls; however, even advanced models like ChatGPT sometimes make syntax errors on new tools, indicating the mechanism of tool use can fail at the syntactic generation step.",
            "evidence_for_mechanism": "Paper reports ChatGPT makes syntax errors in tool interactions (non-zero syntax error rates) and that specialist models or TOOLDEC can surpass or match ChatGPT performance in tool-use benchmarks.",
            "evidence_against_mechanism": "No internal representational evidence; the paper simply observes syntactic failures and uses constrained decoding to prevent them.",
            "intervention_type": "Compared baselines with and without constrained decoding (TOOLDEC) and with different planning strategies (ReAct, DFSDT).",
            "effect_of_intervention": "Applying TOOLDEC reduces syntax errors; in some tool-use settings TOOLDEC-enabled generalists match or exceed ChatGPT baseline performance (exact numeric comparisons in tables).",
            "performance_metrics": "Paper reports ChatGPT win/pass rates in ToolEval and notes syntax error rates for ChatGPT are non-zero; exact numeric values are present in tables of the paper.",
            "notable_failure_modes": "Produces syntax errors on unfamiliar tool formats; errors persist even in advanced models, motivating decoding-time interventions.",
            "comparison_to_humans_or_symbolic": "No explicit numeric comparison to humans or symbolic calculators presented in the paper.",
            "uuid": "e3009.5",
            "source_info": {
                "paper_title": "Don’t Fine-Tune, Decode: Syntax Error-Free Tool Use via Constrained Decoding",
                "publication_date_yy_mm": "2023-10"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Facilitating large language models to master 16000+ real-world apis",
            "rating": 2,
            "sanitized_title": "facilitating_large_language_models_to_master_16000_realworld_apis"
        },
        {
            "paper_title": "Toolkengpt",
            "rating": 2,
            "sanitized_title": "toolkengpt"
        },
        {
            "paper_title": "Toolformer",
            "rating": 2,
            "sanitized_title": "toolformer"
        },
        {
            "paper_title": "Restgpt, Connecting large language models with real-world restful apis",
            "rating": 1,
            "sanitized_title": "restgpt_connecting_large_language_models_with_realworld_restful_apis"
        },
        {
            "paper_title": "Program of thoughts prompting: Disentangling computation from reasoning for numerical reasoning tasks",
            "rating": 1,
            "sanitized_title": "program_of_thoughts_prompting_disentangling_computation_from_reasoning_for_numerical_reasoning_tasks"
        }
    ],
    "cost": 0.01464275,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Don't Fine-Tune, Decode: Syntax Error-Free Tool Use via Constrained Decoding
4 Jun 2024</p>
<p>Kexun Zhang 
Hongqiao Chen 
Lei Li leili@cs.cmu.edu 
William Yang william@cs.ucsb.edu 
Wang Uc 
Santa Barbara </p>
<p>Carnegie Mellon University</p>
<p>California Institute of Technology</p>
<p>Carnegie Mellon University</p>
<p>Don't Fine-Tune, Decode: Syntax Error-Free Tool Use via Constrained Decoding
4 Jun 2024857E1285B90D21E0FC146B6B584AEAD6arXiv:2310.07075v3[cs.CL]Preprint. Under review
Instruction-tuned large language models (LLMs) excel at many tasks but often fail to use external tools due to complicated and unfamiliar syntax constraints.While extensive fine-tuning and prompting can mitigate the issue, these approaches are expensive and hard to generalize.Furthermore, because syntax constraints are only learned implicitly during fine-tuning, models still make frequent syntax errors.Motivated by the fact that these constraints can be better satisfied explicitly with constrained decoding, we propose TOOLDEC, a decoding algorithm using finite state machines to force LLMs to follow tool syntax.Our experiments show that TOOLDEC eliminates all syntax errors, achieving significantly better performance on various base models and benchmarks.More surprisingly, when applied to generalist out-of-the-box LLMs such as Mistral-Instruct, TOOLDEC improves its accuracy in tool use from the initial 0% to an impressive 52%, matching the performance of specialized fine-tuned models such as ToolLLM.We release our code at https://github.com/chenhongqiao/tooldec.</p>
<p>No Errors After ToolDec</p>
<p>Figure 1: On various benchmarks, TOOLDEC improves both fine-tuned specialist models (ToolLLM) and generalist models (Mistral-Instruct and Vicuna).Mistral-Instruct is improved from an initial 0% to be even better than ToolLLM.TOOLDEC also eliminates all syntax errors.</p>
<p>Introduction</p>
<p>Augmenting large language models (LLMs) with external tools (Mialon et al., 2023) enables them to solve complex problems.Current LLMs can utilize retrievers (Shen et al., 2023;Gupta &amp; Kembhavi, 2022;Schick et al., 2023), RESTful APIs (Qin et al., 2023;Song et al., 2023), program interpreters (Chen et al., 2022;Gao et al., 2023), and various other tools.As existing tools are being modified and new tools are being created every day, it is important for LLMs to be able to use unknown tools that are not in the training set.</p>
<p>Out-of-the-box LLMs such as Mistral and Llama, even when instruction-tuned to be very capable on many other tasks (Jiang et al., 2023), can fail in using tools, as demonstrated by its low (and even zero) performance in Figure 1.One major reason for their bad performance is syntax errors.For example, Mistral-Instruct-7B has a syntax error rate of over 90% when using some unknown tools in ToolEval (Qin et al., 2023), which results in its 0% accuracy.Even very capable models such as GPT-4 make syntax errors on new tools.Previous approaches use extensive fine-tuning or prompting (Qin et al., 2023;Hao et al., 2023) to teach LLMs tool syntax, which reduces syntax errors but not all of them.In Figure 1, although the fine-tuned ToolLLM makes significantly fewer syntax errors than the general Mistral-Instruct, it still has an over 20% error rate.We show examples of common modes of failure in Figure 2.</p>
<p>We argue that fine-tuning or prompting is neither optimal nor enough to enforce syntax constraints, because general instruction-tuned models already have a "rough idea" of what tool to use in different scenarios.Fine-tuning or prompting approaches expect the model to learn and follow syntax constraints from tool use examples in training data or in-context demonstration.However, these constraints can be explicitly modeled with symbolic rules.Directly applying these rules in model generation can be more accurate than either fine-tuning or prompting, as they do not need extra compute or prompting while guaranteeing the model is syntax error-free.</p>
<p>To this end, we propose TOOLDEC, a decoding algorithm guided by a finite-state machine (FSM) to ensure LLMs invoke tools properly.We automatically convert tool syntax schemas to an equivalent finite-state machine.During decoding, TOOLDEC transitions from state to state as decoding progresses.At each decoding step, TOOLDEC samples from the valid subset of tokens allowed by the tool syntax.This way, TOOLDEC is able to always generate syntactically correct tool calls.Since syntax constraints are enforced by the FSM, there's no need for them to appear in prompts.We We evaluate TOOLDEC by applying it to 5 base models and evaluating it on 4 benchmarks.On base models that are specifically fine-tuned for tool use purposes, such as ToolLLM (Qin et al., 2023) and ToolkenGPT (Hao et al., 2023), TOOLDEC significantly improves their accuracy by at most 21 points and greatly reduce the number of tokens in the output.On base models that initially have zero accuracy on ToolBench (Qin et al., 2023) such as Mistral (Jiang et al., 2023) and Vicuna (Chiang et al., 2023), TOOLDEC improves their accuracy from 0 to at most 60%.</p>
<p>Our contributions can be summarized as follows:</p>
<p>• We propose TOOLDEC, a constrained decoding algorithm for LLMs to use tools without syntax errors.TOOLDEC can off-load syntax constraints to an FSM, and eliminate all syntax errors.• We verify TOOLDEC's superior performance by combining it with 5 base models and evaluating on 4 benchmarks.Our experiments show TOOLDEC improves all base models significantly.• We further compare TOOLDEC on generalist models with specialized tool-using models.We find that TOOLDEC, as an alternative, can achieve comparable performance while retaining the model's performance on other reasoning benchmarks.</p>
<p>Related Work</p>
<p>Fine-tuning language models to use tools.Language models can be fine-tuned to use tools with data that contain interleaving text and tool use.Earlier studies make language models use a single tool like a retrieval module (Borgeaud et al., 2022;Guu et al., 2020) or a search engine (Nakano et al., 2021) by fine-tuning.Recent advances in tool-augmented language models that use multiple tools (Schick et al., 2023;Parisi et al., 2022) also fine-tune language models to use tools including QA models, translation models, calculators, and search engines.ToolkenGPT (Hao et al., 2023) proposes to use several special tokens to represent tools and only tunes the embeddings of the tokens so that new tool adoption can be more efficient.However, fine-tuning approaches cannot adapt to new tools without training data.</p>
<p>In-context learning for tool use.Language models can learn from in-context examples (Brown et al., 2020) and follow instructions (Ouyang et al., 2022).This makes it possible to simply put the descriptions of tools in the prompt and ask language models to use them.Recent works put tool documentation and demonstration in the prompt to use neural models (Shen et al., 2023), RESTful APIs (Qin et al., 2023;Song et al., 2023), program interpreters (Chen et al., 2022;Gao et al., 2023) and many other tools to solve problems.In-context learning does not need extra model tuning to use new tools.However, the syntax and semantic constraints of new tools are entangled in the prompts, resulting in longer prompts and syntax errors.</p>
<p>Constrained decoding and finite-state machines.Previous constrained decoding methods reduce the large search space of lexically constrained decoding with finite-state machines (Anderson et al., 2017), grouping together similar candidates (Hokamp &amp; Liu, 2017), and better search algorithms (Miao et al., 2019;Lu et al., 2021Lu et al., , 2022)).However, lexical constraints are not expressive enough to regulate tool calls.While finite-state machines have to be weighted and probabilistic to deal with the soft constraints in natural language (Eisner, 2002;Rastogi et al., 2016), the constraints for syntactic tool calls are hard constraints that are much easier for FSMs.Grammar-constrained decoding has been used for structural NLP tasks such as code generation (Yin &amp; Neubig, 2017), semantic parsing (Stengel-Eskin et al., 2024), coreference resolution, POS tagging and many others (Geng et al., 2023).Willard &amp; Louf (2023) uses finite state machines to guide LLMs to generate outputs efficiently and conform to grammar.</p>
<p>Proposed Method: TOOLDEC</p>
<p>To use a tool, an LLM must first refer to an existent tool by its designated name.Then, it needs to generate arguments that adhere to the grammar of that tool (e.g. a JSON Schema).Motivated by the fact that it is easy to verify the syntax of a tool call using a finite-state machine (FSM), we propose TOOLDEC, a LLM tool-use framework that uses an FSM to eliminate syntax errors.During each decoding step, the model samples from a subset of the vocabulary that only contains syntactically correct tokens.This subset is dictated by the current state of the FSM and the sampled token determines the next state to transition to.</p>
<p>We designed an algorithm to automatically construct the described FSM from tool documentation recursively (Section 3.1).It takes advantage of machine-readable endpoint documentation (e.g., OpenAPI), which is very common in software engineering.In addition to constructing an FSM, we use another LLM to remove syntax constraints from the tool documentation (Section 3.2).The goal of this step is to shorten the extensive prompts and demonstrate that FSM on its own is sufficient to guarantee syntactically correct tool calls.An example of constrained decoding with TOOLDEC is provided in Section 3.3.{ name: "flight_search", parameters: { type: "object", properties: { from: { type: "string", description: "Departure...", example_value: "LHR" }, to: { type: "string", description: "Arrival...", example_value: "DXB" }, adult: { type: "integer", description: "Number...", example_value: 1 }, child: { type: "integer", description: "Number...", example_value: 1 }, type: { type: "string", description: "Flight...", example_value: "economy" } }, required: ["from", "to", "passengers"], optional: ["type"] } } "adult": " adult" : 0-9, , "child": " child" : The caption on each state in the FSM denotes the valid token set at that step.FSM will transition to the corresponding state when the token on that edge is generated by the LLM.
0-9},</p>
<p>Construction of TOOLDEC FSM</p>
<p>Definition of TOOLDEC FSM.An FSM is a 5-tuple (S, V, g, s 0 , R), consisting of a finite state set S, an alphabet V , a transition function g : S × V → S, an initial state s 0 and a set of accepting states R. In our case, S and g are constructed from the tool documentation.V is the token vocabulary of the language model.R corresponds to pre-defined tokens that can determine the LM has completed the task, like '<EOS>'.</p>
<p>FSM-constrained decoding.At each decoding step t, TOOLDEC maintains a current state s.The LLM can only sample from the tokens permitted by the FSM, i.e. the tokens for which g(s, •) is defined.These permitted tokens are a subset of V and we denote them as V s .After generating one token a, TOOLDEC transits to another state g(s, a) specified by the FSM transition function.The permitted tokens for each state can be the full vocabulary, or a valid subset corresponding to tool names and argument types.With the next token, we move on to the next decoding step and transition the current state s to the next state g(s, a).The pseudo-code of this algorithm is listed in Algorithm 1.</p>
<p>Constructing FSM from Tool Documentation.In this paper, we focus on the automatic construction of guidance FSM for REST APIs and Python functions.With the following algorithm, we were able to cover 16,000+ tools across 4 different domains, representing various tool-use applications explored in previous studies (Qin et al., 2023;Hao et al., 2023;Yuan et al., 2024).This approach can be extended should future applications emerge because a finite state machine can be algorithmically constructed for any regular grammar.Our FSM construction algorithm assumes that the syntax grammar of a tool is documented in a machine-readable format, for example, in the OpenAPI specification.</p>
<p>In Figure 3, we illustrate an automatically constructed FSM from a JSON Schema.The nodes represent the states.The caption inside a state s illustrates the valid tokens V s and the edges represent possible transitions based on the token sampled.The generation starts at an initial state and stops with an accepting state (the green nodes).For each parameter of a tool, we create a sub-machine for its syntax.For example, the first row with 4 nodes in Figure 3 is the sub-machine for the parameter "from".Each sub-machine has two parts -one for parameter names and one for parameter values.Name sub-machines (with blue backgrounds) only accept one string -the name for a particular parameter.Value sub-machines (with pink backgrounds) accept strings that follow the format of the parameter value.For example, for the parameter "adult", it only accepts digit strings that end with a comma.After generating the name and value of a parameter, an LLM might generate some end-of-generation tokens (with orange backgrounds, such as ' , ' or ' } ') to move on to the next parameter.</p>
<p>For required parameters, their sub-machines must be passed through, while for optional parameters, there's a skip connection that allows the model to go around it without generating an optional parameter (for example, the parameter "type" in Figure 3).Note that this algorithm can also work for nested parameters (parameters that have subfields), because we can just apply the process recursively.</p>
<p>Based on V s , we pre-compute the token mask for every s ∈ S during construction to allow O(1) filtering during inference.This construction process only needs to be executed once for every tool, and can be cached.The size of the FSM scales linearly as the number of arguments of a tool increases, which is the same as the number of tokens if prompting were used.However, our approach is much more efficient because its computation and memory overhead is negligible (less than 0.1%) when compared to the GPU cost of LLMs.</p>
<p>Linking FSMs for Guided Reasoning and Tool Selection.Tool enhanced problem solving involves multiple steps of reasoning and selecting tools for each step.This can be guided by linking multiple FSMs together.For guided tool selection, we tokenized the names of all available tools and constructed a tree structure similar to a trie (Fredkin, 1960).Every leaf node has a g defined to transition to the s 0 of the FSM for that tool.An example can be seen in Figure 4.As the number of tools increases (for example, in the KAMEL (Kalo &amp; Fichtel, 2022) benchmark, toolset size reaches 234), the trie could automatically expanded by adding more nodes to the tree.Reasoning syntax, such as ReAct (Yao et al., 2023), can also be incorporated into the FSM as showns in Figure 4.</p>
<p>Prompt Compression</p>
<p>Since syntax constraints can be effectively handled by our decoding algorithm, we created a prompt compression pipeline to remove these constraints from the tool documentation.For each tool, we prompted an LLM to rewrite the tool documentation while ignoring the hierarchical structure of JSON schema and the typing of each parameter.Resulted was a simple list of parameters with concise descriptions.This list of parameters is necessary for the tool-use LLM to match the context information it has at hand with a tool.We show an example of the compressed prompt in Figure 3.The prompt we used to rewrite the tool documentation can be found in Appendix A.3.</p>
<p>By removing syntax information from the prompt, we reduce the number of tokens and show that syntax constraints are more efficiently handled by decoding algorithms rather than prompting.</p>
<p>Inferencing with FSM and Compressed Prompt</p>
<p>Inferencing with TOOLDEC involves using the TOOLDEC FSM in conjunction with the compressed prompt.First, the compressed prompt, succinct and free of syntax constraints, is provided to the LLM to begin generation.At each step t, we do not directly sample from the next token distribution P (x t |x 1..t−1 ) calculated by the LLM.Instead, we zero out the probabilities of invalid tokens for which the transition function is undefined, and normalize the probabilities,
P (x t = a) = P (x t =a|x 1..t−1 ) a ′ ∈Vs P (x t =a ′ |x 1..t−1 ) , ∃g(s, a), 0, otherwise .
The next token a is then sampled from the modified distribution P (x t |x 1..t−1 , s).</p>
<p>We show an example in Figure 5. First, the semantic description of flight_search is provided to the LLM.At step n, the current state s n only permits the generation of integers or comma, which corresponds to adult's data type integer.By multiplying the token mask with P , we obtain P where the probability of all other tokens are zeroed out.From the shifted probability, we sampled ' , '.</p>
<p>As we moves on to step n + 1, the FSM also transitions to s n+1 following g(s n , ' , ').Here with the zoom in bubble, we show the actual FSM that accepts the parameter name "child", which only accepts ' " ' as the first token.A similar process repeats until the LLM finishes generating a tool call.</p>
<p>ToolDec FSM Generated Output "adult": " adult" : 0-9, "child": " child" : { " from" : " LHR" , " to" : " DXB" , " adult" : 2
0-9},1 1 1 0 1 2 1 1 0 0 9 , a ...</p>
<p>Token Mask</p>
<p>Token Prob.</p>
<p>,</p>
<p>Step N ... ...</p>
<p>Sampled Token</p>
<p>Compressed Prompt flight_search: ...</p>
<p>Generated Output</p>
<p>"adult": " adult" : 0-9, "child": " child" :
0-9},</p>
<p>Experiment</p>
<p>As a model-agnostic decoding algorithm, TOOLDEC can be applied to any LLM with token logits access.We evaluate TOOLDEC by applying it to 5 base LLMs on 4 benchmarks.In this section, we first introduce the base LLMs (Section 4.1) and benchmarks we evaluate TOOLDEC on (Section 4.2).Then we report our main results (Section 4.3) and further ablate why TOOLDEC can be a good complement/alternative for fine-tuning and prompting (Section 4.4).</p>
<p>Base LLMs</p>
<p>We evaluate how TOOLDEC can improve 5 LLMs -ToolLLM (Qin et al., 2023), ToolkenGPT (Hao et al., 2023), RestGPT (Song et al., 2023), Vicuna-7B (Chiang et al., 2023), and Mistral-7B-Instruct (Jiang et al., 2023).The first three are "specialists", particularly designed/fine-tuned for tool-use benchmarks in the same papers that proposed the models.We evaluate them on their specialized benchmarks.Additionally, we evaluate Llama and Mistral-7B, two "generalist" instruction-tuned models to demonstrate that TOOLDEC can also work on base models that are not particularly designed for tool use.These two models are not fine-tuned on the benchmark's training sets.Therefore, their initial performance without the TOOLDEC is very poor compared to their specialist counterparts.</p>
<p>ToolLLM (Qin et al., 2023).ToolLLM is a specialist LLaMA-7B model fine-tuned to use tools on RapidAPI (https://rapidapi.com/).Given each task, ToolLLM is prompted with the documentation of relevant tools.It is then instructed to generate a natural language rationale, a tool to use, and the tool's inputs.This process continues for several iterations until the path of tool calls leads to an answer or the model gives up.ToolLLM can either generate a single path of tool calls (denoted as ToolLLM+ReAct) or run a tree search to find the best path (denoted as ToolLLM+DFSDT).Note that ToolLLM is fine-tuned with the same formatted data synthesized with the same process as its evaluation benchmark, ToolEval.</p>
<p>ToolkenGPT (Hao et al., 2023).ToolkenGPT is a specialist Llama-33B model with an additional vocabulary of tokens learned for tools.The original weights of Llama are frozen while the additional tokens are learned.These tokens for tools, or toolkens, each correspond to a tool.The text spans of tool use in the training data are replaced with toolkens, so that the model can learn when to start a tool call.Although ToolkenGPT is much more efficient than full fine-tuning a model, it still needs to learn the representations of all tools in the evaluation set.</p>
<p>RestGPT (Song et al., 2023).RestGPT learns to use RESTful APIs from in-context tool documentation.RestGPT utilizes several different LLM-based modules to make natural language plans, select which APIs to use, generate tool calls and parse results from them.</p>
<p>Mistral-Instruct (Jiang et al., 2023) and LLaMA (Touvron et al., 2023).Mistral-Instruct-7B and LLaMA-7B are generalist 7B LLMs tuned without tool-specific fine-tuning.When directly evaluated on ToolEval with syntax constraints in the prompt, Mistral cannot solve any tests.This suggests that Mistral is not able to follow syntax constraints when prompted.The same is true for LLaMA-7B.We choose them as base models to show when syntax constraints are taken care of by TOOLDEC; even a generalist model can perform well on tool-using.</p>
<p>Benchmarks and Metrics</p>
<p>We evaluate the baselines and TOOLDEC on four benchmarks -ToolEval (Qin et al., 2023), FuncQA (Hao et al., 2023), KAMEL (Kalo &amp; Fichtel, 2022), and RestBench (Song et al., 2023).We evaluate the performance of all base models with and without TOOLDEC.Other than correctness metrics, we also measure syntax error rate, the proportion of tasks on which the models make syntax errors.</p>
<p>Our experiments are conducted on NVIDIA A6000 GPUs within 60 GPU hours.</p>
<p>ToolEval (Qin et al., 2023).ToolEval is a dataset proposed in the ToolLLM paper.Tasks in it involve 10000+ publicly available REST APIs.We use its more complex subsets to evaluate our method -I2-Category and I3-Instruction.They contain tasks that need complex and unseen tools from multiple categories to solve.On average, a task in these subsets needs more than 7 tools to solve.ToolEval has two main metrics: pass rate measures the percentage of tasks for which the model reaches an answer within limited reasoning steps.win rate compares the quality and correctness of the models' answers to the reference answers from ChatGPT.Qin et al. (2023) finds that these automatic metrics have a high correlation of 75.8% with human annotators.Since ToolEval requires extensive prompting of tool documentation, we measure tok / tool, the average number of tokens required for each tool, to see how much TOOLDEC can shorten the prompts.</p>
<p>FuncQA (Hao et al., 2023).FuncQA tests LLMs' ability in numerical reasoning tasks with 68 math problems.LLMs are required to produce a numerical answer using a few of the 13 arithmetic operations as tools (e.g.multiply, power, lcm).The accuracy is determined by measuring the percentage of problems for which a correct answer is produced, with a 0.1% error tolerance.On average, a problem in FuncQA requires 2.78 tool calls to solve.Following Hao et al. (2023), we report results of other baselines, including ChatGPT without tools, LLaMA with chain-of-thought and tools, LLaMA with ReAct and tools.</p>
<p>KAMEL (Kalo &amp; Fichtel, 2022).KAMEL is a question-answering dataset containing a total of 234 knowledge relations that resemble the characteristics of APIs (e.g.number_of_children).The tools in KAMEL are also more complex and diverse because their number of arguments varies from 1 to 3, and their types include strings, locations, dates, numbers, and other ad-hoc types.</p>
<p>RestBench (Song et al., 2023).RestBench consists of tasks in real-world scenarios, including TMDB, a movie website, and Spotify, an online music player.These tasks directly come from real-user instructions and require multiple tools in the form of RESTful APIs to solve.We use the correct path rate (CP%) proposed by the original paper as the metric to measure accuracy.Correct path rate is the proportion of outputs that contain the correct tool call path annotated by humans.</p>
<p>Results</p>
<p>We list our main results in Table 1.Each green row contains the performance of TOOLDEC applied to the base model in the previous row.Note that on KAMEL, syntax error rate is not available.This is because KAMEL tests the model's ability to select the right tool and does not involve tool arguments and execution.For the same reason, ToolkenGPT + ToolDec is also not available.Also, the win rates on ToolEval are not available for ChatGPT + ReAct, because it is the baseline compared against when computing the win rates.Several observations can be made about the results: TOOLDEC leads to significant improvements of all base models across multiple benchmarks.</p>
<p>On ToolEval, ToolDec improves win rates and pass rates substantially on ToolLLM with either the ReAct or DFSDT strategies.The win rate is improved by 10 points, while the pass rate is improved by 12 on average.Particularly noteworthy is the performance of ToolLLM+DFSDT with TOOLDEC, which not only outperforms ChatGPT but also achieves performance on par with GPT-4.Similarly significant improvements are observed across other benchmarks on other base models as well.</p>
<p>TOOLDEC helps generalist models to match or outperform similar-sized specialist models.</p>
<p>Without TOOLDEC, Mistral-7B cannot pass a single task on ToolEval, while ToolLLM has an average &gt;40% win rate and &gt;40% pass rate.With TOOLDEC, Mistral-7B's performance on ToolEval is on par with ToolLLM + TOOLDEC and even better in several cases and metrics.The same is true for FuncQA and KAMEL.When enhanced with TOOLDEC, the generalist, pre-trained LLaMA-7B model's performance gets 2.2x better on FuncQA and 5.1x better on KAMEL, matching or beating the specialist ToolkenGPT.</p>
<p>TOOLDEC gets much better performance with shorter prompts.On ToolEval, the average number of tokens required for each tool is reduced by 58% and 69% for I2-Category and I3-Instruction.With shorter prompts, TOOLDEC is able to include more tools in the inventory without exceeding the context limit of LLMs.</p>
<p>All models have syntax errors.Fine-tuning or prompting can't eliminate them, but TOOLDEC can.When evaluating on the ToolEval: I3-Instruction dataset, ToolLLM + DFSDT-despite being fine-tuned with data formatted identically to that of the test data-still produces syntax errors in nearly half (49%) of the instances.Mistral is even worse, with syntax errors occurring in over 90% of its responses.This high error rate probably explains its directly impacted its accuracy being exactly 0.Even advanced models like ChatGPT and GPT-4, known for their capabilities, were not immune to syntax mistakes during tool interactions.The same is true for other benchmarks and other base models.When TOOLDEC is applied, both specialist models like ToolLLM and generalist models stop making syntax errors.</p>
<p>Ablation Study</p>
<p>TOOLDEC v.s.Tool-Specialized Fine-Tuning.We argue that it's more ideal to use TOOLDEC on generalist LLMs instead of fine-tuning specialist LLMs to use tools.To demonstrate that, we evaluate both the specialist ToolLLM and the generalist Llama-2-chat and Mistral-Ins on other reasoning and coding benchmarks, including GSM8K (Cobbe et al., 2021), HumanEval (Chen et al., 2021), MBPP (Austin et al., 2021), and BigBenchHard (Suzgun et al., 2022).The details of these evaluations can be found in Appendix A.4.As reported in Table 2, although the specialist ToolLLM can have comparable performance on tool-related benchmarks as TOOLDEC on generalist LLMs, its performance on general reasoning or coding benchmarks is unreasonably bad.On GSM8K, it's solving only 1.2% of the problems, while Llama-2-chat, the generalist model with the same pertaining, solves 23.1%.This suggests that tool-specialized fine-tuning can seriously degrade the model's general ability, probably due to catastrophic forgetting.</p>
<p>TOOLDEC vs. Prompting Syntax Constraints.We argue that removing syntax constraints in prompts doesn't harm TOOLDEC's performance.We conduct a fine-grained ablation study on two approaches (prompting and decoding) to incorporate syntax constraints with two base models -ToolLLM and Mistral.We consider four different settings of syntax constraints: "no prompting, no decoding", "only decoding", "only prompting", "prompting and decoding".We evaluate the win rate of ToolLLM and Mistral under these four settings and report the results in Figure 6.The following observations can be made: 1) Decoding time syntax constraints are much more helpful than in-prompt syntax constraints.For both models, the improvements from constrained decoding are much larger than those from prompting syntax constraints.2) Using decoding time constraints is mostly enough.Extra in-context constraints offer little help.The gaps between the third setting, decoding constraints, and the fourth setting, both constraints are very small.</p>
<p>Conclusion</p>
<p>We propose TOOLDEC, a constrained decoding algorithm to guide LLMs to use external tools.It guarantees that LLMs do not make syntax errors when generating a tool call.TOOLDEC is complementary to existing approaches and improves the performance of all the base LLMs we tested.Surprisingly, TOOLDEC can enable generalist LLMs to be as good as or even better than tool-specialized models.Since very capable language models, such as GPT-4, can still make syntax errors, we believe that TOOLDEC can be used in some security-sensitive areas to avoid syntax errors, thus having a positive societal impact.However, we do acknowledge that syntax error-free doesn't mean error-free.LLMs with TOOLDEC can still make mistakes beyond syntax and should be used with care.</p>
<p>A Appendix</p>
<p>Figure 2 :
2
Figure 2: Common syntactical modes of failure of tool-use LLMs include reasoning format error, tool name error, and tool argument error.Even fine-tuned models have a significant level of syntax error.</p>
<p>"</p>
<p>Departure airport code (Example: LHR).-to: Arrival airport code (Example: DXB).-adult: Number of adult passengers.-child: Number of child passengers.-type: Preferred class type (Optional, Example: economy).</p>
<p>Figure 3 :
3
Figure3: Converting a tool documentation to a simplified prompt and an FSM.The caption on each state in the FSM denotes the valid token set at that step.FSM will transition to the corresponding state when the token on that edge is generated by the LLM.</p>
<p>Figure 4 :
4
Figure4: Linking multiple FSMs to guide the LLM through reasoning and tool selection.After a tool is selected, the FSM then transitions to start generating arguments.</p>
<p>Figure 5 :
5
Figure 5: A decoding step using TOOLDEC FSM.The invalid tokens at the current FSM state are masked out from the token probabilities.</p>
<p>Win rates of Mistral on I2-Category and I3-Instruction under four different settings.Win rates of ToolLLM on I2-Category and I3-Instruction under four different settings.</p>
<p>Figure 6 :
6
Figure 6: Win rates of Mistral and ToolLLM under different settings of syntax constraints.Syntax constraints are much more helpful as decoding constraints than in-context descriptions.</p>
<p>A. 1 Figure 7 :
17
Figure 7: TOOLDEC can prevent function name error, function argument error, and invalid ReAct syntax on ToolLLM.</p>
<p>Table 1 :
1
When applied to various baselines on different benchmarks, TOOLDEC significantly improves the model generations with fewer tokens in the prompt.It also completely eliminates all syntax errors."err." is short for syntax error rate."tok" is short for the average number of tokens for each tool.Instruction win% ↑ pass% ↑ tok ↓ err.% ↓ win% ↑ pass% ↑ tok ↓ err.% ↓
ToolEval : I2-Category ToolEval: I3-ToolLLM + ReAct 36.5 30.5 827 21 49 22138032+ TOOLDEC46.547.5397061486270ToolLLM + DFSDT40.564.5827444158138049+ TOOLDEC50.569397049596270Mistral + ReAct0082792.500138093+ TOOLDEC4126397053326270Mistral + DFSDT00827100001380100+ TOOLDEC5250.5397060356270ChatGPT + ReActn.a.398275n.a.2313809ChatGPT + DFSDT63.064.5827287060138047GPT-4 + ReAct53.567.58274714013802GPT-4 + DFSDT5769.58274735913805FuncQAKAMELaccuracy % ↑err.% ↓accuracy % ↑err.% ↓LLaMA627.98.2n.a.+ TOOLDEC13.2042.4n.a.ToolkenGPT10.327.925.4n.a.+ TOOLDEC13.20n.a.n.a.RestBench: SpotifyRestBench: TMDBcorrect path % ↑err.% ↓correct path % ↑err.% ↓Vicuna + RestGPT20.67.41523+TOOLDEC360230ChatGPT72.33.6653</p>
<p>Table 2 :
2
While tool-specialized models, such as ToolLLM, can perform as well as generalist models + TOOLDEC ( †), their performance on other reasoning benchmarks is much lower (underlined).
ToolEval (I2-Cat) ToolEval (I2-Ins) GSM8K HumanEval MBPP BBHToolLLM-7B36.549.01.22.45.328.1Llama-2-chat-7B  †39.051.023.114.629.639.9Mistral-Ins-7B  †41.053.042.043.943.450.6I2-CategoryI3-Instruction
A.2 Algorithm PseudocodeAlgorithm 1 Finite-State Machine Guided Decoding for Language Models Input: data x i , size m A DFSM defined by (S, V, g, s 0 , R); A language model M that produces the distribution of the next token given a prefix string; An initial string of tokens x 1..k , which represents the prompt from the user.Output:A.3 Prompt to Remove Syntax ConstraintsThe user will give you a list of functions in JSON and you will simplify their descriptions.For each function, write a concise but semantically rich description of its purpose but you do not need to mention the tool it belongs to.List out the parameters, one per line, and write a concise but semantically rich description.You do not need to include syntactical information (such as parameter type) but please include the example value if available.Your response must be in plain text and wrapped in a code block.Here is an example.Please follow the same syntax:1. airport_arrivals_for_flight_fare_search Description: Retrieves information about arriving flights.Parameters: -airportcode: Airport code (Example: LHR).-carriercode: Airline carrier code (Optional).-date: Date for checking arrivals (Optional).A.4 Evaluation DetailsWe report win rates under the ReAct setting on ToolEval.We use lm-eval-harness (https:// github.com/EleutherAI/lm-evaluation-harness) to evaluate LLMs on GSM8K (5-shot) and BigBenchHard (3-shot, CoT) using the default parameters.We use eval-plus (https://github.com/evalplus/evalplus/) to evaluate LLMs on HumanEval and MBPP with greedy decoding and report pass@1 results.
Guided open vocabulary image captioning with constrained beam search. P Anderson, B Fernando, M Johnson, S Gould, 10.18653/v1/D17-1098Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing. the 2017 Conference on Empirical Methods in Natural Language ProcessingCopenhagen, DenmarkAssociation for Computational LinguisticsSeptember 2017</p>
<p>Program synthesis with large language models. J Austin, A Odena, M Nye, M Bosma, H Michalewski, D Dohan, E Jiang, C Cai, M Terry, Q Le, arXiv:2108.077322021arXiv preprint</p>
<p>Improving language models by retrieving from trillions of tokens. S Borgeaud, A Mensch, J Hoffmann, T Cai, E Rutherford, K Millican, G B Van Den Driessche, J.-B Lespiau, B Damoc, A Clark, International conference on machine learning. PMLR2022</p>
<p>Language models are few-shot learners. T Brown, B Mann, N Ryder, M Subbiah, J D Kaplan, P Dhariwal, A Neelakantan, P Shyam, G Sastry, A Askell, Advances in neural information processing systems. 202033</p>
<p>M Chen, J Tworek, H Jun, Q Yuan, H P D O Pinto, J Kaplan, H Edwards, Y Burda, N Joseph, G Brockman, arXiv:2107.03374Evaluating large language models trained on code. 2021arXiv preprint</p>
<p>Program of thoughts prompting: Disentangling computation from reasoning for numerical reasoning tasks. W Chen, X Ma, X Wang, W W Cohen, 20222211arXiv e-prints</p>
<p>An open-source chatbot impressing gpt-4 with 90%* chatgpt quality. W.-L Chiang, Z Li, Z Lin, Y Sheng, Z Wu, H Zhang, L Zheng, S Zhuang, Y Zhuang, J E Gonzalez, I Stoica, E P Xing, Vicuna, March 2023</p>
<p>K Cobbe, V Kosaraju, M Bavarian, M Chen, H Jun, L Kaiser, M Plappert, J Tworek, J Hilton, R Nakano, C Hesse, J Schulman, arXiv:2110.14168Training verifiers to solve math word problems. 2021arXiv preprint</p>
<p>Parameter estimation for probabilistic finite-state transducers. J Eisner, Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics. the 40th Annual Meeting of the Association for Computational Linguistics2002</p>
<p>Trie memory. E Fredkin, Communications of the ACM. 391960</p>
<p>Pal: Programaided language models. L Gao, A Madaan, S Zhou, U Alon, P Liu, Y Yang, J Callan, G Neubig, International Conference on Machine Learning. PMLR2023</p>
<p>Grammar-constrained decoding for structured nlp tasks without finetuning. S Geng, M Josifoski, M Peyrard, R West, Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing. the 2023 Conference on Empirical Methods in Natural Language Processing2023</p>
<p>Visual programming: Compositional visual reasoning without training. T Gupta, A Kembhavi, ArXiv, abs/2211.115592022</p>
<p>Retrieval augmented language model pre-training. K Guu, K Lee, Z Tung, P Pasupat, M Chang, International conference on machine learning. PMLR2020</p>
<p>S Hao, T Liu, Z Wang, Z Hu, Toolkengpt, arXiv:2305.11554Augmenting frozen language models with massive tools via tool embeddings. 2023arXiv preprint</p>
<p>Lexically constrained decoding for sequence generation using grid beam search. C Hokamp, Q Liu, 10.18653/v1/P17-1141Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics. Long Papers. the 55th Annual Meeting of the Association for Computational LinguisticsVancouver, CanadaAssociation for Computational LinguisticsJuly 20171</p>
<p>A Q Jiang, A Sablayrolles, A Mensch, C Bamford, D S Chaplot, D De Las Casas, F Bressand, G Lengyel, G Lample, L Saulnier, L R Lavaud, M.-A Lachaux, P Stock, T L Scao, T Lavril, T Wang, T Lacroix, W E Sayed, Mistral 7b. 2023</p>
<p>Knowledge analysis with multitoken entities in language models. J.-C Kalo, L Fichtel, Kamel, 2022Automated Knowledge Base Construction</p>
<p>Neurologic decoding:(un) supervised neural text generation with predicate logic constraints. X Lu, P West, R Zellers, R Le Bras, C Bhagavatula, Y Choi, Proceedings of the 2021 Conference of the North American Chapter. the 2021 Conference of the North American ChapterHuman Language Technologies2021</p>
<p>Neurologic a* esque decoding: Constrained text generation with lookahead heuristics. X Lu, S Welleck, P West, L Jiang, J Kasai, D Khashabi, R Le Bras, L Qin, Y Yu, R Zellers, Proceedings of the 2022 Conference of the North American Chapter. the 2022 Conference of the North American ChapterHuman Language Technologies2022</p>
<p>Augmented language models: a survey. G Mialon, R Dessì, M Lomeli, C Nalmpantis, R Pasunuru, R Raileanu, B Rozière, T Schick, J Dwivedi-Yu, A Celikyilmaz, arXiv:2302.078422023arXiv preprint</p>
<p>Cgmh: Constrained sentence generation by metropolis-hastings sampling. N Miao, H Zhou, L Mou, R Yan, L Li, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence201933</p>
<p>R Nakano, J Hilton, S Balaji, J Wu, L Ouyang, C Kim, C Hesse, S Jain, V Kosaraju, W Saunders, arXiv:2112.09332Browser-assisted question-answering with human feedback. 2021arXiv preprint</p>
<p>Training language models to follow instructions with human feedback. L Ouyang, J Wu, X Jiang, D Almeida, C Wainwright, P Mishkin, C Zhang, S Agarwal, K Slama, A Ray, Advances in Neural Information Processing Systems. 202235</p>
<p>A Parisi, Y Zhao, N Fiedel, Talm, arXiv:2205.12255Tool augmented language models. 2022arXiv preprint</p>
<p>Y Qin, S Liang, Y Ye, K Zhu, L Yan, Y Lu, Y Lin, X Cong, X Tang, B Qian, arXiv:2307.16789Facilitating large language models to master 16000+ real-world apis. 2023arXiv preprint</p>
<p>Weighting finite-state transductions with neural context. P Rastogi, R Cotterell, J Eisner, 2016In Proceedings of the 2016 conference of the North American chapter of the Association for Computational Linguistics: human language technologies</p>
<p>T Schick, J Dwivedi-Yu, R Dessì, R Raileanu, M Lomeli, L Zettlemoyer, N Cancedda, T Scialom, Toolformer, arXiv:2302.04761Language models can teach themselves to use tools. 2023arXiv preprint</p>
<p>Hugginggpt: Solving ai tasks with chatgpt and its friends in hugging face. Y Shen, K Song, X Tan, D Li, W Lu, Y Zhuang, 2023</p>
<p>Y Song, W Xiong, D Zhu, W Wu, H Qian, M Song, H Huang, C Li, K Wang, R Yao, Y Tian, S Li, Restgpt, Connecting large language models with real-world restful apis. 2023</p>
<p>Zero and few-shot semantic parsing with ambiguous inputs. E Stengel-Eskin, K Rawlins, B V Durme, 2024</p>
<p>Challenging big-bench tasks and whether chain-of-thought can solve them. M Suzgun, N Scales, N Schärli, S Gehrmann, Y Tay, H W Chung, A Chowdhery, Q V Le, E H Chi, D Zhou, J Wei, arXiv:2210.092612022arXiv preprint</p>
<p>Llama: Open and efficient foundation language models. H Touvron, T Lavril, G Izacard, X Martinet, M.-A Lachaux, T Lacroix, B Rozière, N Goyal, E Hambro, F Azhar, A Rodriguez, A Joulin, E Grave, G Lample, 2023</p>
<p>Efficient guided generation for llms. B T Willard, R Louf, arXiv:2307.097022023arXiv preprint</p>
<p>React: Synergizing reasoning and acting in language models. S Yao, J Zhao, D Yu, N Du, I Shafran, K Narasimhan, Y Cao, 2023</p>
<p>A syntactic neural model for general-purpose code generation. P Yin, G Neubig, Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics. Long Papers. the 55th Annual Meeting of the Association for Computational Linguistics20171</p>
<p>EASYTOOL: Enhancing LLM-based Agents with Concise Tool Instruction. S Yuan, K Song, J Chen, X Tan, Y Shen, R Kan, D Li, D Yang, arXiv:2401.06201January 2024</p>            </div>
        </div>

    </div>
</body>
</html>