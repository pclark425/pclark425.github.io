<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-1582 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-1582</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-1582</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-31.html">extraction-schema-31</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of genetic/evolutionary algorithms that use crossover and mutation operations on code, programs, or literature to generate new solutions, with particular attention to measures of novelty, diversity, executability, and functionality.</div>
                <p><strong>Paper ID:</strong> paper-247291786</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2203.02540v5.pdf" target="_blank">Evolving symbolic density functionals</a></p>
                <p><strong>Paper Abstract:</strong> Systematic development of accurate density functionals has been a decades-long challenge for scientists. Despite emerging applications of machine learning (ML) in approximating functionals, the resulting ML functionals usually contain more than tens of thousands of parameters, leading to a huge gap in the formulation with the conventional human-designed symbolic functionals. We propose a new framework, Symbolic Functional Evolutionary Search (SyFES), that automatically constructs accurate functionals in the symbolic form, which is more explainable to humans, cheaper to evaluate, and easier to integrate to existing codes than other ML functionals. We first show that, without prior knowledge, SyFES reconstructed a known functional from scratch. We then demonstrate that evolving from an existing functional ωB97M-V, SyFES found a new functional, GAS22 (Google Accelerated Science 22), that performs better for most of the molecular types in the test set of Main Group Chemistry Database (MGCDB84). Our framework opens a new direction in leveraging computing power for the systematic development of symbolic density functionals.</p>
                <p><strong>Cost:</strong> 0.011</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e1582.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e1582.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of genetic/evolutionary algorithms that use crossover and mutation operations on code, programs, or literature to generate new solutions, with particular attention to measures of novelty, diversity, executability, and functionality.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>RegEvolution-DFT</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Distributed regularized evolution program for symbolic density functionals</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A distributed implementation of regularized evolutionary search that evolves symbolic mathematical/program-like representations of exchange-correlation functionals by iterated selection and mutation, coupled with parameter optimization (CMA-ES) and fingerprint-based equivalence checking to avoid re-evaluation.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Regularized evolution for image classifier architecture search</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Distributed regularized evolution program (this work)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Maintains a population of symbolic functional forms on a population server; in each iteration a parent is chosen by tournament selection, a child is produced by mutating the parent's symbolic instruction list (no crossover reported), the child's numerical parameters are optimized with CMA-ES by workers, and fitness (training/validation error on the MGCDB84 targets) is returned to the population server. A fingerprint server hashes evaluated functional outputs (for a fixed set of features and parameter seeds) to detect equivalent symbolic forms and cache fitnesses. The software is distributed: population server, population DB, fingerprint server, and many workers performing training/evaluation (GPU-enabled JIT for speed).</td>
                        </tr>
                        <tr>
                            <td><strong>input_type</strong></td>
                            <td>symbolic programs / mathematical expressions (symbolic representation of density functionals)</td>
                        </tr>
                        <tr>
                            <td><strong>crossover_operation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>mutation_operation</strong></td>
                            <td>Mutation operates on the symbolic instruction list/AST of a functional: individual mutation choices draw from a predefined instruction set (5 arithmetic ops, 6 power ops, and building-block primitives). Probabilities are explicitly set: each of the 5 arithmetic operations probability 0.06; each of the 6 power instructions probability 0.05; 'u transform' receives probability 0.1; each of 4 other building-block instructions receives probability 0.075. A parent is chosen by tournament selection and a mutation replaces/edits instructions according to these probabilities to produce a child symbolic form. After structural mutation, the child's numeric parameters are optimized using CMA-ES.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_literature</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>uses_code</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>executability_metric</strong></td>
                            <td>Fitness measured as training/validation/test error against reference targets in the MGCDB84 database (errors reported in kcal/mol); numeric parameters of each symbolic form are optimized with CMA-ES and the resulting errors define fitness.</td>
                        </tr>
                        <tr>
                            <td><strong>executability_results</strong></td>
                            <td>Reported example for the starting functional (GAS22-a, same symbolic form as !B97M-V but fully re-optimized): training/validation/test errors = 2.97 / 3.82 / 4.47 kcal/mol. The paper reports validation-error curves (Fig. S4) showing regularized evolution improving over time compared to random search, but full numeric curves for discovered functionals are in figures/tables rather than as a single summary number.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>diversity_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_executability_tradeoff</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>frontier_characterization</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_or_domain</strong></td>
                            <td>Symbolic discovery/evolution of density functional approximations for Kohn-Sham DFT; evaluation on MGCDB84 benchmark database (chemistry energetics datasets).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Random search (tournament size = 1), starting functional GAS22-a (!B97M-V symbolic form with optimized parameters), and existing manual functionals used as references (e.g. !B97M-V).</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Regularized evolution (with tournament-based selection and the described mutation operators) is effective at traversing the symbolic search space and producing functionals with improved validation error compared to random search; random search (parent chosen uniformly, tournament size = 1) is ineffective. Fingerprint-based equivalence checking prevents redundant re-training by hashing functional outputs on a fixed set of features and parameter seeds. Numerical parameter optimization for each structure is handled with CMA-ES. The paper reports explicit mutation instruction probabilities and demonstrates that mutation-only evolutionary search (as implemented) can discover compact symbolic forms (GAS22 variants) that achieve low errors; no crossover operation or explicit novelty metric is described or used.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Evolving symbolic density functionals', 'publication_date_yy_mm': '2022-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1582.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e1582.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of genetic/evolutionary algorithms that use crossover and mutation operations on code, programs, or literature to generate new solutions, with particular attention to measures of novelty, diversity, executability, and functionality.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>RandomSearch-DFT</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Random-search baseline for symbolic functional discovery</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A baseline search procedure where the parent for mutation is selected uniformly at random (implemented by setting tournament size = 1), used to compare against the regularized evolution implementation.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Random search (tournament size = 1)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Same mutation operator and distributed training/evaluation pipeline as the regularized evolution program, but parent selection ignores fitness (uniform random selection); used to generate dashed-line baselines in validation-error plots.</td>
                        </tr>
                        <tr>
                            <td><strong>input_type</strong></td>
                            <td>symbolic programs / mathematical expressions (symbolic representation of density functionals)</td>
                        </tr>
                        <tr>
                            <td><strong>crossover_operation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>mutation_operation</strong></td>
                            <td>Same mutation operator as RegEvolution-DFT: edit the symbolic instruction list using the predefined instruction probabilities (arithmetic ops 0.06 each, power ops 0.05 each, u-transform 0.1, other building blocks 0.075 each).</td>
                        </tr>
                        <tr>
                            <td><strong>uses_literature</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>uses_code</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>executability_metric</strong></td>
                            <td>Training/validation/test error on MGCDB84 after parameter optimization with CMA-ES.</td>
                        </tr>
                        <tr>
                            <td><strong>executability_results</strong></td>
                            <td>Random search produced worse validation errors than regularized evolution as shown in Fig. S4 (dashed lines), and is described as 'ineffective in traversing the search space and generating better functional forms than existing forms'; no single aggregate numeric summary given beyond plotted curves.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>diversity_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_executability_tradeoff</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>frontier_characterization</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_or_domain</strong></td>
                            <td>Symbolic discovery of density functionals, evaluated on MGCDB84</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Compared directly against the Regularized Evolution implementation and to the starting functional GAS22-a (!B97M-V form with optimized parameters).</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Random selection of parents (tournament size = 1) yields a search that is much less effective than tournament-based regularized evolution; demonstrates importance of selection pressure in the evolutionary search. The study uses this to argue that regularized evolution produces more promising structures than random mutation alone.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Evolving symbolic density functionals', 'publication_date_yy_mm': '2022-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1582.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e1582.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of genetic/evolutionary algorithms that use crossover and mutation operations on code, programs, or literature to generate new solutions, with particular attention to measures of novelty, diversity, executability, and functionality.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>AutoML-Zero</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>AutoML-Zero: Evolving machine learning algorithms from scratch</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A cited evolutionary framework that evolves machine learning algorithms starting from a minimal set of primitives (cited as related work).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>AutoML-Zero: Evolving machine learning algorithms from scratch</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>AutoML-Zero (cited)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>A prior work that uses evolutionary search over low-level primitives to discover learning algorithms; cited in related work to situate the present symbolic-evolution approach in the broader literature on evolving algorithmic structures.</td>
                        </tr>
                        <tr>
                            <td><strong>input_type</strong></td>
                            <td>programs / algorithmic primitives (as in the original AutoML-Zero work)</td>
                        </tr>
                        <tr>
                            <td><strong>crossover_operation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>mutation_operation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uses_literature</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uses_code</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>executability_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>executability_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>diversity_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>diversity_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_executability_tradeoff</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>frontier_characterization</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_or_domain</strong></td>
                            <td>Mentioned in related work on evolving algorithms and AutoML.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Cited as related work motivating evolution of algorithmic forms; the present paper adapts evolutionary ideas to symbolic density-functional discovery but does not re-implement AutoML-Zero.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Evolving symbolic density functionals', 'publication_date_yy_mm': '2022-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Exploring density functional subspaces with genetic algorithms <em>(Rating: 2)</em></li>
                <li>Regularized evolution for image classifier architecture search <em>(Rating: 2)</em></li>
                <li>AutoML-Zero: Evolving machine learning algorithms from scratch <em>(Rating: 2)</em></li>
                <li>Evolving reinforcement learning algorithms <em>(Rating: 1)</em></li>
                <li>Fast, accurate, and transferable many-body interatomic potentials by symbolic regression <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-1582",
    "paper_id": "paper-247291786",
    "extraction_schema_id": "extraction-schema-31",
    "extracted_data": [
        {
            "name_short": "RegEvolution-DFT",
            "name_full": "Distributed regularized evolution program for symbolic density functionals",
            "brief_description": "A distributed implementation of regularized evolutionary search that evolves symbolic mathematical/program-like representations of exchange-correlation functionals by iterated selection and mutation, coupled with parameter optimization (CMA-ES) and fingerprint-based equivalence checking to avoid re-evaluation.",
            "citation_title": "Regularized evolution for image classifier architecture search",
            "mention_or_use": "use",
            "system_name": "Distributed regularized evolution program (this work)",
            "system_description": "Maintains a population of symbolic functional forms on a population server; in each iteration a parent is chosen by tournament selection, a child is produced by mutating the parent's symbolic instruction list (no crossover reported), the child's numerical parameters are optimized with CMA-ES by workers, and fitness (training/validation error on the MGCDB84 targets) is returned to the population server. A fingerprint server hashes evaluated functional outputs (for a fixed set of features and parameter seeds) to detect equivalent symbolic forms and cache fitnesses. The software is distributed: population server, population DB, fingerprint server, and many workers performing training/evaluation (GPU-enabled JIT for speed).",
            "input_type": "symbolic programs / mathematical expressions (symbolic representation of density functionals)",
            "crossover_operation": null,
            "mutation_operation": "Mutation operates on the symbolic instruction list/AST of a functional: individual mutation choices draw from a predefined instruction set (5 arithmetic ops, 6 power ops, and building-block primitives). Probabilities are explicitly set: each of the 5 arithmetic operations probability 0.06; each of the 6 power instructions probability 0.05; 'u transform' receives probability 0.1; each of 4 other building-block instructions receives probability 0.075. A parent is chosen by tournament selection and a mutation replaces/edits instructions according to these probabilities to produce a child symbolic form. After structural mutation, the child's numeric parameters are optimized using CMA-ES.",
            "uses_literature": false,
            "uses_code": true,
            "novelty_metric": null,
            "novelty_results": null,
            "executability_metric": "Fitness measured as training/validation/test error against reference targets in the MGCDB84 database (errors reported in kcal/mol); numeric parameters of each symbolic form are optimized with CMA-ES and the resulting errors define fitness.",
            "executability_results": "Reported example for the starting functional (GAS22-a, same symbolic form as !B97M-V but fully re-optimized): training/validation/test errors = 2.97 / 3.82 / 4.47 kcal/mol. The paper reports validation-error curves (Fig. S4) showing regularized evolution improving over time compared to random search, but full numeric curves for discovered functionals are in figures/tables rather than as a single summary number.",
            "diversity_metric": null,
            "diversity_results": null,
            "novelty_executability_tradeoff": null,
            "frontier_characterization": null,
            "benchmark_or_domain": "Symbolic discovery/evolution of density functional approximations for Kohn-Sham DFT; evaluation on MGCDB84 benchmark database (chemistry energetics datasets).",
            "comparison_baseline": "Random search (tournament size = 1), starting functional GAS22-a (!B97M-V symbolic form with optimized parameters), and existing manual functionals used as references (e.g. !B97M-V).",
            "key_findings": "Regularized evolution (with tournament-based selection and the described mutation operators) is effective at traversing the symbolic search space and producing functionals with improved validation error compared to random search; random search (parent chosen uniformly, tournament size = 1) is ineffective. Fingerprint-based equivalence checking prevents redundant re-training by hashing functional outputs on a fixed set of features and parameter seeds. Numerical parameter optimization for each structure is handled with CMA-ES. The paper reports explicit mutation instruction probabilities and demonstrates that mutation-only evolutionary search (as implemented) can discover compact symbolic forms (GAS22 variants) that achieve low errors; no crossover operation or explicit novelty metric is described or used.",
            "uuid": "e1582.0",
            "source_info": {
                "paper_title": "Evolving symbolic density functionals",
                "publication_date_yy_mm": "2022-09"
            }
        },
        {
            "name_short": "RandomSearch-DFT",
            "name_full": "Random-search baseline for symbolic functional discovery",
            "brief_description": "A baseline search procedure where the parent for mutation is selected uniformly at random (implemented by setting tournament size = 1), used to compare against the regularized evolution implementation.",
            "citation_title": "",
            "mention_or_use": "use",
            "system_name": "Random search (tournament size = 1)",
            "system_description": "Same mutation operator and distributed training/evaluation pipeline as the regularized evolution program, but parent selection ignores fitness (uniform random selection); used to generate dashed-line baselines in validation-error plots.",
            "input_type": "symbolic programs / mathematical expressions (symbolic representation of density functionals)",
            "crossover_operation": null,
            "mutation_operation": "Same mutation operator as RegEvolution-DFT: edit the symbolic instruction list using the predefined instruction probabilities (arithmetic ops 0.06 each, power ops 0.05 each, u-transform 0.1, other building blocks 0.075 each).",
            "uses_literature": false,
            "uses_code": true,
            "novelty_metric": null,
            "novelty_results": null,
            "executability_metric": "Training/validation/test error on MGCDB84 after parameter optimization with CMA-ES.",
            "executability_results": "Random search produced worse validation errors than regularized evolution as shown in Fig. S4 (dashed lines), and is described as 'ineffective in traversing the search space and generating better functional forms than existing forms'; no single aggregate numeric summary given beyond plotted curves.",
            "diversity_metric": null,
            "diversity_results": null,
            "novelty_executability_tradeoff": null,
            "frontier_characterization": null,
            "benchmark_or_domain": "Symbolic discovery of density functionals, evaluated on MGCDB84",
            "comparison_baseline": "Compared directly against the Regularized Evolution implementation and to the starting functional GAS22-a (!B97M-V form with optimized parameters).",
            "key_findings": "Random selection of parents (tournament size = 1) yields a search that is much less effective than tournament-based regularized evolution; demonstrates importance of selection pressure in the evolutionary search. The study uses this to argue that regularized evolution produces more promising structures than random mutation alone.",
            "uuid": "e1582.1",
            "source_info": {
                "paper_title": "Evolving symbolic density functionals",
                "publication_date_yy_mm": "2022-09"
            }
        },
        {
            "name_short": "AutoML-Zero",
            "name_full": "AutoML-Zero: Evolving machine learning algorithms from scratch",
            "brief_description": "A cited evolutionary framework that evolves machine learning algorithms starting from a minimal set of primitives (cited as related work).",
            "citation_title": "AutoML-Zero: Evolving machine learning algorithms from scratch",
            "mention_or_use": "mention",
            "system_name": "AutoML-Zero (cited)",
            "system_description": "A prior work that uses evolutionary search over low-level primitives to discover learning algorithms; cited in related work to situate the present symbolic-evolution approach in the broader literature on evolving algorithmic structures.",
            "input_type": "programs / algorithmic primitives (as in the original AutoML-Zero work)",
            "crossover_operation": null,
            "mutation_operation": null,
            "uses_literature": null,
            "uses_code": null,
            "novelty_metric": null,
            "novelty_results": null,
            "executability_metric": null,
            "executability_results": null,
            "diversity_metric": null,
            "diversity_results": null,
            "novelty_executability_tradeoff": null,
            "frontier_characterization": null,
            "benchmark_or_domain": "Mentioned in related work on evolving algorithms and AutoML.",
            "comparison_baseline": "",
            "key_findings": "Cited as related work motivating evolution of algorithmic forms; the present paper adapts evolutionary ideas to symbolic density-functional discovery but does not re-implement AutoML-Zero.",
            "uuid": "e1582.2",
            "source_info": {
                "paper_title": "Evolving symbolic density functionals",
                "publication_date_yy_mm": "2022-09"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Exploring density functional subspaces with genetic algorithms",
            "rating": 2,
            "sanitized_title": "exploring_density_functional_subspaces_with_genetic_algorithms"
        },
        {
            "paper_title": "Regularized evolution for image classifier architecture search",
            "rating": 2,
            "sanitized_title": "regularized_evolution_for_image_classifier_architecture_search"
        },
        {
            "paper_title": "AutoML-Zero: Evolving machine learning algorithms from scratch",
            "rating": 2,
            "sanitized_title": "automlzero_evolving_machine_learning_algorithms_from_scratch"
        },
        {
            "paper_title": "Evolving reinforcement learning algorithms",
            "rating": 1,
            "sanitized_title": "evolving_reinforcement_learning_algorithms"
        },
        {
            "paper_title": "Fast, accurate, and transferable many-body interatomic potentials by symbolic regression",
            "rating": 1,
            "sanitized_title": "fast_accurate_and_transferable_manybody_interatomic_potentials_by_symbolic_regression"
        }
    ],
    "cost": 0.010533,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Supplementary Materials for Evolving symbolic density functionals He Ma et al. This PDF file includes: Sections S1 to S7 Figs. S1 to S5 References
2022</p>
<p>Sci 
Adv 
Supplementary Materials for Evolving symbolic density functionals He Ma et al. This PDF file includes: Sections S1 to S7 Figs. S1 to S5 References
8279202210.1126/sciadv.abq0279Corresponding author:</p>
<p>Supplementary Materials 1 Functional forms</p>
<p>In this section we present the functional forms in main text Eq. 2-3 for general systems (which may contains spin polarization).</p>
<p>The semilocal part of the exchange-correlation functional assumes the following form where a = !/k F with k F = (3⇡ 2 ⇢) 1/3 being the Fermi wave vector and ! being the rangeseparation parameter.</p>
<p>F x, , F c-ss, and F c-os are the exchange, same-spin correlation and opposite-spin correlation enhancement factors that depends on reduced density gradient and kinetic energy density
F x, = F x, (x 2 , w ), F c-ss, = F c-ss, (x 2 , w ), F c-os = F c-os (x 2 ave , w ave )(S3)
where x = |r⇢ | ⇢ 4/3 denotes the reduced density gradient. w is an auxiliary quantity that depends on kinetic energy density ⌧ = 1 2 P occ i |r i | 2 , with 's being Kohn-Sham orbitals and the summation runs over occupied Kohn-Sham orbitals. In particular, w = (t 1)/(t + 1), with t = ⌧ HEG /⌧ where ⌧ HEG = 3 10 (6⇡ 2 ) 2/3 ⇢ 5/3 is the kinetic energy density of homogenous electron gas (HEG). The opposite-spin correlation enhancement factor F c-ss, depends on spinaveraged version of x 2 and w, defined as x 2 ave = 1 2 (x 2 ↵ + x 2 ) and w ave = (t ave 1)/(t ave + 1) with t ave = 1 2 (t ↵ + t ). We note that the form of input features for enhancement factors defined here are widely-used in B97-inspired functional forms.</p>
<p>The nonlocal part of the exchange-correlation functional contains the short-range exactexchange E exact</p>
<p>x-sr , long-range exact exchange E exact x-lr and VV10 nonlocal correlation E VV10 c . The short-range and long-range exact exchange assume the following form
E exact x-sr [⇢] = c x 2 X occ X i,j Z Z ⇤ i (r 1 ) ⇤ j (r 2 ) erfc(!r) r j (r 1 ) i (r 2 )dr 1 dr 2 (S4) E exact x-lr [⇢] = 1 2 X occ X i,j Z Z ⇤ i (r 1 ) ⇤ j (r 2 ) erf(!r) r j (r 1 ) i (r 2 )dr 1 dr 2 (S5)
where r = |r 1 r 2 | and ! is a range-separation parameter controlling the characteristic length scale for range separation. Note that there is a prefactor c x controlling the amount of short-range exact exchange used in the functional form. The exchange functional used in this work thus behaves as purely exact exchange in long range and a mixture of semilocal and exact exchange in short range. The VV10 nonlocal correlation E VV10 c assumes the form
E VV10 c [⇢] = Z ⇢(r 1 ) " 1 32  3 b 2 3/4 + 1 2 Z ⇢(r 2 ) (r 1 , r 2 ; b, C)dr 2 # dr 1 (S6)
where integration kernel depends on two empirical parameters b and C (see Ref. (76) for expression). We keep all the empirical parameters in nonlocal terms to be identical to those in
!B97M-V, namely ! = 0.3, c x = 0.15, b = 6 and C = 0.01.</p>
<p>Evolution of symbolic functional forms</p>
<p>The simplified mathematical forms of functional forms shown in Fig. 4 of the main text is shown below. c's and are parameters. The same symbol (e.g. c 0 ) in different enhancement factors of the same functional represent different parameters. See Table S1 for numerical values for the parameters in the GAS22 functional.</p>
<dl>
<dt>GAS22-a (!B97M-V):</dt>
<dt>F x = c 0 + c 1 w + c 2 x 2 1 + x 2 F c-ss = c 0 + c 1 w + c 2 w 2 + c 3 4 x 8 (1 + x 2 ) 4 + c 4 3 w 4 x 6 (1 + x 2 ) 3 F c-os = c 0 + c 1 w + c 2 w 2 + c 3 w 6 + c 4 w 2 x 2 1 + x 2 + c 5 w 6 x 2 1 + x 2 GAS22-b: F x = c 0 + c 1 w + c 2 x 2 1 + x 2 F c-ss = c 1 w + c 2 w 2 + c 3 6 w 4 x 12 (1 + x 2 ) 6 + c 4 4 x 8 (1 + x 2 ) 4 + x 2 1 + x 2 F c-os = c 0 + c 2 w 2 + c 3 w 6 + c 4 w 6 x 2 1 + x 2 + c 5 w 2 x 2 1 + x 2 GAS22-c: F x = c 0 + c 1 w + c 2 x 2 1 + x 2 F c-ss = c 1 w + c 2 w 2 + c 3 6 w 4 x 12 (1 + x 2 ) 6 + c 4 6 x 12 (1 + x 2 ) 6 + x 2 1 + x 2 F c-os = c 0 + c 2 w 2 + c 3 w 6 + c 4 w 6 3 p x 2 + c 5 w 2 3 p x 2 GAS22</dt>
<dd>F x = c 0 + c 1 w + c 2 x 2 1 + x 2 F c-ss = c 1 w + c 2 w 2 + c 3 6 w 4 x 12 (1 + x 2 ) 6 + c 4 6 x 12 (1 + x 2 ) 6 + x 2 1 + x 2 F c-os = c 0 + c 2 w 2 + c 3 w 6 + c 4 w 6 3 p x 2 + c 5 w 2 3 p x 2 F x c 0 0.862139736374172 c 1 0.317533683085033 c 2 0.936993691972698 0.003840616724010807 F c-ss c 1 4.10753796482853 c 2 5.24218990333846 c 3 7.5380689617542 c 4 1.76643208454076 0.46914023462026644 F c-os c 0 0.805124374375355 c 2 7.98909430970845 c 3 7.54815900595292 c 4 2.00093961824784 c 5 1.76098915061634</dd>
</dl>
<p>Symbolic representations of density functionals</p>
<p>As stated in the Table 1   Symbolic representation of !B97M-V: Figure S1: Exchange enhancement factors F x for functional forms in main text Fig. 4. For reference, the enhancement factor for the !B97M-V functional is plotted in grey. Figure S2: Same-spin correlation enhancement factors F c-ss for functional forms in main text Fig. 4. For reference, the enhancement factor for the !B97M-V functional is plotted in grey. Figure S3: Opposite-spin correlation enhancement factors F c-os for functional forms in main text Fig. 4. For reference, the enhancement factor for the !B97M-V functional is plotted in grey.
Algorithm 1: F !B97M-V x Features: w, x 2 Variables: F , v 0 , v 1 Parameters: , c 00 , c 10 , c 01 Instructions: v 0 = x 2 /(1 + x 2 ) F = c 00 + F v 1 = c 10 ⇥ w F = F + v 1 v 1 = c 01 ⇥ v 0 F = F + v 1 return F Algorithm 2: F !B97M-V c-ss Features: w, x 2 Variables: F , v 0 , v 1 , v 2 , v 3 Parameters: , c 00 , c 10 , c 20 , c 43 , c 04 Instructions: v 0 = x 2 /(1 + x 2 ) F = c 00 + F F + = c 10 ⇥ w v 1 = w 2 F + = c 20 ⇥ v 1 v 1 = w 4 v 2 = v 3 0 v 3 = v 3 ⇥ v 2 F + = c 43 ⇥ v 3 v 2 = v 4 0 F + = c 04 ⇥ v 2 return F Algorithm 3: F !B97M-V c-os Features: w, x 2 Variables: F , v 0 , v 1 , v 2 , v 3 Parameters: , c 00 , c 10 , c 20 , c 21 , c 60 , c 61 Instructions: v 0 = x 2 /(1 + x 2 ) F = c 00 + F F + = c 10 ⇥ w v 1 = w 2 F + = c 20 ⇥ v 1 v 3 = v 1 ⇥ v 0 F + = c 21 ⇥ v 1 v 1 = w 6 F + = c 60 ⇥ v 1 v 3 = v 1 ⇥ v 0 F + = c 61 ⇥ v 3 return F</p>
<p>Enhancement factors of symbolic functionals</p>
<p>Random search studies starting from !B97M-V</p>
<p>In main text Fig. 4 we presented regularized evolution calculations starting from the !B97M-V functional. For comparison, in Fig. S4 we report random search calculations (dash lines). The random search studies are performed with identical set up as regularized evolution experiments, except that the tournament size is set to 1. Therefore, in each iteration of random search experiment, the parent functional used for mutation is randomly selected from the population without referring to the fitness of functional forms. Compared to regularized evolution calculations, random search is found to be ineffective in traversing the search space and generating better functional forms than existing forms. To check for equivalent functional forms and avoid duplicated computations, each functional is assigned a fingerprint. The fingerprint is evaluated by computing the functional values using a set of features and parameters that are randomly chosen but kept consistent during the entire program. The functional values are then hashed and the hash value serves as the functional Figure S5: Distributed design of symbolic regression software program. The program consists of a population server, a population database, a fingerprint server for functional equivalence checking and a number of workers for training and evaluating functional forms. The regularized evolution process is performed on the population server, and all child functionals are sent to workers for training and evaluation. The workers will first check if equivalence forms are already explored. If equivalence forms are explored before, the worker will directly send the cached fitness value in fingerprint server to the population server.</p>
<p>fingerprint. The fingerprint is identical across all equivalent functional forms because they all evaluates to the same values with same parameters and features. All fingerprints and fitness values of explored functionals are cached during the regularized evolution calculations. Every time a new functional form is generated from mutation, its fingerprint will be evaluated to check if equivalent forms have already been explored. If equivalent forms are explored before, the cached fitness values are used without re-training the functional form.</p>
<p>Colab notebook demonstration of GAS22 in self-consistent calculations</p>
<p>We provide an example Colab notebook to demonstrate self-consistent DFT calculations with GAS22 functional at https://colab.research.google.com/github/google-research/ google-research/blob/master/symbolic_functionals/colab/run_GAS22.</p>
<p>ipynb.</p>
<p>ss, F c-ss, + e LDA c-os F c-os ! dr (S1) where 2 {↵, } is the spin index; e LDA x-sr, , e LDA c-ss, , and e LDA c-os are short-range exchange, same-spin correlation and opposite-spin correlation energy densities within local (spin) density approximation. The partition of correlation energy into same-spin and opposite-spin contributions adopts the widely-used scheme proposed by Stoll et al. (59). The short-range LDA exchange energy density e LDA x-sr, is obtained by multiplying the LDA exchange energy density e</p>
<p>.We design the probability such that similar instructions receive identical probabilities andprobabilities distribute evenly among different types of instructions. For the 5 arithmetic operations, each operation receive a probability of 0.06; for the 6 power instructions, each receive a probability of 0.05; u transform receive a probability of 0.1, and the other 4 building block receive a 0.075 each.</p>
<p>Figure S4 :
S4Validation error of symbolic functionals generated by random search and regularized evolution experiments starting from the !B97M-V functional. Random search and regularized evolution results are shown with dashed (solid) lines, with different lines represent independent experiments. The reference values in MGCDB84 database are used as targets for training and evaluation of functionals. Here we make some additional remark on the starting point (termed GAS22-a in the main text) of the regularized evolution and random search studies. GAS22-a has identical symbolic form as !B97M-V, but with all parameters (including 's) optimized on the training set as done for all the symbolic functional forms generated in this work. In the original work that created the !B97M-V functional, the nonlinear parameters 's are not optimized and only linear parameters are optimized. Thus GAS22-a is a different functional as !B97M-V and have different training/validation/test errors: 2.97/3.82/4.47 kcal/mol. 6 Software design In Fig. S5 we present the high-level software design of the distributed regularized evolution program. The program consists of a population server, a population database, a fingerprint server for functional equivalence checking and a number of workers for training and evaluating functional forms. The training of a functional form is performed with the CMA-ES algorithm, which require to compute the the training error on tens of thousands of sets of different parameters. Such calculations are efficiently performed by porting the calculation of training errors to GPU processors through just-in-time compilation.As briefly mentioned in the main text, one functional form may have multiple equivalent symbolic representations. For the purpose the functional equivalence checking, we define equivalent forms as forms that evaluates to the same value given same parameters and features, and we do not consider more complicated forms of equivalence such as the those requiring a mapping of parameters (e.g. the equivalence of B97 exchange functional and the symbolic functional obtained in main text).</p>
<p>Table S1 :
S1Parameters in the GAS22 functional.</p>
<p>of the main text, the instructions used in this work include 3 categories: arithmetic operations, power operations and building blocks from existing functionals. For the category of building blocks of existing functionals, we considered a few additional instructions in addition to the x/(1 + x) presented inTable 1, including PBE exchange enhancementfactor F PBE </p>
<p>x </p>
<p>(63), RPBE exchange enhancement factor F RPBE </p>
<p>x </p>
<p>(77), B88 exchange enhancement </p>
<p>factor F B88 </p>
<p>x </p>
<p>(78) and PBE correlation energy functional E PBE </p>
<p>c </p>
<p>Inhomogeneous electron gas. P Hohenberg, W Kohn, Phys. Rev. 136864P. Hohenberg, W. Kohn, Inhomogeneous electron gas. Phys. Rev. 136, B864 (1964).</p>
<p>R M Martin, Electronic Structure: Basic Theory and Practical Methods. Cambridge Univ. PressR. M. Martin, Electronic Structure: Basic Theory and Practical Methods (Cambridge Univ. Press, 2020).</p>
<p>Density functional theory: Its origins, rise to prominence, and future. R O Jones, Rev. Mod. Phys. 87R. O. Jones, Density functional theory: Its origins, rise to prominence, and future. Rev. Mod. Phys. 87, 897-923 (2015).</p>
<p>Novel algorithms and high-performance cloud computing enable efficient fully quantum mechanical protein-ligand scoring. N Mardirossian, Y Wang, D A Pearlman, G K Chan, T Shiozaki, arXiv:2004.08725physics.chem-ph]N. Mardirossian, Y. Wang, D. A. Pearlman, G. K. Chan, T. Shiozaki, Novel algorithms and high-performance cloud computing enable efficient fully quantum mechanical protein-ligand scoring. arXiv:2004.08725 [physics.chem-ph] (18 April 2020).</p>
<p>Density functional theory in surface chemistry and catalysis. J K Nørskov, F Abild-Pedersen, F Studt, T Bligaard, Proc. Natl. Acad. Sci. 108J. K. Nørskov, F. Abild-Pedersen, F. Studt, T. Bligaard, Density functional theory in surface chemistry and catalysis. Proc. Natl. Acad. Sci. 108, 937-943 (2011).</p>
<p>The long and winding road: Predicting materials properties through theory and computation. G Galli, Handbook of Materials Modeling: Methods: Theory and Modeling. G. Galli, The long and winding road: Predicting materials properties through theory and computation, in Handbook of Materials Modeling: Methods: Theory and Modeling (2020), pp. 37-48.</p>
<p>Self-consistent equations including exchange and correlation effects. W Kohn, L J Sham, Phys. Rev. 140W. Kohn, L. J. Sham, Self-consistent equations including exchange and correlation effects. Phys. Rev. 140, A1133-A1138 (1965).</p>
<p>Perspective: Fifty years of density-functional theory in chemical physics. A D Becke, J. Chem. Phys. 140A. D. Becke, Perspective: Fifty years of density-functional theory in chemical physics. J. Chem. Phys. 140, 18A301 (2014).</p>
<p>Perspective: Kohn-sham density functional theory descending a staircase. H S Yu, S L Li, D G Truhlar, J. Chem. Phys. 130901H. S. Yu, S. L. Li, D. G. Truhlar, Perspective: Kohn-sham density functional theory descending a staircase. J. Chem. Phys., 130901 (2016).</p>
<p>Recent developments in density functional approximations. L Li, K Burke, Handbook of Materials Modeling: Methods: Theory and Modeling. L. Li, K. Burke, Recent developments in density functional approximations, in Handbook of Materials Modeling: Methods: Theory and Modeling (2020), pp. 213-226.</p>
<p>Thirty years of density functional theory in computational chemistry: An overview and extensive assessment of 200 density functionals. N Mardirossian, M Head-Gordon, Mol. Phys. 115N. Mardirossian, M. Head-Gordon, Thirty years of density functional theory in computational chemistry: An overview and extensive assessment of 200 density functionals, Mol. Phys. 115, 2315-2372 (2017).</p>
<p>Systematic optimization of long-range corrected hybrid density functionals. J.-D Chai, M Head-Gordon, J. Chem. Phys. 12884106J.-D. Chai, M. Head-Gordon, Systematic optimization of long-range corrected hybrid density functionals. J. Chem. Phys. 128, 084106 (2008).</p>
<p>ωb97x-v: A 10-parameter, range-separated hybrid, generalized gradient approximation density functional with nonlocal correlation, designed by a survival-of-the-fittest strategy. N Mardirossian, M Head-Gordon, Phys. Chem. Chem. Phys. 16N. Mardirossian, M. Head-Gordon, ωb97x-v: A 10-parameter, range-separated hybrid, generalized gradient approximation density functional with nonlocal correlation, designed by a survival-of-the-fittest strategy. Phys. Chem. Chem. Phys. 16, 9904-9924 (2014).</p>
<p>Mapping the genome of meta-generalized gradient approximation density functionals: The search for b97m-v. N Mardirossian, M Head-Gordon, J. Chem. Phys. 14274111N. Mardirossian, M. Head-Gordon, Mapping the genome of meta-generalized gradient approximation density functionals: The search for b97m-v, J. Chem. Phys. 142, 074111 (2015).</p>
<p>ωb97m-v: A combinatorially optimized, range-separated hybrid, meta-gga density functional with vv10 nonlocal correlation. N Mardirossian, M Head-Gordon, J. Chem. Phys. 144214110N. Mardirossian, M. Head-Gordon, ωb97m-v: A combinatorially optimized, range-separated hybrid, meta-gga density functional with vv10 nonlocal correlation. J. Chem. Phys. 144, 214110 (2016).</p>
<p>Survival of the most transferable at the top of Jacob's ladder: Defining and testing the ωb97m (2) double hybrid density functional. N Mardirossian, M Head-Gordon, J. Chem. Phys. 148241736N. Mardirossian, M. Head-Gordon, Survival of the most transferable at the top of Jacob's ladder: Defining and testing the ωb97m (2) double hybrid density functional. J. Chem. Phys. 148, 241736 (2018).</p>
<p>Applications and validations of the minnesota density functionals. Y Zhao, D G Truhlar, Chem. Phys. Lett. 502Y. Zhao, D. G. Truhlar, Applications and validations of the minnesota density functionals. Chem. Phys. Lett. 502, 1-13 (2011).</p>
<p>Improving the accuracy of hybrid meta-gga density functionals by range separation. R Peverati, D G Truhlar, J. Phys. Chem. Lett. 2R. Peverati, D. G. Truhlar, Improving the accuracy of hybrid meta-gga density functionals by range separation. J. Phys. Chem. Lett. 2, 2810-2817 (2011).</p>
<p>Mn15-l: A new local exchange-correlation functional for kohn-sham density functional theory with broad accuracy for atoms, molecules, and solids. H S Yu, X He, D G Truhlar, J. Chem. Theor. Comput. 12H. S. Yu, X. He, D. G. Truhlar, Mn15-l: A new local exchange-correlation functional for kohn-sham density functional theory with broad accuracy for atoms, molecules, and solids, J. Chem. Theor. Comput. 12, 1280-1293 (2016).</p>
<p>M06-sx screenedexchange density functional for chemistry and solid-state physics. Y Wang, P Verma, L Zhang, Y Li, Z Liu, D G Truhlar, X He, Proc. Natl. Acad. Sci. 117Y. Wang, P. Verma, L. Zhang, Y. Li, Z. Liu, D.G. Truhlar, X. He, M06-sx screened- exchange density functional for chemistry and solid-state physics. Proc. Natl. Acad. Sci. 117, 2294-2301 (2020).</p>
<p>Density-functional thermochemistry. V. Systematic optimization of exchangecorrelation functionals. A D Becke, J. Chem. Phys. 107A. D. Becke, Density-functional thermochemistry. V. Systematic optimization of exchange- correlation functionals. J. Chem. Phys. 107, 8554-8560 (1997).</p>
<p>Quest for a universal density functional: The accuracy of density functionals across a broad spectrum of databases in chemistry and physics. R Peverati, D G Truhlar, Philos. Trans. R. Soc. A Math. Phys. Eng. Sci. 37220120476R. Peverati, D. G. Truhlar, Quest for a universal density functional: The accuracy of density functionals across a broad spectrum of databases in chemistry and physics. Philos. Trans. R. Soc. A Math. Phys. Eng. Sci.372, 20120476 (2014).</p>
<p>Learning to approximate density functionals. B Kalita, L Li, R J Mccarty, K Burke, Acc. Chem. Res. 54B. Kalita, L. Li, R. J. McCarty, K. Burke, Learning to approximate density functionals. Acc. Chem. Res. 54, 818-826 (2021).</p>
<p>Finding density functionals with machine learning. J C Snyder, M Rupp, K Hansen, K.-R Müller, K Burke, Phys. Rev. Lett. 108253002J. C. Snyder, M. Rupp, K. Hansen, K.-R. Müller, K. Burke, Finding density functionals with machine learning. Phys. Rev. Lett. 108, 253002 (2012).</p>
<p>. L Li, J C Snyder, I M Pelaschier, J Huang, U N Niranjan, P Duncan, M Rupp, K R , L. Li, J. C. Snyder, I. M. Pelaschier, J. Huang, U.N. Niranjan, P. Duncan, M. Rupp, K.R.</p>
<p>Understanding machine-learned density functionals. K Müller, Burke, Int. J. Quant. Chem. 116Müller, K. Burke, Understanding machine-learned density functionals. Int. J. Quant. Chem. 116, 819-833 (2016).</p>
<p>Pure density functional for strong correlation and the thermodynamic limit from machine learning. L Li, T E Baker, S R White, K Burke, Phys. Rev. B. 94245129L. Li, T. E. Baker, S. R. White, K. Burke, Pure density functional for strong correlation and the thermodynamic limit from machine learning. Phys. Rev. B 94, 245129 (2016).</p>
<p>Bypassing the kohn-sham equations with machine learning. F Brockherde, L Vogt, L Li, M E Tuckerman, K Burke, K.-R Müller, Nat. Commun. 8872F. Brockherde, L. Vogt, L. Li, M. E. Tuckerman, K. Burke, K.-R. Müller, Bypassing the kohn-sham equations with machine learning. Nat. Commun. 8, 872 (2017).</p>
<p>Quantum chemical accuracy from density functional approximations via machine learning. M Bogojeski, L Vogt-Maranto, M E Tuckerman, K.-R Müller, K Burke, Nat. Commun. 115223M. Bogojeski, L. Vogt-Maranto, M. E. Tuckerman, K.-R. Müller, K. Burke, Quantum chemical accuracy from density functional approximations via machine learning. Nat. Commun. 11, 5223 (2020).</p>
<p>Semi-local machine-learned kinetic energy density functional with third-order gradients of electron density. J Seino, R Kageyama, M Fujinami, Y Ikabata, H Nakai, J. Chem. Phys. 148241705J. Seino, R. Kageyama, M. Fujinami, Y. Ikabata, H. Nakai, Semi-local machine-learned kinetic energy density functional with third-order gradients of electron density. J. Chem. Phys. 148, 241705 (2018).</p>
<p>Deep learning and density-functional theory. K Ryczko, D A Strubbe, I Tamblyn, Phys. Rev. A. 10022512K. Ryczko, D. A. Strubbe, I. Tamblyn, Deep learning and density-functional theory. Phys. Rev. A 100, 022512 (2019).</p>
<p>Orbital-free density functional theory calculation applying semi-local machine-learned kinetic energy density functional and kinetic potential. M Fujinami, R Kageyama, J Seino, Y Ikabata, H Nakai, Chem. Phys. Lett. 748137358M. Fujinami, R. Kageyama, J. Seino, Y. Ikabata, H. Nakai, Orbital-free density functional theory calculation applying semi-local machine-learned kinetic energy density functional and kinetic potential. Chem. Phys. Lett. 748, 137358 (2020).</p>
<p>Machine learning approaches toward orbitalfree density functional theory: Simultaneous training on the kinetic energy density functional and its functional derivative. R Meyer, M Weichselbaum, A W Hauser, J. Chem. Theor. Comput. 16R. Meyer, M. Weichselbaum, A. W. Hauser, Machine learning approaches toward orbital- free density functional theory: Simultaneous training on the kinetic energy density functional and its functional derivative. J. Chem. Theor. Comput. 16, 5685-5694 (2020).</p>
<p>Density functionals for surface science: Exchange-correlation model development with bayesian error estimation. J Wellendorff, K T Lundgaard, A Møgelhøj, V Petzold, D D Landis, J K Nørskov, T Bligaard, K W Jacobsen, Phys. Rev. B. 85235149J. Wellendorff, K. T. Lundgaard, A. Møgelhøj, V. Petzold, D. D. Landis, J. K. Nørskov, T. Bligaard, K. W. Jacobsen, Density functionals for surface science: Exchange-correlation model development with bayesian error estimation. Phys. Rev. B 85, 235149 (2012).</p>
<p>mbeef-vdw: Robust fitting of error estimation density functionals. K T Lundgaard, J Wellendorff, J Voss, K W Jacobsen, T Bligaard, Phys. Rev. B. 93235162K. T. Lundgaard, J. Wellendorff, J. Voss, K. W. Jacobsen, T. Bligaard, mbeef-vdw: Robust fitting of error estimation density functionals. Phys. Rev. B 93, 235162 (2016).</p>
<p>Exploring density functional subspaces with genetic algorithms. M Gastegger, L González, P Marquetand, Monatsh. Chem. 150M. Gastegger, L. González, P. Marquetand, Exploring density functional subspaces with genetic algorithms. Monatsh. Chem. 150, 173-182 (2019).</p>
<p>Bayesian optimization for calibrating and selecting hybrid-density functional models. R A Vargas-Hernandez, J. Phys. Chem. A. 124R. A. Vargas-Hernandez, Bayesian optimization for calibrating and selecting hybrid-density functional models, J. Phys. Chem. A 124, 4053-4061 (2020).</p>
<p>Approximation capabilities of multilayer feedforward networks. K Hornik, Neural Netw. 4K. Hornik, Approximation capabilities of multilayer feedforward networks. Neural Netw. 4, 251-257 (1991).</p>
<p>Kohn-Sham equations as regularizer: Building prior knowledge into machine-learned physics. L Li, S Hoyer, R Pederson, R Sun, E D Cubuk, P Riley, K Burke, Phys. Rev. Lett. 12636401L. Li, S. Hoyer, R. Pederson, R. Sun, E. D. Cubuk, P. Riley, K. Burke, Kohn-Sham equations as regularizer: Building prior knowledge into machine-learned physics. Phys. Rev. Lett. 126, 036401 (2021).</p>
<p>Learning the exchange-correlation functional from nature with fully differentiable density functional theory. M F Kasim, S M Vinko, Phys. Rev. Lett. 127126403M. F. Kasim, S. M. Vinko, Learning the exchange-correlation functional from nature with fully differentiable density functional theory, Phys. Rev. Lett. 127, 126403 (2021).</p>
<p>Using differentiable programming to obtain an energy and density-optimized exchange-correlation functional. S Dick, M Fernandez-Serra, arXiv:2106.04481physics.chem-phS. Dick, M. Fernandez-Serra, Using differentiable programming to obtain an energy and density-optimized exchange-correlation functional. arXiv:2106.04481 [physics.chem-ph] (8 June 2021).</p>
<p>Completing density functional theory by machine learning hidden messages from molecules. R Nagai, R Akashi, O Sugino, Comput. Mater. 643R. Nagai, R. Akashi, O. Sugino, Completing density functional theory by machine learning hidden messages from molecules. npj Comput. Mater. 6, 43 (2020).</p>
<p>Machine-learning-based exchange correlation functional with physical asymptotic constraints. R Nagai, R Akashi, O Sugino, Phys. Rev. Res. 413106R. Nagai, R. Akashi, O. Sugino, Machine-learning-based exchange correlation functional with physical asymptotic constraints. Phys. Rev. Res. 4, 013106 (2022).</p>
<p>A comprehensive data-driven approach toward chemically accurate density functional theory. Y Chen, L Zhang, H Wang, W E , Deepks , J. Chem. Theor. Comput. 17Y. Chen, L. Zhang, H. Wang, W. E, Deepks: A comprehensive data-driven approach toward chemically accurate density functional theory. J. Chem. Theor. Comput. 17, (2021).</p>
<p>Machine learning accurate exchange and correlation functionals of the electronic density. S Dick, M Fernandez-Serra, Nat. Commun. 113509S. Dick, M. Fernandez-Serra, Machine learning accurate exchange and correlation functionals of the electronic density. Nat. Commun. 11, 3509 (2020).</p>
<p>. J Kirkpatrick, B Mcmorrow, D H P Turban, A L Gaunt, J S Spencer, A G D , J. Kirkpatrick, B. McMorrow, D. H. P. Turban, A. L. Gaunt, J. S. Spencer, A. G. D. G.</p>
<p>. A Matthews, L Obika, M Thiry, D Fortunato, L R Pfau, S Castellanos, A W Petersen, Matthews, A. Obika, L. Thiry, M. Fortunato, D. Pfau, L.R. Castellanos, S. Petersen, A. W. R.</p>
<p>Pushing the frontiers of density functionals by solving the fractional electron problem. P Nelson, P Kohli, D Mori-Sánchez, A J Hassabis, Cohen, Science. 374Nelson, P. Kohli, P. Mori-Sánchez, D. Hassabis, A. J. Cohen, Pushing the frontiers of density functionals by solving the fractional electron problem, Science 374, 1385-1389 (2021).</p>
<p>Distilling free-form natural laws from experimental data. M Schmidt, H Lipson, Science. 324M. Schmidt, H. Lipson, Distilling free-form natural laws from experimental data, Science 324, 81-85 (2009).</p>
<p>A physics-inspired method for symbolic regression. S.-M Udrescu, M Tegmark, Ai Feynman, Sci. Adv. 62631S.-M. Udrescu, M. Tegmark, Ai Feynman: A physics-inspired method for symbolic regression. Sci. Adv. 6, eaay2631 (2020).</p>
<p>Sisso: A compressed-sensing method for identifying the best low-dimensional descriptor in an immensity of offered candidates. R Ouyang, S Curtarolo, E Ahmetcik, M Scheffler, L M Ghiringhelli, Phys. Rev. Mater. 283802R. Ouyang, S. Curtarolo, E. Ahmetcik, M. Scheffler, L. M. Ghiringhelli, Sisso: A compressed-sensing method for identifying the best low-dimensional descriptor in an immensity of offered candidates, Phys. Rev. Mater. 2, 083802 (2018).</p>
<p>New tolerance factor to predict the stability of perovskite oxides and halides. C J Bartel, C Sutton, B R Goldsmith, R Ouyang, C B Musgrave, L M Ghiringhelli, M Scheffler, Sci. Adv. 5693C. J. Bartel, C. Sutton, B. R. Goldsmith, R. Ouyang, C. B. Musgrave, L. M. Ghiringhelli, M. Scheffler, New tolerance factor to predict the stability of perovskite oxides and halides. Sci. Adv. 5, eaav0693 (2019).</p>
<p>Neural-guided symbolic regression with semantic prior. L Li, M Fan, R Singh, P Riley, arXiv:1901.07714[cs.LGL. Li, M. Fan, R. Singh, P. Riley, Neural-guided symbolic regression with semantic prior. arXiv:1901.07714 [cs.LG] (23 January 2019).</p>
<p>Discovering symbolic models from deep learning with inductive biases. M D Cranmer, A Sanchez-Gonzalez, P Battaglia, R Xu, K Cranmer, D Spergel, S Ho, Proceedings of the 34th Conference on Neural Information Processing Systems. the 34th Conference on Neural Information Processing SystemsVancouver, CanadaM. D. Cranmer, A. Sanchez-Gonzalez, P. Battaglia, R. Xu, K. Cranmer, D. Spergel, S. Ho, Discovering symbolic models from deep learning with inductive biases, in Proceedings of the 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada, 6 to 12 December 2020 (2020).</p>
<p>Fast, accurate, and transferable many-body interatomic potentials by symbolic regression. A Hernandez, A Balasubramanian, F Yuan, S A Mason, T Mueller, Comput. Mater. 5112A. Hernandez, A. Balasubramanian, F. Yuan, S. A. Mason, T. Mueller, Fast, accurate, and transferable many-body interatomic potentials by symbolic regression. npj Comput. Mater. 5, 112 (2019).</p>
<p>Application of symbolic regression for constitutive modeling of plastic deformation. E Kabliman, A H Kolody, J Kronsteiner, M Kommenda, G Kronberger, Appl. Eng. Sci. 6100052E. Kabliman, A. H. Kolody, J. Kronsteiner, M. Kommenda, G. Kronberger, Application of symbolic regression for constitutive modeling of plastic deformation. Appl. Eng. Sci. 6, 100052 (2021).</p>
<p>Symbolic regression in materials science. Y Wang, N Wagner, J M Rondinelli, MRS Commun. 9Y. Wang, N. Wagner, J. M. Rondinelli, Symbolic regression in materials science. MRS Commun. 9, 793-805 (2019).</p>
<p>Feature engineering and symbolic regression methods for detecting hidden physics from sparse sensor observation data. H Vaddireddy, A Rasheed, A E Staples, O San, Phys. Fluids. 3215113H. Vaddireddy, A. Rasheed, A. E. Staples, O. San, Feature engineering and symbolic regression methods for detecting hidden physics from sparse sensor observation data, Phys. Fluids 32, 015113 (2020).</p>
<p>Symbolic physics learner: Discovering governing equations via Monte Carlo tree search. F Sun, Y Liu, J.-X Wang, H Sun, arXiv:2205.13134[cs.AIF. Sun, Y. Liu, J.-X. Wang, H. Sun, Symbolic physics learner: Discovering governing equations via Monte Carlo tree search. arXiv:2205.13134 [cs.AI] (26 May 2022).</p>
<p>Regularized evolution for image classifier architecture search. E Real, A Aggarwal, Y Huang, Q V Le, Proc. AAAI Conf. AAAI Conf33E. Real, A. Aggarwal, Y. Huang, Q. V. Le, Regularized evolution for image classifier architecture search. Proc. AAAI Conf. Artif. Intell. 33, 4780-4789 (2019).</p>
<p>Accurate and simple analytic representation of the electron-gas correlation energy. J P Perdew, Y Wang, Phys. Rev. B. 45J. P. Perdew, Y. Wang, Accurate and simple analytic representation of the electron-gas correlation energy, Phys. Rev. B 45, 13244-13249 (1992).</p>
<p>Correlation energies in the spin-density functional formalism. H Stoll, C Pavlidou, H Preuß, Theor. Chim. Acta. 55H. Stoll, C. Pavlidou, H. Preuß, Correlation energies in the spin-density functional formalism. Theor. Chim. Acta 55, 29-41 (1980).</p>
<p>AutoML-Zero: Evolving machine learning algorithms from scratch. E Real, C Liang, D R So, Q V Le, Proceedings of 37th International Conference on Machine Learning (ICML). 37th International Conference on Machine Learning (ICML)ICML13E. Real, C. Liang, D. R. So, Q. V. Le, AutoML-Zero: Evolving machine learning algorithms from scratch, in Proceedings of 37th International Conference on Machine Learning (ICML), 13 to 18 July 2020 (ICML, 2020).</p>
<p>J D Co-Reyes, Y Miao, D Peng, E Real, S Levine, Q V Le, H Lee, A Faust, arXiv:2101.03958[cs.LGEvolving reinforcement learning algorithms. J. D. Co-Reyes, Y. Miao, D. Peng, E. Real, S. Levine, Q. V. Le, H. Lee, A. Faust, Evolving reinforcement learning algorithms. arXiv:2101.03958 [cs.LG] (8 January 2021).</p>
<p>Density functionals that recognize covalent, metallic, and weak bonds. J Sun, B Xiao, Y Fang, R Haunschild, P Hao, A Ruzsinszky, G I Csonka, G E Scuseria, J P Perdew, Phys. Rev. Lett. 111106401J. Sun, B. Xiao, Y. Fang, R. Haunschild, P. Hao, A. Ruzsinszky, G.I. Csonka, G.E. Scuseria, J.P. Perdew, Density functionals that recognize covalent, metallic, and weak bonds. Phys. Rev. Lett. 111, 106401 (2013).</p>
<p>Generalized gradient approximation made simple. J P Perdew, K Burke, M Ernzerhof, Phys. Rev. Lett. 77J. P. Perdew, K. Burke, M. Ernzerhof, Generalized gradient approximation made simple. Phys. Rev. Lett. 77, 3865-3868 (1996).</p>
<p>Recent developments in LIBXC-A comprehensive library of functionals for density functional theory. S Lehtola, C Steigemann, M J Oliveira, M A Marques, SoftwareX. 7S. Lehtola, C. Steigemann, M. J. Oliveira, M. A. Marques, Recent developments in LIBXC- A comprehensive library of functionals for density functional theory, SoftwareX 7, 1-5 (2018).</p>
<p>Jacob's ladder of density functional approximations for the exchange-correlation energy. J P Perdew, K Schmidt, AIP Conf. Proc. 5771J. P. Perdew, K. Schmidt, Jacob's ladder of density functional approximations for the exchange-correlation energy. AIP Conf. Proc. 577, 1 (2001).</p>
<p>Imagenet: A large-scale hierarchical image database. J Deng, W Dong, R Socher, L.-J Li, K Li, L Fei-Fei, Proceedings of the 2009 IEEE Conference on Computer Vision and Pattern Recognition. the 2009 IEEE Conference on Computer Vision and Pattern RecognitionIEEEJ. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, L. Fei-Fei, Imagenet: A large-scale hierarchical image database, in Proceedings of the 2009 IEEE Conference on Computer Vision and Pattern Recognition (IEEE, 2009), pp. 248-255.</p>
<p>New developments in classical density functional theory. R Evans, M Oettel, R Roth, G Kahl, J. Phys. Condens. Matter. 28240401R. Evans, M. Oettel, R. Roth, G. Kahl, New developments in classical density functional theory. J. Phys. Condens. Matter 28, 240401 (2016).</p>
<p>Analytical classical density functionals from an equation learning network. S.-C Lin, G Martius, M Oettel, J. Chem. Phys. 15221102S.-C. Lin, G. Martius, M. Oettel, Analytical classical density functionals from an equation learning network. J. Chem. Phys. 152, 021102 (2020).</p>
<p>Densityfunctional fluctuation theory of crowds. J F Méndez-Valderrama, Y A Kinkhabwala, J Silver, I Cohen, T Arias, Nat. Commun. 93538J. F. Méndez-Valderrama, Y. A. Kinkhabwala, J. Silver, I. Cohen, T. Arias, Density- functional fluctuation theory of crowds, Nat. Commun. 9, 3538 (2018).</p>
<p>Advancing mathematics by guiding human intuition with ai. A Davies, P Veličković, L Buesing, S Blackwell, D Zheng, N Tomašev, R Tanburn, P Battaglia, C Blundell, A Juhász, M Lackenby, G Williamson, D Hassabis, P Kohli, Nature. 600A. Davies, P. Veličković, L. Buesing, S. Blackwell, D. Zheng, N. Tomašev, R. Tanburn, P. Battaglia, C. Blundell, A. Juhász, M. Lackenby, G. Williamson, D. Hassabis, P. Kohli, Advancing mathematics by guiding human intuition with ai, Nature 600, 70-74 (2021).</p>
<p>Jax: Composable transformations of python+ numpy programs. J Bradbury, J. Bradbury, Jax: Composable transformations of python+ numpy programs (2018);</p>
<p>. N Hansen, Y Akimoto, P Baudis, Cma-Es/Pycma On Github, 10.5281/zenodo.2559634N. Hansen, Y. Akimoto, P. Baudis, CMA-ES/pycma on Github, Zenodo, 10.5281/zenodo.2559634 (2019).</p>
<p>PySCF: The python-based simulations of chemistry framework. Q Sun, T C Berkelbach, N S Blunt, G H Booth, S Guo, Z Li, J Liu, J Mcclain, E R Sayfutyarova, S Sharma, S Wouters, G K.-L Chan, Wiley Interdiscip. Rev. Comput. Mol. Sci. 81340Q. Sun, T. C. Berkelbach, N. S. Blunt, G. H. Booth, S. Guo, Z. Li, J. Liu, J. McClain, E. R. Sayfutyarova, S. Sharma, S. Wouters, G. K.-L. Chan, PySCF: The python-based simulations of chemistry framework. Wiley Interdiscip. Rev. Comput. Mol. Sci. 8, e1340 (2017).</p>
<p>Property-optimized gaussian basis sets for molecular response calculations. D Rappoport, F Furche, J. Chem. Phys. 133134105D. Rappoport, F. Furche, Property-optimized gaussian basis sets for molecular response calculations, J. Chem. Phys. 133, 134105 (2010).</p>
<p>A standard grid for density functional calculations. P M Gill, B G Johnson, J A Pople, Chem. Phys. Lett. 209P. M. Gill, B. G. Johnson, J. A. Pople, A standard grid for density functional calculations, Chem. Phys. Lett. 209. 506-512 (1993).</p>
<p>Nonlocal van der waals density functional: The simpler the better. O A Vydrov, T Van Voorhis, J. Chem. Phys. 133244103O. A. Vydrov, T. Van Voorhis, Nonlocal van der waals density functional: The simpler the better. J. Chem. Phys. 133, 244103 (2010).</p>
<p>Improved adsorption energetics within densityfunctional theory using revised perdew-burke-ernzerhof functionals. B Hammer, L B Hansen, J K Nørskov, Phys. Rev. B. 59B. Hammer, L. B. Hansen, J. K. Nørskov, Improved adsorption energetics within density- functional theory using revised perdew-burke-ernzerhof functionals. Phys. Rev. B 59, 7413- 7421 (1999).</p>
<p>Density-functional exchange-energy approximation with correct asymptotic behavior. A D Becke, Phys. Rev. A. 38A. D. Becke, Density-functional exchange-energy approximation with correct asymptotic behavior. Phys. Rev. A 38, 3098-3100 (1988).</p>            </div>
        </div>

    </div>
</body>
</html>