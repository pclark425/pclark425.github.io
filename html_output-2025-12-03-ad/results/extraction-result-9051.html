<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-9051 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-9051</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-9051</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-159.html">extraction-schema-159</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being evaluated on cognitive psychology tests, including details of the models, the tests, LLM performance, human baseline performance, and any comparisons or notable findings.</div>
                <p><strong>Paper ID:</strong> paper-272423588</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2409.03381v1.pdf" target="_blank">CogniDual Framework: Self-Training Large Language Models within a Dual-System Theoretical Framework for Improving Cognitive Tasks</a></p>
                <p><strong>Paper Abstract:</strong> Cognitive psychology investigates perception, attention, memory, language, problem-solving, decision-making, and reasoning. Kahneman’s dual-system theory elucidates the human decision-making process, distinguishing between the rapid, intuitive System 1 and the deliberative, rational System 2. Recent advancements have positioned large language Models (LLMs) as formidable tools nearing human-level proficiency in various cognitive tasks. Nonetheless, the presence of a dual-system framework analogous to human cognition in LLMs remains unexplored. This study introduces the CogniDual Framework for LLMs (CFLLMs), designed to assess whether LLMs can, through self-training, evolve from deliberate deduction to intuitive responses, thereby emulating the human process of acquiring and mastering new information. Our findings reveal the cognitive mechanisms behind LLMs’ response generation, enhancing our understanding of their capabilities in cognitive psychology. Practically, self-trained models can provide faster responses to certain queries, reducing computational demands during inference.</p>
                <p><strong>Cost:</strong> 0.021</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e9051.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e9051.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being evaluated on cognitive psychology tests, including details of the models, the tests, LLM performance, human baseline performance, and any comparisons or notable findings.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Llama2-7B on GSM8K</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Llama2 (7B) evaluated on GSM8K</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Evaluation of the open-source Llama2 7B parameter model on GSM8K arithmetic reasoning problems under different prompting and self-training conditions.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>CogniDual Framework: Self-Training Large Language Models within a Dual-System Theoretical Framework for Improving Cognitive Tasks</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Llama2</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Open foundation and fine-tuned chat models (Transformer-based) referenced in the paper; used here in 7B-parameter configuration.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>7B</td>
                        </tr>
                        <tr>
                            <td><strong>test_battery_name</strong></td>
                            <td>GSM8K</td>
                        </tr>
                        <tr>
                            <td><strong>test_description</strong></td>
                            <td>A dataset of high-quality elementary mathematics word problems designed to evaluate arithmetic and multi-step mathematical reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>llm_performance</strong></td>
                            <td>CoT applied: 16.8% accuracy; CoT not applied: 14.6% accuracy; CFLLMs (self-practice, 1000 examples): 15.6% accuracy (mean over 5 trials).</td>
                        </tr>
                        <tr>
                            <td><strong>human_baseline_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_comparison</strong></td>
                            <td>Model performs poorly overall on GSM8K; small improvement with CoT prompting and negligible improvement from self-practice (CFLLMs) — remains well below strong reasoning performance.</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_details</strong></td>
                            <td>Few-shot prompting (8-shot for GSM8K non-CoT), CoT vs non-CoT comparisons, self-practice (CFLLMs) using up to 1000 training examples sampled from dataset; models quantized to 4-bit via GPTQ, LoRA used for fine-tuning; semantic matching judged by LLM prompts.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_caveats</strong></td>
                            <td>No human baseline reported in paper; authors note task contamination for GSM8K (models often output step-by-step reasoning even when asked not to), which may limit observable CFLLMs gains; semantic evaluation used LLM-based semantic matching rather than strict gold-standard script.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'CogniDual Framework: Self-Training Large Language Models within a Dual-System Theoretical Framework for Improving Cognitive Tasks', 'publication_date_yy_mm': '2025-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9051.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e9051.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being evaluated on cognitive psychology tests, including details of the models, the tests, LLM performance, human baseline performance, and any comparisons or notable findings.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Llama2-13B on GSM8K</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Llama2 (13B) evaluated on GSM8K</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Evaluation of the Llama2 13B-parameter model on GSM8K arithmetic reasoning under CoT, non-CoT, and self-practice conditions.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>CogniDual Framework: Self-Training Large Language Models within a Dual-System Theoretical Framework for Improving Cognitive Tasks</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Llama2</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Open foundation and fine-tuned chat models (Transformer-based) referenced in the paper; used here in 13B-parameter configuration.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>13B</td>
                        </tr>
                        <tr>
                            <td><strong>test_battery_name</strong></td>
                            <td>GSM8K</td>
                        </tr>
                        <tr>
                            <td><strong>test_description</strong></td>
                            <td>Arithmetic/multi-step math reasoning dataset.</td>
                        </tr>
                        <tr>
                            <td><strong>llm_performance</strong></td>
                            <td>CoT applied: 29.1% accuracy; CoT not applied: 27.9% accuracy; CFLLMs (1000 examples): 29.1% accuracy (mean over 5 trials).</td>
                        </tr>
                        <tr>
                            <td><strong>human_baseline_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_comparison</strong></td>
                            <td>CoT prompting improves accuracy compared to non-CoT; CFLLMs self-practice yields negligible additional improvement for this dataset.</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_details</strong></td>
                            <td>8-shot non-CoT prompting for GSM8K, CoT variants compared; self-practice with CFLLMs used up to 1000 examples; models quantized to 4-bit with GPTQ; LoRA for fine-tuning; semantic evaluation via LLM-based SemanticMatch prompts.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_caveats</strong></td>
                            <td>No human performance reported; GSM8K may suffer from task contamination (models tend to output derivations even when instructed not to), reducing detectable CFLLMs benefits.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'CogniDual Framework: Self-Training Large Language Models within a Dual-System Theoretical Framework for Improving Cognitive Tasks', 'publication_date_yy_mm': '2025-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9051.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e9051.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being evaluated on cognitive psychology tests, including details of the models, the tests, LLM performance, human baseline performance, and any comparisons or notable findings.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Vicuna-7B on GSM8K</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Vicuna (7B) evaluated on GSM8K</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Open-source Vicuna 7B model assessed on arithmetic reasoning (GSM8K) with/without CoT and after CFLLMs self-practice.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>CogniDual Framework: Self-Training Large Language Models within a Dual-System Theoretical Framework for Improving Cognitive Tasks</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Vicuna</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Open-source chat model derived from instruction tuning (based on LLaMA family); used here in a 7B configuration.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>7B</td>
                        </tr>
                        <tr>
                            <td><strong>test_battery_name</strong></td>
                            <td>GSM8K</td>
                        </tr>
                        <tr>
                            <td><strong>test_description</strong></td>
                            <td>Elementary math word problems for evaluating arithmetic/multi-step reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>llm_performance</strong></td>
                            <td>CoT applied: 14.5% accuracy; CoT not applied: 12.1% accuracy; CFLLMs (1000 examples): 12.6% accuracy (mean over 5 trials).</td>
                        </tr>
                        <tr>
                            <td><strong>human_baseline_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_comparison</strong></td>
                            <td>Low absolute accuracy; some benefit from CoT, minimal gain from CFLLMs self-practice on GSM8K.</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_details</strong></td>
                            <td>Few-shot prompting, CoT vs non-CoT; CFLLMs self-training with up to 1000 examples; 4-bit quantization, LoRA fine-tuning; semantic match judged by LLM.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_caveats</strong></td>
                            <td>No human baseline reported; performance likely affected by dataset contamination and the model's tendency to produce step-by-step reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'CogniDual Framework: Self-Training Large Language Models within a Dual-System Theoretical Framework for Improving Cognitive Tasks', 'publication_date_yy_mm': '2025-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9051.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e9051.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being evaluated on cognitive psychology tests, including details of the models, the tests, LLM performance, human baseline performance, and any comparisons or notable findings.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Vicuna-13B on GSM8K</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Vicuna (13B) evaluated on GSM8K</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Vicuna 13B assessed on GSM8K under CoT, non-CoT, and CFLLMs (self-practice) conditions.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>CogniDual Framework: Self-Training Large Language Models within a Dual-System Theoretical Framework for Improving Cognitive Tasks</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Vicuna</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Open-source chat model (LLaMA-derived instruction-tuned) used here at 13B parameters.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>13B</td>
                        </tr>
                        <tr>
                            <td><strong>test_battery_name</strong></td>
                            <td>GSM8K</td>
                        </tr>
                        <tr>
                            <td><strong>test_description</strong></td>
                            <td>Math word problems dataset assessing arithmetic reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>llm_performance</strong></td>
                            <td>CoT applied: 16.1% accuracy; CoT not applied: 15.7% accuracy; CFLLMs (1000 examples): 15.9% accuracy (mean over 5 trials).</td>
                        </tr>
                        <tr>
                            <td><strong>human_baseline_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_comparison</strong></td>
                            <td>Small improvement with CoT; CFLLMs self-practice yields minimal additional gains for GSM8K.</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_details</strong></td>
                            <td>Few-shot prompting; CoT injected vs removed (GSM8K used 8-shot non-CoT), CFLLMs self-practice up to 1000 examples; models quantized to 4-bit (GPTQ) and fine-tuned with LoRA; semantic judgments performed by an LLM prompt.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_caveats</strong></td>
                            <td>No human baseline; authors attribute small CFLLMs gains to inherent model tendency to produce stepwise reasoning on GSM8K (task contamination).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'CogniDual Framework: Self-Training Large Language Models within a Dual-System Theoretical Framework for Improving Cognitive Tasks', 'publication_date_yy_mm': '2025-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9051.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e9051.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being evaluated on cognitive psychology tests, including details of the models, the tests, LLM performance, human baseline performance, and any comparisons or notable findings.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Vicuna-30B on GSM8K</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Vicuna (30B) evaluated on GSM8K</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Vicuna 30B performance on GSM8K evaluated under CoT, non-CoT, and after CFLLMs self-practice.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>CogniDual Framework: Self-Training Large Language Models within a Dual-System Theoretical Framework for Improving Cognitive Tasks</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Vicuna</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Large (30B) variant of Vicuna used in experiments; transformer-based, instruction-tuned chat model.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>30B</td>
                        </tr>
                        <tr>
                            <td><strong>test_battery_name</strong></td>
                            <td>GSM8K</td>
                        </tr>
                        <tr>
                            <td><strong>test_description</strong></td>
                            <td>Arithmetic reasoning dataset for multi-step math problems.</td>
                        </tr>
                        <tr>
                            <td><strong>llm_performance</strong></td>
                            <td>CoT applied: 36.7% accuracy; CoT not applied: 35.6% accuracy; CFLLMs (1000 examples): 36.2% accuracy (mean over 5 trials).</td>
                        </tr>
                        <tr>
                            <td><strong>human_baseline_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_comparison</strong></td>
                            <td>Largest model achieves relatively higher accuracy on GSM8K; CoT improves performance slightly; CFLLMs self-practice yields minor improvement.</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_details</strong></td>
                            <td>8-shot non-CoT prompting for GSM8K; CFLLMs self-practice using up to 1000 examples drawn from dataset; models quantized to 4-bit, LoRA fine-tuning used.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_caveats</strong></td>
                            <td>Human baseline not provided; GSM8K contamination issues may inflate stepwise reasoning output even when CoT is not requested.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'CogniDual Framework: Self-Training Large Language Models within a Dual-System Theoretical Framework for Improving Cognitive Tasks', 'publication_date_yy_mm': '2025-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9051.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e9051.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being evaluated on cognitive psychology tests, including details of the models, the tests, LLM performance, human baseline performance, and any comparisons or notable findings.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Llama2-7B on ReClor</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Llama2 (7B) evaluated on ReClor</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Llama2 7B evaluated on ReClor reading-comprehension logical reasoning dataset with CoT, non-CoT, and CFLLMs self-practice.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>CogniDual Framework: Self-Training Large Language Models within a Dual-System Theoretical Framework for Improving Cognitive Tasks</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Llama2</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Open foundation/fine-tuned chat model family; 7B parameter variant used.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>7B</td>
                        </tr>
                        <tr>
                            <td><strong>test_battery_name</strong></td>
                            <td>ReClor</td>
                        </tr>
                        <tr>
                            <td><strong>test_description</strong></td>
                            <td>Reading comprehension dataset requiring logical reasoning (questions from standardized tests like GMAT/LSAT).</td>
                        </tr>
                        <tr>
                            <td><strong>llm_performance</strong></td>
                            <td>CoT applied: 51.5% accuracy; CoT not applied: 34.1% accuracy; CFLLMs (1000 examples): 49.0% accuracy (mean over 5 trials).</td>
                        </tr>
                        <tr>
                            <td><strong>human_baseline_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_comparison</strong></td>
                            <td>Substantially better with CoT prompting than without; CFLLMs self-practice markedly improves non-CoT performance (approaches CoT level for this model).</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_details</strong></td>
                            <td>3-shot prompting for ReClor when fabricating CoT reasoning; self-practice used 1000-example training subset; 4-bit quantization and LoRA fine-tuning; semantic matching done by LLM prompts.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_caveats</strong></td>
                            <td>No human baseline provided; semantic matching (accuracy evaluation) relies on LLM-based synonym judgments rather than deterministic matching, which may affect reported accuracies.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'CogniDual Framework: Self-Training Large Language Models within a Dual-System Theoretical Framework for Improving Cognitive Tasks', 'publication_date_yy_mm': '2025-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9051.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e9051.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being evaluated on cognitive psychology tests, including details of the models, the tests, LLM performance, human baseline performance, and any comparisons or notable findings.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Llama2-13B on ReClor</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Llama2 (13B) evaluated on ReClor</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Llama2 13B tested on ReClor logical reasoning with comparisons between CoT prompting, non-CoT, and CFLLMs self-practice.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>CogniDual Framework: Self-Training Large Language Models within a Dual-System Theoretical Framework for Improving Cognitive Tasks</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Llama2</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>13B-parameter variant of Llama2 (Transformer-based open foundation models).</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>13B</td>
                        </tr>
                        <tr>
                            <td><strong>test_battery_name</strong></td>
                            <td>ReClor</td>
                        </tr>
                        <tr>
                            <td><strong>test_description</strong></td>
                            <td>Logical reasoning reading-comprehension dataset from standardized tests (critical thinking).</td>
                        </tr>
                        <tr>
                            <td><strong>llm_performance</strong></td>
                            <td>CoT applied: 89.4% accuracy; CoT not applied: 59.9% accuracy; CFLLMs (1000 examples): 77.7% accuracy (mean over 5 trials).</td>
                        </tr>
                        <tr>
                            <td><strong>human_baseline_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_comparison</strong></td>
                            <td>CoT greatly improves accuracy; CFLLMs self-practice substantially raises non-CoT performance (though still typically below CoT performance for this model).</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_details</strong></td>
                            <td>CoT reasoning sequences were generated (3-shot) for datasets without natural reasoning; CFLLMs self-training used up to 1000 examples; evaluation averaged over 5 trials; quantized to 4-bit for GPU deployment; LoRA used.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_caveats</strong></td>
                            <td>No human baseline; models' semantic matching judgments used for accuracy scoring rather than exact match scripts; performance gains depend on size and amount of self-practice.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'CogniDual Framework: Self-Training Large Language Models within a Dual-System Theoretical Framework for Improving Cognitive Tasks', 'publication_date_yy_mm': '2025-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9051.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e9051.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being evaluated on cognitive psychology tests, including details of the models, the tests, LLM performance, human baseline performance, and any comparisons or notable findings.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Vicuna-7B on ReClor</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Vicuna (7B) evaluated on ReClor</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Vicuna 7B tested on ReClor logical reasoning under CoT, non-CoT, and CFLLMs self-practice conditions.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>CogniDual Framework: Self-Training Large Language Models within a Dual-System Theoretical Framework for Improving Cognitive Tasks</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Vicuna</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Instruction-tuned open-source chat model derived from LLaMA family, 7B configuration.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>7B</td>
                        </tr>
                        <tr>
                            <td><strong>test_battery_name</strong></td>
                            <td>ReClor</td>
                        </tr>
                        <tr>
                            <td><strong>test_description</strong></td>
                            <td>Dataset requiring logical reasoning and reading comprehension.</td>
                        </tr>
                        <tr>
                            <td><strong>llm_performance</strong></td>
                            <td>CoT applied: 55.1% accuracy; CoT not applied: 41.3% accuracy; CFLLMs (1000 examples): 53.4% accuracy (mean over 5 trials).</td>
                        </tr>
                        <tr>
                            <td><strong>human_baseline_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_comparison</strong></td>
                            <td>CoT substantially increases accuracy; CFLLMs self-practice improves non-CoT accuracy toward CoT levels but may not match them.</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_details</strong></td>
                            <td>3-shot CoT construction for ReClor, CFLLMs self-training up to 1000 examples; 4-bit quantization, LoRA fine-tuning, and LLM-based semantic judgment for evaluation.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_caveats</strong></td>
                            <td>Human baseline absent; semantic-evaluation methodology can introduce noise compared to gold-standard scoring; improvements vary with model size.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'CogniDual Framework: Self-Training Large Language Models within a Dual-System Theoretical Framework for Improving Cognitive Tasks', 'publication_date_yy_mm': '2025-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9051.8">
                <h3 class="extraction-instance">Extracted Data Instance 8 (e9051.8)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being evaluated on cognitive psychology tests, including details of the models, the tests, LLM performance, human baseline performance, and any comparisons or notable findings.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Vicuna-13B on ReClor</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Vicuna (13B) evaluated on ReClor</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Vicuna 13B performance on ReClor logical reasoning dataset across CoT, non-CoT, and CFLLMs self-training.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>CogniDual Framework: Self-Training Large Language Models within a Dual-System Theoretical Framework for Improving Cognitive Tasks</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Vicuna</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>13B-parameter Vicuna instruction-tuned chat model (LLaMA-derived).</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>13B</td>
                        </tr>
                        <tr>
                            <td><strong>test_battery_name</strong></td>
                            <td>ReClor</td>
                        </tr>
                        <tr>
                            <td><strong>test_description</strong></td>
                            <td>Logical reasoning reading-comprehension questions derived from standardized tests.</td>
                        </tr>
                        <tr>
                            <td><strong>llm_performance</strong></td>
                            <td>CoT applied: 90.8% accuracy; CoT not applied: 62.5% accuracy; CFLLMs (1000 examples): 78.7% accuracy (mean over 5 trials).</td>
                        </tr>
                        <tr>
                            <td><strong>human_baseline_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_comparison</strong></td>
                            <td>CoT yields very high performance; CFLLMs self-practice notably closes the gap between non-CoT and CoT performance for this model size.</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_details</strong></td>
                            <td>CoT sequences synthesized for dataset; self-practice used up to 1000 examples; models quantized to 4-bit; LoRA fine-tuning; semantic matches judged by LLM prompts.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_caveats</strong></td>
                            <td>No human baseline given; evaluation relies on LLM semantic judgments; CFLLMs improvements vary by dataset and are more pronounced where CoT-vs-non-CoT gaps exist.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'CogniDual Framework: Self-Training Large Language Models within a Dual-System Theoretical Framework for Improving Cognitive Tasks', 'publication_date_yy_mm': '2025-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9051.9">
                <h3 class="extraction-instance">Extracted Data Instance 9 (e9051.9)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being evaluated on cognitive psychology tests, including details of the models, the tests, LLM performance, human baseline performance, and any comparisons or notable findings.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Vicuna-30B on ReClor</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Vicuna (30B) evaluated on ReClor</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Vicuna 30B evaluated on ReClor showing very high accuracy with CoT and strong gains from CFLLMs self-practice for non-CoT prompting.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>CogniDual Framework: Self-Training Large Language Models within a Dual-System Theoretical Framework for Improving Cognitive Tasks</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Vicuna</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Large 30B-parameter Vicuna instruction-tuned chat model used in experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>30B</td>
                        </tr>
                        <tr>
                            <td><strong>test_battery_name</strong></td>
                            <td>ReClor</td>
                        </tr>
                        <tr>
                            <td><strong>test_description</strong></td>
                            <td>Reading comprehension dataset focused on logical reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>llm_performance</strong></td>
                            <td>CoT applied: 99.4% accuracy; CoT not applied: 75.2% accuracy; CFLLMs (1000 examples): 99.2% accuracy (mean over 5 trials).</td>
                        </tr>
                        <tr>
                            <td><strong>human_baseline_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_comparison</strong></td>
                            <td>With CoT the model reaches near-perfect accuracy; CFLLMs self-practice can substantially raise non-CoT performance, in this reported case reaching performance similar to CoT for the largest model.</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_details</strong></td>
                            <td>3-shot CoT generation for dataset, CFLLMs self-practice with up to 1000 examples, GPTQ 4-bit quantization, LoRA fine-tuning; evaluation via LLM-based semantic matching.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_caveats</strong></td>
                            <td>No human baseline reported; extremely high CFLLMs/ReClor numbers for largest model may reflect dataset idiosyncrasies or contamination; authors note that CFLLMs less effective for tasks where CoT and non-CoT accuracy are similar.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'CogniDual Framework: Self-Training Large Language Models within a Dual-System Theoretical Framework for Improving Cognitive Tasks', 'publication_date_yy_mm': '2025-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9051.10">
                <h3 class="extraction-instance">Extracted Data Instance 10 (e9051.10)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being evaluated on cognitive psychology tests, including details of the models, the tests, LLM performance, human baseline performance, and any comparisons or notable findings.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Llama2-7B on LogiQA2.0</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Llama2 (7B) evaluated on LogiQA2.0</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Llama2 7B evaluation on LogiQA2.0 logical reasoning benchmark, under CoT, non-CoT, and CFLLMs self-training.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>CogniDual Framework: Self-Training Large Language Models within a Dual-System Theoretical Framework for Improving Cognitive Tasks</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Llama2</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>7B-parameter Llama2 model (open foundation/fine-tuned chat models).</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>7B</td>
                        </tr>
                        <tr>
                            <td><strong>test_battery_name</strong></td>
                            <td>LogiQA2.0</td>
                        </tr>
                        <tr>
                            <td><strong>test_description</strong></td>
                            <td>An improved dataset for logical reasoning in natural language understanding derived from Chinese civil service exam questions (translated and validated).</td>
                        </tr>
                        <tr>
                            <td><strong>llm_performance</strong></td>
                            <td>CoT applied: 77.3% accuracy; CoT not applied: 0.5% accuracy; CFLLMs (1000 examples): 18.1% accuracy (mean over 5 trials).</td>
                        </tr>
                        <tr>
                            <td><strong>human_baseline_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_comparison</strong></td>
                            <td>Huge gap between CoT and non-CoT prompting (near-zero without CoT); CFLLMs self-practice substantially improves non-CoT performance but typically remains below CoT performance.</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_details</strong></td>
                            <td>For LogiQA2.0 the authors used GPT-4 to fabricate CoT reasoning sequences (3-shot) because dataset answers lack reasoning; CFLLMs self-practice used up to 1000 examples; models quantized and LoRA-trained; semantic matching via LLM prompts.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_caveats</strong></td>
                            <td>Human baseline not provided; authors highlight that small models get near-zero without CoT but CFLLMs can raise them — however, evaluation uses LLM-based semantic judgments which can be subjective.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'CogniDual Framework: Self-Training Large Language Models within a Dual-System Theoretical Framework for Improving Cognitive Tasks', 'publication_date_yy_mm': '2025-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9051.11">
                <h3 class="extraction-instance">Extracted Data Instance 11 (e9051.11)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being evaluated on cognitive psychology tests, including details of the models, the tests, LLM performance, human baseline performance, and any comparisons or notable findings.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Llama2-13B on LogiQA2.0</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Llama2 (13B) evaluated on LogiQA2.0</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Llama2 13B assessed on LogiQA2.0 with large CoT/non-CoT gap and improvements after CFLLMs self-training.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>CogniDual Framework: Self-Training Large Language Models within a Dual-System Theoretical Framework for Improving Cognitive Tasks</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Llama2</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>13B-parameter Llama2 model.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>13B</td>
                        </tr>
                        <tr>
                            <td><strong>test_battery_name</strong></td>
                            <td>LogiQA2.0</td>
                        </tr>
                        <tr>
                            <td><strong>test_description</strong></td>
                            <td>Logical reasoning dataset from civil service exam translations testing natural language logical inference.</td>
                        </tr>
                        <tr>
                            <td><strong>llm_performance</strong></td>
                            <td>CoT applied: 97.9% accuracy; CoT not applied: 5.3% accuracy; CFLLMs (1000 examples): 76.2% accuracy (mean over 5 trials).</td>
                        </tr>
                        <tr>
                            <td><strong>human_baseline_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_comparison</strong></td>
                            <td>Dramatic improvement with CoT; CFLLMs self-practice meaningfully increases non-CoT performance (for larger models can approach CoT-level performance).</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_details</strong></td>
                            <td>GPT-4 generated CoT explanations for dataset; 3-shot prompting; CFLLMs self-practice with up to 1000 examples; models quantized to 4-bit; evaluation via LLM-based SemanticMatch.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_caveats</strong></td>
                            <td>No human baseline; the very large gain from CFLLMs indicates potential dataset-specific effects or the success of internalizing CoT, but evaluation via semantic LLM judgments could be noisy.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'CogniDual Framework: Self-Training Large Language Models within a Dual-System Theoretical Framework for Improving Cognitive Tasks', 'publication_date_yy_mm': '2025-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9051.12">
                <h3 class="extraction-instance">Extracted Data Instance 12 (e9051.12)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being evaluated on cognitive psychology tests, including details of the models, the tests, LLM performance, human baseline performance, and any comparisons or notable findings.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Vicuna-7B on LogiQA2.0</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Vicuna (7B) evaluated on LogiQA2.0</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Vicuna 7B tested on LogiQA2.0 logical reasoning dataset; shows near-zero accuracy without CoT and modest gains from CFLLMs.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>CogniDual Framework: Self-Training Large Language Models within a Dual-System Theoretical Framework for Improving Cognitive Tasks</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Vicuna</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>7B variant of Vicuna (LLaMA-derived instruction-tuned chat model).</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>7B</td>
                        </tr>
                        <tr>
                            <td><strong>test_battery_name</strong></td>
                            <td>LogiQA2.0</td>
                        </tr>
                        <tr>
                            <td><strong>test_description</strong></td>
                            <td>Dataset assessing logical reasoning and natural language inference, based on translated civil service exam questions.</td>
                        </tr>
                        <tr>
                            <td><strong>llm_performance</strong></td>
                            <td>CoT applied: 79.4% accuracy; CoT not applied: 0.1% accuracy; CFLLMs (1000 examples): 16.7% accuracy (mean over 5 trials).</td>
                        </tr>
                        <tr>
                            <td><strong>human_baseline_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_comparison</strong></td>
                            <td>Extremely low performance without CoT; CFLLMs self-practice meaningfully improves non-CoT accuracy but does not reach CoT levels.</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_details</strong></td>
                            <td>CoT sequences were synthesized using GPT-4 (3-shot); CFLLMs self-practice with up to 1000 samples; models quantized 4-bit; SematicMatch performed by LLM prompts.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_caveats</strong></td>
                            <td>No human baseline; semantic-evaluation approach and potential dataset contamination may influence absolute numbers.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'CogniDual Framework: Self-Training Large Language Models within a Dual-System Theoretical Framework for Improving Cognitive Tasks', 'publication_date_yy_mm': '2025-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9051.13">
                <h3 class="extraction-instance">Extracted Data Instance 13 (e9051.13)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being evaluated on cognitive psychology tests, including details of the models, the tests, LLM performance, human baseline performance, and any comparisons or notable findings.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Vicuna-13B on LogiQA2.0</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Vicuna (13B) evaluated on LogiQA2.0</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Vicuna 13B evaluated on LogiQA2.0 showing high CoT performance and strong CFLLMs gains for non-CoT conditions.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>CogniDual Framework: Self-Training Large Language Models within a Dual-System Theoretical Framework for Improving Cognitive Tasks</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Vicuna</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>13B-parameter Vicuna instruction-tuned chat model.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>13B</td>
                        </tr>
                        <tr>
                            <td><strong>test_battery_name</strong></td>
                            <td>LogiQA2.0</td>
                        </tr>
                        <tr>
                            <td><strong>test_description</strong></td>
                            <td>Logical reasoning benchmark derived from translated civil service exam items; assesses natural language logical deduction.</td>
                        </tr>
                        <tr>
                            <td><strong>llm_performance</strong></td>
                            <td>CoT applied: 98.4% accuracy; CoT not applied: 5.1% accuracy; CFLLMs (1000 examples): 66.3% accuracy (mean over 5 trials).</td>
                        </tr>
                        <tr>
                            <td><strong>human_baseline_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_comparison</strong></td>
                            <td>CoT yields near-perfect performance; CFLLMs self-practice considerably improves non-CoT performance for larger models though generally below CoT unless model is large.</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_details</strong></td>
                            <td>GPT-4 used to generate CoT sequences where needed (3-shot); CFLLMs self-practice with up to 1000 examples; models quantized to 4-bit; evaluation via LLM-based semantic similarity judgments.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_caveats</strong></td>
                            <td>No human baseline; high reported gains may reflect dataset properties or potential contamination; evaluation is based on semantic judgments rather than deterministic scoring.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'CogniDual Framework: Self-Training Large Language Models within a Dual-System Theoretical Framework for Improving Cognitive Tasks', 'publication_date_yy_mm': '2025-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9051.14">
                <h3 class="extraction-instance">Extracted Data Instance 14 (e9051.14)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being evaluated on cognitive psychology tests, including details of the models, the tests, LLM performance, human baseline performance, and any comparisons or notable findings.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Vicuna-30B on LogiQA2.0</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Vicuna (30B) evaluated on LogiQA2.0</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Vicuna 30B evaluated on LogiQA2.0 showing near-perfect CoT performance and very high CFLLMs non-CoT performance after self-practice.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>CogniDual Framework: Self-Training Large Language Models within a Dual-System Theoretical Framework for Improving Cognitive Tasks</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Vicuna</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Large-scale 30B-parameter Vicuna instruction-tuned chat model used in experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>30B</td>
                        </tr>
                        <tr>
                            <td><strong>test_battery_name</strong></td>
                            <td>LogiQA2.0</td>
                        </tr>
                        <tr>
                            <td><strong>test_description</strong></td>
                            <td>Logical reasoning dataset focused on natural language logical inference.</td>
                        </tr>
                        <tr>
                            <td><strong>llm_performance</strong></td>
                            <td>CoT applied: 99.3% accuracy; CoT not applied: 27.6% accuracy; CFLLMs (1000 examples): 96.9% accuracy (mean over 5 trials).</td>
                        </tr>
                        <tr>
                            <td><strong>human_baseline_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_comparison</strong></td>
                            <td>With CoT the model achieves near-perfect accuracy; CFLLMs self-practice can elevate non-CoT accuracy to near-CoT levels for the largest model.</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_details</strong></td>
                            <td>CoT reasoning sequences synthesized using GPT-4; 3-shot prompting for these datasets; self-practice used 1000 examples; models quantized to 4-bit and fine-tuned with LoRA; accuracy determined by LLM-based semantic judgments.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_caveats</strong></td>
                            <td>No human baseline; extremely high CFLLMs gains for largest model might reflect dataset-specific effects, contamination, or evaluation methodology (semantic LLM judgments).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'CogniDual Framework: Self-Training Large Language Models within a Dual-System Theoretical Framework for Improving Cognitive Tasks', 'publication_date_yy_mm': '2025-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Chain-of-thought prompting elicits reasoning in large language models <em>(Rating: 2)</em></li>
                <li>Large language models are zero-shot reasoners <em>(Rating: 2)</em></li>
                <li>GSM8K <em>(Rating: 2)</em></li>
                <li>ReClor: A reading comprehension dataset requiring logical reasoning <em>(Rating: 2)</em></li>
                <li>LogiQA 2.0-an improved dataset for logical reasoning in natural language understanding <em>(Rating: 2)</em></li>
                <li>Vicuna: An open-source chatbot impressing gpt-4 with 90%* chatgpt quality <em>(Rating: 1)</em></li>
                <li>Llama 2: Open foundation and fine-tuned chat models <em>(Rating: 1)</em></li>
                <li>Distilling step-by-step! outperforming larger language models with less training data and smaller model sizes <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-9051",
    "paper_id": "paper-272423588",
    "extraction_schema_id": "extraction-schema-159",
    "extracted_data": [
        {
            "name_short": "Llama2-7B on GSM8K",
            "name_full": "Llama2 (7B) evaluated on GSM8K",
            "brief_description": "Evaluation of the open-source Llama2 7B parameter model on GSM8K arithmetic reasoning problems under different prompting and self-training conditions.",
            "citation_title": "CogniDual Framework: Self-Training Large Language Models within a Dual-System Theoretical Framework for Improving Cognitive Tasks",
            "mention_or_use": "use",
            "model_name": "Llama2",
            "model_description": "Open foundation and fine-tuned chat models (Transformer-based) referenced in the paper; used here in 7B-parameter configuration.",
            "model_size": "7B",
            "test_battery_name": "GSM8K",
            "test_description": "A dataset of high-quality elementary mathematics word problems designed to evaluate arithmetic and multi-step mathematical reasoning.",
            "llm_performance": "CoT applied: 16.8% accuracy; CoT not applied: 14.6% accuracy; CFLLMs (self-practice, 1000 examples): 15.6% accuracy (mean over 5 trials).",
            "human_baseline_performance": null,
            "performance_comparison": "Model performs poorly overall on GSM8K; small improvement with CoT prompting and negligible improvement from self-practice (CFLLMs) — remains well below strong reasoning performance.",
            "experimental_details": "Few-shot prompting (8-shot for GSM8K non-CoT), CoT vs non-CoT comparisons, self-practice (CFLLMs) using up to 1000 training examples sampled from dataset; models quantized to 4-bit via GPTQ, LoRA used for fine-tuning; semantic matching judged by LLM prompts.",
            "limitations_or_caveats": "No human baseline reported in paper; authors note task contamination for GSM8K (models often output step-by-step reasoning even when asked not to), which may limit observable CFLLMs gains; semantic evaluation used LLM-based semantic matching rather than strict gold-standard script.",
            "uuid": "e9051.0",
            "source_info": {
                "paper_title": "CogniDual Framework: Self-Training Large Language Models within a Dual-System Theoretical Framework for Improving Cognitive Tasks",
                "publication_date_yy_mm": "2025-04"
            }
        },
        {
            "name_short": "Llama2-13B on GSM8K",
            "name_full": "Llama2 (13B) evaluated on GSM8K",
            "brief_description": "Evaluation of the Llama2 13B-parameter model on GSM8K arithmetic reasoning under CoT, non-CoT, and self-practice conditions.",
            "citation_title": "CogniDual Framework: Self-Training Large Language Models within a Dual-System Theoretical Framework for Improving Cognitive Tasks",
            "mention_or_use": "use",
            "model_name": "Llama2",
            "model_description": "Open foundation and fine-tuned chat models (Transformer-based) referenced in the paper; used here in 13B-parameter configuration.",
            "model_size": "13B",
            "test_battery_name": "GSM8K",
            "test_description": "Arithmetic/multi-step math reasoning dataset.",
            "llm_performance": "CoT applied: 29.1% accuracy; CoT not applied: 27.9% accuracy; CFLLMs (1000 examples): 29.1% accuracy (mean over 5 trials).",
            "human_baseline_performance": null,
            "performance_comparison": "CoT prompting improves accuracy compared to non-CoT; CFLLMs self-practice yields negligible additional improvement for this dataset.",
            "experimental_details": "8-shot non-CoT prompting for GSM8K, CoT variants compared; self-practice with CFLLMs used up to 1000 examples; models quantized to 4-bit with GPTQ; LoRA for fine-tuning; semantic evaluation via LLM-based SemanticMatch prompts.",
            "limitations_or_caveats": "No human performance reported; GSM8K may suffer from task contamination (models tend to output derivations even when instructed not to), reducing detectable CFLLMs benefits.",
            "uuid": "e9051.1",
            "source_info": {
                "paper_title": "CogniDual Framework: Self-Training Large Language Models within a Dual-System Theoretical Framework for Improving Cognitive Tasks",
                "publication_date_yy_mm": "2025-04"
            }
        },
        {
            "name_short": "Vicuna-7B on GSM8K",
            "name_full": "Vicuna (7B) evaluated on GSM8K",
            "brief_description": "Open-source Vicuna 7B model assessed on arithmetic reasoning (GSM8K) with/without CoT and after CFLLMs self-practice.",
            "citation_title": "CogniDual Framework: Self-Training Large Language Models within a Dual-System Theoretical Framework for Improving Cognitive Tasks",
            "mention_or_use": "use",
            "model_name": "Vicuna",
            "model_description": "Open-source chat model derived from instruction tuning (based on LLaMA family); used here in a 7B configuration.",
            "model_size": "7B",
            "test_battery_name": "GSM8K",
            "test_description": "Elementary math word problems for evaluating arithmetic/multi-step reasoning.",
            "llm_performance": "CoT applied: 14.5% accuracy; CoT not applied: 12.1% accuracy; CFLLMs (1000 examples): 12.6% accuracy (mean over 5 trials).",
            "human_baseline_performance": null,
            "performance_comparison": "Low absolute accuracy; some benefit from CoT, minimal gain from CFLLMs self-practice on GSM8K.",
            "experimental_details": "Few-shot prompting, CoT vs non-CoT; CFLLMs self-training with up to 1000 examples; 4-bit quantization, LoRA fine-tuning; semantic match judged by LLM.",
            "limitations_or_caveats": "No human baseline reported; performance likely affected by dataset contamination and the model's tendency to produce step-by-step reasoning.",
            "uuid": "e9051.2",
            "source_info": {
                "paper_title": "CogniDual Framework: Self-Training Large Language Models within a Dual-System Theoretical Framework for Improving Cognitive Tasks",
                "publication_date_yy_mm": "2025-04"
            }
        },
        {
            "name_short": "Vicuna-13B on GSM8K",
            "name_full": "Vicuna (13B) evaluated on GSM8K",
            "brief_description": "Vicuna 13B assessed on GSM8K under CoT, non-CoT, and CFLLMs (self-practice) conditions.",
            "citation_title": "CogniDual Framework: Self-Training Large Language Models within a Dual-System Theoretical Framework for Improving Cognitive Tasks",
            "mention_or_use": "use",
            "model_name": "Vicuna",
            "model_description": "Open-source chat model (LLaMA-derived instruction-tuned) used here at 13B parameters.",
            "model_size": "13B",
            "test_battery_name": "GSM8K",
            "test_description": "Math word problems dataset assessing arithmetic reasoning.",
            "llm_performance": "CoT applied: 16.1% accuracy; CoT not applied: 15.7% accuracy; CFLLMs (1000 examples): 15.9% accuracy (mean over 5 trials).",
            "human_baseline_performance": null,
            "performance_comparison": "Small improvement with CoT; CFLLMs self-practice yields minimal additional gains for GSM8K.",
            "experimental_details": "Few-shot prompting; CoT injected vs removed (GSM8K used 8-shot non-CoT), CFLLMs self-practice up to 1000 examples; models quantized to 4-bit (GPTQ) and fine-tuned with LoRA; semantic judgments performed by an LLM prompt.",
            "limitations_or_caveats": "No human baseline; authors attribute small CFLLMs gains to inherent model tendency to produce stepwise reasoning on GSM8K (task contamination).",
            "uuid": "e9051.3",
            "source_info": {
                "paper_title": "CogniDual Framework: Self-Training Large Language Models within a Dual-System Theoretical Framework for Improving Cognitive Tasks",
                "publication_date_yy_mm": "2025-04"
            }
        },
        {
            "name_short": "Vicuna-30B on GSM8K",
            "name_full": "Vicuna (30B) evaluated on GSM8K",
            "brief_description": "Vicuna 30B performance on GSM8K evaluated under CoT, non-CoT, and after CFLLMs self-practice.",
            "citation_title": "CogniDual Framework: Self-Training Large Language Models within a Dual-System Theoretical Framework for Improving Cognitive Tasks",
            "mention_or_use": "use",
            "model_name": "Vicuna",
            "model_description": "Large (30B) variant of Vicuna used in experiments; transformer-based, instruction-tuned chat model.",
            "model_size": "30B",
            "test_battery_name": "GSM8K",
            "test_description": "Arithmetic reasoning dataset for multi-step math problems.",
            "llm_performance": "CoT applied: 36.7% accuracy; CoT not applied: 35.6% accuracy; CFLLMs (1000 examples): 36.2% accuracy (mean over 5 trials).",
            "human_baseline_performance": null,
            "performance_comparison": "Largest model achieves relatively higher accuracy on GSM8K; CoT improves performance slightly; CFLLMs self-practice yields minor improvement.",
            "experimental_details": "8-shot non-CoT prompting for GSM8K; CFLLMs self-practice using up to 1000 examples drawn from dataset; models quantized to 4-bit, LoRA fine-tuning used.",
            "limitations_or_caveats": "Human baseline not provided; GSM8K contamination issues may inflate stepwise reasoning output even when CoT is not requested.",
            "uuid": "e9051.4",
            "source_info": {
                "paper_title": "CogniDual Framework: Self-Training Large Language Models within a Dual-System Theoretical Framework for Improving Cognitive Tasks",
                "publication_date_yy_mm": "2025-04"
            }
        },
        {
            "name_short": "Llama2-7B on ReClor",
            "name_full": "Llama2 (7B) evaluated on ReClor",
            "brief_description": "Llama2 7B evaluated on ReClor reading-comprehension logical reasoning dataset with CoT, non-CoT, and CFLLMs self-practice.",
            "citation_title": "CogniDual Framework: Self-Training Large Language Models within a Dual-System Theoretical Framework for Improving Cognitive Tasks",
            "mention_or_use": "use",
            "model_name": "Llama2",
            "model_description": "Open foundation/fine-tuned chat model family; 7B parameter variant used.",
            "model_size": "7B",
            "test_battery_name": "ReClor",
            "test_description": "Reading comprehension dataset requiring logical reasoning (questions from standardized tests like GMAT/LSAT).",
            "llm_performance": "CoT applied: 51.5% accuracy; CoT not applied: 34.1% accuracy; CFLLMs (1000 examples): 49.0% accuracy (mean over 5 trials).",
            "human_baseline_performance": null,
            "performance_comparison": "Substantially better with CoT prompting than without; CFLLMs self-practice markedly improves non-CoT performance (approaches CoT level for this model).",
            "experimental_details": "3-shot prompting for ReClor when fabricating CoT reasoning; self-practice used 1000-example training subset; 4-bit quantization and LoRA fine-tuning; semantic matching done by LLM prompts.",
            "limitations_or_caveats": "No human baseline provided; semantic matching (accuracy evaluation) relies on LLM-based synonym judgments rather than deterministic matching, which may affect reported accuracies.",
            "uuid": "e9051.5",
            "source_info": {
                "paper_title": "CogniDual Framework: Self-Training Large Language Models within a Dual-System Theoretical Framework for Improving Cognitive Tasks",
                "publication_date_yy_mm": "2025-04"
            }
        },
        {
            "name_short": "Llama2-13B on ReClor",
            "name_full": "Llama2 (13B) evaluated on ReClor",
            "brief_description": "Llama2 13B tested on ReClor logical reasoning with comparisons between CoT prompting, non-CoT, and CFLLMs self-practice.",
            "citation_title": "CogniDual Framework: Self-Training Large Language Models within a Dual-System Theoretical Framework for Improving Cognitive Tasks",
            "mention_or_use": "use",
            "model_name": "Llama2",
            "model_description": "13B-parameter variant of Llama2 (Transformer-based open foundation models).",
            "model_size": "13B",
            "test_battery_name": "ReClor",
            "test_description": "Logical reasoning reading-comprehension dataset from standardized tests (critical thinking).",
            "llm_performance": "CoT applied: 89.4% accuracy; CoT not applied: 59.9% accuracy; CFLLMs (1000 examples): 77.7% accuracy (mean over 5 trials).",
            "human_baseline_performance": null,
            "performance_comparison": "CoT greatly improves accuracy; CFLLMs self-practice substantially raises non-CoT performance (though still typically below CoT performance for this model).",
            "experimental_details": "CoT reasoning sequences were generated (3-shot) for datasets without natural reasoning; CFLLMs self-training used up to 1000 examples; evaluation averaged over 5 trials; quantized to 4-bit for GPU deployment; LoRA used.",
            "limitations_or_caveats": "No human baseline; models' semantic matching judgments used for accuracy scoring rather than exact match scripts; performance gains depend on size and amount of self-practice.",
            "uuid": "e9051.6",
            "source_info": {
                "paper_title": "CogniDual Framework: Self-Training Large Language Models within a Dual-System Theoretical Framework for Improving Cognitive Tasks",
                "publication_date_yy_mm": "2025-04"
            }
        },
        {
            "name_short": "Vicuna-7B on ReClor",
            "name_full": "Vicuna (7B) evaluated on ReClor",
            "brief_description": "Vicuna 7B tested on ReClor logical reasoning under CoT, non-CoT, and CFLLMs self-practice conditions.",
            "citation_title": "CogniDual Framework: Self-Training Large Language Models within a Dual-System Theoretical Framework for Improving Cognitive Tasks",
            "mention_or_use": "use",
            "model_name": "Vicuna",
            "model_description": "Instruction-tuned open-source chat model derived from LLaMA family, 7B configuration.",
            "model_size": "7B",
            "test_battery_name": "ReClor",
            "test_description": "Dataset requiring logical reasoning and reading comprehension.",
            "llm_performance": "CoT applied: 55.1% accuracy; CoT not applied: 41.3% accuracy; CFLLMs (1000 examples): 53.4% accuracy (mean over 5 trials).",
            "human_baseline_performance": null,
            "performance_comparison": "CoT substantially increases accuracy; CFLLMs self-practice improves non-CoT accuracy toward CoT levels but may not match them.",
            "experimental_details": "3-shot CoT construction for ReClor, CFLLMs self-training up to 1000 examples; 4-bit quantization, LoRA fine-tuning, and LLM-based semantic judgment for evaluation.",
            "limitations_or_caveats": "Human baseline absent; semantic-evaluation methodology can introduce noise compared to gold-standard scoring; improvements vary with model size.",
            "uuid": "e9051.7",
            "source_info": {
                "paper_title": "CogniDual Framework: Self-Training Large Language Models within a Dual-System Theoretical Framework for Improving Cognitive Tasks",
                "publication_date_yy_mm": "2025-04"
            }
        },
        {
            "name_short": "Vicuna-13B on ReClor",
            "name_full": "Vicuna (13B) evaluated on ReClor",
            "brief_description": "Vicuna 13B performance on ReClor logical reasoning dataset across CoT, non-CoT, and CFLLMs self-training.",
            "citation_title": "CogniDual Framework: Self-Training Large Language Models within a Dual-System Theoretical Framework for Improving Cognitive Tasks",
            "mention_or_use": "use",
            "model_name": "Vicuna",
            "model_description": "13B-parameter Vicuna instruction-tuned chat model (LLaMA-derived).",
            "model_size": "13B",
            "test_battery_name": "ReClor",
            "test_description": "Logical reasoning reading-comprehension questions derived from standardized tests.",
            "llm_performance": "CoT applied: 90.8% accuracy; CoT not applied: 62.5% accuracy; CFLLMs (1000 examples): 78.7% accuracy (mean over 5 trials).",
            "human_baseline_performance": null,
            "performance_comparison": "CoT yields very high performance; CFLLMs self-practice notably closes the gap between non-CoT and CoT performance for this model size.",
            "experimental_details": "CoT sequences synthesized for dataset; self-practice used up to 1000 examples; models quantized to 4-bit; LoRA fine-tuning; semantic matches judged by LLM prompts.",
            "limitations_or_caveats": "No human baseline given; evaluation relies on LLM semantic judgments; CFLLMs improvements vary by dataset and are more pronounced where CoT-vs-non-CoT gaps exist.",
            "uuid": "e9051.8",
            "source_info": {
                "paper_title": "CogniDual Framework: Self-Training Large Language Models within a Dual-System Theoretical Framework for Improving Cognitive Tasks",
                "publication_date_yy_mm": "2025-04"
            }
        },
        {
            "name_short": "Vicuna-30B on ReClor",
            "name_full": "Vicuna (30B) evaluated on ReClor",
            "brief_description": "Vicuna 30B evaluated on ReClor showing very high accuracy with CoT and strong gains from CFLLMs self-practice for non-CoT prompting.",
            "citation_title": "CogniDual Framework: Self-Training Large Language Models within a Dual-System Theoretical Framework for Improving Cognitive Tasks",
            "mention_or_use": "use",
            "model_name": "Vicuna",
            "model_description": "Large 30B-parameter Vicuna instruction-tuned chat model used in experiments.",
            "model_size": "30B",
            "test_battery_name": "ReClor",
            "test_description": "Reading comprehension dataset focused on logical reasoning.",
            "llm_performance": "CoT applied: 99.4% accuracy; CoT not applied: 75.2% accuracy; CFLLMs (1000 examples): 99.2% accuracy (mean over 5 trials).",
            "human_baseline_performance": null,
            "performance_comparison": "With CoT the model reaches near-perfect accuracy; CFLLMs self-practice can substantially raise non-CoT performance, in this reported case reaching performance similar to CoT for the largest model.",
            "experimental_details": "3-shot CoT generation for dataset, CFLLMs self-practice with up to 1000 examples, GPTQ 4-bit quantization, LoRA fine-tuning; evaluation via LLM-based semantic matching.",
            "limitations_or_caveats": "No human baseline reported; extremely high CFLLMs/ReClor numbers for largest model may reflect dataset idiosyncrasies or contamination; authors note that CFLLMs less effective for tasks where CoT and non-CoT accuracy are similar.",
            "uuid": "e9051.9",
            "source_info": {
                "paper_title": "CogniDual Framework: Self-Training Large Language Models within a Dual-System Theoretical Framework for Improving Cognitive Tasks",
                "publication_date_yy_mm": "2025-04"
            }
        },
        {
            "name_short": "Llama2-7B on LogiQA2.0",
            "name_full": "Llama2 (7B) evaluated on LogiQA2.0",
            "brief_description": "Llama2 7B evaluation on LogiQA2.0 logical reasoning benchmark, under CoT, non-CoT, and CFLLMs self-training.",
            "citation_title": "CogniDual Framework: Self-Training Large Language Models within a Dual-System Theoretical Framework for Improving Cognitive Tasks",
            "mention_or_use": "use",
            "model_name": "Llama2",
            "model_description": "7B-parameter Llama2 model (open foundation/fine-tuned chat models).",
            "model_size": "7B",
            "test_battery_name": "LogiQA2.0",
            "test_description": "An improved dataset for logical reasoning in natural language understanding derived from Chinese civil service exam questions (translated and validated).",
            "llm_performance": "CoT applied: 77.3% accuracy; CoT not applied: 0.5% accuracy; CFLLMs (1000 examples): 18.1% accuracy (mean over 5 trials).",
            "human_baseline_performance": null,
            "performance_comparison": "Huge gap between CoT and non-CoT prompting (near-zero without CoT); CFLLMs self-practice substantially improves non-CoT performance but typically remains below CoT performance.",
            "experimental_details": "For LogiQA2.0 the authors used GPT-4 to fabricate CoT reasoning sequences (3-shot) because dataset answers lack reasoning; CFLLMs self-practice used up to 1000 examples; models quantized and LoRA-trained; semantic matching via LLM prompts.",
            "limitations_or_caveats": "Human baseline not provided; authors highlight that small models get near-zero without CoT but CFLLMs can raise them — however, evaluation uses LLM-based semantic judgments which can be subjective.",
            "uuid": "e9051.10",
            "source_info": {
                "paper_title": "CogniDual Framework: Self-Training Large Language Models within a Dual-System Theoretical Framework for Improving Cognitive Tasks",
                "publication_date_yy_mm": "2025-04"
            }
        },
        {
            "name_short": "Llama2-13B on LogiQA2.0",
            "name_full": "Llama2 (13B) evaluated on LogiQA2.0",
            "brief_description": "Llama2 13B assessed on LogiQA2.0 with large CoT/non-CoT gap and improvements after CFLLMs self-training.",
            "citation_title": "CogniDual Framework: Self-Training Large Language Models within a Dual-System Theoretical Framework for Improving Cognitive Tasks",
            "mention_or_use": "use",
            "model_name": "Llama2",
            "model_description": "13B-parameter Llama2 model.",
            "model_size": "13B",
            "test_battery_name": "LogiQA2.0",
            "test_description": "Logical reasoning dataset from civil service exam translations testing natural language logical inference.",
            "llm_performance": "CoT applied: 97.9% accuracy; CoT not applied: 5.3% accuracy; CFLLMs (1000 examples): 76.2% accuracy (mean over 5 trials).",
            "human_baseline_performance": null,
            "performance_comparison": "Dramatic improvement with CoT; CFLLMs self-practice meaningfully increases non-CoT performance (for larger models can approach CoT-level performance).",
            "experimental_details": "GPT-4 generated CoT explanations for dataset; 3-shot prompting; CFLLMs self-practice with up to 1000 examples; models quantized to 4-bit; evaluation via LLM-based SemanticMatch.",
            "limitations_or_caveats": "No human baseline; the very large gain from CFLLMs indicates potential dataset-specific effects or the success of internalizing CoT, but evaluation via semantic LLM judgments could be noisy.",
            "uuid": "e9051.11",
            "source_info": {
                "paper_title": "CogniDual Framework: Self-Training Large Language Models within a Dual-System Theoretical Framework for Improving Cognitive Tasks",
                "publication_date_yy_mm": "2025-04"
            }
        },
        {
            "name_short": "Vicuna-7B on LogiQA2.0",
            "name_full": "Vicuna (7B) evaluated on LogiQA2.0",
            "brief_description": "Vicuna 7B tested on LogiQA2.0 logical reasoning dataset; shows near-zero accuracy without CoT and modest gains from CFLLMs.",
            "citation_title": "CogniDual Framework: Self-Training Large Language Models within a Dual-System Theoretical Framework for Improving Cognitive Tasks",
            "mention_or_use": "use",
            "model_name": "Vicuna",
            "model_description": "7B variant of Vicuna (LLaMA-derived instruction-tuned chat model).",
            "model_size": "7B",
            "test_battery_name": "LogiQA2.0",
            "test_description": "Dataset assessing logical reasoning and natural language inference, based on translated civil service exam questions.",
            "llm_performance": "CoT applied: 79.4% accuracy; CoT not applied: 0.1% accuracy; CFLLMs (1000 examples): 16.7% accuracy (mean over 5 trials).",
            "human_baseline_performance": null,
            "performance_comparison": "Extremely low performance without CoT; CFLLMs self-practice meaningfully improves non-CoT accuracy but does not reach CoT levels.",
            "experimental_details": "CoT sequences were synthesized using GPT-4 (3-shot); CFLLMs self-practice with up to 1000 samples; models quantized 4-bit; SematicMatch performed by LLM prompts.",
            "limitations_or_caveats": "No human baseline; semantic-evaluation approach and potential dataset contamination may influence absolute numbers.",
            "uuid": "e9051.12",
            "source_info": {
                "paper_title": "CogniDual Framework: Self-Training Large Language Models within a Dual-System Theoretical Framework for Improving Cognitive Tasks",
                "publication_date_yy_mm": "2025-04"
            }
        },
        {
            "name_short": "Vicuna-13B on LogiQA2.0",
            "name_full": "Vicuna (13B) evaluated on LogiQA2.0",
            "brief_description": "Vicuna 13B evaluated on LogiQA2.0 showing high CoT performance and strong CFLLMs gains for non-CoT conditions.",
            "citation_title": "CogniDual Framework: Self-Training Large Language Models within a Dual-System Theoretical Framework for Improving Cognitive Tasks",
            "mention_or_use": "use",
            "model_name": "Vicuna",
            "model_description": "13B-parameter Vicuna instruction-tuned chat model.",
            "model_size": "13B",
            "test_battery_name": "LogiQA2.0",
            "test_description": "Logical reasoning benchmark derived from translated civil service exam items; assesses natural language logical deduction.",
            "llm_performance": "CoT applied: 98.4% accuracy; CoT not applied: 5.1% accuracy; CFLLMs (1000 examples): 66.3% accuracy (mean over 5 trials).",
            "human_baseline_performance": null,
            "performance_comparison": "CoT yields near-perfect performance; CFLLMs self-practice considerably improves non-CoT performance for larger models though generally below CoT unless model is large.",
            "experimental_details": "GPT-4 used to generate CoT sequences where needed (3-shot); CFLLMs self-practice with up to 1000 examples; models quantized to 4-bit; evaluation via LLM-based semantic similarity judgments.",
            "limitations_or_caveats": "No human baseline; high reported gains may reflect dataset properties or potential contamination; evaluation is based on semantic judgments rather than deterministic scoring.",
            "uuid": "e9051.13",
            "source_info": {
                "paper_title": "CogniDual Framework: Self-Training Large Language Models within a Dual-System Theoretical Framework for Improving Cognitive Tasks",
                "publication_date_yy_mm": "2025-04"
            }
        },
        {
            "name_short": "Vicuna-30B on LogiQA2.0",
            "name_full": "Vicuna (30B) evaluated on LogiQA2.0",
            "brief_description": "Vicuna 30B evaluated on LogiQA2.0 showing near-perfect CoT performance and very high CFLLMs non-CoT performance after self-practice.",
            "citation_title": "CogniDual Framework: Self-Training Large Language Models within a Dual-System Theoretical Framework for Improving Cognitive Tasks",
            "mention_or_use": "use",
            "model_name": "Vicuna",
            "model_description": "Large-scale 30B-parameter Vicuna instruction-tuned chat model used in experiments.",
            "model_size": "30B",
            "test_battery_name": "LogiQA2.0",
            "test_description": "Logical reasoning dataset focused on natural language logical inference.",
            "llm_performance": "CoT applied: 99.3% accuracy; CoT not applied: 27.6% accuracy; CFLLMs (1000 examples): 96.9% accuracy (mean over 5 trials).",
            "human_baseline_performance": null,
            "performance_comparison": "With CoT the model achieves near-perfect accuracy; CFLLMs self-practice can elevate non-CoT accuracy to near-CoT levels for the largest model.",
            "experimental_details": "CoT reasoning sequences synthesized using GPT-4; 3-shot prompting for these datasets; self-practice used 1000 examples; models quantized to 4-bit and fine-tuned with LoRA; accuracy determined by LLM-based semantic judgments.",
            "limitations_or_caveats": "No human baseline; extremely high CFLLMs gains for largest model might reflect dataset-specific effects, contamination, or evaluation methodology (semantic LLM judgments).",
            "uuid": "e9051.14",
            "source_info": {
                "paper_title": "CogniDual Framework: Self-Training Large Language Models within a Dual-System Theoretical Framework for Improving Cognitive Tasks",
                "publication_date_yy_mm": "2025-04"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Chain-of-thought prompting elicits reasoning in large language models",
            "rating": 2,
            "sanitized_title": "chainofthought_prompting_elicits_reasoning_in_large_language_models"
        },
        {
            "paper_title": "Large language models are zero-shot reasoners",
            "rating": 2,
            "sanitized_title": "large_language_models_are_zeroshot_reasoners"
        },
        {
            "paper_title": "GSM8K",
            "rating": 2
        },
        {
            "paper_title": "ReClor: A reading comprehension dataset requiring logical reasoning",
            "rating": 2,
            "sanitized_title": "reclor_a_reading_comprehension_dataset_requiring_logical_reasoning"
        },
        {
            "paper_title": "LogiQA 2.0-an improved dataset for logical reasoning in natural language understanding",
            "rating": 2,
            "sanitized_title": "logiqa_20an_improved_dataset_for_logical_reasoning_in_natural_language_understanding"
        },
        {
            "paper_title": "Vicuna: An open-source chatbot impressing gpt-4 with 90%* chatgpt quality",
            "rating": 1,
            "sanitized_title": "vicuna_an_opensource_chatbot_impressing_gpt4_with_90_chatgpt_quality"
        },
        {
            "paper_title": "Llama 2: Open foundation and fine-tuned chat models",
            "rating": 1,
            "sanitized_title": "llama_2_open_foundation_and_finetuned_chat_models"
        },
        {
            "paper_title": "Distilling step-by-step! outperforming larger language models with less training data and smaller model sizes",
            "rating": 1,
            "sanitized_title": "distilling_stepbystep_outperforming_larger_language_models_with_less_training_data_and_smaller_model_sizes"
        }
    ],
    "cost": 0.020972499999999998,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>CogniDual Framework: Self-Training Large Language Models within a Dual-System Theoretical Framework for Improving Cognitive Tasks
6 Sep 2024</p>
<p>Yongxin Deng 
School of Electronic and Electrical Engineering
Shanghai University of Engineering Science
ShanghaiChina</p>
<p>Xihe Qiu qiuxihe@sues.edu.cn 
School of Electronic and Electrical Engineering
Shanghai University of Engineering Science
ShanghaiChina</p>
<p>Xiaoyu Tan 
INF Technology (shanghai) Co., Ltd
ShanghaiChina</p>
<p>Chao Qu 
INF Technology (shanghai) Co., Ltd
ShanghaiChina</p>
<p>Jing Pan 
School of Art, Design and Architecture
Monash University
MelbourneAustralia</p>
<p>Yuan Cheng 
INF Technology (shanghai) Co., Ltd
ShanghaiChina</p>
<p>Yinghui Xu 
Artificial Intelligence Innovation and Incubation Institute
Fudan University
ShanghaiChina</p>
<p>Wei Chu 
INF Technology (shanghai) Co., Ltd
ShanghaiChina</p>
<p>CogniDual Framework: Self-Training Large Language Models within a Dual-System Theoretical Framework for Improving Cognitive Tasks
6 Sep 2024CA50E26C0C3928F985AFEEDC4CFA8515arXiv:2409.03381v2[cs.CL]large language modelcognitive psychologylanguage processing
Cognitive psychology investigates perception, attention, memory, language, problem-solving, decision-making, and reasoning.Kahneman's dual-system theory elucidates the human decision-making process, distinguishing between the rapid, intuitive System 1 and the deliberative, rational System 2. Recent advancements have positioned large language Models (LLMs) as formidable tools nearing human-level proficiency in various cognitive tasks.Nonetheless, the presence of a dualsystem framework analogous to human cognition in LLMs remains unexplored.This study introduces the CogniDual Framework for LLMs (CFLLMs), designed to assess whether LLMs can, through self-training, evolve from deliberate deduction to intuitive responses, thereby emulating the human process of acquiring and mastering new information.Our findings reveal the cognitive mechanisms behind LLMs' response generation, enhancing our understanding of their capabilities in cognitive psychology.Practically, self-trained models can provide faster responses to certain queries, reducing computational demands during inference.</p>
<p>I. INTRODUCTION</p>
<p>Cognitive psychology seeks to elucidate the processes by which humans acquire, retain, and retrieve knowledge [1], [2].Kahneman's dual-system theory [3]- [8] emerges as a seminal framework within this realm, offering a nuanced understanding of cognitive operations.This theory outlines two distinct cognitive systems: System 1, which is instinctual and facilitates rapid decision-making with minimal cognitive effort, and System 2, which is methodical and requires deliberate focus for complex reasoning tasks.</p>
<p>In the realm of artificial intelligence, the advent of deep learning and the influx of extensive datasets have precipitated the swift advancement of language models (LMs).These models, particularly those utilizing the Transformer architecture [9] such as GPT-4 [10], have garnered significant attention for their advanced language processing abilities [11]- [14], achieving near-human proficiency across numerous linguistic tasks.Trained on expansive natural language corpora, these models demonstrate an ability to comprehend and produce symbol sequences with an intuition akin to human System 1's pattern processing.Furthermore, when prompted to employ CoT problem-solving, LLMs exhibit deep reasoning capabilities paralleling human System 2 [12], [15], [16].Nevertheless, the persistence of such efficient and accurate outputs in the absence of CoT remains uncertain.Should LLMs achieve this, it would suggest the integration of an intuitive operational process comparable to human System 1.</p>
<p>Can LLMs internalize System 2's complex reasoning into System 1's intuitive responses through iterative training?We hypothesize that LLMs, by mimicking human rapid skill acquisition, can generate fast, intuitive answers without additional training data, thus enhancing resource efficiency and reducing dependence on chains of thought (CoT).Our methodology was straightforward yet robust: we commenced by prompting the model with specific reasoning questions, both with and without CoT cues, and subsequently assessed the accuracy of the responses generated under each condition.Following this, the model employed CoT as a scaffold to reengineer non-CoT responses.Theoretically, this self-editing could facilitate the internalization of CoT reasoning steps, potentially enhancing the model's future problem-solving precision without explicit CoT prompts.The final phase involved reevaluating the model's performance post self-improvement to determine if there was an enhancement in CoT-independent operations.Our experiments are designed to uncover whether LLMs can emulate the human cognitive system by internalizing complex reasoning processes, particularly when functioning without direct reasoning instructions.</p>
<p>We applied our methodology to the Vicuna and Llama2 models of varying sizes and evaluated their performance enhancements on reasoning datasets such as GSM8K, ReClor, and LogiQA 2.0.Our findings indicate that LLMs display marked discrepancies in response accuracy when utilizing CoT compared to when it is absent.Following a period of selftraining, LLMs exhibited a substantial increase in response precision in scenarios devoid of CoT.This suggests that LLMs are capable of developing intuitive response mechanisms akin to the human cognitive System 1, as well as the deliberate, sequential reasoning characteristic of System 2. Our research demonstrates the potential to cultivate LLMs' System 2 skills into System 1 proficiencies, enabling rapid application.</p>
<p>This paper presents three principal contributions:</p>
<p>• We propose a self-iterative framework for large models, which is used to explore whether large models themselves possess characteristics similar to human cognitive structures.</p>
<p>• We demonstrate that LLMs can simulate the dual-system characteristics of human cognition.Through experimentation, we have verified that LLMs can not only perform complex reasoning tasks under the guidance of CoT (similar to human System 2), but also respond relying on pattern recognition intuition without CoT (similar to human System 1).• We propose and validate a new method that may allow LLMs to maintain efficient and accurate outputs without relying on CoT.This suggests that LLMs can handle tasks in a manner closer to human System 1, and this method is more efficient in terms of computational resources and time because it avoids additional training data or steps, thus it is expected to play a significant role in resourcelimited application scenarios.</p>
<p>II. COGNIDUAL FRAMEWORK</p>
<p>A. Model Self-Iteration</p>
<p>Our CogniDual framework replicates the human learning curve, as depicted in Figure 1.Initially, we prompt untrained LLMs to answer questions from reasoning datasets without CoT instructions, even compelling the LLMs to provide immediate answers without rationale.We designate this question set as Q n = {q i , for i = 1, 2, . . ., n}, with n denoting the total number of questions.The corresponding answer set is labeled A1 n = {a1 i , for i = 1, 2, . . ., n}, symbolizing the LLMs' initial responses, akin to human cognitive System 1.</p>
<p>These question-answer pairs are preserved.</p>
<p>Subsequently, we introduce CoT directives, guiding LLMs to derive correct answers sequentially.The resulting answers are categorized as A2 n = {a2 i , for i = 1, 2, . . ., n}.We also maintain these pairs.In the third phase, we furnish the LLMs with standard answers from the dataset, denoted as A n = {a i , for i = 1, 2, . . ., n}.</p>
<p>To quantify the proficiency of our LLMs in responding to Q n , we define the accuracy metric as follows:
Acc(A1 n , A n ) = 1 n n i=1 SemanticMatch(a1 i , a i ),(1)Acc(A2 n , A n ) = 1 n n i=1 SemanticMatch(a2 i , a i ),(2)
where SemanticMatch(•, •) assesses the semantic similarity between the LLM's initial response and the standard answer.</p>
<p>Given that standard answers usually include comprehensive reasoning and do not conform to a 'yes or no' format, we cannot rely on character matching scripts to evaluate the LLMs' responses.Instead, we engage the LLMs in semantic synonymy judgments to assess the accuracy of A1 n and A2 n against A n , specifically identifying instances where A2 n is accurate, and A1 n is not.The fourth stage involves the LLMs consolidating the correct answers from A2 n and the incorrect ones from A1 n into new question-answer pairs.Given that A2 n responses encompass extensive reasoning, we require LLMs to distill these answers, converting them from elaborate, reasoned responses to concise answers.The specifics of this process will be explored in Section II-B.In the final step, we employ these restructured question-answer pairs as training material for LLMs and subsequently assess the LLMs' reasoning capabilities on different questions within the same dataset without CoT.Our experimental approach, chosen for its minimal computational resource demands and deployability, utilizes the LoRA training method [17] for LLMs.</p>
<p>B. Pre-training Model Distillation</p>
<p>The framework outlined in Section II-A enables LMs to selftrain independently of external interaction.Nevertheless, our framework necessitates that models complete two supplementary tasks when addressing dataset questions: 1. Synonymy Semantic Judgment: LMs must determine if A1 n , A2 n , and A n are semantically equivalent to assess reasoning accuracy both with and without the CoT; 2. Answer Rewriting: Recognizing the impracticality of manually rewriting numerous answers containing reasoning processes into concise responses, we expect LMs to autonomously perform answer rewriting.Suppose we have an open-source LLM denoted by p θ , which is parameterized by θ.To perform synonymy semantic judgment and achieve SemanticMatch, we can design a specific prompt, Prompt Semantic .This prompt will evaluate whether the two responses a i and a j have identical semantic meanings:
SemanticMatch(a i , a j ) = p θ (a j , a i |Prompt Semantic ). (3)
For answer rewriting, which is also a common task for chat base LLM, we can design a Prompt Rewrite to align the generated answer a j to the target answer a i with the identical format, and acquire the updated answer a ′ i :
a ′ i = p θ (a j , a i |Prompt Rewrite ).(4)
While large-scale models readily accomplish these tasks, smaller models, such as the Llama2-7B, may find them challenging [18].A model that struggles to understand standard answers is unlikely to enhance its capabilities from System 2 to System 1 through self-training alone.To improve training outcomes, we advocate for the pre-training of smaller models using knowledge distillation, equipping them with essential skills for synonymy semantic judgment and answer rewriting.</p>
<p>Knowledge distillation [19], [19]- [24] is a technique for transferring knowledge from a large, complex 'teacher' model to a smaller, simpler 'student' model, facilitating deployment in resource-limited settings without greatly impacting performance.We employ a simplified approach akin to Distilling step-by-step [25].For synonymy semantic judgment, smaller models generate sample A1 n , A2 n , and A n , after which GPT-3.5's advanced generative power yields precise judgments and comprehensive explanations.By creating multiple explanations per question, we ensure a clear delineation of the reasoning pathway.GPT-3.5 also supplies sample rewrites and their justifications for the answer rewriting task.Subsequently, smaller model θ can be trained through supervised fine-tuning using the larger models' outputs A ′ , preparing them for selfimprovement and independent practice:
min θ −E (qi,a ′ i )∼A ′ [log p θ (a ′ i |q i )] .(5)</p>
<p>III. EXPERIMENT</p>
<p>A. Experimental Objectives</p>
<p>This experiment is designed to examine various questions concerning the cognitive and reasoning capabilities of LLMs such as Llama2.Specifically, we aim to determine whether such models exhibit characteristics analogous to the dualsystem cognitive framework observed in humans (Q1), if selfpractice in the absence of Chain of Thought (CoT) guidance enhances reasoning abilities (Q2), whether learning curves indicate improved accuracy with additional examples post selfpractice (Q3), if larger models benefit more from self-practice without CoT guidance in terms of performance (Q4), and whether the enhanced reasoning abilities generalized across different reasoning tasks (Q5).</p>
<p>B. Experimental Setting</p>
<p>To investigate Q1 and Q2 outlined in Section III-A, we employed untrained LLMs as a baseline to evaluate their efficacy both with and without implementing the CoT method.The few-shot methodology was consistently applied in prompt construction, irrespective of CoT method utilization.Given that the GSM8K dataset's solutions entail reasoning sequences, in instances where the CoT method was not applied, we modified the prompting using GPT-4 [10] to exclude the reasoning pathway, employing an 8-shot technique.In contrast, for the Reclor and LogiQA2.0 datasets, which naturally lack reasoning pathways in their answers, we engaged GPT-4 to fabricate corresponding reasoning sequences to assess LLMs' proficiency under the CoT paradigm, adopting a 3-shot approach for these datasets.This baseline was then juxtaposed with our CFLLMs framework.To tackle Q3, we experimented with diverse data volumes within the CFLLMs framework to cultivate the LLMs and scrutinized their performance.</p>
<p>In pursuit of Q4, our framework was applied to LLMs of varying sizes, including Vicuna models (7B, 13B, 30B) [26], [27] and Llama2 models (7B, 13B) [28].To facilitate deployment on a consumer-grade Nvidia RTX 4090 GPU [29] while minimizing memory usage and inference time, we employed the GPTQ [30] approach to quantize the models to 4-bit precision.It is important to note that, despite the ability of 7B-sized models to operate on consumer-grade GPUs without quantization, we opted for 4-bit quantization across all models to maintain a uniform comparison scale and minimize quantization errors.</p>
<p>To address the variability in dataset sizes and their potential influence on experimental results, we standardized our approach by extracting a consistent sample of 1000 data entries from each dataset to form the training set for the LLMs' self-practice.An additional 1000 data entries were selected to comprise the test set.To maintain experimental uniformity, each data entry within these subsets was numbered.For each experiment, we consistently used the first n numbered data entries, with n representing the requisite volume of data for the specific experimental conditions.</p>
<p>For Q5, we selected datasets encompassing various reasoning tasks, such as GSM8K [31], ReClor [32], and LogiQA2.0 [33], [34].GSM8K comprises over 8,000 quality elementary mathematics problems crafted by human authors to assess arithmetic reasoning in LLMs.ReClor features questions from logical reasoning sections of standardized tests like the GMAT and LSAT, challenging the LLMs' critical thinking and complex logical reasoning skills.LogiQA2.0, based on questions from the Chinese civil service exam translated and validated by professional translators and human experts, evaluates the LLMs' capacity for generalizing natural language reasoning.</p>
<p>C. Results</p>
<p>We conducted experiments across a variety of LLMs, differing in type and size, as well as on diverse datasets, to evaluate their reasoning capabilities.This evaluation was based on the mean answer accuracy derived from five experimental trials, detailed in Table I.It is important to note that the figures succeeding "CFLLMs" in the table signify the volume of data utilized for the LLMs' self-practice.The underscored values denote the peak accuracy attained with this methodology for the consistent model and dataset, whereas the bolded values represent the maximum accuracy achieved without employing the CoT method to prompt incremental reasoning, compelling the model to directly generate answers.Red-highlighted numbers in the table reveal that our framework, under the given experimental conditions, did not improve but rather diminished performance.With this groundwork, we can address Q1 and Q2 introduced in Section III-A.The implementation of CoT markedly influences the models' reasoning proficiency on tasks that entail natural language inference, such as reading comprehension and logical deduction.For instance, on the LogiQA2.0 dataset, the accuracy rates for smaller models like Llama2-7B and Vicuna-7B plummet to near zero in the absence of CoT.However, the deployment of the CogniDual Framework, has resulted in a substantial enhancement of performance without CoT.Despite the models' reasoning accuracy not equalling that of CoT use, their ability to intuitively respond to certain questions suggests an inherent decision-making logic akin to the human dual-system cognitive framework.This insight indicates the potential for transforming System 2 capabilities into System 1 through sustained practice, thereby bolstering the LLMs' rapid response to specific queries and diminishing the time and computational resources required for reasoning.Moreover, we observed a negligible improvement from the CogniDual Framework on the GSM8K dataset, attributed to the models' propensity for step-by-step reasoning even when instructed to directly answer.The prevalence of LLMs producing answers with comprehensive derivations is likely due to task contamination, as postulated by Liu et al. [35], where mathematical problems are consistently presented with accompanying detailed solutions throughout the training phase.Our framework aims to enhance the System 1 capabilities of LLMs, rather than augment System 2 directly.Consequently, we can deduce from Q5 that only tasks exhibiting a substantial discrepancy in accuracy between CoT usage and non-usage enable LLMs to advance their internalized reasoning abilities through self-practice.</p>
<p>For Q3 and Q4, the results in Table I indicate that, in general, an increase in additional examples correlates with a more pronounced enhancement in the LLMs' reasoning abilities without CoT, achieved through self-practice.Larger models require fewer examples to approach their System 1 capacity ceiling; beyond this point, further example data yield minimal benefits.This finding suggests that larger models are more adept at leveraging limited data to improve performance without CoT guidance through self-practice, aligning with the research by Jaimovitch et al. [36].</p>
<p>IV. CONCLUSION</p>
<p>This study explores the dual cognitive characteristics of LLMs.Our experimental results indicate that once LLMs internalize CoT reasoning through self-training, they can retain CoT-enhanced problem-solving abilities even without CoT prompts.This finding supports the hypothesis that, with appropriate training, LLMs can convert complex, deliberative System 2 reasoning into faster, more intuitive System 1-like responses.Leveraging this property, we designed a self-training framework to reduce the cognitive load of LLM reasoning.Despite these advancements, further research is necessary to address the study's limitations, including examining how this framework influences the cognitive processing preferences of LLMs.</p>
<p>TABLE I PERFORMANCE
I
EVALUATION OF DIVERSE LLMS BY TYPE AND SIZE ACROSS VARIOUS DATASETS: A DETAILED ASSESSMENT WITH METHODOLOGICAL COMPARISONS.
MethodDatasetsModels LLAMA2-7B LLAMA2-13B Vicuna-7B Vicuna-13B Vicuna-30BGSM8K(Acc)14.627.912.115.735.6CoT Not AppliedReclor(Acc)34.159.941.362.575.2LogiQA2.0(Acc)0.55.30.15.127.6GSM8K(Acc)16.829.114.516.136.7CoT AppliedReclor(Acc)51.589.455.190.899.4LogiQA2.0(Acc)77.397.979.498.499.3GSM8K(Acc)14.928.412.216.135.7CFLLMs(10)Reclor(Acc)356541.865.680.3LogiQA2.0(Acc)2.812.21.29.252.7GSM8K(Acc)14.928.611.915.835.7CFLLMs(100)Reclor(Acc)37.272.343.87298.6LogiQA2.0(Acc)9.433.17.329.192.1GSM8K(Acc)15.128.712.21635.9CFLLMs(500)Reclor(Acc)39.87645.578.398.9LogiQA2.0(Acc)9.772.78.764.496.3GSM8K(Acc)15.62912.615.936.2CFLLMs(1000)Reclor(Acc)4977.753.478.799.2LogiQA2.0(Acc)18.176.216.766.396.9</p>
<p>Dual-process theories of higher cognition: Advancing the debate. J S B Evans, K E Stanovich, Perspectives on psychological science. 832013</p>
<p>On the relative independence of thinking biases and cognitive ability. K E Stanovich, R F West, Journal of personality and social psychology. 9446722008</p>
<p>Thinking, fast and slow. D Kahneman, 2011macmillan</p>
<p>The costs of connection: How data is colonizing human life and appropriating it for capitalism. N Couldry, U A Mejias, 2020Stanford University Press</p>
<p>How computational modeling can force theory building in psychological science. O Guest, A E Martin, Perspectives on Psychological Science. 1642021</p>
<p>An epidemic of uncertainty: rumors, conspiracy theories and vaccine hesitancy. E Pertwee, C Simas, H J Larson, Nature medicine. 2832022</p>
<p>Reprint of the new paradigm of economic complexity. P.-A Balland, T Broekel, D Diodato, E Giuliani, R Hausmann, N O'clery, D Rigby, Research Policy. 5181045682022</p>
<p>Advancing theory with review articles. C Post, R Sarala, C Gatrell, J E Prescott, Journal of Management Studies. 5722020</p>
<p>Attention is all you need. A Vaswani, N Shazeer, N Parmar, J Uszkoreit, L Jones, A N Gomez, L Kaiser, I Polosukhin, ; , I Guyon, U Luxburg, Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems 2017. M Wallach, R Fergus, S V N Vishwanathan, R Garnett, Long Beach, CA, USADecember 4-9, 2017. 2017</p>
<p>J Achiam, S Adler, S Agarwal, L Ahmad, I Akkaya, F L Aleman, D Almeida, J Altenschmidt, S Altman, S Anadkat, vol. abs/2303.08774Gpt-4 technical report. 2023</p>
<p>Training language models to follow instructions with human feedback. L Ouyang, J Wu, X Jiang, D Almeida, C Wainwright, P Mishkin, C Zhang, S Agarwal, K Slama, A Ray, Advances in Neural Information Processing Systems. 202235</p>
<p>Self-instruct: Aligning language model with self generated instructions. Y Wang, Y Kordi, S Mishra, A Liu, N A Smith, D Khashabi, H Hajishirzi, vol. abs/2212.10560ArXiv preprint. 2022</p>
<p>Alpaca: A strong, replicable instructionfollowing model. R Taori, I Gulrajani, T Zhang, Y Dubois, X Li, C Guestrin, P Liang, T B Hashimoto, Stanford Center for Research on Foundation Models. 32023</p>
<p>Promoting equality in large language models: Identifying and mitigating the implicit bias based on bayesian theory. Y Deng, X Qiu, X Tan, J Pan, C Jue, Z Fang, Y Xu, W Chu, Y Qi, ArXiv preprint. 2408.10608, 2024</p>
<p>Chain-of-thought prompting elicits reasoning in large language models. J Wei, X Wang, D Schuurmans, M Bosma, F Xia, E Chi, Q V Le, D Zhou, Advances in Neural Information Processing Systems. 202235</p>
<p>Large language models are zero-shot reasoners. T Kojima, S S Gu, M Reid, Y Matsuo, Y Iwasawa, Advances in neural information processing systems. 202235</p>
<p>Lora: Low-rank adaptation of large language models. E J Hu, Y Shen, P Wallis, Z Allen-Zhu, Y Li, S Wang, L Wang, W Chen, The Tenth International Conference on Learning Representations, ICLR 2022, Virtual Event. April 25-29, 2022. OpenReview.net, 2022</p>
<p>Large language models in the workplace: A case study on prompt engineering for job type classification. B Clavié, A Ciceu, F Naylor, G Soulié, T Brightwell, International Conference on Applications of Natural Language to Information Systems. Springer2023</p>
<p>In-context learning distillation: Transferring few-shot learning ability of pre-trained language models. Y Huang, Y Chen, Z Yu, K Mckeown, abs/2212.10670ArXiv preprint. 2022</p>
<p>Gkd: Generalized knowledge distillation for autoregressive sequence models. R Agarwal, N Vieillard, P Stanczyk, S Ramos, M Geist, O Bachem, ArXiv preprint. 2306.13649, 2023</p>
<p>Explanations from large language models make small reasoners better. S Li, J Chen, Y Shen, Z Chen, X Zhang, Z Li, H Wang, J Qian, B Peng, Y Mao, abs/2210.06726ArXiv preprint. 2022</p>
<p>Large language models are reasoning teachers. N Ho, L Schmid, S.-Y Yun, ArXiv preprint. 2212.10071, 2022</p>
<p>Specializing smaller language models towards multi-step reasoning. Y Fu, H Peng, L Ou, A Sabharwal, T Khot, ArXiv preprint. 2301.12726, 2023</p>
<p>Distilling reasoning capabilities into smaller language models. K Shridhar, A Stolfo, M Sachan, Findings of the Association for Computational Linguistics: ACL 2023. 2023</p>
<p>Distilling step-by-step! outperforming larger language models with less training data and smaller model sizes. C.-Y Hsieh, C.-L Li, C.-K Yeh, H Nakhost, Y Fujii, A Ratner, R Krishna, C.-Y Lee, T Pfister, ArXiv preprint. 2305.02301, 2023</p>
<p>Judging llm-as-a-judge with mt-bench and chatbot arena. L Zheng, W.-L Chiang, Y Sheng, S Zhuang, Z Wu, Y Zhuang, Z Lin, Z Li, D Li, E Xing, Advances in Neural Information Processing Systems. 202436</p>
<p>Vicuna: An open-source chatbot impressing gpt-4 with 90%* chatgpt quality. W.-L Chiang, Z Li, Z Lin, Y Sheng, Z Wu, H Zhang, L Zheng, S Zhuang, Y Zhuang, J E Gonzalez, I Stoica, E P Xing, 2023</p>
<p>Llama 2: Open foundation and fine-tuned chat models. H Touvron, L Martin, K Stone, P Albert, A Almahairi, Y Babaei, N Bashlykov, S Batra, P Bhargava, S Bhosale, abs/2307.09288ArXiv preprint. 2023</p>
<p>Nvidia geforce rtx 4090. 2023NVIDIA</p>
<p>Gptq: Accurate post-training quantization for generative pre-trained transformers. E Frantar, S Ashkboos, T Hoefler, D Alistarh, ArXiv preprint. 2210.17323, 2022</p>
<p>Training verifiers to solve math word problems. K Cobbe, V Kosaraju, M Bavarian, M Chen, H Jun, L Kaiser, M Plappert, J Tworek, J Hilton, R Nakano, ArXiv preprint. 2110.14168, 2021</p>
<p>Reclor: A reading comprehension dataset requiring logical reasoning. W Yu, Z Jiang, Y Dong, J Feng, 8th International Conference on Learning Representations. Addis Ababa, EthiopiaApril 26-30, 2020. OpenReview.net, 20202020</p>
<p>Logiqa: A challenge dataset for machine reading comprehension with logical reasoning. J Liu, L Cui, H Liu, D Huang, Y Wang, Y Zhang, 10.24963/ijcai.2020/501Proceedings of the Twenty-Ninth International Joint Conference on Artificial Intelligence. C Bessiere, Ed Org, the Twenty-Ninth International Joint Conference on Artificial Intelligence20202020</p>
<p>Logiqa 2.0-an improved dataset for logical reasoning in natural language understanding. H Liu, J Liu, L Cui, Z Teng, N Duan, M Zhou, Y Zhang, Speech, and Language Processing. 2023</p>
<p>Task contamination: Language models may not be few-shot anymore. C Li, J Flanigan, ArXiv preprint. 2312.16337, 2023</p>
<p>Think big, teach small: Do language models distil occam's razor?. G Jaimovitch-Lopez, D C Falcón, C Ferri, J Hernández-Orallo, Advances in Neural Information Processing Systems 34: Annual Conference on Neural Information Processing Systems 2021, NeurIPS 2021. Y N Beygelzimer, P Dauphin, J W Liang, Vaughan, December 6-14, 2021. 2021</p>            </div>
        </div>

    </div>
</body>
</html>