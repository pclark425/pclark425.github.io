<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-2334 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-2334</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-2334</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-63.html">extraction-schema-63</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <p><strong>Paper ID:</strong> paper-230564756</p>
                <p><strong>Paper Title:</strong> <a href="https://pubs.rsc.org/en/content/articlepdf/2021/mh/d0mh01451f?page=search" target="_blank">Artificial intelligence and machine learning in design of mechanical materials</a></p>
                <p><strong>Paper Abstract:</strong> Artificial intelligence, especially machine learning (ML) and deep learning (DL) algorithms, is becoming an important tool in the fields of materials and mechanical engineering, attributed to its power to predict materials properties, design de novo materials and discover new mechanisms beyond intuitions. As the structural complexity of novel materials soars, the material design problem to optimize mechanical behaviors can involve massive design spaces that are intractable for conventional methods. Addressing this challenge, ML models trained from large material datasets that relate structure, properties and function at multiple hierarchical levels have oﬀered new avenues for fast exploration of the design spaces. The performance of a ML-based materials design approach relies on the collection or generation of a large dataset that is properly preprocessed using the domain knowledge of materials science underlying chemical and physical concepts, and a suitable selection of the applied ML model. Recent breakthroughs in ML techniques have created vast opportunities for not only overcoming long-standing mechanics problems but also for developing unprecedented materials design strategies. In this review, we first present a brief introduction of state-of-the-art ML models, algorithms and structures. Then, we discuss the importance of data collection, generation and preprocessing. The applications in mechanical property prediction, materials design and computational methods using ML-based approaches are summarized, followed by perspectives on opportunities and open challenges in this emerging and exciting field.</p>
                <p><strong>Cost:</strong> 0.026</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e2334.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e2334.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Glass modulus prediction (MLP/LASSO/GPR)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Machine learning prediction of elastic moduli for silicate and oxide glasses (MLP, LASSO, Gaussian process regression)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Supervised learning applied to predict elastic moduli and other mechanical properties of oxide and silicate glasses from compositional descriptors; methods include multilayer perceptrons (MLP), LASSO regression for interpretability, and Gaussian process regression (GPR) for small/sparse datasets.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>Materials science — glass mechanics / composition–property prediction</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Predict Young's modulus, shear modulus, hardness and related mechanical properties from glass composition and simple derived descriptors to enable rapid screening and design of oxide glasses.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>Relatively abundant for some glass systems (large literature and compiled datasets exist), labeled (experimental/measured property values), often heterogeneous quality; for some tasks data can be sparse requiring GPR or active learning.</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>Structured tabular data (feature vectors of component concentrations and derived compositional descriptors); sometimes augmented with engineered atomistic/local descriptors.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>Moderate nonlinearity between composition and properties; moderate dimensionality (several compositional variables); complexity increases with added target properties (multitask).</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>Established domain with long-standing empirical and theoretical relations between composition and properties; extensive prior data and domain knowledge available.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>Medium — interpretability is valuable for materials design; LASSO used for interpretable relations while neural networks provide higher predictive accuracy but are less interpretable.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Multilayer perceptron (MLP), LASSO regression, Gaussian process regression (GPR)</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>MLP/FFNNs trained in supervised regression on composition-to-property mappings; LASSO linear regression with L1 regularization used for sparse, interpretable models; GPR applied for probabilistic regression and uncertainty quantification on small/sparse datasets to avoid overfitting.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>Supervised learning (with Bayesian regression for GPR)</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Appropriate — models match the structured, labeled composition→property mapping; GPR recommended where data are scarce; LASSO helpful when interpretability required.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>MLP produced the highest accuracy among tested algorithms for glass modulus prediction; LASSO provided simpler, interpretable models with somewhat lower accuracy; GPR avoided overfitting on sparse datasets.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>Enables rapid screening and inverse-design of glass compositions for target mechanical properties, reducing experimental effort and accelerating materials discovery.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Reported comparisons between PR/LASSO/RF/MLP and GPR; MLP highest accuracy, LASSO simpler and interpretable, GPR better for sparse data — qualitative comparative statements provided without hard numeric metrics.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Availability of curated composition–property datasets, use of domain-informed descriptors, and matching model complexity to dataset size (e.g., GPR for small data) improved results.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>When composition–property datasets are sufficient, deep networks (MLP) improve predictive accuracy, but simple/regression-based models (LASSO, GPR) remain valuable for interpretability and small-data robustness.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2334.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e2334.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Copper-alloy design NN</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Neural-network based compositional design and screening of copper alloys</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Supervised neural networks (and comparisons with other regressors) used to rapidly screen copper-alloy composition design space for target tensile strength and electrical conductivity.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>Alloy design — copper alloys (composition→mechanical and electrical properties)</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Discover copper-alloy compositions that simultaneously satisfy target mechanical strength and electrical conductivity constraints.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>Labeled datasets assembled from literature/databases; moderate size (sufficient for supervised model training), quality depends on literature reporting.</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>Structured tabular composition vectors and derived composition features.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>Nonlinear multi-objective composition–property mapping; multi-dimensional continuous search space over composition variables.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>Well-established materials engineering domain with existing empirical rules and prior data; domain expertise available to guide preprocessing and features.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>Medium — designers want interpretable relationships but practical design value can accept black-box suggestions subject to experimental validation.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Feedforward neural networks (deep FFNN), comparisons with LIR, SVR, regression trees, GPR</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>Supervised training of FFNNs to map composition and features to target properties; model selection/validation against classical ML regressors; used as rapid screening (predictive surrogate) in design pipeline.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>Supervised learning</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Applicable and effective as a rapid screening tool; suitable because data are structured and labeled; some alternative models tested for trade-offs.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>Neural networks enabled rapid screening and provided compositional designs meeting target properties; review reports successful discovery tasks though specific metrics are not given.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>Reduces search time for new alloy compositions and focuses experimental validation on promising candidates, accelerating alloy development.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Explicit model selection studies compared LIR, SVR, regression tree and GPR alongside neural networks; neural networks used where higher prediction accuracy was needed, alternatives offered interpretability or small-data robustness.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Curated labeled composition–property datasets and domain-specific feature engineering; evaluation of multiple model classes to balance accuracy and interpretability.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>Supervised neural networks can significantly speed composition-space screening when adequate labeled compositional datasets exist, and comparing simpler models helps balance interpretability and accuracy.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2334.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e2334.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>MOF/zeolite property ML</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Machine learning prediction of mechanical stability and bulk modulus for MOFs and zeolite frameworks</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>ANNs, gradient boosting and other regressors trained on structural/topological descriptors to predict bulk modulus and mechanical stability of porous frameworks (MOFs, zeolites).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>Porous framework materials — MOFs and zeolites mechanical property prediction</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Predict bulk modulus and mechanical stability of thousands of framework structures from structural/topological or atomistic descriptors to prioritize materials.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>Large computational and experimental databases of thousands of structures (abundant) with computed/measured mechanical properties; labeled.</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>Structured descriptors: structural/topological vectors, atomistic features, porosity metrics; sometimes graph-like representations.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>High structural diversity, high-dimensional descriptor space, nonlinear structure–property relations.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>Growing/active research area with established simulation pipelines (DFT/MD) and curated databases; mechanistic models exist but are computationally costly for high-throughput screening.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>Medium — predictions are used to prioritize candidates, while mechanistic validation often performed with higher-fidelity simulations or experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Artificial neural networks (ANN), gradient boosting regressors, graph neural networks (GNNs)</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>Supervised training on descriptors (topological and structural) to predict mechanical properties; in some studies GNNs used to exploit inherent graph-like connectivity of framework materials.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>Supervised learning (with graph-based deep learning for some works)</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Well-suited for high-throughput screening where conventional DFT/MD are too slow; GNNs appropriate when graph connectivity is the natural representation.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>ANNs and gradient-boosting models established credible predictors of bulk modulus and mechanical stability; GNNs offer potential improvements by capturing topology directly.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>Enables prioritization of mechanically robust MOFs/zeolites for application and reduces computational expense by screening large candidate sets before high-fidelity validation.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>GPR and other classical regressors useful for small datasets; GNNs and ANNs advantageous for large structural databases. No standardized quantitative head-to-head metrics reported in the review.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Availability of large curated structural databases and meaningful structural/topological descriptors; models leveraging natural graph structure (GNNs) performed better where applicable.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>For framework materials with large databases, supervised ML on structural descriptors provides fast, effective proxies for expensive simulations, and graph-based methods align naturally with topology-sensitive properties.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2334.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e2334.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>CNN for microstructure→properties</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Convolutional neural networks for predicting mechanical behaviour from microstructure images (high-contrast composites, polymer nanocomposites, AM metals)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Image/voxel-based CNNs trained on FEM- or simulation-generated microstructure images to predict strain/stress fields and effective mechanical properties, often outperforming classical feature-based regressors.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>Heterogeneous materials mechanics — microstructure image to mechanical response mapping</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Predict field-level responses (strain/stress) and effective properties from spatial microstructure images or 3D voxel representations to speed up analyses and enable inverse design.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>Datasets commonly generated via FEM or MD simulations (abundant for synthetic data), labeled (simulated responses); experimental 3D images less abundant.</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>Unstructured/structured image and voxel data (2D/3D grids), high-dimensional spatial fields.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>High complexity: large input dimensionality (images/voxels), multiscale features, nonlinear physics mapping from microstructure to response.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>Emerging/rapidly developing; well-established for image-based ML in computer vision but adapting to physics-informed materials contexts is ongoing.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>Low-to-medium for surrogate tasks (black-box prediction acceptable for screening), but interpretability desired for scientific insight; learned filters can be inspected partially.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Convolutional neural networks (2D/3D CNNs), residual networks for deep architectures</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>CNNs take pixel/voxel arrays of material microstructure as input and regress to field outputs or scalar effective properties; architectures include multi-layer convolutional stacks and residual connections; trained on simulation-generated labeled datasets, often with data augmentation.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>Supervised learning (deep learning — CNNs)</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Highly applicable where microstructures naturally form image/voxel inputs; reduces feature-engineering overhead and learns multiscale spatial embeddings automatically.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>CNN models outperformed ridge regression and gradient boosting when 3D microstructure images were available (e.g., yield strength prediction for AM metals), demonstrating superior capacity to learn hierarchical spatial features.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>Speeds prediction of spatial mechanical fields and enables inverse design workflows; generalizes across shapes/loads when trained on diverse simulated datasets.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Compared with feature-based regressors (Ridge, gradient boosting) and classical ML; CNNs provided better performance on image inputs and reduced preprocessing effort.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Availability of large simulation-generated labeled image datasets, appropriate CNN architectures, and alignment between input representation and network inductive biases (spatial locality via convolutions).</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>For materials that are naturally represented as images/voxels, CNNs effectively learn hierarchical spatial features and often outperform classical regressors that rely on hand-crafted descriptors.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2334.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e2334.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>cGAN inverse elasticity</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Conditional GAN for inverse elasticity — displacement/strain field to modulus distribution</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Conditional generative adversarial networks (cGANs) used to solve inverse elasticity problems by mapping observed displacement/strain images to spatial elastic modulus maps, enabling fast non-destructive evaluation and elastography-like applications.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>Inverse problems in solid mechanics — elastography and non-destructive evaluation</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Infer spatial distribution of elastic modulus inside a body from measured displacement/strain fields (image-to-image inverse mapping).</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>Training data typically generated via forward FEM simulations pairing modulus distributions with resulting displacement/strain fields; labeled and abundant when simulated.</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>Paired images (input: displacement/strain fields; output: modulus distribution) — image-to-image translation task.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>Ill-posed inverse mapping, non-unique solutions possible, high-dimensional outputs; requires models that capture conditional distribution.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>Emerging application area; inverse elasticity has established physics but ML-based image-to-image inversion is newer.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>Medium — solutions often need physical plausibility and may require uncertainty quantification to be trusted for diagnostics.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Conditional generative adversarial networks (cGAN)</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>A cGAN generator maps input field images into predicted modulus maps while a discriminator judges realism conditioned on inputs; trained adversarially with paired simulation data to produce realistic inverse solutions; training may combine L1/L2 reconstruction losses with adversarial loss.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>Supervised generative modeling / conditional generative modeling</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Applicable and effective for fast approximate inverse solutions, especially when forward solvers are expensive; relies on availability of representative paired training data.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>cGAN demonstrated fast and accurate reconstruction of modulus distributions from strain/displacement fields in simulated inclusion systems; suitable for real-time elastography-like use cases according to the review.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>Enables fast non-destructive evaluation, potential real-time diagnostics and high-throughput material inspection, subject to generalization from simulated to experimental data.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Compared qualitatively to traditional iterative inverse solvers (computationally costly); cGAN offers orders-of-magnitude faster inference though with reliance on representative training data and potential generalization limits.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Large, representative paired simulation datasets and conditioning on input fields; adversarial loss improves realism of reconstructed maps over simple regression losses.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>Conditional GANs can learn ill-posed inverse mappings from fields to material distributions when ample paired simulation data exist, trading off exact physical guarantee for fast, realistic reconstructions.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2334.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e2334.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GANs for topology generation</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Generative adversarial networks for architected materials and metamaterial unit-cell topology generation</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>GANs (and cGANs) trained to generate novel 2D/3D periodic unit-cell geometries for architected materials and metamaterials that approach theoretical bounds or satisfy symmetry and porosity constraints.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>Metamaterials and architected materials design — topology generation</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Generate candidate unit-cell topologies with desired mechanical effective properties (e.g., near Hashin–Shtrikman bounds) and specified symmetries/porosities for manufacturable metamaterials.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>Design libraries generated through simulations or prior optimized instances (moderate-to-large synthetic datasets); labeled if properties matched to geometries, otherwise used as unlabeled for generative modeling.</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>Image/voxel or parametric geometry representations (2D periodic unit cells); sometimes combined with property labels.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>Combinatorially large discrete topology space with geometric and symmetry constraints; multi-objective optimization landscape.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>Active/emerging with growing computational resources and manufacturing capabilities; established theoretical bounds exist for guidance.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>Low-to-medium — generated designs require subsequent mechanical evaluation; interpretability of generator typically low but physics constraints can be enforced.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Generative adversarial networks (GANs), conditional GANs (cGANs)</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>GAN frameworks trained on collections of optimized or sampled unit-cell geometries to learn the distribution of high-performing topologies; conditional variants allow control over symmetry/porosity or target properties; generated designs are post-processed and validated by high-fidelity simulations or experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>Unsupervised / generative modeling (conditional generative modeling when labels/controls used)</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Highly applicable to expand and explore topology design spaces efficiently; particularly useful for discovering non-intuitive topologies near theoretical bounds.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>GAN-based generation produced hundreds of candidate topologies approaching theoretical performance bounds and satisfying design constraints; effective at enriching design libraries for further optimization and validation.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>Accelerates discovery of high-performance architected materials, reduces time spent on manual or brute-force topology search, and provides diverse candidate geometries for experimental realization.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Offers a complementary path to topology optimization and genetic algorithms by learning a generative prior over good designs; can be combined with optimization for refinement.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Using representative high-quality design datasets, conditioning on constraints (symmetry/porosity), and coupling generated candidates with physics-based validation ensured practical utility.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>Generative models can efficiently propose diverse, high-performing topologies when trained on representative design examples and guided with conditional controls for manufacturability and symmetry.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2334.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e2334.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>RNN for history-dependent plasticity</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Recurrent neural networks to learn history-dependent constitutive plasticity of heterogeneous RVEs</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>RNNs (including LSTM/GRU variants) trained on temporally sampled deformation paths of representative volume elements (RVEs) to learn path-dependent constitutive laws without imposing traditional plasticity assumptions.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>Computational mechanics — constitutive modeling of elasto-plastic heterogeneous materials</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Model history-dependent stress–strain responses (path-dependent plasticity) of heterogeneous microstructures for use as efficient constitutive surrogates in multiscale simulations.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>Training data generated via high-fidelity FEM simulations of RVEs along many deformation paths (moderate-to-large synthetic labeled datasets), allowing supervised sequence-to-sequence learning.</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>Time series / sequential data (load path histories and resulting stress/strain responses); multi-dimensional temporal sequences.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>High complexity due to path dependence, hysteresis, nonlinear material response and heterogeneity; traditional constitutive models require specific assumptions which may be restrictive.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>Established physics (plasticity theory) but data-driven constitutive modeling is an active research area seeking more flexible surrogates.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>Medium — engineers typically require physically consistent and stable constitutive predictions; interpretability useful but surrogate accuracy and stability are critical.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Recurrent neural networks (RNN), LSTM/GRU variants</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>RNN architectures are trained on sequences of imposed deformation paths and corresponding stresses to learn a mapping that inherently captures history dependence; trained models act as surrogates replacing traditional constitutive updates inside multiscale solvers.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>Supervised learning — sequence modeling / recurrent neural networks</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Applicable and effective where representative deformation paths can be simulated to produce training data; well-suited to capturing complex hysteresis and path dependence without manual constitutive assumptions.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>RNN-based frameworks predicted plastic responses accurately and efficiently across different loading paths and microstructures, enabling replacement of more expensive constitutive evaluations.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>Can substantially reduce computational cost of multiscale simulations and enable data-driven constitutive laws that capture complex microstructure effects not covered by classical models.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Compared conceptually to conventional plasticity formulations; RNNs avoid specific constitutive assumptions and can fit a broader class of behaviors when trained on representative datasets.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>High-fidelity training data across diverse loading histories, careful network architecture to ensure stability, and integration into existing multiscale frameworks aided success.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>Sequence models (RNNs) trained on temporally rich simulation data can learn robust, history-dependent constitutive behavior without manual model specification, provided representative deformation paths are available.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2334.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e2334.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>CNN+LSTM fracture prediction</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Combined convolutional and recurrent neural network (CNN+LSTM) approach for predicting fracture patterns from atomistic simulations</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A hybrid deep-learning pipeline maps atomistic MD crack propagation data (converted to image-like representations) to future fracture patterns, predicting crack paths, lengths and energy release with agreement to MD.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>Fracture mechanics — prediction of crack initiation and propagation in crystalline/bicrystalline solids</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Predict spatiotemporal crack propagation patterns and fracture metrics based on microstructural details and initial crack states using data-driven models trained on MD simulations.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>Training datasets generated from molecular dynamics simulations (moderate size); atomistic data mapped to images to reduce irrelevant atomic details.</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>Time-sequence image-like data (spatial crack maps across time); converted from atomistic coordinates to ordered pixel grids for CNN/LSTM processing.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>High nonlinearity, multi-scale physics, sensitivity to microstructural details (grain boundaries, defects), dynamic fracture processes.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>Well-established fracture mechanics but data-driven predictive modeling of complex crack paths is an emerging area.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>High — fracture behavior prediction benefits from mechanistic interpretability; however, predictive accuracy for design tasks is also valuable.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Hybrid CNN + LSTM deep learning architecture</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>Preprocess MD atomistic snapshots into image representations capturing relevant spatial features; CNN extracts spatial features per time step and an LSTM captures temporal evolution to predict subsequent crack patterns and fracture metrics; trained supervised on MD-labeled sequences.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>Supervised learning (hybrid deep learning — convolutional + recurrent)</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Applicable when high-fidelity MD datasets are available and spatial-to-temporal mapping can be represented in image sequences; useful for fast surrogate predictions of fracture progression.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>Approach captured complex fracture processes and showed good agreement with MD regarding fracture toughness and crack length; generalized to bicrystalline and graded microstructures in reported studies.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>Enables rapid assessment of fracture propagation for design of crack-resistant materials and may guide microstructural design to mitigate crack growth.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Outperformed methods lacking spatiotemporal modeling (e.g., pure CNN snapshots) by explicitly modeling temporal evolution with LSTM; compared qualitatively to MD ground truth.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Careful preprocessing of atomistic data into image-like inputs that retain spatial crack features, combination of spatial and temporal modeling, and representative MD training datasets.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>Combining convolutional spatial feature extraction with recurrent temporal modeling enables accurate prediction of complex, microstructure-sensitive fracture dynamics from atomistic simulation data.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2334.8">
                <h3 class="extraction-instance">Extracted Data Instance 8 (e2334.8)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Bayesian ML & active learning</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Bayesian machine learning (GPR, Bayesian optimization) and active learning for metamaterial design and small-data regimes</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Bayesian methods (Gaussian process regression, Bayesian optimization) and active learning loops applied to design metamaterials under uncertainty, quantify prediction uncertainty, and efficiently augment small experimental/simulation datasets.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>Metamaterial design and experimental design (materials with limited data)</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Design architected/metamaterial topologies that meet mechanical objectives while accounting for noisy data and manufacturing imperfections; efficiently select new experiments/simulations to label in small-data regimes.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>Typically limited/medium — experimental datasets are costly; simulation datasets can be generated but at expense; labeled data often scarce relative to problem dimensionality.</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>Tabular descriptors, image/geometry descriptors, and scalar property labels; sometimes sequential experiment results for active learning.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>High-dimensional design spaces, sensitivity to manufacturing imperfections, and noisy/expensive-to-obtain labels.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>Emerging use of Bayesian ML in materials design; domain has established optimization theory but needs data-efficient strategies.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>High — uncertainty quantification and principled exploration/exploitation strategies are required to make trustworthy experimental decisions.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Gaussian process regression (GPR), Bayesian optimization, active learning</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>GPR used as probabilistic surrogate models providing mean predictions and uncertainty estimates; Bayesian optimization/active learning selects next experiments/simulations to maximize information gain or expected improvement; used to handle noisy labels and small datasets and to quantify predictive uncertainty.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>Bayesian/surrogate modeling and active learning (supervised with uncertainty quantification)</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Highly applicable when data are expensive and uncertainty quantification is necessary for safe, efficient design; often combined with lower-fidelity models or experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>Bayesian approaches yielded data-driven designs of supercompressible metamaterials and enabled efficient exploration of design spaces under uncertainty; active learning augmented small training sets effectively in reported examples.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>Reduces number of expensive experiments/simulations, enables robust designs in presence of noise/manufacturing variability, and yields quantified confidence in predictions.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Compared favorably to brute-force search and deterministic surrogates by reducing required evaluations and providing uncertainty estimates; GPR better than neural nets for small datasets due to nonparametric Bayesian nature.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Use in small-data regimes, incorporation of uncertainty estimates to guide experiments, and coupling with physics-based validation were key to success.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>Bayesian surrogates and active learning substantially improve efficiency and reliability of design when labels are costly and data are limited, by trading off exploration and exploitation using uncertainty estimates.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2334.9">
                <h3 class="extraction-instance">Extracted Data Instance 9 (e2334.9)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Genetic alg + CNN for topology</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Integration of convolutional neural networks with genetic algorithms for accelerated topological design of tessellate composites</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Use of CNNs as fast fitness evaluators within genetic/evolutionary optimization loops to rapidly search enormous pixel-based topology design spaces for composites optimizing strength and toughness.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>Topological design and optimization — tessellate composites and kirigami graphene</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Find optimal pixel/voxel-based topologies for composites to maximize mechanical objectives (e.g., strength, toughness, stretchability) within exponentially large design spaces that are intractable for brute-force enumeration.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>Training data generated by simulations and/or prior optimization runs (moderate synthetic datasets); labels are mechanical responses computed by FEM or MD.</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>Image-like binary/continuous pixel/voxel representations of material layouts with corresponding scalar/mechanical labels.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>Combinatorial explosion of design choices with grid resolution; highly nonconvex, multimodal fitness landscapes.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>Active research area with both classical topology optimization and emergent ML-assisted methods; domain knowledge widely available.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>Medium — final designs typically validated with physics-based solvers; ML used for screening/acceleration rather than fully replacing physics.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Convolutional neural networks (CNN) used as surrogate evaluator combined with genetic/evolutionary algorithms</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>CNN trained to predict mechanical performance from pixel-based topologies; genetic algorithm uses CNN predictions as fitness to quickly evolve candidate designs; promising candidates validated with high-fidelity MD or FEM.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>Hybrid (supervised learning surrogate + evolutionary optimization)</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Very applicable where brute-force is infeasible; surrogate-assisted evolutionary search drastically reduces the number of expensive evaluations required.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>Integration accelerated design search and produced optimal designs validated by MD/FEM; trade-offs include potential mechanical incompatibilities requiring post-processing refinement.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>Enables exploration of high-resolution topologies and discovery of non-intuitive designs that would be computationally prohibitive by direct evaluation alone.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Surrogate-assisted GA outperforms pure brute-force and pure GA with expensive fitness evaluations by cutting evaluation cost; compared qualitatively against standard optimization-only pipelines.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Accurate surrogate CNNs trained on representative topologies, and iterative validation/refinement of ML-proposed candidates, enabled practical acceleration.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>Using ML surrogates inside evolutionary algorithms permits efficient traversal of combinatorially large topology spaces, enabling high-resolution design that would be infeasible with direct evaluations alone.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2334.10">
                <h3 class="extraction-instance">Extracted Data Instance 10 (e2334.10)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Graph NN for architected materials & MOFs</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Graph neural networks for semi-supervised design and property prediction of architected materials and porous frameworks</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>GNNs model architected/truss-like materials and framework materials by representing nodes and edges as joints and beams, allowing prediction of node-level loads or global properties and enabling semi-supervised design workflows.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>Architected/metamaterial design and porous framework property prediction</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Predict load distributions, node-level responses or global mechanical properties from partial observations or graph-structured representations of architected materials to guide topology design.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>Datasets vary; can be moderate (simulated structures) and may include partial labels (semi-supervised settings).</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>Graph-structured data (nodes as joints, edges as truss elements) potentially with node/edge features and partial labels.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>Non-Euclidean data structure, variable graph sizes, and complex interactions across connectivity; multi-scale mechanical behaviors mapped onto graph topology.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>Emerging application of GNNs in materials; graph representations are a natural fit for truss-like architected materials and some frameworks.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>Medium — predictions should respect mechanics; semi-supervised GNNs can leverage limited labeled nodes while learning structural relationships.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Graph neural networks (GNN), graph convolutional networks (GCN)</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>Message-passing GNNs ingest graph topologies and node/edge features to produce node-level or graph-level embeddings used to predict loads or properties; semi-supervised training leverages labeled and unlabeled nodes and can be integrated with design optimization.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>Supervised / semi-supervised graph deep learning</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Well-suited for problems naturally represented as graphs (architected materials, trusses, frameworks); enables prediction and design using partial information.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>GNNs effectively predicted load distributions from partial node measurements and were integrated into design algorithms to engineer topologies; useful when sparsely labeled data available.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>Facilitates topology design and inference from sparse sensor data, and provides scalable approaches for large architected structures represented as graphs.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>GNNs outperform methods that force Euclidean representations on inherently graph-structured problems; they offer natural inductive biases for connectivity-driven mechanics.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Appropriate graph representation (nodes/edges), message-passing architectures, and training on datasets that capture representative connectivity patterns.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>Graph neural networks align with the native representation of many architected materials and can predict node/graph responses from partial observations, enabling semi-supervised design workflows.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2334.11">
                <h3 class="extraction-instance">Extracted Data Instance 11 (e2334.11)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Smart finite elements (ML elements)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Smart finite elements: finite elements augmented with ML models to predict internal forces and avoid iterative internal displacement solves</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Finite elements whose internal force calculations are provided by ML models trained on element state data, reducing need for iterative numerical solves and lowering computational cost in nonlinear analyses.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>Computational mechanics — numerical solvers and finite element method acceleration</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Reduce computational cost of nonlinear finite element analyses by replacing costly internal iterative displacement field solves with ML-based element-level force predictors.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>Training data generated from high-fidelity finite element simulations of elements under various states (moderate synthetic datasets), labeled with internal force responses.</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>Structured tabular inputs per element state (deformation measures) mapping to internal forces; could be multi-dimensional arrays per element.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>Computationally expensive nonlinear solves; need accurate, stable element-level predictions across wide range of states to avoid solver instability.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>Emerging methodology; conceptually builds on established FEM but uses ML to accelerate element evaluations.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>High for stability and convergence — ML element models must be physically consistent and robust to ensure global solver stability.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Supervised ML surrogates embedded within FEM ('smart elements')</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>Train element-level regressors (neural nets or other regressors) to map element kinematic states to internal forces; embed these predictors in FEM assembly to avoid local nonlinear iterations; training uses high-fidelity generated element response data.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>Supervised learning integrated into numerical solver (hybrid physics-ML)</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Potentially highly applicable for speeding up nonlinear FEM analyses if ML element predictions are accurate and stable; requires careful enforcement of physical constraints.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>Concept provides a pathway to reduce computational effort by substituting costly local solves with ML prediction; success contingent on ML model generalization and ensuring solver stability.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>Could substantially accelerate nonlinear multiphysics simulations and enable larger-scale or higher-fidelity analyses within practical compute budgets.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Alternative reduced-order models and clustering-based surrogates exist; smart elements aim for finer-grained per-element acceleration while preserving FEM structure.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>High-fidelity training coverage of element state space, embedding of physical constraints (e.g., conservation, passivity), and verification within global solver loops.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>Embedding accurate, stable ML-based element surrogates into FEM can reduce computational cost, but success hinges on training coverage and enforcement of physical/solver consistency.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2334.12">
                <h3 class="extraction-instance">Extracted Data Instance 12 (e2334.12)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Physics-informed / PINNs (perspective)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Physics-guided machine learning including physics-informed neural networks (PINNs)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Incorporation of governing PDEs and physical constraints into ML loss functions (e.g., PINNs) to improve data efficiency, enforce physical laws, and integrate ML with mechanistic understanding for materials and mechanics problems.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>General computational mechanics and materials modeling (PDE-governed physics)</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Improve ML model reliability and data efficiency for physics-governed prediction tasks by encoding PDEs or conservation laws in training objectives.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>Can reduce data requirements by leveraging governing equations; useful when labeled data are limited but PDEs are known.</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>Dependent on task — spatiotemporal fields, boundary conditions, parameter fields; often continuous function approximation.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>High due to nonlinear PDEs and high-dimensional solution spaces; imposing physical constraints adds complexity to training.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>Emerging and rapidly developing; PINNs have seen successful demos in PDE solution and inverse problems.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>High — mechanistic fidelity is explicitly encoded, so interpretability and adherence to conservation laws are central.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Physics-informed neural networks (PINNs) and physics-guided ML hybrids</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>Neural networks trained with loss terms that penalize residuals of governing PDEs (and boundary/initial condition violations) in addition to data-fit terms; can solve forward and inverse PDE problems and improve generalization by embedding physics.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>Hybrid / physics-informed machine learning</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Particularly applicable when governing equations are known and data are limited; improves physical plausibility and reduces reliance on purely data-driven generalization.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>Promising approach cited for integrating mechanistic knowledge and reducing data needs, though practical implementation details and scaling remain active research topics.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>Could bridge data-driven approaches with mechanistic modeling for trustworthy predictions and discovery of interpretable constitutive relations.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Offers improved physical consistency versus purely data-driven black-box models, at the cost of more complex loss formulations and optimization.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Availability of reliable governing equations, careful weighting of physics vs data loss terms, and numerical stability of training.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>Encoding physics into ML architectures (e.g., PINNs) enhances data efficiency and trustworthiness of predictions, making ML more suitable for scientific discovery where mechanistic fidelity matters.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Generative Adversarial Nets <em>(Rating: 1)</em></li>
                <li>Data-driven design of supercompressible and recoverable metamaterials using Bayesian machine learning <em>(Rating: 2)</em></li>
                <li>Learning history-dependent plasticity using recurrent neural networks <em>(Rating: 2)</em></li>
                <li>Deep Learning Model to Predict Complex Stress and Strain Fields in Hierarchical Composites <em>(Rating: 2)</em></li>
                <li>Predicting elastic behaviors of high-contrast composites using convolutional neural network <em>(Rating: 2)</em></li>
                <li>An unsupervised approach for the identification and characterization of microstructures in 3-D samples of various material systems <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-2334",
    "paper_id": "paper-230564756",
    "extraction_schema_id": "extraction-schema-63",
    "extracted_data": [
        {
            "name_short": "Glass modulus prediction (MLP/LASSO/GPR)",
            "name_full": "Machine learning prediction of elastic moduli for silicate and oxide glasses (MLP, LASSO, Gaussian process regression)",
            "brief_description": "Supervised learning applied to predict elastic moduli and other mechanical properties of oxide and silicate glasses from compositional descriptors; methods include multilayer perceptrons (MLP), LASSO regression for interpretability, and Gaussian process regression (GPR) for small/sparse datasets.",
            "citation_title": "",
            "mention_or_use": "mention",
            "scientific_problem_domain": "Materials science — glass mechanics / composition–property prediction",
            "problem_description": "Predict Young's modulus, shear modulus, hardness and related mechanical properties from glass composition and simple derived descriptors to enable rapid screening and design of oxide glasses.",
            "data_availability": "Relatively abundant for some glass systems (large literature and compiled datasets exist), labeled (experimental/measured property values), often heterogeneous quality; for some tasks data can be sparse requiring GPR or active learning.",
            "data_structure": "Structured tabular data (feature vectors of component concentrations and derived compositional descriptors); sometimes augmented with engineered atomistic/local descriptors.",
            "problem_complexity": "Moderate nonlinearity between composition and properties; moderate dimensionality (several compositional variables); complexity increases with added target properties (multitask).",
            "domain_maturity": "Established domain with long-standing empirical and theoretical relations between composition and properties; extensive prior data and domain knowledge available.",
            "mechanistic_understanding_requirements": "Medium — interpretability is valuable for materials design; LASSO used for interpretable relations while neural networks provide higher predictive accuracy but are less interpretable.",
            "ai_methodology_name": "Multilayer perceptron (MLP), LASSO regression, Gaussian process regression (GPR)",
            "ai_methodology_description": "MLP/FFNNs trained in supervised regression on composition-to-property mappings; LASSO linear regression with L1 regularization used for sparse, interpretable models; GPR applied for probabilistic regression and uncertainty quantification on small/sparse datasets to avoid overfitting.",
            "ai_methodology_category": "Supervised learning (with Bayesian regression for GPR)",
            "applicability": "Appropriate — models match the structured, labeled composition→property mapping; GPR recommended where data are scarce; LASSO helpful when interpretability required.",
            "effectiveness_quantitative": null,
            "effectiveness_qualitative": "MLP produced the highest accuracy among tested algorithms for glass modulus prediction; LASSO provided simpler, interpretable models with somewhat lower accuracy; GPR avoided overfitting on sparse datasets.",
            "impact_potential": "Enables rapid screening and inverse-design of glass compositions for target mechanical properties, reducing experimental effort and accelerating materials discovery.",
            "comparison_to_alternatives": "Reported comparisons between PR/LASSO/RF/MLP and GPR; MLP highest accuracy, LASSO simpler and interpretable, GPR better for sparse data — qualitative comparative statements provided without hard numeric metrics.",
            "success_factors": "Availability of curated composition–property datasets, use of domain-informed descriptors, and matching model complexity to dataset size (e.g., GPR for small data) improved results.",
            "key_insight": "When composition–property datasets are sufficient, deep networks (MLP) improve predictive accuracy, but simple/regression-based models (LASSO, GPR) remain valuable for interpretability and small-data robustness.",
            "uuid": "e2334.0"
        },
        {
            "name_short": "Copper-alloy design NN",
            "name_full": "Neural-network based compositional design and screening of copper alloys",
            "brief_description": "Supervised neural networks (and comparisons with other regressors) used to rapidly screen copper-alloy composition design space for target tensile strength and electrical conductivity.",
            "citation_title": "",
            "mention_or_use": "mention",
            "scientific_problem_domain": "Alloy design — copper alloys (composition→mechanical and electrical properties)",
            "problem_description": "Discover copper-alloy compositions that simultaneously satisfy target mechanical strength and electrical conductivity constraints.",
            "data_availability": "Labeled datasets assembled from literature/databases; moderate size (sufficient for supervised model training), quality depends on literature reporting.",
            "data_structure": "Structured tabular composition vectors and derived composition features.",
            "problem_complexity": "Nonlinear multi-objective composition–property mapping; multi-dimensional continuous search space over composition variables.",
            "domain_maturity": "Well-established materials engineering domain with existing empirical rules and prior data; domain expertise available to guide preprocessing and features.",
            "mechanistic_understanding_requirements": "Medium — designers want interpretable relationships but practical design value can accept black-box suggestions subject to experimental validation.",
            "ai_methodology_name": "Feedforward neural networks (deep FFNN), comparisons with LIR, SVR, regression trees, GPR",
            "ai_methodology_description": "Supervised training of FFNNs to map composition and features to target properties; model selection/validation against classical ML regressors; used as rapid screening (predictive surrogate) in design pipeline.",
            "ai_methodology_category": "Supervised learning",
            "applicability": "Applicable and effective as a rapid screening tool; suitable because data are structured and labeled; some alternative models tested for trade-offs.",
            "effectiveness_quantitative": null,
            "effectiveness_qualitative": "Neural networks enabled rapid screening and provided compositional designs meeting target properties; review reports successful discovery tasks though specific metrics are not given.",
            "impact_potential": "Reduces search time for new alloy compositions and focuses experimental validation on promising candidates, accelerating alloy development.",
            "comparison_to_alternatives": "Explicit model selection studies compared LIR, SVR, regression tree and GPR alongside neural networks; neural networks used where higher prediction accuracy was needed, alternatives offered interpretability or small-data robustness.",
            "success_factors": "Curated labeled composition–property datasets and domain-specific feature engineering; evaluation of multiple model classes to balance accuracy and interpretability.",
            "key_insight": "Supervised neural networks can significantly speed composition-space screening when adequate labeled compositional datasets exist, and comparing simpler models helps balance interpretability and accuracy.",
            "uuid": "e2334.1"
        },
        {
            "name_short": "MOF/zeolite property ML",
            "name_full": "Machine learning prediction of mechanical stability and bulk modulus for MOFs and zeolite frameworks",
            "brief_description": "ANNs, gradient boosting and other regressors trained on structural/topological descriptors to predict bulk modulus and mechanical stability of porous frameworks (MOFs, zeolites).",
            "citation_title": "",
            "mention_or_use": "mention",
            "scientific_problem_domain": "Porous framework materials — MOFs and zeolites mechanical property prediction",
            "problem_description": "Predict bulk modulus and mechanical stability of thousands of framework structures from structural/topological or atomistic descriptors to prioritize materials.",
            "data_availability": "Large computational and experimental databases of thousands of structures (abundant) with computed/measured mechanical properties; labeled.",
            "data_structure": "Structured descriptors: structural/topological vectors, atomistic features, porosity metrics; sometimes graph-like representations.",
            "problem_complexity": "High structural diversity, high-dimensional descriptor space, nonlinear structure–property relations.",
            "domain_maturity": "Growing/active research area with established simulation pipelines (DFT/MD) and curated databases; mechanistic models exist but are computationally costly for high-throughput screening.",
            "mechanistic_understanding_requirements": "Medium — predictions are used to prioritize candidates, while mechanistic validation often performed with higher-fidelity simulations or experiments.",
            "ai_methodology_name": "Artificial neural networks (ANN), gradient boosting regressors, graph neural networks (GNNs)",
            "ai_methodology_description": "Supervised training on descriptors (topological and structural) to predict mechanical properties; in some studies GNNs used to exploit inherent graph-like connectivity of framework materials.",
            "ai_methodology_category": "Supervised learning (with graph-based deep learning for some works)",
            "applicability": "Well-suited for high-throughput screening where conventional DFT/MD are too slow; GNNs appropriate when graph connectivity is the natural representation.",
            "effectiveness_quantitative": null,
            "effectiveness_qualitative": "ANNs and gradient-boosting models established credible predictors of bulk modulus and mechanical stability; GNNs offer potential improvements by capturing topology directly.",
            "impact_potential": "Enables prioritization of mechanically robust MOFs/zeolites for application and reduces computational expense by screening large candidate sets before high-fidelity validation.",
            "comparison_to_alternatives": "GPR and other classical regressors useful for small datasets; GNNs and ANNs advantageous for large structural databases. No standardized quantitative head-to-head metrics reported in the review.",
            "success_factors": "Availability of large curated structural databases and meaningful structural/topological descriptors; models leveraging natural graph structure (GNNs) performed better where applicable.",
            "key_insight": "For framework materials with large databases, supervised ML on structural descriptors provides fast, effective proxies for expensive simulations, and graph-based methods align naturally with topology-sensitive properties.",
            "uuid": "e2334.2"
        },
        {
            "name_short": "CNN for microstructure→properties",
            "name_full": "Convolutional neural networks for predicting mechanical behaviour from microstructure images (high-contrast composites, polymer nanocomposites, AM metals)",
            "brief_description": "Image/voxel-based CNNs trained on FEM- or simulation-generated microstructure images to predict strain/stress fields and effective mechanical properties, often outperforming classical feature-based regressors.",
            "citation_title": "",
            "mention_or_use": "mention",
            "scientific_problem_domain": "Heterogeneous materials mechanics — microstructure image to mechanical response mapping",
            "problem_description": "Predict field-level responses (strain/stress) and effective properties from spatial microstructure images or 3D voxel representations to speed up analyses and enable inverse design.",
            "data_availability": "Datasets commonly generated via FEM or MD simulations (abundant for synthetic data), labeled (simulated responses); experimental 3D images less abundant.",
            "data_structure": "Unstructured/structured image and voxel data (2D/3D grids), high-dimensional spatial fields.",
            "problem_complexity": "High complexity: large input dimensionality (images/voxels), multiscale features, nonlinear physics mapping from microstructure to response.",
            "domain_maturity": "Emerging/rapidly developing; well-established for image-based ML in computer vision but adapting to physics-informed materials contexts is ongoing.",
            "mechanistic_understanding_requirements": "Low-to-medium for surrogate tasks (black-box prediction acceptable for screening), but interpretability desired for scientific insight; learned filters can be inspected partially.",
            "ai_methodology_name": "Convolutional neural networks (2D/3D CNNs), residual networks for deep architectures",
            "ai_methodology_description": "CNNs take pixel/voxel arrays of material microstructure as input and regress to field outputs or scalar effective properties; architectures include multi-layer convolutional stacks and residual connections; trained on simulation-generated labeled datasets, often with data augmentation.",
            "ai_methodology_category": "Supervised learning (deep learning — CNNs)",
            "applicability": "Highly applicable where microstructures naturally form image/voxel inputs; reduces feature-engineering overhead and learns multiscale spatial embeddings automatically.",
            "effectiveness_quantitative": null,
            "effectiveness_qualitative": "CNN models outperformed ridge regression and gradient boosting when 3D microstructure images were available (e.g., yield strength prediction for AM metals), demonstrating superior capacity to learn hierarchical spatial features.",
            "impact_potential": "Speeds prediction of spatial mechanical fields and enables inverse design workflows; generalizes across shapes/loads when trained on diverse simulated datasets.",
            "comparison_to_alternatives": "Compared with feature-based regressors (Ridge, gradient boosting) and classical ML; CNNs provided better performance on image inputs and reduced preprocessing effort.",
            "success_factors": "Availability of large simulation-generated labeled image datasets, appropriate CNN architectures, and alignment between input representation and network inductive biases (spatial locality via convolutions).",
            "key_insight": "For materials that are naturally represented as images/voxels, CNNs effectively learn hierarchical spatial features and often outperform classical regressors that rely on hand-crafted descriptors.",
            "uuid": "e2334.3"
        },
        {
            "name_short": "cGAN inverse elasticity",
            "name_full": "Conditional GAN for inverse elasticity — displacement/strain field to modulus distribution",
            "brief_description": "Conditional generative adversarial networks (cGANs) used to solve inverse elasticity problems by mapping observed displacement/strain images to spatial elastic modulus maps, enabling fast non-destructive evaluation and elastography-like applications.",
            "citation_title": "",
            "mention_or_use": "mention",
            "scientific_problem_domain": "Inverse problems in solid mechanics — elastography and non-destructive evaluation",
            "problem_description": "Infer spatial distribution of elastic modulus inside a body from measured displacement/strain fields (image-to-image inverse mapping).",
            "data_availability": "Training data typically generated via forward FEM simulations pairing modulus distributions with resulting displacement/strain fields; labeled and abundant when simulated.",
            "data_structure": "Paired images (input: displacement/strain fields; output: modulus distribution) — image-to-image translation task.",
            "problem_complexity": "Ill-posed inverse mapping, non-unique solutions possible, high-dimensional outputs; requires models that capture conditional distribution.",
            "domain_maturity": "Emerging application area; inverse elasticity has established physics but ML-based image-to-image inversion is newer.",
            "mechanistic_understanding_requirements": "Medium — solutions often need physical plausibility and may require uncertainty quantification to be trusted for diagnostics.",
            "ai_methodology_name": "Conditional generative adversarial networks (cGAN)",
            "ai_methodology_description": "A cGAN generator maps input field images into predicted modulus maps while a discriminator judges realism conditioned on inputs; trained adversarially with paired simulation data to produce realistic inverse solutions; training may combine L1/L2 reconstruction losses with adversarial loss.",
            "ai_methodology_category": "Supervised generative modeling / conditional generative modeling",
            "applicability": "Applicable and effective for fast approximate inverse solutions, especially when forward solvers are expensive; relies on availability of representative paired training data.",
            "effectiveness_quantitative": null,
            "effectiveness_qualitative": "cGAN demonstrated fast and accurate reconstruction of modulus distributions from strain/displacement fields in simulated inclusion systems; suitable for real-time elastography-like use cases according to the review.",
            "impact_potential": "Enables fast non-destructive evaluation, potential real-time diagnostics and high-throughput material inspection, subject to generalization from simulated to experimental data.",
            "comparison_to_alternatives": "Compared qualitatively to traditional iterative inverse solvers (computationally costly); cGAN offers orders-of-magnitude faster inference though with reliance on representative training data and potential generalization limits.",
            "success_factors": "Large, representative paired simulation datasets and conditioning on input fields; adversarial loss improves realism of reconstructed maps over simple regression losses.",
            "key_insight": "Conditional GANs can learn ill-posed inverse mappings from fields to material distributions when ample paired simulation data exist, trading off exact physical guarantee for fast, realistic reconstructions.",
            "uuid": "e2334.4"
        },
        {
            "name_short": "GANs for topology generation",
            "name_full": "Generative adversarial networks for architected materials and metamaterial unit-cell topology generation",
            "brief_description": "GANs (and cGANs) trained to generate novel 2D/3D periodic unit-cell geometries for architected materials and metamaterials that approach theoretical bounds or satisfy symmetry and porosity constraints.",
            "citation_title": "",
            "mention_or_use": "mention",
            "scientific_problem_domain": "Metamaterials and architected materials design — topology generation",
            "problem_description": "Generate candidate unit-cell topologies with desired mechanical effective properties (e.g., near Hashin–Shtrikman bounds) and specified symmetries/porosities for manufacturable metamaterials.",
            "data_availability": "Design libraries generated through simulations or prior optimized instances (moderate-to-large synthetic datasets); labeled if properties matched to geometries, otherwise used as unlabeled for generative modeling.",
            "data_structure": "Image/voxel or parametric geometry representations (2D periodic unit cells); sometimes combined with property labels.",
            "problem_complexity": "Combinatorially large discrete topology space with geometric and symmetry constraints; multi-objective optimization landscape.",
            "domain_maturity": "Active/emerging with growing computational resources and manufacturing capabilities; established theoretical bounds exist for guidance.",
            "mechanistic_understanding_requirements": "Low-to-medium — generated designs require subsequent mechanical evaluation; interpretability of generator typically low but physics constraints can be enforced.",
            "ai_methodology_name": "Generative adversarial networks (GANs), conditional GANs (cGANs)",
            "ai_methodology_description": "GAN frameworks trained on collections of optimized or sampled unit-cell geometries to learn the distribution of high-performing topologies; conditional variants allow control over symmetry/porosity or target properties; generated designs are post-processed and validated by high-fidelity simulations or experiments.",
            "ai_methodology_category": "Unsupervised / generative modeling (conditional generative modeling when labels/controls used)",
            "applicability": "Highly applicable to expand and explore topology design spaces efficiently; particularly useful for discovering non-intuitive topologies near theoretical bounds.",
            "effectiveness_quantitative": null,
            "effectiveness_qualitative": "GAN-based generation produced hundreds of candidate topologies approaching theoretical performance bounds and satisfying design constraints; effective at enriching design libraries for further optimization and validation.",
            "impact_potential": "Accelerates discovery of high-performance architected materials, reduces time spent on manual or brute-force topology search, and provides diverse candidate geometries for experimental realization.",
            "comparison_to_alternatives": "Offers a complementary path to topology optimization and genetic algorithms by learning a generative prior over good designs; can be combined with optimization for refinement.",
            "success_factors": "Using representative high-quality design datasets, conditioning on constraints (symmetry/porosity), and coupling generated candidates with physics-based validation ensured practical utility.",
            "key_insight": "Generative models can efficiently propose diverse, high-performing topologies when trained on representative design examples and guided with conditional controls for manufacturability and symmetry.",
            "uuid": "e2334.5"
        },
        {
            "name_short": "RNN for history-dependent plasticity",
            "name_full": "Recurrent neural networks to learn history-dependent constitutive plasticity of heterogeneous RVEs",
            "brief_description": "RNNs (including LSTM/GRU variants) trained on temporally sampled deformation paths of representative volume elements (RVEs) to learn path-dependent constitutive laws without imposing traditional plasticity assumptions.",
            "citation_title": "",
            "mention_or_use": "mention",
            "scientific_problem_domain": "Computational mechanics — constitutive modeling of elasto-plastic heterogeneous materials",
            "problem_description": "Model history-dependent stress–strain responses (path-dependent plasticity) of heterogeneous microstructures for use as efficient constitutive surrogates in multiscale simulations.",
            "data_availability": "Training data generated via high-fidelity FEM simulations of RVEs along many deformation paths (moderate-to-large synthetic labeled datasets), allowing supervised sequence-to-sequence learning.",
            "data_structure": "Time series / sequential data (load path histories and resulting stress/strain responses); multi-dimensional temporal sequences.",
            "problem_complexity": "High complexity due to path dependence, hysteresis, nonlinear material response and heterogeneity; traditional constitutive models require specific assumptions which may be restrictive.",
            "domain_maturity": "Established physics (plasticity theory) but data-driven constitutive modeling is an active research area seeking more flexible surrogates.",
            "mechanistic_understanding_requirements": "Medium — engineers typically require physically consistent and stable constitutive predictions; interpretability useful but surrogate accuracy and stability are critical.",
            "ai_methodology_name": "Recurrent neural networks (RNN), LSTM/GRU variants",
            "ai_methodology_description": "RNN architectures are trained on sequences of imposed deformation paths and corresponding stresses to learn a mapping that inherently captures history dependence; trained models act as surrogates replacing traditional constitutive updates inside multiscale solvers.",
            "ai_methodology_category": "Supervised learning — sequence modeling / recurrent neural networks",
            "applicability": "Applicable and effective where representative deformation paths can be simulated to produce training data; well-suited to capturing complex hysteresis and path dependence without manual constitutive assumptions.",
            "effectiveness_quantitative": null,
            "effectiveness_qualitative": "RNN-based frameworks predicted plastic responses accurately and efficiently across different loading paths and microstructures, enabling replacement of more expensive constitutive evaluations.",
            "impact_potential": "Can substantially reduce computational cost of multiscale simulations and enable data-driven constitutive laws that capture complex microstructure effects not covered by classical models.",
            "comparison_to_alternatives": "Compared conceptually to conventional plasticity formulations; RNNs avoid specific constitutive assumptions and can fit a broader class of behaviors when trained on representative datasets.",
            "success_factors": "High-fidelity training data across diverse loading histories, careful network architecture to ensure stability, and integration into existing multiscale frameworks aided success.",
            "key_insight": "Sequence models (RNNs) trained on temporally rich simulation data can learn robust, history-dependent constitutive behavior without manual model specification, provided representative deformation paths are available.",
            "uuid": "e2334.6"
        },
        {
            "name_short": "CNN+LSTM fracture prediction",
            "name_full": "Combined convolutional and recurrent neural network (CNN+LSTM) approach for predicting fracture patterns from atomistic simulations",
            "brief_description": "A hybrid deep-learning pipeline maps atomistic MD crack propagation data (converted to image-like representations) to future fracture patterns, predicting crack paths, lengths and energy release with agreement to MD.",
            "citation_title": "",
            "mention_or_use": "mention",
            "scientific_problem_domain": "Fracture mechanics — prediction of crack initiation and propagation in crystalline/bicrystalline solids",
            "problem_description": "Predict spatiotemporal crack propagation patterns and fracture metrics based on microstructural details and initial crack states using data-driven models trained on MD simulations.",
            "data_availability": "Training datasets generated from molecular dynamics simulations (moderate size); atomistic data mapped to images to reduce irrelevant atomic details.",
            "data_structure": "Time-sequence image-like data (spatial crack maps across time); converted from atomistic coordinates to ordered pixel grids for CNN/LSTM processing.",
            "problem_complexity": "High nonlinearity, multi-scale physics, sensitivity to microstructural details (grain boundaries, defects), dynamic fracture processes.",
            "domain_maturity": "Well-established fracture mechanics but data-driven predictive modeling of complex crack paths is an emerging area.",
            "mechanistic_understanding_requirements": "High — fracture behavior prediction benefits from mechanistic interpretability; however, predictive accuracy for design tasks is also valuable.",
            "ai_methodology_name": "Hybrid CNN + LSTM deep learning architecture",
            "ai_methodology_description": "Preprocess MD atomistic snapshots into image representations capturing relevant spatial features; CNN extracts spatial features per time step and an LSTM captures temporal evolution to predict subsequent crack patterns and fracture metrics; trained supervised on MD-labeled sequences.",
            "ai_methodology_category": "Supervised learning (hybrid deep learning — convolutional + recurrent)",
            "applicability": "Applicable when high-fidelity MD datasets are available and spatial-to-temporal mapping can be represented in image sequences; useful for fast surrogate predictions of fracture progression.",
            "effectiveness_quantitative": null,
            "effectiveness_qualitative": "Approach captured complex fracture processes and showed good agreement with MD regarding fracture toughness and crack length; generalized to bicrystalline and graded microstructures in reported studies.",
            "impact_potential": "Enables rapid assessment of fracture propagation for design of crack-resistant materials and may guide microstructural design to mitigate crack growth.",
            "comparison_to_alternatives": "Outperformed methods lacking spatiotemporal modeling (e.g., pure CNN snapshots) by explicitly modeling temporal evolution with LSTM; compared qualitatively to MD ground truth.",
            "success_factors": "Careful preprocessing of atomistic data into image-like inputs that retain spatial crack features, combination of spatial and temporal modeling, and representative MD training datasets.",
            "key_insight": "Combining convolutional spatial feature extraction with recurrent temporal modeling enables accurate prediction of complex, microstructure-sensitive fracture dynamics from atomistic simulation data.",
            "uuid": "e2334.7"
        },
        {
            "name_short": "Bayesian ML & active learning",
            "name_full": "Bayesian machine learning (GPR, Bayesian optimization) and active learning for metamaterial design and small-data regimes",
            "brief_description": "Bayesian methods (Gaussian process regression, Bayesian optimization) and active learning loops applied to design metamaterials under uncertainty, quantify prediction uncertainty, and efficiently augment small experimental/simulation datasets.",
            "citation_title": "",
            "mention_or_use": "mention",
            "scientific_problem_domain": "Metamaterial design and experimental design (materials with limited data)",
            "problem_description": "Design architected/metamaterial topologies that meet mechanical objectives while accounting for noisy data and manufacturing imperfections; efficiently select new experiments/simulations to label in small-data regimes.",
            "data_availability": "Typically limited/medium — experimental datasets are costly; simulation datasets can be generated but at expense; labeled data often scarce relative to problem dimensionality.",
            "data_structure": "Tabular descriptors, image/geometry descriptors, and scalar property labels; sometimes sequential experiment results for active learning.",
            "problem_complexity": "High-dimensional design spaces, sensitivity to manufacturing imperfections, and noisy/expensive-to-obtain labels.",
            "domain_maturity": "Emerging use of Bayesian ML in materials design; domain has established optimization theory but needs data-efficient strategies.",
            "mechanistic_understanding_requirements": "High — uncertainty quantification and principled exploration/exploitation strategies are required to make trustworthy experimental decisions.",
            "ai_methodology_name": "Gaussian process regression (GPR), Bayesian optimization, active learning",
            "ai_methodology_description": "GPR used as probabilistic surrogate models providing mean predictions and uncertainty estimates; Bayesian optimization/active learning selects next experiments/simulations to maximize information gain or expected improvement; used to handle noisy labels and small datasets and to quantify predictive uncertainty.",
            "ai_methodology_category": "Bayesian/surrogate modeling and active learning (supervised with uncertainty quantification)",
            "applicability": "Highly applicable when data are expensive and uncertainty quantification is necessary for safe, efficient design; often combined with lower-fidelity models or experiments.",
            "effectiveness_quantitative": null,
            "effectiveness_qualitative": "Bayesian approaches yielded data-driven designs of supercompressible metamaterials and enabled efficient exploration of design spaces under uncertainty; active learning augmented small training sets effectively in reported examples.",
            "impact_potential": "Reduces number of expensive experiments/simulations, enables robust designs in presence of noise/manufacturing variability, and yields quantified confidence in predictions.",
            "comparison_to_alternatives": "Compared favorably to brute-force search and deterministic surrogates by reducing required evaluations and providing uncertainty estimates; GPR better than neural nets for small datasets due to nonparametric Bayesian nature.",
            "success_factors": "Use in small-data regimes, incorporation of uncertainty estimates to guide experiments, and coupling with physics-based validation were key to success.",
            "key_insight": "Bayesian surrogates and active learning substantially improve efficiency and reliability of design when labels are costly and data are limited, by trading off exploration and exploitation using uncertainty estimates.",
            "uuid": "e2334.8"
        },
        {
            "name_short": "Genetic alg + CNN for topology",
            "name_full": "Integration of convolutional neural networks with genetic algorithms for accelerated topological design of tessellate composites",
            "brief_description": "Use of CNNs as fast fitness evaluators within genetic/evolutionary optimization loops to rapidly search enormous pixel-based topology design spaces for composites optimizing strength and toughness.",
            "citation_title": "",
            "mention_or_use": "mention",
            "scientific_problem_domain": "Topological design and optimization — tessellate composites and kirigami graphene",
            "problem_description": "Find optimal pixel/voxel-based topologies for composites to maximize mechanical objectives (e.g., strength, toughness, stretchability) within exponentially large design spaces that are intractable for brute-force enumeration.",
            "data_availability": "Training data generated by simulations and/or prior optimization runs (moderate synthetic datasets); labels are mechanical responses computed by FEM or MD.",
            "data_structure": "Image-like binary/continuous pixel/voxel representations of material layouts with corresponding scalar/mechanical labels.",
            "problem_complexity": "Combinatorial explosion of design choices with grid resolution; highly nonconvex, multimodal fitness landscapes.",
            "domain_maturity": "Active research area with both classical topology optimization and emergent ML-assisted methods; domain knowledge widely available.",
            "mechanistic_understanding_requirements": "Medium — final designs typically validated with physics-based solvers; ML used for screening/acceleration rather than fully replacing physics.",
            "ai_methodology_name": "Convolutional neural networks (CNN) used as surrogate evaluator combined with genetic/evolutionary algorithms",
            "ai_methodology_description": "CNN trained to predict mechanical performance from pixel-based topologies; genetic algorithm uses CNN predictions as fitness to quickly evolve candidate designs; promising candidates validated with high-fidelity MD or FEM.",
            "ai_methodology_category": "Hybrid (supervised learning surrogate + evolutionary optimization)",
            "applicability": "Very applicable where brute-force is infeasible; surrogate-assisted evolutionary search drastically reduces the number of expensive evaluations required.",
            "effectiveness_quantitative": null,
            "effectiveness_qualitative": "Integration accelerated design search and produced optimal designs validated by MD/FEM; trade-offs include potential mechanical incompatibilities requiring post-processing refinement.",
            "impact_potential": "Enables exploration of high-resolution topologies and discovery of non-intuitive designs that would be computationally prohibitive by direct evaluation alone.",
            "comparison_to_alternatives": "Surrogate-assisted GA outperforms pure brute-force and pure GA with expensive fitness evaluations by cutting evaluation cost; compared qualitatively against standard optimization-only pipelines.",
            "success_factors": "Accurate surrogate CNNs trained on representative topologies, and iterative validation/refinement of ML-proposed candidates, enabled practical acceleration.",
            "key_insight": "Using ML surrogates inside evolutionary algorithms permits efficient traversal of combinatorially large topology spaces, enabling high-resolution design that would be infeasible with direct evaluations alone.",
            "uuid": "e2334.9"
        },
        {
            "name_short": "Graph NN for architected materials & MOFs",
            "name_full": "Graph neural networks for semi-supervised design and property prediction of architected materials and porous frameworks",
            "brief_description": "GNNs model architected/truss-like materials and framework materials by representing nodes and edges as joints and beams, allowing prediction of node-level loads or global properties and enabling semi-supervised design workflows.",
            "citation_title": "",
            "mention_or_use": "mention",
            "scientific_problem_domain": "Architected/metamaterial design and porous framework property prediction",
            "problem_description": "Predict load distributions, node-level responses or global mechanical properties from partial observations or graph-structured representations of architected materials to guide topology design.",
            "data_availability": "Datasets vary; can be moderate (simulated structures) and may include partial labels (semi-supervised settings).",
            "data_structure": "Graph-structured data (nodes as joints, edges as truss elements) potentially with node/edge features and partial labels.",
            "problem_complexity": "Non-Euclidean data structure, variable graph sizes, and complex interactions across connectivity; multi-scale mechanical behaviors mapped onto graph topology.",
            "domain_maturity": "Emerging application of GNNs in materials; graph representations are a natural fit for truss-like architected materials and some frameworks.",
            "mechanistic_understanding_requirements": "Medium — predictions should respect mechanics; semi-supervised GNNs can leverage limited labeled nodes while learning structural relationships.",
            "ai_methodology_name": "Graph neural networks (GNN), graph convolutional networks (GCN)",
            "ai_methodology_description": "Message-passing GNNs ingest graph topologies and node/edge features to produce node-level or graph-level embeddings used to predict loads or properties; semi-supervised training leverages labeled and unlabeled nodes and can be integrated with design optimization.",
            "ai_methodology_category": "Supervised / semi-supervised graph deep learning",
            "applicability": "Well-suited for problems naturally represented as graphs (architected materials, trusses, frameworks); enables prediction and design using partial information.",
            "effectiveness_quantitative": null,
            "effectiveness_qualitative": "GNNs effectively predicted load distributions from partial node measurements and were integrated into design algorithms to engineer topologies; useful when sparsely labeled data available.",
            "impact_potential": "Facilitates topology design and inference from sparse sensor data, and provides scalable approaches for large architected structures represented as graphs.",
            "comparison_to_alternatives": "GNNs outperform methods that force Euclidean representations on inherently graph-structured problems; they offer natural inductive biases for connectivity-driven mechanics.",
            "success_factors": "Appropriate graph representation (nodes/edges), message-passing architectures, and training on datasets that capture representative connectivity patterns.",
            "key_insight": "Graph neural networks align with the native representation of many architected materials and can predict node/graph responses from partial observations, enabling semi-supervised design workflows.",
            "uuid": "e2334.10"
        },
        {
            "name_short": "Smart finite elements (ML elements)",
            "name_full": "Smart finite elements: finite elements augmented with ML models to predict internal forces and avoid iterative internal displacement solves",
            "brief_description": "Finite elements whose internal force calculations are provided by ML models trained on element state data, reducing need for iterative numerical solves and lowering computational cost in nonlinear analyses.",
            "citation_title": "",
            "mention_or_use": "mention",
            "scientific_problem_domain": "Computational mechanics — numerical solvers and finite element method acceleration",
            "problem_description": "Reduce computational cost of nonlinear finite element analyses by replacing costly internal iterative displacement field solves with ML-based element-level force predictors.",
            "data_availability": "Training data generated from high-fidelity finite element simulations of elements under various states (moderate synthetic datasets), labeled with internal force responses.",
            "data_structure": "Structured tabular inputs per element state (deformation measures) mapping to internal forces; could be multi-dimensional arrays per element.",
            "problem_complexity": "Computationally expensive nonlinear solves; need accurate, stable element-level predictions across wide range of states to avoid solver instability.",
            "domain_maturity": "Emerging methodology; conceptually builds on established FEM but uses ML to accelerate element evaluations.",
            "mechanistic_understanding_requirements": "High for stability and convergence — ML element models must be physically consistent and robust to ensure global solver stability.",
            "ai_methodology_name": "Supervised ML surrogates embedded within FEM ('smart elements')",
            "ai_methodology_description": "Train element-level regressors (neural nets or other regressors) to map element kinematic states to internal forces; embed these predictors in FEM assembly to avoid local nonlinear iterations; training uses high-fidelity generated element response data.",
            "ai_methodology_category": "Supervised learning integrated into numerical solver (hybrid physics-ML)",
            "applicability": "Potentially highly applicable for speeding up nonlinear FEM analyses if ML element predictions are accurate and stable; requires careful enforcement of physical constraints.",
            "effectiveness_quantitative": null,
            "effectiveness_qualitative": "Concept provides a pathway to reduce computational effort by substituting costly local solves with ML prediction; success contingent on ML model generalization and ensuring solver stability.",
            "impact_potential": "Could substantially accelerate nonlinear multiphysics simulations and enable larger-scale or higher-fidelity analyses within practical compute budgets.",
            "comparison_to_alternatives": "Alternative reduced-order models and clustering-based surrogates exist; smart elements aim for finer-grained per-element acceleration while preserving FEM structure.",
            "success_factors": "High-fidelity training coverage of element state space, embedding of physical constraints (e.g., conservation, passivity), and verification within global solver loops.",
            "key_insight": "Embedding accurate, stable ML-based element surrogates into FEM can reduce computational cost, but success hinges on training coverage and enforcement of physical/solver consistency.",
            "uuid": "e2334.11"
        },
        {
            "name_short": "Physics-informed / PINNs (perspective)",
            "name_full": "Physics-guided machine learning including physics-informed neural networks (PINNs)",
            "brief_description": "Incorporation of governing PDEs and physical constraints into ML loss functions (e.g., PINNs) to improve data efficiency, enforce physical laws, and integrate ML with mechanistic understanding for materials and mechanics problems.",
            "citation_title": "",
            "mention_or_use": "mention",
            "scientific_problem_domain": "General computational mechanics and materials modeling (PDE-governed physics)",
            "problem_description": "Improve ML model reliability and data efficiency for physics-governed prediction tasks by encoding PDEs or conservation laws in training objectives.",
            "data_availability": "Can reduce data requirements by leveraging governing equations; useful when labeled data are limited but PDEs are known.",
            "data_structure": "Dependent on task — spatiotemporal fields, boundary conditions, parameter fields; often continuous function approximation.",
            "problem_complexity": "High due to nonlinear PDEs and high-dimensional solution spaces; imposing physical constraints adds complexity to training.",
            "domain_maturity": "Emerging and rapidly developing; PINNs have seen successful demos in PDE solution and inverse problems.",
            "mechanistic_understanding_requirements": "High — mechanistic fidelity is explicitly encoded, so interpretability and adherence to conservation laws are central.",
            "ai_methodology_name": "Physics-informed neural networks (PINNs) and physics-guided ML hybrids",
            "ai_methodology_description": "Neural networks trained with loss terms that penalize residuals of governing PDEs (and boundary/initial condition violations) in addition to data-fit terms; can solve forward and inverse PDE problems and improve generalization by embedding physics.",
            "ai_methodology_category": "Hybrid / physics-informed machine learning",
            "applicability": "Particularly applicable when governing equations are known and data are limited; improves physical plausibility and reduces reliance on purely data-driven generalization.",
            "effectiveness_quantitative": null,
            "effectiveness_qualitative": "Promising approach cited for integrating mechanistic knowledge and reducing data needs, though practical implementation details and scaling remain active research topics.",
            "impact_potential": "Could bridge data-driven approaches with mechanistic modeling for trustworthy predictions and discovery of interpretable constitutive relations.",
            "comparison_to_alternatives": "Offers improved physical consistency versus purely data-driven black-box models, at the cost of more complex loss formulations and optimization.",
            "success_factors": "Availability of reliable governing equations, careful weighting of physics vs data loss terms, and numerical stability of training.",
            "key_insight": "Encoding physics into ML architectures (e.g., PINNs) enhances data efficiency and trustworthiness of predictions, making ML more suitable for scientific discovery where mechanistic fidelity matters.",
            "uuid": "e2334.12"
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Generative Adversarial Nets",
            "rating": 1,
            "sanitized_title": "generative_adversarial_nets"
        },
        {
            "paper_title": "Data-driven design of supercompressible and recoverable metamaterials using Bayesian machine learning",
            "rating": 2,
            "sanitized_title": "datadriven_design_of_supercompressible_and_recoverable_metamaterials_using_bayesian_machine_learning"
        },
        {
            "paper_title": "Learning history-dependent plasticity using recurrent neural networks",
            "rating": 2,
            "sanitized_title": "learning_historydependent_plasticity_using_recurrent_neural_networks"
        },
        {
            "paper_title": "Deep Learning Model to Predict Complex Stress and Strain Fields in Hierarchical Composites",
            "rating": 2,
            "sanitized_title": "deep_learning_model_to_predict_complex_stress_and_strain_fields_in_hierarchical_composites"
        },
        {
            "paper_title": "Predicting elastic behaviors of high-contrast composites using convolutional neural network",
            "rating": 2,
            "sanitized_title": "predicting_elastic_behaviors_of_highcontrast_composites_using_convolutional_neural_network"
        },
        {
            "paper_title": "An unsupervised approach for the identification and characterization of microstructures in 3-D samples of various material systems",
            "rating": 1,
            "sanitized_title": "an_unsupervised_approach_for_the_identification_and_characterization_of_microstructures_in_3d_samples_of_various_material_systems"
        }
    ],
    "cost": 0.0262875,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Artificial intelligence and machine learning in design of mechanical materials
17 December 2020</p>
<p>Kai Guo 
Department of Civil and Environmental Engineering
Laboratory for Atomistic and Molecular Mechanics (LAMM)
Massachusetts Institute of Technology
77 Massachusetts Ave. 1-29002139CambridgeMassachusettsUSA</p>
<p>Zhenze Yang 
Chi-Hua Yu 
Markus J Buehler mbuehler@mit.edu 
Chi Hua </p>
<p>Department of Materials Science and Engineering
Massachusetts Institute of Technology
77 Massachusetts Ave02139CambridgeMassachusettsUSA</p>
<p>Department of Engineering Science
National Cheng Kung University
No. 1, University Road701Tainan CityTaiwan</p>
<p>Center for Computational Science and Engineering
Schwarzman College of Computing
Massachusetts Institute of Technology
77 Massachusetts Ave02139CambridgeMassachusettsUSA</p>
<p>Center for Materials Science and Engineering
77 Massachusetts Ave02139CambridgeMassachusettsUSA</p>
<p>Chi-Hua Yu</p>
<p>National Chung Kung University</p>
<p>Artificial intelligence and machine learning in design of mechanical materials
17 December 202073317A53C76C01FE960276794732694410.1039/d0mh01451fReceived 7th September 2020, Accepted 16th December 2020 received his BEng degree from the Chung Yuan
Artificial intelligence, especially machine learning (ML) and deep learning (DL) algorithms, is becoming an important tool in the fields of materials and mechanical engineering, attributed to its power to predict materials properties, design de novo materials and discover new mechanisms beyond intuitions.As the structural complexity of novel materials soars, the material design problem to optimize mechanical behaviors can involve massive design spaces that are intractable for conventional methods.Addressing this challenge, ML models trained from large material datasets that relate structure, properties and function at multiple hierarchical levels have offered new avenues for fast exploration of the design spaces.The performance of a ML-based materials design approach relies on the collection or generation of a large dataset that is properly preprocessed using the domain knowledge of materials science underlying chemical and physical concepts, and a suitable selection of the applied ML model.Recent breakthroughs in ML techniques have created vast opportunities for not only overcoming longstanding mechanics problems but also for developing unprecedented materials design strategies.In this review, we first present a brief introduction of state-of-the-art ML models, algorithms and structures.Then, we discuss the importance of data collection, generation and preprocessing.The applications in mechanical property prediction, materials design and computational methods using ML-based approaches are summarized, followed by perspectives on opportunities and open challenges in this emerging and exciting field.</p>
<p>Introduction</p>
<p>Materials are of significant importance to us as they are the building blocks of the tools to develop our civilization.Numerous effective methods to find new materials have been invented owing to the discovery of the intimate connection between the structure of materials and their various properties, which can be tentatively classified into mechanical, thermal, optical, electrical, chemical, nuclear, and others. 1 Among those properties, mechanical properties of materials are of particular interest owing to their intimate relationship with the integrity of structures, which ensures that the materials can consistently work as designed without mechanical failures like material degradation, cracking, buckling and delamination.Design of mechanical materials is the process of tailoring the composition and structure of materials to achieve desired or even unprecedented mechanical properties, which are of great importance to many families of advanced materials.4][5][6][7][8] Another emerging category of composites that are rationally designed, called metamaterials, have attracted great interest due to their unprecedented properties compared to conventional materials, attributed to the breakthroughs in experimental techniques and computer-aided optimization tools to design complex material structures. 9,102][13][14] The complexity of compositional and topological structures of advanced materials, however, can easily lead to massive design spaces that exceed the computational limit of brute force approaches and other conventional design algorithms, implying the need for new design approaches.</p>
<p>Over the past a few decades, it has been found that artificial intelligence (AI), a study of computations which perceive, reason, and act like human beings, has the potential to address these challenges. 15Specifically, the most promising one is an approach to AI called machine learning (ML), which can discover the mapping from high-throughput input data to output that is used to make decisions.In simple ML algorithms, the representation of input data is hand-designed by researchers, and each piece in the representation is referred to as a feature.Yet, it was extremely challenging to manually extract appropriate features from some sort of raw data that are easy to understand for human but difficult for machines, i.e., photographs of streets where cars are supposed to be recognized, until the emerge of deep learning (DL), a specific type of ML that can not only learn the representation of the input data but also parse the representation into multiple levels-from simple features to abstract ones-attributed to complex neural network structures. 16ML, especially DL, has achieved many exciting breakthroughs in algorithms and led to great success in computer vision, natural language processing and autonomous driving. 17Materials and mechanics communities are aware of the great opportunities of leveraging ML as a potential new paradigm.9][20][21] In the meantime, numerous research articles in this topic are coming out, and so do reviews of ML in specific materials or mechanics branches, involving energy materials, 22,23 glasses, 24 composites, 25 polymers, 26 bioinspired materials, 27 additive manufacturing, 28,29 continuum materials mechanics, 30 and so on.</p>
<p>In this review, we focus on reviewing the growth and state of the art of research efforts on mechanical materials design using ML, and also attempt to depict a general methodology for performing ML-based mechanical materials researches.As schematically shown in Fig. 1, a typical workflow for combining ML and materials research consists of three key components: (i) a wellorganized material dataset either collected from literature and Professor of Engineering at MIT and directs the Laboratory for Atomistic and Molecular Mechanics.His primary research interests focus on the structure and mechanical properties of biological and bioinspired materials, to characterize, model, and create materials with architectural features from the nano-to the macroscale.His work explores theory, computation and experimental approaches in order to understand and manufacture materials, and his research further investigates interfaces of science and art.</p>
<p>existing databases or generated from experiments and simulations;</p>
<p>(ii) a ML model that is capable to learn and parse the representation for certain tasks; and (iii) a well-defined research problem of mechanical materials that has not been addressed by conventional methods, or has been solved but can be outperformed by ML-based approaches.A ML-based material research needs to glue all of these three components together, and a crucial step is the preprocessing of the raw material database into an appropriate numerical representation, also referred to as a descriptor.The preprocessed data should match the input data structure required by the selected ML model, and consist of essential material features to ensure high accuracy and training efficiency.A highquality preprocessing requires not only expertise in mechanics and materials science, but also domain knowledge in related ML models.The former tells how to identify a challenging mechanical materials problem, acquire a database, and devise data preprocessing.The latter helps to select a suitable ML model to leverage and maximize its strength in given tasks, from prediction of mechanical behaviors of target materials, design of de novo mechanical materials, to development of new computational approaches.</p>
<p>To further discuss the foregoing methodology with the aid of present works in the literature, the paper is organized as follows.We begin with a brief summary of state-of-the-art ML models, algorithms and architectures.Readers can skip the description of the methods if they have already been familiar with them.To learn more about the methods of interest, we refer to the research articles and reviews cited in this section in which more details about the algorithms and examples are presented.Then we move on to a discussion of approaches to collect or generate datasets that are amenable to the ML models, followed by a review of existing applications of ML methods to various mechanical materials design problems.In these sections, inspiring strategies for data preparation, preprocessing, materials problem and ML model selection are highlighted.The paper is concluded with a few perspectives on the new computational paradigm that integrates mechanics and materials science with ML techniques.</p>
<p>A Brief summary of ML models, algorithms and structures</p>
<p>General ML approaches can be classified into three categories known as supervised learning, unsupervised learning and reinforcement learning (Fig. 2).Supervised learning is a taskdriven approach to map inputs to outputs with data being labeled (known as the ground truth) during training, while unsupervised learning are data-driven methods trained with unlabeled data to search for undetected patterns of the given dataset.Reinforcement learning is fairly different compared to supervised learning and unsupervised learning which can be distinguished by the presence of labels.Reinforcement learning focuses on interaction between agents such as Go player with the environment such as chessboard.Both supervised learning and unsupervised learning evaluates the model's performance by minimizing a loss function or objective function.By contrast, the objective of reinforcement learning is to maximize the notion of cumulative reward.There is another category of ML approaches called semi-supervised learning.As the name implies, it lies between supervised and unsupervised learning due to the use of both labeled and unlabeled data (generally mostly unlabeled) during training.In the current field of mechanical materials designs, supervised learning approaches are most widely used as supervised tools are more accurate and mature to implement compared to the tools in other categories.Due to rapid and constant development of ML, the methods listed in the section, which cannot claim to be an exhaustive enumeration of existing ML approaches, briefly summarizes some of them that are feasible for designs of mechanical materials to the best of our knowledge.</p>
<p>Within this context, the simplest forms of ML without complex multilayer structures are classical ML algorithms.Linear regression (LIR) 31 is one of the simplest algorithms aimed to find a linear relation between the input features and continuous output.Least Absolute Shrinkage and Selection Operator (LASSO) 32 is a modification of LIR with additional absolute value penalization added to the loss function.Another reasonable extension of LIR is polynomial regression (PR) 31 which includes polynomial terms in finding linear solutions.To further support non linearity, regression algorithms such as support vector regression (SVR) 33 and random forest (RF) 34 are introduced.These nonlinear models usually handle outliers better and show higher accuracy than linear models.Apart from regression, the other major category of ML tasks is classification.Instead of predicting specific values such as housing prices, the classification algorithms classify input into predefined categories.An example of classification algorithms is logistic regression (LOR), 35 which is a classification algorithm with a loss function in logistic form despite it is named with ''regression''.There are many other classical ML algorithms which can handle both regression and classification problems such as decision tree (DT) 36 and gradient boosting. 37,38eyond classical ML techniques, scientists have developed artificial neural networks (ANNs), loosely inspired by the interconnected neurons in human brains, for deep data mining.The original idea is derived from perceptron, a simple precursor formulation dating back to 1958. 39By stacking multiple layers of neurons, a network structure is developed to learn nonlinear relation between input and output or delicate data distribution.As the depth of layer-by-layer networks increases, the resulting DL models offer tremendous impacts in computer science and various related interdisciplinary areas.</p>
<p>Feedforward neural networks (FFNNs) or multilayer perceptron (MLP) 40,41 are probably the simplest and quintessential DL models.As the names indicate, the information passes through the network in a unidirectional manner for FFNNs.More specifically, each layer which consists of multiple neurons computes the output to the next layer based on the input from the previous layer.The weights or trainable parameters used for calculation for each neuron are optimized to minimize the loss function.In order to approach the minimum of the loss function during the training process, back propagation (BP), a widely used technique in ANNs training, is implemented together with gradient descent (GD) algorithm. 42BP functions as similar as calculating derivatives and GD algorithms determine the direction to jump down to the minimum.The process iterates until the loss function is close to its minimum.</p>
<p>Besides general FFNNs, two types of DL architectures are gaining vast attention due to their applications in computer vision and natural language processing (NLP), known as convolutional neural networks and recurrent neural networks.</p>
<p>Convolutional neural networks (CNNs) were first introduced in 1980, 43 and reformulated in 1999. 44CNNs are image-based DL architecture by calculating mathematical operation ''convolution'' to extract features of images.Convolution preserves the spatial relationship between pixels and is calculated by multiplying the image matrix with the filter matrix.Filters contain trainable weights which are optimized during training for feature extraction.With different filters, separate operations such as edge detection can be performed to one image.By stacking the convolutional layers, simple features will be gradually assembled to intact and complicated ones. 45The CNNs are applied to and show exciting performances in face recognition, images classification and object detection. 40In materials design problems, with the capacity of capturing features at different hierarchical levels, CNNs are well suited to describe the properties of materials (which innately have hierarchical levels), especially biomaterials.These hierarchical features are not just found in materials, but in many other representations of matter, sound and language, and hence universal to the description of key societal systems. 46,47ecurrent neural networks (RNNs) also gain popularity due to their capability of dealing with sequential data.In CNNs, inputs and outputs are supposed to be independent of each other, which might not be suitable for some tasks that emphasize the sequence of the data.For instance, given an incomplete sentence, it would be difficult to predict the next word if the sequential structure of the sentence is omitted.Instead, RNNs act on the sequential data with the output being depended on the previous and later sequence and utilize ''memories'' in determining output of each layer or state.For RNNs with large depth, the gradient calculated by BP easily Fig. 2 A brief overview of ML approaches, including three major categories known as supervised learning, unsupervised learning and reinforcement learning.ML approaches such as linear regression (LIR), support vector regression (SVR), feedforward neural networks (FFNNs), multilayer perceptron (MLP), convolutional neural networks (CNNs) and recurrent neural networks (RNNs) are generally used for supervised learning.Typical approaches to unsupervised learning include k-means clustering, autoencoder and generative adversarial networks (GANs).Reinforcement learning follows a general interactive loop between the agent and the environment.The difference between supervised and unsupervised learning is determined by whether training data is labeled or unlabeled, and there is a category of tasks between them called semi-supervised learning, which combines labeled and unlabeled data (generally mostly unlabeled) during training.It is worth pointing out that some of the aforementioned ML methods are not merely limited to the tasks illustrated in this schematic.For instance, graph neural networks (GNNs) have been widely used for semi-supervised learning tasks, but they are also applicable to supervised and unsupervised learning tasks involving graph representation.</p>
<p>vanishes or explodes. 48,49To address this issue, plenty of mechanisms including Long short-term memory (LSTM), 50 Gated recurrent unit (GRU), 51 ResNet 52 and Attention 53,54 have been developed, increasing the impact of RNNs in NLP tasks such as language translation and speech processing.][57] Generative models have been established to generate new data points based on the distribution of existing data.An intriguing and successful category of architectures among them are generative adversarial networks (GANs), 58 which consist of two neural networks, the generator and the discriminator.The generator proposes new data instances and the discriminator compares the generated data with the real data.These two components contest with each other during the training as the generator aims to ''fool'' the discriminator by producing more genuine images while the discriminator attempts to distinguish real images from false images as accurately as possible.GANs reach convergence when the generator and the discriminator are at Nash equilibrium.The process of balancing the performances of the generator and the discriminator is somewhat similar to equilibrating a physical system with both attractive and repulsive forces which indicates that GANs can potentially shed light on describing physical phenomena.Furthermore, with the objective of generating fake data with restricted conditions or characteristics, a subtype of GANs named conditional GANs (cGANs) 59 have been developed which include labels as a control variable.One of the applications of cGANs is image-to-image translation 60,61 in which an image is used as the constrain of the generator.Unlike GANs, variational autoencoder (VAE) 62 is another type of generative models that uses one neural network which first encodes the input data into an inexplainable code named as latent code and then decodes the latent code to reconstruct the output.</p>
<p>ML methods can also be used to evaluate and improve the performance of other applied ML models.Bayesian learning (BL) 40 is an approach used for parameter estimation and probability comparison to evaluate a given algorithm.Gaussian process regression (GPR) 63 is a nonparametric approach which can provide uncertainty measurements of predictions and build reduced-order models based on Bayesian learning.These approaches are potentially useful for mechanical materials designs problems as they are suitable for relatively small datasets and are working well without prior knowledge of model forms.Moreover, active learning is a learning algorithm that interactively inquires the user and selects data to be labeled. 64Training data would be augmented in an active learning loop with post-hoc experiments or simulations.For further discussion on the application of active learning in materials science, we refer to a recent review paper. 65einforcement learning (RL) is an area of ML in which the agent takes action based on the variation of the environment to maximum long-term gains. 66The training process is aiming at finding a balance between exploration (of uncharted territory) and exploitation (of current knowledge). 66From 2014 to 2017, the presence of AlphaGo, 67 a RL-based AI was able to beat top-notch Go players, showing the power of RL and its potential applications to materials problems such as interactive materials design.</p>
<p>Graph neural networks (GNNs), unlike standard neural networks operating on Euclidean data, operate on graphs that have non-Euclidean data structures consisting of nodes connected by edges without natural orders. 68Recent breakthroughs in GNNs, such as graph convolutional networks (GCNs), 69 have demonstrated the capability of GNNs to learn graph embeddings through message passing between the nodes and its outstanding performance on semi-supervised classification tasks, which are potentially applicable to many materials and mechanics problems that inherently consist of graph structures.</p>
<p>Popular ML models and algorithms used in the design of mechanical materials, along with example applications, are tabulated in Table 1.</p>
<p>Data collection, generation and preprocessing</p>
<p>If ML models are the engines to tackle various tasks, then data is the fuel to power the models.Sufficient amount of data is a prerequisite to make the models work, and high-quality data enable the models to run efficiently.Nevertheless, there arise several vital and difficult questions: how much data is sufficient?How to obtain those data?What is the quality of the input data?And how to improve it?These questions are crucial for the ML-based design of mechanical materials since the data relate the mechanics problems of interest to the applied ML models.Researchers can either collect data from the literature or existing databases, or generate their own databases via highthroughput experiments or simulations (Fig. 1).Feeding the raw data into the ML model is usually accompanied with the following issue: when the data is either too easy or too hard to be obtained, it would be unnecessary or difficult to implement ML-based methods for solving the problem.For instance, there is no need to use ML if the existing method can travel through the entire design space at an acceptable cost, and a more common scenario is that the obtained datasets only cover a small portion of the design space.It is also possible that the collected databases of images or texts are understandable for human but uninterpretable for machines.In those cases, the raw data are, in general, required to be preprocessed before fed into the ML model, emphasizing the importance of leveraging the domain knowledge of the researchers to obtain representative data and perform data preprocessing in a proper manner for better results from the ML model.[76][77][78][79][80][81] Data collection from existing databases or literature</p>
<p>The advent of high-throughput computational materials design leads to the construction of many materials databases, 82 such as AFLOW, 83 Materials Project (MP), 84 MATDAT, 85 MatWeb, 86 MatMatch, 87 MakeItForm, 88 and MatNavi. 89These databases consist of enormous materials properties obtained from experimental measurements and first-principles calculations, including mechanical properties like elastic constants, tensile/ flexural/shear/fatigue strengths, fracture toughness, hardness, and so on.Detailed mechanical features of these databases are listed in Table 2.According to the mechanical problems of interest, sub-datasets of specific properties or material classes can be filtered and collected effectively through the online platforms of those databases.For instance, mechanical properties of inorganic compounds from the MP database have been systematically explored. 90In a separate study, more than one hundred vanadium oxide materials along with various unique compositions have been found in the MP database. 91In order to train DL models, this dataset has been significantly enlarged via a virtual substitution of existing binary materials.As an inspiring example, Raccuglia et al. have leveraged the unreported entries about failed experiments from their archived laboratory notebooks to build a database for use in training and testing the applied ML model. 92abeled datasets can be obtained from surveying the literature as well, such as datasets of copper alloys with different tensile strengths and electrical conductivities, 93 ABO 3 compounds, 94 high-temperature ferroelectric perovskites, 95 and single-molecule magnets. 96In addition, a glass dataset of experimental data was Prediction of modulus distribution by solving inverse elasticity problems; 138 prediction of strain or stress fields in composites; 139 composite design; 164 structural topology optimization; [165][166][167] architected materials design 115 Gaussian process regression (GPR); Bayesian learning</p>
<p>Treat parameters as random variables and calculate the probability distribution of these variables; quantify the uncertainty of model predictions</p>
<p>Modulus 122 or strength 123,124 prediction; design of supercompressible and recoverable metamaterials 110 Active learning Interacts with a user on the fly for labeling new data; augment training data with post-hoc experiments or simulations Strength prediction 124 Genetic or evolutionary algorithms</p>
<p>Mimic evolutionary rules for optimizing objective function</p>
<p>Hardness prediction; 126 designs of active materials; 160,161 design of modular metamaterials 162 Reinforcement learning Maximize cumulative awards with agents reacting to the environments.</p>
<p>Deriving microstructure-based traction-separation laws 174 Graph neural networks (GNNs)</p>
<p>collected from both literature and existing databases. 97The size of the collected dataset relies heavily on the amount of accumulated literatures in the corresponding field.Relatively small datasets with tens to hundreds data points are acceptable for optimization approaches if equipped with an active learning loop. 95,98urthermore, text processing techniques can be utilized to replace manual labor in the extraction of features from research articles.With NLP techniques adopted, an automated workflow of article retrieval, text extraction and database construction was developed.to build a dataset of synthesis parameters across 30 different oxide systems, which is autonomously compiled and tabulated by training the text processing approach using over 640 000 materials synthesis journal articles. 99The materials synthesis databases obtained from this approach enable a broader applications of ML methods than before, such as the prediction of materials synthesis conditions 100 and candidate precursors for target materials. 101</p>
<p>Data generation</p>
<p>When performing high-throughput experiments or simulations, researchers have more freedom to design the features and control the size and distribution of the datasets to be generated.Nevertheless, a major challenge is to balance the expense of data generation and the resulting performance of the applied ML model.Existing works in the literature have shown that leveraging domain knowledge in materials science, solid mechanics and other related fields results in datasets that are more representative of the design spaces and thus display better results from the applied models.</p>
<p>Computational methods can be used to simulate materials of interest and relate the mechanical properties to the representative structures of the materials at different scales, from continuum to atomistic levels.For example, finite element method (FEM) was implemented to generate datasets of three-dimensional (3-D) microstructures of high-contrast composites, [102][103][104][105][106] two-dimensional (2-D) tessellate composites, [107][108][109] and metamaterials. 110Yang et al. created a dataset of synthetic microstructure images of materials with various compositional and dispersive patterns using Gaussian random field (GRF) method. 111High-throughput molecular dynamics (MD) can be utilized as a design space sampling method for the atomistic structures and behaviors of materials like silicate glasses, 112 metal-organic frameworks (MOFs), 113 as well as brittle materials with different crystal orientations. 114 framework for data-driven analysis of materials has been built to avoid unacceptable computational expense of data generation from high-fidelity analyses, such as FEM simulations involving plasticity and damage, and reduced order methods were utilized to generate large databases suitable for ML. 77,78,81It is also possible to reduce the scale of design spaces by considering the symmetries in the materials problems to be investigated.The design spaces of 2-D tessellate composites under symmetric loadings can be truncated by half, [107][108][109] and the generated topologies of architected materials were classified into 17 datasets according to the crystallographic symmetry groups in 2-D space. 115enchmark databases, such as MNIST, 116 are particularly useful for comparing the accuracy and efficiency of various ML techniques on specific tasks.Recently, a benchmark dataset named Mechanical MNIST was constructed by converting the MNIST bitmap images into heterogeneous blocks of materials. 117This dataset, labeled by different forms of mechanical responses calculated from FEM simulations, can be used to evaluate the performance of metamodels of heterogeneous materials under large deformation.</p>
<p>Performing experiments to create sufficient large datasets for training DL models is currently difficult due to the extremely high cost.However, high-throughput experiments are applicable to the validation of trained ML models, 118 and relatively small training sets can be augmented via post-hoc experiments in an active learning loop. 95,98Recently, an autonomous research system has been built to enable not only automated experimentation but also the selection of subsequent experiments under a framework of Bayesian optimization, which can be utilized to mechanical materials design problems such as optimization of additive manufacturing structures. 119</p>
<p>Data preprocessing</p>
<p>ML models expect certain data structures (i.e., images, texts, graphs) as input and thus the datasets need to be preprocessed before fed into the applied model.During preprocessing, data augmentation techniques can be implemented to enlarge the datasets, and irrelevant data points that would deteriorate the performance of the model should be removed.In a recent work on the prediction of fracture patterns in brittle materials, the discrete atoms in a triangular lattice, which is adopted from the MD simulations to generate the datasets of crack patterns, were mapped into ordered pixels in an image that can not only be treated as input to the first convolutional layer of the applied LSTM model but also eliminate the irrelevant information in the atomic structure other than the spatial features of the crack. 114In another example, least angle regression (LARS) was utilized as a feature selection algorithm for a large glass dataset taken from the literature and online databases. 97Image processing techniques, such as rescaling and cropping, were utilized to augment the initial dataset that might be insufficiently large to train a DL model. 120It has been demonstrated that less efforts on preprocessing are required to design features for DL than conventional ML methods due to the ability of the DL models to parse the representation from simple to abstract features through the training process. 121The techniques used to develop data-driven solvers might also inspire efficient methods to process sparse and noisy data of materials responses. 70,71</p>
<p>Applications</p>
<p>Prediction of mechanical behaviors</p>
<p>The ML models, trained on the datasets containing materials information, are supposed to give fast and accurate predictions of target mechanical properties or behaviors, or to discover compositions or structures that outperform the training data in the design space.</p>
<p>Materials with complex and disordered microstructures, such as glasses and alloys, typically have large databases obtained from experiments or simulations focusing on composition-property relationships.Thus, the selected features like concentrations of components are usually arranged as feature vectors, and ML methods good at processing input vectors are particularly suitable for the property prediction tasks of these materials.For instance, different ML algorithms (PR, LASSO, RF and MLP) were adopted to predict the Young's modulus of silicate glasses. 112Among those methods, MLP gives the highest accuracy, and the LASSO algorithm offers a slightly lower accuracy but higher simplicity and interpretability of the model.It is subsequently shown that using GPR instead of neural networks can avoid overfitting for a sparse dataset. 122ecently, a large dataset obtained from the literature and glass datasets was preprocessed to train deep FFNNs that allow the design of eight essential properties of oxide glasses, including Young's modulus, shear modulus and hardness. 97Wang et al. developed a design system based on neural networks for copper alloys that can rapidly screen the composition design space and provide the compositional design of new copper alloys with a target ultimate tensile strength and electrical conductivity. 93To discover strong and conductive copper alloys, Zhao et al. recently reported a systematic study of the selection of ML models (LIR, SVR, regression tree and GPR), dimensionality reduction techniques (principal component analysis, correlation-based and genetic algorithm) and additional features. 123For gradient nanostructured metals, Gaussian process based active learning surrogate models were developed to study the structural gradient effects on strength and deformation mechanisms. 124Furthermore, new superhard materials were proposed with the aid of ML techniques such as SVR, 125 evolutionary algorithms, 126 and GNNs. 127In a study by Wen et al., high entropy alloys predicted by the applied ML models were synthesized, showing higher hardness values than any other sample in the training dataset. 128ML models can also be trained to capture the relationship between salient structural features and mechanical properties.For example, deep neural networks that were trained to learn the relationship between the geometric patterns and mechanical responses of non-uniform cellular materials are capable of solving both forward and inverse problems. 129Liu et al. have achieved the fracture toughness prediction of polycrystalline silicon specimens using two different ML algorithms, RFs and FFNNs. 130In a recent study, the strength and toughness of spider webs were predicted by using a neural network trained with fiber lengths and orientations, as well as web connectivity and density. 131L-based prediction of mechanical properties can also be achieved using atomistic descriptors.For example, local properties (bond length, angle and dihedrals), global properties (density or ring sizes distribution) and porosity-related properties were fed as entries into a gradient boosting regressor to predict mechanical properties of zeolite frameworks. 132,133Given the system temperature, strain rate, vacancy defect and chirality, mechanical properties of single-layer graphene were predicted using different ML algorithms (stochastic gradient descent, k-nearest neighbors, SVR, DT, ANN). 134In a separate work by Moghadam et al., the relationship between the structure and mechanical stability of thousands of MOF materials has been established to predict the bulk modulus of MOF materials using an ANN that inputs structural or topological descriptors. 113or materials that can be represented as tessellated spatial grids of multi-phase voxels, CNNs are advantageous over conventional ML methods in learning embeddings at different length scales ranging from voxels to representative volume elements (RVEs).3][104][105] Convolutional networks with different architectures were used to predict the mechanical properties of polymer nanocomposites based on microstructure images, 135 thermo and mechanical properties of unidirectional composites, 136 and stress fields in cantilevered structures. 137In particular, Herriott and Spear implemented two conventional ML methods (Ridge regression and gradient boosting) and a CNN model to predict the effective yield strength of additive-manufactured metals. 121When 3D images of the microstructures represented by crystal orientation are input to the CNN model, it outperforms the other two methods fed with microstructural features, demonstrating the strengths of CNN in learning higher-level features directly from image data and reducing the efforts on preprocessing and feature extraction.</p>
<p>The capability of generative models to deal with image-toimage translation tasks can be harnessed to achieve fast conversion between material distribution and mechanical fields.Ni and Gao developed a cGAN model to address the inverse elasticity problem of calculating elastic modulus distribution from observed displacement or strain fields in inclusion systems, mimicking an application scenario for real-time elastography and high-throughput non-destructive evaluation techniques. 138Recently, Yang et al. introduced a deep learning approach which predicts complex strain or stress fields of hierarchical composites directly from geometric information. 139Image-to-image translation using GANs has been implemented to investigate mechanical systems and exhibited astonishing performances in reproducing mechanical fields, extracting secondary information and extending to various loading conditions, component shapes and hierarchies.This framework could be further applicable to fast prediction of other physical fields with geometric information in image-based representation.</p>
<p>Mechanical problems involving nonlinearities such as plasticity, fracture and dynamic impact are known to be difficult and computationally expensive for conventional numerical simulation schemes.ML-based approaches have created new opportunities for addressing these long-standing problems.</p>
<p>For fracture problems, Pierson et al. developed a CNN-based methodology to predict the microstructure-sensitive propagation of a 3-D fatigue crack in a polycrystalline alloy based on the past crack surface. 140Guilleminot and Dolbow reported a datadriven framework that can generate new crack patterns in random heterogeneous microstructures through the combination of a manifold learning approach and a crack path reconstruction procedure. 141Moreover, Hsu et al. presented a ML-based approach combining convolutional layers and LSTM for predicting fracture patterns in crystalline solids based on atomistic molecular simulations (Fig. 4a). 114The proposed approach not only captures complex fracture processes but also shows good agreement regarding fracture toughness and crack length (Fig. 4b).The work further examined the crack propagation in more complicated crystal structures including bicrystalline materials and graded microstructures (Fig. 4c).The strong predictive power of their approach can be potentially applied to design materials with enhanced crack resistance.</p>
<p>For nonlinear deformation problems, Mozaffar et al. recently established a data-driven framework consisting of RNNs to learn history-dependent behaviors of heterogeneous RVEs loaded along different deformation paths, and it has enabled the prediction of plasticity-constitutive laws in an efficient and accurate manner without adopting the widelyused assumptions in existing plasticity theories (Fig. 5). 142uang et al. developed a hyperelastic model using FFNNs and a plasticity framework via a combination of FFNNs and Proper Orthogonal Decomposition (POD). 143Yang et al. trained a deep residual network that can predict crystal plasticity using high-throughput discrete dislocation simulations. 120Wu et al. designed a RNN based on GRU to predict the stress-strain evolutions of elasto-plastic composite RVEs subjected to random loading paths. 144Yang et al. utilized ANNs to construct constitutive laws for isotropic hardening elastoplastic materials with complex microstructures. 145In a study by Zhou et al., a discrete dislocation dynamics model of straight dislocations on two parallel slip planes was self-consistently transformed into a continuum model via the integration of asymptotic analysis and ML methods. 146Chen et al. utilized DL models to find the inverse solution to collision load conditions with the post-collision plastic deformation of shell structures given. 147Stern et al. reported a framework for supervised learning in thin creased sheets which can not only accurately classify the patterns of training forces but also generalize to unseen test force patterns, demonstrating how learning can be achieved from plasticity and nonlinearities in materials. 1480][151][152][153]</p>
<p>Topological design</p>
<p>Designing topological structures of multi-phase materials such as composites or architected materials is intractable in some aspects for conventional optimization methods due to the dauntingly large design spaces, while ML-based models have the capability to explore the design spaces more efficiently and to find unprecedented designs with better performance than the structures in training sets.</p>
<p>2-D structures of materials can be represented as pixel images, fed as input to image processing models like CNNs and GANs.These models can significantly enlarge the design spaces to be explored for the optimal design, and the design process can be furtherly accelerated through the integration of appropriate optimization algorithms in the workflow.For instance, Gu et al. used CNN to design tessellate composites with optimized strength and fracture toughness (Fig. 6a-d). 107,108NN was applied to extract local patterns of the composite around the crack tip in the framework.In these problems, the scale of the design space increases exponentially with the number of grid elements in the composites, and finding the optimal design can be easily intractable for brute-force approaches by elevating the grid resolution.In order to address this issue, Yu et al. integrated the CNN model with a genetic algorithm to accelerate the search process using the ML prediction as the fitness function for the optimization algorithm (Fig. 6e and f). 109In a study by Hanakata et al., a CNN-based search algorithm was developed to find optimal arrangements of kirigami cuts in graphenes to maximize stretchability. 1557][158] Since the models were trained with the structures that have already been optimized by standard optimization methods, direct evaluation of mechanical properties (e.g., compliance) in loss functions can be avoided.As a trade-off, designs predicted by ML models may have mechanical incompatibility such as structural discontinuity, but these issues can be refined by connecting a cGAN model to the trained encoder and decoder network. 156Different from a pixel-based representation, a structural topology optimization method has been achieved through the movement of morphable components as basic building blocks, and both SVR and the k-nearest neighbors algorithm were adopted to extract the mapping between the external load and design parameters. 159ven though this approach shrinks the design space, it can  142 avoid mesh dependency and model complexity issues induced by preprocessing structures into pixel images.</p>
<p>Topological design approaches using other ML techniques have also been widely reported in the literature.For example, structural designs of active composite beams and hardmagnetic soft active materials with target deflected shapes were obtained using evolutionary algorithms. 160,161Recently, Wu et al. reported an approach to design modular metamaterials using genetic algorithm and neural networks. 162They applied the method to the design problems of phononic metamaterials and optimization problems of interconnect for stretchable electronics.Kumar et al. built an inverse design framework of spinodoid metamaterials using deep neural networks that can provide optimal topologies for desired properties. 163everaging the strengths of advanced ML techniques usually offers new pathways for the design of mechanical materials.</p>
<p>Bayesian machine learning is a powerful approach for handling noisy data and can quantify the uncertainty of model predictions, which are particularly useful for design of metamaterials that are often sensitive to manufacturing imperfections.Bessa et al. demonstrated that data-driven designs of supercompressible and recoverable metamaterials made of brittle polymeric base materials can be found with the aid of Bayesian machine learning methods (Fig. 7). 1106][167] Mao et al. harnessed GANs to acquire hundreds of designs of 2D periodic units in architected materials that approach the Hashin-Shtrikman upper bounds and at the same time attain desired crystallographic symmetries and porosities. 115Other work reported the development of a semi-supervised approach to design architected materials using GNNs and the analogy between architected materials and graphs, that is, truss elements to edges, and truss pin joints to nodes. 168Graph connectivity and the load levels of a small fraction of nodes are fed as input to the GNNs that can predict the distribution of the load levels of the remaining nodes, and then the GNN model is integrated with a design algorithm to engineer the topological structures of the architected materials.</p>
<p>Development of new computational methods</p>
<p>[73]77,78 Recently, the integration of data-driven frameworks with ML algorithms have offered new perspectives for computational approaches for modeling mechanical phenomena of materials at multi-level scales.</p>
<p>For instance, in order to solve nonlinear heterogeneous structure problems, neural networks have been used in a decoupled computational homogenization method where the effective strain-energy density is first computed at discrete points in a macroscopic strain space and then interpolated on RVEs. 76Inspired by the previous method, a data-driven framework aiming to model and design new composite material systems and structures has been built, accompanied with a method called self-consistent clustering analysis that make the framework applicable to materials problems involving irreversible deformation. 78][171][172] Wang and Sun leveraged RNNs and the concept of directed graph to address the issues on the linkages between multi-scale models of porous media using a recursive data-driven approach, where the databases generated from smaller-scale simulations are used to train RNN models at larger scales (Fig. 8). 173They also implemented reinforcement learning to generate tractionseparation laws for materials with heterogeneous microstructures. 174puano and Rimoli developed a new type of finite elements called ''smart elements'' in which ML models provide force predictions based on the elements' states, circumventing the computation of internal displacement field and the need for numerical iterations. 175han et al. reported an unsupervised approach that combines techniques such as topology classification, image processing, and clustering algorithms to promptly identify and characterize microstructures, including grains in polycrystalline solids, voids in porous materials, and micellar distribution in complex solutions (Fig. 9). 176n a recent work by Samaniego et al., deep neural networks based on the variational form of the boundary value problems were implemented as solvers for partial differential equations (PDEs) in various solid mechanics problems, using a fundamental idea that the energy of the system to be minimized can be naturally treated as a loss function for the neural networks. 177</p>
<p>Perspectives</p>
<p>A straightforward benefit ML brings to materials and mechanics researches is promoting the efficiency of materials designs via experiments and simulations.Exploring a massive design space of novel materials is often intractable for brute force approaches and too complicated to achieve using physical intuition.Instead, ML-based design approaches can incorporate materials and mechanical features during the preprocessing of input data, learn the relationship between materials structures and mechanical behaviors during training, and provide targeted designs using the trained models.It should be pointed out that ML algorithms may not necessarily be beneficial when dealing with material problems in which the overall cost of training and design procedures is more expensive than standard approaches.A promising way to elevate the performance of ML-based methods in those problems is to encode scientific knowledge not only in data preprocessing but also in neural networks architectures.In this regard, recent development in physics-guided ML frameworks, such as physics-informed neural networks (PINNs) in which governing equations in the form of PDEs are incorporated into loss functions, 178 offers new perspectives for the integration of ML and mechanical materials design.</p>
<p>ML approaches that can discover new physics may have a broad application in materials and mechanics researches.It has shown that ML can be trained to learn symbolic expression of physical laws.Well-known physics concepts including Hamiltonian, Lagrangian are predicted by symbolic regression. 179Brunton et al. revealed governing equations underlying a dynamical system with ML algorithms. 180Recent ML work using GNN has shown that the algorithms are capable to discover new analytical solutions for dark matter mass distribution. 181These works derived governing equations in a unique way and may offer a potential new direction for understanding the mechanisms and mechanical behaviors of various materials.</p>
<p>As summarized in this review, most of current researches focus on applying ML algorithms to solve materials and mechanics problems.Yet, it is worth pointing out that mechanical insights also have the potential to facilitate the development of ML.Geiger et al. showed that loss landscape of deep neural networks can be interpreted with a paradigm based on jamming transition. 182nspired by information process in natural neural networks, spike neural networks (SNNs) transmit sparse and asynchronous binary signals between neurons which incorporates time into deep learning networks.As a consequence, SNNs have exhibited favorable properties including low power consumption, fast inference, and event-driven information processing. 183Despite the popularity of ML systems, they are arguably treated as ''black boxes'' due to the difficulty of inspecting how and why those algorithms can make accomplishments.The known knowledge in mechanics and materials science may help us understand the mechanisms behind ML algorithms and develop new learning techniques that can tackle challenging problems in materials design, such as design of hierarchical structures or multifunctional materials with desired overall performance of a set of material properties.</p>
<p>So far, the potential of using ML in design of mechanical materials has not been fully exploited yet with opportunities and challenges lying ahead to be explored and overcome.It is promising that ML-based approaches will revolutionize the way we understand and design materials.</p>
<p>List of abbreviations</p>
<p>Fig. 1
1
Fig.1Schematic of a typical workflow for design of mechanical materials using ML.With a material problem in mind, researchers encode their domain knowledge into the preprocessing of the data collected or generated from the literature, existing databases, high-throughput experiments and simulations, resulting in input data with appropriate representation that can be learned by the selected ML model, which is able to predict mechanical behaviors and/or provide novel designs of the mechanical materials of interest after training.</p>
<p>Fig. 3
3
Fig. 3 Predicting elastic behaviors of high-contrast composites using convolutional neural network (CNN).(a) An example microscale volume element, and (b) a comparison of strain field prediction from FEM and statistical models.(Licensed under CC-BY). 104(c) The compositional structures (top) and spatial statistics (bottom) of three example generated microstructure volume elements, (d) a schematic of the applied 3-D CNN architecture, and (e) a selection of three learned filters that help to distinguish microstructures similar to the three examples shown in (c), respectively (Reproduced with permission. 103Copyright 2017 Elsevier).</p>
<p>Recently, Lu et al. demonstrated a general framework for extracting elastoplastic properties of materials from instrumented indentation results with significantly elevated accuracy and training efficiency, which have been furtherly improved by considering known physical and scaling laws and by utilizing transfer learning techniques when additional new experimental data are available.154</p>
<p>Fig. 4
4
Fig. 4 Predicting dynamical fracture using a deep learning approach, dependent on microstructural details.(a) Workflow of fracture patterns prediction.(b) Comparison of crack path, length and energy release between molecular simulations and the ML approach.(c) Prediction of crack patterns in bicrystalline and gradient materials (Reproduced with permission. 114Copyright 2020 Elsevier).</p>
<p>Fig. 5
5
Fig. 5 Learning history-dependent plasticity using recurrent neural networks.(a) Schematic of sampling temporally deformation paths.(b) A deformed heterogeneous representative volume element (RVE) with distributed circular fillers in the generated database.(c) Comparison of the results predicted by recurrent neural networks and calculated from FEM analyses for two different RVEs under different loading conditions (Licensed under CC-BY).142</p>
<p>Fig. 6
6
Fig.6ML-based tessellate composites design for optimal strength and fracture toughness.(a) Workflow of the ML approach for the prediction of mechanical properties of composites.(b) Ranking comparison between the results from the ML approach and FEM simulations.(c) Optimal designs regarding strength and toughness in mode I test at various resolutions (Reproduced with permission.107Copyright 2017 Elsevier).(d) Extended implementation to composites consisting of anisotropic building blocks (Licensed under CC-BY).108(e) Framework embedded with genetic algorithm to accelerate the design process and (f) optimal designs in mode II test validated by MD simulations (Reproduced with permission.109Copyright 2019 IOP Publishing Ltd).</p>
<p>Fig. 7
7
Fig. 7 Data-driven design of supercompressible and recoverable metamaterials using Bayesian machine learning.(a) Workflow of the data-driven design approach of supercompressible metamaterials.(b and c) Mechanical testing of the obtained designs of (b) a recoverable and highly compressible metamaterial produced by fused filament fabrication using polylactic acid, and (c) a monolithic metamaterial manufactured by two-photon nanolithography (scale bars, 50 mm) (Licensed under CC-BY).110</p>
<p>Fig. 9
9
Fig. 9 An unsupervised approach for the identification and characterization of microstructures in 3-D samples of various material systems.(a) A workflow for autonomous microstructural characterization of 3-D polycrystalline solids.(band c) Results of the ML-based microstructural analysis method on the analysis of (b) voids in porous materials and (c) micellar distribution in complex solutions (Licensed under CC-BY).176</p>
<p>Table 1
1
Popular ML methods in design of mechanical materials
ML methodCharacteristicsExample applications in mechanical materials designLinear regression;Model the linear or polynomial relationshipModulus 112 or strength 123 predictionpolynomial regressionbetween input and output variablesSupport vector machine;Separate high-dimensional data space withStrength 123 or hardness 125 prediction; structural topologySVRone or a set of hyperplanesoptimization 159Random forestConstruct multiple decision trees forModulus 112 or toughness 130 predictionclassification or predictionFeedforward neuralConnect nodes (neurons) with informationPrediction of modulus, 97,112 strength, 93 toughness 130 ornetwork (FFNN); MLPflowing in one directionhardness; 97 prediction of hyperelastic or plastic behaviors; 143,145identification of collision load conditions; 147 design of spinodoidmetamaterials 163CNNsCapture features at different hierarchicalPrediction of strain fields 104,105 or elastic properties 102,103 oflevels by calculating convolutions; operatehigh-contrast composites, modulus of unidirectionalon pixel-based or voxel-based datacomposites, 136 stress fields in cantilevered structures, 137 or yieldstrength of additive-manufactured metals; 121 prediction offatigue crack propagation in polycrystalline alloys; 140 predictionof crystal plasticity; 120 design of tessellate composites; 107-109design of stretchable graphene kirigami; 155structural topology optimization 156-158Recurrent neural networkConnect nodes (neurons) forming a directedPrediction of fracture patterns in crystalline solids; 114 prediction(RNN); LSTM; GRUgraph with history information stored inof plastic behaviors inhidden states; operate on sequential dataheterogeneous materials; 142,144 multi-scalemodeling of porous media 173
Generative adversarial networks (GANs)Train two opponent neural networks to generate and discriminate separately until the two networks reach equilibrium; generate new data according to the distribution of training set</p>
<p>Table 2
2
High-throughput materials databases with mechanical features
Database nameMaterial categoriesMechanical featuresURLAFLOW 83Alloys; inorganic compoundsElastic propertieshttp://www.aflowlib.org/Materials Project (MP) 84Inorganic compounds; nanoporousElastic propertieshttps://materialsproject.org/materialsMATDAT 85Steels; aluminum and titaniumStatic properties; nonlinearhttps://www.matdat.comalloys; weld metals; etc.stress-strainbehaviors; cyclic stress-strainbehaviors; fatigue behaviorsMatWeb 86Polymers; metals; ceramics;Elastic properties; strength;http://www.matweb.comsemiconductors; fibers; etc.toughness; hardness; etc.MatMatch 87Metals; composites; ceramics;Elastic properties; strength;https://matmatch.compolymers; glasses; etc.toughness; hardness; etc.MakeItForm 88Metals; polymers; ceramicsElastic properties; strength;toughness; hardness; etc.
This journal is © The Royal Society of Chemistry 2021
Operate on non-Euclidean data structures; applicable tasks include link prediction, node classification and graph classificationHardness prediction;127 architected materials design168 
https://www.makeitfrom.com NIMS materials database (MatNavi)89 Polymers; inorganic materials; metals Elastic properties; strength; hardness; etc.https://mits.nims.go.jp/en/
Mater. Horiz., 2021, 8, 1153-1172 | 1163
Fig.8A multi-scale multi-physics framework for poromechanics problems driven by directed graph representation and recurrent neural networks (Reproduced with permission.173 Copyright 2018 Elsevier).
(a) A workflow for autonomous microstructural characterization of 3-D polycrystalline solids. (b and c) Results of the ML-based microstructural analysis method on the analysis of (b) voids in porous materials and (c) micellar distribution in complex solutions (Licensed under CC-BY).176 
Acknowledgements We acknowledge support by the Office of Naval Research (N000141612333), AFOSR-MURI (FA9550-15-1-0514), the Army Research Office (W911NF1920098), NIH U01 EB014976 and Ministry of Science and Technology (MOST), Taiwan, (MOST 109-2222-E-006-005-MY2 and MOST 109-2224-E-007-003-). Further, support from the IBM-MIT AI lab, MIT Quest, and Google Cloud Computing, is acknowledged.Conflicts of interestThe authors declare no conflict of interests.
M A Meyers, K K Chawla, Mechanical Behavior of Materials. Cambridge University Press20082nd edn</p>
<p>E J Barbero, Introduction to Composite Materials Design. CRC Press20173rd edn</p>
<p>. M A Meyers, P Y Chen, A Y M Lin, Y Seki, Prog. Mater. Sci. 532008</p>
<p>. P Y Chen, J Mckittrick, M A Meyers, Prog. Mater. Sci. 572012</p>
<p>. U G K Wegst, H Bai, E Saiz, A P Tomsia, R O Ritchie, Nat. Mater. 142015</p>
<p>. S W Cranford, M J Buehler, Biomateriomics. 2012Springer</p>
<p>. G X Gu, I Su, S Sharma, J L Voros, Z Qin, M J Buehler, S Sharma, Z Qin, I Su, G X Gu, M J Buehler, I Su, S Sharma, J L Voros, Z Qin, M J Buehler, J. Biomech. Eng. 210062016</p>
<p>. I Su, G S Jung, N Narayanan, M J Buehler, Curr. Opin. Biomed. Eng. 152020</p>
<p>. Y Liu, X Zhang, Chem. Soc. Rev. 402011</p>
<p>. M Kadic, G W Milton, M Van Hecke, M Wegener, Nat. Rev. Phys. 12019</p>
<p>. L R Meza, S Das, J R Greer, Science. 3452014</p>
<p>. L R Meza, A J Zelhofer, N Clarke, A J Mateos, D M Kochmann, J R Greer, Proc. Natl. Acad. Sci. U. S. A. 1122015</p>
<p>. M S Pham, C Liu, I Todd, J Lertthanasarn, Nature. 5652019</p>
<p>. X Zhang, Y Wang, B Ding, X Li, Small. 162020. 1902842</p>
<p>. P H Winston, Artificial intelligence. 19923rd edn</p>
<p>Deep Learning. I Goodfellow, Y Bengio, A Courville, 2016MIT Press</p>
<p>. Y Lecun, Y Bengio, G Hinton, Nature. 5212015</p>
<p>. Y Liu, T Zhao, W Ju, S Shi, S Shi, S Shi, J Mater, 20173</p>
<p>. K T Butler, D W Davies, H Cartwright, O Isayev, A Walsh, Nature. 5592018</p>
<p>. S Ramakrishna, T Y Zhang, W C Lu, Q Qian, J S C Low, J H R Yune, D Z L Tan, S Bressan, S Sanvito, S R Kalidindi, J. Intell. Manuf. 302019</p>
<p>. R Batra, L Song, R Ramprasad, 10.1038/s41578-020-00255-yNat. Rev. Mater. 2020</p>
<p>. J Wei, P De Luna, Y Bengio, A Aspuru-Guzik, E Sargent, Nature. 5522017</p>
<p>. G H Gu, J Noh, I Kim, Y Jung, J. Mater. Chem. A. 72019</p>
<p>. H Liu, Z Fu, K Yang, X Xu, M Bauchy, 10.1016/j.jnoncrysol.2019.04.039J. Non. Cryst. Solids. 1194192019</p>
<p>. C T Chen, G X Gu, Commun, 20199</p>
<p>. G Chen, Z Shen, A Iyer, U F Ghumman, S Tang, J Bi, W Chen, Y Li, Polymers. 121632020</p>
<p>. C Zhai, T Li, H Shi, J Yeo, J. Mater. Chem. B. 82020</p>
<p>. L Meng, B Mcwilliams, W Jarosinski, H Y Park, Y G Jung, J Lee, J Zhang, JOM. 722020</p>
<p>. G D Goh, S L Sing, W Y Yeong, 10.1007/s10462-020-09876-9Artif. Intell. Rev. 2020</p>
<p>. F E Bock, R C Aydin, C J Cyron, N Huber, S R Kalidindi, B Klusemann, Front. Mater. 61102019</p>
<p>. D C Montgomery, E A Peck, G G Vining, 2012John Wiley &amp; Sons821Introduction to linear regression analysis</p>
<p>. R Tibshirani, J. R. Statist. Soc. B. 581996</p>
<p>. C Cortes, V Vapnik, Mach. Learn. 201995</p>
<p>. L Breiman, Mach. Learn. 452001</p>
<p>Generalized Linear Models, Second eqn. P Mccullagh, J A Nelder, 1989Taylor &amp; Francis</p>
<p>. J R Quinlan, Mach. Learn. 11986</p>
<p>. J H Friedman, Comput. Stat. Data Anal. 382002</p>
<p>. J H Friedman, Ann. Stat. 292001</p>
<p>. F Rosenblatt, Psychol. Rev. 651958</p>
<p>Artificial intelligence: a modern approach. S Russell, P Norvig, 20032nd edn</p>
<p>. S Haykin, N Network, Neural Networks. 2412004</p>
<p>. J Schmidhuber, Neural Networks. 612015</p>
<p>Competition and cooperation in neural nets. K Fukushima, S Miyake, 1982Springer</p>
<p>Shape, contour and grouping in computer vision. Y Lecun, P Haffner, L Bottou, Y Bengio, 1999Springer</p>
<p>. Q Zhang, M Zhang, T Chen, Z Sun, Y Ma, B Yu, Neurocomputing. 3232019</p>
<p>. M J Buehler, Nano Futur. 2020, 4, 035004</p>
<p>. S L Franjou, M Milazzo, C.-H Yu, M J Buehler, Expert Rev. Proteomics. 162019</p>
<p>On the difficulty of training recurrent neural networks. R Pascanu, T Mikolov, Y Bengio, Proceedings of the 30th International Conference on International Conference on Machine Learning (ICML 2013). the 30th International Conference on International Conference on Machine Learning (ICML 2013)2013</p>
<p>. S Hochreiter, Int. J. Uncertainty, Fuzziness Knowledge-Based Syst. 061998</p>
<p>. S Hochreiter, J Schmidhuber, Neural Comput. 91997</p>
<p>Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation. K Cho, B Van Merrie ¨nboer, C Gulcehre, D Bahdanau, F Bougares, H Schwenk, Y Bengio, Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing. the 2014 Conference on Empirical Methods in Natural Language Processing2014</p>
<p>Deep Residual Learning for Image Recognition. K He, X Zhang, S Ren, J Sun, Proceedings of the IEEE conference on computer vision and pattern recognition. the IEEE conference on computer vision and pattern recognition2016</p>
<p>. D Bahdanau, K Cho, Y Bengio, arXiv:1409.04732014arXiv preprint</p>
<p>. V Mnih, N Heess, A Graves, K Kavukcuoglu, Adv. Neural Inf. Process. Syst. 32014</p>
<p>. A W Senior, R Evans, J Jumper, J Kirkpatrick, L Sifre, T Green, C Qin, A , A W R Nelson, A Bridgland, H Penedones, S Petersen, K Simonyan, S Crossan, P Kohli, D T Jones, D Silver, K Kavukcuoglu, D Hassabis, Nature. 5772020</p>
<p>. C.-H Yu, Z Qin, F J Martin-Martinez, M J Buehler, ACS Nano. 132019</p>
<p>. C.-H Yu, M J Buehler, APL Bioeng. 2020, 4, 016108</p>
<p>I Goodfellow, J Pouget-Abadie, M Mirza, B Xu, D Warde-Farley, S Ozair, A Courville, Y Bengio, Generative Adversarial Nets. 2014. 201427</p>
<p>. M Mirza, S Osindero, arXiv:1411.17842014arXiv preprint</p>
<p>Unpaired Image-to-Image Translation Using Cycle-Consistent Adversarial Networks. J Zhu, T Park, P Isola, A A Efros, IEEE. 2017. 2017</p>
<p>Image-to-image translation with conditional adversarial networks. P Isola, J Y Zhu, T Zhou, A A Efros, Proceedings of the IEEE conference on computer vision and pattern recognition. the IEEE conference on computer vision and pattern recognition2017</p>
<p>. D P Kingma, M Welling, arXiv:1312.61142013arXiv preprint</p>
<p>C E Rasmussen, C K I Williams, Gaussian Processes for Machine Learning (Adaptive Computation and Machine Learning). The MIT Press2005</p>
<p>Active learning literature survey. B Settles, 200952Univeristy of Wiconsin Madison</p>
<p>. T Lookman, P V Balachandran, D Xue, R Yuan, Comput. Mater. 2019, 5, 21</p>
<p>L Pack Kaelbling, M L Littman, A W Moore, S Hall, Reinforcement Learning: A Survey. 19964</p>
<p>. D Silver, A Huang, C J Maddison, A Guez, L Sifre, G Van Den Driessche, J Schrittwieser, I Antonoglou, V Panneershelvam, M Lanctot, S Dieleman, D Grewe, J Nham, N Kalchbrenner, I Sutskever, T Lillicrap, M Leach, K Kavukcuoglu, T Graepel, D Hassabis, Nature. 5292016</p>
<p>. J Zhou, G Cui, Z Zhang, C Yang, Z Liu, L Wang, C Li, M Sun, arXiv:1812.084342018arXiv preprint</p>
<p>T N Kipf, M Welling, Semi-Supervised Classification with Graph Convolutional Networks, 5th International Conference on Learning Representations. 2017. 2017</p>
<p>. T Kirchdoerfer, M Ortiz, Comput. Methods Appl. Mech. Eng. 3042016</p>
<p>. T Kirchdoerfer, M Ortiz, Comput. Methods Appl. Mech. Eng. 3262017</p>
<p>. T Kirchdoerfer, M Ortiz, Int. J. Numer. Methods Eng. 1132018</p>
<p>. L Stainier, A Leygue, M Ortiz, Comput. Mech. 642019</p>
<p>. J Yvonnet, D Gonzalez, Q C He, Comput. Methods Appl. Mech. Eng. 1982009</p>
<p>. A Cle ´ment, C Soize, J Yvonnet, Int. J. Numer. Methods Eng. 912012</p>
<p>. B A Le, J Yvonnet, Q.-C He, Int. J. Numer. Methods Eng. 1042015</p>
<p>. Z Liu, M A Bessa, W K Liu, Comput. Methods Appl. Mech. Eng. 3062016</p>
<p>. M A Bessa, R Bostanabad, Z Liu, A Hu, D W Apley, C Brinson, W Chen, W K Liu, Comput. Methods Appl. Mech. Eng. 3202017</p>
<p>. W Yan, S Lin, O L Kafka, Y Lian, C Yu, Z Liu, J Yan, S Wolff, H Wu, E Ndip-Agbor, M Mozaffar, K Ehmann, J Cao, G J Wagner, W K Liu, Comput. Mech. 612018</p>
<p>. Z Liu, M Fleming, W K Liu, Comput. Methods Appl. Mech. Eng. 3302018</p>
<p>. H Li, O L Kafka, J Gao, C Yu, Y Nie, L Zhang, M Tajdari, S Tang, X Guo, G Li, S Tang, G Cheng, W K Liu, Comput. Mech. 642019</p>
<p>. S Curtarolo, G L W Hart, M B Nardelli, N Mingo, S Sanvito, O Levy, Nat. Mater. 122013</p>
<p>. S Curtarolo, W Setyawan, S Wang, J Xue, K Yang, R H Taylor, L J Nelson, G L W Hart, S Sanvito, M Buongiorno-Nardelli, N Mingo, O Levy, Comput. Mater. Sci. 582012</p>
<p>. A Jain, S P Ong, G Hautier, W Chen, W D Richards, S Dacek, S Cholia, D Gunter, D Skinner, G Ceder, K A Persson, Mater, 2013, 1, 011002</p>
<p>MATDAT. 21 October 2020</p>
<p>MatWeb. 21 October 2020</p>
<p>. Matmatch, 21 October 2020</p>
<p>. Makeitform, 21 October 2020</p>
<p>. Matnavi, October 2020</p>
<p>. S Chibani, F X Coudert, Chem. Sci. 102019</p>
<p>. J Noh, J Kim, H S Stein, B Sanchez-Lengeling, J M Gregoire, A Aspuru-Guzik, Y Jung, Matter, 20191</p>
<p>. P Raccuglia, K C Elbert, P D F Adler, C Falk, M B Wenny, A Mollo, M Zeller, S A Friedler, J Schrier, A J Norquist, Nature. 5332016</p>
<p>. C Wang, H Fu, L Jiang, D Xue, J Xie, Comput. Mater. 2019, 5, 87</p>
<p>. P V Balachandran, A A Emery, J E Gubernatis, T Lookman, C Wolverton, A Zunger, Phys. Rev. Mater. 2438022018</p>
<p>. P V Balachandran, B Kowalski, A Sehirlioglu, T Lookman, Nat. Commun. 16682018</p>
<p>. L Holleis, B S Shivaram, P V Balachandran, Appl. Phys. Lett. 1142224042019</p>
<p>. R Ravinder, K H Sridhara, S Bishnoi, H S Grover, M Bauchy, H Jayadeva, N M A Kodamana, Krishnan, Mater. Horiz. 72020</p>
<p>. R Yuan, Z Liu, P V Balachandran, D Xue, Y Zhou, X Ding, J Sun, D Xue, T Lookman, Adv. Mater. 17028842018</p>
<p>. E Kim, K Huang, A Tomala, S Matthews, E Strubell, A Saunders, A Mccallum, E Olivetti, 2017, 4, 170127</p>
<p>. E Kim, K Huang, A Saunders, A Mccallum, G Ceder, E Olivetti, Chem. Mater. 292017</p>
<p>. E Kim, Z Jensen, A Van Grootel, K Huang, M Staib, S Mysore, H S Chang, E Strubell, A Mccallum, S Jegelka, E Olivetti, J. Chem. Inf. Model. 602020</p>
<p>. Z Yang, Y C Yabansu, R Al-Bahrani, W Liao, A N Choudhary, S R Kalidindi, A , Comput. Mater. Sci. 1512018</p>
<p>. A Cecen, H Dai, Y C Yabansu, S R Kalidindi, L Song, Acta Mater. 1462018</p>
<p>. R Liu, Y C Yabansu, A Agrawal, S R Kalidindi, A N Choudhary, Integr. Mater. Manuf. Innov. 42015</p>
<p>. R Liu, Y C Yabansu, Z Yang, A N Choudhary, S R Kalidindi, A , Integr. Mater. Manuf. Innov. 62017</p>
<p>. Z Yang, Y C Yabansu, D Jha, W Liao, A N Choudhary, S R Kalidindi, A , Acta Mater. 1662019</p>
<p>. G X Gu, C T Chen, M J Buehler, Extrem. Mech. Lett. 182018</p>
<p>. G X Gu, C T Chen, D J Richmond, M J Buehler, Mater. Horiz. 52018</p>
<p>. C.-H Yu, Z Qin, M J Buehler, Nano Futur. 2019, 3, 035001</p>
<p>. M A Bessa, P Glowacki, M Houlder, Adv. Mater. 312019. 1904845</p>
<p>. Z Yang, X Li, L C Brinson, A N Choudhary, W Chen, A , J. Mech. Des. 1114162018</p>
<p>. K Yang, X Xu, B Yang, B Cook, H Ramos, N M A Krishnan, M M Smedskjaer, C Hoover, M Bauchy, Sci. Rep. 87392019</p>
<p>. P Z Moghadam, S M J Rogge, A Li, C.-M Chow, J Wieme, N Moharrami, M Aragones-Anglada, G Conduit, D A Gomez-Gualdron, V Van Speybroeck, D Fairen-Jimenez, 2019Matter1</p>
<p>. Y.-C Hsu, C.-H Yu, M J Buehler, Matter. 32020</p>
<p>. Y Mao, Q He, X Zhao, Sci. Adv. 2020, 6, eaaz4169</p>
<p>Y Lecun, C Cortes, The MNIST database of handwritten digits. </p>
<p>. E Lejeune, Extrem. Mech. Lett. 1006592020</p>
<p>. F Ren, L Ward, T Williams, K J Laws, C Wolverton, J Hattrick-Simpers, A Mehta, Sci. Adv. 2018, 4, eaaq1566</p>
<p>. A E Gongora, B Xu, W Perry, C Okoye, P Riley, K G Reyes, E F Morgan, K A Brown, Sci. Adv. 2020, 6, eaaz1708</p>
<p>. Z Yang, S Papanikolaou, A C E Reid, W Liao, A N Choudhary, C Campbell, A , Sci. Rep. 82622020</p>
<p>. C Herriott, A D Spear, Comput. Mater. Sci. 1095992020</p>
<p>. S Bishnoi, S Singh, R Ravinder, M Bauchy, N N Gosvami, H Kodamana, N M A Krishnan, J. Non. Cryst. Solids. 5241196432019</p>
<p>. Q Zhao, H Yang, J Liu, H Zhou, H Wang, W Yang, Mater. Des. 2021, 197, 109248</p>
<p>. X Chen, H Zhou, Y Li, Mater. Des. 1080852019</p>
<p>. A Mansouri Tehrani, A O Oliynyk, M Parry, Z Rizvi, S Couper, F Lin, L Miyagi, T D Sparks, J Brgoch, J. Am. Chem. Soc. 1402018</p>
<p>. P Avery, X Wang, C Oses, E Gossett, D M Proserpio, C Toher, S Curtarolo, E Zurek, Comput. Mater. 2019, 5, 89</p>
<p>. E Mazhnik, A R Oganov, J. Appl. Phys. 751022020</p>
<p>. C Wen, Y Zhang, C Wang, D Xue, Y Bai, S Antonov, L Dai, T Lookman, Y Su, Acta Mater. 1702019</p>
<p>. C Ma, Z Zhang, B Luce, S Pusateri, B Xie, M H Rafiei, N Hu, Comput. Mater. 6402020</p>
<p>. X Liu, C E Athanasiou, N P Padture, B W Sheldon, H Gao, Acta Mater. 1902020</p>
<p>. E L Buehler, I Su, M J Buehler, Extrem. Mech. Lett. 1010342021</p>
<p>. J D Evans, F O , -X Coudert, Chem. Mater. 292017</p>
<p>. R Gaillac, S Chibani, F X Coudert, Chem. Mater. 322020</p>
<p>. Z Zhang, Y Hong, B Hou, Z Zhang, M Negahban, J Zhang, Carbon. 1482019</p>
<p>. Y Wang, M Zhang, A Lin, A Iyer, A S Prasad, X Li, Y Zhang, L S Schadler, W Chen, L C Brinson, Mol. Syst. Des. Eng. 52020</p>
<p>. Q Chen, W Tu, M Ma, J. Appl. Phys. 1751012020</p>
<p>. Z Nie, H Jiang, L B Kara, J. Comput. Inf. Sci. Eng. 2020, 20, 011002</p>
<p>. B Ni, H Gao, 10.1557/mrs.2020.231MRS Bull. 2020</p>
<p>Deep Learning Model to Predict Complex Stress and Strain Fields in Hierarchical Composites. Z Yang, C.-H Yu, M J Buehler, Sci. Adv. in revision</p>
<p>. K Pierson, A Rahman, A D Spear, JOM. 712019</p>
<p>. J Guilleminot, J E Dolbow, Mech. Res. Commun. 1034432020</p>
<p>. M Mozaffar, R Bostanabad, W Chen, K Ehmann, J Cao, M A Bessa, Proc. Natl. Acad. Sci. U. S. A. 1162019</p>
<p>. D Huang, J N Fuhg, C Weißenfels, P Wriggers, Comput. Methods Appl. Mech. Eng. 1130082020</p>
<p>. L Wu, V D Nguyen, N G Kilingar, L Noels, Comput. Methods Appl. Mech. Eng. 1132342020</p>
<p>. H Yang, H Qiu, S Tang, Q Xiang, X Guo, J. Appl. Mech. 87910052020</p>
<p>. Z Zhou, Y Zhu, J Luo, X Yang, X Guo, Int. J. Solids Struct. 1982020</p>
<p>. G Chen, T Li, Q Chen, S Ren, C Wang, S Li, Comput. Mech. 642019</p>
<p>. M Stern, C Arinze, L Perez, S E Palmer, A Murugan, Proc. Natl. Acad. Sci. U. S. A. 1172020</p>
<p>. N Huber, A Konstantinidis, C Tsakmakis, J. Appl. Mech. Trans. ASME. 682001</p>
<p>. N Huber, C Tsakmakis, J. Appl. Mech. Trans. ASME. 682001</p>
<p>. E Tyulyukovskiy, N Huber, J. Mater. Res. 212006</p>
<p>. R Haj-Ali, H K Kim, S W Koh, A Saxena, R Tummala, Int. J. Plast. 242008</p>
<p>. H Li, L Gutierrez, H Toda, O Kuwazuru, W Liu, Y Hangai, M Kobayashi, R Batres, Int. J. Solids Struct. 812016</p>
<p>. L Lu, M Dao, P Kumar, U Ramamurty, G E Karniadakis, S Suresh, Proc. Natl. Acad. Sci. U. S. A. 1172020</p>
<p>. P Z Hanakata, E D Cubuk, D K Campbell, H S Park, Phys. Rev. Lett. 2553042018</p>
<p>. Y Yu, T Hur, J Jung, I G Jang, Struct. Multidiscip. Optim. 592019</p>
<p>. I Sosnovik, I Oseledets, Russ J Numer, Anal. Math. Model. 342019</p>
<p>. D W Abueidda, S Koric, N A Sobh, Comput. Struct. 1062832020</p>
<p>. X Lei, C Liu, Z Du, W Zhang, X Guo, J. Appl. Mech. Trans. ASME. 86110042019</p>
<p>. C M Hamel, D J Roach, K N Long, F Demoly, M L Dunn, H J Qi, Smart Mater. Struct. 650052019</p>
<p>. S Wu, C M Hamel, Q Ze, F Yang, H J Qi, R Zhao, Adv. Intell. Syst. 2020, 2, 2000060</p>
<p>. L Wu, L Liu, Y Wang, Z Zhai, H Zhuang, D Krishnaraju, Q Wang, H Jiang, Extrem. Mech. Lett. 1006572020</p>
<p>. S Kumar, S Tan, L Zheng, D M Kochmann, Comput. Mater. 2020, 6, 73</p>
<p>. C Chen, G X Gu, Adv. Sci. 2020, 7, 1902607</p>
<p>Design automation by integrating generative adversarial networks and topology optimization. S Oh, Y Jung, I Lee, N Kang, Proceedings of the ASME 2018 International Design Engineering Technical Conferences and Computers and Information in Engineering Conference (IDETC/CIE 2018). the ASME 2018 International Design Engineering Technical Conferences and Computers and Information in Engineering Conference (IDETC/CIE 2018)2018</p>
<p>. S Oh, Y Jung, S Kim, I Lee, N Kang, J. Mech. Des. Trans. ASME. 1114052019</p>
<p>Topology design with conditional generative adversarial networks. C Sharpe, C C Seepersad, Proceedings of the ASME 2019 International Design Engineering Technical Conferences and Computers and Information in Engineering Conference (IDETC/CIE 2019). the ASME 2019 International Design Engineering Technical Conferences and Computers and Information in Engineering Conference (IDETC/CIE 2019)2019</p>
<p>. K Guo, M J Buehler, Extrem. Mech. Lett. 1010292020</p>
<p>. Z Liu, C T Wu, J. Mech. Phys. Solids. 1272019</p>
<p>. Z Liu, Comput. Methods Appl. Mech. Eng. 1129132020</p>
<p>. Z Liu, C T Wu, M Koishi, Comput. Methods Appl. Mech. Eng. 3452019</p>
<p>. Z Liu, C T Wu, M Koishi, Comput. Mech. 642019</p>
<p>. K Wang, W C Sun, Comput. Methods Appl. Mech. Eng. 3342018</p>
<p>. K Wang, W Sun, Comput. Methods Appl. Mech. Eng. 3462019</p>
<p>. G Capuano, J J Rimoli, Comput. Methods Appl. Mech. Eng. 3452019</p>
<p>. H Chan, M Cherukara, T D Loeffler, B Narayanan, S K R S Sankaranarayanan, Comput. Mater. 2020, 6, 1</p>
<p>. E Samaniego, C Anitescu, S Goswami, V M Nguyen-Thanh, H Guo, K Hamdia, X Zhuang, T Rabczuk, Comput. Methods Appl. Mech. Eng. 1127902020</p>
<p>. M Raissi, P Perdikaris, G E Karniadakis, J. Comput. Phys. 3782019</p>
<p>. M Schmidt, H Lipson, Science. 3242009</p>
<p>. S L Brunton, J L Proctor, J N Kutz, Proc. Natl. Acad. Sci. U. S. A. 1132016</p>
<p>Discovering Symbolic Models from Deep Learning with Inductive Biases. M Cranmer, A Sanchez-Gonzalez, P Battaglia, R Xu, K Cranmer, D Spergel, S Ho, Advances in Neural Information Processing Systems. 33NeurIPS 2020. 2020</p>
<p>. M Geiger, S Spigler, S D'ascoli, L Sagun, M Baity-Jesi, G Biroli, M Wyart, Phys. Rev. E. 100121152019</p>
<p>. M Pfeiffer, T Pfeil, Front. Neurosci. 7742018</p>            </div>
        </div>

    </div>
</body>
</html>