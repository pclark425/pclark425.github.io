<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-7375 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-7375</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-7375</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-139.html">extraction-schema-139</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models being used to detect anomalies in lists or tabular data, including the methods, datasets, evaluation metrics, and results.</div>
                <p><strong>Paper ID:</strong> paper-87dde6e5f221bf697d79b74f2efafaca9da220fd</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/87dde6e5f221bf697d79b74f2efafaca9da220fd" target="_blank">RAGLog: Log Anomaly Detection using Retrieval Augmented Generation</a></p>
                <p><strong>Paper Venue:</strong> arXiv.org</p>
                <p><strong>Paper TL;DR:</strong> This research work explores the use of a Retrieval Augmented Large Language Model that leverages a vector database to detect anomalies from logs and the experimental results show much promise.</p>
                <p><strong>Paper Abstract:</strong> The ability to detect log anomalies from system logs is a vital activity needed to ensure cyber resiliency of systems. It is applied for fault identification or facilitate cyber investigation and digital forensics. However, as logs belonging to different systems and components differ significantly, the challenge to perform such analysis is humanly challenging from the volume, variety and velocity of logs. This is further complicated by the lack or unavailability of anomalous log entries to develop trained machine learning or artificial intelligence models for such purposes. In this research work, we explore the use of a Retrieval Augmented Large Language Model that leverages a vector database to detect anomalies from logs. We used a Question and Answer configuration pipeline. To the best of our knowledge, our experiment which we called RAGLog is a novel one and the experimental results show much promise.</p>
                <p><strong>Cost:</strong> 0.011</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e7375.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e7375.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models being used to detect anomalies in lists or tabular data, including the methods, datasets, evaluation metrics, and results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>RAGLog</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Retrieval Augmented Generation for Log Anomaly Detection (RAGLog)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A zero-shot log anomaly detection pipeline that stores only normal log-entry samples in a vector database and uses dense-vector retrieval plus an LLM (GPT-3.5/Davinci) in a Q&A prompt to classify individual log entries as 'normal' or 'abnormal' without log parsing.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-3.5 (Davinci)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Generative large language model (referred to as GPT-3.5 / Davinci) used via API to perform semantic comparison and generate a 'normal'/'abnormal' label from a Q&A prompt with retrieved context.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_detection_approach</strong></td>
                            <td>Retrieval-augmented generation (RAG) with dense-vector retrieval of normal examples; zero-shot semantic classification by an LLM comparing the query entry to retrieved normal log entries.</td>
                        </tr>
                        <tr>
                            <td><strong>prompt_template</strong></td>
                            <td>Question-and-Answer template that includes the best-matched retrieved normal log entries and asks the LLM to return exactly 'normal' or 'abnormal' for the queried log entry (temperature = 0.1).</td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td>No LLM fine-tuning. The vector database was populated with only normal log-entry samples (two approaches: random sampling of normal entries, or sampling from k-means clusters). Sample sizes used: BGL - 5 clusters × 10,000 = 50,000 entries; Thunderbird - 4 clusters × 10,000 = 40,000 entries. A held-out 20% of each dataset was randomly sampled for testing.</td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Textual system log entries (time-sequenced log messages).</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td>BGL; Thunderbird</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>Precision, Recall, F1 score</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>RAGLog: Precision = 0.91, Recall = 0.88, F1 = 0.89 (reported in Table 1).</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Compared to LogPrompt (reported here): Precision = 0.25, Recall = 0.83, F1 = 0.38 — RAGLog substantially outperformed LogPrompt on the reported metrics.</td>
                        </tr>
                        <tr>
                            <td><strong>zero_shot_or_few_shot</strong></td>
                            <td>zero-shot</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Authors report high resource consumption and inference latency when running the LLM per log entry; experiment constrained by API cost so only a sampled test set was used; general LLM limitations (token capacity and potential for hallucination) are discussed though the authors state they did not observe hallucinated textual labels in outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost</strong></td>
                            <td>Described qualitatively as high resource consumption and execution latency; cost constraints limited the scope of testing (no quantitative GPU/TPS/token-costs reported).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'RAGLog: Log Anomaly Detection using Retrieval Augmented Generation', 'publication_date_yy_mm': '2023-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7375.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e7375.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models being used to detect anomalies in lists or tabular data, including the methods, datasets, evaluation metrics, and results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LogPrompt</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>LogPrompt: Prompt Engineering Towards ZeroShot and Interpretable Log Analysis</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A prior zero-shot prompt-engineering method for log analysis that evaluated different prompt formats (self-prompt, chain-of-thought, in-context) and numbers of provided log samples, reported in the literature and used here as a baseline.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>LogPrompt: Prompt Engineering Towards ZeroShot and Interpretable Log Analysis</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_detection_approach</strong></td>
                            <td>Zero-shot prompting with varied prompt formats (self-prompt, CoT, in-context) and varying numbers of provided log samples.</td>
                        </tr>
                        <tr>
                            <td><strong>prompt_template</strong></td>
                            <td>Various prompt formats including self-prompt, chain-of-thought, and in-context prompting (exact prompts not reproduced in this paper).</td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Log entries</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>Precision, Recall, F1 score (as reported in comparison table).</td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>As reported in this paper's comparison: Precision = 0.25, Recall = 0.83, F1 = 0.38.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>zero_shot_or_few_shot</strong></td>
                            <td>zero-shot</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Reported low precision in zero-shot scenarios (noted as problematic for operational use).</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'RAGLog: Log Anomaly Detection using Retrieval Augmented Generation', 'publication_date_yy_mm': '2023-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7375.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e7375.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models being used to detect anomalies in lists or tabular data, including the methods, datasets, evaluation metrics, and results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LogGPT / ChatGPT (Qi et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>LogGPT: Exploring ChatGPT for Log-Based Anomaly Detection</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Work that explored using ChatGPT for log-based anomaly detection, testing varied prompt constructs, window sizes and input sequences; reported difficulties in choosing optimal prompts, window-size token limits, and high false positive rates.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>LogGPT: Exploring ChatGPT for Log-Based Anomaly Detection</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>ChatGPT</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_detection_approach</strong></td>
                            <td>Prompting ChatGPT with different prompt constructs and windowing strategies for anomaly detection (investigated window-size and prompt design effects).</td>
                        </tr>
                        <tr>
                            <td><strong>prompt_template</strong></td>
                            <td>Varied prompt constructs and window sizes (exact templates not provided in this paper).</td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Log entries</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>Qualitative report: non-trivial prompt selection, window size limitations, and high false positive rates; exact numeric metrics not provided here.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>zero_shot_or_few_shot</strong></td>
                            <td>zero-shot / prompting (as explored in that cited work)</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>High false positive rates; sensitivity to prompt design and input window size (token limits).</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'RAGLog: Log Anomaly Detection using Retrieval Augmented Generation', 'publication_date_yy_mm': '2023-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7375.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e7375.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models being used to detect anomalies in lists or tabular data, including the methods, datasets, evaluation metrics, and results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Mudgal et al. (ChatGPT assessment)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>An Assessment of ChatGPT on Log Data</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A study that applied ChatGPT with carefully designed prompts to log parsing (excellent parsing performance reported), but found limitations when using ChatGPT for anomaly detection and log summarization.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>An Assessment of ChatGPT on Log Data</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>ChatGPT</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_detection_approach</strong></td>
                            <td>Prompting-based log parsing and other log tasks; assessment-style evaluation rather than fine-tuning.</td>
                        </tr>
                        <tr>
                            <td><strong>prompt_template</strong></td>
                            <td>Prompt engineering for log parsing (exact prompts not provided in this paper).</td>
                        </tr>
                        <tr>
                            <td><strong>training_data</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Log entries</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance</strong></td>
                            <td>Reported strong log parsing performance; for anomaly detection and summarization, limitations were noted but detailed metrics are not provided in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>zero_shot_or_few_shot</strong></td>
                            <td>zero-shot / prompt-based evaluation</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Limitations for anomaly detection and log summarization beyond parsing tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'RAGLog: Log Anomaly Detection using Retrieval Augmented Generation', 'publication_date_yy_mm': '2023-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>LogPrompt: Prompt Engineering Towards ZeroShot and Interpretable Log Analysis <em>(Rating: 2)</em></li>
                <li>LogGPT: Exploring ChatGPT for Log-Based Anomaly Detection <em>(Rating: 2)</em></li>
                <li>An Assessment of ChatGPT on Log Data <em>(Rating: 2)</em></li>
                <li>Log-based Anomaly Detection without Log Parsing <em>(Rating: 1)</em></li>
                <li>Retrieval-augmented generation for knowledge-intensive nlp tasks <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-7375",
    "paper_id": "paper-87dde6e5f221bf697d79b74f2efafaca9da220fd",
    "extraction_schema_id": "extraction-schema-139",
    "extracted_data": [
        {
            "name_short": "RAGLog",
            "name_full": "Retrieval Augmented Generation for Log Anomaly Detection (RAGLog)",
            "brief_description": "A zero-shot log anomaly detection pipeline that stores only normal log-entry samples in a vector database and uses dense-vector retrieval plus an LLM (GPT-3.5/Davinci) in a Q&A prompt to classify individual log entries as 'normal' or 'abnormal' without log parsing.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "GPT-3.5 (Davinci)",
            "model_description": "Generative large language model (referred to as GPT-3.5 / Davinci) used via API to perform semantic comparison and generate a 'normal'/'abnormal' label from a Q&A prompt with retrieved context.",
            "model_size": null,
            "anomaly_detection_approach": "Retrieval-augmented generation (RAG) with dense-vector retrieval of normal examples; zero-shot semantic classification by an LLM comparing the query entry to retrieved normal log entries.",
            "prompt_template": "Question-and-Answer template that includes the best-matched retrieved normal log entries and asks the LLM to return exactly 'normal' or 'abnormal' for the queried log entry (temperature = 0.1).",
            "training_data": "No LLM fine-tuning. The vector database was populated with only normal log-entry samples (two approaches: random sampling of normal entries, or sampling from k-means clusters). Sample sizes used: BGL - 5 clusters × 10,000 = 50,000 entries; Thunderbird - 4 clusters × 10,000 = 40,000 entries. A held-out 20% of each dataset was randomly sampled for testing.",
            "data_type": "Textual system log entries (time-sequenced log messages).",
            "dataset_name": "BGL; Thunderbird",
            "evaluation_metric": "Precision, Recall, F1 score",
            "performance": "RAGLog: Precision = 0.91, Recall = 0.88, F1 = 0.89 (reported in Table 1).",
            "baseline_comparison": "Compared to LogPrompt (reported here): Precision = 0.25, Recall = 0.83, F1 = 0.38 — RAGLog substantially outperformed LogPrompt on the reported metrics.",
            "zero_shot_or_few_shot": "zero-shot",
            "limitations_or_failure_cases": "Authors report high resource consumption and inference latency when running the LLM per log entry; experiment constrained by API cost so only a sampled test set was used; general LLM limitations (token capacity and potential for hallucination) are discussed though the authors state they did not observe hallucinated textual labels in outputs.",
            "computational_cost": "Described qualitatively as high resource consumption and execution latency; cost constraints limited the scope of testing (no quantitative GPU/TPS/token-costs reported).",
            "uuid": "e7375.0",
            "source_info": {
                "paper_title": "RAGLog: Log Anomaly Detection using Retrieval Augmented Generation",
                "publication_date_yy_mm": "2023-11"
            }
        },
        {
            "name_short": "LogPrompt",
            "name_full": "LogPrompt: Prompt Engineering Towards ZeroShot and Interpretable Log Analysis",
            "brief_description": "A prior zero-shot prompt-engineering method for log analysis that evaluated different prompt formats (self-prompt, chain-of-thought, in-context) and numbers of provided log samples, reported in the literature and used here as a baseline.",
            "citation_title": "LogPrompt: Prompt Engineering Towards ZeroShot and Interpretable Log Analysis",
            "mention_or_use": "mention",
            "model_name": null,
            "model_description": null,
            "model_size": null,
            "anomaly_detection_approach": "Zero-shot prompting with varied prompt formats (self-prompt, CoT, in-context) and varying numbers of provided log samples.",
            "prompt_template": "Various prompt formats including self-prompt, chain-of-thought, and in-context prompting (exact prompts not reproduced in this paper).",
            "training_data": null,
            "data_type": "Log entries",
            "dataset_name": null,
            "evaluation_metric": "Precision, Recall, F1 score (as reported in comparison table).",
            "performance": "As reported in this paper's comparison: Precision = 0.25, Recall = 0.83, F1 = 0.38.",
            "baseline_comparison": null,
            "zero_shot_or_few_shot": "zero-shot",
            "limitations_or_failure_cases": "Reported low precision in zero-shot scenarios (noted as problematic for operational use).",
            "computational_cost": null,
            "uuid": "e7375.1",
            "source_info": {
                "paper_title": "RAGLog: Log Anomaly Detection using Retrieval Augmented Generation",
                "publication_date_yy_mm": "2023-11"
            }
        },
        {
            "name_short": "LogGPT / ChatGPT (Qi et al.)",
            "name_full": "LogGPT: Exploring ChatGPT for Log-Based Anomaly Detection",
            "brief_description": "Work that explored using ChatGPT for log-based anomaly detection, testing varied prompt constructs, window sizes and input sequences; reported difficulties in choosing optimal prompts, window-size token limits, and high false positive rates.",
            "citation_title": "LogGPT: Exploring ChatGPT for Log-Based Anomaly Detection",
            "mention_or_use": "mention",
            "model_name": "ChatGPT",
            "model_description": null,
            "model_size": null,
            "anomaly_detection_approach": "Prompting ChatGPT with different prompt constructs and windowing strategies for anomaly detection (investigated window-size and prompt design effects).",
            "prompt_template": "Varied prompt constructs and window sizes (exact templates not provided in this paper).",
            "training_data": null,
            "data_type": "Log entries",
            "dataset_name": null,
            "evaluation_metric": null,
            "performance": "Qualitative report: non-trivial prompt selection, window size limitations, and high false positive rates; exact numeric metrics not provided here.",
            "baseline_comparison": null,
            "zero_shot_or_few_shot": "zero-shot / prompting (as explored in that cited work)",
            "limitations_or_failure_cases": "High false positive rates; sensitivity to prompt design and input window size (token limits).",
            "computational_cost": null,
            "uuid": "e7375.2",
            "source_info": {
                "paper_title": "RAGLog: Log Anomaly Detection using Retrieval Augmented Generation",
                "publication_date_yy_mm": "2023-11"
            }
        },
        {
            "name_short": "Mudgal et al. (ChatGPT assessment)",
            "name_full": "An Assessment of ChatGPT on Log Data",
            "brief_description": "A study that applied ChatGPT with carefully designed prompts to log parsing (excellent parsing performance reported), but found limitations when using ChatGPT for anomaly detection and log summarization.",
            "citation_title": "An Assessment of ChatGPT on Log Data",
            "mention_or_use": "mention",
            "model_name": "ChatGPT",
            "model_description": null,
            "model_size": null,
            "anomaly_detection_approach": "Prompting-based log parsing and other log tasks; assessment-style evaluation rather than fine-tuning.",
            "prompt_template": "Prompt engineering for log parsing (exact prompts not provided in this paper).",
            "training_data": null,
            "data_type": "Log entries",
            "dataset_name": null,
            "evaluation_metric": null,
            "performance": "Reported strong log parsing performance; for anomaly detection and summarization, limitations were noted but detailed metrics are not provided in this paper.",
            "baseline_comparison": null,
            "zero_shot_or_few_shot": "zero-shot / prompt-based evaluation",
            "limitations_or_failure_cases": "Limitations for anomaly detection and log summarization beyond parsing tasks.",
            "computational_cost": null,
            "uuid": "e7375.3",
            "source_info": {
                "paper_title": "RAGLog: Log Anomaly Detection using Retrieval Augmented Generation",
                "publication_date_yy_mm": "2023-11"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "LogPrompt: Prompt Engineering Towards ZeroShot and Interpretable Log Analysis",
            "rating": 2,
            "sanitized_title": "logprompt_prompt_engineering_towards_zeroshot_and_interpretable_log_analysis"
        },
        {
            "paper_title": "LogGPT: Exploring ChatGPT for Log-Based Anomaly Detection",
            "rating": 2,
            "sanitized_title": "loggpt_exploring_chatgpt_for_logbased_anomaly_detection"
        },
        {
            "paper_title": "An Assessment of ChatGPT on Log Data",
            "rating": 2,
            "sanitized_title": "an_assessment_of_chatgpt_on_log_data"
        },
        {
            "paper_title": "Log-based Anomaly Detection without Log Parsing",
            "rating": 1,
            "sanitized_title": "logbased_anomaly_detection_without_log_parsing"
        },
        {
            "paper_title": "Retrieval-augmented generation for knowledge-intensive nlp tasks",
            "rating": 1,
            "sanitized_title": "retrievalaugmented_generation_for_knowledgeintensive_nlp_tasks"
        }
    ],
    "cost": 0.010998,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>RAGLog: Log Anomaly Detection using Retrieval Augmented Generation</h1>
<p>Jonathan Pan, Swee Liang Wong, Yidi Yuan<br>Home Team Science and Technology Agency, Singapore<br>Jonathan_Pan@htx.gov.sg, Wong_Swee_Liang@htx.gov.sg, Yuan_Yidi@htx.gov.sg</p>
<h4>Abstract</h4>
<p>The ability to detect log anomalies from system logs is a vital activity needed to ensure cyber resiliency of systems. It is applied for fault identification or facilitate cyber investigation and digital forensics. However, as logs belonging to different systems and components differ significantly, the challenge to perform such analysis is humanly challenging from the volume, variety and velocity of logs. This is further complicated by the lack or unavailability of anomalous log entries to develop trained machine learning or artificial intelligence models for such purposes. In this research work, we explore the use of a Retrieval Augmented Large Language Model that leverages a vector database to detect anomalies from logs. We used a Question and Answer configuration pipeline. To the best of our knowledge, our experiment which we called RAGLog is a novel one and the experimental results show much promise.</p>
<p>Keywords- Log analysis; Retrieval Augmented Generation, Large Language Model</p>
<h2>I. INTRODUCTION</h2>
<p>The analysis of logs to detect anomalies is an important research topic with practical importance in the field of failure identification [1], [2] and security threat detection [3], [4]. Logs are generated by systems or applications that are codified and configured to report relevant information about the state of the applications or software while running. Here, the application may refer to any software running to perform specific task or tasks. It could be a mobile application, operating system running inside an Internet of Things (IoTs) device or a cloud compute node performing computational tasks. It could also be an environment of compute nodes working collectively on multiple tasks. Such logs and their log entries are generated based on its current configuration at the time of the log generation. These entries are also affected by the state of the application during its execution and its dependent factors that may originate from within the operating environment and executing platform of the application. It would be affected by external factors like users or external systems interacting with the application.</p>
<p>These internal and external factors affecting the log generation may change abruptly and progressively over time resulting in corresponding log entries being included into the log generation process. These factors may originate from planned changes like planned maintenance tasks. They may also originate from unplanned activities. Additionally, these changes may be induced by benign or malicious intent. For the latter,
with the intent to evade detection, even if the logs are not tampered, its entries will be elusive to classical detection techniques. These further complicates the composition of logs to be analyzed.</p>
<p>The objective of performing analysis on logs is done to facilitate the detection of anomalous activities so that immediate or corresponding remediation may be done to contain or remediate the issue recorded in the logs. This is part of the attempt to enhance system resiliency against system faults, degradation and intentionally induced cyber physical attacks. It is also used to facilitate the investigation or analysis of what may have induced the occurrence of such anomalous activities. The scope of this research work is on the detection of such anomalous activities from the logs. However, due to the characteristics of logs, namely being voluminous, varied, and contextual, regular log analysis is difficult, warranting the need for automation. While rule or signature-based automation solution helps, the contextual or semantic complexity of logs limits its efficacy [16].</p>
<p>There is many research work done to develop AI algorithms to detect anomalies from logs. However, log analysis using AI algorithms require extensive preparation and data requirements to train the models [6][7]. The capability of log analysis using AI algorithms to detect anomalies has several challenges and constraints to deal with before it contributes significantly to its intended objectives of keeping system resilient. For supervised models, there is the challenge of acquiring sufficient anomalous data points to train such models. For unsupervised models, it will be the ability to detect the variety and variations of anomalies in logs. Recent research work to apply Large Language Models (LLMs) to log analysis processes have shown promising results but are constrained by model limits such as token capacity, ability to remember and hallucinations. Also, there is limited evaluation on its efficacy.</p>
<p>In our research work, we seek to address these constraints using a Retrieval Augmented Generation approach with a vector database and evaluate its performance in detecting log anomalies. Our novel log anomaly detection solution termed RAGLog uses a Retrieval Augmented Generation construct with a vector database to store subset of normal log entries and a Large Language Model to perform zero shot semantic analysis of the queried log entry. Our pipeline process requires minimal</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>data preprocessing and does not require log parsing. It uses unsupervised clustering to enhance log anomaly detection.</p>
<p>In the next section, we will cover the challenges and complexity of performing log analysis. This is followed by a review of current log analysis algorithms including Large Language Models. A coverage of our RAG construct is described in the section that follows with the details of the experimental setup and its evaluation. This paper concludes with a summary of this work and potential future research direction.</p>
<h2>II. BACKGROUND INFORMATION</h2>
<p>In this section, we articulate the background information related to the need for the analysis of logs, its complexity, and challenges with current log analysis algorithms.</p>
<h2>A. Need for Analysis of Logs</h2>
<p>Logs are generated by software driven applications running on systems or devices to provide information to aid developers and system engineers with their analysis of system's state and condition. It is also used as a form of audit trail to log the occurrences of events in chronological manner. The analysis of logs is also done to facilitate investigation after the occurrence of an incident related to the system that generates the logs. This incident could be in the form of system defect and a malicious or unintended breach of the system. With investigation, the log could provide the means to reconstruct the occurrence of the incident. With such forms of analysis, an investigator or system engineer would attempt to identify the occurrence of anomalous events through the logs. However, to identify such anomalies, one would need to know how to spot such anomalies from voluminous entries posted into the log files.</p>
<h2>B. Challenges with Log Analysis</h2>
<p>The form for logs is typically unique to how the software has been developed or configured to post entries into these textual files. Also, each system or software component may adopt its own logging format and information lexicon representation that details the state of the run-time system when logs are posted. Such information within the logs is highly context specific to the environment which the system resides in [16]. For example, information like the IP addresses or hostnames or resource identities. Entries in the logs are dependent also on the configuration surrounding the involved system and their own respective environmental conditions. In addition to the contextual settings, the log entries are sequenced by its chronological occurrence of events or state. Hence such log entries have a time dimension.</p>
<p>Hence, the analysis of such log datasets requires contextual understanding of the system or component that generates such logs. Also, the analysis requires the means to classify or distinguish what is a normal log entry and what is not a normal log entry. For the latter, such information of recognizing an abnormal entry would be constrained to what may be conceivable based on the engineering design of the system involved or known instances of events that could cause an anomalous event like a cyber security breach attempt. However,
there will be instances where such information or knowledge is only acquired through the occurrence of the event that in turn induces the anomalous log entries. Hence the challenges with log analysis are the need for semantic comprehension [15][16] to perform good log analysis and the challenge of having limitedly available information about the form of anomalies that could occur.</p>
<h2>C. Challenges with Large Language Models</h2>
<p>Current Large Language Models (or Generative Artificial Intelligence) have inherent limitations that includes limits to the size of the tokens that they can handle which in turns limits how much contextual information LLMs can take in or recall as well as potential for hallucinations [17]. Solutions are being researched upon to address such limitations with information retrieval techniques that will be described in subsequent sections.</p>
<h2>III. Related Work</h2>
<p>In this section, we review the current log analysis algorithmic development and their strengths and limitations.</p>
<h2>A. Multi-staged Log Processing</h2>
<p>The current log analysis algorithmic designs typically involve multiple stages of log processing before analysis is applied. It typically starts with log parsing that converts raw logs into structured data features. These extracted features would undergo further transformation as they are typically represented as textual features and would be converted to numerical forms. Log partitioning typically follows that involves converting the contiguous $\log$ into associative partitions to improve anomaly classification. This may involve the use of time-based partitions, partitions organized by windows of similar or compatible operations or identifier-based divisions of log entries. Finally, the anomaly detection algorithm would then be applied after these pre-processing.</p>
<p>Thus far, there are very few developmental attempts to develop an integrated model that could ingest raw log data for immediate model training and inference. Based on our survey, one by Hashemi and Mäntylä [5] and Le and Zhang [15] ingress logs without log parsers. Le and Zhang observed that log parsers could cause inaccurate log parsing due to misinterpretation of the semantic meaning of the log analysis and not handle Out-ofvocabulary (OOV) words well. Our approach removes the need for log parsing, allowing inferences on raw log data inputs.</p>
<h2>B. Algorithms to detect Anomalous Events from Logs</h2>
<p>Many of the log analysis algorithms focused on the key area of detecting anomalous events from logs. From the survey work done by He et al. [6] and Chen et al. [7], the algorithms are either supervised or unsupervised machine learning algorithms. These algorithms may be based on classical machine learning algorithms or deep learning algorithms. Supervised learning algorithms are constrained by the availability of anomalous data with labels within the training datasets. Additionally, even with the availability of anomalous data within the log datasets, the class imbalance could pose a significant challenge to the training</p>
<p>of the model. Also, these models may need to undergo retraining or be reconstructed to internalize the new knowledge. With unsupervised learning algorithms [12][13] for log analysis, their challenge is the efficiency of the algorithms to detect the variety and variations of anomalies captured in log entries as such anomalies may occur and vary significantly over a prolonged period of time. When new anomalies are discovered, these unsupervised models will require retraining. Our approach uses the vector database to store only small samples of normal log entries. The LLM will do anomaly detection without any samples of anomalous log entries. Hence it is a zero shot classifier.</p>
<h2>C. LLM for Log Analysis</h2>
<p>There were recent attempts to apply Large Language models to perform log analysis. Qi et al. [18] proposed a framework for log-based anomaly detection using ChatGPT using varied prompt constructs, window sizes and input sequences. Their work showed the non-triviality of an optimal prompt, window size limitations as well as high false positive rates. Mudgal et al. [19] designed specific prompts with ChatGPT for log parsing that had excellent performance. However, with other areas of log analysis like anomaly detection and log summarization, the LLM exhibited limitations that warrant further research. Liu et al. [20] tested their LogPrompt model in zero-shot scenarios with varying number of provided log samples and different prompt formats (self-prompt, CoT prompts and In-context Prompt). The zero-shot test results showed promise when compared with our log analysis algorithms and other Deep Learning architectures. However, it had very low precision scores which is not optimal if applied to log analysis for operations and maintenance activities to support resiliency.</p>
<p>These preliminary experimentations demonstrate the necessity for further research in applying LLM for log analysis, especially in detecting anomalies in logs, forming the basis of this research work.</p>
<h2>IV. MODEL</h2>
<p>Our construct uses the Retrieval Augmented Generative (RAG) model [22] to analyze log entries by querying its store of samples of normal log entries. In our work, the store is a vector database. The Large Language Model would need to perform semantic analysis between the retrieved log samples from the database and the queried log entry.</p>
<p>This creates an end-to-end model construct that is simple to use and adept for any log source, unlike many other similarly purposed algorithms mentioned in our previous section for log analysis which require the use of multi-stage log processing pipeline.</p>
<h2>A. Formulation for RAG</h2>
<p>The RAG operates in two stages. The first is the retrieval of contextually relevant information. The second involves using the retrieved information to generate the corresponding response. This can be formulated with $x$ as the provided input, which is the queried log entry, $z$ as the set of relevant log entries
from the vector database and $y$ as the generated output from the LLM $f$. This can be expressed in the form.</p>
<p>$$
y=f(x, z)
$$</p>
<p>Our model construct uses dense-vector retrieval approach [23] that encodes the log entries into vector embedding representations using a pre-trained Embedding model from OpenAI. The retrieval score is computed through inner products between the queried vector from the provided log entry against vectors stored in the vector database that contains provided samples of normal log entries. When the retrieval score matches the criteria like highest similarity score or minimal threshold score, the vector database will return the resultant vectors. The retriever that we used is from LangChain [24].</p>
<h2>B. LLM for Semantic Analysis</h2>
<p>With the retrieved vectors, the vector embedding will be decoded using the corresponding decoder by Embedding model. This turns the vector back to the original log entry representation. We frame the log anomaly detection as a Question and Answer [23], using a Question and Answer prompt template to include the best matched retrieved normal log entries to analyze whether a queried log entry is normal or abnormal. The prompt is fed to the Language Large Model.
<img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Fig. 1. RAGLog Architecture</p>
<h2>V. Methodology and Analysis</h2>
<p>In our experiment setup, we designed our experiment to address our research question whether Retrieval Augmented Generation in LLM could perform log anomaly detection.</p>
<h2>A. Log Datasets</h2>
<p>For our log datasets, we used BGL [9] and Thunderbird [21]. These are two popular datasets typically used by researchers to evaluate their log models [7].</p>
<p>The BGL are open real-world datasets from HPC from a BlueGene/L supercomputer at Lawrence Livermore National Labs. This dataset has an important characteristic associated with their appearance of many new log messages in the timeline of the data, that is, the systems change over time. The Thunderbird open dataset of logs was collected by Sandia National Lab. It contains alert and non-alert messages. Both</p>
<p>datasets are labelled with sizeable imbalance for the anomaly class.</p>
<h2>B. Evaluation Metrics</h2>
<p>As the dataset used had binary classification labels, we used Precision to measure the accuracy of the model against type I error (true positive) and Recall to measure the accuracy of the models against type II error (true negative). Finally, we used F1 score to measure the harmonic mean of precision and recall.</p>
<p>$$
\begin{gathered}
\text { Precision }=\frac{T P}{T P+F P} \
\text { Recall }=\frac{T P}{T P+F N} \
F 1 \text { score }=2 \times \frac{\text { Precision } \times \text { Recall }}{\text { Precision }+ \text { Recall }}
\end{gathered}
$$</p>
<p>TP (True Positive) represents the number of correctly classified anomalies, TN (True Negative) represents normal log entries and FP (False Positive) is the number of incorrect anomaly classification. FN (False Negative) is the number of incorrect classifications of log entries as normal while the label or ground truth states overwise.</p>
<h2>C. Experimentation Preparation and Evaluation</h2>
<p>We populated the vector database using two approaches. The first approach was to populate the database with randomly selected samples from the log datasets that contain only normal log entries. The second approach was to populate the database with selected samples of the log database with normal log entries. For this selection, we first applied unsupervised k-means clustering to the dataset and populated the database from random sampling from the cluster classes. We used the elbow approach to select the number of cluster classes. For both approaches, to facilitate our evaluation, we kept the same number of records persisted in the vector databases.</p>
<p>While we applied the same evaluation techniques for both log datasets, we observed notable differences in the distribution of log patterns for both: namely, BGL has a wider distribution surface compared to Thunderbird. The following are the kmeans clustering visualizations of both datasets.
<img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Chart 1. BGL Cluster Visualization Map
<img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>Chart 2. Thunderbird Cluster Visualization Map
For our experiment, we configured the sample size of 10,000 log entries for each cluster class and cluster classes of 5 for BGL dataset. For random sampling, that would be $50,000 \log$ entries that are randomly selected. For Thunderbird, we used the same sample size of 10,000 from each of the 4 classes for the clustered approach and 40,000 for random selection.</p>
<p>After selecting log entries samples, they were then populated into the vector database. Using one predefined prompt template from a Question and Answer pipeline, we will assess the efficacy of our solution to detect log anomalies. In our prompt template, we explicitly directed GPT 3.5 (Davinci) with temperature of 0.1 to generate answers in the form of 'normal' or 'abnormal' to facilitate our evaluation. Due to cost constraints of using GPT 3.5, we randomly sampled from the $20 \%$ of both log datasets that has been set aside for testing.</p>
<h2>D. Results and Analysis</h2>
<p>From our experiment test results shown below in Chart 3, we observed that the clustering approach yielded better results for BGL log datasets as compared to random selection.
<img alt="img-3.jpeg" src="img-3.jpeg" /></p>
<p>Chart 3. Evaluation performance comparison between clustered approach and random selection for both datasets.</p>
<p>The Thunderbird log dataset generally performed well with both randomized and clustering approach. This could be due to concentration of the log pattern distribution for this dataset.</p>
<p>We further evaluated our results with others who had applied zero shot classification using LLM [20]. Also the output from the LLM had either normal or abnormal returns with no other textual hallucination noted.</p>
<table>
<thead>
<tr>
<th style="text-align: left;"></th>
<th style="text-align: left;">Precision</th>
<th style="text-align: left;">Recall</th>
<th style="text-align: left;">F1 score</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">LogPrompt [20]</td>
<td style="text-align: left;">0.25</td>
<td style="text-align: left;">0.83</td>
<td style="text-align: left;">0.38</td>
</tr>
<tr>
<td style="text-align: left;">RAGLog (Ours)</td>
<td style="text-align: left;">0.91</td>
<td style="text-align: left;">0.88</td>
<td style="text-align: left;">0.89</td>
</tr>
</tbody>
</table>
<p>Table 1. Evaluation Comparison for Zero-Shot Classification</p>
<h2>VI. CONCLUSION AND Future DireCTIONS</h2>
<p>Our research work explored the use of Retrieval Augmented Generation model as log anomaly detector (RAGLog). The model's vector database only contained samples of normal log entries that were selected using unsupervised k-means clustering. It achieved good F1 scores when analyzing log entries using zero shot approach for anomalies, with the LLM being given only normal log entries for semantic analysis.</p>
<p>The constraints posed by this approach is the high resource consumption and execution latency for running the LLM and performing log analysis one log entry at a time. Hence, our next step will be to further optimize our RAG model approach to analyze logs faster with larger volumes.</p>
<h2>REFERENCES</h2>
<p>[1] A. Pecchia, D. Cotroneo, Z. Kalbarczyk, and R.K. Iyer, "Improving logbased field failure data analysis of multi-node computing systems", DSN'11: Proc. of the 41st IEEE/IFIP International Conference on Dependable Systems and Networks, pages 97-108. IEEE, 2011.
[2] W. Xu, L. Huang, A. Fox, D. Patterson, and M.I. Jordon, "Detecting large-scale system problems by mining console logs", SOSP'09: Proc. of the ACM Symposium on Operating Systems Principles, 2009.
[3] A. Brandao and P. Georgieva, "Log Files Analysis For Network Intrusion Detection," 2020 IEEE 10th International Conference on Intelligent Systems (IS), 2020, pp. 328-333, doi: 10.1109/IS48319.2020.9199976.
[4] M. Moh, S. Pininti, S. Doddapaneni and T. Moh, "Detecting Web Attacks Using Multi-stage Log Analysis," 2016 IEEE 6th International Conference on Advanced Computing (IACC), 2016, pp. 733-738, doi: 10.1109/IACC.2016.141.
[5] S. Hashemi and M. Mäntylä, "OneLog: Towards End-to-End Training in Software Log Anomaly Detection", arXiv, arXiv:2104.07324, https://doi.org/10.48550/arXiv.2104.07324.
[6] S. He, J. Zhu, P. He and M. R. Lyu, "Experience Report: System Log Analysis for Anomaly Detection," 2016 IEEE 27th International Symposium on Software Reliability Engineering (ISSRE), 2016, pp. 207218, doi: 10.1109/ISSRE.2016.21.
[7] Z. Chen, J. Liu, W. Gu, Y. Su, and M. R. Lyu, "Experience Report: Deep Learning-based System Log Analysis for Anomaly Detection,", arXiv, arXiv:2107.05908, https://doi.org/10.48550/arXiv.2107.05908.
[8] J. Snell, K. Swersky, and R. S. Zemel, "Prototypical networks for fewshot learning", Neural Information Processing Systems, 2017.
[9] A. Oliner and J. Stearley, "What supercomputers say: A study of five system logs", 37th Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN'07). IEEE, pp 575-584, 2007.
[10] V. H. Le and H. Zhang, "Log-based Anomaly Detection without Log Parsing", 2021 36th IEEE/ACM International Conference on Automated Software Engineering (ASE), Nov 2021.
[11] M. Du, F. Li, G. Zheng, and V. Srikumar, "Deeplog: Anomaly detection and diagnosis from system logs through deep learning", Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security, 1285-1298, 2017.
[12] A. Farzad and T. A. Gulliver, "Unsupervised log message anomaly detection", ICT Express 6, 3, 229-237, 2020.
[13] D. Biplob, M. Solaimani, M. A. G. Gulzar, N. Arora, C. Lumezanu, J. Xu, B. Zong, H. Zhang, G. Jiang and L. Khan, "LogLens: A real- time log analysis system." In 2018 IEEE 38th international conference on distributed computing systems (ICDCS), pp. 1052-1062. IEEE, 2018.
[14] J. P. Poh, J. Y. C. Lee, K. X. Tan, and E. Tan, "Physical access log analysis: An unsupervised clustering approach for anomaly detection." In Proceedings of the 3rd International Conference on Data Science and Information Technology, pp. 12-18. 2020.
[15] V. H. Le and H. Zhang, "Log-based Anomaly Detection without Log Parsing", 2021 36 $6^{\text {th }}$ IEEE/ACM International Conference on Automated Software Engineering (ASE), Nov 2021.
[16] A. Ekelhart, E. Kiesling and K. Kurniawan, "Taming the logs Vocabularies for semantic security analysis", SEMANTiCS 2028 - $14^{\text {th }}$ International Conference on Semantic Systems, Science Direct, Procedia Comput Science 137, pp. 109-119, 2018.
[17] R. Zhao, H. Chen, W. Wang, F. Jiao, X.L. Do, C Qin, B. Ding, X. Guo, M. Li, X. Li and S. Joty, "Retrieving Multimodal Information for Augmented Generaion: A Survey, arXiv:2303.10868v2, 2023.
[18] J. Qi, S. Huang, Z. Luan, C. Fung, H. Yang and D. Qian, "LogGPT: Exploring ChatGPT for Log-Based Anomaly Detection", arXiv:2309.01189v1, 2023.
[19] P. Mudgal and R. Wouhaybi, "An Assessment of ChatGPT on Log Data", arXiv:2309.07938v1, 2023.
[20] Y. Liu, S. Tao, W. Meng, J. Wang, W. Ma, Y. Zhao, Y. Chen, H. Yang, Y. Jiang and X. Chen, "LogPrompt: Prompt Engineering Towards ZeroShot and Interpretable Log Analysis", arXiv:2308.07610v1, 2023.
[21] A. Oliner and J. Stearley, "What supercomputers say: A study of five system logs," in DSN, 2007.
[22] P. Lewis, E. Perez, A. Piktus, F. Petroni, V. Karpukhin, N. Goyal, H. Küttler, M. Lewis,W. Yih, T. Rocktäschel, et al., "Retrieval-augmented generation for knowledge-intensive nlp tasks", Advances in Neural Information Processing Systems, 33:9459-9474, 2020.
[23] K. Lee, M. W. Chang, and K. Toutanov, "Latent retrieval for weakly supervised open domain question answering", arXiv:1906.00300, 2019.
[24] H. Chase, LangChain, langchain.com.</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>(C) 2023 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other users for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works.&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>