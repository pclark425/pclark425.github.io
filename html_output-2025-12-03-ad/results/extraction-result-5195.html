<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-5195 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-5195</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-5195</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-109.html">extraction-schema-109</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of theories, models, or empirical findings about the representational format of conceptual knowledge in brains at a functional (not neural) level.</div>
                <p><strong>Paper ID:</strong> paper-259367416</p>
                <p><strong>Paper Title:</strong> Modal and amodal cognition: an overarching principle in various domains of psychology</p>
                <p><strong>Paper Abstract:</strong> Accounting for how the human mind represents the internal and external world is a crucial feature of many theories of human cognition. Central to this question is the distinction between modal as opposed to amodal representational formats. It has often been assumed that one but not both of these two types of representations underlie processing in specific domains of cognition (e.g., perception, mental imagery, and language). However, in this paper, we suggest that both formats play a major role in most cognitive domains. We believe that a comprehensive theory of cognition requires a solid understanding of these representational formats and their functional roles within and across different domains of cognition, the developmental trajectory of these representational formats, and their role in dysfunctional behavior. Here we sketch such an overarching perspective that brings together research from diverse subdisciplines of psychology on modal and amodal representational formats so as to unravel their functional principles and their interactions.</p>
                <p><strong>Cost:</strong> 0.026</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e5195.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e5195.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of theories, models, or empirical findings about the representational format of conceptual knowledge in brains at a functional (not neural) level.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Modal representations</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Modal (experiential, modality-specific) representations</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Representations that preserve the structure of sensory or motor experience (quasi-perceptual, modality-specific traces or simulations) and are used to capture concrete instance-level information about objects, events, and attributes.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_name</strong></td>
                            <td>Modal representation account</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_description</strong></td>
                            <td>Conceptual knowledge is encoded as re-activated sensory-motor traces or image-like representations that preserve the structure of prior experiences (isomorphic mapping between world and representation), and can be instantiated without external stimulation to support perception, simulation, and immediate action.</td>
                        </tr>
                        <tr>
                            <td><strong>representation_format_type</strong></td>
                            <td>Modality-specific, analog / quasi-perceptual</td>
                        </tr>
                        <tr>
                            <td><strong>key_properties</strong></td>
                            <td>Structure-preserving (isomorphic to experience), modality-specific (visual, auditory, tactile, motor), can be holistic, can be multi-modal via cue-integration, often non-compositional or weakly compositional.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_support</strong></td>
                            <td>Behavioral findings of sensorimotor activation during language tasks, imagery effects (Kosslyn-type findings referenced), action-language congruency and priming studies, developmental studies showing early sensorimotor-driven learning, habituation patterns in emotion showing attenuation of 'hot' (sensory/affective) responses, and many experimental tasks where modality-specific manipulations affect performance (as summarized throughout the review).</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_challenges</strong></td>
                            <td>Context-dependent activation in adults (many studies show modal activations are conditional), evidence that modal activations can be epiphenomenal (not causally necessary for comprehension or decision), findings of cross-modal matching and abstraction that require modality-general representations, and failures to find functional effects of sensorimotor activations in some paradigms (mixed replication/robustness).</td>
                        </tr>
                        <tr>
                            <td><strong>applied_domains_or_tasks</strong></td>
                            <td>Perception, mental imagery, language comprehension and production (action verbs, negation), emotion (affective responses), action planning and control, event cognition, developmental word learning.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_models</strong></td>
                            <td>Contrasted with amodal/propositional symbolic accounts which posit modality-independent compositional representations; contrasted with hybrid models that posit both modal traces and amodal representations; often pitted against claims that modal activations are epiphenomenal.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_mechanisms</strong></td>
                            <td>Modal representations are re-activated simulations that can guide immediate perception-action loops, provide detailed instance-level content for comparison and recognition, and be bound across modalities to create richer situation representations (e.g., via convergence zones).</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_open_questions</strong></td>
                            <td>When and whether modal activations are functionally necessary versus epiphenomenal; how modal traces are combined/compositionalized; developmental trajectory (do modal representations give way to amodal?), and mechanisms for cross-modal abstraction and preservation vs. loss of perceptual detail.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Modal and amodal cognition: an overarching principle in various domains of psychology', 'publication_date_yy_mm': '2023-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5195.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e5195.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of theories, models, or empirical findings about the representational format of conceptual knowledge in brains at a functional (not neural) level.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Amodal representations</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Amodal (abstract, symbolic, modality-general) representations</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Abstract, modality-independent representations (e.g., propositional codes, feature lists, frames, schemata) that encode meaning in a structure different from sensory experience and support composition and truth-evaluable assertions.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_name</strong></td>
                            <td>Amodal (symbolic/propositional) representation account</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_description</strong></td>
                            <td>Conceptual knowledge is represented in modality-independent, often compositional symbolic structures (propositions, semantic networks, frames) that abstract away from instance-level sensory details and support combinatorial reasoning and cross-modal comparisons.</td>
                        </tr>
                        <tr>
                            <td><strong>representation_format_type</strong></td>
                            <td>Symbolic / propositional / feature-based / modality-general</td>
                        </tr>
                        <tr>
                            <td><strong>key_properties</strong></td>
                            <td>Structure-agnostic relative to sensory input, compositional (elements can be combined into complex propositions), modality-general (integrates information across modalities), truth-evaluable, supports domain-general reasoning and comparison.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_support</strong></td>
                            <td>Success of propositional/compositional models for language comprehension and reasoning (e.g., Kintsch, McKoon & Ratcliff paradigms), crossmodal matching tasks that require modality-independent scales (e.g., time comparisons across modalities), and developmental findings indicating early availability of abstract core concepts in some domains.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_challenges</strong></td>
                            <td>Grounded/embodied evidence showing sensorimotor involvement in many tasks, mixed evidence about whether propositional representations suffice to explain fast perceptual and action-guiding behavior, and difficulty explaining how abstract symbols acquire content without grounding in experience (the grounding problem).</td>
                        </tr>
                        <tr>
                            <td><strong>applied_domains_or_tasks</strong></td>
                            <td>Language comprehension and production (propositional networks), reasoning/problem solving, cross-modal comparisons, cognitive control and hierarchical task representations, some models of motor schemas (effector-independent programs).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_models</strong></td>
                            <td>Contrasted with modal/embodied accounts (which emphasize sensorimotor traces); often invoked as complementary in hybrid models; stronger on compositionality and combinatoric reasoning but weaker on explaining sensorimotor detail and immediate action guidance.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_mechanisms</strong></td>
                            <td>Operate as abstract codes that can be composed into larger propositions, used by higher-level processes for inference, truth-evaluation, planning, and cross-domain comparison; support hierarchically organized control.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_open_questions</strong></td>
                            <td>How amodal symbols obtain semantic content (grounding), the degree to which amodal representations are innate vs. learned, and how they interact dynamically with modal traces during real-time cognition.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Modal and amodal cognition: an overarching principle in various domains of psychology', 'publication_date_yy_mm': '2023-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5195.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e5195.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of theories, models, or empirical findings about the representational format of conceptual knowledge in brains at a functional (not neural) level.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Modal–Amodal continuum</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Modal-to-amodal representational continuum</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A theoretical framework placing representational formats along a graded plane from structure-preserving, modality-specific (modal) to structure-agnostic, symbolic, modality-general (amodal), emphasizing hybrid and intermediate formats rather than a strict dichotomy.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_name</strong></td>
                            <td>Modal–Amodal continuum framework</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_description</strong></td>
                            <td>Represents conceptual formats on two primary dimensions (analog-to-symbolic and modality-specific-to-modality-general) with modal and amodal extremes and many intermediate formats (e.g., geons, schemas, frames), proposing that cognitive processes operate on different points of this continuum depending on task demands and levels of hierarchy.</td>
                        </tr>
                        <tr>
                            <td><strong>representation_format_type</strong></td>
                            <td>Continuum encompassing analog/modal, symbolic/amodal, and intermediate hybrid formats</td>
                        </tr>
                        <tr>
                            <td><strong>key_properties</strong></td>
                            <td>Graded rather than dichotomous; captures compositionality, modality-specificity, abstraction, and structure-preservation as continuous dimensions; allows domain- and task-dependent placement of representations.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_support</strong></td>
                            <td>Synthesis of evidence across perception, action, language, learning, development, and emotion indicating (1) modality-specific effects in many tasks, (2) modality-general/compositional representations in reasoning and language, and (3) hybrid and context-dependent activation patterns reported in the literature.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_challenges</strong></td>
                            <td>Difficulty in operationalizing exact placement of specific phenomena along the continuum; empirical heterogeneity and mixed results across studies make precise predictions challenging; possible discontinuities (e.g., propositional symbolic threshold) complicate pure continuum view.</td>
                        </tr>
                        <tr>
                            <td><strong>applied_domains_or_tasks</strong></td>
                            <td>Used as an organizing principle across domains covered in the review: perception, action, cognitive control, learning, emotion, language, thought, development, and dysfunction.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_models</strong></td>
                            <td>Integrates and subsumes opposing views (purely modal vs purely amodal) by allowing hybrid accounts; contrasts with single-format theories that cannot account for cross-domain findings.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_mechanisms</strong></td>
                            <td>Predicts that processes and tasks will recruit representations at different points on the continuum (e.g., immediate action/control -> more modal; combinatorial language processing -> more amodal); posits interactions between levels (e.g., binding of modality-specific traces to amodal schemata).</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_open_questions</strong></td>
                            <td>How to measure and map real cognitive representations to coordinates on the continuum; whether transitions are continuous or contain qualitative discontinuities (e.g., true propositional symbols); mechanistic details of interactions between levels remain underspecified.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Modal and amodal cognition: an overarching principle in various domains of psychology', 'publication_date_yy_mm': '2023-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5195.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e5195.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of theories, models, or empirical findings about the representational format of conceptual knowledge in brains at a functional (not neural) level.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Grounded / Perceptual Symbol Systems</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Grounded cognition / Perceptual Symbol Systems (Barsalou)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Theory that concepts are constituted by re-activated modality-specific perceptual and motor states (simulations) rather than amodal symbols; conceptual processing uses the same systems as perception and action.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Perceptions of perceptual symbols</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_name</strong></td>
                            <td>Grounded cognition / Perceptual Symbol Systems</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_description</strong></td>
                            <td>Conceptual knowledge consists of partial re-enactments of past sensorimotor experience (perceptual symbols) which are flexibly combined to form conceptual representations and used in language and reasoning via simulation.</td>
                        </tr>
                        <tr>
                            <td><strong>representation_format_type</strong></td>
                            <td>Modal, distributed sensorimotor traces / simulation-based</td>
                        </tr>
                        <tr>
                            <td><strong>key_properties</strong></td>
                            <td>Context-dependent activation, flexible recombination of experiential traces, modality-specific instantiation, supports detailed instance-level content and mental simulation.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_support</strong></td>
                            <td>Behavioral and neuroimaging studies showing modality-specific activations during language and conceptual tasks, switching costs across modalities in property-verification tasks, and task-dependent embodiment effects summarized in the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_challenges</strong></td>
                            <td>Mixed evidence about functional necessity (some studies show epiphenomenal activations), robustness and boundary conditions of embodiment effects, and the need to explain compositionality and abstract concepts.</td>
                        </tr>
                        <tr>
                            <td><strong>applied_domains_or_tasks</strong></td>
                            <td>Language comprehension, property verification, action-language congruency, developmental simulations, emotion and affective priming paradigms.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_models</strong></td>
                            <td>Opposed to purely amodal symbolic models; shares similarities with modal end of continuum but differs in emphasizing simulation as constitutive of concepts rather than as added trace.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_mechanisms</strong></td>
                            <td>Meaning arises via reactivation (simulation) of distributed perceptual-motor states; combinatorial conceptual content arises from binding and partial reactivation of relevant experiential traces.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_open_questions</strong></td>
                            <td>Extent to which simulations are necessary vs. incidental, how highly abstract concepts are represented, and mechanistic account of how simulations become combinatorial/compositional.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Modal and amodal cognition: an overarching principle in various domains of psychology', 'publication_date_yy_mm': '2023-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5195.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e5195.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of theories, models, or empirical findings about the representational format of conceptual knowledge in brains at a functional (not neural) level.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Language of Thought / Propositional</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Language-of-Thought / Propositional representation (Fodor; Kintsch)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Theory positing that thinking and conceptual representation use internal, language-like (propositional) symbol structures that are compositional and support classical logical and combinatorial operations.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>The language of thought</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_name</strong></td>
                            <td>Language-of-Thought / Propositional representations</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_description</strong></td>
                            <td>Conceptual knowledge is encoded as symbolic propositions (discrete tokens combined by syntactic/compositional rules) forming a combinatorial language-like system underlying thought and higher cognition.</td>
                        </tr>
                        <tr>
                            <td><strong>representation_format_type</strong></td>
                            <td>Amodal, symbolic, compositional / propositional</td>
                        </tr>
                        <tr>
                            <td><strong>key_properties</strong></td>
                            <td>Compositionality, discrete symbols, systematicity, supports rule-based inference, truth-evaluability and explicit propositional structure.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_support</strong></td>
                            <td>Success of symbolic/compositional models in explaining aspects of sentence comprehension, logical reasoning, and structured problem solving; fits accounts of high-level linguistic meaning representations discussed in the review.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_challenges</strong></td>
                            <td>Grounding problem (how symbols get meaning), empirical evidence of sensorimotor involvement in many tasks, criticisms from connectionist and embodied frameworks about universality of symbolic representations.</td>
                        </tr>
                        <tr>
                            <td><strong>applied_domains_or_tasks</strong></td>
                            <td>Language comprehension and production, formal reasoning, models of propositional discourse models (Kintsch construction-integration), cognitive architectures.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_models</strong></td>
                            <td>Contrasts with embodied and distributed models; stronger in compositional explanation but weaker in accounting for perceptual detail and sensorimotor-driven phenomena.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_mechanisms</strong></td>
                            <td>Symbols are combined via syntactic rules to form propositions which are manipulated by cognitive processes for inference, planning, and communication.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_open_questions</strong></td>
                            <td>How symbolic representations are learned/grounded from experience and if purely symbolic codes suffice for perception-action tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Modal and amodal cognition: an overarching principle in various domains of psychology', 'publication_date_yy_mm': '2023-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5195.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e5195.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of theories, models, or empirical findings about the representational format of conceptual knowledge in brains at a functional (not neural) level.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Hybrid / Convergence Zone</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Hybrid models / Convergence Zone framework (Damasio) and Binder & Desai</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Frameworks proposing that conceptual knowledge comprises both modality-specific (modal) traces and modality-independent (amodal) hubs or convergence zones that bind and abstract across modalities.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Time-locked multiregional retroactivation: A systems-level proposal for the neural substrates of recall and recognition.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_name</strong></td>
                            <td>Hybrid representation / Convergence Zone / Hub-and-spoke</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_description</strong></td>
                            <td>Concepts are represented by distributed modality-specific 'spokes' (sensory-motor traces) and amodal 'hubs' or convergence zones that integrate and abstract over modalities; both formats serve complementary functions.</td>
                        </tr>
                        <tr>
                            <td><strong>representation_format_type</strong></td>
                            <td>Hybrid: distributed modality-specific traces + amodal integrative representations (hubs)</td>
                        </tr>
                        <tr>
                            <td><strong>key_properties</strong></td>
                            <td>Dual components (modal spokes and amodal hub), supports both detailed simulations and cross-modal abstraction/compositionality, flexible depending on task demands.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_support</strong></td>
                            <td>Neuropsychological and imaging data (as reviewed) supporting modality-specific activations and domain-general semantic hubs; behavioral work showing conditions where amodal generalization occurs and other conditions where modal traces dominate.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_challenges</strong></td>
                            <td>Precisely specifying functional roles and dynamics between hubs and spokes, variability across domains and developmental stages, and dissociation evidence that sometimes undermines simple hub-spoke mappings.</td>
                        </tr>
                        <tr>
                            <td><strong>applied_domains_or_tasks</strong></td>
                            <td>Semantic memory, language comprehension, crossmodal matching, concept learning, and generalization tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_models</strong></td>
                            <td>Positions between pure modal and pure amodal accounts, aiming to capture strengths of both; more biologically and functionally integrative but raises mechanistic questions about binding and timing.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_mechanisms</strong></td>
                            <td>Convergence zones/hubs bind activations from modality-specific systems to form abstract representations; task demands modulate reliance on spokes vs hubs; supports both simulation-based and symbolic processing.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_open_questions</strong></td>
                            <td>How exactly hubs extract invariant structure, how binding is achieved functionally (timing, attention), and developmental trajectory of hub-spoke formation.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Modal and amodal cognition: an overarching principle in various domains of psychology', 'publication_date_yy_mm': '2023-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5195.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e5195.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of theories, models, or empirical findings about the representational format of conceptual knowledge in brains at a functional (not neural) level.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Predictive coding / hierarchical</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Predictive coding / hierarchical predictive processing (Clark; Friston)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A hierarchical processing account where higher levels encode abstract, modality-general expectations and lower levels encode modality-specific sensory details; perception and cognition emerge from minimizing prediction error across levels.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Whatever next? Predictive brains, situated agents, and the future of cognitive science.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_name</strong></td>
                            <td>Predictive coding / hierarchical predictive processing</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_description</strong></td>
                            <td>Knowledge is organized in a processing hierarchy: higher levels hold abstract/amodal expectations (priors) while lower levels hold specific/modality-bound representations; interaction via top-down predictions and bottom-up prediction errors yields perception, inference, and abstraction.</td>
                        </tr>
                        <tr>
                            <td><strong>representation_format_type</strong></td>
                            <td>Hierarchical mixture: lower-level modal codes, higher-level amodal/abstract priors (continuum)</td>
                        </tr>
                        <tr>
                            <td><strong>key_properties</strong></td>
                            <td>Top-down/bottom-up interaction, hierarchical abstraction, dynamic updating via prediction-error minimization, supports both modal detail and amodal generalization depending on level.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_support</strong></td>
                            <td>Explains a wide range of perceptual phenomena (context effects, word superiority), and provides an integrative account consistent with findings of modality-specific lower-level processing and abstract higher-level processing discussed in paper.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_challenges</strong></td>
                            <td>Broadness of theory makes specific empirical tests difficult; debates about falsifiability and whether predictive coding can fully account for representational content and combinatorial symbolic structure.</td>
                        </tr>
                        <tr>
                            <td><strong>applied_domains_or_tasks</strong></td>
                            <td>Perception, language comprehension, event segmentation, cross-modal integration, and accounts of hierarchical cognitive control.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_models</strong></td>
                            <td>Provides a mechanistic bridge between modal and amodal formats by placing them at different hierarchical levels; contrasts with single-level symbolic or purely modal simulation accounts.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_mechanisms</strong></td>
                            <td>Generative models at higher levels send predictions; lower levels return prediction errors prompting model updating; abstraction emerges in higher-level priors that are modality-general.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_open_questions</strong></td>
                            <td>Operationalizing representational format at each level, demonstrating direct causal role of prediction-error dynamics in conceptual abstraction, and specifying how compositional symbolic structure arises within the predictive hierarchy.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Modal and amodal cognition: an overarching principle in various domains of psychology', 'publication_date_yy_mm': '2023-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5195.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e5195.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of theories, models, or empirical findings about the representational format of conceptual knowledge in brains at a functional (not neural) level.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Recognition-by-components (Geon)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Recognition-by-components (Geon theory; Biederman)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A functional model of object representation proposing view-invariant, component-based (geon) structural descriptions that are nonlinguistic and amodal relative to viewpoint.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Recognition-by-components: A theory of human image understanding.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_name</strong></td>
                            <td>Geon / recognition-by-components theory</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_description</strong></td>
                            <td>Objects are represented as configurations of a limited set of geometric components (geons) and their spatial relations, producing viewpoint-invariant, compositional object representations that are closer to amodal structural formats than to image-like representations.</td>
                        </tr>
                        <tr>
                            <td><strong>representation_format_type</strong></td>
                            <td>Amodal, structural, compositional (component-based)</td>
                        </tr>
                        <tr>
                            <td><strong>key_properties</strong></td>
                            <td>Finite primitive set (geons), compositional assembly, viewpoint invariance, emphasizes structural relations over image-specific detail.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_support</strong></td>
                            <td>Explains object recognition robustness across views, supports compositional recognition tasks where component recombination predicts recognition performance (cited historically in review).</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_challenges</strong></td>
                            <td>Multiple-views theories and template-like holistic representations explain some phenomena better; debate about whether geon decomposition captures all real-world object recognition complexities.</td>
                        </tr>
                        <tr>
                            <td><strong>applied_domains_or_tasks</strong></td>
                            <td>Object recognition, visual categorization, studies contrasting viewpoint-invariant vs. view-based representations.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_models</strong></td>
                            <td>Located toward the amodal/compositional quadrant of the continuum; contrasted with multiple-view/template and holistic image-like accounts.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_mechanisms</strong></td>
                            <td>Visual input is parsed into geon primitives and relations, producing a structural description used for recognition and categorization.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_open_questions</strong></td>
                            <td>Extent to which geon primitives are psychologically real across varied object classes and how geon-like representations interact with modality-specific pictorial traces for recognition.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Modal and amodal cognition: an overarching principle in various domains of psychology', 'publication_date_yy_mm': '2023-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5195.8">
                <h3 class="extraction-instance">Extracted Data Instance 8 (e5195.8)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of theories, models, or empirical findings about the representational format of conceptual knowledge in brains at a functional (not neural) level.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Multiple-views theory</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Multiple canonical-view / template-matching theories (Tarr & Bülthoff)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Theories proposing that object representations are stored as several canonical viewpoint-specific holistic templates, and recognition proceeds by aligning input to the stored view that best matches.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Is human object recognition better described by geon structural descriptions or by multiple views?.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_name</strong></td>
                            <td>Multiple-views (viewpoint-specific / template) theory</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_description</strong></td>
                            <td>Object memory contains multiple stored 2-D (or holistic) canonical views that are matched (possibly via rotation) against incoming images to accomplish recognition; representations are relatively modal, image-like, and viewpoint-specific.</td>
                        </tr>
                        <tr>
                            <td><strong>representation_format_type</strong></td>
                            <td>Modal, viewpoint-specific, template-like / holistic</td>
                        </tr>
                        <tr>
                            <td><strong>key_properties</strong></td>
                            <td>Viewpoint-specific templates, holistic representations, requires alignment/rotation operations for recognition, preserves pictorial detail.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_support</strong></td>
                            <td>Accounts for viewpoint effects and some recognition phenomena where alignment to stored views predicts performance; used as example placement on the modal side of the continuum in the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_challenges</strong></td>
                            <td>Cannot easily explain viewpoint-invariant recognition without large template sets; geon-style structural descriptions and feature-analysis models explain invariance with fewer primitives.</td>
                        </tr>
                        <tr>
                            <td><strong>applied_domains_or_tasks</strong></td>
                            <td>Object recognition, studies of viewpoint dependence, comparison with structural-description models.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_models</strong></td>
                            <td>Opposed to geon structural/compositional models; more modal and image-like versus amodal compositional accounts.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_mechanisms</strong></td>
                            <td>Recognition via matching input image to nearest stored canonical view and performing transformations (e.g., mental rotation) to align viewpoints.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_open_questions</strong></td>
                            <td>How viewpoint-specific templates are learned and stored efficiently, and how holistic templates interact with structural/compositional representations.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Modal and amodal cognition: an overarching principle in various domains of psychology', 'publication_date_yy_mm': '2023-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5195.9">
                <h3 class="extraction-instance">Extracted Data Instance 9 (e5195.9)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of theories, models, or empirical findings about the representational format of conceptual knowledge in brains at a functional (not neural) level.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>SUSTAIN / category models</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>SUSTAIN (network model of category learning; Love et al.) and prototype/exemplar models</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Computational models of category learning that explain how representations of categories (prototypes, exemplars, clusters) are formed and used for classification and generalization, including mechanisms for abstraction and attentional weighting.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>SUSTAIN: A network model of category learning.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_name</strong></td>
                            <td>SUSTAIN / prototype and exemplar models</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_description</strong></td>
                            <td>Models propose that category knowledge arises from either stored exemplars, an abstracted prototype, or dynamically formed clusters (SUSTAIN) with attentional tuning and dimensional weighting, explaining how abstraction from instances can occur functionally.</td>
                        </tr>
                        <tr>
                            <td><strong>representation_format_type</strong></td>
                            <td>Distributed exemplar representations, prototype (summary) representations, cluster-based hybrid (SUSTAIN)</td>
                        </tr>
                        <tr>
                            <td><strong>key_properties</strong></td>
                            <td>Instance-based vs. abstract summary forms, attentional weighting of diagnostic dimensions, capacity for generalization and sensitivity to exemplar variability.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_support</strong></td>
                            <td>Accounts for many category-learning phenomena and effects of exemplar variability and label-order on learning (discussed in review, e.g., Ramscar, Lupyan work), and SUSTAIN explains clustering and rule-learning patterns.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_challenges</strong></td>
                            <td>Debates about whether people use exemplars, prototypes, or rules in different tasks; how such models scale to complex real-world conceptual structure; mapping to neural implementation.</td>
                        </tr>
                        <tr>
                            <td><strong>applied_domains_or_tasks</strong></td>
                            <td>Concept learning, categorization, word learning, generalization vs. discrimination tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_models</strong></td>
                            <td>Offers process-level mechanisms for abstraction versus purely symbolic accounts; complements grounded accounts by explaining statistical/discriminative learning processes that produce amodal abstractions.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_mechanisms</strong></td>
                            <td>Learning driven by error and attention-driven clustering or abstraction; diagnostic features are upweighted leading to prototype-like or cluster representations under different conditions.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_open_questions</strong></td>
                            <td>How to predict when exemplar vs prototype vs cluster representations will dominate, and integration with modality-specific simulation accounts.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Modal and amodal cognition: an overarching principle in various domains of psychology', 'publication_date_yy_mm': '2023-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5195.10">
                <h3 class="extraction-instance">Extracted Data Instance 10 (e5195.10)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of theories, models, or empirical findings about the representational format of conceptual knowledge in brains at a functional (not neural) level.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Rescorla–Wagner / discriminative</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Rescorla–Wagner associative learning and discriminative error-driven account (Ramscar et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Error-driven associative learning framework where cue competition and prediction-error-driven updating can lead to abstraction or retention of modal features depending on exemplar variability and predictive structure.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Pavlovian conditioning: It's not what you think it is.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_name</strong></td>
                            <td>Rescorla–Wagner and discriminative (error-driven) learning account</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_description</strong></td>
                            <td>Learning updates associative weights via prediction error; when exemplars are variable and cue-competition occurs, learners abstract over uninformative dimensions producing amodal representations, whereas low variability favors retention of modal instance details.</td>
                        </tr>
                        <tr>
                            <td><strong>representation_format_type</strong></td>
                            <td>Associative weight matrices that can yield more abstract (amodal) or more concrete (modal) representational outcomes depending on input structure</td>
                        </tr>
                        <tr>
                            <td><strong>key_properties</strong></td>
                            <td>Error-driven updating, cue competition, sensitivity to exemplar variability, yields discriminative emphasis on diagnostic features producing abstraction.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_support</strong></td>
                            <td>Empirical results summarized showing variability-driven abstraction in evaluative conditioning and conceptual learning (e.g., Reichmann et al. 2022; Ramscar et al. manipulations), and classical findings on cue competition and associative learning.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_challenges</strong></td>
                            <td>Associative models historically criticized for not capturing higher-level compositional structure; distinguishing abstraction due to model dynamics vs. other cognitive processes experimentally can be difficult.</td>
                        </tr>
                        <tr>
                            <td><strong>applied_domains_or_tasks</strong></td>
                            <td>Associative learning, evaluative conditioning, word learning, concept learning and generalization tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_models</strong></td>
                            <td>Provides a mechanistic learning account that can produce amodal abstractions without appealing to pre-existing symbolic formats; contrasts with purely symbolic/innate accounts.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_mechanisms</strong></td>
                            <td>Prediction errors drive strengthening/weakening of cue-outcome associations; cue competition removes uninformative cues, biasing representations towards diagnostic (abstract) features.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_open_questions</strong></td>
                            <td>How to scale to structured/compositional semantic knowledge and how to integrate with simulation-based/modal representations; empirical separation of learning-driven abstraction vs. task strategy effects.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Modal and amodal cognition: an overarching principle in various domains of psychology', 'publication_date_yy_mm': '2023-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5195.11">
                <h3 class="extraction-instance">Extracted Data Instance 11 (e5195.11)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of theories, models, or empirical findings about the representational format of conceptual knowledge in brains at a functional (not neural) level.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Theory of Event Coding (TEC) & Perception-Action</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Theory of Event Coding (TEC) and Perception-for-Action model (Hommel; Milner & Goodale)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Frameworks linking perception and action representations: TEC posits common code representations for perceived and produced event features (often amodal at planning level), while the perception-action model distinguishes ventral (perception) and dorsal (action control) streams with different representational formats.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>The Theory of Event Coding (TEC): A framework for perception and action planning.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_name</strong></td>
                            <td>Theory of Event Coding (TEC) / Perception-for-Action model</td>
                        </tr>
                        <tr>
                            <td><strong>theory_or_model_description</strong></td>
                            <td>TEC: perception and action share common representational codes (event files) that can be amodal/abstract for planning; Perception-for-Action: two visual streams (ventral amodal perception and dorsal modality-specific action control) operate with different representational formats.</td>
                        </tr>
                        <tr>
                            <td><strong>representation_format_type</strong></td>
                            <td>TEC: event-file bindings that can be amodal/abstract or include modality-specific features; Perception-action: dorsal stream—modal/action-oriented; ventral stream—perceptual/recognition-oriented (more amodal at higher levels).</td>
                        </tr>
                        <tr>
                            <td><strong>key_properties</strong></td>
                            <td>Binding of stimulus and response features, shared codes for perception and action, planned actions can be represented abstractly while control can rely on modality-specific metrics.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_support</strong></td>
                            <td>Behavioral literature on response-effect learning, compatibility effects, and many studies discussed in review showing interactions between perception and action representations; neuropsychological evidence for dorsal/ventral stream specialization.</td>
                        </tr>
                        <tr>
                            <td><strong>empirical_challenges</strong></td>
                            <td>Empirical inconsistencies (e.g., illusions may affect grasping similarly to perception), mixed findings on whether planning is amodal and control modal, and variable generalization in response-effect learning.</td>
                        </tr>
                        <tr>
                            <td><strong>applied_domains_or_tasks</strong></td>
                            <td>Action planning and control, motor learning, response-effect compatibility tasks, studies of perception-action dissociations.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_models</strong></td>
                            <td>Bridges modal and amodal accounts by specifying representational roles across planning vs control and perception vs action streams; contrasts with purely symbolic or purely simulation accounts of action representation.</td>
                        </tr>
                        <tr>
                            <td><strong>functional_mechanisms</strong></td>
                            <td>Formation of event files binding stimulus and action features (TEC); ventral pathway supports recognition/abstract identification while dorsal pathway computes egocentric, metric control signals for action.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_open_questions</strong></td>
                            <td>Degree and conditions under which planning is amodal vs. modal; reconciling mixed empirical results about illusions, Weber's law violations, and generalization across effect features.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Modal and amodal cognition: an overarching principle in various domains of psychology', 'publication_date_yy_mm': '2023-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Perceptions of perceptual symbols <em>(Rating: 2)</em></li>
                <li>The language of thought <em>(Rating: 2)</em></li>
                <li>Whatever next? Predictive brains, situated agents, and the future of cognitive science. <em>(Rating: 2)</em></li>
                <li>Recognition-by-components: A theory of human image understanding. <em>(Rating: 2)</em></li>
                <li>The Theory of Event Coding (TEC): A framework for perception and action planning. <em>(Rating: 2)</em></li>
                <li>SUSTAIN: A network model of category learning. <em>(Rating: 2)</em></li>
                <li>Pavlovian conditioning: It's not what you think it is. <em>(Rating: 1)</em></li>
                <li>Time-locked multiregional retroactivation: A systems-level proposal for the neural substrates of recall and recognition. <em>(Rating: 1)</em></li>
                <li>The free-energy principle: A unified brain theory? <em>(Rating: 1)</em></li>
                <li>Is human object recognition better described by geon structural descriptions or by multiple views?. <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-5195",
    "paper_id": "paper-259367416",
    "extraction_schema_id": "extraction-schema-109",
    "extracted_data": [
        {
            "name_short": "Modal representations",
            "name_full": "Modal (experiential, modality-specific) representations",
            "brief_description": "Representations that preserve the structure of sensory or motor experience (quasi-perceptual, modality-specific traces or simulations) and are used to capture concrete instance-level information about objects, events, and attributes.",
            "citation_title": "here",
            "mention_or_use": "use",
            "theory_or_model_name": "Modal representation account",
            "theory_or_model_description": "Conceptual knowledge is encoded as re-activated sensory-motor traces or image-like representations that preserve the structure of prior experiences (isomorphic mapping between world and representation), and can be instantiated without external stimulation to support perception, simulation, and immediate action.",
            "representation_format_type": "Modality-specific, analog / quasi-perceptual",
            "key_properties": "Structure-preserving (isomorphic to experience), modality-specific (visual, auditory, tactile, motor), can be holistic, can be multi-modal via cue-integration, often non-compositional or weakly compositional.",
            "empirical_support": "Behavioral findings of sensorimotor activation during language tasks, imagery effects (Kosslyn-type findings referenced), action-language congruency and priming studies, developmental studies showing early sensorimotor-driven learning, habituation patterns in emotion showing attenuation of 'hot' (sensory/affective) responses, and many experimental tasks where modality-specific manipulations affect performance (as summarized throughout the review).",
            "empirical_challenges": "Context-dependent activation in adults (many studies show modal activations are conditional), evidence that modal activations can be epiphenomenal (not causally necessary for comprehension or decision), findings of cross-modal matching and abstraction that require modality-general representations, and failures to find functional effects of sensorimotor activations in some paradigms (mixed replication/robustness).",
            "applied_domains_or_tasks": "Perception, mental imagery, language comprehension and production (action verbs, negation), emotion (affective responses), action planning and control, event cognition, developmental word learning.",
            "comparison_to_other_models": "Contrasted with amodal/propositional symbolic accounts which posit modality-independent compositional representations; contrasted with hybrid models that posit both modal traces and amodal representations; often pitted against claims that modal activations are epiphenomenal.",
            "functional_mechanisms": "Modal representations are re-activated simulations that can guide immediate perception-action loops, provide detailed instance-level content for comparison and recognition, and be bound across modalities to create richer situation representations (e.g., via convergence zones).",
            "limitations_or_open_questions": "When and whether modal activations are functionally necessary versus epiphenomenal; how modal traces are combined/compositionalized; developmental trajectory (do modal representations give way to amodal?), and mechanisms for cross-modal abstraction and preservation vs. loss of perceptual detail.",
            "uuid": "e5195.0",
            "source_info": {
                "paper_title": "Modal and amodal cognition: an overarching principle in various domains of psychology",
                "publication_date_yy_mm": "2023-10"
            }
        },
        {
            "name_short": "Amodal representations",
            "name_full": "Amodal (abstract, symbolic, modality-general) representations",
            "brief_description": "Abstract, modality-independent representations (e.g., propositional codes, feature lists, frames, schemata) that encode meaning in a structure different from sensory experience and support composition and truth-evaluable assertions.",
            "citation_title": "here",
            "mention_or_use": "use",
            "theory_or_model_name": "Amodal (symbolic/propositional) representation account",
            "theory_or_model_description": "Conceptual knowledge is represented in modality-independent, often compositional symbolic structures (propositions, semantic networks, frames) that abstract away from instance-level sensory details and support combinatorial reasoning and cross-modal comparisons.",
            "representation_format_type": "Symbolic / propositional / feature-based / modality-general",
            "key_properties": "Structure-agnostic relative to sensory input, compositional (elements can be combined into complex propositions), modality-general (integrates information across modalities), truth-evaluable, supports domain-general reasoning and comparison.",
            "empirical_support": "Success of propositional/compositional models for language comprehension and reasoning (e.g., Kintsch, McKoon & Ratcliff paradigms), crossmodal matching tasks that require modality-independent scales (e.g., time comparisons across modalities), and developmental findings indicating early availability of abstract core concepts in some domains.",
            "empirical_challenges": "Grounded/embodied evidence showing sensorimotor involvement in many tasks, mixed evidence about whether propositional representations suffice to explain fast perceptual and action-guiding behavior, and difficulty explaining how abstract symbols acquire content without grounding in experience (the grounding problem).",
            "applied_domains_or_tasks": "Language comprehension and production (propositional networks), reasoning/problem solving, cross-modal comparisons, cognitive control and hierarchical task representations, some models of motor schemas (effector-independent programs).",
            "comparison_to_other_models": "Contrasted with modal/embodied accounts (which emphasize sensorimotor traces); often invoked as complementary in hybrid models; stronger on compositionality and combinatoric reasoning but weaker on explaining sensorimotor detail and immediate action guidance.",
            "functional_mechanisms": "Operate as abstract codes that can be composed into larger propositions, used by higher-level processes for inference, truth-evaluation, planning, and cross-domain comparison; support hierarchically organized control.",
            "limitations_or_open_questions": "How amodal symbols obtain semantic content (grounding), the degree to which amodal representations are innate vs. learned, and how they interact dynamically with modal traces during real-time cognition.",
            "uuid": "e5195.1",
            "source_info": {
                "paper_title": "Modal and amodal cognition: an overarching principle in various domains of psychology",
                "publication_date_yy_mm": "2023-10"
            }
        },
        {
            "name_short": "Modal–Amodal continuum",
            "name_full": "Modal-to-amodal representational continuum",
            "brief_description": "A theoretical framework placing representational formats along a graded plane from structure-preserving, modality-specific (modal) to structure-agnostic, symbolic, modality-general (amodal), emphasizing hybrid and intermediate formats rather than a strict dichotomy.",
            "citation_title": "here",
            "mention_or_use": "use",
            "theory_or_model_name": "Modal–Amodal continuum framework",
            "theory_or_model_description": "Represents conceptual formats on two primary dimensions (analog-to-symbolic and modality-specific-to-modality-general) with modal and amodal extremes and many intermediate formats (e.g., geons, schemas, frames), proposing that cognitive processes operate on different points of this continuum depending on task demands and levels of hierarchy.",
            "representation_format_type": "Continuum encompassing analog/modal, symbolic/amodal, and intermediate hybrid formats",
            "key_properties": "Graded rather than dichotomous; captures compositionality, modality-specificity, abstraction, and structure-preservation as continuous dimensions; allows domain- and task-dependent placement of representations.",
            "empirical_support": "Synthesis of evidence across perception, action, language, learning, development, and emotion indicating (1) modality-specific effects in many tasks, (2) modality-general/compositional representations in reasoning and language, and (3) hybrid and context-dependent activation patterns reported in the literature.",
            "empirical_challenges": "Difficulty in operationalizing exact placement of specific phenomena along the continuum; empirical heterogeneity and mixed results across studies make precise predictions challenging; possible discontinuities (e.g., propositional symbolic threshold) complicate pure continuum view.",
            "applied_domains_or_tasks": "Used as an organizing principle across domains covered in the review: perception, action, cognitive control, learning, emotion, language, thought, development, and dysfunction.",
            "comparison_to_other_models": "Integrates and subsumes opposing views (purely modal vs purely amodal) by allowing hybrid accounts; contrasts with single-format theories that cannot account for cross-domain findings.",
            "functional_mechanisms": "Predicts that processes and tasks will recruit representations at different points on the continuum (e.g., immediate action/control -&gt; more modal; combinatorial language processing -&gt; more amodal); posits interactions between levels (e.g., binding of modality-specific traces to amodal schemata).",
            "limitations_or_open_questions": "How to measure and map real cognitive representations to coordinates on the continuum; whether transitions are continuous or contain qualitative discontinuities (e.g., true propositional symbols); mechanistic details of interactions between levels remain underspecified.",
            "uuid": "e5195.2",
            "source_info": {
                "paper_title": "Modal and amodal cognition: an overarching principle in various domains of psychology",
                "publication_date_yy_mm": "2023-10"
            }
        },
        {
            "name_short": "Grounded / Perceptual Symbol Systems",
            "name_full": "Grounded cognition / Perceptual Symbol Systems (Barsalou)",
            "brief_description": "Theory that concepts are constituted by re-activated modality-specific perceptual and motor states (simulations) rather than amodal symbols; conceptual processing uses the same systems as perception and action.",
            "citation_title": "Perceptions of perceptual symbols",
            "mention_or_use": "mention",
            "theory_or_model_name": "Grounded cognition / Perceptual Symbol Systems",
            "theory_or_model_description": "Conceptual knowledge consists of partial re-enactments of past sensorimotor experience (perceptual symbols) which are flexibly combined to form conceptual representations and used in language and reasoning via simulation.",
            "representation_format_type": "Modal, distributed sensorimotor traces / simulation-based",
            "key_properties": "Context-dependent activation, flexible recombination of experiential traces, modality-specific instantiation, supports detailed instance-level content and mental simulation.",
            "empirical_support": "Behavioral and neuroimaging studies showing modality-specific activations during language and conceptual tasks, switching costs across modalities in property-verification tasks, and task-dependent embodiment effects summarized in the paper.",
            "empirical_challenges": "Mixed evidence about functional necessity (some studies show epiphenomenal activations), robustness and boundary conditions of embodiment effects, and the need to explain compositionality and abstract concepts.",
            "applied_domains_or_tasks": "Language comprehension, property verification, action-language congruency, developmental simulations, emotion and affective priming paradigms.",
            "comparison_to_other_models": "Opposed to purely amodal symbolic models; shares similarities with modal end of continuum but differs in emphasizing simulation as constitutive of concepts rather than as added trace.",
            "functional_mechanisms": "Meaning arises via reactivation (simulation) of distributed perceptual-motor states; combinatorial conceptual content arises from binding and partial reactivation of relevant experiential traces.",
            "limitations_or_open_questions": "Extent to which simulations are necessary vs. incidental, how highly abstract concepts are represented, and mechanistic account of how simulations become combinatorial/compositional.",
            "uuid": "e5195.3",
            "source_info": {
                "paper_title": "Modal and amodal cognition: an overarching principle in various domains of psychology",
                "publication_date_yy_mm": "2023-10"
            }
        },
        {
            "name_short": "Language of Thought / Propositional",
            "name_full": "Language-of-Thought / Propositional representation (Fodor; Kintsch)",
            "brief_description": "Theory positing that thinking and conceptual representation use internal, language-like (propositional) symbol structures that are compositional and support classical logical and combinatorial operations.",
            "citation_title": "The language of thought",
            "mention_or_use": "mention",
            "theory_or_model_name": "Language-of-Thought / Propositional representations",
            "theory_or_model_description": "Conceptual knowledge is encoded as symbolic propositions (discrete tokens combined by syntactic/compositional rules) forming a combinatorial language-like system underlying thought and higher cognition.",
            "representation_format_type": "Amodal, symbolic, compositional / propositional",
            "key_properties": "Compositionality, discrete symbols, systematicity, supports rule-based inference, truth-evaluability and explicit propositional structure.",
            "empirical_support": "Success of symbolic/compositional models in explaining aspects of sentence comprehension, logical reasoning, and structured problem solving; fits accounts of high-level linguistic meaning representations discussed in the review.",
            "empirical_challenges": "Grounding problem (how symbols get meaning), empirical evidence of sensorimotor involvement in many tasks, criticisms from connectionist and embodied frameworks about universality of symbolic representations.",
            "applied_domains_or_tasks": "Language comprehension and production, formal reasoning, models of propositional discourse models (Kintsch construction-integration), cognitive architectures.",
            "comparison_to_other_models": "Contrasts with embodied and distributed models; stronger in compositional explanation but weaker in accounting for perceptual detail and sensorimotor-driven phenomena.",
            "functional_mechanisms": "Symbols are combined via syntactic rules to form propositions which are manipulated by cognitive processes for inference, planning, and communication.",
            "limitations_or_open_questions": "How symbolic representations are learned/grounded from experience and if purely symbolic codes suffice for perception-action tasks.",
            "uuid": "e5195.4",
            "source_info": {
                "paper_title": "Modal and amodal cognition: an overarching principle in various domains of psychology",
                "publication_date_yy_mm": "2023-10"
            }
        },
        {
            "name_short": "Hybrid / Convergence Zone",
            "name_full": "Hybrid models / Convergence Zone framework (Damasio) and Binder & Desai",
            "brief_description": "Frameworks proposing that conceptual knowledge comprises both modality-specific (modal) traces and modality-independent (amodal) hubs or convergence zones that bind and abstract across modalities.",
            "citation_title": "Time-locked multiregional retroactivation: A systems-level proposal for the neural substrates of recall and recognition.",
            "mention_or_use": "use",
            "theory_or_model_name": "Hybrid representation / Convergence Zone / Hub-and-spoke",
            "theory_or_model_description": "Concepts are represented by distributed modality-specific 'spokes' (sensory-motor traces) and amodal 'hubs' or convergence zones that integrate and abstract over modalities; both formats serve complementary functions.",
            "representation_format_type": "Hybrid: distributed modality-specific traces + amodal integrative representations (hubs)",
            "key_properties": "Dual components (modal spokes and amodal hub), supports both detailed simulations and cross-modal abstraction/compositionality, flexible depending on task demands.",
            "empirical_support": "Neuropsychological and imaging data (as reviewed) supporting modality-specific activations and domain-general semantic hubs; behavioral work showing conditions where amodal generalization occurs and other conditions where modal traces dominate.",
            "empirical_challenges": "Precisely specifying functional roles and dynamics between hubs and spokes, variability across domains and developmental stages, and dissociation evidence that sometimes undermines simple hub-spoke mappings.",
            "applied_domains_or_tasks": "Semantic memory, language comprehension, crossmodal matching, concept learning, and generalization tasks.",
            "comparison_to_other_models": "Positions between pure modal and pure amodal accounts, aiming to capture strengths of both; more biologically and functionally integrative but raises mechanistic questions about binding and timing.",
            "functional_mechanisms": "Convergence zones/hubs bind activations from modality-specific systems to form abstract representations; task demands modulate reliance on spokes vs hubs; supports both simulation-based and symbolic processing.",
            "limitations_or_open_questions": "How exactly hubs extract invariant structure, how binding is achieved functionally (timing, attention), and developmental trajectory of hub-spoke formation.",
            "uuid": "e5195.5",
            "source_info": {
                "paper_title": "Modal and amodal cognition: an overarching principle in various domains of psychology",
                "publication_date_yy_mm": "2023-10"
            }
        },
        {
            "name_short": "Predictive coding / hierarchical",
            "name_full": "Predictive coding / hierarchical predictive processing (Clark; Friston)",
            "brief_description": "A hierarchical processing account where higher levels encode abstract, modality-general expectations and lower levels encode modality-specific sensory details; perception and cognition emerge from minimizing prediction error across levels.",
            "citation_title": "Whatever next? Predictive brains, situated agents, and the future of cognitive science.",
            "mention_or_use": "use",
            "theory_or_model_name": "Predictive coding / hierarchical predictive processing",
            "theory_or_model_description": "Knowledge is organized in a processing hierarchy: higher levels hold abstract/amodal expectations (priors) while lower levels hold specific/modality-bound representations; interaction via top-down predictions and bottom-up prediction errors yields perception, inference, and abstraction.",
            "representation_format_type": "Hierarchical mixture: lower-level modal codes, higher-level amodal/abstract priors (continuum)",
            "key_properties": "Top-down/bottom-up interaction, hierarchical abstraction, dynamic updating via prediction-error minimization, supports both modal detail and amodal generalization depending on level.",
            "empirical_support": "Explains a wide range of perceptual phenomena (context effects, word superiority), and provides an integrative account consistent with findings of modality-specific lower-level processing and abstract higher-level processing discussed in paper.",
            "empirical_challenges": "Broadness of theory makes specific empirical tests difficult; debates about falsifiability and whether predictive coding can fully account for representational content and combinatorial symbolic structure.",
            "applied_domains_or_tasks": "Perception, language comprehension, event segmentation, cross-modal integration, and accounts of hierarchical cognitive control.",
            "comparison_to_other_models": "Provides a mechanistic bridge between modal and amodal formats by placing them at different hierarchical levels; contrasts with single-level symbolic or purely modal simulation accounts.",
            "functional_mechanisms": "Generative models at higher levels send predictions; lower levels return prediction errors prompting model updating; abstraction emerges in higher-level priors that are modality-general.",
            "limitations_or_open_questions": "Operationalizing representational format at each level, demonstrating direct causal role of prediction-error dynamics in conceptual abstraction, and specifying how compositional symbolic structure arises within the predictive hierarchy.",
            "uuid": "e5195.6",
            "source_info": {
                "paper_title": "Modal and amodal cognition: an overarching principle in various domains of psychology",
                "publication_date_yy_mm": "2023-10"
            }
        },
        {
            "name_short": "Recognition-by-components (Geon)",
            "name_full": "Recognition-by-components (Geon theory; Biederman)",
            "brief_description": "A functional model of object representation proposing view-invariant, component-based (geon) structural descriptions that are nonlinguistic and amodal relative to viewpoint.",
            "citation_title": "Recognition-by-components: A theory of human image understanding.",
            "mention_or_use": "mention",
            "theory_or_model_name": "Geon / recognition-by-components theory",
            "theory_or_model_description": "Objects are represented as configurations of a limited set of geometric components (geons) and their spatial relations, producing viewpoint-invariant, compositional object representations that are closer to amodal structural formats than to image-like representations.",
            "representation_format_type": "Amodal, structural, compositional (component-based)",
            "key_properties": "Finite primitive set (geons), compositional assembly, viewpoint invariance, emphasizes structural relations over image-specific detail.",
            "empirical_support": "Explains object recognition robustness across views, supports compositional recognition tasks where component recombination predicts recognition performance (cited historically in review).",
            "empirical_challenges": "Multiple-views theories and template-like holistic representations explain some phenomena better; debate about whether geon decomposition captures all real-world object recognition complexities.",
            "applied_domains_or_tasks": "Object recognition, visual categorization, studies contrasting viewpoint-invariant vs. view-based representations.",
            "comparison_to_other_models": "Located toward the amodal/compositional quadrant of the continuum; contrasted with multiple-view/template and holistic image-like accounts.",
            "functional_mechanisms": "Visual input is parsed into geon primitives and relations, producing a structural description used for recognition and categorization.",
            "limitations_or_open_questions": "Extent to which geon primitives are psychologically real across varied object classes and how geon-like representations interact with modality-specific pictorial traces for recognition.",
            "uuid": "e5195.7",
            "source_info": {
                "paper_title": "Modal and amodal cognition: an overarching principle in various domains of psychology",
                "publication_date_yy_mm": "2023-10"
            }
        },
        {
            "name_short": "Multiple-views theory",
            "name_full": "Multiple canonical-view / template-matching theories (Tarr & Bülthoff)",
            "brief_description": "Theories proposing that object representations are stored as several canonical viewpoint-specific holistic templates, and recognition proceeds by aligning input to the stored view that best matches.",
            "citation_title": "Is human object recognition better described by geon structural descriptions or by multiple views?.",
            "mention_or_use": "mention",
            "theory_or_model_name": "Multiple-views (viewpoint-specific / template) theory",
            "theory_or_model_description": "Object memory contains multiple stored 2-D (or holistic) canonical views that are matched (possibly via rotation) against incoming images to accomplish recognition; representations are relatively modal, image-like, and viewpoint-specific.",
            "representation_format_type": "Modal, viewpoint-specific, template-like / holistic",
            "key_properties": "Viewpoint-specific templates, holistic representations, requires alignment/rotation operations for recognition, preserves pictorial detail.",
            "empirical_support": "Accounts for viewpoint effects and some recognition phenomena where alignment to stored views predicts performance; used as example placement on the modal side of the continuum in the paper.",
            "empirical_challenges": "Cannot easily explain viewpoint-invariant recognition without large template sets; geon-style structural descriptions and feature-analysis models explain invariance with fewer primitives.",
            "applied_domains_or_tasks": "Object recognition, studies of viewpoint dependence, comparison with structural-description models.",
            "comparison_to_other_models": "Opposed to geon structural/compositional models; more modal and image-like versus amodal compositional accounts.",
            "functional_mechanisms": "Recognition via matching input image to nearest stored canonical view and performing transformations (e.g., mental rotation) to align viewpoints.",
            "limitations_or_open_questions": "How viewpoint-specific templates are learned and stored efficiently, and how holistic templates interact with structural/compositional representations.",
            "uuid": "e5195.8",
            "source_info": {
                "paper_title": "Modal and amodal cognition: an overarching principle in various domains of psychology",
                "publication_date_yy_mm": "2023-10"
            }
        },
        {
            "name_short": "SUSTAIN / category models",
            "name_full": "SUSTAIN (network model of category learning; Love et al.) and prototype/exemplar models",
            "brief_description": "Computational models of category learning that explain how representations of categories (prototypes, exemplars, clusters) are formed and used for classification and generalization, including mechanisms for abstraction and attentional weighting.",
            "citation_title": "SUSTAIN: A network model of category learning.",
            "mention_or_use": "mention",
            "theory_or_model_name": "SUSTAIN / prototype and exemplar models",
            "theory_or_model_description": "Models propose that category knowledge arises from either stored exemplars, an abstracted prototype, or dynamically formed clusters (SUSTAIN) with attentional tuning and dimensional weighting, explaining how abstraction from instances can occur functionally.",
            "representation_format_type": "Distributed exemplar representations, prototype (summary) representations, cluster-based hybrid (SUSTAIN)",
            "key_properties": "Instance-based vs. abstract summary forms, attentional weighting of diagnostic dimensions, capacity for generalization and sensitivity to exemplar variability.",
            "empirical_support": "Accounts for many category-learning phenomena and effects of exemplar variability and label-order on learning (discussed in review, e.g., Ramscar, Lupyan work), and SUSTAIN explains clustering and rule-learning patterns.",
            "empirical_challenges": "Debates about whether people use exemplars, prototypes, or rules in different tasks; how such models scale to complex real-world conceptual structure; mapping to neural implementation.",
            "applied_domains_or_tasks": "Concept learning, categorization, word learning, generalization vs. discrimination tasks.",
            "comparison_to_other_models": "Offers process-level mechanisms for abstraction versus purely symbolic accounts; complements grounded accounts by explaining statistical/discriminative learning processes that produce amodal abstractions.",
            "functional_mechanisms": "Learning driven by error and attention-driven clustering or abstraction; diagnostic features are upweighted leading to prototype-like or cluster representations under different conditions.",
            "limitations_or_open_questions": "How to predict when exemplar vs prototype vs cluster representations will dominate, and integration with modality-specific simulation accounts.",
            "uuid": "e5195.9",
            "source_info": {
                "paper_title": "Modal and amodal cognition: an overarching principle in various domains of psychology",
                "publication_date_yy_mm": "2023-10"
            }
        },
        {
            "name_short": "Rescorla–Wagner / discriminative",
            "name_full": "Rescorla–Wagner associative learning and discriminative error-driven account (Ramscar et al.)",
            "brief_description": "Error-driven associative learning framework where cue competition and prediction-error-driven updating can lead to abstraction or retention of modal features depending on exemplar variability and predictive structure.",
            "citation_title": "Pavlovian conditioning: It's not what you think it is.",
            "mention_or_use": "use",
            "theory_or_model_name": "Rescorla–Wagner and discriminative (error-driven) learning account",
            "theory_or_model_description": "Learning updates associative weights via prediction error; when exemplars are variable and cue-competition occurs, learners abstract over uninformative dimensions producing amodal representations, whereas low variability favors retention of modal instance details.",
            "representation_format_type": "Associative weight matrices that can yield more abstract (amodal) or more concrete (modal) representational outcomes depending on input structure",
            "key_properties": "Error-driven updating, cue competition, sensitivity to exemplar variability, yields discriminative emphasis on diagnostic features producing abstraction.",
            "empirical_support": "Empirical results summarized showing variability-driven abstraction in evaluative conditioning and conceptual learning (e.g., Reichmann et al. 2022; Ramscar et al. manipulations), and classical findings on cue competition and associative learning.",
            "empirical_challenges": "Associative models historically criticized for not capturing higher-level compositional structure; distinguishing abstraction due to model dynamics vs. other cognitive processes experimentally can be difficult.",
            "applied_domains_or_tasks": "Associative learning, evaluative conditioning, word learning, concept learning and generalization tasks.",
            "comparison_to_other_models": "Provides a mechanistic learning account that can produce amodal abstractions without appealing to pre-existing symbolic formats; contrasts with purely symbolic/innate accounts.",
            "functional_mechanisms": "Prediction errors drive strengthening/weakening of cue-outcome associations; cue competition removes uninformative cues, biasing representations towards diagnostic (abstract) features.",
            "limitations_or_open_questions": "How to scale to structured/compositional semantic knowledge and how to integrate with simulation-based/modal representations; empirical separation of learning-driven abstraction vs. task strategy effects.",
            "uuid": "e5195.10",
            "source_info": {
                "paper_title": "Modal and amodal cognition: an overarching principle in various domains of psychology",
                "publication_date_yy_mm": "2023-10"
            }
        },
        {
            "name_short": "Theory of Event Coding (TEC) & Perception-Action",
            "name_full": "Theory of Event Coding (TEC) and Perception-for-Action model (Hommel; Milner & Goodale)",
            "brief_description": "Frameworks linking perception and action representations: TEC posits common code representations for perceived and produced event features (often amodal at planning level), while the perception-action model distinguishes ventral (perception) and dorsal (action control) streams with different representational formats.",
            "citation_title": "The Theory of Event Coding (TEC): A framework for perception and action planning.",
            "mention_or_use": "use",
            "theory_or_model_name": "Theory of Event Coding (TEC) / Perception-for-Action model",
            "theory_or_model_description": "TEC: perception and action share common representational codes (event files) that can be amodal/abstract for planning; Perception-for-Action: two visual streams (ventral amodal perception and dorsal modality-specific action control) operate with different representational formats.",
            "representation_format_type": "TEC: event-file bindings that can be amodal/abstract or include modality-specific features; Perception-action: dorsal stream—modal/action-oriented; ventral stream—perceptual/recognition-oriented (more amodal at higher levels).",
            "key_properties": "Binding of stimulus and response features, shared codes for perception and action, planned actions can be represented abstractly while control can rely on modality-specific metrics.",
            "empirical_support": "Behavioral literature on response-effect learning, compatibility effects, and many studies discussed in review showing interactions between perception and action representations; neuropsychological evidence for dorsal/ventral stream specialization.",
            "empirical_challenges": "Empirical inconsistencies (e.g., illusions may affect grasping similarly to perception), mixed findings on whether planning is amodal and control modal, and variable generalization in response-effect learning.",
            "applied_domains_or_tasks": "Action planning and control, motor learning, response-effect compatibility tasks, studies of perception-action dissociations.",
            "comparison_to_other_models": "Bridges modal and amodal accounts by specifying representational roles across planning vs control and perception vs action streams; contrasts with purely symbolic or purely simulation accounts of action representation.",
            "functional_mechanisms": "Formation of event files binding stimulus and action features (TEC); ventral pathway supports recognition/abstract identification while dorsal pathway computes egocentric, metric control signals for action.",
            "limitations_or_open_questions": "Degree and conditions under which planning is amodal vs. modal; reconciling mixed empirical results about illusions, Weber's law violations, and generalization across effect features.",
            "uuid": "e5195.11",
            "source_info": {
                "paper_title": "Modal and amodal cognition: an overarching principle in various domains of psychology",
                "publication_date_yy_mm": "2023-10"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Perceptions of perceptual symbols",
            "rating": 2,
            "sanitized_title": "perceptions_of_perceptual_symbols"
        },
        {
            "paper_title": "The language of thought",
            "rating": 2,
            "sanitized_title": "the_language_of_thought"
        },
        {
            "paper_title": "Whatever next? Predictive brains, situated agents, and the future of cognitive science.",
            "rating": 2,
            "sanitized_title": "whatever_next_predictive_brains_situated_agents_and_the_future_of_cognitive_science"
        },
        {
            "paper_title": "Recognition-by-components: A theory of human image understanding.",
            "rating": 2,
            "sanitized_title": "recognitionbycomponents_a_theory_of_human_image_understanding"
        },
        {
            "paper_title": "The Theory of Event Coding (TEC): A framework for perception and action planning.",
            "rating": 2,
            "sanitized_title": "the_theory_of_event_coding_tec_a_framework_for_perception_and_action_planning"
        },
        {
            "paper_title": "SUSTAIN: A network model of category learning.",
            "rating": 2,
            "sanitized_title": "sustain_a_network_model_of_category_learning"
        },
        {
            "paper_title": "Pavlovian conditioning: It's not what you think it is.",
            "rating": 1,
            "sanitized_title": "pavlovian_conditioning_its_not_what_you_think_it_is"
        },
        {
            "paper_title": "Time-locked multiregional retroactivation: A systems-level proposal for the neural substrates of recall and recognition.",
            "rating": 1,
            "sanitized_title": "timelocked_multiregional_retroactivation_a_systemslevel_proposal_for_the_neural_substrates_of_recall_and_recognition"
        },
        {
            "paper_title": "The free-energy principle: A unified brain theory?",
            "rating": 1,
            "sanitized_title": "the_freeenergy_principle_a_unified_brain_theory"
        },
        {
            "paper_title": "Is human object recognition better described by geon structural descriptions or by multiple views?.",
            "rating": 1,
            "sanitized_title": "is_human_object_recognition_better_described_by_geon_structural_descriptions_or_by_multiple_views"
        }
    ],
    "cost": 0.026430999999999996,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Modal and amodal cognition: an overarching principle in various domains of psychology
17 October 2023</p>
<p>Barbara Kaup barbara.kaup@uni-tuebingen.de 
Department of Psychology
Fachbereich Psychologie
University of Tübingen
Schleichstr. 472076TübingenGermany</p>
<p>Rolf Ulrich rolf.ulrich@uni-tuebingen.de 
Department of Psychology
Fachbereich Psychologie
University of Tübingen
Schleichstr. 472076TübingenGermany</p>
<p>Karin M Bausenhart 
Department of Psychology
Fachbereich Psychologie
University of Tübingen
Schleichstr. 472076TübingenGermany</p>
<p>Donna Bryce 
Department of Psychology
Fachbereich Psychologie
University of Tübingen
Schleichstr. 472076TübingenGermany</p>
<p>Department of Psychology
University of Augsburg
AugsburgGermany</p>
<p>Martin V Butz 
Department of Psychology
Fachbereich Psychologie
University of Tübingen
Schleichstr. 472076TübingenGermany</p>
<p>Department of Computer Science
University of Tübingen
Sand 1472076TübingenGermany</p>
<p>David Dignath 
Department of Psychology
Fachbereich Psychologie
University of Tübingen
Schleichstr. 472076TübingenGermany</p>
<p>Carolin Dudschig 
Department of Psychology
Fachbereich Psychologie
University of Tübingen
Schleichstr. 472076TübingenGermany</p>
<p>Volker H Franz 
Department of Computer Science
University of Tübingen
Sand 1472076TübingenGermany</p>
<p>Claudia Friedrich 
Department of Psychology
Fachbereich Psychologie
University of Tübingen
Schleichstr. 472076TübingenGermany</p>
<p>Caterina Gawrilow 
Department of Psychology
Fachbereich Psychologie
University of Tübingen
Schleichstr. 472076TübingenGermany</p>
<p>Jürgen Heller 
Department of Psychology
Fachbereich Psychologie
University of Tübingen
Schleichstr. 472076TübingenGermany</p>
<p>Markus Huff 
Department of Psychology
Fachbereich Psychologie
University of Tübingen
Schleichstr. 472076TübingenGermany</p>
<p>Leibniz-Institut für Wissensmedien
TübingenGermany</p>
<p>Mandy Hütter 
Department of Psychology
Fachbereich Psychologie
University of Tübingen
Schleichstr. 472076TübingenGermany</p>
<p>Markus Janczyk 
Department of Psychology
University of Bremen
BremenGermany</p>
<p>Hartmut Leuthold 
Department of Psychology
Fachbereich Psychologie
University of Tübingen
Schleichstr. 472076TübingenGermany</p>
<p>Hanspeter Mallot 
Department of Biology
University of Tübingen
Auf der Morgenstelle 2872076TübingenGermany</p>
<p>Hans-Christoph Nürk 
Department of Psychology
Fachbereich Psychologie
University of Tübingen
Schleichstr. 472076TübingenGermany</p>
<p>Michael Ramscar 
Department of Psychology
Fachbereich Psychologie
University of Tübingen
Schleichstr. 472076TübingenGermany</p>
<p>Nadia Said 
Department of Psychology
Fachbereich Psychologie
University of Tübingen
Schleichstr. 472076TübingenGermany</p>
<p>Jennifer Svaldi 
Department of Psychology
Fachbereich Psychologie
University of Tübingen
Schleichstr. 472076TübingenGermany</p>
<p>German Center for Mental Health (DZPG)
partner siteTübingenGermany</p>
<p>Hong Yu Wong 
Department of Philosophy
University of Tübingen
TübingenGermany</p>
<p>Modal and amodal cognition: an overarching principle in various domains of psychology
17 October 202316E25FD47C2B25C31C33E86BF6719A5C10.1007/s00426-023-01878-wReceived: 17 April 2023 / Accepted: 17 September 2023 /
Accounting for how the human mind represents the internal and external world is a crucial feature of many theories of human cognition.Central to this question is the distinction between modal as opposed to amodal representational formats.It has often been assumed that one but not both of these two types of representations underlie processing in specific domains of cognition (e.g., perception, mental imagery, and language).However, in this paper, we suggest that both formats play a major role in most cognitive domains.We believe that a comprehensive theory of cognition requires a solid understanding of these representational formats and their functional roles within and across different domains of cognition, the developmental trajectory of these representational formats, and their role in dysfunctional behavior.Here we sketch such an overarching perspective that brings together research from diverse subdisciplines of psychology on modal and amodal representational formats so as to unravel their functional principles and their interactions.How humans mentally represent information is a fundamental issue within psychology and beyond.Not surprisingly, most theories about human cognition involve representational assumptions, at least implicitly.Depending on the domain of investigation, different types of mental representations are typically in the foreground.In research on thinking, memory, or language processing, the traditional assumption is that properties, objects, situations, and events are captured through symbolic representations (e.g.,</p>
<p>because it is more abstract than any particular experience.Likewise, although the word "stain" mainly refers to visual features, its symbolic meaning representation will itself be abstracted from visual experience.It is thus reasonable to assume that these two symbolic representations-for "melody" and "stain"-share a common format, despite them both referring to entities that are typically perceived via different senses.Accordingly, these symbolic meaning representations can be modality-unspecific.</p>
<p>By contrast, in research on perception, it is often assumed that representations are modality-specific and resemble the entity being represented.For instance, when perceiving a dog, humans appear to create a rather specific representation that preserves many of the properties of the particular dog being perceived.In this sense, the representation is concrete rather than abstract.From this perspective, perceptual representations can be seen as being inherently different, depending on whether the represented entity is mainly characterized by auditory, visual, olfactory, or other sensory features.Accordingly, these representations can be modalityspecific.This is also a core assumption in various theories on imagery, which suggest that mental representations are concrete and modality-specific (e.g., Kosslyn, 1980; but see Pylyshyn, 1981, andalso Pitt, 2013) and thus are quasi-perceptual (Ward et al., 2019).</p>
<p>However, researchers in most domains of cognitive psychology nowadays do not assume that all mental representations are of one exclusive type.For instance, in research on conceptual knowledge (for an overview, see Murphy, 2002;Pecher, 2013), hybrid forms of mental representations are explicitly discussed.For example, a hybrid representation of the concept 'dog' could consist of a symbolic component listing typical attributes of dogs and also a component with experiential traces that stem from sensory experiences encountered in the past.Finally, it is worth noting that the two representational formats described above are unlikely to constitute a dichotomy in a strict sense.Instead, they may represent the endpoints of a "continuum" that ranges from modality-specific to abstract symbolic representations (see Fig. 1; Meteyard et al., 2012; see also Gentner &amp; Asmuth, 2019).We deliberately placed "continuum" in quotation marks because the transition from concrete to abstract might not be entirely continuous but may contain a discontinuity.This seems especially true when it comes to a transition to propositional representations with symbols as elements (see the transition between the last two representations in Fig. 1 marked by a dashed line to indicate the possible discontinuity).</p>
<p>In summary, questions concerning the nature of mental representations are central to virtually all domains within cognitive psychology, and different types of mental representations are explicitly discussed in many of these domains.Nonetheless, an overarching analysis of representational issues, particularly concerning various types of representations, is to the best of our knowledge, not yet available.Consequently, it seems that cognitive psychology lacks a comprehensive theoretical account of the functions and interactions of different representational formats, thus remaining poorly understood.Needless to say, it follows that the same can be said of the domains of application, developmental trajectories, and possible malfunctions of these representational formats.Moreover, computationally it is something of a given that the nature of a cognitive process will depend on the format of the representation it operates on (Bröker &amp; Ramscar, 2020); as is the reverse, namely that particular processes might call for particular representational formats (e.g., putative combinatoric processes in language might require more abstract proposition-like representations, whereas processes utilized for immediate action might require very detailed representations in absolute metrics (e.g., Ganel &amp; Goodale, 2003).Thus, a comprehensive understanding of cognitive processes would also appear to require a better understanding of representational format.</p>
<p>We suggest that one goal of current research in cognitive psychology research should be to better understand representational issues in cognition.We consider it theoretically fruitful to assess whether it is possible to integrate the various representational formats from different subfields of cognitive psychology (e.g., propositional representations vs. mental models in research on spatial reasoning; prototypes vs. exemplars in research on conceptual knowledge; cf.Murphy, 2016).We suggest that it is worthwhile to investigate whether all representational formats can be located on one continuum from concrete to abstract.Such a research endeavor would not only allow parsimonious explanations of the respective phenomena but also allow for theoretical relationships between the different subfields of psychology to be uncovered, paving the way for a more general theory of human cognition.</p>
<p>One factor that complicates this endeavor is that a wealth of different terms are used to refer to the respective representational distinctions: concrete vs. abstract (Reed, 2016;Snodgrass, 2006), symbolic vs. analog (Dehaene et al., 1998;Furman &amp; Rubinsten, 2012), propositional vs. analog (Johnson-Laird, 1983;Zimmer, 2006), digital vs. analog (Dretske, 1981;Katz, 2008), perception-based vs. meaningbased (Anderson, 1995), descriptive vs. perceptual (Newen &amp; Marchi, 2016), modality-specific vs. modality-unspecific (Vaina, 1984), modality-specific vs. supramodal (Binder &amp; Desai, 2011;Kiefer &amp; Pulvermüller, 2012), perspectivespecific vs. perspective-flexible (Brunyé et al., 2008), LoTlike vs. non-LoT-like formats (Quilty-Dunn et al., 2022), to name just a few.One pair of terms that recently gained much attention in research on cognitive psychology is the opposition between modal and amodal representations (Anderson, 2009).In the following, we will base our considerations on these terms in the following way (see Fig. 2). 1odal representations are fundamentally experiential in nature and are therefore rather concrete.The structure of these representations preserves structural aspects of how we experience the world: that is, mappings between the world on the one hand, and representations of it on the other, are isomorphic.Sensory representations in perception that rely on prothetic continua2 (e.g., intensity) or involve mental images are classical examples of modal representations.As these examples suggest, modal representations can be relatively simple (e.g., representing one particular value of an attribute dimension) or highly complex (e.g., representing a rich image of a multi-faceted situation).Moreover, modal representations need not necessarily concern only one sensory modality, but may draw on several different modalities (for instance, by means of cue integration, e.g., Ernst &amp; Banks, 2002).Information from various modalities may be associated in a modal representation (e.g., the smell and the sound of a dog), but, importantly, in a modal representation, there is no representational component that combines information in an abstract, modality-unspecific way.Instead, modal representations either concern only one modality or encompass several modality-specific representations (for one idea of how the individual modality-specific representations can be bound together, see the convergence zone framework proposed by Damasio, 1989).Modal representations are often also considered holistic rather than compositional (but see Barsalou et al., 2003).</p>
<p>Amodal representations, by contrast, encompass an abstract description of the state of affairs they represent.Their structure is different from the structure of the things they represent.Amodal representations may capture information from one or more modalities, but these representations themselves are modality-unspecific.Feature-based word meaning representations, semantic networks, schemata, and frames are examples of amodal representations.contrast, dimensions (e.g., the wavelength of visible light) that produce experiences (e.g., color) that allow qualitative judgments (e.g., "this apple is green but not red") are considered phenomena belonging to the metathetic domain (Stevens, 1957).</p>
<p>Footnote 2 (continued) Propositional representations constitute another typical example.Traditionally, these representations are held to be symbolic codes emerging from combining elementary building blocks of meaning.These representations can be combined or "composed" into more complex propositional representations in much the same way words are combined into sentences (Frege, 1892).Thus, like language, propositional representations are held to be compositional.In this sense, propositional representations are often considered to be linguistic representations and are usually supposed to be the language of thought, according to traditional theories in cognitive science (Fodor, 2008;Pinker, 1999).Like modal representations, amodal representations can be simple (e.g., capturing only a single attribute or entity) or highly complex (e.g., capturing a series of events and situations interconnected by causal relations and involving many different objects and attributes).Although propositional representations are certainly a prime example of amodal representations, amodal representations need not necessarily be language-like.For instance, a representation of an object in terms of elementary geons (cf. the recognition-by-components theory of Biederman, 1987), as opposed to several viewpoint-specific holistic object representations (cf.Tarr &amp; Bülthoff, 1995), is nonlinguistic but shares several aspects of amodal representations (e.g., a finite set of basic components, compositional structure, view-point invariance).Thus, Geon theory is closer to the amodal end of the modal-amodal continuum than, for instance, a visual image of an object (see Fig. 3).In addition, although proposals for amodal representations with a compositional structure seem particularly suited to accounting for meaning representations in language and other higher-level cognitive processes (such as reasoning or problem-solving), they have also been postulated Fig. 3 The modal-amodal continuum comprising different forms of representations, ranging from image-like representations to frames and propositions in other domains of cognition, such as in action planning (e.g., Glover, 2004).</p>
<p>It is also important to point out here that not all authors agree with the above characterization of linguistic meaning representation in terms of a strictly compositional rule-based assembly of discrete elementary building blocks which is intrinsic to the traditional Language-of-Thought/Generative-Grammar Paradigm in cognitive science (Fodor, 1975(Fodor, , 2008;;Fodor &amp; Pylyshyn, 1988).Increasingly many authors instead assume meaning representations of different levels of abstraction that are grounded in perception and action, and are characterized by weak compositionality (e.g., Goldberg, 2003Goldberg, , 2019;;Langacker, 2008; see also Michel, 2023).</p>
<p>The distinction between modal and amodal representation applies not only to information input but also to action.For example, a motor plan can be specific to a particular muscle group or a limb, which would be a modal representation of a concrete action (e.g., pointing with the right index finger to a target object).This notion resembles the motor plans suggested by Keele (1968).However, others like Schmidt (1975; see also Rosenbaum, 1980) assume that each amodal motor program is represented as a schema.For example, such a schema would allow one to produce one's signature even with different effectors (e.g., the fingers when signing a check or the whole arm when writing the same signature much larger on a blackboard; see Liu et al., 2020, for recent neuropsychological evidence for effector-independent action representations).</p>
<p>Our distinction between modal and amodal representations is largely consistent with the instance level of Reed's taxonomy of abstraction (Reed, 2016), according to which the terms modal vs. amodal refer to representations of instances, such as the representation of a particular dog.A modal representation is a concrete representation that resembles an earlier sensory experience that can be activated without external stimulation.By contrast, amodal representations are abstract, and under some accounts extend to including propositional representations of meaning, in which a proposition is anything that can be asserted or denied using words (e.g., my dog smells bad) and can be determined to be true or false (Reed, 2016).Therefore, according to Reed, amodal representations can be evaluated for their truth value and modal representations for their similarity.</p>
<p>Above, we specified several attribute dimensions on which modal and amodal representations may differ.The question arises whether these dimensions are correlated and whether a particular dimension is more prominent than others.We assume that two dimensions are particularly crucial and thus define our framework.One dimension runs from structure-preserving to structure-agnostic, or in other words, from analog to symbolic.The other dimension runs from modality-specific to modality-general, whereby modality here refers to perceptual modality (visual, auditory, tactile, etc.) or response modality (arms, feet, mouth, etc.; see Fig. 4).We believe that the distinction between modal and amodal representations is best captured by the diagonal in this diagram.Thus, the prototypical modal representations are located in the lower left and the prototypical amodal representations in the upper right quadrant.For example, the multiple-views theory assumes several canonical viewpoint specific holistic object representations that are rotated to align with the input image during object recognition (Tarr &amp; Bülthoff, 1995) and can thus be located in the lower left quadrant.Likewise, a prime example for a theory in the upper right quadrant are views postulating propositional representations created during language comprehension which are truly symbolic and capture information from different modalities in a modality-general way (Kintsch, 1998;McKoon &amp; Ratcliff, 1992).Another less prototypical but at least as clear example for this quadrant are theories in time perception where time is represented by the number of pulses registered by an internal timing mechanism during the perception of a time interval (e.g., Ulrich et al., 2022).This mechanism is not modality-specific as it potentially receives input from different modalities (time intervals during visual or auditory or tactile perception), allowing the comparison of a tone's duration with a light's duration.Although these are the most relevant quadrants for the distinction between modal and amodal representations, it is nevertheless possible to find examples that fit in one of the other quadrats.For instance, we would locate the Geon theory in thelower right quadrant because this theory assumes visual objects to be composed of geometric ions (e.g., cylinder and brick Geons; Biederman, 1987).For the upper left quadrant, we see Baddeley's visuospatital sketchpad as a possible candidate, because here representations are analog in nature but not truly visual.Rather they are thought to combine Fig. 4 The modal-amodal continuum in a plane given by the two dimensions "analog-to-symbolic" and "modality-specific-to-modality-general".Modality may refer to the input side as well as the response side information from visual, tactile and haptic sensory channels (Magnussen, 2013).In summary, we believe that nearly all representational formats can be located within this twodimensional plane even though it may sometimes be that the suggested format cannot be exclusively located within a single quadrant. 3 The considerations above reveal how the psychological reality of different types of representational formats has been largely accepted in cognitive psychology (albeit this acceptance is typically implicit).It is further notable that this view has recently even found its way into related disciplines such as philosophy of mind (e.g., Butterfill &amp; Sinigaglia, 2014;Camp, 2009;Wajnerman Paz, 2018) and cognitive neuroscience (e.g., Leshinskaya &amp; Caramazza, 2016, see also Kuhnke et al., 2022).Yet it remains the case that the relationship between these formats and their functions for cognition is intensively debated, especially in the literature on the human conceptual system (e.g., Barsalou, 2016).In fact, the theoretical accounts range from a strong view of grounded cognition, which assumes that concepts are modal representations (e.g., Glenberg &amp; Gallese, 2012) to a view that assumes that concepts are represented in an amodal format (e.g., Machery, 2016;Mahon, 2015).However, most accounts consider a hybrid view according to which the cognitive system involves both representational formats (e.g., Binder &amp; Desai, 2011;Dove, 2009Dove, , 2022;;Kiefer &amp; Pulvermüller, 2012;Zwaan, 2014).</p>
<p>The fragmented debate about the role and functions of modal and amodal representations, along with the many implicit assumptions many theories make about them, calls for an explicit, overarching approach that addresses this issue from different angles within psychology (i.e., perception, action, learning, emotion, language, and thought) and brings together the various theoretical ideas about the interaction and function of amodal and modal representations.In order to arrive at a comprehensive understanding of cognition, these different perspectives on the distinction between modal and amodal representations need to be integrated.A synthesis is required beyond studies within isolated, individual subfields of cognition.Crucially, such an overarching approach would also allow to distinguish between domain-specific and domain-general aspects of the cognitive processes that operate on modal and amodal representation.Accordingly, we consider it of central relevance for research in cognitive psychology to investigate the functions of modal and amodal representations for human cognition and to analyze their interplay within the subfields of psychology.</p>
<p>In what follows, we will briefly sketch the questions arising in the different subfields of psychology concerning the functions and interactions of modal and amodal representations.We start with the subfield of perception, and in subsequent sections discuss the topics of action, cognitive control, learning, emotion, language, thought, development, and dysfunction.</p>
<p>Perception</p>
<p>Philosophers and psychologists have long speculated about how people perceive the outside world.Extreme positions can be distinguished and classified within the framework mentioned above.It is often assumed that perception comprises elementary units which are assembled or synthesized, a general assumption consistent with the amodal view.One appealing aspect of this view is that it is compatible with a more widespread research strategy, that of decomposing complex systems into their elements, thereby decreasing their complexity, and making research appear more tractable.The underlying assumption here is that the elements identified are functionally independent, and thus can be studied in isolation (Bechtel &amp; Richardson, 2010).This research strategy of decomposing complex systems is evident in cognitive research in general but particularly prominent in the study of perception. 4or example, the philosopher John Locke (1632-1704) assumed that complex ideas (e.g., the idea of an apple) are composed of impressions (i.e., sensations, e.g., the features "red" and "round," and "juicy") that emerge from the senses (see Hergenhan, 2009).Furthermore, he assumed that these atoms could be combined in an almost infinite number of ways.A similar idea was held by Wilhelm Wundt , who believed that perception is a passive process fed by many simultaneously active elementary primitives.Wundt's elementism, however, was later challenged by Gestalt psychologists, who coined the well-known phrase "The whole is more than the sum of the parts" and thus tried to understand perception within a holistic framework, a position that is consistent with the modal view.</p>
<p>This basic distinction between holistic and compositional representation is also found in more recent theories of perception.For example, Neisser (1967) in his seminal book Cognitive Psychology, elaborated on the distinction between 3 One issue which we wish to flag but set aside concerns whether we are realists or instrumentalists about mental representations (Dennett, 1991;Fodor, 1985;Matthews, 2007;Sprevak, 2013).Whilst the issue of realism about mental representations and their features, such as their format, is a vital issue in the philosophy of science, we do not wish to commit ourselves to either side here.We thank an anonymous reviewer for directing our attention to this issue.</p>
<p>"template-matching" and "feature-analyses" to understand human pattern recognition, which at the time was inspired by the burgeoning field of artificial intelligence.Unlike Gestalt psychologists, who never moved away from the concept of "template-matching" to understand how humans recognize a letter such as A, pioneers of machine perception such as Selfridge (1959) assumed that features are first identified from a pattern resulting in a feature list, which is then synthesized in a subsequent hierarchical process.The basic idea of feature analysis and subsequent synthesis is also found in McClelland and Rumelhart's (1981) interactive activation model or in the Geon theory mentioned earlier (Biederman, 1987).Moreover, psychophysicists have assumed that even low-level processes assemble many spatial frequency codes (i.e., spatial "atoms", Campbell &amp; Robson, 1968) to account for fundamental phenomena like the perception of Mach band patterns.Likewise, Miller and Ulrich (2003) assumed that basic perceptual processes involve many grains (i.e., temporal "atoms") to account for various basic findings on reaction time.By contrast, viewpoint-specific theories (e.g., Ullman, 1989) reinforce the notion of "template-matching."They proceed from the core assumption that each object is represented in memory by a single two-dimensional canonical view to which objects in the three-dimensional view are aligned to for recognition.</p>
<p>Although these two global approaches to object perception (template-matching vs. feature-analysis) are incompatible, each approach can explain certain phenomena that others cannot (Palmer, 1999).Of course, on the flipside, each approach has its own problems.Similar to the case in physics (e.g., concerning the fundamentally different particle vs. wave-theory of light), traditionally no theory has united both approaches in the psychology of perception. 5ather, the field has traditionally been characterized by the existence of a contrasting framework of fundamentally different theories.However, some recent suggestions may help resolve the debate between template-matching versus feature-analysis.For example, the theory of predictive coding (Clark, 2013;Friston, 2010;Rao &amp; Ballard, 1999) envisions perception as a processing hierarchy in which bottom-up (sensory processing) and top-down processing (expectations) interact, an assumption that was also central for McClelland and Rumelhart (1981) in explaining the socalled word superiority effect. 6From a predictive coding perspective, perception is based on a dynamic prediction system that generates downward expectations about sensory input and updates these expectations to minimize the error associated with subsequent predictions.The knowledge used for making predictions is stored at several processing levels within this hierarchy of top-down and bottom-up processing.Knowledge stored at higher levels represents abstract information that does not contain specific features.However, moving downward to the other end of this hierarchy, these representations become increasingly specific in their details.Thus, applying the terminology we outlined earlier, the knowledge represented within this hierarchical structure, from its bottom to its top, can be regarded as a modal-toamodal continuum (cf.Gilead et al., 2020;Hutchinson &amp; Barrett, 2019;Michel, 2021). 7he essential function of perception is to allow organisms to interact with the environment.From this perspective it is understandable why many researchers have focused on the interaction between perception and motor function.Although predictive coding also seeks to understand this interaction (see Hutchinson &amp; Barrett, 2019), several researchers have focused solely on sensor-motor interactions.For example, Wolfgang Prinz has argued that perception and motor processes rely on the same representation (i.e., "common coding"; Prinz, 1990Prinz, , 1997)).Consistent with this idea, many researchers argue that actions and action intentions can alter perception (e.g., Proffitt, 2006, Witt, 2011; but see Durgin et al., 2012, andalso Firestone &amp;Scholl, 2016).Other researchers, however, argue that conscious perception and sensorimotor processes are based on different processes and representations.For example, within the perception-action model (Goodale &amp; Milner, 2018;Milner &amp; Goodale, 1995), it is assumed that object perception and sensorimotor processing involve different cortical streams (the ventral vision-for-perception and the dorsal visionfor-action stream).Further, it has been suggested that the representations associated with these two streams employ different formats (e.g., Ganel &amp; Goodale, 2003).</p>
<p>Typically, various sensory modalities (i.e., audition, vision, smell, and touch) contribute to perceptual experience.Despite this, people can also compare information across modalities.For instance, as mentioned above people can compare the duration of a tone to the duration of light and vice versa (e.g., Bratzke &amp; Ulrich, 2019;Ellinghaus et al., 2021).They can even compare the brightness of a visual stimulus to the loudness of a tone and vice versa (Heller, 2021;Stevens &amp; Marks, 1965).This aspect of crossmodal processing has been extensively studied in psychophysics, but the cognitive mechanisms underlying this ability are poorly understood.A typical assumption is that crossmodal matching operates on an amodal representation, such as a common intensity scale in intensity matching (Heller, 2021).However, even the representational format of such a fundamental perceptual quantity is not yet well understood (i.e., how intensity is coded and compared intra-and crossmodally).Nevertheless, with regard to time perception, intramodal timing (e.g., comparing the duration of two successive tones) is typically easier than crossmodal timing, a finding that suggests that modality-specific timing also plays a crucial role in time perception (Ulrich et al., 2006).Accordingly, investigating the cognitive mechanisms underlying cross-and intramodal perceptual processes is an essential step toward a better understanding of the interplay between modal and amodal representations in perception.</p>
<p>Research on perception, especially visual perception, usually focuses on stationary stimulus configurations.However, the visual input that humans typically encounter is temporally structured on multiple scales.Humans must deal with dynamic and transient information representing subsequent events.One prominent theoretical account of this dynamic perceptual process is the event segmentation theory (Zacks, 2020;Zacks et al., 2007).The theory assumes that an interplay of bottom-up and top-down processes guides the perception of dynamic events.The continuous incoming stream of sensory information is segmented into meaningful segments at points of change (Zacks et al., 2009), leading to a structured perceptual representation of each event in working memory, the so-called "working event model".Although working event models are still close to the sensory input, they already constitute a form of abstraction as they are internally structured and interconnected.Constructing working event models is guided by abstract knowledge in longterm memory-more specifically by amodal event models and abstract event schemata.Thus, from the perspective we have laid out above, event perception in this theory can be characterized as an interplay of modal and amodal cognitive processes at different levels of abstraction.</p>
<p>Interestingly, it has been shown that while memory performance is better for excerpts with than without an event boundary (Huff et al., 2014(Huff et al., , 2017;;Newtson &amp; Engquist, 1976), dual-task performance is worse at event boundaries.Also, the processing of sensory information seems to be increased at event boundaries compared to during an event (e.g., Huff et al., 2012;Zacks et al., 2020).These findings suggest that elaborate updating processes occur at event boundaries (Huff et al., 2012), possibly focusing mainly on sensory information processing.After perceiving an event boundary, however, participants' memory for details of the sensory information declines (Gernsbacher, 1985).This finding is in line with the view that updating involves the abstraction of information.</p>
<p>The representational formats associated with various aspects of perception may also depend on the specific contextual setting for other tasks, such as object recognition.For example, objects close to an individual's personal space may be represented in a more modal format when they become more relevant for actions.By contrast, objects outside their personal space may be represented in an amodal format that only includes a few categorical features of an object.This idea is reminiscent of theories of motor control that distinguish between an early phase of action planning and a later phase of action control that works on more amodal and modal representations, respectively (Elliott et al., 2001;Fuster, 2001;Hommel et al., 2001;Jeannerod, 1986;Milner &amp; Goodale, 1995;Thomaschke et al., 2012;Woodworth, 1899).</p>
<p>In conclusion, at their core, psychological theories of perceptual processes have always revolved around representational formats.For this reason, the theoretical relevance of representational formats for understanding cognitive processes becomes particularly prominent in the study of perception.However, contemporary theories of perception have abandoned the traditional dichotomy between modal and amodal representations in favor of a hierarchical view.</p>
<p>Here, the assumption is that representations become more abstract (i.e., move from modal to amodal) at higher levels of the processing hierarchy.For example, this view suggests that at higher levels of processing, people can compare information (e.g., stimulus intensity and stimulation duration) across sensory modalities.</p>
<p>Action</p>
<p>As mentioned earlier, it is often assumed that actions proceed in two subsequent phases: first, relatively abstract aspects of the action need to be decided, such as which effector to use and which type of action to perform.Traditionally, this phase has been called the planning phase of the action.Second, concrete details of the selected action have to be specified as, for example, how much force the muscles have to exert to achieve a desired trajectory of the effector or to grip an object, often referred to as the control phase (see also Flanagan et al., 1997).</p>
<p>The gradient from relatively abstract planning to fairly concrete control suggests that the internal representations guiding these phases might range from more abstract to more concrete, with the latter including a specific response modality (e.g., left hand).Such a view is in line with the most influential current theories on action control, and ample evidence has been provided to support such a distinction (e.g., Ballard et al., 1997;Bridgeman et al., 1997;Glover, 2004;Goodale, 2020;Hommel et al., 2001;Jeannerod, 1994;Milner &amp; Goodale, 1995;Thomaschke et al., 2012;Woodworth, 1899).Even theories that are mainly concerned with the high-level identification and meaning of actions (e.g., Vallacher &amp; Wegner, 1987, 2012) can be subsumed in this framework because they abstract from details of the implementation of the action (like muscle movements) and can therefore be considered to be working at a relatively abstract level-similar to what other theories call the planning stage of the action.</p>
<p>However, a closer look shows that the evidence supporting the idea of a transition from amodal planning to modal control is not as clear-cut as is often assumed.For example, the theory of event coding (Hommel et al., 2001; see also Janczyk et al., 2023a) and the perception-action model (Milner &amp; Goodale, 1995) currently dominate research on action planning and control.These theories focus on different aspects of actions and usually implicitly presume that representations of different formats underlie them: the theory of event coding is mainly concerned with planning and assumes the underlying representation is amodal and abstracted from modality-specific information.The perception-action model assumes a dedicated sub-system (the dorsal vision-for-action stream) that is mainly concerned with controlling actions and operates on modal representations, at least when executing well-practiced skilled actions.Unskilled actions, by contrast, are assumed to be guided by the ventral vision-for-perception stream.</p>
<p>However, while a good amount of evidence supports these postulates, there are studies that might appear to contradict any straightforward distinction between amodal planning and modal control.For example, some studies have indicated that representations of duration and color, that can be conceived as being modal, are involved in action planning (e.g., Koch &amp; Kunde, 2002;Kunde, 2003; see also Kunde, 2006), thereby challenging the idea of (purely) amodal planning.Yet, the empirical picture is not that clear.First, results like those reported by Koch and Kunde might be interpreted as involving some sort of abstraction from the effect colors, which might move the representation more to the amodal endpoint of the continuum.On the other hand, Földes et al. (2008) concluded that the observed effects are due to phonological recoding instead.Results showing that anticipation of the action-effect interval duration prolongs initiation of the action (Dignath &amp; Janczyk, 2017;Dignath et al., 2014) are in line with timing research suggesting that interval discrimination/production can be coded in terms of absolute durations operating on modal representation (e.g., Bartolo &amp; Merchant, 2009;Wright et al., 1997), although more research is needed to test this idea in action control.Likewise, the idea that action planning is based on abstract, amodal representations is not fully compatible with recent studies targeting generalization in response-effect learning and compatibility (see Eichfelder et al., 2023;Janczyk &amp; Miller, 2023;Koch et al., 2021; but see Esser et al., 2023, andHommel et al., 2003).Other studies have indicated that the execution of unskilled actions is similar to the execution of skilled actions (in terms of Garner interference8 ; see Eloka et al., 2015;Janczyk et al., 2010), in contrast to what is assumed by the perception-action model (e.g., Ganel &amp; Goodale, 2003), further challenging the idea of a qualitative difference between modal (i.e., here: analytical) control of skilled actions and amodal (i.e., here: holistic) control of unskilled actions.In general, the idea that perceptual tasks are influenced by Garner interference whereas motor control tasks are not, is much less well-supported than was initially thought (Bhatia et al., 2022a).</p>
<p>Other studies also undermine the assumption that two fundamentally different types of representations are involved in perception and action control (see the Section on Perception).For instance, it has been claimed that certain visual illusions that are present in perception are not present in grasping (e.g., the Ebbinghaus-Illusion; Aglioti et al., 1995).However, there is good evidence that the Ebbinghaus-Illusion does in fact affect grasping to a similar degree (Franz &amp; Gegenfurtner, 2008; for a multi-lab replication study, see Kopiske et al., 2016).Finally, many studies have claimed to show evidence that while perception follows Weber's law,9 grasping does not (e.g., Ganel et al., 2008).However, a recent evaluation of the literature by Bhatia et al. (2022b) calls this claim into question, arguing that when analyses are corrected for methodological problems, grasping follows Weber's law just as perception does.In conclusion, there are several empirical findings that call into question whether it really is the case that early phases of action planning are based on more amodal representations and later phases of action control on more modal representations.Accordingly, further research is needed to understand the different functions of modal and amodal representations, along with their possible interactions in action planning and execution, especially in relation to the time course of actions themselves.For instance, it is possible that secondary tasks involving more amodal representations influence particular aspects of early action phases, whereas secondary tasks involving more modal representations influence particular aspects of later action phases.</p>
<p>Cognitive control</p>
<p>Cognitive control allows humans to act in a goal-oriented manner according to their long-term plans and to flexibly adapt their behavior to the specifics of situations.Thus, cognitive control (or executive control) is a vital component of the human cognitive system, and two different control modes may be distinguished (Braver, 2012): Proactive control actively maintains goal-directed information to optimize the cognitive system for a forthcoming, demanding event.</p>
<p>Reactive control depends on detecting processing conflicts, such as in the Stroop task, where participants experience interference from a word's meaning when they are asked to report the competing color of the ink it is printed in.Whereas proactive control leads to long-term processing adjustments through top-down biases, reactive control is a transient process triggered by bottom-up processes that leads to processing adjustments in the short-term.</p>
<p>Representational issues are inherent to this distinction between two control modes and are crucial for research on cognitive control in general.Following insights into the functional organization of the prefrontal cortex (e.g., Koechlin et al., 2003;Miller &amp; Cohen, 2001), and in line with the predictive coding view of cognition (e.g., Gilead et al., 2020), it has been suggested that cognitive control is hierarchically structured, operating on concrete stimulus-response associations at the lower end to more and more abstract and domain-general mechanisms and representations at the higher end of the hierarchy (Badre &amp; Nee, 2018;Schumacher &amp; Hazeltine, 2016).For example, the conflict monitoring hypothesis (Botvinick et al., 2001) assumes that conflicting responses developing at lower processing levels are monitored and that an abstract signal (i.e., Hopfield energy) reflecting conflict strength is issued to higher processing levels that bias subsequent information processing. 10In contrast to the conflict monitoring hypothesis, episodic memory or binding accounts of cognitive control (e.g., Hommel et al., 2004) assume that reactive conflict adaptations result from the processes operating on specific stimulus-response links (e.g., Frings et al., 2020).Accordingly, these theories predict adaptations specific to individual stimulus-response associations.</p>
<p>There are two main experimental approaches to studying cognitive control effects on performance (e.g., Bausenhart et al., 2021;Dudschig, 2022b), resulting in either local or global processing adaptations.The local approach investigates changes of control on a trial-by-trial basis.Specifically, if an incongruency (i.e., conflict) is detected in one trial, this results in the upregulation of control.Thus, in the following trial, the influence of task-irrelevant information is reduced (see also Botvinick et al., 2001), resulting in a reduced congruency effect.The opposite holds for trials following congruent trials (i.e., non-conflict trials).This adaptation is often referred to as the congruency sequence effect (CSE or Gratton effect; Gratton et al., 1992;Stürmer et al., 2002; for a review, see Braem et al., 2014).The second approach focuses on global instead of local changes in conflict adaptation that may mainly result from proactive control.Specifically, this approach varies the relative frequency of congruent and incongruent trials within a block, and the congruency effects are generally relatively small when the proportion of incongruent trials is high, a finding that has been interpreted in terms of strategic top-down adjustments within information processing (for a review, see Bugg, 2017).</p>
<p>Most importantly, both local and global effects allow researchers to address the distinction between modal and amodal representations by asking whether conflict adaptation is domain-specific or domain-general.For example, most studies report reduced or absent CSEs (as a measure of reactive control) when stimulus and response features or tasks change from one trial to the next (Braem et al., 2014;Dignath et al., 2019), which supports the idea of modal stimulus-response representations underlying the CSE and reactive control.However, a few studies suggest that under specific circumstances domain-general adaptation (operating on amodal representations) can occur (e.g., Hsu et al., 2021;Kan et al., 2013) For instance, when experiencing a syntactic conflict during sentence comprehension, the congruency effect in a subsequent Stroop task is reduced (Kan et al., 2013).Yet, recent attempts to directly replicate this original finding have failed (Aczel et al., 2021;Dudschig, 2022a) and extensions to semantic rather than syntactic conflict conditions were also unsuccessful (Simi et al., 2023).Interestingly, for proactive control, there is some evidence for domain-general adjustments when providing explicit information about upcoming congruency (e.g., conflict) (Bugg &amp; Smallwood, 2016;Jiménez et al., 2021), but overall, not enough research has addressed these important issues for firm conclusions to be drawn.</p>
<p>To sum up, representational issues are of central importance for cognitive control theories.For local conflict adaptation, current evidence suggests that adaptation is based on more modal processes and representations.Proactive control, on the other hand, is probably based on more amodal processes and representations.However, future research is needed to corroborate these representational assumptions in research on cognitive control using paradigms that explicitly address whether variables higher up the hierarchy (e.g., task goals, situational context) implement more abstract representations than the apparently lowlevel associative stimulus-response mechanisms involved for instance in the CSE.At the same time, to study amodal representations, future research should minimize the contributions of concrete stimulus-response links (cf.Braem et al., 2019;Schmidt, 2019).Finally, it might be worthwhile to employ research methods targeting different representational processing levels.For instance, low-level response activation could be assessed by using mouse-tracking (Potamianou &amp; Bryce, 2023), response force (Weissman, 2019), as well as brain-based measures such as the lateralized readiness potential (Dudschig &amp; Kaup, 2020;Leuthold et al., 2004), which could be complemented by brain-based analysis methods that are specifically suited to reveal also higher-level representational brain states involved in cognitive control (cf.Freund et al., 2021).</p>
<p>Learning</p>
<p>One of the most basic types of learning is that of learning to represent associations between objects and events (and their attributes) in the world.This process involves learning to discriminate informative from uninformative environmental relationships by means of error-driven processes (Rescorla, 1988; see also Ramscar et al., 2013a, b;Dayan &amp; Berridge, 2014).The notion of associations plays a central role in several domains of cognitive psychology, such as in research on concept learning and semantic memory (e.g., Kelter &amp; Kaup, 2012;Love et al., 2004), word learning (e.g., Ramscar et al., 2013a, b) and conditioning (e.g., De Houwer et al., 2001;Hütter, 2022).However, although the term "association" has a long history, going back to Aristotle and Locke (see Strube, 1984), and is used to explain many phenomena in psychology, it is unclear whether associative learning involves the same types of representations in all cases.In particular, it is unclear to what degree associative learning involves abstraction from individual experiences and, accordingly, the degree to which it involves forming relationships between amodal rather than modal representations is also unclear.In addition, questions about the degree to which abstraction processes are involved in associative learning across different domains, and whether they differ between them, remain largely unexplored.</p>
<p>One way to study these questions is to investigate the factors that trigger abstraction processes and the creation of amodal representations during associative learning.It has been suggested that abstraction is triggered by variability in the exemplars on both sides of the relationship (e.g., Ramscar et al., 2010;Raviv et al., 2022).For instance, if a person sees many different female faces and these are always combined with one of several pleasant images, then this might ultimately trigger the learning of an association between two amodal representations ('female'-'positive valence'; Hütter et al., 2014).By contrast, if the person experiences only one specific exemplar on both sides of the relationship, then this is more likely to give rise to the learning of an association between two concrete modal representations (e.g., a visual representation of the face and a concrete positive image).Differences concerning the variability of the exemplars on both sides of the target relationship might explain differences in the stability of the learned associations as they are typically observed in classical vs. evaluative conditioning11 (Hofmann et al., 2010).Recent research directly manipulating the variability of the exemplars presented as conditioned stimuli in an evaluative conditioning paradigm showed the hypothesized relationship between variability and abstraction (Reichmann et al., 2022).</p>
<p>One parsimonious explanation for why variability in the conditioned stimuli leads to abstraction begins with the observation that associative learning can be characterized as an error-driven process that serves to reduce learner's uncertainty about the environment (Rescorla, 1988;Kiefer &amp; Hohwy, 2019).A critical part of the learning process is cue competition, by which the values of reliable cues are reinforced, and unreliable cues devalued during learning (Rescorla, 1988; see also Siegel &amp; Allan, 1996;Miller et al., 1995).As a result, cues that produce little or no prediction error for an outcome will become positively valued at the expense of cues that lead to prediction errors, which become negatively valued (Ramscar, 2021).The result of cue competition is thus discrimination between relevant and irrelevant features, which leads to representations becoming more abstract and amodal (such that Ramscar, et al., 2010 argue that the term 'associative learning' is itself a misnomer, and that since in practice, representations in the computational models of this process are largely shaped by the error-driven unlearning of uninformative cues, the learning process itself is better conceived of in discriminative terms; for a more traditional perspective, see Reed, 2016 who argues that abstraction processes serve to emphasize distinctive attributes for discrimination).Cue competition is possible in a situation in which a set of complex stimuli predict a set of discrete elements (i.e. when a large cue set is used to predict a smaller set of outcomes, as is the case when a person sees an object with all its features and then hears its label).By contrast, learning from stimuli that lack a rich cue structure hinders cue competition and thus inhibits discrimination learning.For instance, as is the case when a person hears a label and then sees the object it refers to with all its features.Consistent with this, it has been shown that learning to appropriately apply labels to objects is easier for participants when they are trained with a "Feature-Label" procedure compared to when they are trained with a "Label-Feature" procedure (Ramscar et al., 2010).One reason may be that the former leads learners to develop representations that depict the predictive relationships between features and labels, discarding information on non-diagnostic features (i.e., more abstract amodal representations; see also Apfelbaum &amp; McMurray, 2011;Hoppe et al., 2020;Nixon, 2020;Vujovic et al., 2021).The latter may, by contrast, produce representations that provide a more detailed (modal) picture of the structure of the world (i.e., the actual cue probabilities).Thus, there seems to be a trade-off between complexity and discrimination in more abstract amodal representations which seems to be advantageous for labeling (Ramscar, 2013).</p>
<p>However, it is important to note that Ramscar et al.'s (2010) results showed differences in learning outcomes that in principle may or may not be due to different degrees of abstraction in the involved representations.Thus, future research is needed to determine whether learning is advantageous when conditions allow for cue-competition because these conditions lead learners to distort input representations towards abstract representations more than when conditions do not allow for cue competition, and whether these latter situations lead learners to retain more of the modal features of these input stimuli.If this prediction were to be born out in future research, the view that error-driven learning leads to a trade-off between complexity and discrimination could offer a unifying account of the results of studies of the effects of variability on learning and generalization seen across various domains (Raviv et al., 2022).</p>
<p>There may, of course, be other factors that trigger abstraction processes in associative learning.For instance, it has been shown that in concept learning, redundant linguistic labels facilitate the learning process (Lupyan et al., 2007).One reason may be that, as a results of their importance, linguistic labels serve to trigger abstraction processes merely by their presence.In addition, abstraction processes in associative learning might depend on the particular task at hand as well as on the mindset of the learner.It also seems conceivable that the involvement of abstraction processes varies over development.Although grounded cognition researchers often implicitly assume a modal-to-amodal trajectory, there is also evidence for amodal representations being available very early in development (e.g., Rugani et al., 2015;Walker et al., 2010; see also section Development).In our view, examining which types of representations are involved in associative learning under which conditions, and at which points during development, will play an important role in better understanding the functions and interplay of modal and amodal representations.Of course, the nature of the representations involved (modal vs. amodal) is also relevant for other forms of learning, such as procedural or motoric learning (e.g., Pashler &amp; Baylis, 1991a, b), and further investigation in these domains will constitute another fruitful direction of future research.</p>
<p>In conclusion, research into associative learning suggests that variability in the learning exemplars leads learners to build more abstract representations, focusing on the relevant and ignoring the irrelevant stimulus dimensions (cf.Ramscar et al., 2010;Reed, 2016).Also, in concept learning, learners seem to gain from conditions that allow for cue competition and thus in principle provide the opportunity for the learning mechanisms to acquire more abstract amodal representations.However, until now it is not clear whether the gain in performance seen in studies examining this idea is actually due to abstraction processes taking place.Initial research in the domain of evaluative conditioning suggests that this is indeed the case (Reichmann et al., 2022).Future research is necessary to confirm the presumed relationship between learning success and the format of the representations created.Further relevant questions for future research concern not only the domain specificity of abstraction processes, but also their developmental path.</p>
<p>Emotion</p>
<p>Emotions constitute a fundamental part of human experience, serving several essential functions: emotions drive our actions, communicate relevant information about our internal states to our social surroundings, and guide our attention by informing us about relevant environmental changes.However, theoretical accounts of emotion differ significantly when it comes to the question of representational formats.Some scholars see emotions as an (amodal) memory unit in an associative network where these emotions enter into relationships with coincident events (Bower, 1981).On the other hand, grounded-cognition accounts of emotion postulate a purely modal representational format for emotions (Niedenthal et al., 2005).In contrast to these more extreme views, most accounts assume a hybrid view, acknowledging that emotions have both modal and amodal components.For instance, theories distinguish between 'hot' and 'cold' aspects of emotions (Metcalfe &amp; Mischel, 1999), feelings and appraisals (Lazarus &amp; Smith, 1988), motor and conceptual level (Leventhal &amp; Scherer, 1987) or between affective and semantic valence (Itkes &amp; Kron, 2019).</p>
<p>Interestingly, when an emotional stimulus is repeatedly encountered (i.e., emotional habituation, Bradley et al., 1993), modal components of emotions seem particularly attenuated.Habituation is assumed to reflect a basic form of memory (Sokolow, 1963).More specifically, theories assume that the current sensory input is compared against a representation of the repeated stimulus in memory: the stronger the match between the two, the more affective responses will be attenuated (Wagner, 1979).Often habituation is linked to changes in attention; after several repetitions, a stimulus provides no further information and attention is allocated elsewhere (Turatto et al., 2018).Under this framework, affective responses are functionally related to attention allocation, because affective responses signal the need for further processing resources (Codispoti et al., 2016;Öhman, 1992).For instance, physiological responses related to valence and arousal are reduced (e.g., Codispoti et al., 2016), as well as behavioral responses (i.e., Jia et al., 2022) and self-reports (Itkes et al., 2017).In contrast, part of the semantic analysis of emotional stimuli, as indicated by the late positive potential in the human EEG, seems to be resistant to habituation (Codispoti et al., 2016).This could suggest that 'cold', amodal representations are unaffected by repeated exposure.Such dissociation between 'hot' affective responses and 'cold' semantic knowledge also is in line with findings of habituation for subjective ratings, suggesting that participants´ self-reports often combine different sources of information: either they focus more on their actual feelings when encountering a stimulus or they can base their judgment more on the semantic knowledge associated with the stimulus (e.g., Robinson &amp; Clore, 2002).One way to disentangle both sources of information are instructions for self-reports that emphasize either feelings or knowledge (Kron et al., 2014).With repeated exposure, feeling-based self-reports habituate, but not knowledge-based self-reports (Itkes et al., 2017).Together, this evidence suggests that repeated exposure influences 'hot' and 'cold' responses to emotional stimuli differently.While 'hot' aspects of affective responses diminish, 'cold' aspects of evaluative knowledge remain unchanged.Thus, emotional habituation might be a means to bias processing away from modal and towards more amodal representations in processing emotional stimuli.However, more research is needed to better understand such a representational shift during habituation (see Heimer et al., 2023 for a recent approach).</p>
<p>Another area in emotion research where representational issues seem relevant is the affective priming paradigm (Klauer &amp; Musch, 2003).Here, participants classify the valence of a target stimulus which is preceded by a nominally irrelevant prime stimulus.Evaluative categorizations are faster and more accurate for congruent combinations in which prime and target display the same valence (e.g., happy-sunshine) compared to incongruent combinations in which prime and target display a different valence (e.g., happy-war).Two theoretical accounts have been proposed.The first explanation is based on amodal theories and explains affective congruency effects in analogy to semantic priming (Fazio et al., 1986).The semantic priming account assumes that the valence of the prime stimulus pre-activates a corresponding target valence facilitating responses in congruent combinations, but impairing classification for incongruent combinations.The second explanation is based on theories of response priming, suggesting that a prime activates a corresponding response which then facilitates (or impairs) responses during congruent (incongruent) combinations.The canonical example of response priming are Stroop-like tasks in which relevant target responses compete with irrelevant distractor responses.To explain response priming, theories have adopted a dynamic system view (Scherbaum et al., 2012), which does not employ amodal symbols, but instead describes behavior in terms of continuous states, in line with some (namely anti-representationalist) theories of grounded cognition and simulation (see Spivey, 2008).In fact, Niedenthal and colleagues speculated that "the detection of emotion congruence [in affective priming] is determined by the extent to which the target of judgment must be simulated in order to produce the inference.Extensive simulation will bring more perceptual aspects into the simulation and thereby produce greater, or more easily detectable, emotion congruence.Less simulation will yield a response with fewer perceptual aspects of the concept."(Niedenthal et al., 2003, p. 316).However, to which extent affective priming reflects 'hot' affective responses or rather 'cold' evaluative knowledge is a matter of debate (see Rohr &amp; Wentura, 2022).For example, suppose the above considerations are correct and emotional habituation biases towards more amodal processing.In that case, studies examining the effect of habituation on affective priming might be highly informative concerning the psychological reality of the two different types of accounts of affective priming.</p>
<p>In conclusion, although emotions are often characterized by comprising two components one of which is more modal and the other more amodal, it is still unclear how these components interact or under which one or the other component takes the lead.</p>
<p>Language</p>
<p>According to traditional theories, the representations of meaning involved in language comprehension and production are amodal, and have a compositional structure (e.g., Kintsch, 1988;McKoon &amp; Ratcliff, 1992, 1998;Reed, 2016).During comprehension, people presumably create a coherent network of propositions by identifying the propositions in a sentence or text and their interrelations in terms of argument overlap or rhetorical structure (Asher &amp; Lascarides, 2003;Kintsch &amp; Van Dijk, 1978).Moreover, comprehenders presumably infer particular propositions to fill potential coherence gaps in the linguistic input.Likewise, for language production, such a propositional representation is assumed to constitute the starting point of the production process (e.g., Levelt, 1989).However, grounded comprehension and production models have received more attention within the last two decades.These models assume that modal sensorimotor processes play an essential role in meaning representation during language processing (e.g., Barsalou, 1999;Glenberg &amp; Gallese, 2012;Glenberg &amp; Kaschak, 2002;Zwaan, 2004; for critical reviews, see Machery, 2007Machery, , 2010;;Mahon &amp; Caramazza, 2008;Winter et al., 2022).</p>
<p>According to these latter models, meaning representations in language processing are assumed to involve the re-activations of experiences with objects, events, and situations that the linguistic stimulus (word, sentence or text) refers to.However, so far, the evidence for this view is mixed.While there is evidence that modal representations are activated during language processing, their activation seems contextdependent (e.g., Lebois et al., 2015;and Yee &amp; Thompson-Schill, 2016 for an overview).Also, it remains unclear whether they play a functional role in language processing (e.g., Montero-Melis et al., 2022;Ostarek &amp; Huettig, 2019;Pulvermüller et al., 2005;Strozyk et al., 2019;Vermeulen et al., 2008;Yee et al., 2013).Thus, it is conceivable that modal representations constitute a mere epiphenomenon, possibly a residual from language acquisition during which sensorimotor meaning representations might be functionally relevant.Alternatively, language comprehension and production might be better characterized by hybrid representations comprising modal and amodal components.This would explain why some studies reported strong evidence for the involvement of modal representations during language processing, whereas others do not (for an overview, see Kaup et al., 2015;Kaup &amp; Ulrich, 2017; see also Berndt et al., 2018Berndt et al., , 2020;;Ostarek &amp; Hüttig, 2017;Schütt et al., 2022Schütt et al., , 2023)).Although the hybrid hypothesis has become popular in recent years (e.g., Binder &amp; Desai, 2011;Dove, 2009Dove, , 2011Dove, , 2022;;Wajnerman Paz, 2018;Zwaan, 2014), a systematic investigation of the factors that influence which type of representation gains the upper hand during comprehension and production is still missing.</p>
<p>An important question for future research is to understand better the conditions under which modal and amodal meaning representations play a functional role in language processing.One important factor seems to be the level of processing required by the task; with the increasing likelihood of modal representations, the "deeper" the meaning of the linguistic stimulus has to be processed (e.g., Miller &amp; Kaup, 2020).In addition, the amount and type of direct experiences that a comprehender has made with the described entities and situations in the past determine the type of and the degree to which modal representations are involved in comprehension (e.g., Beilock et al., 2008;Buchanan et al., 2022;Capuano et al., 2023;Casasanto, 2009;Holt &amp; Beilock, 2006;Öttl et al., 2017;Ong et al., 2014;Wolter et al., 2015Wolter et al., , 2017)).Modal representations seem to be primarily activated if the comprehender has made some form of direct experience with the referents themselves or with a similar referent, allowing for what might be called an "indirect grounding" of verbally acquired concepts (e.g., Günther et al., 2020;Günther et al., 2022;Yee et al., 2013; see also Andrews et al., 2009).Also, as implied by the Construal-Level Theory, one relevant factor might be the psychological distance to the objects, situations, and events that the linguistic stimulus refers to (Trope &amp; Liberman, 2010).</p>
<p>In line with this latter assumption, some recent studies have observed relationships between both temporal and spatial distance and abstractness level (Bausenhart et al., in press; Bausenhart et al., in prep a).More specifically, a series of experiments based on the implicit association test paradigm (IAT, Greenwald et al., 1998; see also Bar-Anan et al., 2006), revealed that response times in a task in which participants decided about the psychological distance a stimulus refers to (proximal vs. distal) or its abstractness (concrete vs. abstract) were influenced by the particular response key assignment in the task.Decisions were faster when distal entities were assigned the same key as abstract entities and proximal entities the same key as concrete entities, suggesting an association between abstractness and psychological distance.Interestingly, for temporal distance, the effects were much clearer when the distal time point to which the "now" (proximal) was compared was the future compared to when it was the past.One potential reason for this is that the future is not only distant but also uncertain, which according to construal-level theory should additionally increase the psychological distance.These experiments show that abstraction level and temporal and spatial distance are cognitively related.However, in the domain of temporal distance, this association seems to be less straightforward and symmetrical than one might expect.</p>
<p>Another series of experiments investigated how spatial distance modulates cognitive representations.Participants were presented with sentence-completion tasks based on a paradigm by Kaup et al. (2021), to assess how distance primes the completion of an incomplete sentence.For example, participants saw an initial sentence fragment that implied near or far spatial distance from the location at which the experiment took place (e.g., In Los Angeles [vs. Stuttgart], the woman buys….They were then asked to select a sentence completion from one of two options, differing in the level of abstraction (e.g., clothes vs. trousers).In another condition, it was the abstraction level that was manipulated in the initial sentence fragment, and participants were to complete the sentence with the best-fitting spatial location (e.g., The woman buys clothes in… to be completed with Los Angeles or Stuttgart).It was predicted that participants would choose a close location most often for a more concrete term in the initial sentence fragment and a more distal location for a more abstract term, and vice versa.These predictions were clearly born out in certain tasks and conditions, namely when spatial distance was implemented in absolute terms (e.g., by means of explicitly mentioning locations), as well as in a forced-matching task, in which participants were presented both initial fragments and both endings at once and were asked to match them into two sentences.The latter task probably works well because it provides a sort of reference for interpreting the categories.For example, trousers may be specific or abstract, depending on whether they are compared to jeans or clothes (Bausenhart et al., in preparation b).</p>
<p>Another possibility is that cognitive control processes (Botvinick et al., 2001) influence which type of representations constitute the basis for processing.Specifically, it seems conceivable that following an experienced conflict, the linguistic system operates on amodal rather than modal meaning representations.There is little relevant evidence yet with which to evaluate this possibility.The studies mentioned above, looking at the question whether control processes are domain-general or domain-specific did not observe any evidence that perceiving a semantic conflict in one trial of a linguistic task would influence the processing of semantic conflict in a subsequent trial (Simi et al., 2023).One might take this to suggest that conflict adjustments do not target the representational format utilized during language comprehension.However, as these studies did not directly investigate the format of representation, this conclusion is premature.We are not aware of any studies directly investigating the hypothesis of a relationship between the experience of conflict and the representational format used in language comprehension.However, recent studies concerned with the processing of negation may give some hints.Negation has been shown to be difficult to process, and it has been suggested that one reason for this difficulty has to do with the fact that in negative constructions, the non-factual situation is explicitly mentioned (i.e., The destination is not on the left side, explicitly mentions the left side although this is the exact opposite of the true destination's property).This might lead to processing difficulties in particular, when comprehenders engage in full-fledged mental simulations of the sensorimotor aspects of the linguistic content, as not on the left side would activate sensorimotor processing focusing on the left side (see Kaup &amp; Dudschig, 2020 for an overview on negation research).Indeed, participants show response activation of the contralateral effector when processing phrases like not left or not right as indicated by the lateral readiness potential (Dudschig &amp; Kaup, 2018).Importantly, however, this tendency to activate the wrong response side following the processing of negation was strongly reduced when the previous trial also contained a negated phrase.This might suggest that the experience of a conflict led participants to reduce simulating the linguistic material and instead turn to more amodal representations that are less prone to automatically activate sensorimotor processes related to the individual words in the linguistic phrases.However, before definite conclusions can be drawn, future research that directly tests the format of the created representations is needed.</p>
<p>In conclusion, there is much evidence that language comprehenders use modal meaning representations during comprehension.However, it is still unclear whether these are functional for comprehension or not.Further, the exact conditions under which comprehenders use more modal or more amodal representations have yet to be determined.Several factors are likely to play a role, including the level of processing required by the task at hand and the amount of experience a comprehender has with the reference entities.Additionally, it seems likely that the psychological distance to the reference situation or the disruptions that occurred through modal processing in previous processing may also play a role.Future research is required to investigate the interplay between modal and amodal meaning representations during language comprehension, and to establish their functional role for comprehension.</p>
<p>Thought</p>
<p>According to many researchers in cognitive psychology, thinking is deeply rooted in how people perceive space.Space is thus assumed to be an essential component of cognition.Accordingly, space serves to structure thoughts and thus enables humans to understand the world around them.According to metaphoric mapping accounts (Boroditsky, 2000;Gentner et al., 2002;Lakoff &amp; Johnson, 1980;Lakoff &amp; Núñez, 2000, Winter et al., 2015), abstract thinking is achieved by mapping abstract domains that cannot be directly experienced onto modal domains that can be more directly experienced.In particular, it is often believed that spatial experiences structure thinking about non-spatial domains such as time or numerosity (Boroditsky &amp; Ramscar, 2002;Casasanto et al., 2010), allowing reasoning about magnitude.For example, a study by Janczyk et al. (2023b) indicated that although space and time are mentally associated, as are space and numbers, time and numbers are not mentally associated in the same way.This result is consistent with the notion that the non-spatial domains, numerosity and time, draw on spatial thinking.</p>
<p>However, not all authors agree that space is a predominant feature of quantitative reasoning.For instance, Walsh (2003) proposes that humans rely on a general magnitude system, which processes magnitude information regardless of whether it relates to space, numbers, or time (see also Bueti &amp; Walsh, 2009).In contrast to the metaphoric mapping view, this view assumes an amodal representation as the basis of quantitative reasoning (but see Patro et al., 2016b).To summarize, it is controversial whether quantitative reasoning exclusively operates on amodal or modal representations, or a hybrid of both.</p>
<p>For example, the Spatial-Numerical Associations of Response Codes (SNARC) effect describes the associations between smaller numbers with the left side of space and larger numbers with the right side of space observed in Western cultures (Dehaene et al., 1993).Many influences have been demonstrated in SNARC research that are typically explained by referring to modal representations, in particular by assuming that numbers are positioned on a mental number line, which is shaped by experiences (e.g., Fischer &amp; Shaki, 2015;Patro et al., 2016a).However, little is known about how different modal representations interact with space-number associations, because different modalities are usually associated.Some studies provide first evidence concerning different modal influences on the SNARC effect by employing a virtual-reality setup, in which the perceived placement of the hands is manipulated independently of their actual location.These studies suggest that when the numbers are presented close to the body within the reaching space of the hands, the arrangement of the perceived hands in space does not matter much.Instead, the decisive factor in this case seems to be which hand (left or right) is used for responding.By contrast, when the numbers are presented further away from the body and hands, the hands' arrangement matters, strengthening the horizontal or sagittal SNARC depending on their perceptual arrangement (Koch et al., 2022;Lohmann et al., 2018).In summary, the influence of different modalities for the SNARC seems to depend on the sensory and motor conditions of the setup.</p>
<p>Other accounts seek to explain the SNARC effect by exclusively invoking amodal representations.For instance, the serial order working memory account (e.g., van Dijck et al., 2014) postulates a domain-general mechanism that spatially orders all numerical and non-numerical sequences.In typical SNARC studies, there is a strong correspondence between the ordinal position of numbers and their magnitude, making it difficult to differentiate whether the ordinal position or the numerical magnitude is the crucial factor of the SNARC effect.In a recent study, however, the two accounts were compared directly using different stimulus sets in which the ordinal position of particular critical numbers differed considerably from their magnitude position on a continuous mental number line (e.g., 1,2,3,8; 2,3,4,9; 1,6,7,8; 2,7,8,9).Overall, the response-time pattern obtained with a parity-judgment task requiring left vs. right-hand responses supported the view that number magnitude is mentally mapped to space according to magnitude as well as ordinal sequence.This effect even held when the serial position of the numbers was made salient by having participants learn the serial order of the numbers beforehand and recall the number sets after the parity judgment task.One potential limitation of these result could be that the learned set was irrelevant for solving the parity-judgment task.Thus, follow-up studies are needed to rule out that different results would be obtained when the learned sets are relevant for the SNARC task (Koch et al., 2021).</p>
<p>As mentioned earlier, space is believed to modulate the representational format of human thinking in another research domain.In particular, the construal-level theory postulates that thinking about specific states of affairs involves representations at different levels of abstractness depending on the psychological distances to the state of affairs in question (Trope &amp; Liberman, 2010).However, although previous research has indicated that representations differ for proximal vs. distal things, the cognitive format of these representations has not yet received much attention.First evidence for distance-dependent representational formats was obtained in a recent study on spatial landmark memories.More specifically, LeVinh et al. (2020) investigated the so-called position-dependent recall effect in a virtual environment simulation of familiar places in Tübingen, a small university town in Southern Germany.Participants were immersed in a virtual environment showing a familiar location in downtown Tübingen.After ensuring that the location was recognized, subjects turned until they found a workspace laid out so that they had to take a particular body orientation to complete the task.The workspace comprised five objects identifiable as buildings surrounding a particular target area (in this case, the Timber Market).Participants were then asked to drag and drop the blocks into a configuration rebuilding the target area.The compass bearing of the produced viewing direction was recorded.These compass bearings clearly showed a position-dependent recall effect, meaning that participants built their configuration from the viewing direction consistent with their current location.More importantly for our present purposes, however, the strength of this position-dependent-recall effect decreased with the distance to the target area for two-thirds of the participants.</p>
<p>In conclusion, space seems to play a fundamental role in thinking related to the planning of actions and navigation and for more abstract thoughts such as reasoning about time and number.However, whether these phenomena can best be explained through modal or amodal representations is still debatable.So far only a few research studies have been conducted to understand the interplay between modal and amodal representations in explaining the respective effects.We think that this is a pressing issue for future research.</p>
<p>Development</p>
<p>The issue of the representation format has only started to become the focus of developmental research.However, the idea that sensorimotor information initially drives ontogenetic cognitive development and thus forms the basis of higher cognitive processes has been around for a while.It was already an important aspect of Jean Piaget's work (Piaget, 1952).However, Piaget did not argue for strong interactions between modal and amodal cognitive processes.Instead, he suggested that children progress to concepts that are independent of their sensorimotor experiences during their primary school years.Contrary to this assumption, more recent work suggests that perceptual simulation is crucial for the development of higher cognitive processes, even in school-aged children (e.g., De Koning et al., 2017;Engelen et al., 2011;Vogt et al., 2019) and in adults (e.g., Borghi et al., 2004;Pecher et al., 2003;Stanfield &amp; Zwaan, 2001).</p>
<p>However, one objection must be considered when interpreting these and other similar results.The involvement of modal representations in higher cognitive processes appears to be context-and task-dependent in adults (e.g., Areshenkoff et al., 2017;Bub &amp; Masson, 2010;de la Vega et al., 2012;Dudschig and Kaup 2017;Dudschig et al., 2015, Hoenig et al., 2008;Lebois et al., 2015;Louwerse &amp; Jeuniaux, 2010;Ostarek &amp; Hüttig, 2017;Pecher, 2013Pecher, , 2018;;Pulvermüller, 2013;Ulrich &amp; Maienborn, 2010;Van Dam et al., 2012, 2014;Yee &amp; Thompson-Schill, 2016;Tomasino et al., 2007).Thus, as mentioned earlier, the claim that modal representations in adult higher cognitive processes constitute a mere epiphenomenon without functional relevance cannot be ruled out (Ostarek &amp; Huettig, 2019).One possible explanation for why adult modal representations can nevertheless become activated during higher cognitive processes is that such activations are merely residual manifestations of earlier cognitive development.According to this view, modal representations are functionally relevant for higher cognitive processes early on during development, but they lose their functional relevance during the course of development such that their manifestations in adults are epiphenomenal (see Fig. 5, left side).This view in turn suggests that the cognitive-developmental trajectory proceeds from modal to amodal representations.</p>
<p>Such embodied conceptualizations contrast with recent theorizing based on evolutionary psychology and comparative research (e.g., Spelke &amp; Kinzler, 2007).This line of argument maintains that early cognitive development is guided by abstract core knowledge (e.g., about living beings, objects, actions, numbers, and space), presumably preparing humans to process modal information in a particularly efficient way.Theories and findings on category acquisition might serve as an illustration of different pathways related to the emergence of amodal representations during ontogenetic development (see Fig. 5).According to the theory of Piaget, cognitive psychology initially considered first categories to be basic level ones, based on perceptual similarities (Rosch et al., 1976).However, research with infants showed that early categorization can occur on more than one basis and that basic level categories are often acquired later than particular superordinate categories (Mandler, 2004).For example, infants appear to have amodal representations available in the field of biological understanding, regarding the classification of living beings.Here, children do not build up biological knowledge by learning specific, concrete information and eventually progressing to abstract rules and principles.Instead, they appear to start with an initially amodal abstract core concept of "living beings", which structures several abstract modality-specific patterns, such as typical visual properties of faces.During development, the system gradually fits in all the concrete details and mechanisms that elaborate those concepts and patterns.</p>
<p>A somewhat comparable perspective also emerged in associative learning beginning with Seligman's findings indicating that abstract visual properties promote specific types of learning (e.g., rapid learning of snake-or spider-fear associations, Seligman, 1970).Interestingly, preparedness has been shown to be already evident in infants, who rapidly establish fear of snakes even when they had no experience of snakes (DeLoache &amp; LoBue, 2009).In other words, in contrast to the modal-to-amodal trajectory proposal mentioned above, other accounts favor the idea that amodal representations are available even early in development.According to this view, rudimentary abstract concepts scaffold the encoding of modal experiences, enriching and restructuring amodal representations (see Fig. 5, right side).</p>
<p>Further relevant evidence comes from studies employing the looking-while-listening paradigm (Bergelson &amp; Aslin, 2017;Bergelson &amp; Swingley, 2012) to investigate the processes underlying vocabulary learning in infants (Kartushina &amp; Mayor, 2019;Steil et al., 2021).In this paradigm, infants hear spoken words and see two pictures on a screen while their eye-movements are recorded.If an infant focuses on an appropriate object when hearing a label, this is taken as evidence that the infant has learned the label.The results of such studies appear to provide further evidence that cognitive processing makes use of amodal information even in infancy.Specifically, it has been shown that the success of infants matching objects to labels correlates with differences in the frequency with which objects occur in their lives: infants correctly fixate on the labeled object more often when the difference in frequency between the two objects shown is higher.This result can be interpreted as showing that infants learn to match objects that they frequently see to labels that they frequently hear, which in turn suggest that children's associative learning mechanisms are capable of mapping between experiences in different modalities.In terms of our proposed framework, this suggests that the learning mechanisms that lead to the development of abstract, amodal representations are available even at the earliest stages of development.</p>
<p>In addition to these considerations concerning the two different developmental trajectories, research in developmental psychology can also be informative regarding the function of amodal representations for cognition.For example, it is well known that achievements in cognitive development are often correlated with achievements in linguistic abilities (e.g., Schneider et al., 2004).This relation has been particularly intensively discussed concerning the theory of mind abilities (e.g., De Villiers, 2007;Milligan et al., 2007, and the contributions in Astington &amp; Baird, 2005).In principle, these relationships may reflect an underlying development in the ability to use amodal representations (cf.Dove, 2014).Amodal abilities might then boost linguistic abilities (e.g., using terms for mental states) and non-linguistic cognitive abilities (e.g., understanding the mental state of others).If so, studying the relationship between the developing linguistic and non-linguistic cognitive abilities will contribute to a better understanding of the functions of amodal representations for cognitive processes in general.</p>
<p>In conclusion, representational issues seem of great importance to developmental theories.In principle, two different perspectives can be outlined that postulate either a modal-to-amodal trajectory or an early-amodal-representations view.Further, developmental research can be very informative for more general representational theories, particularly concerning the functions that modal and amodal representations play.It thus appears a promising avenue for future research to investigate different issues by exploring the functions and interactions of modal and amodal representations during early childhood and later stages of development.In particular, it seems important that the psychological reality of the two different developmental trajectories be assessed in different cognitive domains.</p>
<p>Dysfunction</p>
<p>A further important question is whether the representational concepts outlined above can be profitably applied to clinical research to understand dysfunctional behavior and cognition better.Despite their often being neglected, resolving representational issues could be a key to describing dysfunctional behavior and improving treatments for abnormal behavior.In this vein, impulsivity is crucial for a better understanding of many kinds of dysfunctional behavior (Blume et al., 2019;Dawe &amp; Loxton, 2004;Diamond, 2013;Fineberg et al., 2014;Schroeder et al., 2020).Although impulsive behavior often has a strong negative impact on an individual's life, and on society more broadly, it is still unknown what mechanisms underlie or trigger impulsivity.One possibility is that overly impulsive individuals cannot inhibit behavior triggered by modal representations.Another possibility is that inhibitory issues are generally problematic in impulsive individuals, and that this applies to both modal and amodal representations of objects, events, and situations.</p>
<p>Impairments in inhibitory control are considered a central mechanism in the maintenance of pathological eating behavior such as food-related craving, emotional eating, restrained eating and binge eating (Lavagnino et al., 2016;Wolz et al., 2020Wolz et al., , 2021)).It is possible that pathological eating behavior is only triggered by modal food representations (e.g., picture-like representations, which are often targeted in food advertisements or experienced with food, such as when passing by the tempting display of a bakery), but that it is not triggered, or triggered less, by amodal food-related representations (e.g., representations given rise by verbal descriptions of a nice meal, the menu in a restaurant; cf.Rumiati &amp; Foroni, 2016).A better understanding of the type of representations that are involved in overeating can lead to improved treatments by revealing their exact relationships with the mechanisms that complicate daily food choices.Such understanding is essential because overeating can be observed in most societies and has already led to pandemic health problems such as overweight and obesity (Ng et al., 2014).In a more general sense, understanding modal and amodal aspects of dysfunctions and disorders can help us understand what is necessary for healthy functioning.In the same vein, the exploration of the effectiveness of if-then plans (i.e., on implementation intentions) that specifically target abstraction processes is of great importance (for research on if-then plans, see Gollwitzer, 1999; see also Gawrilow &amp; Gollwitzer, 2008;Gawrilow et al., 2011).If pathological eating behavior indeed reflects a predominance of modal food representations, then interventions that focus on abstraction processes should be especially effective.To our knowledge, this option has not been investigated in research on pathological eating behavior.</p>
<p>To date there has been little research on the format of representations in research on pathological eating behavior.This is surprising as the view that particular formats are more likely to trigger pathological eating behavior seems to suggest itself.However, first support for this proposal comes from two recent studies using the stop signal task (SST; Logan, 1994;Logan &amp; Cowan, 1984) in which representational format was manipulated indirectly by varying the format of the presented stimuli (pictures vs. words). 12Satiated individuals were relatively good at inhibiting pictorial stimuli compared to word stimuli, whereas this was not the case for hungry individuals (however, this difference between the two groups was similar for food-and non-food items; van den Hoek Ostende et al., under review).Although future studies are needed to determine the relevant factors that lead to an increase or decrease of inhibitory control in stimuli of different formats in different groups of participants, this is clearly a promising line of research.An additional complication arises from the possibility that experimentally induced homeostatic states (i.e., hunger and satiety) may be insufficiently sensitive to reveal differences between healthy populations and populations with trait overeating.To this end, restrained eaters may provide a better sample for study because they are characterized by investing cognitive effort to restrain food intake despite homeostatic signals of hunger, but also by occasionally losing control over food intake, eventually leading to weight gain (Adams et al., 2019).Indeed, when comparing participants with very high and very low restraint scores (Restraint Scale; Herman &amp; Mack, 1975), only individuals with high restraint scores showed differences in processing pictures and words specific for food pictures.More specifically, for food stimuli, highrestraint individuals were particularly good at inhibiting pictures but not words ( Van den Hoek Ostende et al., 2023).This is interesting because it opens the possibility that this group of people strategically upregulates control for a type of stimulus (i.e., pictures) that seems most threatening them, perhaps because these stimuli convey sensorimotor features that trigger pathological eating behavior.Future research is necessary to investigate whether these differences also transfer to actual food intake after processing these types of stimuli.</p>
<p>The above considerations concern the role of modal and amodal representations in the elusive boundary between normal and abnormal behavior as incorporated in the Research Domain Criteria (RDoC) matrix (Insel et al., 2010).However, the functional role of these different representational formats may even be a key to understanding severe clinical disorders.In fact, functional cognitive differences with direct relation to amodal representations have typically been associated with schizophrenia (e.g., Silberstein, 2014).Another example is a newly emerging cognitive approach in autism literature, the "Thinking in pictures" theory (e.g., Bòkkon et al., 2013;Kunda &amp; Goel, 2011;Landgraf &amp; Osterheider, 2013).It hypothesizes that some characteristics which individuals with autism show when solving specific tasks are due to the predominance of modal representations, compared to the more amodal-verbally mediated-approach that individuals without autism use.</p>
<p>Before closing this section, we would like to point out that the distinction between modal and amodal representations is also highly relevant to an emerging research field in clinical psychology, namely the use of virtual reality (VR) setups in researching and treating clinical disorders.Notably, clinical research can highly benefit from VR, as VR environments effectively elicit psychological symptoms (e.g., craving in response to virtual chocolate stimuli; Schroeder et al., 2023b), allowing for causal inferences through highly effective manipulations (e.g., body size manipulations of 12 Although stimulus format is certainly not be confused with the format of the mental representation that they give rise to, we still report these studies here, because they are the only available research in this domain that is related to our debate.We do this based on the assumption that stimuli of different external formats might more readily give rise to one or the other form of mental representation and therefore stimulus format can be considered as an indirect way of manipulating representational format.Thus, although a verbal description and a picture can both in principle lead to a modal or an amodal representation, it still seems to be the case that a verbal description is closer to an amodal representation, and a picture is closer to a modal representation.Thus, it seems plausible to assume that a verbal description can be more readily represented in an amodal representation and a picture more readily in a modal representation.</p>
<p>embodied avatars to measure weight anxiety; Schroeder et al., 2023a).Furthermore, the development of VR applications is also considered a promising tool with increasing potential for the treatment of mental disorders (Freeman et al., 2017;Rizzo &amp; Koenig, 2017).On these grounds, we consider VR not only an optimal method for testing the contribution of modal and amodal processes in mental disorders by enabling the manipulation of stimulus format involving highly photorealistic stimuli as well as their spatial attributes.We are also convinced that insights from research on modal and amodal processes will most likely be fruitful for the development of effective treatment applications in VR.For example, particularly for VR cue exposure and VRbased corrections of attentional biases (Riva et al., 2021), the results of this research can inform future VR studies regarding the required degree of modality in stimulus presentation.</p>
<p>In conclusion, although representational issues seem highly relevant to several areas of clinical psychology, to date only minimal research on the role of different representational formats in human dysfunctions has been conducted.However, some recent studies concerned with inhibitory capacities that indirectly manipulated representational formats by varying the stimulus type indicated that representational issues seem to offer a key to better understanding the mechanism behind pathological eating behavior.In general, we believe that understanding modal and amodal aspects of dysfunctions and disorders can help us understand what is necessary for healthy functioning and pave the way for effective interventions and prevention programs, especially involving the newly emerging VR-based methods.</p>
<p>Conclusion</p>
<p>The distinction between modal and amodal representations is widely discussed in cognitive psychology, particularly in relation to perception and language.However, it is becoming evident that this differentiation also plays a significant role in other fields of psychology, although receiving less attention than in perception and language.In our review, we have identified three research questions that are crucial for advancing our understanding of representational formats in psychology and related fields.First, it is important to determine the conditions under which cognitive processes rely more on modal or amodal representations.Based on our analysis, we have identified potential factors that may influence the dominance of one representation type over the other, such as the proximity to the object being represented, the frequency of encountering an item, or the age of the individual involved.Second, we need to investigate the functions of modal and amodal representations in cognition.Our analysis reveals that modal representations are well-suited for immediate actions or representing stimuli in close proximity, while amodal representations serve as a basis for comparisons and crossmodal matches.Lastly, we should examine how processes based on modal and amodal cognition interact.Our analysis suggests that certain domains, such as language, learning, and event cognition, are likely to exhibit strong interactions between these two cognitive approaches.</p>
<p>• While our review has predominantly focused on representational formats, it has become apparent that solely considering formats without accounting for cognitive processes is often insufficient.A more comprehensive understanding of cognition necessitates a more explicit examination of both representational formats and the cognitive processes that operate on them.Taking an integrated view could provide valuable insights into why different representations are integrated into the cognitive system.• Our review also shows that the distinction between modal and amodal representations is less sharp than might perhaps have been hoped.However, it is worth bearing in mind that the vagueness of concepts might sometime be beneficial for scientific progress, in that it can inspire new ideas and enable us to see relationships that might otherwise not be evident, allowing us to connect different research fields.We thus agree with William James (1890, p. 6) that the mental is undoubtedly vague and therefore "it is better not to be pedantic but let the science be as vague as its subject", or in Marvin Minsky's (1988) terms: "It often does more harm than good to force definitions on things we don't understand.</p>
<p>[…] Especially when it comes to understand minds, we still know so little that we can't be sure our ideas about psychology are even aimed in the right directions.In any case, one must not mistake defining things for knowing what they are." (p. 39).Accordingly, we suggest the distinction between modal and amodal representations, despite not being crystal clear, can foster a fruitful exchange of theoretical ideas between domains.This endeavor is undoubtedly made more difficult if each area uses other terms for similar theoretical concepts.What we have sought to show is how overarching principles of different types of representations can be identified, and our hope is that they may contribute to the development of more integrative accounts of human cognition.</p>
<p>Fig. 1
1
Fig. 1 Illustration of the continuum ranging from very concrete modality-specific representations on the one hand (left side) to more abstract symbolic representations on the other hand (right side)</p>
<p>Fig. 2
2
Fig. 2 Properties and examples of modal and amodal representations (see text for further explanations)</p>
<p>Fig. 5
5
Fig. 5 The modal-to-amodal trajectory view (left) versus the early-amodal-representations view (right)</p>
<p>As stressed above, it is unclear to what degree all of these dimensions are continuous in a strict sense, especially concerning the dimensions ranging from 'experiential' to 'describing' and also 'structure preserved' to 'different structure'.
2 Physical dimensions (e.g., sound pressure) that produce experiences (e.g., loudness), which allow quantitative judgments (e.g., "louder than") are regarded to belong to the prothetic domain. By
The philosopher Immanuel Kant (1724-1804), however, claimed that the mind is not decomposable and therefore, among other things, psychology can never become a science. Early psychologists like Wilhelm Wundt, however, challenged his view.
From the point of view of optimal encoding,Barlow (1972, p. 371)   suggested that "the sensory system is organized to achieve as complete a representation of the sensory stimulus as possible with the minimum number of active neurons" which led the way to combining the advantages of feature and template-based approaches into the theory of "sparse coding"(Olshausen &amp; Field 1996
).6  This effect describes the phenomenon that a letter is easier to recognize within words than in
isolation.7  As noted byHutchinson and Barrett (2019), the idea of top-down representations is not new. However, there is increasing research that tests this core idea embodied in this predictive coding framework.
This interference emerges when the variation of a task-irrelevant dimension (e.g., length of a line) affects the discrimination or classification of stimuli along a task-relevant dimension (e.g., the thickness of the line). In such cases, the two dimensions are not separable but integral dimensions(Garner, 1976).
  9  According to this law, the just noticeable difference between two stimulus magnitudes (e.g., two successively lifted weights) is proportional to the smaller stimulus magnitude of the two magnitudes (for a formal definition, seeLuce &amp; Galanter, 1963).
In this view, when conflicting responses are detected, cognitive control mechanisms are engaged that serve to increase the influence of task-relevant information (e.g., the ink color of a word in the Stroop task) and inhibit the influence of task-irrelevant information (e.g., word's meaning), helping to resolve the conflict and achieve an agent's goals. These control mechanisms have recently been implemented in the diffusion model of conflict tasks(Mackenzie &amp; Dudschig, 2021;Ulrich et al., 2015) to account for various conflict adaptation effects(Koob et al., 2022, Koob et al., 2023). More recent versions of the conflict monitoring theory even assume that the monitoring process does not register conflict but detects the affective response (i.e., negative valence, increased arousal) caused by conflict(Dignath et al., 2020, for a review). Thus, on this latter account the relevant representations are assumed to be more modal.
Evaluative conditioning occurs when the valence of a stimulus changes as a result of its repeated pairing with another stimulus that carries a positive or negative valence.
AcknowledgementsWe would like to thank Arthur Glenberg, Diane Pecher, and Tessa Warren for their very helpful and inspiring input on the topics covered in this manuscript.We also thank all the doctoral and post-doctoral students in the research unit for recurring discussions on representational issues in cognitive science that greatly helped us develop the perspective presented here.Funding Open Access funding enabled and organized by Projekt DEAL.This research was supported by Deutsche Forschungsgemeinschaft (DFG, German Research Foundation) 1422488154; 381713393,Author contributions Barbara Kaup and Rolf Ulrich wrote the draft for the main manuscript text.All authors reviewed and edited the manuscript.The content of the manuscript emerged in group discussions with all authors over a longer period of time in the context of the research group "Modal and Amodal Cognition: Functions and Interactions".
Is there evidence for crossdomain congruency sequence effect? A replication of. B Aczel, M Kovacs, M Bognar, B Palfi, A Hartanto, S Onie, L E Tiong, T R Evans, 10.1098/rsos.191353Royal Society Open Science. Kan et al.82021. 2013. 191353</p>
<p>Do restrained eaters show increased BMI, food craving and disinhibited eating? A comparison of the Restraint Scale and the Restrained Eating scale of the Dutch Eating Behaviour Questionnaire. R C Adams, C D Chambers, N S Lawrence, 10.1098/rsos.190174Royal Society Open Science. 662019. 190174</p>
<p>Size-contrast illusions deceive the eye but not the hand. S Aglioti, J F Desouza, M A Goodale, 10.1016/s0960-9822(95)00133-3Current Biology. 51995</p>
<p>J R Anderson, Cognitive psychology and its implications. Freeman and Company19954th ed.</p>
<p>J R Anderson, Cognitive psychology and its implications. Freeman and Company20097th ed.</p>
<p>Integrating experiential and distributional data to learn semantic representations. M Andrews, G Vigliocco, D Vinson, Psychological Review. 1162009</p>
<p>Using variability to guide dimensional weighting: Associative mechanisms in early word learning. K S Apfelbaum, B Mcmurray, 10.1111/j.1551-6709.2011.01181.xCognitive Science. 352011</p>
<p>Task-dependent motor representations evoked by spatial words: Implications for embodied accounts of word meaning. C N Areshenkoff, D N Bub, M E Masson, 10.1016/j.jml.2016.06.006Journal of Memory and Language. 922017</p>
<p>N Asher, A Lascarides, Logics of conversation. Cambridge University Press2003</p>
<p>Why language matters for theory of mind. J W Astington, Baird, 10.1093/acprof:oso/9780195159912.001.0001oso/ 97801 95159 912. 001. 0001J. A.2005Oxford University Press</p>
<p>Frontal cortex and the hierarchical control of behavior. D Badre, D E Nee, 10.1016/j.tics.2017.11.005Trends in Cognitive Sciences. 222018</p>
<p>Deictic codes for the embodiment of cognition. D H Ballard, M M Hayhoe, P K Pook, R P Rao, 10.1017/S0140525X97001611Behavioral and Brain Sciences. 201997</p>
<p>The association between psychological distance and construal level: Evidence from an implicit association test. Y Bar-Anan, N Liberman, Y Trope, 10.1037/0096-3445.135.4.609Journal of Experimental Psychology: General. 1352006</p>
<p>Single units and sensation: A neuron doctrine for perceptual psychology?. H B Barlow, Perception. 11972</p>
<p>Perceptions of perceptual symbols. L W Barsalou, Behavioral and Brain Sciences. 221999</p>
<p>On staying grounded and avoiding Quixotic dead ends. L W Barsalou, 10.3758/s13423-016-1028-3Psychonomic Bulletin and Review. 232016</p>
<p>Grounding conceptual knowledge in modality-specific systems. L W Barsalou, W K Simmons, A K Barbey, C D Wilson, 10.1016/s1364-6613(02)00029-3Trends in Cognitive Sciences. 7022003</p>
<p>Learning and generalization of time production in humans: Rules of transfer across modalities and interval durations. R Bartolo, H Merchant, 10.1007/s00221-009-1895-1Experimental Brain Research. 1972009</p>
<p>Association between abstraction and time: Are future and past more abstract than the present. K M Bausenhart, R Ulrich, B Kaup, Quarterly Journal of Experimental Psychology. Bausenhart, K. M., Ulrich, R., &amp; Kaup, B.in preparation a. Implicit association between abstraction and space</p>
<p>K M Bausenhart, R Ulrich, B Kaup, Distancedependent representations: Evidence from a sentence completion paradigm. in preparation b</p>
<p>Effects of conflict trial proportion: A comparison of the Eriksen and Simon tasks. Attention, Perception, &amp; Psychophysics. K M Bausenhart, R Ulrich, J Miller, 10.3758/s13414-020-02164-2202183</p>
<p>Discovering complexity: Decomposition and localization as strategies in scientific research. W Bechtel, R C Richardson, 10.7551/mitpress/8328.001.00012010MIT Press</p>
<p>Sports experience changes the neural processing of action language. S L Beilock, I M Lyons, A Mattarella-Micke, H C Nusbaum, S L Small, 10.1073/pnas.0803424105Proceedings of the National Academy of Sciences. 1052008</p>
<p>Nature and origins of the lexicon in 6-mo-olds. E Bergelson, R Aslin, 10.1073/pnas.1712966114PNAS. 1142017</p>
<p>At 6-9 months, human infants know the meanings of many common nouns. E Bergelson, D Swingley, 10.1073/pnas.1113380109PNAS. 1092012</p>
<p>Activating concepts by activating experiential traces: Investigations with a series of anagram solution tasks. E Berndt, C Dudschig, B Kaup, 10.1080/17470218.2016.12619Quarterly Journal of Experimental Psychology. 712018</p>
<p>Green as a cbemcuru: Modal as well as amodal color cues can help to solve anagrams. E Berndt, C Dudschig, B Kaup, 10.1007/s00426-018-1055-yPsychological Research Psychologische Forschung. 842020</p>
<p>K Bhatia, M Janczyk, V H Franz, Is there Garner interference in manual estimation? Poster presented at the44th European Conference on Visual Perception. Nijmegen, Netherlands2022a</p>
<p>Grasping follows Weber's law: How to use response variability as a proxy to JND. K Bhatia, C Löwenkamp, V H Franz, 10.1167/jov.22.12.13Journal of Vision. 2022b</p>
<p>Recognition-by-components: A theory of human image understanding. I Biederman, 10.1037/0033-295x.94.2.115Psychological Review. 941987</p>
<p>The neurobiology of semantic memory. J R Binder, R H Desai, 10.1016/j.tics.2011.10.001Trends in Cognitive Sciences. 152011</p>
<p>The interplay of delay aversion, timing skills, and impulsivity in children experiencing attention-defcit/hyperactivity disorder (ADHD) symptoms. F Blume, J Kuehnhausen, T Reinelt, A Wirth, W A Rauch, C Schwenck, C Gawrilow, 10.1007/s12402-019-00298-4ADHD Attention Deficit and Hyperactivity Disorders. 112019</p>
<p>Interdisciplinary implications on autism, savantism, Asperger syndrome and the biophysical picture representation: Thinking in pictures. I Bókkon, V Salari, F Scholkmann, J Dai, F Grass, 10.1016/j.cogsys.2012.05.002Cognitive Systems Research. 222013</p>
<p>Putting words in perspective. A M Borghi, A M Glenberg, M P Kaschak, 10.3758/BF03196865Memory and Cognition. 322004</p>
<p>Metaphoric structuring: Understanding time through spatial metaphors. L Boroditsky, 10.1016/S0010-0277(99)00073-6Cognition. 752000</p>
<p>The roles of body and mind in abstract thought. L Boroditsky, M Ramscar, 10.1111/1467-9280.00434Psychological Science. 132002</p>
<p>M M Botvinick, T S Braver, D M Barch, C S Carter, J D Cohen, 10.1037/0033-295X.108.3.624Conflict monitoring and cognitive control. 2001108</p>
<p>Mood and memory. G H Bower, 10.1037/0003-066X.36.2.129American Psychologist. 361981</p>
<p>Emotion, novelty, and the startle reflex: Habituation in humans. M M Bradley, P J Lang, B N Cuthbert, 10.1037/0735-7044.107.6.970Behavioral Neuroscience. 1071993</p>
<p>What determines the specificity of conflict adaptation? A review, critical analysis, and proposed synthesis. S Braem, E L Abrahamse, W Duthoo, W Notebaert, 10.3389/fpsyg.2014.01134Frontiers in Psychology. 511342014</p>
<p>Measuring adaptive control in conflict tasks. S Braem, J M Bugg, J R Schmidt, M J C Crump, D H Weissman, W Notebaert, T Egner, 10.1016/j.tics.2019.07.002Trends in Cognitive Sciences. 232019</p>
<p>Temporal reproduction within and across senses: Testing the supramodal property of the pacemakercounter model. D Bratzke, R Ulrich, 10.1037/xhp0000667Journal of Experimental Psychlogy: Human Perception and Performance. 452019</p>
<p>The variable nature of cognitive control: A dual mechanisms framework. T S Braver, 10.1016/j.tics.2011.12.010Trends in Cognitive Sciences. 1622012</p>
<p>Interaction of cognitive and sensorimotor maps of visual space. B Bridgeman, S Peery, S Anand, 10.3758/BF03211912Perception &amp; Psychophysics. 591997</p>
<p>Representing absence of evidence: Why algorithms and representations matter in models of language and cognition. Language, Cognition and Neuroscience. F Bröker, M Ramscar, 10.1080/23273798.2020.1862257202057</p>
<p>Representational flexibility and specificity following spatial descriptions of realworld environments. T T Brunyé, D N Rapp, H A Taylor, 10.1016/j.cognition.2008.03.005Cognition. 1082008</p>
<p>On the nature of hand-action representations evoked during written sentence comprehension. D N Bub, M E Masson, 10.1016/j.cognition.2010.06.001Cognition. 1162010</p>
<p>An extension of the QWERTY effect: Not just the right hand, expertise and typeability predict valence ratings of words. Psychology of Language and Communication. E M Buchanan, K D Valentine, A Wilkowsky, 10.2478/plc-2022-0005202226</p>
<p>The parietal cortex and the representation of time, space, number and other magnitudes. D Bueti, V Walsh, 10.1098/rstb.2009.0028Philosophical Transactions of the Royal Society of London B: Biological Sciences. 2009364</p>
<p>Context, Conflict, and Control. J M Bugg, 10.1002/9781118920497.ch5Handbook of Cognitive Control. T Egner, Wiley2017</p>
<p>The next trial will be conflicting! Effects of explicit congruency precues on cognitive control. J M Bugg, A Smallwood, 10.1007/s00426-014-0638-5Psychological Research Psychologische Forschung. 802016</p>
<p>Intention and motor representation in purposive action. S Butterfill, C Sinigaglia, 10.1111/j.1933-1592.2012.00604.xPhilosophy and Phenomenological Research. 882014</p>
<p>E Camp, 10.1111/j.1933-1592.2009.00245.xPutting Thoughts to Work: Concepts, Systematicity, and Stimulus-Independence. 200978</p>
<p>Application of Fourier analysis to the visibility of gratings. F W Campbell, J G Robson, 10.1113/jphysiol.1968.sp008574The Journal of Physiology. 19731968</p>
<p>The experiential basis of compatibility effects in reading-by-rotating paradigms. F Capuano, B Claus, B Kaup, 10.1007/s00426-022-01663-1Psychological Research. 872023</p>
<p>Embodiment of abstract concepts: Good and bad in right-and left-handers. D Casasanto, 10.1037/a0015854Journal of Experimental Psychology: General. 1383512009</p>
<p>Space and time in the child's mind: Evidence for a cross-dimensional asymmetry. D Casasanto, O Fotakopoulou, L Boroditsky, 10.1111/j.1551-6709.2010.01094.xCognitive Science. 342010</p>
<p>Whatever next? Predictive brains, situated agents, and the future of cognitive science. A Clark, 10.1017/S0140525X12000477Behavioral and Brain Science. 362013</p>
<p>The fate of unattended stimuli and emotional habituation: Behavioral interference and cortical changes. M Codispoti, A De Cesarei, S Biondi, V Ferrari, 2016Cognitive, Affective</p>
<p>. 10.3758/s13415-016-0453-0Behavioral Neuroscience. 16</p>
<p>Time-locked multiregional retroactivation: A systems-level proposal for the neural substrates of recall and recognition. A R Damasio, 10.1016/0010-0277(89)90005-xCognition. 33900051989</p>
<p>The role of impulsivity in the development of substance use and eating disorders. S Dawe, N J Loxton, 10.1016/j.neubiorev.2004.03.007Neuroscience &amp; Biobehavioral Reviews. 282004</p>
<p>Model-based and model-free Pavlovian reward learning: Revaluation, revision, and revelation. P Dayan, K C Berridge, 10.3758/s13415-014-0277-8Cognitive, Affective, &amp; Behavioral Neuroscience. 142014</p>
<p>Association learning of likes and dislikes: A review of 25 years of research on human evaluative conditioning. J De Houwer, S Thomas, F Baeyens, 10.1037/0033-2909.127.6.853Psychological Bulletin. 1272001</p>
<p>Size does matter: Implied object size is mentally simulated during language comprehension. Discourse Processes. B B De Koning, S I Wassenburg, L T Bos, M Van Der Schoot, 10.1080/0163853X.2015.11196042017. 11196544</p>
<p>Emotional valence and physical space: Limits of interaction. I De La Vega, M De Filippis, M Lachmair, C Dudschig, B Kaup, 10.1037/a0024979Journal of Experimental Psychology: Human Perception and Performance. 382012</p>
<p>The interface language and theory of mind. De, J Villiers, 10.1016/j.lingua.2006.11.006Lingua. 1172007</p>
<p>The mental representation of parity and number magnitude. S Dehaene, S Bossini, P Giraux, 10.1037/0096-3445.122.3.371Journal of Experimental Psychology: General. 1221993</p>
<p>Abstract representations of numbers in the animal and human brain. S Dehaene, G Dehaene-Lambertz, L Cohen, 10.1037/0096-3445.122.3.371Trends in Neurosciences. 211998</p>
<p>The narrow fellow in the grass: Human infants associate snakes and fear. J S Deloache, V Lobue, 10.1111/j.1467-7687.2008.00753.xDevelopmental Science. 122009</p>
<p>Real Patterns. D C Dennett, 10.2307/2027085The Journal of Philosophy. 881851991</p>
<p>Executive functions. Annual Review of Psychology. A Diamond, 10.1146/annurev-psych-113011-143750201364</p>
<p>Anticipation of delayed actioneffect: Learning when an effect occurs, without knowing what this effect will be. D Dignath, M Janczyk, 10.1007/s00426-016-0797-7Psychological Research. 812017</p>
<p>Reconciling cognitive-control and episodic-retrieval accounts of sequential conflict modulation: Binding of control-states into event-files. D Dignath, L Johannsen, B Hommel, A Kiesel, 10.1037/xhp0000673Journal of Experimental Psychology. 452019Human Perception and Performance</p>
<p>Representing the hyphen in bi-directional action-effect associations: Automatic integration of time intervals into cognitive action structures. D Dignath, R Pfister, A B Eder, A Kiesel, W Kunde, 10.1037/xlm0000022Journal of Experimental Psychology: Learning. 402014Memory, and Cognition.</p>
<p>Motivation drives conflict adaptation. Motivation. D Dignath, R Wirth, J Kühnhausen, C Gawrilow, W Kunde, A Kiesel, 10.1037/mot0000136Science. 62020</p>
<p>Beyond perceptual symbols: A call for representational pluralism. G Dove, 10.1016/j.cognition.2008.11.016Cognition. 1102009</p>
<p>On the need for embodied and dis-embodied cognition. G Dove, 10.3389/fpsyg.2010.00242Frontiers in Psychology. 12011</p>
<p>Thinking in words: Language as an embodied medium of thought. G Dove, 10.1111/tops.12102Topics in Cognitive Science. 62014</p>
<p>Abstract concepts and the embodied mind: Rethinking grounded cognition. G Dove, 10.1093/oso/9780190061975.001.00011093/ oso/ 97801 90061 975. 001. 00012022Oxford University Press</p>
<p>Knowledge and the flow of information. F Dretske, 10.1086/2890621981MIT Press</p>
<p>Are control processes domain-general? A replication of 'To adapt or not to adapt? The question of domaingeneral cognitive control. C Dudschig, Kan, 10.1098/rsos.210550Royal Society Open Science. 92105502022b. 2013</p>
<p>Language and non-linguistic cognition: Shared mechanisms and principles reflected in the N400. C Dudschig, 10.1016/j.biopsycho.2022.108282Biological Psychology. 1691082822022a</p>
<p>What's up? Emotionspecific activation of vertical space during language processing. C Dudschig, I De La Vega, B Kaup, 10.1016/j.actpsy.2014.09.015Acta Psychologica. 1562015</p>
<p>Is it all task-specific? The role of binary responses, verbal mediation, and saliency for eliciting language-space associations. C Dudschig, B Kaup, 10.1037/xlm0000297Journal of Experimental Psychology: Learning, Memory, and Cognition. 201743259</p>
<p>How does "not left" become "right"? Electrophysiological evidence for a dynamic conflict-bound negation processing account. C Dudschig, B Kaup, 10.1037/xhp0000481Journal of Experimental Psychology: Human Perception and Performance. 4457162018</p>
<p>Negation as conflict: Conflict adaptation following negating vertical spatial words. Brain and Language. C Dudschig, B Kaup, 10.1016/j.bandl.2020.1048422020210104842</p>
<p>The social psychology of perception experiments: Hills, backpacks, glucose, and the problem of generalizability. F H Durgin, B Klein, A Spiegel, C J Strawser, M Williams, 10.1037/a0027805201238805Journal of Experimental Psychology. Human Perception and Performance</p>
<p>Is there hierarchical generalization in response-effect learning? Experimental Brain Research. L A Eichfelder, V H Franz, M Janczyk, 10.1007/s00221-022-06473-w2023241</p>
<p>Humans integrate duration information across sensory modalities: Evidence for an amodal internal reference of time. R Ellinghaus, S Giel, R Ulrich, K M Bausenhart, 10.1037/xlm0001002Journal of Experimental Psychology: Learning, Memory, and Cognition. 472021</p>
<p>A century later: Woodworth's (1899) two-component model of goal-directed aiming. D Elliott, W F Helsen, R Chua, 10.1037/0033-2909.127.3.342Psychological Bulletin. 1272001</p>
<p>Garner-Interference in left-handed awkward grasping. O Eloka, F Feuerhake, M Janczyk, V H Franz, 10.1007/s00426-014-0585-1Psychological Research Psychologische Forschung. 792015</p>
<p>Perceptual simulation in developing language comprehension. J A A Engelen, S Bouwmeester, A B H De Bruin, R A Zwaan, 10.1016/j.jecp.2011.06.009Journal of Experimental Child Psychology. 1102011</p>
<p>Humans integrate visual and haptic information in a statistically optimal fashion. M O Ernst, M S Banks, 10.1038/415429aNature. 41592002</p>
<p>Action-effect knowledge transfers to similar effect stimuli. S Esser, H Haider, C Lustig, T Tanaka, K Tanaka, 10.1007/s00426-023-01800-4Psychological Research Psychologische Forschung. 2023</p>
<p>Human reasoning: The psychology of deduction. J S B Evans, S E Newstead, R M Byrne, 10.4324/97813157850281993Psychology Press28</p>
<p>On the automatic activation of attitudes. R H Fazio, D M Sanbonmatsu, M C Powell, F R Kardes, 10.1037/0022-3514.50.2.229Journal of Personality and Social Psychology. 501986</p>
<p>New developments in human neurocognition: Clinical, genetic, and brain imaging correlates of impulsivity and compulsivity. N Fineberg, S Chamberlain, A Goudriaan, D Stein, L Vanderschuren, C Gillan, 10.1017/S1092852913000801CNS Spectrums. 1912014</p>
<p>Cognition does not affect perception: Evaluating the evidence for "top-down" effects. Behavioral and Brain Sciences. C Firestone, B J Scholl, 10.1017/S0140525X15000965201639</p>
<p>Two steps to space for numbers. M H Fischer, S Shaki, 10.3389/fpsyg.2015.00612Frontiers in Psychology. 62015</p>
<p>The role of internal models in motion planning and control: Evidence from grip force adjustments during movements of hand-held loads. J R Flanagan, A M Wing, 10.1523/JNEUROSCI.17-04-01519.1997The Journal of Neuroscience. 171997. 1997</p>
<p>The language of thought. J A Fodor, 10.1177/0265691475005002091975Harvard University Press</p>
<p>Fodor's guide to mental representation: The intelligent auntie's vade-mecum. Mind. J A Fodor, 10.1093/mind/xciv.373.76198594</p>
<p>LOT 2: The language of thought revisited. J A Fodor, 10.1093/acprof:oso/9780199548774.001.0001oso/ 97801 99548 774. 001. 00012008Oxford University Press</p>
<p>Connectionism and cognitive architecture: A critical analysis. J A Fodor, Z W Pylyshyn, 10.1016/0010-0277(88)90031-5Cognition. 281988</p>
<p>Exploring the representational basis of response-effect compatibility: Evidence from bilingual verbal response-effect mappings. N Földes, A M Philipp, A Badets, I Koch, 10.1016/j.actpsy.2018.03.006Acta Psychologica. 1862018</p>
<p>Grasping visual illusions: Consistent data and no dissociation. V H Franz, K R Gegenfurtner, 10.1080/02643290701862449Cognitive Neuropsychology. 25492008. 02643 29070 18624</p>
<p>Virtual reality in the assessment, understanding, and treatment of mental health disorders. D Freeman, S Reeve, A Robinson, A Ehlers, D Clark, B Spanlang, M Slater, 10.1017/S003329171700040XPsychological Medicine. 472017</p>
<p>Über Sinn und Bedeutung. G Frege, Zeitschrift Für Philosophie Und Philosophische Kritik. 1001892</p>
<p>Neural coding of cognitive control: The representational similarity analysis approach. M C Freund, J A Etzel, T S Braver, 10.1016/j.tics.2021.03.011Trends in Cognitive Sciences. 252021</p>
<p>Binding and retrieval in action control (BRAC). C Frings, B Hommel, I Koch, K Rothermund, D Dignath, C Giesen, 10.1016/j.tics.2020.02.004Trends in Cognitive Sciences. 242020</p>
<p>The free-energy principle: A unified brain theory?. K J Friston, 10.1038/nrn2787Nature Reviews Neuroscience. 112010</p>
<p>Symbolic and non-symbolic numerical representation in adults with and without developmental dyscalculia. T Furman, O Rubinsten, 10.1186/1744-9081-8-55Behavioral and Brain Functions. 82012</p>
<p>The prefrontal cortex -an update: Time is the essence. J M Fuster, 10.1016/S0896-6273(01)00285-9Neuron. 30012001</p>
<p>Visual coding for action violates fundamental psychophysical principles. T Ganel, E Chajut, D Algom, 10.1016/j.cub.2008.04.052Current Biology. 182008</p>
<p>Visual control of action but not perception requires analytical processing of object shape. T Ganel, M A Goodale, 10.1038/nature02156Nature. 42669672003</p>
<p>Interaction of stimulus dimensions in concept and choice processes. W R Garner, 10.1016/0010-0285(76)90006-2Cognitive Psychology. 9761976</p>
<p>Implementation intentions facilitate response inhibition in children with ADHD. C Gawrilow, P M Gollwitzer, 10.1007/s10608-007-9150-1Cognitive Therapy and Research. 322008</p>
<p>If-then plans benefit executive functions in children with ADHD. C Gawrilow, P M Gollwitzer, G Oettingen, 10.1521/jscp.2011.30.6.616Journal of Social and Clinical Psychology. 302011</p>
<p>Metaphoric extension, relational categories, and abstraction. Language, Cognition and Neuroscience. D Gentner, J Asmuth, 10.1080/23273798.2017.1410560201934</p>
<p>As time goes by: Evidence for two systems in processing space→ time metaphors. D Gentner, M Imai, L Boroditsky, 10.1080/01690960143000317Language and Cognitive Processes. 175172002</p>
<p>Surface information loss in comprehension. M A Gernsbacher, 10.1016/0010-0285(85)90012-xCognitive Psychology. 173900121985</p>
<p>Above and beyond the concrete: The diverse representational substrates of the predictive brain. M Gilead, Y Trope, N Liberman, 10.1017/S0140525X19002000Behavioral and Brain Sciences. 43e1212020</p>
<p>Action-based language: A theory of language acquisition, comprehension, and production. A M Glenberg, V Gallese, 10.1016/j.cortex.2011.04.010Cortex. 482012</p>
<p>Grounding language in action. A M Glenberg, M Kaschak, 10.3758/BF03196313Psychonomic Bulletin and Review. 92002</p>
<p>Separate visual representations in the planning and control of action. S Glover, 10.1017/S0140525X04000020Behavioral and Brain Sciences. 272004</p>
<p>Constructions: A new theoretical approach to language. A E Goldberg, 10.1016/S1364-6613(03)00080-9Trends in Cognitive Sciences. 7032003</p>
<p>Explain me this: Creativity, competition, and the partial productivity of constructions. A E Goldberg, 10.1515/97806911839542019Princeton University Press</p>
<p>Implementation intentions: Strong effects of simple plans. P M Gollwitzer, 10.1037/0003-066X.54.7.493American Psychologist. 541999</p>
<p>Transforming abstract plans into concrete actions. M A Goodale, 10.1073/pnas.2020708117Proceedings of the National Academy of Sciences. 117472020</p>
<p>Two visual pathways-Where have they taken us and where will they lead in future?. M A Goodale, A D Milner, 10.1016/j.cortex.2017.12.002Cortex. 982018</p>
<p>Optimizing the use of information: Strategic control of activation of responses. G Gratton, M G Coles, E Donchin, 10.1037/0096-3445.121.4.480Journal of Experimental Psychology: General. 1211992</p>
<p>Measuring individual differences in implicit cognition: The Implicit Association Test. A G Greenwald, D E Mcghee, J L K Schwartz, 10.1037/0022-3514.74.6.1464Journal of Personality and Social Psychology. 741998</p>
<p>Immediate sensorimotor grounding of novel concepts learned from language alone. F Günther, T Nguyen, L Chen, C Dudschig, B Kaup, A M Glenberg, 10.1016/j.jml.2020.104172Journal of Memory and Language. 1152020. 104172</p>
<p>The limits of automatic sensorimotor processing during word processing: Investigations with repeated linguistic experience, memory consolidation during sleep, and rich linguistic learning contexts. F Günther, S A Press, C Dudschig, B Kaup, 10.1007/s00426-021-01620-4Psychological Research Psychologische Forschung. 862022</p>
<p>Temporal dynamics of the semantic versus affective representations of valence during reversal learning. O Heimer, A Kron, U Hertz, 10.1016/j.cognition.2023.105423Cognition. 2361054232023</p>
<p>Internal references in cross-modal judgments: A global psychophysical perspective. J Heller, 10.1037/rev0000280Psychological Review. 1282021</p>
<p>An introduction to the history of psychology. B R Hergenhan, 20096th edn. Wadsworth, Cengage Learning</p>
<p>Restrained and unrestrained eating. C P Herman, D Mack, 10.1111/j.1467-6494.1975.tb00727.xJournal of Personality. 4341975</p>
<p>Conceptual flexibility in the human brain: Dynamic recruitment of semantic maps from visual, motor, and motionrelated areas. K Hoenig, E J Sim, V Bochev, B Herrnberger, M Kiefer, 10.1162/jocn.2008.20123Journal of Cognitive Neuroscience. 202008</p>
<p>Evaluative conditioning in humans: A meta-analysis. W Hofmann, J De Houwer, M Perugini, F Baeyens, G Crombez, 10.1037/a0018916Psychological Bulletin. 1362010</p>
<p>Expertise and its embodiment: Examining the impact of sensorimotor skill expertise on the representation of action-related text. L E Holt, S L Beilock, 10.3758/bf03193983Psychonomic Bulletin &amp; Review. 132006</p>
<p>Acquisition and generalization of action effects. B Hommel, D Alonso, L Fuentes, 10.1080/13506280344000176Visual Cognition. 102003</p>
<p>The Theory of Event Coding (TEC): A framework for perception and action planning. B Hommel, J Müsseler, G Aschersleben, W Prinz, 10.1017/S0140525X01000103Behavioral and Brain Sciences. 242001</p>
<p>A feature-integration account of sequential effects in the Simon task. B Hommel, R W Proctor, K P L Vu, 10.1007/s00426-003-0132-yPsychological Research Psychologische Forschung. 200468</p>
<p>Order matters! Influences of linear order on linguistic category learning. D B Hoppe, J Van Rij, P Hendriks, M Ramscar, 10.1111/cogs.12910Cognitive Science. 44e129102020</p>
<p>Direct impact of cognitive control on sentence processing and comprehension. Language, Cognition and Neuroscience. N S Hsu, S E Kuchinsky, J M Novick, 10.1080/23273798.2020.183637920213679</p>
<p>Changes in situation models modulate processes of event perception in audiovisual narratives. M Huff, T G K Meitz, F Papenmeier, 10.1037/a0036780Journal of Experimental Psychology: Learning. 402014Memory, and Cognition</p>
<p>Fandom biases retrospective judgments not perception. M Huff, F Papenmeier, A E Maurer, T G K Meitz, B Garsoffky, S Schwan, 10.1038/srep43083Scientific Reports. 7430832017</p>
<p>Visual target detection is impaired at event boundaries. M Huff, F Papenmeier, J M Zacks, 10.1080/13506285.2012.705359Visual Cognition. 202012</p>
<p>The power of predictions: An emerging paradigm for psychological research. J B Hutchinson, L F Barrett, 10.1177/0963721419831992Current Directions in Psychological Science. 282019</p>
<p>An integrative review of dual and single-process accounts of evaluative conditioning. M Hütter, 10.1038/s44159-022-00102-7Nature Reviews Psychology. 12022</p>
<p>What is learned from repeated pairings? On the scope and generalizability of evaluative conditioning. M Hütter, F Kutzner, K Fiedler, 10.1037/a0033409Journal of Experimental Psychology: General. 1432014</p>
<p>Research domain criteria (RDoC): Toward a new classification framework for research on mental disorders. T Insel, B Cuthbert, M Garvey, R Heinssen, D S Pine, K Quinn, 10.1176/appi.ajp.2010.09091379American Journal of Psychiatry. 1673792010</p>
<p>Dissociating affective and semantic valence. O Itkes, R Kimchi, H Haj-Ali, A Shapiro, A Kron, 10.1037/xge0000291Journal of Experimental Psychology: General. 14672017</p>
<p>Affective and semantic representations of valence: A conceptual framework. O Itkes, A Kron, 10.1177/1754073919868759Emotion Review. 1142019</p>
<p>Grasping for parsimony: Do some motor actions escape dorsal processing? Neuropsychologia. W James, &amp; Henry Holt, Co, M Janczyk, V H Franz, W Kunde, 10.1016/j.neuropsychologia.2010.06.034The principles of psychology. 1890. 20101</p>
<p>Perception and action as viewed from the Theory of Event Coding: A multi-lab replication and effect size estimation of common experimental designs. M Janczyk, C G Giesen, B Moeller, D Dignath, R Pfister, 10.1007/s00426-022-01705-8Psychological Research Psychologische Forschung. 872023a</p>
<p>Is there a cognitive link between the domains of deictic time and number. M Janczyk, I Koch, R Ulrich, 10.1037/xlm0001162Journal of Experimental Psychology: Learning, Memory, and Cognition. 492023b</p>
<p>Generalization of unpredictable action effect features: Large individual differences with little on-average effect. M Janczyk, J Miller, 10.1177/17470218231184996The Quarterly Journal of Experimental Psychology. 962023. 17470 21823 11849</p>
<p>The formation of finger grip during prehension: A cortically mediated visuomotor pattern. M Jeannerod, 10.1016/0166-4328(86)90008-2Behavioral Brain Research. 19861986</p>
<p>The representing brain: Neural correlates of motor intention and imagery. M Jeannerod, 10.1017/S0140525X00034026Behavioral and Brain Sciences. 1721994</p>
<p>Habituation to emotional distractors attenuates emotion-induced blindness. L Jia, L Wang, B Sung, C Wang, D Chen, J Wang, 10.1037/emo0000917Emotion. 222022</p>
<p>It is harder than you think: On the boundary conditions of exploiting congruency cues. L Jiménez, C Méndez, E Abrahamse, S Braem, 10.1037/xlm0000844Journal of Experimental Psychology: Learning. 472021Memory, and Cognition</p>
<p>Mental models: Towards a cognitive science of language, inference, and consciousness. P N Johnson-Laird, 1983Harvard University Press</p>
<p>To adapt or not to adapt: The question of domain-general control. I P Kan, S Teubner-Rhodes, A B Drummey, L Nutile, L Krupa, J M Novick, 10.1016/j.cognition.2013.09.001Cognition. 1292013</p>
<p>Word knowledge in six-to ninemonth-old Norwegian infants? Not without additional frequency cues. N Kartushina, J Mayor, 10.1098/rsos.180711Royal Society Open Science. 2019</p>
<p>Analog and digital representation. Minds &amp; Machines. M Katz, 10.1007/s11023-008-9112-8200818</p>
<p>The role of sensorimotor processes in meaning composition. B Kaup, I De La Vega, J Strozyk, C Dudschig, 10.4324/9781315751962Conceptual and interactive embodiment. M Fischer, Y Coello, 2015962</p>
<p>Understanding negation: Issues in the processing of negation. B Kaup, C Dudschig, 10.1093/oxfordhb/9780198830528.013.33The oxford handbook of negation. V Deprez, T Espinal, Oxford University Press2020</p>
<p>Associations between abstract concepts: Investigating the relationship between deictic time and valence. B Kaup, N Scherer, R Ulrich, 10.3389/fpsyg.2021.612720Frontiers in Psychology. 126127202021</p>
<p>Die Beziehung zwischen sprachlicher und nicht-sprachlicher Kognition: Die Bedeutung von Repräsentationsformaten. B Kaup, R Ulrich, 10.1026/0033-3042/a000354Psychologische Rundschau. 682017</p>
<p>Movement control in skilled motor performance. S W Keele, 10.1037/h0026739Psychological Bulletin. 701968</p>
<p>Conceptual knowledge, categorization, and meaning. S Kelter, B Kaup, 10.1515/9783110589825-011Semantics. An international handbook of natural language meaning. C Maienborn, K Heusinger, &amp; P Portner, de Gruyter20123</p>
<p>Representation in the prediction error minimization framework. A Kiefer, J Hohwy, 10.4324/9780429244629-24Routledge companion to philosophy of psychology. S Robins, J Symons, &amp; P Calvo, 201997804</p>
<p>Conceptual representations in mind and brain: Theoretical developments, current evidence and future directions. M Kiefer, F Pulvermüller, 10.1016/j.cortex.2011.04.006Cortex. 482012</p>
<p>The role of knowledge in discourse comprehension: A construction-integration model. W Kintsch, 10.1037/0033-295X.95.2.163Psychological Review. 951988</p>
<p>Comprehension: A paradigm for cognition. W Kintsch, 1998Cambridge University Press</p>
<p>Toward a model of text comprehension and production. W Kintsch, T A Van Dijk, 10.1037/0033-295X.85.5.363Psychological Review. 851978</p>
<p>Affective priming: Findings and theories. K C Klauer, J Musch, 10.4324/9781410606853-7The psychology of evaluation: Affective processes in cognition and emotion. J Musch, K C Klauer, Lawrence Erlbaum Associates Publishers2003</p>
<p>Exploring the role of verbal-semantic overlap in response-effect compatibility. I Koch, N Földes, W Kunde, A M Philipp, 10.1016/j.actpsy.2021.103275Acta Psychologica. 2151032752021</p>
<p>Verbal response-effect compatibility. I Koch, W Kunde, 10.3758/bf03213411Memory &amp; Cognition. 302002</p>
<p>Mental number representations are spatially mapped both by their magnitudes and ordinal positions. N Koch, J Huber, J Lohmann, K Cipora, M V Butz, H.-C Nuerk, 10.1525/collabra.67908Collabra: Psychology. 91679082021</p>
<p>Embodied magnitude processing: On the relation between the SNARC effect and perceived reachability. N Koch, J Lohmann, M V Butz, H.-C Nuerk, Journal of Numerical Cognition. 2022preregistered report</p>
<p>The architecture of cognitive control in the human prefrontal cortex. E Koechlin, C Ody, F Kouneiher, 10.1126/science.1088545Science. 30256482003</p>
<p>The role of task-relevant and task-irrelevant information in congruency sequence effects: Applying the diffusion model for conflict tasks. V Koob, I G Mackenzie, R Ulrich, H Leuthold, M Janczyk, 10.1016/j.cogpsych.2022.101528Cognitive Psychology. 1401015282022</p>
<p>V Koob, I G Mackenzie, R Ulrich, H Leuthold, M Janczyk, The role of task-relevant and task-irrelevant information in congruency sequence effects: Applying the Diffusion Model for Conflict tasks. 2023101528</p>
<p>The functional subdivision of the visual brain: Is there a real illusion effect on action? A multi-lab replication study. Cortex. K K Kopiske, N Bruno, C Hesse, T Schenk, V H Franz, 10.1016/j.cortex.2016.03.020201679</p>
<p>Spending one's time: The hedonic principle in ad libitum viewing of pictures. S M Kosslyn, A Kron, M Pilkiw, A Goldstein, D H Lee, K Gardhouse, A K Anderson, 10.1037/a0037696Emotion. 1461980. 2014Harvard University PressImage and mind</p>
<p>Meta-analytic evidence for a novel hierarchical model of conceptual processing. P Kuhnke, M C Beaupain, J Arola, M Kiefer, G Hartwigsen, 10.1101/2022.11.05.515278bioRxiv. 2022</p>
<p>Thinking in pictures as a cognitive account of autism. M Kunda, A K Goel, 10.1007/s10803-010-1137-1Journal of Autism and Developmental Disorders. 412011</p>
<p>Temporal response-effect compatibility. Psychological Research Psychologische Forschung. W Kunde, 10.1007/s00426-002-0114-5200367</p>
<p>Antezedente Effektrepräsentationen in der Verhaltenssteuerung. W Kunde, 10.1026/0033-3042.57.1.34Psychologische Rundschau. 572006</p>
<p>G Lakoff, M Johnson, Metaphors we live by. University of Chicago press1980</p>
<p>Where mathematics comes from: How the embodied mind brings mathematics into being. G Lakoff, R E Núñez, 2000Basic books</p>
<p>To see or not to see: that is the question." the "protection-against-schizophrenia" (PaSZ) model: Evidence from congenital blindness and visuocognitive aberrations. M O S Landgraf, M Osterheider, 10.3389/fpsyg.2013.00352Frontiers in Psychology. 42013</p>
<p>Cognitive grammar: A basic introduction. R W Langacker, 2008Oxford Univ</p>
<p>Inhibitory control in obesity and binge eating disorder: A systematic review and meta-analysis of neurocognitive and neuroimaging studies. L Lavagnino, D Arnone, B Cao, J C Soares, S Selvaraj, 10.1016/j.neubiorev.2016.06.041Neuroscience and Biobehavioral Reviews. 682016</p>
<p>Knowledge and appraisal in the cognition-emotion relationship. R S Lazarus, C A Smith, 10.1080/02699938808412701Cognition &amp; Emotion. 2411988</p>
<p>Are automatic conceptual cores the gold standard of semantic processing? The context-dependence of spatial meaning in grounded congruency effects. L A Lebois, C D Wilson-Mendenhall, L W Barsalou, 10.1111/cogs.12174Cognitive Science. 392015</p>
<p>For a cognitive neuroscience of concepts: Moving beyond the grounding issue. A Leshinskaya, A Caramazza, 10.3758/s13423-015-0870-zPsychonomic Bulletin and Review. 232016</p>
<p>Preparing for action: Inferences from CNV and LRP. H Leuthold, W Sommer, R Ulrich, 10.1027/0269-8803.18.23.77Journal of Psychophysiology. 182/32004</p>
<p>Speaking: From intention to articulation. W J M Levelt, 1989Bradford</p>
<p>The relationship of emotion to cognition: A functional approach to a semantic controversy. H Leventhal, K Scherer, 10.1080/02699938708408361Cognition and Emotion. 1611987</p>
<p>The influence of position on spatial representation in working memory. L Levinh, A Meert, H A Mallot, 10.1007/978-3-030-57983-8_4Lecture Notes in Artificial Intelligence. 121622020</p>
<p>Evidence for an effector-independent action system from people born without hands. Y Liu, G Vannuscorps, A Caramazza, E Striem-Amit, 10.1073/pnas.2017789117Proceedings of the National Academy of Sciences. 117452020</p>
<p>On the ability to inhibit thought and action: A users' guide to the stop signal paradigm. G D Logan, 10.1037/a0035230D. Dagenbach &amp; T. H. Carr1994Academic PressInhibitory processes in attention, memory, and language</p>
<p>On the ability to inhibit thought and action: A theory of an act of control. G D Logan, W B Cowan, 10.1037/0033-295X.91.3.295Psychological Review. 911984</p>
<p>How deep Is your SNARC? Interactions between numerical magnitude, response hands, and reachability in peripersonal space. J Lohmann, P A Schroeder, H.-C Nuerk, C Plewnia, M V Butz, 10.3389/fpsyg.2018.00622Frontiers in Psychology. 92018</p>
<p>The linguistic and embodied nature of conceptual processing. M M Louwerse, P Jeuniaux, 10.1016/j.cognition.2009.09.002Cognition. 1142010</p>
<p>SUSTAIN: A network model of category learning. B C Love, D L Medin, T M Gureckis, 10.1037/0033-295X.111.2.309Psychological Review. 1113092004</p>
<p>Discrimination. R D Luce, E Galanter, Handbook of mathematical psychology. R D Luce, R R Bush, &amp; E Galanter, John Wiley1963I</p>
<p>Language is not just for talking: Redundant labels facilitate learning of novel categories. G Lupyan, D H Rakison, J L Mcclelland, 10.1111/j.1467-9280.2007.02028.xPsychological Science. 182007</p>
<p>Concept empiricism: A methodological critique. E Machery, 10.1016/j.cognition.2006.05.002Cognition. 1042007</p>
<p>Précis of doing without concepts. E Machery, 10.1017/S0140525X09991531Behavioral Brain Sciences. 332010</p>
<p>The amodal brain and the offloading hypothesis. E Machery, 10.3758/s13423-015-0878-4Psychonomic Bulletin and Review. 232016</p>
<p>DMCfun: An R package for fitting diffusion model of conflict DMC) to reaction time and error rate data. I G Mackenzie, C Dudschig, 10.1016/j.metip.2021.100074Methods in Psychology. 51000742021</p>
<p>Visual working memory. S Magnussen, Encyclopedia of the mind. H Pashler, Sage20132</p>
<p>What is embodied about cognition? Language, Cognition and Neuroscience. B Z Mahon, 10.1080/23273798.2014.987791201530</p>
<p>A critical look at the embodied cognition hypothesis and a new proposal foregrounding conceptual content. B Z Mahon, A Caramazza, 10.1016/j.jphysparis.2008.03.004Journal of Physiology. 1022008</p>
<p>The foundations of mind: Origins of conceptual thought. J M Mandler, 2004Oxford University Press</p>
<p>The measure of mind: Propositional attitudes and their attribution. R J Matthews, 2007Clarendon Press</p>
<p>An interactive activation model of context effects in letter perception: I. An account of basic findings. J L Mcclelland, D E Rumelhart, 10.1037/0033-295X.88.5.375Psychological Review. 881981</p>
<p>Inference during reading. G Mckoon, R Ratcliff, 10.1037/0033-295x.99.3.440Psychological Review. 991992</p>
<p>Memory-based language processing: Psycholinguistic research in the 1990s. G Mckoon, R Ratcliff, 10.1146/annurev.psych.49.1.25Annual Review of Psychology. 491998</p>
<p>A hot/cool-system analysis of delay of gratification: Dynamics of willpower. J Metcalfe, W Mischel, 10.1037/0033-295X.106.1.3Psychological Review. 1061999</p>
<p>Coming of age: A review of embodiment and the neuroscience of semantics. L Meteyard, S R Cuadrado, B Bahrami, G Vigliocco, 10.1016/j.cortex.2010.11.002Cortex. 482012</p>
<p>Overcoming the modal/amodal dichotomy of concepts. C Michel, 10.1007/s11097-020-09678-yPhenomenology and the Cognitive Sciences. 202021</p>
<p>Scaling up Predictive Processing to language with Construction Grammar. C Michel, 10.1080/09515089.2022.2050198Philosophical Psychology. 363982023. 20501</p>
<p>An integrative theory of prefrontal cortex function. E K Miller, J D Cohen, 10.1146/annurev.neuro.24.1.167Annual Review of Neuroscience. 242001</p>
<p>Influences of task and attention on action verb congruence effects: How automatic are embodiment effects?. J Miller, B Kaup, 10.1016/j.actpsy.2020.103155Acta Psychologica. 2102020</p>
<p>Simple reaction time and statistical facilitation: A parallel grains model. J Miller, R Ulrich, 10.1016/s0010-0285(02)00517-0Cognitive Psychology. 46022003</p>
<p>Assessment of the Rescorla-Wagner model. R R Miller, R C Barnet, N J Grahame, 10.1037/0033-2909.117.3.363Psychological Bulletin. 1173631995</p>
<p>Language and theory of mind: Meta-analysis of the relation between language ability and false-belief understanding. K Milligan, J W Astington, L A Dack, 10.1111/j.1467-8624.2007.01018.xChild Development. 782007</p>
<p>The visual brain in action. A D Milner, M A Goodale, 1995Oxford University Press</p>
<p>No evidence for embodiment: The motor system is not needed to keep action words in working memory. M Minsky, Simon, Schuster, G Montero-Melis, J Van Paridon, M Ostarek, E Bylund, 10.1016/j.cortex.2022.02.006Cortex. 1501988. 2022Society of mind</p>
<p>The big book of concepts. G L Murphy, 10.7551/mitpress/1602.001.00012002MIT press</p>
<p>Is there an exemplar theory of concepts?. G L Murphy, Psychonomic Bulletin and Review. 232016</p>
<p>Cognitive psychology. U Neisser, 1967Meredith Publishing Company</p>
<p>Concepts and their organizational structure: Concepts are templates based on mental files. A Newen, F Marchi, 10.30965/9783969750025_011Concepts and categorization. D Hommen, C Kann, T Osswald, 2016Mentis: Münster</p>
<p>The perceptual organization of ongoing behavior. D Newtson, G Engquist, 10.1016/0022-1031(76)90076-7Journal of Experimental Social Psychology. 1251976</p>
<p>Global, regional, and national prevalence of overweight and obesity in children and adults during 1980-2013: a systematic analysis for the Global Burden of Disease Study. M Ng, T Fleming, M Robinson, B Thomson, N Graetz, C Margono, 10.1016/S0140-6736(14)60460-8The Lancet. 384142014. 2013</p>
<p>Embodiment in attitudes, social perception, and emotion. P M Niedenthal, L W Barsalou, P Winkielman, S Krauth-Gruber, F Ric, 10.1207/s15327957pspr0903_1Personality and Social Psychology Review. 92005</p>
<p>The psychology of evaluation: Affective processes in cognition and emotion. P M Niedenthal, A Rohmann, N Dalle, 10.4324/9781410606853-20J. Musch &amp; K. C. Klauer2003Lawrence Erlbaum Associates PublishersWhat is primed by emotion concepts and emotion words</p>
<p>Of mice and men: Speech sound acquisition as discriminative learning from prediction error, not just statistical tracking. J S Nixon, 10.1016/j.cognition.2019.104081Cognition. 1971040812020</p>
<p>Orienting and attention: Preferred preattentive processing of potentially phobic stimuli. Attention and information processing in infants and adults. A Öhman, Perspectives from human and animal research. Lawrence Erlbaum Associates, Inc1992</p>
<p>Emergence of simple-cell receptive field properties by learning a sparse code for natural images. B A Olshausen, D J Field, 10.1038/381607a0Nature. 38165831996</p>
<p>A test of motor skill-specific action embodiment in ice-hockey players. N T Ong, K R Lohse, R Chua, S Sinnett, N J Hodges, 10.1016/j.actpsy.2014.04.005Acta Psychologica. 1502014</p>
<p>A task-dependent causal role for low-level visual processes in spoken word comprehension. M Ostarek, F Huettig, 10.1037/xlm0000375Journal of Experimental Psychology: Learning, Memory, and Cognition. 432017</p>
<p>Six challenges for embodiment research. M Ostarek, F Huettig, 10.1177/0963721419866441Current Directions in Psychological Science. 288664412019</p>
<p>Forming associations between language and sensorimotor traces during novel word learning. B Öttl, C Dudschig, B Kaup, 10.1017/langcog.2016.5Language and Cognition. 92017</p>
<p>Vision science: Photons to phenomenology. S E Palmer, 1999MIT press</p>
<p>Procedural learning: 1. Locus of practice effects in speeded choice tasks. H Pashler, G Baylis, 10.1037/0278-7393.17.1.20Journal of Experimental Psychology: Learning, Memory and Cognition. 171991a</p>
<p>Procedural learning: 2. Intertrial repetition effects in speeded choice tasks. H Pashler, G Baylis, 10.1037/0278-7393.17.1.33Journal of Experimental Psychology: Learning, Memory and Cognition. 171991b</p>
<p>How to rapidly construct a spatial-numerical representation in preliterate children (at least temporarily). K Patro, U Fischer, H.-C Nuerk, U Cress, 10.1111/desc.12296Developmental Science. 192016a</p>
<p>The mental number line in the preliterate brain: The role of early directional experiences. K Patro, H.-C Nuerk, U Cress, 10.1111/cdep.12179Child Development Perspectives. 102016b</p>
<p>The perceptual representation of mental categories. D Pecher, 10.1093/oxfordhb/9780195376746.013.0024D. Reisberg2013Oxford University PressNew YorkThe Oxford Handbook of Cognitive Psychology</p>
<p>Curb your embodiment. D Pecher, 10.1111/tops.12311Topics in Cognitive Science. 102018</p>
<p>Verifying properties from different modalities for concepts produces switching costs. D Pecher, R Zeelenberg, L W Barsalou, 10.1111/1467-9280.t01-1-01429Psychological Science. 142003</p>
<p>The origins of intelligence in children. J Piaget, 10.1037/11494-0001952</p>
<p>How the mind works. S Pinker, 10.1111/j.1749-6632.1999.tb08538.xAnnals of the New York Academy of Science. 1999882</p>
<p>The stanford encyclopedia of philosophy. D Pitt, E. N. Zalta2013Mental representation</p>
<p>How flexible is cognitive control? (Mouse) tracking conflict adaptation across context similarities. H Potamianou, D Bryce, 10.1007/s00426-023-01874-02023Psychological Research</p>
<p>A common coding approach to perception and action. W Prinz, 10.1007/978-3-642-75348-0_7Relationships between perception and action. O Neumann, W Prinz, Berlin, HeidelbergSpringer1990</p>
<p>Perception and action planning. W Prinz, 10.1080/713752551European Journal of Cognitive Psychology. 925511997</p>
<p>Embodied perception and the economy of action. D R Proffitt, 10.1111/j.1745-6916.2006.00008.xPerspectives on Psychological Science. 12006</p>
<p>How neurons make meaning: Brain mechanisms for embodied and abstract-symbolic semantics. F Pulvermüller, 10.1016/j.tics.2013.06.004Trends in Cognitive Sciences. 172013</p>
<p>Functional links between motor and language systems. F Pulvermüller, O Hauk, V V Nikulin, R J Ilmoniemi, 10.1111/j.1460-9568.2005.03900.xEuropean Journal of Neuroscience. 212005</p>
<p>The imagery debate: Analogue media versus tacit knowledge. Z W Pylyshyn, 10.1037/0033-295X.88.1.16Psychological Review. 881981</p>
<p>The best game in town: the re-emergence of the language of thought hypothesis across the cognitive sciences. Z W Pylyshyn, J Quilty-Dunn, N Porot, E Mandelbaum, 10.1017/S0140525X22002849Behavioral and Brain Sciences. 491984. 2022. 20028MIT PressComputation and Cognition</p>
<p>Suffixing, prefixing, and the functional order of regularities in meaningful strings. M Ramscar, 10.1016/0024-3841(88)90060-5Psihologija. 4642013</p>
<p>A discriminative account of the learning, representation and processing of inflection systems. M Ramscar, 10.1080/23273798.2021.2014062Language, Cognition and Neuroscience. 2021. 2014062</p>
<p>Children value informativity over logic in word learning. M Ramscar, M Dye, J Klein, 10.1177/0956797612460691Psychological Science. 244606912013a</p>
<p>Error and expectation in language learning: The curious absence of "mouses" in adult speech. M Ramscar, M Dye, S M Mccauley, 10.1353/lan.2013.00682013b</p>
<p>The effects of feature-label-order and their implications for symbolic learning. M Ramscar, D Yarlett, M Dye, K Denny, K Thorpe, 10.1111/j.1551-6709.2009.01092.xCognitive Science. 342010</p>
<p>Predictive coding in the visual cortex: A functional interpretation of some extra-classical receptive-field effects. R P N Rao, D H Ballard, 10.1038/4580Nature Neuroscience. 21999</p>
<p>How variability shapes learning and generalization. L Raviv, G Lupyan, S C Green, 10.1016/j.tics.2022.03.007Trends in Cognitive Sciences. 2662022</p>
<p>A taxonomic analysis of abstraction. S K Reed, 10.1177/1745691616646304Perspectives on Psychological Science. 112016</p>
<p>Variability and abstraction in evaluative conditioning: Consequences for the generalization of likes and dislikes. K Reichmann, M Hütter, B Kaup, M Ramscar, 10.1016/j.jesp.2023.104478Journal of Experimental Social Psychology. 1082022. 104478</p>
<p>Pavlovian conditioning: It's not what you think it is. R A Rescorla, 10.1037/0003-066x.43.3.151American Psychologist. 431988</p>
<p>Virtual reality in the treatment of eating disorders. G Riva, C Malighetti, S Serino, 10.1002/cpp.2622Clinical Psychology &amp; Psychotherapy. 282021</p>
<p>Is clinical virtual reality ready for primetime. A Rizzo, S T Koenig, Neuropsychology. 312017</p>
<p>Belief and feeling: Evidence for an accessibility model of emotional self-report. M D Robinson, G L Clore, 10.1037/0033-2909.128.6.934Psychological Bulletin. 12862002</p>
<p>How emotion relates to language and cognition, seen through the lenses of evaluative priming paradigms. M Rohr, D Wentura, 10.3389/fpsyg.2022.911068Frontiers in Psychology. 2022</p>
<p>Basic objects in natural categories. E Rosch, C B Mervis, W D Gray, D M Johnson, P Boyes-Braem, 10.1016/0010-0285(76)90013-XCognitive Psychology. 8900131976</p>
<p>Human movement initiation: Specification of arm, direction, and extent. D A Rosenbaum, 10.1037/0096-3445.109.4.444Journal of Experimental Psychology: General. 1091980</p>
<p>Number-space mapping in the newborn chick resembles humans' mental number line. R Rugani, G Vallortigara, K Priftis, L Regolin, 10.1126/science.aaa1379Science. 3472015</p>
<p>We are what we eat: How food is represented in our mind/brain. R I Rumiati, F Foroni, 10.3758/s13423-015-0908-2Psychonomic Bulletin and Review. 232016</p>
<p>Dynamic goal states: Adjusting cognitive control without conflict monitoring. S Scherbaum, M Dshemuchadse, H Ruge, T Goschke, 10.1016/j.neuroimage.2012.06.021NeuroImage. 6312012</p>
<p>Evidence against conflict monitoring and adaptation: An updated review. J R Schmidt, 10.3758/s13423-018-1520-zPsychonomic Bulletin &amp; Review. 262019</p>
<p>A schema theory of discrete motor skill learning. R Schmidt, 10.1037/h0076770Psychological Review. 821975</p>
<p>Interrelationships among theory of mind, executive control, language development, and working memory in young children: A longitudinal analysis. W Schneider, K Lockl, O Fernandez, 10.5860/choice.42-6177W. Schneider, R. Schumann-Hengsteler, &amp; B. Sodian2004Psychology PressYoung children's cognitive development: Interrelationships among executive functioning, working memory, verbal ability, and theory of mind</p>
<p>Body dissatisfied in which body? Embodiment and selective visual attention in body-mass modified self-avatars. P Schroeder, N Gehrer, N Reimer, M Reents, J Vagedes, J Svaldi, Cyberpsychology, Behavior, and Social Networking. 2023aaccepted</p>
<p>Playing with temptation: Stopping abilities to chocolate are superior, but also more extensive. P Schroeder, K Mayer, R Wirth, J Svaldi, 10.1016/j.appet.2022.106383Appetite. 181163832023b</p>
<p>Metaanalysis of the effects of transcranial direct current stimulation on inhibitory control. P A Schroeder, T Schwippel, I Wolz, J Svaldi, 10.1016/j.brs.2020.05.006Brain Stimulation. 1352020</p>
<p>Hierarchical task representation: Task files and response selection. E H Schumacher, E Hazeltine, 10.1177/096372141666508Current Directions in Psychological Science. 25665082016. 21416</p>
<p>Sentencebased mental simulations: Evidence from behavioral experiments using garden-path sentences. E Schütt, C Dudschig, B K Bergen, B Kaup, 10.3758/s13421-022-01367-2Memory &amp; Cognition. 512022</p>
<p>Replacing vertical actions by mouse movements: A web-suited paradigm for investigating vertical spatial associations. E Schütt, I G Mackenzie, B Kaup, C Dudschig, 10.1007/s00426-022-01650-6Psychological Research Psychologische Forschung. 872023</p>
<p>Pandemonium: A paradigm for learning. Symposium on the mechanization of thought processes. O G Selfridge, 1959Stationary Office</p>
<p>On the generality of laws of learning. M Seligman, 10.1037/h0029790Psychological Review. 771970</p>
<p>The widespread influence of the Rescorla-Wagner model. S Siegel, L G Allan, 10.3758/BF03210755Psychonomic Bulletin &amp; Review. 331996</p>
<p>The architecture of cognition: Rethinking Fodor and Pylyshyn's systematicity challenge. M Silberstein, 10.7551/mitpress/9780262027236.003.0017P. Calvo &amp; J. Symons2014MIT PressOrder and disorders in the form of thought: The dynamics of systematicity</p>
<p>Cognitive control mechanisms in language processing: are there both within-and across-task conflict adaptation effects?. N Simi, I G Mackenzie, H Leuthold, M Janczyk, C Dudschig, Quarterly Journal of Experimental Psychology. 762023</p>
<p>Categories and concepts. E E Smith, D L Medin, 10.4159/harvard.97806748662701981Harvard University Press97806270</p>
<p>J G Snodgrass, 10.1002/0470018860.s00469Representations, abstract and concrete. Encyclopedia of Cognitive Science. 2006</p>
<p>Higher nervous functions: The orienting reflex. Y N Sokolov, Annual Review of Physiology. 251963</p>
<p>E S Spelke, K D Kinzler, 10.1111/j.1467-7687.2007.00569.xCore knowledge. Developmental Science. 200710</p>
<p>The continuity of mind. M Spivey, 10.4135/9781452257044.n235Realism and instrumentalism. Encyclopedia of the Mind. SAGE Publications Inc2008. 2013</p>
<p>The effect of implied orientation derived from verbal context on picture recognition. R A Stanfield, R A Zwaan, 10.1111/1467-9280.00326Psychological Science. 122001</p>
<p>No evidence of robust noun-referent associations in German-learning 6-to 14-montholds. J N Steil, C K Friedrich, U Schild, 10.3389/fpsyg.2021.718742Frontiers in Psychology. 1244102021</p>
<p>Cross-modality matching of brightness and loudness. J C Stevens, L E Marks, 10.1073/pnas.54.2.407Proceedings of the National Academy of Sciences. 541965</p>
<p>On the psychophysical law. S S Stevens, 10.1037/h0046162Psychological Review. 6431957</p>
<p>Do I need to have my hands free to understand hand-related language? Investigating the functional relevance of experiential simulations. J V Strozyk, C Dudschig, B Kaup, 10.1007/s00426-017-0900-8Psychological Research Psychologische Forschung. 832019</p>
<p>G Strube, 10.1007/978-3-642-69633-6_9Assoziation: Prozeß des Erinnerns und die Struktur des Gedächtnisses. Springer19846</p>
<p>Control over location-based response activation in the Simon task: Behavioral and electrophysiological evidence. B Stürmer, H Leuthold, E Soetens, H Schröter, W Sommer, 10.1037/0096-1523.28.6.1345Journal of Experimental Psychology: Human Perception and Performance. 2862002</p>
<p>Is human object recognition better described by geon structural descriptions or by multiple views?. M J Tarr, H H Bülthoff, 10.1037/0096-1523.21.6.1494Comment on Biederman and Gerhardstein. 211995. 1993Journal of Experimental Psychology: Human Perception and Performance</p>
<p>The planning and control model of motorvisual priming: Reconciling motorvisual impairment and facilitation effects. R Thomaschke, B Hopkins, R C Miall, 10.1037/a0027453Psychological Review. 1192012</p>
<p>Stimulus properties matter more than perspective: An fMRI study of mental imagery and silent reading of action phrases. B Tomasino, C J Werner, P H Weiss, G R Fink, 10.1016/j.neuroimage.2007.03.035NeuroImage. 362007</p>
<p>Construal-level theory of psychological distance. Y Trope, N Liberman, 10.1037/a0018963Psychological Review. 1172010</p>
<p>Episodic and semantic memory. E Tulving, Organization and memory. E Tulving, W Donaldson, Academic Press1972</p>
<p>Filtering visual onsets via habituation: A context-specific long-term memory of irrelevant stimuli. M Turatto, F Bonetti, D Pascucci, 10.1146/annurev.ph.25.030163.002553Psychonomic Bulletin &amp; Review. 252018</p>
<p>Aligning pictorial descriptions: An approach to object recognition. S Ullman, 10.1016/0010-0277(89)90036-XCognition. 32900361989</p>
<p>Weber's law for timing and time perception: Reconciling the poisson clock with scalar expectancy theory (SET). R Ulrich, K Bausenhart, J Wearden, 10.1163/22134468-bja100552022Timing &amp; Time Perception</p>
<p>Left-right coding of past and future in language: The mental timeline during sentence processing. R Ulrich, C Maienborn, 10.1016/j.cognition.2010.08.001Cognition. 1172010</p>
<p>Crossmodal temporal discrimination: Assessing the predictions of a general pacemaker-counter model. R Ulrich, J Nitschke, T Rammsayer, 10.3758/BF03193716Perception &amp; Psychophysics. 682006</p>
<p>Automatic and controlled stimulus processing in conflict tasks: Superimposed diffusion processes and delta functions. R Ulrich, H Schröter, H Leuthold, T Birngruber, 10.1016/j.cogpsych.2015.02.005Cognitive Psychology. 782015</p>
<p>Towards a computational theory of semantic memory. L M Vaina, 10.1007/978-94-010-9188-6_6Cognitive constraints on communication. L Vaina, J Hintikka, New YorkSpringer1984</p>
<p>What do people think they are doing-action identification and human-behavior. R R Vallacher, D M Wegner, 10.1037/0033-295X.94.1.3Psychological Review. 941987</p>
<p>Action identification theory. R R Vallacher, D M Wegner, 10.4135/9781446249215.n17Handbook of theories of social psychology. P A Van Lange, A W Kruglanski, E T Higgins, Sage Publications20121</p>
<p>Flexibility in embodied language processing: Context effects in lexical access. W O Van Dam, I A Brazil, H Bekkering, S Rueschemeyer, 10.1111/tops.12100Topics in Cognitive Science. 62014</p>
<p>Flexibility in embodied lexical-semantic representations. W O Van Dam, M Van Dijk, H Bekkering, S A Rueschemeyer, 10.1002/hbm.21365Human Brain Mapping. 33102012</p>
<p>Faster when fed: Satiated individuals inhibit (food)pictures better than words. M M Van Den Hoek Ostende, U Schwarz, C Gawrilow, B Kaup, J Svaldi, European Eating Disorders Review. under review</p>
<p>Practice makes perfect: Restrained eaters' heightened control for food images. M M Van Den Hoek Ostende, U Schwarz, C Gawrilow, B Kaup, J Svaldi, 10.1002/erv.3023European Eating Disorders Review. 2023</p>
<p>A working memory account of the interaction between numbers and spatial attention. J.-P Van Dijck, E L Abrahamse, F Acar, B Ketels, W Fias, 10.1080/17470218.2014.903984Quarterly Journal of Experimental Psychology. 672014</p>
<p>Sensory load incurs conceptual processing costs. N Vermeulen, O Corneille, P M Niedenthal, 10.1016/j.cognition.2008.09.004Cognition. 1092008</p>
<p>When words are upside down: Language-space associations in children and adults. A Vogt, B Kaup, C Dudschig, 10.1016/j.jecp.2019.06.001Journal of Experimental Child Psychology. 1862019</p>
<p>Language learning as uncertainty reduction: The role of prediction error in linguistic generalization and item-learning. M Vujović, M Ramscar, E Wonnacott, 10.1016/j.jml.2021.104231Journal of Memory and Language. 1191042312021</p>
<p>Habituation and memory. A R Wagner, Mechanisms of learning and motivation: A memorial volume for Jerry Konorski. A Dickinson, R A Boakes, Lawrence Erlbaum Associates1979</p>
<p>An efficient coding approach to the debate on grounded cognition. Wajnerman Paz, A , 10.1007/s11229-018-1815-7Synthese. 1952018</p>
<p>Preverbal infants' sensitivity to synesthetic cross-modality correspondences. P Walker, J G Bremner, U Mason, J Spring, K Mattock, A Slater, P J Scott, 10.1177/0956797609354734Psychological Science. 212010</p>
<p>A theory of magnitude: Common cortical metrics of time, space and quantity. V Walsh, 10.1016/j.tics.2003.09.002Trends in Cognitive Sciences. 72003</p>
<p>Spontaneous vicarious perception of the content of another's visual perspective. E Ward, G Ganis, P Bach, 10.1016/j.cub.2019.01.046Current Biology. 292019</p>
<p>Let your fingers do the walking: Finger force distinguishes competing accounts of the congruency sequence effect. D H Weissman, 10.3758/s13423-019-01626-5Psychonomic Bulletin &amp; Review. 262019</p>
<p>The action-sentence compatibility effect (ACE): Meta-analysis of a benchmark finding for embodiment. A Winter, C Dudschig, J Miller, R Ulrich, B Kaup, 10.1016/j.actpsy.2022.103712Acta Psychologica. 2301037122022</p>
<p>Of magnitudes and metaphors: Explaining cognitive interactions between space. B Winter, T Marghetis, T Matlock, 10.1016/j.cortex.2014.10.015Cortex. 642015</p>
<p>Action's effect on perception. J K Witt, 10.1177/0963721411408770Current Directions in Psychological Science. 204087702011. 21411</p>
<p>Musical metaphors: Evidence for a spatial grounding of non-literal sentences describing auditory events. S Wolter, C Dudschig, I De La Vega, B Kaup, 10.1016/j.actpsy.2014.09.006Acta Psychologica. 1562015</p>
<p>Reading sentences describing high-or low-pitched auditory events: Only pianists show evidence for a horizontal space-pitch association. S Wolter, C Dudschig, B Kaup, 10.1007/s00426-016-0812-zPsychological Research Psychologische Forschung. 812017</p>
<p>Emotional reactivity, suppression of emotions and response inhibition in emotional eaters: A multi-method pilot study. I Wolz, S Biehl, J Svaldi, 10.1016/j.appet.2021.105142Appetite. 1611051422021</p>
<p>Laboratory-based interventions targeting food craving: A systematic review and meta-analysis. I Wolz, J Nannt, J Svaldi, 10.1111/obr.12996Obesity Reviews. 2020</p>
<p>The accuracy of voluntary movement. R S Woodworth, 10.1037/h0092992Psychological Review. 31899</p>
<p>Learning and generalization of auditory temporalinterval discrimination in humans. B A Wright, D V Buonomano, H W Mahncke, M M Merzenich, 10.1523/jneurosci.17-10-03956.1997The Journal of Neuroscience. 171997</p>
<p>Manual experience shapes object representations. E Yee, E G Chrysikou, E Hoffman, S L Thompson-Schill, 10.1177/0956797612464658Psychological Science. 244646582013</p>
<p>Putting concepts into context. E Yee, S L Thompson-Schill, 10.3758/s13423-015-0948-7Psychonomic Bulletin &amp; Review. 232016</p>
<p>Event perception and memory. J M Zacks, 10.1146/annurev-psych-010419-051101Annual Review of Psychology. 7112020</p>
<p>Segmentation in reading and film comprehension. J M Zacks, N K Speer, J R Reynolds, 10.1037/a0015305Journal of Experimental Psychology: General. 1382009</p>
<p>Event perception: A mind-brain perspective. J M Zacks, N K Speer, K M Swallow, T S Braver, J R Reynolds, 10.1037/0033-2909.133.2.273Psychological Bulletin. 1332007</p>
<p>Repräsentation und Repräsentationsformate. H D Zimmer, Handbuch der Allgemeinen Psychologie -Kognition. J Funke, P A French, Hogrefe2006</p>
<p>The immersed experiencer: Toward an embodied theory of language comprehension. R A Zwaan, 10.1016/S0079-7421(03)44002-4The Psychology of Learning and Motivation. B H Ross, Academic Press200443</p>
<p>Embodiment and language comprehension: Reframing the discussion. R A Zwaan, 10.1016/j.tics.2014.02.008Trends in Cognitive Sciences. 182014</p>
<p>Publisher's Note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations. </p>            </div>
        </div>

    </div>
</body>
</html>