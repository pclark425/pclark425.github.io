<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-8170 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-8170</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-8170</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-150.html">extraction-schema-150</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve tasks, including details of the memory mechanism, tasks, comparative results, ablations, and key findings.</div>
                <p><strong>Paper ID:</strong> paper-278420582</p>
                <p><strong>Paper Title:</strong> Enhancing memory retrieval in generative agents through LLM-trained cross attention networks</p>
                <p><strong>Paper Abstract:</strong> Introduction The surge in the capabilities of large language models (LLMs) has propelled the development of Artificial General Intelligence (AGI), highlighting generative agents as pivotal components for emulating complex AI behaviors. Given the high costs associated with individually training LLMs for each AI agent, there is a critical need for advanced memory retrieval mechanisms to maintain the unique characteristics and memories of individual AI agents. Methods In this research, we developed a text-based simulation of a generative agent world, constructing a community with multiple agents and locations in which certain levels of interaction were enabled. Within this framework, we introduced a novel memory retrieval system using an Auxiliary Cross Attention Network (ACAN). This system calculates and ranks attention weights between an agent's current state and stored memories, selecting the most relevant memories for any given situation. In a novel approach, we incorporated LLM assistance, comparing memories retrieved by our model with those extracted using a base method during training, and constructing a novel loss function based on these comparisons to optimize the training process effectively. To our knowledge, this is the first study to utilize LLMs to train a dedicated agent memory retrieval network. Results Our empirical evaluations demonstrate that this approach substantially enhances the quality of memory retrieval, thereby increasing the adaptability and behavioral consistency of agents in fluctuating environments. Discussion Our findings not only introduce new perspectives and methodologies for memory retrieval in generative agents but also extend the utility of LLMs in memory management across varied AI agent applications.</p>
                <p><strong>Cost:</strong> 0.012</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e8170.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e8170.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve tasks, including details of the memory mechanism, tasks, comparative results, ablations, and key findings.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ACAN</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Auxiliary Cross Attention Network</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A learned memory-retrieval network that ranks and selects relevant episodic memories for generative agents by computing cross-attention between a query (current agent state) and memory keys; trained with LLM-provided supervision comparing its retrievals against a baseline.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>Generative agents with ACAN</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Text-based generative agents (simulated village characters) whose decision prompts are produced by an LLM and whose external memory retrieval is performed by the ACAN network using cross-attention over stored memories.</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-3.5-turbo (ChatGPT)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>The paper uses GPT-3.5-turbo to generate agent behaviors and as the environment LLM; embeddings use text-embedding-ada-002 (1536-d). Model sizes are not specified in the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Generative agent decision-making and event attendance</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Simulated multi-agent daily activity in a text-based village where agents retrieve memories to plan actions, interact, and decide whether to attend scheduled events (invitations). Evaluation includes LLM scoring of retrieved memories and attendance probability experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>multi-agent simulation / memory retrieval for decision-making</td>
                        </tr>
                        <tr>
                            <td><strong>memory_used</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>external episodic memory bank (long-term/episodic)</td>
                        </tr>
                        <tr>
                            <td><strong>memory_mechanism</strong></td>
                            <td>Cross-attention: query vector (from current agent state) is projected and dotted with memory keys; attention probabilities are softmaxed (scaled by sqrt(embed_size)) and used to rank memories; top-k selected as retrieved set. The model is trained with LLM-based scoring supervision.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_representation</strong></td>
                            <td>Textual episodic memories (observations, actions, thoughts) stored as key/value entries and embedded with text-embedding-ada-002 (1536-d).</td>
                        </tr>
                        <tr>
                            <td><strong>memory_retrieval_method</strong></td>
                            <td>Rank memories by cross-attention weights P = Softmax((q_query • m_key^T)/α); select top-k (top-5 during experiments). Training updates network to maximize LLM-assigned superiority relative to baseline retrieval.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td>Memory relevance score (LLM-evaluated) mean = 5.94 (std = 1.66) over 435 test entries; event attendance (invitation trials) mean attendance = 32.6% (std = 2.881%); training loss decreased from 1.5 to 0.12 across epochs.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_performance_with_without_memory</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_or_comparison</strong></td>
                            <td>Compared against a Weighted Memory Retrieval (WMR) baseline: ACAN memory scores higher (5.94 vs 5.05, T=7.44, p=2.42e-13). Attendance higher under ACAN (32.6% vs 24.6%, paired t-test T=11.31, p=0.00035). No internal ACAN ablation studies reported (e.g., removing attention or LLM supervision).</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>ACAN significantly improves retrieval relevance (LLM-scored) and agent behavioral consistency (higher event attendance). Cross-attention enables better integration of long-term memories and reduces variance compared to static weighted heuristics; using LLM feedback to shape the loss improves retrieval quality.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Training and evaluation rely on an external LLM for scoring which increases computational cost and API usage, slows training, and may limit generalizability; no human evaluation reported for training/test; no ablations isolating components (e.g., effect of LLM supervision vs. attention architecture) were provided.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Enhancing memory retrieval in generative agents through LLM-trained cross attention networks', 'publication_date_yy_mm': '2025-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8170.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e8170.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve tasks, including details of the memory mechanism, tasks, comparative results, ablations, and key findings.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>WMR</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Weighted Memory Retrieval</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A baseline retrieval heuristic that scores memories by a weighted sum of Recency, Importance (LLM-generated), and Relevance (cosine similarity between memory and query embeddings).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>Generative agents with WMR baseline</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Same text-based generative agents as above but using a static weighted scoring function (WMR) to retrieve top-k memories for LLM prompting.</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-3.5-turbo (ChatGPT) used for agent behavior and for producing the 'Importance' score</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>GPT-3.5-turbo used to generate agent actions and to produce per-memory 'Importance' values; embeddings produced by text-embedding-ada-002 (1536-d).</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Generative agent decision-making and event attendance (baseline condition)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Agents operate in the same simulated village and use WMR to retrieve memories for action planning and event attendance decisions.</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>multi-agent simulation / heuristic memory retrieval</td>
                        </tr>
                        <tr>
                            <td><strong>memory_used</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>external episodic memory bank (long-term/episodic)</td>
                        </tr>
                        <tr>
                            <td><strong>memory_mechanism</strong></td>
                            <td>Heuristic scoring: WMR(m) = w_r*Recency(m) + w_i*Importance(m) + w_s*Relevance(m,q), where Recency decays hourly by factor 0.995, Importance is provided by an LLM, and Relevance is cosine similarity of embeddings.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_representation</strong></td>
                            <td>Textual memories embedded with text-embedding-ada-002 (1536-d) including observations/actions/thoughts.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_retrieval_method</strong></td>
                            <td>Compute WMR scores for all memories and select top-k highest-scoring memories as the retrieved set.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td>Memory relevance score (LLM-evaluated) mean = 5.05 (std = 1.88) over 435 test entries; event attendance mean = 24.6% (std = 3.847%).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_performance_with_without_memory</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_or_comparison</strong></td>
                            <td>Serves as the baseline compared to ACAN; ACAN significantly outperforms WMR on LLM-scored retrieval and attendance metrics (see ACAN comparisons). No further ablations of WMR components reported.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>WMR provides a competitive heuristic baseline that combines recency, LLM-assigned importance, and embedding similarity, but it is outperformed by a learned cross-attention retriever that adapts to context.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Static weighting cannot account for nuanced contextual dependencies; more variable performance (higher std) across scenarios; depends on LLM-generated Importance scores (external dependency).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Enhancing memory retrieval in generative agents through LLM-trained cross attention networks', 'publication_date_yy_mm': '2025-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8170.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e8170.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve tasks, including details of the memory mechanism, tasks, comparative results, ablations, and key findings.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Generative agents (GPT-driven)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>LLM-driven Generative Agents (ChatGPT-based)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Text-only simulated agents (Farmer, Grocer, Doctor, etc.) whose action planning and behavior are produced by GPT-3.5-turbo, relying on external episodic memory retrieval to inform decisions over multi-day interactions.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>GPT-3.5-turbo driven generative agents</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Discrete-time, turn-based agents powered by GPT-3.5-turbo that plan, act, and move across locations; each decision is conditioned on current state plus externally retrieved memories.</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-3.5-turbo</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>ChatGPT model used to generate agent plans, interactions, and to provide some scoring/importance annotations; exact parameter count not specified.</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Simulated daily life and social interactions in a multi-agent village</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Agents perform hour-by-hour planning and interactions across locations; tasks include interpersonal interactions, planning events, attending invitations; memory retrieval informs these behaviors.</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>multi-agent simulation / social behavior generation</td>
                        </tr>
                        <tr>
                            <td><strong>memory_used</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>external episodic memory bank</td>
                        </tr>
                        <tr>
                            <td><strong>memory_mechanism</strong></td>
                            <td>Agents query an external memory bank at each decision step; retrieval is either WMR (heuristic) or ACAN (learned cross-attention), then retrieved memories are concatenated with the agent state and sent as prompt context to GPT-3.5-turbo.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_representation</strong></td>
                            <td>Textual records of past observations, thoughts, and actions, embedded with text-embedding-ada-002.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_retrieval_method</strong></td>
                            <td>Either WMR ranking (baseline) or ACAN cross-attention ranking; top-k memories are included into the LLM prompt for action generation.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_performance_with_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>ablation_or_comparison</strong></td>
                            <td>The main experimental comparison is between agents using WMR vs agents using ACAN retrieval. Performance differences reported in memory-score and attendance metrics (see ACAN & WMR entries).</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Using a better retriever (ACAN) to supply memories to LLM-driven agents improves agent behavioral consistency and task outcomes (higher attendance, better LLM-scored memory relevance).</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Agents' behavior evaluation and training depend on LLM scoring and use of an LLM for behavior generation, contributing to cost and potential evaluation biases; paper does not report agent performance without any memory retrieval.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Enhancing memory retrieval in generative agents through LLM-trained cross attention networks', 'publication_date_yy_mm': '2025-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8170.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e8170.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve tasks, including details of the memory mechanism, tasks, comparative results, ablations, and key findings.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LLM-based evaluator</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Large Language Model as Memory Relevance Evaluator</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Using an LLM to score and compare retrieved memory sets (ACAN vs baseline) given the agent's query/context; these scores are incorporated into a custom loss to train the retrieval network and also used as test-time evaluation.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>LLM-based evaluation component</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>An LLM (ChatGPT/GPT-3.5-turbo) is used both to assign 'Importance' scores within WMR and to score entire retrieved memory sets for supervised training of ACAN and for test-time evaluation on a 1–10 scale.</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-3.5-turbo (used for behavior) and/or unspecified ChatGPT LLM used for evaluation</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>LLM serves as an automatic judge of memory relevance and as a source of importance annotations; specific prompting or rubric details not deeply specified beyond a 1–10 scoring scale.</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Memory relevance scoring for training and evaluation</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Given an agent current state q and two retrieved memory sets (m_r from ACAN and m'_r from baseline), the LLM assigns scores Score_LLM and Score'_LLM (1–10) based on contextual appropriateness; scores drive training loss and evaluation.</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>automatic evaluation / supervision</td>
                        </tr>
                        <tr>
                            <td><strong>memory_used</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_mechanism</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_representation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_retrieval_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_performance_with_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>ablation_or_comparison</strong></td>
                            <td>LLM scoring is used to compare retrieval outputs and compute a loss: output_score = (Score_LLM - Score'_LLM)/10; loss = max(-log(output_score + 1), 0). Authors report training loss drop when using LLM supervision (1.5 -> 0.12). No comparison to human evaluation in training (no ablation replacing LLM supervision with humans).</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>LLMs can provide scalable supervision and evaluation signals for training/assessing a retrieval network, enabling improved retrieval quality without human labels; this supervision aligns retrieval with contextual relevance as judged by the LLM.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Reliance on LLM judgment introduces cost, potential biases, and possible lack of external validity; the paper acknowledges LLM supervision may not generalize and recommends adding human validation in future work.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Enhancing memory retrieval in generative agents through LLM-trained cross attention networks', 'publication_date_yy_mm': '2025-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Generative agents: interactive simulacra of human behavior <em>(Rating: 2)</em></li>
                <li>Memory sandbox: transparent and interactive memory management for conversational agents <em>(Rating: 2)</em></li>
                <li>Memorybank: enhancing large language models with long-term memory <em>(Rating: 2)</em></li>
                <li>My agent understands me better: integrating dynamic human-like memory recall and consolidation in LLM-based agents <em>(Rating: 2)</em></li>
                <li>RAP: retrieval-augmented planning with contextual memory for multimodal LLM agents <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-8170",
    "paper_id": "paper-278420582",
    "extraction_schema_id": "extraction-schema-150",
    "extracted_data": [
        {
            "name_short": "ACAN",
            "name_full": "Auxiliary Cross Attention Network",
            "brief_description": "A learned memory-retrieval network that ranks and selects relevant episodic memories for generative agents by computing cross-attention between a query (current agent state) and memory keys; trained with LLM-provided supervision comparing its retrievals against a baseline.",
            "citation_title": "here",
            "mention_or_use": "use",
            "agent_name": "Generative agents with ACAN",
            "agent_description": "Text-based generative agents (simulated village characters) whose decision prompts are produced by an LLM and whose external memory retrieval is performed by the ACAN network using cross-attention over stored memories.",
            "model_name": "GPT-3.5-turbo (ChatGPT)",
            "model_description": "The paper uses GPT-3.5-turbo to generate agent behaviors and as the environment LLM; embeddings use text-embedding-ada-002 (1536-d). Model sizes are not specified in the paper.",
            "task_name": "Generative agent decision-making and event attendance",
            "task_description": "Simulated multi-agent daily activity in a text-based village where agents retrieve memories to plan actions, interact, and decide whether to attend scheduled events (invitations). Evaluation includes LLM scoring of retrieved memories and attendance probability experiments.",
            "task_type": "multi-agent simulation / memory retrieval for decision-making",
            "memory_used": true,
            "memory_type": "external episodic memory bank (long-term/episodic)",
            "memory_mechanism": "Cross-attention: query vector (from current agent state) is projected and dotted with memory keys; attention probabilities are softmaxed (scaled by sqrt(embed_size)) and used to rank memories; top-k selected as retrieved set. The model is trained with LLM-based scoring supervision.",
            "memory_representation": "Textual episodic memories (observations, actions, thoughts) stored as key/value entries and embedded with text-embedding-ada-002 (1536-d).",
            "memory_retrieval_method": "Rank memories by cross-attention weights P = Softmax((q_query • m_key^T)/α); select top-k (top-5 during experiments). Training updates network to maximize LLM-assigned superiority relative to baseline retrieval.",
            "performance_with_memory": "Memory relevance score (LLM-evaluated) mean = 5.94 (std = 1.66) over 435 test entries; event attendance (invitation trials) mean attendance = 32.6% (std = 2.881%); training loss decreased from 1.5 to 0.12 across epochs.",
            "performance_without_memory": null,
            "has_performance_with_without_memory": true,
            "ablation_or_comparison": "Compared against a Weighted Memory Retrieval (WMR) baseline: ACAN memory scores higher (5.94 vs 5.05, T=7.44, p=2.42e-13). Attendance higher under ACAN (32.6% vs 24.6%, paired t-test T=11.31, p=0.00035). No internal ACAN ablation studies reported (e.g., removing attention or LLM supervision).",
            "key_findings": "ACAN significantly improves retrieval relevance (LLM-scored) and agent behavioral consistency (higher event attendance). Cross-attention enables better integration of long-term memories and reduces variance compared to static weighted heuristics; using LLM feedback to shape the loss improves retrieval quality.",
            "limitations_or_challenges": "Training and evaluation rely on an external LLM for scoring which increases computational cost and API usage, slows training, and may limit generalizability; no human evaluation reported for training/test; no ablations isolating components (e.g., effect of LLM supervision vs. attention architecture) were provided.",
            "uuid": "e8170.0",
            "source_info": {
                "paper_title": "Enhancing memory retrieval in generative agents through LLM-trained cross attention networks",
                "publication_date_yy_mm": "2025-05"
            }
        },
        {
            "name_short": "WMR",
            "name_full": "Weighted Memory Retrieval",
            "brief_description": "A baseline retrieval heuristic that scores memories by a weighted sum of Recency, Importance (LLM-generated), and Relevance (cosine similarity between memory and query embeddings).",
            "citation_title": "here",
            "mention_or_use": "use",
            "agent_name": "Generative agents with WMR baseline",
            "agent_description": "Same text-based generative agents as above but using a static weighted scoring function (WMR) to retrieve top-k memories for LLM prompting.",
            "model_name": "GPT-3.5-turbo (ChatGPT) used for agent behavior and for producing the 'Importance' score",
            "model_description": "GPT-3.5-turbo used to generate agent actions and to produce per-memory 'Importance' values; embeddings produced by text-embedding-ada-002 (1536-d).",
            "task_name": "Generative agent decision-making and event attendance (baseline condition)",
            "task_description": "Agents operate in the same simulated village and use WMR to retrieve memories for action planning and event attendance decisions.",
            "task_type": "multi-agent simulation / heuristic memory retrieval",
            "memory_used": true,
            "memory_type": "external episodic memory bank (long-term/episodic)",
            "memory_mechanism": "Heuristic scoring: WMR(m) = w_r*Recency(m) + w_i*Importance(m) + w_s*Relevance(m,q), where Recency decays hourly by factor 0.995, Importance is provided by an LLM, and Relevance is cosine similarity of embeddings.",
            "memory_representation": "Textual memories embedded with text-embedding-ada-002 (1536-d) including observations/actions/thoughts.",
            "memory_retrieval_method": "Compute WMR scores for all memories and select top-k highest-scoring memories as the retrieved set.",
            "performance_with_memory": "Memory relevance score (LLM-evaluated) mean = 5.05 (std = 1.88) over 435 test entries; event attendance mean = 24.6% (std = 3.847%).",
            "performance_without_memory": null,
            "has_performance_with_without_memory": true,
            "ablation_or_comparison": "Serves as the baseline compared to ACAN; ACAN significantly outperforms WMR on LLM-scored retrieval and attendance metrics (see ACAN comparisons). No further ablations of WMR components reported.",
            "key_findings": "WMR provides a competitive heuristic baseline that combines recency, LLM-assigned importance, and embedding similarity, but it is outperformed by a learned cross-attention retriever that adapts to context.",
            "limitations_or_challenges": "Static weighting cannot account for nuanced contextual dependencies; more variable performance (higher std) across scenarios; depends on LLM-generated Importance scores (external dependency).",
            "uuid": "e8170.1",
            "source_info": {
                "paper_title": "Enhancing memory retrieval in generative agents through LLM-trained cross attention networks",
                "publication_date_yy_mm": "2025-05"
            }
        },
        {
            "name_short": "Generative agents (GPT-driven)",
            "name_full": "LLM-driven Generative Agents (ChatGPT-based)",
            "brief_description": "Text-only simulated agents (Farmer, Grocer, Doctor, etc.) whose action planning and behavior are produced by GPT-3.5-turbo, relying on external episodic memory retrieval to inform decisions over multi-day interactions.",
            "citation_title": "here",
            "mention_or_use": "use",
            "agent_name": "GPT-3.5-turbo driven generative agents",
            "agent_description": "Discrete-time, turn-based agents powered by GPT-3.5-turbo that plan, act, and move across locations; each decision is conditioned on current state plus externally retrieved memories.",
            "model_name": "GPT-3.5-turbo",
            "model_description": "ChatGPT model used to generate agent plans, interactions, and to provide some scoring/importance annotations; exact parameter count not specified.",
            "task_name": "Simulated daily life and social interactions in a multi-agent village",
            "task_description": "Agents perform hour-by-hour planning and interactions across locations; tasks include interpersonal interactions, planning events, attending invitations; memory retrieval informs these behaviors.",
            "task_type": "multi-agent simulation / social behavior generation",
            "memory_used": true,
            "memory_type": "external episodic memory bank",
            "memory_mechanism": "Agents query an external memory bank at each decision step; retrieval is either WMR (heuristic) or ACAN (learned cross-attention), then retrieved memories are concatenated with the agent state and sent as prompt context to GPT-3.5-turbo.",
            "memory_representation": "Textual records of past observations, thoughts, and actions, embedded with text-embedding-ada-002.",
            "memory_retrieval_method": "Either WMR ranking (baseline) or ACAN cross-attention ranking; top-k memories are included into the LLM prompt for action generation.",
            "performance_with_memory": null,
            "performance_without_memory": null,
            "has_performance_with_without_memory": null,
            "ablation_or_comparison": "The main experimental comparison is between agents using WMR vs agents using ACAN retrieval. Performance differences reported in memory-score and attendance metrics (see ACAN & WMR entries).",
            "key_findings": "Using a better retriever (ACAN) to supply memories to LLM-driven agents improves agent behavioral consistency and task outcomes (higher attendance, better LLM-scored memory relevance).",
            "limitations_or_challenges": "Agents' behavior evaluation and training depend on LLM scoring and use of an LLM for behavior generation, contributing to cost and potential evaluation biases; paper does not report agent performance without any memory retrieval.",
            "uuid": "e8170.2",
            "source_info": {
                "paper_title": "Enhancing memory retrieval in generative agents through LLM-trained cross attention networks",
                "publication_date_yy_mm": "2025-05"
            }
        },
        {
            "name_short": "LLM-based evaluator",
            "name_full": "Large Language Model as Memory Relevance Evaluator",
            "brief_description": "Using an LLM to score and compare retrieved memory sets (ACAN vs baseline) given the agent's query/context; these scores are incorporated into a custom loss to train the retrieval network and also used as test-time evaluation.",
            "citation_title": "here",
            "mention_or_use": "use",
            "agent_name": "LLM-based evaluation component",
            "agent_description": "An LLM (ChatGPT/GPT-3.5-turbo) is used both to assign 'Importance' scores within WMR and to score entire retrieved memory sets for supervised training of ACAN and for test-time evaluation on a 1–10 scale.",
            "model_name": "GPT-3.5-turbo (used for behavior) and/or unspecified ChatGPT LLM used for evaluation",
            "model_description": "LLM serves as an automatic judge of memory relevance and as a source of importance annotations; specific prompting or rubric details not deeply specified beyond a 1–10 scoring scale.",
            "task_name": "Memory relevance scoring for training and evaluation",
            "task_description": "Given an agent current state q and two retrieved memory sets (m_r from ACAN and m'_r from baseline), the LLM assigns scores Score_LLM and Score'_LLM (1–10) based on contextual appropriateness; scores drive training loss and evaluation.",
            "task_type": "automatic evaluation / supervision",
            "memory_used": null,
            "memory_type": null,
            "memory_mechanism": null,
            "memory_representation": null,
            "memory_retrieval_method": null,
            "performance_with_memory": null,
            "performance_without_memory": null,
            "has_performance_with_without_memory": null,
            "ablation_or_comparison": "LLM scoring is used to compare retrieval outputs and compute a loss: output_score = (Score_LLM - Score'_LLM)/10; loss = max(-log(output_score + 1), 0). Authors report training loss drop when using LLM supervision (1.5 -&gt; 0.12). No comparison to human evaluation in training (no ablation replacing LLM supervision with humans).",
            "key_findings": "LLMs can provide scalable supervision and evaluation signals for training/assessing a retrieval network, enabling improved retrieval quality without human labels; this supervision aligns retrieval with contextual relevance as judged by the LLM.",
            "limitations_or_challenges": "Reliance on LLM judgment introduces cost, potential biases, and possible lack of external validity; the paper acknowledges LLM supervision may not generalize and recommends adding human validation in future work.",
            "uuid": "e8170.3",
            "source_info": {
                "paper_title": "Enhancing memory retrieval in generative agents through LLM-trained cross attention networks",
                "publication_date_yy_mm": "2025-05"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Generative agents: interactive simulacra of human behavior",
            "rating": 2,
            "sanitized_title": "generative_agents_interactive_simulacra_of_human_behavior"
        },
        {
            "paper_title": "Memory sandbox: transparent and interactive memory management for conversational agents",
            "rating": 2,
            "sanitized_title": "memory_sandbox_transparent_and_interactive_memory_management_for_conversational_agents"
        },
        {
            "paper_title": "Memorybank: enhancing large language models with long-term memory",
            "rating": 2,
            "sanitized_title": "memorybank_enhancing_large_language_models_with_longterm_memory"
        },
        {
            "paper_title": "My agent understands me better: integrating dynamic human-like memory recall and consolidation in LLM-based agents",
            "rating": 2,
            "sanitized_title": "my_agent_understands_me_better_integrating_dynamic_humanlike_memory_recall_and_consolidation_in_llmbased_agents"
        },
        {
            "paper_title": "RAP: retrieval-augmented planning with contextual memory for multimodal LLM agents",
            "rating": 1,
            "sanitized_title": "rap_retrievalaugmented_planning_with_contextual_memory_for_multimodal_llm_agents"
        }
    ],
    "cost": 0.012447999999999999,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Enhancing memory retrieval in generative agents through LLM-trained cross attention networks</p>
<p>Kyle Perkins 
Alain Lioret 
Chuanyang Hong 
Qingyun He </p>
<p>Florida International University
United States</p>
<p>Université Paris
France</p>
<p>Susan Neimand</p>
<p>Miami Dade College
United States</p>
<p>School of Computing and Artificial Intelligence
School of Finance and Economics
Southwestern University of Finance and Economics
ChengduChina</p>
<p>Anhui Science and Technology University
BengbuChina</p>
<p>Enhancing memory retrieval in generative agents through LLM-trained cross attention networks
879CCC9A7C6F0EC5F1DBA8C3130DD9A7RECEIVED March ACCEPTED April PUBLISHED May CITATIONartificial intelligence (AI)large language models (LLMs)generative agentsmemory retrievalattention mechanism
Hong C and He Q () Enhancing memory retrieval in generative agents through LLM-trained cross attention networks.</p>
<p>Introduction:</p>
<p>The surge in the capabilities of large language models (LLMs) has propelled the development of Artificial General Intelligence (AGI), highlighting generative agents as pivotal components for emulating complex AI behaviors.Given the high costs associated with individually training LLMs for each AI agent, there is a critical need for advanced memory retrieval mechanisms to maintain the unique characteristics and memories of individual AI agents.</p>
<p>Methods:</p>
<p>In this research, we developed a text-based simulation of a generative agent world, constructing a community with multiple agents and locations in which certain levels of interaction were enabled.Within this framework, we introduced a novel memory retrieval system using an Auxiliary Cross Attention Network (ACAN).This system calculates and ranks attention weights between an agent's current state and stored memories, selecting the most relevant memories for any given situation.In a novel approach, we incorporated LLM assistance, comparing memories retrieved by our model with those extracted using a base method during training, and constructing a novel loss function based on these comparisons to optimize the training process e ectively.To our knowledge, this is the first study to utilize LLMs to train a dedicated agent memory retrieval network.</p>
<p>Results: Our empirical evaluations demonstrate that this approach substantially enhances the quality of memory retrieval, thereby increasing the adaptability and behavioral consistency of agents in fluctuating environments.</p>
<p>Introduction</p>
<p>The release of GPT-4 by OpenAI has demonstrated the impressive capabilities of large language models (LLMs) and their potential for Artificial General Intelligence (AGI).Consequently, various Artificial Intelligence (AI) applications based on LLMs have made significant advancements across different fields.Among these, personalized AI agents that simulate human behavior have garnered increasing attention and are considered a crucial pathway toward AGI (Xi et al., 2023).</p>
<p>The concept of an agent refers to entities possessing desires, beliefs, intentions, and the ability to take actions (Zalta et al., 1995).Currently, the goal of LLM based generative agents is to simulate believable human behavior, creating more personalized AI.This requires AI not only to simulate human behavior at a single point in time but to ensure long-term coherence.Such AI would be better suited by architectures that manage ever-growing memories as new interactions, conflicts, and events arise and fade over time while handling cascading social dynamics that unfold between multiple agents (Park et al., 2023).</p>
<p>Therefore, personalized AI requires not only the general intelligence provided by LLMs but also long-term personalized memories that are private, extensible, and explainable to the user.Additionally, it requires an efficient method to retrieve these relevant memories based on the current context faced by the agent.</p>
<p>To achieve this goal, the ideal approach would be to train a dedicated LLM for each agent.However, considering the complexity of LLM training (Yang et al., 2024) and the practical demands of a large variety and number of agents, this approach is impractical.Therefore, the common practice is to store the agent's memories externally and provide the necessary memories to the LLM in the form of linguistic feedback during decision-making (Shinn et al., 2023).</p>
<p>In this approach to implementing agents, the method of memory retrieval becomes critically important.The ability to extract memories relevant to the current context faced by the agent will directly determine how well the agent's behavior can simulate real human actions.Common memory retrieval methods include temporal decay ranking, evaluation of memory importance, vector similarity matching, and combinations of these techniques (Park et al., 2023).However, these existing methods still have significant limitations in matching the complex correlations between the agent's current context and the memories stored in the memory bank.</p>
<p>Faced with this challenge, we developed a text-based generative agent simulation environment featuring multiple characters and locations, as depicted in Figure 1.This simulation framework enabled the modeling of agents with diverse characteristics, including varying ages, genders, identities, professions, and personalities, all portrayed by LLMs.These agents operated within a virtual village, residing in their respective homes and interacting in public spaces.Through extended simulations and systematic observation of the agents' behaviors and feedback, we sought to evaluate the impact of different memory retrieval methods on the agents' ability to simulate human behavior effectively.</p>
<p>Building on this foundation, we propose an innovative memory retrieval method designed for generative agents that simulate human-like interactions.This method uses an Auxiliary Cross Attention Network (ACAN) to optimize memory retrieval.Inspired by the self-attention mechanism described in Vaswani et al. (2017), ACAN transforms the agent's current state and observed context into a query vector.This query is compared with stored memories in the memory bank, which are represented as key-value pairs.The attention mechanism calculates scores by aligning the query with the memory keys, and the attention weights are ranked.Based on these ranked attention scores, the most relevant memories are selected as the retrieved memory set.</p>
<p>The retrieved memories are combined with the agent's current state and input into the LLM to guide the agent's behavior.To train this network and enhance its ability to simulate the human memory retrieval process, we innovatively introduced the use of LLMs to assist in network training.By comparing the memories retrieved by this network with traditional memory retrieval methods, allowing the LLM to evaluate and score the quality of the retrieved memories based on the agent's current state.These scores are then incorporated into the custom loss function to guide the training of the ACAN.This method ensures that the network is updated in a way that better reflects human-like memory retrieval patterns.To the best of our knowledge, this is the first approach that integrates LLMs into the training process of a memory retrieval network for agents.</p>
<p>Compared to existing static memory retrieval algorithms, the ACAN approach introduces dynamic improvements by incorporating the agent's historical memory formation process with a cross-attention mechanism that is optimized through LLM feedback.Our experiments demonstrate that ACAN substantially outperforms traditional methods in memory retrieval, resulting in enhanced adaptability of agents and more effective interactions with their environment and other agents.We evaluated the quality of the retrieved memories using LLMs in a comprehensive test simulation set and conducted a quantitative analysis of agent behavior consistency across various memory retrieval modes.This novel memory retrieval method allows agents to better simulate human-like responses based on their current state, thereby significantly improving their ability to engage in complex interpersonal interactions.</p>
<p>In summary, our paper makes the following contributions:</p>
<p>• We constructed a novel, text-based generative agent simulation environment, featuring multiple characters and locations, which simulates real-life interactions at a low computational cost, demonstrating a novel application of LLMs in simulating human-like agent behavior.</p>
<p>• We introduced an innovative Auxiliary Cross Attention</p>
<p>Network for memory retrieval in AI agents simulating human behavior.By calculating attention weights between the agent's current state and all memories in the memory bank, ACAN ranks and retrieves the most relevant memories, leading to Enhanced Memory Retrieval compared to base methods.• We introduced a novel methodology for training neural networks with LLM assistance, where LLMs evaluate memory retrieval outputs and help in shaping the loss function.This innovative use of LLMs in training AI agents offers a fresh perspective on their application in the AI agent field.• We provide a detailed comparison between our method and commonly used memory retrieval techniques, demonstrating our approach's superior ability to dynamically adapt to the agent's evolving memory and environment.This novel memory retrieval method enables agents to more accurately simulate human-like responses based on their current state, significantly enhancing their capacity to engage in complex interpersonal interactions.</p>
<p>FIGURE</p>
<p>Illustration of the simulated world and memory retrieval process.</p>
<p>Related work . Large language models and generative agent</p>
<p>Generative artificial intelligence refers to AI systems that generate text, images, videos, or other data types based on prompts.These systems are exemplified by LLMs such as ChatGPT and GPT-4, which have achieved tremendous success across various tasks in the field of Natural Language Processing (NLP) (OpenAI, 2022).The primary feature of LLMs is their use of large-scale datasets to train large-scale models, such as GPT-3 (Brown et al., 2020), a precursor to ChatGPT, which was trained using massive data and the Transformer architecture (Vaswani et al., 2017).</p>
<p>The success of OpenAI's ChatGPT has sparked considerable interest among researchers as a potential spark for Artificial General Intelligence (AGI) (Xi et al., 2023).Numerous studies have validated the exceptional performance of LLMs when appropriately prompted in downstream tasks, showcasing their versatility and intelligence (Bang et al., 2023;Wei et al., 2022).These models have been effectively employed in a variety of applications, such as translation (Jiao et al., 2023), text generation across diverse genres (Cao et al., 2023), and narrative content adaptation (Musacchio et al., 2024).</p>
<p>A particularly notable application is the development of AI agents capable of mimicking human behaviors using ChatGPT, which illustrates the models' capability to generate believably human-like interactions (Xi et al., 2023).</p>
<p>In the broadest sense, an "agent" is defined as an entity capable of action (Zalta et al., 1995).Within the field of artificial intelligence, there has been a longstanding commitment to using agents as believable proxies for human behavior, a goal that holds significant importance across AI and its applications (Bates et al., 1994;Laird and VanLent, 2001;Yannakakis, 2012).Typically, AI-based agents are designed to perceive their environments through sensors, make decisions, and perform actions using effectors (Wooldridge and Jennings, 1995;Russell and Norvig, 2016).These agents combine sensory data with pre-programmed behaviors to interact with their surroundings effectively, but creating agents that truly mimic the nuanced behaviors of humans remains a complex endeavor.</p>
<p>Despite this, the development of AI agents that can accurately and credibly simulate complex human behaviors has proven to be challenging (Schweitzer et al., 2020;Abdalla and Mishra, 2021).Currently, the widespread success of LLMs, exemplified by GPT-4, across various AI domains (Achiam et al., 2023), has enabled these models to leverage extensive training data on human behavior (Brown et al., 2020), providing agents with enhanced creativity and adaptability.This capability enables agents to process information more effectively and respond in ways that closely mimic human reactions.Consequently, an increasing number of researchers are exploring the use of LLMs to develop Generative Agents with robust content generation capabilities (Park et al., 2023;Liu et al., 2023;Wang et al., 2024).These agents are finding applications in diverse fields, demonstrating the versatility and potential of LLM-driven agent applications.</p>
<p>LLM-based agents primarily utilize prompt chains (Wu T. et al., 2022) to generate concise natural language descriptions and actions for characters within prototype systems, thereby creating populated prototypes for social computing systems (Park J. S. et al., 2022).Additionally, LLMs are employed to craft interactive experiences in user-engaging games, facilitating dynamic actions (Freiknecht and Effelsberg, 2020) and text-based adventure games (Callison-Burch et al., 2022).Further extending their application, LLM-driven Generative Agents are used to construct virtual communities.Within these simulated environments, researchers have observed social phenomena emerging from the cooperation among multiple agents (Park et al., 2023).For instance, in a virtual community, an agent planning a Valentine's Day party autonomously spreads invitations throughout the community and coordinates the timing of the event over the following two days.</p>
<p>To enable Generative Agents, assisted by LLMs, to perform such complex functions, researchers have explored methods beyond first-order prompting.They have enhanced language models with static knowledge bases and information retrieval schemes (Khattab et al., 2022), and extended these concepts to develop agent architectures that dynamically update past experiences at each step, integrating these with the agents' current contexts and plans.For instance, applications in various domains utilize such memory-enhanced agents to process layered information and improve decision-making (Yu et al., 2024).This integration can either reinforce or contradict the ongoing interactions, providing a more adaptive and responsive agent behavior (Park et al., 2023).</p>
<p>However, the complex behavior of agents inevitably leads to challenges similar to human decision-making, particularly the need for an appropriate memory system.This system must enable agents to retrieve the most relevant memories when needed, thereby facilitating recollection and thought processes akin to human cognition.Without such a system, agents may exhibit inconsistent behaviors over time, undermining the believability and effectiveness of their interactions.</p>
<p>. Agent memory retrieval</p>
<p>In constructing memory systems for Generative Agents, agents' memories-comprised of sequences of past observations, thoughts, and actions (Nuxoll and Laird, 2007)-play a crucial role in strategy formulation and decision-making processes.Just as the human brain utilizes prior experiences for adaptive behavior (Squire, 1986;Schwabe et al., 2014), agents require specialized memory mechanisms to effectively manage sequential tasks.Research by Schuurmans (2023) demonstrated that transformer-based large language models (LLMs), when augmented with external memory, achieve computational universality.This augmentation allows agents to revisit and reapply past strategies without altering the model's weights, which is critical for reliable adaptation in complex environments.</p>
<p>Before the advent of LLM-based agents, extensive research had already been conducted on enhancing model performance through memory mechanisms.For instance, Memory Transformer and Recurrent Memory Transformer (Burtsev et al., 2020;Bulatov et al., 2022) introduced memory tokens and recurrent mechanisms to improve transformers' understanding of long-sequence tasks, especially for global context processing.Memorizing Transformers (Wu Y. et al., 2022) leveraged non-differentiable memory lookup systems to retrieve past inputs during inference, enabling realtime memory retrieval.Additionally, hardware-related research has explored optimizing memory utilization to improve model efficiency (Sridharan et al., 2023).However, these memory mechanisms primarily targeted deep learning models, optimizing performance through memory augmentation or architectural adjustments within a fixed model framework.</p>
<p>In contrast, LLM-derived agents, functioning as independent entities, face a more complex and dynamic memory landscape.These agents do not rely solely on internally generated representations from training, but also draw heavily from their interaction history and external memory repositories.For example, Memory Sandbox (Huang et al., 2023) introduced a system where users can manage conversational memories of LLM-powered agents, treating them as data objects that can be viewed, manipulated, and controlled, thus enhancing interaction transparency and coherence.Similarly, AgentSims (Lin et al., 2023) provided a sandbox infrastructure for task-based evaluations of LLM agents in simulated environments, giving researchers a platform to test memory and planning mechanisms in LLMs.A recent survey (Zhang et al., 2024) further highlights the significance of memory modules in enabling LLM-based agents to achieve self-evolving capabilities and interact effectively in realworld contexts.Furthermore, the Retrieval-Augmented Planning (RAP) framework (Kagaya et al., 2024) leverages contextual memory to enhance decision-making in both text-based and multimodal environments.</p>
<p>Enhancing memory retrieval in generative agents not only improves LLM performance but also enhances the extraction of external memories, thereby boosting the agents' behavior and adaptability.This is particularly critical in multi-agent systems, where each agent may have distinct external memory structures, making efficient retrieval essential.The primary method for memory utilization in LLM-based agents involves using relevant memories as prompts.However, as agents accumulate more historical data through interactions, two major challenges arise.First, the length of these records may exceed the processing limits of the LLM's Transformer architecture, causing content truncation.Second, the growing volume of observations and actions complicates the retrieval of relevant memories, leading to potential misalignment between the agent's responses and the current context.Addressing these challenges requires the development of efficient memory retrieval systems capable of managing and utilizing extensive historical data in a way that maintains coherence and relevance in the agent's interactions.</p>
<p>To address these challenges, current improvements in agent memory management include techniques such as text truncation (Park H. H. et al., 2022), input segmentation (Mohtashami and Jaggi, 2023), and other approaches aimed at reducing complexity, such as increasing the sequence length limits of Transformerbased LLMs (Guo et al., 2021), or incorporating self-controlled memory systems to manage long-term and short-term memory efficiently (Liang et al., 2023).Furthermore, methods for integrating and summarizing memories to create condensed representations have been developed (Zhao et al., 2024;Liang et al., 2023), enhancing the efficiency of memory retrieval in dynamic and complex interaction scenarios.Retrieval models such as Alonso et al. (2024) integrate chained-of-table search, vector-database retrieval, and prompting mechanisms to handle time-sensitive and context-dependent queries.Similarly, Hou et al. (2024) propose a human-like memory architecture for LLM-based dialogue agents, leveraging cue-based recall and a mathematical model for dynamic memory consolidation, enabling temporal and context-sensitive retrieval.Additionally, data structures and embedding techniques have been explored to compress memories, facilitating faster ./fpsyg. .</p>
<p>response times in interactions (Modarressi et al., 2023;Qian et al., 2023), while SQL-integrated systems enable efficient management of large-scale historical data through SQL commands (Hu et al., 2023;Zhou et al., 2023).</p>
<p>In multi-agent systems, when agents interact with their environment and other agents, the ability to retrieve the most relevant information from their memory is essential.Particularly in environments that require collaboration among multiple agents, the quality of memory retrieval significantly influences the agents' decision-making, actions, and adaptability.This crucial aspect of memory optimization is aligned with the objectives of multiagent reinforcement learning (MARL), where enhancing agent capabilities is a primary focus (Gronauer and Diepold, 2022).For example, the introduction of memory-driven communication mechanisms via memory devices has enabled agents to share and update information about their environment during task execution, significantly improving coordination and performance in complex multi-agent systems (Pesce and Montana, 2020).</p>
<p>However, unlike traditional MARL approaches that primarily utilize memory for storing learned policies or state-action histories, LLM-based multi-agent systems rely on pre-trained models, and their intelligence is not updated through real-time training as in MARL.In MARL, agents continuously improve by interacting with their environment, refining their strategies via reinforcement learning.In contrast, LLM agents depend on external, evolving memory banks to access accumulated historical interactions.The focus thus shifts from real-time learning to optimizing memory retrieval, as these external memories are queried in real-time.ACAN enhances LLM agents by improving how relevant memories are retrieved, allowing for more effective decision-making and adaptability in complex environments.MemoryBank (Zhong et al., 2024) exemplifies this, using past interaction data and the forgetting curve theory to optimize memory retrieval.Similarly, advanced methods use metrics like Recency, Relevance, and Importance to dynamically rank and retrieve the most suitable memories (Park et al., 2023), underscoring the importance of adaptive memory systems in evolving agent environments.</p>
<p>In summary, the literature review underscores the critical role of memory in enhancing the capability and adaptability of agents within multi-agent systems.The efficacy of generative agents in practical applications is directly determined by the capability of memory retrieval systems to extract the most relevant memories from the memory bank, akin to human-like recollection based on the current context faced by the agent.However, current methods of memory retrieval still struggle to perfectly extract the most relevant memories from the memory bank as a human would, based on the agent's current scenario.</p>
<p>Methods</p>
<p>To validate the effectiveness of our proposed Auxiliary Cross Attention Network for agent memory retrieval, we have structured the experimental section into distinct parts.The first part details the operational architecture of our text-based generative agent community, which is powered by ChatGPT.The second part describes the structure and training methodology of the Auxiliary Cross Attention Network.Together, these sections provide a comprehensive overview of the experimental framework.</p>
<p>. Generative agent architecture</p>
<p>To construct a virtual agent community for testing memory retrieval mechanisms, we simplified the structure described in Park et al. (2023) and proposed a purely text-based community architecture without visual imagery.This setup allows for the instantiation of maps and unique agent entities, where the locations on the map and the number and characteristics of each agent, including their professions and personalities, can be freely defined.We adopted the same GPT-3.5-turboversion of ChatGPT used in Park et al. (2023) to generate agent behaviors.This approach ensures that the comparison of memory retrieval performance is not influenced by variations in the capabilities of the large language models.</p>
<p>In our community architecture, we designated eight agents, each assigned a representative occupation: Farmer, Grocer, Doctor, Mayor, Chef, Hunter, Blacksmith, and Carpenter.Each agent was also given a personality description relevant to their profession.This configuration enriches the complexity of the agent community while balancing the time required for simulation.</p>
<p>Furthermore, in terms of the map design, we allocated a specific home and workplace for each agent, along with a corresponding functional description to ensure alignment with the agent's profession.For instance, the agent with the occupation "Farmer" has "Fields" as their workplace, while the "Doctor" is associated with the "Clinic" as their workplace.Beyond the individual homes and workplaces of each agent, the map includes several communal locations such as the "Village Square" and "Playground" to enhance interactions among the agents.</p>
<p>As illustrated in Figure 2, to streamline the simulation process, we structured the map and temporal dimensions using a discretized, turn-based format.Temporally, we divided each day within the simulated community into 16 active hours, from 6:00 AM to 9:00 PM, with the remaining hours allocated for sleep.</p>
<p>During each hour, agents sequentially act based on their current states and observations.They plan their actions, decide whether to interact with other agents at the same location, and upon completing their actions, they determine their next destination based on the outcomes and their current states.This setup ensures a controlled environment where the impact of agent interactions and decision-making processes can be methodically analyzed.</p>
<p>During the simulation process, memory preservation and retrieval are integral to every action undertaken by an agent.Each time an agent's plan or action is determined through a prompt processed by the LLM, it requires extracting relevant memories from the agent's memory bank using a memory retrieval algorithm.This retrieval is based on the current state query to decide the agent's subsequent actions.Additionally, after each action, agents store their experiences, actions, and observations back into the memory bank, enhancing the resources available for future memory retrieval.Thus, under these simulation conditions, the critical role of the memory retrieval algorithm is further emphasized, highlighting its importance in the functionality and effectiveness of the generative agents.</p>
<p>. Auxiliary cross attention network for memory retrieval</p>
<p>In this section, we outline our methodological approach step by step, including the algorithmic details necessary to train the Auxiliary Cross Attention Network for Memory Retrieval.To commence training, we must first generate the requisite training data through simulation.Both the simulation and the subsequent training phases require a foundational memory retrieval system to facilitate the agent's memory recall processes effectively.</p>
<p>Existing memory retrieval methods for agents primarily focus on relevance and temporal validity.For instance, Hou et al. (2024) propose a human-like memory architecture with cue-based recall and dynamic memory consolidation.Retrieval models such as Alonso et al. (2024) employ vector-database mechanisms to handle time-sensitive and context-dependent queries.Similarly, Park et al. (2023) introduce a generative memory scoring framework that balances multiple retrieval criteria.To address these aspects comprehensively, we have implemented a unified memory scoring method, Weighted Memory Retrieval (WMR), as our baseline memory retrieval approach, which calculates memory retrieval scores based on the following criteria:
WMR(m) = w r • Recency(m) + w i • Importance(m) +w s • Relevance(m, q),(1)
In this formulation, Recency represents the memory decay score, which decreases hourly by a decay factor of 0.995.The Importance score is generated by LLM, determining the agent's perceived significance of the memory.Relevance measures the cosine similarity between the embedding vectors of each memory in the memory bank and the current state's query embedding.This is mathematically expressed as:
Relevance(m, q) = m • q |m||q| (2)
where m is the memory embedding vector and q is the query embedding vector.</p>
<p>After applying this scoring system, the memories with the highest scores are selected, and the top k memories are retrieved as the base memory set m ′ r .During the training of our Auxiliary Cross Attention Network, as detailed in Algorithm 1, we systematically employ a dataset consisting of the states q faced by each agent during decisionmaking and the associated memory bank M collected during the simulation.The decision-making contexts and the corresponding memory banks of each agent are converted into high-quality text embeddings using the text-embedding-ada-002 model provided by OpenAI (Neelakantan et al., 2022).This model ensures the embeddings preserve the semantic richness essential for effective training.The algorithm iteratively adjusts the network weights to optimize the retrieval of relevant memories based on the agents' current contextual needs.This optimization is facilitated by a cross attention mechanism that aligns the agent's query with the most relevant information from the memory bank.</p>
<p>Furthermore, drawing upon research in explainable deep learning (Serrano and Smith, 2019), we innovatively decided to determine the output of the model, specifically the retrieved memories, not by the weighted memories vector m weighted , but rather through the model's cross attention mechanism.The computation of attention probabilities is defined by the following equation:
P = Softmax q query • m T key α(3)
This change emphasizes the importance of interpretability in memory retrieval, allowing for a clearer understanding of how and why certain memories are retrieved based on the agents' current queries.• Generate text embeddings for queries q ∈ Q and memories m ∈ M q using the text-embedding-ada-002 model from OpenAI.</p>
<p>• Set scale factor α = √ embed_size.</p>
<p>for each training iteration do for each query q in Q do q query = QueryNetwork(q) ; // Query embedding To further refine our model's memory retrieval capabilities, the cross attention weights across different memories in the memory bank are ranked, and the top-k memories are selected as the output m r for the model's retrieved memory.</p>
<p>To ensure that retrieved memories effectively guide an agent's behavior during training, it is essential to assess their quality.While human evaluation is often considered the gold standard, it can be impractical due to its time-consuming nature, higher costs, and potential variability among evaluators.Recent studies have demonstrated that large language models (LLMs) can serve as reliable evaluators for natural language generation (NLG) tasks, exhibiting strong correlation with human judgments.For instance, Wang et al. (2023) found that ChatGPT achieved state-of-the-art or competitive correlation with human evaluations across various NLG tasks.Similarly, Chiang and Lee (2023) showed that LLMbased evaluations were consistent with expert human assessments in tasks such as open-ended story generation and adversarial attacks.Given the dynamic nature of agent interactions, LLMs offer a consistent and scalable method for evaluating memory relevance, effectively considering context and quality.</p>
<p>Therefore, we employ an LLM to compare and score the memories retrieved by our model, denoted as m r , against those retrieved using a baseline method, denoted as m ′ r .This comparison is based on the current state of the agent and the memory query state, denoted by q.The LLM evaluates the relevance of m r and m ′ r to the agent's current state and query q, assigning scores based on their contextual appropriateness and alignment with the agent's goals on a scale from 1 to 10, producing scores Score LLM and Score ′ LLM , respectively.The following loss function is then computed to train the model effectively:
output_score = Score LLM − Score ′ LLM 10 (4) loss = max(− log(output_score + 1), 0) (5)
The cross attention mechanism within our model dynamically ranks and retrieves memories based on their relevance to the given query q, leveraging the current agent state for context.This process not only enhances the responsiveness of the model to the evolving scenario within the agent environment but also aligns the retrieved memories more closely with the needs of the agent.</p>
<p>The loss function of our model is meticulously designed to optimize memory retrieval capabilities.It is defined as the logarithm of the normalized difference between scores assigned to the model-generated and baseline memories, effectively penalizing deviations from expected outcomes.This approach ensures the model not only learns to accurately retrieve relevant memories but also continually refines its retrieval process based on ground truth data, enhancing its adaptability in real-world scenarios.</p>
<p>To support this advanced training approach, the model parameters are finely tuned using the Adam optimizer.This optimizer is chosen for its ability to efficiently manage sparse gradients and adaptively adjust learning rates, which are vital for quickly converging to the most effective solutions.</p>
<p>The integration of a cross attention network, optimized through the use of large language models, further enhances the model's memory retrieval capabilities.This setup improves the efficiency and relevance of how memories are accessed within generative agents, leveraging the computational power of LLMs to refine the training process effectively.The use of LLMs to guide the training process allows our model to operate effectively with the support of advanced AI technologies, thereby making a significant contribution to the field of AI-driven memory management.</p>
<p>Results</p>
<p>. Result analysis of auxiliary cross attention network</p>
<p>For the generation of our training dataset, we simulated the behavior of a pre-defined community of eight agents over three consecutive days, each consisting of 16 h of interactions.During these simulations, agents engaged in various tasks, similar to the agent-based interactions described in Generative Agents (Park et al., 2023).Each agent's behavior was guided by ChatGPT (GPT-3.5-turbo),which generated context-specific interactions and stored the outcomes as memories.At every decision-making step, the agents' current state, past memories, and retrieved memories [ranked by the Weighted Memory Retrieval (WMR) method] were saved in the memory bank and vectorized using the text-embedding-ada-002 model, producing an embedding size of 1,536.Each training data entry included the agent's current state q, the corresponding memory bank M q , and the WMR retrieved memories m ′ r ranked based on Recency, Importance, and Relevance.</p>
<p>The structure of a single training entry consisted of the agent's query (current state), the action taken, the type of action (e.g., interaction, decision), the prompt guiding the action, and the retrieved memories at that point in time.This complete data structure captures how an agent's decision is informed by both past experiences and context-specific information, ensuring a comprehensive training process.In total, 1,280 unique training entries were generated, each encapsulating the dynamic interaction between the agents and their environments, enhancing data diversity and robustness.</p>
<p>Once the training dataset was prepared, we configured the training parameters for the memory retrieval model.We used the Adam optimizer with a learning rate of 0.001 and a batch size of 16, while the text embeddings for memory were fixed at a size of 1,536.During retrieval, the model output the top five memories ranked by attention weights.The entire training process was executed on an NVIDIA RTX 4060 GPU, which significantly accelerated the model's convergence.Each agent's interaction data, including the current state, query, and retrieved memories, were incorporated into the model to optimize the memory retrieval process for generative agents in multi-agent settings.</p>
<p>The effectiveness of the model's training under the assistance of a LLM is demonstrated in Figure 3.This figure illustrates the significant decrease in training loss across epochs.</p>
<p>As illustrated in Figure 3, the model demonstrates significant improvement under the guidance of LLMs.The training loss declines sharply from an initial value of 1.5 to 0.12.This reduction is driven by the loss function, which incorporates scores provided by the LLM based on the agent's current context, to assess the memories retrieved by both the proposed and baseline methods.This downward trend indicates the model's increasing effectiveness in adapting to the data, optimizing parameter adjustments to better capture and utilize representative memories.Consequently, this enhancement enables the model to consistently outperform the baseline method in memory scoring, contributing to the significant reduction in loss.</p>
<p>To rigorously evaluate the performance of our proposed model, we conducted test simulations spanning a complete day, covering 16 h, using both the WMR memory retrieval method and the ACAN memory retrieval method based on the fully trained Auxiliary Cross Attention Network.The test involved eight agents, each representing different professions and personalities, consistent with the setup used during the training phase.These simulations generated a total of 435 data entries for comparative analysis.Given the nascent stage of research in this area, particularly regarding LLM-based generative agents, the baseline memory retrieval method we used Park et al. (2023) represents one of the most state-of-the-art approaches currently available for comparison in agent memory retrieval.This ensures a fair and meaningful benchmark against which the performance of our ACAN model could be evaluated.</p>
<p>The assessment of the test data was conducted in the same manner as during training, where a large language model was employed in conjunction with the agent's contextual state to score the memories generated during the simulation on a scale from 1 to 10.We compared the memory retrieval scores from the ACAN model with those retrieved using the WMR memory retrieval method across all test data.</p>
<p>As illustrated in Figure 4, the results of memory retrieval using the ACAN model in comparison with the WMR method show that the ACAN method consistently achieves higher memory scores than the baseline.Specifically, the ACAN group scored an average of 5.94 with a standard deviation of 1.66, whereas the baseline group scored an average of 5.05 with a standard deviation of 1.88.Statistical tests further validate the significance of these differences, with a T-statistic of 7.44 and a corresponding P-value of 2.42 × 10 −13 , significantly below the common significance level of 0.05.This strongly indicates that the ACAN model substantially outperforms the baseline method in terms of memory retrieval effectiveness.</p>
<p>The superior performance of the ACAN model can be attributed to its dynamic cross-attention mechanism, which optimizes memory retrieval by continuously adapting to the agent's evolving state and context.This mechanism allows the ACAN model to rank memories based not only on basic relevance metrics such as recency but also on a more nuanced evaluation of the importance of past experiences, as influenced by real-time feedback from the LLM.In contrast, the WMR method relies on static retrieval strategies that do not account for these contextual factors, leading to less accurate and less relevant memory retrieval.</p>
<p>Furthermore, the reduced standard deviation in the ACAN results indicates that the model consistently performs well across different scenarios, demonstrating its robustness in diverse environments.The WMR method, with a higher standard deviation, shows more variability in its effectiveness, suggesting that its performance is more dependent on specific scenarios or task conditions.</p>
<p>These findings also have broader implications for agent behavior and decision-making.By retrieving more relevant and contextually appropriate memories, the ACAN model enhances the agent's ability to make informed decisions that closely mimic human-like responses.This, in turn, improves the quality of the agent's interactions with both the environment and other agents.The results provide empirical support for the hypothesis that the ACAN model's memory retrieval mechanism leads to more natural and effective decision-making processes in multi-agent settings.</p>
<p>In addition, a deeper analysis of the memory scores reveals that the ACAN model particularly excels in scenarios that require the integration of complex, long-term memories.This suggests that the model's cross-attention mechanism not only improves short-term relevance but also facilitates the retrieval of critical long-term memories that might otherwise be overlooked in traditional retrieval methods.This highlights the potential for the ACAN model to enhance not only immediate decision-making but also more complex tasks involving strategic planning and social interactions.</p>
<p>. Quantitative analysis of memory retrieval</p>
<p>While the training of our model and the assessments on the generated test set were conducted with the support of LLMs, we aimed to analyze the effectiveness of our proposed memory retrieval method without direct LLM intervention.For this purpose, a quantitative analysis experiment was designed, where agents received specific invitations under different memory retrieval modes, and their attendance probabilities were compared.This experimental setup allows us to evaluate how different memory retrieval strategies impact the agents' perception of external stimuli and their cognitive ability to mimic human behavior.</p>
<p>For the experimental design, each day, random agents were invited at a specified hour to attend events at designated locations, occurring for 10 h excluding sleep times.Following the agents' agreement to attend, their actual appearance at the event at the appointed time was recorded.This simulation was conducted over a span of ten days, involving eight agents under two  1, we compared the memory retrieval effectiveness of the ACAN model and the WMR method across five trials.In these experiments, agents using the ACAN model adhered to invitations 32.6% of the time on average, whereas agents using the WMR method adhered 24.6% of the time.This indicates that agents employing the ACAN model have a significantly higher likelihood of attending the events, with an average attendance rate that is eight percentage points higher than that of the WMR method.Additionally, observing the memory retrieval process of the agents revealed that those who successfully attended the events could accurately recall the relevant invitation information, further validating the ACAN model's effectiveness in enhancing memory retrieval accuracy.</p>
<p>To further quantify the statistical significance of this difference, a paired samples t-test was conducted.The t-test results yielded a T-statistic of 11.31 and a P-value of 0.00035, indicating that the observed difference in attendance rates between the two methods is highly significant (well below the common significance threshold of 0.05).This provides strong evidence that the ACAN model substantially improves the agents' responsiveness to invitations and their likelihood of attending events compared to the baseline WMR method.</p>
<p>Additionally, the standard deviations across the five trials show some variability in the results (2.881% for the ACAN method and 3.847% for the baseline method), but the ACAN model consistently outperformed the baseline, demonstrating both its stability and reliability.These findings emphasize the robustness of the ACAN-based memory retrieval approach in enhancing agents' event attendance behavior and improving their ability to respond to interactions within dynamic and complex simulated environments.</p>
<p>These findings demonstrate the robustness of the ACAN-based memory retrieval approach in enhancing agents' event attendance behavior and their responsiveness to interactions within dynamic and complex simulated environments.The integration of crossattention mechanisms in ACAN likely facilitates better contextual understanding and memory utilization, which in turn leads to more effective decision-making and engagement in scheduled events.Consequently, the higher attendance rates associated with the ACAN model not only reinforce its effectiveness but also highlight its potential to simulate complex human-like social behaviors.This makes ACAN a valuable tool for applications that require nuanced, contextually-aware decision-making, enhancing the capability of agents to navigate and adapt within multifaceted interactive settings.</p>
<p>Discussion</p>
<p>This study successfully developed and implemented a textbased generative agent simulation world, creating a community with multiple locations and agents that engage in various interactions.Based on this foundation, we designed an innovative memory retrieval system using the Auxiliary Cross Attention Network.This system simulates human behavior by ranking the attention weights between the agent's current state and memories in the memory bank, retrieving the memories most relevant to the current state.To train this model, we introduced an innovative approach by leveraging the assistance of LLMs.During training, the LLM scores the memories retrieved by our model against those retrieved by the baseline method, using these scores along with a novel loss function to train the model effectively.</p>
<p>Our evaluations leveraged a test data set generated from simulations of LLM-based agent interactions, representing a typical day in the life of these agents.This simulated environment, along with our specially designed agent invitation and attendance experiments, provided a robust framework for validating the advantages of our memory retrieval method over traditional approaches.The results from these evaluations confirm that our system significantly enhances the memory retrieval process, thereby supporting more effective decision-making in generative agents.By optimizing how memories are retrieved and utilized, our method allows agents to respond in ways that are more closely aligned with human behavior based on their current state, thereby enriching their ability to engage in and navigate complex interpersonal interactions.</p>
<p>Despite the achievements of our study, there are notable limitations to consider.The model's effectiveness relies heavily on continuous evaluations by Large Language Models (LLMs), increasing computational demands and operational costs due to LLM API token usage.Additionally, LLM feedback slows training, potentially limiting rapid development and scalability.Our evaluation method, dependent on LLMs, may not generalize across different configurations or domains, and using LLMs instead of human assessment for training and testing could affect result rigor and objectivity, raising concerns about robustness and generalizability.However, recent work such as Edge et al. (2024) demonstrates that LLMs can reliably evaluate relevance and faithfulness in RAG systems, supporting their use as cost-effective alternatives to human assessments.To further enhance robustness, especially in nuanced scenarios, incorporating human validation may serve as a valuable complement.</p>
<p>The broader impacts of our Auxiliary Cross Attention Network (ACAN) model extend significantly across the AI discipline, introducing a novel adaptive framework for memory retrieval that not only enriches theoretical models of AI agent interactions but also demonstrates substantial practical applications.Leveraging LLM assessments to shape the loss function during training is an innovative approach that significantly refines the precision of memory retrieval.This advancement holds great promise for revolutionizing human-agent interactions by enabling more natural and complex interpersonal simulations.Future research should focus on further enhancing the model's capabilities through more sophisticated neural network architectures which could advance the state of memory retrieval in AI agents.Additionally, developing autonomous feedback mechanisms will be crucial for advancing AI agents that can adapt independently to dynamic environments, thus pushing the boundaries of what is possible in Artificial General Intelligence.This focus on improving memory retrieval systems directly supports the evolution of more intelligent and responsive AI agents, paving the way for broader and more effective implementations in various AI-based domains.</p>
<p>Conclusions</p>
<p>This study has introduced the Auxiliary Cross Attention Network (ACAN), a pioneering memory retrieval system for generative agents, showcasing a significant advancement in AI agent driven by large language models (LLMs).ACAN effectively enhances agent adaptability and behavioral consistency by dynamically ranking and retrieving memories based on the agent's current state, thus addressing the critical need for sophisticated memory management mechanisms in Artificial General Intelligence.While the reliance on LLMs for training and evaluating the system poses challenges for scalability and efficiency, it simultaneously highlights the need for innovations that could decrease such dependencies and enhance the autonomy of the system.This research not only demonstrates the potential of ACAN in improving memory retrieval within varied agent interactions but also highlights the broader applicability of LLMs in advancing AI technologies.Moving forward, the focus will be on refining these methodologies to further enhance the capabilities and independence of AI agents in complex environments.</p>
<p>FIGURE</p>
<p>FIGURE Discrete time cycle of agent activities in the simulated community.The diagram illustrates the daily schedule from : AM to : PM, delineating the key activities: planning, action, and movement, underpinned by continuous perception.</p>
<p>Input:</p>
<p>Training dataset consisting of query set q, associated memory bank M q , and WMR retrieved memories m ′ r Output: Retrieved memories m r based on attention mechanism 1 Initialize:</p>
<p>P9</p>
<p>= Softmax(A) ; // Attention probabilities 6 m weighted = P • m value ; // Weighted memories 7 m r = Top-K(P, k) ; // Retrieved memories 8Calculate the Score LLM by using the LLM to compare (m r , m ′ r ), considering the query q and the current agent state.Compute the Loss using Score LLM as input to the loss function.of the cross attention network for memory retrieval.</p>
<p>FIGURE</p>
<p>FIGURETraining loss curve over epochs.</p>
<p>FIGURE</p>
<p>FIGUREScore distribution of memory retrieved by ACAN and weighted memory retrieval (WMR).</p>
<p>TABLE Detailed attendance rates across five trials for ACAN and weighted memory retrieval (WMR).
./fpsyg..MetricACANWMRTrial 135%27%Trial 236%29%Trial 329%19%Trial 432%23%Trial 531%25%Mean attendance rate32.6%24.6%Standard deviation2.881%3.847%different memory modes, generating a total of 100 invitation andattendance records.As shown in Table
Frontiers in Psychology frontiersin.org
Data availability statementThe datasets presented in this study can be found in online repositories.The names of the repository/repositories and accession number(s) can be found at: https://github.com/HongChuanYang/Training-by-LLM-Enhanced-Memory-Retrieval-for-Generative-Agents-via-ACAN.Author contributionsCH: Conceptualization, Investigation, Methodology, Software, Writing -original draft.QH: Data curation, Visualization, Writing -review &amp; editing.FundingThe author(s) declare that financial support was received for the research and/or publication of this article.This work was supported by the talent introduction project of the School of Finance and Economics at Anhui Science and Technology University, titled "Research on Data-Driven Chance Constraint Optimization Problem with Application to Portfolio Management" (grant number CJYJ202401).Conflict of interestThe authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.Generative AI statementThe author(s) declare that Gen AI was used in the creation of this manuscript.During the preparation of this work, the author(s) used ChatGPT-4o to assist in refining grammatical accuracy in the writing process.After using this tool, the author(s) thoroughly reviewed and edited the content as needed and take full responsibility for the content of the publication.Publisher's noteAll claims expressed in this article are solely those of the authors and do not necessarily represent those of their affiliated organizations, or those of the publisher, the editors and the reviewers.Any product that may be evaluated in this article, or claim that may be made by its manufacturer, is not guaranteed or endorsed by the publisher.
Agent-oriented software engineering methodologies: analysis and future directions. R Abdalla, A Mishra, 10.1155/2021/1629419Complexity. 202116294192021</p>
<p>. J Achiam, S Adler, S Agarwal, L Ahmad, I Akkaya, F Aleman, </p>
<p>L , 10.48550/arXiv.2303.08774arXiv:2303.08774GPT-4 technical report. 2023arXiv preprint</p>
<p>Toward conversational agents with context and time sensitive long-term memory. N Alonso, T Figliolia, A Ndirango, B Millidge, 10.48550/arXiv.2406.00057arXiv:2406.000572024arXiv preprint</p>
<p>Y Bang, S Cahyawijaya, N Lee, W Dai, D Su, B Wilie, 10.18653/v1/2023.ijcnlp-main.45arXiv:2302.04023doi: 10.18653A multitask, multilingual, multimodal evaluation of chatGPT on reasoning, hallucination, and interactivity. 2023arXiv preprint</p>
<p>The role of emotion in believable agents. J Bates, 10.1145/176789.176803Commun. ACM. 371994</p>
<p>. T Brown, B Mann, N Ryder, M Subbiah, J D Kaplan, P Dhariwal, 2020</p>
<p>Language models are few-shot learners. 10.48550/arXiv.2005.14165Adv. Neural Inf. Process. Syst. 33</p>
<p>. A Bulatov, Y Kuratov, M Burtsev, 2022Recurrent memory transformer</p>
<p>. 10.5555/3600270.3601075Adv. Neural Inf. Process. Syst. 35</p>
<p>. M S Burtsev, Y Kuratov, A Peganov, G V Sapunov, 2020</p>
<p>Dungeons and dragons as a dialog challenge for artificial intelligence. C Callison-Burch, G S Tomar, L J Martin, D Ippolito, S Bailis, D Reitter, 10.18653/v1/2022.emnlp-main.637arXiv:2006.11527doi: 10.18653Memory transformer. 2022arXiv preprint</p>
<p>Y Cao, S Li, Y Liu, Z Yan, Y Dai, P S Yu, 10.48550/arXiv.2303.04226arXiv:2303.04226A comprehensive survey of AI-generated content (AIGC): a history of generative ai from gan to chatGPT. 2023arXiv preprint</p>
<p>Can large language models be an alternative to human evaluations?. C.-H Chiang, H.-Y Lee, 10.48550/arXiv.2305.01937arXiv:2305.019372023arXiv preprint</p>
<p>From local to global: a graph rag approach to query-focused summarization. D Edge, H Trinh, N Cheng, J Bradley, A Chao, A Mody, 10.48550/arXiv.2404.16130arXiv:2404.161302024arXiv preprint</p>
<p>Procedural generation of interactive stories using language models. J Freiknecht, W Effelsberg, 10.1145/3402942.3409599Proceedings of the 15th International Conference on the Foundations of Digital Games. the 15th International Conference on the Foundations of Digital GamesNew York, NYAssociation for Computing Machinery2020</p>
<p>Multi-agent deep reinforcement learning: a survey. S Gronauer, K Diepold, M Guo, J Ainslie, D Uthus, S Ontanon, J Ni, Y.-H Sung, 10.18653/v1/2022.findings-naacl.55arXiv:2112.07916doi: 10.18653/v1/2022.findings-naacl.55Longt5: efficient text-to-text transformer for long sequences. 2022. 202155arXiv preprint</p>
<p>my agent understands me better: integrating dynamic human-like memory recall and consolidation in LLM-based agents. Y Hou, H Tamoto, H Miyashita, 10.1145/3613905.3650839Extended Abstracts of the CHI Conference on Human Factors in Computing Systems. 2024</p>
<p>ChatDB: augmenting LLMS with databases as their symbolic memory. C Hu, J Fu, C Du, S Luo, J Zhao, H Zhao, 10.48550/arXiv.2306.03901arXiv:2306.039012023arXiv preprint</p>
<p>Memory sandbox: transparent and interactive memory management for conversational agents. Z Huang, S Gutierrez, H Kamana, S Macneil, 10.1145/3586182.3615796Adjunct Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology. New York, NYAssociation for Computing Machinery2023</p>
<p>Is chatGPT a good translator? A preliminary study. W Jiao, W Wang, J.-T Huang, X Wang, Z Tu, 10.48550/arXiv.2301.08745arXiv:2301.08745.0874512023arXiv preprint</p>
<p>RAP: retrieval-augmented planning with contextual memory for multimodal LLM agents. T Kagaya, T J Yuan, Y Lou, J Karlekar, S Pranata, A Kinose, 10.48550/arXiv.2402.03610arXiv:2402.036102024arXiv preprint</p>
<p>Demonstrate-search-predict: composing retrieval and language models for knowledge-intensive NLP. O Khattab, K Santhanam, X L Li, D Hall, P Liang, C Potts, 10.48550/arXiv.2212.14024arXiv:2212.140242022arXiv preprint</p>
<p>Human-level AI's killer application: interactive computer games. J Laird, M Vanlent, 10.1609/aimag.v22i2.1558AI Mag. 222001</p>
<p>Unleashing infinite-length input capacity for large-scale language models with self-controlled memory system. X Liang, B Wang, H Huang, S Wu, P Wu, L Lu, 10.48550/arXiv.2304.13343arXiv:2304.133432023arXiv preprint</p>
<p>Agentsims: an open-source sandbox for large language model evaluation. J Lin, H Zhao, A Zhang, Y Wu, H Ping, Q Chen, 10.48550/arXiv.2308.04026arXiv:2308.040262023arXiv preprint</p>
<p>. R Liu, R Yang, C Jia, G Zhang, D Zhou, A M Dai, 2023</p>
<p>Training socially aligned language models in simulated human society. 10.48550/arXiv.2305.16960arXiv:2305.16960arXiv preprint</p>
<p>Ret-LLM: towards a general read-write memory for large language models. A Modarressi, A Imani, M Fayyaz, H Schütze, 10.48550/arXiv.2305.14322arXiv:2305.143222023arXiv preprint</p>
<p>Random-access infinite context length for transformers. A Mohtashami, M Jaggi, 10.48550/arXiv.2305.16300Adv. Neural Inf. Process. Syst. 362023</p>
<p>Adapting large language models to narrative content. E Musacchio, L Siciliani, P Basile, G Semeraro, A Neelakantan, T Xu, R Puri, A Radford, J M Han, J Tworek, 10.48550/arXiv.2201.10005arXiv:2201.10005Text and code embeddings by contrastive pre-training. 2024. 20226arXiv preprint</p>
<p>Extending cognitive architecture with episodic memory. A M Nuxoll, J E Laird, AAAI. Palo Alto, CAAAAI Press2007. 2022. April 3, 2023Introducing ChatGPT. Available online at</p>
<p>Efficient classification of long documents using transformers. H H Park, Y Vyas, K Shah, 10.18653/v1/2022.acl-short.79arXiv:2203.112582022arXiv preprint</p>
<p>. J S Park, J O'brien, C J Cai, M R Morris, P Liang, M S Bernstein, 2023</p>
<p>Generative agents: interactive simulacra of human behavior. 10.1145/3586183.3606763Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology. the 36th Annual ACM Symposium on User Interface Software and TechnologyNew York, NYAssociation for Computing Machinery</p>
<p>Social simulacra: creating populated prototypes for social computing systems. J S Park, L Popowski, C Cai, M R Morris, P Liang, M S Bernstein, 10.1145/3526113.3545616Proceedings of the 35th Annual ACM Symposium on User Interface Software and Technology. the 35th Annual ACM Symposium on User Interface Software and TechnologyNew York, NYAssociation for Computing Machinery2022</p>
<p>Improving coordination in small-scale multiagent deep reinforcement learning through memory-driven communication. E Pesce, G Montana, 10.1007/s10994-019-05864-5Mach. Learn. 1092020</p>
<p>. C Qian, X Cong, C Yang, W Chen, Y Su, J Xu, 2023</p>
<p>10.48550/arXiv.2307.07924arXiv:2307.07924Communicative agents for software development. arXiv preprint</p>
<p>Artificial Intelligence: A Modern Approach. S J Russell, P Norvig, 10.48550/arXiv.2301.04589arXiv:2301.04589Memory augmented large language models are computationally universal. Pearson, D Schuurmans, Upper Saddle River, NJ2016. 2023arXiv preprint</p>
<p>Reconsolidation of human memory: brain mechanisms and clinical relevance. L Schwabe, K Nader, J C Pruessner, 10.1016/j.biopsych.2014.03.008Biol. Psychiatry. 762014</p>
<p>An agent-based model of opinion polarization driven by emotions. F Schweitzer, T Krivachy, D Garcia, 10.31235/osf.io/8m2wqComplexity. 52820352020. 2020</p>
<p>S Serrano, N A Smith, 10.48550/arXiv.1906.03731arXiv:1906.03731Is attention interpretable?. 2019arXiv preprint</p>
<p>Reflexion: language agents with verbal reinforcement learning. N Shinn, F Cassano, A Gopinath, K Narasimhan, S Yao, 10.5555/3666122.3666499Adv. Neural Inf. Process. Syst. 362023</p>
<p>Mechanisms of memory. L R Squire, 10.1126/science.3086978Science. 2321986</p>
<p>X-former: in-memory acceleration of transformers. S Sridharan, J R Stevens, K Roy, A Raghunathan, 10.1109/TVLSI.2023.3282046IEEE Transactions on Very Large Scale Integration (VLSI) Systems. 312023</p>
<p>Attention is all you need. A Vaswani, N Shazeer, N Parmar, J Uszkoreit, L Jones, A N Gomez, 10.5555/3295222.3295349Adv. Neural Inf. Process. Syst. 302017</p>
<p>J Wang, Y Liang, F Meng, Z Sun, H Shi, Z Li, 10.18653/v1/2023.newsum-1.1arXiv:2303.04048Is chatGPT a good nlg evaluator? A preliminary study. 2023arXiv preprint</p>
<p>A survey on large language model based autonomous agents. L Wang, C Ma, X Feng, Z Zhang, H Yang, J Zhang, 10.1007/s11704-024-40231-1Front. Comput. Sci. 181863452024</p>
<p>J Wei, Y Tay, R Bommasani, C Raffel, B Zoph, S Borgeaud, 10.48550/arXiv.2206.07682arXiv:2206.07682Emergent abilities of large language models. 2022arXiv preprint</p>
<p>. M Wooldridge, N R Jennings, 1995Intelligent agents: theory and practice</p>
<p>. 10.1007/3-540-58855-8Knowl. Eng. Rev. 10</p>
<p>Promptchainer: chaining large language model prompts through visual programming. T Wu, E Jiang, A Donsbach, J Gray, A Molina, M Terry, 10.1145/3491101.3519729CHI Conference on Human Factors in Computing Systems Extended Abstracts. 2022</p>
<p>Memorizing transformers. Y Wu, M N Rabe, D Hutchins, C Szegedy, Z Xi, W Chen, X Guo, W He, Y Ding, B Hong, 10.48550/arXiv.2309.07864arXiv:2203.08913The rise and potential of large language model based agents: a survey. 2022. 2023arXiv preprint</p>
<p>Harnessing the power of llms in practice: a survey on chatGPT and beyond. J Yang, H Jin, R Tang, X Han, Q Feng, H Jiang, 10.1145/3649506ACM Trans. Knowl. Discov. Data. 182024</p>
<p>Game AI revisited. G N Yannakakis, 10.1145/2212908.2212954Proceedings of the 9th Conference on Computing Frontiers. the 9th Conference on Computing Frontiers2012</p>
<p>Finmem: a performance-enhanced llm trading agent with layered memory and character design. Y Yu, H Li, Z Chen, Y Jiang, Y Li, D Zhang, 10.1609/aaaiss.v3i1.31290Proc. AAAI Symp. Ser. 3. AAAI Symp. Ser. 32024</p>
<p>Stanford Encyclopedia of Philosophy. E N Zalta, U Nodelman, C Allen, Z Bo, X Ma, C Li, R Chen, X Dai, Q , 10.48550/arXiv.2404.13501arXiv:2404.13501A survey on the memory mechanism of large language model based agents. Stanford, CA1995. 2024The Metaphysics Research Lab, Philosophy Department, Stanford University. Zhang,arXiv preprint</p>
<p>Expel: LLM agents are experiential learners. A Zhao, D Huang, Q Xu, M Lin, Y.-J Liu, G Huang, 10.1609/aaai.v38i17.29936Proc. AAAI Conf. AAAI Conf2024. 19632-1964238</p>
<p>Memorybank: enhancing large language models with long-term memory. W Zhong, L Guo, Q Gao, H Ye, Y Wang, 10.1609/aaai.v38i17.29946Proc. AAAI Conf. AAAI Conf2024. 19724-1973138</p>
<p>X Zhou, G Li, Z Liu, 10.48550/arXiv.2308.05481arXiv:2308.05481LLM as DBA. 2023arXiv preprint</p>            </div>
        </div>

    </div>
</body>
</html>