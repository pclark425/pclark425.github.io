<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-6491 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-6491</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-6491</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-129.html">extraction-schema-129</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' reasoning methods, the diversity or similarity of reasoning styles, the tasks or benchmarks used to evaluate them, performance results, and any direct comparisons between diverse and similar reasoning approaches.</div>
                <p><strong>Paper ID:</strong> paper-272690308</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2409.10038v4.pdf" target="_blank">On the Diagram of Thought</a></p>
                <p><strong>Paper Abstract:</strong> Large Language Models (LLMs) excel at many tasks but often falter on complex problems that require structured, multi-step reasoning. We introduce the Diagram of Thought (DoT), a new framework that enables a single LLM to build and navigate a mental map of its reasoning. Instead of thinking in a straight line, the model constructs a dynamic diagram of ideas, where it can propose different lines of thought, critique its own steps, and synthesize validated insights into a final conclusion. This entire process is self-contained within the model, making it highly efficient by avoiding the complex external controllers or search algorithms required by other methods. To ensure the reliability of this process, we ground DoT in a rigorous mathematical framework from category theory. This foundation guarantees that the way the model combines information is logical, consistent, and robust, regardless of the order in which ideas were explored. The result is a more powerful and transparent reasoning process that produces a fully auditable, step-by-step trace of the LLM's thinking, bridging the gap between fluent language and formal reasoning.</p>
                <p><strong>Cost:</strong> 0.014</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e6491.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e6491.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' reasoning methods, the diversity or similarity of reasoning styles, the tasks or benchmarks used to evaluate them, performance results, and any direct comparisons between diverse and similar reasoning approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>DoT</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Diagram of Thought</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A framework that has a single auto-regressive LLM internally construct and traverse a typed DAG of roles (Problem, Proposer, Critic, Summarizer) via role tokens to propose, critique, refine, and synthesize reasoning steps; synthesis is normatively modeled as a categorical colimit (meet-plus-closure) yielding formal consistency and invariance guarantees.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>unspecified auto-regressive LLM</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_name</strong></td>
                            <td>Diagram of Thought (DoT)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_type</strong></td>
                            <td>DAG-based / branching (internalized graph)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_style_diversity</strong></td>
                            <td>diverse</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>illustrative examples (QF-LIA instantiation / synthetic traces)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Structured multi‑step reasoning requiring parallel lines of thought, critique, refinement and synthesis (illustrated with logical/arithmetic examples and a QF-LIA instantiation).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_target_method</strong></td>
                            <td>Chain-of-Thought; Tree-of-Thought; Graph-of-Thought; Cumulative Reasoning</td>
                        </tr>
                        <tr>
                            <td><strong>performance_difference</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>analysis_notes</strong></td>
                            <td>DoT internally encodes branching reasoning within a single LLM using role tokens and a typed serialization plus a lightweight validator; critiques validate or invalidate proposer nodes with monotone state updates; summarization is formalized as the colimit (meet-plus-closure) of validated propositions, giving formal guarantees (consistency, order-invariance, robustness to redundant evidence). The paper argues DoT is strictly more expressive than linear CoT in the posetal case, avoids external search controllers required by ToT/GoT, and provides auditability and a clear normative target for training (e.g., auxiliary losses to align summarizers to colimit semantics). No empirical benchmarked performance numbers or statistical tests are reported.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_study_present</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'On the Diagram of Thought', 'publication_date_yy_mm': '2024-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6491.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e6491.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' reasoning methods, the diversity or similarity of reasoning styles, the tasks or benchmarks used to evaluate them, performance results, and any direct comparisons between diverse and similar reasoning approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>CoT</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Chain-of-Thought prompting</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A prompting method that elicits step-by-step linear reasoning traces from LLMs to improve complex problem solving by exposing intermediate steps.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Chain of thought prompting elicits reasoning in large language models.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>various LLMs (few-shot prompting)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_name</strong></td>
                            <td>Chain-of-Thought (CoT)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_type</strong></td>
                            <td>sequential</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_style_diversity</strong></td>
                            <td>single style</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Eliciting intermediate step-by-step reasoning for complex problems (general-purpose reasoning tasks).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_target_method</strong></td>
                            <td>Diagram of Thought (DoT)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_difference</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>analysis_notes</strong></td>
                            <td>Paper describes CoT as linearizing reasoning which improves transparency but is rigid: it cannot naturally express parallel hypotheses or backtracking without restarting. DoT is presented as a generalization where a linear CoT is a special-case chain; DoT can represent branching validated evidence that CoT cannot faithfully encode.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_study_present</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'On the Diagram of Thought', 'publication_date_yy_mm': '2024-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6491.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e6491.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' reasoning methods, the diversity or similarity of reasoning styles, the tasks or benchmarks used to evaluate them, performance results, and any direct comparisons between diverse and similar reasoning approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ToT</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Tree-of-Thought</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A framework that organizes intermediate states as nodes in a tree and uses search algorithms (e.g., BFS/DFS) guided by heuristics to explore multiple reasoning paths, enabling systematic backtracking and exploration.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Tree of thoughts: Deliberate problem solving with large language models.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>various LLMs (controller-managed search)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_name</strong></td>
                            <td>Tree-of-Thought (ToT)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_type</strong></td>
                            <td>tree-search</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_style_diversity</strong></td>
                            <td>diverse</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Deliberate problem solving via explicit tree search over partial solution nodes (suitable for combinatorial and multi-step tasks).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_target_method</strong></td>
                            <td>Diagram of Thought (DoT)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_difference</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>analysis_notes</strong></td>
                            <td>ToT enables branching and search but usually requires an external controller for search management and pruning; DoT contrasts by internalizing graph construction/navigation inside a single LLM and using natural language critiques rather than simple heuristic scores.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_study_present</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'On the Diagram of Thought', 'publication_date_yy_mm': '2024-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6491.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e6491.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' reasoning methods, the diversity or similarity of reasoning styles, the tasks or benchmarks used to evaluate them, performance results, and any direct comparisons between diverse and similar reasoning approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GoT</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Graph-of-Thought</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A generalization of tree-based reasoning where intermediate reasoning states form arbitrary graphs allowing merging of paths and more complex dependencies.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Graph of thoughts: Solving elaborate problems with large language models.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>various LLMs (controller-managed graph systems)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_name</strong></td>
                            <td>Graph-of-Thought (GoT)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_type</strong></td>
                            <td>graph-based</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_style_diversity</strong></td>
                            <td>diverse</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Complex multi-step reasoning where merging partial solutions and modeling intricate dependencies is beneficial.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_target_method</strong></td>
                            <td>Diagram of Thought (DoT)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_difference</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>analysis_notes</strong></td>
                            <td>GoT generalizes ToT to arbitrary graphs and can merge reasoning paths, but often requires external graph management; DoT provides similar expressive power while keeping graph construction internal to the model via role tokens and typed serialization.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_study_present</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'On the Diagram of Thought', 'publication_date_yy_mm': '2024-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6491.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e6491.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' reasoning methods, the diversity or similarity of reasoning styles, the tasks or benchmarks used to evaluate them, performance results, and any direct comparisons between diverse and similar reasoning approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Self-consistency</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Self-consistency sampling</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An ensemble-style decoding method that samples multiple reasoning paths (CoT traces) and aggregates answers (e.g., majority voting) to improve robustness.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Self-consistency improves chain of thought reasoning in language models.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>various LLMs using sampling</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_name</strong></td>
                            <td>Self-consistency</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_type</strong></td>
                            <td>ensemble (sampling + aggregation)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_style_diversity</strong></td>
                            <td>diverse</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Improve reasoning correctness by sampling diverse chains of thought and picking a consensus answer.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_target_method</strong></td>
                            <td>Diagram of Thought (DoT)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_difference</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>analysis_notes</strong></td>
                            <td>Self-consistency implicitly acknowledges path diversity by sampling multiple CoT traces and aggregating, but lacks explicit intermediate critique/refinement mechanisms; DoT provides explicit structured critique and refinement inside a single run, enabling synthesis aligned with categorical semantics.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_study_present</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'On the Diagram of Thought', 'publication_date_yy_mm': '2024-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6491.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e6491.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' reasoning methods, the diversity or similarity of reasoning styles, the tasks or benchmarks used to evaluate them, performance results, and any direct comparisons between diverse and similar reasoning approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>CR</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Cumulative Reasoning</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A multi-agent, role-specialized approach where multiple LLM instances or prompts play distinct roles (proposer, verifier, etc.) and interact iteratively to refine solutions.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Cumulative reasoning with large language models.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>multi-instance LLM setups (role-specialized)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_name</strong></td>
                            <td>Cumulative Reasoning (CR)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_type</strong></td>
                            <td>multi-agent / role-based</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_style_diversity</strong></td>
                            <td>mixed</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Iterative collaborative refinement using specialized roles to propose and verify intermediate reasoning steps.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_target_method</strong></td>
                            <td>Diagram of Thought (DoT)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_difference</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>analysis_notes</strong></td>
                            <td>CR uses explicit role specialization and multi-agent interaction but incurs coordination overhead and external orchestration; DoT adopts explicit roles (proposer/critic/summarizer) but integrates them into a single LLM via conditional generation to avoid multi-agent coordination costs.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_study_present</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'On the Diagram of Thought', 'publication_date_yy_mm': '2024-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6491.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e6491.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models' reasoning methods, the diversity or similarity of reasoning styles, the tasks or benchmarks used to evaluate them, performance results, and any direct comparisons between diverse and similar reasoning approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Self-Refine</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Self-Refine (iterative self-feedback)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An approach where an LLM critiques and refines its own outputs iteratively, typically applied to whole-output refinement rather than structured intermediate-step refinement.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Self-refine: Iterative refinement with self-feedback.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>unspecified LLM using iterative self-feedback</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_name</strong></td>
                            <td>Self-Refine</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_method_type</strong></td>
                            <td>iterative refinement</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_style_diversity</strong></td>
                            <td>homogeneous</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Iteratively critique and improve a generated output via self-feedback loops.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_target_method</strong></td>
                            <td>Diagram of Thought (DoT)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_difference</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>analysis_notes</strong></td>
                            <td>Self-Refine focuses on refining whole outputs and lacks the structured, typed intermediate-node validation that DoT provides; DoT applies critique at intermediate steps with monotone validation and structured serialization enabling categorical interpretation.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_study_present</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'On the Diagram of Thought', 'publication_date_yy_mm': '2024-09'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Chain of thought prompting elicits reasoning in large language models. <em>(Rating: 2)</em></li>
                <li>Tree of thoughts: Deliberate problem solving with large language models. <em>(Rating: 2)</em></li>
                <li>Graph of thoughts: Solving elaborate problems with large language models. <em>(Rating: 2)</em></li>
                <li>Self-consistency improves chain of thought reasoning in language models. <em>(Rating: 2)</em></li>
                <li>Cumulative reasoning with large language models. <em>(Rating: 2)</em></li>
                <li>Self-refine: Iterative refinement with self-feedback. <em>(Rating: 2)</em></li>
                <li>On the power of foundation models. <em>(Rating: 1)</em></li>
                <li>Towards reasoning in large language models: A survey. <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-6491",
    "paper_id": "paper-272690308",
    "extraction_schema_id": "extraction-schema-129",
    "extracted_data": [
        {
            "name_short": "DoT",
            "name_full": "Diagram of Thought",
            "brief_description": "A framework that has a single auto-regressive LLM internally construct and traverse a typed DAG of roles (Problem, Proposer, Critic, Summarizer) via role tokens to propose, critique, refine, and synthesize reasoning steps; synthesis is normatively modeled as a categorical colimit (meet-plus-closure) yielding formal consistency and invariance guarantees.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "unspecified auto-regressive LLM",
            "model_size": null,
            "reasoning_method_name": "Diagram of Thought (DoT)",
            "reasoning_method_type": "DAG-based / branching (internalized graph)",
            "reasoning_style_diversity": "diverse",
            "benchmark_name": "illustrative examples (QF-LIA instantiation / synthetic traces)",
            "task_description": "Structured multi‑step reasoning requiring parallel lines of thought, critique, refinement and synthesis (illustrated with logical/arithmetic examples and a QF-LIA instantiation).",
            "performance_metric": "",
            "performance_value": null,
            "comparison_target_method": "Chain-of-Thought; Tree-of-Thought; Graph-of-Thought; Cumulative Reasoning",
            "performance_difference": null,
            "statistical_significance": null,
            "analysis_notes": "DoT internally encodes branching reasoning within a single LLM using role tokens and a typed serialization plus a lightweight validator; critiques validate or invalidate proposer nodes with monotone state updates; summarization is formalized as the colimit (meet-plus-closure) of validated propositions, giving formal guarantees (consistency, order-invariance, robustness to redundant evidence). The paper argues DoT is strictly more expressive than linear CoT in the posetal case, avoids external search controllers required by ToT/GoT, and provides auditability and a clear normative target for training (e.g., auxiliary losses to align summarizers to colimit semantics). No empirical benchmarked performance numbers or statistical tests are reported.",
            "ablation_study_present": false,
            "uuid": "e6491.0",
            "source_info": {
                "paper_title": "On the Diagram of Thought",
                "publication_date_yy_mm": "2024-09"
            }
        },
        {
            "name_short": "CoT",
            "name_full": "Chain-of-Thought prompting",
            "brief_description": "A prompting method that elicits step-by-step linear reasoning traces from LLMs to improve complex problem solving by exposing intermediate steps.",
            "citation_title": "Chain of thought prompting elicits reasoning in large language models.",
            "mention_or_use": "mention",
            "model_name": "various LLMs (few-shot prompting)",
            "model_size": null,
            "reasoning_method_name": "Chain-of-Thought (CoT)",
            "reasoning_method_type": "sequential",
            "reasoning_style_diversity": "single style",
            "benchmark_name": "",
            "task_description": "Eliciting intermediate step-by-step reasoning for complex problems (general-purpose reasoning tasks).",
            "performance_metric": "",
            "performance_value": null,
            "comparison_target_method": "Diagram of Thought (DoT)",
            "performance_difference": null,
            "statistical_significance": null,
            "analysis_notes": "Paper describes CoT as linearizing reasoning which improves transparency but is rigid: it cannot naturally express parallel hypotheses or backtracking without restarting. DoT is presented as a generalization where a linear CoT is a special-case chain; DoT can represent branching validated evidence that CoT cannot faithfully encode.",
            "ablation_study_present": false,
            "uuid": "e6491.1",
            "source_info": {
                "paper_title": "On the Diagram of Thought",
                "publication_date_yy_mm": "2024-09"
            }
        },
        {
            "name_short": "ToT",
            "name_full": "Tree-of-Thought",
            "brief_description": "A framework that organizes intermediate states as nodes in a tree and uses search algorithms (e.g., BFS/DFS) guided by heuristics to explore multiple reasoning paths, enabling systematic backtracking and exploration.",
            "citation_title": "Tree of thoughts: Deliberate problem solving with large language models.",
            "mention_or_use": "mention",
            "model_name": "various LLMs (controller-managed search)",
            "model_size": null,
            "reasoning_method_name": "Tree-of-Thought (ToT)",
            "reasoning_method_type": "tree-search",
            "reasoning_style_diversity": "diverse",
            "benchmark_name": "",
            "task_description": "Deliberate problem solving via explicit tree search over partial solution nodes (suitable for combinatorial and multi-step tasks).",
            "performance_metric": "",
            "performance_value": null,
            "comparison_target_method": "Diagram of Thought (DoT)",
            "performance_difference": null,
            "statistical_significance": null,
            "analysis_notes": "ToT enables branching and search but usually requires an external controller for search management and pruning; DoT contrasts by internalizing graph construction/navigation inside a single LLM and using natural language critiques rather than simple heuristic scores.",
            "ablation_study_present": false,
            "uuid": "e6491.2",
            "source_info": {
                "paper_title": "On the Diagram of Thought",
                "publication_date_yy_mm": "2024-09"
            }
        },
        {
            "name_short": "GoT",
            "name_full": "Graph-of-Thought",
            "brief_description": "A generalization of tree-based reasoning where intermediate reasoning states form arbitrary graphs allowing merging of paths and more complex dependencies.",
            "citation_title": "Graph of thoughts: Solving elaborate problems with large language models.",
            "mention_or_use": "mention",
            "model_name": "various LLMs (controller-managed graph systems)",
            "model_size": null,
            "reasoning_method_name": "Graph-of-Thought (GoT)",
            "reasoning_method_type": "graph-based",
            "reasoning_style_diversity": "diverse",
            "benchmark_name": "",
            "task_description": "Complex multi-step reasoning where merging partial solutions and modeling intricate dependencies is beneficial.",
            "performance_metric": "",
            "performance_value": null,
            "comparison_target_method": "Diagram of Thought (DoT)",
            "performance_difference": null,
            "statistical_significance": null,
            "analysis_notes": "GoT generalizes ToT to arbitrary graphs and can merge reasoning paths, but often requires external graph management; DoT provides similar expressive power while keeping graph construction internal to the model via role tokens and typed serialization.",
            "ablation_study_present": false,
            "uuid": "e6491.3",
            "source_info": {
                "paper_title": "On the Diagram of Thought",
                "publication_date_yy_mm": "2024-09"
            }
        },
        {
            "name_short": "Self-consistency",
            "name_full": "Self-consistency sampling",
            "brief_description": "An ensemble-style decoding method that samples multiple reasoning paths (CoT traces) and aggregates answers (e.g., majority voting) to improve robustness.",
            "citation_title": "Self-consistency improves chain of thought reasoning in language models.",
            "mention_or_use": "mention",
            "model_name": "various LLMs using sampling",
            "model_size": null,
            "reasoning_method_name": "Self-consistency",
            "reasoning_method_type": "ensemble (sampling + aggregation)",
            "reasoning_style_diversity": "diverse",
            "benchmark_name": "",
            "task_description": "Improve reasoning correctness by sampling diverse chains of thought and picking a consensus answer.",
            "performance_metric": "",
            "performance_value": null,
            "comparison_target_method": "Diagram of Thought (DoT)",
            "performance_difference": null,
            "statistical_significance": null,
            "analysis_notes": "Self-consistency implicitly acknowledges path diversity by sampling multiple CoT traces and aggregating, but lacks explicit intermediate critique/refinement mechanisms; DoT provides explicit structured critique and refinement inside a single run, enabling synthesis aligned with categorical semantics.",
            "ablation_study_present": false,
            "uuid": "e6491.4",
            "source_info": {
                "paper_title": "On the Diagram of Thought",
                "publication_date_yy_mm": "2024-09"
            }
        },
        {
            "name_short": "CR",
            "name_full": "Cumulative Reasoning",
            "brief_description": "A multi-agent, role-specialized approach where multiple LLM instances or prompts play distinct roles (proposer, verifier, etc.) and interact iteratively to refine solutions.",
            "citation_title": "Cumulative reasoning with large language models.",
            "mention_or_use": "mention",
            "model_name": "multi-instance LLM setups (role-specialized)",
            "model_size": null,
            "reasoning_method_name": "Cumulative Reasoning (CR)",
            "reasoning_method_type": "multi-agent / role-based",
            "reasoning_style_diversity": "mixed",
            "benchmark_name": "",
            "task_description": "Iterative collaborative refinement using specialized roles to propose and verify intermediate reasoning steps.",
            "performance_metric": "",
            "performance_value": null,
            "comparison_target_method": "Diagram of Thought (DoT)",
            "performance_difference": null,
            "statistical_significance": null,
            "analysis_notes": "CR uses explicit role specialization and multi-agent interaction but incurs coordination overhead and external orchestration; DoT adopts explicit roles (proposer/critic/summarizer) but integrates them into a single LLM via conditional generation to avoid multi-agent coordination costs.",
            "ablation_study_present": false,
            "uuid": "e6491.5",
            "source_info": {
                "paper_title": "On the Diagram of Thought",
                "publication_date_yy_mm": "2024-09"
            }
        },
        {
            "name_short": "Self-Refine",
            "name_full": "Self-Refine (iterative self-feedback)",
            "brief_description": "An approach where an LLM critiques and refines its own outputs iteratively, typically applied to whole-output refinement rather than structured intermediate-step refinement.",
            "citation_title": "Self-refine: Iterative refinement with self-feedback.",
            "mention_or_use": "mention",
            "model_name": "unspecified LLM using iterative self-feedback",
            "model_size": null,
            "reasoning_method_name": "Self-Refine",
            "reasoning_method_type": "iterative refinement",
            "reasoning_style_diversity": "homogeneous",
            "benchmark_name": "",
            "task_description": "Iteratively critique and improve a generated output via self-feedback loops.",
            "performance_metric": "",
            "performance_value": null,
            "comparison_target_method": "Diagram of Thought (DoT)",
            "performance_difference": null,
            "statistical_significance": null,
            "analysis_notes": "Self-Refine focuses on refining whole outputs and lacks the structured, typed intermediate-node validation that DoT provides; DoT applies critique at intermediate steps with monotone validation and structured serialization enabling categorical interpretation.",
            "ablation_study_present": false,
            "uuid": "e6491.6",
            "source_info": {
                "paper_title": "On the Diagram of Thought",
                "publication_date_yy_mm": "2024-09"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Chain of thought prompting elicits reasoning in large language models.",
            "rating": 2,
            "sanitized_title": "chain_of_thought_prompting_elicits_reasoning_in_large_language_models"
        },
        {
            "paper_title": "Tree of thoughts: Deliberate problem solving with large language models.",
            "rating": 2,
            "sanitized_title": "tree_of_thoughts_deliberate_problem_solving_with_large_language_models"
        },
        {
            "paper_title": "Graph of thoughts: Solving elaborate problems with large language models.",
            "rating": 2,
            "sanitized_title": "graph_of_thoughts_solving_elaborate_problems_with_large_language_models"
        },
        {
            "paper_title": "Self-consistency improves chain of thought reasoning in language models.",
            "rating": 2,
            "sanitized_title": "selfconsistency_improves_chain_of_thought_reasoning_in_language_models"
        },
        {
            "paper_title": "Cumulative reasoning with large language models.",
            "rating": 2,
            "sanitized_title": "cumulative_reasoning_with_large_language_models"
        },
        {
            "paper_title": "Self-refine: Iterative refinement with self-feedback.",
            "rating": 2,
            "sanitized_title": "selfrefine_iterative_refinement_with_selffeedback"
        },
        {
            "paper_title": "On the power of foundation models.",
            "rating": 1,
            "sanitized_title": "on_the_power_of_foundation_models"
        },
        {
            "paper_title": "Towards reasoning in large language models: A survey.",
            "rating": 1,
            "sanitized_title": "towards_reasoning_in_large_language_models_a_survey"
        }
    ],
    "cost": 0.01402175,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>On the Diagram of Thought
29 Aug 2025</p>
<p>Yifan Zhang 
IIIS
Tsinghua University</p>
<p>Yang Yuan 
IIIS
Tsinghua University</p>
<p>Shanghai Qi Zhi Institute</p>
<p>Chi-Chih Yao 
IIIS
Tsinghua University</p>
<p>Shanghai Qi Zhi Institute</p>
<p>On the Diagram of Thought
29 Aug 2025CEB473E9D96A1CF61A68518F176E082BarXiv:2409.10038v4[cs.CL]
Large Language Models (LLMs) excel at many tasks but often falter on complex problems that require structured, multi-step reasoning.We introduce the Diagram of Thought (DoT), a new framework that enables a single LLM to build and navigate a mental map of its reasoning.Instead of thinking in a straight line, the model constructs a dynamic diagram of ideas, where it can propose different lines of thought, critique its own steps, and synthesize validated insights into a final conclusion.This entire process is self-contained within the model, making it highly efficient by avoiding the complex external controllers or search algorithms required by other methods.To ensure the reliability of this process, we ground DoT in a rigorous mathematical framework from category theory.This foundation guarantees that the way the model combines information is logical, consistent, and robust, regardless of the order in which ideas were explored.The result is a more powerful and transparent reasoning process that produces a fully auditable, step-by-step trace of the LLM's thinking, bridging the gap between fluent language and formal reasoning.</p>
<p>Introduction</p>
<p>Large Language Models (LLMs) (Brown et al., 2020;Touvron et al., 2023) have exhibited remarkable proficiency across a spectrum of natural language tasks.However, achieving robust performance on complex reasoning problems that necessitate structured exploration, iterative refinement, backtracking, and self-correction remains a formidable challenge (Huang and Chang, 2022).Initial prompting strategies, such as Chain-of-Thought (CoT) (Wei et al., 2022), encourage step-by-step reasoning by eliciting intermediate steps.While beneficial, the inherent linearity of CoT struggles to capture the dynamic, non-sequential nature of sophisticated problem-solving, which often involves generating parallel hypotheses, critical evaluation, and synthesis-processes ill-suited to a strictly linear progression.</p>
<p>Recognizing these limitations, subsequent research has explored more complex reasoning structures.Frameworks like Tree-of-Thought (ToT) (Yao et al., 2023) utilize tree structures to manage multiple reasoning paths, while Graph-of-Thought (GoT) (Besta et al., 2024) generalizes this to arbitrary graphs.Other approaches, such as Cumulative Reasoning (CR) (Zhang et al., 2023), leverage multi-agent paradigms with specialized roles.Despite their advancements, these methods frequently require external controllers or multi-component pipelines.In contrast, DoT retains a single-model</p>
<p>Related Work</p>
<p>The pursuit of robust reasoning within Large Language Models (LLMs) has driven considerable research beyond basic input-output functionality.Initial breakthroughs like Chain-of-Thought (CoT) prompting (Wei et al., 2022;Kojima et al., 2022) demonstrated that eliciting intermediate reasoning steps significantly improves performance on complex tasks.CoT effectively linearizes reasoning, enhancing transparency but suffering from rigidity; its sequential nature hinders exploration of alternatives or recovery from early errors without restarting.Methods like Self-consistency (Wang et al., 2022) mitigate this by sampling multiple reasoning paths and selecting the majority answer, implicitly acknowledging path diversity but lacking explicit refinement mechanisms.</p>
<p>Recognizing the constraints of linearity, subsequent work explored more complex structures.Tree-of-Thought (ToT) (Yao et al., 2023) introduced tree structures where nodes represent partial solutions and edges denote reasoning operators.ToT utilizes search algorithms (e.g., BFS, DFS) guided by heuristic evaluations (often LLM-based) to explore possibilities, enabling systematic search and backtracking.However, ToT generally necessitates an external controller for search management and pruning.Graph-of-Thought (GoT) (Besta et al., 2024) extends this to arbitrary graphs, allowing for more intricate dependency modeling, such as merging reasoning paths, but often requiring more sophisticated external graph management systems.</p>
<p>Collaborative and iterative refinement approaches offer another perspective.Cumulative Reasoning (CR) (Zhang et al., 2023) employs multiple LLM instances (or prompts) assigned specific roles (e.g., proposer, verifier), interacting iteratively.While modular, this introduces coordination overhead.Self-Refine (Madaan et al., 2023) focuses on iterative improvement where an LLM critiques and refines its own output, though typically applied to the entire output rather than intermediate reasoning steps within a structured process.</p>
<p>From a foundational perspective, Yuan (2023) uses category theory to analyze the inherent capabilities and limitations of LLMs.This work proves that prompt-based tuning is restricted to "representable" tasks within the pretext task category, potentially explaining the limitations of simpler methods like CoT.Conversely, the theory suggests fine-tuning offers broader potential, theoretically enabling a sufficiently powerful model to solve any task within that category given adequate resources.</p>
<p>Diagram of Thought (DoT) builds upon these diverse approaches while offering key distinctions.Like ToT and GoT, DoT utilizes non-linear structures (DAGs) for reasoning.However, it distinctively internalizes the graph construction and navigation within a single auto-regressive model via role tokens, minimizing external control dependencies.This contrasts with the external orchestration often required by ToT and GoT.DoT employs explicit cognitive roles (propose, critique, summarize), similar to CR, but integrates them seamlessly within one model through conditional generation, avoiding multi-agent coordination complexities.The use of rich natural language critiques potentially offers more nuanced feedback than the simple heuristic scores sometimes used in ToT.Importantly, by grounding the reasoning process in Topos Theory, DoT aims for a level of formal rigor and consistency guarantees that distinguish it from purely heuristic methods, resonating with the structural analysis provided by works like Yuan (2023).DoT thus presents a unified, self-contained, interpretable, and formally-grounded approach to advance complex reasoning in LLMs.</p>
<p>The Diagram of Thought Framework</p>
<p>In this section, we formally define the Diagram of Thought (DoT) framework.DoT operationalizes complex, iterative reasoning as the dynamic construction and traversal of a Directed Acyclic Graph (DAG) G = (V, E) entirely within a single auto-regressive language model LM.This internal graph structure allows the model to manage parallel lines of thought, critique intermediate steps, refine ideas based on feedback, and synthesize validated conclusions.</p>
<p>Definition 3.1 (DoT Graph Components).The DoT graph G = (V, E) is composed of:</p>
<p>• Nodes v ∈ V : Each node represents a semantic unit or reasoning step.Every node v is associated with:</p>
<p>-A specific role role(v) ∈ R = {Problem, Proposer, Critic, Summarizer}.-Textual content content(v), generated by the LLM LM while assuming the role role(v).</p>
<p>-Optionally, an internal state state(v) ∈ {active, validated, invalidated, initial}.For example, a 'Proposer' node might start as 'active', become 'validated' after a positive critique, or 'invalidated' after a negative critique.• Edges (u, v) ∈ E: A directed edge from node u to node v encodes that v depends on u.We standardize that, when emitting node v (with fresh ID v), all edges in its block have dst= v and src&lt; v.This covers:</p>
<p>-Logical dependency (a new proposition depends on earlier premises).A node may depend on multiple sources, indicated by multiple edge records in its emission block.-Procedural dependency (a critic depends on the proposition it evaluates: proposer → critic).</p>
<p>-Contextual dependency (a summarizer depends on the validated nodes it uses).The graph is acyclic by construction since every edge targets the current node and all sources are previously emitted nodes.</p>
<p>The construction of this graph is implicitly managed by the LLM's standard auto-regressive generation process, strategically guided by special role tokens.</p>
<p>Roles, Generation, and Iterative Reasoning</p>
<p>A core mechanism of DoT involves augmenting the LLM's vocabulary V with a distinct set of role-specific tokens:
T roles = {<problem>, <proposer>, <critic>, <summarizer>}.
Let V ′ = V ∪ T roles be the augmented vocabulary.The LLM LM operates by predicting the next token w t ∈ V ′ based on the preceding sequence (history) H t−1 = w 1 , . . ., w t−1 :
P (w t |H t−1 ; θ) = LM(H t−1 ),
where θ denotes the model parameters.The generated sequence H T = w 1 , . . ., w T represents a serialized traversal and construction of the DoT graph G.</p>
<p>The role tokens function as control signals, prompting the LLM to adopt a specific cognitive function for the subsequent text generation, thereby determining the role and content of the next node(s) in the graph:</p>
<p>• <problem>: Typically precedes the initial problem statement P.This establishes the root node
v start ∈ V with role(v start ) = Problem and content(v start ) = P.P i ) = P i .
All dependencies are declared explicitly via serialized @edge records defined in Section 3.2.The new node typically starts with state(v P i ) = active.• <critic>: Instructs the LLM to evaluate one or more preceding 'Proposer' nodes.The LLM generates a critique C j , assessing validity, identifying flaws, or suggesting improvements.This creates a node v C j with role(v C j ) = Critic and explicit dependency edges from the propositions to the critic.We adopt a monotone validation discipline:</p>
<p>-If the critique validates a proposition, its state transitions to 'validated'.This state is absorbing.</p>
<p>-If the critique identifies flaws, its state transitions to 'invalidated'.This renders the proposition ineligible for summarization.The reasoning path is expected to continue from the critique node to generate a refinement.• <summarizer>: Prompts the LLM to synthesize a final answer or consolidated conclusion.The model is trained to condition its summary generation on the validated parts of the graph, which are accessible through the serialized history H t−1 .It performs a conceptual aggregation respecting the declared dependencies and generates the summary text S.This creates a final node v S with role(v S ) = Summarizer and explicit @edge records from the validated propositions that contributed to the summary.Generation often terminates after this step.</p>
<p>The LLM learns to predict appropriate role token transitions based on the entire preceding history H t−1 , effectively learning to navigate and structure the reasoning process.For instance, after generating a proposition via <proposer>, the model learns it's often appropriate to predict <critic>.Following a critical critique (<critic> leading to state 'invalidated'), the model might predict <proposer> again to generate a refinement, or explore an alternative branch.</p>
<p>The DoT reasoning process unfolds as the LLM generates a serialized representation of the DAG G:</p>
<ol>
<li>Initialization: The process begins with the problem statement, formatted using the typed serialization from Section 3.2 (e.g., @node id=1 role=problem ...).This defines the root node v 1 .2. Proposal: The LLM predicts <proposer> and generates the text for a proposition P 2 , along with its node definition (@node id=2 role=proposer) and an edge from a prior node (@edge src=1 dst=2 kind=use).This adds node v 2 (state: active) to G. 3. Critique: The LLM predicts <critic>, generates a critique C 3 for P 2 , and emits the corresponding node and edge records (@node id=3 role=critic, @edge src=2 dst=3 kind=critique).It also emits a status record (@status target=2 mark=validated|invalidated) that updates the state of v 2 .4. Continuation (Branching/Refinement/Exploration): Based on the history (including the state of v 2 ), the LLM predicts the next role token:</li>
</ol>
<p>• If v 2 was validated: The LLM might predict <proposer> to generate a new proposition P 4 building upon v 2 (adding node v 4 and an @edge from v 2 ).• If v 2 was invalidated by C 3 : The LLM might predict <proposer> to generate a refined proposition P 4 that addresses the critique, with an edge from v 3 (@edge src=3 dst=4 kind=refine).Alternatively, it might backtrack to generate an alternative proposition P 5 stemming from the root node v 1 .5. Iteration: Steps 2-4 repeat, progressively extending the DAG.The requirement that edge destinations must have higher IDs than their sources syntactically enforces acyclicity.6. Summarization: Eventually, the LLM predicts <summarizer>.It is trained to generate a summary by synthesizing information from validated nodes, adding a summary node and explicit @edge records from the nodes it used.</p>
<p>This process yields a structured, interpretable trace of reasoning, captured within a single, selfcontained generated sequence.</p>
<p>Typed Serialization, Validation, and Extraction</p>
<p>To ground the reasoning process and ensure auditability, we introduce a disciplined, typed serialization format.Natural language content is interleaved with structured records (prefixed with '@') that define the DAG's nodes, edges, and states.For example, @node id=3 role=critic creates a critic node, and @edge src=2 dst=3 kind=critique establishes its dependency on a previous proposition.Node IDs are strictly increasing, guaranteeing acyclicity by construction.</p>
<p>During inference, a lightweight, controller-light validator enforces this structure.It uses grammarconstrained masking to ensure the LLM only generates syntactically and logically valid records (e.g., an edge's source must be a previously defined node).This process is deterministic and avoids external search algorithms or planners.A deterministic extraction map, Φ, converts any well-formed trace into a formal diagram, enabling the categorical semantics described in Section 4. The full grammar, operational semantics, and validation rules are detailed in Appendix B.</p>
<p>Training and Controller-Light Inference</p>
<p>Training: The DoT capability is instilled in the LLM LM through fine-tuning on datasets formatted according to the DoT structure.Such data consists of sequences H = w 1 , . . ., w T containing appropriately interleaved role tokens (T roles ) and natural language text segments, representing valid, coherent reasoning DAGs.Potential data sources include:</p>
<p>• Curated examples derived from human step-by-step reasoning traces, augmented with role tokens and serialized records.• Synthetically generated examples from structured problem-solving processes (e.g., program execution traces, mathematical proofs), formatted using the typed serialization from Section 3.2.• Bootstrapped data generated by an initial version of a DoT model, potentially filtered or refined based on correctness or coherence metrics.</p>
<p>The training objective is the standard auto-regressive language modeling loss (e.g., cross-entropy) applied over the entire sequence, including role tokens and content tokens:
L(θ) = − 1 |H| |H| t=1 log P (w t |w 1 , . . . , w t−1 ; θ).
This objective trains the model LM to simultaneously learn the reasoning patterns associated with each role (proposing, critiquing, summarizing) and the appropriate transitions between these roles based on the context, thereby internalizing the ability to construct and navigate the DoT graph structure.</p>
<p>Inference: To solve a new problem P using DoT, inference proceeds as follows:</p>
<ol>
<li>Initialize the generation history H with the serialized problem statement, e.g., @node id=1 role=problem .... 2. Perform auto-regressive generation using the trained LLM LM.At each step t, sample or select the next token w t ∼ LM(H t−1 ) using a chosen decoding strategy (e.g., greedy decoding, nucleus sampling) and the well-formedness constraints from Section 3.2.3. Append the generated token w t to the history:
H t = H t−1 ⊕ w t .</li>
<li>Repeat steps 2 and 3 until a termination condition is met.Common conditions include:</li>
</ol>
<p>• Generation of the <summarizer> token and its subsequent content, followed by a special end token.• Reaching a predefined maximum sequence length or generation budget.</p>
<p>• Generation of a specific end-of-sequence token.</p>
<p>The final output is typically the textual content associated with the <summarizer> node, although the complete generated sequence H provides the full reasoning trace (the serialized DoT graph) for interpretability.Notably, this entire process is self-contained within the single LLM LM; no external graph management system or search/planning controller is required during inference, beyond a deterministic syntax validator and (when typed blocks are present) a decidable entailment check.</p>
<p>4 Topos-Theoretic Formalization of DoT Order convention.We compute colimits in the information order Pred(S) := Sub(S) op , where arrows are reversed inclusions.In this order, "more information" is larger.For a (finite) family of validated predicates {P v ⊆ S}, the colimit in Pred(S) corresponds to the greatest lower bound in inclusion order, i.e.</p>
<p>colim Pred(S)
{P v } = v P v .
Equivalently-working in the reflective subposet of c-closed subobjects-this meet is computed there; read back in Sub(S) the summary is the meet followed by the closure operator c (meet-plus-closure) on finite sets.We keep the posetal fragment explicit (Assumption (A4)); the general-arrow case is handled via slice sheafification (Cor.4.6).</p>
<p>While the operational description in Section 3 details the DoT mechanism, establishing its logical soundness and robustness requires a deeper, formal framework.We leverage Topos Theory (MacLane and Moerdijk, 2012;Johnstone, 2002;Lambek and Scott, 1988), which provides a setting with finite limits, exponentials, and a subobject classifier to interpret intuitionistic logic.This makes it suitable for formalizing the dynamic, evidence-aggregating, and context-dependent reasoning inherent in the DoT process.</p>
<p>An elementary topos E is a category that encapsulates key properties needed for modeling logical systems and computation:</p>
<ol>
<li>Finite Limits: E has a terminal object 1, binary products A × B, and pullbacks.This allows for combining and constraining information.2. Cartesian Closure: For any objects A, B ∈ E, there exists an exponential object B A , representing the internal collection of morphisms A → B. This enables modeling functions, predicates, and higher-order logic.3. Subobject Classifier Ω: There exists an object Ω and a truth arrow ⊤ : 1 → Ω such that every monomorphism m : P → A corresponds uniquely to a characteristic morphism χ m : A → Ω. Ω internalizes the logic of the topos, which is generally a Heyting algebra, supporting intuitionistic reasoning.</li>
</ol>
<p>Crucially for DoT, many relevant topoi, particularly presheaf topoi E = Set C op , possess not only finite limits but also all small colimits.Colimits provide the canonical mechanism for synthesizing or "gluing together" information distributed across different stages or nodes according to their specified relationships, which is precisely what the <summarizer> role is designed to do.Since slices of a topos are again topoi, the slice (E/S) also has all small colimits.</p>
<p>In what follows, we fix a presheaf topos E = Set C op .This is the category of all functors from a small category C to the category of sets.We also fix a designated semantic object S ∈ E representing the universe of discourse.Our formalization takes place within the slice category (E/S), where propositions are subobjects of S. For concreteness, one may take C to index problem contexts and S(c) to be the set of admissible semantic states at context c.For the QF-LIA instantiation used in examples, we take C to be a finite discrete category (a single object in simple cases) and interpret terms componentwise so that interpretation remains decidable.</p>
<p>Definition 4.1 (Categorical Semantics of DoT Components).Within the fixed presheaf topos E = Set C op and slice (E/S), assume a Lawvere-Tierney topology j : Ω → Ω with associated closure operator c : Sub(S) → Sub(S) (extensive, idempotent, monotone):</p>
<p>• Semantic Space (S): A base object S ∈ E representing the universe of discourse or the space of all possible solutions and intermediate states.</p>
<p>• Propositions (P ): A proposition (e.g., "the solution is 42") is interpreted as a subobject P → S, i.e., an object of the slice category (E/S).This models the proposition as a "subset" of the universe of discourse S that satisfies the proposition.• Logical Dependency/Entailment: A dependency where proposition Q follows from proposition P is modeled by the inclusion P ≤ Q in the lattice Sub(S); equivalently, by a morphism P → Q over S in the slice (E/S).• Critiques as Judgements (typed): A <critic> node is evidence about a proposition.Semantically, a critique is either (i) a predicate on P (a map δ P : P → Ω) that, when validated, induces closure under j, or (ii) an arrow P → Q witnessing refinement along with coequalizer constraints.In the posetal fragment, validated critiques induce inclusions P → Q; in the general fragment, they may induce general arrows over S. • Validation as a Closure: Validation is modeled by a universal closure c : Sub(S) → Sub(S) induced by j (extensive, idempotent, monotone, pullback-stable).A proposition is validated iff c(P ) = P (i.e., it is c-closed).• Refinement (P ⇝ P ′ ): When a critique constrains P , a refinement step produces P ′ → S with P ′ ≤ c(P ) (incorporating validated constraints).• Validated Diagram: Only validated proposer nodes enter the colimit computation; critique nodes provide the morphisms and generate equalities between paths.</p>
<p>Assumption 4.2 (Fixed, pullback-stable validation modality).There exists a Lawvere-Tierney topology j : Ω → Ω on E whose induced universal closure c on Sub(S) models validation.The closure is extensive, monotone, idempotent, and pullback-stable.All results in this section are relative to this fixed j.We assume throughout the slice (E/S): (i) effective internal equivalence relations, (ii) pullback-stable coequalizers of these relations, and (iii) Beck-Chevalley compatibility for base-change along S → a j S, so that the induced slice reflector a /S j preserves the coproduct/coequalizer colimit shapes we use.</p>
<p>Semantic Target and Normative Conditions</p>
<p>The following assumptions connect the practical LLM behavior with our formal model.They are idealized, normative conditions that define the target semantics for a well-behaved DoT agent.The operational mechanisms are designed to make LLM traces more likely to satisfy these conditions upon interpretation.</p>
<p>The Reasoning Diagram and its Synthesis via Colimit</p>
<p>The DoT-DAG G = (V, E) specifies the shape of a diagram within (E/S).We formalize this structure with the following definition:  • Each proposer node v mapped to a subobject D G (v) → S;
Definition 4.3 (DoT Index Category J G ). Given a DoT DAG G = (V, E), let V prop ⊆ V
• Critique nodes supply arrows (predicates, entailments) between these subobjects and generate the relations in ≡; only validated critiques contribute arrows; • Each arrow u → v in J G mapped to a morphism over S, witnessing entailment/refinement coherence.</p>
<p>Functoriality ensures that composite dependencies (via paths modulo ≡) are respected in the slice.</p>
<p>Proof Sketch.We define the functor D G by mapping each node v to its semantic interpretation D G (v) as a subobject in (E/S) and each dependency path
u → v in G to a corresponding morphism D G (u) → D G (v)
. Assumptions (A1) and (A3) guarantee that this mapping is well-defined and that it preserves composition and identities.</p>
<p>Synthesis by Colimit and Reflection.The <summarizer> aggregates validated content.We distinguish an inclusion/posetal setting (our main focus) and a general-arrow setting.In the latter, sheafification induces a base-change: a /S j : (E/S) → (Sh j (E)/a j S), and summaries are read over a j S via the unit S → a j S.  where a /S j : (E/S) → (Sh j (E)/a j S) is the slice reflector (sheafification) induced by j and the unit S → a j S effects the base-change.The functor a /S j is a left adjoint and hence preserves colimits; we rely on the existence of coproducts and pullback-stable coequalizers of internal equivalence relations in (E/S).In the posetal fragment, this reduces to Theorem 4.5.</p>
<p>Proof Sketch.Compute the colimit in (E/S) using coproducts and pullback-stable coequalizers of internal equivalence relations, then apply the left exact reflector a /S j .Preservation holds for these shapes under the usual stability hypotheses in slices (Beck-Chevalley).In the posetal fragment, the colimit of the diagram read in Pred(S) is the meet in Sub(S), and a /S j acts as the closure c.</p>
<p>Operational note.The online validator enforces only local typing/equality checks; the full slice-colimit and sheafification are an offline semantic idealization.A practical runtime may compute the join over validated proposers as a conservative under-approximation of a /S j (colim D valid ).Proof Sketch.Case (1): in a fixed context c 0 , finite satisfiability implies the finite intersections are non-empty; hence the (finite) meet is non-empty at c 0 , and extensivity of c preserves non-emptiness.Case (2): compactness is model-theoretic; we read satisfiability in a model where the infinite set is realized.We do not claim componentwise non-emptiness in a fixed S without additional compactness of S(c).</p>
<p>Formal Guarantees: Consistency and Robustness</p>
<p>Corollary 4.8 (Soundness w.r.t.satisfiability).If [[•]] maps into Sub(S) and the validated family {P v } v∈V valid is jointly satisfiable in T (e.g., every finite subset is satisfiable), then the meet v P v is satisfiable.Consequently, the summary c ( v P v ) is consistent (non-initial).</p>
<p>Remark 4.9 (Internal Logic, Modality, and Colimits).The internal logic of E equips Sub(S) with a Heyting algebra.Validation via a Lawvere-Tierney topology promotes propositions to c-closed ones.The summary is the colimit in the reflective subcategory of c-closed subobjects, aligning the operational notion of "gluing together validated parts" with a categorical universal construction.</p>
<p>Proposition 4.10 (Robustness under Diagram Isomorphisms).Let D valid,1 : J valid,1 → (E/S) and D valid,2 : J valid,2 → (E/S) represent validated reasoning steps from two different runs.If there is an isomorphism of diagrams, then their slice-colimits are isomorphic:
colim D valid,1 ∼ = colim D valid,2 .
This implies that the synthesized semantic content depends on the abstract structure of the validated reasoning diagram, not on incidental variations that preserve this structure.</p>
<p>Proof Sketch.This is a direct consequence of the universal property of a colimit.If two diagrams are isomorphic, there is a canonical isomorphism between their respective colimits.</p>
<p>Immediate Consequences</p>
<p>The formalization of the DoT synthesis step as a colimit in the information order (equivalently, as meet-plus-closure under inclusion) entails several immediate and desirable properties, grounded in the lattice-theoretic structure of subobjects and the properties of the closure operator c.</p>
<p>Proposition 4.11 (Properties of Synthesis).Let P = {P v } v∈V valid be a set of validated subobjects.The synthesis operation, Summary(P) = c( v∈V valid P v ), exhibits the following properties:</p>
<ol>
<li>Finiteness in practice: as runs are finite, all meets are finite; infinitary variants require compactness assumptions and are outside our core claims.</li>
</ol>
<p>Monotonicity (information order):</p>
<p>Adding a new validated proposition P new can only refine (never weaken) the summary.In inclusion order, Summary(P ∪ {P new }) ⊆ Summary(P).</p>
<p>Idempotence (finite meets):</p>
<p>The system is robust to redundant validation.Re-processing already validated information over finite families does not alter the conclusion.
Summary(P) = c v∈P c(P v ) = c v∈P P v .
Since validated propositions are already c-closed (P v = c(P v )), this property is inherent.</p>
<ol>
<li>Conservativity (Redundancy Elimination): If a validated proposition P w is already no stronger than the others' conjunction (i.e., P w ⊇ v∈V valid {w} P v ), its explicit inclusion does not change the summary.Summary(P) = Summary(P \ {P w }).</li>
</ol>
<p>Proof.These properties are direct consequences of the underlying mathematics.Monotonicity follows from the monotonicity of and c.Idempotence follows from c(c(X)) = c(X).Conservativity follows because if P w contains the meet of the others, it does not change that meet.</p>
<p>Proposition 4.12 (Greatest c-closed Lower Bound (Canonicity)).For any family P ⊆ Sub(S) of validated subobjects, c( P) is the greatest c-closed lower bound of P (in inclusion order).That is, for any X with X = c(X) and X ≤ P for all P ∈ P, we have X ≤ c( P).</p>
<p>Proof.Immediate from adjunction in Pred(S): c op preserves colimits, so under inclusion order this is c applied to a meet, yielding the greatest lower bound in the reflective sub-poset of c-closed subobjects.</p>
<p>Proposition 4.13 (Generalization of Linear Reasoning).A linear Chain-of-Thought (CoT) process corresponds to a special case of a DoT diagram.If the validated diagram forms a simple chain
P 1 → P 2 → • • • → P n ,
where each step builds directly on the last and strengthens information (so
P 1 ⊇ P 2 ⊇ • • • ⊇ P n in Sub(S)
), then the synthesis simplifies to the final step.</p>
<p>Summary({P 1 , . . ., P n }) = P n .</p>
<p>Proof.For a chain P 1 ≥ • • • ≥ P n under inclusion, their meet is n i=1 P i = P n .Applying c gives Summary = c(P n ).Since P n is validated, it is c-closed, so c(P n ) = P n .</p>
<p>Proposition 4.14 (Composition of Independent Branches).If the set of validated propositions can be partitioned into two disjoint sets, A and B, representing independent lines of reasoning, the overall summary is the validated join of their individual summaries.
Summary(A ∪ B) = c(Summary(A) ∧ Summary(B)) = c c( v∈A P v ) ∧ c( w∈B P w ) .
Proof.By definition (information colimit), Summary(A ∪ B) = c v∈A P v ∧ w∈B P w .A standard property of any closure operator is that c(X ∧ Y ) = c(c(X) ∧ c(Y )).The result follows directly.</p>
<p>Bridging Formalism and LLM Generation</p>
<p>It is crucial to understand the relationship between this formal topos-theoretic model and the actual behavior of an LLM.The LLM does not explicitly perform computations within a topos.Instead:</p>
<p>• The topos framework provides the normative semantic model.It defines what constitutes sound, consistent, and robust synthesis.Theorems 4.5, 4.7, and Proposition 4.10 describe desirable properties of an ideal reasoning process.</p>
<p>• The LLM, trained on DoT-structured data (using the serialization from Section 3.2), learns to generate text sequences that functionally approximate the operations described by the formalism.</p>
<p>The generated sequence induces an abstract diagram that is then interpreted under Assumptions (A1)-(A4).• Specifically, the <summarizer> role learns to generate text that effectively acts like a colimit: it synthesizes information from validated precursor nodes, respects their dependencies, and aims for a coherent, non-redundant aggregation.• The fidelity of this approximation depends heavily on the training data and model capacity.</p>
<p>The topos model provides a precise target against which the LLM's reasoning behavior can be evaluated.One could design specific training objectives, such as a discriminative loss that penalizes generated summaries whose typed content violates the entailments dictated by the colimit construction.</p>
<p>This formalism offers a rigorous language for defining correctness criteria and provides a theoretical target for DoT behavior.Operational invalidation can either be modeled (i) as the absence of a validated inclusion (posetal fragment), or (ii) via a separate counterevidence object I ∈ Sub(S) with summaries computed as c ( valid) ∧ ¬I in the Heyting algebra Sub(S).We adopt the posetal refinement fragment for the main development and leave full revision semantics to future work.Proof sketch.In a CoT chain P 1 ≤ • • • ≤ P n , any two validated items are comparable.If P and Q are incomparable in Sub(S), there does not exist a chain embedding that preserves inclusions and maps both P, Q to validated nodes with their original ordering.The DoT summary is c(P ∧ Q) by Thm.4.5.Any chain that outputs c(P ∧ Q) must place either P or Q above the other, contradicting incomparability unless the content is changed.Thus DoT expresses branching validated evidence that CoT cannot faithfully encode.This theorem provides a formal witness to the intuition that branching structures are strictly more expressive for problems involving parallel, non-exclusive lines of evidence.</p>
<p>Separation from Linear Chain-of-Thought</p>
<p>Conclusion</p>
<p>This paper introduced the Diagram of Thought (DoT), a framework that internalizes complex reasoning as DAG construction within a single auto-regressive LLM, guided by role-specific tokens and enforced by a lightweight, controller-light validator.We showed how DoT unifies proposition generation, critique, refinement, and summarization without a heavyweight search/planning controller.We established a normative formalization using Topos Theory, where the synthesis of validated evidence corresponds to computing a colimit and reflecting it along a Lawvere-Tierney topology.</p>
<p>Crucially, we moved beyond informal assumptions by specifying a decidable typed serialization with online validation, a monotone state-update discipline, and support for multi-premise critiques.We made the derivation of the validation modality (the Lawvere-Tierney closure) from critique schemas more explicit.Our correctness claims are conditional on these checkable and auditable mechanisms, providing a solid bridge between the operational system and its semantic model.</p>
<p>This topos-theoretic perspective provides several key benefits:</p>
<p>• It assigns clear mathematical meaning (subobjects, diagrams, and colimits in the slice (E/S)) to DoT components.In summary, the primary advantages of DoT include an auditable reasoning trace, explicit compositional structure, and a clear theoretical target.</p>
<p>A Worked Example Trace</p>
<p>This example shows DoT applied to a problem with multiple independent conditions, demonstrating branching and invalidation.</p>
<p>@node id=1 role=problem Is the point (4, 6) inside the region defined by x &gt; 2, y &gt; 5, and x &lt; 10? @node id=2 role=proposer @edge src=1 dst=2 kind=use @prop id=2 { "gt": [4, 2] } First, I will check the condition x &gt; 2. For the point (4, 6), x=4.The inequality is 4 &gt; 2, which is true.@node id=3 role=critic @edge src=2 dst=3 kind=critique The arithmetic is correct.This condition holds.@status target=2 mark=validated @node id=4 role=proposer @edge src=1 dst=4 kind=use @prop id=4 { "gt": [6, 5] } Next, I will check the condition y &gt; 5.For the point (4, 6), y=6.The inequality is 6 &gt; 5, which is also true.@node id=5 role=critic @edge src=4 dst=5 kind=critique Correct.The second condition holds.@status target=4 mark=validated @node id=6 role=proposer @edge src=1 dst=6 kind=use @prop id=6 { "lt": [6, 0] } Let me try an alternative, incorrect check.Maybe the condition was y &lt; 0. For y=6, 6 &lt; 0 is false.@node id=7 role=critic @edge src=6 dst=7 kind=critique This proposition is arithmetically correct (6 is not less than 0), but it addresses a condition not present in the problem statement.This path is irrelevant.@status target=6 mark=invalidated @node id=8 role=proposer @edge src=1 dst=8 kind=use @prop id=8 { "lt": [4, 10] } Finally, I check the third condition, x &lt; 10.For x=4, 4 &lt; 10 is true.@node id=9 role=critic @edge src=8 dst=9 kind=critique This is correct.The final condition is met.@status target=8 mark=validated @node id=10 role=summarizer @edge src=2 dst=10 kind=use @edge src=4 dst=10 kind=use @edge src=8 dst=10 kind=use Summary: All three conditions (x &gt; 2, y &gt; 5, and x &lt; 10) are met for the point (4, 6).Therefore, the point is inside the specified region.The validated propositions are ID=2, ID=4, and ID=8.</p>
<p>B DoT Serialization and Validation Details</p>
<p>This section provides the complete details for the typed serialization, validation, and extraction mechanisms summarized in Section 3.2.</p>
<p>Serializer.We present a node-first, into-the-current-node serializer that guarantees acyclicity and supports on-line checks.The serializer is optional for usability, but recommended whenever formal guarantees or auditability are invoked.When it is disabled, DoT traces remain interpretable as natural language; the formal guarantees in Section 4 apply to the typed subtrace (if any), and free text is semantically inert.</p>
<p>B.1 Grammar and Record Specification</p>
<p>Node identifiers and roles.Each node carries a fresh natural-number ID and an explicit role:</p>
<p>@node id=⟨n⟩ role={problem,proposer,critic,summarizer}.</p>
<p>IDs are strictly increasing in emission order.</p>
<p>Typed edges and emission order.Edges are explicit, typed dependencies into the current node j:</p>
<p>@edge src=⟨i⟩ dst=j kind={refine,critique,use}, i &lt; j.</p>
<p>Well-formedness requires that sources src refer only to previously emitted node IDs.For critiques, the dependency direction is proposer → critic (the critic depends on the proposition it evaluates).</p>
<p>Admissible role/kind pairs (type table ).Let r(•) be node roles.Allowed triples for an @edge src=i dst=j kind=k are:</p>
<p>• kind=critique: r(i) = proposer, r(j) = critic.A critic node's block may only contain edges of this kind.</p>
<p>• kind=refine: r(i) ∈ {proposer, critic}, r(j) = proposer.</p>
<p>• kind=use: r(i) = proposer, r(j) ∈ {proposer, summarizer}.Critics are relational and cannot be a source for 'use' edges; instead they are reified via @entails as above.</p>
<p>Arrow declarations (entailments) between proposers.Critiques can declare typed entailments between proposer nodes that become arrows in the extracted diagram:
@entails src=⟨i⟩ dst=⟨k⟩ [ witness=⟨j⟩],
with typing requirements: r(i) = r(k) = proposer, and the witness must be a critic node j.</p>
<p>Entailments are validated by a corresponding @status target= record for the source proposition.</p>
<p>Validation marks.Critiques emit a status for their target proposition:
@status target=⟨k⟩ mark={validated,invalidated} [ just=⟨i⟩].
Only propositions with a validated status contribute objects to the categorical diagram.We adopt a monotone state discipline: a proposition's status may be set only once (first-writer wins).</p>
<p>Lexical discipline (fencing).Typed records must begin with the reserved sigil @.Free-form natural-language text lines must not begin with @.This ensures unambiguous lexing.To embed text (including leading @) we use a length-prefixed fence that is streaming-safe: @@len=⟨N ⟩@@ ⟨exactly N bytes of raw text⟩ may contain @ and newlines .</p>
<p>Concrete grammar (BNF).</p>
<p>Let N be decimal naturals and Role be the set of roles.Eq ::= @eq src=N dst=N PropBlock ::= @prop id=N Prop Text ::= arbitrary natural-language line not starting with @ Esc ::= @@len=N@@ Bytes {N}</p>
<p>B.2 Validation and Extraction</p>
<p>Well-formedness judgment.We write Γ ⊢ Trace ok, where the context Γ = (seen, role, state) tracks: seen node IDs, each node's role, and node states.Selected rules:
n &gt; max(seen(Γ)) r ∈ {. . . } Γ ⊢ @node id=n role=r ok (Node-Intro) i ∈ seen(Γ) i &lt; j dst = j (r(i), r(j), k) admissible Γ ⊢ @edge src=i dst=j kind=k ok (Edge-Intro) i ∈ seen(Γ) role(i) = proposer state(i) = active Γ ⊢ @status target=i mark=m ok (Status-Intro)
Online validation.We employ a lightweight online validator V with DFA control over record kinds and register-based side conditions: (i) a monotone counter for the next ID, (ii) hash maps for roles and states, and (iii) a congruence-closure structure for equalities.Given a candidate token, V performs local checks (e.g., src &lt; dst = current id).At inference, this validator provides masks to the LLM decoder, ensuring only well-formed sequences are generated.</p>
<p>B.3 Operational Semantics and Meta-Theory</p>
<p>Standing scope.We treat DoT's semantics as a normative target: the LLM approximates the colimit behavior, while V ensures the typed fraction is well-formed and auditable.</p>
<p>Proposition B.2 (Relative soundness to typed subtrace).Any conclusion in Section 4 is a function of the extracted typed diagram Φ(H) alone; untyped/free text has no effect on the semantics.</p>
<p>We give selected small-step rules over states (G, σ, H) where G is the partial DAG, σ the node-state map, and H the emitted prefix.</p>
<p>Rules (sketch).Proposer-Intro: on a well-typed @node with role=proposer, extend G with a vertex v, set σ(v) = active.Critic-Intro: on role=critic, add the critic node.Validate: on @status with mark=validated for target u where σ(u) = active, set σ(u) = validated.</p>
<p>Theorem B.3 (Order-Invariance (semantic; typed-content invariant)).Consider two well-posed traces, H 1 and H 2 , that contain the same multiset of typed records and induce the same dependency partial order.Then their extracted index categories are isomorphic, J G 1 ∼ = J G 2 , and their semantic summaries are isomorphic.</p>
<p>Proof sketch.Both traces correspond to topological sorts of the same dependency DAG of records; extraction is functorial and respects the quotient by validated equalities, hence yields isomorphic diagrams; the (reflected) colimit is invariant under diagram isomorphism.</p>
<p>B.4 Algorithm and Implementation Details</p>
<p>The state of the reasoning process (the DAG) is implicitly encoded within the auto-regressive history H t .The LLM conditions its prediction on this history, using its attention mechanism to represent the current state of the DoT graph.Algorithm 1 provides a high-level sketch.</p>
<p>Controller-light decoding (formalization).Decoding uses a static, deterministic mask derived from the validator's DFA and local typing maps.Illegal token classes are never sampled.There is no branching search or external resampling loop.The only state external to the LM is the validator's finite map store.</p>
<p>Auxiliary supervision for summaries-as-colimits.To align the <summarizer> with the normative target, one can add an auxiliary loss that penalizes violations of literals that are entailed by the finite-meet of validated propositions.This complements the standard maximum-likelihood training on full traces.</p>
<p>Algorithm 1 Diagram of Thought (DoT) Generation Process (Appendix Version)</p>
<p>1: Input: Problem statement P 2: Initialize generation history H with serialized problem statement for node v 1 ; set current node j ← 1. 3: Initialize node states (e.g., in a dictionary) σ[v 1 ] ← initial.4: while termination condition not met (e.g., max length, <summarizer> generated) do 5:</p>
<p>Predict next role token r ∈ T roles based on history H: r ∼ LM(H).</p>
<p>6:</p>
<p>Append r to H.</p>
<p>7:</p>
<p>if r = <proposer> then 8:</p>
<p>Emit @node id= j+1 role=proposer; set j ← j+1.</p>
<p>9:</p>
<p>Emit zero or more edges @edge src= i dst= j with i &lt; j.</p>
<p>10:</p>
<p>Generate proposition text P j .Append records and text to H.</p>
<p>11:</p>
<p>Update state: σ[j] ← active.</p>
<p>12:</p>
<p>else if r = <critic> then 13:</p>
<p>Emit @node id= j+1 role=critic; set j ← j+1.</p>
<p>14:</p>
<p>Emit one or more @edge src= k m dst= j kind=critique.</p>
<p>15:</p>
<p>Generate critique text C j ; then emit @status target= k mark=validated|invalidated.</p>
<p>16:</p>
<p>Append records and text to H.  Emit @node id= j+1 role=summarizer; set j ← j+1.</p>
<p>20:</p>
<p>Emit zero or more @edge src= i dst= j kind=use with σ[i] = validated.</p>
<p>21:</p>
<p>Generate summary text S. Append records and text to H.</p>
<p>22:</p>
<p>Set termination condition to true.</p>
<p>23:</p>
<p>end if 24: end while 25: Output: Final text S from the summarizer node v S .</p>
<p>C Additional Formal Details</p>
<p>C.1 From Critique Schemas to a Nucleus</p>
<p>We make the construction explicit from finitely many critique schemas, derived from a typed core logic, and require that each schema is stable under pullback along maps over S:</p>
<p>• Local entailment (LE): a validated critique introducing P → Q (mono) over S.</p>
<p>• Equivalence identification (EQ): a validated critique emitting parallel arrows s, t : X ⇒ Y that generate an internal equivalence relation and a record that triggers its (pullback-stable) coequalizer.• Type refinement (TR): narrows a subobject P by pullback along a mono R → S.</p>
<p>We close these schemas under finite meets and pullback.The induced operator c that sends each subobject to the least subobject closed under these rules is a nucleus: it is monotone, extensive, idempotent, and pullback-stable by construction.By the standard nucleus-Lawvere-Tierney corre-spondence, c uniquely determines a topology j whose fiberwise closure agrees with c (Johnstone, 2002).</p>
<p>Lemma C.1 (Rule closure &amp; nucleus completion).Let c 0 be the operator generated by LE, EQ, TR, finite meets, and pullbacks.Then c 0 is extensive and monotone.Define c(X) := { Y | X ≤ Y, Y closed under the rules and finite meets }.Then c is idempotent, pullback-stable, and meet-preserving, hence a nucleus on Sub(S).</p>
<p>C.2 Further Categorical Results</p>
<p>Lemma C.2 (Slice reflection and stability conditions).Let a j : E → Sh j (E) be sheafification (left exact reflector).The induced functor on slices a /S j : (E/S) → (Sh j (E)/a j S) is a left adjoint and therefore preserves all colimits.For the diagram shapes we extract (coproducts and coequalizers of internal equivalence relations), we additionally assume pullback-stability in (E/S) so that these colimits have the intended universal property relative to base-change along S → a j S.</p>
<p>Proposition C.3 (Gluing validated diagrams via pushouts of monos).Let D 1 : J 1 → (E/S) and D 2 : J 2 → (E/S) be validated diagrams whose overlap is a common subdiagram K : J K → (E/S) with all legs monomorphisms.Then, in a presheaf topos, there is a canonical isomorphism
colim(D 1 ∪ K D 2 ) ∼ = colim(D 1 ) ⨿ colim(K) colim(D 2 ),
and hence, after reflection, the overall summary satisfies Summary(D
1 ∪ K D 2 ) ∼ = a /S j colim(D 1 ) ⨿ colim(K) colim(D 2 ) .
Proof sketch.Presheaf categories are extensive; monos are stable under colimits and pullback.Van Kampen-style properties yield that finite colimits commute along monos, giving the stated isomorphism; reflection preserves the colimit shape.</p>
<p>C.3 Validation and Termination</p>
<p>We enforce well-formedness with the validator V (Appendix B).At inference, decoding is constrained by V ; violations are rejected before token commitment.Termination is guaranteed by a budget on non-@status statements and the explicit <summarizer:end> token.</p>
<p>Defeasible validation (ranked nucleus; formal variant).For more complex, non-monotone reasoning, we can define a finite priority set ρ ∈ {0, . . ., R} on critique schemas and an increasing chain of nuclei c ≤ρ .A retraction step from rank ρ to ρ ′ &lt; ρ replaces c ≤ρ by c ≤ρ ′ on affected objects.This yields limited non-monotone updates while retaining controller-light decoding and our order-invariance result for a fixed ρ.In the absence of path equalities (no @eq/@coeq on arrows), extraction runs in O(|H| α(|H|)) time and O(|H|) space.When path equalities are present, we maintain congruence-closure on arrows (e.g., via e-graphs); this is near-linear in typical traces but can be super-linear in the worst case, depending on the signature and saturation strategy.</p>
<p>D Detailed Proofs</p>
<p>Proof.The proof proceeds by demonstrating totality, determinism, and analyzing the computational complexity.</p>
<p>The extraction map Φ is defined for any trace H that is deemed well-formed by the validator V .Well-formedness ensures that every record in the trace can be unambiguously parsed and interpreted.</p>
<p>Every @node record has a unique, strictly increasing ID.Every @edge record refers to a src ID that has already been emitted and a dst ID corresponding to the current node, preventing forward references and cycles in the dependency graph of records.Typed records for status, entailments, and equalities have their targets and roles checked for validity.</p>
<p>Since every syntactically valid record has a defined semantic action (e.g., add a node, add an edge, update a state, record an equality), the extraction process is defined for the entire trace.Hence, Φ is total on the set of well-formed traces.</p>
<ol>
<li>We must show that a given well-formed trace H maps to a single, unique diagram.</li>
</ol>
<p>The set of nodes V in the extracted DAG G is uniquely determined by the set of @node records.The set of edges E is uniquely determined by the set of @edge records.The index category J G is formed by taking the free category on the graph of validated proposer nodes and quotienting by the smallest congruence ≡ generated by validated @eq and @coeq records.The smallest congruence is unique.</p>
<p>The diagram functor D G : J G → (E/S) maps each object (proposer node) to its unique semantic interpretation and each arrow to its corresponding interpretation.</p>
<p>Because each step of the extraction process is a deterministic function of the input trace, the final output (G, J G , D G ) is unique.Now, let us calculate the complexity:</p>
<p>• Parsing the trace H is a single linear pass, O(|H|).</p>
<p>• Building the graph structure (nodes and edges) involves processing each record once.Using hash maps to store node information (roles, states), this takes O(|H|) time and space.</p>
<p>• When only node equalities are present, managing these with a union-find data structure takes O(|H| α(|H|)) time, where α is the inverse Ackermann function.</p>
<p>• When path equalities are introduced, a more complex congruence closure algorithm is needed.While algorithms like e-graphs perform with near-linear amortized time in practice, their worst-case complexity can be higher depending on the specific theory.We state the complexity parametrically in this case.</p>
<p>The stated complexity bounds follow.</p>
<p>Theorem D.2 (Order-Invariance (semantic; typed-content invariant)).Let a well-posed trace be one that (i) obeys the NodeBlock grammar, and (ii) contains at most one @status record for each proposer node ID (single-assignment).Consider two well-posed traces, H 1 and H 2 , that contain the same multiset of typed records (@node, @edge, @status, @eq/@coeq) and induce the same dependency partial order on those records after quotienting by validated equalities.Then their extracted index categories are isomorphic, J G 1 ∼ = J G 2 .In the posetal case, the resulting subobjects are equal; in the general case, their reflected slice-colimits are isomorphic.</p>
<p>Proof.The core insight is that the extraction map Φ is sensitive only to the set of typed records and their dependency partial order, not the specific linear sequence in which they appear, provided that sequence is a valid topological sort of the dependency graph.</p>
<p>Since H 1 and H 2 contain the same multiset of typed records, they will result in the same set of proposer nodes, the same dependency edges between nodes, the same status assignments, and the same set of declared equalities.</p>
<p>The well-formedness rules (src &lt; dst, etc.) ensure that any valid trace is a topological sort of the underlying dependency graph of records.If H 1 and H 2 induce the same dependency partial order, they are simply two different valid topological sorts of the same abstract structure.</p>
<p>The extraction map Φ constructs the diagram by first identifying all nodes and edges from the records and then applying the validated equalities.This process does not depend on the linear order of emission, only on the final set of records.Therefore, Φ(H 1 ) and Φ(H 2 ) will produce the same abstract graph G, the same set of validated equalities, and thus the same index category J G and diagram D G .Since the categories and diagrams are identical, they are trivially isomorphic (J G 1 = J G 2 ).</p>
<p>By Proposition 4.10, isomorphic (in this case, identical) diagrams have isomorphic colimits.After reflection, the resulting summaries are isomorphic.In the posetal sub-case where the summary is a specific subobject (the meet-plus-closure), the summaries will be equal.• Each proposer node v mapped to a subobject D G (v) → S;</p>
<p>• Critique nodes supply arrows (predicates, entailments) between these subobjects and generate the relations in ≡; only validated critiques contribute arrows; • Each arrow u → v in J G mapped to a morphism over S, witnessing entailment/refinement coherence.</p>
<p>Functoriality ensures that composite dependencies (via paths modulo ≡) are respected in the slice.</p>
<p>Proof.We construct the functor D G : J G → (E/S) by defining its action on objects and morphisms and verifying that it satisfies the functoriality axioms.</p>
<p>As per Definition 4.3, the extraction map Φ applied to the trace yields a DAG G.We consider the full subgraph consisting of validated proposer nodes V prop,valid .The index category J G has these nodes as its objects.Its morphisms are the equivalence classes of dependency paths between these nodes, quotiented by the congruence ≡ generated by validated equalities.</p>
<p>For each object v ∈ Ob(J G ), Assumption (A1) states that its content can be interpreted as a subobject of S. We define the action of D G on objects as this interpretation:
D G (v) := [[content(v)]] → S.
This defines an object in the slice category (E/S).</p>
<p>A morphism in J G from u to v is an equivalence class of paths [p].It is sufficient to define the action of D G on the generating edges of these paths and show it respects the equivalence relation.</p>
<p>A generating edge corresponds to a validated dependency, typically established by a critic, from a proposition u to a proposition v. Assumption (A1) states that this dependency is interpreted as a morphism f uv : D G (u) → D G (v) over S. We define D G on this edge to be this morphism.We must show this is well-defined on equivalence classes.Assumption (A3) states that if two paths p and q are congruent (p ≡ q), their semantic interpretations are equal, i.e., D G (p) = D G (q).This ensures that the mapping D G ([p]) := D G (p) is well-defined.</p>
<p>Then we check the two functor axioms:</p>
<p>• The identity morphism on an object v in J G corresponds to the empty path from v to v. D G maps this to the identity morphism id D G (v) in (E/S).</p>
<p>• For composable morphisms [p] : u → v and [q] : v → w in J G , their composition is [q • p].By our definition, D G ([q
• p]) = D G (q) • D G (p) = D G ([q]) • D G ([p]).
Thus, D G is a valid functor from the index category J G to the slice category (E/S).Proof.We formalize synthesis as a colimit in the information order, which is the poset Pred(S) := Sub(S) op .In this poset, an arrow P → Q corresponds to an inclusion Q → P in Sub(S).Larger objects in Pred(S) represent stronger propositions (smaller subsets of S).</p>
<p>The colimit of a diagram in a poset is the join (supremum) of all objects in the diagram.The join of a set of objects {P v } in Pred(S) corresponds to their meet (infimum or greatest lower bound) in the original poset Sub(S).Therefore, the unvalidated synthesis is v∈V valid D G (v).</p>
<p>The summarizer only considers validated propositions.Semantically, this means the synthesis takes place in the subcategory of c-closed subobjects, Sub c (S).This subcategory is reflective in Sub(S), with the closure operator c : Sub(S) → Sub c (S) being the reflector (a left adjoint to the inclusion functor).</p>
<p>As a left adjoint, the reflector c preserves colimits.Therefore, the colimit in the subcategory Sub c (S) can be computed by taking the colimit in the larger category Sub(S) and then applying the reflector.</p>
<p>Since P w contains the meet of the others, intersecting with P w does not change the result.That is, if X ⊆ Y , then X ∧ Y = X.Therefore:
  v∈V valid {w} P v   ∧ P w = v∈V valid {w} P v .
Applying the closure operator c to both sides gives:
c v∈P P v = c   v∈V valid {w} P v   ,
which is precisely Summary(P) = Summary(P \ {P w }).</p>
<p>Figure 1
1
Figure1High-level illustration of the Diagram of Thought (DoT) process.Edges encode dependencies from earlier to later nodes: a critic depends on the proposition it evaluates (proposer → critic), and the summarizer depends on validated propositions.A single LLM generates the DAG representing proposing (circles), critiquing (rectangles), refining/verification, and synthesis (ellipse).</p>
<p>Figure 2
2
Figure 2 Illustrative example: Applying DoT reasoning steps to compare numerical values.Critiques might identify incorrect digit comparisons.</p>
<p>Figure 3
3
Figure 3 Illustrative example: A character-counting task where intermediate steps (identifying 'r's) and potential critiques (missed counts, double counts) could form a DoT graph.</p>
<p>(</p>
<p>A1) (Abstract Interpretation) Proposer nodes admit interpretations as subobjects of S; critique content interprets as arrows/predicates that constrain these subobjects.Edges in the DoT graph correspond to morphisms over S. 1 (A2) (Validation) The critique-driven validation corresponds to a Lawvere-Tierney closure c on Sub(S); validated nodes are exactly the c-closed subobjects.(A3) (Structural Coherence) Parallel derivations that are identified by validated critiques are considered equal.Formally, we quotient the free path category by the smallest congruence generated by critique-established equalities (see Def. 4.3).(A4) (Monicity / Posetality) For our main result, we consider the posetal case where all critiqueinduced morphisms in (E/S) are monomorphisms (refinements/inclusions).</p>
<p>Theorem 4.4 (DoT Process as Diagram Construction).A DoT reasoning process generating DAG G = (V, E) defines a functor (a diagram) D G : J G → (E/S) with:</p>
<p>Theorem 4.5 (Summarization as finite meet-plus-closure in the reflective subposet (posetal case)).Assume validated critiques induce inclusions so that the diagram of validated propositions D valid lands in the posetal fragment.Let V valid be the (finite) set of c-closed proposer nodes produced by a finite run.Then the summary is Summary = c v∈V valid D G (v) .</p>
<p>Corollary 4.6 (General case via slice sheafification (Appendix)).For a general validated diagram D valid : J valid → (E/S) with non-posetal arrows and explicit coequalizer relations extracted by Φ, the synthesized summary is Summary ∼ = a /S j colim D valid ,</p>
<p>Theorem 4.7 (Conditional consistency via closure validation).Fix E = Set C op and a closure c on Sub(S).Let V valid be the set of c-closed, non-initial subobjects produced by a run.Consider either of the following settings:1.Finite family: V valid is finite and every finite subfamily is satisfiable in the background theory T relative to a fixed context c 0 ∈ C. Then c v∈V valid D G (v) (c 0 ) ̸ = ∅ and the summary is non-initial.2. Model-compact setting: T enjoys first-order compactness and satisfaction is read in some model M |= T (not necessarily the fixed S).If every finite subset of the validated family is satisfiable in M, then there exists a model witnessing joint satisfiability of the whole family; consequently the abstract meet is non-empty in that model, and its c-closure is consistent.</p>
<p>Theorem 4 .
4
15 (Structural separation from linear CoT).Let E = Set C op , fix S ∈ E, and assume validated arrows are inclusions in Sub(S) (posetal case).Suppose a DoT run yields two validated, incomparable propositions P, Q ∈ Sub(S) (i.e., P ̸ ≤ Q and Q ̸ ≤ P ).Consider any attempt to faithfully embed this validated diagram into a linear Chain-of-Thought (a single chain of inclusions) via an inclusion-preserving functor on objects and arrows.No such embedding exists that preserves the validated arrows.Consequently, DoT's summary c(P ∧ Q) cannot be obtained by a faithful chain embedding without altering the diagram (e.g., weakening one branch to force comparability).</p>
<p>Trace ::= NodeBlock + NodeBlock ::= Node ; Edge * ; [Status] ; (Entails * | ϵ) ; (Eq * | ϵ) ; [PropBlock] ; Free * Free ::= Text | Esc Node ::= @node id=N role=(problem|proposer|critic|summarizer) Edge ::= @edge src=N dst=N kind=(refine|critique|use) Status ::= @status target=N mark=(validated|invalidated) [ just=N] Entails ::= @entails src=N dst=N [ witness=N]</p>
<p>Extraction map.Given a well-formed trace H, the extraction map Φ(H) returns: (i) a finite DAG G = (V, E) on proposer nodes; (ii) an index category J G by quotienting the free path category by validated equalities; and (iii) a diagram D G : J G → (E/S).Theorem B.1 (Totality and Determinism of Extraction).Any well-formed trace H yields a unique DAG G and a unique diagram D G under Φ.Extraction runs in O(|H| α(|H|)) time and O(|H|) space, where path equalities may add complexity depending on the congruence closure algorithm used.</p>
<p>17 :
17
Update state of target (monotonically): if σ[k] = active, set σ[k] ← m.</p>
<p>D. 1
1
Proofs for Section 3 (Operational Framework) Theorem D.1 (Totality and Determinism of Extraction (Full Proof)).Any well-formed trace H satisfying the ID and edge-typing rules yields a unique DAG G and a unique diagram D G under Φ.</p>
<p>D. 2
2
Proofs for Section 4 (Topos-Theoretic Formalization) Theorem D.3 (DoT Process as Diagram Construction).A DoT reasoning process generating DAG G = (V, E) defines a functor (a diagram) D G : J G → (E/S) with:</p>
<p>For a path p = e n • • • • • e 1 , we define its interpretation as the composition of the morphisms corresponding to the edges:D G (p) := D G (e n ) • • • • • D G (e 1 ).</p>
<p>Theorem D. 4 (
4
Summarization as finite meet-plus-closure in the reflective subposet (posetal case)).Assume validated critiques induce inclusions so that the diagram of validated propositions D valid lands in the posetal fragment.Let V valid be the (finite) set of c-closed proposer nodes produced by a finite run.Then the summary is Summary = c v∈V valid D G (v) .</p>
<p>Its state is state(v start ) = initial.• <proposer>: Signals the LLM to generate a hypothesis, intermediate reasoning step, or potential solution fragment P i .This creates a new node v P i with role(v P</p>
<p>i ) = Proposer and content(v</p>
<p>• It formalizes conditions under which synthesis preserves desirable properties via closure-based validation and a slice-colimit construction, with a precise split between the posetal and generalarrow settings (Theorem 4.5, Cor.4.6), and makes the validation modality constructible from critique schemas.• It demonstrates semantic invariance under isomorphic rearrangements (Proposition 4.10) and compositional gluing via pushouts of monos (Proposition C.3). • It strictly generalizes linear CoT in the posetal setting (Theorem 4.15), matching intuitive gains from branching with a crisp categorical witness.</p>
<p>This is a strong assumption; our framework is normative: it specifies the target semantics an ideal DoT agent should realize, enabled by the typed serialization in Section 3.2.
This appendix provides detailed proofs for the theorems, propositions, and lemmas presented in the main text. We assume familiarity with basic concepts from category theory and topos theory, as found in references like(MacLane and Moerdijk, 2012;Johnstone, 2002).
Combining these steps, the summary is the reflection of the meet of the validated propositions:Since the run is finite, the meet is over a finite set.Corollary D.5 (General case via slice sheafification).For a general validated diagram D valid : J valid → (E/S) with non-posetal arrows and explicit coequalizer relations extracted by Φ, the synthesized summary iswhere a /S j : (E/S) → (Sh j (E)/a j S) is the slice reflector (sheafification) induced by j.Proof.The logic is analogous to the posetal case but lifted from posets to general categories.A general topos, and thus its slice (E/S), is cocomplete.This means the colimit of the diagram D valid , let's call it L = colim D valid , exists in (E/S).It is constructed using coproducts to gather all information and coequalizers to enforce the dependencies and equalities specified by the diagram's arrows.The Lawvere-Tierney topology j defines a reflective subcategory of j-sheaves, Sh j (E) → E. The reflector is the sheafification functor a j .This induces a reflector on the slice categories, a /S j : (E/S) → (Sh j (E)/a j S), as stated in Lemma C.2.This functor maps objects in the slice to their "validated" or "sheafy" counterparts.As a left adjoint, the slice reflector a /S j preserves all colimits.Therefore, the summary, which is the colimit computed within the category of validated objects, is equivalent to computing the colimit first in the ambient slice category and then applying the reflector:When restricted to subobjects, the sheafification functor a j acts as the closure operator c.The colimit in the information order corresponds to the meet.Thus, for a posetal diagram, a /S j (colim D valid ) reduces to c( D G (v)), recovering the result of Theorem 4.5.Theorem D.6 (Conditional consistency via closure validation).Fix E = Set C op and a closure c on Sub(S).Let V valid be the set of c-closed, non-initial subobjects produced by a run.For a finite family, if every finite subfamily is satisfiable in the background theory T relative to a fixed context c 0 ∈ C, then the summary is non-initial.Proof.Let's focus on the finite family case, which is most relevant to practical runs.Let L = v∈V valid D G (v) be the meet of the interpretations of the validated propositions.The summary is Summary = c(L).We need to show that the summary is a non-initial subobject of S. A subobject is non-initial if its component at some stage c ∈ C is a non-empty set.The premise states that the finite family {D G (v)} v∈V valid is jointly satisfiable relative to a fixed context c 0 ∈ C. In the presheaf topos E = Set C op , this means there exists an element x ∈ S(c 0 ) such that for everyThe existence of such an element x implies that the intersection of these subsets is non-empty:In a presheaf topos, limits (including meets of subobjects) are computed componentwise.Therefore, the component of the meet subobject L at stage c 0 is precisely this intersection:Since this set is non-empty, the subobject L is non-initial.The closure operator c is extensive, meaning that for any subobject P , we have an inclusion P → c(P ).This holds componentwise, so for every c ′ ∈ C, we have P (c ′ ) ⊆ (c(P ))(c ′ ).Applying this to our meet L at context c 0 , we have:Since we established that L(c 0 ) is a non-empty set, its superset (c(L))(c 0 ) must also be non-empty.The summary, Summary = c(L), has a non-empty component at stage c 0 .Therefore, the summary is a non-initial subobject.Proposition D.7 (Robustness under Diagram Isomorphisms).Let D valid,1 : J valid,1 → (E/S) and D valid,2 : J valid,2 → (E/S) represent validated reasoning steps from two different runs.If there is an isomorphism of diagrams, then their slice-colimits are isomorphic.Proof.This is a standard result from category theory demonstrating the universal nature of colimits.Let D 1 : J 1 → C and D 2 : J 2 → C be two diagrams (here, C = (E/S)).An isomorphism of diagrams is a pair (σ, η), where σ : J 1 → J 2 is an isomorphism of categories and η :For each object i ∈ Ob(J 1 ), we have a morphism η i : D 1 (i) → D 2 (σ(i)).Composing this with the cocone map for L 2 gives a family of morphismsThis family constitutes a cocone over the diagram D 1 .By the universal property of L 1 , there exists a unique morphism h : L 1 → L 2 such that for every i ∈ Ob(J 1 ), the following diagram commutes:Since (σ, η) is an isomorphism, there exists an inverse (σ −1 , η −1 ), where η −1 : D 2 → D 1 • σ −1 is a natural isomorphism.Symmetrically, we can construct a cocone over D 2 with vertex L 1 .By the universal property of L 2 , there exists a unique morphism k :defined by its interaction with the cocone of L 1 .For any i ∈ Ob(J 1 ):From the definition of k, we have k • β j = α σ −1 (j) • (η −1 ) j .Substituting j = σ(i):Since η −1 is the inverse of η, their composition is the identity natural transformation, so (η −1 ) σ(i)So, the map k • h satisfies the same universal property as the identity map id L 1 .By the uniqueness part of the universal property, any endomorphism of the colimit object with this property must be the identity.Thus, kProposition D.8 (Properties of Synthesis).The synthesis operation, Summary(P) = c( v∈V valid P v ), exhibits Monotonicity, Idempotence, and Conservativity.Proof.Let P = {P v } v∈V valid .The properties follow directly from the definition of the summary and the standard properties of meet (∧) in a poset and a closure operator (c).We want to show that Summary(P ∪ {P new }) ⊆ Summary(P).The meet of a larger set of subobjects is always a subobject of the meet of a smaller set:The closure operator c is monotone: if X ⊆ Y , then c(X) ⊆ c(Y ).Applying c to both sides of the inclusion above preserves the relation:This is the desired result.Then we want to show Summary(P) = c( v∈P c(P v )).By assumption, all propositions in P are validated, meaning they are already c-closed.Thus, for each v ∈ V valid , P v = c(P v ).Substituting this into the right-hand side gives c( v∈P P v ), which is the definition of Summary(P).The property is inherent to the setup.Assume P w ⊇ v∈V valid {w} P v .We want to show Summary(P) = Summary(P \ {P w }).The meet of all propositions in P is:
Graph of thoughts: Solving elaborate problems with large language models. Maciej Besta, Nils Blach, Ales Kubicek, Robert Gerstenberger, Michal Podstawski, Lukas Gianinazzi, Joanna Gajda, Tomasz Lehmann, Hubert Niewiadomski, Piotr Nyczyk, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence202438</p>
<p>Language models are few-shot learners. Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Advances in neural information processing systems. 202033</p>
<p>Jie Huang, Kevin Chen, -Chuan Chang, arXiv:2212.10403Towards reasoning in large language models: A survey. 2022arXiv preprint</p>
<p>T Peter, Johnstone, Sketches of an Elephant: A Topos Theory Compendium. Oxford University Press20022</p>
<p>Large language models are zero-shot reasoners. Takeshi Kojima, Shane Shixiang, Machel Gu, Yutaka Reid, Yusuke Matsuo, Iwasawa, Advances in neural information processing systems. 202235</p>
<p>Introduction to higher-order categorical logic. Joachim Lambek, Philip J Scott, 1988Cambridge University Press7</p>
<p>Sheaves in geometry and logic: A first introduction to topos theory. Saunders Maclane, Ieke Moerdijk, 2012Springer Science &amp; Business Media</p>
<p>Self-refine: Iterative refinement with self-feedback. Aman Madaan, Niket Tandon, Prakhar Gupta, Skyler Hallinan, Luyu Gao, Sarah Wiegreffe, Uri Alon, Nouha Dziri, Shrimai Prabhumoye, Yiming Yang, arXiv:2303.176512023arXiv preprint</p>
<p>Thibaut Hugo Touvron, Gautier Lavril, Xavier Izacard, Marie-Anne Martinet, Timothée Lachaux, Baptiste Lacroix, Naman Rozière, Eric Goyal, Hambro, arXiv:2302.13971Faisal Azhar, et al. Llama: Open and efficient foundation language models. 2023arXiv preprint</p>
<p>Self-consistency improves chain of thought reasoning in language models. Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, Sharan Narang, Aakanksha Chowdhery, Denny Zhou, arXiv:2203.111712022arXiv preprint</p>
<p>Chain of thought prompting elicits reasoning in large language models. Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Ed Chi, Quoc Le, Denny Zhou, arXiv:2201.119032022arXiv preprint</p>
<p>Tree of thoughts: Deliberate problem solving with large language models. Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Thomas L Griffiths, Yuan Cao, Karthik Narasimhan, arXiv:2305.106012023arXiv preprint</p>
<p>On the power of foundation models. Yang Yuan, International Conference on Machine Learning. PMLR2023</p>
<p>Yifan Zhang, Jingqin Yang, Yang Yuan, Andrew Chi-Chih Yao, arXiv:2308.04371Cumulative reasoning with large language models. 2023arXiv preprint</p>            </div>
        </div>

    </div>
</body>
</html>