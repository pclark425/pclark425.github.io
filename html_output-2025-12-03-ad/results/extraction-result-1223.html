<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-1223 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-1223</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-1223</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-27.html">extraction-schema-27</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of world models used in AI systems, including details about their fidelity, interpretability, computational efficiency, and task-specific utility.</div>
                <p><strong>Paper ID:</strong> paper-260775912</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2308.05701v2.pdf" target="_blank">Exploring the Potential of World Models for Anomaly Detection in Autonomous Driving</a></p>
                <p><strong>Paper Abstract:</strong> In recent years there have been remarkable advancements in autonomous driving. While autonomous vehicles demonstrate high performance in closed-set conditions, they encounter difficulties when confronted with unexpected situations. At the same time, world models emerged in the field of model-based reinforcement learning as a way to enable agents to predict the future depending on potential actions. This led to outstanding results in sparse reward and complex control tasks. This work provides an overview of how world models can be leveraged to perform anomaly detection in the domain of autonomous driving. We provide a characterization of world models and relate individual components to previous works in anomaly detection to facilitate further research in the field.</p>
                <p><strong>Cost:</strong> 0.021</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e1223.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e1223.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of world models used in AI systems, including details about their fidelity, interpretability, computational efficiency, and task-specific utility.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>World Models (Ha & Schmidhuber)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>World Models (Ha and Schmidhuber)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A class of latent-space generative models that embed high-dimensional visual observations into a compact latent state via a VAE-style encoder, learn action-conditioned dynamics in latent space, and decode latent states back to observations for prediction and planning.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>World Models</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>World Models (Ha & Schmidhuber)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Convolutional VAE encoder maps image frames to a low-dimensional Gaussian latent (e.g., 32-D µ, σ), an MDN-RNN (Mixture Density Network on top of an RNN) models p(s_{t+1}|s_t,a_t,h_t) to capture stochastic next-state distributions, and a decoder reconstructs observations from latent states; designed for action-conditioned imagination and planning.</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>latent world model</td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>model-based reinforcement learning (demonstrated on control tasks and simulated environments / games)</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_metric</strong></td>
                            <td>reconstruction loss (VAE ELBO), next-state prediction likelihood (MDN loss), sampling-based prediction quality</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_performance</strong></td>
                            <td>Qualitative: reported to produce strong task results in sparse-reward and complex control tasks; no numerical fidelity metrics provided in this survey paper.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_assessment</strong></td>
                            <td>Partially interpretable: latent Gaussian factors can be visualized and sampled; however core transition (MDN-RNN) is a neural black box, so only indirect interpretability via latent traversals and reconstructions is possible.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_method</strong></td>
                            <td>visualization of latent samples and reconstructions; inspection of generated rollouts (imagination); no explicit symbolic interpretation reported here.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost</strong></td>
                            <td>Not quantified in this paper; architecture implies modest-size encoder/MDN-RNN but training cost depends on dataset size; no explicit GPU/time counts given.</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_comparison</strong></td>
                            <td>Paper states model-based approaches (world models) can reduce expensive policy learning by enabling policy training inside the learned model, but no quantitative efficiency comparison provided.</td>
                        </tr>
                        <tr>
                            <td><strong>task_performance</strong></td>
                            <td>Reported qualitatively as producing 'outstanding results' on sparse reward and complex control benchmarks in prior work; no numeric task metrics in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>task_utility_analysis</strong></td>
                            <td>World Models provide actionable imagined trajectories for planning and anomaly detection; high-fidelity reconstructions help detection, but VAEs can generalize to unseen data making anomaly detection nontrivial.</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoffs_observed</strong></td>
                            <td>Stochastic MDN-RNN captures multiple futures but increases modeling complexity; deterministic components (RNN hidden path) help memory but risk collapsing multi-future modeling — a trade-off between remembering history and modeling multimodality.</td>
                        </tr>
                        <tr>
                            <td><strong>design_choices</strong></td>
                            <td>Uses convolutional VAE encoder to Gaussian latents, MDN-RNN transition model, decoder for reconstruction; Gaussian prior chosen to regularize latent space and improve robustness to unrealistic predicted latents.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Compared qualitatively to model-free RL: world models allow imagination-based policy learning and unified predictive/reconstructive functionality versus separate models for perception/prediction; no quantitative baselines provided.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_configuration</strong></td>
                            <td>No single optimal config given; paper emphasizes design choices (stochastic vs deterministic paths, latent dimensionality, training data cleanliness) and recommends careful training and definition of normality for downstream tasks like anomaly detection.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Exploring the Potential of World Models for Anomaly Detection in Autonomous Driving', 'publication_date_yy_mm': '2023-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1223.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e1223.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of world models used in AI systems, including details about their fidelity, interpretability, computational efficiency, and task-specific utility.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>PlaNet</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>PlaNet (Learning Latent Dynamics for Planning from Pixels)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A model-based agent that learns latent dynamics (RSSM) from pixel observations to plan via imagined latent trajectories, combining deterministic RNN hidden path with stochastic latent states.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Learning Latent Dynamics for Planning from Pixels</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>PlaNet (RSSM-based latent dynamics)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Uses a Recurrent State Space Model (RSSM): deterministic hidden state h_t = f(h_{t-1}, s_{t-1}, a_{t-1}) implemented with an RNN and a stochastic state s_t sampled from p(s_t|h_t); paired with VAE-style encoder/decoder for observation mapping and planning over imagined latent trajectories.</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>latent world model (RSSM hybrid deterministic-stochastic)</td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>model-based RL planning from pixels; control tasks and simulated environments</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_metric</strong></td>
                            <td>latent transition log-likelihood, reconstruction loss (VAE ELBO), planning return (task reward)</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_performance</strong></td>
                            <td>Reported to enable planning in latent space with good empirical task performance in prior work; no numeric fidelity values provided in this survey.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_assessment</strong></td>
                            <td>Latent states and deterministic path can be inspected via decoded reconstructions; transition dynamics remain neural and largely black-box except via visualization of rollouts.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_method</strong></td>
                            <td>visualization of imagined latent trajectories decoded to pixels; no explicit symbolic interpretability methods reported here.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost</strong></td>
                            <td>Not specified; RSSM adds both deterministic and stochastic components increasing model complexity relative to simple SSMs; no runtime or parameter counts given.</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_comparison</strong></td>
                            <td>PlaNet/Dreamer-style RSSMs are described as effective for planning versus training policies in the real environment; no quantitative efficiency numbers reported.</td>
                        </tr>
                        <tr>
                            <td><strong>task_performance</strong></td>
                            <td>Described qualitatively as enabling planning over imagined trajectories and good task performance in prior benchmarks; no explicit numbers given in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>task_utility_analysis</strong></td>
                            <td>RSSM's hybrid design trades memory (deterministic path) and multimodal prediction (stochastic path) to support planning; useful for anomaly detection by predicting action-conditioned futures and comparing to observations.</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoffs_observed</strong></td>
                            <td>RSSM deterministic path aids memory but can hinder modeling multiple futures; stochastic path models multimodality but struggles with long-term memory — explicit trade-off discussed.</td>
                        </tr>
                        <tr>
                            <td><strong>design_choices</strong></td>
                            <td>Combines deterministic RNN hidden states with stochastic latent variables; uses VAE embedding and action-conditioned transitions; sampling-based rollouts for multiple futures.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Compared conceptually to purely deterministic SSMs and fully stochastic SSMs; RSSM balances both to enable planning while modeling multiple futures; no empirical head-to-head numbers in this survey.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_configuration</strong></td>
                            <td>No prescriptive optimum; paper highlights RSSM benefits for planning and suggests attention to uncertainty and memory design when applying to anomaly detection.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Exploring the Potential of World Models for Anomaly Detection in Autonomous Driving', 'publication_date_yy_mm': '2023-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1223.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e1223.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of world models used in AI systems, including details about their fidelity, interpretability, computational efficiency, and task-specific utility.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Dreamer / DreamerV2 / DreamerV3</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Dreamer family (latent imagination agents, Dreamer, DreamerV2, DreamerV3)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Agents that learn world models for latent imagination to train policies entirely within the learned model; later iterations replace Gaussian latents with categorical latents for improved discrete representations and scalability.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Dream to Control: Learning Behaviors by Latent Imagination</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Dreamer (and DreamerV2/V3)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Uses PlaNet-style RSSM world model to learn a latent dynamics model plus actor-critic architectures that are trained by imagining trajectories in the latent space; DreamerV2/V3 introduce categorical latent spaces (discrete latent distributions) instead of Gaussian latents.</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>latent world model (imagination-based policy learning)</td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>model-based RL (control tasks, diverse domains including Atari; general RL benchmarks)</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_metric</strong></td>
                            <td>reconstruction loss (ELBO), imagined-trajectory policy returns, next-state prediction likelihood</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_performance</strong></td>
                            <td>Described qualitatively as enabling high task performance on diverse domains in cited literature; this survey provides no numeric scores.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_assessment</strong></td>
                            <td>Latent representations can be inspected via decoding; categorical latents may improve interpretability of discrete factors but overall model remains neural and not fully transparent.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_method</strong></td>
                            <td>visualization of decoded latent imaginations and trajectory rollouts; no explicit explainability algorithms described in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost</strong></td>
                            <td>Not quantified here; training Dreamer family is nontrivial but exact compute budgets/parameter counts are not provided in this survey.</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_comparison</strong></td>
                            <td>Reported as effective for training behaviors by imagination, reducing real-environment interactions; no quantitative comparisons included in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>task_performance</strong></td>
                            <td>Prior Dreamer work cited as achieving strong RL performance; survey notes Dreamer reuses PlaNet RSSM and is effective for policy learning, no numeric metrics provided.</td>
                        </tr>
                        <tr>
                            <td><strong>task_utility_analysis</strong></td>
                            <td>Dreamer shows that accurate latent prediction and imagination can translate into strong policy performance; however, survey warns that model fidelity does not automatically guarantee downstream success in new tasks like anomaly detection unless normality is well defined.</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoffs_observed</strong></td>
                            <td>Switching Gaussian to categorical latents (DreamerV2/V3) is a design trade-off intended to improve representation power and scalability, possibly at cost of different training dynamics and interpretability trade-offs.</td>
                        </tr>
                        <tr>
                            <td><strong>design_choices</strong></td>
                            <td>RSSM backbone, latent imagination for policy learning, iterations moving from Gaussian to categorical latent representations.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Compared at a qualitative level to model-free RL: Dreamer enables policy learning inside a model, often more sample-efficient; no numerical head-to-head numbers provided in the surveyed paper.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_configuration</strong></td>
                            <td>No single recommended configuration; paper suggests that selection of latent type (Gaussian vs categorical), uncertainty handling, and training data definition are key considerations for downstream uses like anomaly detection.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Exploring the Potential of World Models for Anomaly Detection in Autonomous Driving', 'publication_date_yy_mm': '2023-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1223.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e1223.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of world models used in AI systems, including details about their fidelity, interpretability, computational efficiency, and task-specific utility.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>E2C</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Embed to Control (E2C)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A locally-linear latent dynamics model that encodes images into a Gaussian latent and assumes locally linear dynamics for control in latent space.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Embed to Control: A Locally Linear Latent Dynamics Model for Control from Raw Images</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>E2C (Embed to Control)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>VAE-style encoder produces Gaussian latent states; dynamics assumed locally linear at each timestep, approximating global nonlinear dynamics via local Jacobians A(s), B(s) and sampling next-state from a Gaussian with linearized dynamics.</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>latent world model (locally-linear SSM)</td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>control from raw images (model-based control tasks)</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_metric</strong></td>
                            <td>reconstruction error, next-state MSE under locally-linear approximation</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_performance</strong></td>
                            <td>Not specified numerically in this survey; presented historically as a notable locally-linear latent dynamics approach.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_assessment</strong></td>
                            <td>Some interpretability from locally-linear assumption (Jacobian matrices relate latent/state derivatives) but core components are neural nets making full interpretability limited.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_method</strong></td>
                            <td>analysis via local Jacobians (A(s), B(s)) approximating dynamics; no broader explainability methods described here.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost</strong></td>
                            <td>Not quantified in paper.</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_comparison</strong></td>
                            <td>Locally-linear dynamics aim for computationally tractable control in latent space; no quantitative comparisons provided here.</td>
                        </tr>
                        <tr>
                            <td><strong>task_performance</strong></td>
                            <td>Recognized historically as useful for control tasks from images; survey provides no numeric metrics.</td>
                        </tr>
                        <tr>
                            <td><strong>task_utility_analysis</strong></td>
                            <td>Design prioritizes locally-linear control-relevant structure, which may improve control utility at the cost of expressiveness for highly nonlinear global dynamics.</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoffs_observed</strong></td>
                            <td>Local linearization trades global expressivity for locally interpretable dynamics and potentially simpler planning/control.</td>
                        </tr>
                        <tr>
                            <td><strong>design_choices</strong></td>
                            <td>Gaussian VAE latent with locally-linear transition model and explicit Jacobian parameterization A(s), B(s).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Compared conceptually to fully neural transition models (e.g., RSSM) which model complex nonlinearities at the expense of structured interpretability.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_configuration</strong></td>
                            <td>No explicit optimal configuration for anomaly detection; paper notes locally-linear assumption may be suitable when control-oriented structure is a priority.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Exploring the Potential of World Models for Anomaly Detection in Autonomous Driving', 'publication_date_yy_mm': '2023-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1223.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e1223.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of world models used in AI systems, including details about their fidelity, interpretability, computational efficiency, and task-specific utility.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>RSSM</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Recurrent State Space Model (RSSM)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A hybrid transition architecture that combines deterministic RNN hidden states (deterministic path) with stochastic latent states (stochastic path) to model sequential latent dynamics for planning and imagination.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Learning Latent Dynamics for Planning from Pixels</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>RSSM (Recurrent State Space Model)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Transition model with deterministic state h_t = f(h_{t-1}, s_{t-1}, a_{t-1}) implemented by an RNN and stochastic state s_t sampled from p(s_t|h_t); enables both memory via h_t and multimodal predictions via stochastic s_t.</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>latent world model (hybrid deterministic-stochastic)</td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>planning and control from pixels; used in PlaNet and Dreamer families</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_metric</strong></td>
                            <td>prediction likelihood in latent space, quality of decoded imagined rollouts, reconstruction ELBO</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_performance</strong></td>
                            <td>No numeric metrics in survey; described as effective for planning and imagination in prior literature.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_assessment</strong></td>
                            <td>Partially interpretable via decoded rollouts; internal h_t and s_t are neural and not directly semantically interpreted in general.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_method</strong></td>
                            <td>visualization of decoded imagined trajectories and latent samples; no explicit introspection tools discussed here.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost</strong></td>
                            <td>More expensive than purely stochastic or purely deterministic SSMs due to maintaining both paths; no explicit compute numbers provided.</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_comparison</strong></td>
                            <td>Described qualitatively as balancing capability to remember (deterministic path) and model multimodality (stochastic path); no quantitative efficiency comparisons.</td>
                        </tr>
                        <tr>
                            <td><strong>task_performance</strong></td>
                            <td>Enables successful planning-based control in prior works (PlaNet/Dreamer); survey does not supply numerical benchmarks.</td>
                        </tr>
                        <tr>
                            <td><strong>task_utility_analysis</strong></td>
                            <td>RSSM is useful for downstream tasks (planning, anomaly detection) as it can generate multiple futures and maintain history; however, latent correction is limited compared to Bayesian update schemes.</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoffs_observed</strong></td>
                            <td>Deterministic path helps with memory but limits multiple-future modeling; stochastic path supports multi-future but makes long-term memory harder — core trade-off discussed.</td>
                        </tr>
                        <tr>
                            <td><strong>design_choices</strong></td>
                            <td>Hybrid design mixing RNN hidden state and stochastic latent sampling; action-conditioned transitions.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Compared to VRKN which removes need for deterministic path by using Kalman-style updates and principled uncertainty handling; RSSM is simpler but may overestimate aleatoric uncertainty.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_configuration</strong></td>
                            <td>Not specified; paper suggests considering uncertainty handling and Kalman updates for settings requiring principled correction of latent estimates.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Exploring the Potential of World Models for Anomaly Detection in Autonomous Driving', 'publication_date_yy_mm': '2023-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1223.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e1223.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of world models used in AI systems, including details about their fidelity, interpretability, computational efficiency, and task-specific utility.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>VRKN</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Variational Recurrent Kalman Network (VRKN)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A state-space world model that integrates principled Gaussian filtering (Kalman updates) with learned encoders to maintain and correct latent state estimates, explicitly modeling aleatoric and epistemic uncertainty.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>On Uncertainty in Deep State Space Models for Model-Based Reinforcement Learning</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>VRKN (Variational Recurrent Kalman Networks)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Encodes observations to intermediate representation w_t and covariance, computes latent state estimates via Gaussian marginalization and Kalman updates consistent with the generative model, captures epistemic uncertainty via Monte Carlo dropout, and represents aleatoric uncertainty in latent distributions.</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>latent world model (probabilistic state-space with Kalman-style inference)</td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>model-based RL and sequential state estimation tasks; proposed as more principled uncertainty-aware latent dynamics</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_metric</strong></td>
                            <td>likelihoods under generative model, calibrated uncertainty estimates, reconstruction loss; improved calibration of aleatoric/epistemic uncertainty</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_performance</strong></td>
                            <td>Survey reports that VRKN eliminates overestimation of aleatoric uncertainty present in RSSMs and can correct latent estimates with Kalman updates, but provides no numeric performance figures in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_assessment</strong></td>
                            <td>Improved interpretability of uncertainty due to explicit Gaussian updating and separate epistemic/aleatoric modeling; latent state corrections have a probabilistic semantics.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_method</strong></td>
                            <td>Kalman update equations and explicit covariance propagation give principled uncertainty diagnostics; Monte Carlo dropout used to estimate epistemic uncertainty.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost</strong></td>
                            <td>Not quantified; Kalman computations introduce closed-form Gaussian marginalizations which may be computationally efficient relative to complex learned inference schemes, but total cost depends on implementation.</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_comparison</strong></td>
                            <td>Claimed to avoid overestimation of uncertainty and provide more principled inference than RSSM; no numerical efficiency comparisons in survey.</td>
                        </tr>
                        <tr>
                            <td><strong>task_performance</strong></td>
                            <td>Argued to yield better calibrated uncertainty and improved state estimation vs RSSM in prior work; no numeric task metrics in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>task_utility_analysis</strong></td>
                            <td>Better-specified uncertainties and latent correction via Kalman updates make VRKNs attractive for anomaly detection where principled confidence and correction are important.</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoffs_observed</strong></td>
                            <td>VRKN trades design complexity (Bayesian updates, dropout-based epistemic estimates) for better uncertainty calibration and correctability of latent states compared to RSSM.</td>
                        </tr>
                        <tr>
                            <td><strong>design_choices</strong></td>
                            <td>Bayesian-Gaussian marginalization and Kalman updates; explicit separation of epistemic and aleatoric uncertainty; encoding to intermediate representation with covariance outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Contrasted to RSSM which cannot correct latent state estimates and tends to overestimate aleatoric uncertainty; VRKN presented as more principled for uncertainty-sensitive tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_configuration</strong></td>
                            <td>Paper suggests VRKN-like Bayesian updating is preferable when accurate uncertainty and latent-state correction are required (e.g., anomaly detection), but no single optimal architecture prescribed.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Exploring the Potential of World Models for Anomaly Detection in Autonomous Driving', 'publication_date_yy_mm': '2023-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1223.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e1223.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of world models used in AI systems, including details about their fidelity, interpretability, computational efficiency, and task-specific utility.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>MILE</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Model-Based Imitation Learning (MILE)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A world-model approach applied to urban driving that uses imitation learning rather than RL, encoding high-resolution observations, lifting features into 3D, and pooling into bird's-eye view (BEV) for predictions.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Model-Based Imitation Learning for Urban Driving</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>MILE (Model-Based Imitation Learning)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Encodes high-resolution observations and learns depth distributions per feature, lifts features into 3D, pools into BEV space and maps to vectors; transition model computes deterministic history h_t from h_{t-1} and s_{t-1} and then stochastic s_t conditioned on h_t and actions.</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>latent world model adapted for imitation learning (vision-to-BEV latent dynamics)</td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>autonomous driving (urban driving predictions and planning via imitation learning)</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_metric</strong></td>
                            <td>reconstruction/prediction loss on BEV features, imitation loss vs expert trajectories; fidelity measured in prior work via downstream imitation metrics</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_performance</strong></td>
                            <td>No numerical metrics provided in this survey; MILE is described as adapting world model ideas to driving tasks with BEV representations.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_assessment</strong></td>
                            <td>BEV feature representations offer more interpretable spatial structure than raw pixel latents; latent-to-BEV mapping aids scene-level interpretability.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_method</strong></td>
                            <td>lifting pixels to 3D and pooling into BEV provides spatially grounded latent features; visual inspection of BEV reconstructions/rollouts.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost</strong></td>
                            <td>Not specified; lifting high-resolution features and depth distributions implies nontrivial compute, but no explicit numbers given.</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_comparison</strong></td>
                            <td>MILE follows world-model design but applied with IL and BEV lifting to be more suitable for driving; no direct efficiency comparisons given.</td>
                        </tr>
                        <tr>
                            <td><strong>task_performance</strong></td>
                            <td>Reported in referenced MILE work as effective for urban driving imitation; survey contains no numeric task outcomes.</td>
                        </tr>
                        <tr>
                            <td><strong>task_utility_analysis</strong></td>
                            <td>Design emphasizes task relevance by constructing BEV latent features and conditioning transitions on planned actions — likely improving utility for driving anomaly detection because rollouts are action-conditioned and spatially grounded.</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoffs_observed</strong></td>
                            <td>Use of high-resolution encoders and BEV lifting increases representational fidelity at computational cost; no numeric trade-offs provided.</td>
                        </tr>
                        <tr>
                            <td><strong>design_choices</strong></td>
                            <td>High-resolution encoding, learned depth distributions per feature, lifting to BEV, action-conditioned stochastic state model with deterministic history derived from h_{t-1} and s_{t-1}.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>MILE contrasts with RL-based world models by using imitation learning and BEV-lifted features to better fit autonomous driving tasks; survey notes MILE as a driving-domain adaptation of world model ideas.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_configuration</strong></td>
                            <td>Paper recommends designing training/evaluation datasets and normality definitions carefully and using planned actions for rollouts; MILE's BEV/lift design is recommended for driving-specific tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Exploring the Potential of World Models for Anomaly Detection in Autonomous Driving', 'publication_date_yy_mm': '2023-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1223.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e1223.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of world models used in AI systems, including details about their fidelity, interpretability, computational efficiency, and task-specific utility.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GAIA-1 (Wayve)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>GAIA-1 (Wayve's generative world model)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An industrial-scale generative world model trained on fleet data that leverages video, text, and action inputs to generate realistic driving videos and likely supports downstream autonomy tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Introducing GAIA-1: A Cutting-Edge Generative AI Model for Autonomy</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GAIA-1</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Described as a large-scale generative model ingesting multimodal fleet data (video, text, actions) to produce realistic driving video predictions; exact architecture not detailed in the surveyed paper.</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>large-scale generative world model / foundation model for autonomy</td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>autonomous driving (fleet-scale learning, video generation, autonomy foundation model)</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_metric</strong></td>
                            <td>not specified in this survey; likely measured by realism of generated driving videos and downstream performance on autonomy tasks in original Wayve materials</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_performance</strong></td>
                            <td>Not reported in this paper; only qualitative statement that it generates realistic driving videos when trained on fleet data.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_assessment</strong></td>
                            <td>No interpretability details given; industrial generative models are typically neural and largely opaque unless inspected with additional tools.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_method</strong></td>
                            <td>not described in this survey.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost</strong></td>
                            <td>Implied large-scale fleet training (high compute) but no concrete numbers provided.</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_comparison</strong></td>
                            <td>Not quantified; suggested as an industrial instantiation of world models trained at scale, implying high data and compute efficiency for broad coverage but no explicit comparisons.</td>
                        </tr>
                        <tr>
                            <td><strong>task_performance</strong></td>
                            <td>Not quantified here; presented as an early industrial example of world models for autonomy.</td>
                        </tr>
                        <tr>
                            <td><strong>task_utility_analysis</strong></td>
                            <td>Large-scale multimodal world models may provide broad generalization, but survey cautions that defining normality and controlling training data is critical for anomaly detection use-cases.</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoffs_observed</strong></td>
                            <td>Implied trade-off: fleet-scale training improves coverage but risks incorporating unlabeled anomalies into the notion of normality, complicating anomaly detection.</td>
                        </tr>
                        <tr>
                            <td><strong>design_choices</strong></td>
                            <td>Multimodal inputs (video, text, actions) and large-scale fleet training; specifics not provided in the survey.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Presented as an industrial counterpart to academic world models; no empirical comparisons provided.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_configuration</strong></td>
                            <td>Survey emphasizes the need for careful training-data curation and definitions of normality when using fleet-trained foundation world models for anomaly detection.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Exploring the Potential of World Models for Anomaly Detection in Autonomous Driving', 'publication_date_yy_mm': '2023-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1223.8">
                <h3 class="extraction-instance">Extracted Data Instance 8 (e1223.8)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of world models used in AI systems, including details about their fidelity, interpretability, computational efficiency, and task-specific utility.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Tesla general world model</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Tesla 'general world model' (Elluswamy)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Early reported industrial efforts at a general world model for autonomy trained on fleet data, intended as a foundation model for driving.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Foundation models for autonomy</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Tesla (general world model, as referenced)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Described in cited material as a fleet-trained general world model for autonomy; paper gives no architectural details beyond being trained at fleet scale on driving data.</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>large-scale generative world model / foundation model for autonomy</td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>autonomous driving (fleet-scale foundation model)</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_metric</strong></td>
                            <td>not specified in this survey; likely assessed by realism of predictions and downstream autonomy metrics in originating work</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_performance</strong></td>
                            <td>Not reported in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_assessment</strong></td>
                            <td>No interpretability information provided in the survey.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_method</strong></td>
                            <td>not described.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost</strong></td>
                            <td>Implied to be large due to fleet-scale training; no quantitative details.</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_comparison</strong></td>
                            <td>Not provided; survey mentions it as an industrial example but no quantitative comparisons.</td>
                        </tr>
                        <tr>
                            <td><strong>task_performance</strong></td>
                            <td>Not provided within this survey.</td>
                        </tr>
                        <tr>
                            <td><strong>task_utility_analysis</strong></td>
                            <td>Large-scale world models may generalize well but could absorb unlabeled anomalies into the training distribution, challenging anomaly detection unless training data are curated.</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoffs_observed</strong></td>
                            <td>Potential trade-off between wide coverage from fleet data and contamination of normality with anomalies; survey highlights this concern.</td>
                        </tr>
                        <tr>
                            <td><strong>design_choices</strong></td>
                            <td>Not specified in survey; only that it is trained on fleet data.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Mentioned as industrial parallel to academic world models (e.g., PlaNet/Dreamer) but no direct comparison available.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_configuration</strong></td>
                            <td>Survey recommends careful control of training and evaluation datasets to define normality when using fleet-trained foundation models for anomaly detection.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Exploring the Potential of World Models for Anomaly Detection in Autonomous Driving', 'publication_date_yy_mm': '2023-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1223.9">
                <h3 class="extraction-instance">Extracted Data Instance 9 (e1223.9)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of world models used in AI systems, including details about their fidelity, interpretability, computational efficiency, and task-specific utility.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>MDN-RNN</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Mixture Density Network - RNN (MDN-RNN)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A recurrent neural network whose outputs parameterize a mixture distribution over next latent states, enabling stochastic multi-modal next-state predictions in world models.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>World Models</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>MDN-RNN</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>RNN (e.g., LSTM/GRU) outputs mixture distribution parameters (weights, means, variances) for next-state latent distribution p(s_{t+1}|s_t,a_t,h_t), allowing sampling of multiple possible futures.</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>stochastic transition model component for latent world models</td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>used inside latent world models for control and planning (e.g., video-based model learning / RL)</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_metric</strong></td>
                            <td>mixture density negative log-likelihood, predictive log-likelihood, sample quality when decoded</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_performance</strong></td>
                            <td>No numerical performance values reported in this survey; MDN-RNN cited as a component in prior world model work.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_assessment</strong></td>
                            <td>Stochastic mixture components are somewhat interpretable (modes correspond to different predicted futures), but overall RNN dynamics remain black-box.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_method</strong></td>
                            <td>inspection of mixture modes and sampled rollouts decoded to pixels; no formal interpretability methods described here.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost</strong></td>
                            <td>Not quantified; MDN outputs increase parameterization relative to unimodal outputs but costs not specified.</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_comparison</strong></td>
                            <td>MDN-RNN enables multimodal predictions versus unimodal Gaussian predictions; computational overhead implied but not quantified.</td>
                        </tr>
                        <tr>
                            <td><strong>task_performance</strong></td>
                            <td>Enables multiple-future modeling important for planning and anomaly detection; survey provides no numeric metrics.</td>
                        </tr>
                        <tr>
                            <td><strong>task_utility_analysis</strong></td>
                            <td>Useful for capturing multimodality in next-state predictions which is valuable for anticipating alternative futures and detecting deviations (anomalies).</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoffs_observed</strong></td>
                            <td>Modeling multiple modes increases representational power but complicates training and sampling; potential increased computation and instability versus simpler predictors.</td>
                        </tr>
                        <tr>
                            <td><strong>design_choices</strong></td>
                            <td>Use of mixture outputs (weights/means/variances) from an RNN to model stochastic transitions.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Compared implicitly to single-Gaussian predictors and RSSM-style stochastic pathways; MDN-RNN offers richer multimodality at additional complexity.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_configuration</strong></td>
                            <td>Not specified here; selection between MDN-RNN and RSSM/Kalman-style models depends on desired trade-off between multimodality and principled uncertainty correction.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Exploring the Potential of World Models for Anomaly Detection in Autonomous Driving', 'publication_date_yy_mm': '2023-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1223.10">
                <h3 class="extraction-instance">Extracted Data Instance 10 (e1223.10)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of world models used in AI systems, including details about their fidelity, interpretability, computational efficiency, and task-specific utility.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>SABer-VAE</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Structural Attention-based Recurrent VAE (SABer-VAE)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An approach for vehicle-trajectory anomaly detection that encodes vehicle-vehicle and lane-vehicle interactions, uses attention modules and a stochastic Koopman-based transition to predict next vehicle states for anomaly scoring.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Structural Attention-Based Recurrent Variational Autoencoder for Highway Vehicle Anomaly Detection</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>SABer-VAE (Chakraborty et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Dual-path encoder: one path with self-attention models vehicle-vehicle interactions producing Gaussian latent parameters µ,σ; second path models lane-vehicle interactions; transition uses a stochastic Koopman operator where NN-predicted Koopman matrices evolve latent states for one-step predictions; anomaly score derived from prediction loss.</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>latent predictive model for trajectory data (attention-VAE with Koopman transition)</td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>trajectory anomaly detection (highway vehicle trajectories)</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_metric</strong></td>
                            <td>prediction loss on future vehicle states (used as anomaly score), likelihood under latent VAE distribution</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_performance</strong></td>
                            <td>No numeric fidelity/performance metrics provided in this survey; presented as a trajectory-specific anomaly detection instantiation using latent prediction.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_assessment</strong></td>
                            <td>Attention modules and Koopman matrices give partial structure for interpreting interactions and linearized dynamics in latent space; overall neural components remain partially opaque.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_method</strong></td>
                            <td>attention visualization for interaction modeling and inspection of predicted Koopman dynamics; anomaly scores derived from prediction errors.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost</strong></td>
                            <td>Not provided in this survey.</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_comparison</strong></td>
                            <td>Designed to operate on trajectory graphs rather than raw sensor pixels, implying computational efficiency for trajectory data; no quantitative comparison provided.</td>
                        </tr>
                        <tr>
                            <td><strong>task_performance</strong></td>
                            <td>Claims usefulness for trajectory anomaly detection in cited work; survey provides no numerical benchmarks.</td>
                        </tr>
                        <tr>
                            <td><strong>task_utility_analysis</strong></td>
                            <td>SABer-VAE shows an example where latent predictive world-model ideas (embedding + transition + decoding/prediction) are effective for anomaly detection in structured trajectory data.</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoffs_observed</strong></td>
                            <td>Specialized trajectory modeling (attention + Koopman) trades generality on raw sensor domains for better structured modeling of vehicle interactions.</td>
                        </tr>
                        <tr>
                            <td><strong>design_choices</strong></td>
                            <td>Self-attention for interactions, dual-encoder design, stochastic Koopman operator for transition modeling, Gaussian latent VAE encoding.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Contrasted implicitly with sensor-based world models; SABer-VAE uses map/trajectory inputs and is not action-conditioned in the same way as sensor-world models.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_configuration</strong></td>
                            <td>Not specified in this survey; example highlights that task-specialized embedding and transition choices (attention + Koopman) improve utility on trajectory anomaly detection.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Exploring the Potential of World Models for Anomaly Detection in Autonomous Driving', 'publication_date_yy_mm': '2023-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>World Models <em>(Rating: 2)</em></li>
                <li>Learning Latent Dynamics for Planning from Pixels <em>(Rating: 2)</em></li>
                <li>Dream to Control: Learning Behaviors by Latent Imagination <em>(Rating: 2)</em></li>
                <li>Mastering Atari with Discrete World Models <em>(Rating: 1)</em></li>
                <li>Embed to Control: A Locally Linear Latent Dynamics Model for Control from Raw Images <em>(Rating: 2)</em></li>
                <li>On Uncertainty in Deep State Space Models for Model-Based Reinforcement Learning <em>(Rating: 2)</em></li>
                <li>Model-Based Imitation Learning for Urban Driving <em>(Rating: 2)</em></li>
                <li>Structural Attention-Based Recurrent Variational Autoencoder for Highway Vehicle Anomaly Detection <em>(Rating: 2)</em></li>
                <li>Introducing GAIA-1: A Cutting-Edge Generative AI Model for Autonomy <em>(Rating: 1)</em></li>
                <li>Foundation models for autonomy <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-1223",
    "paper_id": "paper-260775912",
    "extraction_schema_id": "extraction-schema-27",
    "extracted_data": [
        {
            "name_short": "World Models (Ha & Schmidhuber)",
            "name_full": "World Models (Ha and Schmidhuber)",
            "brief_description": "A class of latent-space generative models that embed high-dimensional visual observations into a compact latent state via a VAE-style encoder, learn action-conditioned dynamics in latent space, and decode latent states back to observations for prediction and planning.",
            "citation_title": "World Models",
            "mention_or_use": "mention",
            "model_name": "World Models (Ha & Schmidhuber)",
            "model_description": "Convolutional VAE encoder maps image frames to a low-dimensional Gaussian latent (e.g., 32-D µ, σ), an MDN-RNN (Mixture Density Network on top of an RNN) models p(s_{t+1}|s_t,a_t,h_t) to capture stochastic next-state distributions, and a decoder reconstructs observations from latent states; designed for action-conditioned imagination and planning.",
            "model_type": "latent world model",
            "task_domain": "model-based reinforcement learning (demonstrated on control tasks and simulated environments / games)",
            "fidelity_metric": "reconstruction loss (VAE ELBO), next-state prediction likelihood (MDN loss), sampling-based prediction quality",
            "fidelity_performance": "Qualitative: reported to produce strong task results in sparse-reward and complex control tasks; no numerical fidelity metrics provided in this survey paper.",
            "interpretability_assessment": "Partially interpretable: latent Gaussian factors can be visualized and sampled; however core transition (MDN-RNN) is a neural black box, so only indirect interpretability via latent traversals and reconstructions is possible.",
            "interpretability_method": "visualization of latent samples and reconstructions; inspection of generated rollouts (imagination); no explicit symbolic interpretation reported here.",
            "computational_cost": "Not quantified in this paper; architecture implies modest-size encoder/MDN-RNN but training cost depends on dataset size; no explicit GPU/time counts given.",
            "efficiency_comparison": "Paper states model-based approaches (world models) can reduce expensive policy learning by enabling policy training inside the learned model, but no quantitative efficiency comparison provided.",
            "task_performance": "Reported qualitatively as producing 'outstanding results' on sparse reward and complex control benchmarks in prior work; no numeric task metrics in this paper.",
            "task_utility_analysis": "World Models provide actionable imagined trajectories for planning and anomaly detection; high-fidelity reconstructions help detection, but VAEs can generalize to unseen data making anomaly detection nontrivial.",
            "tradeoffs_observed": "Stochastic MDN-RNN captures multiple futures but increases modeling complexity; deterministic components (RNN hidden path) help memory but risk collapsing multi-future modeling — a trade-off between remembering history and modeling multimodality.",
            "design_choices": "Uses convolutional VAE encoder to Gaussian latents, MDN-RNN transition model, decoder for reconstruction; Gaussian prior chosen to regularize latent space and improve robustness to unrealistic predicted latents.",
            "comparison_to_alternatives": "Compared qualitatively to model-free RL: world models allow imagination-based policy learning and unified predictive/reconstructive functionality versus separate models for perception/prediction; no quantitative baselines provided.",
            "optimal_configuration": "No single optimal config given; paper emphasizes design choices (stochastic vs deterministic paths, latent dimensionality, training data cleanliness) and recommends careful training and definition of normality for downstream tasks like anomaly detection.",
            "uuid": "e1223.0",
            "source_info": {
                "paper_title": "Exploring the Potential of World Models for Anomaly Detection in Autonomous Driving",
                "publication_date_yy_mm": "2023-12"
            }
        },
        {
            "name_short": "PlaNet",
            "name_full": "PlaNet (Learning Latent Dynamics for Planning from Pixels)",
            "brief_description": "A model-based agent that learns latent dynamics (RSSM) from pixel observations to plan via imagined latent trajectories, combining deterministic RNN hidden path with stochastic latent states.",
            "citation_title": "Learning Latent Dynamics for Planning from Pixels",
            "mention_or_use": "mention",
            "model_name": "PlaNet (RSSM-based latent dynamics)",
            "model_description": "Uses a Recurrent State Space Model (RSSM): deterministic hidden state h_t = f(h_{t-1}, s_{t-1}, a_{t-1}) implemented with an RNN and a stochastic state s_t sampled from p(s_t|h_t); paired with VAE-style encoder/decoder for observation mapping and planning over imagined latent trajectories.",
            "model_type": "latent world model (RSSM hybrid deterministic-stochastic)",
            "task_domain": "model-based RL planning from pixels; control tasks and simulated environments",
            "fidelity_metric": "latent transition log-likelihood, reconstruction loss (VAE ELBO), planning return (task reward)",
            "fidelity_performance": "Reported to enable planning in latent space with good empirical task performance in prior work; no numeric fidelity values provided in this survey.",
            "interpretability_assessment": "Latent states and deterministic path can be inspected via decoded reconstructions; transition dynamics remain neural and largely black-box except via visualization of rollouts.",
            "interpretability_method": "visualization of imagined latent trajectories decoded to pixels; no explicit symbolic interpretability methods reported here.",
            "computational_cost": "Not specified; RSSM adds both deterministic and stochastic components increasing model complexity relative to simple SSMs; no runtime or parameter counts given.",
            "efficiency_comparison": "PlaNet/Dreamer-style RSSMs are described as effective for planning versus training policies in the real environment; no quantitative efficiency numbers reported.",
            "task_performance": "Described qualitatively as enabling planning over imagined trajectories and good task performance in prior benchmarks; no explicit numbers given in this paper.",
            "task_utility_analysis": "RSSM's hybrid design trades memory (deterministic path) and multimodal prediction (stochastic path) to support planning; useful for anomaly detection by predicting action-conditioned futures and comparing to observations.",
            "tradeoffs_observed": "RSSM deterministic path aids memory but can hinder modeling multiple futures; stochastic path models multimodality but struggles with long-term memory — explicit trade-off discussed.",
            "design_choices": "Combines deterministic RNN hidden states with stochastic latent variables; uses VAE embedding and action-conditioned transitions; sampling-based rollouts for multiple futures.",
            "comparison_to_alternatives": "Compared conceptually to purely deterministic SSMs and fully stochastic SSMs; RSSM balances both to enable planning while modeling multiple futures; no empirical head-to-head numbers in this survey.",
            "optimal_configuration": "No prescriptive optimum; paper highlights RSSM benefits for planning and suggests attention to uncertainty and memory design when applying to anomaly detection.",
            "uuid": "e1223.1",
            "source_info": {
                "paper_title": "Exploring the Potential of World Models for Anomaly Detection in Autonomous Driving",
                "publication_date_yy_mm": "2023-12"
            }
        },
        {
            "name_short": "Dreamer / DreamerV2 / DreamerV3",
            "name_full": "Dreamer family (latent imagination agents, Dreamer, DreamerV2, DreamerV3)",
            "brief_description": "Agents that learn world models for latent imagination to train policies entirely within the learned model; later iterations replace Gaussian latents with categorical latents for improved discrete representations and scalability.",
            "citation_title": "Dream to Control: Learning Behaviors by Latent Imagination",
            "mention_or_use": "mention",
            "model_name": "Dreamer (and DreamerV2/V3)",
            "model_description": "Uses PlaNet-style RSSM world model to learn a latent dynamics model plus actor-critic architectures that are trained by imagining trajectories in the latent space; DreamerV2/V3 introduce categorical latent spaces (discrete latent distributions) instead of Gaussian latents.",
            "model_type": "latent world model (imagination-based policy learning)",
            "task_domain": "model-based RL (control tasks, diverse domains including Atari; general RL benchmarks)",
            "fidelity_metric": "reconstruction loss (ELBO), imagined-trajectory policy returns, next-state prediction likelihood",
            "fidelity_performance": "Described qualitatively as enabling high task performance on diverse domains in cited literature; this survey provides no numeric scores.",
            "interpretability_assessment": "Latent representations can be inspected via decoding; categorical latents may improve interpretability of discrete factors but overall model remains neural and not fully transparent.",
            "interpretability_method": "visualization of decoded latent imaginations and trajectory rollouts; no explicit explainability algorithms described in this paper.",
            "computational_cost": "Not quantified here; training Dreamer family is nontrivial but exact compute budgets/parameter counts are not provided in this survey.",
            "efficiency_comparison": "Reported as effective for training behaviors by imagination, reducing real-environment interactions; no quantitative comparisons included in this paper.",
            "task_performance": "Prior Dreamer work cited as achieving strong RL performance; survey notes Dreamer reuses PlaNet RSSM and is effective for policy learning, no numeric metrics provided.",
            "task_utility_analysis": "Dreamer shows that accurate latent prediction and imagination can translate into strong policy performance; however, survey warns that model fidelity does not automatically guarantee downstream success in new tasks like anomaly detection unless normality is well defined.",
            "tradeoffs_observed": "Switching Gaussian to categorical latents (DreamerV2/V3) is a design trade-off intended to improve representation power and scalability, possibly at cost of different training dynamics and interpretability trade-offs.",
            "design_choices": "RSSM backbone, latent imagination for policy learning, iterations moving from Gaussian to categorical latent representations.",
            "comparison_to_alternatives": "Compared at a qualitative level to model-free RL: Dreamer enables policy learning inside a model, often more sample-efficient; no numerical head-to-head numbers provided in the surveyed paper.",
            "optimal_configuration": "No single recommended configuration; paper suggests that selection of latent type (Gaussian vs categorical), uncertainty handling, and training data definition are key considerations for downstream uses like anomaly detection.",
            "uuid": "e1223.2",
            "source_info": {
                "paper_title": "Exploring the Potential of World Models for Anomaly Detection in Autonomous Driving",
                "publication_date_yy_mm": "2023-12"
            }
        },
        {
            "name_short": "E2C",
            "name_full": "Embed to Control (E2C)",
            "brief_description": "A locally-linear latent dynamics model that encodes images into a Gaussian latent and assumes locally linear dynamics for control in latent space.",
            "citation_title": "Embed to Control: A Locally Linear Latent Dynamics Model for Control from Raw Images",
            "mention_or_use": "mention",
            "model_name": "E2C (Embed to Control)",
            "model_description": "VAE-style encoder produces Gaussian latent states; dynamics assumed locally linear at each timestep, approximating global nonlinear dynamics via local Jacobians A(s), B(s) and sampling next-state from a Gaussian with linearized dynamics.",
            "model_type": "latent world model (locally-linear SSM)",
            "task_domain": "control from raw images (model-based control tasks)",
            "fidelity_metric": "reconstruction error, next-state MSE under locally-linear approximation",
            "fidelity_performance": "Not specified numerically in this survey; presented historically as a notable locally-linear latent dynamics approach.",
            "interpretability_assessment": "Some interpretability from locally-linear assumption (Jacobian matrices relate latent/state derivatives) but core components are neural nets making full interpretability limited.",
            "interpretability_method": "analysis via local Jacobians (A(s), B(s)) approximating dynamics; no broader explainability methods described here.",
            "computational_cost": "Not quantified in paper.",
            "efficiency_comparison": "Locally-linear dynamics aim for computationally tractable control in latent space; no quantitative comparisons provided here.",
            "task_performance": "Recognized historically as useful for control tasks from images; survey provides no numeric metrics.",
            "task_utility_analysis": "Design prioritizes locally-linear control-relevant structure, which may improve control utility at the cost of expressiveness for highly nonlinear global dynamics.",
            "tradeoffs_observed": "Local linearization trades global expressivity for locally interpretable dynamics and potentially simpler planning/control.",
            "design_choices": "Gaussian VAE latent with locally-linear transition model and explicit Jacobian parameterization A(s), B(s).",
            "comparison_to_alternatives": "Compared conceptually to fully neural transition models (e.g., RSSM) which model complex nonlinearities at the expense of structured interpretability.",
            "optimal_configuration": "No explicit optimal configuration for anomaly detection; paper notes locally-linear assumption may be suitable when control-oriented structure is a priority.",
            "uuid": "e1223.3",
            "source_info": {
                "paper_title": "Exploring the Potential of World Models for Anomaly Detection in Autonomous Driving",
                "publication_date_yy_mm": "2023-12"
            }
        },
        {
            "name_short": "RSSM",
            "name_full": "Recurrent State Space Model (RSSM)",
            "brief_description": "A hybrid transition architecture that combines deterministic RNN hidden states (deterministic path) with stochastic latent states (stochastic path) to model sequential latent dynamics for planning and imagination.",
            "citation_title": "Learning Latent Dynamics for Planning from Pixels",
            "mention_or_use": "mention",
            "model_name": "RSSM (Recurrent State Space Model)",
            "model_description": "Transition model with deterministic state h_t = f(h_{t-1}, s_{t-1}, a_{t-1}) implemented by an RNN and stochastic state s_t sampled from p(s_t|h_t); enables both memory via h_t and multimodal predictions via stochastic s_t.",
            "model_type": "latent world model (hybrid deterministic-stochastic)",
            "task_domain": "planning and control from pixels; used in PlaNet and Dreamer families",
            "fidelity_metric": "prediction likelihood in latent space, quality of decoded imagined rollouts, reconstruction ELBO",
            "fidelity_performance": "No numeric metrics in survey; described as effective for planning and imagination in prior literature.",
            "interpretability_assessment": "Partially interpretable via decoded rollouts; internal h_t and s_t are neural and not directly semantically interpreted in general.",
            "interpretability_method": "visualization of decoded imagined trajectories and latent samples; no explicit introspection tools discussed here.",
            "computational_cost": "More expensive than purely stochastic or purely deterministic SSMs due to maintaining both paths; no explicit compute numbers provided.",
            "efficiency_comparison": "Described qualitatively as balancing capability to remember (deterministic path) and model multimodality (stochastic path); no quantitative efficiency comparisons.",
            "task_performance": "Enables successful planning-based control in prior works (PlaNet/Dreamer); survey does not supply numerical benchmarks.",
            "task_utility_analysis": "RSSM is useful for downstream tasks (planning, anomaly detection) as it can generate multiple futures and maintain history; however, latent correction is limited compared to Bayesian update schemes.",
            "tradeoffs_observed": "Deterministic path helps with memory but limits multiple-future modeling; stochastic path supports multi-future but makes long-term memory harder — core trade-off discussed.",
            "design_choices": "Hybrid design mixing RNN hidden state and stochastic latent sampling; action-conditioned transitions.",
            "comparison_to_alternatives": "Compared to VRKN which removes need for deterministic path by using Kalman-style updates and principled uncertainty handling; RSSM is simpler but may overestimate aleatoric uncertainty.",
            "optimal_configuration": "Not specified; paper suggests considering uncertainty handling and Kalman updates for settings requiring principled correction of latent estimates.",
            "uuid": "e1223.4",
            "source_info": {
                "paper_title": "Exploring the Potential of World Models for Anomaly Detection in Autonomous Driving",
                "publication_date_yy_mm": "2023-12"
            }
        },
        {
            "name_short": "VRKN",
            "name_full": "Variational Recurrent Kalman Network (VRKN)",
            "brief_description": "A state-space world model that integrates principled Gaussian filtering (Kalman updates) with learned encoders to maintain and correct latent state estimates, explicitly modeling aleatoric and epistemic uncertainty.",
            "citation_title": "On Uncertainty in Deep State Space Models for Model-Based Reinforcement Learning",
            "mention_or_use": "mention",
            "model_name": "VRKN (Variational Recurrent Kalman Networks)",
            "model_description": "Encodes observations to intermediate representation w_t and covariance, computes latent state estimates via Gaussian marginalization and Kalman updates consistent with the generative model, captures epistemic uncertainty via Monte Carlo dropout, and represents aleatoric uncertainty in latent distributions.",
            "model_type": "latent world model (probabilistic state-space with Kalman-style inference)",
            "task_domain": "model-based RL and sequential state estimation tasks; proposed as more principled uncertainty-aware latent dynamics",
            "fidelity_metric": "likelihoods under generative model, calibrated uncertainty estimates, reconstruction loss; improved calibration of aleatoric/epistemic uncertainty",
            "fidelity_performance": "Survey reports that VRKN eliminates overestimation of aleatoric uncertainty present in RSSMs and can correct latent estimates with Kalman updates, but provides no numeric performance figures in this paper.",
            "interpretability_assessment": "Improved interpretability of uncertainty due to explicit Gaussian updating and separate epistemic/aleatoric modeling; latent state corrections have a probabilistic semantics.",
            "interpretability_method": "Kalman update equations and explicit covariance propagation give principled uncertainty diagnostics; Monte Carlo dropout used to estimate epistemic uncertainty.",
            "computational_cost": "Not quantified; Kalman computations introduce closed-form Gaussian marginalizations which may be computationally efficient relative to complex learned inference schemes, but total cost depends on implementation.",
            "efficiency_comparison": "Claimed to avoid overestimation of uncertainty and provide more principled inference than RSSM; no numerical efficiency comparisons in survey.",
            "task_performance": "Argued to yield better calibrated uncertainty and improved state estimation vs RSSM in prior work; no numeric task metrics in this paper.",
            "task_utility_analysis": "Better-specified uncertainties and latent correction via Kalman updates make VRKNs attractive for anomaly detection where principled confidence and correction are important.",
            "tradeoffs_observed": "VRKN trades design complexity (Bayesian updates, dropout-based epistemic estimates) for better uncertainty calibration and correctability of latent states compared to RSSM.",
            "design_choices": "Bayesian-Gaussian marginalization and Kalman updates; explicit separation of epistemic and aleatoric uncertainty; encoding to intermediate representation with covariance outputs.",
            "comparison_to_alternatives": "Contrasted to RSSM which cannot correct latent state estimates and tends to overestimate aleatoric uncertainty; VRKN presented as more principled for uncertainty-sensitive tasks.",
            "optimal_configuration": "Paper suggests VRKN-like Bayesian updating is preferable when accurate uncertainty and latent-state correction are required (e.g., anomaly detection), but no single optimal architecture prescribed.",
            "uuid": "e1223.5",
            "source_info": {
                "paper_title": "Exploring the Potential of World Models for Anomaly Detection in Autonomous Driving",
                "publication_date_yy_mm": "2023-12"
            }
        },
        {
            "name_short": "MILE",
            "name_full": "Model-Based Imitation Learning (MILE)",
            "brief_description": "A world-model approach applied to urban driving that uses imitation learning rather than RL, encoding high-resolution observations, lifting features into 3D, and pooling into bird's-eye view (BEV) for predictions.",
            "citation_title": "Model-Based Imitation Learning for Urban Driving",
            "mention_or_use": "mention",
            "model_name": "MILE (Model-Based Imitation Learning)",
            "model_description": "Encodes high-resolution observations and learns depth distributions per feature, lifts features into 3D, pools into BEV space and maps to vectors; transition model computes deterministic history h_t from h_{t-1} and s_{t-1} and then stochastic s_t conditioned on h_t and actions.",
            "model_type": "latent world model adapted for imitation learning (vision-to-BEV latent dynamics)",
            "task_domain": "autonomous driving (urban driving predictions and planning via imitation learning)",
            "fidelity_metric": "reconstruction/prediction loss on BEV features, imitation loss vs expert trajectories; fidelity measured in prior work via downstream imitation metrics",
            "fidelity_performance": "No numerical metrics provided in this survey; MILE is described as adapting world model ideas to driving tasks with BEV representations.",
            "interpretability_assessment": "BEV feature representations offer more interpretable spatial structure than raw pixel latents; latent-to-BEV mapping aids scene-level interpretability.",
            "interpretability_method": "lifting pixels to 3D and pooling into BEV provides spatially grounded latent features; visual inspection of BEV reconstructions/rollouts.",
            "computational_cost": "Not specified; lifting high-resolution features and depth distributions implies nontrivial compute, but no explicit numbers given.",
            "efficiency_comparison": "MILE follows world-model design but applied with IL and BEV lifting to be more suitable for driving; no direct efficiency comparisons given.",
            "task_performance": "Reported in referenced MILE work as effective for urban driving imitation; survey contains no numeric task outcomes.",
            "task_utility_analysis": "Design emphasizes task relevance by constructing BEV latent features and conditioning transitions on planned actions — likely improving utility for driving anomaly detection because rollouts are action-conditioned and spatially grounded.",
            "tradeoffs_observed": "Use of high-resolution encoders and BEV lifting increases representational fidelity at computational cost; no numeric trade-offs provided.",
            "design_choices": "High-resolution encoding, learned depth distributions per feature, lifting to BEV, action-conditioned stochastic state model with deterministic history derived from h_{t-1} and s_{t-1}.",
            "comparison_to_alternatives": "MILE contrasts with RL-based world models by using imitation learning and BEV-lifted features to better fit autonomous driving tasks; survey notes MILE as a driving-domain adaptation of world model ideas.",
            "optimal_configuration": "Paper recommends designing training/evaluation datasets and normality definitions carefully and using planned actions for rollouts; MILE's BEV/lift design is recommended for driving-specific tasks.",
            "uuid": "e1223.6",
            "source_info": {
                "paper_title": "Exploring the Potential of World Models for Anomaly Detection in Autonomous Driving",
                "publication_date_yy_mm": "2023-12"
            }
        },
        {
            "name_short": "GAIA-1 (Wayve)",
            "name_full": "GAIA-1 (Wayve's generative world model)",
            "brief_description": "An industrial-scale generative world model trained on fleet data that leverages video, text, and action inputs to generate realistic driving videos and likely supports downstream autonomy tasks.",
            "citation_title": "Introducing GAIA-1: A Cutting-Edge Generative AI Model for Autonomy",
            "mention_or_use": "mention",
            "model_name": "GAIA-1",
            "model_description": "Described as a large-scale generative model ingesting multimodal fleet data (video, text, actions) to produce realistic driving video predictions; exact architecture not detailed in the surveyed paper.",
            "model_type": "large-scale generative world model / foundation model for autonomy",
            "task_domain": "autonomous driving (fleet-scale learning, video generation, autonomy foundation model)",
            "fidelity_metric": "not specified in this survey; likely measured by realism of generated driving videos and downstream performance on autonomy tasks in original Wayve materials",
            "fidelity_performance": "Not reported in this paper; only qualitative statement that it generates realistic driving videos when trained on fleet data.",
            "interpretability_assessment": "No interpretability details given; industrial generative models are typically neural and largely opaque unless inspected with additional tools.",
            "interpretability_method": "not described in this survey.",
            "computational_cost": "Implied large-scale fleet training (high compute) but no concrete numbers provided.",
            "efficiency_comparison": "Not quantified; suggested as an industrial instantiation of world models trained at scale, implying high data and compute efficiency for broad coverage but no explicit comparisons.",
            "task_performance": "Not quantified here; presented as an early industrial example of world models for autonomy.",
            "task_utility_analysis": "Large-scale multimodal world models may provide broad generalization, but survey cautions that defining normality and controlling training data is critical for anomaly detection use-cases.",
            "tradeoffs_observed": "Implied trade-off: fleet-scale training improves coverage but risks incorporating unlabeled anomalies into the notion of normality, complicating anomaly detection.",
            "design_choices": "Multimodal inputs (video, text, actions) and large-scale fleet training; specifics not provided in the survey.",
            "comparison_to_alternatives": "Presented as an industrial counterpart to academic world models; no empirical comparisons provided.",
            "optimal_configuration": "Survey emphasizes the need for careful training-data curation and definitions of normality when using fleet-trained foundation world models for anomaly detection.",
            "uuid": "e1223.7",
            "source_info": {
                "paper_title": "Exploring the Potential of World Models for Anomaly Detection in Autonomous Driving",
                "publication_date_yy_mm": "2023-12"
            }
        },
        {
            "name_short": "Tesla general world model",
            "name_full": "Tesla 'general world model' (Elluswamy)",
            "brief_description": "Early reported industrial efforts at a general world model for autonomy trained on fleet data, intended as a foundation model for driving.",
            "citation_title": "Foundation models for autonomy",
            "mention_or_use": "mention",
            "model_name": "Tesla (general world model, as referenced)",
            "model_description": "Described in cited material as a fleet-trained general world model for autonomy; paper gives no architectural details beyond being trained at fleet scale on driving data.",
            "model_type": "large-scale generative world model / foundation model for autonomy",
            "task_domain": "autonomous driving (fleet-scale foundation model)",
            "fidelity_metric": "not specified in this survey; likely assessed by realism of predictions and downstream autonomy metrics in originating work",
            "fidelity_performance": "Not reported in this paper.",
            "interpretability_assessment": "No interpretability information provided in the survey.",
            "interpretability_method": "not described.",
            "computational_cost": "Implied to be large due to fleet-scale training; no quantitative details.",
            "efficiency_comparison": "Not provided; survey mentions it as an industrial example but no quantitative comparisons.",
            "task_performance": "Not provided within this survey.",
            "task_utility_analysis": "Large-scale world models may generalize well but could absorb unlabeled anomalies into the training distribution, challenging anomaly detection unless training data are curated.",
            "tradeoffs_observed": "Potential trade-off between wide coverage from fleet data and contamination of normality with anomalies; survey highlights this concern.",
            "design_choices": "Not specified in survey; only that it is trained on fleet data.",
            "comparison_to_alternatives": "Mentioned as industrial parallel to academic world models (e.g., PlaNet/Dreamer) but no direct comparison available.",
            "optimal_configuration": "Survey recommends careful control of training and evaluation datasets to define normality when using fleet-trained foundation models for anomaly detection.",
            "uuid": "e1223.8",
            "source_info": {
                "paper_title": "Exploring the Potential of World Models for Anomaly Detection in Autonomous Driving",
                "publication_date_yy_mm": "2023-12"
            }
        },
        {
            "name_short": "MDN-RNN",
            "name_full": "Mixture Density Network - RNN (MDN-RNN)",
            "brief_description": "A recurrent neural network whose outputs parameterize a mixture distribution over next latent states, enabling stochastic multi-modal next-state predictions in world models.",
            "citation_title": "World Models",
            "mention_or_use": "mention",
            "model_name": "MDN-RNN",
            "model_description": "RNN (e.g., LSTM/GRU) outputs mixture distribution parameters (weights, means, variances) for next-state latent distribution p(s_{t+1}|s_t,a_t,h_t), allowing sampling of multiple possible futures.",
            "model_type": "stochastic transition model component for latent world models",
            "task_domain": "used inside latent world models for control and planning (e.g., video-based model learning / RL)",
            "fidelity_metric": "mixture density negative log-likelihood, predictive log-likelihood, sample quality when decoded",
            "fidelity_performance": "No numerical performance values reported in this survey; MDN-RNN cited as a component in prior world model work.",
            "interpretability_assessment": "Stochastic mixture components are somewhat interpretable (modes correspond to different predicted futures), but overall RNN dynamics remain black-box.",
            "interpretability_method": "inspection of mixture modes and sampled rollouts decoded to pixels; no formal interpretability methods described here.",
            "computational_cost": "Not quantified; MDN outputs increase parameterization relative to unimodal outputs but costs not specified.",
            "efficiency_comparison": "MDN-RNN enables multimodal predictions versus unimodal Gaussian predictions; computational overhead implied but not quantified.",
            "task_performance": "Enables multiple-future modeling important for planning and anomaly detection; survey provides no numeric metrics.",
            "task_utility_analysis": "Useful for capturing multimodality in next-state predictions which is valuable for anticipating alternative futures and detecting deviations (anomalies).",
            "tradeoffs_observed": "Modeling multiple modes increases representational power but complicates training and sampling; potential increased computation and instability versus simpler predictors.",
            "design_choices": "Use of mixture outputs (weights/means/variances) from an RNN to model stochastic transitions.",
            "comparison_to_alternatives": "Compared implicitly to single-Gaussian predictors and RSSM-style stochastic pathways; MDN-RNN offers richer multimodality at additional complexity.",
            "optimal_configuration": "Not specified here; selection between MDN-RNN and RSSM/Kalman-style models depends on desired trade-off between multimodality and principled uncertainty correction.",
            "uuid": "e1223.9",
            "source_info": {
                "paper_title": "Exploring the Potential of World Models for Anomaly Detection in Autonomous Driving",
                "publication_date_yy_mm": "2023-12"
            }
        },
        {
            "name_short": "SABer-VAE",
            "name_full": "Structural Attention-based Recurrent VAE (SABer-VAE)",
            "brief_description": "An approach for vehicle-trajectory anomaly detection that encodes vehicle-vehicle and lane-vehicle interactions, uses attention modules and a stochastic Koopman-based transition to predict next vehicle states for anomaly scoring.",
            "citation_title": "Structural Attention-Based Recurrent Variational Autoencoder for Highway Vehicle Anomaly Detection",
            "mention_or_use": "mention",
            "model_name": "SABer-VAE (Chakraborty et al.)",
            "model_description": "Dual-path encoder: one path with self-attention models vehicle-vehicle interactions producing Gaussian latent parameters µ,σ; second path models lane-vehicle interactions; transition uses a stochastic Koopman operator where NN-predicted Koopman matrices evolve latent states for one-step predictions; anomaly score derived from prediction loss.",
            "model_type": "latent predictive model for trajectory data (attention-VAE with Koopman transition)",
            "task_domain": "trajectory anomaly detection (highway vehicle trajectories)",
            "fidelity_metric": "prediction loss on future vehicle states (used as anomaly score), likelihood under latent VAE distribution",
            "fidelity_performance": "No numeric fidelity/performance metrics provided in this survey; presented as a trajectory-specific anomaly detection instantiation using latent prediction.",
            "interpretability_assessment": "Attention modules and Koopman matrices give partial structure for interpreting interactions and linearized dynamics in latent space; overall neural components remain partially opaque.",
            "interpretability_method": "attention visualization for interaction modeling and inspection of predicted Koopman dynamics; anomaly scores derived from prediction errors.",
            "computational_cost": "Not provided in this survey.",
            "efficiency_comparison": "Designed to operate on trajectory graphs rather than raw sensor pixels, implying computational efficiency for trajectory data; no quantitative comparison provided.",
            "task_performance": "Claims usefulness for trajectory anomaly detection in cited work; survey provides no numerical benchmarks.",
            "task_utility_analysis": "SABer-VAE shows an example where latent predictive world-model ideas (embedding + transition + decoding/prediction) are effective for anomaly detection in structured trajectory data.",
            "tradeoffs_observed": "Specialized trajectory modeling (attention + Koopman) trades generality on raw sensor domains for better structured modeling of vehicle interactions.",
            "design_choices": "Self-attention for interactions, dual-encoder design, stochastic Koopman operator for transition modeling, Gaussian latent VAE encoding.",
            "comparison_to_alternatives": "Contrasted implicitly with sensor-based world models; SABer-VAE uses map/trajectory inputs and is not action-conditioned in the same way as sensor-world models.",
            "optimal_configuration": "Not specified in this survey; example highlights that task-specialized embedding and transition choices (attention + Koopman) improve utility on trajectory anomaly detection.",
            "uuid": "e1223.10",
            "source_info": {
                "paper_title": "Exploring the Potential of World Models for Anomaly Detection in Autonomous Driving",
                "publication_date_yy_mm": "2023-12"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "World Models",
            "rating": 2,
            "sanitized_title": "world_models"
        },
        {
            "paper_title": "Learning Latent Dynamics for Planning from Pixels",
            "rating": 2,
            "sanitized_title": "learning_latent_dynamics_for_planning_from_pixels"
        },
        {
            "paper_title": "Dream to Control: Learning Behaviors by Latent Imagination",
            "rating": 2,
            "sanitized_title": "dream_to_control_learning_behaviors_by_latent_imagination"
        },
        {
            "paper_title": "Mastering Atari with Discrete World Models",
            "rating": 1,
            "sanitized_title": "mastering_atari_with_discrete_world_models"
        },
        {
            "paper_title": "Embed to Control: A Locally Linear Latent Dynamics Model for Control from Raw Images",
            "rating": 2,
            "sanitized_title": "embed_to_control_a_locally_linear_latent_dynamics_model_for_control_from_raw_images"
        },
        {
            "paper_title": "On Uncertainty in Deep State Space Models for Model-Based Reinforcement Learning",
            "rating": 2,
            "sanitized_title": "on_uncertainty_in_deep_state_space_models_for_modelbased_reinforcement_learning"
        },
        {
            "paper_title": "Model-Based Imitation Learning for Urban Driving",
            "rating": 2,
            "sanitized_title": "modelbased_imitation_learning_for_urban_driving"
        },
        {
            "paper_title": "Structural Attention-Based Recurrent Variational Autoencoder for Highway Vehicle Anomaly Detection",
            "rating": 2,
            "sanitized_title": "structural_attentionbased_recurrent_variational_autoencoder_for_highway_vehicle_anomaly_detection"
        },
        {
            "paper_title": "Introducing GAIA-1: A Cutting-Edge Generative AI Model for Autonomy",
            "rating": 1,
            "sanitized_title": "introducing_gaia1_a_cuttingedge_generative_ai_model_for_autonomy"
        },
        {
            "paper_title": "Foundation models for autonomy",
            "rating": 1,
            "sanitized_title": "foundation_models_for_autonomy"
        }
    ],
    "cost": 0.02092,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Exploring the Potential of World Models for Anomaly Detection in Autonomous Driving</p>
<p>Daniel Bogdoll bogdoll@fzi.de 
FZI Research Center for Information Technology
Germany</p>
<p>Karlsruhe Institute of Technology
Germany</p>
<p>Lukas Bosch 
Karlsruhe Institute of Technology
Germany</p>
<p>Tim Joseph 
FZI Research Center for Information Technology
Germany</p>
<p>Helen Gremmelmaier 
FZI Research Center for Information Technology
Germany</p>
<p>Yitian Yang 
FZI Research Center for Information Technology
Germany</p>
<p>J Marius Zöllner 
FZI Research Center for Information Technology
Germany</p>
<p>Karlsruhe Institute of Technology
Germany</p>
<p>Exploring the Potential of World Models for Anomaly Detection in Autonomous Driving
50D2776732D3F87BEB58A75F6DCDDDC7world modelanomalyvisioncorner caseautonomous drivingpredictionreconstructionlatent space
In recent years there have been remarkable advancements in autonomous driving.While autonomous vehicles demonstrate high performance in closed-set conditions, they encounter difficulties when confronted with unexpected situations.At the same time, world models emerged in the field of model-based reinforcement learning as a way to enable agents to predict the future depending on potential actions.This led to outstanding results in sparse reward and complex control tasks.This work provides an overview of how world models can be leveraged to perform anomaly detection in the domain of autonomous driving.We provide a characterization of world models and relate individual components to previous works in anomaly detection to facilitate further research in the field.</p>
<p>I. INTRODUCTION</p>
<p>The detection of anomalies, or corner cases, is a challenging task with applications in autonomous driving.Neural networks, used in tasks like semantic segmentation, tend to be overconfident when confronted with the unseen.Therefore, an anomaly detection system can increase the reliability of autonomous systems which build on such components [1].In perception systems of autonomous vehicles, anomalies can range from sensor failures due to bad lighting conditions, over pedestrians suddenly crossing the street, to abnormal driving patterns from other vehicles.The different contexts in which anomalies arise, and their inherent unpredictability, pose a challenge to their detection.Many recent approaches focus on unsupervised learning of models describing normality.The idea is to detect anomalies by their deviation from the learned model of normality [1]- [5].Typically, the learning of normality is achieved by exploiting that models learn their training data's underlying patterns, which implicitly makes them learn a notion of normality corresponding to their training data [5].</p>
<p>At the same time, world models emerged in the field of Reinforcement Learning (RL) as a way to enable agents to predict the future conditioned on actions.This led to outstanding results in sparse reward and complex control tasks.Based on these successes, the question arises whether such world models, which learn a compact representation of the world and predict future changes, can be used outside of RL.</p>
<p>In this work, we introduce anomaly detection methods for autonomous driving in Sec.II and world models in Sec.III.In Sec.IV, we describe our concept for the detection of anomalies with world models and conclude our thoughts in Sec.V. Fig. 1.The bottom row shows a scene reconstruction of a world model [6] Compared to the ground truth, the model cannot recover all scene components, such as the bicyclist.This phenomenon can be exploited through a clear definition of normality and targeted training to detect anomalies.</p>
<p>II. ANOMALY DETECTION IN AUTONOMOUS DRIVING</p>
<p>There are endless possibilities of deviations from normality, which makes it hard to formally define anomalies.Termöhlen et al. [1] were the first to formulate a definition in the domain of autonomous driving: "A corner case is given, if there is a non-predictable relevant object/class in [a] relevant location".This section provides an overview of works on defining and detecting anomalies.</p>
<p>Anomaly Types.Breitenstein et al. [7] developed a fivelevel systematization of corner cases, focussing on camera data.Heidecker et al. generalized the work and extended it by a method layer, which describes corner cases "due to uncertainty inherent in the methodology or the data" [8].The first three layers describe anomalies in the surrounding environment.The fourth layer describes anomalies that stem from the utilized software stack itself.The sensor layer encompasses anomalies introduced by sensor attributes.The content layer describes anomalies detectable within a single frame, such as changing weather conditions or unknown objects.The temporal layer includes anomalies that become apparent only when analyzing multiple frames focusing on behavior.The method layer describes anomalies introduced by the used methodology, including the underlying training data.These may be expressed through uncertainty or other means.Unlike the previous layers, the method layer defines anomalies depending on the system's capabilities.Zhou and Beyerer argue similarly, defining corner cases as "interpretation problem[s] in the networks" based on training and test data [9].</p>
<p>Detection Methods.As one of the early works, Breitenstein et al. [10] investigated concepts for detecting anomalies for autonomous driving based on camera data, classifying approaches into reconstructive, generative, predictive, confidence score, and feature extraction-based methods.Bogdoll et al. extended the work by including lidar-and radar-based methods [11].Here, we provide an overview of these.</p>
<p>Reconstructive approaches aim to detect anomalies by reconstructing input frames from a compressed representation.Anomalies are identified when the reconstruction error or another suitable metric exceeds a predefined threshold, indicating the model's inability to represent the input accurately.Reconstruction-based methods build on the assumption that reconstructive models trained on normal input data fail to reconstruct anomalies.Similarly, Generative methods are also based on reconstructing methods, but "also regard the discriminator's decision or the distance between the generated and the training distribution" [10].</p>
<p>Predictive methods predict future frames based on preceding frames.Subsequently, anomalies are detected when a significant deviation between the prediction and the actual observation is encountered.The deviation can be measured with techniques from reconstruction-based approaches, e.g., reconstruction error.</p>
<p>Confidence score-based methods involve estimating the uncertainty associated with a model's prediction.Anomalies are detected when the confidence score of a model is low.Suggesting that the model is uncertain about the prediction might indicate that the observed data is potentially abnormal.</p>
<p>Lastly, feature extraction based methods detect anomalies by transforming the input data into a lower-dimensional feature space, which can emphasize meaningful patterns and separate anomalous data points from normal ones.Techniques such as deep feature extraction, clustering algorithms, and one-class support vector machines can be employed in this context.Contrary to previous methods, this approach only allows classification, not pixel or point-wise detection.</p>
<p>For training and evaluation of such such methods, various datasets are available [12]- [14].Oftentimes, normality is represented by the classes and data provided by Cityscapes [15], while anomalies include categories such as costumed people, lost cargo, or animals.</p>
<p>III. WORLD MODELS</p>
<p>This section provides a high-level characterization of world models as well as important examples from the literature.World models originate from the field of Reinforcement Learning.Here, for every state transition, an agent additionally receives a reward.Given the goal to maximize the expected cumulative reward, the question arises: Which actions to take?In model-free RL, the agent directly optimizes for this target based on its interactions with the environment.In modelbased Reinforcement Learning, however, a dynamics model is learned first in order to predict the dynamics of the environment.This way, the costly policy learning can be done purely in the dynamics model.</p>
<p>While the term world model for such a dynamics model dates back to the early days of Artificial Intelligence [16], in modern days Ha and Schmidhuber coined the term [17].However, they did not provide a clear definition.They were the first who modeled "dynamics observed from high dimensional visual data where [the] input is a sequence of raw pixel frames" [17].LeCun broadly defines a world model as an "internal model of how the world works" [18].Following Kendall, "A world model is a generative model that is able to predict the next state conditioned on an action" [19].Chen et al. describe world models based on their capabilities to provide "abstract perceptual representations" and "explicit future predictions" [20].Combining these concepts, we define a world model as follows:</p>
<p>A world model embeds sensory observations into a latent state, predicts action-conditioned state transitions, and is able to decode into observation space.</p>
<p>Such a stochastic, generative world model W, as shown in Figure II, can be described by three conditional probability distributions [21], [22], where the representation model
p(s t | s t−1 , a t−1 , o t )(1)
describes the dependence of a latent state on the associated observation, the prediction model
p(s t | s t−1 , a t−1 )(2)
describes the transition from one latent state to the next.It is possible to predict multiple next states by sampling:
s t+1 ∼ p(s t+1 | s t , a t ).
Finally, the observation model
p(o t | s t )(3)
describes the dependence of an observation on the associated latent state, which allows sampling reconstructions from it:
ôt ∼ p(o t | s t ).</p>
<p>A. Problem Formulation</p>
<p>To model the interaction of an agent and a realistic environment, we adapt the well-known terminology from Partially Observable Markov Decision Processes (POMDP) and assume Markovian properties, as shown in Figure 3.It can be assumed that no actor within the environment has access to its latent state.In the domain of autonomous driving, any agent controlling an actor thus relies on sensory observations from the actor itself.The agent can be understood as a software component that controls the vehicle, given its sensor data as observations.With each action, the internal state of the environment gets updated.</p>
<p>Agent
Environment s ∈ S −→ s ′ ∈ S Actor Action a ∈ A Observation o ∈ Ω Fig. 3.
Interaction of an agent with an actor in an environment, where A is a set of actions, S is a set of states, and Ω is a set of observations.Given an observation o, the action a of the agent results in a state transition s −→ s ′ of the environment.</p>
<p>B. Embedding Models</p>
<p>While contrastive approaches exist [22], most recent works implement VAEs as the embedding model to embed observations in a latent state space and utilize a reconstruction loss during training [17], [21]- [26].This also allows for decoding latent representations.Given a latent state s t , the corresponding decoder can be used to obtain a reconstruction ôt of the original observation o t .The state space structure is implicitly given by the embedding model.A common choice are Gaussian state spaces.Ha &amp; Schmidhuber [17] use a convolutional Variational Autoencoder (VAE) to encode twodimensional RGB image frames into low dimensional vectors µ, σ ∈ R 32 , which represent the parameters of a Gaussian distribution N (µ, σI).Latent states s ∈ R 32 are sampled from this distribution.The authors claim that the Gaussian prior makes the world model "more robust to unrealistic [s] vectors" predicted by their transition model.The locally linear latent state space dynamics model Embed to Control (E2C) [23] uses a similar VAE-type encoder, also resulting in a Gaussian state space.PlaNet, a model-based agent proposed by Hafner et al. [21], performs planning over imagined latent state trajectories, using the embedding model from Ha and Schmidhuber [17].The reinforcement learning agent Dreamer, proposed by Hafner et al. [22], utilizes the previously introduced world model PlaNet.In contrast, Dreamers recent iterations DreamerV2 [25] and DreamerV3 [26] replace the Gaussian state space with a categorical state space, where image frames are mapped to a categorical distribution.From this distribution, a latent state s encoded in categoricals is sampled.</p>
<p>Variational Recurrent Kalman Networks (VRKN), proposed by Becker &amp; Neumann [24], encode observations using a Neural Network with two output heads, which directly maps an observation to an intermediate representation w t and its diagonal covariance σ wt .The latent state is then calculated using Bayes rule for Gaussian distributions (Kalman updates).</p>
<p>Hu et al. presented their Model-Based Imitation Learning (MILE) for predictions in urban environments [6], [16].Compared to previous works, which apply world models in the context of RL, they use Imitation Learning (IL) to train their model.Inspired by Philion and Fidler [27], they encode highresolution observations and lift the resulting features into 3D space based on a learned depth probability distribution for each feature.A pooling operation into Bird's-Eye View (BeV) space and mapping to a 1D vector follow.</p>
<p>C. Transition Models</p>
<p>A central idea of a world model is to be able to look ahead by predicting future latent states.Given a latent state s t and an action a t , a world model is able to predict future states.Therefore, in addition to an embedding model as described above, a transition model is needed.</p>
<p>Inspired by Stochastic Optimal Control algorithms, E2C [23]  PlaNet [21] uses a Recurrent State Space Model (RSSM) [21] to model latent dynamics.RSSMs combine State Space Models (SSM) and Recurrent Neural Networks by introducing a deterministic path to SSMs, consisting of the hidden states of an RNN.More precisely, the transition model is an RSSM consisting of a deterministic state model h t = f (h t−1 , s t−1 , a t−1 ) implemented as an RNN, and a stochastic state model s t ∼ p(s t | h t ).The sequence of hidden states h 1:T is called the deterministic path, while the sequence of stochastic latent states s 1:T is called the stochastic path of the RSSM.While purely deterministic transitions "prevent the model from capturing multiple futures", the stochastic transitions in state space models make "it difficult to remember information over multiple time steps" [21].The RSSM of PlaNet is reused in all iterations of Dreamer.</p>
<p>VRKN [24] improve on RSSMs by eliminating the need for a deterministic path with a more principled modeling of aleatoric and epistemic uncertainty.This is achieved by using an inference scheme consistent with the generative model, i.e., by imposing the same assumptions on World Model learning and inference.Latent state estimates are forwarded using closed-form Gaussian marginalization, and then updated based on the respective observation using Kalman updates, thereby incorporating information from previous states.Epistemic uncertainty is captured using Monte Carlo dropout layers.Aleatoric uncertainty is captured in two ways: First, the latent state is a distribution capturing multiple possible futures, which provides information about aleatoric uncertainty.Second, Kalman updates enable the update of state estimates based on the respective observation.RSSMs can not correct latent state estimates and thus explain differences between estimates and observations implicitly by the transition model.VRKN can correct differences between state estimates
- - ✓ ✓ ✓ - Generative - - ✓ ✓ ✓ - Predictive - - - - - ✓ Confidence Score - - ✓ - - - Feature Extraction - - ✓ - - -
and observations with Kalman updates.This eliminates the overestimation of aleatoric uncertainty present in RSSMs.MILE [6] follows a similar approach as Hafner et al [21].The difference is that the deterministic history h t in MILE is obtained only from the previous history h t−1 and stochastic state s t−1 , i.e., h t = f (h t−1 , s t−1 ) where f is modeled as an RNN.Actions are later introduced in the stochastic state model s t ∼ p(s t | h t , a t−1 ).</p>
<p>In addition to this academic progress, world models are also finding their way into the industry.GAIA-1 by Wayve, trained on fleet data, "leverages video, text, and action inputs to generate realistic driving videos" [28].Similarly, Elluswamy presented early results of a "general world model" developed by Tesla, also trained on fleet data [29].</p>
<p>IV. ANOMALY DETECTION WITH WORLD MODELS</p>
<p>After presenting anomalies in the domain of autonomous driving and recent world models, we now introduce our concept of utilizing world models to detect multiple forms of anomalies.Following the approach presented by Breitenstein et al. [10], we map the previously introduced detection methods to corner case levels [7], [8], as shown in Table I.We mark a method only as applicable if it is the primary detection approach, since oftentimes multiple methods are being used, supplementing each other.While sensor layer corner cases can affect sensory observations and might thus be detectable, we focus on anomalies in the surrounding environment.Thus we deem anomalies on the sensor layer out of scope.</p>
<p>World models are especially interesting for anomaly detection, as they are able to perform all detection approaches from the literature: As the embedding model is typically implemented as a stochastic VAE, it has both reconstructive and generative capabilities.The core purpose of the transition model is prediction.For both the embedding model and the transition model, epistemic uncertainty estimates are possible.Finally, since we have access to the model, features are available.This allows world models to detect a wide variety of anomalies in a single pass, compared to a plethora of models which would be necessary otherwise.In addition, the end-to-end training approach of world models allows for the manifestation of a common definition of normality.</p>
<p>In general, the field of anomaly detection, especially for autonomous driving, faces several challenges at the moment [11], [14], [30].We want to address them systematically, introducing several assumptions in the following.</p>
<p>Normality.Since we aim to detect anomalies based on the capabilities of a world model, the learned normality of this world model is of utmost importance.However, real-world data collected at scale will contain unlabeled anomalies [31].Thus, achieving a clear disjunction between normality and anomalies, represented by training and evaluation data, is hard.This is especially important for un-and self-supervised approaches, which learn from all patterns included in the training data.If they pick up unknown anomalies from the training data, which are defined as anomalies in the evaluation data, this can lead to a situation where these human-defined anomalies are no longer anomalies for the detecting system.</p>
<p>Mapping.Typically, a detection system provides "metricbased assessments of situations" [30].To provide more context, it is often of interest to map detections to a corner case category, as shown in Table I.While the Table only shows the applicability of methods, the actual assignment during inference is challenging.For example, if a latent representation of an input deviates from learned representations of normal samples, a domain shift or a sufficiently large unknown object could be the reason.</p>
<p>Evaluation.For evaluation, concrete scenarios containing anomalies are necessary.However, deriving concrete scenarios from the rather broad corner case categories in a scalable fashion is hard [30], [32].In most benchmarks, the anomaly type is defined as either unknown objects, domain shifts, or abnormal behavior [14].Accordingly, the computer vision community focuses on "contextual anomalies on the scene level" [11].Addressing these challenges, we define the following assumptions:</p>
<p>• To properly define anomalies, full control over both the training and evaluation data is necessary • For a precise definition of normality, anomalies cannot be part of the training data • For the evaluation, human-defined anomalies are required, which must be in agreement with the normality defined by the training data In order to have full control over both training and test data, a controlled environment is necessary.The next sections will first introduce training and test data, followed by the general inference concept of the model and concrete methods for the detection of anomalies.</p>
<p>A. Training Data</p>
<p>As described earlier, the definition of an anomaly depends on the capabilities of the perception system, which depends on the data it was trained on.Following this concept, in order to detect anomalies, a concept of normality needs to be defined first.We can clearly define both the static and the dynamic environment of the training dataset D train norm based on several attributes: Region, Weather, Time of Day, Objects, Actors, and Behaviors.In a similar fashion, these can be found in the 6-Layer PEGASUS model [33].Based on a simulation engine [34], [35], these can be set in a reproducible and deterministic way.For the behavior of the ego-vehicle during training, a driving model providing expert demonstrations is well suited [6], [34], [36].Combining the static and dynamic attributes of the environment and a driving model for the ego vehicle allows for the assembly of a well-defined and largescale dataset for training.If anomaly detection approaches shall be compared based on an evaluation dataset D eval ano , they need to share a common definition of normality in the form of a prescribed training dataset D train norm .Today, this is typically not the case, which makes it impossible to truly compare approaches [14].For training details, we refer to common literature in the domain of world models [6], [17], [21], [22].</p>
<p>B. Evaluation Data</p>
<p>For the evaluation dataset D eval ano we need to integrate anomalies purposefully.Since the training dataset is well defined, this is possible on all corner case levels separately: On the sensor layer, perturbations can be added to the sensor configuration or sensor data.On the domain level, different regions, weather conditions, or daytimes can be chosen.For both the object and scene level, unknown objects or known objects in atypical places can be inserted.Finally, for the scenario layer, atypical behaviors can be defined or generated.For all of these anomalies, ground truth is available, which allows us to use them for evaluation.In addition, it is possible to combine corner case levels.</p>
<p>C. Model Inference</p>
<p>As shown in Figure II, future actions are necessary for the rollout of a world model.In Reinforcement Learning or Imitation Learning, typically a policy is learned to select an action a t = (acc t , δ t ) during inference, as visible in Figure 5. Applied to the domain of anomaly detection for autonomous driving though, a set of planned actions is known beforehand which can be utilized for the rollout, similar to the known actions used for planning with the PLaNet model [21].In autonomous driving, it is still common to divide the overarching task into a subset of modules, most importantly perception, prediction, planning, and control.Given information about the state of the actor and some vehicle model, the planning module is able to compute a list of planned actions, as shown in Figure 4.While the state of the actor is implicitly included in the environment state s, some attributes of it can be explicitly known or measured, as shown in Equation 4.  [6].Compared with the ground truth, the model is able to predict normal behavior.Under the hypothesis that it cannot predict atypical behavior unseen during training, differences between future observations and the predictions can be used for anomaly detection.
s actor =                  coordinates:
(x, y, z), rotation:</p>
<p>(ϕ, θ, ψ), velocity:</p>
<p>v, acceleration:</p>
<p>acc, steering angle: δ, . . .
                 (4)
Now, given observations, a list of past and planned actions, and a world model W, a sequence of future latent states, also referred to as a rollout trajectory, can be predicted.Based on
p(o 1:T | a 0:T −1 ) ≜ E p(s 1:T |a 0:T −1 ) T t=1 p(o t | s t )(5)
which describes the next T observations conditioned on T given actions [21], we can sample N times from the distribution in order to derive multiple futures in observation space:
{ô n 1:T } N n=1 ∼ p(o 1:T | a 0:T −1 )(6)</p>
<p>D. Anomaly Detection</p>
<p>To the best of our knowledge, no existing method for anomaly detection based on sensor data utilizes a world model as described in Section III.The anomaly detection method proposed by Chakraborty et al. [37] is the only approach known to us which utilizes embeddings, latent state transitions, and decodings to detect anomalies.However, their transition model is not action-conditioned and their input consists of map and trajectory data instead of sensor observations.In the following, we will introduce methods from the literature, which can also be implemented based on a world model, from the categories reconstructive, generative, predictive, confidence score, and feature extraction, as shown in Table I.</p>
<p>Reconstructive and Generative.Most world models leverage embedding models which make use of a reconstructive training objective [17], [21], [22], [25], [26], which form a reconstructive element inside a world model applicable to anomaly detection.While there are many anomaly detection approaches that use different forms of reconstructions [38]- [40], their concepts can be applied to world models.It is important to keep in mind that well-trained VAEs generalize well and are able to reconstruct the unseen [41], which is why special care is necessary during training and the design of anomaly detection methods.</p>
<p>Confronted with a domain level corner case, the reconstruction quality can be poor for the entire frame.This can be detected, especially in comparison to cases where only certain regions of the reconstruction have poor quality.This classification task can be performed based on methods such as reconstruction quality [42], reconstruction probability [43], or even combinations with extracted features [44], [45].Some of these methods also provide pixel-wise anomaly scores, which can be used for object level or scene level corner cases, which are hard to distinguish from a detection point of view.For example, Vojir et al. [46] aim to detect anomalies on roads using a reconstructive approach.The idea is to reconstruct the surface of the road and the remaining environment from a latent representation in such a way that the road reconstruction shows minimal error while the reconstruction of the remaining environment shows maximal error.The resulting pixel-wise errors are combined with a semantic segmentation output by feeding both into the semantic coupling module, which outputs two maps, one for the road class and one for the anomaly class.</p>
<p>Predictive.Predictive capabilities form the core of a world model, enabling the prediction of future latent states and, based on the observation model, the reconstruction into the observation space, as shown in Figure 5.Given such predictions, either the epistemic uncertainty or the comparison to future observations, which are available after ∆t, can be used to detect scenario level corner cases.When multiple futures are being predicted, distance metrics in their latent representations can be used to detect the prediction which generally aligns best with the ground truth.</p>
<p>Liu et al. [3] were the first to propose an approach to video anomaly detection involving the prediction of a future image frame and comparing the predicted frame with the ground truth frame.The approach adopts U-Net [47] to predict future frames based on the preceding image sequence.Intensity and gradient losses are directly computed between predicted and ground truth frames.To compute an optical flow loss, the authors leverage Flownet [48] to estimate the optical flow between the predicted or ground truth frames and their preceding frames.An optical flow constraint boosts anomaly detection performance as it imposes motion consistency for normal events through capturing temporal information.Based on the assumption that normal events are well predicted, the final anomaly score is based on the Peak Signal-to-Noise Ratio (PSNR) between predicted and ground truth frames.Similarly, Termöhlen et al. [1] use a convolutional Autoencoder to predict an image frame from a sequence of preceding frames, but in the domain of camera-based autonomous driving.An error map is built from pixel-wise prediction errors and weighted subsequently based on semantic information.</p>
<p>Chakraborty et al. [37] propose a Structural Attentionbased Recurrent VAE (SABer-VAE) for detecting anomalies in vehicle trajectories.The environment is modeled as a road map consisting of equidistant nodes on each lane.Furthermore, vehicle positions are given in coordinates at each timestep.The authors detect anomalies in observed vehicle trajectories by predicting future vehicle states and calculating a prediction loss from which a final anomaly score is derived.</p>
<p>Their embedding model consists of two paths.The primary encoding path models vehicle-vehicle interactions with a selfattention module.It takes vehicle positions and their relative distance to each other as inputs and transforms them, analogously to [17], but using a different architecture, into the parameters µ and σ of a Gaussian latent state distribution.The secondary encoding path models lane-vehicle interactions and consists only of an attention module to calculate embeddings.Their transition model uses a stochastic Koopman operator, where two Neural Networks predict the Koopman matrices in order to predict the "one-step future states of vehicles".</p>
<p>Confidence-and Feature-based.The process of embedding environment observations into a latent space is one form of feature extraction.Based on these features or uncertainties w.r.t. to latent states, a whole observation or state can be classified as an anomaly [49], enabling the detection of domain level corner cases.In single cases, where a large part of an image consists of object level or scene level corner cases, these can also be detected, but this dependence does not allow for the general detection of these levels.For example, Norlander &amp; Sopasakis [50] propose the Conditional Latent Space Variational Autoencoder (CL-VAE) to detect anomalies in class-labeled data.The authors train a VAE using a Gaussian mixture model such that for each class in the data set, a Gaussian prior is fitted in the latent space.The authors show that anomalies lie between the clusters, which can be visually confirmed.The favorable structure of the latent space can be used for anomaly detection by employing techniques such as Isolation Forests [51].Another approach for anomaly detection in surveillance videos is proposed by Park et al. [5], who propose a memory module, which represents a storage of latent representations of normal image frames.A U-Net [47] based encoder extracts query features from a video frame.The queries are fed into the memory model to update the latent memory items.To reconstruct image frames, the memory items are concatenated with the query features and fed into the decoder, which outputs a reconstructed frame.Since "prediction can be considered as a reconstruction of the future frame using previous ones" [5], the model can be adapted to predict the next frame with minimal effort using the same underlying architecture and loss functions.For training, the authors extend the reconstruction loss by adding a feature compactness as well as a feature separateness loss to condition the latent memory and query space.During inference, an anomaly score is obtained by combining the Euclidean distance between the extracted query and the closest memory item with the PSNR between input and reconstruction.</p>
<p>V. CONCLUSION</p>
<p>We presented a detailed characterization of world models together with anomaly detection approaches from the literature which build on ideas already present in world models or applicable to our characterization.We show that world models hold great potential for the task of anomaly detection in the context of autonomous driving.Along with a clear definition of anomalies and the categorization of anomaly detection approaches into predictive, generative, confidence score, and feature extraction-based methods, we showed that world models can be used to implement existing ideas from current approaches in a unified anomaly detection framework.</p>
<p>VI. ACKNOWLEDGMENT</p>
<p>Fig. 4 .
4
Fig. 4. Planned actions in the context of autonomous driving.Based on a vehicle model, the planning module determines a finite list of actions for the ego vehicle in order to reach planned future vehicle states.</p>
<p>Fig. 5 .
5
Fig.5.On the left, the last input frame for the prediction and its reconstruction are shown.The bottom row on the right shows the predictions of a world model conditioned on actions, where each action consists of acceleration and steering angle values as shown in the top row[6].Compared with the ground truth, the model is able to predict normal behavior.Under the hypothesis that it cannot predict atypical behavior unseen during training, differences between future observations and the predictions can be used for anomaly detection.</p>
<p>Fig. 2. A world model during inference, given high dimensional observations ot . . .o t−i ∈ Ω and past and planned actions a t−i . . .a t+j ∈ A at time t.All state transitions up to st ∈ S are computed with a representation model p(st | s t−1 , a t−1 , ot), where the observations are first being embedded.The embedding of actions is possible but optional.Future state transitions can be computed with the prediction model p(st | s t−1 , a t−1 ) based on the Markov assumption, where each state only depends on its predecessor.With the observation model p(ot | st), reconstructions ôt ∈ Ω can be decoded from state st.
a t−2a t−1a ta t+1. . .s t−2T ransitions t−1T ransitions tT ransitions t+1T ransitions t+2. . .DecodingEmbeddingôt−1ôtôt+1ôt+2o t−1o tarXiv:2308.05701v2 [cs.AI] 18 Sep 2023</p>
<p>assumes locally linear dynamics at each time step to approximate global non-linear dynamics.Future latent states are sampled from a Gaussian distribution N (A t µ t + B t a t + o t , C t ), where µ t and σ t are the parameters of s t computed by the embedding model.A(s t ) is the local Jacobian with respect to s t , B(s t ) the local Jacobian with respect to a t , o(s t ) is an offset and C t = A t Σ t A T t + H t with system noise H t .Ha &amp; Schmidhuber [17] use a Recurrent Neural Network (RNN) with a Mixture Density Network (MDN) output layer, called MDN-RNN, to model the probability distribution p(s t+1 | s t , a t , h t ), from which s t+1 can be sampled.The additional parameter h t is the RNNs hidden state.</p>
<p>This work results from the jbDATA project supported by the German Federal Ministry for Economic Affairs and Climate Action of Germany (BMWK) and the European Union, grant number 19A23003H.
Towards Corner Case Detection for Autonomous Driving. J.-A Termöhlen, A Bär, D Lipinski, T Fingscheidt, Intelligent Vehicles Symposium (IV). 2019</p>
<p>Learning Temporal Regularity in Video Sequences. M Hasan, J Choi, J Neumann, A K Roy-Chowdhury, L S Davis, arXiv:1604.045742016</p>
<p>Future Frame Prediction for Anomaly Detection -A New Baseline. W Liu, W Luo, D Lian, S Gao, Computer Vision and Pattern Recognition Conference (CVPR). 2018</p>
<p>Learning Regularity in Skeleton Trajectories for Anomaly Detection in Videos. R Morais, V Le, T Tran, B Saha, M Mansour, S Venkatesh, Computer Vision and Pattern Recognition Conference (CVPR). 2019</p>
<p>Learning Memory-Guided Normality for Anomaly Detection. H Park, J Noh, B Ham, Computer Vision and Pattern Recognition Conference (CVPR). 2020</p>
<p>Model-Based Imitation Learning for Urban Driving. A Hu, G Corrado, N Griffiths, Z Murez, C Gurau, H Yeo, A Kendall, R Cipolla, J Shotton, Neural Information Processing Systems (NeurIPS). 2022</p>
<p>Systematization of Corner Cases for Visual Perception in Automated Driving. J Breitenstein, J.-A Termöhlen, D Lipinski, T Fingscheidt, Intelligent Vehicles Symposium (IV). 2020</p>
<p>An Application-Driven Conceptualization of Corner Cases for Perception in Highly Automated Driving. F Heidecker, J Breitenstein, K Rösch, J Löhdefink, M Bieshaar, C Stiller, T Fingscheidt, B Sick, Intelligent Vehicles Symposium (IV). 2021</p>
<p>Corner Cases in Data-Driven Automated Driving: Definitions, Properties and Solutions. J Zhou, J Beyerer, Intelligent Vehicles Symposium (IV). 2023</p>
<p>Corner Cases for Visual Perception in Automated Driving: Some Guidance on Detection Approaches. J Breitenstein, J.-A Termöhlen, D Lipinski, T Fingscheidt, arXiv:2102.058972021</p>
<p>Anomaly Detection in Autonomous Driving: A Survey. D Bogdoll, M Nitsche, J M Zöllner, Computer Vision and Pattern Recognition Conference (CVPR) Workshop. 2022</p>
<p>AD-Datasets: A Meta-Collection of Data Sets for Autonomous Driving. D Bogdoll, F Schreyer, J M Zöllner, International Conference on Vehicle Technology and Intelligent Transport Systems (VEHITS). 2022</p>
<p>Impact, Attention, Influence: Early Assessment of Autonomous Driving Datasets. D Bogdoll, J Hendl, F Schreyer, N Gowda, M Färber, J M Zöllner, International Conference on Control and Robotics Engineering (ICCRE). 2023</p>
<p>Perception Datasets for Anomaly Detection in Autonomous Driving: A Survey. D Bogdoll, S Uhlemeyer, K Kowol, J M Zöllner, Intelligent Vehicles Symposium (IV). 2023</p>
<p>The Cityscapes Dataset for Semantic Urban Scene Understanding. M Cordts, M Omran, S Ramos, T Rehfeld, M Enzweiler, R Benenson, U Franke, S Roth, B Schiele, Conference on Computer Vision and Pattern Recognition (CVPR). 2016</p>
<p>Neural World Models for Computer Vision. A Hu, 2022University of CambridgePh.D. dissertation</p>
<p>World Models. D Ha, J Schmidhuber, arXiv:1803.101222018</p>
<p>A Path Towards Autonomous Machine Intelligence. Y Lecun, OpenReview:BZ5a1r-kVsf. 2022</p>
<p>A Kendall, Frontiers in Embodied AI for Autonomous Driving. CVPR Workshop on End-to-End Autonomous Driving. 2023</p>
<p>End-toend Autonomous Driving: Challenges and Frontiers. L Chen, P Wu, K Chitta, B Jaeger, A Geiger, H Li, arXiv:2306.169272023</p>
<p>Learning Latent Dynamics for Planning from Pixels. D Hafner, T Lillicrap, I Fischer, R Villegas, D Ha, H Lee, J Davidson, International Conference on Machine Learning (ICML). 2019</p>
<p>Dream to Control: Learning Behaviors by Latent Imagination. D Hafner, T Lillicrap, J Ba, M Norouzi, International Conference on Learning Representations (ICLR). 2020</p>
<p>Embed to Control: A Locally Linear Latent Dynamics Model for Control from Raw Images. M Watter, J T Springenberg, J Boedecker, M Riedmiller, Conference on Neural Information Processing Systems (NeurIPS). 2015</p>
<p>On Uncertainty in Deep State Space Models for Model-Based Reinforcement Learning. P Becker, G Neumann, Transactions on Machine Learning Research. 2022TMLR</p>
<p>Mastering Atari with Discrete World Models. D Hafner, T Lillicrap, M Norouzi, J Ba, International Conference on Learning Representations (ICLR). 2021</p>
<p>D Hafner, J Pasukonis, J Ba, T Lillicrap, arXiv:2301.04104Mastering Diverse Domains through World Models. 2023</p>
<p>Lift, Splat, Shoot: Encoding Images From Arbitrary Camera Rigs by Implicitly Unprojecting to 3D. J Philion, S Fidler, European Conference on Computer Vision (ECCV). 2020</p>
<p>Introducing GAIA-1: A Cutting-Edge Generative AI Model for Autonomy. WAYVE</p>
<p>Foundation models for autonomy. A Elluswamy, CVPR Workshop on Autonomous Driving. 2023</p>
<p>Description of corner cases in automated driving: Goals and challenges. D Bogdoll, J Breitenstein, F Heidecker, M Bieshaar, B Sick, T Fingscheidt, J M Zöllner, International Conference on Computer Vision (ICCV) Workshop. 2021</p>
<p>Unknown-Aware Object Detection: Learning What You Don't Know from Videos in the Wild. X Du, X Wang, G Gozum, Y Li, Computer Vision and Pattern Recognition Conference (CVPR). 2022</p>
<p>One Ontology to Rule Them All: Corner Case Scenarios for Autonomous Driving. D Bogdoll, S Guneshka, J M Zöllner, European Conference on Computer Vision (ECCV) Workshop. 2022</p>
<p>6-layer model for a structured description and categorization of urban traffic and environment. M Scholtes, L Westhofen, L R Turner, K Lotto, M Schuldes, H Weber, N Wagener, C Neurohr, M H Bollmann, F Körtke, J Hiller, M Hoss, J Bock, L Eckstein, IEEE Access. 92021</p>
<p>CARLA: An open urban driving simulator. A Dosovitskiy, G Ros, F Codevilla, A Lopez, V Koltun, Conference on Robot Learning (CoRL). 2017</p>
<p>From model-based to data-driven simulation: Challenges and trends in autonomous driving. F Mütsch, H Gremmelmaier, N Becker, D Bogdoll, M R Zofka, J M Zöllner, Computer Vision and Pattern Recognition Conference (CVPR) Workshop. 2023</p>
<p>End-to-end urban driving by imitating a reinforcement learning coach. Z Zhang, A Liniger, D Dai, F Yu, L Van Gool, International Conference on Computer Vision (ICCV). 2021</p>
<p>Structural Attention-Based Recurrent Variational Autoencoder for Highway Vehicle Anomaly Detection. N Chakraborty, A Hasan, S Liu, T Ji, W Liang, D L Mcpherson, K Driggs-Campbell, International Conference on Autonomous Agents and Multiagent Systems (AAMAS). 2023</p>
<p>Pixel-wise Anomaly Detection in Complex Driving Scenes. G Di Biase, H Blum, R Siegwart, C Cadena, Computer Vision and Pattern Recognition Conference (CVPR). 2021</p>
<p>Dense anomaly detection by robust learning on synthetic negative data. M Grcić, P Bevandić, Z Kalafatić, S Šegvić, arXiv:2112.128332021</p>
<p>On advantages of mask-level recognition for outlier-aware segmentation. M Grcić, J Šarić, S Šegvić, Computer Vision and Pattern Recognition Conference (CVPR) Workshop. 2023</p>
<p>Compressing Sensor Data for Remote Assistance of Autonomous Vehicles using Deep Generative Models. D Bogdoll, J Jestram, J Rauch, C Scheib, M Wittig, J M Zöllner, Conference on Neural Information Processing Systems (NeurIPS) Workshop. 2021</p>
<p>Anomaly Detection with Adversarial Dual Autoencoders. H S Vu, D Ueta, K Hashimoto, K Maeno, S Pranata, S M Shen, arXiv:1902.069242019</p>
<p>Implicit Discriminator in Variational Autoencoder. P Munjal, A Paul, N C Krishnan, International Joint Conference on Neural Networks (IJCNN). 2020</p>
<p>Latent Space Autoregression for Novelty Detection. D Abati, A Porrello, S Calderara, R Cucchiara, Computer Vision and Pattern Recognition Conference (CVPR). 2019</p>
<p>Image Anomaly Detection Using Normal Data Only by Latent Space Resampling. L Wang, D Zhang, J Guo, Y Han, Applied Sciences. 102020</p>
<p>Road Anomaly Detection by Partial Image Reconstruction with Segmentation Coupling. T Vojir, T Šipka, R Aljundi, N Chumerin, D O Reino, J Matas, International Conference on Computer Vision (ICCV). 2021</p>
<p>U-Net: Convolutional Networks for Biomedical Image Segmentation. O Ronneberger, P Fischer, T Brox, Medical Image Computing and Computer-Assisted Intervention (MICCAI). 2015</p>
<p>FlowNet: Learning Optical Flow with Convolutional Networks. A Dosovitskiy, P Fischer, E Ilg, P Hausser, C Hazirbas, V Golkov, P Van Der Smagt, D Cremers, T Brox, International Conference on Computer Vision (ICCV). 2015</p>
<p>Anomaly Detection in the Latent Space of VAEs. S Klaus, Karlsruher Institut für Technologie. 2022Abschlussarbeit -Bachelor</p>
<p>Latent space conditioning for improved classification and anomaly detection. E Norlander, A Sopasakis, arXiv:1911.105992019</p>
<p>Isolation Forest. F T Liu, K M Ting, Z.-H Zhou, International Conference on Data Mining (ICDM). 2008</p>            </div>
        </div>

    </div>
</body>
</html>