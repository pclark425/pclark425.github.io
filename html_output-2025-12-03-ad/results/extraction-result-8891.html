<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-8891 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-8891</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-8891</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-156.html">extraction-schema-156</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of representational formats of conceptual knowledge at a functional (not neural) level, including descriptions of the format, supporting or challenging evidence, cognitive tasks or phenomena used as evidence, comparisons between formats, and theoretical claims or implications.</div>
                <p><strong>Paper ID:</strong> paper-68dd4b89ce1407372a29d05ca9e4e1a2e0513617</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/68dd4b89ce1407372a29d05ca9e4e1a2e0513617" target="_blank">A Solution to Plato's Problem: The Latent Semantic Analysis Theory of Acquisition, Induction, and Representation of Knowledge.</a></p>
                <p><strong>Paper TL;DR:</strong> A new general theory of acquired similarity and knowledge representation, latent semantic analysis (LSA), is presented and used to successfully simulate such learning and several other psycholinguistic phenomena.</p>
                <p><strong>Cost:</strong> 0.018</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e8891.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e8891.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of representational formats of conceptual knowledge at a functional (not neural) level, including descriptions of the format, supporting or challenging evidence, cognitive tasks or phenomena used as evidence, comparisons between formats, and theoretical claims or implications.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LSA</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Latent Semantic Analysis</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A computational-level, high-dimensional distributed representation of word and passage meaning formed by SVD on a word×context matrix; similarity is measured by vector cosines and dimensionality is optimized to induce higher-order (indirect) relations from local co-occurrence statistics.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>representational_format_name</strong></td>
                            <td>distributed vector-space representation (latent semantic space)</td>
                        </tr>
                        <tr>
                            <td><strong>representational_format_description</strong></td>
                            <td>Concepts (words, passages) are represented as vectors in a common high-dimensional space derived by singular value decomposition (SVD) of a word×context frequency matrix (after log-frequency and inverse-entropy weighting). Similarity is operationalized as the cosine (angle) between vectors; contexts (paragraphs) and items (words) occupy the same space and passage meaning can be composed as a (weighted) average of the vectors of its words.</td>
                        </tr>
                        <tr>
                            <td><strong>format_type</strong></td>
                            <td>distributed representation (linear, dimensionality-reduced)</td>
                        </tr>
                        <tr>
                            <td><strong>cognitive_task_or_phenomenon</strong></td>
                            <td>Multiple-choice synonym test (TOEFL), vocabulary acquisition (reading-based learning rate), contextual disambiguation, semantic priming / lexical decision, text coherence/comprehensibility, inferential activation (construction-integration phenomena), prediction of topic/usage</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>LSA trained on ~4.6M words (30,473 text samples) achieved 51.5/80 TOEFL synonym items (64.4% raw; ~52.5% corrected for guessing), close to an ETS-tested human sample; optimal performance occurred near ~300 dimensions (performance fell steeply with too few or too many dimensions: ~13% correct at 2–3 dimensions; ~16% with no reduction). Dimensionality optimization multiplied learning effectiveness (roughly threefold improvement over raw data). Simulated reading using LSA's inductive effects estimated ≈0.20 words gained per paragraph, giving ≈10 words/day at ~50 paragraphs/day. About ~75% of LSA's acquired word knowledge arose from indirect (higher-order) inference rather than direct co-occurrence.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_other_formats</strong></td>
                            <td>Contrasted explicitly with (a) raw local co-occurrence / mutual-information style statistics (which performed poorly), (b) low-dimensional factor/MDS approaches (2–3 dimensions gave poor performance), (c) classical associative/conditioning views (LSA separates local associative encoding from a subsequent global condensation step), and (d) symbolic/feature or prototype accounts (LSA can be isomorphic to feature-based accounts if a sufficient set of quantitative features exists). Empirical tests favor a mid-range, high-dimensional distributed representation (LSA) for capturing word similarity from large corpora over simpler local or very low-dimensional approaches.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_counter_evidence</strong></td>
                            <td>Functional limitations discussed: current LSA ignores word order and syntax (bag-of-words), phonology/morphology, perceptual grounding, and explicit part-of-speech or pragmatic constraints; single-vector-per-word struggles with balanced polysemy/homography (averaged vector may be orthogonal to any particular sense); computationally requires large corpora and SVD (not psychologically literal); linear representations may fail for phenomena needing hierarchical or ordered structure; results sensitive to context-window selection and corpus composition; SVD-based dimensionality optimum must be chosen (non-monotonic relation to performance).</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_claims_or_implications</strong></td>
                            <td>At a functional level LSA is proposed as a plausible computational-level mechanism for much of semantic acquisition and representation: (1) global dimension-optimized condensation of local co-occurrence yields powerful inductive inference (bridges 'poverty of the stimulus'), (2) distributed semantic space supports generalization, analogy, and agreement across speakers, (3) semantic knowledge is graded/continuous (probabilistic), (4) representations unify episodic (context vectors) and semantic (word vectors) knowledge in the same space, and (5) many phenomena attributed to specialized innate constraints may be substantially explained by general-purpose statistical induction over large natural corpora.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': "A Solution to Plato's Problem: The Latent Semantic Analysis Theory of Acquisition, Induction, and Representation of Knowledge.", 'publication_date_yy_mm': '1997-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8891.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e8891.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of representational formats of conceptual knowledge at a functional (not neural) level, including descriptions of the format, supporting or challenging evidence, cognitive tasks or phenomena used as evidence, comparisons between formats, and theoretical claims or implications.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Dimensionality-optimized representation</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Dimensionality optimization via singular value decomposition (SVD)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Functional principle that representing co-occurrence-derived pairwise relations in a reduced number of latent dimensions yields better estimates of conceptual similarity and stronger indirect inferences than using raw high-dimensional data or extreme low-dimensional reductions.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>representational_format_name</strong></td>
                            <td>dimensionality-reduced latent-space representation</td>
                        </tr>
                        <tr>
                            <td><strong>representational_format_description</strong></td>
                            <td>Pairwise noisy estimates of similarity (from local co-occurrence) are jointly fit into a k-dimensional linear space (k chosen to optimize performance). The reduced set of orthogonal latent factors captures global covariance structure and allows indirect relations to be inferred through the geometry of the space.</td>
                        </tr>
                        <tr>
                            <td><strong>format_type</strong></td>
                            <td>distributed, dimensionality-reduced (linear algebraic)</td>
                        </tr>
                        <tr>
                            <td><strong>cognitive_task_or_phenomenon</strong></td>
                            <td>Vocabulary-synonym selection (TOEFL), learning rate simulations, text comprehension coherence, indirect associative inference</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Performance exhibits a strong non-monotonic dependence on number of dimensions; a mid-range (≈300) dimensions produced best TOEFL results while both very low (2–3) and very high (full dimension) performed poorly; optimal dimensionality triples effective learned words relative to raw matrix cosines.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_other_formats</strong></td>
                            <td>Compared to raw high-dimensional co-occurrence (worse) and very low-dimensional factor interpretations (worse), dimensionality optimization yields superior inductive generalization; relates to factor analysis and MDS but applied to very large word×context matrices.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_counter_evidence</strong></td>
                            <td>Requires selection of an optimal k (empirically determined); linear SVD cannot capture non-linear or hierarchical relations; performance sensitive to corpus and preprocessing choices (window size, weighting), and SVD itself is not proposed as a literal neural computation.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_claims_or_implications</strong></td>
                            <td>Dimensionality choice is a central inductive mechanism: matching representational dimensionality to the underlying structure of a domain amplifies weak local constraints into strong global knowledge; this principle can explain rapid acquisition and far-reaching generalization from sparse local data.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': "A Solution to Plato's Problem: The Latent Semantic Analysis Theory of Acquisition, Induction, and Representation of Knowledge.", 'publication_date_yy_mm': '1997-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8891.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e8891.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of representational formats of conceptual knowledge at a functional (not neural) level, including descriptions of the format, supporting or challenging evidence, cognitive tasks or phenomena used as evidence, comparisons between formats, and theoretical claims or implications.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Local association / conditioning</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Local associative (contiguity-based) representation / conditioning</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Traditional account in which knowledge is built by recording pairwise contiguities or conditioned associations between stimuli and contexts, typically local and symmetrical or asymmetrical co-occurrence strengths.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>representational_format_name</strong></td>
                            <td>associative pairwise representation</td>
                        </tr>
                        <tr>
                            <td><strong>representational_format_description</strong></td>
                            <td>Conceptual relations are initially encoded as local associations (weighted co-occurrence or conditioning strengths) between items and the contexts in which they occur; these pairwise links form the raw data for higher-level processes.</td>
                        </tr>
                        <tr>
                            <td><strong>format_type</strong></td>
                            <td>associative / local (symbolic-numeric) hybrid</td>
                        </tr>
                        <tr>
                            <td><strong>cognitive_task_or_phenomenon</strong></td>
                            <td>Classical conditioning analogies, pairwise co-occurrence statistics, immediate priming, simple associative learning experiments</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>LSA adopts local co-occurrence as its input (log-frequency and inverse-entropy weighting approximating associative conditioning), but shows that local pairwise associations alone (without global condensation) yield poor performance (e.g., raw transformed matrix cosines produced ~16% correct on TOEFL), indicating that local association must be combined with a global representation process to achieve human-like semantic performance.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_other_formats</strong></td>
                            <td>LSA decomposes analyses into a local associative encoding stage and a separate global condensation (SVD) stage; pure local association accounts are insufficient for the observed inductive generalizations and vocabulary learning rates.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_counter_evidence</strong></td>
                            <td>Local pairwise models fail to predict indirect similarity (synonyms that never co-occur) and give poor performance on large vocabulary synonym tests; chaining-stepwise association predictions are weak because distance constraints require global context.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_claims_or_implications</strong></td>
                            <td>Local associative processes are necessary but not sufficient; a separate global integrative condensation step (e.g., dimensionality-reduced embedding) is required to transform local associations into robust representational similarity supporting broad generalization.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': "A Solution to Plato's Problem: The Latent Semantic Analysis Theory of Acquisition, Induction, and Representation of Knowledge.", 'publication_date_yy_mm': '1997-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8891.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e8891.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of representational formats of conceptual knowledge at a functional (not neural) level, including descriptions of the format, supporting or challenging evidence, cognitive tasks or phenomena used as evidence, comparisons between formats, and theoretical claims or implications.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Feature/prototype/exemplar and rule-based theories</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Feature-based, prototype, exemplar, and symbolic rule-based representations</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A class of functional representations in which concepts are defined by lists of features, similarity to prototypes, collections of exemplars, or explicit rules/constraints (including proposed innate lexical constraints).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>representational_format_name</strong></td>
                            <td>feature/prototype/exemplar/symbolic rule representations</td>
                        </tr>
                        <tr>
                            <td><strong>representational_format_description</strong></td>
                            <td>Features: concepts = sets of discrete semantic features; Prototype: category represented by an averaged ideal; Exemplar: categories represented by stored instances; Symbolic/rule: concepts defined by explicit predicates and constraints (e.g., syntax/word-mapping constraints).</td>
                        </tr>
                        <tr>
                            <td><strong>format_type</strong></td>
                            <td>symbolic / feature-based / exemplar-based (or hybrid)</td>
                        </tr>
                        <tr>
                            <td><strong>cognitive_task_or_phenomenon</strong></td>
                            <td>Categorization, typicality effects, rule-based learning (e.g., constraints in early lexical acquisition), experiments on word-learning constraints (e.g., mutual exclusivity), theoretical claims about poverty of the stimulus (Chomskian arguments)</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Paper argues that feature/prototype/exemplar and strong innate constraint accounts have explanatory power for some phenomena but may be unnecessary for many aspects of lexical similarity acquisition, because LSA (a domain-general statistical induction mechanism) recovers substantial semantic knowledge from usage statistics without prespecified features or language-specific constraints.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_other_formats</strong></td>
                            <td>Authors argue LSA can be isomorphic to feature-based accounts if sufficiently many quantitative features are available, and that many rule/constraint views postulate strong innate structure that may not be required to explain observed rates of vocabulary acquisition; LSA provides a parsimonious alternative for many similarity phenomena.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_counter_evidence</strong></td>
                            <td>Classic prototype/exemplar/symbolic accounts can naturally handle compositional rules, ordered/hierarchical structure, and explicit logical categories where LSA (bag-of-words, linear) may fail; also, human learners show some constraints (e.g., pragmatic or morphological cues) that LSA does not encode.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_claims_or_implications</strong></td>
                            <td>If distributional induction like LSA is effective, many phenomena attributed to specialized innate symbolic constraints could instead arise from domain-general statistical induction; however, symbolic/feature accounts may still be necessary to cover compositional syntax and rule-based phenomena that are not captured by purely distributional linear spaces.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': "A Solution to Plato's Problem: The Latent Semantic Analysis Theory of Acquisition, Induction, and Representation of Knowledge.", 'publication_date_yy_mm': '1997-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8891.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e8891.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of representational formats of conceptual knowledge at a functional (not neural) level, including descriptions of the format, supporting or challenging evidence, cognitive tasks or phenomena used as evidence, comparisons between formats, and theoretical claims or implications.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Semantic network / spreading activation</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Semantic network / spreading-activation representations</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Graph-style functional representations in which concepts are nodes linked by labeled (typed) associations and activation spreads over links to produce priming and retrieval-like behavior.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>representational_format_name</strong></td>
                            <td>semantic network (spreading activation)</td>
                        </tr>
                        <tr>
                            <td><strong>representational_format_description</strong></td>
                            <td>Knowledge represented as a network of nodes (concepts) connected by weighted associations; processing involves activation propagation, which yields graded similarity and priming effects.</td>
                        </tr>
                        <tr>
                            <td><strong>format_type</strong></td>
                            <td>network-structured / symbolic-numeric hybrid</td>
                        </tr>
                        <tr>
                            <td><strong>cognitive_task_or_phenomenon</strong></td>
                            <td>Priming, lexical decision, associative retrieval, classic semantic memory phenomena</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>LSA is conceptually related to spreading-activation ideas (both produce graded similarity and indirect association), but LSA provides a compact continuous vector geometry derived from global statistics rather than an explicit graph of labeled links; LSA captures higher-order relations that simple link-chaining in networks often fails to predict.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_other_formats</strong></td>
                            <td>Unlike explicit symbolic semantic networks, LSA's vector-space captures indirect relations without explicit links and can better predict synonymy where no direct co-occurrence exists; however, semantic networks can more directly encode discrete relations and roles.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_counter_evidence</strong></td>
                            <td>Network approaches can represent explicit relational structure, role-filler bindings, and non-symmetric relations more naturally than current LSA; simple spreading activation models without global condensation fail to derive many of the higher-order inferences LSA produces.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_claims_or_implications</strong></td>
                            <td>LSA suggests a complementary view: global statistical condensation can underlie the link strengths that semantic networks assume; distributed vector representations may provide a quantitative substrate for graded activation patterns used in semantic-network accounts.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': "A Solution to Plato's Problem: The Latent Semantic Analysis Theory of Acquisition, Induction, and Representation of Knowledge.", 'publication_date_yy_mm': '1997-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8891.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e8891.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of representational formats of conceptual knowledge at a functional (not neural) level, including descriptions of the format, supporting or challenging evidence, cognitive tasks or phenomena used as evidence, comparisons between formats, and theoretical claims or implications.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Construction-Integration (CI) style propositional representation</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Construction-Integration (CI) propositional representation (Kintsch-style)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A psychological functional model of text comprehension in which an initial construction of multiple activated propositions (including multiple senses) is followed by an integration stage that selects and consolidates the appropriate meaning/situation model.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>representational_format_name</strong></td>
                            <td>propositional / situation-model representation (construction–integration)</td>
                        </tr>
                        <tr>
                            <td><strong>representational_format_description</strong></td>
                            <td>Text comprehension proceeds by constructing a set of propositional representations and activated senses, then integrating them via constraint satisfaction to build a coherent situation model; propositions are discrete, structured units (relations, arguments).</td>
                        </tr>
                        <tr>
                            <td><strong>format_type</strong></td>
                            <td>symbolic / structured representation (propositional)</td>
                        </tr>
                        <tr>
                            <td><strong>cognitive_task_or_phenomenon</strong></td>
                            <td>Contextual disambiguation, priming time-course (early multiple-activation then selection), coherence-driven comprehension, inference generation</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>LSA can simulate aspects of CI at the representational level by using vector averages of sentence/paragraph words to predict coherence and inferential activation; experiments reanalyzed showed LSA-derived sentence cosines predicted human comprehensibility and priming patterns (e.g., disambiguation over time) even without explicit propositional coding.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_other_formats</strong></td>
                            <td>CI uses structured propositional units and temporal dynamics; LSA offers an economical distributional alternative that can approximate CI's outcomes for coherence and inference tasks via continuous vector composition, though it lacks explicit propositional structure and temporal integration mechanisms.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_counter_evidence</strong></td>
                            <td>CI accounts naturally model temporal activation-and-selection dynamics and explicit inference structure; LSA in its current form lacks mechanisms for multiple token senses per word and temporal processing stages, though it can approximate some CI predictions via vector composition.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_claims_or_implications</strong></td>
                            <td>LSA provides a candidate representational substrate that can instantiate elements of CI (gist, coherence, inference) via vector composition and global similarity geometry, suggesting that continuous distributional representations might underlie or approximate propositional comprehension processes.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': "A Solution to Plato's Problem: The Latent Semantic Analysis Theory of Acquisition, Induction, and Representation of Knowledge.", 'publication_date_yy_mm': '1997-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <p class="empty-note">No potentially relevant new papers extracted.</p>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-8891",
    "paper_id": "paper-68dd4b89ce1407372a29d05ca9e4e1a2e0513617",
    "extraction_schema_id": "extraction-schema-156",
    "extracted_data": [
        {
            "name_short": "LSA",
            "name_full": "Latent Semantic Analysis",
            "brief_description": "A computational-level, high-dimensional distributed representation of word and passage meaning formed by SVD on a word×context matrix; similarity is measured by vector cosines and dimensionality is optimized to induce higher-order (indirect) relations from local co-occurrence statistics.",
            "citation_title": "here",
            "mention_or_use": "use",
            "representational_format_name": "distributed vector-space representation (latent semantic space)",
            "representational_format_description": "Concepts (words, passages) are represented as vectors in a common high-dimensional space derived by singular value decomposition (SVD) of a word×context frequency matrix (after log-frequency and inverse-entropy weighting). Similarity is operationalized as the cosine (angle) between vectors; contexts (paragraphs) and items (words) occupy the same space and passage meaning can be composed as a (weighted) average of the vectors of its words.",
            "format_type": "distributed representation (linear, dimensionality-reduced)",
            "cognitive_task_or_phenomenon": "Multiple-choice synonym test (TOEFL), vocabulary acquisition (reading-based learning rate), contextual disambiguation, semantic priming / lexical decision, text coherence/comprehensibility, inferential activation (construction-integration phenomena), prediction of topic/usage",
            "key_findings": "LSA trained on ~4.6M words (30,473 text samples) achieved 51.5/80 TOEFL synonym items (64.4% raw; ~52.5% corrected for guessing), close to an ETS-tested human sample; optimal performance occurred near ~300 dimensions (performance fell steeply with too few or too many dimensions: ~13% correct at 2–3 dimensions; ~16% with no reduction). Dimensionality optimization multiplied learning effectiveness (roughly threefold improvement over raw data). Simulated reading using LSA's inductive effects estimated ≈0.20 words gained per paragraph, giving ≈10 words/day at ~50 paragraphs/day. About ~75% of LSA's acquired word knowledge arose from indirect (higher-order) inference rather than direct co-occurrence.",
            "comparison_with_other_formats": "Contrasted explicitly with (a) raw local co-occurrence / mutual-information style statistics (which performed poorly), (b) low-dimensional factor/MDS approaches (2–3 dimensions gave poor performance), (c) classical associative/conditioning views (LSA separates local associative encoding from a subsequent global condensation step), and (d) symbolic/feature or prototype accounts (LSA can be isomorphic to feature-based accounts if a sufficient set of quantitative features exists). Empirical tests favor a mid-range, high-dimensional distributed representation (LSA) for capturing word similarity from large corpora over simpler local or very low-dimensional approaches.",
            "limitations_or_counter_evidence": "Functional limitations discussed: current LSA ignores word order and syntax (bag-of-words), phonology/morphology, perceptual grounding, and explicit part-of-speech or pragmatic constraints; single-vector-per-word struggles with balanced polysemy/homography (averaged vector may be orthogonal to any particular sense); computationally requires large corpora and SVD (not psychologically literal); linear representations may fail for phenomena needing hierarchical or ordered structure; results sensitive to context-window selection and corpus composition; SVD-based dimensionality optimum must be chosen (non-monotonic relation to performance).",
            "theoretical_claims_or_implications": "At a functional level LSA is proposed as a plausible computational-level mechanism for much of semantic acquisition and representation: (1) global dimension-optimized condensation of local co-occurrence yields powerful inductive inference (bridges 'poverty of the stimulus'), (2) distributed semantic space supports generalization, analogy, and agreement across speakers, (3) semantic knowledge is graded/continuous (probabilistic), (4) representations unify episodic (context vectors) and semantic (word vectors) knowledge in the same space, and (5) many phenomena attributed to specialized innate constraints may be substantially explained by general-purpose statistical induction over large natural corpora.",
            "uuid": "e8891.0",
            "source_info": {
                "paper_title": "A Solution to Plato's Problem: The Latent Semantic Analysis Theory of Acquisition, Induction, and Representation of Knowledge.",
                "publication_date_yy_mm": "1997-04"
            }
        },
        {
            "name_short": "Dimensionality-optimized representation",
            "name_full": "Dimensionality optimization via singular value decomposition (SVD)",
            "brief_description": "Functional principle that representing co-occurrence-derived pairwise relations in a reduced number of latent dimensions yields better estimates of conceptual similarity and stronger indirect inferences than using raw high-dimensional data or extreme low-dimensional reductions.",
            "citation_title": "here",
            "mention_or_use": "use",
            "representational_format_name": "dimensionality-reduced latent-space representation",
            "representational_format_description": "Pairwise noisy estimates of similarity (from local co-occurrence) are jointly fit into a k-dimensional linear space (k chosen to optimize performance). The reduced set of orthogonal latent factors captures global covariance structure and allows indirect relations to be inferred through the geometry of the space.",
            "format_type": "distributed, dimensionality-reduced (linear algebraic)",
            "cognitive_task_or_phenomenon": "Vocabulary-synonym selection (TOEFL), learning rate simulations, text comprehension coherence, indirect associative inference",
            "key_findings": "Performance exhibits a strong non-monotonic dependence on number of dimensions; a mid-range (≈300) dimensions produced best TOEFL results while both very low (2–3) and very high (full dimension) performed poorly; optimal dimensionality triples effective learned words relative to raw matrix cosines.",
            "comparison_with_other_formats": "Compared to raw high-dimensional co-occurrence (worse) and very low-dimensional factor interpretations (worse), dimensionality optimization yields superior inductive generalization; relates to factor analysis and MDS but applied to very large word×context matrices.",
            "limitations_or_counter_evidence": "Requires selection of an optimal k (empirically determined); linear SVD cannot capture non-linear or hierarchical relations; performance sensitive to corpus and preprocessing choices (window size, weighting), and SVD itself is not proposed as a literal neural computation.",
            "theoretical_claims_or_implications": "Dimensionality choice is a central inductive mechanism: matching representational dimensionality to the underlying structure of a domain amplifies weak local constraints into strong global knowledge; this principle can explain rapid acquisition and far-reaching generalization from sparse local data.",
            "uuid": "e8891.1",
            "source_info": {
                "paper_title": "A Solution to Plato's Problem: The Latent Semantic Analysis Theory of Acquisition, Induction, and Representation of Knowledge.",
                "publication_date_yy_mm": "1997-04"
            }
        },
        {
            "name_short": "Local association / conditioning",
            "name_full": "Local associative (contiguity-based) representation / conditioning",
            "brief_description": "Traditional account in which knowledge is built by recording pairwise contiguities or conditioned associations between stimuli and contexts, typically local and symmetrical or asymmetrical co-occurrence strengths.",
            "citation_title": "",
            "mention_or_use": "mention",
            "representational_format_name": "associative pairwise representation",
            "representational_format_description": "Conceptual relations are initially encoded as local associations (weighted co-occurrence or conditioning strengths) between items and the contexts in which they occur; these pairwise links form the raw data for higher-level processes.",
            "format_type": "associative / local (symbolic-numeric) hybrid",
            "cognitive_task_or_phenomenon": "Classical conditioning analogies, pairwise co-occurrence statistics, immediate priming, simple associative learning experiments",
            "key_findings": "LSA adopts local co-occurrence as its input (log-frequency and inverse-entropy weighting approximating associative conditioning), but shows that local pairwise associations alone (without global condensation) yield poor performance (e.g., raw transformed matrix cosines produced ~16% correct on TOEFL), indicating that local association must be combined with a global representation process to achieve human-like semantic performance.",
            "comparison_with_other_formats": "LSA decomposes analyses into a local associative encoding stage and a separate global condensation (SVD) stage; pure local association accounts are insufficient for the observed inductive generalizations and vocabulary learning rates.",
            "limitations_or_counter_evidence": "Local pairwise models fail to predict indirect similarity (synonyms that never co-occur) and give poor performance on large vocabulary synonym tests; chaining-stepwise association predictions are weak because distance constraints require global context.",
            "theoretical_claims_or_implications": "Local associative processes are necessary but not sufficient; a separate global integrative condensation step (e.g., dimensionality-reduced embedding) is required to transform local associations into robust representational similarity supporting broad generalization.",
            "uuid": "e8891.2",
            "source_info": {
                "paper_title": "A Solution to Plato's Problem: The Latent Semantic Analysis Theory of Acquisition, Induction, and Representation of Knowledge.",
                "publication_date_yy_mm": "1997-04"
            }
        },
        {
            "name_short": "Feature/prototype/exemplar and rule-based theories",
            "name_full": "Feature-based, prototype, exemplar, and symbolic rule-based representations",
            "brief_description": "A class of functional representations in which concepts are defined by lists of features, similarity to prototypes, collections of exemplars, or explicit rules/constraints (including proposed innate lexical constraints).",
            "citation_title": "",
            "mention_or_use": "mention",
            "representational_format_name": "feature/prototype/exemplar/symbolic rule representations",
            "representational_format_description": "Features: concepts = sets of discrete semantic features; Prototype: category represented by an averaged ideal; Exemplar: categories represented by stored instances; Symbolic/rule: concepts defined by explicit predicates and constraints (e.g., syntax/word-mapping constraints).",
            "format_type": "symbolic / feature-based / exemplar-based (or hybrid)",
            "cognitive_task_or_phenomenon": "Categorization, typicality effects, rule-based learning (e.g., constraints in early lexical acquisition), experiments on word-learning constraints (e.g., mutual exclusivity), theoretical claims about poverty of the stimulus (Chomskian arguments)",
            "key_findings": "Paper argues that feature/prototype/exemplar and strong innate constraint accounts have explanatory power for some phenomena but may be unnecessary for many aspects of lexical similarity acquisition, because LSA (a domain-general statistical induction mechanism) recovers substantial semantic knowledge from usage statistics without prespecified features or language-specific constraints.",
            "comparison_with_other_formats": "Authors argue LSA can be isomorphic to feature-based accounts if sufficiently many quantitative features are available, and that many rule/constraint views postulate strong innate structure that may not be required to explain observed rates of vocabulary acquisition; LSA provides a parsimonious alternative for many similarity phenomena.",
            "limitations_or_counter_evidence": "Classic prototype/exemplar/symbolic accounts can naturally handle compositional rules, ordered/hierarchical structure, and explicit logical categories where LSA (bag-of-words, linear) may fail; also, human learners show some constraints (e.g., pragmatic or morphological cues) that LSA does not encode.",
            "theoretical_claims_or_implications": "If distributional induction like LSA is effective, many phenomena attributed to specialized innate symbolic constraints could instead arise from domain-general statistical induction; however, symbolic/feature accounts may still be necessary to cover compositional syntax and rule-based phenomena that are not captured by purely distributional linear spaces.",
            "uuid": "e8891.3",
            "source_info": {
                "paper_title": "A Solution to Plato's Problem: The Latent Semantic Analysis Theory of Acquisition, Induction, and Representation of Knowledge.",
                "publication_date_yy_mm": "1997-04"
            }
        },
        {
            "name_short": "Semantic network / spreading activation",
            "name_full": "Semantic network / spreading-activation representations",
            "brief_description": "Graph-style functional representations in which concepts are nodes linked by labeled (typed) associations and activation spreads over links to produce priming and retrieval-like behavior.",
            "citation_title": "",
            "mention_or_use": "mention",
            "representational_format_name": "semantic network (spreading activation)",
            "representational_format_description": "Knowledge represented as a network of nodes (concepts) connected by weighted associations; processing involves activation propagation, which yields graded similarity and priming effects.",
            "format_type": "network-structured / symbolic-numeric hybrid",
            "cognitive_task_or_phenomenon": "Priming, lexical decision, associative retrieval, classic semantic memory phenomena",
            "key_findings": "LSA is conceptually related to spreading-activation ideas (both produce graded similarity and indirect association), but LSA provides a compact continuous vector geometry derived from global statistics rather than an explicit graph of labeled links; LSA captures higher-order relations that simple link-chaining in networks often fails to predict.",
            "comparison_with_other_formats": "Unlike explicit symbolic semantic networks, LSA's vector-space captures indirect relations without explicit links and can better predict synonymy where no direct co-occurrence exists; however, semantic networks can more directly encode discrete relations and roles.",
            "limitations_or_counter_evidence": "Network approaches can represent explicit relational structure, role-filler bindings, and non-symmetric relations more naturally than current LSA; simple spreading activation models without global condensation fail to derive many of the higher-order inferences LSA produces.",
            "theoretical_claims_or_implications": "LSA suggests a complementary view: global statistical condensation can underlie the link strengths that semantic networks assume; distributed vector representations may provide a quantitative substrate for graded activation patterns used in semantic-network accounts.",
            "uuid": "e8891.4",
            "source_info": {
                "paper_title": "A Solution to Plato's Problem: The Latent Semantic Analysis Theory of Acquisition, Induction, and Representation of Knowledge.",
                "publication_date_yy_mm": "1997-04"
            }
        },
        {
            "name_short": "Construction-Integration (CI) style propositional representation",
            "name_full": "Construction-Integration (CI) propositional representation (Kintsch-style)",
            "brief_description": "A psychological functional model of text comprehension in which an initial construction of multiple activated propositions (including multiple senses) is followed by an integration stage that selects and consolidates the appropriate meaning/situation model.",
            "citation_title": "",
            "mention_or_use": "mention",
            "representational_format_name": "propositional / situation-model representation (construction–integration)",
            "representational_format_description": "Text comprehension proceeds by constructing a set of propositional representations and activated senses, then integrating them via constraint satisfaction to build a coherent situation model; propositions are discrete, structured units (relations, arguments).",
            "format_type": "symbolic / structured representation (propositional)",
            "cognitive_task_or_phenomenon": "Contextual disambiguation, priming time-course (early multiple-activation then selection), coherence-driven comprehension, inference generation",
            "key_findings": "LSA can simulate aspects of CI at the representational level by using vector averages of sentence/paragraph words to predict coherence and inferential activation; experiments reanalyzed showed LSA-derived sentence cosines predicted human comprehensibility and priming patterns (e.g., disambiguation over time) even without explicit propositional coding.",
            "comparison_with_other_formats": "CI uses structured propositional units and temporal dynamics; LSA offers an economical distributional alternative that can approximate CI's outcomes for coherence and inference tasks via continuous vector composition, though it lacks explicit propositional structure and temporal integration mechanisms.",
            "limitations_or_counter_evidence": "CI accounts naturally model temporal activation-and-selection dynamics and explicit inference structure; LSA in its current form lacks mechanisms for multiple token senses per word and temporal processing stages, though it can approximate some CI predictions via vector composition.",
            "theoretical_claims_or_implications": "LSA provides a candidate representational substrate that can instantiate elements of CI (gist, coherence, inference) via vector composition and global similarity geometry, suggesting that continuous distributional representations might underlie or approximate propositional comprehension processes.",
            "uuid": "e8891.5",
            "source_info": {
                "paper_title": "A Solution to Plato's Problem: The Latent Semantic Analysis Theory of Acquisition, Induction, and Representation of Knowledge.",
                "publication_date_yy_mm": "1997-04"
            }
        }
    ],
    "potentially_relevant_new_papers": [],
    "cost": 0.01819475,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>A Solution to Plato's Problem: The Latent Semantic Analysis Theory of Acquisition, Induction, and Representation of Knowledge</h1>
<p>Thomas K Landauer<br>University of Colorado at Boulder</p>
<p>Susan T. Dumais<br>Bellcore</p>
<h4>Abstract</h4>
<p>How do people know as much as they do with as little information as they get? The problem takes many forms; learning vocabulary from text is an especially dramatic and convenient case for research. A new general theory of acquired similarity and knowledge representation, latent semantic analysis (LSA), is presented and used to successfully simulate such learning and several other psycholinguistic phenomena. By inducing global knowledge indirectly from local co-occurrence data in a large body of representative text, LSA acquired knowledge about the full vocabulary of English at a comparable rate to schoolchildren. LSA uses no prior linguistic or perceptual similarity knowledge; it is based solely on a general mathematical learning method that achieves powerful inductive effects by extracting the right number of dimensions (e.g., 300) to represent objects and contexts. Relations to other theories, phenomena, and problems are sketched.</p>
<h2>Prologue</h2>
<p>"How much do we know at any time? Much more, or so I believe, than we know we know!"</p>
<ul>
<li>Agatha Christie, The Moving Finger</li>
</ul>
<p>A typical American seventh grader knows the meaning of $10-15$ words today that she did not know yesterday. She must have acquired most of them as a result of reading because (a) the majority of English words are used only in print, (b) she already knew well almost all the words she would have encountered in speech, and (c) she learned less than one word by direct instruction. Studies of children reading grade-school text find that about one word in every 20 paragraphs goes from wrong to right on a vocabulary test. The typical seventh grader would have read less than 50 paragraphs since yesterday, from which she should have learned less than three new words. Apparently, she mastered the meanings of many words that she did not encounter. Evidence for all these assertions is given in detail later.</p>
<p>This phenomenon offers an ideal case in which to study a problem that has plagued philosophy and science since Plato</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup>24 centuries ago, the fact that people have much more knowledge than appears to be present in the information to which they have been exposed. Plato's solution, of course, was that people must come equipped with most of their knowledge and need only hints and contemplation to complete it.</p>
<p>In this article we suggest a very different hypothesis to explain the mystery of excessive learning. It rests on the simple notion that some domains of knowledge contain vast numbers of weak interrelations that, if properly exploited, can greatly amplify learning by a process of inference. We have discovered that a very simple mechanism of induction, the choice of the correct dimensionality in which to represent similarity between objects and events, can sometimes, in particular in learning about the similarity of the meanings of words, produce sufficient enhancement of knowledge to bridge the gap between the information available in local contiguity and what people know after large amounts of experience.</p>
<h2>Overview</h2>
<p>In this article we report the results of using latent semantic analysis (LSA), a high-dimensional linear associative model that embodies no human knowledge beyond its general learning mechanism, to analyze a large corpus of natural text and generate a representation that captures the similarity of words and text passages. The model's resulting knowledge was tested with a standard multiple-choice synonym test, and its learning power compared to the rate at which school-aged children improve their performance on similar tests as a result of reading. The model's improvement per paragraph of encountered text approximated the natural rate for schoolchildren, and most of its acquired knowledge was attributable to indirect inference rather than direct co-occurrence relations. This result can be interpreted in at least two ways. The more conservative interpretation is that it shows that with the right analysis a substantial portion of the information needed to answer common vocabulary test questions can be inferred from the contextual statistics of usage alone. This is not a trivial conclusion. As we alluded to earlier</p>
<p>and elaborate later, much theory in philosophy, linguistics, artificial intelligence research, and psychology has supposed that acquiring human knowledge, especially knowledge of language, requires more specialized primitive structures and processes, ones that presume the prior existence of special foundational knowledge rather than just a general purpose analytic device. This result questions the scope and necessity of such assumptions. Moreover, no previous model has been applied to simulate the acquisition of any large body of knowledge from the same kind of experience used by a human learner.</p>
<p>The other, more radical, interpretation of this result takes the mechanism of the model seriously as a possible theory about all human knowledge acquisition, as a homologue of an important underlying mechanism of human cognition in general. In particular, the model employs a means of induction-dimension opti-mization-that greatly amplifies its learning ability, allowing it to correctly infer indirect similarity relations only implicit in the temporal correlations of experience. The model exhibits humanlike generalization that is based on learning and that does not rely on primitive perceptual or conceptual relations or representations. Similar induction processes are inherent in the mechanisms of certain other theories (e.g., some associative, semantic, and neural network models). However, as we show later, substantial effects arise only if the body of knowledge to be learned contains appropriate structure and only when a suffi-cient-possibly quite large-quantity of it has been learned. As a result, the posited induction mechanism has not previously been credited with the significance it deserves or exploited to explain the many poorly understood psychological phenomena to which it may be germane. The mechanism lends itself, among other things, to a deep reformulation of associational learning theory that appears to offer explanations and modeling directions for a wide variety of cognitive phenomena. One set of phenomena that we discuss later in detail, along with some auxiliary data and simulation results, is contextual disambiguation of words and passages in text comprehension.</p>
<p>Because readers with different theoretical interests may find these two interpretations differentially attractive, we have followed a slightly unorthodox manner of exposition. Although we later present a general theory, or at least the outline of one, that incorporates and fleshes out the implications of the inductive mechanism of the formal model, we have tried to keep this development somewhat independent of the report of our simulation studies. That is, we eschew the conventional stance that the theory is primary and the simulation studies are tests of it. Indeed, the historical fact is that the mathematical text analysis technique came first, as a practical expedient for automatic information retrieval, the vocabulary acquisition simulations came next, and the theory arose last, as a result of observed empirical successes and discovery of the unsuspectedly important effects of the model's implicit inferential operations.</p>
<h2>The Problem of Induction</h2>
<p>One of the deepest, most persistent mysteries of cognition is how people acquire as much knowledge as they do on the basis of as little information as they get. Sometimes called "Plato's problem" or "the poverty of the stimulus," the question is how observing a relatively small set of events results in beliefs that
are usually correct or behaviors that are usually adaptive in a large, potentially infinite variety of situations. Following Plato, philosophers (e.g., Goodman, 1972; Quine, 1960), psychologists (e.g., Shepard, 1987; Vygotsky, 1968), linguists (e.g., Chomsky, 1991; Jackendoff, 1992; Pinker, 1990), computation scientists (e.g., Angluin \&amp; Smith, 1983; Michaelski, 1983) and combinations thereof (Holland, Holyoak, Nisbett, \&amp; Thagard, 1986) have wrestled with the problem in many guises. Quine (1960), following a tortured history of philosophical analysis of scientific truth, has called the problem "the scandal of induction," essentially concluding that purely experience-based objective truth cannot exist. Shepard (1987) has placed the problem at the heart of psychology, maintaining that a general theory of generalization and similarity is as necessary to psychology as Newton's laws are to physics. Perhaps the most well-advertised examples of the mystery lie in the acquisition of language. Chomsky (e.g., Chomsky, 1991) and followers assert that a child's exposure to adult language provides inadequate evidence from which to learn either grammar or lexicon. Gold, Osherson, Feldman, and others (see Osherson, Weinstein, \&amp; Stob, 1986) have formalized this argument, showing mathematically that certain kinds of languages cannot be learned to certain criteria on the basis of finite data. The puzzle presents itself with quantitative clarity in the learning of vocabulary during the school years, the particular case that we address most fully in this article. Schoolchildren learn to understand words at a rate that appears grossly inconsistent with the information about each word provided by the individual language samples to which they are exposed and much faster than they can be made to by explicit tuition.</p>
<p>Recently Pinker (1994) has summarized the broad spectrum of evidence on the origins of language - in evolution, history, anatomy, physiology, and development. In accord with Chomsky's dictum, he concludes that language learning must be based on a very strong and specific innate foundation, a set of general rules and predilections that need parameter setting and filling in, but not acquisition as such, from experience. Although this "language instinct" position is debatable as stated, it rests on an idea that is surely correct, that some powerful mechanism exists in the minds of children that can use the finite information they receive to turn them into competent users of human language. What we want to know, of course, is what this mechanism is, what it does, how it works. Unfortunately the rest of the instinctivist answers are as yet of limited help. The fact that the mechanism is given by biology or that it exists as an autonomous mental or physical "module" (if it does), tells us next to nothing about how the mind solves the basic inductive problem.</p>
<p>Shepard's (1987) answer to the induction problem in stimulus generalization is equally dependent on biological givens, but offers a more precise description of some parts of the proposed mechanism. He has posited that the nervous system has evolved general functional relations between monotone transductions of perceptual values and the similarity of central interpretive processes. On average, he has maintained, the similarities generated by these functions are adaptive because they predict in what situations-consequential regions in his terminology-the same behavioral cause-effect relations are likely to hold. Shepard's mathematical laws for stimulus generalization are empiri-</p>
<p>cally correct or nearly so for a considerable range of low-dimensional perceptual continua and for certain functions computed on behaviorally measured relations such as choices between stimuli or judgments of similarity or inequality on some experiential dimension. However, his laws fall short of being able to predict whether cheetahs are considered more similar to zebras or tigers, whether friendship is thought to be more similar to love or hate, and are mute, or at least very incomplete, on the similarity of the meanings of the words cheetah, zebra, tiger, love, hate, and pode. Indeed, it is the generation of psychological similarity relations based solely on experience and the achievement of bridging inferences from experience about cheetahs and friendship to behavior about tigers and love and from hearing conversations about one to knowledge about the other that pose the most difficult and tantalizing puzzle.</p>
<p>Often the cognitive aspect of the induction puzzle is cast as the problem of categorization, of finding a mechanism by which a set of stimuli, words, or concepts (cheetahs, tigers) come to be treated as the same for some purposes (running away from, or using metaphorically to describe a friend or enemy). The most common attacks on this problem invoke similarity as the underlying relation among stimuli, concepts, or features (e.g., Rosch, 1978; Smith \&amp; Medin, 1981; Vygotsky, 1968). But as Goodman (1972) has trenchantly remarked, "similarity is an impostor," at least for the solution of the fundamental problem of induction. For example, the categorical status of a concept is often assumed to be determined by similarity to a prototype, or to some set of exemplars (e.g., Rosch, 1978; Smith \&amp; Medin, 1981). Similarity is either taken as primitive (e.g., Posner \&amp; Keele, 1968; Rosch, 1978) or as dependent on shared component features (e.g., Smith \&amp; Medin, 1981; Tversky, 1977; Tversky \&amp; Gati, 1978). But this throws us into an unpleasant regress: When is a feature a feature? Do bats have wings? When is a wing a wing? Apparently, the concept wing is also a category dependent on the similarity of features. Presumably, the regress ends when it grounds out in the primitive perceptual relations assumed, for example, by Shepard's theory. But only some basic perceptual similarities are relevant to any feature or category, others are not; a wing can be almost any color. The combining of disparate things into a common feature identity or into a common category must very often depend on experience. How does that work? Crisp categories, logically defined on rules about feature combinations, such as those often used in category learning, probability estimation, choice and judgment experiments, lend themselves to acquisition by logical rule-induction processes, although whether such processes are what humans always or usually use is questionable (Holland, Holyoak, Nisbett, \&amp; Thagard, 1986; Medin, Goldstone, \&amp; Gentner, 1993; Murphy \&amp; Medin, 1985; Smith \&amp; Medin, 1981). Surely, the natural acquisition of fuzzy or probabilistic features or categories relies on some other underlying process, some mechanism by which experience with examples can lead to treating new instances more or less equivalently, some mechanism by which common significance, common fate, or common context of encounter can generate acquired similarity. We seek a mechanism by which the experienced and functional similarity of con-cepts-especially complex, largely arbitrary ones, such as the meaning of concept, component, or feature, or, perhaps, the component features of which concepts might consist-are cre-
ated from an interaction of experience with the logical (or mathematical or neural) machinery of mind.</p>
<p>In attempting to explain the astonishing rate of vocabulary learning-some $7-10$ words per day-in children during the early years of preliterate language growth, theorists such as Carey (1985), Clark (1987), Keil (1989), and Markman (1994) have hypothesized constraints on the assignment of meanings to words. For example it has been proposed that early learners assume that most words are names for perceptually coherent objects, that any two words usually have two distinct meanings, that words containing common sounds have related meanings, that an unknown speech sound probably refers to something for which the child does not yet have a word, and that children obey certain strictures on the structure of relations among concept classes. Some theorists have supposed that the proposed constraints are biological givens, some have supposed that they derive from progressive logical derivation during development, some have allowed that constraints may have prior bases in experience. Many have hedged on the issue of origins, which is probably not a bad thing, given our state of knowledge. For the most part, proposed constraints on lexicon learning have also been described in qualitative mentalistic terminology that fails to provide entirely satisfying causal explanations: Exactly how, for example does a child apply the idea that a new word has a new meaning?</p>
<p>What all modern theories of knowledge acquisition (as well as Plato's) have in common is the postulation of constraints that greatly (in fact, infinitely) narrow the solution space of the problem that is to be solved by induction, that is, by learning. This is the obvious, indeed the only, escape from the inductive paradox. The fundamental notion is to replace an intractably large or infinite set of possible solutions with a problem that is soluble on the data available. So, for example, if biology specifies a function on wavelength of light that is assumed to map the difference between two objects that differ only in color onto the probability that doing the same thing with them will have the same consequences, then a bear need sample only one color of a certain type of berry before knowing which others to pick.</p>
<p>There are several problematical aspects to constraint-based resolutions of the induction paradox. One is whether a particular constraint exists as supposed. For example, is it true that young children assume that the same object is given only one name, and if so is the assumption correct about the language to which they are exposed? (It is not in adult English usage; ask 100 people what to title a recipe or name a computer command, and you will get almost 30 different answers on average-see Furtias, Landauer, Gomez, \&amp; Dumais, 1983, 1987). These are empirical questions, and ones to which most of the research in early lexical acquisition has been addressed. One can also wonder about the origin of a particular constraint and whether it is plausible to regard it as a primitive process with an evolutionary basis. For example, most of the constraints proposed for language learning are very specific and relevant only to human language, making their postulation consistent with a very strong instinctive and modular view of mental processes.</p>
<p>The existence and origin of particular constraints is only one part of the problem. The existence of some set of constraints is a logical necessity, so that showing that some exist is good but not nearly enough. We also need to know whether a particular</p>
<p>set of constraints is logically and pragmatically sufficient, that is, whether the problem space remaining after applying them is soluble. For example, suppose that young children do, in fact, assume that there are no synonyms. How much could that help them in learning the lexicon from the language to which they are exposed? Enough? Indeed, that particular constraint leaves the mapping problem potentially infinite; it could even exacerbate the problem by tempting the child to assign too much or the wrong difference to our dog, the collie, and Fido. Add in the rest of the constraints that have been proposed: Enough now?</p>
<p>How can one determine whether a specified combination of constraints would solve the problem, or perhaps better, determine how much of the problem it would solve? We believe that the best available strategy is to specify a concrete computational model embodying the proposed constraints and to simulate as realistically as possible its application to the acquisition of some measurable and interesting properties of human knowledge. In particular, with respect to constraints supposed to allow the learning of language and other large bodies of complexly structured knowledge, domains in which there are very many facts each weakly related to very many others, effective simulation may require data sets of the same size and content as those encountered by human learners. Formally, that is because weak local constraints can combine to produce strong inductive effects in aggregate. A simple analog is the familiar example of a diagonal brace to produce rigidity in a structure made of three beams. Each connection between three beams can be a single bolt. Two such connections exert no constraint at all on the angle between the beams. However, when all three beams are so connected, all three angles are completely specified. In structures consisting of thousands of elements weakly connected (i.e., constrained) in hundreds of different ways (i.e., in hundreds of dimensions instead of two), the effects of constraints may emerge only in very large, naturally generated ensembles. In other words, experiments with miniature or concocted subsets of language experience may not be sufficient to reveal or assess the forces that hold conceptual knowledge together. The relevant quantitative effects of such phenomena may only be ascertainable from experiments or simulations based on the same masses of input data encountered by people.</p>
<p>Moreover, even if a model could solve the same difficult problem that a human does given the same data it would not prove that the model solves the problem in the same way. What to do? Apparently, one necessary test is to require a conjunction of both kinds of evidence-observational or experimental evidence, that learners are exposed to and influenced by a certain set of constraints, and evidence that the same constraints approximate natural human learning and performance when embedded in a simulation model running over a natural body of data. However, in the case of effective but locally weak constraints, the first part of this two-pronged test-experimental or observational demonstration of their human use-might well fail. Such constraints might not be detectable by isolating experiments or in small samples of behavior. Thus, although an experiment or series of observational studies could prove that a particular constraint is used by people, it could not prove that it is not. A useful strategy for such a situation is to look for additional effects predicted by the postulated constraint system in other
phenomena exhibited by learners after exposure to large amounts of data.</p>
<h2>The Latent Semantic Analysis Model</h2>
<p>The model we have used for simulation is a purely mathematical analysis technique. However, we want to interpret the model in a broader and more psychological manner. In doing so, we hope to show that the fundamental features of the theory that we later describe are plausible, to reduce the otherwise magical appearance of its performance, and to suggest a variety of relations to psychological phenomena other than the ones to which we have as yet applied it.</p>
<p>We explicate all of this in a somewhat spiral fashion. First, we try to explain the underlying inductive mechanism of dimensionality optimization upon which the model's power hinges. We then sketch how the model's mathematical machinery operates and how it has been applied to data and prediction. Next, we offer a psychological process interpretation of the model that shows how it maps onto but goes beyond familiar theoretical ideas, empirical principles, findings, and conjectures. We finally return to a more detailed and rigorous presentation of the model and its applications.</p>
<h2>An Informal Explanation of the Inductive Value of Dimensionality Optimization</h2>
<p>Suppose that Jack and Jill can only communicate by telephone. Jack, sitting high on a hill and looking down at the terrain below estimates the distances separating three houses: A, B, and C. He says that House A is 5 units from both House B and House C, and that Houses B and C are separated by 8 units. Jill uses these estimates to plot the position of the three houses, as shown in the top portion of Figure 1. But then Jack says, "By the way, they are all on the same straight, flat road." Now Jill knows that Jack's estimates must have contained errors and revises her own in a way that uses all three together to improve each one, to $4.5,4.5$, and 9.0 , as shown in the bottom portion of Figure 1.</p>
<p>Three distances among three objects are always consistent in
<img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Figure 1. An illustration of the advantage of assuming the correct dimensionality when estimating a set of interpoint distances. Given noisy estimates of $A B, A C$, and $C B$, the top portion would be the best guess unless the data source was known to be one-dimensional, in which case the bottom construction would recover the true line lengths more accurately.</p>
<p>two dimensions so long as they obey the triangle inequality (the longest distance must be less than or equal to the sum of the other two). But, knowing that all three distances must be accommodated in one dimension strengthens the constraint (the longest must be exactly equal to the sum of the other two). If the dimensional constraint is not met, the apparent errors in the estimates must be resolved. One compromise is to adjust each distance by the same proportion so as to make two of the lengths add up to the third. The important point is that knowing the dimensionality improves the estimates. Of course, this works the other way around as well. Had the distances been generated from a two- or three-dimensional array (e.g., the road was curved or hilly), accommodating the estimates on a straight line would have distorted their original relations and added error rather than reducing it.</p>
<p>Sometimes researchers have considered dimensionality reduction as a method to reduce computational complexity or for smoothing, that is for simplifying the description of data or interpolating intermediate points (e.g., Church \&amp; Hanks, 1990; Grefenstette, 1994; Schütze, 1992a, 1992b). However, as we will see later, choosing the optimum dimensionality, when appropriate, can have a much more dramatic effect than these interpretations would seem to suggest.</p>
<p>Let us now construe the semantic similarity between two words in terms of distance in semantic space: The smaller the distance, the greater the similarity. Suppose we also assume that two words that appear in the same window of discourse-a phrase, a sentence, a paragraph, or what have you-tend to come from nearby locations in semantic space. ${ }^{1}$ We could then obtain an initial estimate of the relative similarity of any pair of words by observing the relative frequency of their joint occurrence in such windows.</p>
<p>Given a finite sample of language, such estimates would be quite noisy. Moreover, because of the huge number of words relative to received discourse, many pairwise frequencies would be zero. But two words could also fail to co-occur for a variety of reasons other than thin sampling statistics, with different implications for their semantic similarity. The words might be truly unrelated (e.g., semantic and carburetor). On the other hand, they might be near-perfect synonyms of which people usually use only one in a given utterance (e.g., overweight or corpulent), have somewhat different but systematically related meanings (e.g., purple and lavender), or be relevant to different aspects of the same object (e.g., gears and brakes) and therefore tend not to occur together (just as only one view of the same object may be present in a given scene). To estimate similarity in this situation, more complex, indirect relations (for example, that both gears and brakes co-occur with cars, but semantic and carburetor have no common bridge) must somehow be used.</p>
<p>One way of doing this is to take all of the local estimates of distance into account at once. This is exactly analogous to our houses example, and, as in that example, the choice of dimensionality in which to accommodate the pairwise estimates determines how well their mutual constraints combine to give the right results. That is, we suppose that word meanings are represented as points (or vectors; later we use angles rather than distances) in $k$ dimensional space, and we conjecture that it is possible to materially improve estimates of pairwise meaning
similarities, and to accurately estimate the similarities among related pairs never observed together, by fitting them simultaneously into a space of the same $(k)$ dimensionality.</p>
<p>This idea is closely related to familiar uses of factor analysis and multi-dimensional scaling, and to unfolding, (J. D. Carroll \&amp; Arabie, in press; Coombs, 1964), but using a particular kind of data and writ very large. Charles Osgood (1971) seems to have anticipated such a theoretical development when computational power eventually rose to the task, as it now has. How much improvement results from optimal dimensionality choice depends on empirical issues, the distribution of interword distances, the frequency and composition of their contexts in natural discourse, the detailed structure of distances among words estimated with varying precision, and so forth.</p>
<p>The scheme just outlined would make it possible to build a communication system in which two parties could come to agree on the usage of elementary components (e.g., words, at least up to the relative similarity among pairs of words). The same process would presumably be used to reach agreement on similarities between words and perceptual inputs and between perceptual inputs and each other, but for clarity and simplicity and because the word domain is where we have data and have simulated the process, we concentrate here on word-word relations. Suppose that a communicator possesses a representation of a large number of words as points in a high dimensional space. In generating strings of words, the sender tends to choose words located near each other. Over short time spans, contiguities among output words would reflect closeness in the sender's semantic space. A receiver could make first-order estimates of the distance between pairs by their relative frequency of occurrence in the same temporal contexts (e.g., a paragraph). If the receiver then sets out to represent the results of its statistical knowledge as points in a space of the same or nearly the same dimensionality as that from which it was generated, it may be able to do better, especially, perhaps, in estimating the similarities of words that never or rarely occur together. How much better depends, as we have already said, on matters that can only be settled by observation.</p>
<p>Except for some technical matters, our model works exactly as if the assumption of such a communicative process characterizes natural language (and, possibly, other domains of natural knowledge). In essence, and in detail, it assumes that the psychological similarity between any two words is reflected in the way they co-occur in small subsamples of language, that the source of language samples produces words in a way that ensures a mostly orderly stochastic mapping between semantic similarity and output distance. It then fits all of the pairwise similarities into a common space of high but not unlimited dimensionality. Because, as we see later, the model predicts what words should occur in the same contexts, an organism using such a mechanism could, either by evolution or learning,</p>
<p><sup id="fnref2:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>adaptively adjust the number of dimensions on the basis of trial and error. By the same token, not knowing this dimensionality a priori, in our studies we have varied the dimensionality of the simulation model to determine what produces the best results. ${ }^{2}$</p>
<p>More conceptually or cognitively elaborate mechanisms for the representation of meaning also might generate dimensional constraints and might correspond more closely to the mentalistic hypotheses of current linguistic and psycho-linguistic theories. For example, theories that postulate meaningful semantic features could be effectively isomorphic to LSA given the identification of a sufficient number of sufficiently independent features and their accurate quantitative assignment to all the words of a large vocabulary. But suppose that it is not necessary to add such subjective interpretations or elaborations for the model to work. Then LSA could be a direct expression of the fundamental principles on which semantic similarity (as well as other perceptual and memorial relations) are built rather than being a reflection of some other system. It is too early to tell whether the model is merely a mathematical convenience that approximates the effects of true cognitive features and processes or corresponds directly to the actual underlying mechanism of which more qualitative theories now current are themselves but partial approximations. The model we propose is at the computational level described by Marr (1982; see also Anderson, 1990), that is, it specifies the natural problem that must be solved and an abstract computational method for its solution.</p>
<h2>A Psychological Description of LSA as a Theory of Learning, Memory, and Knowledge</h2>
<p>We give a more complete description of LSA as a mathematical model later when we use it to simulate lexical acquisition. However, an overall outline is necessary to understand a roughly equivalent psychological theory we wish to present first. The input to LSA is a matrix consisting of rows representing unitary event types by columns representing contexts in which instances of the event types appear. One example is a matrix of unique word types by many individual paragraphs in which the words are encountered, where a cell contains the number of times that a particular word type, say model, appears in a particular paragraph, say this one. After an initial transformation of the cell entries, this matrix is analyzed by a statistical technique called singular value decomposition (SVD) closely akin to factor analysis, which allows event types and individual contexts to be re-represented as points or vectors in a high dimensional abstract space (Golub, Luk, \&amp; Overton, 1981). The final output is a representation from which one can calculate similarity measures between all pairs consisting of either event types or contexts (e.g., word-word, word-paragraph, or paragraph-paragraph similarities).</p>
<p>Psychologically, the data that the model starts with are raw, first-order co-occurrence relations between stimuli and the local contexts or episodes in which they occur. The stimuli or event types may be thought of as unitary chunks of perception or memory. The first-order process by which initial pairwise associations are entered and transformed in LSA resembles classical conditioning in that it depends on contiguity or co-occurrence, but weights the result first nonlinearly with local occurrence frequency, then inversely with a function of the number of differ-
ent contexts in which the particular component is encountered overall and the extent to which its occurrences are spread evenly over contexts. However, there are possibly important differences in the details as currently implemented; in particular, LSA associations are symmetrical; a context is associated with the individual events it contains by the same cell entry as the events are associated with the context. This would not be a necessary feature of the model; it would be possible to make the initial matrix asymmetrical, with a cell indicating the co-occurrence relation, for example, between a word and closely following words. Indeed, Lund and Burgess (in press; Lund, Burgess, \&amp; Atchley, 1995), and Schütze (1992a, 1992b), have explored related models in which such data are the input.</p>
<p>The first step of the LSA analysis is to transform each cell entry from the number of times that a word appeared in a particular context to the log of that frequency. This approximates the standard empirical growth functions of simple learning. The fact that this compressive function begins anew with each context also yields a kind of spacing effect; the association of A and B is greater if both appear in two different contexts than if they each appear twice in one context. In a second transformation, all cell entries for a given word are divided by the entropy for that word, $-\Sigma p \log p$ over all its contexts. Roughly speaking, this step accomplishes much the same thing as conditioning rules such as those described by Rescorla \&amp; Wagner (1972), in that it makes the primary association better represent the informative relation between the entities rather than the mere fact that they occurred together. Somewhat more formally, the inverse entropy measure estimates the degree to which observing the occurrence of a component specifies what context it is in; the larger the entropy of, say, a word, the less information its observation transmits about the places it has occurred, so the less usage-defined meaning it acquires, and conversely, the less the meaning of a particular context is determined by containing the word.</p>
<p>It is interesting to note that automatic information retrieval methods (including LSA when used for the purpose) are greatly improved by transformations of this general form, the present one usually appearing to be the best (Harman, 1986). It does not seem far-fetched to believe that the necessary transform for good information retrieval, retrieval that brings back text corresponding to what a person has in mind when the person offers one or more query words, corresponds to the functional relations in basic associative processes. Anderson (1990) has drawn attention to the analogy between information retrieval in external systems and those in the human mind. It is not clear which way the relationship goes. Does information retrieval in automatic systems work best when it mimics the circumstances that make people think two things are related, or is there a general logic that tends to make them have similar forms? In automatic information retrieval the logic is usually assumed to be that idealized searchers have in mind exactly the same text as they would like the system to find and draw the words in</p>
<p><sup id="fnref3:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>their queries from that text (see Bookstein \&amp; Swanson, 1974). Then the system's challenge is to estimate the probability that each text in its store is the one that the searcher was thinking about. This characterization, then, comes full circle to the kind of communicative agreement model we outlined above: The sender issues a word chosen to express a meaning he or she has in mind, and the receiver tries to estimate the probability of each of the sender's possible messages.</p>
<p>Gallistel (1990), has argued persuasively for the need to separate local conditioning or associative processes from global representation of knowledge. The LSA model expresses such a separation in a very clear and precise way. The initial matrix after transformation to log frequency divided by entropy represents the product of the local or pairwise processes. ${ }^{3}$ The subsequent analysis and dimensionality reduction takes all of the previously acquired local information and turns it into a unified representation of knowledge.</p>
<p>Thus, the first processing step of the model, modulo its associational symmetry, is a rough approximation to conditioning or associative processes. However, the model's next steps, the singular value decomposition and dimensionality optimization, are not contained as such in any extant psychological theory of learning, although something of the kind may be hinted at in some modern discussions of conditioning and, on a smaller scale and differently interpreted, is often implicit and sometimes explicit in many neural net and spreading-activation architectures. This step converts the transformed associative data into a condensed representation. The condensed representation can be seen as achieving several things, although they are at heart the result of only one mechanism. First, the re-representation captures indirect, higher-order associations. That is, if a particular stimulus, $X$, (e.g., a word) has been associated with some other stimulus, $Y$, by being frequently found in joint context (i.e., contiguity), and $Y$ is associated with $Z$, then the condensation can cause $X$ and $Z$ to have similar representations. However, the strength of the indirect $X Z$ association depends on much more than a combination of the strengths of $X Y$ and $Y Z$. This is because the relation between $X$ and $Z$ also depends, in a wellspecified manner, on the relation of each of the stimuli, $X, Y$, and $Z$, to every other entity in the space. In the past, attempts to predict indirect associations by stepwise chaining rules have not been notably successful (see, e.g., Pollio, 1968; Young, 1968). If associations correspond to distances in space, as supposed by LSA, stepwise chaining rules would not be expected to work well; if $X$ is two units from $Y$ and $Y$ is two units from $Z$, all we know about the distance from $X$ to $Z$ is that it must be between zero and four. But with data about the distances between $X, Y, Z$, and other points, the estimate of $X Z$ may be greatly improved by also knowing $X Y$ and $Y Z$.</p>
<p>An alternative view of LSA's effects is the one given earlier, the induction of a latent higher order similarity structure (thus its name) among representations of a large collection of events. Imagine, for example, that every time a stimulus (e.g., a word) is encountered, the distance between its representation and that of every other stimulus that occurs in close proximity to it is adjusted to be slightly smaller. The adjustment is then allowed to porcolate through the whole previously constructed structure of relations, each point pulling on its neighbors until all settle into a compromise configuration (physical objects, weather sys-
tems, and Hopfield nets do this too; Hopfield, 1982). It is easy to see that the resulting relation between any two representations depends not only on direct experience with them but with everything else ever experienced. Although the current mathematical implementation of LSA does not work in this incremental way, its effects are much the same. The question, then, is whether such a mechanism, when combined with the statistics of experience, produces a faithful reflection of human knowledge.</p>
<p>Finally, to anticipate what is developed later, the computational scheme used by LSA for combining and condensing local information into a common representation captures multivariate correlational contingencies among all the events about which it has local knowledge. In a mathematically well-defined sense it optimizes the prediction of the presence of all other events from those currently identified in a given context and does so using all relevant information it has experienced.</p>
<p>Having thus cloaked the model in traditional memory and learning vestments, we next reveal it as a bare mathematical formalism.</p>
<h2>A Neural Net Analog of LSA</h2>
<p>We describe the matrix-mathematics of singular value decomposition used in LSA more fully, but still informally, next and in somewhat greater detail in the Appendix. But first, for those more familiar with neural net models, we offer a rough equivalent in that terminology. Conceptually, the LSA model can be viewed as a simple but rather large three-layered neural net. It has a Layer 1 node for every word type (event type), a Layer 3 node for every text window (context or episode) ever encountered, several hundred Layer 2 nodes-the choice of number is presumed to be important-and complete connectivity between Layers 1 and 2 and between Layers 2 and 3. (Obviously, one could substitute other identifications of the elements and episodes). The network is symmetrical; it can be run in either direction. One finds an optimal number of middle-layer nodes, then maximizes the accuracy (in a least-squares sense) with which activating any Layer 3 node activates the Layer 1 nodes that are its elementary contents, and, simultaneously, vice versa. The conceptual representation of either kind of event, a unitary episode or a word, for example, is a pattern of activation across Layer 2 nodes. All activations and summations are linear.</p>
<p>Note that the vector multiplication needed to generate the middle-layer activations from Layer 3 values is, in general, different from that to generate them from Layer 1 values. Thus a different computation is required to assess the similarity between two episodes, two event types, or an event type and an episode, even though both kinds of entities can be represented as values in the same middle-layer space. Moreover, an event type or a set of event types could also be compared with another of the same or with an episode or combination of episodes by computing their activations on Layer 3. Thus the network can</p>
<p><sup id="fnref4:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>create artificial or "imaginary" episodes, and, by the inverse operations, episodes can generate "utterances" to represent themselves as patterns of event types with appropriately varying strengths. The same things are true in the equivalent singular-value-decomposition matrix model of LSA.</p>
<h2>The Singular Value Decomposition (SVD) Realization of LSA</h2>
<p>The principal virtues of SVD for this research are that it embodies the kind of inductive mechanisms that we want to explore, that it provides a convenient way to vary dimensionality, and that it can fairly easily be applied to data of the amount and kind that a human learner encounters over many years of experience. Realized as a mathematical data-analysis technique, however, the particular model studied should be considered only one case of a class of potential models that one would eventually wish to explore, a case that uses a very simplified parsing and representation of input and makes use only of linear relations. In possible elaborations one might want to add features that make it more closely resemble what we know or think we know about the basic processes of perception, learning, and memory. It is plausible that complicating the model appropriately might allow it to simulate phenomena to which it has not been applied and to which it currently seems unlikely to give a good account, for example certain aspects of grammar and syntax that involve ordered and hierarchical relations rather than unsigned similarities. However, what is most interesting at this point is how much it does in its present form.</p>
<h2>Singular Value Decomposition (SVD)</h2>
<p>SVD is the general method for linear decomposition of a matrix into independent principal components of which factor analysis is the special case for square matrices with the same entities as columns and rows. Factor analysis finds a parsimonious representation of all the intercorrelations between a set of variables in terms of a new set of abstract variables, each of which is unrelated to any other but which can be combined to regenerate the original data. SVD does the same thing for an arbitrarily shaped rectangular matrix in which the columns and rows stand for different things, as in the present case one stands for words, the other for contexts in which the words appear. (For those with yet other vocabularies, SVD is a form of eigenvalueeigenvector analysis or principal components decomposition and, in a more general sense, of two-way, two-mode multidimensional scaling (see J. D. Carroll \&amp; Arabie, in press).</p>
<p>To implement the model concretely and simulate human word learning, SVD was used to analyze 4.6 million words of text taken from an electronic version of Grolier's Academic American Encyclopedia, a work intended for young students. This encyclopedia has 30,473 articles. From each article we took a sample consisting of (usually) the whole text, or its first 2,000 characters, whichever was less, for a mean text sample length of 151 words, roughly the size of a rather long paragraph. The text data were cast into a matrix of 30,473 columns, each column representing one text sample, by 60,768 rows, each row representing a unique word type that appeared in at least two samples. The cells in the matrix contained the frequency with which a
particular word type appeared in a particular text sample. The raw cell entries were first transformed to [ln ( $1+$ cell frequency)/entropy of the word over all contexts]. This matrix was then submitted to SVD and the-for example- 300 most important dimensions were retained (those with the highest singular values, i.e., the ones that captured the greatest variance in the original matrix). The reduced dimensionality solution then generates a vector of 300 real values to represent each word and each context. See Figure 2. Similarity was usually measured by the cosine between vectors. ${ }^{4}$</p>
<p>We postulate that the power of the model comes from (optimal) dimensionality reduction. Here is still another, more specific, explanation of how this works. The condensed vector for a word is computed by SVD as a linear combination of data from every cell in the matrix. That is, it is not only the information about the word's own occurrences across documents, as represented in its vector in the original matrix, that determines the 300 values of its condensed vector. Rather, SVD uses everything it can-all linear relations in its assigned dimensional-ity-to induce word vectors that best predict all and only those text samples in which the word occurs. This expresses a belief that a representation that captures much of how words are used in natural context captures much of what we mean by meaning.</p>
<p>Putting this in yet another way, a change in the value of any cell in the original matrix can, and usually does, change every coefficient in every condensed word vector. Thus, SVD, when the dimensionality is reduced, gives rise to a new representation that partakes of indirect inferential information.</p>
<h2>A Brief Note on Neurocognitive and Psychological Plausibility</h2>
<p>We, of course, intend no claim that the mind or brain actually computes a SVD on a perfectly remembered event-by-context matrix of its lifetime experience using the mathematical machinery of complex sparse-matrix manipulation algorithms. What we suppose is merely that the mind-brain stores and reprocesses its input in some manner that has approximately the same effect. The situation is akin to the modeling of sensory processing with Fourier decomposition, where no one assumes that the brain uses fast Fourier transform the way a computer does, only that the nervous system is sensitive to and produces a result that reflects the frequency-spectral composition of the input. For</p>
<p><sup id="fnref5:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p><img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Figure 2. A schematic illustration of dimension reduction by singular value decomposition (SVD). In Figure 2A, rows stand for word types, columns for text contexts in which the words occurred, and cell entries ( $x$ ) are (transformed raw) frequencies with which a given word appeared in a given context. In Figures 2B and 2C columns are artificial orthogonal factors extracted from the data, and the cell entries ( $y$ and $z$ ) are derived by linear combination of all the data in the upper matrix in a way that is optimal for reconstructing the pattern similarities between words in a smaller number of dimensions.</p>
<p>LSA, hypotheses concerning how the brain might produce an SVD-like result remain to be specified, although it may not be totally vacuous to point out certain notable correspondences:</p>
<ol>
<li>Interneuronal communication processes are effectively vector multiplication processes between axons, dendrites, and cell bodies; the excitation of one neuron by another is proportional to the dot product (the numerator of a cosine) of the output of one and the sensitivities of the other across the synaptic connections that they share.</li>
<li>Single-cell recordings from motor-control neurons show that their combined population effects in immediate, delayed, and mentally rotated movement control are well described as vector averages (cosine weighted sums) of their individual representations of direction (Georgopoulos, 1996), just as LSA's context vectors are vector averages of their component word vectors.</li>
<li>The neural net models popularly used to simulate brain processes can be recast as matrix algebraic operations.</li>
</ol>
<p>It is also worth noting that many mathematical models of laboratory learning and other psychological phenomena have
employed vector representations and linear combination operations on them to good effect (e.g., Eich, 1982; Estes, 1986; Hintzman, 1986; Murdock, 1993), and many semantic networkrepresented theories, such as Kintsch (1988), could easily be recast in vector algebra. From this one can conclude that such representations and operations do not always distort psychological reality. LSA differs from prior application of vector models in psychology primarily in that it derives element values empirically from effects of experience rather than either prespecifying them by human judgment or experimenter hypothesis or fitting them as free parameters to predict behavior, that it operates over large bodies of experience and knowledge, and that, in general, it uses much longer vectors and more strongly and explicitly exploits optimal choice of dimensionality.</p>
<h2>Evaluating the Model</h2>
<p>Four pertinent questions were addressed by simulation. The first was whether such a simple linear model could acquire</p>
<p>knowledge of humanlike word meaning similarities to a significant extent if given a large amount of natural text. Second, supposing it did, would its success depend strongly on the dimensionality of its representation? Third, how would its rate of acquisition compare with that of a human reading the same amount of text? Fourth, how much of its knowledge would come from indirect inferences that combine information across samples rather than directly from the local contextual contiguity information present in the input data?</p>
<h2>LSA's Acquisition of Word Knowledge From Text</h2>
<p>In answer to the first question, we begin with results from the most successful runs, which used around 300 dimensions, a value that we have often found effective in other applications to large data sets. After training, the model's word knowledge was tested with 80 retired items from the synonym portion of the Test of English as a Foreign Language (TOEFL), kindly provided, along with normative data, by Educational Testing Service (ETS; Landauer \&amp; Dumais, 1994, 1996). Each item consists of a stem word, the problem word in testing parlance, and four alternative words from which the test taker is asked to choose that with the most similar meaning to the stem. The model's choices were determined by computing cosines between the vector for the stem word in each item and each of the four alternatives and choosing the word with the largest cosine (except in six cases where the encyclopedia text did not contain the stem, the correct alternative, or both, for which it was given a score of .25 ). The model got 51.5 correct, or $64.4 \%$ ( $52.5 \%$ corrected for guessing by the standard formula [correctchance/(1-chance)]. By comparison, a large sample of applicants to U.S. colleges from non-English-speaking countries who took tests containing these items averaged 51.6 items correct, or $64.5 \%$ ( $52.7 \%$ corrected for guessing). Although we do not know how such a performance would compare, for example, with U.S. school children of a particular age, we have been told that the average score is adequate for admission to many universities. For the average item, LSA's pattern of cosines over incorrect alternatives correlated .44 with the relative frequency of student choices.</p>
<p>Thus, the model closely mimicked the behavior of a group of moderately proficient English readers with respect to judgments of meaning similarity. We know of no other fully automatic application of a knowledge acquisition and representation model, one that does not depend on knowledge being entered by a human but only on its acquisition from the kinds of experience on which a human relies, that has been capable of performing well on a full-scale test used for adults. It is worth noting that LSA achieved this performance using text samples whose initial representation was simply a "bag of words"; that is, all information from word order was ignored, and there was, therefore, no explicit use of grammar or syntax. Because the model could not see or hear, it could also make no use of phonology, morphology, orthography, or real-world perceptual knowledge. More about this later.</p>
<h2>The Effect of Dimensionality</h2>
<p>The idea underlying our interpretation of the model supposes that the correct choice of dimensionality is important to success.
<img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>Figure 3. The effect of number of dimensions retained in latent-seman-tic-analysis (LSA)-singular-value-decomposition (SVD) simulations of word-meaning similarities. The dependent measure is the proportion of 80 multiple-choice synonym test items for which the model chose the correct answer. LSA was trained on text samples from 30,473 articles in an electronic file of text for the Grotiers Academic American Encyclopedia.</p>
<p>To determine whether it was, the simulation was repeated using a wide range of numbers of dimensions. See Figure 3 (note that the abscissa is on a log scale with points every 50 dimensions in the midregion of special interest). Two or three dimensions, as used, for example in many factor analytic and multidimensional scaling attacks on word meaning (e.g., Deese, 1965; Fillenbaum \&amp; Rapoport, 1971; Rapoport \&amp; Fillenbaum, 1972) and in the Osgood semantic differential (Osgood, Suci, \&amp; Tannenbaum, 1957), resulted in only $13 \%$ correct answers when corrected for guessing. More importantly, using too many factors also resulted in very poor performance. With no dimensionality reduction at all, that is, using cosines between rows of the original (but still transformed) matrix, only $16 \%$ of the items were correct. ${ }^{7}$ Near maximum performance of $45-53 \%$, corrected for guessing, was obtained over a fairly broad region around 300 dimensions. The irregularities in the results (e.g., the dip at 200 dimensions) are unexplained; very small changes in computed cosines can tip LSA's choice of the best test alternative in some cases. Thus choosing the optimal dimensionality of the reconstructed representation approximately tripled the number of words the model learned as compared to using the dimensionality of the raw data.</p>
<p><sup id="fnref6:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>Computational constraints prevented assessing points above 1,050 dimensions, except for the full-dimensional case at 30,473 dimensions that could be computed without performing an SVD. However, it is the mid range around the hypothesized optimum dimensionality that is of particular interest here, the matter of determining whether there is a distinct nonmonotonicity in accord with the idea that dimensionality optimization is important. To test the statistical significance of the obvious nonmonotonicity in Figure 3, we fitted separate log functions to the points below and above the observed maximum at 300 dimensions, not including the 300 point itself to avoid the bias of having selected the peak, or the extreme 30,473 point. The positive and negative slopes, respectively, had $r=.98(d f=5)$ and $-.86(d f=12)$, and associated $p s&lt;.0002$. Thus, it is clear that there is a strong nonmonotonic relation between number of LSA dimensions and accuracy of simulation, with several hundred dimensions needed for maximum performance, but still a small fraction of the dimensionality of the raw data.</p>
<h2>The Learning Rate of LSA Versus Humans and Its Reliance on Induction</h2>
<p>Next, in order to judge how much of the human learner's problem the model is able to solve, we need to know how rapidly it gains competence relative to human language learners. Even though the model can pass an adult vocabulary test, if it were to require much more data than a human to achieve the same performance one would have to conclude that its induction method was missing something important that humans possess. Unfortunately, we cannot use the ETS normative data directly for this comparison because we don't know how much English their sample of test takers had read, and because, unlike LSA, the ETS students were mostly second-language learners.</p>
<p>For similar reasons, although we have shown that LSA makes use of dimensionality reduction, we do not know how much, quantitatively, this feature would contribute to the problem given the language exposure of a normal human vocabulary learner. We report next some attempts to compare LSA with human word-knowledge acquisition rates and to assess the utility of its inductive powers under normal circumstances.</p>
<p>The rate and sources of schoolchildren's vocabulary acquisition. LSA gains its knowledge of words by exposure to text, a process that is at least partially analogous to reading. How much vocabulary knowledge do humans learn from reading and at what rate? We expand here on the brief summary given earlier. The main parameters of human learning in this major expertise acquisition task have been determined with reasonable accuracy. First note that we are concerned only with knowledge of the relative similarity of individual words taken as units, not with their production or with knowledge of their syntactical or grammatical function, their component spelling, sounds, or morphology or with their real-world pragmatics or referential semantics. That is not to say that these other kinds of word knowledge, which have been the focus of most of the work on lexicon acquisition in early childhood, are unimportant, only that what has been best estimated quantitatively for English vocabulary acquisition as a whole and what LSA has so far been used to simulate is knowledge of the similarity of word meanings.</p>
<p>Reasonable bounds for the long-term overall rate of gain of
human vocabulary comprehension, in terms comparable to our LSA results, are fairly well established. The way such numbers usually have been estimated is to choose words at random from a large dictionary, do some kind of test on a sample of people to see what proportion of the words they know, then reinflate. Several researchers have estimated comprehension vocabularies of young adults, with totals ranging from 40,000 to 100,000 for high school graduates (Nagy \&amp; Anderson, 1984; Nagy \&amp; Herman, 1987). The variation appears to be largely determined by the size of the dictionaries sampled and to some extent by the way in which words are defined as being separate from each other and by the testing methods employed (see Anglin, 1993; Miller, 1991; and Miller and Wakefield's commentary in Anglin, 1993, for review and critiques). The most common testing methods have been multiple-choice tests much like those of TOEFL, but a few other procedures have been employed with comparable results. Here is one example of an estimation method. Moyer and Landauer (Landauer, 1986) sampled 1,000 words from Webster's Third New International Dictionary (1964) and presented them to Stanford University undergraduates along with a list of 30 common categories. If a student classified a word correctly and rated it familiar it was counted as known. Landauer then went through the dictionary and guessed how many of the words could have been classified correctly by knowing some other morphologically related word and adjusted the results accordingly. The resulting estimate was around 100,000 words. This is at the high end of published estimates. The lowest frequently cited estimate is around 40,000 by the last year of high school (Nagy \&amp; Anderson, 1984). It appears, however, that all existing estimates are somewhat low because as many as $60 \%$ of the words found in a daily newspaper do not occur in dictionaries mostly names, some quite common (Walker \&amp; Amsler, 1986) and most have not adequately counted conventionalized multiword idioms and stock phrases whose meanings cannot or might not be derived from their components.</p>
<p>By simple division, knowing 40,000 to 100,000 words by 20 years of age means adding an average of $7-15$ new words a day from age 2 onwards. The rate of acquisition during late elementary and high school years has been estimated at between 3,000 and 5,400 words per year ( $10-15$ per day), with some years in late elementary school showing more rapid gains than the average (Anglin, 1993; Nagy \&amp; Herman, 1987; M. Smith, 1941). In summary, it seems safe to assume that, by the usual measures, the total meaning comprehension vocabularies of average fifth-to-eighth-grade students increase by somewhere between 10 and 15 new words per day.</p>
<p>In the LSA simulations every orthographically distinct word, defined as a letter string surrounded by spaces or punctuation marks, is treated as a separate word type. Therefore the most appropriate, although not perfect, correspondence in human word learning is the number of distinct orthographic forms for which the learner must have learned, rather than deduced, the meaning tested by TOEFL. Anglin's (1993; Anglin, Alexander, \&amp; Johnson, 1996) recent estimates of schoolchildren's vocabulary attempted to differentiate words whose meaning was stored literally from ones deduced from morphology. This was done by noting when the children mentioned or appeared to use word components during the vocabulary test and measuring their ability to do so when asked. He estimated gains of $9-12$</p>
<p>separate learned words per day for first-to-fifth-grade students, without including most proper names or words that have entered the language since around 1980. In addition to the usual factors noted above, there are additional grounds for suspecting that Anglin's estimates may be somewhat low; in particular, the apparent use of morphological analysis could sometimes instead be the result of induced similarity between meanings of independently learned words. For example, LSA computes a relatively high cosine between independent and independence ( $\cos =$ .60), perception and perceptual ( $\cos =.84$ ), comprehension and incomprehensible ( $\cos =.25$; where the average cosine between unrelated words is $\approx .07 \pm \approx .04$ ). LSA, of course has no knowledge of the internal structure of words. Thus children (or adults) asked to tell what independently means might think of independent not by breaking down independence into morphemic components, but because one word reminds them of the other (and adult introspection might fool itself similarly). However, these quibbles are rather beside the point for present purposes. The issue is whether LSA can achieve a rate of learning of word-meaning similarity that approaches or exceeds that of children, and for that purpose the estimates of Anglin, and virtually all others, give an adequate target. To show that its mechanism can do a substantial part of what children accomplish, LSA need only learn a substantial fraction of 10 words per day.</p>
<p>However, a further step in interpreting the LSA-child comparison allows us to more fully resolve the "excess learning" paradox. As mentioned earlier, children in late grade school must acquire most of their new word meanings from reading. The proof is straightforward. The number of different word types in spoken vocabulary is less than a quarter that in the printed vocabulary that people are able to read by the end of high school. ${ }^{6}$ Moreover, because the total quantity of heard speech is very large and spoken language undoubtedly provides superior cues for meaning acquisition, such as perceptual correlates, pragmatic context, gestures, and the outright feedback of disambiguating social and tutorial interactions, almost all of the words encountered in spoken language must have been well learned by the middle of primary school. Indeed estimates of children's word understanding knowledge by first grade range upwards toward the tens of thousands used in speech by an average adult (Seashore, 1947). Finally, very little vocabulary is learned from direct instruction. Most schools devote very little time to it, and it produces meager results. Authorities guess that at best 100 words a year could come from this source (Durkin, 1979).</p>
<p>It has been estimated that the average fifth-grade child spends about 15 min per day reading in school and another 15 min out of school reading books, magazines, mail, and comic books (Anderson, Wilson, \&amp; Fielding, 1988; Taylor, Frye, \&amp; Maruyama, 1990). If we assume 30 min per day total for 150 school days and 15 min per day for the rest of the year, we get an average of 21 min per day. At an average reading speed of 165 words per min (Carver, 1990) and a nominal paragraph length of 70 words, they read about 2.5 paragraphs per minute and about 50 per day. Thus, while reading, schoolchildren are adding about one new word to their comprehension vocabulary every 2 min or five paragraphs. Combining estimates of reader and text vocabularies (Nagy, Herman, \&amp; Anderson, 1985) with an
average reading speed of 165 words per minute (Anderson \&amp; Freebody, 1983; Carver, 1990; Taylor et al., 1990), one can infer that young readers encounter about one not-yet-known word per paragraph of reading. Thus the opportunity is there to acquire the daily ration. However, this would be an extremely rapid rate of learning. Consider the necessary equivalent list-learning speed. One would have to give children a list of 50 new words, each with one paragraph of exemplary context, and expect them to derive and permanently retain $10-15$ sufficiently precise meanings after a single very rapid study trial.</p>
<p>Word meanings are acquired by reading, but how? Several research groups have tried to mimic or enhance the contextual learning of words. The experiments are usually done by selecting nonsense or unknown words at the frontier of grade-level vocabulary knowledge and embedding them in sampled or carefully constructed sentences or paragraphs that imply aspects of meaning for the words. The results are uniformly discouraging. For example, Jenkins, Stein, and Wysocki (1984) constructed paragraphs around 18 low-frequency words and had fifth graders read them up to 10 times each over several days. The chance of learning a new word on one reading, as measured by a forcedchoice definition test, was between .05 and .10 . More naturalistic studies have used paragraphs from school books and measured the chance of a word moving from incorrect to correct on a later test as a result of one reading or one hearing (Elley, 1989; Nagy et al., 1985). About one word in 20 paragraphs makes the jump, a rate of 0.05 words per paragraph read. At 50 paragraphs read per day, children would acquire only 2.5 words per day. (Carver and Leibert, 1995, assert that even these rates are high as a result of methodological flaws.)</p>
<p>Thus, experimental attempts intended to produce accelerated vocabulary acquisition have attained less than one half the natural rate, and measurements made under more realistic conditions</p>
<p><sup id="fnref7:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>find at best one fourth the normal rate. ${ }^{7}$ This leads to the conclusion that much of what the children learned about words from the texts they read must have gone unmeasured in these experiments.</p>
<p>The rate and sources of LSA's vocabulary acquisition. We wish now to make comparisons between the word-knowledge acquisition of LSA and that of children. First, we want to obtain a comparable estimate of LSA's overall rate of vocabulary growth. Second, to evaluate our hypothesis that the model, and by implication, a child, relies strongly on indirect as well as direct learning in this task, we wish to estimate the relative effects of experience with a passage of text on knowledge of the particular words contained in it, and its indirect effects on knowledge of all other words in the language, effects that would not have been measured in the empirical studies of children acquiring vocabulary from text. If LSA learns close to 10 words from the same amount of text that students read, assuming that children use a similar mechanism would resolve the excesslearning paradox.</p>
<p>Because the indirect effects in LSA depend both on the model's computational procedures and on empirical properties of the text it learns from, it is necessary to obtain estimates relevant to a body of text equivalent to what school-age children read. We currently lack a full corpus of representative children's reading on which to perform the SVD. However, we do have access to detailed word-distribution statistics from such a corpus, the one on which the American Heritage Word Frequency Book (J. B. Carroll, Davies, \&amp; Richman, 1971) was based. By assuming that learners would acquire knowledge about the words in the J. B. Carroll et al. materials in the same way as knowledge about words in the encyclopedia, except with regard to the different words involved, these statistics can provide the desired estimates.</p>
<p>It is clear enough that, for a human, learning about a word's meaning from a textual encounter depends on knowing the meaning of other words. As described above, in principle this dependence is also present in the LSA model. The reduced dimensional vector for a word is a linear combination of information about all other words. Consequently, data solely about other words, for example a text sample containing words $Y$ and $Z$, but not word $X$, can change the representation of $X$ because it changes the representations of $Y$ and $Z$, and all three must be accommodated in the same overall structure. However, estimating the absolute sizes of such indirect effects in words learned per paragraph or per day, and its size relative to the direct effect of including a paragraph actually containing word $X$ calls for additional analysis.</p>
<p>Details of estimating direct and indirect effects. The first step in this analysis was to partition the influences on the knowledge that LSA acquired about a given word into two components, one attributable to the number of passages containing the word itself, the other attributable to the number of passages not containing it. To accomplish this we performed variants of our encyclopedia-TOEFL analysis in which we altered the text data submitted to SVD. We independently varied the number of text samples containing stem words and the number of text samples containing no words from the TOEFL test items. For each stem word from the TOEFL test we randomly selected various numbers of text samples in which it appeared and replaced all occur-
rences of the stem word in those contexts with a corresponding nonsense word. After analysis we tested the nonsense words by substituting them for the originals in the TOEFL test items. In this way we maintained the natural contextual environment of words while manipulating their frequency. Ideally, we wanted to vary the number of text samples per nonsense word so as to have $2,4,8,16$, and 32 occurrences in different repetitions of the experiment. However, because not all stem words had appeared sufficiently often in the corpus, this goal was not attainable, and the actual mean numbers of text samples in the five conditions were $2.0,3.8,7.4,12.8$, and 22.2 . We also varied the total number of text samples analyzed by the model by taking successively smaller nested random subsamples of the original corpus. We examined total corpus sizes of 2,500; 5,000; 10,000; 15,000; 20,000; 25,000; and 30,473 text samples (the full original corpus). In all cases we retained every text sample that contained any word from any of the TOEFL items. ${ }^{8}$ Thus the stem words were always tested by their discriminability from words that had appeared the same, relatively large, number of times in all conditions.</p>
<p>For this analysis we adopted a new, more sensitive outcome measure. Our original figure of merit, the number of TOEFL test items in which the correct alternative had the highest cosine with the stem, mimics human test scores but contains unnecessary binary quantification noise. We substituted a discrimination</p>
<p><sup id="fnref8:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>ratio measure, computed by subtracting the average cosine between a stem word and the three incorrect alternatives from the cosine between the stem word and the correct alternative, then dividing the result by the standard deviation of cosines between the stem and the incorrect alternatives, that is, (cos stem.correct - mean cos stem.incorrect ${ }<em 1-3="1-3">{1-3}$ )/(std cos stem.incorrect ${ }</em>$ measure. The $z$ scores also had additive properties needed for the following analyses.}$ ). This yields a $z$ score, which can also be interpreted as a $d^{\prime</p>
<p>The results are depicted in Figure 4. Both experimental factors had strong influences; on average the difference between correct and incorrect alternatives grows with both the number of text samples containing the stem word, $S$, and with additional text samples containing no words on the test, T , and there is a positive interaction between them. For both overall log functions $r&gt;.98 ; F(6)$ for $T=26.0, p&lt;&lt;.001 ; F(4)$ for $S=64.6, p$ $&lt;&lt;.001$; the interaction was tested as the linear regression of slope on $\log S$ as a function of $\log T, r^{2}=.98, F(4)=143.7$, $p=.001$.) These effects are illustrated in Figure 4 along with logarithmic trend lines for $T$ within each level of $S$.</p>
<p>Because of the expectable interaction effects-experience with a word helps more when there is experience with other words-quantitative estimates of the total gain from new reading and of the relative contributions of the two factors are only meaningful for a particular combination of the two factors. In other words, to determine how much learning encountering a particular word in a new text sample contributes, one must know
<img alt="img-3.jpeg" src="img-3.jpeg" /></p>
<p>Figure 4. The combined effect in latent semantic analysis (LSA) simulations of the average number of contexts in which a test word appeared (the parameter), and the total number of other contexts, those containing no words from the synonym test items. The dependent measure is the normalized difference in LSA similarity (cosine) of the test words to their correct and incorrect alternatives. The variables were experimentally manipulated by randomly replacing test words with nonsense words and choosing random nested subsamples of total text. The fitted lines are separate empirical log functions for each parameter value.
how many other text samples with and without that word the learner or model has previously met.</p>
<p>In the last analysis step, we estimated, for every word in the language, how much the $z$ score for that word increased as a result of including a text sample that contained it and for including a text sample that did not contain it, given a selected point in a simulated schoolchild's vocabulary learning history. We then calculated the number of words that would be correct given a TOEFL-style synonym test of all English words. To anticipate the result, for a simulated seventh grader we concluded that the direct effect of reading a sample on knowledge of words in the sample was an increase of approximately 0.05 words of total vocabulary, and the effect of reading the sample on other words (i.e., all those not in the sample) was a total vocabulary gain of approximately 0.15 words. Multiplying by a nominal 50 samples read, we get a total vocabulary increase of about 10 words per day. Details of this analysis are given next.</p>
<p>Details of LSA simulation of total vocabulary gain. First, we devised an overall empirical model of the joint effects of direct and indirect textual experience that could be fit to the full set of data of Figure 4:</p>
<p>$$
z=\mathrm{a}(\log \mathrm{~b} T)(\log \mathrm{c} S)
$$</p>
<p>where $T$ is the total number of text samples analyzed, $S$ is the number of text samples containing the stem word, and $\mathrm{a}, \mathrm{b}$, and c are fitted constants ( $\mathrm{a}=0.128, \mathrm{~b}=0.076, \mathrm{c}=31.910$ for the present data, least squares fitted by the Microsoft Excel Version 5.0 (1993) iterative equation solver.) Its predictions are correlated with observed $z$ with $r=.98$. To convert its predictions to an estimate of probability correct, we assumed $z$ to be a normal deviate and determined the area under the normal curve to the right of its value minus that of the expected value for the maximum from a sample of three. In other words, we assumed that the cosines for the three incorrect alternatives in each item were drawn from the same normal distribution and that the probability of LSA choosing the right answer is the probability that the cosine of the stem to the correct alternative is greater than the expected maximum of three incorrect alternatives. The overall two-step model is correlated $r=.89$ with observed percentage correct.</p>
<p>Next, we estimated for every word in the language (a) the probability that a word of its frequency appears in the next text sample that a typical seventh grader encounters and (b) the number of times the individual would have encountered that word previously. We then calculated, from Equation 1, (c) the expected increase in $z$ for a word of that frequency as a result of one additional passage containing it and (d) the expected increase in $z$ for a word of that frequency as a result of one additional passage not containing it. Finally, we converted $z$ to probability correct, multiplied by the corresponding frequencies, and cumulated gains in number correct over all individual words in the language to get the total vocabulary gains from reading a single text sample.</p>
<p>The J. B. Carroll et al. (1971) data give the frequency of occurrence of each word type in a representative corpus of text read by schoolchildren. Conveniently, this corpus is nearly the same in both overall size, five million words, and in number of word types, 68,000 , as our encyclopedia sample (counting, for</p>
<p>the encyclopedia sample, singletons not included in the SVD analysis), so that no correction for sample size, which alters word frequency distributions, was necessary.</p>
<p>Simulating a schoolchild's learning. To simulate the rate of learning for an older grade school child, we assumed that she would have read a total of 3.8 million words, equivalent to 25,000 of our encyclopedia text samples, and set $T$ equal to 25,000 before reading a new paragraph and to 25,001 afterward. We divided the word types in J. B. Carroll et al. (1971) into 37 frequency bands ( $&lt;1,1,2, \ldots 20$ and roughly logarithmic thereafter to $&gt;37,000$ ) and for each band set $S$ equal to an interpolated central frequency of words in the band. ${ }^{9}$ We then calculated the expected number of additional words known in each band (the probability correct estimated from the jointeffect model times the probability of occurrence of a token belonging to the band, or the total number of types in the band, respectively) to get (a) the expected direct increase due to one encounter with a test word and (b) the expected increase due to the indirect effect of reading a passage on all other words in the language. ${ }^{10}$</p>
<p>The result was that the estimated direct effect was 0.0007 words gained per word encountered, and the indirect effect was a total vocabulary gain of 0.1500 words per text sample read. Thus the total increase per paragraph read in the number of words the simulated student would get right on a test of all the words in English would be approximately $0.0007 \times 70$ (approximate number of words in an average paragraph) +0.15 $=0.20$. Because the average student reads about 50 paragraphs a day (Taylor et al., 1990), the total amounts to about 10 new words per day.</p>
<p>About the accuracy of the simulations. Before further interpreting these results, let us consider their likely precision. The only obvious factors that might lead to overestimated effects are differences between the training samples and text normally read by schoolchildren. First, it is possible that the heterogeneity of the text samples, each of which was drawn from an article on a different topic, might cause a sorting of words by meaning that is more beneficial to LSA word learning than is normal children's text. Counterpoised against this possibility, however, is the reasonable expectation that school reading has been at least partially optimized for children's vocabulary acquisition.</p>
<p>Second, the encyclopedia text samples had a mean of 151 words, and we have equated them with assumed 70 word paragraphs read by schoolchildren. This was done because our hypothesis is that connected passages of text on a particular topic are the effective units of context for learning words and that the best correspondence was between the encyclopedia initial-text samples, usually full short articles, and paragraphs of text read by children. To check the assumption that window-size differences would not materially alter conclusions from the present analysis, we recomputed the TOEFL discrimination ratio results at 300 dimensions for a smaller window size by subdividing the original $\leq 2,000$ character samples into exhaustive sequential subsets of $\leq 500$ characters, thus creating a set of 68,527 contexts with a mean of 73 words per sample. The new result was virtually identical to the original value, $z=0.93$. versus 0.89 , corresponding by the models above to about $53 \%$ versus $52 \%$ correct on TOEFL, respectively.</p>
<p>There are a several reasons to suspect that the estimated LSA
learning rate is biased downward rather than upward relative to children's learning. First to continue with the more technical aspects of the analysis, the text samples used were suboptimal in several respects. The crude 2,000 character length cutoff was used because the available machine-readable text had no consistent paragraph or sentence indicators. This resulted in the inclusion of a large number of very short samples, things like "Constantinople: See Istanbul," and of many long segments that contained topical changes that surely would have been signaled by paragraphs in the original.</p>
<p>Of course, we do not know how the human mind chooses the context window. Several alternatives suggest themselves. And it is plausible that the effective contexts are sliding windows rather than the independent samples used here and likely that experienced readers parse text input into phrases, sentences, paragraphs, and other coherent segments rather than arbitrary isolated pieces. Thus, although LSA learning does not appear to be very sensitive to moderate differences in the context window size, window selection was probably not optimized in the reported simulations as well as it is in human reading. The more general question of the effect of window size and manner of selection is of great interest, but requires additional data and analysis.</p>
<p>For the present discussion, more interesting and important differences involve a variety of sources of evidence about word meanings to which human word learners have access but LSA did not. First, of course, humans are exposed to vast quantities of spoken language in addition to printed words. Although we have noted that almost all words heard in speech would be passed on vocabulary tests before seventh grade, the LSA mechanism supposes both that knowledge of these words is still growing slowly in representational quality as a result of new</p>
<p><sup id="fnref9:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>contextual encounters and, more importantly, that new experience with any word improves knowledge of all others.</p>
<p>Second, the LSA analysis treats text segments as mere "bags of words," ignoring all information present in the order of the words, thus making no use of syntax or of the logical, grammatical, discursive, or situational relations it caries. Experts on reading instruction (e.g., Drum \&amp; Konopak, 1987; Durkin, 1979) mental abilities (e.g., Sternberg, 1987) and psycholinguistics (e.g., Kintsch \&amp; Vipond, 1979; Miller, 1978) have stressed the obvious importance of these factors to the reader's ability to infer word meanings from text. Indeed, Durkin (1983, p. 139) asserts that scrambled sentences would be worthless context for vocabulary instruction (which may well have some validity for human students who have learned some grammar, but clearly is not for LSA).</p>
<p>In the simulations, words were treated as arbitrary units with no internal structure and no perceptual identities; thus LSA could also take no advantage of morphological relations or sound or spelling similarities. Moreover, the data for the simulations was restricted to text, with no evidence provided on which to associate either words or text samples with real-world objects or events or with its own thoughts, emotions, or intended actions as a person might. LSA could make no use of perceptual or experiential relations in the externally referenced world of language or of phonological symbolism (onomatopoeia) to infer the relation between words. Finally, LSA is neither given nor acquires explicitly usable knowledge of grammar (e.g., part-ofspeech word classes) or of the pragmatic constraints, such as one-object-one-word, postulated by students of early language acquisition.</p>
<p>Thus, the LSA simulations must have suffered considerable handicaps relative to the modeled seventh-grade student to whom it was compared. Suppose that the seventh grader's extra abilities are used simply to improve the input data represented in Figure 2, for example, by adding an appropriate increment to plurals of words whose singulars appear in a text sample, parsing the input so that verbs and modifiers were tallied jointly only with their objects rather than everything in sight. Such additional information and reduced noise in the input data would improve direct associational effects and presumably be duly amplified by the inductive properties of the dimensionalitymatching mechanisms.</p>
<h2>Conclusions From the Vocabulary Simulations</h2>
<p>There are three important conclusions to be drawn from the results we have described. In descending order of certainty, they are</p>
<ol>
<li>LSA learns a great deal about word meaning similarities from text, an amount that equals what is measured by multiplechoice tests taken by moderately competent English readers.</li>
<li>About three quarters of LSA's word knowledge is the result of indirect induction, the effect of exposure to text not containing words used in the tests.</li>
<li>Putting all considerations together, it appears safe to conclude that there is enough information present in the language to which human learners are exposed to allow them to acquire the knowledge they exhibit on multiple-choice vocabulary tests. That is, if the human induction system equals LSA in its effi-
ciency of extracting word similarity relations from discourse and has a moderately better system for input parsing and uses some additional evidence from speech and real-world experience, it should have no trouble at all doing the relevant learning it does without recourse to language-specific innate knowledge.</li>
</ol>
<p>Let us expand a bit on the apparent paradox of schoolchildren increasing their comprehension vocabularies more rapidly than they learn the words in the text they read. This observation could result from either a measurement failure or from induced learning of words not present. The LSA simulation results actually account for the paradox in both ways. First, of course, we have demonstrated very strong inductive learning. But, the descriptive model fitted to the simulation data was also continuous, that is, it assumed that knowledge, in the form of correct placement in the high-dimensional semantic space, is always partial and grows on the basis of small increments distributed over many words. Measurements of children's vocabulary growth from reading have usually looked only at words gotten wrong before reading to see how many of them are gotten right afterwards. In contrast, the LSA simulations computed an increment in probability correct for every word in the potential vocabulary. Thus, it implicitly expresses the hypothesis that word meanings grow continuously and that correct performance on a multiple choice vocabulary test is a stochastic event governed by individual differences in experience, by sampling of alternatives in the test items and by fluctuations, perhaps contextually determined, in momentary knowledge states. As a result, word meanings are constantly in flux, and no word is ever perfectly known. So, for the most extreme example, the simulation computed a probability of one in 500,000 that even the word the would be incorrectly answered by some seventh grader on some test at some time.</p>
<p>It is obvious, then, that LSA provides a solution to Plato's problem for at least one case, that of learning word similarities from text. Of course, human knowledge of word meaning is evinced in many other ways, supports many other kinds of performance, and almost certainly reflects knowledge not captured by judgments of similarity. However, it is an open question to what extent LSA, given the right input, can mimic other aspects of lexical knowledge as well.</p>
<h2>Generalizing the Domain of LSA</h2>
<p>There is no reason to suppose that the mind uses dimensionality optimization only to induce similarities involving words. Many other aspects of cognition would also profit from a means to extract more knowledge from a multitude of local co-occurrence data. Although the full range and details of LSA's implications and applicability await much more research, we give some examples of promising directions, phenomena for which it provides new explanations, interpretations, and predictions. In what follows there are reports of new data, new accounts of established experimental facts, reinterpretation of common observations, and some speculative discussion of how old problems might look less opaque in this new light.</p>
<h2>Other Aspects of Lexical Knowledge</h2>
<p>By now many readers may wonder how the word similarities learned by LSA relate to meaning. Whereas it is probably impos-</p>
<p>sible to say what word meaning is in a way that satisfies all students of the subject, it is clear that two of its most important aspects are usage and reference. Obviously, the similarity relations between words that are extracted by LSA are based on usage. Indeed, the underlying mathematics can be described as a way to predict the use of words in context, and the only reference of a word that LSA can be considered to have learned in our simulations is reference to other words and to sets of words (although the latter, the contexts of the analysis, may be considered to be coded descriptions of nonlinguistic events). It might be tempting to dismiss LSA's achievements as a sort of statistical mirage, a reflection of the conditions that generate meaning, but not a representation that actually embodies it. We believe that this would be a mistake. Certainly words are most often used to convey information grounded in nonlinguistic events. But to do so, only a small portion of them, and few of the encounters from which the meanings even of those are derived, need ever have been directly experienced in contextual association with the perception of objects, events, or nonlinguistic internal states. Given the strong inductive possibilities inherent in the system of words itself, as the LSA results have shown, the vast majority of referential meaning may well be inferred from experience with words alone. Note that the inductive leaps made by LSA in the simulations were all from purely abstract symbols to other purely abstract symbols. Consider how much more powerful word-based learning would be with the addition of machinery to represent other relations. But for such more elaborate mechanisms to work, language users must agree to use words in the same way, a job much aided by the LSA mechanism.</p>
<p>Even without such extension, however, the LSA model suggests new ways of understanding many familiar properties of language other than word similarity. Here is one homely example. Because, in LSA, word meaning is generated by a statistical process operating over samples of data, it is no surprise that meaning is fluid, that one person's usage and referent for a word is slightly different from the next person's, that one's understanding of a word changes with time, that words drift in both usage and reference over time for the whole community. Indeed, LSA provides a potential technique for measuring the drift in an individual or group's understanding of words as a function of language exposure or interactive history.</p>
<h2>Real-World Reference</h2>
<p>But still, to be more than an abstract system like mathematics words must touch reality at least occasionally. LSA's inductive mechanism would be valuable here as well. Although not so easily quantified, Plato's problem surely frustrates identification of the perceptual or pragmatic referent of words like mommy, rabbit, cow, girl, good-bye, chair, run, cry, and eat in the infinite number of real-world situations in which they can potentially appear. What LSA adds to this part of lexicon learning is again its demonstration of the possibility of stronger indirect association than has usually been credited. Because, purely at the wordword level, rabbit has been indirectly preestablished to be something like dog, animal, object, furry, cute, fast, ears, etc., it is much less mysterious that a few contiguous pairings of the word with scenes including the thing itself can teach the proper
correspondences. Indeed, if one judiciously added numerous pictures of scenes with and without rabbits to the context columns in the encyclopedia corpus matrix, and filled in a handful of appropriate cells in the rabbit and hare word rows, LSA could easily learn that the words rabbit and hare go with pictures containing rabbits and not to ones without, and so forth. Of course, LSA alone does not solve the visual figure-ground, object parsing, binding, and recognition parts of the problem, but even here it may eventually help by providing a powerful way to generate and represent learned and indirect similarity relations among perceptual features. In any event, the mechanisms of LSA would allow a word to become similar to a perceptual or imaginal experience, thus, perhaps, coming to "stand for" it in thought, to be evoked by it, or to evoke similar images.</p>
<p>Finally, merely using the right word in the right place is, in and of itself, an adaptive ability. A child can usefully learn that the place she lives is Colorado, a college student that operant conditioning is related to learning, a businessperson that TQM is the rage, before needing any clear idea of what these terms stand for. Many well-read adults know that Buddha sat long under a banyan tree (whatever that is) and Tahitian natives lived idyllically on breadfruit and poi (whatever those are). More or less correct usage often precedes referential knowledge (Levy \&amp; Nelson, 1994), which itself can remain vague but connotatively useful. Moreover, knowing in what contexts to use a word can function to amplify learning more about it by a bootstrapping operation in which what happens in response provides new context if not explicit verbal correction.</p>
<p>Nonetheless, the implications of LSA for learning pragmatic reference seem most interesting. To take this one step deeper, consider Quine's famous gavagai problem. He asks us to imagine a child who sees a scene in which an animal runs by. An adult says "gavagai." What is the child to think gavagai means: ears, white, running, or something else in the scene? There are infinite possibilities. In LSA, if two words appear in the same context and every other word in that context appears in many other contexts without them, the two can acquire similarity to each other but not to the rest. This is illustrated in Figures A2 and A4 in the Appendix, which we urge the reader to examine. This solves the part of the problem that is based on Quine's erroneous implicit belief that experiential knowledge must directly reflect first-order contextual associations. What about legs and ears and running versus the whole gavagai? Well, of course, these might actually be what is meant. But by LSA's inductive process, component features of legs, tail, ears, fur, and so forth either before or later are all related to each other, not only because of the occasions on which they occur together, but by indirect result of occasions when they occur with other things and more important, by occasions in which they do not occur at all. Thus the new object in view is not just a collection of unrelated features, each in a slightly different orientation than ever seen before, but a conglomerate of weakly glued features all of which are changed and made yet more similar to each other and to any word selectively used in their presence.</p>
<p>Now consider the peculiar fact that people seem to agree on words for totally private experiences, words like ache and love. How can someone know that his experience of an ache or of love is like that of his sister? Recognizing that we are having</p>
<p>the same private experience as someone else is an indirect inference, an inference that is often mediated by agreeing on a common name for the experience. We have seen how LSA can lead to agreement on the usage of a word in the absence of any external referent and how it can make a word highly similar to a context even if it never occurs in that context. It does both by resolving the mutual entailments of a multitude of other wordword, word-context, and context-context similarities, in the end defining the word as a point in meaning space that is much the same - but never identical - for different speakers and, perforce, is related to other words and other contextual experiences in much the same way for all. If many times when a mother has a dull pain in her knee, she says "nache," the child may find himself thinking "nache" when having the same experience, even though the mother has never overtly explained herself and never said "nache" when the child's knee hurt. But the verbal and situational contexts of knee pains jointly point to the same place in the child's LSA space as in hers and so does her novel name for the child's similar private experiences. Note, also, how experiences with verbal discourse alone could indirectly influence similarity among perceptual concepts as such, and vice versa, another way to make ears and tails, aches and pains, run together. Thus, language does not just reflect perception; the two are reciprocally helpful to each other (see D'Andrade, 1993; Lucy \&amp; Shweder, 1979, for cogent anthropological evidence on this point).</p>
<h2>Conditioning, Perceptual Learning, and Chunking</h2>
<p>In this section we take the notion of the model as a homologue of associative learning a few tentative steps further. At this point in the development of the theory, this part must remain conjectural and only roughly specified. The inductive processes of LSA depend on and accrue only to large bodies of naturally interrelated data; thus testing more elaborate and complex models demands more data, computational resources, and time than has been available. Nevertheless, a sketch of some possible implications and extensions shows how the dimensionality-optimizing inductive process might help to explain a variety of important phenomena that appear more puzzling without it and suggests new lines of theory and investigation.</p>
<p>After the dimensionality reduction of LSA every component event is represented as a vector, and so is each context. There is, then, no fundamental difference between components and contexts, except in regard to temporal scale and repeatability; words, for example, are shorter events that happen more than once, and paragraphs are longer events that are almost never met again. Thus, in a larger theoretical framework, or in a real brain, any mental event might serve in either or both roles. For mostly computational reasons, we have so far been able to deal only with two temporal granularities, one nested relation in which repeatability was a property of one type of event and not the other. But there is no reason why much more complex structures, with mental (or neural) events at varying temporal scales and various degrees of repeatability could not exploit the same dimensionality-matching mechanism to produce similarities and generalization among and between psychological entities of many kinds, such as stimuli, responses, percepts, concepts, memories, ideas, images, and thoughts. Because of the
mathematical manner in which the model creates representations, a condensed vector representing a context is the same as an appropriately weighted vector average of the condensed vectors of all the events whose local temporal associations constituted it. This has the important property that a new context composed of old units also has a vector representation in (technically, a linear transform of) the space, which in turn gives rise to similarity and generalization effects among new event complexes in an essentially identical fashion to those for two old units or two old contexts. In some examples we give later, the consequences of representing larger segments of experience as a weighted vector sum of the smaller components of which they are built are illustrated. For example, we show how the vector-average representation of a sentence or a paragraph predicts comprehension of a following paragraph, whereas its sharing of explicit words, even when appropriately weighted, does not, and we give examples in which the condensed-vector representation for a whole paragraph determines which of two words it is most similar to, whereas any one word in it may not.</p>
<h2>A New Light on Classical Association Theory</h2>
<p>Since at least the English associationists, the question of whether association happens by contiguity, similarity, or both has been much argued. LSA provides an interesting answer. In the first instance, similarity is acquired by a process that begins, but only begins, with contiguity. The high-dimensional combination of contiguity data finishes the construction of similarity. But the relations expressed by the high-dimensional representation into which contiguity data are fit are themselves ones of similarity. Thus similarity itself is built of both contiguity and still more similarity. This might explain why an introspectionist, or an experimentalist, could be puzzled about which does what. Even though they are different, the two keep close company, and after sufficient experience, there is a chicken-and-egg relation between their causative effects on representation.</p>
<h2>Analogy to Episodic and Semantic Memories</h2>
<p>Another interesting aspect of this notion is the light in which it places the distinction between episodic and semantic memory. In our simulations, the model represents knowledge gained from reading as vectors standing for unique paragraph-like samples of text and as vectors standing for individual word types. The word representations are thus semantic, meanings abstracted and averaged from many experiences, while the context representations are episodic, unique combinations of events that occurred only once ever. The retained information about the context paragraph as a single average vector is a representation of gist rather than surface detail. (And, as mentioned earlier, although text passages do not contain all the juice of real biological experience, they are often reasonably good surrogates of nonverbal experience.) Yet both words and episodes are represented by the same defining dimensions, and the relation of each to the other has been retained, if only in the condensed, less detailed form of induced similarity rather than perfect knowledge of history.</p>
<h2>Analogy to Explicit and Implicit Memories</h2>
<p>In a similar way, the word-versus-context difference might be related to difference between implicit and explicit memories. Retrieving a context vector brings a particular past happening to mind, whereas retrieving a word vector instantiates an abstraction of many happenings irreversibly melded. Thus, for example, recognition that a word came from a particular previously presented list might occur by having the word retrieve one or more context vectors-perhaps experienced as conscious recollections-and evaluating their relation to the word. On the other hand, changes in a word's ability to prime other words occur continuously, and the individual identity of the many occasions that caused the changes, either directly or indirectly, are irretrievable. Although such speculations obviously go far beyond supporting evidence at this point, there is no reason to believe that the processes that rekindle context and word vectors could not be different (indeed, different mathematical operations are required in the SVD model), or even differentially supported by different brain structures. We go no further down this path now than to drop this crumb for future explorations to follow.</p>
<h2>Expertise</h2>
<p>The theory and simulation results bear interestingly on expertise. Compare the rate of learning a new word, one never encountered before, for a simulated rank novice and an expert reader. Take the rank novice to correspond to the model meeting its second text sample (so as to avoid $\log 1$ in the descriptive model). Assume the expert to have spent 10 years acquiring domain knowledge. Reading 3 hr per day, at 240 words per minute, the expert is now reading his $2,000,001$ st 70 -word paragraph. Extrapolating the model of Equation 1 predicts that the novice gains .14 in probability correct for the new word, the expert .56. Although these extrapolations should not be taken seriously as estimates for human learners because they go outside the range of the empirical data to which the model is known to conform, they nevertheless illustrate the large effects on the ability to acquire new knowledge that can arise from the inductive power inherent in the possession of large bodies of old knowledge. In this case the learning rate, the amount learned about a particular item per exposure to it, is approximately four times as great for the simulated expert as for the simulated novice.</p>
<p>The LSA account of knowledge growth casts a new light on expertise by suggesting that great masses of knowledge contribute to superior performance not only by direct application of the stored knowledge to problem solving, but also by greater ability to add new knowledge to long-term memory, to infer indirect relations among bits of knowledge and to generalize from instances of experience.</p>
<h2>Contextual Disambiguation</h2>
<p>LSA simulations to date have represented a word as a kind of frequency-weighted average of all its predicted usages. For words that convey only one meaning, this is fine. For words that generate a few closely related meanings, it is a good compromise. This is the case for the vast majority of word types
but, unfortunately, not necessarily for a significant proportion of word tokens, because relatively frequent words like line, fly, and bear often have many senses, as this phenomenon is traditionally described. ${ }^{15}$ For words that are seriously ambiguous when standing alone, such as line, ones that might be involved in two or more very different meanings with nearly equal frequency, this would appear to be a serious flaw. The average LSA vector for balanced homographs like bear can bear little similarity to any of their major meanings. However, we see later that although this raises an issue in need of resolution, it does not prevent LSA from simulating contextual meaning, a potentially important clue in itself.</p>
<p>It seems manifest that skilled readers disambiguate words as they go. The introspective experience resembles that of perceiving an ambiguous figure; only one or another interpretation usually reaches awareness. Lexical priming studies beginning with Ratcliff \&amp; McKoon (1978) and Swinney (1979) as well as eye movement studies (Rayner, Pacht, \&amp; Duffy, 1994), suggest that ambiguous words first activate multiple interpretations, but very soon settle to that sense most appropriate to their discourse contexts. A contextual disambiguation process can be mimicked using LSA in its current form, but the acquisition and representation of multiple separate meanings of a single word cannot.</p>
<p>Consider the sentence, "The player caught the high fly to left field." On the basis of the encyclopedia-based word space, the vector average of the words in this sentence has a cosine of .37 with ball, .31 with baseball, and .27 with hit, all of which are related to the contextual meaning of $f y$, but none of which is in the sentence. In contrast, the sentence vector has cosines of $.17 . .18$, and .13 with insect, airplane, and bird. Clearly, if LSA had appropriate separate entries for $f y$ that included its baseball sense, distance from the sentence average would choose the right one. However, LSA has only a single vector to represent $f y$, and (as trained on the encyclopedia) it is unlike any of the right words. It has cosines of only $.02, .01$, and -.02 respectively with ball, baseball, and hit (compared to .69, .53 and .24 , respectively with insect, airplane, and bird). The sentence representation has correctly caught the drift, but the single averagedvector representation for the word $f y$, which falls close to midway between airplane and insect, is nearly orthogonal to any of the other words. More extensive simulations of LSA-based contextual disambiguation and their correlations with empirical data on text comprehension are described later. Meanwhile, we sketch several ways in which LSA might account for multiple meanings of the same word: first a way in which it might be extended to induce more than one vector for a word, then ways in which a single vector as currently computed might give rise to multiple meanings.</p>
<p>It is well-known that, for a human reader, word senses are almost always reliably disambiguated by local context. Usually one or two words to either side of an ambiguous word are enough to settle the overall meaning of a phrase (Choueka \&amp; Lusignan, 1985). Context-based techniques for lexical disam-</p>
<p><sup id="fnref10:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>biguation have been tried in computational linguistic experiments with reasonably good results (e.g., Grefenstette, 1994; Schütze, 1992a; Schütze \&amp; Pedersen, 1995; Walker \&amp; Amsler, 1986). However, no practical means for automatically extracting and representing all the different senses of all the words in a language from language experience alone has emerged.</p>
<p>How might separate senses be captured by an LSA-like model? Suppose that the input for LSA were a three-way rather than a two-way matrix, with columns of paragraphs, ranks of all the phrases that make up all the paragraphs, and rows of all the word types that make up all the phrases. Partway between paragraphs and words, phrases would seldom, but sometimes, repeat. Cells would contain the number of times that a word type appeared in a particular phrase in a particular paragraph. (A neural network equivalent might have an additional layer of nodes. Note that in either case, the number of such intermediate vectors would be enormous, a presently insurmountable computational barrier.)
The reduced-dimensionality representation would constitute a predictive device that would estimate the likelihood of any word occurring in any phrase context or any paragraph, or any phrase occurring in any paragraph, whether they had occurred there in the first place or not. The idea is that the phrase-level vectors would carry distinctions corresponding approximately to differential word senses. In simulating text comprehension, a dynamic performance model might start with the average of the words in a paragraph and, using some constraint satisfaction method, arrive at a representation of the paragraph as a set of imputed phrase vectors and their average.
A very different, much simpler, possibility is that each word has but a single representation, but because LSA representations have very high dimensionality, the combination of a word with a context can have very different effects on the meaning of different passages. Consider the sentences, "The mitochondria are in the cells," versus "The monks are in the cells," in which abstract semantic dimensions of the context determine the sense of cells as biological or artificial objects. In one case the overall passage-meaning vector has a direction intermediate between that of mitochondria and that of cells, in the other case between monks and cells. If mitochondria and monks are in orthogonal planes in semantic space, the resultant vectors are quite different. Now suppose that the current context-specific meaning of cells-and perhaps its conscious expression-is represented by the projection of its vector onto the vector for the whole passage; that is, only components of meaning that it shares with the context, after averaging, comprise its disambiguated meaning. In this way, two or more distinct senses could arise from a single representation, the number and distinctions among senses depending only on the variety and distinctiveness of different contexts in which the word is found. In this interpretation, the multiple senses described by lexicographers are categorizations imposed on the contextual environments in which a word is found.
Put another way, a 300 -dimensional vector has plenty of room to represent a single orthographic string in more than one way so long as context is sufficient to select the relevant portion of the vector to be expressed. In addition, it might be supposed that the relations among the words in a current topical context would be subjected to a local re-representation process, a sec-
ondary SVD-like condensation, or some other mutual constraint satisfaction process using the global cosines as input that would have more profound meaning-revision effects than simple projection.</p>
<p>Finally, the contextual environment of a word might serve to retrieve related episode representations that would, by the same kinds of processes, cause the resultant meaning, and perhaps the resultant experience, to express the essence of a particular subset of past experiences. Given an isolated word, the system might settle competitively on a retrieved vector for just one or the average of a concentrated cluster of related episodes, thus giving rise to the same phenomenology, perhaps by the same mechanism, as the capture quality of ambiguous visual figures. Thus the word cell might give rise to an image of either a microscopic capsule or a room.</p>
<p>A resolution of which, if any, of these hypothetical mechanisms accounts for multiple word-meaning phenomena is beyond the current state of LSA theory and data; the moral of the discussion is just that LSA's single-vector representation of a word is not necessarily a fatal or permanent flaw. Whereas some of the evidence to follow inclines us to the single-representation view, we consider the issue as distinctly open.</p>
<h2>Text Comprehension: An LSA Interpretation of Construction-Integration Theory</h2>
<p>Some research has been done using LSA to represent the meaning of segments of text larger than words and to simulate behaviors that might otherwise fall prey to the ambiguity problem. In this work, individual word senses are not separately identified or represented, but the overall meaning of phrases, sentences, or paragraphs is constructed from a linear combination of their words. By hypothesis, the various unintended-meaning components of the many different words in a passage tend to be unrelated and point in many directions in meaning hyperspace, whereas their vector average reflects the overall topic or meaning of the passage. We recount two studies illustrating this strategy. Both involve phenomena that have previously been addressed by the construction-integration (CI) model (Kintsch, 1988). In both, the current version of LSA, absent any mechanism for multiple-word-sense representation, is used in place of the intellectually coded propositional analyses of CI.</p>
<p>Predicting coherence and comprehensibility. Foltz, Kintsch, and Landauer, in an unpublished study (1993), reanalyzed data from experiments on text comprehension as a function of discourse coherence. As part of earlier studies (McNamara, Kintsch, Butler-Songer, \&amp; Kintsch, 1996), a single short text about heart function had been reconstructed in four versions that differed greatly in coherence according to the propositional analysis measures developed by Van Dijk and Kintsch (1983). In coherent passages, succeeding sentences used concepts introduced in preceding sentences so that the understanding of each sentence and of the overall text-the building of the text base and situation model in CI terms-could proceed in a gradual, stepwise fashion. In less coherent passages, more new concepts were introduced without precedent in the propositions of preceding sentences. The degree of coherence was assessed by the number of overlapping concepts in propositions of successive sentences. Empirical comprehension tests with college student</p>
<p>readers established that the relative comprehensibility of the four passages was correctly ordered by their propositionally estimated coherence.</p>
<p>In the reanalysis, sentences from a subcorpus of 27 encyclopedia articles related to the heart were first subjected to SVD and a 100 -dimensional solution used to represent the contained words. Then each sentence in the four experimental paragraphs was represented as the average of the vectors of the words it contained. Finally, the coherence of each paragraph was reestimated as the average cosine between its successive sentences. Figure 5 shows the relation of this new measure of coherence to the average empirical comprehension scores for the paragraphs. The LSA coherence measure corresponds well to measured comprehensibility. In contrast, an attempt to predict comprehensibility by correlating surface-structure word types in common between successive sentences (i.e., computing cosines between vectors in the full-dimension transformed matrix), also shown in Figure 5, fails, largely because there is little overlap at the word level. LSA, by capturing the central meaning of the passages appears to reflect the differential relations among sentences that led to comprehension differences.</p>
<p>Simulating contextual word disambiguation and sentential meaning inference. Another reanalysis illustrates this reinterpretation of CI in LSA terms more directly with a different data set. Till, Mross, and Kintsch (1988) performed semantic priming experiments in which readers were presented word by word with short paragraphs and interrupted at strategically placed points to make lexical decisions about words related either to one or another of two senses of a just-presented homographic word or to words not contained in the passages but
<img alt="img-4.jpeg" src="img-4.jpeg" /></p>
<p>Figure 5. Prediction of measured text comprehensibility of a set of experimentally altered text passages taken from McNamara et al. (1996). Predictions were based on the similarity of each sentence to that of the succeeding sentence, putative measures of conceptual coherence. For latent semantic analysis (LSA), sentences were represented by the average of the LSA-derived vectors of the words they contained. The control condition (word level) used the same analysis but without dimension reduction.
related inferentially to the story situation that a reader would presumably assemble in comprehending the discourse up to that point. They also varied the interval between the last text word shown and the target for lexical decision. Here is an example of two matched text paragraphs and the four target words for lexical decisions used in conjunction with them.</p>
<ol>
<li>The gardener pulled the hose around to the holes in the yard. Perhaps the water would solve his problem with the mole.</li>
<li>The patient sensed that this was not a routine visit. The doctor hinted that there was serious reason to remove the mole.</li>
</ol>
<p>Targets for lexical decision: ground, face; drown, cancer
Across materials, Till et al. (1988) balanced the materials by switching words and paragraphs with different meanings and included equal numbers of nonwords. In three experiments of this kind, the principal findings were (a) in agreement with Ratcliff and McKoon (1978) and Swinney (1979), words related to both senses of an ambiguous word were primed immediately after presentation, (b) after about 300 ms only the context appropriate associates remained significantly primed, and (c) words related to inferred situational themes were not primed at short intervals, but were at delays of 1 s .</p>
<p>The standard CI interpretation of these results is that in the first stage of comprehending a passage-construction-multiple nodes representing all senses of each word are activated in long-term memory, and in the next stage-integration-iterative excitation and inhibition among the nodes leads to dominance of appropriate word meanings and finally to creation of a propositional structure representing the situation described by the passage.</p>
<p>LSA as currently developed is, of course, mute on the temporal dynamics of comprehension, but it does provide an objective way to represent, simulate, and assess the degree of semantic similarity between words and between words and longer passages. To illustrate, an LSA version of the CI account for the Till et al. (1988) experiment might go like this:</p>
<ol>
<li>First, a central meaning for each graphemic word type is retrieved: the customary vector for each word. Following this, there are two possibilities, depending on whether one assumes single or multiple representations for words.</li>
<li>Assuming only a single, average representation for each word, the next step is computation of the vector average for all words in the passage. As this happens, words related to the average meanings being generated, including both appropriate relatives of the homograph and overall "inference" words, become activated, while unrelated meanings, including unrelated associates of the homograph, decline.</li>
</ol>
<p>On the other interpretation, an additional stage is inserted between these two in which the average meaning for some or all of the words in the passage disambiguates the separate words individually, choosing a set of senses that are then combined. The stimulus asynchrony data of Till et al. (1988) seems to suggest the latter interpretation in that inappropriate homograph relatives lose priming faster than inference words acquire it, but there are other possible explanations for this result, in particular that the overall passage meaning simply evolves slowly with the most holistic interpretations emerging last. In any event, the current LSA representation can only simulate the meaning relations between the words and passages and is indifferent to which</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>${ }^{15}$ For example, among the most frequent 400 words in the Kucera and Francis (1967) count, at least 60 have two or more common meanings, whereas in a sample of 400 that appeared only once in the corpus there were no more than 10 .&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref3:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref4:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref5:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref6:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref7:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref8:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref9:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref10:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>