<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-9258 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-9258</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-9258</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-162.html">extraction-schema-162</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <p><strong>Paper ID:</strong> paper-249889853</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2206.09426v2.pdf" target="_blank">ADBench: Anomaly Detection Benchmark</a></p>
                <p><strong>Paper Abstract:</strong> Given a long list of anomaly detection algorithms developed in the last few decades, how do they perform with regard to (i) varying levels of supervision, (ii) different types of anomalies, and (iii) noisy and corrupted data? In this work, we answer these key questions by conducting (to our best knowledge) the most comprehensive anomaly detection benchmark with 30 algorithms on 57 benchmark datasets, named ADBench. Our extensive experiments (98,436 in total) identify meaningful insights into the role of supervision and anomaly types, and unlock future directions for researchers in algorithm selection and design. With ADBench, researchers can easily conduct comprehensive and fair evaluations for newly proposed methods on the datasets (including our contributed ones from natural language and computer vision domains) against the existing baselines. To foster accessibility and reproducibility, we fully open-source ADBench and the corresponding results.</p>
                <p><strong>Cost:</strong> 0.026</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e9258.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e9258.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>BERT-embeddings</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>BERT pretrained [CLS] token embedding (used as tabular features)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Pretrained BERT transformer is used to extract the [CLS] token embedding for NLP datasets; those dense vectors are treated as tabular features and passed to the benchmarked anomaly detection methods.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>BERT (pretrained; [CLS] token embeddings)</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>Transformer (bidirectional encoder)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Text → dense vector embeddings → used as tabular numeric features</td>
                        </tr>
                        <tr>
                            <td><strong>data_domain</strong></td>
                            <td>NLP datasets in ADBench (Agnews, Amazon, IMDB, Yelp, 20newsgroups, etc.)</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>Class-based rare/anomalous classes (multi-class downsampled anomalies to ~5%); essentially 'rare class' or class-outlier anomalies in text corpora</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Extract the pretrained BERT [CLS] embedding for each text instance (pretrained on BookCorpus + English Wikipedia as stated), treat the resulting fixed-length vector as tabular input, then run the suite of tabular anomaly detection algorithms (unsupervised, semi-supervised, supervised) on those embeddings.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_methods</strong></td>
                            <td>Full ADBench set of tabular AD methods (examples: LOF, KNN, IForest, OCSVM, ECOD, COPOD, DeepSVDD, DAGMM, XGBOD, DevNet, FTTransformer, XGBoost, CatBoost, RandomForest, etc.)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>AUCROC, AUCPR (reported across ADBench experiments)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>The paper reports AUCROC / AUCPR of the tabular AD algorithms when run on BERT-extracted embeddings (these results are given in the full tables, e.g., Table D4/D5 and label-informed tables). Example numbers (from ADBench tables for embedding-based NLP datasets): LOF AUCROC on Agnews = 71.80 (Table D4); aggregated label-informed methods (FTTransformer, tree ensembles) achieve median AUCROC ~74.7 (FTTransformer) and ~76.5 (ensemble median) at γ_l = 1% overall (main-text aggregate). The paper does not report a single numeric performance figure for 'BERT as a detector' because BERT is used only for feature extraction and the evaluation is reported per downstream AD algorithm.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td>BERT is not compared head-to-head vs other language models as anomaly detectors; it is only one backbone used to produce embeddings. The paper compares downstream tabular AD algorithms' performance on these embeddings. The authors note embeddings often make NLP datasets usable by tabular AD methods and report the AD algorithm comparisons on those embeddings; no direct claim that BERT embeddings are superior to alternate embeddings is made in the main analyses.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>The paper notes limitations: (i) BERT is used only as a frozen feature extractor — no fine-tuning for AD — so it is not evaluated as an end-to-end language-model anomaly detector; (ii) backbone choice (BERT vs other text embeddings) is not exhaustively analyzed — authors state they analyze results based on BERT (and ResNet18) and leave backbone impact to future work; (iii) high embedding dimensionality complicates synthetic anomaly generation and some robustness experiments, so certain synthetic anomaly analyses exclude the CV/NLP embedding datasets; (iv) no experiments on zero-shot or prompting of language models to directly label anomalies are presented.</td>
                        </tr>
                        <tr>
                            <td><strong>unique_insights</strong></td>
                            <td>Using pretrained language-model embeddings (BERT) enables treating originally unstructured NLP datasets as tabular data for benchmarking classical and modern tabular AD methods; this pipeline allows standard tabular AD algorithms (including tree ensembles and transformers for tabular data) to be applied, and the benchmark shows that tree ensembles and FTTransformer can yield competitive detection performance on those embeddings. However, the paper emphasizes that choice of backbone and embedding extractor was not varied in-depth and that embedding-based datasets were not used in all synthetic-anomaly or corruption experiments due to computational/complexity concerns.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'ADBench: Anomaly Detection Benchmark', 'publication_date_yy_mm': '2022-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9258.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e9258.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>RoBERTa-embeddings</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>RoBERTa pretrained embeddings (alternative backbone provided)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>The paper provides versions of the NLP datasets where embeddings are extracted by pretrained RoBERTa; these embeddings are released but the primary analysis focuses on BERT embeddings.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>RoBERTa (pretrained; embedding extractor)</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>Transformer (bidirectional encoder)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Text → dense vector embeddings → used as tabular numeric features</td>
                        </tr>
                        <tr>
                            <td><strong>data_domain</strong></td>
                            <td>NLP datasets in ADBench (same as BERT: Agnews, Amazon, IMDB, Yelp, 20newsgroups, etc.)</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>Rare-class / downsampled multi-class anomalies (5% anomalies by default in these multi-class NLP datasets)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Pretrained RoBERTa is used to extract fixed-length embeddings (provided as an alternate backbone). The embeddings are intended to be consumed by the same tabular AD algorithms used throughout ADBench.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_methods</strong></td>
                            <td>Same downstream ADBench tabular AD algorithms (LOF, KNN, IForest, DeepSVDD, DAGMM, XGBOD, DevNet, FTTransformer, ensemble trees, etc.).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>AUCROC, AUCPR</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>The authors state they release RoBERTa-based embeddings but analyze results primarily using BERT; therefore the paper does not present a focused comparison table isolating RoBERTa-derived results in the main analysis. The RoBERTa versions are provided in the dataset release.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td>Not directly compared in the paper — RoBERTa embeddings are provided but the main experimental analyses and figures are based on BERT (and ResNet18 for CV).</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>RoBERTa embeddings were not a primary analysis backbone; the paper explicitly says it analyzes results based on the datasets generated by BERT and ResNet18, leaving backbone impact (including RoBERTa) for future work. Thus no conclusions about RoBERTa vs BERT for AD are drawn.</td>
                        </tr>
                        <tr>
                            <td><strong>unique_insights</strong></td>
                            <td>The ADBench release includes alternate embedding backbones (RoBERTa) to facilitate downstream comparisons, but the benchmark's conclusions about algorithm performance are based on the BERT-extracted features; researchers are encouraged to evaluate backbone effects separately.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'ADBench: Anomaly Detection Benchmark', 'publication_date_yy_mm': '2022-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9258.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e9258.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Other text embeddings (fastText/Glove)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>fastText / GloVe style embeddings (mentioned as alternative prior work)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>The paper mentions prior works that used fastText and GloVe (and other embedding methods) to create features for anomaly detection on text, but in ADBench the authors primarily used BERT for NLP embedding extraction.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>fastText / GloVe (word embedding methods mentioned as alternatives)</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>Embedding lookup / shallow embedding (non-contextual / bag-of-words style embeddings)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Text → word / sentence embeddings → tabular vectors</td>
                        </tr>
                        <tr>
                            <td><strong>data_domain</strong></td>
                            <td>NLP datasets (mentioned in context of past AD work such as DATE and other NLP-AD studies)</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>Rare-class / class-outlier anomalies in text</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Referenced as prior approaches where word/sentence embeddings (fastText, GloVe) were used to produce features for downstream anomaly detection models; ADBench chose BERT for richer contextual embeddings.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_methods</strong></td>
                            <td>Referenced prior AD methods in NLP (e.g., DATE uses fastText/GloVe in other works), but ADBench's downstream baselines remain the tabular AD algorithms in the benchmark.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>AUCROC, AUCPR (general AD evaluation metrics referenced in the benchmark)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>No performance numbers for fastText/GloVe in this paper's experiments — they are cited as alternative embedding approaches used in prior works.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td>Paper does not compare fastText/GloVe embeddings vs BERT within ADBench; it notes previous studies used such embeddings but ADBench uses BERT for the main analyses.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Mention only — no empirical evaluation in this paper; thus no failure cases reported here for fastText/GloVe within ADBench.</td>
                        </tr>
                        <tr>
                            <td><strong>unique_insights</strong></td>
                            <td>The paper highlights that transferring pretrained semantic features (contextual embeddings like BERT) is effective for adapting non-tabular CV/NLP datasets into the tabular AD benchmarking pipeline, and notes prior works that used fastText/GloVe as simpler embedding alternatives.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'ADBench: Anomaly Detection Benchmark', 'publication_date_yy_mm': '2022-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>DATE: Detecting anomalies in text via self-supervision of transformers <em>(Rating: 2)</em></li>
                <li>Deep Semi-supervised Anomaly Detection <em>(Rating: 2)</em></li>
                <li>Do we really need to learn representations from in-domain data for outlier detection? <em>(Rating: 1)</em></li>
                <li>Adapting pretrained features for anomaly detection and segmentation (Panda) <em>(Rating: 2)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-9258",
    "paper_id": "paper-249889853",
    "extraction_schema_id": "extraction-schema-162",
    "extracted_data": [
        {
            "name_short": "BERT-embeddings",
            "name_full": "BERT pretrained [CLS] token embedding (used as tabular features)",
            "brief_description": "Pretrained BERT transformer is used to extract the [CLS] token embedding for NLP datasets; those dense vectors are treated as tabular features and passed to the benchmarked anomaly detection methods.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "BERT (pretrained; [CLS] token embeddings)",
            "model_type": "Transformer (bidirectional encoder)",
            "model_size": null,
            "data_type": "Text → dense vector embeddings → used as tabular numeric features",
            "data_domain": "NLP datasets in ADBench (Agnews, Amazon, IMDB, Yelp, 20newsgroups, etc.)",
            "anomaly_type": "Class-based rare/anomalous classes (multi-class downsampled anomalies to ~5%); essentially 'rare class' or class-outlier anomalies in text corpora",
            "method_description": "Extract the pretrained BERT [CLS] embedding for each text instance (pretrained on BookCorpus + English Wikipedia as stated), treat the resulting fixed-length vector as tabular input, then run the suite of tabular anomaly detection algorithms (unsupervised, semi-supervised, supervised) on those embeddings.",
            "baseline_methods": "Full ADBench set of tabular AD methods (examples: LOF, KNN, IForest, OCSVM, ECOD, COPOD, DeepSVDD, DAGMM, XGBOD, DevNet, FTTransformer, XGBoost, CatBoost, RandomForest, etc.)",
            "performance_metrics": "AUCROC, AUCPR (reported across ADBench experiments)",
            "performance_results": "The paper reports AUCROC / AUCPR of the tabular AD algorithms when run on BERT-extracted embeddings (these results are given in the full tables, e.g., Table D4/D5 and label-informed tables). Example numbers (from ADBench tables for embedding-based NLP datasets): LOF AUCROC on Agnews = 71.80 (Table D4); aggregated label-informed methods (FTTransformer, tree ensembles) achieve median AUCROC ~74.7 (FTTransformer) and ~76.5 (ensemble median) at γ_l = 1% overall (main-text aggregate). The paper does not report a single numeric performance figure for 'BERT as a detector' because BERT is used only for feature extraction and the evaluation is reported per downstream AD algorithm.",
            "comparison_to_baseline": "BERT is not compared head-to-head vs other language models as anomaly detectors; it is only one backbone used to produce embeddings. The paper compares downstream tabular AD algorithms' performance on these embeddings. The authors note embeddings often make NLP datasets usable by tabular AD methods and report the AD algorithm comparisons on those embeddings; no direct claim that BERT embeddings are superior to alternate embeddings is made in the main analyses.",
            "limitations_or_failure_cases": "The paper notes limitations: (i) BERT is used only as a frozen feature extractor — no fine-tuning for AD — so it is not evaluated as an end-to-end language-model anomaly detector; (ii) backbone choice (BERT vs other text embeddings) is not exhaustively analyzed — authors state they analyze results based on BERT (and ResNet18) and leave backbone impact to future work; (iii) high embedding dimensionality complicates synthetic anomaly generation and some robustness experiments, so certain synthetic anomaly analyses exclude the CV/NLP embedding datasets; (iv) no experiments on zero-shot or prompting of language models to directly label anomalies are presented.",
            "unique_insights": "Using pretrained language-model embeddings (BERT) enables treating originally unstructured NLP datasets as tabular data for benchmarking classical and modern tabular AD methods; this pipeline allows standard tabular AD algorithms (including tree ensembles and transformers for tabular data) to be applied, and the benchmark shows that tree ensembles and FTTransformer can yield competitive detection performance on those embeddings. However, the paper emphasizes that choice of backbone and embedding extractor was not varied in-depth and that embedding-based datasets were not used in all synthetic-anomaly or corruption experiments due to computational/complexity concerns.",
            "uuid": "e9258.0",
            "source_info": {
                "paper_title": "ADBench: Anomaly Detection Benchmark",
                "publication_date_yy_mm": "2022-06"
            }
        },
        {
            "name_short": "RoBERTa-embeddings",
            "name_full": "RoBERTa pretrained embeddings (alternative backbone provided)",
            "brief_description": "The paper provides versions of the NLP datasets where embeddings are extracted by pretrained RoBERTa; these embeddings are released but the primary analysis focuses on BERT embeddings.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "RoBERTa (pretrained; embedding extractor)",
            "model_type": "Transformer (bidirectional encoder)",
            "model_size": null,
            "data_type": "Text → dense vector embeddings → used as tabular numeric features",
            "data_domain": "NLP datasets in ADBench (same as BERT: Agnews, Amazon, IMDB, Yelp, 20newsgroups, etc.)",
            "anomaly_type": "Rare-class / downsampled multi-class anomalies (5% anomalies by default in these multi-class NLP datasets)",
            "method_description": "Pretrained RoBERTa is used to extract fixed-length embeddings (provided as an alternate backbone). The embeddings are intended to be consumed by the same tabular AD algorithms used throughout ADBench.",
            "baseline_methods": "Same downstream ADBench tabular AD algorithms (LOF, KNN, IForest, DeepSVDD, DAGMM, XGBOD, DevNet, FTTransformer, ensemble trees, etc.).",
            "performance_metrics": "AUCROC, AUCPR",
            "performance_results": "The authors state they release RoBERTa-based embeddings but analyze results primarily using BERT; therefore the paper does not present a focused comparison table isolating RoBERTa-derived results in the main analysis. The RoBERTa versions are provided in the dataset release.",
            "comparison_to_baseline": "Not directly compared in the paper — RoBERTa embeddings are provided but the main experimental analyses and figures are based on BERT (and ResNet18 for CV).",
            "limitations_or_failure_cases": "RoBERTa embeddings were not a primary analysis backbone; the paper explicitly says it analyzes results based on the datasets generated by BERT and ResNet18, leaving backbone impact (including RoBERTa) for future work. Thus no conclusions about RoBERTa vs BERT for AD are drawn.",
            "unique_insights": "The ADBench release includes alternate embedding backbones (RoBERTa) to facilitate downstream comparisons, but the benchmark's conclusions about algorithm performance are based on the BERT-extracted features; researchers are encouraged to evaluate backbone effects separately.",
            "uuid": "e9258.1",
            "source_info": {
                "paper_title": "ADBench: Anomaly Detection Benchmark",
                "publication_date_yy_mm": "2022-06"
            }
        },
        {
            "name_short": "Other text embeddings (fastText/Glove)",
            "name_full": "fastText / GloVe style embeddings (mentioned as alternative prior work)",
            "brief_description": "The paper mentions prior works that used fastText and GloVe (and other embedding methods) to create features for anomaly detection on text, but in ADBench the authors primarily used BERT for NLP embedding extraction.",
            "citation_title": "",
            "mention_or_use": "mention",
            "model_name": "fastText / GloVe (word embedding methods mentioned as alternatives)",
            "model_type": "Embedding lookup / shallow embedding (non-contextual / bag-of-words style embeddings)",
            "model_size": null,
            "data_type": "Text → word / sentence embeddings → tabular vectors",
            "data_domain": "NLP datasets (mentioned in context of past AD work such as DATE and other NLP-AD studies)",
            "anomaly_type": "Rare-class / class-outlier anomalies in text",
            "method_description": "Referenced as prior approaches where word/sentence embeddings (fastText, GloVe) were used to produce features for downstream anomaly detection models; ADBench chose BERT for richer contextual embeddings.",
            "baseline_methods": "Referenced prior AD methods in NLP (e.g., DATE uses fastText/GloVe in other works), but ADBench's downstream baselines remain the tabular AD algorithms in the benchmark.",
            "performance_metrics": "AUCROC, AUCPR (general AD evaluation metrics referenced in the benchmark)",
            "performance_results": "No performance numbers for fastText/GloVe in this paper's experiments — they are cited as alternative embedding approaches used in prior works.",
            "comparison_to_baseline": "Paper does not compare fastText/GloVe embeddings vs BERT within ADBench; it notes previous studies used such embeddings but ADBench uses BERT for the main analyses.",
            "limitations_or_failure_cases": "Mention only — no empirical evaluation in this paper; thus no failure cases reported here for fastText/GloVe within ADBench.",
            "unique_insights": "The paper highlights that transferring pretrained semantic features (contextual embeddings like BERT) is effective for adapting non-tabular CV/NLP datasets into the tabular AD benchmarking pipeline, and notes prior works that used fastText/GloVe as simpler embedding alternatives.",
            "uuid": "e9258.2",
            "source_info": {
                "paper_title": "ADBench: Anomaly Detection Benchmark",
                "publication_date_yy_mm": "2022-06"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "DATE: Detecting anomalies in text via self-supervision of transformers",
            "rating": 2,
            "sanitized_title": "date_detecting_anomalies_in_text_via_selfsupervision_of_transformers"
        },
        {
            "paper_title": "Deep Semi-supervised Anomaly Detection",
            "rating": 2,
            "sanitized_title": "deep_semisupervised_anomaly_detection"
        },
        {
            "paper_title": "Do we really need to learn representations from in-domain data for outlier detection?",
            "rating": 1,
            "sanitized_title": "do_we_really_need_to_learn_representations_from_indomain_data_for_outlier_detection"
        },
        {
            "paper_title": "Adapting pretrained features for anomaly detection and segmentation (Panda)",
            "rating": 2,
            "sanitized_title": "adapting_pretrained_features_for_anomaly_detection_and_segmentation_panda"
        }
    ],
    "cost": 0.026396,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>ADBench: Anomaly Detection Benchmark</p>
<p>Songqiao Han 
Shanghai University of Finance and Economics</p>
<p>Xiyang Hu 
Carnegie Mellon University</p>
<p>Hailiang Huang hlhuang@shufe.edu.cn 
Shanghai University of Finance and Economics</p>
<p>Minqi Jiang 
Shanghai University of Finance and Economics</p>
<p>Yue Zhao zhaoy@cmu.edu 
Carnegie Mellon University</p>
<p>ADBench: Anomaly Detection Benchmark</p>
<p>Given a long list of anomaly detection algorithms developed in the last few decades, how do they perform with regard to (i) varying levels of supervision, (ii) different types of anomalies, and (iii) noisy and corrupted data? In this work, we answer these key questions by conducting (to our best knowledge) the most comprehensive anomaly detection benchmark with 30 algorithms on 57 benchmark datasets, named ADBench. Our extensive experiments (98,436 in total) identify meaningful insights into the role of supervision and anomaly types, and unlock future directions for researchers in algorithm selection and design. With ADBench, researchers can efficiently conduct comprehensive and fair evaluations for newly proposed methods on the datasets (including our contributed ones from natural language and computer vision domains) against the existing baselines. To foster accessibility and reproducibility, we fully open-source ADBench and the corresponding results.</p>
<p>Introduction</p>
<p>Anomaly detection (AD), which is also known as outlier detection, is a key machine learning (ML) task with numerous applications, including anti-money laundering [94], rare disease detection [196], social media analysis [186,193], and intrusion detection [88]. AD algorithms aim to identify data instances that deviate significantly from the majority of data objects [59,139,146,160], and numerous methods have been developed in the last few decades [3,85,102,103,129,156,172,198]. Among them, the majority are designed for tabular data (i.e., no time dependency and graph structure). Thus, we focus on the tabular AD algorithms and datasets in this work.</p>
<p>Although there are already some benchmark and evaluation works for tabular AD [25,38,42,53,166], they generally have the limitations as follows: (i) primary emphasis on unsupervised methods only without including emerging (semi-)supervised AD methods; (ii) limited analysis of the algorithm performance concerning anomaly types (e.g., local vs. global); (iii) the lack of analysis on model robustness (e.g., noisy labels and irrelevant features); (iv) the absence of using statistical tests for algorithm comparison; and (v) no coverage of more complex CV and NLP datasets, which have attracted extensive attention nowadays.</p>
<p>To address these limitations, we design (to our best knowledge) the most comprehensive tabular anomaly detection benchmark called ADBench. By analyzing both research needs and deployment requirements in the industry, we design the experiments with three major angles in anomaly detection (see §3.3): (i) the availability of supervision (e.g., ground truth labels) by including 14 unsupervised, 7 semi-supervised, and 9 supervised methods; (ii) algorithm performance under different types of anomalies by simulating the environments with four types of anomalies; and (iii) algorithm robustness and stability under three settings of data corruptions. Fig. 1 provides an overview of ADBench. selection; (ii) with merely 1% labeled anomalies, most semi-supervised methods can outperform the best unsupervised method, justifying the importance of supervision; (iii) in controlled environments, we observe that the best unsupervised methods for specific types of anomalies are even better than semi-and fully-supervised methods, revealing the necessity of understanding data characteristics; (iv) semi-supervised methods show potential in achieving robustness in noisy and corrupted data, possibly due to their efficiency in using labels and feature selection. See §4 for additional results and insights.</p>
<p>We summarize the primary contributions of ADBench as below:</p>
<ol>
<li>The most comprehensive AD benchmark. ADBench examines 30 detection algorithms' performance on 57 benchmark datasets (of which 47 are existing ones and we create 10). 2. Research and application-driven benchmark angles. By analyzing the needs of research and real-world applications, we focus on three critical comparison angles: availability of supervision, anomaly types, and algorithm robustness under noise and data corruption. 3. Insights and future directions for researchers and practitioners. With extensive results, we</li>
</ol>
<p>show the necessity of algorithm selection, and the value of supervision and prior knowledge. 4. Fair and accessible AD evaluation. We open-source ADBench with BSD-2 License at https: //github.com/Minqi824/ADBench, for benchmarking newly proposed methods.</p>
<p>2 Related Work 2.1 Anomaly Detection Algorithms Unsupervised Methods by Assuming Anomaly Data Distributions. Unsupervised AD methods are proposed with different assumptions of data distribution [3], e.g., anomalies located in low-density regions, and their performance depends on the agreement between the input data and the algorithm assumption(s). Many unsupervised methods have been proposed in the last few decades [3,15,129,150,198], which can be roughly categorized into shallow and deep (neural network) methods. The former often carries better interpretability, while the latter handles large, high-dimensional data better. Please see Appx. §A.1, recent book [3], and surveys [129,150] for additional information.</p>
<p>Supervised Methods by Treating Anomaly Detection as Binary Classification. With the accessibility of full ground truth labels (which is rare), supervised classifiers may identify known anomalies at the risk of missing unknown anomalies. Arguably, there are no specialized supervised anomaly detection algorithms, and people often use existing classifiers for this purpose [3,170] such as Random Forest [21] and neural networks [89]. One known risk of supervised methods is that ground truth labels are not necessarily sufficient to capture all types of anomalies during annotation. These methods are therefore limited to detecting unknown types of anomalies [3]. Recent machine learning books [4,54] and scikit-learn [133] may serve as good sources of supervised ML methods.</p>
<p>Semi-supervised Methods with Efficient Use of Labels. Semi-supervised AD algorithms can capitalize the supervision from partial labels, while keeping the ability to detect unseen types of anomalies. To this end, some recent studies investigate using partially labeled data for improving detection performance and leveraging unlabeled data to facilitate representation learning. For instance, some semi-supervised models are trained only on normal samples, and detect anomalies that deviate from the normal representations learned in the training process [7,8,188]. In ADBench, semi-supervision mostly refers to incomplete label learning in weak-supervision (see [204]). More discussions on semi-supervised AD are deferred to Appx. §A.3.</p>
<p>Existing Datasets and Benchmarks for Tabular AD</p>
<p>AD Datasets in Literature. Existing benchmarks mainly evaluate a part of the datasets derived from the ODDS Library [145], DAMI Repository [25], ADRepository [129], and Anomaly Detection Meta-Analysis Benchmarks [42]. In ADBench, we include almost all publicly available datasets, and add larger datasets adapted from CV and NLP domains, for a more holistic view. See details in §3.2.</p>
<p>Existing Benchmarks. There are some notable works that take effort to benchmark AD methods on tabular data, e.g., [25,38,42,150,166] (see Appx. A.4). How does ADBench differ from them?</p>
<p>First, previous studies mainly focus on benchmarking the shallow unsupervised AD methods. Considering the rapid advancement of ensemble learning and deep learning methods, we argue that a comprehensive benchmark should also consider them. Second, most existing works only evaluate public benchmark datasets and/or some fully synthetic datasets; we organically incorporate both of them to unlock deeper insights. More importantly, existing benchmarks primarily focus on direct performance comparisons, while the settings may not be sufficiently complex to understand AD algorithm characteristics. We strive to address the above issues in ADBench, and illustrate the main differences between the proposed ADBench and existing AD benchmarks in Table 1.</p>
<p>Also, "anomaly detection" is an overloaded term; there are AD benchmarks for time-series [85,87,132], graph [101], CV [6,27,201] and NLP [143], but they are different from tabular AD in nature.</p>
<p>Connections with Related Fields and Other Opportunities</p>
<p>While ADBench focuses on the AD tasks, we note that there are some closely related problems, including out-of-distribution (OOD) detection [182,183], novelty detection [116,137], and open-set recognition (OSR) [51,112]. Uniquely, AD usually does not assume the train set is anomaly-free, while other related tasks may do. Some methods designed for these related fields, e.g., OCSVM [157], can be used for AD as well; future benchmark can consider including: (i) OOD methods: MSP [65], energy-based EBO [104], and Mahalanobis distance-based MDS [92]; (ii) novelty detection methods: OCGAN [135] and Adversarial One-Class Classifier [154]; and (iii) OSR methods: OpenGAN [79] and PROSER [202]. See [155] for deeper connections and differences between AD and these fields.</p>
<p>We consider saliency detection (SD) [44,46] and camouflage detection (CD) [45] as good inspirations and applications of AD tasks. Saliency detection identifies important regions in the images, where explainable AD algorithms [123], e.g., FCDD [106], may help the task. Camouflage detection finds concealed objects in the background, e.g., camouflaged anomalies blurred with normal objects [110], where camouflage-resistant AD methods [40] help detect concealed objects (that look normal but are abnormal). Future work can explore the explainability of detected objects in AD. Newly-added Datasets in ADBench. Since most of these datasets are relatively small, we introduce 10 more complex datasets from CV and NLP domains with more samples and richer features in ADBench (highlighted in Appx. Table B1). Pretrained models are applied to extract data embedding from CV and NLP datasets to access more complex representations, which has been widely used in AD literature [33,115,152] and shown better results than using the raw features. For NLP datasets, we use BERT [75] pretrained on the BookCorpus and English Wikipedia to extract the embedding of the [CLS] token. For CV datasets, we use ResNet18 [62] pretrained on the ImageNet [35] to extract the embedding after the last average pooling layer. Following previous works [151,152], we set one of the multi-classes as normal, downsample the remaining classes to 5% of the total instances as anomalies, and report the average results over all the respective classes. Including these originally non-tabular datasets helps to see whether tabular AD methods can work on CV/NLP data after necessary preprocessing. See Appx. B.2 for more details on datasets.  Table 1, existing benchmarks only focus on the unsupervised setting, i.e., none of the labeled anomalies is available. Despite, in addition to unlabeled samples, one may have access to a limited number of labeled anomalies in real-world applications, e.g., a few anomalies identified by domain experts or human-in-the-loop techniques like active learning [5,7,78,189]. 1RUPDO $QRPDO\ (a) Local Notably, there is a group of semi-supervised AD algorithms [127,128,130,131,152,168,203] that have not been covered by existing benchmarks.</p>
<p>Benchmark Angles in</p>
<p>Our design: We first benchmark existing unsupervised anomaly detection methods, and then evaluate both semi-supervised and fully-supervised methods with varying levels of supervision following the settings in [127,131,203] to provide a fair comparison. For example, labeled anomalies γ l = 10% means that 10% anomalies in the train set are known while other samples remain unlabeled. The complete experiment results of un-, semi-, and full-supervised algorithms are presented in §4.2.</p>
<p>Angle II: Types of Anomalies</p>
<p>Motivation. While extensive public datasets can be used for benchmarking, they often consist of a mixture of different types of anomalies, making it challenging to understand the pros and cons of AD algorithms regarding specific types of anomalies [55,166]. In real-world applications, one may know specific types of anomalies of interest. To better understand the impact of anomaly types, we create synthetic datasets based on public datasets by injecting specific types of anomalies to analyze the response of AD algorithms.</p>
<p>Our design: In ADBench, we create realistic synthetic datasets from benchmark datasets by injecting specific types of anomalies. Some existing works, such as PyOD [198], generate fully synthetic anomalies by assuming their data distribution, which fails to create complex anomalies. We follow and enrich the approach in [166] to generate "realistic" synthetic data; ours supports more types of anomaly generation. The core idea is to build a generative model (e.g., Gaussian mixture model GMM used in [166], Sparx [191], and ADBench) using the normal samples from a benchmark dataset and discard its original anomalies as we do not know their types. Then, We could generate normal samples and different types of anomalies based on their definitions by tweaking the generative model. The generation of normal samples is the same in all settings if not noted, and we provide the generation process of four types of anomalies below (also see our codebase for details).</p>
<p>Definition and Generation Process of Four Types of Common Anomalies Used in ADBench:</p>
<p>• Local anomalies refer to the anomalies that are deviant from their local neighborhoods [22]. We follow the GMM procedure [118,166] to generate synthetic normal samples, and then scale the covariance matrixΣ = αΣ by a scaling parameter α = 5 to generate local anomalies. • Global anomalies are more different from the normal data [68], generated from a uniform distribution Unif α · min X k , α · max X k , where the boundaries are defined as the min and max of an input feature, e.g., k-th feature X k , and α = 1.1 controls the outlyingness of anomalies. • Dependency anomalies refer to the samples that do not follow the dependency structure which normal data follow [117], i.e., the input features of dependency anomalies are assumed to be independent of each other. Vine Copula [1] method is applied to model the dependency structure of original data, where the probability density function of generated anomalies is set to complete independence by removing the modeled dependency (see [117] We scale the mean feature vector of normal samples by α = 5, i.e.,μ = αμ, where α controls the distance between anomaly clusters and the normal, and use the scaled GMM to generate anomalies. Fig. 3 shows 2-d t-SNE [169] visualization of the four types of synthetic outliers generated from Lymphography dataset, where they generally satisfy the expected characteristics. Local anomalies (Fig. 3a) are well overlapped with the normal samples. Global anomalies (Fig. 3b) are more deviated from the normal samples and on the edges of normal clusters. The other two types of anomalies are as expected, with no clear dependency structure in Fig. 3c and having anomaly cluster(s) in Fig. 3d. In ADBench, we analyze the algorithm performances under all four types of anomalies above ( §4.3).</p>
<p>Angle III: Model Robustness with Noisy and Corrupted Data</p>
<p>Motivation. Model robustness has been an important aspect of anomaly detection and adversarial machine learning [24,41,47,76,177]. Meanwhile, the input data likely suffers from noise and corruption to some extent in real-world applications [42,55,60,124]. However, this important view has not been well studied in existing benchmarks, and we try to understand this by evaluating AD algorithms under three noisy and corruption settings (see results in §4.4):</p>
<p>• Duplicated Anomalies. In many applications, certain anomalies likely repeat multiple times in the data for reasons such as recording errors [83]. The presence of duplicated anomalies is also called the "anomaly masking" [55, 60, 100], posing challenges to many AD algorithms [25], e.g., the density-based KNN [11,144]. Besides, the change of anomaly frequency would also affect the behavior of detection methods [42]. Therefore, we simulate this setting by splitting the data into train and test set, then duplicating the anomalies (both features and labels) up to 6 times in both sets, and observing how AD algorithms change. • Irrelevant Features. Tabular data may contain irrelevant features caused by measurement noise or inconsistent measuring units [28,55], where these noisy dimensions could hide the characteristics of anomaly data and thus make the detection process more difficult [128,150]. We add irrelevant features up to 50% of the total input features (i.e., d in the problem definition) by generating uniform noise features from Unif min X k , max X k of randomly selected k-th input feature X k while the labels stay correct, and summarize the algorithm performance changes. • Annotation Errors. While existing studies [131,152] explored anomaly contamination in the unlabeled samples, we further discuss the more generalized impact of label contamination on the algorithm performance, where the label flips [122,200] between the normal samples and anomalies are considered (up to 50% of total labels). Note this setting does not affect unsupervised methods as they do not use any labels. Discussion of annotation errors is meaningful since manual annotation or some automatic labeling techniques are always noisy while being treated as perfect.</p>
<p>Experiment Results and Analyses</p>
<p>We </p>
<p>Experiment Setting</p>
<p>Datasets, Train/test Data Split, and Independent Trials. As described in §3.2 and Appx. Table B1, ADBench includes 57 existing and freshly proposed datasets, which cover different fields including healthcare, security, and more. Although unsupervised AD algorithms are primarily designed for the transductive setting (i.e., outputting the anomaly scores on the input data only other than making predictions on the newcoming data), we adapt all the algorithms for the inductive setting to predict the newcoming data, which is helpful in applications and also common in popular AD library PyOD [198], TODS [84], and PyGOD [102]. Thus, we use 70% data for training and the remaining 30% as the test set. We use stratified sampling to keep the anomaly ratio consistent. We repeat each experiment 3 times and report the average. Detailed settings are described in Appx. C.</p>
<p>Hyperparameter Settings. For all the algorithms in ADBench, we use their default hyperparameter (HP) settings in the original paper for a fair comparison. Refer to the Appx. C for more information. (c) Boxplot of AUCROC (@1% labeled anomalies) on 57 datasets; we denote un-, semi-, and fully supervised methods in light yellow, green, and purple.  shows that semi-supervised methods leverage the labels more efficiently than fully-supervised methods with a small labeled anomaly ratio γ l . (c) and (d) present the boxplots of AUCROC and runtime. Ensemble methods are marked with " † ".
3 &amp; $ 2 &amp; 6 9 0 / 2 ) &amp; % / 2 ) &amp; 2 ) + % 2 6 . 1 1 6 2 ' &amp; 2 3 2 ' ( &amp; 2 ' ' H H S 6 9 ' ' ' $ * 0 0 / 2 ' $ ,) R UH V W * $ 1 R P D O\ ' H H S 6 $ ' 5 ( 3 ( 1 ' H Y 1 H W 3 5 H 1 H W ) ( $ : $ ' ; * % 2 ' 1 % 6 9 0 0 / 3 5 H V 1 H W ) 7 7 5 ) / * % ; * % &amp; D W%
None of the unsupervised methods is statistically better than the others, as shown in the critical difference diagram of Fig. 4a (where most algorithms are horizontally connected without statistical significance). We also note that some DL-based unsupervised methods like DeepSVDD and DAGMM are surprisingly worse than shallow methods. Without the guidance of label information, DL-based unsupervised algorithms are harder to train (due to more hyperparameters) and more difficult to tune hyperparameters, leading to unsatisfactory performance.</p>
<p>Semi-supervised methods outperform supervised methods when limited label information is available. For γ l ≤ 5%, i.e., only less than 5% labeled anomalies are available during training, the detection performance of semi-supervised methods (median AUCROC= 75.56% for γ l = 1% and AUCROC= 80.95% for γ l = 5%) are generally better than that of fully-supervised algorithms (median AUCROC= 60.84% for γ l = 1% and AUCROC= 72.69% for γ l = 5%). For most semisupervised methods, merely 1% labeled anomalies are sufficient to surpass the best unsupervised method (shown as the dashed line in Fig. 4b), while most supervised methods need 10% labeled anomalies to achieve so. We also show the improvement of algorithm performances about the increasing γ l , and notice that with a large number of labeled anomalies, both semi-supervised and supervised methods have comparable performance. Putting these together, we verify the assumed advantage of semi-supervised methods in leveraging limited label information more efficiently.</p>
<p>Latest network architectures like Transformer and emerging ensemble methods yield competitive performance in AD. Fig. 4b shows FTTransformer and ensemble methods like XGB(oost) and CatB(oost) provide satisfying detection performance among all the label-informed algorithms, even these methods are not specifically proposed for the anomaly detection tasks. For γ l = 1%, the AUCROC of FTTransformer and the median AUCROC of ensemble methods are 74.68% and 76.47%, respectively, outperforming the median AUCROC of all label-informed methods 72.91%. The great performance of tree-based ensembles (in tabular AD) is consistent with the findings in literature [20,58,170], which may be credited to their capacity to handle imbalanced AD datasets via aggregation. Future research may focus on understanding the cause and other merits of ensemble trees in tabular AD, e.g., better model efficiency.
'HHS69'' '$<em>00 /2'$ +%26 62' &amp;232' (&amp;2' 3&amp;$ 2&amp;690 ,)RUHVW &amp;2) &amp;%/2) .11 /2) $YJ5DQN (a) Local anomalies 'HHS69'' '$</em>00 /2'$ &amp;2) (&amp;2' /2) &amp;232' 2&amp;690 62' 3&amp;$ +%26 ,)RUHVW &amp;%/2) .11 $YJ5DQN (b) Global anomalies (&amp;2' +%26 &amp;232' 'HHS69'' 2&amp;690 '$<em>00 3&amp;$ /2'$ ,)RUHVW &amp;%/2) 62' &amp;2) /2) .11 $YJ5DQN (c) Dependency anomalies 'HHS69'' /2) &amp;2) 62' .11 '$</em>00 (&amp;2' /2'$ &amp;%/2) ,)RUHVW &amp;232' +%26 3&amp;$ 2&amp;690 $YJ5DQN
(d) Clustered anomalies Performance of unsupervised algorithms highly depends on the alignment of its assumptions and the underlying anomaly type. As expected, local anomaly factor (LOF) is statistically better than other unsupervised methods for the local anomalies (Fig. 5a), and KNN, which uses k-th (global) nearest neighbor's distance as anomaly scores, is the statistically best detector for global anomalies (Fig. 5b). Again, there is no algorithm performing well on all types of anomalies; LOF achieves the best AUCROC on local anomalies (Fig. 5a) and the second best AUCROC rank on dependency anomalies (Fig. 5c), but performs poorly on clustered anomalies (Fig. 5d). Practitioners should select algorithms based on the characteristics of the underlying task, and consider the algorithm which may cover more high-interest anomaly types [93].</p>
<p>The "power" of prior knowledge on anomaly types may overweigh the usage of partial labels.</p>
<p>For the local, global, and dependency anomalies, most label-informed methods perform worse than the best unsupervised methods of each type (corresponding to LOF, KNN, and KNN). For example, the detection performance of XGBOD for the local anomalies is inferior to the best unsupervised method LOF when γ l ≤ 50%, while other methods perform worse than LOF in all cases (See Fig. 6a). Why could not label-informed algorithms beat unsupervised methods in this setting? We believe that partially labeled anomalies cannot well capture all characteristics of specific types of anomalies, and learning such decision boundaries is challenging. For instance, different local anomalies often exhibit various behaviors, as shown in Fig. 3a, which may be easier to identify by a generic definition of "locality" in unsupervised methods other than specific labels. Thus, incomplete label information may bias the learning process of these label-informed methods, which explains their relatively inferior performances compared to the best unsupervised methods. This conclusion is further verified by the results of clustered anomalies (See Fig. 6d), where label-informed (especially semi-supervised) methods outperform the best unsupervised method OCSVM, as few labeled anomalies can already represent similar behaviors in the clustered anomalies (Fig. 3d). (d) Clustered anomalies Figure 6: Semi-(left of each subfigure) and supervised (right) algorithms' performance on different types of anomalies with varying levels of labeled anomalies. Surprisingly, these label-informed algorithms are inferior to the best unsupervised method except for the clustered anomalies.</p>
<p>Future</p>
<p>ideal world, one may combine multiple AD algorithms based on the composition of anomaly types, via frameworks like dynamic model selection and combination [197]. To our knowledge, the latest advancement in this end [71] provides an equivalence criterion for measuring to what degree two anomaly detection algorithms detect the same kind of anomalies. Furthermore, future research may also consider designing semi-supervised AD methods capable of detecting different types of unknown anomalies while effectively improving performance by the partially available labeled data. Another interesting direction is to train an offline AD model using synthetically generated anomalies and then adapt it for online prediction on real-world datasets with likely similar anomaly types. Unsupervised domain adaption and transfer learning for AD [33,185] may serve as useful references.</p>
<p>Algorithm Robustness under Noisy and Corrupted Data</p>
<p>In this section, we investigate the algorithm robustness (i.e., ∆performance; see absolute performance plot in Appx. D9) of different AD algorithms under noisy and data corruption described in §3.3.3. The default γ l is set to 100% since we only care about the relative change of model performance. Fig. 7   Unsupervised methods are more susceptible to duplicated anomalies. As shown in Fig. 7a, almost all unsupervised methods are severely impacted by duplicated anomalies. Their AUCROC deteriorates proportionally with the increase in duplication. When anomalies are duplicated by 6 times, the median ∆AUCROC of unsupervised methods is −16.43%, compared to that of semisupervised methods −0.05% (Fig. 7b) and supervised methods 0.13% (Fig. 7c). One explanation is that unsupervised methods often assume the underlying data is imbalanced with only a smaller percentage of anomalies-they rely on this assumption to detect anomalies. With more duplicated anomalies, the underlying data becomes more balanced, and the minority assumption of anomalies is violated, causing the degradation of unsupervised methods. Differently, more balanced datasets do not affect the performance of semi-and fully-supervised methods remarkably, with the help of labels.</p>
<p>Irrelevant features cause little impact on supervised methods due to feature selection. Compared to the unsupervised and most semi-supervised methods, the training process of supervised methods is fully guided by the data labels (y), therefore performing robustly to the irrelevant features (i.e., corrupted X) due to the direct (or indirect) feature selection process. For instance, ensemble trees like XGBoost can filter irrelevant features. As shown in Fig. 7f, even the worst performing supervised algorithm (say ResNet) in this setting yields ≤ 5% degradation when 50% of the input features are corrupted by the uniform noises, while the un-and semi-supervised methods could face up to 10% degradation. Besides, the robust performances of supervised methods (and some semi-supervised methods like DevNet) indicate that the label information can be beneficial for feature selection. Also, Fig. 7f shows that minor irrelevant features (e.g., 1%) help supervised methods as regularization to generalize better.</p>
<p>Both semi-and fully-supervised methods show great resilience to minor annotation errors.</p>
<p>Although the detection performance of these methods is significantly downgraded when the annotation errors are severe (as shown in Fig. 7g and 7h), their degradation with regard to minor annotation errors is acceptable. The median ∆AUCROC of semi-and fully-supervised methods for 5% annotation errors is −1.52% and −1.91%, respectively. That being said, label-informed methods are still acceptable in practice as the annotation error should be relatively small [95,181]. Future Direction 4: Noise-resilient AD Algorithms. Our results indicate there is an improvement space for robust unsupervised AD algorithms. One immediate remedy is to incorporate unsupervised feature selection [30,125,126] to combat irrelevant features. Moreover, label information could serve as effective guidance for model training against data noise, and it helps semi-and fullysupervised methods to be more robust. Given the difficulty of acquiring full labels, we suggest using semi-supervised methods as the backbone for designing more robust AD algorithms.</p>
<p>Conclusions and Future Work</p>
<p>In this paper, we introduce ADBench, the most comprehensive tabular anomaly detection benchmark with 30 algorithms and 57 benchmark datasets. Based on the analyses on multiple comparison angles, we unlock insights into the role of supervision, the importance of prior knowledge of anomaly types, and the principles of designing robust detection algorithms. On top of them, we summarize a few promising future research directions for anomaly detection, along with the fully released benchmark suite for evaluating new algorithms.</p>
<p>ADBench can extend to understand the algorithm performance with (i) mixed types of anomalies; (ii) different levels of (intrinsic) anomaly ratio; and (iii) more data modalities. Also, future benchmarks can consider the latest algorithms [28,99,161], and curate datasets from emerging fields like drug discovery [69], molecule optimization [49, 50], interpretability and explainability [123,180], and bias and fairness [32,67,123,159,165,190]. </p>
<p>Supplementary Material for ADBench: Anomaly Detection Benchmark</p>
<p>Additional information on related works, algorithms, datasets, and additional experiment settings and results</p>
<p>A Related Works with More Details</p>
<p>We provide more details on existing AD algorithms and benchmarks, and the primary content discussed in §2.</p>
<p>A.1 Unsupervised Methods</p>
<p>Unsupervised Methods by Assuming Anomaly Data Distributions. Unsupervised AD methods are proposed with different assumptions of data distribution [3], e.g., anomalies located in lowdensity regions, and their performance often depends on the agreement between the input data and the algorithm assumption(s). Many unsupervised methods have been proposed in the last few decades [3,15,129,150,198], which can be roughly categorized into shallow and deep (neural network) methods. The former often carry better interpretability, while the latter handles large, high-dimensional data better. Recent book [3] and surveys [129,150] provide great details on these algorithms, while we further elaborate on a few representative unsupervised methods. More algorithm details and hyperparameter settings are illustrated in Appx. §B.1</p>
<p>Representative Shallow Methods. Some representative shallow methods include: (i) Isolation Forest (IForest) [100] builds an ensemble of trees to isolate the data points and defines the anomaly score as the distance of an individual instance to the root; (ii) One-class SVM (OCSVM) [157] maximizes the margin between origin and the normal samples, where the decision boundary is the hyper-plane that determines the margin; and (iii) Empirical-Cumulative-distribution-based Outlier Detection (ECOD) [97] computes the empirical cumulative distribution per dimension of the input data, and then aggregates the tail probabilities per dimension for calculating the anomaly score.</p>
<p>Representative Deep Methods. Deep (neural network) methods have gained more attention recently, and we briefly review some representative ones in this section. Deep Autoencoding Gaussian Mixture Model (DAGMM) [205] jointly optimizes the deep autoencoder and the Gaussian mixture model in an end-to-end neural network fashion. The joint optimization balances autoencoding reconstruction, density estimation of latent representation, and regularization and helps the autoencoder escape from less attractive local optima and further reduce reconstruction errors, avoiding pre-training. Deep Support Vector Data Description (DeepSVDD) [151] trains a neural network to learn a transformation that minimizes the volume of a data-enclosing hypersphere in the output space, and calculates the anomaly score as the distance of transformed embedding to the center of the hypersphere.</p>
<p>A.2 Supervised Methods</p>
<p>Due to the difficulty and cost of collecting large-scale labeled data, fully-supervised anomaly detection is often impractical as it assumes the availability of labeled training data with both normal and anomaly samples [129]. Although some loss functions (e.g., focal loss [98]) are devised to address the class imbalance problem, they are often not specific for AD tasks. There also exist a few works [57, 73] discussing the relationship between fully-supervised and semi-supervised AD methods, and argue that semi-supervised AD needs to be ground on the unsupervised learning paradigm instead of the supervised one for detecting both known and unknown anomalies. We implement several representative supervised classification algorithms in ADBench (as shown in Appx. §B.1), and recommend interesting readers to recent machine learning books [4,54] and scikit-learn [133] for more details about recent supervised methods designed for the classification tasks.</p>
<p>A.3 Semi-supervised Methods</p>
<p>Semi-supervised AD algorithms are designed to capitalize the supervision from partial labels, while keeping the ability to detect unseen types of anomalies. To this end, some recent studies investigate efficiently using partially labeled data for improving detection performance, and leverage the unlabeled data to facilitate representation learning. We further provide some technical details on representative semi-supervised AD methods here. Please see Appx. §B.1 for more algorithm details and hyperparameter settings in ADBench.</p>
<p>Representative Methods. Extreme Gradient Boosting Outlier Detection (XGBOD) [195] uses multiple unsupervised AD algorithms to extract useful representations from the underlying data that augment the predictive capabilities of an embedded supervised classifier on an improved feature space. Deep Semi-supervised Anomaly Detection (DeepSAD) [152] is an end-to-end methodology considered the state-of-the-art method in semi-supervised anomaly detection. DeepSAD improves the DeepSVDD [151] model by the inverse loss function for the labeled anomalies. REPresentations for a random nEarest Neighbor distance-based method (REPEN) [127] proposes a ranking model-based framework, which unifies representation learning and anomaly detection to learn low-dimensional representations tailored for random distance-based detectors. Deviation Networks (DevNet) [131] constructs an end-to-end neural network for learning anomaly scores, which forces the network to produce statistically higher anomaly scores for identified anomalies than that of unlabeled data. Pairwise Relation prediction-based ordinal regression Network (PReNet) [130] formulates the anomaly detection problem as a pairwise relation prediction task, which defines a two-stream ordinal regression neural network to learn the relation of randomly sampled instance pairs. Feature Encoding with AutoEncoders for Weakly-supervised Anomaly Detection (FEAWAD) [203] leverages an autoencoder to encode the input data and utilize hidden representation, reconstruction residual vector and reconstruction error as the new representations for improving the DevNet [131] and DAGMM [205].</p>
<p>A.4 Existing AD Benchmarks</p>
<p>As we show in Table 1, there is a line of existing AD benchmarks. [150] discusses a unifying review of both the shallow and deep anomaly detection methods, but they mainly focus on the theoretical perspective and thus lack results from the experimental views. [25] benchmarks 19 different unsupervised methods on 10 datasets, and analyzes the characteristics of density-based and clustering-based algorithms. [38] tests 14 unsupervised anomaly detection methods on 15 public datasets, and analyzes the scalability, memory consumption, and robustness of different methods. [166] proposes a generic process for the generation of realistic synthetic data. The synthetic normal instances are reconstructed from existing real-world benchmark data, while synthetic anomalies are in line with a characterizable deviation from the modeling of synthetic normal data.</p>
<p>[42] evaluates 8 unsupervised methods on 19 public datasets, and produces a large corpus of synthetic anomaly detection datasets that vary in their construction across several dimensions that are important to real-world applications. [25] compares 12 unsupervised anomaly detection approaches on 23 datasets, providing a characterization of benchmark datasets and their suitability as anomaly detection benchmark sets.</p>
<p>All these existing works lay the foundation of AD algorithm design, and we further improve the foundation by considering more datasets, algorithms, and comparison aspects.</p>
<p>B More Details on ADBench</p>
<p>B.1 ADBench Algorithm List</p>
<p>We organize all the algorithms in ADBench into the following three categories and report their hyperparameter settings which mainly refer to the settings of their original papers or repositories (e.g., PyOD 1 and scikit-learn 2 ).</p>
<p>(i) 14 unsupervised algorithms:</p>
<ol>
<li>Principal Component Analysis (PCA) [162]. PCA is a linear dimensionality reduction using singular value decomposition of the data to project it to a lower dimensional space. When used for AD, it projects the data to the lower dimensional space and then uses the reconstruction errors as the anomaly scores. If not specified, the default hyperparameters in PyOD are used for the PCA (and the other unsupervised algorithms deployed by PyOD).</li>
</ol>
<p>2.</p>
<p>One-class SVM (OCSVM) [157]. OCSVM maximizes the margin between the origin and the normal samples, and defines the decision boundary as the hyperplane that determines the margin. 3. Local Outlier Factor (LOF) [22]. LOF measures the local deviation of the density of a given sample with respect to its neighbors. 4. Clustering Based Local Outlier Factor (CBLOF) [64]. CBLOF calculates the anomaly score by first assigning samples to clusters, and then using the distance among clusters as anomaly scores. 5. Connectivity-Based Outlier Factor (COF) [167]. COF uses the ratio of the average chaining distance of data points and the average chaining distance of k-th nearest neighbor of the data point, as the anomaly score for observations. 6. Histogram-based outlier detection (HBOS) [52]. HBOS assumes feature independence and calculates the degree of outlyingness by building histograms. 7. K-Nearest Neighbors (KNN) [144]. KNN views the anomaly score of the input instance as the distance to its k-th nearest neighbor.  [136]. LODA is an ensemble method and is particularly useful in domains where a large number of samples need to be processed in real-time or in domains where the data stream is subject to concept drift and the detector needs to be updated online. 14. Isolation Forest (IForest) [100]. IForest isolates observations by randomly selecting a feature and then randomly selecting a split value between the maximum and minimum values of the selected feature.</p>
<p>(ii) 7 semi-supervised algorithms:</p>
<ol>
<li>Semi-Supervised Anomaly Detection via Adversarial Training (GANomaly) [7]. A GANbased method that defines the reconstruction error of the input instance as the anomaly score. We replace the convolutional layer in the original GANomaly with the dense layer with tanh activation function for evaluating it on the tabular data, where the hidden size of the encoder-decoder-encoder structure of GANomaly is set to half of the input dimension. We train the GANomaly for 50 epochs with 64 batch size, where the SGD [149] optimizer with 0.01 learning rate and 0.7 momentum is applied for both the generator and the discriminator. 2. Deep Semi-supervised Anomaly Detection (DeepSAD) [152]. A deep one-class method that improves the unsupervised DeepSVDD [151] by penalizing the inverse of the distances of anomaly representation such that anomalies must be mapped further away from the hypersphere center. The hyperparameter η in the loss function is set to 1.0, where DeepSAD is trained for 50 epochs with 128 batch size. Adam optimizer with 0.001 learning rate and 10 −6 weight decay is applied for updating the network parameters. DeepSAD additionally employs an autoencoder for calculating the initial center of the hypersphere, where the autoencoder is trained for 100 epochs with 128 batch size, and optimized by Adam optimizer with learning rate 0.001 and 10 −6 weight decay. 3. REPresentations for a random nEarest Neighbor distance-based method (REPEN) [127].</li>
</ol>
<p>A neural network-based model that leverages transformed low-dimensional representation for random distance-based detectors. The hidden size of REPEN is set to 20, and the margin of triplet loss is set to 1000. REPEN is trained for 30 epochs with 256 batch size, where the total number of steps (batches of samples) is set to 50. Adadelta [187] optimizer with 0.001 learning rate and 0.95 ρ is applied to update network parameters. 4. Deviation Networks (DevNet) [131]. A neural network-based model uses a prior probability to enforce a statistical deviation score of input instances. The margin hyperparameter a in the deviation loss is set to 5. DevNet is trained for 50 epochs with 512 batch size, where the total number of steps is set to 20. RMSprop [149] optimizer with 0.001 learning rate and 0.95 ρ is applied to update network parameters. 5. Pairwise Relation prediction-based ordinal regression Network (PReNet) [130] [195]. XGBOD first uses the passedin unsupervised outlier detectors to extract richer representations of the data and then concatenates the newly generated features to the original feature for constructing the augmented feature space. An XGBoost classifier is then applied to this augmented feature space. We use the default hyperparameters in PyOD.</p>
<p>(iii) 9 supervised algorithms:</p>
<ol>
<li>Naive Bayes (NB) [14]. NB methods are based on applying Bayes' theorem with the "naive" assumption of conditional independence between every pair of features given the value of the class variable. We use the Gaussian NB in ADBench. 2. Support Vector Machine (SVM) [31]. SVM is effective in high-dimensional spaces and could still be effective in cases where the number of dimensions is greater than the number of samples. We use the default hyperparameters in scikit-learn for SVM (and for the following MLP and RF). 3. Multi-layer Perceptron (MLP) [148]. MLP uses the binary cross entropy loss to update network parameters. 4. Random Forest (RF) [21]. RF is a meta estimator that fits several decision tree classifiers on various sub-samples of the dataset and uses averaging to improve the predictive accuracy and control over-fitting. 5. eXtreme Gradient Boosting (XGBoost) [29]. XGBoost is an optimized distributed gradient boosting method designed to be highly efficient, flexible, and portable. We use the default hyperparameter settings in the XGBoost official repository 1 </li>
</ol>
<p>B.2 ADBench Dataset List</p>
<p>Overview. As described in §3.2, ADBench is the largest AD benchmark with 57 datasets. More specifically, Table B1 shows the datasets used in ADBench, covering many application domains, including healthcare (e.g., disease diagnosis), audio and language processing (e.g., speech recognition), image processing (e.g., object identification), finance (e.g., financial fraud detection), and more, where we show this information in the last column. We resample the sample size to 1,000 for those datasets smaller than 1,000, and use the subsets of 10,000 for those datasets greater than 10,000 due to the computational cost. Fig. B1 provides the anomaly ratio distribution of the datasets, where the median is equal to 5%. We release all the datasets and their raw version(s) when possible at https://github.com/Minqi824/ADBench/tree/main/datasets.</p>
<p>Newly-added Datasets in ADBench. Since most of the public datasets are relatively small and simple, we introduce 10 more complex datasets from CV and NLP domains with more samples and richer features in ADBench (highlighted in Table B1 in blue).</p>
<p>Reasoning of Using CV/NLP Datasets. It is often challenging to directly run large CV and NLP datasets on selected shallow methods, e.g., OCSVM [157] and kNN [144] with high time complexity, we follow DeepSAD [152], ADIB [33], and DATE [115] to extract representations of CV and NLP datasets by neural networks for downstream detection tasks. More specifically, ADIB [33] shows that "transferring features from semantic tasks can provide powerful and generic representations for various AD problems", which is true even when the pre-trained task is only loosely related to downstream AD tasks. Similarly, DeepSAD [152] uses pre-trained autoencoder to extract features for training classical AD detectors like OCSVM [157] and IForest [100]. For NLP datasets, DATE [115] uses fastText [72] and Glove [134] embeddings for evaluating classical AD methods (e.g., OCSVM [157] and IForest [100]) against proposed methods in NLP datasets.</p>
<p>We want to elaborate further on the reasons for adapting CV and NLP datasets for tabular AD. First, some shallow models, such as OCSVM [157], cannot directly run on (large, high-dimensional) CV datasets. Second, it is interesting to see whether tabular AD methods can work on CV/NLP data representations, which carry values in real-world applications where deep models are infeasible to run. Moreover, the extracted representations often lead to better downstream detection results [33]. Thus, we extract features from CV and NLP datasets by deep models to create "tabular" versions of them. Although not perfect, this may provide insights into shallow methods' performance on (originally infeasible) CV and NLP datasets.</p>
<p>CV Datasets: For MNIST-C, we set original MNIST images to be normal and corrupted images in MNIST-C to be abnormal, like in the recent work [91]. For MVTec-10, we test different AD algorithms on the 15 image sets, where anomalies correspond to various manufacturing defects. For CIFAR10, FashionMNIST, and SVHN, we follow previous works [151,152] and set one of the multi-classes as normal and downsample the remaining classes to 5% of the total instances as anomalies by default, and report the average results over all the respective classes.</p>
<p>NLP Datasets: For Amazon and Imdb, we regard the original negative class as the anomaly class. For Yelp, we regard the reviews of 0 and 1 stars as the anomaly class, and the reviews of 3 and 4 stars as the normal class. For 20newsgroups dataset, like in DATE [115] and CVDD [153], we only take the articles from the six top-level classes: computer, recreation, science, miscellaneous, politics, religion.</p>
<p>Similarly, for the multi-classes datasets 20newsgroups and Agnews, we set one of the classes as normal and downsample the remaining classes to 5% of the total instances as anomalies.</p>
<p>Backbone Choices of Feature Extraction. Pretrained models are applied to extract data embedding from CV and NLP datasets to access these more complex representations. For CV datasets, following [16] and [147], we use ResNet18 1 [62] pretrained on the ImageNet [35] to extract meaningful embedding after the last average pooling layer. We also provide the embedding version that are extracted by the ImageNet-pretrained ViT 2 [39]. For NLP datasets, instead of using traditional embedding methods like fastText [19,72]  in our codebase 1 . Although we release all the generated datasets for completeness, we analyze the results based on the datasets generated by BERT and ResNet18. Future work may consider analyzing the impact of backbones on detection performance. $QRPDO\UDWLRQXPDQRPDOLHVWRWDOVDPSOHV RIRFFXUUHQFHV PHGLDQ Figure B1: Distribution of anomaly ratios in 57 datasets in ADBench, where 40 datasets' anomaly ratio is below 10% (median=5%).   In addition to Fig. 3 that demonstrates the synthetic anomalies on Lymphography dataset in §3.3.2, we provide another example here for Ionosphere data. </p>
<p>B.4 Open-source Release</p>
<p>As mentioned before, the full experiment code, datasets, and examples of benchmarking new algorithms are available at https://github.com/Minqi824/ADBench. We specify the key environment setting of using ADBench, e.g., scikit-learn==0.20.3, pyod==0.9.8, etc. With our interactive example in Jupyter notebooks, one may compare a newly proposed AD algorithm easily.</p>
<p>C Details on Experiment Setting</p>
<p>We provide additional details on experiment setting to §4.1 in this section.</p>
<p>General Experimental Settings. Although unsupervised AD algorithms are primarily designed for the transductive setting (i.e., outputting the anomaly scores on the input data only other than making predictions on newcoming data), we adapt all the algorithms for the inductive setting to predict the newcoming data, which is helpful in applications and also common in popular AD library PyOD [198], TODS [84, 85], and PyGOD [102]. Thus, we use 70% data for training and the remaining 30% as a testing set. We use stratified sampling to keep the anomaly ratio consistent. We repeat each experiment 3 times and report the average. The 10 complex CV and NLP datasets are mainly considered for evaluating algorithm performance on the public datasets and are not included in the experiments of different types of anomalies and algorithm robustness, since such high-dimensional data could make it hard to generate synthetic anomalies (e.g., the Vine Copula is computationally expensive for fitting such high-dimensional data), or introduce too much noise in input data (e.g., the noise ratio of irrelevant features 50% would lead to 384 noise features in the 768 input dimensions of NLP data). Future works may resort to the help of the latest generative methods like diffusion models [184].</p>
<p>Hyperparameter Settings. For all the algorithms in ADBench, we use their default hyperparameter (HP) settings in the original paper for a fair comparison. Specific values can be found in Appx.B.1 and our codebase 1 . It is also acknowledged that it is possible to use a small hold-out data for hyperparameter tuning for semi-and fully-supervised methods [164], while we do not consider this setting in this work. In addition to the AUCROC results presented in §4.2, we also show the AUCPR results of model performance on 57 benchmark datasets in Fig. D3, where the corresponding conclusions are similar to that of AUCROC results. There is still no statistically superior solution for unsupervised methods regarding AUCPR. Semi-supervised methods perform better than supervised methods when only limited label data is available, say the labeled anomalies γ l is less than 5%. Besides, we show that the semi-supervised GANomaly, which learns an intermediate representation of the normal data, performs worse than those anomaly-informed models leveraging labeled anomalies (see Fig. D3(b)). This conclusion verifies that merely capturing the normal behaviors is not enough for detecting the underlying anomalies, where the lack of knowledge about the true anomalies would lead to high false positives/negatives [128,130,131].   (g) AUCROC, γ l = 100% Figure D4: Boxplot of AUCROC. We denote unsupervised methods in (light yellow), semisupervised methods in (light green), and supervised methods in (light purple). Consistent with the CD diagrams, we notice that none of the unsupervised methods visually outperform. (g) AUCPR, γ l = 100% Figure D5: Boxplot of AUCPR. We denote unsupervised methods in (light yellow), semi-supervised methods in (light green), and supervised methods in (light purple). Consistent with the CD diagrams, we notice that none of the unsupervised methods visually outperform.   Figure D6: Inference time of included algorithms. We denote unsupervised methods in (light yellow), semi-supervised methods in (light green), and supervised methods in (light purple). Consistent with the train time in Fig. 4d, PCA, HBOS, GANomaly and NB take the least inference time on test datasets, while more complex feature representation methods like SOD and XGBOD spend more time due to the search of the feature subspace.</p>
<p>D.2 Additional Results for Different Types of Anomalies §4.3</p>
<p>We additionally show the AUCPR results for model performance on different types of anomalies in Fig. D7 and Fig. D8, which are consistent with the conclusions drawn in §4.3, i.e., the unsupervised methods are significantly better if their model assumptions conform to the underlying anomaly types. Moreover, the prior knowledge of anomaly types can be more important than that of label information, where those label-informed algorithms generally underperform the best unsupervised methods for local, global, and dependency anomalies.</p>
<p>We want to note that XGBOD can be regarded as an exception to the above observations, which is comparable to or even outperforms the best unsupervised model when more labeled anomalies are available. Recall that XGBOD employs the stacking ensemble method [174], where heterogeneous unsupervised methods are integrated with the supervised model XGBoost, therefore XGBOD is more adaptable to different data assumptions while effectively leveraging the label information. This validates the conclusion that such ensemble learning techniques should be considered in future research directions.   (h)). X-axis denotes either the duplicated times or the noise ratio. Y-axis denotes the AUCROC performance and its range remains consistent across different algorithms. The results reveal unsupervised methods' susceptibility to duplicated anomalies and the usage of label information in defending irrelevant features. Un-, semi-, and fully-supervised methods are denoted as unsup, semi, and sup, respectively. The results are mostly consistent with the observations in Fig. 7 ( §4.4) showing the relative performance change.</p>
<p>In Fig. D9, we provide the performance of the AD algorithms under noisy and corrupted data. Along with the relative performance changes shown in Fig. 7, the analysis in 4.4 still stands.</p>
<p>In addition to the primary results shown in §4.4, we provide the AUCPR results for algorithm robustness in Fig. D10 and D11. The AUCPR results confirm the robustness of supervised methods for irrelevant features. Besides, both semi-and fully-supervised methods are robust to minor annotation errors, say the annotation errors are less than 10%.</p>
<p>One thing to note is we observe AUCPR performance improves under the setting of duplicated anomalies (see Fig. D10 (a)-(c)). This is expected as AUCPR emphasizes the positive classes (i.e., anomalies), and more duplicated anomalies favor this metric. Since this observation is consistently true for both unsupervised and label-informed methods, it would not largely impact our selection of algorithms. However, if we care about both anomaly and normal classes equally, the results on AUCROC in §4.4 still stand -unsupervised methods are more susceptible to duplicate anomalies.    Figure D11: Algorithm performance under noisy and corrupted data (i.e., duplicated anomalies for (a)-(c), irrelevant features for (d)-(f), and annotation errors for (g) and (h)). X-axis denotes either the duplicated times or the noise ratio. Y-axis denotes the AUCPR performance and its range remains consistent across different algorithms. The results reveal unsupervised methods' susceptibility to duplicated anomalies and the usage of label information in defending irrelevant features. Un-, semi-, and fully-supervised methods are denoted as unsup, semi, and sup, respectively.</p>
<p>D.4 Full Performance Tables on Benchmark Datasets (in addition to §4.2 and Appendix D.1)</p>
<p>In the following tables, we first present the AUCROC and AUCPR for all unsupervised methods, and then show the label-informed methods' performance at different levels of labeled anomaly ratio (i.e., γ l = {1%, ..., 100%}). We would expect these results are useful in constructing unsupervised anomaly detection model selection methods like MetaOD [199], where the historical algorithm performance table serves as a great source for building strong meta-learning methods.   (2) 14.17 (5) 6.38 (13) 10.53 (7) 3.78 (14) 12.74 (6) Table D11: AUCPR of 16 label-informed algorithms on 57 benchmark datasets, with labeled anomaly ratio γ l = 10%. We show the performance rank in parenthesis (lower the better), and mark the best performing method(s) in bold.  Table D12: AUCROC of 16 label-informed algorithms on 57 benchmark datasets, with labeled anomaly ratio γ l = 25%. We show the performance rank in parenthesis (lower the better), and mark the best performing method(s) in bold.    </p>
<p>Figure 1 :
1The design of the proposed ADBench is driven by research and application needs.</p>
<p>ADBench 3.3.1 Angle I: Availability of Ground Truth Labels (Supervision) Motivation. As shown in</p>
<p>Figure 3: Illustration of four types of synthetic anomalies shown on Lymphography dataset. See the additional demo in Appx. Fig. B2.</p>
<p>conduct 98,436 experiments (Appx. C) to answer Q1 ( §4.2): How do AD algorithms perform with varying levels of supervision? Q2 ( §4.3): How do AD algorithms respond to different types of anomalies? Q3 ( §4.4): How robust are AD algorithms with noisy and corrupted data? In each subsection, we first present the key results and analyses (please refer to the additional points in Appx. D), and then propose a few open questions and future research directions.</p>
<p>Boxplot of train time (see inf. time in Appx. Fig. D6) on 57 datasets; we denote un-, semi-, and fully supervised methods in light yellow, green, and purple.</p>
<p>Figure 4 :
4Average AD model performance across 57 benchmark datasets. (a) shows that no unsupervised algorithm statistically outperforms the rest. (b)</p>
<p>Figure 5 :
5Avg. rank (lower the better) of unsupervised methods on different types of anomalies. Groups of algorithms not significantly different are connected horizontally in the CD diagrams. The unsupervised methods perform well when their assumptions conform to the underlying anomaly type.</p>
<p>Figure 7 :
7Algorithm performance change under noisy and corrupted data (i.e., duplicated anomalies for (a)-(c), irrelevant features for (d)-(f), and annotation errors for (g) and (h)). X-axis denotes either the duplicated times or the noise ratio. Y-axis denotes the % of performance change (∆AUCROC), and its range remains consistent across different algorithms. The results reveal unsupervised methods' susceptibility to duplicated anomalies and the usage of label information in defending irrelevant features. Un-, semi-, and fully-supervised methods are denoted as unsup, semi, and sup, respectively.</p>
<p>8 .
8Subspace Outlier Detection (SOD)[80]. SOD aims to detect outliers in varying subspaces of high-dimensional feature space.9. Copula Based Outlier Detector (COPOD)[96]. COPOD is a hyperparameter-free, highly interpretable outlier detection algorithm based on empirical copula models. 10. Empirical-Cumulative-distribution-based Outlier Detection (ECOD)[97]. ECOD is a hyperparameter-free, highly interpretable outlier detection algorithm based on empirical CDF functions. Basically, it uses ECDF to estimate the density of each feature independently, and assumes that outliers locate the tails of the distribution. 11. Deep Support Vector Data Description (DeepSVDD)[151]. DeepSVDD trains a neural network while minimizing the volume of a hypersphere that encloses the network representations of the data, forcing the network to extract the common factors of variation.12. Deep Autoencoding Gaussian Mixture Model (DAGMM) [205]. DAGMM utilizes a deep autoencoder to generate a low-dimensional representation and reconstruction error for each input data point, which is further fed into a Gaussian Mixture Model (GMM). We train the DAGMM for 200 epochs with 256 batch size, where the patience of early stopping is set to 50. The learning rate of Adam [77] optimizer is 0.0001 and is decayed once the number of epochs reaches 50. The latent dimension of DAGMM is set to 1 and the number of Gaussian mixture components is set to 4. The λ 1 and λ 2 for energy and covariance in the objective function are set to 0.1 and 0.005, respectively. 13. Lightweight on-line detector of anomalies (LODA)</p>
<p>Figure B2 :
B2Illustration of four types of synthetic anomalies shown on Ionosphere dataset.</p>
<p>Fig.
D4 and D5 show the boxplots of AUCROC and AUCPR of 30 algorithms on the 57 benchmark datasets. These results validate the no-free-lunch theorem, where no model is both the best and the most stable performer. For example, DeepSVDD and RF are the most stable detectors among unand fully-supervised methods, respectively, but they are inferior to most of the other algorithms. Besides, IForest and CatB(oost) can be regarded as two very competitive methods among un-and fully-supervised methods, respectively, but their variances of model performance are relatively large compared to the other methods.Additionally, we also present the full results in tables in §D.4. Avg. rank (lower the better) and avg. AUCPR (on each line) of unsupervised methods; groups of algorithms not statistically different are connected horizontally. Avg. AUCPR (on 57 datasets) vs. % of labeled anomalies (xaxis); semi-supervised (left) and fully-supervised (right). Most labelinformed algorithms outperform the best unsupervised algorithm CBLOF (denoted as the dashed line) with 10% labeled anomalies.</p>
<p>Figure D3 :
D3AD model's AUCPR on 57 benchmark datasets. Generally, the AUCPR results are consistent with the AUCROC results in §4.2. (a) shows that no unsupervised algorithm can statistically outperform. (b) shows the AUCPR of semi-and supervised methods under varying ratios of labeled anomalies γ l . The semi-supervised methods leverage the labels more efficiently w/ small γ l .</p>
<p>Figure D9 :
D9Algorithm performance under noisy and corrupted data (i.e., duplicated anomalies for (a)-(c), irrelevant features for (d)-(f), and annotation errors for (g) and</p>
<p>Figure D10 :
D10Algorithm performance change under noisy and corrupted data (i.e., duplicated anomalies for (a)-(c), irrelevant features for (d)-(f), and annotation errors for (g) and (h)). y-axis denotes the % of performance change (∆AUCPR) and its range remains consistent across different algorithms. The results reveal the usage of label information in defending irrelevant features, and the robustness of label-informed methods to the minor annotation errors. Un-, semi-, and fully-supervised methods are denoted as unsup, semi, and sup, respectively. The results are mostly consistent with the observations inFig. 7 ( §4.4)showing the AUCROC.</p>
<p>Table 1 :
1Comparison among ADBench and existing benchmarks, where ADBench comprehensively includes the most datasets and algorithms, uses both benchmark and synthetic datasets, covers both shallow and deep learning (DL) algorithms, and considers multiple comparison angles.Benchmark 
Coverage ( §3.2) 
Data Source 
Algorithm Type 
Comparison Angle ( §3.3) </p>
<h1>datasets # algo. Real-world Synthetic Shallow</h1>
<p>DL 
Supervision Types Robustness </p>
<p>Ruff et al. [150] 
3 
9 </p>
<p>Goldstein et al. [53] 
10 
19 </p>
<p>Domingues et al. [38] 
15 
14 </p>
<p>Soenen et al. [164] 
16 
6 </p>
<p>Steinbuss et al. [166] 
19 
4 </p>
<p>Emmott et al. [42] 
19 
8 </p>
<p>Campos et al. [25] 
23 
12 </p>
<p>ADBench (ours) 
57 
30 </p>
<p>). We use Kernel Density Estimation (KDE) [61] to estimate the probability density function of features and generate normal samples. • Clustered anomalies, also known as group anomalies [93], exhibit similar characteristics [42, 99].</p>
<p>Overall Model Performance on Datasets with Varying Degrees of Supervision As introduced in §3.3.1, we first present the results of unsupervised methods on 57 datasets inFig. 4a, and then compare label-informed semi-and fully-supervised methods under varying degrees of supervision, i.e., different label ratios of γ l (from 1% to 100% full labeled anomalies) inFig. 4b.Evaluation Metrics and Statistical Tests. We evaluate different AD methods by two widely used 
metrics: AUCROC (Area Under Receiver Operating Characteristic Curve) and AUCPR (Area Under 
Precision-Recall Curve) value 1 . Besides, the critical difference diagram (CD diagram) [34, 70] based 
on the Wilcoxon-Holm method is used for comparing groups of AD methods statistically (p ≤ 0.05). </p>
<p>4.2 'HHS69'' 
'$*00 
/2'$ 
&amp;2) 
2&amp;690 
/2) 
+%26 
62' 
&amp;232' 
3&amp;$ 
(&amp;2' 
.11 
,)RUHVW 
&amp;%/2) </p>
<p>$YJ5DQN </p>
<p>(a) Avg. rank (lower the better) and avg. 
AUCROC (on each line) of unsupervised 
methods; groups of algorithms not statisti-
cally different are connected horizontally. </p>
<p>/DEHOHG$QRPDOLHV </p>
<p>$8&amp;52&amp; </p>
<p>*$1RPDO\ 
'HHS6$' 
5(3(1 
'HY1HW </p>
<p>35H1HW 
)($:$' 
;*%2' 
%HVW8QVXS </p>
<p>/DEHOHG$QRPDOLHV </p>
<p>$8&amp;52&amp; </p>
<p>1% 
690 
0/3 
5HV1HW 
)77UDQVIRUPHU </p>
<p>5) 
/<em>% 
;</em>% 
&amp;DW% 
%HVW8QVXS </p>
<p>(b) Avg. AUCROC (on 57 datasets) vs. % of labeled anomalies (x-
axis); semi-supervised (left) and fully-supervised (right). Most label-
informed algorithms outperform the best unsupervised algorithm 
CBLOF (denoted as the dashed line) with 10% labeled anomalies. </p>
<p>3 
&amp; 
$ </p>
<p>2 
&amp; 
6 
9 
0 </p>
<p>/ 
2 
) </p>
<p>&amp; 
% 
/ 
2 
) </p>
<p>&amp; 
2 
) + </p>
<p>% 
2 
6 . </p>
<p>1 
1 6 
2 
' </p>
<p>&amp; 
2 
3 
2 
' </p>
<p>( 
&amp; 
2 
' ' </p>
<p>H 
H 
S 
6 
9 
' 
' </p>
<p>' 
$ 
* 
0 
0 </p>
<p>/ 
2 
' 
$ </p>
<p>,) 
R 
UH 
V 
W * </p>
<p>$ 
1 
R 
P 
D 
O\ </p>
<p>' H H S 6 </p>
<p>$ 
' 5 ( 3 ( 1 
' H Y 1 H W 3 5 H 1 H W ) ( $ : $ ' ; * % 2 ' 1 % 
6 9 0 0 / 3 
5 H V 1 H W 
) 7 7 
5 ) 
/ * % ; * % &amp; D W% </p>
<p>$8&amp;52&amp; </p>
<p>demonstrates the results.$8&amp;52&amp; </p>
<p>3&amp;$ 
2&amp;690 
/2) 
&amp;%/2) 
&amp;2) </p>
<p>+%26 
.11 
62' 
&amp;232' 
(&amp;2' </p>
<p>'HHS69'' 
'$*00 
/2'$ 
,)RUHVW </p>
<p>(a) Duplicated Anomalies, unsup </p>
<p>$8&amp;52&amp; </p>
<p>*$1RPDO\ 
'HHS6$' 
5(3(1 
'HY1HW </p>
<p>35H1HW 
)($:$' 
;*%2' </p>
<p>(b) Duplicated Anomalies, semi </p>
<p>$8&amp;52&amp; </p>
<p>1% 
690 
0/3 
5HV1HW 
)77UDQVIRUPHU </p>
<p>5) 
/<em>% 
;</em>% 
&amp;DW% </p>
<p>(c) Duplicated Anomalies, sup </p>
<p>$8&amp;52&amp; </p>
<p>3&amp;$ 
2&amp;690 
/2) 
&amp;%/2) 
&amp;2) </p>
<p>+%26 
.11 
62' 
&amp;232' 
(&amp;2' </p>
<p>'HHS69'' 
'$*00 
/2'$ 
,)RUHVW </p>
<p>(d) Irrelevant Features, unsup </p>
<p>$8&amp;52&amp; </p>
<p>*$1RPDO\ 
'HHS6$' 
5(3(1 
'HY1HW </p>
<p>35H1HW 
)($:$' 
;*%2' </p>
<p>(e) Irrelevant Features, semi </p>
<p>$8&amp;52&amp; </p>
<p>1% 
690 
0/3 
5HV1HW 
)77UDQVIRUPHU </p>
<p>5) 
/<em>% 
;</em>% 
&amp;DW% </p>
<p>(f) Irrelevant Features, sup </p>
<p>$8&amp;52&amp; </p>
<p>*$1RPDO\ 
'HHS6$' 
5(3(1 
'HY1HW </p>
<p>35H1HW 
)($:$' 
;*%2' </p>
<p>(g) Annotation Errors, semi </p>
<p>$8&amp;52&amp; </p>
<p>1% 
690 
0/3 
5HV1HW 
)77UDQVIRUPHU </p>
<p>5) 
/<em>% 
;</em>% 
&amp;DW% </p>
<p>(h) Annotation Errors, sup </p>
<p>Li, Y. Zhao, X. Hu, N. Botta, C. Ionescu, and G. Chen. Ecod: Unsupervised outlier detection using empirical cumulative distribution functions. TKDE, pages 1-1, 2022. [98] T.-Y. Lin, P. Goyal, R. Girshick, K. He, and P. Dollár. Focal loss for dense object detection. In ICCV, pages 2980-2988, 2017. [99] B. Liu, P. Tan, and J. Zhou. Unsupervised anomaly detection by robust density estimation. In AAAI, Liu, M. Ott, N. Goyal, J. Du, M. Joshi, D. Chen, O. Levy, M. Lewis, L. Zettlemoyer, and V. Stoyanov. Roberta: A robustly optimized bert pretraining approach. arXiv:1907.11692, 2019.[85] K.-H. Lai, D. Zha, J. Xu, Y. Zhao, G. Wang, and X. Hu. Revisiting time series outlier detection: 
Definitions and benchmarks. In NeurIPS, 2021. </p>
<p>[86] K. Lang. Newsweeder: Learning to filter netnews. In ICML, pages 331-339. Elsevier, 1995. </p>
<p>[87] A. Lavin and S. Ahmad. Evaluating real-time anomaly detection algorithms-the numenta anomaly 
benchmark. In 2015 IEEE 14th ICML and applications (ICMLA), pages 38-44. IEEE, 2015. </p>
<p>[88] A. Lazarevic, L. Ertoz, V. Kumar, A. Ozgur, and J. Srivastava. A comparative study of anomaly detection 
schemes in network intrusion detection. In SDM, pages 25-36. SIAM, 2003. </p>
<p>[89] Y. LeCun, Y. Bengio, and G. Hinton. Deep learning. nature, 521(7553):436-444, 2015. </p>
<p>[90] Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner. Gradient-based learning applied to document recognition. 
Proceedings of the IEEE, 86(11):2278-2324, 1998. </p>
<p>[91] C. H. Lee and K. Lee. Semi-supervised anomaly detection algorithm based on kl divergence (sad-kl). 
arXiv:2203.14539, 2022. </p>
<p>[92] K. Lee, K. Lee, H. Lee, and J. Shin. A simple unified framework for detecting out-of-distribution samples 
and adversarial attacks. NeurIPS, 31, 2018. </p>
<p>[93] M.-C. Lee, S. Shekhar, C. Faloutsos, T. N. Hutson, and L. Iasemidis. Gen 2 out: Detecting and ranking 
generalized anomalies. In Big Data, pages 801-811. IEEE, 2021. </p>
<p>[94] M.-C. Lee, Y. Zhao, A. Wang, P. J. Liang, L. Akoglu, V. S. Tseng, and C. Faloutsos. Autoaudit: Mining 
accounting and time-evolving graphs. In Big Data, pages 950-956. IEEE, 2020. </p>
<p>[95] G. Li, Y. Xie, and L. Lin. Weakly supervised salient object detection using image labels. In AAAI, 
volume 32, 2018. </p>
<p>[96] Z. Li, Y. Zhao, N. Botta, C. Ionescu, and X. Hu. Copod: copula-based outlier detection. In ICDM, pages 
1118-1123. IEEE, 2020. </p>
<p>[97] Z. pages 4101-4108. AAAI Press, 2022. </p>
<p>[100] F. T. Liu, K. M. Ting, and Z.-H. Zhou. Isolation forest. In ICDM, pages 413-422. IEEE, 2008. </p>
<p>[101] K. Liu, Y. Dou, Y. Zhao, X. Ding, X. Hu, R. Zhang, K. Ding, C. Chen, H. Peng, K. Shu, et al. Bench-
marking node outlier detection on graphs. arXiv preprint arXiv:2206.10071, 2022. </p>
<p>[102] K. Liu, Y. Dou, Y. Zhao, X. Ding, X. Hu, R. Zhang, K. Ding, C. Chen, H. Peng, K. Shu, et al. Pygod: A 
python library for graph outlier detection. ArXiv, 2204.12095, 2022. </p>
<p>[103] S. Liu and M. Hauskrecht. Event outlier detection in continuous time. In ICML, pages 6793-6803, 2021. </p>
<p>[104] W. Liu, X. Wang, J. Owens, and Y. Li. Energy-based out-of-distribution detection. NeurIPS, 33:21464-
21475, 2020. </p>
<p>[105] Y. [106] P. Liznerski, L. Ruff, R. A. Vandermeulen, B. J. Franks, M. Kloft, and K. R. Muller. Explainable deep 
one-class classification. In ICLR, 2020. </p>
<p>[107] W.-Y. Loh. Classification and regression trees. WIREs Data Mining and Knowledge Discovery, 1, 2011. </p>
<p>[108] I. Loshchilov and F. Hutter. Decoupled weight decay regularization. ArXiv, 1711.05101, 2017. </p>
<p>[109] M. Q. Ma, Y. Zhao, X. Zhang, and L. Akoglu. A large-scale study on unsupervised outlier model selection: 
Do internal strategies suffice? ArXiv, 2104.01422, 2021. </p>
<p>[110] X. Ma, J. Wu, S. Xue, J. Yang, C. Zhou, Q. Z. Sheng, H. Xiong, and L. Akoglu. A comprehensive survey 
on graph anomaly detection with deep learning. TKDE, 2021. </p>
<p>[111] A. L. Maas, R. E. Daly, P. T. Pham, D. Huang, A. Y. Ng, and C. Potts. Learning word vectors for sentiment 
analysis. In ACL, pages 142-150. Association for Computational Linguistics, 2011. </p>
<p>[112] A. Mahdavi and M. Carvalho. A survey on open set recognition. In AIKE, pages 37-44. IEEE, 2021. </p>
<p>[113] D. Malerba, F. Esposito, and G. Semeraro. A further comparison of simplification methods for decision-
tree induction. In Learning from data, pages 365-374. Springer, 1996. </p>
<p>[114] O. L. Mangasarian, W. N. Street, and W. H. Wolberg. Breast cancer diagnosis and prognosis via linear 
programming. Operations Research, 43(4):570-577, 1995. 
[201] Y. Zheng, X. Wang, Y. Qi, W. Li, and L. Wu. Benchmarking unsupervised anomaly detection and 
localization. ArXiv, 2205.14852, 2022. </p>
<p>[202] D.-W. Zhou, H.-J. Ye, and D.-C. Zhan. Learning placeholders for open-set recognition. In CVPR, pages 
4401-4410, 2021. </p>
<p>[203] Y. Zhou, X. Song, Y. Zhang, F. Liu, C. Zhu, and L. Liu. Feature encoding with autoencoders for weakly 
supervised anomaly detection. TNNLS, 2021. </p>
<p>[204] Z.-H. Zhou. A brief introduction to weakly supervised learning. Natl. Sci. Rev., 5(1):44-53, 2018. </p>
<p>[205] B. Zong, Q. Song, M. R. Min, W. Cheng, C. Lumezanu, D. Cho, and H. Chen. Deep autoencoding 
gaussian mixture model for unsupervised anomaly detection. In ICLR, 2018. </p>
<p>. A neural network-based model that defines a two-stream ordinal regression to learn the relation of instance pairs. The score targets of {unlabeled, unlabeled}, {labeled, unlabeled} and {labeled, labeled} sample pairs are set to 0, 4 and 8, respectively. PReNet is trained for 50 epochs with 512 batch size, where the total number of steps is set to 20. RMSprop optimizer with a learning rate of 0.001 and 0.01 weight decay is applied to update network parameters.6. Feature Encoding With Autoencoders for Weakly Supervised Anomaly Detection (FEAWAD) [203]. A neural network-based model that incorporates the network architecture of DAGMM [205] with the deviation loss of DevNet [131]. FEAWAD is trained for 30 epochs with 512 batch size, where the total number of steps is set to 20. Adam optimizer with 0.0001 learning rate is applied to update network parameters. 7. Extreme Gradient Boosting Outlier Detection (XGBOD)</p>
<p>. 6. Highly Efficient Gradient Boosting Decision Tree (LightGBM) [74]. LightGBM is a gradient boosting framework that uses tree-based learning algorithms with faster training speed, higher efficiency, lower memory usage, and better accuracy. The default hyperparameter settings in the LightGBM official repository 2 are used. 7. Categorical Boosting (CatBoost) [138]. CatBoost is a fast, scalable, high-performance gradient boosting on decision trees. CatBoost uses the default hyperparameter settings in its official repository 3 . 8. Residual Nets (ResNet) [56]. This method introduces a ResNet-like architecture [62] for tabular based data. ResNet is trained for 100 epochs with 64 batch size. AdamW [108] optimizer with 0.001 learning rate is applied to update network parameters. 9. Feature Tokenizer + Transformer (FTTransformer) [56]. FTTransformer is an effective adaptation of the Transformer architecture [171] for tabular data. FTTransformer is trained for 100 epochs with 64 batch size. AdamW optimizer with 0.0001 learning rate and 10 −5 weight decay is applied to update network parameters.</p>
<p>or Glove [134], we apply BERT 3 [75] pretrained on the BookCorpus and English Wikipedia to extract more enriching embedding of the [CLS] token. In addition, we provide the embedding version that are extracted by the pretrained RoBERTa 4 [105]</p>
<p>Table B1 :
B1Data description of the 57 datasets included in ADBench; 10 newly added datasets from CV and NLP domain are highlighted in blue at the bottom of the table.Data </p>
<h1>Samples # Features # Anomaly % Anomaly</h1>
<p>Category Reference </p>
<p>ALOI 
49534 
27 
1508 
3.04 
Image 
[42] 
annthyroid 
7200 
6 
534 
7.42 
Healthcare 
[141] 
backdoor 
95329 
196 
2329 
2.44 
Network 
[119] 
breastw 
683 
9 
239 
34.99 
Healthcare 
[173] 
campaign 
41188 
62 
4640 
11.27 
Finance 
[131] 
cardio 
1831 
21 
176 
9.61 
Healthcare 
[12] 
Cardiotocography 
2114 
21 
466 
22.04 
Healthcare 
[12] 
celeba 
202599 
39 
4547 
2.24 
Image 
[131] 
census 
299285 
500 
18568 
6.20 
Sociology 
[131] 
cover 
286048 
10 
2747 
0.96 
Botany 
[18] 
donors 
619326 
10 
36710 
5.93 
Sociology 
[131] 
fault 
1941 
27 
673 
34.67 
Physical 
[42] 
fraud 
284807 
29 
492 
0.17 
Finance 
[131] 
glass 
214 
7 
9 
4.21 
Forensic 
[43] 
Hepatitis 
80 
19 
13 
16.25 
Healthcare 
[36] 
http 
567498 
3 
2211 
0.39 
Web 
[145] 
InternetAds 
1966 
1555 
368 
18.72 
Image 
[25] 
Ionosphere 
351 
33 
126 
35.90 Oryctognosy 
[163] 
landsat 
6435 
36 
1333 
20.71 Astronautics 
[42] 
letter 
1600 
32 
100 
6.25 
Image 
[48] 
Lymphography 
148 
18 
6 
4.05 
Healthcare 
[26] 
magic.gamma 
19020 
10 
6688 
35.16 
Physical 
[42] 
mammography 
11183 
6 
260 
2.32 
Healthcare 
[176] 
mnist 
7603 
100 
700 
9.21 
Image 
[90] 
musk 
3062 
166 
97 
3.17 
Chemistry 
[37] 
optdigits 
5216 
64 
150 
2.88 
Image 
[10] 
PageBlocks 
5393 
10 
510 
9.46 
Document 
[113] 
pendigits 
6870 
16 
156 
2.27 
Image 
[9] 
Pima 
768 
8 
268 
34.90 
Healthcare 
[145] 
satellite 
6435 
36 
2036 
31.64 Astronautics 
[145] 
satimage-2 
5803 
36 
71 
1.22 Astronautics 
[145] 
shuttle 
49097 
9 
3511 
7.15 Astronautics 
[145] 
skin 
245057 
3 
50859 
20.75 
Image 
[42] 
smtp 
95156 
3 
30 
0.03 
Web 
[145] 
SpamBase 
4207 
57 
1679 
39.91 
Document 
[25] 
speech 
3686 
400 
61 
1.65 
Linguistics 
[23] 
Stamps 
340 
9 
31 
9.12 
Document 
[25] 
thyroid 
3772 
6 
93 
2.47 
Healthcare 
[142] 
vertebral 
240 
6 
30 
12.50 
Biology 
[17] 
vowels 
1456 
12 
50 
3.43 
Linguistics 
[82] 
Waveform 
3443 
21 
100 
2.90 
Physics 
[107] 
WBC 
223 
9 
10 
4.48 
Healthcare 
[114] 
WDBC 
367 
30 
10 
2.72 
Healthcare 
[114] 
Wilt 
4819 
5 
257 
5.33 
Botany 
[25] 
wine 
129 
13 
10 
7.75 
Chemistry 
[2] 
WPBC 
198 
33 
47 
23.74 
Healthcare 
[114] 
yeast 
1484 
8 
507 
34.16 
Biology 
[66] </p>
<p>CIFAR10 
5263 
512 
263 
5.00 
Image 
[81] 
FashionMNIST 
6315 
512 
315 
5.00 
Image 
[178] 
MNIST-C 
10000 
512 
500 
5.00 
Image 
[120] 
MVTec-AD 
See Table B2. 
Image 
[16] 
SVHN 
5208 
512 
260 
5.00 
Image 
[121] </p>
<p>Agnews 
10000 
768 
500 
5.00 
NLP 
[192] 
Amazon 
10000 
768 
500 
5.00 
NLP 
[63] 
Imdb 
10000 
768 
500 
5.00 
NLP 
[111] 
Yelp 
10000 
768 
500 
5.00 
NLP 
[192] 
20newsgroups 
See Table B3. 
NLP 
[86] </p>
<p>Table B2 :
B2Detailed description of the MVTec-AD dataset; see the full dataset list inTable B1. For MVTec-AD dataset, we evaluate 30 algorithms on each class and report the average performance of all classes.Class </p>
<h1>Samples # Features # Anomaly % Anomaly</h1>
<p>Carpet 
397 
512 
89 
22.42 
Grid 
342 
512 
57 
16.67 
Leather 
369 
512 
92 
24.93 
Tile 
347 
512 
84 
24.21 
Wood 
326 
512 
60 
18.40 
Bottle 
292 
512 
63 
21.58 
Cable 
374 
512 
92 
24.60 
Capsule 
351 
512 
109 
31.05 
Hazelnut 
501 
512 
70 
13.97 
Metal Nut 
335 
512 
93 
27.76 
Pill 
434 
512 
141 
32.49 
Screw 
480 
512 
119 
24.79 
Toothbrush 
102 
512 
30 
29.41 
Transistor 
313 
512 
40 
12.78 
Zipper 
391 
512 
119 
30.43 </p>
<p>Total 
5354 
512 
1258 
23.50 </p>
<p>Table B3 :
B3Detailed description of the 20newsgroups dataset; see the full dataset list inTable B1. For 20newsgroups dataset, we evaluate 30 algorithms on each class and report the average performance of all classes.Class </p>
<h1>Samples # Features # Anomaly % Anomaly</h1>
<p>Computer 
3090 
768 
154 
4.98 
Recreation 
2514 
768 
125 
4.97 
Science 
2497 
768 
124 
4.97 
Miscellaneous 
615 
768 
30 
4.88 
Politics 
1657 
768 
82 
4.95 
Religion 
1532 
768 
76 
4.96 </p>
<p>Total 
11905 
768 
591 
4.96 
B.3 Additional Demonstration of Synthetic Anomalies for  §3.3.2 </p>
<p>Extensive Experiments. In total ADBench conducts 98,436 experiments, where each denotes one algorithm's result on a dataset under a specific setting. More specifically, we have 27,090 experiments in §4.2. For 47 classical datasets: • Unsupervised methods on benchmark real-world datasets {14 algorithms, 47 datasets, 3 repeat times} leads to 1,974 experiments. • Semi-and fully-supervised on real-world datasets {16 algorithms, 47 datasets, 3 repeat times, 7 settings of labeled anomalies} leads to 15,792 experiments. Semi-and fully-supervised on real-world datasets {16 algorithms, 74 subclasses, 1 repeat times, 7 settings of labeled anomalies} leads to 8,288 experiments.As we described in Appx. B.2, we totally have 74 subclasses for the 10 CV and NLP datasets, thus 
generating: </p>
<p>• Unsupervised methods on benchmark datasets {14 algorithms, 74 subclasses, 1 repeat times} leads 
to 1,036 experiments. 
• Additionally, we have 17,766 experiments for understanding the algorithm performances under four 
types of anomalies in  §4.3: </p>
<p>• Unsupervised methods on benchmark real-world datasets {14 algorithms, 47 datasets, 3 repeat 
times} leads to 1,974 experiments. 
• Semi-and fully-supervised on benchmark datasets {16 algorithms, 47 datasets, 3 repeat times, 7 
settings of labeled anomalies} leads to 15,792 experiments. </p>
<p>Finally, we have 53,580 experiments for evaluating the algorithm robustness under three settings of 
data noises and corruptions in  §4.4: </p>
<p>• For duplicated anomalies and irrelevant features {30 algorithms, 47 datasets, 3 repeat times, 5 
settings of data noises, 2 scenarios} leads to 42,300 experiments. 
• For annotation errors {16 algorithms, 47 datasets, 3 repeat times, 5 settings of data noises} leads to 
11,280 experiments. </p>
<p>Computational Resources. Classical anomaly detection models are run on an Intel i7-8700 @3.20 
GHz, 16GB RAM, 12-core workstation. For deep learning models (especially for ResNet and 
FTTransformer), we run experiments on an NVIDIA Tesla V100 GPU accelerator. The model 
runtime on benchmark datasets is reported in Appx.  §D.1. 
D Additional Experiment Results </p>
<p>D.1 Additional Results for Overall Model Performance on Benchmark Datasets in  §4.2 </p>
<p>Figure D7: AUCPR CD Diagram of unsupervised methods on different types of anomalies. The unsupervised methods perform well when their assumptions conform to the anomaly types.'HHS69'' 
'$*00 
&amp;232' 
+%26 
3&amp;$ 
/2'$ 
,)RUHVW 
(&amp;2' 
62' 
2&amp;690 
&amp;%/2) 
&amp;2) 
.11 
/2) </p>
<p>$YJ5DQN </p>
<p>(a) Local anomalies </p>
<p>'HHS69'' 
'$*00 
/2'$ 
(&amp;2' 
&amp;2) 
/2) 
&amp;232' 
2&amp;690 
3&amp;$ 
62' 
+%26 
&amp;%/2) 
,)RUHVW 
.11 </p>
<p>$YJ5DQN </p>
<p>(b) Global anomalies </p>
<p>(&amp;2' 
+%26 
&amp;232' 
2&amp;690 
3&amp;$ 
/2'$ 
'$*00 
'HHS69'' 
,)RUHVW 
&amp;%/2) 
62' 
.11 
/2) 
&amp;2) </p>
<p>$YJ5DQN </p>
<p>(c) Dependency anomalies </p>
<p>'HHS69'' 
/2) 
&amp;2) 
.11 
62' 
'$*00 
(&amp;2' 
/2'$ 
&amp;%/2) 
,)RUHVW 
&amp;232' 
+%26 
3&amp;$ 
2&amp;690 </p>
<p>$YJ5DQN </p>
<p>(d) Clustered anomalies </p>
<p>/DEHOHG$QRPDOLHV </p>
<p>$8&amp;35 </p>
<p>*$1RPDO\ 
'HHS6$' 
5(3(1 
'HY1HW </p>
<p>35H1HW 
)($:$' 
;*%2' 
%HVW8QVXS </p>
<p>/DEHOHG$QRPDOLHV </p>
<p>$8&amp;35 </p>
<p>1% 
690 
0/3 
5HV1HW 
)77UDQVIRUPHU </p>
<p>5) 
/<em>% 
;</em>% 
&amp;DW% 
%HVW8QVXS </p>
<p>(a) Local anomalies </p>
<p>/DEHOHG$QRPDOLHV </p>
<p>$8&amp;35 </p>
<p>*$1RPDO\ 
'HHS6$' 
5(3(1 
'HY1HW </p>
<p>35H1HW 
)($:$' 
;*%2' 
%HVW8QVXS </p>
<p>/DEHOHG$QRPDOLHV </p>
<p>$8&amp;35 </p>
<p>1% 
690 
0/3 
5HV1HW 
)77UDQVIRUPHU </p>
<p>5) 
/<em>% 
;</em>% 
&amp;DW% 
%HVW8QVXS </p>
<p>(b) Global anomalies </p>
<p>/DEHOHG$QRPDOLHV </p>
<p>$8&amp;35 </p>
<p>*$1RPDO\ 
'HHS6$' 
5(3(1 
'HY1HW </p>
<p>35H1HW 
)($:$' 
;*%2' 
%HVW8QVXS </p>
<p>/DEHOHG$QRPDOLHV </p>
<p>$8&amp;35 </p>
<p>1% 
690 
0/3 
5HV1HW 
)77UDQVIRUPHU </p>
<p>5) 
/<em>% 
;</em>% 
&amp;DW% 
%HVW8QVXS </p>
<p>(c) Dependency anomalies </p>
<p>/DEHOHG$QRPDOLHV </p>
<p>$8&amp;35 </p>
<p>*$1RPDO\ 
'HHS6$' 
5(3(1 
'HY1HW </p>
<p>35H1HW 
)($:$' 
;*%2' 
%HVW8QVXS </p>
<p>/DEHOHG$QRPDOLHV </p>
<p>$8&amp;35 </p>
<p>1% 
690 
0/3 
5HV1HW 
)77UDQVIRUPHU </p>
<p>5) 
/<em>% 
;</em>% 
&amp;DW% 
%HVW8QVXS </p>
<p>(d) Clustered anomalies </p>
<p>Figure D8: Semi-(left of each subfigure) and supervised (right) algorithms' performance on different 
types of anomalies with varying levels of labeled anomalies for AUCPR performance. Surprisingly, 
these label-informed algorithms are inferior to the best unsupervised method except for the clustered 
anomalies. 
D.3 Additional Results for Algorithm Robustness in  §4.4 </p>
<p>$8&amp;52&amp; </p>
<p>3&amp;$ 
2&amp;690 
/2) 
&amp;%/2) 
&amp;2) </p>
<p>+%26 
.11 
62' 
&amp;232' 
(&amp;2' </p>
<p>'HHS69'' 
'$*00 
/2'$ 
,)RUHVW </p>
<p>(a) Duplicated Anomalies, unsup </p>
<p>$8&amp;52&amp; </p>
<p>*$1RPDO\ 
'HHS6$' 
5(3(1 
'HY1HW </p>
<p>35H1HW 
)($:$' 
;*%2' </p>
<p>(b) Duplicated Anomalies, semi </p>
<p>$8&amp;52&amp; </p>
<p>1% 
690 
0/3 
5HV1HW 
)77UDQVIRUPHU </p>
<p>5) 
/<em>% 
;</em>% 
&amp;DW% </p>
<p>(c) Duplicated Anomalies, sup </p>
<p>$8&amp;52&amp; </p>
<p>3&amp;$ 
2&amp;690 
/2) 
&amp;%/2) 
&amp;2) </p>
<p>+%26 
.11 
62' 
&amp;232' 
(&amp;2' </p>
<p>'HHS69'' 
'$*00 
/2'$ 
,)RUHVW </p>
<p>(d) Irrelevant Features, unsup </p>
<p>$8&amp;52&amp; </p>
<p>*$1RPDO\ 
'HHS6$' 
5(3(1 
'HY1HW </p>
<p>35H1HW 
)($:$' 
;*%2' </p>
<p>(e) Irrelevant Features, semi </p>
<p>$8&amp;52&amp; </p>
<p>1% 
690 
0/3 
5HV1HW 
)77UDQVIRUPHU </p>
<p>5) 
/<em>% 
;</em>% 
&amp;DW% </p>
<p>(f) Irrelevant Features, sup </p>
<p>$8&amp;52&amp; </p>
<p>*$1RPDO\ 
'HHS6$' 
5(3(1 
'HY1HW </p>
<p>35H1HW 
)($:$' 
;*%2' </p>
<p>(g) Annotation Errors, semi </p>
<p>$8&amp;52&amp; </p>
<p>1% 
690 
0/3 
5HV1HW 
)77UDQVIRUPHU </p>
<p>5) 
/<em>% 
;</em>% 
&amp;DW% </p>
<p>(h) Annotation Errors, sup </p>
<p>Table D4 :
D4AUCROC of 14 unsupervised algorithms on 57 benchmark datasets. We show the 
performance rank in parenthesis (the lower, the better), and mark the best performing method(s) in 
bold. </p>
<p>Datasets 
PCA 
OCSVM 
LOF 
CBLOF 
COF 
HBOS 
KNN 
SOD 
COPOD 
ECOD 
Deep 
SVDD </p>
<p>DA 
GMM 
LODA 
IForest </p>
<p>ALOI 
56.65(6) 
55.85(8) 
66.63(1) 
55.22(9) 
64.68(2) 
52.63(11) 
61.47(3) 
61.09(4) 
53.75(10) 
56.60(7) 
50.29(14) 
51.96(12) 
51.33(13) 
56.66(5) 
annthyroid 
66.25(8) 
57.23(12) 
70.20(7) 
62.26(10) 
65.92(9) 
60.15(11) 
71.69(6) 
77.38(3) 
76.80(4) 
78.03(2) 
76.62(5) 
56.53(13) 
41.02(14) 
82.01(1) 
backdoor 
80.13(7) 
86.20(2) 
85.68(3) 
81.16(4) 
73.03(8) 
71.43(10) 
80.82(6) 
69.54(11) 
80.97(5) 
86.33(1) 
55.16(14) 
56.26(13) 
69.22(12) 
72.15(9) 
breastw 
95.13(8) 
80.30(10) 
40.61(12) 
96.81(7) 
38.84(13) 
98.94(3) 
97.01(6) 
93.97(9) 
99.68(1) 
99.17(2) 
65.66(11) 
N/A(N/A) 
98.49(4) 
98.32(5) 
campaign 
72.78(4) 
65.52(9) 
58.85(10) 
66.61(8) 
57.26(11) 
78.61(1) 
72.10(5) 
69.04(7) 
77.69(2) 
76.78(3) 
48.70(14) 
56.08(12) 
51.43(13) 
71.71(6) 
cardio 
95.55(1) 
93.91(3) 
66.33(13) 
89.93(7) 
71.41(12) 
84.67(8) 
76.64(9) 
73.25(11) 
92.35(5) 
94.44(2) 
58.96(14) 
75.01(10) 
90.34(6) 
93.19(4) 
Cardiotocography 
74.67(2) 
77.86(1) 
59.51(10) 
64.54(7) 
53.77(12) 
60.86(9) 
56.23(11) 
51.69(14) 
67.02(6) 
68.92(4) 
53.53(13) 
62.01(8) 
73.65(3) 
67.57(5) 
celeba 
79.38(1) 
70.70(6) 
38.55(14) 
73.99(4) 
38.58(13) 
76.18(2) 
59.63(9) 
47.85(11) 
75.68(3) 
72.82(5) 
50.36(10) 
44.74(12) 
60.11(8) 
70.41(7) 
census 
68.74(2) 
54.58(10) 
47.19(12) 
59.41(8) 
41.35(13) 
64.94(5) 
66.75(4) 
62.31(6) 
69.07(1) 
68.44(3) 
51.07(11) 
59.29(9) 
36.86(14) 
59.52(7) 
cover 
93.73(1) 
92.62(3) 
84.58(10) 
89.30(6) 
76.91(12) 
80.24(11) 
85.97(9) 
74.46(13) 
88.64(7) 
93.42(2) 
46.20(14) 
89.89(5) 
92.34(4) 
86.74(8) 
donors 
83.15(1) 
71.93(7) 
55.49(11) 
60.44(10) 
70.54(9) 
78.23(4) 
81.09(3) 
55.21(12) 
81.76(2) 
74.45(6) 
50.27(13) 
70.57(8) 
24.86(14) 
77.68(5) 
fault 
46.02(10) 
47.69(9) 
58.93(5) 
64.06(3) 
62.10(4) 
51.28(8) 
72.98(1) 
68.11(2) 
43.88(12) 
43.41(13) 
51.67(7) 
45.86(11) 
41.71(14) 
57.02(6) 
fraud 
90.35(8) 
90.62(6) 
94.92(2) 
91.70(5) 
93.05(4) 
90.29(9) 
93.56(3) 
94.97(1) 
88.32(13) 
89.85(10) 
64.98(14) 
89.53(11) 
88.99(12) 
90.38(7) 
glass 
66.29(12) 
35.36(14) 
69.20(11) 
82.94(1) 
72.24(10) 
77.23(3) 
82.29(2) 
73.36(7) 
72.43(9) 
75.70(6) 
47.49(13) 
76.09(5) 
73.13(8) 
77.13(4) 
Hepatitis 
75.95(4) 
67.75(7) 
38.02(14) 
66.40(8) 
41.45(13) 
79.85(2) 
52.76(11) 
68.17(6) 
82.05(1) 
79.67(3) 
50.96(12) 
54.80(10) 
64.87(9) 
69.75(5) 
http 
99.72(2) 
99.59(4) 
27.46(11) 
99.60(3) 
88.78(8) 
99.53(5) 
3.37(13) 
78.04(9) 
99.29(6) 
98.10(7) 
69.05(10) 
N/A(N/A) 
12.48(12) 
99.96(1) 
InternetAds 
61.67(11) 
68.28(4) 
65.83(8) 
70.58(1) 
63.79(9) 
68.03(5) 
69.99(2) 
61.85(10) 
67.05(7) 
67.10(6) 
60.20(12) 
N/A(N/A) 
55.38(13) 
69.01(3) 
Ionosphere 
79.19(8) 
75.92(10) 
90.59(2) 
90.72(1) 
86.76(4) 
62.49(13) 
88.26(3) 
86.41(5) 
79.34(7) 
75.59(11) 
50.89(14) 
73.41(12) 
78.42(9) 
84.50(6) 
landsat 
35.76(14) 
36.15(13) 
53.90(7) 
63.55(2) 
53.50(8) 
55.14(6) 
57.95(4) 
59.54(3) 
41.55(11) 
56.61(5) 
63.61(1) 
43.92(10) 
38.17(12) 
47.64(9) 
letter 
50.29(12) 
46.18(14) 
84.49(2) 
75.62(5) 
80.03(4) 
59.74(7) 
86.19(1) 
84.09(3) 
54.32(9) 
50.76(10) 
56.64(8) 
50.42(11) 
50.24(13) 
61.07(6) 
Lymphography 
99.82(2) 
99.54(4) 
89.86(9) 
99.83(1) 
90.85(8) 
99.49(6) 
55.91(13) 
72.49(11) 
99.48(7) 
99.52(5) 
32.29(14) 
72.11(12) 
85.55(10) 
99.81(3) 
magic.gamma 
67.22(9) 
60.65(12) 
68.51(6) 
75.13(3) 
66.64(10) 
70.86(5) 
82.38(1) 
75.40(2) 
68.33(7) 
64.36(11) 
60.26(13) 
58.58(14) 
68.02(8) 
73.25(4) 
mammography 
88.72(3) 
84.95(6) 
74.39(12) 
83.74(9) 
77.53(11) 
86.27(5) 
84.53(7) 
81.51(10) 
90.69(2) 
90.75(1) 
56.98(13) 
N/A(N/A) 
83.91(8) 
86.39(4) 
mnist 
85.29(1) 
82.95(3) 
67.13(11) 
79.45(6) 
70.78(9) 
60.42(12) 
80.58(5) 
60.10(13) 
77.74(7) 
84.60(2) 
53.40(14) 
67.23(10) 
72.27(8) 
80.98(4) 
musk 
100.00(3) 
80.58(8) 
41.18(13) 
100.00(1) 
38.69(14) 
100.00(1) 
69.89(11) 
74.09(10) 
94.20(7) 
95.11(6) 
43.52(12) 
76.85(9) 
95.11(5) 
99.99(4) 
optdigits 
51.65(11) 
54.00(10) 
56.10(9) 
87.51(1) 
49.15(12) 
81.63(2) 
41.73(13) 
58.92(8) 
68.71(4) 
61.04(7) 
38.89(14) 
62.57(5) 
61.74(6) 
70.92(3) 
PageBlocks 
90.64(2) 
88.76(5) 
75.90(12) 
85.04(7) 
72.65(13) 
80.58(10) 
81.94(9) 
77.75(11) 
88.05(6) 
90.92(1) 
57.77(14) 
89.61(3) 
83.34(8) 
89.57(4) 
pendigits 
93.73(3) 
93.75(2) 
47.99(12) 
90.40(7) 
45.07(13) 
93.04(4) 
72.95(9) 
66.29(10) 
90.68(6) 
91.22(5) 
39.92(14) 
64.22(11) 
89.10(8) 
94.76(1) 
Pima 
70.77(5) 
66.92(7) 
65.71(9) 
71.42(3) 
61.05(11) 
71.07(4) 
73.43(1) 
61.25(10) 
69.10(6) 
51.54(13) 
51.03(14) 
55.92(12) 
65.93(8) 
72.87(2) 
satellite 
59.62(10) 
59.02(11) 
55.88(12) 
71.32(3) 
54.74(14) 
74.80(2) 
65.18(5) 
63.96(6) 
63.20(7) 
75.06(1) 
55.30(13) 
62.33(8) 
61.98(9) 
70.43(4) 
satimage-2 
97.62(4) 
97.35(6) 
47.36(14) 
99.84(1) 
56.70(12) 
97.65(3) 
92.60(10) 
83.08(11) 
97.21(7) 
97.11(8) 
53.14(13) 
96.29(9) 
97.56(5) 
99.16(2) 
shuttle 
98.62(5) 
97.40(7) 
57.11(12) 
83.48(8) 
51.72(14) 
98.63(4) 
69.64(9) 
69.51(10) 
99.35(3) 
99.40(2) 
52.05(13) 
97.92(6) 
60.95(11) 
99.56(1) 
skin 
45.26(10) 
49.45(6) 
46.47(8) 
69.49(2) 
41.66(12) 
60.15(5) 
71.46(1) 
60.35(4) 
47.55(7) 
39.09(13) 
44.05(11) 
N/A(N/A) 
45.75(9) 
68.21(3) 
smtp 
88.41(3) 
80.70(4) 
71.84(10) 
79.68(5) 
79.60(6) 
70.52(12) 
89.62(2) 
59.85(14) 
79.09(7) 
71.86(9) 
78.24(8) 
71.32(11) 
67.43(13) 
89.73(1) 
SpamBase 
54.66(6) 
52.47(9) 
43.33(11) 
54.97(5) 
40.96(13) 
64.74(4) 
53.35(8) 
52.35(10) 
70.09(1) 
66.89(2) 
53.55(7) 
N/A(N/A) 
41.99(12) 
64.76(3) 
speech 
50.79(9) 
50.19(13) 
52.48(6) 
50.58(12) 
55.97(1) 
50.59(11) 
51.03(8) 
55.86(2) 
52.89(4) 
51.58(7) 
53.43(3) 
52.75(5) 
49.84(14) 
50.74(10) 
Stamps 
91.47(2) 
83.86(8) 
51.26(14) 
68.18(11) 
53.81(13) 
90.73(5) 
68.61(10) 
73.26(9) 
93.40(1) 
91.41(3) 
55.84(12) 
88.88(6) 
87.18(7) 
91.21(4) 
thyroid 
96.34(3) 
87.92(10) 
86.86(11) 
94.73(6) 
90.87(9) 
95.62(5) 
95.93(4) 
92.81(8) 
94.30(7) 
97.78(2) 
49.64(14) 
79.75(12) 
74.30(13) 
98.30(1) 
vertebral 
37.06(8) 
37.99(6) 
49.29(2) 
41.41(4) 
48.71(3) 
28.56(13) 
33.79(11) 
40.32(5) 
25.64(14) 
37.51(7) 
36.67(9) 
53.20(1) 
30.57(12) 
36.66(10) 
vowels 
65.29(9) 
61.59(10) 
93.12(3) 
89.92(5) 
94.04(2) 
72.21(7) 
97.26(1) 
92.65(4) 
53.15(12) 
45.81(14) 
52.49(13) 
60.58(11) 
70.36(8) 
73.94(6) 
Waveform 
65.48(10) 
56.29(12) 
73.32(3) 
72.42(6) 
72.56(5) 
68.77(8) 
73.78(2) 
68.57(9) 
75.03(1) 
73.25(4) 
54.47(13) 
49.35(14) 
60.13(11) 
71.47(7) 
WBC 
98.20(7) 
99.03(4) 
54.17(13) 
99.46(1) 
60.90(11) 
98.72(6) 
90.56(10) 
94.60(9) 
99.11(2) 
99.11(2) 
55.50(12) 
N/A(N/A) 
96.91(8) 
99.01(5) 
WDBC 
99.05(4) 
98.86(6) 
89.00(12) 
99.32(3) 
96.26(9) 
99.50(1) 
91.72(11) 
91.90(10) 
99.42(2) 
97.20(8) 
65.69(14) 
76.67(13) 
98.26(7) 
98.95(5) 
Wilt 
20.39(14) 
31.28(12) 
50.65(2) 
32.54(10) 
49.66(3) 
32.49(11) 
48.42(4) 
53.25(1) 
33.40(9) 
39.43(7) 
46.08(5) 
37.29(8) 
26.42(13) 
41.94(6) 
wine 
84.37(4) 
73.07(6) 
37.74(13) 
25.86(14) 
44.44(12) 
91.36(1) 
44.98(11) 
46.11(10) 
88.65(3) 
71.34(7) 
59.52(9) 
61.70(8) 
90.12(2) 
80.37(5) 
WPBC 
46.01(10) 
45.35(12) 
41.41(14) 
44.77(13) 
45.88(11) 
51.24(1) 
46.59(9) 
51.14(2) 
49.34(4) 
46.83(7) 
49.79(3) 
47.80(6) 
49.31(5) 
46.63(8) 
yeast 
41.15(7) 
41.00(9) 
45.31(2) 
44.85(3) 
44.48(5) 
39.64(10) 
39.06(12) 
42.46(6) 
36.99(14) 
39.61(11) 
47.92(1) 
41.11(8) 
44.58(4) 
37.76(13) 
CIFAR10 
63.87(6) 
63.76(7) 
68.57(1) 
64.23(4) 
64.70(3) 
57.50(13) 
64.75(2) 
64.22(5) 
58.64(11) 
61.04(10) 
56.04(14) 
58.08(12) 
62.34(8) 
61.28(9) 
FashionMNIST 
86.09(3) 
85.24(4) 
67.57(12) 
88.17(1) 
71.44(11) 
78.68(10) 
86.60(2) 
81.73(7) 
81.07(8) 
83.63(6) 
63.32(14) 
67.29(13) 
80.28(9) 
84.89(5) 
MNIST-C 
73.75(5) 
72.21(8) 
68.27(12) 
80.86(2) 
69.81(11) 
70.82(10) 
81.26(1) 
74.00(4) 
71.26(9) 
72.64(7) 
51.85(14) 
58.56(13) 
74.37(3) 
73.74(6) 
MVTec-AD 
72.42(8) 
69.84(10) 
74.19(2) 
75.98(1) 
69.70(11) 
73.36(4) 
72.96(6) 
71.57(9) 
72.91(7) 
73.46(3) 
57.10(14) 
66.47(13) 
68.51(12) 
73.19(5) 
SVHN 
60.53(6) 
60.73(5) 
64.51(1) 
60.30(7) 
63.47(2) 
56.08(13) 
62.63(3) 
61.09(4) 
56.75(12) 
58.27(9) 
53.47(14) 
57.22(11) 
58.26(10) 
58.62(8) 
Agnews 
54.70(8) 
54.34(9) 
71.80(1) 
60.02(5) 
68.97(2) 
53.87(10) 
64.11(3) 
62.81(4) 
52.98(12) 
53.04(11) 
42.51(14) 
52.02(13) 
55.47(7) 
56.74(6) 
Amazon 
55.06(10) 
54.14(12) 
56.11(9) 
57.36(3) 
56.96(4) 
56.52(7) 
60.03(2) 
60.05(1) 
56.94(5) 
56.79(6) 
39.08(14) 
53.58(13) 
54.20(11) 
56.13(8) 
Imdb 
47.06(12) 
46.07(14) 
48.71(9) 
49.35(6) 
49.64(5) 
49.10(7) 
47.83(10) 
49.86(4) 
50.68(3) 
50.73(1) 
50.73(2) 
47.67(11) 
46.43(13) 
49.09(8) 
Yelp 
60.71(11) 
60.28(12) 
67.09(3) 
64.90(5) 
66.11(4) 
61.85(9) 
69.84(1) 
67.74(2) 
62.36(7) 
62.15(8) 
54.62(14) 
56.28(13) 
61.36(10) 
62.53(6) 
20news 
56.66(7) 
56.45(8) 
62.14(1) 
57.59(5) 
61.80(2) 
56.28(9) 
59.33(3) 
58.56(4) 
55.79(11) 
56.00(10) 
50.24(14) 
54.17(13) 
55.53(12) 
56.90(6) </p>
<p>Table D5 :
D5AUCPR of 14 unsupervised algorithms on 57 benchmark datasets. We show the perfor-
mance rank in parenthesis (lower the better), and mark the best performing method(s) in bold. </p>
<p>Datasets 
PCA 
OCSVM 
LOF 
CBLOF 
COF 
HBOS 
KNN 
SOD 
COPOD 
ECOD 
Deep 
SVDD </p>
<p>DA 
GMM 
LODA 
IForest </p>
<p>ALOI 
4.17(9) 
5.02(5) 
8.08(1) 
4.46(7) 
6.85(2) 
3.69(13) 
6.02(3) 
5.97(4) 
3.62(14) 
3.90(11) 
4.01(10) 
4.33(8) 
4.53(6) 
3.90(12) 
annthyroid 
16.12(8) 
10.37(12) 
15.71(9) 
13.69(11) 
14.39(10) 
16.99(5) 
16.74(6) 
18.84(4) 
16.58(7) 
24.65(2) 
21.95(3) 
9.64(13) 
7.06(14) 
30.47(1) 
backdoor 
31.29(3) 
9.69(9) 
26.14(4) 
6.96(11) 
24.68(5) 
4.91(13) 
45.22(1) 
39.41(2) 
7.69(10) 
11.25(8) 
12.85(7) 
6.50(12) 
14.51(6) 
4.75(14) 
breastw 
95.11(6) 
82.70(10) 
28.55(12) 
91.54(8) 
27.60(13) 
97.71(3) 
92.19(7) 
84.88(9) 
99.40(1) 
98.54(2) 
50.92(11) 
N/A(N/A) 
97.04(4) 
96.04(5) 
campaign 
27.90(6) 
29.22(5) 
14.51(11) 
23.99(8) 
13.01(13) 
37.99(2) 
27.18(7) 
18.88(9) 
38.58(1) 
37.40(3) 
11.60(14) 
14.62(10) 
13.47(12) 
32.26(4) 
cardio 
66.06(2) 
62.89(3) 
23.79(13) 
61.95(4) 
28.67(11) 
52.10(8) 
40.72(9) 
28.54(12) 
60.42(5) 
68.59(1) 
22.50(14) 
28.92(10) 
53.41(7) 
59.95(6) 
Cardiotocography 
47.95(3) 
52.61(1) 
30.66(11) 
45.44(4) 
28.21(13) 
38.28(8) 
34.79(9) 
27.99(14) 
40.46(7) 
43.57(5) 
34.03(10) 
30.61(12) 
48.00(2) 
41.47(6) 
celeba 
15.89(1) 
10.73(6) 
1.71(14) 
11.33(5) 
1.77(13) 
13.82(2) 
3.14(9) 
2.66(10) 
13.69(3) 
12.37(4) 
2.34(11) 
1.95(12) 
4.04(8) 
8.96(7) 
census 
10.02(1) 
6.76(11) 
5.45(12) 
7.44(9) 
4.88(14) 
8.69(6) 
9.00(4) 
8.52(7) 
9.92(2) 
9.72(3) 
6.87(10) 
8.71(5) 
5.01(13) 
7.78(8) 
cover 
9.80(6) 
11.41(4) 
8.12(8) 
5.83(12) 
4.00(13) 
6.83(10) 
6.16(11) 
3.88(14) 
11.37(5) 
15.63(2) 
8.12(9) 
27.59(1) 
13.06(3) 
8.85(7) 
donors 
17.90(3) 
9.86(8) 
7.88(11) 
6.89(12) 
8.80(10) 
23.36(1) 
14.75(4) 
9.69(9) 
21.58</p>
<p>Table D6 :
D6AUCROC of 16 label-informed algorithms on 57 benchmark datasets, with labeled anomaly 
ratio γ l = 1%. We show the performance rank in parenthesis (lower the better), and mark the best 
performing method(s) in bold. </p>
<p>Datasets 
GANomaly 
DeepSAD 
REPEN 
DevNet 
PReNet 
FEAWAD 
XGBOD 
NB 
SVM 
MLP 
ResNet 
FTTrans 
former 
RF 
LGB 
XGB 
CatB </p>
<p>ALOI 
55.53(3) 
59.13(2) 
54.53(5) 
47.03(15) 
46.47(16) 
55.06(4) 
60.53(1) 
49.31(13) 
52.42(8) 
48.50(14) 
49.89(12) 
51.74(9) 
51.04(10) 
50.60(11) 
53.08(7) 
53.22(6) 
annthyroid 
75.67(9) 
76.82(7) 
72.20(11) 
74.78(10) 
75.95(8) 
77.66(5) 
92.89(2) 
80.62(4) 
59.25(15) 
62.84(12) 
52.04(16) 
76.97(6) 
60.93(14) 
62.62(13) 
89.91(3) 
95.58(1) 
backdoor 
82.28(9) 
91.98(3) 
89.44(5) 
92.91(2) 
94.23(1) 
82.60(7) 
85.67(6) 
63.10(13) 
80.03(10) 
89.69(4) 
71.15(12) 
62.89(14) 
58.05(15) 
37.26(16) 
82.55(8) 
76.47(11) 
breastw 
91.99(3) 
88.36(5) 
86.03(7) 
74.61(10) 
69.24(12) 
78.39(9) 
86.57(6) 
52.11(16) 
71.27(11) 
52.59(15) 
53.60(14) 
95.70(2) 
65.01(13) 
90.20(4) 
84.81(8) 
97.30(1) 
campaign 
56.58(12) 
64.32(7) 
57.57(11) 
66.20(6) 
67.62(5) 
58.45(10) 
74.21(2) 
51.87(14) 
47.20(16) 
60.69(9) 
49.37(15) 
61.16(8) 
56.28(13) 
68.27(4) 
73.81(3) 
81.61(1) 
cardio 
82.03(6) 
69.21(12) 
83.07(5) 
89.74(2) 
87.54(3) 
79.57(8) 
83.94(4) 
58.89(15) 
79.91(7) 
61.55(14) 
N/A(N/A) 
75.38(9) 
63.98(13) 
73.56(11) 
74.67(10) 
94.01(1) 
Cardiotocography 
53.99(15) 
64.94(12) 
81.22(3) 
81.91(2) 
79.33(4) 
70.67(10) 
71.54(9) 
76.00(7) 
54.85(14) 
48.18(16) 
65.16(11) 
76.31(6) 
60.95(13) 
75.31(8) 
78.81(5) 
85.89(1) 
celeba 
81.23(2) 
54.65(14) 
54.85(13) 
73.84(5) 
71.65(6) 
71.59(7) 
74.86(4) 
50.71(15) 
55.00(11) 
62.62(8) 
59.78(9) 
55.63(10) 
54.91(12) 
29.53(16) 
78.00(3) 
81.50(1) 
census 
58.91(12) 
60.87(11) 
68.18(8) 
73.80(5) 
66.57(10) 
67.16(9) 
77.20(3) 
50.66(16) 
54.87(14) 
76.76(4) 
51.06(15) 
70.22(7) 
58.28(13) 
71.26(6) 
79.67(2) 
84.53(1) 
cover 
42.98(16) 
87.11(9) 
98.60(4) 
99.04(2) 
98.63(3) 
86.37(10) 
92.92(8) 
50.00(14) 
80.88(11) 
93.84(7) 
62.00(13) 
99.80(1) 
62.41(12) 
43.18(15) 
96.09(6) 
97.90(5) 
donors 
49.17(15) 
97.54(4) 
82.72(10) 
99.71(2) 
99.89(1) 
96.82(6) 
95.52(8) 
95.34(9) 
0.89(16) 
70.69(12) 
60.51(13) 
97.89(3) 
60.49(14) 
77.58(11) 
96.18(7) 
96.98(5) 
fault 
63.88(2) 
67.84(1) 
63.79(3) 
61.70(4) 
61.19(6) 
56.16(8) 
54.62(10) 
61.26(5) 
39.48(16) 
47.40(14) 
47.10(15) 
55.25(9) 
53.37(13) 
53.89(12) 
53.98(11) 
60.88(7) 
fraud 
90.52(5) 
87.66(9) 
92.18(2) 
89.77(7) 
91.91(3) 
81.61(12) 
89.84(6) 
50.00(15) 
92.44(1) 
85.73(10) 
50.99(14) 
75.38(13) 
84.92(11) 
44.99(16) 
87.90(8) 
90.86(4) 
glass 
67.58(15) 
71.95(13) 
85.97(6) 
87.54(4) 
90.77(2) 
74.71(12) 
81.83(11) 
55.90(16) 
83.87(9) 
82.49(10) 
84.57(8) 
86.30(5) 
67.63(14) 
84.94(7) 
88.63(3) 
91.09(1) 
Hepatitis 
56.31(13) 
62.67(11) 
70.29(7) 
68.49(9) 
69.21(8) 
50.98(15) 
76.56(4) 
53.62(14) 
50.00(16) 
74.39(6) 
67.50(10) 
74.76(5) 
56.31(12) 
82.29(2) 
80.78(3) 
83.14(1) 
http 
99.80(9) 
99.88(8) 
99.98(7) 
100.00(1) 
100.00(1) 
99.99(6) 
99.78(11) 
81.67(14) 
83.31(13) 
0.10(16) 
100.00(1) 
100.00(5) 
83.33(12) 
42.47(15) 
100.00(1) 
99.79(10) 
InternetAds 
67.89(4) 
71.41(2) 
62.48(6) 
51.66(13) 
53.10(11) 
60.17(7) 
63.57(5) 
50.28(14) 
57.56(8) 
42.13(15) 
51.93(12) 
N/A(N/A) 
54.25(10) 
55.15(9) 
69.52(3) 
77.18(1) 
Ionosphere 
91.98(1) 
73.84(9) 
77.56(3) 
55.28(13) 
54.48(14) 
50.28(16) 
75.87(5) 
50.75(15) 
74.22(7) 
74.09(8) 
64.41(11) 
65.63(10) 
59.44(12) 
74.91(6) 
77.37(4) 
87.27(2) 
landsat 
45.19(16) 
74.50(3) 
57.12(14) 
70.89(7) 
73.67(4) 
64.90(11) 
76.46(2) 
73.59(5) 
56.48(15) 
69.12(8) 
59.53(13) 
71.78(6) 
60.09(12) 
68.47(9) 
67.12(10) 
80.98(1) 
letter 
69.52(4) 
72.18(2) 
59.98(6) 
50.85(12) 
50.54(13) 
54.87(9) 
71.41(3) 
50.00(14) 
48.39(15) 
41.45(16) 
74.71(1) 
51.19(11) 
54.16(10) 
57.03(8) 
58.71(7) 
63.54(5) 
Lymphography 
96.80(4) 
80.40(10) 
93.63(7) 
80.56(9) 
78.14(11) 
82.39(8) 
98.73(2) 
66.78(14) 
50.00(16) 
62.50(15) 
77.79(12) 
94.88(6) 
72.04(13) 
97.25(3) 
95.89(5) 
99.65(1) 
magic.gamma 
52.62(14) 
76.58(6) 
73.47(7) 
80.89(1) 
80.46(2) 
70.00(11) 
76.70(5) 
77.04(4) 
50.99(16) 
53.69(13) 
51.56(15) 
77.36(3) 
59.53(12) 
72.14(9) 
70.33(10) 
72.51(8) 
mammography 
77.28(8) 
84.40(6) 
88.92(3) 
88.57(4) 
84.47(5) 
89.16(2) 
78.78(7) 
73.34(10) 
60.78(13) 
19.48(16) 
61.43(12) 
77.23(9) 
58.85(14) 
39.41(15) 
66.95(11) 
89.83(1) 
mnist 
69.68(11) 
75.32(8) 
79.96(5) 
78.71(7) 
79.73(6) 
71.04(10) 
88.35(2) 
64.07(14) 
69.29(12) 
85.93(3) 
67.36(13) 
74.27(9) 
64.05(15) 
61.14(16) 
80.02(4) 
91.19(1) 
musk 
99.12(3) 
86.41(11) 
84.71(12) 
88.19(10) 
99.75(1) 
88.26(9) 
89.38(8) 
50.00(15) 
43.08(16) 
95.16(6) 
96.23(5) 
97.39(4) 
63.78(13) 
55.51(14) 
89.42(7) 
99.44(2) 
optdigits 
45.68(15) 
84.32(10) 
99.23(4) 
99.93(1) 
99.71(2) 
99.39(3) 
94.15(8) 
50.74(14) 
87.83(9) 
82.84(11) 
67.12(13) 
98.55(5) 
75.39(12) 
43.88(16) 
94.92(7) 
96.46(6) 
PageBlocks 
74.79(6) 
84.76(4) 
88.50(2) 
70.47(8) 
73.14(7) 
61.84(12) 
83.79(5) 
64.43(11) 
53.97(14) 
36.07(16) 
37.37(15) 
70.32(9) 
55.59(13) 
65.55(10) 
86.54(3) 
93.81(1) 
pendigits 
55.69(12) 
82.47(7) 
86.56(4) 
87.20(3) 
82.95(6) 
68.54(10) 
84.71(5) 
55.56(13) 
49.41(14) 
74.99(9) 
45.87(15) 
87.79(2) 
60.46(11) 
43.88(16) 
77.76(8) 
89.96(1) 
Pima 
59.71(8) 
58.30(10) 
67.54(2) 
59.88(7) 
58.30(11) 
58.78(9) 
64.07(3) 
56.31(12) 
48.99(15) 
23.38(16) 
54.05(14) 
63.06(4) 
54.29(13) 
62.21(5) 
61.70(6) 
71.28(1) 
satellite 
68.69(13) 
78.70(6) 
75.58(8) 
82.60(1) 
81.44(2) 
77.99(7) 
80.29(4) 
78.99(5) 
55.48(16) 
75.44(9) 
59.20(15) 
75.09(10) 
64.68(14) 
73.73(11) 
70.75(12) 
80.40(3) 
satimage-2 
96.55(7) 
95.66(9) 
96.40(8) 
98.37(3) 
98.44(2) 
97.99(4) 
97.86(5) 
50.00(14) 
47.99(15) 
79.10(12) 
94.53(11) 
96.78(6) 
69.75(13) 
40.98(16) 
94.64(10) 
98.77(1) 
shuttle 
73.14(14) 
98.80(2) 
98.92(1) 
97.62(8) 
97.80(6) 
98.13(5) 
98.76(4) 
93.12(10) 
92.87(11) 
48.11(16) 
92.43(12) 
97.74(7) 
57.76(15) 
74.26(13) 
96.18(9) 
98.77(3) 
skin 
52.14(16) 
96.98(5) 
92.43(12) 
95.38(7) 
95.03(9) 
96.42(6) 
91.98(13) 
93.22(10) 
99.74(1) 
92.72(11) 
97.14(4) 
97.84(3) 
57.37(15) 
76.50(14) 
95.34(8) 
99.02(2) 
smtp 
51.69(14) 
82.74(3) 
76.47(8) 
75.99(9) 
75.24(10) 
64.06(11) 
79.87(5) 
50.00(15) 
62.98(12) 
86.40(1) 
52.83(13) 
79.07(6) 
83.32(2) 
43.01(16) 
81.12(4) 
78.85(7) 
SpamBase 
53.46(14) 
58.01(13) 
75.55(8) 
83.90(2) 
80.46(4) 
62.61(11) 
77.84(5) 
67.52(10) 
36.27(16) 
69.28(9) 
47.11(15) 
81.04(3) 
58.96(12) 
75.70(6) 
75.64(7) 
84.57(1) 
speech 
47.46(14) 
52.35(7) 
52.03(8) 
56.06(3) 
58.16(1) 
53.12(5) 
54.63(4) 
50.00(12) 
58.15(2) 
46.78(15) 
50.35(10) 
53.02(6) 
49.52(13) 
50.30(11) 
44.69(16) 
51.54(9) 
Stamps 
71.87(9) 
63.28(13) 
88.76(2) 
84.81(5) 
84.88(4) 
67.60(10) 
81.48(6) 
51.19(16) 
67.00(12) 
54.56(15) 
72.83(8) 
89.04(1) 
55.40(14) 
67.26(11) 
80.95(7) 
86.75(3) 
thyroid 
92.36(6) 
91.81(7) 
98.53(2) 
96.75(4) 
97.78(3) 
89.02(10) 
91.16(9) 
50.00(15) 
54.16(14) 
71.35(11) 
56.02(13) 
91.64(8) 
59.84(12) 
42.36(16) 
94.80(5) 
98.57(1) 
vertebral 
36.95(16) 
53.66(11) 
45.66(15) 
64.09(6) 
66.15(3) 
70.46(1) 
60.27(8) 
51.66(13) 
64.57(5) 
66.93(2) 
55.40(10) 
58.59(9) 
50.48(14) 
60.27(7) 
64.76(4) 
53.56(12) 
vowels 
78.31(9) 
79.02(6) 
78.60(8) 
78.79(7) 
86.68(1) 
84.77(3) 
86.46(2) 
52.22(15) 
63.66(14) 
13.49(16) 
81.67(5) 
73.06(11) 
64.13(13) 
64.87(12) 
73.85(10) 
83.24(4) 
Waveform 
53.14(11) 
63.29(7) 
58.57(9) 
73.37(1) 
70.59(2) 
51.49(15) 
67.01(5) 
50.00(16) 
58.74(8) 
57.57(10) 
69.15(3) 
67.55(4) 
52.23(13) 
52.81(12) 
51.77(14) 
66.29(6) 
WBC 
93.28(8) 
93.20(9) 
97.59(5) 
98.77(1) 
98.25(4) 
87.79(10) 
96.44(7) 
54.52(16) 
58.43(15) 
63.64(14) 
80.39(11) 
98.65(2) 
65.35(13) 
75.76(12) 
97.11(6) 
98.63(3) 
WDBC 
97.52(7) 
90.44(11) 
98.81(5) 
99.91(1) 
99.82(3) 
99.76(4) 
95.24(10) 
56.02(15) 
61.79(14) 
0.45(16) 
82.49(13) 
99.87(2) 
90.15(12) 
95.27(9) 
95.46(8) 
98.49(6) 
Wilt 
42.80(16) 
63.86(9) 
44.02(15) 
65.31(7) 
66.26(5) 
59.60(10) 
59.39(11) 
66.89(4) 
72.34(1) 
65.67(6) 
70.32(2) 
58.73(12) 
53.51(13) 
52.71(14) 
66.94(3) 
65.08(8) 
wine 
65.53(11) 
64.33(12) 
95.95(5) 
99.98(2) 
100.00(1) 
96.11(4) 
90.23(8) 
56.18(14) 
50.00(15) 
2.79(16) 
80.56(9) 
98.92(3) 
58.21(13) 
79.38(10) 
93.41(6) 
91.60(7) 
WPBC 
47.57(15) 
50.38(11) 
49.88(13) 
60.50(2) 
60.73(1) 
56.13(3) 
52.14(8) 
53.41(6) 
50.00(12) 
46.33(16) 
54.05(4) 
53.46(5) 
52.25(7) 
51.51(10) 
51.82(9) 
47.78(14) 
yeast 
49.88(14) 
50.62(12) 
44.59(15) 
59.06(4) 
58.75(5) 
54.13(7) 
55.95(6) 
59.50(3) 
61.90(1) 
53.99(8) 
44.38(16) 
60.48(2) 
52.26(11) 
52.77(9) 
50.26(13) 
52.55(10) 
CIFAR10 
60.30(9) 
61.10(7) 
62.48(4) 
59.91(11) 
57.78(13) 
60.95(8) 
64.46(3) 
50.00(16) 
61.20(6) 
59.75(12) 
60.08(10) 
61.47(5) 
51.21(15) 
55.50(14) 
64.58(2) 
67.54(1) 
FashionMNIST 
80.12(5) 
83.18(3) 
76.44(7) 
72.02(8) 
71.75(9) 
77.27(6) 
84.64(2) 
50.00(16) 
57.06(12) 
69.27(10) 
53.52(14) 
65.75(11) 
53.60(13) 
50.61(15) 
82.65(4) 
87.70(1) 
MNIST-C 
74.58(11) 
78.48(9) 
80.96(6) 
88.04(1) 
84.59(4) 
75.28(10) 
85.34(2) 
50.24(15) 
61.88(13) 
79.90(7) 
47.11(16) 
78.58(8) 
63.60(12) 
58.72(14) 
83.45(5) 
85.24(3) 
MVTec-AD 
74.00(2) 
64.46(4) 
72.87(3) 
63.16(8) 
63.40(5) 
60.73(12) 
63.34(7) 
50.90(16) 
51.27(15) 
60.85(11) 
55.02(14) 
61.29(9) 
58.09(13) 
61.21(10) 
63.40(6) 
76.12(1) 
SVHN 
57.82(8) 
57.72(9) 
60.05(2) 
59.96(3) 
55.45(10) 
58.74(7) 
59.45(5) 
50.05(16) 
50.52(15) 
55.36(11) 
55.21(12) 
59.45(4) 
51.25(14) 
54.89(13) 
59.20(6) 
62.12(1) 
Agnews 
59.31(12) 
63.27(10) 
72.66(3) 
75.06(2) 
75.96(1) 
64.79(9) 
68.87(5) 
53.39(15) 
68.81(6) 
61.65(11) 
69.53(4) 
57.97(13) 
50.77(16) 
55.93(14) 
68.80(7) 
68.28(8) 
Amazon 
58.47(12) 
59.22(11) 
62.62(7) 
74.64(2) 
74.67(1) 
66.65(3) 
64.47(6) 
50.85(14) 
33.95(16) 
58.21(13) 
65.01(5) 
60.04(8) 
50.67(15) 
59.30(10) 
65.94(4) 
59.76(9) 
Imdb 
49.34(16) 
53.36(11) 
57.98(8) 
66.07(1) 
64.51(2) 
58.60(6) 
59.85(5) 
53.55(10) 
58.49(7) 
52.57(12) 
63.23(4) 
52.09(14) 
49.99(15) 
54.11(9) 
63.44(3) 
52.45(13) 
Yelp 
67.92(8) 
60.66(12) 
69.83(5) 
77.80(1) 
73.99(2) 
71.38(3) 
69.12(7) 
57.20(13) 
45.28(16) 
63.45(10) 
67.11(9) 
61.20(11) 
51.06(15) 
56.82(14) 
69.65(6) 
70.12(4) 
20news 
57.29(4) 
57.86(3) 
56.65(6) 
60.43(1) 
59.18(2) 
54.79(10) 
56.13(7) 
50.04(15) 
53.99(13) 
56.97(5) 
55.55(9) 
49.65(16) 
54.50(11) 
53.89(14) 
54.48(12) 
55.69(8) </p>
<p>Table D7 :
D7AUCPR of 16 label-informed algorithms on 57 benchmark datasets, with labeled anomaly 
ratio γ l = 1%. We show the performance rank in parenthesis (lower the better), and mark the best 
performing method(s) in bold. </p>
<p>Datasets 
GANomaly 
DeepSAD 
REPEN 
DevNet 
PReNet 
FEAWAD 
XGBOD 
NB 
SVM 
MLP 
ResNet 
FTTrans 
former 
RF 
LGB 
XGB 
CatB </p>
<p>ALOI 
3.83(14) 
6.10(2) 
4.51(6) 
3.76(15) 
3.86(13) 
4.56(4) 
6.68(1) 
3.29(16) 
4.99(3) 
4.08(11) 
4.33(7) 
3.95(12) 
4.25(8) 
4.12(9) 
4.08(10) 
4.53(5) 
annthyroid 
34.35(5) 
29.25(9) 
27.38(11) 
31.79(8) 
33.92(6) 
32.05(7) 
65.84(1) 
43.64(4) 
13.79(15) 
12.99(16) 
15.88(14) 
29.12(10) 
22.34(12) 
21.96(13) 
54.84(3) 
61.79(2) 
backdoor 
6.95(16) 
38.49(7) 
28.84(10) 
87.83(1) 
86.20(2) 
68.50(4) 
25.79(12) 
28.06(11) 
51.54(5) 
71.48(3) 
34.99(8) 
33.83(9) 
16.55(14) 
10.42(15) 
42.00(6) 
19.24(13) 
breastw 
85.14(3) 
79.62(9) 
81.19(7) 
77.74(10) 
72.83(12) 
80.86(8) 
83.82(5) 
54.37(14) 
76.04(11) 
56.04(13) 
51.70(16) 
90.82(2) 
54.04(15) 
85.12(4) 
81.93(6) 
93.23(1) 
campaign 
23.13(7) 
19.87(9) 
15.09(13) 
23.18(6) 
23.62(5) 
20.35(8) 
32.98(2) 
11.83(16) 
13.13(15) 
19.21(10) 
13.51(14) 
18.71(11) 
16.55(12) 
25.70(4) 
28.63(3) 
36.63(1) 
cardio 
38.52(10) 
30.03(12) 
54.24(4) 
66.86(2) 
63.47(3) 
52.19(5) 
50.41(6) 
20.48(14) 
41.60(9) 
14.11(15) 
N/A(N/A) 
48.60(7) 
29.30(13) 
42.16(8) 
36.18(11) 
70.42(1) 
Cardiotocography 
33.18(15) 
40.99(12) 
58.09(5) 
61.74(2) 
58.84(4) 
52.60(9) 
46.13(10) 
53.30(7) 
37.51(13) 
21.50(16) 
46.12(11) 
59.03(3) 
34.71(14) 
52.95(8) 
55.45(6) 
65.09(1) 
celeba 
11.72(6) 
3.79(13) 
2.94(15) 
15.19(1) 
14.62(2) 
14.47(3) 
11.64(7) 
2.64(16) 
7.71(9) 
7.51(10) 
7.81(8) 
6.87(11) 
5.46(12) 
3.10(14) 
14.31(4) 
12.62(5) 
census 
7.47(15) 
9.57(13) 
9.88(12) 
19.70(6) 
18.33(9) 
19.76(5) 
27.07(3) 
6.71(16) 
13.22(10) 
19.66(7) 
8.87(14) 
19.01(8) 
12.47(11) 
21.98(4) 
30.88(1) 
30.59(2) 
cover 
0.89(16) 
24.22(10) 
58.34(6) 
68.57(2) 
65.28(3) 
51.36(7) 
58.61(5) 
1.02(15) 
18.12(11) 
35.14(9) 
15.24(13) 
81.57(1) 
15.73(12) 
1.04(14) 
62.00(4) 
38.30(8) 
donors 
9.68(15) 
79.14(6) 
17.03(14) 
90.73(3) 
98.08(1) 
94.62(2) 
60.93(9) 
84.66(5) 
3.07(16) 
20.07(13) 
36.26(11) 
85.13(4) 
23.75(12) 
38.36(10) 
68.71(8) 
72.67(7) 
fault 
48.92(3) 
49.92(1) 
49.84(2) 
48.46(5) 
48.91(4) 
44.25(9) 
43.21(10) 
45.17(7) 
29.76(16) 
35.17(15) 
36.23(14) 
44.88(8) 
38.52(13) 
43.06(11) 
42.53(12) 
47.30(6) 
fraud 
42.43(6) 
28.00(13) 
42.35(7) 
52.80(3) 
55.13(1) 
54.48(2) 
38.57(10) 
0.14(15) 
21.23(14) 
41.61(8) 
31.53(12) 
48.90(4) 
48.38(5) 
0.14(15) 
36.75(11) 
39.79(9) 
glass 
13.34(16) 
15.19(15) 
23.20(11) 
18.25(13) 
31.20(8) 
49.47(1) 
36.70(3) 
15.35(14) 
44.54(2) 
21.84(12) 
29.46(9) 
29.18(10) 
32.33(6) 
32.00(7) 
35.87(4) 
35.84(5) 
Hepatitis 
21.59(14) 
28.50(12) 
43.55(8) 
43.85(7) 
44.05(6) 
35.85(10) 
52.70(2) 
21.43(15) 
16.00(16) 
34.40(11) 
42.58(9) 
45.40(5) 
26.75(13) 
50.91(3) 
54.55(1) 
49.15(4) 
http 
73.48(11) 
74.48(10) 
93.99(7) 
100.00(1) 
100.00(1) 
97.78(6) 
80.39(8) 
63.50(13) 
61.84(14) 
0.37(16) 
100.00(1) 
99.70(5) 
66.27(12) 
0.38(15) 
100.00(1) 
77.95(9) 
InternetAds 
46.05(3) 
42.68(4) 
41.92(5) 
33.91(10) 
34.32(9) 
39.10(6) 
36.29(7) 
18.82(14) 
34.55(8) 
17.30(15) 
30.48(11) 
N/A(N/A) 
25.24(13) 
30.27(12) 
47.94(2) 
55.26(1) 
Ionosphere 
89.55(1) 
69.44(3) 
64.46(8) 
50.93(13) 
53.97(12) 
49.57(14) 
65.38(6) 
46.42(16) 
63.89(9) 
68.45(4) 
57.52(11) 
57.75(10) 
48.79(15) 
65.26(7) 
66.24(5) 
82.86(2) 
landsat 
18.28(16) 
45.05(4) 
28.74(15) 
37.63(9) 
37.40(11) 
39.89(7) 
50.99(2) 
39.34(8) 
32.44(12) 
45.06(3) 
31.81(13) 
37.61(10) 
30.74(14) 
40.65(6) 
44.72(5) 
53.27(1) 
letter 
15.94(4) 
18.33(3) 
13.33(9) 
14.25(7) 
14.87(5) 
14.36(6) 
18.55(2) 
6.25(16) 
12.38(10) 
7.45(15) 
28.06(1) 
8.07(13) 
7.87(14) 
13.46(8) 
11.80(11) 
11.44(12) 
Lymphography 
65.66(6) 
43.96(14) 
62.57(8) 
60.68(10) 
57.53(11) 
63.50(7) 
83.69(2) 
36.34(15) 
4.11(16) 
49.48(12) 
61.85(9) 
80.75(4) 
45.60(13) 
80.81(3) 
79.46(5) 
94.13(1) 
magic.gamma 
39.96(16) 
64.64(5) 
66.45(4) 
71.97(2) 
72.46(1) 
62.42(8) 
63.84(7) 
70.82(3) 
42.53(14) 
48.51(12) 
41.69(15) 
64.51(6) 
44.79(13) 
58.22(9) 
56.69(11) 
57.72(10) 
mammography 
15.75(13) 
32.24(7) 
40.20(4) 
40.49(3) 
36.69(6) 
53.56(1) 
23.52(10) 
29.90(8) 
18.01(12) 
1.37(16) 
22.86(11) 
42.24(2) 
12.30(14) 
2.44(15) 
28.94(9) 
37.72(5) 
mnist 
17.88(16) 
32.84(10) 
48.06(7) 
56.31(2) 
55.93(3) 
50.16(6) 
51.69(5) 
22.77(15) 
28.89(12) 
52.97(4) 
32.16(11) 
39.59(9) 
25.39(13) 
24.23(14) 
41.73(8) 
56.31(1) 
musk 
89.49(2) 
46.21(12) 
39.11(13) 
78.41(6) 
94.05(1) 
78.76(5) 
55.84(8) 
3.16(16) 
20.90(15) 
55.74(9) 
89.07(3) 
74.64(7) 
29.36(14) 
48.96(11) 
54.93(10) 
88.03(4) 
optdigits 
2.83(16) 
27.71(13) 
96.95(4) 
99.02(1) 
98.73(2) 
98.69(3) 
48.64(8) 
4.31(14) 
35.64(10) 
38.83(9) 
29.25(12) 
93.10(5) 
33.03(11) 
3.15(15) 
57.85(6) 
57.02(7) 
PageBlocks 
41.22(7) 
51.76(3) 
57.34(2) 
40.91(8) 
45.31(6) 
33.40(12) 
47.12(5) 
34.27(11) 
26.74(13) 
20.62(15) 
20.93(14) 
39.79(9) 
17.00(16) 
34.30(10) 
49.13(4) 
67.14(1) 
pendigits 
2.80(15) 
27.59(8) 
46.66(4) 
53.88(2) 
57.07(1) 
41.55(5) 
34.75(6) 
13.37(13) 
24.20(10) 
9.47(14) 
27.38(9) 
48.91(3) 
19.12(12) 
2.25(16) 
30.29(7) 
23.01(11) 
Pima 
43.77(11) 
44.26(10) 
50.96(2) 
45.76(7) 
44.44(9) 
42.87(12) 
50.02(3) 
44.93(8) 
37.15(15) 
23.61(16) 
41.13(13) 
47.15(6) 
38.80(14) 
47.18(5) 
47.40(4) 
53.50(1) 
satellite 
65.05(10) 
67.43(9) 
71.23(5) 
79.41(1) 
77.14(2) 
75.32(3) 
70.55(6) 
73.20(4) 
44.82(16) 
60.43(12) 
50.63(14) 
70.54(7) 
48.47(15) 
60.63(11) 
58.41(13) 
70.24(8) 
satimage-2 
43.15(10) 
40.06(11) 
85.70(7) 
89.99(3) 
92.20(2) 
94.21(1) 
46.18(9) 
1.21(16) 
30.29(13) 
2.87(15) 
78.32(8) 
88.59(5) 
33.82(12) 
9.10(14) 
85.77(6) 
88.73(4) 
shuttle 
46.19(14) 
96.40(4) 
97.27(1) 
96.52(2) 
96.50(3) 
96.39(5) 
95.52(7) 
90.40(10) 
86.80(12) 
25.53(15) 
88.44(11) 
96.06(6) 
20.75(16) 
54.32(13) 
91.09(9) 
94.95(8) 
skin 
21.98(16) 
83.45(8) 
58.19(14) 
68.55(10) 
66.43(11) 
87.83(5) 
77.24(9) 
84.91(6) 
98.57(1) 
60.08(13) 
94.57(3) 
88.78(4) 
31.08(15) 
61.98(12) 
83.77(7) 
95.74(2) 
smtp 
21.46(12) 
61.13(2) 
41.68(7) 
50.02(4) 
66.68(1) 
25.12(11) 
50.02(3) 
0.04(15) 
17.73(13) 
38.92(8) 
11.71(14) 
33.94(9) 
50.01(5) 
0.04(15) 
50.01(5) 
28.13(10) 
SpamBase 
40.69(15) 
45.89(13) 
63.07(8) 
75.16(2) 
72.64(3) 
60.04(9) 
68.17(5) 
53.63(11) 
34.12(16) 
56.96(10) 
43.22(14) 
71.31(4) 
48.87(12) 
66.16(7) 
67.01(6) 
76.82(1) 
speech 
1.61(15) 
2.44(5) 
2.41(6) 
3.00(3) 
2.97(4) 
3.15(2) 
2.06(7) 
1.63(14) 
3.48(1) 
1.81(11) 
1.89(10) 
1.93(9) 
1.65(13) 
1.69(12) 
1.50(16) 
2.04(8) 
Stamps 
29.94(9) 
15.90(15) 
53.59(1) 
48.27(4) 
49.94(3) 
38.55(6) 
27.26(10) 
11.60(16) 
39.29(5) 
18.26(13) 
26.67(11) 
52.80(2) 
15.95(14) 
24.17(12) 
30.14(8) 
34.72(7) 
thyroid 
53.25(8) 
38.94(10) 
79.14(2) 
74.23(3) 
79.44(1) 
62.31(5) 
45.13(9) 
2.47(15) 
12.08(14) 
17.01(12) 
21.29(11) 
57.06(7) 
13.43(13) 
2.47(15) 
73.72(4) 
58.56(6) 
vertebral 
10.60(16) 
16.44(13) 
20.03(11) 
31.27(2) 
30.37(3) 
38.38(1) 
20.29(10) 
15.98(14) 
21.77(8) 
18.80(12) 
24.05(6) 
20.58(9) 
15.98(14) 
26.33(5) 
28.37(4) 
23.74(7) 
vowels 
24.96(10) 
18.93(14) 
29.27(8) 
34.85(6) 
38.61(2) 
42.34(1) 
34.97(5) 
7.72(15) 
20.88(13) 
2.02(16) 
37.55(4) 
24.53(11) 
23.54(12) 
26.69(9) 
29.55(7) 
38.45(3) 
Waveform 
4.44(10) 
12.50(2) 
4.50(9) 
9.00(3) 
6.65(7) 
3.73(14) 
7.21(4) 
2.90(16) 
5.54(8) 
4.17(13) 
13.56(1) 
6.82(5) 
3.50(15) 
4.38(11) 
4.20(12) 
6.74(6) 
WBC 
42.31(12) 
56.30(10) 
73.49(6) 
83.17(2) 
81.48(4) 
68.44(7) 
65.07(8) 
12.94(16) 
13.72(15) 
34.75(13) 
46.09(11) 
81.78(3) 
28.14(14) 
60.18(9) 
86.33(1) 
76.80(5) 
WDBC 
59.54(11) 
39.38(13) 
91.29(5) 
98.21(1) 
96.59(3) 
94.21(4) 
68.19(10) 
14.48(14) 
10.09(15) 
1.64(16) 
44.39(12) 
97.13(2) 
78.80(7) 
88.39(6) 
74.97(9) 
77.12(8) 
Wilt 
4.60(16) 
9.71(8) 
5.07(15) 
8.33(10) 
8.23(11) 
10.67(7) 
12.08(5) 
11.15(6) 
12.45(4) 
8.00(12) 
22.71(1) 
7.12(14) 
8.56(9) 
7.61(13) 
15.87(3) 
17.13(2) 
wine 
14.75(14) 
18.73(13) 
83.97(5) 
99.85(2) 
100.00(1) 
92.74(3) 
59.74(7) 
19.47(12) 
8.11(15) 
4.72(16) 
45.56(10) 
91.62(4) 
23.51(11) 
59.17(8) 
77.45(6) 
53.41(9) 
WPBC 
22.57(15) 
27.27(13) 
29.49(7) 
33.66(3) 
34.91(2) 
32.97(4) 
29.67(6) 
29.23(9) 
23.00(14) 
22.31(16) 
37.53(1) 
31.41(5) 
28.75(11) 
29.39(8) 
29.14(10) 
27.87(12) 
yeast 
33.70(14) 
33.95(13) 
32.36(16) 
41.43(5) 
40.74(6) 
38.78(7) 
41.68(3) 
41.84(2) 
43.43(1) 
34.25(12) 
32.88(15) 
41.49(4) 
35.62(11) 
36.72(9) 
36.05(10) 
36.73(8) 
CIFAR10 
9.20(12) 
9.16(13) 
11.62(8) 
13.02(3) 
12.66(7) 
13.67(1) 
13.31(2) 
5.00(16) 
12.80(6) 
10.29(10) 
9.82(11) 
10.54(9) 
5.71(15) 
8.04(14) 
12.80(5) 
12.91(4) 
FashionMNIST 
21.07(11) 
32.45(7) 
26.71(10) 
39.41(4) 
39.84(3) 
45.76(1) 
40.81(2) 
5.01(16) 
15.81(13) 
31.85(8) 
17.53(12) 
27.08(9) 
9.33(15) 
11.47(14) 
38.78(5) 
36.64(6) 
MNIST-C 
22.44(12) 
29.20(10) 
38.69(9) 
64.55(1) 
60.66(2) 
48.14(5) 
50.35(3) 
5.39(16) 
23.36(11) 
48.01(6) 
10.85(15) 
42.30(8) 
22.23(13) 
12.95(14) 
48.65(4) 
46.00(7) 
MVTec-AD 
57.38(2) 
45.33(5) 
55.41(3) 
44.41(7) 
44.31(8) 
44.85(6) 
42.43(10) 
25.76(16) 
28.76(15) 
43.84(9) 
35.13(14) 
47.87(4) 
35.63(13) 
42.25(11) 
41.85(12) 
60.55(1) 
SVHN 
8.12(11) 
7.70(12) 
10.36(5) 
12.08(1) 
10.45(4) 
11.13(2) 
10.31(6) 
5.07(16) 
7.16(14) 
8.67(9) 
8.50(10) 
11.12(3) 
5.55(15) 
7.69(13) 
10.25(7) 
10.22(8) 
Agnews 
6.74(14) 
10.92(9) 
16.93(4) 
25.45(2) 
26.51(1) 
20.22(3) 
13.70(7) 
5.78(15) 
16.41(5) 
9.48(11) 
15.02(6) 
7.93(13) 
5.31(16) 
8.30(12) 
13.26(8) 
9.54(10) 
Amazon 
6.19(13) 
7.32(10) 
9.62(6) 
16.14(2) 
17.30(1) 
13.57(3) 
9.05(7) 
5.51(14) 
3.57(16) 
7.12(11) 
13.17(4) 
8.67(8) 
5.22(15) 
8.36(9) 
9.97(5) 
6.95(12) 
Imdb 
4.88(16) 
6.09(10) 
7.73(8) 
9.40(1) 
8.95(3) 
7.80(7) 
8.08(6) 
5.66(13) 
9.00(2) 
5.79(11) 
8.89(4) 
5.75(12) 
5.09(15) 
6.17(9) 
8.77(5) 
5.59(14) 
Yelp 
9.03(12) 
9.04(11) 
17.12(4) 
20.32(1) 
19.42(2) 
17.30(3) 
13.40(6) 
6.49(15) 
8.33(14) 
11.38(10) 
14.27(5) 
11.38(9) 
5.37(16) 
8.50(13) 
12.83(7) 
12.21(8) 
20news 
7.20(14) 
10.52(1) 
7.95(9) 
10.30(2) 
9.85(3) 
7.97(7) 
7.55(12) 
4.83(16) 
7.99(6) 
7.85(10) 
7.30(13) 
6.11(15) 
8.60(5) 
9.35(4) 
7.96(8) 
7.84(11) </p>
<p>Table D8 :
D8AUCROC of 16 label-informed algorithms on 57 benchmark datasets, with labeled anomaly ratio γ l = 5%. We show the performance rank in parenthesis (lower the better), and mark the best performing method(s) in bold.Datasets 
GANomaly 
DeepSAD 
REPEN 
DevNet 
PReNet 
FEAWAD 
XGBOD 
NB 
SVM 
MLP 
ResNet 
FTTrans 
former 
RF 
LGB 
XGB 
CatB </p>
<p>ALOI 
56.71(4) 
57.88(2) 
52.13(9) 
47.46(16) 
48.51(13) 
52.77(8) 
65.99(1) 
48.37(14) 
49.86(11) 
48.95(12) 
47.91(15) 
51.97(10) 
56.68(5) 
55.28(6) 
57.22(3) 
55.05(7) 
annthyroid 
76.22(14) 
79.92(11) 
78.91(12) 
81.64(10) 
82.42(7) 
89.05(6) 
97.24(2) 
81.99(9) 
49.80(16) 
71.31(15) 
77.35(13) 
95.13(4) 
82.25(8) 
93.14(5) 
95.24(3) 
98.51(1) 
backdoor 
81.81(12) 
95.13(3) 
89.33(10) 
95.58(2) 
94.37(4) 
96.80(1) 
91.07(8) 
79.06(13) 
86.80(11) 
93.12(7) 
66.31(16) 
89.84(9) 
76.68(14) 
76.63(15) 
93.34(6) 
94.34(5) 
breastw 
92.28(11) 
90.67(12) 
97.61(4) 
99.18(2) 
92.79(9) 
92.67(10) 
96.72(6) 
99.73(1) 
72.44(15) 
95.42(7) 
49.28(16) 
88.59(13) 
85.59(14) 
97.53(5) 
95.12(8) 
99.10(3) 
campaign 
64.43(14) 
69.71(10) 
57.88(16) 
81.03(5) 
80.65(6) 
71.01(8) 
88.41(2) 
69.02(11) 
68.58(12) 
70.18(9) 
59.17(15) 
67.08(13) 
72.78(7) 
84.86(4) 
86.48(3) 
88.89(1) 
cardio 
82.46(13) 
79.71(14) 
95.56(5) 
97.12(1) 
96.36(3) 
87.96(10) 
95.73(4) 
71.04(15) 
83.30(12) 
90.85(7) 
N/A(N/A) 
92.65(6) 
85.07(11) 
88.03(9) 
89.79(8) 
96.82(2) 
Cardiotocography 
54.77(16) 
81.24(12) 
89.88(3) 
91.17(1) 
90.73(2) 
81.89(10) 
83.73(8) 
86.77(5) 
80.19(13) 
84.67(6) 
60.64(15) 
81.73(11) 
79.49(14) 
83.03(9) 
84.55(7) 
89.12(4) 
celeba 
68.79(12) 
75.40(10) 
56.47(16) 
91.01(1) 
90.64(3) 
86.63(6) 
87.45(5) 
74.33(11) 
56.62(15) 
90.93(2) 
58.14(14) 
89.93(4) 
63.12(13) 
83.72(9) 
83.90(8) 
84.69(7) 
census 
59.66(14) 
69.05(13) 
69.20(12) 
81.03(5) 
75.34(10) 
76.32(8) 
87.48(2) 
57.28(15) 
79.56(6) 
75.94(9) 
56.06(16) 
78.81(7) 
70.47(11) 
83.37(4) 
88.04(1) 
86.81(3) 
cover 
44.46(16) 
94.43(9) 
99.69(2) 
99.47(4) 
99.47(3) 
91.01(11) 
97.18(6) 
96.92(7) 
89.40(12) 
96.38(8) 
68.67(14) 
99.92(1) 
84.32(13) 
57.48(15) 
94.08(10) 
99.24(5) 
donors 
68.62(15) 
99.92(4) 
82.81(13) 
99.99(1) 
99.95(3) 
99.99(2) 
99.59(7) 
99.42(8) 
64.53(16) 
99.62(6) 
95.70(11) 
99.90(5) 
77.22(14) 
95.13(12) 
97.90(10) 
99.29(9) 
fault 
64.26(12) 
68.76(4) 
68.70(5) 
67.54(7) 
66.67(9) 
62.94(14) 
69.30(3) 
63.65(13) 
62.06(15) 
66.07(10) 
50.92(16) 
66.99(8) 
65.00(11) 
69.68(2) 
68.15(6) 
72.02(1) 
fraud 
90.52(5) 
87.66(9) 
92.18(2) 
89.77(7) 
91.91(3) 
81.61(12) 
89.84(6) 
50.00(15) 
92.44(1) 
85.73(10) 
50.99(14) 
75.38(13) 
84.92(11) 
44.99(16) 
87.90(8) 
90.86(4) 
glass 
67.84(16) 
84.34(11) 
82.27(13) 
91.37(9) 
94.46(4) 
93.72(5) 
95.73(3) 
92.73(6) 
80.63(14) 
82.59(12) 
89.96(10) 
91.48(8) 
78.85(15) 
92.17(7) 
95.97(2) 
98.37(1) 
Hepatitis 
56.94(15) 
74.83(12) 
88.10(4) 
86.62(5) 
83.71(8) 
72.08(13) 
85.44(6) 
77.79(11) 
50.00(16) 
85.11(7) 
80.48(10) 
82.99(9) 
69.71(14) 
89.29(3) 
89.66(2) 
91.72(1) 
http 
99.80(11) 
99.90(10) 
99.98(8) 
100.00(1) 
100.00(1) 
99.99(7) 
98.33(12) 
98.33(12) 
83.31(14) 
0.14(16) 
100.00(1) 
100.00(1) 
100.00(6) 
39.87(15) 
100.00(1) 
99.97(9) 
InternetAds 
67.94(8) 
72.98(4) 
79.79(2) 
61.68(11) 
57.82(12) 
63.57(10) 
75.77(3) 
51.49(14) 
69.28(5) 
57.14(13) 
50.82(15) 
N/A(N/A) 
68.01(7) 
68.68(6) 
67.87(9) 
81.94(1) 
Ionosphere 
92.09(4) 
81.01(9) 
94.21(1) 
68.67(13) 
67.54(14) 
63.46(15) 
93.43(3) 
85.42(7) 
83.55(8) 
71.41(12) 
50.49(16) 
76.83(10) 
74.95(11) 
88.77(5) 
87.23(6) 
93.99(2) 
landsat 
46.33(16) 
85.54(4) 
59.84(15) 
77.78(12) 
78.32(11) 
81.22(7) 
87.34(2) 
71.02(13) 
79.27(10) 
80.25(8) 
66.81(14) 
86.98(3) 
79.52(9) 
84.70(5) 
82.67(6) 
88.44(1) 
letter 
69.64(4) 
73.09(3) 
66.43(5) 
65.01(7) 
63.18(11) 
64.18(8) 
83.13(1) 
48.83(14) 
40.02(16) 
42.09(15) 
76.96(2) 
59.82(13) 
62.33(12) 
65.92(6) 
63.80(9) 
63.50(10) 
Lymphography 
96.84(2) 
86.90(8) 
92.94(4) 
80.25(9) 
79.68(10) 
93.47(3) 
77.40(13) 
73.19(14) 
50.00(16) 
70.06(15) 
87.01(7) 
91.87(5) 
78.22(12) 
91.31(6) 
78.66(11) 
99.71(1) 
magic.gamma 
61.44(15) 
82.08(6) 
78.24(10) 
82.76(5) 
83.38(4) 
84.04(3) 
84.58(2) 
76.10(13) 
49.30(16) 
85.08(1) 
71.05(14) 
81.91(7) 
78.06(12) 
79.11(9) 
78.22(11) 
81.85(8) 
mammography 
75.46(13) 
90.90(6) 
91.90(3) 
92.90(2) 
93.17(1) 
91.28(4) 
87.22(10) 
87.26(9) 
69.49(16) 
89.65(8) 
77.88(12) 
90.80(7) 
72.62(14) 
71.32(15) 
86.44(11) 
91.15(5) 
mnist 
69.09(14) 
84.99(12) 
92.30(7) 
95.39(3) 
93.37(5) 
84.77(13) 
96.28(2) 
57.22(16) 
87.89(10) 
89.03(9) 
67.59(15) 
92.84(6) 
86.55(11) 
92.07(8) 
94.45(4) 
97.02(1) 
musk 
97.34(9) 
96.46(10) 
93.97(11) 
100.00(1) 
100.00(1) 
100.00(1) 
99.90(5) 
83.33(13) 
54.07(16) 
100.00(1) 
78.75(15) 
99.89(6) 
81.60(14) 
83.97(12) 
99.66(8) 
99.78(7) 
optdigits 
46.44(16) 
94.98(10) 
99.67(4) 
99.98(1) 
99.98(2) 
99.94(3) 
98.23(8) 
80.46(13) 
90.94(12) 
99.48(5) 
52.71(15) 
98.84(7) 
93.91(11) 
78.07(14) 
96.75(9) 
99.04(6) 
PageBlocks 
72.69(15) 
93.01(4) 
91.22(6) 
86.42(12) 
90.38(7) 
89.67(9) 
94.73(2) 
88.46(10) 
58.16(16) 
90.15(8) 
82.94(13) 
88.03(11) 
76.84(14) 
92.74(5) 
94.28(3) 
96.80(1) 
pendigits 
56.82(16) 
97.41(11) 
99.75(2) 
99.76(1) 
99.69(3) 
99.59(4) 
98.28(8) 
99.10(5) 
84.95(12) 
98.23(10) 
70.59(14) 
98.27(9) 
84.29(13) 
64.95(15) 
98.33(7) 
99.03(6) 
Pima 
60.11(13) 
63.23(12) 
73.18(4) 
78.02(1) 
76.43(2) 
63.55(11) 
69.92(8) 
71.13(6) 
47.99(15) 
32.37(16) 
51.59(14) 
68.69(9) 
67.36(10) 
71.80(5) 
70.80(7) 
73.80(3) 
satellite 
69.49(15) 
88.65(3) 
81.31(12) 
84.34(10) 
84.41(9) 
85.32(7) 
89.34(2) 
79.37(13) 
61.94(16) 
87.79(5) 
75.45(14) 
87.82(4) 
82.71(11) 
86.74(6) 
85.20(8) 
90.22(1) 
satimage-2 
96.60(10) 
98.11(3) 
97.79(7) 
98.03(4) 
97.82(6) 
98.55(2) 
97.83(5) 
91.43(12) 
65.61(15) 
96.65(9) 
85.08(14) 
96.99(8) 
87.97(13) 
50.02(16) 
93.66(11) 
98.93(1) 
shuttle 
77.41(16) 
98.71(4) 
98.83(3) 
97.57(8) 
97.69(7) 
97.29(11) 
99.73(1) 
94.63(14) 
97.04(13) 
97.49(9) 
97.97(6) 
97.44(10) 
78.01(15) 
97.16(12) 
98.00(5) 
98.85(2) 
skin 
52.78(16) 
99.41(4) 
90.56(14) 
95.72(11) 
95.24(12) 
98.56(8) 
99.22(5) 
94.89(13) 
99.60(3) 
97.23(10) 
99.83(1) 
99.06(6) 
78.23(15) 
99.00(7) 
98.53(9) 
99.72(2) 
smtp 
51.69(14) 
82.74(3) 
76.47(8) 
75.99(9) 
75.24(10) 
74.57(11) 
79.87(5) 
50.00(15) 
62.98(12) 
86.40(1) 
52.83(13) 
79.07(6) 
83.32(2) 
43.01(16) 
81.12(4) 
78.85(7) 
SpamBase 
53.66(16) 
70.72(13) 
83.55(8) 
90.24(3) 
90.87(2) 
79.04(11) 
89.24(4) 
79.84(10) 
68.44(14) 
87.16(6) 
54.44(15) 
87.75(5) 
78.45(12) 
84.84(7) 
82.86(9) 
91.87(1) 
speech 
47.49(15) 
53.11(11) 
53.13(10) 
62.36(3) 
63.60(1) 
54.61(7) 
58.20(4) 
49.88(14) 
63.40(2) 
50.39(13) 
53.45(9) 
56.61(6) 
47.39(16) 
51.71(12) 
56.82(5) 
53.58(8) 
Stamps 
72.13(14) 
74.61(12) 
95.30(3) 
94.14(5) 
96.07(2) 
79.40(10) 
95.09(4) 
83.22(9) 
54.66(16) 
75.90(11) 
71.39(15) 
91.02(6) 
73.95(13) 
84.90(8) 
87.03(7) 
96.07(1) 
thyroid 
92.65(11) 
95.21(10) 
99.55(1) 
99.50(3) 
99.50(2) 
99.42(4) 
98.89(7) 
96.53(8) 
71.37(14) 
85.18(12) 
51.29(16) 
99.35(5) 
78.61(13) 
71.20(15) 
95.76(9) 
98.99(6) 
vertebral 
37.14(16) 
61.49(13) 
55.86(15) 
77.65(4) 
77.24(5) 
77.20(7) 
69.29(11) 
81.21(3) 
71.90(9) 
67.05(12) 
69.77(10) 
81.88(1) 
56.29(14) 
73.50(8) 
81.65(2) 
77.22(6) 
vowels 
78.54(9) 
80.31(7) 
86.47(6) 
89.12(2) 
92.49(1) 
86.69(5) 
87.82(3) 
73.29(12) 
55.90(15) 
14.35(16) 
80.28(8) 
73.35(11) 
66.06(14) 
73.15(13) 
73.74(10) 
87.31(4) 
Waveform 
52.99(16) 
68.05(10) 
80.58(5) 
84.84(1) 
82.30(3) 
64.09(13) 
74.68(7) 
77.42(6) 
60.62(15) 
61.03(14) 
72.60(8) 
80.85(4) 
64.74(12) 
64.81(11) 
71.76(9) 
84.82(2) 
WBC 
92.78(7) 
94.96(6) 
97.88(5) 
98.38(2) 
98.28(3) 
68.09(14) 
74.32(12) 
65.00(15) 
58.91(16) 
76.82(10) 
72.86(13) 
97.98(4) 
81.68(8) 
81.23(9) 
76.14(11) 
98.61(1) 
WDBC 
97.52(7) 
90.44(11) 
98.81(5) 
99.91(1) 
99.82(3) 
99.73(4) 
95.24(10) 
56.02(15) 
61.79(14) 
0.45(16) 
82.49(13) 
99.87(2) 
90.15(12) 
95.27(9) 
95.46(8) 
98.49(6) 
Wilt 
38.88(16) 
81.89(4) 
49.93(15) 
67.91(12) 
68.39(10) 
80.51(6) 
83.57(3) 
74.33(9) 
79.01(8) 
65.79(13) 
87.83(2) 
64.93(14) 
68.20(11) 
80.75(5) 
80.35(7) 
89.99(1) 
wine 
65.76(14) 
82.24(12) 
99.91(3) 
100.00(1) 
100.00(1) 
99.82(5) 
88.29(11) 
95.82(7) 
50.00(15) 
3.90(16) 
88.46(10) 
99.82(4) 
73.73(13) 
89.63(9) 
94.27(8) 
99.20(6) 
WPBC 
47.66(15) 
55.28(13) 
57.32(10) 
68.74(2) 
69.92(1) 
57.00(11) 
61.95(6) 
55.92(12) 
44.53(16) 
54.06(14) 
64.60(3) 
60.63(7) 
60.11(8) 
57.48(9) 
62.26(5) 
64.39(4) 
yeast 
48.22(15) 
54.78(12) 
47.57(16) 
65.99(2) 
66.12(1) 
59.70(7) 
55.83(10) 
63.75(3) 
62.62(4) 
53.76(13) 
50.93(14) 
60.65(6) 
56.28(9) 
57.22(8) 
55.18(11) 
62.04(5) 
CIFAR10 
60.37(13) 
64.91(9) 
71.88(4) 
71.06(5) 
65.98(8) 
67.83(7) 
75.50(2) 
50.54(16) 
61.36(11) 
64.51(10) 
55.79(14) 
61.16(12) 
54.31(15) 
70.83(6) 
75.67(1) 
73.73(3) 
FashionMNIST 
79.87(10) 
86.83(6) 
87.79(5) 
88.59(4) 
86.04(7) 
81.73(9) 
91.92(1) 
52.53(16) 
68.13(13) 
74.74(12) 
62.50(14) 
77.93(11) 
61.54(15) 
83.07(8) 
90.37(2) 
90.15(3) 
MNIST-C 
74.58(14) 
85.83(7) 
82.41(12) 
93.29(1) 
91.68(2) 
87.72(6) 
90.87(3) 
60.20(16) 
83.56(10) 
84.27(8) 
60.69(15) 
84.12(9) 
82.86(11) 
82.09(13) 
90.65(4) 
88.24(5) 
MVTec-AD 
74.14(5) 
68.81(11) 
72.72(6) 
71.58(7) 
71.29(8) 
62.91(13) 
76.56(4) 
53.39(16) 
56.56(14) 
64.59(12) 
54.82(15) 
69.49(10) 
70.60(9) 
76.56(3) 
77.29(2) 
82.41(1) 
SVHN 
57.94(12) 
59.56(10) 
64.82(4) 
67.36(1) 
62.21(9) 
63.69(6) 
67.23(2) 
49.84(16) 
62.54(8) 
58.40(11) 
57.44(13) 
56.13(14) 
52.59(15) 
63.56(7) 
66.56(3) 
63.93(5) 
Agnews 
59.61(14) 
71.91(11) 
84.30(3) 
84.67(2) 
84.73(1) 
76.00(7) 
78.14(5) 
52.97(15) 
75.65(8) 
82.97(4) 
64.24(13) 
67.08(12) 
52.85(16) 
73.49(10) 
78.08(6) 
75.48(9) 
Amazon 
58.78(14) 
61.53(12) 
69.54(8) 
82.86(2) 
83.35(1) 
72.33(6) 
74.70(5) 
51.41(15) 
72.21(7) 
78.45(3) 
59.85(13) 
66.80(11) 
51.11(16) 
68.07(10) 
76.52(4) 
69.50(9) 
Imdb 
49.59(16) 
59.52(13) 
72.56(5) 
77.35(1) 
77.09(2) 
72.52(6) 
69.03(9) 
52.76(14) 
72.80(4) 
73.43(3) 
65.74(10) 
60.16(12) 
51.58(15) 
63.62(11) 
69.74(8) 
71.08(7) 
Yelp 
67.87(12) 
64.79(13) 
79.86(7) 
86.80(1) 
86.73(2) 
82.74(4) 
80.12(6) 
58.21(15) 
76.40(8) 
86.15(3) 
63.24(14) 
70.17(11) 
53.62(16) 
75.66(9) 
80.88(5) 
74.69(10) 
20news 
57.42(12) 
64.54(6) 
56.56(14) 
66.66(1) 
65.49(2) 
61.30(8) 
64.95(4) 
56.48(15) 
51.87(16) 
58.33(11) 
60.13(9) 
56.89(13) 
58.58(10) 
64.40(7) 
65.12(3) 
64.81(5) </p>
<p>Table D9 :
D9AUCPR of 16 label-informed algorithms on 57 benchmark datasets, with labeled anomaly ratio γ l = 5%. We show the performance rank in parenthesis (lower the better), and mark the best performing method(s) in bold.Datasets 
GANomaly 
DeepSAD 
REPEN 
DevNet 
PReNet 
FEAWAD 
XGBOD 
NB 
SVM 
MLP 
ResNet 
FTTrans 
former 
RF 
LGB 
XGB 
CatB </p>
<p>ALOI 
3.92(11) 
5.85(4) 
4.35(9) 
4.55(8) 
4.67(7) 
3.83(14) 
7.59(1) 
3.49(15) 
3.39(16) 
3.88(12) 
4.02(10) 
3.85(13) 
5.88(3) 
4.77(6) 
6.00(2) 
5.45(5) 
annthyroid 
36.68(12) 
37.97(11) 
36.09(14) 
43.73(8) 
43.73(9) 
51.83(6) 
77.54(2) 
42.73(10) 
11.84(16) 
25.83(15) 
36.36(13) 
76.62(3) 
49.66(7) 
64.75(5) 
72.25(4) 
78.01(1) 
backdoor 
7.05(16) 
62.79(7) 
28.48(15) 
88.48(3) 
88.58(2) 
88.99(1) 
61.12(8) 
30.12(14) 
51.30(9) 
85.62(4) 
42.59(13) 
74.80(5) 
43.47(12) 
47.18(11) 
63.30(6) 
50.67(10) 
breastw 
85.59(12) 
83.65(13) 
95.32(4) 
98.65(2) 
92.91(8) 
93.09(7) 
91.96(9) 
99.49(1) 
75.47(15) 
94.88(6) 
56.83(16) 
85.66(11) 
79.61(14) 
95.09(5) 
91.30(10) 
98.04(3) 
campaign 
23.50(14) 
26.68(10) 
15.33(16) 
39.15(6) 
39.32(5) 
29.98(8) 
47.53(1) 
24.15(12) 
24.90(11) 
27.35(9) 
20.49(15) 
23.76(13) 
31.65(7) 
43.55(4) 
44.55(3) 
46.68(2) 
cardio 
39.02(15) 
45.81(13) 
82.12(4) 
85.56(1) 
82.34(3) 
77.24(6) 
79.07(5) 
59.27(11) 
45.71(14) 
67.55(8) 
N/A(N/A) 
76.95(7) 
64.82(9) 
57.80(12) 
63.75(10) 
83.34(2) 
Cardiotocography 
33.71(16) 
60.87(12) 
75.22(3) 
76.46(1) 
75.97(2) 
64.45(8) 
62.98(10) 
73.90(4) 
55.11(14) 
65.29(6) 
45.15(15) 
63.22(9) 
58.32(13) 
61.57(11) 
64.77(7) 
70.42(5) 
celeba 
10.97(11) 
9.34(12) 
3.12(16) 
24.67(2) 
26.54(1) 
22.52(3) 
18.27(6) 
12.02(10) 
7.09(14) 
22.35(4) 
5.78(15) 
19.25(5) 
8.64(13) 
15.78(8) 
16.37(7) 
12.24(9) 
census 
7.65(16) 
15.02(12) 
10.07(14) 
29.48(5) 
25.59(6) 
25.55(7) 
34.55(2) 
9.40(15) 
22.77(8) 
20.63(10) 
13.12(13) 
19.57(11) 
22.59(9) 
34.12(3) 
36.65(1) 
33.00(4) 
cover 
0.91(16) 
71.12(9) 
93.61(1) 
90.55(3) 
89.60(4) 
80.01(7) 
79.02(8) 
68.07(10) 
45.91(13) 
44.76(14) 
50.32(11) 
92.30(2) 
50.22(12) 
13.43(15) 
83.02(5) 
81.41(6) 
donors 
15.61(16) 
97.85(5) 
17.11(15) 
99.87(1) 
99.15(3) 
99.86(2) 
92.83(7) 
88.51(10) 
63.57(13) 
94.42(6) 
91.83(8) 
99.02(4) 
52.91(14) 
70.40(12) 
80.89(11) 
89.69(9) 
fault 
49.56(12) 
50.97(9) 
53.82(4) 
53.54(5) 
54.77(2) 
50.95(10) 
53.32(6) 
47.65(14) 
46.80(15) 
52.37(8) 
42.40(16) 
50.00(11) 
48.39(13) 
53.93(3) 
53.23(7) 
56.50(1) 
fraud 
42.43(6) 
28.00(13) 
42.35(7) 
52.80(3) 
55.13(1) 
54.48(2) 
38.57(10) 
0.14(15) 
21.23(14) 
41.61(8) 
31.53(12) 
48.90(4) 
48.38(5) 
0.14(15) 
36.75(11) 
39.79(9) 
glass 
13.43(16) 
23.23(14) 
24.01(13) 
36.61(12) </p>
<p>Table D10 :
D10AUCROC of 16 label-informed algorithms on 57 benchmark datasets, with labeled anomaly ratio γ l = 10%. We show the performance rank in parenthesis (lower the better), and mark the best performing method(s) in bold.Datasets 
GANomaly 
DeepSAD 
REPEN 
DevNet 
PReNet 
FEAWAD 
XGBOD 
NB 
SVM 
MLP 
ResNet 
FTTrans 
former 
RF 
LGB 
XGB 
CatB </p>
<p>ALOI 
56.59(7) 
56.63(6) 
54.54(8) 
49.55(13) 
49.50(14) 
53.11(9) 
72.10(1) 
47.78(15) 
47.05(16) 
51.34(10) 
49.79(12) 
50.89(11) 
60.67(2) 
57.98(4) 
58.95(3) 
56.85(5) 
annthyroid 
82.83(11) 
87.41(9) 
82.05(14) 
83.31(10) 
82.78(12) 
93.07(7) 
98.21(3) 
82.54(13) 
40.43(16) 
80.53(15) 
90.88(8) 
98.67(2) 
93.72(6) 
97.39(5) 
97.56(4) 
98.85(1) 
backdoor 
83.69(14) 
96.47(5) 
89.40(12) 
97.84(1) 
96.39(6) 
96.73(3) 
96.17(7) 
79.46(15) 
94.03(9) 
95.82(8) 
58.20(16) 
93.93(10) 
87.71(13) 
93.93(11) 
97.22(2) 
96.69(4) 
breastw 
92.59(13) 
94.61(11) 
97.92(8) 
99.49(3) 
98.79(5) 
88.12(14) 
97.88(9) 
99.75(1) 
79.54(15) 
99.54(2) 
60.44(16) 
98.18(7) 
93.69(12) 
99.01(4) 
97.43(10) 
98.78(6) 
campaign 
73.02(10) 
71.02(13) 
57.92(16) 
83.85(5) 
83.84(6) 
72.49(12) 
90.77(1) 
75.62(9) 
68.88(14) 
72.51(11) 
62.26(15) 
79.61(8) 
80.15(7) 
88.25(4) 
88.72(3) 
90.08(2) 
cardio 
82.87(15) 
86.51(13) 
98.09(4) 
98.35(2) 
97.97(5) 
96.57(7) 
97.42(6) 
90.04(12) 
86.19(14) 
94.32(8) 
N/A(N/A) 
98.27(3) 
91.53(11) 
93.39(10) 
94.30(9) 
98.46(1) 
Cardiotocography 
55.12(16) 
86.65(10) 
91.80(4) 
93.15(2) 
93.33(1) 
85.38(13) 
89.77(7) 
90.85(6) 
83.19(14) 
91.02(5) 
69.36(15) 
86.43(11) 
85.64(12) 
87.23(8) 
87.03(9) 
91.85(3) 
celeba 
72.16(13) 
80.00(11) 
57.33(16) 
93.69(2) 
93.65(3) 
88.66(9) 
92.90(5) 
88.89(8) 
79.76(12) 
94.03(1) 
62.02(15) 
93.03(4) 
71.10(14) 
90.03(6) 
89.17(7) 
87.29(10) 
census 
60.45(16) 
71.90(12) 
69.07(13) 
84.88(5) 
79.66(6) 
79.20(7) 
88.53(1) 
62.38(14) 
79.12(9) 
79.02(10) 
61.42(15) 
76.73(11) 
79.14(8) 
85.87(4) 
86.07(3) 
87.91(2) 
cover 
45.42(16) 
96.71(10) 
99.92(2) 
99.88(3) 
99.87(4) 
95.43(11) 
97.76(9) 
98.72(6) 
92.73(12) 
97.86(8) 
73.39(14) 
99.92(1) 
92.37(13) 
61.22(15) 
98.25(7) 
99.50(5) 
donors 
69.68(16) 
99.99(3) 
82.79(15) 
99.99(1) 
99.95(5) 
99.98(4) 
99.83(7) 
99.42(11) 
99.72(8) 
99.84(6) 
99.43(10) 
99.99(2) 
90.19(14) 
99.01(13) 
99.28(12) 
99.72(9) 
fault 
64.59(14) 
72.45(5) 
72.43(6) 
72.10(7) 
72.04(8) 
68.44(12) 
73.43(3) 
67.35(13) 
63.85(15) 
73.92(2) 
55.75(16) 
71.13(9) 
70.86(10) 
73.16(4) 
70.80(11) 
75.79(1) 
fraud 
90.51(3) 
87.57(7) 
92.22(1) 
87.01(8) 
88.45(5) 
80.95(13) 
84.86(11) 
50.00(15) 
88.04(6) 
85.69(9) 
59.19(14) 
90.27(4) 
84.91(10) 
42.32(16) 
84.41(12) 
90.98(2) 
glass 
67.84(16) 
87.31(12) 
88.12(10) 
90.86(8) 
95.77(3) 
89.62(9) 
97.44(2) 
87.85(11) 
86.33(13) 
82.77(14) 
93.27(7) 
95.06(4) 
79.60(15) 
94.50(5) 
94.49(6) 
99.15(1) 
Hepatitis 
56.34(15) 
85.24(13) 
93.02(8) 
95.68(3) 
93.86(6) 
88.61(12) 
94.25(5) 
91.89(10) 
50.00(16) 
92.91(9) 
91.54(11) 
93.12(7) 
85.17(14) 
96.29(2) 
95.32(4) 
96.35(1) 
http 
99.80(11) 
99.93(9) 
99.98(7) 
100.00(1) 
100.00(1) 
99.84(10) 
98.33(12) 
98.33(12) 
83.31(14) 
0.17(16) 
100.00(1) 
100.00(1) 
100.00(6) 
44.39(15) 
100.00(1) 
99.97(8) 
InternetAds 
68.04(11) 
75.03(7) 
82.43(2) 
70.71(9) 
66.90(12) 
70.04(10) 
76.69(3) 
53.78(15) 
75.03(8) 
66.53(13) 
57.26(14) 
N/A(N/A) 
75.62(6) 
76.23(5) 
76.41(4) 
84.26(1) 
Ionosphere 
92.29(5) 
85.56(8) 
95.65(1) 
78.94(11) 
78.19(12) 
76.77(13) 
94.53(3) 
87.70(7) 
82.17(10) 
75.95(14) 
60.35(16) 
70.87(15) 
83.89(9) 
91.81(6) 
92.67(4) 
94.62(2) 
landsat 
47.40(16) 
90.09(3) 
57.21(15) 
78.71(12) 
79.95(11) 
82.93(9) 
90.50(2) 
71.45(14) 
82.73(10) 
88.41(5) 
77.68(13) 
89.73(4) 
87.15(7) 
87.86(6) 
86.80(8) 
91.93(1) 
letter 
69.72(10) 
74.65(3) 
73.25(4) 
71.95(7) 
72.77(6) 
68.32(12) 
87.32(1) 
57.29(13) 
56.00(14) 
49.01(16) 
77.99(2) 
52.18(15) 
69.54(11) 
71.15(9) 
71.56(8) 
73.23(5) 
Lymphography 
96.93(6) 
88.16(13) 
99.60(2) 
94.67(7) 
97.94(4) 
93.02(9) 
89.37(12) 
80.08(15) 
50.00(16) 
90.60(11) 
90.96(10) 
97.13(5) 
85.98(14) 
98.69(3) 
93.40(8) 
99.72(1) 
magic.gamma 
62.86(15) 
85.00(4) 
79.34(12) 
82.80(9) 
83.35(7) 
83.11(8) 
87.10(1) 
75.87(14) 
55.23(16) 
86.90(2) 
76.90(13) 
85.37(3) 
83.72(6) 
82.77(10) 
80.87(11) 
84.84(5) 
mammography 
72.50(15) 
91.46(5) 
92.42(3) 
93.44(1) 
93.07(2) 
91.69(4) 
87.59(10) 
90.43(7) 
67.10(16) 
91.19(6) 
78.25(12) 
88.80(9) 
77.68(13) 
72.52(14) 
84.90(11) 
89.16(8) 
mnist 
69.06(14) 
90.78(12) 
96.72(5) 
97.63(3) 
97.47(4) 
93.65(10) 
98.17(1) 
51.71(16) 
89.94(13) 
92.08(11) 
66.94(15) 
95.62(8) 
94.35(9) 
95.93(7) 
96.66(6) 
98.09(2) 
musk 
99.47(9) 
98.38(11) 
99.28(10) 
100.00(1) 
100.00(1) 
100.00(1) 
99.99(6) 
93.10(12) 
57.33(16) 
100.00(1) 
80.53(15) 
99.95(8) 
90.79(13) 
88.83(14) 
99.98(7) 
100.00(1) 
optdigits 
46.08(16) 
98.73(8) 
99.94(4) 
99.98(1) 
99.98(2) 
99.94(3) 
99.07(7) 
91.99(13) 
92.18(12) 
99.63(5) 
72.94(15) 
98.13(11) 
98.27(10) 
87.20(14) 
98.52(9) 
99.51(6) 
PageBlocks 
80.20(15) 
94.45(5) 
93.81(6) 
86.77(13) 
89.75(10) 
93.45(7) 
96.07(4) 
90.08(9) 
72.80(16) 
92.57(8) 
83.56(14) 
89.57(11) 
89.30(12) 
96.47(2) 
96.42(3) 
97.77(1) 
pendigits 
57.10(16) 
99.38(9) 
99.78(4) 
99.86(3) 
99.70(6) 
99.87(2) 
98.97(11) 
99.54(7) 
89.42(14) 
99.30(10) 
90.72(13) 
99.91(1) 
90.75(12) 
85.90(15) 
99.47(8) 
99.73(5) 
Pima 
60.29(13) 
66.07(12) 
69.69(9) 
76.24(2) 
77.35(1) 
71.49(8) 
73.83(6) 
74.76(5) 
48.36(16) 
58.11(14) 
49.26(15) 
69.65(10) 
69.61(11) 
75.29(4) 
73.70(7) 
75.53(3) 
satellite 
71.53(16) 
91.07(4) 
80.74(13) 
84.48(10) 
83.94(11) 
86.78(9) 
91.41(3) 
79.02(14) 
76.90(15) 
88.21(8) 
81.79(12) 
92.62(1) 
89.68(5) 
89.62(6) 
88.98(7) 
92.46(2) 
satimage-2 
96.54(10) 
98.00(7) 
99.46(1) 
98.33(6) 
98.59(4) 
96.75(9) 
98.40(5) 
94.00(11) 
71.95(15) 
96.89(8) 
82.68(14) 
98.88(3) 
93.53(12) 
61.69(16) 
89.33(13) 
99.11(2) 
shuttle 
68.73(16) 
99.01(3) 
98.72(5) 
97.55(10) 
97.69(8) 
98.30(7) 
99.88(1) 
93.94(13) 
87.58(15) 
97.47(11) 
97.64(9) 
97.27(12) 
90.47(14) 
98.67(6) 
98.94(4) 
99.51(2) 
skin 
52.26(16) 
99.64(3) 
90.29(14) 
95.70(11) 
95.30(12) 
98.22(10) 
99.58(4) 
94.81(13) 
99.53(5) 
99.14(8) 
99.78(2) 
99.24(6) 
89.54(15) 
99.16(7) 
99.13(9) 
99.84(1) 
smtp 
51.69(14) 
82.74(3) 
76.47(8) 
75.99(9) 
75.24(11) 
75.69(10) 
79.87(5) 
50.00(15) 
62.98(12) 
86.40(1) 
52.83(13) 
79.07(6) 
83.32(2) 
43.01(16) 
81.12(4) 
78.85(7) 
SpamBase 
54.01(16) 
80.28(13) 
87.14(9) 
91.35(6) 
92.96(3) 
83.93(11) 
94.64(1) 
83.50(12) 
69.45(14) 
91.92(4) 
63.20(15) 
91.84(5) 
84.55(10) 
91.16(7) 
88.85(8) 
94.32(2) 
speech 
47.49(16) 
54.23(11) 
57.89(7) 
68.71(2) 
70.28(1) 
59.51(5) 
57.27(9) 
58.63(6) 
57.79(8) 
52.67(12) 
52.58(13) 
68.65(3) 
51.69(15) 
52.34(14) 
56.02(10) 
63.20(4) 
Stamps 
72.38(15) 
85.97(11) 
96.92(2) 
95.37(8) 
96.40(5) 
87.25(9) 
96.81(3) 
84.57(12) 
87.03(10) 
83.58(13) 
60.44(16) 
96.29(6) 
76.48(14) 
95.72(7) 
96.50(4) 
97.55(1) 
thyroid 
92.77(13) 
97.10(10) 
99.70(2) 
99.73(1) 
99.64(3) 
99.46(6) 
98.84(8) 
99.34(7) 
64.11(16) 
90.95(14) 
74.21(15) 
99.61(4) 
92.97(12) 
95.65(11) 
97.97(9) 
99.50(5) 
vertebral 
37.26(16) 
68.06(11) 
56.21(15) 
76.86(9) 
78.26(7) 
77.24(8) 
85.83(2) 
83.34(4) 
75.85(10) 
67.41(12) 
62.55(14) 
80.82(6) 
65.78(13) 
82.36(5) 
87.31(1) 
84.73(3) 
vowels 
78.52(15) 
82.64(12) 
92.68(5) 
95.69(3) 
96.99(1) 
93.00(4) 
95.74(2) 
88.52(9) 
79.63(14) 
15.44(16) 
81.05(13) 
84.07(11) 
84.80(10) 
88.89(8) 
91.02(7) 
92.56(6) 
Waveform 
52.95(16) 
74.37(13) 
83.65(5) 
88.17(3) 
88.84(2) 
77.71(12) 
83.77(4) 
81.92(7) 
80.17(10) 
62.68(15) 
78.54(11) 
80.45(9) 
70.38(14) 
81.63(8) 
82.52(6) 
89.82(1) 
WBC 
93.57(9) 
95.88(7) 
98.28(4) 
98.91(3) 
99.03(2) 
97.37(6) 
87.60(12) 
86.84(13) 
58.91(16) 
90.09(11) 
70.28(15) 
97.64(5) 
86.29(14) 
95.80(8) 
92.67(10) 
99.37(1) 
WDBC 
97.56(8) 
95.51(12) 
100.00(1) 
100.00(1) 
100.00(1) 
99.82(6) 
97.50(9) 
80.99(14) 
61.79(15) 
33.04(16) 
96.76(10) 
99.92(5) 
96.15(11) 
98.40(7) 
94.81(13) 
99.94(4) 
Wilt 
47.50(16) 
92.05(3) 
52.98(15) 
68.14(13) 
69.06(12) 
87.92(7) 
90.42(5) 
78.61(10) 
79.70(9) 
65.92(14) 
92.41(2) 
70.15(11) 
82.05(8) 
89.13(6) 
90.59(4) 
95.66(1) 
wine 
66.14(15) 
89.42(12) 
99.87(5) 
100.00(1) 
100.00(1) 
100.00(1) 
87.18(13) 
99.89(4) 
45.77(16) 
99.20(8) 
94.20(9) 
99.63(7) 
77.52(14) 
92.98(10) 
91.78(11) 
99.69(6) 
WPBC </p>
<p>Table D13 :
D13AUCPR of 16 label-informed algorithms on 57 benchmark datasets, with labeled anomaly ratio γ l = 25%. We show the performance rank in parenthesis (lower the better), and mark the best performing method(s) in bold.Datasets 
GANomaly 
DeepSAD 
REPEN 
DevNet 
PReNet 
FEAWAD 
XGBOD 
NB 
SVM 
MLP 
ResNet 
FTTrans 
former 
RF 
LGB 
XGB 
CatB </p>
<p>Table D14 :
D14AUCROC of 16 label-informed algorithms on 57 benchmark datasets, with labeled anomaly ratio γ l = 50%. We show the performance rank in parenthesis (lower the better), and mark the best performing method(s) in bold.Datasets 
GANomaly 
DeepSAD 
REPEN 
DevNet 
PReNet 
FEAWAD 
XGBOD 
NB 
SVM 
MLP 
ResNet 
FTTrans 
former 
RF 
LGB 
XGB 
CatB </p>
<p>Table D16 :
D16AUCROC of 16 label-informed algorithms on 57 benchmark datasets, with labeled anomaly ratio γ l = 75%. We show the performance rank in parenthesis (lower the better), and mark the best performing method(s) in bold.Datasets 
GANomaly 
DeepSAD 
REPEN 
DevNet 
PReNet 
FEAWAD 
XGBOD 
NB 
SVM 
MLP 
ResNet 
FTTrans 
former 
RF 
LGB 
XGB 
CatB </p>
<p>Table D18 :
D18AUCROC of 16 label-informed algorithms on 57 benchmark datasets, with labeled anomaly ratio γ l = 100%. We show the performance rank in parenthesis (lower the better), and mark the best performing method(s) in bold.Datasets 
GANomaly 
DeepSAD 
REPEN 
DevNet 
PReNet 
FEAWAD 
XGBOD 
NB 
SVM 
MLP 
ResNet 
FTTrans 
former 
RF 
LGB 
XGB 
CatB </p>
<p>We present the results based on AUCROC and observe similar results for AUCPR; See Appx. D for all.
https://pyod.readthedocs.io/en/latest/pyod.html 2 https://scikit-learn.org/stable/
https://xgboost.readthedocs.io/en/stable/parameter.html 2 https://lightgbm.readthedocs.io/en/latest/Parameters.html 3 https://catboost.ai/en/docs/references/training-parameters/
https://pytorch.org/hub/pytorch_vision_resnet/ 2 https://github.com/lukemelas/PyTorch-Pretrained-ViT 3 https://huggingface.co/bert-base-uncased 4 https://huggingface.co/roberta-base
https://github.com/Minqi824/ADBench/tree/main/datasets
ADBench repo: https://github.com/Minqi824/ADBench
AknowledgementWe briefly describe the authors' contributions. We thank anonymous reviewers for their insightful feedback and comments. We appreciate the suggestions of Xueying Ding, Kwei-Herng (Henry) Lai, Meng-Chieh Lee, Ninghao Liu, Yuwen Yang, and Allen Zhu. Y.Z. is partly supported by the Norton Graduate Fellowship.GANomaly  DeepSAD  REPEN  DevNet  PReNet  FEAWAD  XGBOD  NB  SVM  MLP  ResNet  FTTrans  former  RFLGB XGB CatB ALOI 55.25(8)59.29(6)53.09(11)51.65(13)51.44(14)57.54(7)75.96(1)49.27(15)53.86(9)52.16(12)47.74(16)53.45(10)71.83(2)65.23(3)64.77(4)62.78(5) annthyroid 80.96(15)93.06(9)82.78(12)82.39(13)82.11(14)96.95(7)98.78(4)82.95(11)50.73(16)91.29(10)96.08(8)99.05(1)98.58(6)98.70(5)98.83(3)98.97(2) backdoor 82.96(15)97.07(8)89.49(13)97.49(6)96.45(9)98.00(4)97.20(7)76.77(16)94.51(12)95.98(10)86.10(14)94.98(11)97.92(5)98.40(2)98.39(10)
Pair-copula constructions of multiple dependence. K Aas, C Czado, A Frigessi, H Bakken, Insurance: Mathematics and economics. 442K. Aas, C. Czado, A. Frigessi, and H. Bakken. Pair-copula constructions of multiple dependence. Insurance: Mathematics and economics, 44(2):182-198, 2009.</p>
<p>The classification performance of rda. S Aeberhard, D Coomans, O De Vel, Dept. of Computer Science and Dept. of Mathematics and Statistics. James Cook University of North QueenslandTech. RepS. Aeberhard, D. Coomans, and O. de Vel. The classification performance of rda. Dept. of Computer Science and Dept. of Mathematics and Statistics, James Cook University of North Queensland, Tech. Rep, pages 92-01, 1992.</p>
<p>An introduction to outlier analysis. C C Aggarwal, Outlier analysis. C. C. Aggarwal. An introduction to outlier analysis. In Outlier analysis, pages 1-34. 2017.</p>
<p>Neural Networks and Deep Learning -A Textbook. C C Aggarwal, SpringerC. C. Aggarwal. Neural Networks and Deep Learning -A Textbook. Springer, 2018.</p>
<p>Semi-supervised statistical approach for network anomaly detection. N B Aissa, M Guerroumi, Procedia Computer Science. 83N. B. Aissa and M. Guerroumi. Semi-supervised statistical approach for network anomaly detection. Procedia Computer Science, 83:1090-1095, 2016.</p>
<p>Anomalib: A deep learning library for anomaly detection. S Akcay, D Ameln, A Vaidya, B Lakshmanan, N Ahuja, U Genc, arXiv:2202.08341S. Akcay, D. Ameln, A. Vaidya, B. Lakshmanan, N. Ahuja, and U. Genc. Anomalib: A deep learning library for anomaly detection. arXiv:2202.08341, 2022.</p>
<p>Ganomaly: Semi-supervised anomaly detection via adversarial training. S Akcay, A Atapour-Abarghouei, T P Breckon, ACCV. S. Akcay, A. Atapour-Abarghouei, and T. P. Breckon. Ganomaly: Semi-supervised anomaly detection via adversarial training. In ACCV, pages 622-637, 2018.</p>
<p>Skip-ganomaly: Skip connected and adversarially trained encoder-decoder anomaly detection. S Akçay, A Atapour-Abarghouei, T P Breckon, IJCNN. IEEES. Akçay, A. Atapour-Abarghouei, and T. P. Breckon. Skip-ganomaly: Skip connected and adversarially trained encoder-decoder anomaly detection. In IJCNN, pages 1-8. IEEE, 2019.</p>
<p>Methods of combining multiple classifiers based on different representations for pen-based handwritten digit recognition. F Alimoglu, E Alpaydin, TAINN. Citeseer. F. Alimoglu and E. Alpaydin. Methods of combining multiple classifiers based on different representations for pen-based handwritten digit recognition. In TAINN. Citeseer, 1996.</p>
<p>. E Alpaydin, C Kaynak, Cascading classifiers. Kybernetika. 344E. Alpaydin and C. Kaynak. Cascading classifiers. Kybernetika, 34(4):369-374, 1998.</p>
<p>Fast outlier detection in high dimensional spaces. F Angiulli, C Pizzuti, ECML/PKDD. SpringerF. Angiulli and C. Pizzuti. Fast outlier detection in high dimensional spaces. In ECML/PKDD, pages 15-27. Springer, 2002.</p>
<p>Sisporto 2.0: a program for automated analysis of cardiotocograms. D Ayres-De Campos, J Bernardes, A Garrido, J Marques-De Sa, L Pereira-Leite, Journal of Maternal-Fetal Medicine. D. Ayres-de Campos, J. Bernardes, A. Garrido, J. Marques-de Sa, and L. Pereira-Leite. Sisporto 2.0: a program for automated analysis of cardiotocograms. Journal of Maternal-Fetal Medicine, 2000.</p>
<p>Automl: state of the art with a focus on anomaly detection, challenges, and research directions. M Bahri, F Salutari, A Putina, M Sozio, IJDSA. M. Bahri, F. Salutari, A. Putina, and M. Sozio. Automl: state of the art with a focus on anomaly detection, challenges, and research directions. IJDSA, pages 1-14, 2022.</p>
<p>an essay towards solving a problem in the doctrine of chances. T Bayes, Lii, Philos. Trans. Royal Soc. A. T. Bayes. Lii. an essay towards solving a problem in the doctrine of chances. Philos. Trans. Royal Soc. A, pages 370-418, 1763.</p>
<p>Classification-based anomaly detection for general data. L Bergman, Y Hoshen, ICLR. L. Bergman and Y. Hoshen. Classification-based anomaly detection for general data. In ICLR, 2019.</p>
<p>Mvtec ad-a comprehensive real-world dataset for unsupervised anomaly detection. P Bergmann, M Fauser, D Sattlegger, C Steger, CVPR. P. Bergmann, M. Fauser, D. Sattlegger, and C. Steger. Mvtec ad-a comprehensive real-world dataset for unsupervised anomaly detection. In CVPR, pages 9592-9600, 2019.</p>
<p>Analysis of the sagittal balance of the spine and pelvis using shape and orientation parameters. E Berthonnaud, J Dimnet, P Roussouly, H Labelle, Clinical Spine Surgery. 181E. Berthonnaud, J. Dimnet, P. Roussouly, and H. Labelle. Analysis of the sagittal balance of the spine and pelvis using shape and orientation parameters. Clinical Spine Surgery, 18(1):40-47, 2005.</p>
<p>Comparative accuracies of artificial neural networks and discriminant analysis in predicting forest cover types from cartographic variables. J A Blackard, D J Dean, Computers and electronics in agriculture. 243J. A. Blackard and D. J. Dean. Comparative accuracies of artificial neural networks and discriminant analysis in predicting forest cover types from cartographic variables. Computers and electronics in agriculture, 24(3):131-151, 1999.</p>
<p>Enriching word vectors with subword information. P Bojanowski, E Grave, A Joulin, T Mikolov, TACL. 5P. Bojanowski, E. Grave, A. Joulin, and T. Mikolov. Enriching word vectors with subword information. TACL, 5:135-146, 2017.</p>
<p>V Borisov, T Leemann, K Seßler, J Haug, M Pawelczyk, G Kasneci, arXiv:2110.01889Deep neural networks and tabular data: A survey. V. Borisov, T. Leemann, K. Seßler, J. Haug, M. Pawelczyk, and G. Kasneci. Deep neural networks and tabular data: A survey. arXiv:2110.01889, 2021.</p>
<p>Random forests. Machine learning. L Breiman, 45L. Breiman. Random forests. Machine learning, 45(1):5-32, 2001.</p>
<p>Lof: identifying density-based local outliers. M M Breunig, H.-P Kriegel, R T Ng, J Sander, SIGMOD. M. M. Breunig, H.-P. Kriegel, R. T. Ng, and J. Sander. Lof: identifying density-based local outliers. In SIGMOD, pages 93-104, 2000.</p>
<p>Description and analysis of the brno276 system for lre2011. N Brümmer, S Cumani, O Glembek, M Karafiát, P Matějka, J Pešán, O Plchot, M Soufifar, E D Villiers, J H Černockỳ, Odyssey 2012-the speaker and language recognition workshop. N. Brümmer, S. Cumani, O. Glembek, M. Karafiát, P. Matějka, J. Pešán, O. Plchot, M. Soufifar, E. d. Villiers, and J. H.Černockỳ. Description and analysis of the brno276 system for lre2011. In Odyssey 2012-the speaker and language recognition workshop, 2012.</p>
<p>Learned robust pca: A scalable deep unfolding approach for high-dimensional outlier detection. H Cai, J Liu, W Yin, NeurIPS. 342021H. Cai, J. Liu, and W. Yin. Learned robust pca: A scalable deep unfolding approach for high-dimensional outlier detection. NeurIPS, 34, 2021.</p>
<p>On the evaluation of unsupervised outlier detection: measures, datasets, and an empirical study. Data mining and knowledge discovery. G O Campos, A Zimek, J Sander, R J Campello, B Micenková, E Schubert, I Assent, M E Houle, 30G. O. Campos, A. Zimek, J. Sander, R. J. Campello, B. Micenková, E. Schubert, I. Assent, and M. E. Houle. On the evaluation of unsupervised outlier detection: measures, datasets, and an empirical study. Data mining and knowledge discovery, 30(4):891-927, 2016.</p>
<p>A knowledge-elicitation tool for sophisticated users. B Cestnik, I Kononenko, I Bratko, European Conference on European Working Session on Learning EWSL. 87B. Cestnik, I. Kononenko, and I. Bratko. A knowledge-elicitation tool for sophisticated users. In European Conference on European Working Session on Learning EWSL, volume 87, 1987.</p>
<p>Segmentmeifyoucan: A benchmark for anomaly segmentation. R Chan, K Lis, S Uhlemeyer, H Blum, S Honari, R Siegwart, P Fua, M Salzmann, M Rottmann, NeurIPS. 2021R. Chan, K. Lis, S. Uhlemeyer, H. Blum, S. Honari, R. Siegwart, P. Fua, M. Salzmann, and M. Rottmann. Segmentmeifyoucan: A benchmark for anomaly segmentation. In NeurIPS, 2021.</p>
<p>Data-efficient and interpretable tabular anomaly detection. C.-H Chang, J Yoon, S Arik, M Udell, T Pfister, ArXiv. C.-H. Chang, J. Yoon, S. Arik, M. Udell, and T. Pfister. Data-efficient and interpretable tabular anomaly detection. ArXiv, 2203.02034, 2022.</p>
<p>Xgboost: A scalable tree boosting system. T Chen, C Guestrin, KDD. T. Chen and C. Guestrin. Xgboost: A scalable tree boosting system. In KDD, pages 785-794, 2016.</p>
<p>Outlier detection ensemble with embedded feature selection. L Cheng, Y Wang, X Liu, B Li, AAAI. 34L. Cheng, Y. Wang, X. Liu, and B. Li. Outlier detection ensemble with embedded feature selection. In AAAI, volume 34, pages 3503-3512, 2020.</p>
<p>Support vector machine. C Cortes, V Vapnik, Machine learning. 203C. Cortes and V. Vapnik. Support vector machine. Machine learning, 20(3):273-297, 1995.</p>
<p>A framework for determining the fairness of outlier detection. I Davidson, S S Ravi, ECAI 2020. IOS PressI. Davidson and S. S. Ravi. A framework for determining the fairness of outlier detection. In ECAI 2020, pages 2465-2472. IOS Press, 2020.</p>
<p>Transfer-based semantic anomaly detection. L Deecke, L Ruff, R A Vandermeulen, H Bilen, ICML. L. Deecke, L. Ruff, R. A. Vandermeulen, and H. Bilen. Transfer-based semantic anomaly detection. In ICML, pages 2546-2558, 2021.</p>
<p>Statistical comparisons of classifiers over multiple data sets. J Demšar, The JMLR. 7J. Demšar. Statistical comparisons of classifiers over multiple data sets. The JMLR, 7:1-30, 2006.</p>
<p>Imagenet: A large-scale hierarchical image database. J Deng, W Dong, R Socher, L.-J Li, K Li, L Fei-Fei, CVPR. IeeeJ. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, and L. Fei-Fei. Imagenet: A large-scale hierarchical image database. In CVPR, pages 248-255. Ieee, 2009.</p>
<p>Computer-intensive methods in statistics. P Diaconis, B Efron, Scientific American. 2485P. Diaconis and B. Efron. Computer-intensive methods in statistics. Scientific American, 248(5), 1983.</p>
<p>A comparison of dynamic reposing and tangent distance for drug activity prediction. T Dietterich, A Jain, R Lathrop, T Lozano-Perez, NeurIPS. 6T. Dietterich, A. Jain, R. Lathrop, and T. Lozano-Perez. A comparison of dynamic reposing and tangent distance for drug activity prediction. NeurIPS, 6, 1993.</p>
<p>A comparative evaluation of outlier detection algorithms: Experiments and analyses. R Domingues, M Filippone, P Michiardi, J Zouaoui, Pattern Recognition. 74R. Domingues, M. Filippone, P. Michiardi, and J. Zouaoui. A comparative evaluation of outlier detection algorithms: Experiments and analyses. Pattern Recognition, 74:406-421, 2018.</p>
<p>An image is worth 16x16 words: Transformers for image recognition at scale. A Dosovitskiy, L Beyer, A Kolesnikov, D Weissenborn, X Zhai, T Unterthiner, M Dehghani, M Minderer, G Heigold, S Gelly, ICLR. A. Dosovitskiy, L. Beyer, A. Kolesnikov, D. Weissenborn, X. Zhai, T. Unterthiner, M. Dehghani, M. Minderer, G. Heigold, S. Gelly, et al. An image is worth 16x16 words: Transformers for image recognition at scale. In ICLR, 2020.</p>
<p>Date: Detecting anomalies in text via self-supervision of transformers. A Manolache, F Brad, E Burceanu, NAACL. A. Manolache, F. Brad, and E. Burceanu. Date: Detecting anomalies in text via self-supervision of transformers. In NAACL, pages 267-277, 2021.</p>
<p>Novelty detection: a review-part 1: statistical approaches. Signal processing. M Markou, S Singh, 83M. Markou and S. Singh. Novelty detection: a review-part 1: statistical approaches. Signal processing, 83(12):2481-2497, 2003.</p>
<p>Fault detection and diagnosis in nonlinear systems. R Martinez-Guerra, J L Mata-Machuca, SpringerR. Martinez-Guerra and J. L. Mata-Machuca. Fault detection and diagnosis in nonlinear systems. Springer, 2016.</p>
<p>An algorithm for generating artificial test clusters. G W Milligan, Psychometrika. 501G. W. Milligan. An algorithm for generating artificial test clusters. Psychometrika, 50(1):123-127, 1985.</p>
<p>Unsw-nb15: a comprehensive data set for network intrusion detection systems (unsw-nb15 network data set). N Moustafa, J Slay, 2015 military communications and information systems conference (MilCIS). IEEEN. Moustafa and J. Slay. Unsw-nb15: a comprehensive data set for network intrusion detection systems (unsw-nb15 network data set). In 2015 military communications and information systems conference (MilCIS), pages 1-6. IEEE, 2015.</p>
<p>Mnist-c: A robustness benchmark for computer vision. N Mu, J Gilmer, arXiv:1906.02337N. Mu and J. Gilmer. Mnist-c: A robustness benchmark for computer vision. arXiv:1906.02337, 2019.</p>
<p>Reading digits in natural images with unsupervised feature learning. Y Netzer, T Wang, A Coates, A Bissacco, B Wu, A Y Ng, Y. Netzer, T. Wang, A. Coates, A. Bissacco, B. Wu, and A. Y. Ng. Reading digits in natural images with unsupervised feature learning. 2011.</p>
<p>Self: Learning to filter noisy labels with self-ensembling. D T Nguyen, C K Mummadi, T P N Ngo, T H P Nguyen, L Beggel, T Brox, ICLR. D. T. Nguyen, C. K. Mummadi, T. P. N. Ngo, T. H. P. Nguyen, L. Beggel, and T. Brox. Self: Learning to filter noisy labels with self-ensembling. In ICLR, 2019.</p>
<p>Toward explainable deep anomaly detection. G Pang, C Aggarwal, KDD. G. Pang and C. Aggarwal. Toward explainable deep anomaly detection. In KDD, pages 4056-4057, 2021.</p>
<p>Homophily outlier detection in non-iid categorical data. G Pang, L Cao, L Chen, Data Mining and Knowledge Discovery. 354G. Pang, L. Cao, and L. Chen. Homophily outlier detection in non-iid categorical data. Data Mining and Knowledge Discovery, 35(4):1163-1224, 2021.</p>
<p>Unsupervised feature selection for outlier detection by modelling hierarchical value-feature couplings. G Pang, L Cao, L Chen, H Liu, ICDM. IEEEG. Pang, L. Cao, L. Chen, and H. Liu. Unsupervised feature selection for outlier detection by modelling hierarchical value-feature couplings. In ICDM, pages 410-419. IEEE, 2016.</p>
<p>Learning homophily couplings from non-iid data for joint feature selection and noise-resilient outlier detection. G Pang, L Cao, L Chen, H Liu, IJCAI. G. Pang, L. Cao, L. Chen, and H. Liu. Learning homophily couplings from non-iid data for joint feature selection and noise-resilient outlier detection. In IJCAI, pages 2585-2591, 2017.</p>
<p>Learning representations of ultrahigh-dimensional data for random distance-based outlier detection. G Pang, L Cao, L Chen, H Liu, KDD. G. Pang, L. Cao, L. Chen, and H. Liu. Learning representations of ultrahigh-dimensional data for random distance-based outlier detection. In KDD, pages 2041-2050, 2018.</p>
<p>Explainable deep few-shot anomaly detection with deviation networks. G Pang, C Ding, C Shen, A V D Hengel, 2108.00462ArXiv. G. Pang, C. Ding, C. Shen, and A. v. d. Hengel. Explainable deep few-shot anomaly detection with deviation networks. ArXiv, 2108.00462, 2021.</p>
<p>Deep learning for anomaly detection: A review. G Pang, C Shen, L Cao, A V D Hengel, ACM Computing Surveys (CSUR). 542G. Pang, C. Shen, L. Cao, and A. V. D. Hengel. Deep learning for anomaly detection: A review. ACM Computing Surveys (CSUR), 54(2):1-38, 2021.</p>
<p>Deep weakly-supervised anomaly detection. G Pang, C Shen, H Jin, A V D Hengel, ArXiv. G. Pang, C. Shen, H. Jin, and A. v. d. Hengel. Deep weakly-supervised anomaly detection. ArXiv, 1910.13601, 2019.</p>
<p>Deep anomaly detection with deviation networks. G Pang, C Shen, A Van Den, Hengel, KDD. G. Pang, C. Shen, and A. van den Hengel. Deep anomaly detection with deviation networks. In KDD, pages 353-362, 2019.</p>
<p>Tsb-uad: an end-to-end benchmark suite for univariate time-series anomaly detection. J Paparrizos, Y Kang, P Boniol, R S Tsay, T Palpanas, M J Franklin, VLDB15J. Paparrizos, Y. Kang, P. Boniol, R. S. Tsay, T. Palpanas, and M. J. Franklin. Tsb-uad: an end-to-end benchmark suite for univariate time-series anomaly detection. VLDB, 15(8):1697-1711, 2022.</p>
<p>Scikit-learn: Machine learning in python. F Pedregosa, G Varoquaux, A Gramfort, V Michel, B Thirion, O Grisel, M Blondel, P Prettenhofer, R Weiss, V Dubourg, the JMLR. 12F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O. Grisel, M. Blondel, P. Prettenhofer, R. Weiss, V. Dubourg, et al. Scikit-learn: Machine learning in python. the JMLR, 12:2825-2830, 2011.</p>
<p>Glove: Global vectors for word representation. J Pennington, R Socher, C D Manning, EMNLP. J. Pennington, R. Socher, and C. D. Manning. Glove: Global vectors for word representation. In EMNLP, pages 1532-1543, 2014.</p>
<p>Ocgan: One-class novelty detection using gans with constrained latent representations. P Perera, R Nallapati, B Xiang, CVPR. P. Perera, R. Nallapati, and B. Xiang. Ocgan: One-class novelty detection using gans with constrained latent representations. In CVPR, pages 2898-2906, 2019.</p>
<p>Loda: Lightweight on-line detector of anomalies. T Pevnỳ, Machine Learning. 102T. Pevnỳ. Loda: Lightweight on-line detector of anomalies. Machine Learning, 102(2):275-304, 2016.</p>
<p>A review of novelty detection. M A Pimentel, D A Clifton, L Clifton, L Tarassenko, Signal processing. 99M. A. Pimentel, D. A. Clifton, L. Clifton, and L. Tarassenko. A review of novelty detection. Signal processing, 99:215-249, 2014.</p>
<p>Catboost: unbiased boosting with categorical features. L Prokhorenkova, G Gusev, A Vorobev, A V Dorogush, A Gulin, NeurIPS. 31L. Prokhorenkova, G. Gusev, A. Vorobev, A. V. Dorogush, and A. Gulin. Catboost: unbiased boosting with categorical features. NeurIPS, 31, 2018.</p>
<p>Latent outlier exposure for anomaly detection with contaminated data. C Qiu, A Li, M Kloft, M Rudolph, S Mandt, 2202.08088ArXiv. C. Qiu, A. Li, M. Kloft, M. Rudolph, and S. Mandt. Latent outlier exposure for anomaly detection with contaminated data. ArXiv, 2202.08088, 2022.</p>
<p>Neural transformation learning for deep anomaly detection beyond images. C Qiu, T Pfrommer, M Kloft, S Mandt, M Rudolph, ICML. C. Qiu, T. Pfrommer, M. Kloft, S. Mandt, and M. Rudolph. Neural transformation learning for deep anomaly detection beyond images. In ICML, pages 8703-8714, 2021.</p>
<p>Induction of decision trees. J R Quinlan, Machine learning. 11J. R. Quinlan. Induction of decision trees. Machine learning, 1(1):81-106, 1986.</p>
<p>Inductive knowledge acquisition: a case study. J R Quinlan, P J Compton, K Horn, L Lazarus, Australian Conference on Applications of expert systems. J. R. Quinlan, P. J. Compton, K. Horn, and L. Lazarus. Inductive knowledge acquisition: a case study. In Australian Conference on Applications of expert systems, pages 137-156, 1987.</p>
<p>An information retrieval approach to building datasets for hate speech detection. M M Rahman, D Balakrishnan, D Murthy, M Kutlu, M Lease, NeurIPS. 2021M. M. Rahman, D. Balakrishnan, D. Murthy, M. Kutlu, and M. Lease. An information retrieval approach to building datasets for hate speech detection. In NeurIPS, 2021.</p>
<p>Efficient algorithms for mining outliers from large data sets. S Ramaswamy, R Rastogi, K Shim, SIGMOD. S. Ramaswamy, R. Rastogi, and K. Shim. Efficient algorithms for mining outliers from large data sets. In SIGMOD, pages 427-438, 2000.</p>
<p>ODDS library. S Rayana, S. Rayana. ODDS library, 2016.</p>
<p>Online false discovery rate control for anomaly detection in time series. Q Rebjock, B Kurt, T Januschowski, L Callot, NeurIPS. 342021Q. Rebjock, B. Kurt, T. Januschowski, and L. Callot. Online false discovery rate control for anomaly detection in time series. NeurIPS, 34, 2021.</p>
<p>Panda: Adapting pretrained features for anomaly detection and segmentation. T Reiss, N Cohen, L Bergman, Y Hoshen, CVPR. T. Reiss, N. Cohen, L. Bergman, and Y. Hoshen. Panda: Adapting pretrained features for anomaly detection and segmentation. In CVPR, pages 2806-2814, 2021.</p>
<p>The perceptron: a probabilistic model for information storage and organization in the brain. F Rosenblatt, Psychological review. 656386F. Rosenblatt. The perceptron: a probabilistic model for information storage and organization in the brain. Psychological review, 65(6):386, 1958.</p>
<p>An overview of gradient descent optimization algorithms. ArXiv. S Ruder, 1609.04747S. Ruder. An overview of gradient descent optimization algorithms. ArXiv, 1609.04747, 2016.</p>
<p>A unifying review of deep and shallow anomaly detection. L Ruff, J R Kauffmann, R A Vandermeulen, G Montavon, W Samek, M Kloft, T G Dietterich, K.-R Müller, Proceedings of the IEEE. the IEEEL. Ruff, J. R. Kauffmann, R. A. Vandermeulen, G. Montavon, W. Samek, M. Kloft, T. G. Dietterich, and K.-R. Müller. A unifying review of deep and shallow anomaly detection. Proceedings of the IEEE, 2021.</p>
<p>Deep one-class classification. L Ruff, R Vandermeulen, N Goernitz, L Deecke, S A Siddiqui, A Binder, E Müller, M Kloft, ICML. L. Ruff, R. Vandermeulen, N. Goernitz, L. Deecke, S. A. Siddiqui, A. Binder, E. Müller, and M. Kloft. Deep one-class classification. In ICML, pages 4393-4402, 2018.</p>
<p>Deep semisupervised anomaly detection. L Ruff, R A Vandermeulen, N Görnitz, A Binder, E Müller, K Müller, M Kloft, ICLR. OpenReview.net. L. Ruff, R. A. Vandermeulen, N. Görnitz, A. Binder, E. Müller, K. Müller, and M. Kloft. Deep semi- supervised anomaly detection. In ICLR. OpenReview.net, 2020.</p>
<p>Self-attentive, multi-context one-class classification for unsupervised anomaly detection on text. L Ruff, Y Zemlyanskiy, R Vandermeulen, T Schnake, M Kloft, ACL. L. Ruff, Y. Zemlyanskiy, R. Vandermeulen, T. Schnake, and M. Kloft. Self-attentive, multi-context one-class classification for unsupervised anomaly detection on text. In ACL, pages 4061-4071, 2019.</p>
<p>Adversarially learned one-class classifier for novelty detection. M Sabokrou, M Khalooei, M Fathy, E Adeli, CVPR. M. Sabokrou, M. Khalooei, M. Fathy, and E. Adeli. Adversarially learned one-class classifier for novelty detection. In CVPR, pages 3379-3388, 2018.</p>
<p>A unified survey on anomaly, novelty, open-set, and out-of-distribution detection: Solutions and future challenges. M Salehi, H Mirzaei, D Hendrycks, Y Li, M H Rohban, M Sabokrou, arXiv:2110.14051M. Salehi, H. Mirzaei, D. Hendrycks, Y. Li, M. H. Rohban, and M. Sabokrou. A unified survey on anomaly, novelty, open-set, and out-of-distribution detection: Solutions and future challenges. arXiv:2110.14051, 2021.</p>
<p>Understanding anomaly detection with deep invertible networks through hierarchies of distributions and features. R Schirrmeister, Y Zhou, T Ball, D Zhang, NeurIPS. 33R. Schirrmeister, Y. Zhou, T. Ball, and D. Zhang. Understanding anomaly detection with deep invertible networks through hierarchies of distributions and features. NeurIPS, 33:21038-21049, 2020.</p>
<p>Support vector method for novelty detection. B Schölkopf, R C Williamson, A J Smola, J Shawe-Taylor, J C Platt, NIPS. Citeseer12B. Schölkopf, R. C. Williamson, A. J. Smola, J. Shawe-Taylor, J. C. Platt, et al. Support vector method for novelty detection. In NIPS, volume 12, pages 582-588. Citeseer, 1999.</p>
<p>Ssd: A unified framework for self-supervised outlier detection. V Sehwag, M Chiang, P Mittal, ICLR. V. Sehwag, M. Chiang, and P. Mittal. Ssd: A unified framework for self-supervised outlier detection. In ICLR, 2020.</p>
<p>Fairod: Fairness-aware outlier detection. S Shekhar, N Shah, L Akoglu, AIES. S. Shekhar, N. Shah, and L. Akoglu. Fairod: Fairness-aware outlier detection. In AIES, pages 210-220, 2021.</p>
<p>Timeseries anomaly detection using temporal hierarchical one-class network. L Shen, Z Li, J Kwok, NeurIPS. 33L. Shen, Z. Li, and J. Kwok. Timeseries anomaly detection using temporal hierarchical one-class network. NeurIPS, 33:13016-13026, 2020.</p>
<p>Anomaly detection for tabular data with internal contrastive learning. T Shenkar, L Wolf, International Conference on Learning Representations. T. Shenkar and L. Wolf. Anomaly detection for tabular data with internal contrastive learning. In International Conference on Learning Representations, 2021.</p>
<p>A novel anomaly detection scheme based on principal component classifier. M.-L Shyu, S.-C Chen, K Sarinnapakorn, L Chang, Miami Univ Coral Gables Fl Dept of Electrical and Computer EngineeringTechnical reportM.-L. Shyu, S.-C. Chen, K. Sarinnapakorn, and L. Chang. A novel anomaly detection scheme based on principal component classifier. Technical report, Miami Univ Coral Gables Fl Dept of Electrical and Computer Engineering, 2003.</p>
<p>Classification of radar returns from the ionosphere using neural networks. V G Sigillito, S P Wing, L V Hutton, K B Baker, Johns Hopkins APL Technical Digest. 103V. G. Sigillito, S. P. Wing, L. V. Hutton, and K. B. Baker. Classification of radar returns from the ionosphere using neural networks. Johns Hopkins APL Technical Digest, 10(3):262-266, 1989.</p>
<p>The effect of hyperparameter tuning on the comparative evaluation of unsupervised anomaly detection methods. J Soenen, E Van Wolputte, L Perini, V Vercruyssen, W Meert, J Davis, H Blockeel, Proceedings of the KDD'21 Workshop on Outlier Detection and Description. the KDD'21 Workshop on Outlier Detection and DescriptionJ. Soenen, E. Van Wolputte, L. Perini, V. Vercruyssen, W. Meert, J. Davis, and H. Blockeel. The effect of hyperparameter tuning on the comparative evaluation of unsupervised anomaly detection methods. In Proceedings of the KDD'21 Workshop on Outlier Detection and Description, pages 1-9, 2021.</p>
<p>Deep clustering based fair outlier detection. H Song, P Li, H Liu, KDD. H. Song, P. Li, and H. Liu. Deep clustering based fair outlier detection. In KDD, pages 1481-1489, 2021.</p>
<p>Benchmarking unsupervised outlier detection with realistic synthetic data. G Steinbuss, K Böhm, TKDD15G. Steinbuss and K. Böhm. Benchmarking unsupervised outlier detection with realistic synthetic data. TKDD, 15(4):1-20, 2021.</p>
<p>Enhancing effectiveness of outlier detections for low density patterns. J Tang, Z Chen, A W , .-C Fu, D W Cheung, PAKDD. SpringerJ. Tang, Z. Chen, A. W.-C. Fu, and D. W. Cheung. Enhancing effectiveness of outlier detections for low density patterns. In PAKDD, pages 535-548. Springer, 2002.</p>
<p>Anomaly detection by leveraging incomplete anomalous knowledge with anomaly-aware bidirectional gans. B Tian, Q Su, J Yin, B. Tian, Q. Su, and J. Yin. Anomaly detection by leveraging incomplete anomalous knowledge with anomaly-aware bidirectional gans. ArXiv, 2204.13335, 2022.</p>
<p>Visualizing data using t-sne. L Van Der Maaten, G Hinton, JMLR. 911L. Van der Maaten and G. Hinton. Visualizing data using t-sne. JMLR, 9(11), 2008.</p>
<p>Rade: Resource-efficient supervised anomaly detection using decision tree-based ensemble methods. S Vargaftik, I Keslassy, A Orda, Y Ben-Itzhak, Machine Learning. 110S. Vargaftik, I. Keslassy, A. Orda, and Y. Ben-Itzhak. Rade: Resource-efficient supervised anomaly detection using decision tree-based ensemble methods. Machine Learning, 110(10):2835-2866, 2021.</p>
<p>Attention is all you need. NeurIPS, 30. A Vaswani, N Shazeer, N Parmar, J Uszkoreit, L Jones, A N Gomez, Ł Kaiser, I Polosukhin, A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez, Ł. Kaiser, and I. Polosukhin. Attention is all you need. NeurIPS, 30, 2017.</p>
<p>Further analysis of outlier detection with deep generative models. Z Wang, B Dai, D Wipf, J Zhu, NeurIPS. 33Z. Wang, B. Dai, D. Wipf, and J. Zhu. Further analysis of outlier detection with deep generative models. NeurIPS, 33:8982-8992, 2020.</p>
<p>Multisurface method of pattern separation for medical diagnosis applied to breast cytology. W H Wolberg, O L Mangasarian, Proceedings of the national academy of sciences. the national academy of sciences87W. H. Wolberg and O. L. Mangasarian. Multisurface method of pattern separation for medical diagnosis applied to breast cytology. Proceedings of the national academy of sciences, 87(23):9193-9196, 1990.</p>
<p>Stacked generalization. D H Wolpert, Neural networks. 52D. H. Wolpert. Stacked generalization. Neural networks, 5(2):241-259, 1992.</p>
<p>No free lunch theorems for optimization. D H Wolpert, W G Macready, IEEE transactions on evolutionary computation. 11D. H. Wolpert and W. G. Macready. No free lunch theorems for optimization. IEEE transactions on evolutionary computation, 1(1):67-82, 1997.</p>
<p>Comparative evaluation of pattern recognition techniques for detection of microcalcifications in mammography. K S Woods, J L Solka, C E Priebe, W P KegelmeyerJr, C C Doss, K W Bowyer, State of The Art in Digital Mammographic Image Analysis. World ScientificK. S. Woods, J. L. Solka, C. E. Priebe, W. P. Kegelmeyer Jr, C. C. Doss, and K. W. Bowyer. Comparative evaluation of pattern recognition techniques for detection of microcalcifications in mammography. In State of The Art in Digital Mammographic Image Analysis, pages 213-231. World Scientific, 1994.</p>
<p>Do wider neural networks really help adversarial robustness? NeurIPS. B Wu, J Chen, D Cai, X He, Q Gu, 342021B. Wu, J. Chen, D. Cai, X. He, and Q. Gu. Do wider neural networks really help adversarial robustness? NeurIPS, 34, 2021.</p>
<p>H Xiao, K Rasul, R Vollgraf, arXiv:1708.07747Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms. H. Xiao, K. Rasul, and R. Vollgraf. Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms. arXiv:1708.07747, 2017.</p>
<p>Do we really need to learn representations from in-domain data for outlier detection? ArXiv. Z Xiao, Q Yan, Y Amit, 2105.09270Z. Xiao, Q. Yan, and Y. Amit. Do we really need to learn representations from in-domain data for outlier detection? ArXiv, 2105.09270, 2021.</p>
<p>Beyond outlier detection: Outlier interpretation by attention-guided triplet deviation network. H Xu, Y Wang, S Jian, Z Huang, Y Wang, N Liu, F Li, WWW. H. Xu, Y. Wang, S. Jian, Z. Huang, Y. Wang, N. Liu, and F. Li. Beyond outlier detection: Outlier interpretation by attention-guided triplet deviation network. In WWW, pages 1328-1339, 2021.</p>
<p>Dp-ssl: Towards robust semi-supervised learning with a few labeled samples. Y Xu, J Ding, L Zhang, S Zhou, NeurIPS. 342021Y. Xu, J. Ding, L. Zhang, and S. Zhou. Dp-ssl: Towards robust semi-supervised learning with a few labeled samples. NeurIPS, 34, 2021.</p>
<p>Benchmarking generalized out-of-distribution detection. J Yang, P Wang, D Zou, Z Zhou, K Ding, W Peng, H Wang, G Chen, B Li, Y Sun, J. Yang, P. Wang, D. Zou, Z. Zhou, K. Ding, W. Peng, H. Wang, G. Chen, B. Li, Y. Sun, et al. Openood: Benchmarking generalized out-of-distribution detection. 2022.</p>
<p>Generalized out-of-distribution detection: A survey. J Yang, K Zhou, Y Li, Z Liu, arXiv:2110.11334J. Yang, K. Zhou, Y. Li, and Z. Liu. Generalized out-of-distribution detection: A survey. arXiv:2110.11334, 2021.</p>
<p>L Yang, Z Zhang, S Hong, R Xu, Y Zhao, Y Shao, W Zhang, M.-H Yang, B Cui, arXiv:2209.00796Diffusion models: A comprehensive survey of methods and applications. arXiv preprintL. Yang, Z. Zhang, S. Hong, R. Xu, Y. Zhao, Y. Shao, W. Zhang, M.-H. Yang, and B. Cui. Diffusion models: A comprehensive survey of methods and applications. arXiv preprint arXiv:2209.00796, 2022.</p>
<p>Z Yang, I S Bozchalooi, E Darve, arXiv:2006.03689Anomaly detection with domain adaptation. Z. Yang, I. S. Bozchalooi, and E. Darve. Anomaly detection with domain adaptation. arXiv:2006.03689, 2020.</p>
<p>Ring: Real-time emerging anomaly monitoring system over text streams. W Yu, J Li, M Z A Bhuiyan, R Zhang, J Huai, IEEE Transactions on Big Data. 54W. Yu, J. Li, M. Z. A. Bhuiyan, R. Zhang, and J. Huai. Ring: Real-time emerging anomaly monitoring system over text streams. IEEE Transactions on Big Data, 5(4):506-519, 2017.</p>
<p>Adadelta: an adaptive learning rate method. ArXiv, 1212. M D Zeiler, 5701M. D. Zeiler. Adadelta: an adaptive learning rate method. ArXiv, 1212.5701, 2012.</p>
<p>Adversarially learned anomaly detection. H Zenati, M Romain, C.-S Foo, B Lecouat, V Chandrasekhar, ICDM. IEEEH. Zenati, M. Romain, C.-S. Foo, B. Lecouat, and V. Chandrasekhar. Adversarially learned anomaly detection. In ICDM, pages 727-736. IEEE, 2018.</p>
<p>Meta-aad: Active anomaly detection with deep reinforcement learning. D Zha, K.-H Lai, M Wan, X Hu, ICDM. IEEED. Zha, K.-H. Lai, M. Wan, and X. Hu. Meta-aad: Active anomaly detection with deep reinforcement learning. In ICDM, pages 771-780. IEEE, 2020.</p>
<p>Towards fair deep anomaly detection. H Zhang, I Davidson, FAccT. H. Zhang and I. Davidson. Towards fair deep anomaly detection. In FAccT, pages 138-148, 2021.</p>
<p>S Zhang, V Ursekar, L Akoglu, Sparx: Distributed outlier detection at scale. KDD. S. Zhang, V. Ursekar, and L. Akoglu. Sparx: Distributed outlier detection at scale. KDD, 2022.</p>
<p>Character-level convolutional networks for text classification. X Zhang, J Zhao, Y Lecun, NIPS. 28X. Zhang, J. Zhao, and Y. LeCun. Character-level convolutional networks for text classification. NIPS, 28, 2015.</p>
<p>Multi-attributed heterogeneous graph convolutional network for bot detection. J Zhao, X Liu, Q Yan, B Li, M Shao, H Peng, Information Sciences. 537J. Zhao, X. Liu, Q. Yan, B. Li, M. Shao, and H. Peng. Multi-attributed heterogeneous graph convolutional network for bot detection. Information Sciences, 537:380-393, 2020.</p>
<p>Towards unsupervised hpo for outlier detection. Y Zhao, L Akoglu, arXiv:2208.11727arXiv preprintY. Zhao and L. Akoglu. Towards unsupervised hpo for outlier detection. arXiv preprint arXiv:2208.11727, 2022.</p>
<p>Xgbod: improving supervised outlier detection with unsupervised representation learning. Y Zhao, M K Hryniewicki, IJCNN. IEEEY. Zhao and M. K. Hryniewicki. Xgbod: improving supervised outlier detection with unsupervised representation learning. In IJCNN, pages 1-8. IEEE, 2018.</p>
<p>Accelerating large-scale unsupervised heterogeneous outlier detection. Y Zhao, X Hu, C Cheng, C Wang, C Wan, W Wang, J Yang, H Bai, Z Li, C Xiao, MLSys. 3Y. Zhao, X. Hu, C. Cheng, C. Wang, C. Wan, W. Wang, J. Yang, H. Bai, Z. Li, C. Xiao, et al. Suod: Accelerating large-scale unsupervised heterogeneous outlier detection. MLSys, 3:463-478, 2021.</p>
<p>Lscp: Locally selective combination in parallel outlier ensembles. Y Zhao, Z Nasrullah, M K Hryniewicki, Z Li, SDM. SIAMY. Zhao, Z. Nasrullah, M. K. Hryniewicki, and Z. Li. Lscp: Locally selective combination in parallel outlier ensembles. In SDM, pages 585-593. SIAM, 2019.</p>
<p>Pyod: A python toolbox for scalable outlier detection. Y Zhao, Z Nasrullah, Z Li, JMLR. 20Y. Zhao, Z. Nasrullah, and Z. Li. Pyod: A python toolbox for scalable outlier detection. JMLR, 20:1-7, 2019.</p>
<p>Automatic unsupervised outlier model selection. Y Zhao, R Rossi, L Akoglu, NeurIPS. 342021Y. Zhao, R. Rossi, and L. Akoglu. Automatic unsupervised outlier model selection. NeurIPS, 34, 2021.</p>
<p>Meta label correction for noisy label learning. G Zheng, A H Awadallah, S Dumais, 2021. 48.55(10) 79.66G. Zheng, A. H. Awadallah, and S. Dumais. Meta label correction for noisy label learning. AAAI, 2021. 48.55(10) 79.66(2)</p>
<p>. N/A, 80.24(11) 81.58(10) 88.93(2) Cardiotocography 35.04(16) 80.5588N/A(N/A) 88.20(5) 87.29(8) 80.24(11) 81.58(10) 88.93(2) Cardiotocography 35.04(16) 80.55(10)</p>
<p>We show the performance rank in parenthesis (lower the better), and mark the best performing method(s) in bold. ALOI 3.80Table D15: AUCPR of 16 label-informed algorithms on 57 benchmark datasets, with labeled anomaly ratio γ l = 50%. Datasets GANomaly DeepSAD REPEN DevNet PReNet FEAWAD XGBOD NB SVM MLP ResNet FTTrans former RF LGB XGB CatBTable D15: AUCPR of 16 label-informed algorithms on 57 benchmark datasets, with labeled anomaly ratio γ l = 50%. We show the performance rank in parenthesis (lower the better), and mark the best performing method(s) in bold. Datasets GANomaly DeepSAD REPEN DevNet PReNet FEAWAD XGBOD NB SVM MLP ResNet FTTrans former RF LGB XGB CatB ALOI 3.80(16)</p>
<p>We show the performance rank in parenthesis (lower the better), and mark the best performing method(s) in bold. ALOI 3.90Table D17: AUCPR of 16 label-informed algorithms on 57 benchmark datasets, with labeled anomaly ratio γ l = 75%. Datasets GANomaly DeepSAD REPEN DevNet PReNet FEAWAD XGBOD NB SVM MLP ResNet FTTrans former RF LGB XGB CatBTable D17: AUCPR of 16 label-informed algorithms on 57 benchmark datasets, with labeled anomaly ratio γ l = 75%. We show the performance rank in parenthesis (lower the better), and mark the best performing method(s) in bold. Datasets GANomaly DeepSAD REPEN DevNet PReNet FEAWAD XGBOD NB SVM MLP ResNet FTTrans former RF LGB XGB CatB ALOI 3.90(16)</p>
<p>We show the performance rank in parenthesis (lower the better), and mark the best performing method(s) in bold. ALOI 3.92Table D19: AUCPR of 16 label-informed algorithms on 57 benchmark datasets, with labeled anomaly ratio γ l = 100%. Datasets GANomaly DeepSAD REPEN DevNet PReNet FEAWAD XGBOD NB SVM MLP ResNet FTTrans former RF LGB XGB CatBTable D19: AUCPR of 16 label-informed algorithms on 57 benchmark datasets, with labeled anomaly ratio γ l = 100%. We show the performance rank in parenthesis (lower the better), and mark the best performing method(s) in bold. Datasets GANomaly DeepSAD REPEN DevNet PReNet FEAWAD XGBOD NB SVM MLP ResNet FTTrans former RF LGB XGB CatB ALOI 3.92(16)</p>            </div>
        </div>

    </div>
</body>
</html>