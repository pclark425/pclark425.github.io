<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-4804 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-4804</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-4804</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-106.html">extraction-schema-106</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models (LLMs or neural language models) being used to solve puzzle games that require spatial knowledge (such as Sudoku or other spatial reasoning tasks). Include details about the models, the puzzles, the mechanisms or strategies used, performance metrics, evidence of spatial reasoning, limitations, and comparisons.</div>
                <p><strong>Paper ID:</strong> paper-249191287</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2205.14268v3.pdf" target="_blank">NeuPSL: Neural Probabilistic Soft Logic</a></p>
                <p><strong>Paper Abstract:</strong> In this paper, we introduce Neural Probabilistic Soft Logic (NeuPSL), a novel neuro-symbolic (NeSy) framework that unites state-of-the-art symbolic reasoning with the low-level perception of deep neural networks. To model the boundary between neural and symbolic representations, we propose a family of energy-based models, NeSy Energy-Based Models, and show that they are general enough to include NeuPSL and many other NeSy approaches. Using this framework, we show how to seamlessly integrate neural and symbolic parameter learning and inference in NeuPSL. Through an extensive empirical evaluation, we demonstrate the benefits of using NeSy methods, achieving upwards of 30% improvement over independent neural network models. On a well-established NeSy task, MNIST-Addition, NeuPSL demonstrates its joint reasoning capabilities by outperforming existing NeSy approaches by up to 10% in low-data settings. Furthermore, NeuPSL achieves a 5% boost in performance over state-of-the-art NeSy methods in a canonical citation network task with up to a 40 times speed up.</p>
                <p><strong>Cost:</strong> 0.016</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e4804.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e4804.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models (LLMs or neural language models) being used to solve puzzle games that require spatial knowledge (such as Sudoku or other spatial reasoning tasks). Include details about the models, the puzzles, the mechanisms or strategies used, performance metrics, evidence of spatial reasoning, limitations, and comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>NeuPSL</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Neural Probabilistic Soft Logic</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A neuro-symbolic framework that integrates neural networks with Probabilistic Soft Logic (PSL) by instantiating deep hinge-loss Markov random fields (Deep-HL-MRFs) to perform convex joint inference over outputs while backpropagating gradients into neural perception components.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>NeuPSL (Neuro-Symbolic HL-MRF + CNN)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>A hybrid system combining (task-specific) neural perception modules (CNNs for image inputs in Visual-Sudoku and MNIST tasks, and single-layer softmax networks for citation experiments) with a PSL symbolic layer that produces deep hinge-loss potentials aggregated into a convex energy (Deep-HL-MRF). Neural networks are standard convolutional architectures (described in the paper's Table 2) or simple dense softmax classifiers; exact parameter counts are not provided in the paper. Training is end-to-end via energy-based losses with gradients passed from PSL potentials back to neural weights.</td>
                        </tr>
                        <tr>
                            <td><strong>puzzle_name</strong></td>
                            <td>Visual-Sudoku-Classification</td>
                        </tr>
                        <tr>
                            <td><strong>puzzle_description</strong></td>
                            <td>A Visual Sudoku validity classification task where 4x4 Sudoku puzzles are constructed from unlabeled MNIST digit images and the model must decide whether a puzzle is valid (no duplicate digits in any row, column, or block). The task requires spatial reasoning to enforce Sudoku structural constraints (row/column/block uniqueness).</td>
                        </tr>
                        <tr>
                            <td><strong>mechanism_or_strategy</strong></td>
                            <td>Joint neuro-symbolic inference: CNNs produce per-cell class probabilities (NEURAL predicates); PSL rules encode Sudoku constraints (row/column/block uniqueness, simplex constraints, and pinning rules) as hinge-loss potentials; NeuPSL performs convex MAP-style optimization (ADMM) to find labels y minimizing the Deep-HL-MRF energy and backpropagates through the potentials for joint learning of neural and symbolic parameters. Overlap across puzzles is exploited via shared image identifiers to perform cross-example joint reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_of_spatial_reasoning</strong></td>
                            <td>Explicit symbolic encoding of spatial Sudoku structure (Row Constraint, Column Constraint, Block Constraint rules) enforces spatial relations among grid cells; joint inference across puzzles restricts label assignments consistent with spatial constraints (paper shows scenarios where overlapping images across puzzles eliminate inconsistent digit assignments); empirical improvements in Visual-Sudoku-Classification vs purely neural baselines indicate the model uses structural/spatial constraints during inference.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>NeuPSL achieves ~70% accuracy on Visual-Sudoku-Classification using roughly 64 unique MNIST images across 16 puzzles (reported in text). NeuPSL attains 70% accuracy with a neural component trained as a 93% 4-digit distinguisher without digit labels. Inference/runtime: per Table 17, example inference times range (for NeuPSL Visual Sudoku) roughly 4.5–12.6 sec and learning times 43–170 sec depending on data size/unique puzzles; exact numbers depend on experiment setting.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>NeuPSL uses a real-valued relaxation of logical constraints (may overlook integer/discrete nuances); inference is slower than purely neural feedforward baselines and may be unsuitable for real-time settings; energy-based learning (energy loss) can lead to degenerate solutions without careful regularization (simplex constraint, negative-log regularizer) and the energy loss does not necessarily align with downstream metrics.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Outperforms CNN-Visual (pixels→validity) and CNN-Digit (given ground-truth digit labels) baselines in low-data/overlap settings; CNN baselines failed to generalize even with larger training sets (e.g., 256 MNIST images across 64 puzzles). NeuPSL leverages joint symbolic structure more effectively than independent neural models. NeuPSL inference is an order of magnitude faster than DeepProbLog for comparable NeSy inference, but NeuPSL training can be slower than DPL due to full-dataset gradient steps.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4804.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e4804.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models (LLMs or neural language models) being used to solve puzzle games that require spatial knowledge (such as Sudoku or other spatial reasoning tasks). Include details about the models, the puzzles, the mechanisms or strategies used, performance metrics, evidence of spatial reasoning, limitations, and comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>CNN-Visual</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Convolutional Neural Network (Visual baseline)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A baseline CNN that takes the raw pixels of a 4x4 Sudoku puzzle (16 MNIST images) and outputs the probability the puzzle is valid, trained with cross-entropy loss.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>CNN-Visual (baseline)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>A convolutional neural network architecture (details summarized in the paper's Table 10) that processes 16 image inputs and predicts puzzle validity. Trained end-to-end with cross-entropy; architecture and hyperparameters are tuned as described in the paper but exact parameter counts are not provided.</td>
                        </tr>
                        <tr>
                            <td><strong>puzzle_name</strong></td>
                            <td>Visual-Sudoku-Classification</td>
                        </tr>
                        <tr>
                            <td><strong>puzzle_description</strong></td>
                            <td>Same 4x4 Visual Sudoku task constructed from unlabeled MNIST digits requiring detection of duplicate digits in rows/columns/blocks (spatial constraints).</td>
                        </tr>
                        <tr>
                            <td><strong>mechanism_or_strategy</strong></td>
                            <td>Purely feed-forward CNN classification mapping image pixels of entire puzzle to a validity label; does not perform explicit symbolic or joint reasoning across puzzles or enforce Sudoku constraints via symbolic rules.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_of_spatial_reasoning</strong></td>
                            <td>No explicit spatial reasoning mechanisms; attempts to learn Sudoku structure implicitly via convolutional features, but the paper reports failure to generalize even with larger datasets, indicating limited ability to capture Sudoku relational constraints.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Reported to struggle and fail to generalize in Visual-Sudoku-Classification: the CNN-Visual baseline underperforms NeuPSL; specific failing cases noted (even with 256 MNIST images across 64 puzzles it failed to generalize). Exact accuracy numbers for CNN-Visual per setting are provided in paper figures/tables but the paper states CNNs 'struggle' compared to NeuPSL.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Cannot enforce global Sudoku constraints or leverage cross-example overlaps; lacks joint inference—thus poor generalization in low-data structured tasks; much faster inference (feedforward) but poorer predictive performance.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Performed substantially worse than NeuPSL on Visual-Sudoku-Classification; CNN-Digit (given labels) also struggled relative to NeuPSL despite having 'unfair' label access advantage.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4804.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e4804.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models (LLMs or neural language models) being used to solve puzzle games that require spatial knowledge (such as Sudoku or other spatial reasoning tasks). Include details about the models, the puzzles, the mechanisms or strategies used, performance metrics, evidence of spatial reasoning, limitations, and comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>CNN-Digit</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Convolutional Neural Network (Digit-label baseline)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A baseline model that receives ground-truth digit labels (16 labels for a 4x4 puzzle) and predicts puzzle validity to test whether a neural model can learn Sudoku rules given perfect perception.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>CNN-Digit (baseline)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>A neural model (architecture summarized in paper's Table 11) that takes as input the ground-truth digit labels for all 16 cells of the Visual Sudoku and outputs a probability distribution over validity; trained with cross-entropy. This baseline is 'unfair' since it assumes perfect digit recognition.</td>
                        </tr>
                        <tr>
                            <td><strong>puzzle_name</strong></td>
                            <td>Visual-Sudoku-Classification</td>
                        </tr>
                        <tr>
                            <td><strong>puzzle_description</strong></td>
                            <td>4x4 Sudoku validity classification requiring spatial constraint checking among grid cells.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanism_or_strategy</strong></td>
                            <td>Feed-forward network operating on symbolic digit labels (rather than pixels); learns to map label configurations to validity, without explicit symbolic rule enforcement.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_of_spatial_reasoning</strong></td>
                            <td>Relies on implicit pattern learning from labeled configurations; the reported poor generalization indicates that even with labels, purely neural mapping struggled to capture global Sudoku constraints in the experimental low-data settings.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Reported to struggle and fail to generalize in many settings; paper states CNN-Digit and CNN-Visual both struggled to leverage structure and failed to generalize even at highest data/overlap settings used (e.g., 256 images across 64 puzzles). Exact accuracy numbers appear in the paper's figures/tables.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Even with direct access to labels, the feed-forward neural baseline failed to capture global combinatorial constraints and generalize in low-data structured settings; lacks mechanisms for joint reasoning across examples.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Significantly outperformed by NeuPSL; NeuPSL uses symbolic constraints to enforce Sudoku structure which CNN-Digit lacks.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4804.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e4804.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models (LLMs or neural language models) being used to solve puzzle games that require spatial knowledge (such as Sudoku or other spatial reasoning tasks). Include details about the models, the puzzles, the mechanisms or strategies used, performance metrics, evidence of spatial reasoning, limitations, and comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>DeepProbLog (DPL)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>DeepProbLog</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A neuro-symbolic probabilistic programming framework that extends ProbLog by integrating neural predicates (neural-annotated disjunctions) to compute fact probabilities used in symbolic probabilistic inference (marginal/MAP).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>DeepProbLog</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>DeepProbLog (NeSy framework + neural nets)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Probabilistic logic programming (ProbLog) extended with neural-annotated disjunctions (nADs) where neural networks produce probabilities for facts and symbolic ProbLog marginalization yields query probabilities. Training uses SGD on losses comparing predicted marginals to targets; architecture of embedded neural networks depends on task.</td>
                        </tr>
                        <tr>
                            <td><strong>puzzle_name</strong></td>
                            <td>MNIST-Add (addition-with-unlabeled-digits)</td>
                        </tr>
                        <tr>
                            <td><strong>puzzle_description</strong></td>
                            <td>MNIST-Add is a neuro-symbolic task where MNIST images represent digits and only the sum of digits is provided; the model must infer individual digits to satisfy addition constraints. While not a spatial puzzle, it is a structured reasoning task with combinatorial constraints.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanism_or_strategy</strong></td>
                            <td>Neural networks output probabilities for digit labels via nADs; ProbLog performs marginal inference over worlds to compute marginal probabilities of query atoms; learning minimizes distance between predicted marginals and training targets. DPL can perform marginal or MAP inference; marginal inference reduces to sum/product algebraic expressions.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_of_spatial_reasoning</strong></td>
                            <td>Not directly applicable to spatial puzzles in the present paper; DPL is used in MNIST-Add (arithmetic constraints) which demonstrates structured joint reasoning but the paper notes DPL was not straightforward/used for Visual-Sudoku due to high output dimensionality.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>On MNIST-Add tasks, DPL performs well in many settings and improves with added overlap; in several MNIST-Add settings DPL achieves comparable or superior accuracy (see Table 15); however, in one largest data setting DPL produced erroneous results (not reported). For Visual-Sudoku, DPL was not included due to scalability concerns, so no Visual-Sudoku metrics.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Exact marginal inference in ProbLog/DPL is #P-complete and scales poorly; authors report DPL is much slower on inference for larger joint problems and in Visual-Sudoku high-dimensional output makes scalable DPL instantiation non-trivial; DPL timed out or was impractical in some citation experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Compared to NeuPSL on MNIST-Add, NeuPSL often matched or outperformed DPL in low-data overlap settings and was significantly faster at inference (NeuPSL inference an order of magnitude faster than DPL), but DPL uses marginal probabilistic semantics and may perform better in some large-data cases.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e4804.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e4804.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models (LLMs or neural language models) being used to solve puzzle games that require spatial knowledge (such as Sudoku or other spatial reasoning tasks). Include details about the models, the puzzles, the mechanisms or strategies used, performance metrics, evidence of spatial reasoning, limitations, and comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Logic Tensor Networks (LTNs)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Logic Tensor Networks</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A neuro-symbolic approach that maps real-valued neural outputs into fuzzy logic predicates and aggregates formula satisfaction using differentiable real-logic semantics (e.g., product real semantics and generalized mean quantifiers), enabling end-to-end learning to maximize logical satisfaction.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Logic Tensor Networks</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Logic Tensor Networks (LTN)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>LTNs forward neural network predictions into differentiable fuzzy-logic predicate functions; real-valued logic operators (e.g., product semantics) and formula aggregators (generalized means) form a satisfaction objective G(w) which is maximized during learning. Model parameters are neural network weights; symbolic semantics are differentiable but typically not parameterized.</td>
                        </tr>
                        <tr>
                            <td><strong>puzzle_name</strong></td>
                            <td>MNIST-Add (addition-with-unlabeled-digits)</td>
                        </tr>
                        <tr>
                            <td><strong>puzzle_description</strong></td>
                            <td>Structured arithmetic reasoning task involving MNIST images where only sum labels are provided; requires joint reasoning over digit identities but is not principally spatial like Sudoku.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanism_or_strategy</strong></td>
                            <td>Neural predictions are interpreted as fuzzy-truth values; logical formulas (e.g., digit-sum relations) are converted into differentiable satisfaction terms aggregated into a global loss; learning maximizes satisfaction, and inference returns highest-satisfaction output assignments.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_of_spatial_reasoning</strong></td>
                            <td>LTNs were applied to MNIST-Add (non-spatial) in the paper and are not reported for Visual-Sudoku due to implementation/scalability difficulties; thus no direct evidence of spatial reasoning in this paper for LTNs.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>On MNIST-Add experiments LTNs achieved mixed results: in some settings LTN performs worse or has higher variance compared to NeuPSL and DPL (see Table 15 and extended results); exact numbers are in the paper's tables.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Scalability and expressivity depend strongly on choice of real-valued semantics and aggregators; in high-dimensional joint-output tasks (e.g., Visual Sudoku) instantiation is non-trivial and LTNs provided limited benefit in the evaluations relative to joint PSL-based NeuPSL.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Compared with NeuPSL, LTNs benefit less from joint information in overlap experiments and underperform NeuPSL and DPL in many MNIST-Add low-data settings; inference with LTNs is feedforward-fast but yields lower predictive performance in joint reasoning tasks evaluated.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Visual sudoku puzzle classification: A suite of collective neuro-symbolic tasks <em>(Rating: 2)</em></li>
                <li>Hinge-loss Markov random fields and probabilistic soft logic <em>(Rating: 2)</em></li>
                <li>DeepProbLog <em>(Rating: 2)</em></li>
                <li>Logic Tensor Networks <em>(Rating: 2)</em></li>
                <li>DeepStochLog <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-4804",
    "paper_id": "paper-249191287",
    "extraction_schema_id": "extraction-schema-106",
    "extracted_data": [
        {
            "name_short": "NeuPSL",
            "name_full": "Neural Probabilistic Soft Logic",
            "brief_description": "A neuro-symbolic framework that integrates neural networks with Probabilistic Soft Logic (PSL) by instantiating deep hinge-loss Markov random fields (Deep-HL-MRFs) to perform convex joint inference over outputs while backpropagating gradients into neural perception components.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "NeuPSL (Neuro-Symbolic HL-MRF + CNN)",
            "model_description": "A hybrid system combining (task-specific) neural perception modules (CNNs for image inputs in Visual-Sudoku and MNIST tasks, and single-layer softmax networks for citation experiments) with a PSL symbolic layer that produces deep hinge-loss potentials aggregated into a convex energy (Deep-HL-MRF). Neural networks are standard convolutional architectures (described in the paper's Table 2) or simple dense softmax classifiers; exact parameter counts are not provided in the paper. Training is end-to-end via energy-based losses with gradients passed from PSL potentials back to neural weights.",
            "puzzle_name": "Visual-Sudoku-Classification",
            "puzzle_description": "A Visual Sudoku validity classification task where 4x4 Sudoku puzzles are constructed from unlabeled MNIST digit images and the model must decide whether a puzzle is valid (no duplicate digits in any row, column, or block). The task requires spatial reasoning to enforce Sudoku structural constraints (row/column/block uniqueness).",
            "mechanism_or_strategy": "Joint neuro-symbolic inference: CNNs produce per-cell class probabilities (NEURAL predicates); PSL rules encode Sudoku constraints (row/column/block uniqueness, simplex constraints, and pinning rules) as hinge-loss potentials; NeuPSL performs convex MAP-style optimization (ADMM) to find labels y minimizing the Deep-HL-MRF energy and backpropagates through the potentials for joint learning of neural and symbolic parameters. Overlap across puzzles is exploited via shared image identifiers to perform cross-example joint reasoning.",
            "evidence_of_spatial_reasoning": "Explicit symbolic encoding of spatial Sudoku structure (Row Constraint, Column Constraint, Block Constraint rules) enforces spatial relations among grid cells; joint inference across puzzles restricts label assignments consistent with spatial constraints (paper shows scenarios where overlapping images across puzzles eliminate inconsistent digit assignments); empirical improvements in Visual-Sudoku-Classification vs purely neural baselines indicate the model uses structural/spatial constraints during inference.",
            "performance_metrics": "NeuPSL achieves ~70% accuracy on Visual-Sudoku-Classification using roughly 64 unique MNIST images across 16 puzzles (reported in text). NeuPSL attains 70% accuracy with a neural component trained as a 93% 4-digit distinguisher without digit labels. Inference/runtime: per Table 17, example inference times range (for NeuPSL Visual Sudoku) roughly 4.5–12.6 sec and learning times 43–170 sec depending on data size/unique puzzles; exact numbers depend on experiment setting.",
            "limitations_or_failure_cases": "NeuPSL uses a real-valued relaxation of logical constraints (may overlook integer/discrete nuances); inference is slower than purely neural feedforward baselines and may be unsuitable for real-time settings; energy-based learning (energy loss) can lead to degenerate solutions without careful regularization (simplex constraint, negative-log regularizer) and the energy loss does not necessarily align with downstream metrics.",
            "comparison_baseline": "Outperforms CNN-Visual (pixels→validity) and CNN-Digit (given ground-truth digit labels) baselines in low-data/overlap settings; CNN baselines failed to generalize even with larger training sets (e.g., 256 MNIST images across 64 puzzles). NeuPSL leverages joint symbolic structure more effectively than independent neural models. NeuPSL inference is an order of magnitude faster than DeepProbLog for comparable NeSy inference, but NeuPSL training can be slower than DPL due to full-dataset gradient steps.",
            "uuid": "e4804.0"
        },
        {
            "name_short": "CNN-Visual",
            "name_full": "Convolutional Neural Network (Visual baseline)",
            "brief_description": "A baseline CNN that takes the raw pixels of a 4x4 Sudoku puzzle (16 MNIST images) and outputs the probability the puzzle is valid, trained with cross-entropy loss.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "CNN-Visual (baseline)",
            "model_description": "A convolutional neural network architecture (details summarized in the paper's Table 10) that processes 16 image inputs and predicts puzzle validity. Trained end-to-end with cross-entropy; architecture and hyperparameters are tuned as described in the paper but exact parameter counts are not provided.",
            "puzzle_name": "Visual-Sudoku-Classification",
            "puzzle_description": "Same 4x4 Visual Sudoku task constructed from unlabeled MNIST digits requiring detection of duplicate digits in rows/columns/blocks (spatial constraints).",
            "mechanism_or_strategy": "Purely feed-forward CNN classification mapping image pixels of entire puzzle to a validity label; does not perform explicit symbolic or joint reasoning across puzzles or enforce Sudoku constraints via symbolic rules.",
            "evidence_of_spatial_reasoning": "No explicit spatial reasoning mechanisms; attempts to learn Sudoku structure implicitly via convolutional features, but the paper reports failure to generalize even with larger datasets, indicating limited ability to capture Sudoku relational constraints.",
            "performance_metrics": "Reported to struggle and fail to generalize in Visual-Sudoku-Classification: the CNN-Visual baseline underperforms NeuPSL; specific failing cases noted (even with 256 MNIST images across 64 puzzles it failed to generalize). Exact accuracy numbers for CNN-Visual per setting are provided in paper figures/tables but the paper states CNNs 'struggle' compared to NeuPSL.",
            "limitations_or_failure_cases": "Cannot enforce global Sudoku constraints or leverage cross-example overlaps; lacks joint inference—thus poor generalization in low-data structured tasks; much faster inference (feedforward) but poorer predictive performance.",
            "comparison_baseline": "Performed substantially worse than NeuPSL on Visual-Sudoku-Classification; CNN-Digit (given labels) also struggled relative to NeuPSL despite having 'unfair' label access advantage.",
            "uuid": "e4804.1"
        },
        {
            "name_short": "CNN-Digit",
            "name_full": "Convolutional Neural Network (Digit-label baseline)",
            "brief_description": "A baseline model that receives ground-truth digit labels (16 labels for a 4x4 puzzle) and predicts puzzle validity to test whether a neural model can learn Sudoku rules given perfect perception.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "CNN-Digit (baseline)",
            "model_description": "A neural model (architecture summarized in paper's Table 11) that takes as input the ground-truth digit labels for all 16 cells of the Visual Sudoku and outputs a probability distribution over validity; trained with cross-entropy. This baseline is 'unfair' since it assumes perfect digit recognition.",
            "puzzle_name": "Visual-Sudoku-Classification",
            "puzzle_description": "4x4 Sudoku validity classification requiring spatial constraint checking among grid cells.",
            "mechanism_or_strategy": "Feed-forward network operating on symbolic digit labels (rather than pixels); learns to map label configurations to validity, without explicit symbolic rule enforcement.",
            "evidence_of_spatial_reasoning": "Relies on implicit pattern learning from labeled configurations; the reported poor generalization indicates that even with labels, purely neural mapping struggled to capture global Sudoku constraints in the experimental low-data settings.",
            "performance_metrics": "Reported to struggle and fail to generalize in many settings; paper states CNN-Digit and CNN-Visual both struggled to leverage structure and failed to generalize even at highest data/overlap settings used (e.g., 256 images across 64 puzzles). Exact accuracy numbers appear in the paper's figures/tables.",
            "limitations_or_failure_cases": "Even with direct access to labels, the feed-forward neural baseline failed to capture global combinatorial constraints and generalize in low-data structured settings; lacks mechanisms for joint reasoning across examples.",
            "comparison_baseline": "Significantly outperformed by NeuPSL; NeuPSL uses symbolic constraints to enforce Sudoku structure which CNN-Digit lacks.",
            "uuid": "e4804.2"
        },
        {
            "name_short": "DeepProbLog (DPL)",
            "name_full": "DeepProbLog",
            "brief_description": "A neuro-symbolic probabilistic programming framework that extends ProbLog by integrating neural predicates (neural-annotated disjunctions) to compute fact probabilities used in symbolic probabilistic inference (marginal/MAP).",
            "citation_title": "DeepProbLog",
            "mention_or_use": "use",
            "model_name": "DeepProbLog (NeSy framework + neural nets)",
            "model_description": "Probabilistic logic programming (ProbLog) extended with neural-annotated disjunctions (nADs) where neural networks produce probabilities for facts and symbolic ProbLog marginalization yields query probabilities. Training uses SGD on losses comparing predicted marginals to targets; architecture of embedded neural networks depends on task.",
            "puzzle_name": "MNIST-Add (addition-with-unlabeled-digits)",
            "puzzle_description": "MNIST-Add is a neuro-symbolic task where MNIST images represent digits and only the sum of digits is provided; the model must infer individual digits to satisfy addition constraints. While not a spatial puzzle, it is a structured reasoning task with combinatorial constraints.",
            "mechanism_or_strategy": "Neural networks output probabilities for digit labels via nADs; ProbLog performs marginal inference over worlds to compute marginal probabilities of query atoms; learning minimizes distance between predicted marginals and training targets. DPL can perform marginal or MAP inference; marginal inference reduces to sum/product algebraic expressions.",
            "evidence_of_spatial_reasoning": "Not directly applicable to spatial puzzles in the present paper; DPL is used in MNIST-Add (arithmetic constraints) which demonstrates structured joint reasoning but the paper notes DPL was not straightforward/used for Visual-Sudoku due to high output dimensionality.",
            "performance_metrics": "On MNIST-Add tasks, DPL performs well in many settings and improves with added overlap; in several MNIST-Add settings DPL achieves comparable or superior accuracy (see Table 15); however, in one largest data setting DPL produced erroneous results (not reported). For Visual-Sudoku, DPL was not included due to scalability concerns, so no Visual-Sudoku metrics.",
            "limitations_or_failure_cases": "Exact marginal inference in ProbLog/DPL is #P-complete and scales poorly; authors report DPL is much slower on inference for larger joint problems and in Visual-Sudoku high-dimensional output makes scalable DPL instantiation non-trivial; DPL timed out or was impractical in some citation experiments.",
            "comparison_baseline": "Compared to NeuPSL on MNIST-Add, NeuPSL often matched or outperformed DPL in low-data overlap settings and was significantly faster at inference (NeuPSL inference an order of magnitude faster than DPL), but DPL uses marginal probabilistic semantics and may perform better in some large-data cases.",
            "uuid": "e4804.3"
        },
        {
            "name_short": "Logic Tensor Networks (LTNs)",
            "name_full": "Logic Tensor Networks",
            "brief_description": "A neuro-symbolic approach that maps real-valued neural outputs into fuzzy logic predicates and aggregates formula satisfaction using differentiable real-logic semantics (e.g., product real semantics and generalized mean quantifiers), enabling end-to-end learning to maximize logical satisfaction.",
            "citation_title": "Logic Tensor Networks",
            "mention_or_use": "use",
            "model_name": "Logic Tensor Networks (LTN)",
            "model_description": "LTNs forward neural network predictions into differentiable fuzzy-logic predicate functions; real-valued logic operators (e.g., product semantics) and formula aggregators (generalized means) form a satisfaction objective G(w) which is maximized during learning. Model parameters are neural network weights; symbolic semantics are differentiable but typically not parameterized.",
            "puzzle_name": "MNIST-Add (addition-with-unlabeled-digits)",
            "puzzle_description": "Structured arithmetic reasoning task involving MNIST images where only sum labels are provided; requires joint reasoning over digit identities but is not principally spatial like Sudoku.",
            "mechanism_or_strategy": "Neural predictions are interpreted as fuzzy-truth values; logical formulas (e.g., digit-sum relations) are converted into differentiable satisfaction terms aggregated into a global loss; learning maximizes satisfaction, and inference returns highest-satisfaction output assignments.",
            "evidence_of_spatial_reasoning": "LTNs were applied to MNIST-Add (non-spatial) in the paper and are not reported for Visual-Sudoku due to implementation/scalability difficulties; thus no direct evidence of spatial reasoning in this paper for LTNs.",
            "performance_metrics": "On MNIST-Add experiments LTNs achieved mixed results: in some settings LTN performs worse or has higher variance compared to NeuPSL and DPL (see Table 15 and extended results); exact numbers are in the paper's tables.",
            "limitations_or_failure_cases": "Scalability and expressivity depend strongly on choice of real-valued semantics and aggregators; in high-dimensional joint-output tasks (e.g., Visual Sudoku) instantiation is non-trivial and LTNs provided limited benefit in the evaluations relative to joint PSL-based NeuPSL.",
            "comparison_baseline": "Compared with NeuPSL, LTNs benefit less from joint information in overlap experiments and underperform NeuPSL and DPL in many MNIST-Add low-data settings; inference with LTNs is feedforward-fast but yields lower predictive performance in joint reasoning tasks evaluated.",
            "uuid": "e4804.4"
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Visual sudoku puzzle classification: A suite of collective neuro-symbolic tasks",
            "rating": 2,
            "sanitized_title": "visual_sudoku_puzzle_classification_a_suite_of_collective_neurosymbolic_tasks"
        },
        {
            "paper_title": "Hinge-loss Markov random fields and probabilistic soft logic",
            "rating": 2,
            "sanitized_title": "hingeloss_markov_random_fields_and_probabilistic_soft_logic"
        },
        {
            "paper_title": "DeepProbLog",
            "rating": 2,
            "sanitized_title": "deepproblog"
        },
        {
            "paper_title": "Logic Tensor Networks",
            "rating": 2,
            "sanitized_title": "logic_tensor_networks"
        },
        {
            "paper_title": "DeepStochLog",
            "rating": 1,
            "sanitized_title": "deepstochlog"
        }
    ],
    "cost": 0.0160655,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>NeuPSL: Neural Probabilistic Soft Logic</p>
<p>Connor Pryor cfpryor@ucsc.edu 
Charles Dickens cadicken@ucsc.edu 
Eriq Augustine eaugusti@ucsc.edu 
Alon Albalak alonalbalak@ucsb.edu 
William Wang william@cs.ucsb.edu 
Lise Getoor getoor@ucsc.edu 
Santa Cruz 
Santa Uc 
Barbara 
NeuPSL: Neural Probabilistic Soft Logic</p>
<p>In this paper, we introduce Neural Probabilistic Soft Logic (NeuPSL), a novel neuro-symbolic (NeSy) framework that unites state-of-the-art symbolic reasoning with the low-level perception of deep neural networks. To model the boundary between neural and symbolic representations, we propose a family of energy-based models, NeSy Energy-Based Models, and show that they are general enough to include NeuPSL and many other NeSy approaches. Using this framework, we show how to seamlessly integrate neural and symbolic parameter learning and inference in Ne-uPSL. Through an extensive empirical evaluation, we demonstrate the benefits of using NeSy methods, achieving upwards of 30% improvement over independent neural network models. On a wellestablished NeSy task, MNIST-Addition, NeuPSL demonstrates its joint reasoning capabilities by outperforming existing NeSy approaches by up to 10% in low-data settings. Furthermore, NeuPSL achieves a 5% boost in performance over state-ofthe-art NeSy methods in a canonical citation network task with up to a 40 times speed up. arXiv:2205.14268v3 [cs.LG] 23 May 2023 common back-propagation engines such as PyTorch or Tensorflow, allowing for scalable end-to-end gradient training.Our key contributions include: 1) We define Neuro-Symbolic Energy-Based Models (NeSy-EBMs), a family of energy-based models, and show how they provide a foundation for describing, understanding and comparing NeSy systems. 2) We introduce NeuPSL, describe how it fits into the NeSy ecosystem and supports scalable joint inference, and show how it can be trained end-to-end using a joint energybased learning loss. 3) We perform extensive evaluations over two image classification tasks and two citation network datasets. Our results show NeuPSL consistently outperforms existing approaches on joint inference tasks and can more efficiently leverage structure, particularly in low-data settings.</p>
<p>Introduction</p>
<p>The field of artificial intelligence (AI) has long sought a symbiotic union of neural and symbolic methods. Neural-based methods excel at low-level perception and learn from large training data sets but struggle with interpretability and generalizing in low-data settings. Meanwhile, symbolic methods can effectively use domain knowledge, context, and common sense to reason with limited data but have difficulty representing complex low-level patterns. Recently, neuro-symbolic computing (NeSy) [Besold et al., 2017;d'Avila Garcez et al., 2019;De Raedt et al., 2020] has emerged as a promising new research area with the goal of developing systems that integrate neural and symbolic methods in a mutually beneficial manner.</p>
<p>A neural and symbolic union has the potential to yield two highly desirable capabilities -the ability to perform struc-* These authors contributed equally to this work tured prediction (joint inference) across related examples that possess complex low-level features and the ability to jointly learn (joint learning) and adapt parameters over neural and symbolic models simultaneously. For instance, predicting the result of competitions between teams using historical performance statistics in a tournament bracket requires methods to perform joint inference to reason over low-level trends and avoid inconsistencies such as two first-place finishes. Unfortunately, joint inference problems quickly grow in complexity as the output space typically increases combinatorially. For example, in the tournament setting, as the number of entries increases, the number of potential solutions grows exponentially (O(2 n )). An open challenge in the NeSy community is scaling joint inference and reasoning. This paper introduces Neural Probabilistic Soft Logic (Ne-uPSL), a novel NeSy method that integrates deep neural networks with a symbolic method designed for fast joint learning and inference. NeuPSL extends probabilistic soft logic (PSL) [Bach et al., 2017], a state-of-the-art and scalable probabilistic programming framework that can reason statistically (using probabilistic inference) and logically (using soft rules). PSL has been shown to excel in a wide variety of tasks, including natural language processing [Beltagy et al., 2014;Deng and Wiebe, 2015;Liu et al., 2016;Rospocher, 2018], data mining [Alshukaili et al., 2016;Kimmig et al., 2019], recommender systems [Kouki et al., 2015], knowledge graph discovery [Pujara et al., 2013], fairness modeling [Farnadi et al., 2019;Dickens et al., 2020], and causal reasoning [Sridhar et al., 2018]. The key innovation of NeuPSL is a new class of predicates that rely on neural network output for their values. This change fundamentally alters the learning and joint inference problems by requiring efficient integrated symbolic and neural parameter learning. The appeal of this extension is that it allows for the semantics and implementation of the symbolic language to remain the same as PSL, while also incorporating the added benefit of low-level neural perception. To gain a deeper understanding of optimizing the symbolic and neural parameters, we propose a versatile mathematical framework, Neuro-Symbolic Energy-Based Models (NeSy-EBMs), that enables many NeSy systems to utilize established Energy-Based Model learning losses and algorithms. Utilizing this theory and leveraging the unique relaxation properties of PSL, we show that a gradient over these neural predicates can be calculated and passed back to 3 Neuro-Symbolic Energy-Based Models</p>
<p>With the success and growth of NeSy research, there is an increasing need for a common formalization of NeSy systems to accelerate the research and understanding of the field. We fill this need with a general mathematical framework, Neuro-Symbolic Energy-Based Models (NeSy-EBMs). NeSy-EBMs encompass previous approaches and establishes the foundation of our approach. Energy-Based Models (EBMs) [Le-Cun et al., 2006] measure the compatibility of a collection of observed (or input) variables x ∈ X and target (or output) variables y ∈ Y with a scalar-valued energy function: E : Y × X → R. Low energy states of the variables represent high compatibility. Prediction or inference in EBMs is performed by finding the lowest energy state of the variables y given x. Energy functions are parameterized by variables w ∈ W, and learning is the task of finding a parameter setting that associates low energy to correct solutions.</p>
<p>Building on the well-known EBM framework, NeSy-EBMs are a family of EBMs that integrate neural architectures with explicit encodings of symbolic relations. The input variables are organized into neural, x nn ∈ X nn , and symbolic, x sy ∈ X sy , vectors. Furthermore, the parameters of the energy function, w, are partitioned into neural weights, w nn ∈ W nn , and symbolic weights, w sy ∈ W sy . Formally, Definition 1 (NeSy-EBM). Let y ∈ Y and x sy ∈ X sy be vectors of variables with symbolic interpretations. Let g nn be neural networks with neural weights w nn ∈ W nn and inputs x nn ∈ X nn . A symbolic potential is a function of y, x sy , and g nn (·) parameterized by symbolic weights w sy ∈ W sy : ψ(y, x sy , w sy , g nn (x nn , w nn )) ∈ R. A NeSy-EBM energy function is a mapping of a vector of m symbolic potential outputs, Ψ(y, x sy , w sy , x nn , w nn ) = [ψ i (y, x sy , w sy , g nn (x nn , w nn ))] m i=1 , to a real value: E(Ψ(y, x sy , w sy , x nn , w nn )) ∈ R.</p>
<p>NeSy-EBMs are differentiated from one another by the instantiation process, the form of the symbolic potentials, and the definition of the energy function. In appendix, we formally show how two NeSy systems DeepProbLog (DPL) [Manhaeve et al., 2018] and Logic Tensor Networks (LTNs) [Badreddine et al., 2022] fit into the NeSy-EBM framework. In summary, DPL uses neural network outputs to specify event probabilities that are used in logical formulae defining probabilistic dependencies. The definition of the DPL symbolic potentials and energy function are tied to the inference task; a different definition of the symbolic potential and energy function is used to implement marginal versus MAP inference. For marginal, the most common DPL inference, symbolic potentials are functions of marginal probabilities, and the energy function is a joint distribution that is the sum of the symbolic potentials. LTNs instantiate a model which forwards neural network predictions into functions representing symbolic relations with real-valued or fuzzy logic semantics. The fuzzy logic functions are symbolic potentials that are aggregated to define the energy function. The following section will introduce how our approach, NeuPSL, is instantiated as a NeSy-EBM. Using this common framework, understanding and theoretical advances can be made across NeSy approaches.</p>
<p>Joint Reasoning in NeSy-EBMs</p>
<p>We highlight two important categories of NeSy-EBM energy functions: joint and independent. Formally, an energy function that is additively separable over the output variables y is an independent energy function, i.e., corresponding to each of the n y components of the output variable y there exists functions n y functions E 1 (y[1], x sy , w sy , g(x nn , w nn )), · · · , E ny (y[n y ], x sy , w sy , g(x nn , w nn )) such that
E(·) = ny i=1 E i (y[i],
x sy , w sy , g(x nn , w nn )).</p>
<p>While a function that is not separable over output variables y is a joint energy function. This categorization allows for an important distinction during inference and learning. Independent energy functions simplify inference and learning as finding an energy minimizer, y * , can be distributed across the independent functions E i . In other words, the predicted value for a variable y[i] has no influence over that of y [j] where j ̸ = i and can therefore be predicted separately, i.e., independently. However, independent energy functions cannot leverage some joint information that may be used to improve predictions. See appendix for further details.</p>
<p>Neural Probabilistic Soft Logic</p>
<p>Having laid the NeSy-EBM groundwork, we now introduce Neural Probabilistic Soft Logic (NeuPSL), a novel NeSy-EBM framework that extends the probabilistic soft logic (PSL) framework [Bach et al., 2017]. At its core, NeuPSL leverages the power of neural networks' low-level perception by seamlessly integrating their outputs with a collection of symbolic potentials generated through a PSL program. Figure 1 provides a graphical representation of this process. The symbolic potentials and neural networks together define a deep hinge-loss Markov random field (Deep-HL-MRF), a tractable probabilistic graphical model that supports scalable convex joint inference. This section provides a comprehensive description of how NeuPSL instantiates its symbolic potentials and how the symbolic potentials are combined to define an energy function, while the following section details NeuPSL's end-to-end neural-symbolic inference, learning, and joint reasoning processes.</p>
<p>NeuPSL instantiates the symbolic potentials of its energy function using the PSL language where dependencies between relations and attributes of entities in a domain, defined as atoms, are encoded with weighted first-order logical clauses and linear arithmetic inequalities referred to as rules. To illustrate, consider a setting in which a neural network is used to classify the species of an animal in an image.</p>
<p>Further, suppose there exists external information suggesting when two images may contain the same entity. The information linking the images may come from various sources, such as the images' caption or metadata indicating the images were captured by the same device within a short period of time. NeuPSL represents the neural network's animal classification of an image (Image 1 ) as a species (Species) with the atom NEURAL(Image 1 , Species) and the probability that two images (Image 1 and Image 2 ) contain the same entity with the atom SAMEENTITY(Image 1 , Image 2 ). Additionally, we represent NeuPSL's classification of Image 2 with CLASS(Image 2 , Species). The following weighted logical rule in NeuPSL represents the notion that two images identified as the same entity may also be of the same species:
w : NEURAL(Image 1 , Species) ∧ SAMEENTITY(Image 1 , Image 2 ) → CLASS(Image 2 , Species)(1)
The parameter w is the weight of the rule, and it quantifies its relative importance in the model. Note these rules can either be hard or soft constraints. Atoms and weighted rules are templates for creating symbolic potentials or soft constraints. To create these symbolic potentials, atoms and rules are instantiated with observed data and neural predictions. Atoms instantiated with elements from the data are referred to as ground atoms. Then, valid combinations of ground atoms substituted in the rules create ground rules. To illustrate, suppose that there are two images {Id1, Id2} and three species classes {Cat, Dog, F rog}. Using the above data for cats would result in the following ground rules (analogous ground rules would be created for dogs and frogs):
w : NEURAL(Id1, Cat)∧SAMEENTITY(Id1, Id2) → CLASS(Id2, Cat) w : NEURAL(Id2, Cat)∧SAMEENTITY(Id2, Id1) → CLASS(Id1, Cat)
Ground atoms are mapped to either an observed variable, x sy,i , target variable, y i , or a neural function with inputs x nn and parameters w nn,i : g nn,i (x nn , w nn,i ). Then, variables are aggregated into the vectors x sy = [x syi ] nx i=1 and y = [y i ] ny i=1 and neural outputs are aggregated into the vector g nn = [g nn,i ] ng i=1 . Ground rules are either logical (e.g., Equation 1) or arithmetic defined over x sy , y, and g nn . These ground rules create one or more potentials ϕ(·) ∈ R, where logical rules are relaxed using Łukasiewicz continuous valued logical semantics [Klir and Yuan, 1995]. Each potential ϕ(·) is associated with a weight w psl inherited from its instantiating rule. The potentials and weights from the instantiation process are used to define a member of a tractable class of graphical models, deep hinge-loss Markov random fields (Deep-HL-MRF):</p>
<p>Definition 2 (Deep Hinge-Loss Markov Random Field). Let y ∈ [0, 1] ny and x sy ∈ [0, 1] nx be vectors of [0, 1] valued variables. Let g nn = [g nn,i ] ng i=1 be functions with corresponding parameters w nn = [w nn,i ] ng i=1 and inputs x nn . A deep hinge-loss potential is a function of the form 
ϕ(y, x sy , x nn , w nn ) = max(l(y, x sy , g nn (x nn , w nn )), 0) α (2)
where l(·) is a linear function and α ∈ {1, 2}. Let T = [t i ] r i=1 denote an ordered partition of a set of m deep hingeloss potentials:
{ϕ 1 , · · · , ϕ m }. For each partition t i define Φ i (y, x sy , x nn , w nn ) := j∈ti ϕ i (y, x sy , x nn , w nn ) and let Φ(y, x sy , x nn , w nn ) := [Φ i (y, x sy , x nn , w nn )] r i=1 . Fur- ther, let w psl = [w psl,i ] r i=1
be a vector of non-negative weights corresponding to the partition T . Then, a deep hinge-loss energy function is
E(y, x sy , x nn , w nn , w psl ) = w T psl Φ(y, x sy , x nn , w nn ) (3) Further, let c = [c i ] q i=1
be a vector of q linear constraints in standard form, defining the feasible set Ω = {y, x sy | c i (y, x sy ) ≤ 0, ∀i ∈ {0, · · · , q}}. Then a deep hinge-loss Markov random field, P, with random variables y conditioned on x sy and x nn is a probability density of the form P (y|x sy , x nn ) = exp(−E(y,xsy,xnn,wnn,w psl )) y|y,xsy ∈Ω exp(−E(·))dy (y, x sy ) ∈ Ω 0 o.w.</p>
<p>Deep-HL-MRFs naturally fit into the NeSy-EBM framework. The symbolic potentials of deep-HL-MRFs are the aggregated and scaled deep hinge-loss potentials:
ψ N euP SL (y, x sy , w psl , g nn (x nn , w nn )) = w psl Φ(y, x sy , x nn , w nn )(4)
Then the energy function is the sum of symbolic potentials:
E N euP SL (y, x sy , x nn , w nn , w psl ) = r i=1 ψ N euP SL,i (y, x sy , w psl , g nn (x nn , w nn ))(5)</p>
<p>NeuPSL Inference and Learning</p>
<p>There is a clear connection between neural and symbolic inference in NeuPSL that allows any neural architecture to interact with symbolic reasoning in a simple and expressive manner. The NeuPSL neural-symbolic interface and inference pipeline is shown in Figure 1. Neural inference is computing the output of the neural networks given the input x nn , i.e., computing g nn,i (x nn , w nn,i ) for all i. NeuPSL symbolic inference minimizes the energy function over y:
y * = arg min y|(y,xsy)∈Ω E(y, x sy , x nn , w nn , w psl )(6)
Note that the hinge-loss potentials are convex in y and hence, with the common constraint enforcing symbolic parameters to be non-negative, i.e., w psl &gt; 0, the energy function is convex in y. Any scalable convex optimizer can be applied to solve (6). NeuPSL uses the alternating direction method of multipliers [Boyd et al., 2010]. NeuPSL learning is the task of finding both neural and symbolic parameters, i.e., rule weights, that assign low energy to correct values of the output variables and higher energies to incorrect values. Learning objectives are functionals mapping an energy function and a set of training examples S = {(y i , x sy,i , x nn,i ) : i = 1, · · · , P } to a real-valued loss. As the energy function for NeuPSL is parameterized by the neural weights w nn and symbolic weights w psl , we express the learning objective as a function of w nn , w psl , and S: L(S, w nn , w psl ). Learning objectives follow the standard empirical risk minimization framework and are therefore separable over the training examples in S as a sum of per-sample loss functions L i (y i , x i , x nn,i , w nn , w psl ). Concisely, NeuPSL learning is the following minimization:</p>
<p>arg min wnn,w psl L(w nn , w psl , S) = arg min
wnn,w psl P i=1 L i (y i , x sy,i , x nn,i , w nn , w psl )
In the learning setting, variables y i from the training set S are partitioned into vectors y i,t and z i . The variables y i,t represent variables for which there is a corresponding truth value, while z i represent latent variables. Without loss of generality, we write y i = (y i,t , z i ).</p>
<p>There are multiple losses that one could motivate for optimizing the parameters of an EBM. Common losses, including the loss we present in this work, use the following terms: z * i = arg min z|((yi,t,z),x)∈Ω E((y i,t , z), x sy,i , x nn,i , w nn , w psl )
y * i = arg min y|(y,xi)∈Ω E(y, x sy,i , x nn,i , w nn , w psl )
In words, z * i and y * i are the lowest energy states given (y i,t , x sy,i , x nn,i ) and (x sy,i , x nn,i ), respectively. A special case of learning is when the per-sample losses are not functions of z * i and y * i , and more specifically, the losses do not require any subproblem optimization. We refer to this situation as constraint learning. Constraint learning reduces the time required per iteration at the cost of expressivity.</p>
<p>All interesting learning losses for NeuPSL are a composition of the energy function. Thus, a gradient-based learning algorithm will require the following partial derivatives: *
∂E(·) ∂w psl [i] = Φ i (y, x sy , x nn , w nn ) ∂E(·) ∂w nn [i] = w T psl ∇ wnn[i] Φ(y, x sy , x nn , w nn )
Continuing with the derivative chain rule and noting the potential can be squared (α = 2) or linear (α = 1), the potential partial derivative with respect to w nn [i] is the piece-wise defined function: *
∂ϕ(·) ∂w nn [i] = ∂ ∂gnn[i] ϕ(·) · ∂ ∂wnn[i] g nn <a href="·">i</a> α = 1 2 · ϕ(·) · ∂ ∂gnn[i] ϕ(·) · ∂ ∂wnn[i] g nn <a href="·">i</a> α = 2 ∂ϕ(·) ∂g nn [i] = 0 ϕ(·) = 0 ∂ ∂gnn[i]
l(y, x sy , g nn (x nn , w nn )) ϕ(·) &gt; 0 Since l(y, x sy , g nn (x nn , w nn )) is a linear function, the partial gradient with respect to g nn [i] is trivial. With the partial derivatives presented here, standard backpropagation-based algorithms for computing gradients can be applied for both neural and symbolic parameter learning.</p>
<p>Energy Loss: A variety of differentiable loss functions can be chosen for L. For simplicity, in this work, we present the energy loss. The energy loss parameter learning scheme directly minimizes the energy of the training samples, i.e., the per-sample losses are:
L i (y i , x sy,i , x nn,i ,w nn , w psl ) = E((y i,t , z * i ),
x sy,i , x nn,i , w nn , w psl ) Notice that inference over the latent variables is necessary for gradient and objective value computations. However, a complete prediction from NeuPSL, i.e., inference over all components of y, is unnecessary. Therefore the parameter learning problem is as follows:
arg min wnn,w psl P i=1 min z∈Ω w T psl Φ((y i,t , z), x sy,i , x nn,i , w nn )
With L2 regularization, the NeuPSL energy function is strongly convex in all components of y i . Thus, by Danskin (1966), the gradient of the energy loss, L i (·), with respect to w psl at y i , x i , x nn,i w nn is:
∇ w psl L i (y i , x sy,i ,w nn , w psl ) = Φ((y i,t , z * i ), x sy,i , x nn,i , w nn )
* Note arguments of the energy function and symbolic potentials are dropped for simplicity, i.e., E(·) = E(y, xsy,i, xnn,i, wnn, w psl ), ϕ(·) = ϕ(y, xsy, xnn, wnn), and gnn<a href="·">i</a> = gnn<a href="xnn, wnn">i</a>.</p>
<p>Then the per-sample energy loss partial derivative with respect to w nn [j] at y i , x sy,i , x nn,i , w psl is:
∂L i (y i , x sy,i , x nn,i , w nn , w psl ) ∂w nn [j] = R r=1 w psl [r] q∈τr ∂ϕ q ((y i,t , z * i ), x sy,i , x nn,i , w nn ) ∂w nn [j]
Details on the learning algorithms and accounting for degenerate solutions of the energy loss are included in supplementary materials.</p>
<p>Experimental Evaluation</p>
<p>We evaluate NeuPSL's prediction performance and inference time on three tasks to demonstrate the significance of joint symbolic inference and learning. NeuPSL, implemented using the open-source PSL software package, can be integrated with any neural network library (here, we used Tensor-Flow). * Our investigation addresses the following questions: Q1) Can neuro-symbolic methods provide a boost over conventional purely data-driven neural models? Q2) Can we effectively leverage structural relationships across training examples through joint reasoning? Q3) How does NeuPSL compare with other neuro-symbolic methods in terms of time efficiency on large scale problems?</p>
<p>MNIST Addition</p>
<p>The first set of experiments are conducted on a variation of MNIST Addition, a widely used NeSy evaluation task [Manhaeve et al., 2018]. The task involves determining the sum of two lists of MNIST images. For example, a MNIST-Add1 addition is ( + = 8), and a MNIST-Add2 addition is ( , + , = 41). The challenge stems from the lack of labels for the MNIST images in the addition equation. Only the final sum of the equation is given, leaving the task of identifying the individual digits and determining their values up to the model being used.</p>
<p>While NeuPSL proves to be successful in the original MNIST-Add setting (appendix for further details), here we are interested in exploring the power of joint inference and learning capabilities in NeSy systems. We introduce a variant of the MNIST-Add task in which digits are reused across multiple addition examples, i.e., we introduce overlap. Figure 2 demonstrates the process of introducing overlap and how joint models narrow the space of possible labels when MNIST images are re-used. For instance, in the scenario presented in Figure 2, the same MNIST image of a zero is utilized in two separate additions. To comply with both addition constraints, the potential label space is restricted and can no longer include options such as two or three, as they would violate one of the addition rules. In contrast, a model performing independent reasoning would have no way of enforcing this constraint across examples.  In the overlap variant of MNIST-Add, we focus on lowdata settings to understand whether NeSy systems' joint reasoning can effectively leverage additional structure to overcome a lack of data. To create overlap, we begin with a set of n unique MNIST images from which we re-sample to create (n + m)/2 MNIST-Add1 and (n + m)/4 MNIST-Add2 additions. We vary the amount of overlap with m ∈ {0, n/2, n} and compare performance with n ∈ {40, 60, 80}. Results are reported over ten test sets of 1, 000 MNIST images with overlap proportional to the respective train set. Initially, there is not enough structure from the additions with no overlap for symbolic inference to discern the correct digit labels for training the neural models. Then, despite the number of unique MNIST images remaining the same, as the number of additions increases, DPL and Ne-uPSL improve their prediction performance by leveraging the added joint information (Q2). In all cases, NeuPSL performs best and uses the added structure most efficiently. LTNs and the CNN baseline benefit the least from joint information, a consequence of both learning and inference being performed independently across batches of additions (Q1). In this task, 4x4 Sudoku puzzles are constructed using unlabeled MNIST images. The model must identify whether a puzzle is correct, i.e., no duplicate digits in any row, column, or square. Therefore this task does not require learning the underlying label for images but rather whether an entire puzzle is valid. For instance, does not need to belong to a "3" class, instead and need to be labeled as different symbols. Similar to MNIST-Add we explore an overlap variant in low-data settings, with overlapping MNIST images across puzzles.</p>
<p>Visual Sudoku Classification</p>
<p>We compare NeuPSL with two baselines, CNN-Visual and CNN-Digit. The first, CNN-Visual, takes the pixels for a Sudoku puzzle as input and outputs the probability the puzzle is valid. The second, CNN-Digit, is provided the (unfair) advantage of all sixteen image labels as input. We use this to verify whether a neural model can learn Sudoku rules. Scalably developing LTN and DPL models in this new setting is not straightforward due to the large dimensionality of the output space. A non-expert implementation of a visual sudoku model in DPL and LTN may result in suboptimal reports on model performance and are therefore not included. Figure 4 shows the accuracy of NeuPSL and CNN models on Visual-Sudoku-Classification with varying amounts  of overlap. CNN-Visual and CNN-Digit struggle to leverage the problem structure and fail to generalize even the highest data and overlap setting with 256 MNIST images across 64 puzzles. However, NeuPSL achieves 70% accuracy using roughly 64 MNIST images across 16 puzzles, again showing it efficiently leverages joint information across training examples (Q1 and Q2). This is a particularly impressive result as the neural network in the NeuPSL model was trained to be a 93% 4-digit distinguisher without digit labels.</p>
<p>Citation Network Node Classification</p>
<p>In our final experiment, we evaluate the performance of Ne-uPSL on two widely studied citation network node classification datasets: Citeseer and Cora [Sen et al., 2008]. In these datasets, symbolic models have the potential to improve predictions by leveraging the homophilic structure of the citation network, i.e., two papers connected in the network are more likely to have the same label. This setting differs from Visual-Sudoku-Classification and MNIST-Add as the symbolic relations are not always true. Moreover, the symbolic relations can be defined over a general and potentially large number of nodes in the network, i.e., a node can be connected to any number of neighbors. We propose two NeuPSL models for citation network node classification. Both models integrate a neural network that uses a paper's features to provide an initial classification, which is then adjusted via symbolic reasoning. The first model, NeuPSL LP (Label Propagation), directly uses the bag-of-words feature vector, while the second model, NeuPSL LP +F P (Label + Feature Propagation), first performs the feature construction procedure as described in Wu et al. (2019) to obtain a richer representation to provide to the neural model. We examine the runtime and model perfor-mance of NeSy methods NeuPSL LP , NeuPSL LP +F P , DPL and its scalable extension, DeepStochLog [Winters et al., 2022], and a Graph Convolutional Network (GCN) [Kipf and Welling, 2017]. Additionally, we include the performance of two baselines, LP P SL and Neural P SL . These baselines represent the distinct symbolic and neural components used in the NeuPSL LP model but perform only neural or symbolic reasoning, not both. We averaged the results over ten randomly sampled splits using 5% of the nodes for training, 5% of the nodes for validation, and 1000 nodes for testing. Table 1 shows DeepStochLog, GCN, and NeuPSL all outperform the independent baselines (Q1), with NeuPSL LP +F P performing the best. These results demonstrate the power of using NeSy systems to effectively leverage structure to improve prediction performance. Additionally, NeuPSL is capable of scaling its joint inference process to larger structures, achieving higher accuracy with an 8 and 40 times speed up over DeepStochLog in Citeseer and Cora, respectively (Q3). Surprisingly, NeuPSL also achieves a higher prediction performance than even a GCN model while using significantly fewer trainable parameters.</p>
<p>Conclusion</p>
<p>In this paper, we introduced NeuPSL, a novel NeSy framework that integrates neural architectures and a tractable class of graphical models for jointly reasoning over symbolic relations and showed its utility across a range of neuro-symbolic tasks. There are many avenues for future work, including exploring different learning objectives, such as ones that balance traditional neural and energy-based losses and new application domains. Each of these is likely to provide new challenges and insights.</p>
<p>A Appendix</p>
<p>The appendix includes the following sections: Limitations, Formulating Existing NeSy Frameworks as NeSy-EBMs, Joint Reasoning in NeSy-EBMs, NeuPSL Parameter Learning, Dataset Details, NeuPSL Models, Baseline Models, Extended Evaluation Details, and Computational Hardware Details.</p>
<p>B Limitations</p>
<p>Practitioners applying NeuPSL should consider the following three limitations. First, NeuPSL operates on real-valued logic, which improves scalability but is a relaxation of the original problem. This relaxation may overlook nuances (e.g., integer constraints) of the original task. Second, while NeuPSL demonstrates excellent performance in solving joint symbolic inference tasks, it comes at the expense of a higher inference runtime than a purely neural model. The computational demands of NeuPSL may limit its applicability in scenarios where real-time processing is necessary. Lastly, NeuPSL is trained in this work with the energy learning loss. Using this loss reduces the energy of the truth data but does not necessarily align with a downstream evaluation metric, and we have identified some degenerate solutions (Appendix E.1). Exploring the adaptation of NeuPSL to support different learning losses is an interesting avenue for future research.</p>
<p>C Formulating Existing NeSy Frameworks as NeSy-EBMs</p>
<p>This section shows how to formulate two popular NeSy frameworks, DeepProbLog (DPL) [Manhaeve et al., 2018] and LTNs (LTNs) [Badreddine et al., 2022], as NeSy-EBMs.</p>
<p>C.1 DeepProbLog</p>
<p>DeepProbLog (DPL) extends the probabilistic programming language ProbLog [De Raedt et al., 2007]. A ProbLog program consists of (i) a set of probabilistic facts F of the form p :: f where p is a probability and f is a {0, 1} valued symbolic variable and (ii) a set R of symbolic statements or rules. The following ProbLog program is a common example that models the likelihood of a burglary or an earthquake, given an alarm was sounded and is also presented in Manhaeve et al. A subset of the probabilistic facts F ⊆ F defines a possible instantiation, or world:
t F := F ∪ {f | R ∪ F ⊨ f }.
For the example, t {burglary, hearsAlarm(mary)} = {burglary, hearsAlarm(mary), alarm, calls(mary)}.</p>
<p>Then, the probability of a world, P (t F ), is the product of the probabilities of the probabilistic facts in the world:
P (t F ) := Π f [i]∈F p[i]Π f [i]∈F \F (1 − p[i]).
For the running example, P (t {burglary, hearsAlarm(mary)} ) = 0.1 · 0.5 · (1 − 0.2) · (1 − 0.4). Finally, the probability of a query atom, q, is defined as the sum of the probabilities of the worlds containing q:
P (q) := F ∈F | q∈t F P (t F ).
ProbLog inference, specifically as it is applied in the deep extension proposed by Manhaeve et al. (2018), is a marginal inference problem. Specifically, the inference task is computing the marginal probability of a single query atom as shown above. This is equivalent to finding the weighted model count (WMC) of the worlds where the query atom is true. Thus, the exact marginal inference problem in ProbLog is #P-complete, i.e., it is at least NP-hard. This means that computing the exact probability of a query in a ProbLog program is a computationally challenging problem that requires exponential time in the worst case. Therefore, exact marginal inference in ProbLog is generally only feasible for small or moderately sized problems. For larger problems with more variables, approximate inference techniques are used to obtain approximate probabilities more efficiently De Raedt et al. [2007]; Moldovan et al. [2015].</p>
<p>DPL introduces syntax and semantics to ProbLog to support specifying probabilities of events with neural networks Manhaeve et al. [2018,2021]. Specifically, a set of neural annotated disjunctions (nADs) are specified by a user and take the form:
nn(id, v, u 1 ) :: h(v, u 1 ) ; · · · ; nn(id, v, u n ) :: h(v, u n ) ; ⊨ b 1 , · · · , b m ,
where the b i are atoms, v is a vector of features that the neural component, identified by id, has access to. Moreover, the output of the neural component, nn(id, v, u i ), is interpreted as the probability that the atom h i is true and the sum of the outputs of the neural model must sum to 1:
n i=1 nn(id, v, u 1 ) = 1.
The interpretation of an annotated disjunction is that whenever all of the atoms b 1 , · · · , b m are true, then each h i will be true with probability nn(id, v, u i ).</p>
<p>Inference in DPL is exactly the same as ProbLog marginal inference with a single query atom, except a forward pass is made with the neural network to compute the probabilities of the nADs. Learning the parameters of the DPL model is the task of finding the setting of the trainable parameters, denoted by x, that minimizes a sum of losses, L(). Each loss measures the distance between a vector of n desired probabilities p true and [P (q 1 ), · · · , P (q n )], the marginal inference values predicted by DPL:</p>
<p>arg min
x 1 n n i=1 L(P (q i ), p true [i]).
Though instantiating the marginal probability function is non-trivial and computationally expensive, marginal inference ultimately reduces to a series of differentiable algebraic operations and is therefore differentiable. DPL uses stochastic gradient descent to find parameters minimizing the training objective.</p>
<p>DPL is a NeSy-EBM. The fact probabilities, p, are partitioned into the observed NeSy-EBM symbolic variables x sy , the vector of symbolic parameters, w sy , and neural network outputs, g(x nn , w nn ). Without loss of generality, suppose
p = x sy w sy g(x nn , w nn ) .
The query atoms, i.e., the atoms present in the DPL model that are not specified in the set of probabilistic facts, correspond to the symbolic variables y.</p>
<p>The definition of the DPL symbolic potentials and energy function are tied to the inference task; a different definition of the symbolic potential and energy function is used to implement marginal versus MAP inference. As previously mentioned, DPL predictions are most commonly obtained by performing marginal inference for a single query atom. Moreover, a consequence of the DPL semantics is that the marginal inference problem reduces to an analytical expression composed of only product and sum operations. Thus, from the NeSy EBM perspective, to implement marginal inference DPL interprets a program with a set of probabilistic facts and data to define a symbolic potential for every marginal probability and then the energy function is simply the sum of the symbolic potentials. On the other hand, for MAP inference, DPL creates a symbolic potential for every possible world and the energy function is equivalent to the negative of the joint probability distribution implied by the DPL program. We will only formally cover the marginal inference case.</p>
<p>The probability of a world t F , defined by the subset of probabilistic facts F ∈ F is a function of the DPL fact probabilities, p, and hence is a function of x sy , w sy , and g(x nn , w nn ):
P t F (x sy , w sy , g(x nn , w nn )) := Π xsy[j]∈F x sy [j] · Π xsy[j]∈F \F (1 − x sy [j]) · Π wsy[j]∈F w sy [j] · Π wsy[j]∈F \F (1 − w sy [j]) · Π g(xnn,wnn)[j]∈F g(x nn , w nn )[j] · Π g(xnn,wnn)[j]∈F \F (1 − g(x nn , w nn )[j]) .
Then, as in ProbLog, the marginal probability of a query atom is a function of the probabilities of the worlds. For the world t F , defined by the subset of probabilistic facts F ⊆ F, let χ t F [·] be the indicator function identifying if a setting of the variables y matches the world t F :
χt F [ŷ] := 1 ((ŷ[i] = 1) =⇒ y[i] ∈ tF ) ∀i ∈ {1, · · · , ny} 0 o.w. . With χ t F [y]
, it is also possible to write the marginal probability of a variable as function of x sy , w sy , and g(x nn , w nn ):
P y[i] (xsy, wsy, g(xnn, wnn)) := ŷ∈{0,1} nyŷ [i]   F ∈P(F ) χt F [ŷ]Pt F (xsy, wsy, g(xnn, wnn))   .
Let d : [0, 1]×[0, 1] → R be a metric quantifying the distance between its two arguments. For each variable y[i] for i ∈ {1, · · · , n y } define a symbolic potential:</p>
<p>ψDP L,i(y, xsy, wsy, g(xnn, wnn)) := d(y[i], P y[i] (xsy, wsy, g(xnn, wnn))).</p>
<p>Let Ψ DP L (·) := ψ DP L,t F i (·) ny i=1 be the vector of all n y symbolic potentials. The energy function to produce marginal inference DPL predictions is then the summation of all the symbolic potentials:</p>
<p>EDP L(ΨDP L(y, xsy, wsy, g(xnn, wnn)))
:= ny i=1
ΨDP L(y, xsy, wsy, g(xnn, wnn))[i].</p>
<p>Clearly, the optimal value of the energy function is 0 and is achieved at the unique setting of the variables matching their corresponding marginal probability. Thus inference is equivalent to evaluating the marginal probabilities for each variable.</p>
<p>C.2 Logic Tensor Networks</p>
<p>Logic Tensor Networkss (LTNs) forwards deep neural network predictions into functions representing symbolic relations with real-valued or fuzzy logic semantics Badreddine et al. [2022]. The fuzzy logic functions are combined using a formula aggregator to define a satisfaction level. Badreddine et al. (2022) suggest using the product real logical semantics to translate logical statements, i.e., given two truth values a and b in [0, 1]:
¬(a) := 1 − a ∧(a, b) := a · b ∨(a, b) := a + b − a · b =⇒ (a, b) := a + b − a · b
Additionally, generalized mean semantics for existential and universal quantifiers are used for collections of truth values a = [a] n i=1 :
∃(a) := 1 n n i=1 a p i 1 p ∀(a) := 1 − 1 n n i=1 (1 − a i ) p 1 p ,
where p ∈ R + is a hyperparameter. For example, consider the logical statement ∃v ∈ V (P (u, v) ∧ Q(v)) .</p>
<p>LTNs instantiate predicate arguments with features. Let X U and X V be collections of variable feature vectors such that  (v). Then, the logical statement in the example is a composition of the specified real-logic operators and quantifiers. For a provided instance of the argument u the real-valued logic function for the example is:</p>
<p>hu(XU , XV , xQ; w)
:= 1 ∥V∥ v∈V nn(X[u], X[v]; w) · xQ[v] p 1 p .
Using the generalized mean semantics for the universal quantifier as the formula aggregator, the satisfaction level of the LTNs model prediction is:
G(w) := 1 − 1 ∥U∥ u∈U 1 − hu(XU , XV , xQ; w) p 1 p .
There are many ways to instantiate an LTN depending on the modeler's choice of real-logic semantics, the formula aggregator, and the logical relations. The example above illustrates a common setting of the real-logic semantics and the formula aggregator for a specific composition of logical formula.</p>
<p>The parameters of the LTNs are the deep neural network weights. Learning is the task of finding a setting of the weights which maximize the satisfaction of an aggregated set of logical formula instantiated with observations and features:
w * = arg max w G(w).
In other words, learning in LTNs can be understood as optimizing under first-order logic constraints relaxed into a loss function. There are a variety of real-valued logical semantics and formula aggregators that result in the satisfaction level function G(w) being differentiable with respect to the weights. Given a trained set of parameters obtained by learning, w * , inference is presented as querying the truth value of an instantiated predicate or logical formula. A prediction in LTNs in a multi-class or joint output setting such is obtained by evaluating the truth-value of all possible outputs and returning the highest valued configuration, i.e., the state with maximum satisfaction.</p>
<p>Through the lens of NeSy-EBMs, the system's fuzzy logic semantics define the symbolic potentials and the formula aggregator is the energy function. More formally, the NeSy-EBM unobserved and observed symbolic variables and neural network outputs partition the instantiated predicates of the real-valued logic functions h i . Each of the m real-valued logic functions can be written as a function of only the symbolic variables and the neural network outputs: h i (y, x sy , g(x nn , w nn )). The functions h i are the symbolic potentials of the NeSy-EBM:</p>
<p>ψLT N,i(y, xsy, wsy, g(xnn, wnn) := hi(y, xsy, g(xnn, wnn).</p>
<p>Let Ψ LT N s (·) := [ψ LT N s,i (·)] m i=1 be the vector of all m symbolic potentials. Then, the formula aggregator defines the energy function. Using the generalized mean semantics for the universal quantifier, the NeSy-EBM energy function for LTNs is:</p>
<p>ELT N (ΨLT N s(y, xsy, wsy, g(xnn, wnn)))
:= 1 m m i=1 1 − ΨLT N s(y, xsy, wsy, g(xnn, wnn))[i] p 1 p .
The LTNs framework is general and the scalability and expressivity of the system are dependent on the modeler's choice of the domain of the unobserved variables: Y, the real-valued logical semantics, and the formula aggregator. Furthermore, notice there is no explicit use of the symbolic parameters w sy as the LTNs framework uses standard realvalued logics that typically do not have trainable parameters. LTNs learning is finding the parameters with the highest satisfaction, i.e., learning with the energy loss in the NeSy-EBM framework. The NeSy-EBM framework connects LTNs to the EBM literature, which suggests principled alternative learning algorithms. Moreover, the NeSy-EBM framework sheds light on design choices for the various components of the LTNs to ensure the applicability of first-order methods for learning and desirable scalability and expressiveness properties of inference.</p>
<p>D Joint Reasoning in NeSy-EBMs</p>
<p>This section expands the discussion of joint reasoning in NeSy-EBMs. To reiterate, we highlight two important categories of NeSy-EBM energy functions: joint and independent. Formally, an energy function that is additively separable over the output variables y is an independent energy function, i.e., corresponding to each of the n y components of the output variable y there exists functions n y functions E 1 (y[1], x sy , w sy , g(x nn , w nn )), · · · , E ny (y[n y ], x sy , w sy , g(x nn , w nn )) such that
E(·) = ny i=1 E i (y[i], x sy , w sy , g(x nn , w nn )).
While a function that is not separable over output variables y is a joint energy function. This categorization allows for an important distinction during inference and learning. Independent energy functions simplify inference and learning as finding an energy minimizer, y * , can be distributed across the independent functions E i . In other words, the predicted value for a variable y[i] has no influence over that of y[j] where j ̸ = i and can therefore be predicted separately, i.e., independently. However, independent energy functions cannot leverage some joint information that may be used to improve predictions.</p>
<p>To illustrate, recall the example described in the Neural Probabilistic Soft Logic section where a neural network is used to classify the species of an animal in an image with external information. Figure 5 outlines the distinction between independent and joint prediction for this scenario. In Figure 5(a), the independent setting, the input is a single image, and the energy function is defined over the three possible classes: dog, cat, and frog. While in Figure 5(b), the joint setting, the input is a pair of images, and the energy function is defined for every possible combination of labels (e.g., (dog, dog), (dog, cat), etc.). The joint energy function of (b) leverages external information suggesting the images are of the same entity. Joint reasoning enables a model to make structured predictions that resolve contradictions an independent model could not detect.</p>
<p>For NeSy-EBMs, a joint energy function encodes dependencies between its output variables through its symbolic potentials. NeuPSL additionally benefits from scalable convex inference to speed up learning over a dependent set of output variables. As we see in the Experimental Evaluation section, utilizing joint inference and learning in NeSy-EBMs not only provides a boost in performance but produces results that non-joint methods cannot (even with five times the amount of data).</p>
<p>E NeuPSL Parameter Learning</p>
<p>This section details the NeuPSL parameter learning algorithm. We begin by discussing degenerate solutions to the energy loss problem and techniques for overcoming them. We then provide the precise parameter updates we use to efficiently fit NeuPSL model parameters while avoiding the discussed degenerate solutions.</p>
<p>E.1 Energy Loss Degenerate Solutions</p>
<p>In this section, we show two degenerate solutions of the energy loss learning problem for NeuPSL and methods for overcoming them. Recall that the NeuPSL energy loss learning Note that the symbolic parameters are constrained to be nonnegative real numbers. Furthermore, as every symbolic potential has the form:</p>
<p>ϕi(y, xsy, xnn, wnn) = max(li(y, xsy, gnn(xnn, wnn)), 0) α we have that ϕ i (y, x sy , x nn , w nn ) ≥ 0 for all settings of the variables y, x sy , x nn , w nn . Thus,
Φ i (y, x sy , x nn , w nn ) := j∈ti ϕ i (y, x sy , x nn , w nn ) ≥ 0 and Φ(y, x sy , x nn , w nn ) := [Φ i (y, x sy , x nn , w nn )] r i=1 ⪰ 0. Therefore, we have that L(w nn , w psl , S) = P i=1 min z|((yi,t,z),xsy)∈Ω w T psl Φ((y i,t , z), x sy,i , x nn,i , w nn ) ≥ 0
In fact, L(w nn , w psl , S) = 0 when w psl = 0. The 0 solution to the weight learning problem is degenerate and should be avoided. Precisely, w psl = 0 results in a collapsed energy function: a function that assigns all points y ∈ Y to the same energy. Collapsed energy functions have no predictive power since inference, i.e., finding a lowest energy state of the variables is trivial and uninformative. To overcome this degenerate solution a simplex constraint on the symbolic parameters, w psl ∈ ∆ r := {w ∈ R r + ∥w∥ 1 = 1}, is added, making the degenerate solution w psl = 0 infeasible. This constraint also ensures the non-negativity of the parameters and does not inhibit the expressivity of NeuPSL when the deep HL-MRF is exclusively used to obtain MAP inference predictions. This property of (deep) HL-MRFs was shown by Srinivasan et al. (2021), where they proved and leveraged the fact that MAP inference in HL-MRFs is invariant to the scale of the weights. Formally, for all weight configurations w psl and scalarsc ∈ R + , arg max y|(y,xsy)∈Ω E(y, x sy , x nn , w nn , w psl ) = arg max y|(y,xsy)∈Ω E(y, x sy , x nn , w nn ,c · w psl )</p>
<p>The w psl = 0 is infeasible with the simplex constraint; however, an additional degenerate solution arises from its introduction. This is because the energy loss is concave in the symbolic parameters w psl for fixed w nn and S, as is shown in following lemma and its corresponding proof. Consequently, a solution to the constrained energy loss learning problem must exist at corner points of the simplex. Lemma 1. The energy loss function
L(w nn ,w psl , S) = P i=1 min z|((yi,t,z),x)∈Ω w T psl Φ((y i,t , z), x sy,i , x nn,i , w nn ) is concave in w psl . Proof. For all i E((y i,t ,z * i ), x sy,i , x nn,i , w nn , w psl ) = inf z|((yi,t,z),xsy)∈Ω w T psl Φ((y i,t , z), x sy,i , x nn,i , w nn )
is a pointwise infimum of a set of affine, hence concave, functions of w psl and is therefore concave [Boyd and Vandenberghe, 2004]. Therefore,
L(w nn , w psl , S) = P i=1 E((y i,t , z * i ), x sy,i , x nn,i , w nn , w psl )(7)
is a sum of concave functions of w psl and is concave.</p>
<p>Additionally, note that the unit simplex, ∆ r , is a convex set, and, more precisely, a polyhedron. Following from its definition, a concave function is minimized over a polyhedron at one of the vertices. This solution is undesirable for the energy minimization problem because each symbolic relation corresponding to the parameters should have an influence over the model predictions. For this reason, we propose using a negative logarithm as a parameter regularizer, giving the simplex corner solutions infinitely high energy. With negative log regularization and simplex constraints, energy loss symbolic parameter learning is:
min wnn∈Wnn,w psl ∈∆ r L(w nn , w psl , S) − r i=1 log b (w psl [i])(8)</p>
<p>E.2 Exponentiated Gradient Descent</p>
<p>As suggested by Dickens et al. (2022), we minimize the energy loss with respect to the symbolic parameters constrained to the unit simplex via normalized exponentiated gradient descent [Kivinen and Warmuth, 1997;Shalev-Shwartz, 2012]. Then, minimization over neural parameters is performed with standard gradient descent. With an initial step size parameter η &gt; 0, the parameter updates are
w k+1 nn = w k nn + η∇w nn L(w k nn , w k psl , S) w k+1 psl [i] = w k psl [i] exp{−η ∂L(w k nn ,w k psl ,S) ∂w k psl [i] } r j=1 exp{− ∂L(w k nn ,w k psl ,S) ∂w k psl [j] } , ∀i = 1, · · · , r
With this update, the symbolic parameter w psl is guaranteed to satisfy the simplex constraints. </p>
<p>F.1 MNIST-Add</p>
<p>The MNIST-Add task, originally proposed by Manhaeve et al. (2018), constructs addition equations using MNIST images with only their summation as a label. As shown in Figure 6, equations consist of two numbers each comprised of k MNIST images, i.e., MNIST-Add1 consists of two numbers with one image each (k = 1) and MNIST-Add2 consists of two numbers with two images each (k = 2). Given two numbers (2 * k images), the classification task is to predict the sum.</p>
<p>Generation Addition examples are created by shuffling a list of MNIST images and then partitioning, in order, pairs of numbers. For example, let the corresponding list of MNIST images be [ , , , , , ]. First this list is shuffled, [ , , , , , ], and then partitioned into 2 * k tuples in order. In this scenario, MNIST-Add1 creates 3 addition examples,
[ , ], [ , ], [ , ] .
Overlap The process for generating addition examples for overlap variations is the same, but the list of MNIST images contains duplicates. Specifically, a list of n ∈ {40, 60, 80} unique MNIST images are randomly selected without replacement from the original MNIST train split. Then, a list of m ∈ {0, n/2, n} images are randomly selected with replacement from these n images. These two lists are combined to create a final list of MNIST images (n + m images). This list is used to generate MNIST-Add examples using the process Figure 7: An example of a valid Visual-Sudoku-Classification puzzle.</p>
<p>described above. This process is then repeated to generate a validation set and then repeated again to generate the test set. The MNIST images in the test set are pulled from the original MNIST test split to avoid leaking data and n = 1000. In this task, 4x4 Sudoku puzzles are constructed using unlabeled MNIST images, e.g., Figure 7. The model must identify whether a puzzle is correct, i.e., no duplicate digits in any row, column, or square.</p>
<p>F.2 Visual-Sudoku-Classification</p>
<p>Generation Puzzles are created from a list of MNIST images, where this list has an equal representation of each class (e.g., zeroes, ones, twos, and threes). To create a "correct" puzzle, four images of each class are randomly selected without replacement from this list and arranged in a layout that adheres to the traditional sudoku puzzle rules. This layout is randomly chosen from all possible correct solutions. The first image represents the top-left corner, and the final image represents the bottom-right corner of the puzzle. For example, Figure 7 would be {1, 2, 4, 3, 4, 3, 1, 2, 2, 4, 3, 1, 3, 1, 2, 4}.</p>
<p>In addition to generating correctly solved Sudoku puzzles, incorrect puzzles are generated. Instead of randomly creating puzzles and checking if they are correct, we begin with the correct puzzles and corrupt them. In this way, we hope to create puzzles that are more subtle and closer to the incorrect puzzles that a human may create, as opposed to randomly generated puzzles that may be obviously incorrect.</p>
<p>The corruptions are done in one of two ways: replacement or substitution. A replacement corruption chooses a random cell and replaces it with a random image of another class. Replacement images are chosen uniformly from the same split. A substitution corruption randomly chooses two cells in the same puzzle and swaps them.</p>
<p>Each correct puzzle has one corrupted puzzle made from it, resulting in a balanced dataset. A fair coin is flipped for each puzzle to decide which corruption method will be used. After each corruption is made, a fair coin is flipped to see if the process continues. After the complete corruption process, the puzzle is checked to ensure it is not a valid Sudoku puzzle.  If the puzzle is invalid, it is added to the split. Otherwise, the process is repeated using the same correct puzzle.</p>
<p>Overlap The process for generating puzzle examples for overlap variations is the same, but the list of MNIST images contains duplicates. Specifically, a list of n ∈ {64, 128, 256} unique MNIST images are randomly selected without replacement from the original MNIST train split, with an equal representation of four classes (zeros, ones, twos, and threes). Then, a list of m ∈ {0, n, 3.0 · n} images are randomly selected with replacement from these n images, where there is an equal representation of the four class. These two lists are combined to create a final list of MNIST images (n + m images). This list is used to generate puzzles using the process described above. This process is then repeated to generate a validation set and then repeated again to generate the test set. The MNIST images in the test set are pulled from the original MNIST test split to avoid leaking data and n = 1000.</p>
<p>G NeuPSL Models</p>
<p>This section provides an overview of the NeuPSL models used in the Experimental Evaluation. The subsequent subsections will examine the symbolic model, neural model, and hyperparameters employed for each setting.</p>
<p>G.1 MNIST-Add1</p>
<p>The NeuPSL model for the MNIST-Add1 experiment integrates the neural model summarized in Table 2 with the symbolic model depicted in Figure 8. The symbolic model contains the following predicates:</p>
<p>• NEURAL(Img, X) The NEURAL predicate is the class probability for each image as inferred by the neural network. Img is MNIST image identifier and X is a digit class that the image may represent.</p>
<p>• DIGITSUM(X, Y, Z) The DIGITSUM predicate determines if two digits (X and Y) sum to a number (Z). For   example, DIGITSUM(4, 5, 9) would return 1 as 4 added to 5 is 9. Conversely, DIGITSUM(2, 2, 5) would return 0 as 2 added to 2 is not 5.</p>
<p>• SUM(Img1, Img2, Z) The SUM predicate is the probability that the digits represented in the images identified by arguments Img1 and Img2 add up to the number identified by the argument Z. This predicate instantiates decision variables, i.e., variables from this predicate are not fixed during inference and learning as described in the NeSy EBM, NeuPSL, and Inference and Learning sections.</p>
<p>• POSSIBLEDIGITS(X, Z) The POSSIBLEDIGITS predicate determines if a digit (X) can be included in a sum that equals a number (Z). For example, POSSIBLEDIGITS(9, 0) would return 0 as no positive digit when added to 9 will equal 0. Conversely, POSSIBLEDIGITS(9, 17) would return 1 as 8 added to 9 equals 17.</p>
<p>The Digit Sums rules represents the summation of the two images Img1 and Img2, i.e., if the neural model labels the image id Img1 as digit X and Img2 as Y and the digits X and Y sum to Z then the sum of the images must be Z.</p>
<p>The Digit Constraints rules restrict the possible values of the SUM predicate based on the neural model's prediction. For instance, if the neural model predicts that the digit label for image Img1 is 1, then the sum that Img1 is involved in cannot be any less than 1 or greater than 10.</p>
<p>Hyperparameters Table 3 presents the hyperparameter values and tuning ranges for the NeuPSL MNIST-Add1 models. The hyperparameter search was conducted on a single split generated from a list of 600 MNIST images, with the best parameters applied to all data settings. Any unspecified values were left at their default settings. The ADMM Max Iterations parameter refers to the number of ADMM iterations conducted between each step of gradient descent during the learning process. The Neural Learning Rate parameter refers to the learning rate of the neural model used to predict image labels.</p>
<p>G.2 MNIST-Add2</p>
<p>The NeuPSL model for the MNIST-Add2 experiment integrates the neural model summarized in Table 2 with the symbolic model depicted in Figure 9. The symbolic model contains the following predicates:</p>
<p>• NEURAL(Img, X) The NEURAL predicate is the class probability for each image as inferred by the neural network. Img is MNIST image identifier and X is a digit class that the image may represent.</p>
<p>• DIGITSUM(X, Y, Z) The DIGITSUM predicate determines if two digits (X and Y) sum to a number (Z). For example, DIGITSUM(4, 5, 9) would return 1 as 4 added to 5 is 9. Conversely, DIGITSUM(2, 2, 5) would return 0 as 2 added to 2 is not 5.</p>
<p>• SUM(Img1, Img2, Img3, Img4, Z) The SUM predicate is the probability that the numbers represented in the images identified by arguments (Img1, Img2) and (Img3, Img4) add up to the number identified by the argument Z. This predicate instantiates decision variables, i.e., variables from this predicate are not fixed during inference and learning as described in the NeSy EBM, NeuPSL, and Inference and Learning sections.</p>
<p>• POSSIBLETENDIGITS(X, Z) POSSIBLETENDIGITS takes a 0 or 1 value representing whether the digit identified by the argument X is possible when it is in the tens place of a number involved in a sum that totals to the number identified by the argument Z. For instance POSSIBLETENDIGITS(9, 70) = 0 as no positive number added to a number with a 9 in the tens place, e.g., 92, equals 70, while POSSIBLETENDIGITS(9, 170) = 1 as 78 added to 92 is 170.</p>
<p>• POSSIBLEONESDIGITS(X, Z)POSSIBLEONESDIGITS takes a 0 or 1 value representing whether the digit identified by the argument X is possible when it is in the ones place of a number involved in a sum that totals to the number identified by the argument Z. For instance # Tens Digit Sums
w1 : NEURAL(Img1, X) ∧ NEURAL(Img3, Y) ∧ DIGITSUM(X, Y, Z) → IMAGEDIGITSUM(Img1, Img3, Z) w2 : ¬NEURAL(Img1, X) ∧ NEURAL(Img3, Y) ∧ DIGITSUM(X, Y, Z) → ¬IMAGEDIGITSUM(Img1, Img3, Z) w3 : NEURAL(Img1, X) ∧ ¬NEURAL(Img3, Y) ∧ DIGITSUM(X, Y, Z) → ¬IMAGEDIGITSUM(Img1, Img3, Z) # Ones Digit Sums w4 : NEURAL(Img2, X) ∧ NEURAL(Img4, Y) ∧ DIGITSUM(X, Y, Z) → IMAGEDIGITSUM(Img2, Img4, Z) w5 : ¬NEURAL(Img2, X) ∧ NEURAL(Img4, Y) ∧ DIGITSUM(X, Y, Z) → ¬IMAGEDIGITSUM(Img2, Img4, Z) w6 : NEURAL(Img2, X) ∧ ¬NEURAL(Img4, Y) ∧ DIGITSUM(X, Y, Z) → ¬IMAGEDIGITSUM(Img2, Img4, Z) # Place Digit Sums IMAGEDIGITSUM(Img1, Img3, Z10) ∧ IMAGEDIGITSUM(Img2, Img4, Z1) ∧ PLACENUMBERSUM(Z10, Z1, Z)
→ SUM(Img1, Img2, Img3, Img4, Z)</p>
<p>¬IMAGEDIGITSUM(Img1, Img3, Z10) ∧ IMAGEDIGITSUM(Img2, Img4, Z1) ∧ PLACENUMBERSUM(Z10, Z1, Z)</p>
<p>→ ¬SUM(Img1, Img2, Img3, Img4, Z)</p>
<p>IMAGEDIGITSUM(Img1, Img3, Z10) ∧ ¬IMAGEDIGITSUM(Img2, Img4, Z1) ∧ PLACENUMBERSUM(Z10, Z1, Z)</p>
<p>→ ¬SUM(Img1, Img2, Img3, Img4, Z)  </p>
<h1>Tens Digit Constraints</h1>
<h1>Column Constraint</h1>
<p>NEURAL(Puzzle, X, +Y, Number) = 1.</p>
<h1>Block Constraint</h1>
<p>NEURAL(Puzzle, "0", "0", Number) + NEURAL(Puzzle, "0", "1", Number) + NEURAL(Puzzle, "1", "0", Number) + NEURAL(Puzzle, "1", "1", Number) = 1.</p>
<p>NEURAL(Puzzle, "2", "0", Number) + NEURAL(Puzzle, "2", "1", Number) + NEURAL(Puzzle, "3", "0", Number) + NEURAL(Puzzle, "3", "1", Number) = 1.</p>
<p>NEURAL(Puzzle, "0", "2", Number) + NEURAL(Puzzle, "0", "3", Number) + NEURAL(Puzzle, "1", "2", Number) + NEURAL(Puzzle, "1", "3", Number) = 1.</p>
<p>NEURAL(Puzzle, "2", "2", Number) + NEURAL(Puzzle, "2", "3", Number) + NEURAL(Puzzle, "3", "2", Number) + NEURAL(Puzzle, "3", "3", Number) = 1. • IMAGEDIGITSUM(Img1, Img2, Z) The IMAGEDIGITSUM predicate is the probability that the digits represented in the images specified by Img1 and Img2 will sum up to the number indicated by the argument Z. These variables are considered latent in the NeuPSL model as there are no truth labels for sums of images in the ones or tens places.</p>
<p>• PLACENUMBERSUM (Z10, Z1, Z) The PLACENUMBERSUM predicate takes a 0 or 1 value representing whether the sum of the numbers Z10 and Z1, where Z10 is the sum of digits in the tens place and Z1 is the sum of digits in the one place, adds up to the number Z. For instance PLACENUMBERSUM(1, 15, 25) is 1 as 1 · 10 + 15 = 25.</p>
<p>The Tens Digit Sums and Ones Digit Sums rules compute the sum of two images in the same manner as the Digit Sums rules in the MNIST-Add1 model. The sum of the digits is captured by the latent variables instantiated by the predicate IMAGEDIGITSUM.</p>
<p>The Place Digit Sums rules use the value of the IMAGEDIGITSUM variables to infer the sum of the images. More specifically, if the IMAGEDIGITSUM of the images in the tens place, Img1 and Img3), is Z10, and the IMAGEDIGITSUM of the images in the ones place, Img2 and Img4) is Z1, and if according to PLACENUMBERSUM the sum of the numbers Z10 and Z1 is Z, then the SUM of the images must be Z. Notice that these rules are hard constraints as it is always possible and desirable to find values of the IMAGEDIGITSUM and SUM variables that satisfy these relations.</p>
<p>The Tens Digit Constraint rules restrict the possible values of the SUM predicate based on the neural model's prediction  for the digit in the tens place of a number. For instance, if the neural model predicts that the digit label for the image Img1 is 1 and Img1 is in the tens place of a number, then the sum that Img1 is involved in cannot be any less than 10 or greater than 118.</p>
<p>The Ones Digit Constraint rules restrict the possible values of the SUM predicate based on the neural model's prediction for the digit in the ones place of a number. For instance, if the neural model predicts that the digit label for the image Img2 is 5 and Img2 is in the one place of a number, then the sum that Img2 is involved in cannot be any less than 5 or greater than 194.</p>
<p>The Number Sum Constraint rules limit the values that IMAGEDIGITSUM and SUM can take using constraints representing the possible sums in the tens and ones place. For instance, if the IMAGEDIGITSUM of two images, Img1 and Img3, both in the tens place of two numbers being added, is 17, then the SUM cannot be less than 170 or greater than 188. Furthermore, if the IMAGEDIGITSUM of two images, Img2 and Img4, both in the tens place of two numbers being added, is 17, then the SUM cannot be less than 17 or greater than 197, and must have a 7 in the ones place.</p>
<p>Hyperparameters Table 4 presents the hyperparameter values and tuning ranges for the NeuPSL MNIST-Add2 models. The hyperparameter search was conducted on a single split generated from a list of 600 MNIST images, with the best parameters applied to all data settings. Any unspecified values were left at their default settings. The ADMM Max Iterations parameter refers to the number of ADMM iterations  </p>
<p>G.3 Visual-Sudoku-Classification</p>
<p>The NeuPSL model for the Visual-Sudoku-Classification experiment integrates the neural model summarized in Table 2 with the symbolic model depicted in Figure 10. The symbolic model contains the following predicates:</p>
<p>• NEURAL(Puzzle, X, Y, Number) The NEURAL predicate contains the output class probability for each digit image inferred by the neural network. Puzzle is sudoku puzzle's identifier, X and Y represent the location of image in the puzzle, and Number is a digit that image may represent.</p>
<p>• DIGIT(Puzzle, X, Y, Number) The DIGIT predicate has the same arguments as the NEURAL predicate, representing PSL's digit prediction on the image.</p>
<p>• FIRSTPUZZLE, X, Y(Puzzle) The FIRSTPUZZLE predicate pins the values for the first row of the first puzzle to an arbitrary assignment. This is used to force the neural model to learn the correct label representation for easier evaluation.</p>
<p>The Row Constraint, Column Constraint, and Block Constraint rules encode the standard Sudoku rules into constraints. These constraints restrict multiple instances of a digit from appearing in a row, column, or block, respectively.</p>
<p>The Pin First Column rules are used to assign arbitrary classes to the first row of a Sudoku puzzle. The first row of the first correct puzzle from the training set is used to determine this arbitrary label assignment. By assigning the first row to arbitrary classes, the neural model is provided a starting point for differentiating between the different classes and makes the final evaluation easier.</p>
<p>Hyperparameters Table 5 presents the hyperparameter values and tuning ranges for the NeuPSL Visual-Sudoku-Classification models. A hyperparameter search was conducted for each data setting on the initial split, with the optimal hyperparameters applied to all subsequent splits. Any unspecified values were left at their default settings. The ADMM Max Iterations parameter refers to the number of ADMM iterations conducted between each step of gradient descent during the learning process. The Neural Learning Rate parameter refers to the learning rate of the neural model used to predict image labels.</p>
<p>G.4 Citation Network Node Classification</p>
<p>The NeuPSL model for the Citation Network Node Classification experiments integrates a single-layered neural model with the symbolic model depicted in Figure 11. The singlelayer neural model connects the input to a dense-layered output containing a soft-max activation, kernel regularizer, and bias regularizer. The symbolic model contains the following predicates:</p>
<p>• NEURAL(Paper, Label) The NEURAL predicate contains the output class probability for each paper as  inferred by the neural network. Paper is the identifier and Label is the category it can take.</p>
<p>• CATEGORY(Paper, Label) The CATEGORY predicate has the same arguments as the NEURAL predicate and represents PSL's label prediction on the paper.</p>
<p>• LINK(Paper1, Paper2) The LINK predicate denotes whether two papers share a citation link.</p>
<p>The Label Propagation rule propagates node labels to neighbors. In this sense, it encodes the idea that papers shar-ing a citation link are likely to have the same underlying label category.</p>
<p>Hyperparameters Table 6 presents the hyperparameter values and tuning ranges for the NeuPSL citation network node classification models. A hyperparameter search was conducted for each data setting on the initial split, with the optimal hyperparameters applied to all subsequent splits. The search process was divided into two distinct stages: a neural hyperparameter search and a symbolic hyperparameter search. The optimal hyperparameters identified during  Iterations parameter refers to the number of ADMM iterations conducted between each step of gradient descent during learning. The Alpha is a value that weights the importance of the structural gradient passed back from the symbolic potentials and the gradient with respect to the labels. The Gradient</p>
<p>Steps parameter refers to the number of gradient steps taken for joint learning. The Gradient</p>
<p>Step Size parameter refers to the step size used in learning the symbolic parameters.</p>
<p>H Baseline Models</p>
<p>This section provides additional details of the baseline models used in the Experimental Evaluation. The subsequent subsections will examine the architectural structure and hyperparameters employed for each setting.</p>
<p>H.1 MNIST-Add</p>
<p>The CNN baseline neural models for the MNIST-Add1 and MNIST-Add2 experiments are summarized in Table 7 and  Table 8 respectively. These models take as input either two MNIST images (MNIST-Add1) or four MNIST images   (MNIST-Add1) and output a probability distribution of the resulting sum. Both models were trained to minimize crossentropy loss.</p>
<p>Hyperparameters Table 9 presents the hyperparameter values and tuning ranges for the baseline MNIST-Add1 and MNIST-Add2 models. A hyperparameter search was conducted for three data sizes on the initial split, with the optimal results applied to all subsequent splits. All experiments involving overlap utilized the best hyperparameters identified from the MNIST-Add1 300 additions and MNIST-Add2 150 additions searches. Any unspecified values were left at their default settings. The Batch Size parameter refers to the number of addition examples per batch of training and evaluation. The Learning Rate parameter refers to the learning rate of the model used to predict. </p>
<p>H.2 Visual-Sudoku-Classification</p>
<p>The CNN-Visual and CNN-Digit baseline neural models for the Visual-Sudoku-Classification experiments are summarized in Table 10 and Table 11 respectively. The input to the CNN-Visual baseline takes 16 MNIST images as input and produces a probability distribution indicating the likelihood that the images form a correct puzzle. The input to the CNN-Digit baseline takes 16 MNIST image ground truth labels as input and produces a probability distribution indicating the likelihood that the images' labels form a correct puzzle. Both models were trained to minimize cross-entropy loss.</p>
<p>Hyperparameters Table 12 presents the hyperparameter values and tuning ranges for the CNN-Visual and CNN-Digit    baseline neural models. A hyperparameter search was conducted for each data setting on the initial split, with the optimal hyperparameters applied to all subsequent splits. Any unspecified values were left at their default settings. The Learning Rate parameter refers to the learning rate of the neural model.</p>
<p>H.3 Citation Network Node Classification</p>
<p>As described in the Experimental Evaluation, the LP P SL and Neural P SL baseline models represent the distinct symbolic and neural components used in NeuPSL LP . Therefore, the LP P SL model is depicted in Figure 11, and the Neural P SL model is a single-layered neural model connecting the input to a dense-layered output containing a soft-max activation, kernel regularizer, and bias regularizer. Hyperparameters were set to the best values found for the NeuPSL LP neural hyperparameter search (Table 6).</p>
<p>The GCN model follows the same architecture proposed by Kipf and Welling [2017] and is summarized in Table 13. The GCN takes a collection of node identifiers as input and outputs each node's class label.</p>
<p>Hyperparameters Table 14 presents the hyperparameter values and tuning ranges for the GCN model. Each GCN model was trained with 50 percent dropout, a batch size of 1024, and 1000 epochs (utilizing early stopping on the validation set with a patience of 250). A hyperparameter search was conducted for each data setting on the initial split, with the optimal hyperparameters applied to all subsequent splits. Any unspecified values were left at their default settings.  Table 15: Test set accuracy and standard deviation on MNIST-Add. Results reported here are run and averaged over the same ten splits.</p>
<p>I Extended Evaluation Details</p>
<p>This section provides NeSy model details and expands the Experimental Evaluation presented earlier on MNIST-Add and provides inference and learning times for all experiments.</p>
<p>I.1 NeSy Model Details</p>
<p>The NeSy methods used in this work, along with their respective publications and implementation codes, are listed below: </p>
<p>I.2 MNIST-Add Extended Results</p>
<p>In this section, we conduct an extended analysis of the MNIST-Add experiment by comparing the performance of NeuPSL, DeepProbLog (DPL) [Manhaeve et al., 2021], Logic Tensor Networks (LTNs) [Badreddine et al., 2022] and neural baselines in non-overlap settings with commonly used split sizes in the research community [Manhaeve et al., 2021]. Ten train splits are generated by randomly selecting, without replacement, n ∈ {600, 6000, 50000} unique MNIST images from the original MNIST train split and converted to MNIST additions as described in the Datasets appendix. This process is then repeated to create validation and test splits, with the test splits being pulled from the original MNIST test split to prevent data leakage and n = 10000. Table 15 shows the average accuracy and standard deviation for MNIST-Add1 and MNIST-Add2. * The best average accuracy and results within a standard deviation of the * In the largest data setting, there appeared to be an error with DPL, and the results produced were random. Rather than present these potentially misleadingly low results, we indicate with '-'.     Figure 12 summarizes the inference and learning times associated with the MNIST-Add experiments described in Section 6.1. When evaluating the performance of the NeSy meth- ods that perform complex symbolic inference (DPL and Ne-uPSL), a trade-off is observed. NeuPSL inference runs an order of magnitude faster than DPL but, surprisingly, takes longer to train on roughly the same number of gradient steps. This timing difference derives from NeuPSL taking full gradient steps over the entire train dataset while DPL takes batched stochastic gradient steps. Symbolic inference is a subprocess of NeSy-EBM learning, and DPL performs inference over a single addition, while NeuPSL performs inference over every addition. An interesting direction for future work is to take batched gradient steps during NeuPSL learning, where the batches contain a set of overlapping additions.</p>
<p>I.3 Inference and Learning Runtime</p>
<p>Compared with the CNN and LTN models, DPL and Ne-uPSL run orders of magnitude slower. CNN and LTN inference is equivalent to making a feed-forward pass through a neural network. This will, therefore, be significantly faster than the complex symbolic inference done in DPL and Ne-uPSL, but comes with a decrease in predictive performance.</p>
<p>J Computational Hardware Details</p>
<p>All timing experiments were performed on an Ubuntu 22.04.1 Linux machine with Intel Xeon Processor E5-2630 v4 at 3.10GHz.</p>
<p>Figure 1 :
1NeuPSL inference and learning pipeline.</p>
<p>Figure 2 :
2Example of overlapping MNIST images in MNIST-Add1. On the left, distinct images are used for each zero. On the right, the same image is used for both zeros.</p>
<p>Figure 3 :
3Average test set accuracy and standard deviation on MNIST-Add datasets with varying amounts of overlap.</p>
<p>Figure 3
3summarizes average performance for varying overlap settings. Each panel varies the number of additions for a set number of unique MNIST images. For example, the upper left panel presents the results obtained for MNIST-Add1 with 40 unique images used to generate 20, 30, and 40 additions.</p>
<p>Inspired by the Visual Sudoku problem proposed by Wang et al. (2019), Augustine et al. (2022) introduced a novel NeSy task, Visual-Sudoku-Classification.</p>
<dl>
<dt>Figure 4 :</dt>
<dt>4Average test set accuracy and standard deviation on Visual-Sudoku-Classification with varying amounts of overlap.</dt>
<dd>
<p>burglary. 0.2 :: earthquake. 0.5 :: hearsAlarm(mary). 0.4 :: hearsAlarm(john). # Rules alarm : − earthquake. alarm : − burglary. calls(X) : − alarm, hearsAlarm(X).</p>
</dd>
</dl>
<p>Figure 5 :
5Example of non-joint and joint energy functions.</p>
<p>Figure 6 :
6Example of MNIST-Add1 and MNIST-Add2.F Dataset DetailsIn this section, we provide additional information on the MNIST-Add and Visual-Sudoku-Classification datasets. Both datasets are generated from the original MNIST image classification dataset introduced by LeCun et al.(1998). Each MNIST image is a 28x28 matrix consisting of pixel grayscale values normalized to lie in the range [0, 1].</p>
<p>Inspired by the Visual Sudoku problem proposed by Wang et al. (2019), Augustine et al. (2022) introduced a novel NeSy task, Visual-Sudoku-Classification.</p>
<p>:
NEURAL(Img1, X) ∧ NEURAL(Img2, Y) ∧ DIGITSUM(X, Y, Z) → SUM(Img1, Img2, Z) w2 : ¬NEURAL(Img1, X) ∧ NEURAL(Img2, Y) ∧ DIGITSUM(X, Y, Z) → ¬SUM(Img1, Img2, Z) w3 : NEURAL(Img1, X) ∧ ¬NEURAL(Img2, Y) ∧ DIGITSUM(X, Y, Z) → ¬SUM(Img1,Img2, Z) # Digit Constraints w4 : NEURAL(Img1, +X) &gt;= SUM(Img1, Img2, Z){X : POSSIBLEDIGITS(X, Z)} w5 : NEURAL(Img2, +X) &gt;= SUM(Img1, Img2, Z){X : POSSIBLEDIGITS(X, Z)} # Simplex Constraints SUM(Img1, Img2, +Z) = 1.</p>
<p>Figure 8 :
8NeuPSL</p>
<p>w7 :
w7NEURAL(Img1, +X) &gt;= SUM(Img1, Img2, Img3, Img4, Z){X : POSSIBLETENSDIGITS(X, Z)} w8 : NEURAL(Img3, +X) &gt;= SUM(Img1, Img2, Img3, Img4, Z){X : POSSIBLETENSDIGITS(X, Z)} # Ones Digit Constraints w9 : NEURAL(Img2, +X) &gt;= SUM(Img1, Img2, Img3, Img4, Z){X : POSSIBLEONESDIGITS(X, Z)} w10 : NEURAL(Img4, +X) &gt;= SUM(Img1, Img2, Img3, Img4, Z){X : POSSIBLEONESDIGITS(X, Z)} # Digit Sum Constraints w11 : NEURAL(Img1, +X) &gt;= IMAGEDIGITSUM(Img1, Img3, Z){X : POSSIBLEDIGITS(X, Z)} w12 : NEURAL(Img3, +X) &gt;= IMAGEDIGITSUM(Img1, Img3, Z){X : POSSIBLEDIGITS(X, Z)} w13 : NEURAL(Img2, +X) &gt;= IMAGEDIGITSUM(Img2, Img4, Z){X : POSSIBLEDIGITS(X, Z)} w14 : NEURAL(Img4, +X) &gt;= IMAGEDIGITSUM(Img2, Img4, Z){X : POSSIBLEDIGITS(X, Z)} # Number Sum Constraints IMAGEDIGITSUM(Img1, Img3, +X) &gt;= SUM(Img1, Img2, Img3, Img4, Z){X : POSSIBLETENSSUMS(X, Z)} IMAGEDIGITSUM(Img2, Img4, +X) &gt;= SUM(Img1, Img2, Img3, Img4, Z){X : POSSIBLEONESSUMS(X, Z)} # Simplex Constraints SUM(Img1, Img2, Img3, Img4, +X) = 1.IMAGEDIGITSUM(Img1, Img2, +X) = 1.</p>
<p>Figure 9 :
9NeuPSL</p>
<h1>0 Figure 10 :</h1>
<p>010Pin First Column w2 : FIRSTPUZZLE(Puzzle, X, Y) − NEURAL(Puzzle, X, Y) = 0.NeuPSL Visual-Sudoku-Classification Symbolic Model POSSIBLEONESDIGITS(9, 7) = 0 as no positive number added to a number with a 9 in the ones place, e.g., 9, equals 7 while POSSIBLEONESDIGITS(9, 170) = 1 as 71 added to 99 is 170.</p>
<p>Figure 12 :
12Inference and learning time for MNIST-Add experiments presented in Section 6.1.</p>
<p>Test set accuracy and inference runtime in seconds on two citation network datasets.Method 
Citeseer 
Cora 
(Accuracy) 
(Seconds) 
(Accuracy) 
(Seconds) </p>
<p>Neural P SL 
57.76 ± 1.71 
-
57.12 ± 2.13 
-
LP P SL 
50.88 ± 1.18 
-
73.32 ± 2.39 
-</p>
<p>DeepProbLog 
timeout 
timeout 
timeout 
timeout 
DeepStochLog 61.30 ± 1.44 34.42 ± 0.87 69.96 ± 1.47 165.28 ± 4.49 
GCN 
67.50 ± 0.57 3.10 ± 0.04 79.52 ± 1.13 
1.31 ± 0.01 
NeuPSL LP 
67.34 ± 1.17 3.98 ± 0.05 76.80 ± 2.27 
4.00 ± 0.31 
NeuPSL LP +F P 68.48 ± 1.22 4.23 ± 0.05 81.22 ± 0.79 
4.07 ± 0.14 </p>
<p>Table 1: </p>
<p>problem is :
isarg min (wnn,w psl )∈R nn ×R r + L(wnn, w psl , S)= 
arg min </p>
<p>(wnn,w psl )∈R nn ×R r </p>
<ul>
<li></li>
</ul>
<p>P </p>
<p>i=1 </p>
<p>E((yi,t, z  *<br />
i ), xsy,i, xnn,i, wnn, w psl ) </p>
<p>= 
arg min </p>
<p>(wnn,w psl )∈R nn ×R r </p>
<ul>
<li></li>
</ul>
<p>P </p>
<p>i=1 </p>
<p>min </p>
<p>z|((y i,t ,z),x)∈Ω </p>
<p>w T 
psl Φ((yi,t, z), xsy,i, xnn,i, wnn) </p>
<p>Table 2 :
2Neural architecture used in NeuPSL for both MNIST-Add and Visual-Sudoku-Classification experiments.</p>
<p>Table 3 :
3NeuPSL hyperparameters for the MNIST-Add1 experiment.</p>
<p>Table 4 :
4NeuPSL hyperparameters for the MNIST-Add2 experiments.</p>
<p>Table 5 :
5NeuPSL hyperparameters for the Visual-Sudoku-Classification experiments.conducted between each step of gradient descent during the 
learning process. The Neural Learning Rate parameter refers 
to the learning rate of the neural model used to predict image 
labels. </p>
<p>Table 6 :
6NeuPSL hyperparameters for the citation network node classification experiments.</p>
<p>Table 7 :
7Neural architecture for the MNIST-Add2 CNN baseline[Badreddine et al., 2022].the neural search were subsequently set during the symbolic search. All neural models were trained for 250 epochs utilizing early stopping on the validation set with a patience of 25. Final hyperparameter values for LP P SL and Neural P SL are the same as NeuPSL LP . Any unspecified values were left at their default settings. The Hidden Layer Size parameter refers to the size of a single hidden layer, where "None" removes that hidden layer, resulting in a model with only input and output layers. The Learning Rate parameter refers to the learning rate of the neural model. The Weight Regularization parameter adds a kernel and bias regularizer to the hidden layer and output. The ADMM Step Size parameter refers to the initial step size of the ADMM reasoner. The ADMM Max</p>
<p>Table 8 :
8Neural architecture for the MNIST-Add2 CNN baseline[Badreddine et al., 2022].Model 
Number of Hyperparameter 
Tuning Range 
Final 
Additions </p>
<p>MNIST-Add1 </p>
<p>300 
Learning Rate 
{1e-3, 1e-4, 1e-5} 1e-3 
Batch Size 
{16, 32, 64, 128} 
32 </p>
<p>3,000 
Learning Rate 
{1e-3, 1e-4, 1e-5} 1e-3 
Batch Size 
{16, 32, 64, 128} 
16 </p>
<p>25,000 
Learning Rate 
{1e-3, 1e-4, 1e-5} 1e-3 
Batch Size 
{16, 32, 64, 128} 
32 </p>
<p>MNIST-Add2 </p>
<p>150 
Learning Rate 
{1e-3, 1e-4, 1e-5} 1e-3 
Batch Size 
{16, 32, 64, 128} 
32 </p>
<p>1,500 
Learning Rate 
{1e-3, 1e-4, 1e-5} 1e-3 
Batch Size 
{16, 32, 64, 128} 
32 </p>
<p>12,500 
Learning Rate 
{1e-3, 1e-4, 1e-5} 1e-3 
Batch Size 
{16, 32, 64, 128} 
64 </p>
<p>Table 9 :
9CNN baseline hyperparameters for the MNIST-Add1 and MNIST-Add2 experiments.</p>
<p>Table 11 :
11Neural architecture for the Visual-Sudoku-Classification CNN-Digit baseline.</p>
<p>Table 12 :
12CNN-Visual and CNN-Digit hyperparameters for the Visual-Sudoku-Classification experiment.Order 
Layer 
Parameters 
Value </p>
<p>1 
Graph Conv Layer 
Number of Parameters 
237056 </p>
<p>2 
Graph conv Layer 
Number of Parameters 
390 
Activation 
softmax </p>
<p>Table 13 :
13Neural architecture for the citation network node classification GCN model. Weight Regularizer {1.0e-3, 5.0e-4} 1.0e-3Hyperparameter 
Tuning Range 
Final Value </p>
<p>Hidden Units 
{16, 32, 64} 
64 
Learning Rate 
{1e-2, 1e-3} 
1e-3 </p>
<p>Table 14 :
14GCN hyperparameters for the citation network node classification experiments.</p>
<p>CNN 17.16 ± 00.62 78.99 ± 01.14 96.30 ± 00.30 01.31 ± 00.23 01.69 ± 00.27 23.88 ± 04.32 LTNs 69.23 ± 15.68 93.90 ± 00.51 80.54 ± 23.33 02.02 ± 00.97 71.79 ± 27.76 77.54 ± 35.55 DPL 85.61 ± 01.28 92.59 ± 01.40 -<em> 71.37 ± 03.90 87.44 ± 02.15 -</em> NeuPSL 82.58 ± 02.56 93.66 ± 00.32 97.34 ± 00.26 56.94 ± 06.33 87.05 ± 01.48 93.91 ± 00.37Method </p>
<p>MNIST-Add1 
MNIST-Add2 
Number of Additions 
300 
3,000 
25,000 
150 
1,500 
12,500 </p>
<p>DeepProbLog (DPL): All DPL results use the DPL models presented in [Manhaeve et al., 2021], using default hyperparameters. Code was obtained from github.com/ML-KULeuven/deepproblog. DeepStochLog (DSL): All DeepStochLog results use the DeepStochLog models presented in [Winters et al., 2021], using default hyperparameters. Code was obtained from github.com/ML-KULeuven/deepstochlog. Logic Tensor Networks (LTNs): All LTNs results use the LTNs models presented in [Badreddine et al., 2022], using default hyperparameters. Code was obtained from github.com/logictensornetworks/logictensornetworks. Licenses for NeuPSL, DeepProbLog, DeepStochLog, are under Apache License 2.0 and Logic Tensor Networks are under MIT License.</p>
<p>NeuPSL LP +F P 4.23 ± 0.05 32.94 ± 0.36 NeuPSL LP +F P 4.07 ± 0.14 36.50 ± 0.53Setting 
Method 
Inference 
Learning 
(sec) 
(sec) </p>
<p>Citeseer 
NeuPSL LP 
3.98 ± 0.05 29.90 ± 0.82 
Cora 
NeuPSL LP 
4.00 ± 0.31 33.41 ± 1.23 </p>
<p>Table 16 :
16Inference and learning time for NeuPSL on Citation Network Node Classification experiments presented in Section 6.3.Unique Puzzles 
Inference 
Learning 
Digits 
(sec) 
(sec) </p>
<p>64 </p>
<p>4 
4.65 ± 0.16 
43.18 ± 1.35 
8 
6.47 ± 0.19 
52.56 ± 1.08 
16 
12.56 ± 0.66 68.64 ± 0.89 </p>
<p>128 </p>
<p>8 
4.54 ± 0.07 
52.45 ± 0.94 
16 
6.48 ± 0.18 
68.91 ± 1.01 
32 
12.62 ± 0.52 102.60 ± 0.90 </p>
<p>256 </p>
<p>8 
4.67 ± 0.20 
68.62 ± 1.04 
16 
6.53 ± 0.30 102.76 ± 2.05 
32 
12.59 ± 0.53 170.66 ± 5.82 </p>
<p>Table 17 :
17Inference and learning time for NeuPSL on Visual Sudoku Puzzle Classification experiments presented in Section 6.2.best are in bold. In all but two settings, NeuPSL is either the highest-performing model or within a standard deviation of the highest-performing model. Moreover, NeuPSL has a markedly lower variance for nearly all training examples in both MNIST-Add tasks.</p>
<p>Table 16
16summarizes the inference and learning time for Ne-uPSL on Citation Network Node Classification experiments presented in Section 6.3 andTable 17summarizes the inference and learning time for NeuPSL on Visual Sudoku Puzzle Classification experiments presented in Section 6.2.
AcknowledgmentsThis work was partially supported by the National Science Foundation grant CCF-2023495.Order
Structuring linked data search results using probabilistic soft logic. Duhai Alshukaili, Alvarao Fernandees, Norman Paton, ISWC. Duhai Alshukaili, Alvarao Fernandees, and Norman Paton. Structuring linked data search results using probabilistic soft logic. In ISWC, 2016.</p>
<p>Visual sudoku puzzle classification: A suite of collective neuro-symbolic tasks. Eriq Augustine, Connor Pryor, Charles Dickens, Jay Pujara, William Yang Wang, Lise Getoor, International Workshop on Neural-Symbolic Learning and Reasoning (NeSy). 2022Eriq Augustine, Connor Pryor, Charles Dickens, Jay Pujara, William Yang Wang, and Lise Getoor. Visual sudoku puzzle classification: A suite of collective neuro-symbolic tasks. In International Workshop on Neural-Symbolic Learning and Reasoning (NeSy), 2022.</p>
<p>Hinge-loss Markov random fields and probabilistic soft logic. Stephen Bach, Matthias Broecheler, Bert Huang, Lise Getoor, JMLR. 181Stephen Bach, Matthias Broecheler, Bert Huang, and Lise Getoor. Hinge-loss Markov random fields and probabilistic soft logic. JMLR, 18(1):1-67, 2017.</p>
<p>Dimensions of neuralsymbolic integration -A structured survey. Sebastian Bader, Pascal Hitzler, arXivSebastian Bader and Pascal Hitzler. Dimensions of neural- symbolic integration -A structured survey. arXiv, 2005.</p>
<p>Logic tensor networks. Samy Badreddine, Artur D&apos;avila Garcez, Luciano Serafini, Michael Spranger, AI303103649Samy Badreddine, Artur d'Avila Garcez, Luciano Serafini, and Michael Spranger. Logic tensor networks. AI, 303(4):103649, 2022.</p>
<p>Probabilistic soft logic for semantic textual similarity. Islam Beltagy, Katrin Erk, Raymond Mooney, ACL. Islam Beltagy, Katrin Erk, and Raymond Mooney. Proba- bilistic soft logic for semantic textual similarity. In ACL, 2014.</p>            </div>
        </div>

    </div>
</body>
</html>