<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-9232 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-9232</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-9232</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-162.html">extraction-schema-162</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <p><strong>Paper ID:</strong> paper-3827029</p>
                <p><strong>Paper Title:</strong> <a href="https://arxiv.org/pdf/1803.04967v1.pdf" target="_blank">Recurrent Neural Network Attention Mechanisms for Interpretable System Log Anomaly Detection</a></p>
                <p><strong>Paper Abstract:</strong> Deep learning has recently demonstrated state-of-the art performance on key tasks related to the maintenance of computer systems, such as intrusion detection, denial of service attack detection, hardware and software system failures, and malware detection. In these contexts, model interpretability is vital for administrator and analyst to trust and act on the automated analysis of machine learning models. Deep learning methods have been criticized as black box oracles which allow limited insight into decision factors. In this work we seek to bridge the gap between the impressive performance of deep learning models and the need for interpretable model introspection. To this end we present recurrent neural network (RNN) language models augmented with attention for anomaly detection in system logs. Our methods are generally applicable to any computer system and logging source. By incorporating attention variants into our RNN language models we create opportunities for model introspection and analysis without sacrificing state-of-the art performance. We demonstrate model performance and illustrate model interpretability on an intrusion detection task using the Los Alamos National Laboratory (LANL) cyber security dataset, reporting upward of 0.99 area under the receiver operator characteristic curve despite being trained only on a single day's worth of data.</p>
                <p><strong>Cost:</strong> 0.014</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e9232.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e9232.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Attn-RNN LM</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Attention-augmented Recurrent Neural Network Language Models for System Log Anomaly Detection</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Unsupervised LSTM-based language models augmented with dot-product attention to assign negative log-likelihood anomaly scores to system log lines, enabling interpretable anomaly detection and online training for streaming logs.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Custom attention-augmented RNN language model</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>LSTM (recurrent neural network) with dot-product attention</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Sequential categorical token data (log-line token sequences; both field-level tokens and character sequences)</td>
                        </tr>
                        <tr>
                            <td><strong>data_domain</strong></td>
                            <td>Computer system logs (LANL authentication logs: source user, destination user, source pc, destination pc, auth type, logon type, orientation, success/fail)</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>Rare/novel events and intrusions (red team attacks); outliers in sequence likelihood</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Unsupervised next-token language modeling using LSTMs; per-log-line anomaly score = sum negative log probabilities of tokens (sequence likelihood). Models augmented with dot-product attention over prior hidden states to provide selective context and interpretability. Trained in a syncopated online fashion (daily evaluation then training on day's data).</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_methods</strong></td>
                            <td>Non-attention Event Model (EM), Bidirectional Event Model (BEM), Tiered EM/T-BEM (upper-tier user-sequence LSTM), comparisons across attention variants (Fixed, Syntax, Semantic1, Semantic2, Tiered Attention)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Area Under the Receiver Operator Characteristic Curve (AUC ROC); statistics reported over 5 random initializations</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>Reported AUCs up to ~0.99 (paper: 'upward of 0.99 AUC') on LANL authentication detection task with training on a single day and evaluation on the next day; low variance across runs for most models.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td>Adding attention to the unidirectional EM brought performance to match the BEM; attention variants achieved similar AUCs to BEM on word-tokenized data. Semantic attention variants improved performance on variable-length/looser-structure (character) inputs but did not outperform BEM in that setting. Tiered attention yielded little improvement over tiered baselines.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Shared vocabulary across fields caused misclassification (model can predict tokens appropriate to other fields); Fixed and Syntax attention performed poorly on character-tokenized (variable-length field) data; Fixed attention increased variance for some character models; attention does not always improve tiered models and may be unnecessary when bidirectionality already provides shortcuts; experiments limited to authentication logs and a short train/eval window (days 7→8) with no hyperparameter tuning.</td>
                        </tr>
                        <tr>
                            <td><strong>unique_insights</strong></td>
                            <td>Attention provides immediate interpretability via per-timestep attention weights, revealing which fields (e.g., source user, source PC) drive predictions; attention can act as a shortcut mechanism comparable to bidirectionality for capturing relevant context; semantic (input-dependent) attention is better suited to variable-length or loose-structure sequences, while fixed/syntactic attention suit fixed-structure sequences; online syncopated training stabilizes anomaly score scales for daily streaming deployment.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Recurrent Neural Network Attention Mechanisms for Interpretable System Log Anomaly Detection', 'publication_date_yy_mm': '2018-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9232.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e9232.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>EM</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Event Model (EM) — Unidirectional LSTM language model</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A single-layer LSTM language model applied to token sequences of individual log-lines; computes next-token predictive distributions and uses negative log-likelihood as an anomaly score.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Recurrent Neural Network Language Models for Open Vocabulary Event-Level Cyber Anomaly Detection</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Event Model (EM)</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>Unidirectional LSTM</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>single layer, 128 hidden units (experiment hyperparameters)</td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Sequential categorical token data (log-line tokens)</td>
                        </tr>
                        <tr>
                            <td><strong>data_domain</strong></td>
                            <td>LANL authentication logs</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>Outlier/log-line unlikely under learned language model</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Embed tokens, run through unidirectional LSTM to predict next token probabilities; anomaly score = sum negative log probabilities across tokens in a log-line.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_methods</strong></td>
                            <td>Used as baseline versus attention-augmented EM and BEM</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>AUC ROC</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>Lower than BEM on word-tokenized baseline; improved to BEM-level when attention was added.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td>Outperformed by BEM (bidirectional) on word models; attention variants applied to EM closed this gap.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Only conditions on prior tokens within same log-line (no forward context); less effective than bidirectional models on fixed-structure word data unless augmented with attention.</td>
                        </tr>
                        <tr>
                            <td><strong>unique_insights</strong></td>
                            <td>Serves as a simple and fast baseline; benefits substantially from attention which supplies direct access to earlier hidden states.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Recurrent Neural Network Attention Mechanisms for Interpretable System Log Anomaly Detection', 'publication_date_yy_mm': '2018-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9232.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e9232.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>BEM</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Bidirectional Event Model (BEM)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An LSTM language model that conditions predictions on both preceding and following tokens within a log-line by combining forward and backward LSTM hidden states.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Recurrent Neural Network Language Models for Open Vocabulary Event-Level Cyber Anomaly Detection</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Bidirectional Event Model (BEM)</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>Bidirectional LSTM</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>single layer, 128 hidden units per direction (experiment hyperparameters)</td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Sequential categorical token data (log-line tokens)</td>
                        </tr>
                        <tr>
                            <td><strong>data_domain</strong></td>
                            <td>LANL authentication logs</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>Outlier/log-line unlikely under bidirectional context-aware model</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Combine forward hidden state h(t-1) and backward hidden state h_b(t+1) to predict token at position t; negative log-likelihood of sequence forms anomaly score.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_methods</strong></td>
                            <td>Compared to EM and attention-augmented EM</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>AUC ROC</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>Strong performance; outperforms EM on word-tokenized baselines; attention on EM matched BEM performance on word data.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td>Better than unaugmented EM on word-tokenized data; comparable to attention-augmented EM.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Requires access to future tokens within a log-line (not causal) which may be less appropriate for some online streaming settings; less interpretable than attention without additional mechanisms.</td>
                        </tr>
                        <tr>
                            <td><strong>unique_insights</strong></td>
                            <td>Bidirectionality is a strong baseline for modeling intra-line context; attention can match its performance while adding interpretability.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Recurrent Neural Network Attention Mechanisms for Interpretable System Log Anomaly Detection', 'publication_date_yy_mm': '2018-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9232.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e9232.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Tiered Models</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Tiered Language Models (T-EM, T-BEM) with upper-tier user-sequence LSTM</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Two-tier architecture where a lower-tier LSTM models tokens within a log-line and an upper-tier LSTM models a user's sequence of log-lines, passing a summary context vector to the lower tier.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Recurrent Neural Network Language Models for Open Vocabulary Event-Level Cyber Anomaly Detection</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Tiered EM / Tiered BEM (T-EM / T-BEM)</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>Hierarchical LSTM (lower-tier LSTM for events, upper-tier LSTM for user sequences); optionally bidirectional lower tier</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Hierarchical sequences (tokens within events, events within user timelines)</td>
                        </tr>
                        <tr>
                            <td><strong>data_domain</strong></td>
                            <td>LANL authentication logs (per-user event sequences)</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>Anomalous events in the context of a user's recent history (rare sequence events)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Lower-tier LSTM encodes each log-line; upper-tier LSTM ingests summaries (previous lower-tier hidden states average or attention-weighted) to provide context for subsequent lower-tier predictions; anomaly score remains negative log-likelihood of log-line.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_methods</strong></td>
                            <td>Compared to single-tier EM/BEM and attention-augmented variants</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>AUC ROC; variance across initializations</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>Tiered attention showed little difference in AUC compared to tiered means; tiered/bidirectional lower-tier reduced variance for character models.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td>Tiered architectures incorporate inter-log-line user context; attention in tiered models produced marginal gains, suggesting attention shortcuts may be unnecessary when tiered/bidirectional structures already provide context.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Adding attention to the tiered model provided limited performance improvement; complexity increases and attention may be redundant when bidirectionality or upper-tier context suffices.</td>
                        </tr>
                        <tr>
                            <td><strong>unique_insights</strong></td>
                            <td>Replacing mean pooling with attention in the tiered aggregation allows interpretable weighting of which lower-tier hidden states are passed upwards, but may not always improve detection performance for this task.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Recurrent Neural Network Attention Mechanisms for Interpretable System Log Anomaly Detection', 'publication_date_yy_mm': '2018-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9232.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e9232.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Attention Variants</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Fixed, Syntax, Semantic1, Semantic2, and Tiered Attention (dot-product attention variants)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Five attention query-definition strategies using dot-product attention over prior hidden states: a single shared fixed query, position-dependent syntax queries, two semantic (input-dependent) queries, and a tiered attention for upper-tier aggregation.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Dot-product attention variants (Fixed, Syntax, Semantic1, Semantic2, Tiered Attention)</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>Attention mechanism applied over LSTM hidden states (dot-product with learned key/value matrices and queries)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Sequential token data (per-step attention over previous hidden states)</td>
                        </tr>
                        <tr>
                            <td><strong>data_domain</strong></td>
                            <td>System log sequences (authentication log tokens)</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>Sequence-context anomalies (wrong or unexpected tokens given attended context)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Compute keys K = tanh(V W_a) from prior hidden states V; compute query q (definition depends on variant: shared vector, position-dependent, h(t)-based, concatenated query portion of h, or upper-tier transform); weights d = softmax(q K^T) produce attention vector a = d V concatenated with h(t-1) for prediction.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_methods</strong></td>
                            <td>Compared against EM (no attention) and BEM; different attention types compared against each other</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>AUC ROC; attention weight summaries (mean/std heatmaps) for interpretability</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>On word-tokenized data, all attention variants produced similar AUCs and improved EM to match BEM. For character-tokenized data, Semantic variants improved performance (but not beyond BEM), whereas Fixed and Syntax did not help and sometimes increased variance.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td>Attention-equipped EM matched or approached BEM performance; semantic attentions performed better than fixed/syntax on variable-length/loose-structure inputs.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Fixed and Syntax attention ill-suited to character-tokenized variable-length fields; Fixed attention sometimes greatly increased variance; attention may not help tiered models.</td>
                        </tr>
                        <tr>
                            <td><strong>unique_insights</strong></td>
                            <td>Different query constructions encode prior assumptions: Fixed encodes fixed-position importance, Syntax encodes position-dependent but value-agnostic importance, Semantic makes importance input-dependent; attention weight summaries yield interpretable feature importance over fields (e.g., source user and source PC often dominant).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Recurrent Neural Network Attention Mechanisms for Interpretable System Log Anomaly Detection', 'publication_date_yy_mm': '2018-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9232.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e9232.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Tokenization Modes</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Word-level and Character-level Tokenization for Language Modeling of Logs</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Two tokenization strategies: word-level (field tokens with per-field vocabulary and OOV handling) and character-level (printable ASCII including delimiters) influencing model behavior and attention suitability.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Word-tokenized / Character-tokenized language models</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>Preprocessing/tokenization choices for LSTM language models</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Categorical field tokens (word) or sequences of characters (character)</td>
                        </tr>
                        <tr>
                            <td><strong>data_domain</strong></td>
                            <td>Authentication logs</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>Field-level token anomalies or character-level anomalies in identifiers</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Word tokenization: split CSV fields into tokens, per-field vocabulary with OOV for rare values (threshold 40). Character tokenization: use printable ASCII including delimiters to avoid OOV, retain delimiters for field boundary cues.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_methods</strong></td>
                            <td>Models run with both tokenizations for comparison</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>AUC ROC and attention-weight behavior/variance</td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td>Word models: attention and BEM performed very well (AUC ~0.99). Character models: semantic attention improved performance but generally BEM remained strong; fixed/syntax attention often did not help and increased variance.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td>Tokenization choice affects suitability of attention variant; word tokenization benefits from syntax-based assumptions while character tokenization benefits from input-dependent (semantic) attention.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Word model requires OOV handling and per-field common-value bias which they mitigated via per-user centering; shared vocabulary across fields can cause errors; character models showed greater sensitivity/variance for some attention variants.</td>
                        </tr>
                        <tr>
                            <td><strong>unique_insights</strong></td>
                            <td>Delimiters in character tokenization serve as strong positional cues that attention often attends to (delimiter hidden states), suggesting models learn field-boundary summaries stored in subsequent delimiter positions.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Recurrent Neural Network Attention Mechanisms for Interpretable System Log Anomaly Detection', 'publication_date_yy_mm': '2018-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9232.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e9232.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>DeepLog</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>DeepLog: Anomaly Detection and Diagnosis from System Logs through Deep Learning</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Prior work using LSTM models on parsed log sequences for anomaly detection and diagnosis, cited as related work for system log anomaly detection.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>DeepLog: Anomaly Detection and Diagnosis from System Logs through Deep Learning</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>DeepLog (LSTM-based)</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>LSTM</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Sequences of process API calls / parsed log sequences</td>
                        </tr>
                        <tr>
                            <td><strong>data_domain</strong></td>
                            <td>System logs for malware/attack detection</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>Anomalous sequences of API calls or log events</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Prior approach that custom-parses logs to sequences and uses LSTM to model normal sequence behavior for anomaly detection (cited in related work).</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_methods</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>unique_insights</strong></td>
                            <td>Paper contrasts current work by noting their approach works directly with raw text with only tokenization, whereas DeepLog uses customized parsing.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Recurrent Neural Network Attention Mechanisms for Interpretable System Log Anomaly Detection', 'publication_date_yy_mm': '2018-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9232.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e9232.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or tabular data, including details of the models, data types, methods, results, comparisons, and limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Zhang et al.</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Automated IT system failure prediction: A deep learning approach</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Prior work using clustering on raw text from multiple log sources to create feature sequences fed to LSTMs for hardware and software failure prediction, cited in related work.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Automated IT system failure prediction: A deep learning approach</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>LSTM-based failure prediction pipeline</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>LSTM</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Feature sequences derived from clustered raw text</td>
                        </tr>
                        <tr>
                            <td><strong>data_domain</strong></td>
                            <td>IT system logs for failure prediction</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>System failures and precursor anomalies</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Clustering raw log text to generate sequences then using LSTM for failure prediction (cited as related work).</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_methods</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>unique_insights</strong></td>
                            <td>Used as contrast: this paper's approach requires minimal preprocessing (tokenization only) while Zhang et al. perform clustering and parsing.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Recurrent Neural Network Attention Mechanisms for Interpretable System Log Anomaly Detection', 'publication_date_yy_mm': '2018-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>DeepLog: Anomaly Detection and Diagnosis from System Logs through Deep Learning <em>(Rating: 2)</em></li>
                <li>Recurrent Neural Network Language Models for Open Vocabulary Event-Level Cyber Anomaly Detection <em>(Rating: 2)</em></li>
                <li>Frustratingly short attention spans in neural language modeling <em>(Rating: 1)</em></li>
                <li>Attentive Language Models <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-9232",
    "paper_id": "paper-3827029",
    "extraction_schema_id": "extraction-schema-162",
    "extracted_data": [
        {
            "name_short": "Attn-RNN LM",
            "name_full": "Attention-augmented Recurrent Neural Network Language Models for System Log Anomaly Detection",
            "brief_description": "Unsupervised LSTM-based language models augmented with dot-product attention to assign negative log-likelihood anomaly scores to system log lines, enabling interpretable anomaly detection and online training for streaming logs.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "Custom attention-augmented RNN language model",
            "model_type": "LSTM (recurrent neural network) with dot-product attention",
            "model_size": null,
            "data_type": "Sequential categorical token data (log-line token sequences; both field-level tokens and character sequences)",
            "data_domain": "Computer system logs (LANL authentication logs: source user, destination user, source pc, destination pc, auth type, logon type, orientation, success/fail)",
            "anomaly_type": "Rare/novel events and intrusions (red team attacks); outliers in sequence likelihood",
            "method_description": "Unsupervised next-token language modeling using LSTMs; per-log-line anomaly score = sum negative log probabilities of tokens (sequence likelihood). Models augmented with dot-product attention over prior hidden states to provide selective context and interpretability. Trained in a syncopated online fashion (daily evaluation then training on day's data).",
            "baseline_methods": "Non-attention Event Model (EM), Bidirectional Event Model (BEM), Tiered EM/T-BEM (upper-tier user-sequence LSTM), comparisons across attention variants (Fixed, Syntax, Semantic1, Semantic2, Tiered Attention)",
            "performance_metrics": "Area Under the Receiver Operator Characteristic Curve (AUC ROC); statistics reported over 5 random initializations",
            "performance_results": "Reported AUCs up to ~0.99 (paper: 'upward of 0.99 AUC') on LANL authentication detection task with training on a single day and evaluation on the next day; low variance across runs for most models.",
            "comparison_to_baseline": "Adding attention to the unidirectional EM brought performance to match the BEM; attention variants achieved similar AUCs to BEM on word-tokenized data. Semantic attention variants improved performance on variable-length/looser-structure (character) inputs but did not outperform BEM in that setting. Tiered attention yielded little improvement over tiered baselines.",
            "limitations_or_failure_cases": "Shared vocabulary across fields caused misclassification (model can predict tokens appropriate to other fields); Fixed and Syntax attention performed poorly on character-tokenized (variable-length field) data; Fixed attention increased variance for some character models; attention does not always improve tiered models and may be unnecessary when bidirectionality already provides shortcuts; experiments limited to authentication logs and a short train/eval window (days 7→8) with no hyperparameter tuning.",
            "unique_insights": "Attention provides immediate interpretability via per-timestep attention weights, revealing which fields (e.g., source user, source PC) drive predictions; attention can act as a shortcut mechanism comparable to bidirectionality for capturing relevant context; semantic (input-dependent) attention is better suited to variable-length or loose-structure sequences, while fixed/syntactic attention suit fixed-structure sequences; online syncopated training stabilizes anomaly score scales for daily streaming deployment.",
            "uuid": "e9232.0",
            "source_info": {
                "paper_title": "Recurrent Neural Network Attention Mechanisms for Interpretable System Log Anomaly Detection",
                "publication_date_yy_mm": "2018-06"
            }
        },
        {
            "name_short": "EM",
            "name_full": "Event Model (EM) — Unidirectional LSTM language model",
            "brief_description": "A single-layer LSTM language model applied to token sequences of individual log-lines; computes next-token predictive distributions and uses negative log-likelihood as an anomaly score.",
            "citation_title": "Recurrent Neural Network Language Models for Open Vocabulary Event-Level Cyber Anomaly Detection",
            "mention_or_use": "use",
            "model_name": "Event Model (EM)",
            "model_type": "Unidirectional LSTM",
            "model_size": "single layer, 128 hidden units (experiment hyperparameters)",
            "data_type": "Sequential categorical token data (log-line tokens)",
            "data_domain": "LANL authentication logs",
            "anomaly_type": "Outlier/log-line unlikely under learned language model",
            "method_description": "Embed tokens, run through unidirectional LSTM to predict next token probabilities; anomaly score = sum negative log probabilities across tokens in a log-line.",
            "baseline_methods": "Used as baseline versus attention-augmented EM and BEM",
            "performance_metrics": "AUC ROC",
            "performance_results": "Lower than BEM on word-tokenized baseline; improved to BEM-level when attention was added.",
            "comparison_to_baseline": "Outperformed by BEM (bidirectional) on word models; attention variants applied to EM closed this gap.",
            "limitations_or_failure_cases": "Only conditions on prior tokens within same log-line (no forward context); less effective than bidirectional models on fixed-structure word data unless augmented with attention.",
            "unique_insights": "Serves as a simple and fast baseline; benefits substantially from attention which supplies direct access to earlier hidden states.",
            "uuid": "e9232.1",
            "source_info": {
                "paper_title": "Recurrent Neural Network Attention Mechanisms for Interpretable System Log Anomaly Detection",
                "publication_date_yy_mm": "2018-06"
            }
        },
        {
            "name_short": "BEM",
            "name_full": "Bidirectional Event Model (BEM)",
            "brief_description": "An LSTM language model that conditions predictions on both preceding and following tokens within a log-line by combining forward and backward LSTM hidden states.",
            "citation_title": "Recurrent Neural Network Language Models for Open Vocabulary Event-Level Cyber Anomaly Detection",
            "mention_or_use": "use",
            "model_name": "Bidirectional Event Model (BEM)",
            "model_type": "Bidirectional LSTM",
            "model_size": "single layer, 128 hidden units per direction (experiment hyperparameters)",
            "data_type": "Sequential categorical token data (log-line tokens)",
            "data_domain": "LANL authentication logs",
            "anomaly_type": "Outlier/log-line unlikely under bidirectional context-aware model",
            "method_description": "Combine forward hidden state h(t-1) and backward hidden state h_b(t+1) to predict token at position t; negative log-likelihood of sequence forms anomaly score.",
            "baseline_methods": "Compared to EM and attention-augmented EM",
            "performance_metrics": "AUC ROC",
            "performance_results": "Strong performance; outperforms EM on word-tokenized baselines; attention on EM matched BEM performance on word data.",
            "comparison_to_baseline": "Better than unaugmented EM on word-tokenized data; comparable to attention-augmented EM.",
            "limitations_or_failure_cases": "Requires access to future tokens within a log-line (not causal) which may be less appropriate for some online streaming settings; less interpretable than attention without additional mechanisms.",
            "unique_insights": "Bidirectionality is a strong baseline for modeling intra-line context; attention can match its performance while adding interpretability.",
            "uuid": "e9232.2",
            "source_info": {
                "paper_title": "Recurrent Neural Network Attention Mechanisms for Interpretable System Log Anomaly Detection",
                "publication_date_yy_mm": "2018-06"
            }
        },
        {
            "name_short": "Tiered Models",
            "name_full": "Tiered Language Models (T-EM, T-BEM) with upper-tier user-sequence LSTM",
            "brief_description": "Two-tier architecture where a lower-tier LSTM models tokens within a log-line and an upper-tier LSTM models a user's sequence of log-lines, passing a summary context vector to the lower tier.",
            "citation_title": "Recurrent Neural Network Language Models for Open Vocabulary Event-Level Cyber Anomaly Detection",
            "mention_or_use": "use",
            "model_name": "Tiered EM / Tiered BEM (T-EM / T-BEM)",
            "model_type": "Hierarchical LSTM (lower-tier LSTM for events, upper-tier LSTM for user sequences); optionally bidirectional lower tier",
            "model_size": null,
            "data_type": "Hierarchical sequences (tokens within events, events within user timelines)",
            "data_domain": "LANL authentication logs (per-user event sequences)",
            "anomaly_type": "Anomalous events in the context of a user's recent history (rare sequence events)",
            "method_description": "Lower-tier LSTM encodes each log-line; upper-tier LSTM ingests summaries (previous lower-tier hidden states average or attention-weighted) to provide context for subsequent lower-tier predictions; anomaly score remains negative log-likelihood of log-line.",
            "baseline_methods": "Compared to single-tier EM/BEM and attention-augmented variants",
            "performance_metrics": "AUC ROC; variance across initializations",
            "performance_results": "Tiered attention showed little difference in AUC compared to tiered means; tiered/bidirectional lower-tier reduced variance for character models.",
            "comparison_to_baseline": "Tiered architectures incorporate inter-log-line user context; attention in tiered models produced marginal gains, suggesting attention shortcuts may be unnecessary when tiered/bidirectional structures already provide context.",
            "limitations_or_failure_cases": "Adding attention to the tiered model provided limited performance improvement; complexity increases and attention may be redundant when bidirectionality or upper-tier context suffices.",
            "unique_insights": "Replacing mean pooling with attention in the tiered aggregation allows interpretable weighting of which lower-tier hidden states are passed upwards, but may not always improve detection performance for this task.",
            "uuid": "e9232.3",
            "source_info": {
                "paper_title": "Recurrent Neural Network Attention Mechanisms for Interpretable System Log Anomaly Detection",
                "publication_date_yy_mm": "2018-06"
            }
        },
        {
            "name_short": "Attention Variants",
            "name_full": "Fixed, Syntax, Semantic1, Semantic2, and Tiered Attention (dot-product attention variants)",
            "brief_description": "Five attention query-definition strategies using dot-product attention over prior hidden states: a single shared fixed query, position-dependent syntax queries, two semantic (input-dependent) queries, and a tiered attention for upper-tier aggregation.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "Dot-product attention variants (Fixed, Syntax, Semantic1, Semantic2, Tiered Attention)",
            "model_type": "Attention mechanism applied over LSTM hidden states (dot-product with learned key/value matrices and queries)",
            "model_size": null,
            "data_type": "Sequential token data (per-step attention over previous hidden states)",
            "data_domain": "System log sequences (authentication log tokens)",
            "anomaly_type": "Sequence-context anomalies (wrong or unexpected tokens given attended context)",
            "method_description": "Compute keys K = tanh(V W_a) from prior hidden states V; compute query q (definition depends on variant: shared vector, position-dependent, h(t)-based, concatenated query portion of h, or upper-tier transform); weights d = softmax(q K^T) produce attention vector a = d V concatenated with h(t-1) for prediction.",
            "baseline_methods": "Compared against EM (no attention) and BEM; different attention types compared against each other",
            "performance_metrics": "AUC ROC; attention weight summaries (mean/std heatmaps) for interpretability",
            "performance_results": "On word-tokenized data, all attention variants produced similar AUCs and improved EM to match BEM. For character-tokenized data, Semantic variants improved performance (but not beyond BEM), whereas Fixed and Syntax did not help and sometimes increased variance.",
            "comparison_to_baseline": "Attention-equipped EM matched or approached BEM performance; semantic attentions performed better than fixed/syntax on variable-length/loose-structure inputs.",
            "limitations_or_failure_cases": "Fixed and Syntax attention ill-suited to character-tokenized variable-length fields; Fixed attention sometimes greatly increased variance; attention may not help tiered models.",
            "unique_insights": "Different query constructions encode prior assumptions: Fixed encodes fixed-position importance, Syntax encodes position-dependent but value-agnostic importance, Semantic makes importance input-dependent; attention weight summaries yield interpretable feature importance over fields (e.g., source user and source PC often dominant).",
            "uuid": "e9232.4",
            "source_info": {
                "paper_title": "Recurrent Neural Network Attention Mechanisms for Interpretable System Log Anomaly Detection",
                "publication_date_yy_mm": "2018-06"
            }
        },
        {
            "name_short": "Tokenization Modes",
            "name_full": "Word-level and Character-level Tokenization for Language Modeling of Logs",
            "brief_description": "Two tokenization strategies: word-level (field tokens with per-field vocabulary and OOV handling) and character-level (printable ASCII including delimiters) influencing model behavior and attention suitability.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "Word-tokenized / Character-tokenized language models",
            "model_type": "Preprocessing/tokenization choices for LSTM language models",
            "model_size": null,
            "data_type": "Categorical field tokens (word) or sequences of characters (character)",
            "data_domain": "Authentication logs",
            "anomaly_type": "Field-level token anomalies or character-level anomalies in identifiers",
            "method_description": "Word tokenization: split CSV fields into tokens, per-field vocabulary with OOV for rare values (threshold 40). Character tokenization: use printable ASCII including delimiters to avoid OOV, retain delimiters for field boundary cues.",
            "baseline_methods": "Models run with both tokenizations for comparison",
            "performance_metrics": "AUC ROC and attention-weight behavior/variance",
            "performance_results": "Word models: attention and BEM performed very well (AUC ~0.99). Character models: semantic attention improved performance but generally BEM remained strong; fixed/syntax attention often did not help and increased variance.",
            "comparison_to_baseline": "Tokenization choice affects suitability of attention variant; word tokenization benefits from syntax-based assumptions while character tokenization benefits from input-dependent (semantic) attention.",
            "limitations_or_failure_cases": "Word model requires OOV handling and per-field common-value bias which they mitigated via per-user centering; shared vocabulary across fields can cause errors; character models showed greater sensitivity/variance for some attention variants.",
            "unique_insights": "Delimiters in character tokenization serve as strong positional cues that attention often attends to (delimiter hidden states), suggesting models learn field-boundary summaries stored in subsequent delimiter positions.",
            "uuid": "e9232.5",
            "source_info": {
                "paper_title": "Recurrent Neural Network Attention Mechanisms for Interpretable System Log Anomaly Detection",
                "publication_date_yy_mm": "2018-06"
            }
        },
        {
            "name_short": "DeepLog",
            "name_full": "DeepLog: Anomaly Detection and Diagnosis from System Logs through Deep Learning",
            "brief_description": "Prior work using LSTM models on parsed log sequences for anomaly detection and diagnosis, cited as related work for system log anomaly detection.",
            "citation_title": "DeepLog: Anomaly Detection and Diagnosis from System Logs through Deep Learning",
            "mention_or_use": "mention",
            "model_name": "DeepLog (LSTM-based)",
            "model_type": "LSTM",
            "model_size": null,
            "data_type": "Sequences of process API calls / parsed log sequences",
            "data_domain": "System logs for malware/attack detection",
            "anomaly_type": "Anomalous sequences of API calls or log events",
            "method_description": "Prior approach that custom-parses logs to sequences and uses LSTM to model normal sequence behavior for anomaly detection (cited in related work).",
            "baseline_methods": null,
            "performance_metrics": null,
            "performance_results": null,
            "comparison_to_baseline": null,
            "limitations_or_failure_cases": null,
            "unique_insights": "Paper contrasts current work by noting their approach works directly with raw text with only tokenization, whereas DeepLog uses customized parsing.",
            "uuid": "e9232.6",
            "source_info": {
                "paper_title": "Recurrent Neural Network Attention Mechanisms for Interpretable System Log Anomaly Detection",
                "publication_date_yy_mm": "2018-06"
            }
        },
        {
            "name_short": "Zhang et al.",
            "name_full": "Automated IT system failure prediction: A deep learning approach",
            "brief_description": "Prior work using clustering on raw text from multiple log sources to create feature sequences fed to LSTMs for hardware and software failure prediction, cited in related work.",
            "citation_title": "Automated IT system failure prediction: A deep learning approach",
            "mention_or_use": "mention",
            "model_name": "LSTM-based failure prediction pipeline",
            "model_type": "LSTM",
            "model_size": null,
            "data_type": "Feature sequences derived from clustered raw text",
            "data_domain": "IT system logs for failure prediction",
            "anomaly_type": "System failures and precursor anomalies",
            "method_description": "Clustering raw log text to generate sequences then using LSTM for failure prediction (cited as related work).",
            "baseline_methods": null,
            "performance_metrics": null,
            "performance_results": null,
            "comparison_to_baseline": null,
            "limitations_or_failure_cases": null,
            "unique_insights": "Used as contrast: this paper's approach requires minimal preprocessing (tokenization only) while Zhang et al. perform clustering and parsing.",
            "uuid": "e9232.7",
            "source_info": {
                "paper_title": "Recurrent Neural Network Attention Mechanisms for Interpretable System Log Anomaly Detection",
                "publication_date_yy_mm": "2018-06"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "DeepLog: Anomaly Detection and Diagnosis from System Logs through Deep Learning",
            "rating": 2,
            "sanitized_title": "deeplog_anomaly_detection_and_diagnosis_from_system_logs_through_deep_learning"
        },
        {
            "paper_title": "Recurrent Neural Network Language Models for Open Vocabulary Event-Level Cyber Anomaly Detection",
            "rating": 2,
            "sanitized_title": "recurrent_neural_network_language_models_for_open_vocabulary_eventlevel_cyber_anomaly_detection"
        },
        {
            "paper_title": "Frustratingly short attention spans in neural language modeling",
            "rating": 1,
            "sanitized_title": "frustratingly_short_attention_spans_in_neural_language_modeling"
        },
        {
            "paper_title": "Attentive Language Models",
            "rating": 1,
            "sanitized_title": "attentive_language_models"
        }
    ],
    "cost": 0.01404575,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Recurrent Neural Network Attention Mechanisms for Interpretable System Log Anomaly Detection</p>
<p>Andy Brown browna52@wwu.edu 
Pacific Northwest National Laboratory
Pacific Northwest National Laboratory
Western Washington University
Western Washington University</p>
<p>Aaron Tuor aaron.tuor@pnnl.gov 
Pacific Northwest National Laboratory
Pacific Northwest National Laboratory
Western Washington University
Western Washington University</p>
<p>Brian Hutchinson brian.hutchinson@wwu.edu 
Pacific Northwest National Laboratory
Pacific Northwest National Laboratory
Western Washington University
Western Washington University</p>
<p>Nicole Nichols nicole.nichols@pnnl.gov 
Pacific Northwest National Laboratory
Pacific Northwest National Laboratory
Western Washington University
Western Washington University</p>
<p>Recurrent Neural Network Attention Mechanisms for Interpretable System Log Anomaly Detection
CCS CONCEPTS • Computing methodologies → Anomaly detectionOnline learning settingsFeature selectionUnsupervised learningNeural networksMachine learning algorithmsKEYWORDS Anomaly detection, Attention, Recurrent Neural Networks, Inter- pretable Machine Learning, Online Training, System Log Analysis *
Deep learning has recently demonstrated state-of-the art performance on key tasks related to the maintenance of computer systems, such as intrusion detection, denial of service attack detection, hardware and software system failures, and malware detection. In these contexts, model interpretability is vital for administrator and analyst to trust and act on the automated analysis of machine learning models. Deep learning methods have been criticized as black box oracles which allow limited insight into decision factors. In this work we seek to "bridge the gap" between the impressive performance of deep learning models and the need for interpretable model introspection. To this end we present recurrent neural network (RNN) language models augmented with attention for anomaly detection in system logs. Our methods are generally applicable to any computer system and logging source. By incorporating attention variants into our RNN language models we create opportunities for model introspection and analysis without sacrificing state-of-the art performance. We demonstrate model performance and illustrate model interpretability on an intrusion detection task using the Los Alamos National Laboratory (LANL) cyber security dataset, reporting upward of 0.99 area under the receiver operator characteristic curve despite being trained only on a single day's worth of data.A. Brown et al.detection, and 2) we illustrate how model introspection in these systems is made possible by the attention mechanisms.</p>
<p>INTRODUCTION</p>
<p>System log analysis is critical for a wide range of tasks in maintaining large scale computer systems such as enterprise computer networks and high performance computing clusters. These include security tasks such as intrusion detection, insider threat detection, and malware detection, as well as more general maintenance tasks such as detecting hardware failure and modeling data or traffic flow patterns. Extracting knowledge from information rich system logs is complicated by several factors:</p>
<p>(1) Log sources can generate terabytes of data per day.</p>
<p>(2) Labeled data for application areas of interest is often scarce, unbalanced, or system specific. (3) Actionable information may be obscured by complex, undiscovered relationships across logging sources and system entities (e.g. users, PCs, processes, nodes).</p>
<p>Due to these factors, unaided human monitoring and assessment is impractical, so considerable research has been directed to automated methods for visualization and analysis of system logs. Furthermore, as administrative decisions may be of considerable consequence to organizations and associated persons, it is crucial to have some understanding of the factors involved in automated decision processes, even for highly effective algorithms.</p>
<p>Addressing these factors, we present unsupervised recurrent neural network (RNN) language models for system log anomaly detection. By modeling the normal distribution of events in system logs, the anomaly detection approach can discover complex relationships buried in these logs. Since the methods are unsupervised, the models do not depend on the time consuming and otherwise expensive procurement of labeled data. Our language modeling framework requires little to no feature engineering: it is applicable to any serializable logging source. Further, the models are trained online using bounded resources dictated by the daily volume of the log sources.</p>
<p>Our main contributions in this work are twofold: 1) we evaluate the effectiveness of augmenting RNN language models with several attention mechanisms specifically designed for system log anomaly</p>
<p>RELATED WORK</p>
<p>Recently, several researchers have used Long Short-Term Memory (LSTM) Networks [7] in system log analysis. Zhang et al. [23] use clustering techniques on the raw text from multiple log sources to generate feature sequences fed to an LSTM for hardware and software failure predictions. Du et al. [5] employ customized parsing methods on the raw text of system logs to generate sequences for LSTM Denial of Service attack detection. In contrast to these methods our approach works directly with raw text with no preprocessing beyond tokenization using known field delimiters. Others have incorporated LSTM networks to preprocess sequences of process API calls as components to malware detection systems [14] trained on labeled malware examples.</p>
<p>Attention-equipped LSTM models have been used to improve performance on complex sequence modeling tasks. Attention provides a dynamic weighted average of values from different points in a calculation during the processing of a sequence to provide long term context for downstream discriminative or generative prediction. In recent work [4,16,22], researchers have augmented LSTM language models with attention mechanisms in order to add capacity for modeling long term syntactic dependencies. Yogatama et al. [22] characterize attention as a differentiable random access memory. They compare attention language models with differentiable stack based memory [6] (which provides a bias for hierarchical structure), demonstrating the superiority of stack based memory on a verb agreement task with multiple attractors. Daniluk et al. [4] explore three additive attention [2] mechanisms with successive partitioning of the output of the LSTM; splitting the output into separate key, value, and prediction vectors performed best, likely due to removing the need for a single vector to encode information for multiple steps in the computation. In contrast we augment our language models with dot product attention [11,18], but also use separate vectors for the components of our attention mechanisms.</p>
<p>Many decision processes raise ethical dilemmas [12] or are applied in critical domains with high consequence. Such factors necessitate human interpretation of how a model is generating its predictions to ensure acceptable results. Vellido et al. [19] observe the gap between data modeling, knowledge extraction, and potential machine learning solutions, underscoring the need for interpretable automated decision processes. However, interpretability has multiple goals that are not always aligned with production of the most generalizable model architecture [10]. Hence, there is currently a large research focus on making interpretable deep learning algorithms for sensitive and critical application areas. Some proposed model introspection techniques include dimensionality reduction [20], analysis of intermediate layers [1] and saliency based methods [3,13]. In contrast to other deep learning components, attention mechanisms allow an immediate view into what factors are affecting model decisions. Xu et al. [21] examine attention weights to determine what convolutional neural networks are "looking" at while making predictions. Similarly, Rocktäschel et al. [15] analyze matrices of word-to-word attention weights for insight into how their LSTM entailment classifier reasons about sentences. We apply 1,C6@D1,U7@D2,C6,C6,Negotiate,Batch,LogOn,Success </p>
<p>METHODS</p>
<p>Here we describe the unsupervised language modeling framework and its extension via five variations of attention. In each case, the language models consume a sequence of log-line tokens and output log-line-level anomaly scores.</p>
<p>Preliminaries</p>
<p>3.1.1 Language Modeling. We assume that each log-line consists of a sequence of T tokens:
x (1:T ) = x (1) , x (2) , . . . , x (T ) . Each token x (t ) ∈ V,
where V denotes the vocabulary. A language model is a model that assigns probabilities to sequences: P(x (1:T ) ). A language model often evaluates the probability of a sequence using the chain rule of probability:
P(x (1:T ) ) = T t =1 P(x (t ) |x (&lt;t ) )(1)
where x (&lt;t ) denotes the (potentially empty) sequence of tokens from x (1) to x (t −1) . The conditional probabilities on the righthand side can be modeled with a recurrent neural network, as will be described in the Section 3.2.</p>
<p>Our data consist of a series of log-lines, each affiliated with a user. We denote user u's ith log-line with x (u,i) (1:T ) , but omit the superscript when it is non-essential. Our language models all output a single anomaly score, the negative log-likelihood, for each log-line. Figure 1 illustrates two methods to partition log lines into sequences of tokens: word and character tokenization. For word based language modeling, the tokens are the fields of the CSV format log file. The user fields are further split on the "@" character to generate user name and domain tokens. A frequency threshold is applied to replace infrequent words with an "out of vocabulary" (OOV) token; a value must occur in a field at least 40 times to be added to the vocabulary. The OOV token ensures that our models will have non-zero probabilities when encountering previously unseen words during evaluation.</p>
<p>Tokenization.</p>
<p>For character based language modeling we use a primitive vocabulary consisting of printable ASCII characters. This circumvents the out of vocabulary issues with the word model. Delimiters are left in the character inputs to give context of switching fields to the models. For both word and character tokenization, the time field is ignored and not tokenized. </p>
<p>Cyber Anomaly Language Models</p>
<p>We recently introduced a language modeling framework for cyber anomaly [17] that forms the starting point of this work. The first of four models presented in [17] is the "Event Model" (EM), which applies a standard LSTM [7] to the token sequences of individual events (log-lines). In order to feed the categorical tokens x (1:T ) into the model, we first perform an embedding lookup on each token to yield the sequence x (1:T ) (bold font), where each x (t ) ∈ R L emb for some embedding dimension hyperparameter, L emb . There are unique embedding vectors for each element in the vocabulary; these embedding vectors are parameters of the model, learned jointly with all other model parameters. An LSTM maps an embedding vector sequence to a sequence of hidden vectors h (1:T ) : 1
LSTM(x (1:T ) ) = h (1:T )(2)
Intuitively, h (t ) is a summary of the input sequence x (1:t ) defined by the same, standard LSTM equations used in [17]. Given the previous hidden state h (t −1) , weight matrix W and bias vector b, the probability distribution over the token at step t is:
p (t ) = softmax h (t −1) L h W L h × |V | + b |V | ∈ R |V |(3)
This conditions each prediction on all tokens that precede it in the log-line. The second model in [17] is the Bidirectional Event Model (BEM), which updates Eqn. 3 to also incorporate the hidden state from a backward-running LSTM, with hidden vector h b (t +1) and additional weight matrix W b as follows:
p (t ) = softmax h (t −1) W + h b (t +1) W b + b(4)
The BEM conditions each prediction on the all of the other tokens in the log-line (preceding or following), for richer context. The EM and BEM only condition predictions on other tokens in the same log line. However, Tuor et al. [17] also introduce tiered language model variants that employ an "upper tier" LSTM to model a user's sequence of log-lines (see Fig. 2). Each log-line is still For all language models (including the tiered models which incorporate inter-log-line context) we optimize the model parameters by minimizing the negative log-likelihood produced by EM or BEM predictions. The negative log-likelihood minimization objective also serves as the anomaly score for the log line (less probable events receiving higher anomaly scores).</p>
<p>Attention</p>
<p>In this work we use dot product attention (Figure 3), wherein an "attention vector" a is generated from three values: 1) a key matrix K, 2) a value matrix V, and 3) a query vector q. In this formulation, keys are a function of the value matrix:
K = tanh(VW a ),(5)
parameterized by W a . The importance of each timestep is determined by the magnitude of the dot product of each key vector with the query vector q ∈ R L a for some attention dimension hyperparameter, L a . These magnitudes determine the weights, d on the weighted sum of value vectors, a:
d = softmax(qK T ) (6) a = dV(7)
In an LSTM, the information relevant to a given prediction (e.g. of the next token, x (t +1) ) is accumulated and propagated via the LSTM's cell state, c (t ) . For any given prediction, however, certain tokens are likely to be more relevant than others. Attention provides a mechanism for predictions to be directly, selectively conditioned on a subset of the relevant tokens. In practice, this is accomplished by making p (t ) a function of the concatenation of h (t −1) with an attention vector a (t −1) that is a weighted sum over hidden states :
p (t ) = softmax h (t −1) a (t −1) W + b(8)
This attention mechanism not only introduces shortcuts in the flow of information over time, allowing the model to more readily access the relevant information for any given prediction, but the weights on the weighted sum also yield insights into the model's decision process, aiding interpretability. We first examine the case of adding attention to the standard EM. Each token-step t is associated with its own value matrix V (t ) , and query vector q (t ) . The value matrix V (t ) is the matrix of hidden states up to but excluding token-step t, where L h is the dimension of the LSTM hidden states. These are the values over which the weighted sum will be performed. (1) . . .
V (t ) =        hh (t −1)        ∈ R (t −1)×L h(9)
From the value matrix and weight matrix W a ∈ R L h ×L a , we compute a set of keys for each token/step:
K (t ) = tanh(V (t ) W a ) ∈ R (t −1)×L a(10)
Then,
d (t ) = softmax(q (t ) K T (t ) )(11)a (t ) = d (t ) V (t )(12)
Our EM attention variants differ primarily in the definition of the query vector q (t ) .</p>
<p>Fixed Attention.</p>
<p>In the fixed variation of attention [16] we let q (t ) = q for some fixed, learned vector q that is shared across all tokens/steps. This assumes some positions in the sequence are more important than others, but that importance does not depend on the token one is trying to predict.</p>
<p>Syntax</p>
<p>Attention. Syntax attention differs from fixed attention in that q (t ) is not shared across t. This assumes that some tokens are more important than others and this importance depends on the position in the sequence for the token to predict, but not on the actual values for tokens x 1 , . . . , x t −1 .</p>
<p>Semantic Attention 1.</p>
<p>For the first "semantic" variation, our query is a a function of the current hidden state and parameter matrix W sem1 ∈ R L h ×L a :
q (t ) = tanh(h (t ) W sem1 )(13)
3.3.4 Semantic Attention 2. Instead of making q (t ) a function of h (t ) , in this variant we interpret each h (t ) emitted from the LSTM as the concatenation of two vectors: h ′ (t ) and q (t ) . The query portion, q (t ) is used as before, but now the value
V (t ) defined in Eqn. 9 contains h ′ (1) through h ′ (t −1)
. Note that, per the LSTM equations, both h ′ (t ) and q (t ) will be fed back into the LSTM at time t + 1. Fig. 2, in original formulation of the tiered model, the lower tier LSTM hidden states are averaged in the process of passing information from the lower tier to the upper tier. Implementation of attention for the tiered language models replaces this mean with a weighted average via attention. Let V (u,i) be the lower tier hidden states for user u's ith log line:</p>
<p>Tiered Attention. As shown in
V (u,i) =          h (u,i)(1)
. . .  Let W t ier ∈ R L k ×L a and W a ∈ R L a ×L k be parameter matrices. We then define the following attention mechanisms:
h (u,i) (T )         (14)q = tanh(h (T ) W (t ier ) )(15)K = tanh(VW a )(16)d = softmax(qK T ) (17) a = dV(18)
We then replace the average of the hidden states in the tiered model with a. Note that each sequence shares weights W a and W t ier .</p>
<p>The BEM tiered attention model (TA-BEM) is depicted in Figure 5.</p>
<p>Online Training</p>
<p>We employ a syncopated online training algorithm, which both allows our model to continually adapt to changing distributions of activities on a network and to be deployed on high throughput streaming data sources. At the beginning of each day/cycle, the parameters of the current model are fixed for evaluation, thereby avoiding evolving anomaly score scale issues that could result from continuous online training. After anomaly scores have been calculated for the day's events we train on the current day's events. The days events are then discarded, bounding the storage demands of the algorithm to a day's worth of activity (plus model parameters).</p>
<p>On the first day we do not evaluate as the model has not had a training phase yet. At the cost of the additional space complexity of storing two copies of the model parameters, the training and evaluation phases can be run concurrently. The evaluation and training parameters are then synced daily so that the evaluation copy is updated with the parameters of the training copy at the beginning of each day.</p>
<p>EXPERIMENTS</p>
<p>This section discusses the data, experimental setup, evaluation metrics, and results assessing performance for the proposed methods.</p>
<p>Data</p>
<p>We evaluate our models on the publicly available LANL [8] dataset. LANL consists of over one billion log lines collected over 58 consecutive days. The logs contain anonymized process, network flow, DNS, and authentication information. Interleaved are attacks by a red team. Our experiments focus on modeling the authentication logs, which contain the following fields:</p>
<p>Source user, Destination user, Source pc, Destination pc, Authentication type, Logon type, Authentication orientation, Success/failure. These events are collected from desktop PCs, servers, and active directory servers using the Windows OS. We filter automated system events by discarding all log-lines that have a machine listed as the source user. Red team event log-lines are indicated in the dataset. As our models are fully unsupervised, we use the red team labels only for evaluation of model performance.</p>
<p>Experimental Setup</p>
<p>To assess our model's ability to spin up rapidly and detect anomalies with minimal burn-in time, we limit our scope to days 7 and 8, which contain 1 and 261 red team events respectively. Each of these days contains over seven million user log lines. We chose these particular days for evaluation because day 8 has the largest number of red events in the dataset. The entire experimental process is therefore 1) train on day 7, 2) evaluate on day 8. Further simulating a rapid deployment process, we performed no hyper-parameter tuning. Our learning rate is fixed to 0.01; we train using the ADAM [9] optimizer; the minibatch size is 64; our LSTMs have a single layer with 128 hidden units; our token embedding size is 128 and our attention size is 128. To estimate model variability, we trained each model five times with the fixed hyper-parameters but different random weight initializations. In our results section we report statistics over the five runs.</p>
<p>Metrics and Score Normalization</p>
<p>We evaluate our results using the area under the receiver operating characteristic curve (AUC ROC). ROC plots the true positive rate against the false positive rate as the detection threshold is swept. Perfect detection yields an AUC of 1 and random guessing yields 0.5. Recall that our anomaly scores, z (u,i) are given by the sum of the negative log probabilities of the tokens in line x  Table 2: AUC statistics for character tokenization models tokenization, we center each user's anomaly score:
z (u,i) ← z (u,i) − 1 N u i z (u,i) , ∀ u ,(19)
where N u is the number of events by user u in the day. This reduces inter-user anomaly bias, which can stem from the uneven distribution of user name tokens. This normalization is unnecessary for the character tokenization, as the user names are composed from a common character vocabulary.</p>
<p>Results</p>
<p>In this section we discuss performance of the different attention mechanisms. We note that variance of model performance across random parameter initializations is quite low for most models. This low variance given only a single day of pretraining suggests our method behaves predictably despite rapid deployment. word level LSTM baselines, the BEM outperforms the EM. However, adding attention to the EM improves performance to match the BEM. All variations of attention have very similar AUC scores. We hypothesize that the word model equally benefits from Syntax and Semantic attention, as it has a consistent syntax structure. Tiered word models with attention do not demonstrate as significant performance gains, however, both forward and bidirectional attention models trend slightly upwards in mean and maximum values from their non-attention counterparts. Table 2, the Fixed and Syntax attention models appear ill-suited for characterbased models with variable length fields; neither Fixed nor Syntax attention improve performance here, and the character EM model augmented with Fixed attention has a standard deviation 2-15 times that of other models. In contrast, semantic variants, where the attention weights are a function of the current input as opposed to sequence position, do improve performance but are not on par with the BEM. For the tiered models, we see little difference by incorporating attention, suggesting the shortcuts introduced by attention are unnecessary to propagate user context across loglines. One interesting outcome is that a tiered model with either attention or a bidirectional lower tier has reduced variance across random initializations by a large factor for the character models.</p>
<p>Word Tokenization Models.</p>
<p>Character Tokenization Models. As shown in</p>
<p>ANALYSIS</p>
<p>While attention performs comparably to bidirectionality, it offers substantial advantages in its interpretability. Investigating which fields the model is attending to (and when) offers clues to its decision-making. In this section we illustrate two approaches to analysis of attention-equipped LSTM language models: 1) Analysis of global model behavior from summary statistics of attention weights, and 2) analysis of particular model decisions from case studies of attention weights and language model predictions.</p>
<p>Global Behavior</p>
<p>We can gain insight into the global behavior of an attention-equipped LSTM from summary statistics such as the mean and standard deviation of attention weights over the course of a day's predictions. Figure 6 shows the average attention weights for each EM attention model when predicting the last meaningful token (Success/Fail). Error bars of one standard deviation are shown to illustrate the variability of these weights.</p>
<p>Heatmaps of average attention weights for the four EM attention models proposed in Section 3.3 are provided in Figures 7, 8, 9 and 10. Each time step in a sequence generates its own set of weights, d (t ) , over the previous hidden states. The larger the weight values are the more relevant the associated hidden state is to the current prediction. Note that the first input token is excluded from our figures as it has no previous hidden states to attend over. Figure 7 shows the mean weights for the Fixed attention which has a single fixed query that does not change with the context at the current time step. The source user, destination domain and source PC dominate the weight vectors, suggesting that they are the most important fields to this model. </p>
<p>Fixed.</p>
<p>Syntax.</p>
<p>With the syntax model ( Figure 8) each time step gets its own set of query weights. This makes sense for word tokenized models that have position dependent syntax. As an example of the model exhibiting intuitive behavior, when predicting the source PC, the model is attending heavily over the source user. </p>
<p>Semantic.</p>
<p>While the semantic attention mechanisms do not assume a fixed syntactic structure, Figures 9 and 10 show that both semantic attention variants learn reasonable attention strategies on this fixed syntax data. Overall they produce similar attention maps, attending heavily to source user and source PC. Semantic 1 also attends heavily to authentication type, while Semantic 2 also deems destination user and destination PC to be important.</p>
<p>Tiered attention models.</p>
<p>For the tiered model with a lower forward-directional LSTM, the attention weights were nearly all 1.0 for the second to last hidden state. This state is making the decision on success/fail, which conceptually makes sense with the goal of top tier LSTM to pass the most relevant information forward for the next event. Conversely, the tiered model with bidirectional LSTM cells attended fully on the very first hidden state. As Figure 5 shows, the backward LSTM ends with the first hidden state. Thus, the bidirectional tiered model is collecting both the final hidden state from the forward LSTM and the backward LSTM as its summary. This suggests that the shortcut connections attention provides are not needed for this model and task.  Figure 11: Red team word case study with semantic attention. See Figure 13 for description.  Figure 12: Low anomaly word case study with semantic attention. See Figure 13 for description.</p>
<p>Case Studies</p>
<p>We consider three case studies evaluated using semantic attention models. Figures 11 and 13 depict two randomly sampled red events evaluated with word and character semantic attention models, respectively. For contrast, Figure 12 is a random non-anomalous event evaluated with the semantic word model. Tokens where the predicted and true values diverge are of significant interest as they contribute heavily to the anomaly score. We can disregard the low probabilities when predicting the source user as it is impossible to foresee what user will be associated with a random input sequence.</p>
<p>Word Tokenization.</p>
<p>First consider the two word case studies. In both cases the source PC prediction is incorrect with low confidence. In the low-anomaly case the model is able to correctly predict the destination PC given the source PC token with very high probability. However, the red team event predicted a token associated with a different field for the destination PC. Examining the weights we see that the red team event was attending heavily over the hidden state taking the destination user domain as input and predicting the source user. We note that DOM1 is a very common domain in the LANL dataset and that the attention is likely considering the prediction that will be made from the embedding which relates to the current input token. This misclassification exposes a disadvantage in having a shared vocabulary for each field. Individual vocabularies for each field could improve performance, at the cost of minor feature engineering.</p>
<p>Character Tokenization.</p>
<p>Finally, we examine model function when processing a character tokenized red team event. When predicting the destination PC characters the hidden state associated with the comma character right before the prediction of the source PC has the largest associated weight. The second largest weight is the comma character right before the destination PC field begins. This may suggest that the model is learning positional information from the comma characters, or that it is accumulating summary vectors of the fields and "storing them" in the subsequent delimiter hidden state. Another point of interest is the attention weight   Figure 13: Red team case character study with Semantic attention. Coloring of the true token and predicted token rows is based on the probability of the given character during prediction. Green represents a near 100% probability while red is near 0%. Attention weights d(t) correspond to the top row of predictions. For example, when predicting character character 34, K, the model uses attention weights d(34). We provide a shifted copy of the predicted tokens at the bottom of the figure to align with the hidden states being attended to. Best viewed in color.</p>
<p>vector d(34). It will substantially impact our anomaly score as our model had almost 100% confidence that the next character would be 'K', while the true token, 'N', has near 0% probability. Again we see a heavy dependence on the delimiter hidden states.</p>
<p>CONCLUSIONS</p>
<p>In this paper we propose five attention mechanism implementations. The fixed and syntactic attention variants can be effective for modeling sequences with a fixed structure while semantic variants are more effective for input sequences that have varying lengths and looser structures. While maintaining state-of-the-art performance, the attention mechanisms provide information on both feature importance and relational mapping between features. Additionally, architectural insights can be gleaned from the attention applied, which may in the future lead to designing more effective models. Other future work includes evaluating the system on different tasks and domains (e.g. detection of hardware failures from computer logs). One could explore additional attention variants; e.g., bidirectional models with attention may lead to further gains in performance. Finally, equipping a lower tier model with the ability to attend over upper tier hidden states, may effectively weight the relevance of previous events in a user's log sequence.</p>
<p>Figure 1 :
1Top: Word tokens; Bottom: Character tokens the same concept to explore what factors our models attend over when predicting anomaly scores.</p>
<p>Figure 2 :
2Tiered language model (T-EM)[17].</p>
<p>Figure 3 :
3Dot Product Attention. modeled by an EM or BEM, but the input is the concatenation of embedding vectors x t along with a context vector produced by the upper tier LSTM. The upper tier LSTM takes as input a summary of the lower-tier hidden states (the average lower-tier hidden state concatenated with the final hidden state). The upper and lower tiers are trained jointly. For later reference, we name these models T-EM and T-BEM, respectively.</p>
<p>Figure 4 :
4Event Model (EM) with attention. Dotted lines indicate which hidden states are being attended over.</p>
<p>Figure 5 :
5Tiered attention with bidirectional lower tier</p>
<p>Figure 6 :Figure 7 :Figure 8 :
678Comparison of attention weights when predicting success/failure token. Average Fixed attention weights. Average Syntax attention weights.</p>
<p>Figure 9 :Figure 10 :
910Average Average Semantic 2 attention weights.</p>
<p>Table 1 shows
1AUC statistics for the word tokenization model experiments. Comparing the First Workshop On Machine Learning for Computer Systems, June 2018, Tempe, AZ USA A. Brown et al.
In this paper we assume all vectors are row vectors and adopt the notation convention of left multiplying matrices with row vectors (omitting the conventional transpose to avoid clutter).
ACKNOWLEDGMENTSThe research described in this paper is part of the Analysis in Motion Initiative at Pacific Northwest National Laboratory; conducted under the Laboratory Directed Research and Development Program at PNNL, a multi-program national laboratory operated by Battelle for the U.S. Department of Energy. The authors also thank Nvidia for their donations of Titan X GPU's used in this research.
Understanding intermediate layers using linear classifier probes. Guillaume Alain, Yoshua Bengio, arXiv:1610.01644arXiv preprintGuillaume Alain and Yoshua Bengio. 2016. Understanding intermediate layers using linear classifier probes. arXiv preprint arXiv:1610.01644 (2016).</p>
<p>Neural machine translation by jointly learning to align and translate. Dzmitry Bahdanau, Kyunghyun Cho, Yoshua Bengio, arXiv:1409.0473arXiv preprintDzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. 2014. Neural ma- chine translation by jointly learning to align and translate. arXiv preprint arXiv:1409.0473 (2014).</p>
<p>. Chun-Hao Chang, Elliot Creager, Anna Goldenberg, David Duvenaud, n. d.Chun-Hao Chang, Elliot Creager, Anna Goldenberg, and David Duvenaud. [n. d.].</p>
<p>Interpreting Neural Network Classifications with Variational Dropout Saliency Maps. n. d.Interpreting Neural Network Classifications with Variational Dropout Saliency Maps. ([n. d.]).</p>
<p>Frustratingly short attention spans in neural language modeling. Michał Daniluk, Tim Rocktäschel, Johannes Welbl, Sebastian Riedel, arXiv:1702.04521arXiv preprintMichał Daniluk, Tim Rocktäschel, Johannes Welbl, and Sebastian Riedel. 2017. Frustratingly short attention spans in neural language modeling. arXiv preprint arXiv:1702.04521 (2017).</p>
<p>DeepLog: Anomaly Detection and Diagnosis from System Logs through Deep Learning. Min Du, Feifei Li, Guineng Zheng, Vivek Srikumar, Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security. the 2017 ACM SIGSAC Conference on Computer and Communications SecurityACMMin Du, Feifei Li, Guineng Zheng, and Vivek Srikumar. 2017. DeepLog: Anomaly Detection and Diagnosis from System Logs through Deep Learning. In Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security. ACM, 1285-1298.</p>
<p>Learning to transduce with unbounded memory. Edward Grefenstette, Karl Moritz Hermann, Mustafa Suleyman, Phil Blunsom, Advances in Neural Information Processing Systems. Edward Grefenstette, Karl Moritz Hermann, Mustafa Suleyman, and Phil Blunsom. 2015. Learning to transduce with unbounded memory. In Advances in Neural Information Processing Systems. 1828-1836.</p>
<p>Long Short-Term Memory. Sepp Hochreiter, Jürgen Schmidhuber, 10.1162/neco.1997.9.8.1735Neural Comput. 9Sepp Hochreiter and Jürgen Schmidhuber. 1997. Long Short-Term Memory. Neural Comput. 9, 8 (Nov. 1997), 1735-1780. https://doi.org/10.1162/neco.1997.9. 8.1735</p>
<p>Cyber security data sources for dynamic network research. D Alexander, Kent, Dynamic Networks and Cyber-Security. 137Alexander D Kent. 2016. Cyber security data sources for dynamic network research. Dynamic Networks and Cyber-Security 1 (2016), 37.</p>
<p>Adam: A Method for Stochastic Optimization. P Diederik, Jimmy Kingma, Ba, arXiv:1412.6980Diederik P. Kingma and Jimmy Ba. 2014. Adam: A Method for Stochastic Optimiza- tion. CoRR abs/1412.6980 (2014). arXiv:1412.6980 http://arxiv.org/abs/1412.6980</p>
<p>The Mythos of Model Interpretability. Zachary Chase Lipton, arXiv:1606.03490Zachary Chase Lipton. 2016. The Mythos of Model Interpretability. CoRR abs/1606.03490 (2016). arXiv:1606.03490 http://arxiv.org/abs/1606.03490</p>
<p>Effective approaches to attention-based neural machine translation. Minh-Thang Luong, Hieu Pham, Christopher D Manning, arXiv:1508.04025arXiv preprintMinh-Thang Luong, Hieu Pham, and Christopher D Manning. 2015. Effec- tive approaches to attention-based neural machine translation. arXiv preprint arXiv:1508.04025 (2015).</p>
<p>The ethics of algorithms: Mapping the debate. Patrick Brent Daniel Mittelstadt, Mariarosaria Allo, Sandra Taddeo, Luciano Wachter, Floridi, Big Data &amp; Society. 32053951716679679Brent Daniel Mittelstadt, Patrick Allo, Mariarosaria Taddeo, Sandra Wachter, and Luciano Floridi. 2016. The ethics of algorithms: Mapping the debate. Big Data &amp; Society 3, 2 (2016), 2053951716679679.</p>
<p>Explaining hyperspectral imaging based plant disease identification: 3D CNN and saliency maps. Koushik Nagasubramanian, Sarah Jones, K Asheesh, Arti Singh, Baskar Singh, Soumik Ganapathysubramanian, Sarkar, n. d.. n. d.Koushik Nagasubramanian, Sarah Jones, Asheesh K Singh, Arti Singh, Baskar Ganapathysubramanian, and Soumik Sarkar. [n. d.]. Explaining hyperspectral imaging based plant disease identification: 3D CNN and saliency maps. ([n. d.]).</p>
<p>Malware classification with recurrent networks. Razvan Pascanu, W Jack, Hermineh Stokes, Mady Sanossian, Anil Marinescu, Thomas, Acoustics, Speech and Signal Processing (ICASSP), 2015 IEEE International Conference on. IEEE. Razvan Pascanu, Jack W Stokes, Hermineh Sanossian, Mady Marinescu, and Anil Thomas. 2015. Malware classification with recurrent networks. In Acoustics, Speech and Signal Processing (ICASSP), 2015 IEEE International Conference on. IEEE, 1916-1920.</p>
<p>Tim Rocktäschel, Edward Grefenstette, Karl Moritz Hermann, Tomáš Kočiskỳ, Phil Blunsom, arXiv:1509.06664Reasoning about entailment with neural attention. arXiv preprintTim Rocktäschel, Edward Grefenstette, Karl Moritz Hermann, Tomáš Kočiskỳ, and Phil Blunsom. 2015. Reasoning about entailment with neural attention. arXiv preprint arXiv:1509.06664 (2015).</p>
<p>Attentive Language Models. Giancarlo Salton, Robert Ross, John Kelleher, Proceedings of the Eighth International Joint Conference on Natural Language Processing. the Eighth International Joint Conference on Natural Language Processing1Giancarlo Salton, Robert Ross, and John Kelleher. 2017. Attentive Language Models. In Proceedings of the Eighth International Joint Conference on Natural Language Processing (Volume 1: Long Papers), Vol. 1. 441-450.</p>
<p>Aaron Tuor, Ryan Baerwolf, Nicolas Knowles, Brian Hutchinson, Nicole Nichols, Rob Jasper, arXiv:1712.00557Recurrent Neural Network Language Models for Open Vocabulary Event-Level Cyber Anomaly Detection. arXiv preprintAaron Tuor, Ryan Baerwolf, Nicolas Knowles, Brian Hutchinson, Nicole Nichols, and Rob Jasper. 2017. Recurrent Neural Network Language Models for Open Vo- cabulary Event-Level Cyber Anomaly Detection. arXiv preprint arXiv:1712.00557 (2017).</p>
<p>Attention is all you need. Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, Illia Polosukhin, Advances in Neural Information Processing Systems. Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. In Advances in Neural Information Processing Systems. 6000-6010.</p>
<p>Making machine learning models interpretable. Alfredo Vellido, José David Martín-Guerrero, Paulo Jg Lisboa, ESANN. Citeseer12Alfredo Vellido, José David Martín-Guerrero, and Paulo JG Lisboa. 2012. Making machine learning models interpretable.. In ESANN, Vol. 12. Citeseer, 163-172.</p>
<p>Principal component analysis. Chemometrics and intelligent laboratory systems. Svante Wold, Kim Esbensen, Paul Geladi, 2Svante Wold, Kim Esbensen, and Paul Geladi. 1987. Principal component analysis. Chemometrics and intelligent laboratory systems 2, 1-3 (1987), 37-52.</p>
<p>Show, Attend and Tell: Neural Image Caption Generation with Visual Attention. Kelvin Xu, Jimmy Ba, Ryan Kiros, Kyunghyun Cho, Aaron C Courville, Ruslan Salakhutdinov, Richard S Zemel, Yoshua Bengio, arXiv:1502.03044Kelvin Xu, Jimmy Ba, Ryan Kiros, Kyunghyun Cho, Aaron C. Courville, Ruslan Salakhutdinov, Richard S. Zemel, and Yoshua Bengio. 2015. Show, Attend and Tell: Neural Image Caption Generation with Visual Attention. CoRR abs/1502.03044 (2015). arXiv:1502.03044 http://arxiv.org/abs/1502.03044</p>
<p>Memory Architectures in Recurrent Neural Network Language Models. Dani Yogatama, Yishu Miao, Gabor Melis, Wang Ling, Adhiguna Kuncoro, Chris Dyer, Phil Blunsom, International Conference on Learning Representations. Dani Yogatama, Yishu Miao, Gabor Melis, Wang Ling, Adhiguna Kuncoro, Chris Dyer, and Phil Blunsom. 2018. Memory Architectures in Recurrent Neural Net- work Language Models. In International Conference on Learning Representations. https://openreview.net/forum?id=SkFqf0lAZ</p>
<p>Automated IT system failure prediction: A deep learning approach. Ke Zhang, Jianwu Xu, Martin Renqiang Min, Guofei Jiang, Konstantinos Pelechrinis, Hui Zhang, Big Data (Big Data). Ke Zhang, Jianwu Xu, Martin Renqiang Min, Guofei Jiang, Konstantinos Pelechri- nis, and Hui Zhang. 2016. Automated IT system failure prediction: A deep learning approach. In Big Data (Big Data), 2016 IEEE International Conference on. IEEE, 1291-1300.</p>            </div>
        </div>

    </div>
</body>
</html>