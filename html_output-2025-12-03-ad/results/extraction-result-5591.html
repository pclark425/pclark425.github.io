<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-5591 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-5591</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-5591</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-115.html">extraction-schema-115</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or structured/tabular data, including details of the models, methods, datasets, types of anomalies, performance, and comparisons to traditional methods.</div>
                <p><strong>Paper ID:</strong> paper-269922196</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2405.11238v2.pdf" target="_blank">SimAD: A Simple Dissimilarity-Based Approach for Time-Series Anomaly Detection</a></p>
                <p><strong>Paper Abstract:</strong> Despite the prevalence of reconstruction-based deep learning methods, time-series anomaly detection (TSAD) remains a tremendous challenge. Existing approaches often struggle with limited temporal contexts, insufficient representation of normal patterns, and flawed evaluation metrics, all of which hinder their effectiveness in detecting anomalous behavior. To address these issues, we introduce a simple dissimilarity-based approach for time-series anomaly detection (SimAD). Specifically, SimAD first incorporates a patching-based feature extractor capable of processing extended temporal windows and employs the EmbedPatch encoder to fully integrate normal behavioral patterns. Second, we design an innovative ContrastFusion module in SimAD, which strengthens the robustness of anomaly detection by highlighting the distributional differences between normal and abnormal data. Third, we introduce two robust enhanced evaluation metrics, unbiased affiliation (UAff) and normalized affiliation (NAff), designed to overcome the limitations of existing metrics by providing better distinctiveness and semantic clarity. The reliability of these two metrics has been demonstrated by both theoretical and experimental analyses. Experiments conducted on seven diverse time-series datasets clearly demonstrate SimAD’s superior performance compared with state-of-the-art (SOTA) methods, achieving relative improvements of 19.85% on ${F}1$ , 4.44% on Aff-F1, 77.79% on NAff-F1, and 9.69% on AUC on six multivariate datasets. Code and pretrained models are available at https://github.com/EmorZz1G/SimAD</p>
                <p><strong>Cost:</strong> 0.013</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e5591.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e5591.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or structured/tabular data, including details of the models, methods, datasets, types of anomalies, performance, and comparisons to traditional methods.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GPT2-Adapter</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>GPT2-Adapter (LLM-enhanced time series anomaly detection baseline)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An adaptation of a GPT-2 style large language model used as a baseline for time-series anomaly detection by repurposing token prediction to time-series prediction and using prediction loss for anomaly scoring; included as an experimental baseline in this paper and evaluated on multiple multivariate and univariate time-series datasets.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT2-Adapter (GPT-2 based adapter)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>A GPT-2 style decoder-only transformer pre-trained as a language model, adapted via adapter layers / limited fine-tuning to map token prediction to time-series prediction; used to produce prediction losses that serve as anomaly scores. The paper describes it as a GPT-2 based adapter that fine-tunes feed-forward and layer-norm parameters to convert next-token prediction into time-series forecasting.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_detection_method</strong></td>
                            <td>Adapter-based fine-tuning of a pre-trained GPT-2 style LLM to predict next time steps; anomaly scores computed from prediction (reconstruction/prediction) loss (i.e., scoring by prediction error).</td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Sequences — multivariate and univariate time series (temporal sequences)</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>Time-series anomalies including point anomalies and segment/sequence anomalies (the paper discusses both short-duration and long-duration/segment anomalies)</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td>Evaluated as a baseline on the paper's suite: MSL, SMAP, PSM, SWaT, WADI, Swan (multivariate) and UCR (univariate) — reported in comparison tables</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Evaluated with point-level F1, AUC and sequence-level Aff-F1 plus the paper's proposed UAff-F1 and NAff-F1. Reported performance for GPT2-Adapter is generally low compared to SOTA; example values from the paper: MSL F1=13.72, AUC=52.03, Aff-F1≈68.81 (Aff-Pre/Aff-Rec reported), SWaT F1=22.30, AUC=52.30 (see Table II).</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Compared to SimAD and other baselines, GPT2-Adapter underperforms on most datasets; the paper states GPT2-Adapter 'falls short' due to modal-alignment and fine-tuning challenges and lacks specialized optimization for time-series anomaly detection.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Reported limitations include modal/alignment issues when applying natural-language LLMs to time-series data, difficulties fine-tuning LLM parameters for anomaly tasks, lack of time-series-specific optimization, and generally poorer detection performance (especially for segment anomalies and some datasets) relative to methods specialized for time-series; model size and computational cost are also noted as larger than many baselines in the paper's time-cost table.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'SimAD: A Simple Dissimilarity-Based Approach for Time-Series Anomaly Detection', 'publication_date_yy_mm': '2025-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5591.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e5591.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or structured/tabular data, including details of the models, methods, datasets, types of anomalies, performance, and comparisons to traditional methods.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LLM (GPT-2 family) for TSAD</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Large Language Models (e.g., GPT-2 family) applied to Time Series Anomaly Detection</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>The paper cites and discusses the emerging practice of adapting large pre-trained language models (LLMs) such as GPT-2 for anomaly detection on time-series by reprogramming or fine-tuning them to perform forecasting/prediction and using prediction errors as anomaly signals; LLM-based approaches are discussed in related work and as a baseline class.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-2 family / generic LLMs</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Decoder-only Transformer LLM architectures pre-trained on large corpora (the paper refers generically to GPT-2 style LLMs); specifics such as parameter counts or exact architecture sizes are not provided in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_detection_method</strong></td>
                            <td>Typically adapted by mapping token prediction to time-series prediction (adapter modules or fine-tuning) and using prediction/reconstruction loss as anomaly score; approaches range from adapter-based fine-tuning to reprogramming a pretrained LM for forecasting.</td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Sequences — time series (multivariate and univariate temporal sequences); the paper frames this as applying LLMs to time-series forecasting/prediction tasks rather than to lists or tabular data specifically.</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>Time-series anomalies (point anomalies and sequence/segment anomalies); the paper emphasizes segment detection difficulties for some LLM approaches.</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>When discussed as a class, the paper notes typical evaluation metrics used in TSAD: F1, AUC, Aff-F1, and the proposed UAff-F1 / NAff-F1; no single LLM family-wide performance is provided beyond specific baseline (GPT2-Adapter) numbers.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>The paper positions LLM-adaptations as an emerging direction but states that existing LLM-based attempts (e.g., GPT2-Adapter) often underperform compared to TSAD-specialized models due to modality alignment and optimization issues.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Cited weaknesses include modal alignment (language pretraining vs numerical time-series), difficulty in fine-tuning LLMs for temporal prediction/anomaly tasks, and lack of optimizations tailored to time series which lead to subpar detection performance and practical inefficiency.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'SimAD: A Simple Dissimilarity-Based Approach for Time-Series Anomaly Detection', 'publication_date_yy_mm': '2025-11'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>One Fits All: Power General Time Series Analysis by Pretrained LM <em>(Rating: 2)</em></li>
                <li>Time-llm: Time series forecasting by reprogramming large language models <em>(Rating: 2)</em></li>
                <li>Llm4ts: Aligning pre-trained llms as data-efficient timeseries forecasters <em>(Rating: 2)</em></li>
                <li>GPT-Adapter <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-5591",
    "paper_id": "paper-269922196",
    "extraction_schema_id": "extraction-schema-115",
    "extracted_data": [
        {
            "name_short": "GPT2-Adapter",
            "name_full": "GPT2-Adapter (LLM-enhanced time series anomaly detection baseline)",
            "brief_description": "An adaptation of a GPT-2 style large language model used as a baseline for time-series anomaly detection by repurposing token prediction to time-series prediction and using prediction loss for anomaly scoring; included as an experimental baseline in this paper and evaluated on multiple multivariate and univariate time-series datasets.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "GPT2-Adapter (GPT-2 based adapter)",
            "model_description": "A GPT-2 style decoder-only transformer pre-trained as a language model, adapted via adapter layers / limited fine-tuning to map token prediction to time-series prediction; used to produce prediction losses that serve as anomaly scores. The paper describes it as a GPT-2 based adapter that fine-tunes feed-forward and layer-norm parameters to convert next-token prediction into time-series forecasting.",
            "model_size": null,
            "anomaly_detection_method": "Adapter-based fine-tuning of a pre-trained GPT-2 style LLM to predict next time steps; anomaly scores computed from prediction (reconstruction/prediction) loss (i.e., scoring by prediction error).",
            "data_type": "Sequences — multivariate and univariate time series (temporal sequences)",
            "anomaly_type": "Time-series anomalies including point anomalies and segment/sequence anomalies (the paper discusses both short-duration and long-duration/segment anomalies)",
            "dataset_name": "Evaluated as a baseline on the paper's suite: MSL, SMAP, PSM, SWaT, WADI, Swan (multivariate) and UCR (univariate) — reported in comparison tables",
            "performance_metrics": "Evaluated with point-level F1, AUC and sequence-level Aff-F1 plus the paper's proposed UAff-F1 and NAff-F1. Reported performance for GPT2-Adapter is generally low compared to SOTA; example values from the paper: MSL F1=13.72, AUC=52.03, Aff-F1≈68.81 (Aff-Pre/Aff-Rec reported), SWaT F1=22.30, AUC=52.30 (see Table II).",
            "baseline_comparison": "Compared to SimAD and other baselines, GPT2-Adapter underperforms on most datasets; the paper states GPT2-Adapter 'falls short' due to modal-alignment and fine-tuning challenges and lacks specialized optimization for time-series anomaly detection.",
            "limitations_or_failure_cases": "Reported limitations include modal/alignment issues when applying natural-language LLMs to time-series data, difficulties fine-tuning LLM parameters for anomaly tasks, lack of time-series-specific optimization, and generally poorer detection performance (especially for segment anomalies and some datasets) relative to methods specialized for time-series; model size and computational cost are also noted as larger than many baselines in the paper's time-cost table.",
            "uuid": "e5591.0",
            "source_info": {
                "paper_title": "SimAD: A Simple Dissimilarity-Based Approach for Time-Series Anomaly Detection",
                "publication_date_yy_mm": "2025-11"
            }
        },
        {
            "name_short": "LLM (GPT-2 family) for TSAD",
            "name_full": "Large Language Models (e.g., GPT-2 family) applied to Time Series Anomaly Detection",
            "brief_description": "The paper cites and discusses the emerging practice of adapting large pre-trained language models (LLMs) such as GPT-2 for anomaly detection on time-series by reprogramming or fine-tuning them to perform forecasting/prediction and using prediction errors as anomaly signals; LLM-based approaches are discussed in related work and as a baseline class.",
            "citation_title": "",
            "mention_or_use": "mention",
            "model_name": "GPT-2 family / generic LLMs",
            "model_description": "Decoder-only Transformer LLM architectures pre-trained on large corpora (the paper refers generically to GPT-2 style LLMs); specifics such as parameter counts or exact architecture sizes are not provided in this paper.",
            "model_size": null,
            "anomaly_detection_method": "Typically adapted by mapping token prediction to time-series prediction (adapter modules or fine-tuning) and using prediction/reconstruction loss as anomaly score; approaches range from adapter-based fine-tuning to reprogramming a pretrained LM for forecasting.",
            "data_type": "Sequences — time series (multivariate and univariate temporal sequences); the paper frames this as applying LLMs to time-series forecasting/prediction tasks rather than to lists or tabular data specifically.",
            "anomaly_type": "Time-series anomalies (point anomalies and sequence/segment anomalies); the paper emphasizes segment detection difficulties for some LLM approaches.",
            "dataset_name": null,
            "performance_metrics": "When discussed as a class, the paper notes typical evaluation metrics used in TSAD: F1, AUC, Aff-F1, and the proposed UAff-F1 / NAff-F1; no single LLM family-wide performance is provided beyond specific baseline (GPT2-Adapter) numbers.",
            "baseline_comparison": "The paper positions LLM-adaptations as an emerging direction but states that existing LLM-based attempts (e.g., GPT2-Adapter) often underperform compared to TSAD-specialized models due to modality alignment and optimization issues.",
            "limitations_or_failure_cases": "Cited weaknesses include modal alignment (language pretraining vs numerical time-series), difficulty in fine-tuning LLMs for temporal prediction/anomaly tasks, and lack of optimizations tailored to time series which lead to subpar detection performance and practical inefficiency.",
            "uuid": "e5591.1",
            "source_info": {
                "paper_title": "SimAD: A Simple Dissimilarity-Based Approach for Time-Series Anomaly Detection",
                "publication_date_yy_mm": "2025-11"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "One Fits All: Power General Time Series Analysis by Pretrained LM",
            "rating": 2,
            "sanitized_title": "one_fits_all_power_general_time_series_analysis_by_pretrained_lm"
        },
        {
            "paper_title": "Time-llm: Time series forecasting by reprogramming large language models",
            "rating": 2,
            "sanitized_title": "timellm_time_series_forecasting_by_reprogramming_large_language_models"
        },
        {
            "paper_title": "Llm4ts: Aligning pre-trained llms as data-efficient timeseries forecasters",
            "rating": 2,
            "sanitized_title": "llm4ts_aligning_pretrained_llms_as_dataefficient_timeseries_forecasters"
        },
        {
            "paper_title": "GPT-Adapter",
            "rating": 1,
            "sanitized_title": "gptadapter"
        }
    ],
    "cost": 0.0128775,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>SimAD: A Simple Dissimilarity-based Approach for Time Series Anomaly Detection</p>
<p>Zhijie Zhong 
Zhiwen Yu 
Senior Member IEEEXing Xi 
Yue Xu 
Member IEEEWenming Cao 
Yiyuan Yang 
Member IEEEKaixiang Yang 
Jane You jane.you@polyu.edu.hk 
Extractor Feature 
Encoder Embedpatch 
Contrastfusion </p>
<p>Zhijie Zhong is with Pengcheng Laboratory
518066Shenzhen, GuangdongChina</p>
<p>School of Future Technology
South China University of Technology
510650GuangzhouGuangdongChina</p>
<p>School of Computer Science and Engineering
Pengcheng Laboratory
South China University of Technology
510650, 518066Guangzhou, ShenzhenGuangdong, GuangdongChina, China</p>
<p>School of Computer Science and Engineering
South China University of Technology
510650GuangzhouGuangdongChina</p>
<p>Department of Information and Computing Science
Chongqing Jiaotong University</p>
<p>the University of Oxford
OxfordUK</p>
<p>Department of Industrial and Systems En-gineering
The Hong Kong Polytechnic University
China</p>
<p>Xi'an Jiaotong University
1986Xi'anChina</p>
<p>La Trobe University
1992MelbourneVIC, inAustralia</p>
<p>University of South Australia
Adelaide SAAus-tralia</p>
<p>Senior Lecturer with Griffith University
NathanQLDAustralia</p>
<p>The Hong Kong Polytechnic University
Hong Kong</p>
<p>SimAD: A Simple Dissimilarity-based Approach for Time Series Anomaly Detection
B4660CD7FFA41B7ED2FC0A3B22422D8Ffrom 1993 to 2002. SheData miningTime seriesAnomaly detectionDeep learningOutlier detectionEvaluation metrics Her current research interests include image processingpattern recognitionmedical imagingbiometrics computingmultimedia systemsand data mining
Despite the prevalence of reconstruction-based deep learning methods, time series anomaly detection remains a tremendous challenge.Existing approaches often struggle with limited temporal contexts, insufficient representation of normal patterns, and flawed evaluation metrics, all of which hinder their effectiveness in detecting anomalous behavior.To address these issues, we introduce a Simple dissimilarity-based approach for time series Anomaly Detection, referred to as SimAD.Specifically, SimAD first incorporates a patching-based feature extractor capable of processing extended temporal windows and employs the EmbedPatch encoder to fully integrate normal behavioral patterns.Second, we design an innovative ContrastFusion module in SimAD, which strengthens the robustness of anomaly detection by highlighting the distributional differences between normal and abnormal data.Third, we introduce two robust enhanced evaluation metrics, Unbiased Affiliation (UAff) and Normalized Affiliation (NAff), designed to overcome the limitations of existing metrics by providing better distinctiveness and semantic clarity.The reliability of these two metrics has been demonstrated by both theoretical and experimental analyses.Experiments conducted on seven diverse time series datasets clearly demonstrate SimAD's superior performance compared to state-of-theart methods, achieving relative improvements of 19.85% on F1, 4.44% on Aff-F1, 77.79% on NAff-F1, and 9.69% on AUC on six multivariate datasets.Code and pre-trained models are available at https://github.com/EmorZz1G/SimAD.</p>
<p>I. INTRODUCTION</p>
<p>Time series anomaly detection (TSAD) is a critical component of time series analysis, focused on accurately detecting abnormal patterns in time series data and identifying their specific locations [1,2].TSAD methods utilize time series data to identify anomalies in web traffic, which play a vital role in ensuring the stability, security, and efficient functioning of web services [3].Unsupervised methods have garnered considerable attention in academic research, particularly for addressing this challenge through reconstruction-based approaches [4,5,6,7,8].These methods assume that models are perfectly trained on normal data and assign higher anomaly scores to anomalous data during the testing phase.However, these methods have shown insufficient performance in practical applications.A thorough review of existing research [9,10,11,12], coupled with comprehensive experiments (detailed in our analyses), has enabled us to identify several critical challenges in the field of time series anomaly detection:</p>
<p>• Challenge 1: Many methods rely on the reconstruction assumption, which is inadequate for enhancing the detection performance and may not always hold true [13,9].Our experiments, including both sensitivity and ablation analyses, validate this limitation.• Challenge 2: Failure to adequately utilize extended time windows: The complexity of the attention mechanism has constrained previous methods, capping the window length at 200 or fewer [13,14].This limitation, in turn, prevents the capture of more informative data.• Challenge 3: Limited expressive power hinders the representation of normal features.On one hand, certain methods fail to effectively model either normal or abnormal data, or both.On the other hand, most models are constrained by a limited number of parameters, which restricts their expressive capacity.</p>
<p>To address the above challenges, we propose a Simple dissimilarity-based approach for time series Anomaly Detection method, referred to as SimAD, in both univariate and multivariate settings.Specifically, to tackle Challenge 2, we design a feature extractor that can process longer time windows by splitting the sequence into multiple patches.This strategy enables SimAD to learn extended temporal receptive fields while using fewer parameters.To address Challenges 1 and 3, we design the EmbedPatch encoder and incorporate an enhanced attention mechanism for layer-wise modeling of dissimilarities between normal and abnormal data features.Thus, the EmbedPatch encoder can learn discriminative representations of normal data more effectively.Essentially, the proposed EmbedPatch encoder is a prototype, using V vectors to store prototypical features of normal data.The key differences between the EmbedPatch encoder and traditional prototypes can be highlighted in two aspects: 1) Prototypes typically use the last layer to preserve features, while the EmbedPatch encoder, acting as the value matrices for the attention mechanism, not only preserves features at different layers but also serves as a querying arXiv:2405.11238v2[cs.LG] 15 Jul 2025 repository for each level; 2) In traditional prototypes, query results are obtained by calculating the similarity between prototypes and features.In contrast, the EmbedPatch encoder generates query results by interacting the attention scores with the value matrices.With the EmbedPatch encoder, each layer of attention mechanism incorporates a series of embedded patches to learn features of that specific layer, giving it a stronger capability to learn richer and more distinctive representations, which are beneficial to performance improvement of anomaly detection.Finally, we introduce the ContrastFusion module to amplify the divergence of normal and abnormal data's distributions for further accentuating their dissimilarity.</p>
<p>Furthermore, we have analyzed the shortcomings of existing evaluation metrics, including inflated metrics, low discriminative power, and insufficient semantic relevance.These issues have contributed to false perceptions of progress in TSAD [15,16,17].To enable a fair comparison of performance, we propose two improved evaluation metrics: Unbiased Affiliation (UAff) and Normalized Affiliation (NAff).These metrics are designed to address the limitations of existing metrics by providing better distinctiveness and semantics.We have conducted analyses from both theoretical and experimental perspectives to establish the reliability of the newly proposed metrics.As demonstrated via extensive experiments, the proposed approach outperforms the state-of-the-art (SOTA) methods in time series anomaly detection.</p>
<p>In summary, our paper makes the following contributions: 1) We propose SimAD, a simple yet effective algorithm designed for time series anomaly detection that can handle extended time windows.SimAD is a straightforward framework based on dissimilarity measures, and its effectiveness has been validated through comprehensive evaluations from multiple perspectives.2) We introduce two improved TSAD evaluation metrics,</p>
<p>UAff and NAff, which address challenges such as inaccurate assessments and lack of semantic clarity.The reliability of the proposed metrics is demonstrated through theoretical and experimental analyses.Furthermore, a comprehensive evaluation of the issues, limitations, and strengths of existing metrics is conducted.3) Our algorithm outperforms significantly SOTA methods on real-world datasets, excelling in point-level evaluations such as F1 and AUC, as well as sequence-level evaluations like Aff, UAff and NAff (See Fig. 3).Moreover, we have released both our code and pre-trained models.</p>
<p>II. RELATED WORK</p>
<p>Unsupervised learning methods [4,18] have garnered considerable attention due to the scarcity of labeled data for anomaly detection in time series sequences [1,19,13,20,9,21].In past studies, anomaly detection algorithms have become one of the key data analysis tools and are widely used in fields like remote sensing and imaging [22,23,24,25].These methods can be categorized as follows (detailed discussion in Appendix A): (1) Algorithms based on classical machine learning [26,27,28] transform traditional machine learning approaches into deep networks, enhancing their ability to handle complex data.(2) Reconstruction-based approaches [19,14,29] involve training models using normal data and leveraging reconstruction error as an anomaly score, attributing higher scores to anomalous data during testing.(3) Prediction-based techniques, as demonstrated in [30], learn from historical data to predict future observations, considering prediction errors as the foundation for anomaly detection.(4) Generative adversarial learning based methods [31,32,33] utilize generative models to learn the distribution of normal data and a discriminator network to detect anomalies.</p>
<p>Recently, some innovative algorithms have emerged in the field of anomaly detection, including: (1) Transformer-based approaches [13,34,21] leverage the power of Transformer, which has shown exceptional success in natural language processing tasks, and are increasingly being applied to anomaly detection.</p>
<p>(2) Contrastive learning-based methods [35,36,20,37,38] utilize contrastive learning to obtain robust representations, specifically tailored for anomaly detection.(3) Diffusion-based methods [39,40] model the propagation of anomalies in complex networks and time series sequences by using the diffusion process.(4) Large Language Models (LLMs) [41] exploit cutting-edge models, like GPT-2, adapted specifically for anomaly detection tasks, capitalizing on the sophisticated architectures and knowledge representation capabilities.These algorithms can be considered extensions or variations of the above categories, which incorporate advanced network structures and knowledge representation methods to enhance anomaly detection performance.However, existing methods have not effectively addressed the above three challenges.Most methods are constrained by a limited number of learnable parameters, which hinders them from capturing long-term dependencies in data.Moreover, some reconstruction-based methods solely focus on the task of reconstruction.The differences between our dissimilarity-based approach and Contrastive learning-based methods are in the framework (EmbedPatch &amp; ContrastFusion), motivation (dissimilarity of perspectives [42]), and implementation, as discussed in Appendix I.</p>
<p>III. PROPOSED APPROACH</p>
<p>A. Framework of SimAD 1) Overview: In Fig. 2(a), SimAD comprises a Feature Extractor, EmbedPatch Encoder, and ContrastFusion module.In the context of temporal anomaly detection, the original time series data is denoted as X ∈ R T ×C , where T denotes the length of time series and C the number of channels.The goal of this task is to predict the label y ∈ R T for X, where y i = 1 indicates an anomaly at the i-th time point and y i = 0 otherwise.The input data X is first processed by the Feature Extractor to generate patch tokens N. Next, at each layer of the EmbedPatch Encoder, the attention mechanism combines the patch tokens from the previous layer with the current tokens to capture their interdependencies.We then utilize a linear layer to reconstruct the original features and compute anomaly scores.Finally, we design the ContrastFusion module to strengthen the distinction between normal and abnormal data distributions, thereby enhancing overall detection performance.</p>
<p>2) Feature Extractor: To extract unified sequence-level temporal features, we devised a patch-based feature extractor, which allows SimAD to process longer time windows and capture richer semantic information.Specifically, X is first fed to the feature extractor.To address distribution shifts [43,44], we introduce Instance Normalization (IN) [43].The improved Positional Embedding (PE) is then used to incorporate temporal positional encoding, enabling SimAD to learn the relationships between C channels actively.The improved positional encoding (PE) applies sinusoidal positional encoding solely to the temporal positions, in contrast to the original PE [45], without the necessity of encoding the channel indices.This distinction arises from the differing implications of the channels in time series and the word embeddings in the language model.</p>
<p>Then, for C channels, the temporal sequence is processed through two operations via Patching(•).First, the original input
X ∈ R T ×C is segmented into M patches of length P , resulting in an intermediate representation N ′ ∈ R M ×P ×C , where T = M ×P . Next, N ′ is reshaped to obtain N ′ ∈ R M ×(P •C) .
In this paper, we use the superscript "′" to denote intermediate process variables, such as N ′ .Finally, Value Embedding (VE) is a simple linear transformation that maps all patches into a unified
D-dimensional space, specifically N ∈ R M ×D . It is defined as N = VE(N ′ ) = LayerNorm (Linear (LayerNorm (N ′ ))).
Here, D is a predefined and represents the final dimension of the model.The term LayerNorm refers to layer normalization [45], which has been shown to be more suitable for sequential data.The term Linear refers to linear layer.The processing performed by the Feature Extractor can be described as below:
X ′ = PE(IN(X)), N = VE(Patching(X ′ )),(1)
where N refers to the naive representation and the original input of EmbedPatch Encoder.With the designed feature extractor that maintains the framework's simplicity, SimAD can handle data with longer time windows, whose necessity will be demonstrated by in Section IV-C.</p>
<p>3) EmbedPatch Encoder: To enhance SimAD's capability of modeling the dissimilarity between normal and abnormal samples, we made an improvement to the original attention mechanism.Inspired by [9,11,12], this improvement involves incorporating the EmbedPatch E (i) ∈ R V ×D with embedded queries into the EmbedPatch Encoder backbone of SimAD, where V denotes the number of patch embeddings (Embed-Patch) and (i) for i-th layer of encoder.Determining a proper V often requires prior and a larger number of embeddings to accommodate different scenarios [46].Therefore, a linear projection is stacked on EmbedPatch to obtain E (i),′ ∈ R M * ×D for reducing the dimensionality, where M * ≪ V .Here, M * represents the number of embeddings.It equals M from the Feature Extractor (M * = M ), but they serve different purposes in the context.Embedding (EmbedPatch) is learnable, whereas naive representation refers to the raw, high-dimensional features extracted directly from the original time series.Intuitively, each of the M patches finds a corresponding embedding from the V patch embeddings, resulting in M * new embeddings for the original patches.This simple component allows SimAD to efficiently learn key information from normal samples without being overly dependent on prior knowledge.</p>
<p>To achieve this, we employ an improved multi-head attention.For each head k ∈ [1, 2, . . ., U ], we define the query matrix as
Q (i) k = N (i) W Q k , the key matrix as K (i) k = N (i) W K k
, and the value matrix as
V (i) k = E (i),′ k = W V k E (i) k , where W Q k , W K k ∈ R D×d , W V k ∈ R M * ×V ,E (i) = [E (i) 1 , E (i) 2 , . . . , E (i) U ], E(i)
k ∈ R V ×d , and d is defined as D U , which represents the dimension of the head.For the first layer of the EmbedPatch Encoder, its input N (1) is the output N from the Feature Extractor.Next, we define the attention calculation between different patches in each layer as below:
Z (i) k = Attention Q (i) k , K (i) k , V (i) k = Softmax (Q (i) k K (i)⊤ k √ d V (i) k .(2)
Note that the
Q (i) k and K (i)
k here are generated by different parameters, so the attention scores are asymmetric.On the top of each layer, we utilize a linear layer to aggregate features Z (i) k from different heads, resulting in Z (i) ∈ R M ×D .Specifically, we first concatenate the features from U heads along the last dimension.For each
Z (i) k ∈ R M ×d , the concatenation yields Z (i),′ (∈ R M ×D ) = Z (i) 1 , . . . , Z(i)
U .Subsequently, this concatenated feature is aggregated via a linear layer Linear, resulting in
Z (i) = Linear(Z (i),′ ).
Subsequently, we proceed with the original "Add &amp; Norm" operation to generate the input, N (i+1) , for the next layer:
N (i)′ = LayerNorm( N (i) + Z (i) ), N (i+1) = LayerNorm( N (i)′ + FFN(N (i)′ ) ),(3)
where FFN(•) denotes a 2-layer feed-forward network (FFN), as in [45], the superscript N ′ to denote intermediate variables, and the subscript (i) to indicate features at different layers.Finally, a linear layer is used to restore X from the last layer.As shown in Fig. 2(a), the final output of the EmbedPatch Encoder is processed by a linear layer, which can be expressed as X = Linear(N (−1) ).Here, N (−1) represents the features from the last layer of the encoder.</p>
<p>To enable the model to detect anomalies in long-context time series, we need to optimize the parameters of SimAD's Feature Extractor and EmbedPatch Encoder.During the training phase, the Mean Square Error (MSE) [13,19] is used to measure the difference between X and X, and a patch-based similarity loss is employed to ensure continuity between patches.The MSE term ensures that the model reconstructs the time series accurately locally.However, this point-to-point reconstruction alone cannot guide the model to detect anomalies over long time windows.The similarity term addresses this limitation.It first converts X into N ∈ R M ×(P •C) using the previous Patching operation.Then, it calculates patch-based similarity along the last dimension.The final training loss is given by Eq. ( 4).</p>
<p>During the testing phase, SimAD utilizes L rec to calculate anomaly scores and detect anomalies.
L rec = MSE( X, X) + (1 − Similarity( X, X)),(4)
where cosine similarity is adopted as a similarity measure.</p>
<p>4) ContrastFusion Module:</p>
<p>Although the EmbedPatch Encoder enables SimAD to memorize normal samples, it does not substantially enhance the discrimination between normal and abnormal data.To mitigate this limitation, the ContrastFusion module is designed to employ contrastive learning to enlarge the feature distance between normal and abnormal data' features.</p>
<p>To generate negative samples for contrastive learning without introducing prior, we adopt the simplest method by using Gaussian noise [9,1].Specifically, we use the equation X − = X+α•J, where J is sampled from a Gaussian distribution, and α controls the level of noise.This is a common time series data augmentation method [9,1].From then on, we use variables with subscript "−" to represent negative samples or features.Inspired by denoising autoencoders [47], we incorporate a denoising loss into the final objective function.Similarly, to guide the model to focus on contextual temporal associations during denoising, we added an extra similarity term.
L denoise = MSE( X− , X + ) + (1 − Similarity( X− , X + ) ).
(5) X + indicates the branch opposite to the negative sample X − , emphasizing their opposition and being differentiated by colors/symbols in Fig. 2(a) for convenience and consistency.Keep in mind that X + = X in this case.The two branches of ContrastFusion, which are optimized without regard to reconstruction, share structural similarities with previous image self-supervised techniques such as SimCLR [48] and SimSiam [49].Therefore, our methodology can also be considered a self-supervised (and/or unsupervised [4]) learning strategy.</p>
<p>To learn invariant features, we feed positive samples X + and negative samples X − into the Feature Extractor and Embed-Patch Encoder, resulting in the acquisition of representations N + and N − .Previous self-supervised works [48,49,10,1] have shown that constructing different views through data augmentation can guide models to learn invariant features.For this purpose, we utilize a projection head P(•), akin to prior contrastive learning methods, to facilitate the acquisition of meaningful and discriminative representations.
H + = P(N + ) = Linear(ReLU(Linear(N + ))),(6)
where ReLU is the activation function.We derive lowdimensional representations H + and H − for N + and N − respectively.To design an asymmetric feature contrastive loss, we utilize gradient stopping.
Lcont = MSE(H + , StopGrad(H − )) + (1 − Similarity(H + , StopGrad(H − ))) + MSE(H − , StopGrad(H + )) + (1 − Similarity(H − , StopGrad(H + ))).(7)
5) Joint optimization for Training: As described above, SimAD aims to optimize the reconstruction of positive samples, denoise noisy samples, and amplify the feature differences between positive and negative samples (see in Fig. 2(b)).During the initial stages of training, the model focuses primarily on reconstruction and denoising.Since the contrastive loss may introduce additional training complexity, the weight of contrastive loss incrementally rises in the initial N warm-up iterations until it reaches the maximum value of β max :
β i = min{ i+1 Nwarm−up , β max }.
The overall objective function combines the reconstruction loss, denoising loss, and contrastive loss, as below:
L = L rec + L denoise − βL cont .(8)
Algorithm 1 shows the training workflow of SimAD, highlighting the simplicity of our method in design and implementation.
L score = MSE( X, X) + (1 − Similarity( X, X)). (9)
Note that the first term (MSE) has a length of T time points, while the second term (similarity) has a length of M patches.To match the length, each patch in the similarity term is replicated P times to reach T time points in the implementation.</p>
<p>As shown in Fig. 2(c), this process involves inputting time series data into SimAD and performing feature extraction and representation to obtain the final feature Z (L) .This feature is then fed into a linear layer to reconstruct the data as closely as possible to the original: X = Linear(Z (L) ).We then compute the MSE and cosine similarity between the reconstructed and original data.In inference stage, the ContrastFusion module is not used, eliminating the need to generate negative samples or compute similarities between positive and negative samples.</p>
<p>C. Improving Affiliation Metrics</p>
<p>Recent studies [15,16,17] have highlighted the limitations of conventional metrics used in time series anomaly detection.The affiliation metric [50] is a parameter-free method that has shown promising performance.However, based on experiments and theoretical analysis (see Appendix C), the Affiliation precision (Aff-Pre) tends to approach 0.5, while the Affiliation recall (Aff-Rec) tends to approach 0.99 when confronting with random anomaly scores.This leads to an Affiliation F1 score (Aff-F1) of approximately 0.7, suggesting that the metric's discriminatory capability is insufficient.To address this limitation, we introduce Unbiased Affiliation (UAff) and Normalized Affiliation (NAff) metrics.Both of them exhibit superior discriminatory ability and provide a more accurate reflection of an algorithm's performance.</p>
<p>Experimental findings (Table I) indicate that the Affiliation precision (Aff-Pre) varies across different datasets but consistently tends to approach 0.5, which can be interpreted as a dataset-specific bias, denoted by Aff-Pre bias .Meanwhile, it is noteworthy that there has been insufficient encouragement for high-precision models, while the penalties for low-precision models are inadequate.In this context, we design Unbiased Affiliation precision (UAff-Pre) and Unbiased Affiliation F1 (UAff-F1), both of which can alleviate the dataset-specific bias and offer a more equitable assessment of the algorithm's precision performance.</p>
<p>UAff-Pre =</p>
<p>Aff-Pre − Aff-Pre bias 1 − Aff-Pre bias (10)
UAff-F1 = 2 • |UAff-Pre| • Aff-Rec |UAff-Pre| + Aff-Rec • (−1) |UAff-Pre&lt;0| . (11)
where UAff-F1 is negative when UAff-Pre &lt; 0. Although UAff-Pre denotes an improvement over its original version and surpasses UAff-F1, it does introduce additional parameters, thereby deviating from its parameter-free nature.Since the majority of real-world datasets exhibit Aff-Pre bias ≤ 0.55, we further propose a modified version of NAff metrics.The computation follows a similar process, with the exception that we set Aff-Pre bias = β for constant while maintaining other aspects unchanged.In other words, NAff-Pre can be calculated as Aff-Pre−β 1−β , and NAff-F1 is calculated similarly to UAff-F1.The mathematical and experimental analyses of the metrics are in the Sec.C.</p>
<p>IV. EXPERIMENTS</p>
<p>We evaluate the effectiveness of our proposed SimAD by conducting extensive comparison experiments against stateof-the-art competing methods on six real-world multivariable datasets: MSL, SMAP, PSM, SWaT, WADI, and Swan.Additionally, we utilize a univariate dataset UCR [51].The details of the above six multivariable datasets are in Table I.</p>
<p>We employ the F1 without point adjustment, Aff-F1, and the improved UAff-F1 and NAff-F1 for performance evaluation.We exclude the point-adjusted F1 score due to its acknowledged potential for false improvements.It is noted that although the classical F1 score is not optimal for time series data, it can still be employed for evaluation purposes [15], as detailed in Appendix D-A.Furthermore, we present an analysis of VUS [52] scores (Table X in Appendix) for all the datasets.In TSAD, the F1 score evaluates model performance by balancing precision (Prec) and recall (Rec).It is defined as:
Prec = TP TP + FP , Rec = TP TP + FN , F1 = 2 × Prec × Rec Prec + Rec . (12)
Here, TP, FP, and FN represent true positives, false positives, and false negatives.The F1 score ranges from 0 to 1, with higher values indicating better anomaly detection performance.Due to space limitations and the need for conciseness, the calculation of Aff-F1 and VUS refer to the original papers [50,52].</p>
<p>We extensively discuss UAff and NAff in Sec.C, comparing them with other metrics, and summarize the limitations and advantages of existing metrics in detail.</p>
<p>A. Baselines</p>
<p>Our model is compared against 20 baselines, which include machine learning-based models like LOF, Isolation Forest (IForest) and PCA; deep learning-enhanced models like Deep SVDD [26] and Deep Isolation Forest (Deep IF) [27]; reconstructionbased models like USAD [19], TCN-ED [14], AdaMemBLS [1] and NPSR [53]; prediction-based methods like TimesNet [30], and M2N2 [54]; Transformer-based models such as Anomaly Transformer (AnomTrans) [13] and TranAD [21]; contrastive learning-based models like COUTA [35], NCAD [36], and DCdetector [20]; diffusion-based model D3R [39]; and LLMbased GPT2-Adapter [41].</p>
<p>B. Quantified Comparisons</p>
<p>Table II shows comparison results between our proposed SimAD and baselines on six real-world datasets.It is obvious that SimAD performs superior to other models, particularly on datasets SWaT, WADI, and Swan.Specifically, compared to the best baseline on each dataset, SimAD exhibits an improvements of 5.15% (76.88%→82.03%),13.31% (50.67%→63.98%),and 15.24% (55.99%→71.23%) in F1 score.In contrast, the NAff-F1 score exhibits absolute improvements of 11.09% (55.73%→66.82%),30.87% (45.39%→76.26%),and 19.05% (33.99%→53.04%)respectively.In addition, SimAD has shown slight superiority over other models on datasets MSL and SMAP.On these datasets, SimAD achieved an absolute improvement of 1.26% and 1.00% in Aff-F1, respectively, along with higher scores in other metrics as well.</p>
<p>Table III summarizes the evaluation metric scores of models across all datasets, clearly indicating that SimAD achieved an improvements of 9.07% on F1, 3.18% on Aff-F1, 16.63% on UAff-F1, and 20.55% on NAff-F1, and 6.83% AUC, compared to the SOTA baseline.In contrast, although models such as TimesNet and D3R exhibit good performance on specific evaluation metrics (UAff-F1, Aff-F1), their performances on other metrics (Aff-F1, NAff-F1) are inferior to those of SimAD, and even lower than those of random algorithms.Fig. 3 shows the advantages of our model, compared to other baseline models across multiple evaluation metrics.This further confirms the superior generalization capability of SimAD, whereas other algorithms may display larger performance fluctuations due to an excessive focus on specific dataset characteristics.(See a more detailed comparison in Appendix E-D.) Additionally, we evaluate the effectiveness of our model in handling univariate dataset UCR in Table IV, which includes Avg.+ (calculated using only positive values) and Avg.scores.From this table, SimAD demonstrates superior performance.Specifically, SimAD achieves an improvement of 13.33% (1.66% → 14.99%) in Avg.+ F1 and 13.38% (1.61%→14.99%) in Avg.F1, compared to the best baseline.Furthermore, SimAD achieves an improvement of 25.75% (9.41%→35.16%) in Avg.+ UAff-F1 and 17.52% (2.01%→19.53%) in Avg.UAff-F1, compared to the best baseline.</p>
<p>C. Sensitivity Analysis</p>
<p>We performed sensitivity analysis on hyperparameters of SimAD, which include the window size and the number of patch embeddings.Fig. 4 illustrates the influence of different window sizes on the model's performance on the WADI dataset.As the window size increases, the model's loss exhibits a decreasing trend, and its accuracy consistently improves.A larger window size incorporates more temporal and contextual information, enabling the model to capture patterns and trends and improve the detection performance.It is worth noting that when the window size increases from 1024 to 2048, the model's loss further decreases while the improvement in the     F1 score is limited.This suggests that larger window sizes also increase the optimization difficulty.patch embedding is set to 0 (i.e., the original attention mechanism), the model's performance is significantly lower.This demonstrates the effectiveness of EmbedPatch in enhancing the memory of normal samples.As the number of patch embedding increases, both the model's Rec Loss and F1 Score exhibit fluctuating changes.It can be inferred that the model achieves the optimal performance when the number of patch embedding is between 100 and 200.From Fig. 5(b-d), it is evident that increasing the number of layers and setting an appropriate level of noise and dimension of features can result in improved model performance on the WADI dataset.However, a notable decline in performance is observed when the dimension is set to 128.This indicates that models with smaller dimensions face challenges in learning complex features.
Methods F1 AUC Aff-Pre Aff-Rec Aff-F1 UAff-F1 NAff-F1 F1 AUC Aff-Pre Aff-Rec Aff-F1 UAff-F1 NAff-F1 F1 AUC Aff-Pre Aff-Rec Aff-F1 UAff-F1 NAff-F1RandomDatasets MSL SMAP SWaT Variations F1 Aff-Pre Aff-Rec Aff-F1 UAff-F1 NAff-F1 F1 Aff-Pre Aff-Rec Aff-F1 UAff-F1 NAff-F1 F1 Aff-Pre Aff-Rec Aff-F1 UAff-F1 NAff-F1 w/o</p>
<p>D. Ablation Analysis</p>
<p>To validate the effectiveness of our model, we conducted ablation studies on ContrastFusion, data augmentation, Embed-Patch, and asymmetric optimization in Fig. 6.Here we provide the descriptions about the model's variants:</p>
<ol>
<li>
<p>w/o Contrastive (Cont.):indicates the removal of contrastive learning in the ContrastFusion.By removing this, L cont (Eq.( 7)) no longer works, and the similarity relationships between positive and negative samples will not be learned.</p>
</li>
<li>
<p>w/o Aug: signifies negative sample generation without denoising learning, where L denoise (Eq.( 5)) does not work.It is noteworthy that despite generating negative samples, it is still possible to conduct contrastive learning between positive and negative samples, i.e., L cont (Eq.( 7)) remains active.</p>
</li>
<li>
<p>w/o Embeder: when the Embeder, i.e., E, is removed, the architecture of SimAD regresses to a Transformer.Originally, the value matrix in SimAD was V = W V E. After regressing to a Transformer, the generation of V aligns with matrices Q and K, i.e., V = NW V .For simplicity, W V represents learnable parameters, and N is the pre-input.When EmbedPatch is removed, SimAD's backbone reverts to a Transformer, where self-attention is uniform across Q, K, and V.</p>
</li>
<li>
<p>w/o Asymmetric (Asym.):our asymmetric optimization relies on gradient stop.Removing the asymmetric optimization eliminates the StopGrad from the equation.As both MSE and Similarity losses are symmetric, after removing this operation, Eq. ( 7) regresses to a symmetric optimization method.</p>
</li>
<li>
<p>w/o Cos: indicates the removal the cosine terms from Eq. ( 4), (5), and (7) while keeping the MSE loss.</p>
</li>
</ol>
<p>The detailed ablation studies are in Table V The comprehensive results of ablation studies, along with the setting of the experiment, are in Table V.</p>
<p>To verify the effectiveness of the EmbedPatch encoder and ContrastFusion modules in our proposed SimAD framework for addressing the first Challenge outlined in the introduction, i.e., enhancing the dissimilarity between features of both normal and abnormal data, we extracted feature representations before and after the ContrastFusion projection head.Next, we conducted a multi-sampling to calculate the KL divergence between normal and abnormal features at both stages.The results are in Table VI.From this table, it can be observed that removing the ContrastFusion module (w/o Cont.) leads to an increase in KL divergence between the feature distributions of normal and abnormal data on the SWaT and WADI datasets, indicating that the representations become more distinct.Moreover, when both components are integrated into our model, the separation between normal and abnormal feature distributions is maximized.This demonstrates that SimAD effectively overcomes the limitations of previous approaches.</p>
<p>Moreover, Fig. 7 provides an illustration of the training on dataset PSM.It is evident that the w/o Embedder module achieves the lowest loss but with the lowest F1 score.This</p>
<p>E. Visualization Analysis 1) Real-world cases analysis:</p>
<p>The performance of SimAD on dataset SWaT is in Fig. 8a and Fig. 10 (in Appendix E-B).The first row of images showcases the original data and the ground truth labels.Its y-axis represents the magnitude of the first channel in the time series.The second row of images denotes the predicted results, which effectively detects most anomalies by assigning significantly higher scores to abnormal data.The y-axis represents the magnitude of the anomaly score.The third and fourth rows of images illustrate the results obtained using L2 loss and patch-based cosine similarity loss as anomaly scores respectively.</p>
<p>It is noticed that the former focuses more on short-duration anomalies, while the latter can capture long-duration anomalies.</p>
<p>In Appendix E-B, Fig. 11 shows the detection results of Anom-Trans and NPSR.Our method exhibits superior performance compared to AnomTrans, as the latter only detects a few anomalies and encounters difficulties in accurately detecting segment anomalies.The case study highlights the effectiveness and rationale behind our anomaly score design.</p>
<p>2) Explanation of patch embedding: Fig. 8b shows the detection performance of SimAD, where the fourth row denotes the similarity between the query and the embedding of the last layer, while the vertical axes of the third and fourth regions illustrates correlations between the query embedding and the learned embedding of value matrices.In the third and the fourth regions of the right subfigure, the horizonal axis denotes the ordinal number of the embedding.The colors in the heatmap indicate the strength of these correlations, with precise values corresponding to the color bar for reference.Specifically, given a time window of 2048, we divide it into 64 non-overlapping patches, each with a length of 32.There are 64 learned embedding in the last layer of our EmbedPatch Encoder.In the following, we consider the 64 non-overlapping     patches from the input window as the query embedding.Correspondingly, the 64 learned embedding produced by the final layer of the EmbedPatch Encoder serves as the value matrices.Next, we compute the pairwise correlations between the 64 non-overlapping patches and 64 learned embedding representations, resulting into a attention feature map.This feature map is depicted in the fourth region of the right subfigure.In contrast, the third region of the right subfigure highlights the top five most relevant query embeddings, selected from the 64 patches (i.e., segments of the 2048-length time window), for each learned embedding.In the third region, patches that exhibit weak relevance to all embeddings are shown in black.Conversely, patches with stronger relevance to certain embeddings are displayed in vibrant colors, highlighting their higher correlations relative to other patches.It is important to note that the attention feature map denotes the correlations between the query (Q) vectors and the value (V) vectors in the last layer of the EmbedPatch Encoder, i.e., the relationships between the input patches from the time series and the learned embedding, rather than the correlations between the query (Q) vectors and the key (K) vectors.Combined with Fig. 12 in Appendix E-B, it can be observed that in the lower layers, the embedding establishes relationships with a majority of queries.However, only the normal data can establish relationships with EmbedPatch in the higher layers.This means that in the shallow layers, SimAD learns general representations.While in the higher layers, SimAD learns features associated with normal data, which results in less similarity between abnormal data and EmbedPatch.Consequently, the patch embeddings enhance the detection performance of SimAD.</p>
<p>V. CONCLUSION</p>
<p>This paper introduces a Simple dissimilarity-based approach for time series Anomaly Detection (SimAD).The proposed framework is distinguished by its simplicity and versatility, allowing for the use of longer time windows.Experimental results demonstrate the superiority of our method compared to existing approaches.Additionally, we present two improved evaluation metrics, UAff and NAff, which effectively assess the algorithm's performance and overcome many shortcomings of previous metrics.In future work, we plan to extend this detection scheme to various other scenarios and aim to develop a unified model for anomaly detection.</p>
<p>A. RELATED WORK</p>
<p>Unsupervised methods have garnered considerable attention due to the scarcity of labeled data for anomaly detection in time series sequences.These methods are particularly advantageous in scenarios where obtaining labeled data is expensive, timeconsuming, or impractical.The primary objective is to identify outliers or anomalies that deviate significantly from expected patterns without relying on prior annotations.Broadly, these methods can be categorized as follows:</p>
<p>(1) Algorithms based on classical machine learning, such as those proposed in [26,27], transform traditional machine learning techniques into deep neural network architectures.This transformation enhances their ability to handle complex and high-dimensional data, allowing for more nuanced feature extraction and representation learning.By integrating classical algorithms with deep learning, these methods can capture intricate patterns that signify anomalies more effectively than their purely classical counterparts.</p>
<p>(2) Reconstruction-based methods, exemplified by [19,14,29], primarily involve training models on normal data to learn how to reconstruct input time series.During testing, the reconstruction error is used as an anomaly score, with anomalous data typically yielding higher errors due to their deviation from learned normal patterns.This approach relies on the assumption that normal data can be accurately reconstructed, while anomalies will result in significant discrepancies.For instance, USAD [19] employs a dual-decoder network structure and utilizes two-stage training to enhance performance.In this architecture, one decoder reconstructs the input data to capture normal patterns, while the second decoder focuses on learning the residuals-discrepancies that occur during reconstruction.This dual-decoder approach enables the model to effectively differentiate between normal and anomalous instances by analyzing both reconstruction fidelity and residual errors, thereby improving anomaly detection accuracy.</p>
<p>(3) Prediction-based techniques, as demonstrated by [30], focus on learning from historical data to predict future observations.These models are trained to forecast the next time step or series of steps based on past values.The prediction errors-defined as the difference between predicted and actual values-serve as the basis for anomaly detection.This method effectively identifies anomalies that manifest as significant deviations from expected future behavior.For example, PatchTST [55] employs a single-scale patch-based MLP as its core architecture, whereas the work in [56] applies an MLP to capture frequency-domain information in time series data for predictive modeling.</p>
<p>(4) Generative adversarial learning approaches, such as those discussed in [31,32,33], employ a dual-network framework consisting of a generator and a discriminator.The generator learns to model the distribution of normal data, while the discriminator is tasked with distinguishing between normal instances and anomalies.This adversarial training process enhances the system's ability to detect subtle anomalies by leveraging the power of generative models to simulate normal data distributions.</p>
<p>In recent years, some innovative algorithms have emerged in the field of anomaly detection, including: (1) Transformer-based methods [13,34,21] harness the architecture of Transformers, which have shown exceptional performance in natural language processing tasks.These models apply self-attention mechanisms that allow them to weigh the importance of different parts of the input data, thus enabling them to capture temporal dependencies and contextual information crucial for identifying anomalies in time series data.</p>
<p>(2) Contrastive learning-based methods [35,36,20,37,38] focus on learning robust representations by contrasting positive and negative pairs.In the context of anomaly detection, these methods can effectively differentiate between normal and anomalous instances by learning to identify subtle differences in representation, thereby enhancing the model's sensitivity to anomalies.For example, COUTA [35] emphasized calibrating irregular noise and enhancing the significance of normal samples through uncertainty modeling, introducing a one-class loss based on prior distribution to improve prediction reliability.</p>
<p>(3) Diffusion-based approaches [39,40] utilize mathematical diffusion processes to model how anomalies propagate through complex networks and time series sequences.These techniques are particularly effective in scenarios where the relationships between data points are crucial, as they capture the dynamics of anomaly spread and enhance detection capabilities in interconnected systems.For example, D3R [39] addresses the instability of time series data in non-stationary environments, a common challenge that often leads to a high false positive rate.D3R employs a decomposition and reconstruction method to manage data drift, integrating a noise diffusion model that directly recovers contaminated data.This strategy mitigates the substantial retraining costs typically associated with changes in information bottlenecks, thereby improving overall detection reliability.</p>
<p>(4) Large Language Models (LLMs), such as those adapted for anomaly detection tasks [41], leverage advanced architectures like GPT-2.These models utilize their extensive capabilities in knowledge representation and context understanding to identify anomalies in time series data.By applying techniques from language modeling to time series analysis, LLMs can uncover complex patterns and detect outliers with high accuracy.Generally, the basic structure of these models is consistent with GPT-2.They use self-attention mechanism, feed-forward neural network, and layer normalization to learn sequential features.Their basic units are self-attention module and residual feedforward neural network, which are stacked multiple times to form the model's decoder.As a pure decoder model, it predicts the next token in an autoregressive way, so an encoder isn't needed.GPT-Adapter [41] just fine-tunes the parameters of the feed-forward neural network and layer normalization.It uses only some of the pre-trained GPT model's parameters to transform text token prediction into time series prediction and assess anomalies based on prediction loss.</p>
<p>B. DETAILED EXPERIMENTAL SETTINGS</p>
<p>We utilize official or open-source baselines that have been published on GitHub.These baselines can be downloaded by following:</p>
<p>B. Implementation details</p>
<p>In our default configuration, we set the length of the sliding window to 2048.The patch size is 32.The model is configured with a hidden dimension of 512, 8 attention heads, and 8 layers.We utilize 1000 embedding features.For all methods, we use the optimal F1 search strategy.The training process employs the AdamW optimizer with a batch size 256 and a learning rate of 10 −3 .We also utilize cosine learning rate scheduling.</p>
<p>The training is conducted over 20 epochs, with each epoch randomly sampling 500 samples.Our algorithm is implemented in Python using PyTorch.All experiments were performed on an NVIDIA A800 (80GB) GPU.</p>
<p>To emphasize the engineering implementation details of the algorithm, we explain the key components in model construction.This section can be directly cross-referenced with the documentation and code comments in our repository.Positional Embedding: We use cosine-based positional encoding for temporal positions but do not encode channel position information.The Instance Normalization layer follows the original author's implementation without modifications.EmbedPatch Encoder: Each layer contains two transformation matrices, Q and K, implemented using PyTorch's Linear layer with tensor reshaping for multi-head attention.The value matrix V for feature embedding uses PyTorch's native Embedding layer combined with Linear for feature selection.Reconstruction Layer: The final layer of SimAD uses a linear transformation to reconstruct features into the original time-series data, recovering all channels of every patch.ContrastFusion Projection Head: A two-layer feedforward network (FFN) consisting of Linear → ReLU → Linear is used.Note that low-dimensional features for each patch must be derived concurrently.Anomaly Score Construction: During inference, ensure alignment between the two loss terms.We use linear interpolation to match the length of the cosine similarity score to the MSE score.</p>
<p>C. Complexity Analysis</p>
<p>Assume that batch size is denoted by B, time series length T , channels C, and patch length P , the number of patches is M = T P , the shape of the input can be denoted as (B, M, P × C).With hidden dimension D, the intermediate feature shape is (B, M, D).At this point, the computational bottleneck lies in the Transformer's self-attention and FFN.The complexity of self-attention is quadratic concerning the sequence length, with a computational complexity of
(B • M 2 • D), while the FFN complexity is (B • M • D 2 ). The overall computational complexity of the model is B • (M 2 • D + M • D 2 ).
When the number of patches is greater than the model dimension, this complexity can be approximated as (B • M 2 • D).At this point, the length of the time series affects the computational efficiency, leading to slower model performance.</p>
<p>C. ANALYSES OF UAFF AND NAFF METRICS</p>
<p>To demonstrate the reliability of the proposed UAff and NAff metrics both theoretically and practically, we analyze their mathematical properties and practical performance.</p>
<p>A. Mathematical analysis of metrics</p>
<p>1) Range analysis: Since NAff is a specific case of UAff, we begin by analyzing UAff.To keep it brevity, we use the following abbreviations: uaf for UAff-F1, uap for UAff-Pre, ap for Aff-Pre, ar for Aff-Rec, and ap b for Aff-Pre bias .</p>
<p>Thus, we have uap = .It is theoretically confirmed that both ap and ap b fall within the range of [0, 1].The partial derivatives of uap with respect to ap and ap b can be given by:
∂uap ∂ap = 1 1 − ap b ≥ 0 (13) ∂uap ∂ap b = ap − 1 (1 − ap b ) 2 ≤ 0(14)
From the above formulas, it can be seen that uap increases monotonically with ap and decreases monotonically with ap b .When ap = 1, uap reaches its maximum value of 1.In the case where ap = 0 and ap b = 1, uap approaches a minimum value of −∞.As concluded in [50], ap b = 1 is applicable only when all the data are anomalies.However, the proportion of anomalies in most datasets is typically below 0.5.Hence, it follows that ap b &lt; 1 2 + 1 2 ×0.5 2 = 0.6125.Furthermore, the minimum value of ap b tends to approach 0.5.Given that ap b is derived from simulated calculations, we propose a more lenient condition of ap b &gt; 0.4.In practical scenarios, the range for ap b becomes broader, specifically ap b ∈ (0.4, 0.6125).From Eq.( 14), in the case where ap = 0 and ap b → 0.6125, uap tends towards 0−0.6125 1−0.6125 = −1.587.Therefore, it can be concluded that uap falls within the range of (−1.587, 1].</p>
<p>Next, let us proceed with the analysis of uaf next.Given that ar falls within the range of [0, 1], as indicated by Eq. ( 11), it becomes evident that when uap is within the range of [0, 1], the maximum value of uaf is 1.In the case where ap b falls within the interval of (−1.587, 0), it becomes necessary to determine the minimum value of uaf.This problem can be reformulated as the search for the corresponding ap b within the range of (0, 1.587) that yield the maximum uaf.</p>
<p>The minimum value of uaf can be obtained by computing − 2×1.587×1</p>
<p>1.587+1 = −1.227.Consequently, the range of UAff-F1 is (−1.227,1].Based on the above analysis, it can be concluded that the range of NAff-F1 is [−1, 1] since it is a specific case of UAff-F1.</p>
<p>2) Distinctiveness of metrics: It can be briefly analyzed that UAff provides greater discrimination than the original Aff.The design intention is to ensure that the ratio of UAff to Aff, uap ap , is always greater than 1 or less than 1 in the case of equal Aff-Pre.In this case, the ratio depends solely on Aff-Pre.Therefore, the problem can be reformulated as proving: with respect to ap, we obtain:
∂D ∂ap = ap b (1 − ap) 1 − ap b ≥ 0. (15)
Hence, when ap = 1, D max = 1, indicating that D ≤ 1, which aligns with our objective.Based on results in Table III, it is evident that the random algorithm attains the 9th position in Aff-F1, whereas it only achieves the 19th and 15th positions in UAff-F1 and NAff-F1, respectively.This observation highlights that the enhanced metrics can provide a more precise evaluation of the algorithm's actual performance.The rankings strongly suggest that the UAff-F1 and NAff-F1 metrics offer a superior assessment, compared to the original Aff-F1.</p>
<p>B. Bias data of Affiliation precision</p>
<p>Table I presents various datasets' actual and ideal biases.The theoretical ideal bias is determined by assuming the presence of only one anomaly segment in the test data, considering the anomaly rate and theoretical analysis from [50].It is noted that the disparity between two biases falls within an acceptable range.In practical scenarios where obtaining the true bias is challenging, the UAff can still be computed by estimating the anomaly ratio and calculating the theoretical bias.
Bias ideal = 1 2 + 1 2 • (AnomalyRatio) 2(16)
As the occurrence ratio of anomalies is typically low in realworld scenarios, with most anomalies accounting for less than 10% of the data, theoretically, Bias ideal &lt; 0.505.Therefore, in practice, we set β = Aff-Pre Bias = 0.5 as the standard parameter for NAff.Despite the slight variation from the anomaly rates in publicly available datasets, it is important to note that in the case of real datasets such as Swan, the highest anomaly ratio is 32.6%, resulting in Bias ideal = 0.5531.This scenario is not uncommon, and even in such cases, setting β to 0.5 does not significantly impact the evaluation of different methods.Therefore, setting β = 0.5 in practice is deemed reasonable.Furthermore, setting β = 0.5 instead of 0.55 aligns better with real-world scenarios and human cognition, and is more consistent with the original design intent of our metrics.</p>
<p>C. Experimental analysis of UAff and NAff metrics</p>
<p>Our previous proof compared UAff and NAff with the original Aff, providing empirical and theoretical analyses in Appendix C. We drew inspiration from the ranking-based approach [52].To highlight the strengths and weaknesses of different metrics, we designed a new experiment.</p>
<p>Experiment Design: We assume a time series of length 1000 with AnomSeq anomaly segments, with a minimum length of MinLen and a maximum length of MaxLen.Using a Random algorithm, we generate uniformly distributed anomaly scores, and then create models with varying performance levels, such as M60, which correctly predicts 60% of normal and anomalous points.Correct anomaly predictions receive a higher anomaly score using a random value U , i.e., U * 0.1 + 0.9.Incorrect normal predictions as anomalies also receive higher scores.In other cases, the model outputs an anomaly score of 0. This experiment is repeated 20 times, and the average result is taken.</p>
<p>To investigate different scenarios, we designed three demos in Table VII.Demo1 denotes many anomalies with short intervals.Demo2 denotes a few anomalies with long intervals.Demo3 denotes a few anomalies with extremely long intervals.The score threshold is set to 95%.From the results in this table, we have the following observations:</p>
<p>1) NAff-F1 is better than Aff-F1: In Demo1 and Demo2, the Aff-F1 for the Random model are 63.50 and 66.45, which are misleading.Our NAff-F1 scores are 0.06 and 1.18, indicating that NAff-F1 is more robust and better at distinguishing random models.Besides, NAff-F1 has a wider value interval, enhancing its discriminative power.2) Weak model evaluation: For the M10 model, which performs worse than a random model, an effective metric should be able to distinguish it from random model.Metrics that achieve this include AUC, NAff-F1, R A R, and V ROC.However, the original Aff falls short, assigning a score of 59.38 to M10 in Demo1.</p>
<p>3) Scoring misleadingness: F1PA is a point-adjusted F1 score that can be misleading when the anomaly interval is long, as seen in Demo3.In such cases, even a random model can achieve a high score of 94.59.Our metrics provide meaningful differentiation, with scores of 19.01, -38.78, and 35.14 for Random, M10, and M60, respectively, distinguishing between these models clearly.4) Parameter selection: R A R requires selecting an interval length, which can lead to inaccurate evaluations when anomalies are short, as demonstrated in Demos 1 and 2. In Demo 1, the R A R scores for Random, M10, and M60 are all above 74, showing that the metric fails to distinguish between these models.This issue is mitigated with longer anomaly intervals, as seen in Demo 3, where M10 has a R A R score of 25.81, significantly lower than 50.In contrast, our metric does not require parameter selection and provides accurate evaluations across various scenarios.5) Weakness of point-based evaluation: F1, Acc, Pre, and Rec are point-based metrics that are easily influenced by threshold selection and strict label matching, resulting in suboptimal results, even for perfect models like M100.In contrast, event-based metrics are not affected.Based on these studies, we demonstrate the advantages of our metric over previous ones.We recommend using NAff-F1 and VUS PR in the future, and other VUS series metrics can also be used when the anomaly interval is long.Random1 predicts all timestamps as anomalies, while Ran-dom2 uniformly and randomly predicts anomalies.However, both algorithms achieve high point-adjustment F1 scores (F1PA), indicating that F1PA lacks robustness in this case.</p>
<p>D. INVESTIGATION OF EXISTING EVALUATION METRICS A. Flaws in previous metrics</p>
<p>The F1 score can exhibit this issue, as it is more suitable for evaluating shorter interval anomalies (such as the last).However, its results can still be informative and provide some reference when facing non-random predictions.</p>
<p>Pred1 is the top-performing model among the mentioned ones.However, its Aff-F1 score is lower than that of Random1.This is because the original Aff-F1 metric does not account for false predictions.However, the enhanced UAff-F1 metric provides a better basis for comparing the performance of Pred1 and Random1.Additionally, Pred1 outperforms Pred2, although the difference in their Aff-F1 scores is small and even lower than that of Random1.In this case, the UAff-F1 metric can provide a more effective comparison between the two models, yielding scores of 0.1818 and 0.0057 for Pred1 and Pred2, respectively, while assigning lower scores to Random1 and Random2.</p>
<p>Based on the above analysis, we can conclude that F1 can serve as a valuable reference metric for non-random algorithms.F1PA may result in false improvements, whereas Aff-F1 lacks sufficient discriminative power and provides inaccurate evaluations for random algorithms.Ultimately, we recommend using the enhanced UAff-F1 metric for a more accurate performance assessment.</p>
<p>B. Limitations &amp; Advantages of metrics</p>
<p>We referenced the study VUS [52] and analyzed the attributes of various metrics, focusing on discrimination and semantics as key evaluation criteria.It is important to note the following properties of existing evalutation metrics:</p>
<p>1) Non-Threshold: This indicates that the metric does not require the setting of a threshold.2) Sequence: This signifies that the metric can effectively evaluate sequential anomalies.</p>
<p>0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 1  Pred1 0 0 0 0 1 0 1 1 1 1 1 0 0 0 1 0 Pred1PA Fig. 9.A case of artificial data illustrating the shortcomings of different metrics.
1 0 1 0 1 0 1 1 1 1 1 0 1 0 1 0 Random2PA Random1 1 1 1 1 1 1 1 1 1 1 1 1 1</p>
<p>TABLE VIII THE PROPERTIES OF DIFFERENT METRICS. Metric/Property</p>
<p>Score Threshold Sequence-adapted Parameter-free Discrimination Semantics
ACC ✗ ✗ ✗ ✗ ✗ F1 ✗ ✗ ✗ ✗ ✗ F1PA ✗ ✓ ✗ ✗ ✗ AUC ✓ ✗ ✗ ✓ ✓ Aff-F1 ✓ ✓ ✓ ✗ ✓ UAff-F1 ✓ ✓ ✓ ✓ ✓ R A R ✓ ✓ ✗ ✓ ✓ R A P ✓ ✓ ✗ ✓ ✓ V ROC ✓ ✓ ✓ ✓ ✓ V PR ✓ ✓ ✓ ✓ ✓
3) Parameter-Free: This means the metric does not require additional parameters for its evaluation.4) Discrimination: This attribute reflects the metric's ability to differentiate between random, weak, and strong models.For example, our research found that the F1PA metric exhibits low discrimination, as even a random model could achieve a score of 94. 5) Semantics: This denotes that the metric is associated with human-understandable meaning.For instance, the AUC metric provides clear semantics for point anomalies or short anomalies.Similarly, the Aff metric offers semantic relatedness by indicating how closely the detected anomalies align with the actual anomaly range-a higher score suggests a closer match.These attributes are critical for evaluating the effectiveness of different metrics in anomaly detection.Table VIII summarizes the properties of the different metrics.</p>
<ol>
<li>Affs (including the metrics we proposed) are based on local affiliation, which enhances their ability to evaluate a model's early warning and post-alert performance.2. The VUS series of metrics are designed based on AUC, with a focus on evaluating a model's tendency towards anomalies and normal events.In contrast, our metrics and VUS represent two distinct approaches to evaluation.3.For a comprehensive comparison of other metrics, please see Appendix C-C.Below, we summarize the key conclusions:</li>
</ol>
<p>1) NAff-F1 has a better discriminative ability than Aff-F1, which was our initial design goal.2) ACC, F1PA, and Aff exhibit insufficient weak model evaluation capabilities and cannot effectively evaluate random models and weak models.3) Scoring misleadingness: F1PA has the strongest misleading score.4) Refer to the table above; some metrics require additional parameters.As Paparrizos et al. [52] suggests: "We observe that this change implies a larger variation for several threshold-based measures.Thus, the latter confirms the limitations and the non-robustness of threshold-based measures to the anomaly cardinality ratio."Thresholdbased metrics have certain limitations.5) Weakness of point-based evaluation: Previous research [60] has shown that current datasets may have unreasonable labels.When using point-based metrics, the weaknesses of the evaluation metrics are magnified.Strict label matching can lead to inaccurate evaluations.These observations highlight the complexity of real-world scenarios and the varied emphasis of different metrics.In the TSAD community, interval evaluation is currently deemed more crucial, which is why we prioritize Aff and VUS metrics.As the field of TSAD is diverse, no single evaluation metric is universally appropriate, and the choice of metric should be made carefully for each case [61].</p>
<p>In summary, it is currently recommended that "when publishing results in TSAD research, multiple metrics should be included, and both the code and the anomaly scores should be made available to facilitate easy comparison with any evaluation metric."[61] A more comprehensive and systematic investigation would require a broader research scope, which is beyond the focus of this paper.To contribute to the advancement of TSAD, we have made our model code, weights, and training and testing scripts available in order to reproduce results reported in our work.</p>
<p>E. DETAILED RESULTS OF EXPERIMENTS</p>
<p>Table IX presents the performance of three models, namely SimAD, AnomTrans, and DCdetector, on the UCR dataset.Considering the overall performance across all sub-datasets, it is evident that the SimAD model consistently achieves higher F1 scores compared to the baseline models.Additionally, the SimAD model for anomaly detection demonstrates the highest number of datasets with positive evaluation scores.By excluding datasets with negative evaluation scores, SimAD exhibits significantly higher composite scores for all evaluation metrics than the other baseline models.These findings indicate that SimAD can detect a wider range of anomalies.The specific results of the ablation experiments are presented in Table V.</p>
<p>A. Additional results of comparison</p>
<p>Since the VUS series evaluates anomaly detection models differently, we included four VUS metrics in the comparative
R A R R A P V ROC V PR R A R R A P V ROC V PR R A R R A P V ROC V PR R A R R A P V ROC V PR R A R R A P V ROC V PR R A R R A P V ROC V</p>
<p>B. Additional visualization analysis</p>
<p>Fig. 10 demonstrates the impact of different loss functions on the predicted results, threshold values, and anomaly scores.The figure shows that our model's performance is enhanced when both the L2 and cosine loss functions are employed, as compared to using either the L2 loss function alone or the cosine loss function alone.</p>
<p>Fig. 11 illustrates the actual detection performance of the AnomTrans and NPSR on the SWaT dataset.AnomTrans can only detect a few anomalies.In Case 1, two anomalies were not detected and AnomTrans struggled with accurately detecting segment anomalies.Moreover, the anomaly score differentiation is relatively low, as in Case 2, where it has limited success detecting anomalies.In cases 3 and 4, NPSR is more effective in detecting anomalies than AnomTrans, especially segment anomalies.However, NPSR fails to detect certain anomalies, such as near time points 6500 and 8000.Additionally, NPSR tends to produce more false positives, as observed around time point 140000, where a few instances are falsely classified as positive.Furthermore, Fig. 12 illustrates the similarity scores at various model layers.In the initial layer, the similarity scores exhibit a relatively dispersed pattern.However, as the number of layers increases, the similarity scores gradually rise, leading to more focused attention.</p>
<p>C. Analysis of cosine similarity loss</p>
<ol>
<li>Direct Explanation: MSE enforces point-wise reconstruction by requiring the model to return each time point in the sequence to its original value, acting as a point-wise loss.Cosine similarity, on the other hand, enhances the alignment between patches, promoting smoother transitions and reducing noise interference during reconstruction.2. Semantic Explanation: Patch-based time series studies suggest that patches are more effective at capturing the semantic information of sequences.While interpolative learning can reconstruct individual time points, patches benefit from more than just simple interpolation.Traditional patch learning often relies solely on MSE loss, ignoring this benefit.3. Visual Explanation: As shown in Fig. 10, incorporating cosine loss enables the model to better detect longer anomalies.For additional details, see Section E-B. 4. Numerical Explanation: Ablation experiments were conducted by removing cosine terms from Equations 4, 5, and 7 while keeping the MSE loss.The results, presented in Table V, indicate a significant decrease in model performance after removing these terms.</li>
</ol>
<p>D. Detailed quantified comparison</p>
<p>For a detailed comparison, we group Deep SVDD, Deep IF, USAD, TCN-ED, NPSR, and TimesNet, as they can be considered traditional deep learning methods.The remaining methods are grouped as in Section IV-A.Below is the analysis and discussion.</p>
<p>1.In the traditional deep learning group, NPSR has achieved the highest average ranking.Our proposed method significantly outperforms NPSR on datasets SWaT, WADI, and Swan.All of these dataset are more complex and higherdimensional.The superiority of our proposed method over NPSR can be attributed to that the former can handle highdimensional data better and have a larger parameter capacity.</p>
<ol>
<li>
<p>Among Transformer-based models, TranAD has obtained the highest average ranking.With more parameters, TranAD performs better on datasets SWaT, PSM, and Swan.However, since these models rely on point-wise modeling of time series data, their complexity is high, limiting their performance.In contrast, SimAD employs a patch mechanism, allowing the model to support window sizes of 1024 or higher, resulting in a larger receptive field and the ability to capture more information.SimAD's patch mechanism enables larger window sizes and better information capture compared to point-wise Transformer models like TranAD.learning to enhance model robustness.However, its reliance on a TCN network structure and complex sample generation strategy necessitates high-quality datasets.This results in superior performance on MSL and SMAP but causes sharp declines on other datasets.In contrast, our method employs a simpler negative sample generation strategy and a more complex network structure, making it less dependent on dataset quality.Our method's simpler negative sample generation and more complex network structure make it more adaptable to various dataset qualities compared to contrastive learning methods like COUTA. 4. D3R is the only diffusion model.It preserves stable components in time series data, such as trends and periodic information, which enhances anomaly detection, particularly for unstable time series data with sudden increases.However, its performance is limited by stronger prior assumptions and data quality requirements, making it less effective across all datasets.In contrast, SimAD operates on more general assumptions, recognizing that normal and anomalous data have different representations.This universal modeling approach allows SimAD to adapt more effectively to a wide range of datasets.SimAD's general assumptions about data representation enable it to adapt more effectively across various datasets compared to the diffusion model D3R.</p>
</li>
<li>
<p>GPT2-Adapter is an LLM-enhanced time series anomaly detection model that integrates large language models with time series data.Although it represents a pioneering effort in applying LLMs to this field, its performance in anomaly detection falls short.This is mainly due to challenges with aligning natural language models with time series data, difficulties in fine-tuning LLM parameters, and the lack of specialized optimization for time series anomaly detection.Consequently, GPT2-Adapter often underperforms in practical scenarios.Despite being a pioneer in LLM-based approaches, GPT2-Adapter falls short due to modal alignment issues and insufficient optimization for time series anomaly detection.</p>
</li>
</ol>
<p>F. TIME COSTS</p>
<p>Table XI presents a comparative analysis of SimAD and other models regarding model size, training time, and testing time using the SWaT dataset.The estimated training time for all methods involved training on 128,000 samples to ensure a fair comparison.However, an issue with the original code of the D3R model caused its reported testing time to be excessively long (2794.25s).To provide a more accurate estimation, we estimated the actual testing time of D3R to be 15.98s.</p>
<p>In terms of model size, SimAD demonstrates a significant advantage over D3R and GP2-Adapter (LLM model).Its smaller model size indicates efficient memory usage.SimAD also performs well regarding inference time, showing shorter inference times than other models.This implies that SimAD can make predictions faster during deployment, which can be crucial in real-time applications.</p>
<p>However, it's important to note that SimAD has a longer training time and a larger model size than the other models in the analysis.Despite this, considering that SimAD achieves performance improvements of over 60%, the model size and inference speed of SimAD are still within an acceptable range.To further improve SimAD, future work will explore model optimization techniques to reduce the model size while maintaining or enhancing its performance.This would address the longer training time and larger model size, making SimAD even more efficient and practical for deployment.G. BOADER IMPACTS Time series anomaly detection is crucial in identifying abnormal behaviours and events.Its applications span across various domains, including risk prevention, health monitoring, and industrial inspection.The demand for effective anomaly detection techniques is high due to its wide industrial coverage.In practical scenarios, labeled data for anomalous events is often scarce.However, our method is designed to adapt to this situation and provide highly accurate detection results.There are scenarios where the model needs to perform well under resource-constrained conditions.Therefore, it becomes necessary for our model to incorporate other techniques that can reduce its size and enable it to adapt to such situations.In the future, we aspire to address this limitation by considering the model lightweight while ensuring detection accuracy, thereby creating greater societal value.</p>
<p>H. LIMITATIONS Significant computational costs are incurred due to the adoption of a Transformer-like architecture as the backbone of the model.In the future, we will explore alternative network frameworks, such as MAMBA or convolutional networks, that are more lightweight and efficient.Furthermore, considering the existing limitations of current time series anomaly detection algorithms, such as inaccurate evaluation and lengthy computation, we aim to propose novel evaluation metrics that are both accurate and efficient for anomaly detection.</p>
<p>Below is the in-depth analysis of the intrinsic shortcomings of the model.</p>
<p>TSAD in Practical Scenarios: TSAD often requires fast and effective models.Our Transformer-based model's computational cost is a limitation.Assuming batch size B, time series length T , channels C, and patch length P , the number of patches is M = T P , and the final input is (B, M, P × C).With hidden dimension D, the intermediate feature shape is (B, M, D).At this point, the computational bottleneck lies in the Transformer's self-attention and feedforward network (FFN) [45].The complexity of self-attention is quadratic concerning the sequence length, with a computational complexity of (B • M 2 • D), while the FFN complexity is
(B•M •D 2 ). The overall computational complexity of the model is B •(M 2 •D+M •D 2 ).
When the number of patches is greater than the model dimension, this complexity can be approximated as (B • M 2 • D).Note that SimAD's ContrastFusion is a twolayer FFN projection head, whose complexity equals that of the FFN.During reconstruction, an extra linear layer with lower complexity than the FFN is used, and their complexities differ by a constant factor.Thus, SimAD's overall complexity is dominated by the EmbedPatch Encoder's complexity, with other components contributing less.At this point, the length of the time series affects the computational efficiency, leading to slower model performance.</p>
<p>To address the computational cost, we can replace the attention backbone in SimAD with frameworks like SSM or MAMBA, whose complexity is linear concerning the sequence length, resulting in (B • M • D 2 ) overall, with FFN as the bottleneck.However, when N is less than the model dimension, linear complexity models do not resolve the bottleneck.In this case, we can explore other FFN structures, such as using grouped Linear layers, dividing the input into G groups of size D G .This reduces the FFN complexity to
(B • M • D 2 G ).</p>
<p>Comparison with Non-Patch-Based Transformer Models:</p>
<p>For non-patch-based Transformer models like AnomTrans, the computational bottleneck lies in the self-attention calculation, leading to a complexity of (B • T 2 • D).Since we slice the sequential data, the actual sequence length in our network is shorter.Therefore, our computational complexity is more efficient.</p>
<p>Comparison with Channel-Independent and Patch-Based Models: For channel-independent, patch-based models like DCdetector, the complexity is (B • C • M 2 • D), where B is the batch size, C is the number of channels, M is the length of the patch sequence, and D is the dimensionality of features.These models must process each channel independently, resulting in higher computational complexity.Consequently, our approach offers a more efficient alternative in this respect.</p>
<p>I. INSIGHTS BEHIND SIMAD</p>
<ol>
<li>
<p>Our model emphasizes simplicity &amp; effectiveness, avoiding excessive complexity.Our goal is to establish a new paradigm for time series anomaly detection (TSAD), akin to how SimCLR sets the foundation for image representation.We consider that a simpler, more effective model allows for further exploration and development, leaving ample room for future improvements to SimAD.For example, SimAD employs the simplest noise augmentation for generating negative samples and utilizes a straightforward MSE loss for constructing an asymmetric optimization strategy, yet it still delivers excellent results.We expect that SimAD's focus on simplicity and core principles will make it a cornerstone of future TSAD research, offering new perspectives to the community.</p>
</li>
<li>
<p>Our proposed UAff and NAff are simple &amp; effective metrics.Many related works have highlighted the shortcomings of existing TSAD metrics.While the Affiliation metric provides a solid foundation, it has notable deficiencies: it fails to accurately evaluate random algorithms and weaker methods, and its discrimination is limited, overlooking performance differences between models.We believe that simplicity and effectiveness are central to our approach, as reflected in our improvements to the metrics.</p>
</li>
<li>
<p>We fully leverage the concept of viewing similarity from different perspectives, operating under the belief that normal and abnormal time series representations are inherently dissimilar.Although SimAD may superficially resemble BYOL [62] in terms of its loss function design, the underlying motivations differ significantly.BYOL is based on the premise that representations of different views of the same data should be similar in the shared latent space.This is achieved in BYOL by employing contrastive learning to bring representations of different views closer together.Besides, BYOL updates its parameters via exponential moving averages.In contrast, SimAD employs a strategy that emphasizes maximizing the dissimilarity between representations of normal data and those of abnormal data.Furthermore, our model updates its parameters through an asymmetric loss optimization objective function, guided by a stop-gradient mechanism.SimSiam [49] is a self-supervised learning framework that enhances image generalization by learning view-invariant representations, using noise as a form of real-world augmentation.It utilizes two networks without parameter sharing and employs a cosine similarity loss to align projected and pre-projected features, effectively preventing collapse to trivial solutions.In contrast, our proposed method, SimAD, is designed to distinguish between normal and anomalous data by encouraging the projected features of two views to diverge in a low-dimensional space.This key difference in both implementation and objective distinguishes SimAD from SimSiam.</p>
</li>
<li>
<p>The motivation of negative samples: Previous research (Sec.4.5.1 in [9]) has shown that adding noise and scaling to time series data can alter the underlying information within the series.Study [35] employed a single time point alteration strategy to generate synthetic anomalies (contaminated data), while [63] used contrastive learning-based single-class algorithms.Both approaches indicate that adding noise can create varying perspectives, thereby helping to clarify the model's decision boundaries.</p>
</li>
</ol>
<p>The distinction between normal and anomalous instances is influenced by previous research, which indicates that adding noise can distort the original information in time series, potentially generating synthetic anomalies.This is intuitive, as increased noise leads to greater deviations from the original patterns.While TSAD currently does not use labels during training, research has shown that contrastive learning with negative samples can enhance a model's decision boundaries.As the gap between original time series data and augmented data widens, the model becomes better at capturing consistent information, such as trends and periodic patterns.</p>
<p>Our experiments and visualizations suggest that EmbedPatch primarily learns from normal data, resulting in less resemblance to anomalous time series.It is acknowledged that simple noise may not capture all the complexities of real-world anomalies.Future research aims to develop strategies that better address various real-world anomalies, as exemplified in [63].Nonetheless, our paper presents a more foundational approach using simpler strategies, offering a fresh perspective for the TSAD community.</p>
<p>In time series anomaly detection, [37] introduces noise into the embedding and tasks the model with denoising to reconstruct the original time series.Similarly, in image anomaly detection, [11] demonstrates the effectiveness of "adding perturbations to feature tokens, guiding the model to learn knowledge of normal samples through the denoising task."Building on this prior work, we assert that the primary function of denoising is to guide the model in learning the patterns of normal data, implicitly directing its focus towards normal behavior.Our ablation experiments further validate this point, showing that the model's performance deteriorates when denoising is not applied.</p>
<ol>
<li>The concept of "Dissimilarity" refers to the dissimilarity between normal and abnormal samples or representations.Specifically, this concept manifests in the following aspects:</li>
</ol>
<p>• Dissimilarity between positive and negative samples:</p>
<p>We expand the representation space between positive (original time series) and negative (constructed using noise) samples, thereby reducing their similarity and increasing their dissimilarity.• Dissimilarity between normal and abnormal samples: By diminishing the similarity between positive and negative samples, our objective is to heighten the differentiation between normal and abnormal samples, thus enabling the model to enhance anomaly detection efficacy.The distinction between normal and abnormal sample representations forms the core motivation behind SimAD.As no labels are accessible during training, it is hard to determine whether a sample is anomalous.Nonetheless, prior research as well as our own work indicate that even in the absence of labels, SimAD can effectively model the dissimilarity between normal and abnormal instances through learning the dissmilarity of positive and negative samples.• Dissimilarity embedded in EmbedPatch: EmbedPatch, a crucial component in our model, introduces learnable parameters independent from input data.These parameters enable the model to capture the most prevalent features in data and increase the difficulty of reconstruction, compelling the model to learn the universal characteristics of time series.A higher-layer EmbedPatch acquires more abstract normal semantic information, while a lower-layer EmbedPatch extracts simpler patterns from the time series.• Contrastive learning design utilizing dissimilarity: We consider normal and abnormal time series as having dissimilar view representations.Equation 7 uses MSE and cosine similarity to separate the representation spaces of normal and abnormal data, thereby enlarging their dissimilarity.While our approach based on dissimilarity shares some similarities with the concept of contrastive learning to a certain extent, there are fundamental differences in principles and implementation goals.From a theoretical perspective, contrastive learning often assumes that the augmented samples are similar to the original samples, with other dissimilar samples serving as negative samples.However, based on the findings of previous studies [63], considering augmented samples as negative samples in time series, i.e., dissimilar to the original samples, aligns better with the characteristics of time series data.Therefore, in principle, our dissimilarity-based approach differs from contrastive learning methods.In terms of implementation, our dissimilarity-based approach places greater emphasis on the dissimilarity between patches and the dissimilarity between normal and abnormal instances, utilizing cosine similarity to characterize this relationship.This implementation aspect also sets our approach apart from contrastive learning methods, hence the designation of our method as the "dissimilarity-based" approach seems more appropriate.</p>
<p>J. DISCUSSION</p>
<p>How does patch-based feature extraction work?Patchbased feature extraction methods are not new in the context of time series, and they have been effectively verified in time series prediction and anomaly detection in the past.For example, in PatchTST [55], the authors use the patch approach to segment the time series, and then use an attention model to learn the time series features and predict future time series data.In DCdetector [20], the authors also adopt the patch-based method to model the local and global time series information.In this way, the model is guided to capture the differences between normal and abnormal time series in both global and local aspects, and finally, these features are utilized to complete the anomaly detection.However, in previous papers, there is a lack of indepth exploration of the patch-based approach.Mainly, these methods are limited by the size of the time window.Usually, the time window size they set by default is 105, and the size of the patch is often 3, with a maximum of 7.Under such settings, the intuitive understanding is that they use three time points to represent the features of a very small interval of the time series.In fact, this method does not have a significant difference from the past modeling methods that are completely based on the time window.Because ultimately, the model is still limited by the time window of 105, which makes the model only learn the time series features in a local area.But in the real world, time series data often contains at least tens of thousands or even hundreds of thousands of timestamps.Therefore, a time window of 105 makes it difficult for the model to learn longer context relationships.To address this issue, for the first time, we scale the time window to 2048, which is 20 times larger compared to the previous models.However, this expansion comes at a cost.Since a longer time window requires the model to process more data at once, it will lead to extremely slow model inference speed, which is at least one-twentieth of the previous speed.And in the actual inference scenario, this is completely unusable.To solve this problem, we make improvements in the way of time series feature extraction, that is, we change the fixed mindset of using the original patch.We also expand the size of the patch to at least 32 lengths.That is to say, we use the data of 32 time points for representation.Finally, the model only needs to process 2048/32 basic units, so the features actually processed by the model are reduced.At the same time, due to the existence of a lot of redundant data in the time series itself, this processing method does not limit the model's learning of time series data.For example, in some time series, the channel values of the time series may remain around a certain level for a long time, with only slight fluctuations.In this case, the truly effective information is to mine the stable values of the time series during this period.Or, in the time series, periodic information is often very common, and there may be slight changes within each period.Similarly, most of the time series data is redundant at this time.Therefore, the patch-based processing and expanding the size of the patch to 32 will not affect the model's learning of time series data.Meanwhile, our experiments also show that when the time window is larger and the patch is larger, the loss of the model is actually smaller, which means that the model fits the time series more perfectly.</p>
<p>Yue Xu received the B.S. degree in 2025 from the South China University of Technology, Guangzhou,China and he is currently working toward the M.A. degree with the South China University of Technology, Guangzhou, China.His research interests include adversarial attack, continual learning and anomaly detection.</p>
<p>Fig. 1 .
1
Fig. 1.The Overview of SimAD.</p>
<p>Fig. 2 .
2
Fig. 2. The framework and workflow of SimAD.</p>
<p>Algorithm 1 1 # 2 # 3 # 4 # 5 # 6 # 7 for x in data_loader: 8 x1F
112345678
The Pseudo-Code for Training SimAD.J: I.I.D GA U S S I A N N O I S E FE: FEA T U R E EX T R A C T O R EN C: EM B E DPA T C H EN C O D E R CF: CO N T R A S TFU S I O N SI MAD: CO M B I N A T I O N O F FE, EN C, A N D CF R: RE A R R A N G E D A T A , x2 = x, x + J9 x_out1, sim1 = SimAD(x1) # SI MAD PR O C E S S I N G x_out2, sim2 = SimAD(x2) # RE C O N S T R U C T S A N D P R O J E C T S S S F U N C T I O N def loss_func(s1,s2): return l2_loss(s1,s2) + (1-cos_loss(s1,s2)).mean() B. Baselines 1) Inference: Anomaly score: To calculate the anomaly score for query samples, we use the following equation:</p>
<p>Fig. 3 .
3
Fig. 3. Comparison analysis of relative performance.</p>
<p>Fig. 4 .
4
Fig. 4. The impact of window size on F1-score and the reconstruction loss when the window size varies from 32 to 2048.</p>
<p>Fig. 5 (Fig. 5 .
55
Fig. 5. Different numbers of embeddings and other hyper-parameters.The error bar represents the standard deviation.</p>
<p>Fig. 7 .
7
Fig. 7. Loss and F1 score variations on dataset PSM.</p>
<p>(a) Detection performances in real-world.</p>
<p>Similarity scores of query and embedding.</p>
<p>Fig. 8 .
8
Fig. 8. Real world case study on dataset SWaT.</p>
<p>ACKNOWLEDGMENT</p>
<p>This work was supported in part by National Natural Science Foundation of China No. 62476101, 92467109, U21A20478, 62306052, National Key R&amp;D Program of China 2023YFA1011601, the Major Key Project of PCL, China under Grant PCL2023AS7-1, and Natural Science Foundation of Chongqing under Grant CSTB2023NSCQ-LZX0092. APPENDIX This is the appendix of SimAD: A Simple Dissimilaritybased Approach for Time Series Anomaly Detection.</p>
<p>ap−ap b 1 −
1
ap b</p>
<p>uap ap ≥ 1
1
or uap ap ≤ 1.By calculating the partial derivative of D = uap ap = ap−ap b ap(1−ap b )</p>
<p>Fig. 9
9
Fig.9illustrates an artificial example of time series anomaly detection.The top row represents the true labels of the time series data.Random1, Random2, Pred1, and Pred2 denote the anomaly scores generated by two random and other algorithms.The labels ending with "PA" indicate point adjustment, where if the model predicts any part of an anomaly segment, the entire segment is considered an identified anomaly.</p>
<p>Fig. 11 .Fig. 12 .
1112
Fig. 11.Other algorithms' detection performances in real-world.</p>
<p>TABLE II COMPARISON
II
RESULTS.ALL RESULTS ARE IN %, THE BEST IN BOLD, AND THE SECOND IN UNDERLINED.
DatasetsMSLSMAPSWaTMethodsF1AUC Aff-Pre Aff-Rec Aff-F1 UAff-F1 NAff-F1 F1AUC Aff-Pre Aff-Rec Aff-F1 UAff-F1 NAff-F1 F1AUC Aff-Pre Aff-Rec Aff-F1 UAff-F1 NAff-F1Random18.60 50.01 51.34 99.9967.840.005.2022.06 50.18 51.48 100.067.970.005.7421.06 50.10 52.9499.99 69.230.0011.09LOF19.36 55.75 53.5788.90 66.868.7413.22 23.64 62.39 46.0081.26 58.74 -19.84 -14.58 58.22 84.59 99.872.705.255.255.25IForest10.90 59.09 55.0997.63 70.44 14.3118.45 23.78 61.15 39.4570.23 50.52 -36.64 -32.45 38.52 83.80 100.02.715.275.275.27PCA10.33 53.25 55.5097.44 70.72 15.7319.77 22.96 58.70 39.6770.31 50.72 -36.15 -31.93 26.05 81.85 99.962.705.255.255.25Deep SVDD 24.30 61.80 52.6799.93 68.98 10.5310.13 21.28 61.14 44.9888.45 59.64 -17.60 -18.02 22.57 86.81 53.58 99.9969.77 13.7513.37USAD22.50 57.12 51.9097.29 67.697.737.3116.57 62.79 39.5669.48 50.41 -31.78 -32.12 21.70 88.66 53.00100.0 69.28 11.7111.31TCN-ED19.66 51.14 51.4499.99 67.936.045.6122.90 58.91 51.3999.98 67.895.865.4221.65 89.23 52.98100.0 69.26 11.6411.24COUTA20.88 55.59 51.2499.65 67.685.294.8522.69 58.74 51.48 100.067.976.185.7447.65 75.54 79.9833.20 46.92 42.7642.73TranAD22.81 50.03 52.8299.34 68.97 11.0710.66 22.74 59.74 39.4170.30 50.51 -32.21 -32.56 25.50 88.90 55.6599.66 71.42 20.6420.30NCAD22.05 60.20 56.3883.30 67.25 22.4622.14 23.09 53.45 51.88 99.9968.327.677.2568.72 82.92 65.0185.58 73.89 44.6444.46Deep IF19.11 55.94 51.45 100.067.946.085.64 29.14 60.09 53.7598.67 69.59 14.3113.93 21.65 89.52 52.98 100.069.26 11.6411.24AnomTrans 18.39 52.61 50.2199.83 66.81 -4.530.8316.06 52.18 55.8499.11 71.44 16.4920.9023.44 80.80 50.2499.49 66.77 -10.830.96TimesNet21.24 57.18 51.1299.95 67.644.814.3624.37 53.73 49.5099.86 66.19 -1.52-1.99 21.66 73.24 57.8493.77 71.55 27.1626.86DCdetector 11.62 50.31 51.9697.77 67.852.527.5226.56 58.50 55.5599.78 71.37 15.4819.97 23.24 52.78 52.6398.30 68.56 -1.2810.00D3R23.98 63.00 53.6199.97 69.798.927.6522.71 54.56 51.43 100.067.92 -0.210.0745.89 79.95 61.4778.52 68.96 29.4736.02GPT2-Adapter 13.72 52.03 53.3197.01 68.817.806.7524.12 55.48 53.2899.84 69.487.183.6722.30 52.30 52.5198.13 68.41 -1.790.07NPSR23.72 61.16 52.0599.81 68.422.897.8822.68 61.26 51.46 100.067.95 -0.065.68 76.88 90.18 71.2181.16 75.86 52.5455.73M2N221.76 59.15 51.38 100.00 67.880.175.3622.68 54.05 51.46 100.00 67.950.525.6938.50 67.79 59.1596.83 73.44 27.5430.77AdaMemBLS 19.11 51.78 57.0795.37 71.41 20.9924.6426.93 53.66 53.3099.80 69.497.2412.38 74.10 81.61 53.57 100.00 69.762.6513.32Ours30.02 62.70 56.3099.76 71.9818.5022.37 29.39 65.46 56.8499.82 72.44 19.9124.07 82.03 90.31 78.4680.88 79.65 64.9366.82DatasetsWADIPSMNIPS-TS-Swan</p>
<p>TABLE III THE
III
AVERAGE PERFORMANCE AND RANKING OF DIFFERENT ALGORITHMS.RK.DENOTES THE RANKING.
Avg.F1 RK. Aff-F1 RK. UAff-F1 RK. NAff-F1 RK. AUC RK. V PR RK. Avg. RK.Random26.62 69.21 90.001911.5115 50.10 20 27.71 1816.17LOF26.18 41.19 209.051313.7610 71.23 3 39.75 912.00IForest31.46 7 46.45 1911.09 1115.159 73.19 2 43.39 79.17PCA31.00 8 47.13 188.691413.1013 64.88 8 37.84 1312.33Deep SVDD 29.32 65.15 157.73157.3418 70.44 5 50.13 311.17USAD28.69 65.06 167.33176.9719 65.58 7 51.95 212.33TCN-ED27.96 69.41 812.16 1011.7614 64.61 9 46.07 610.33COUTA35.59 4 59.96 1722.44422.185 63.52 11 36.75 149.17TranAD29.66 67.37 1313.88813.5511 64.41 10 47.66 59.50NCAD34.82 5 68.73 1027.30227.022 62.24 12 38.21 127.17Deep IF28.90 69.69 713.57913.1812 66.56 6 39.69 109.33AnomTrans 25.63 68.17 12-2.11209.5817 57.56 17 26.49 1917.17TimesNet28.61 66.02 1426.68326.413 60.27 15 36.47 1510.67DCdetector 24.05 70.01 66.141816.618 52.07 19 28.33 1714.67D3R33.19 6 70.16 510.00 1210.0216 62.01 13 39.59 1110.50GPT2-Adapter 25.22 68.67 117.49165.1120 53.51 18 28.33 1616.67NPSR45.71 2 71.60 216.58725.074 71.01 4 49.29 43.83M2N230.43 9 70.64 417.58619.127 60.28 14 21.55 2010.00AdaMemBLS 40.88 3 70.70 318.58519.166 59.24 16 42.17 86.83Ours54.79 1 74.78 143.31146.961 77.27 1 52.96 11.00</p>
<p>TABLE IV COMPARISON
IV
OF DIFFERENT MODELS ON DATASET UCR.
DatasetsUCRMetrics MethodsF1 Aff-Pre Aff-Rec Aff-F1 UAff-F1 NAff-F1AnomTrans 1.17 50.6698.94 66.88 9.4110.88Avg.+DCdetector 1.66 Ours 14.99 57.83 50.9099.96 67.41 99.91 72.52 35.16 6.715.52 34.38AnomTrans 1.15 50.3997.73 66.551.301.23Avg.DCdetector 1.61 Ours 14.99 57.83 50.6383.30 67.06 97.47 72.52 19.53 2.012.64 19.46</p>
<p>TABLE VI THE
VI
KL DIVERGENCE BETWEEN NORMAL AND ANOMALOUS FEATURES BOTH BEFORE AND AFTER PROJECTION.
DatasetsSWaTWADIVariationsBefore Proj. After Proj.Before Proj. After Proj.w/o Cont.7.34E-011.66E-024.95E-052.85E-03w/o Embeder4.34E-012.04E-023.25E-031.59E-01Ours4.25E-015.04E-013.00E-029.89E-01can be attributed to that EmbedPatch contributes SimAD tomemorizing normal samples and enhancing generalization.By capturing the characteristics of normal data, EmbedPatchimproves the effectiveness of anomaly detection by leveragingthe distinct differences between normal and abnormal samples,as demonstrated in Fig. 8(b) and Fig. 12 in Appendix E.The w/o Contrastive module also exhibits a low loss butsuffers from negative optimization, resulting in a relativelylow F1 score. In contrast, SimAD, despite having a higherloss, achieves the highest F1 score. This demonstrates thatoptimizing solely for reconstruction is inadequate, and SimADeffectively addresses the challenges outlined in the introduction.</p>
<p>TABLE IX COMPARISON
IX
RESULTS ON UCR DATASETS.
DatasetsUCRMetricsMethodsF1Aff-Pre Aff-Rec Aff-F1 UAff-F1 NAff-F1AnomTrans147244244244141148CountDCdetector Ours149 240206 240206 240206 240127 173144 177AnomTrans1.1750.6698.9466.889.4110.88Avg.+DCdetector Ours1.66 14.9950.90 57.8399.96 99.9167.41 72.526.71 35.165.52 34.38AnomTrans1.1550.3997.7366.551.301.23Avg.DCdetector Ours1.61 14.9950.63 57.8383.30 97.4767.06 72.522.01 19.532.64 1.00</p>
<p>TABLE X PERFORMANCE
X
OF DIFFERENT METHODS ON VUS METRICS.
DatasetsMSLSMAPSWaTWADIPSMNIPS-TS-SwanMethods</p>
<p>ROC, and V PR.The metrics V ROC and V PR assess performance based on the surfaces created by ROC and PR curves.As shown in Table X our method achieves the best performance on MSL, SMAP, SWaT, and WADI, and demonstrates strong competitiveness on PSM and Swan.This can be attributed to the anomaly ratios of dataset and evaluation metrics.Specifically, PSM and Swan have a higher ratio of anomalies, which may impact performance.Overall, SimAD is the most stable, performing consistently well across multiple metrics and datasets, compared with other methods.
PRRandom57.2714.1557.5614.6657.5917.2052.7114.1457.2916.2651.2112.7456.817.7058.358.5855.7233.0155.0932.5938.1735.4386.1983.58LOF62.1517.2960.8517.1958.0018.6357.5618.5966.9442.3366.6741.8846.177.8845.237.7381.3665.2480.4264.5590.3489.8389.4288.56IForest65.3818.3764.7418.2959.3016.4659.3116.4573.2553.1172.2952.0778.9928.4777.8927.0275.8155.9275.1955.5091.8892.0091.2790.98PCA59.8118.2059.4218.0844.0311.6943.9011.6961.6144.3861.8744.7548.857.8348.257.7274.5254.9373.9754.5591.5091.6490.4290.23Deep SVDD60.1519.4459.5419.3642.0011.5541.9511.5650.9656.4850.9656.4857.2154.8257.1654.7354.0066.9853.9766.9282.2792.7380.8991.74USAD59.5920.0058.8619.7733.7611.2733.7811.2884.7163.4184.3862.7450.8254.3150.7854.2464.4769.5564.0269.1893.7096.1491.4094.50TCN-ED58.9818.2058.6218.1343.9311.7343.7911.7361.5357.9561.5357.9450.8654.3150.8354.2458.2043.0257.4842.6482.2792.7280.8891.73COUTA61.9718.9161.4918.6844.8211.9144.7211.9172.6825.0972.5725.0646.4730.2745.6529.4364.7343.2964.5043.1583.7893.3682.1592.26TranAD57.7717.6757.2517.5545.2711.9845.1511.9886.5964.2986.2564.1960.2744.0359.9443.6572.8556.2872.4256.0289.0993.6188.0192.59NCAD67.9821.4767.2921.3248.3913.2148.3713.2276.8644.9676.7644.9145.808.5144.528.1367.6048.5567.0948.2687.4094.7385.3193.44Deep IF53.1917.2452.3317.0456.9314.7756.8914.7750.1956.4050.1956.3947.9713.5847.0712.2368.3746.4867.7145.9882.2792.7380.8991.74AnomTrans53.2513.1753.0313.2152.7516.5652.6116.5521.528.2921.498.2950.497.8350.297.7149.8431.6649.1231.5685.4683.5783.5681.64TimesNet65.4120.9564.6320.6749.0112.9348.8312.9131.2710.3131.1010.2981.7534.7679.8032.6267.2249.1766.3748.0592.6195.3391.5894.30DCDetector52.1714.6952.0014.6860.6516.8860.3816.8750.8514.7050.8414.6851.628.2351.608.2152.1332.5651.7332.4487.5985.0985.8483.11D3R69.7421.0469.0220.9354.9816.5648.6713.2371.0339.9184.3857.2749.887.4949.258.4266.4749.4466.9249.3852.3644.8789.2788.29GPT2-Adapter52.9716.7953.5717.3859.9019.0357.3115.7851.1114.1050.0110.2950.988.6751.329.5248.2436.5652.4532.7947.3741.5984.3184.23NPSR67.5819.1866.4419.7247.6014.2241.9111.4287.5267.2684.9365.4287.9454.4588.2356.7272.5758.6570.5552.1253.9247.6190.9090.35M2N265.8221.6965.4021.5548.8014.3648.7414.3661.4126.3361.1426.1645.078.1543.997.9839.1930.2239.2030.1063.9529.5163.6929.15AdaMemBLS58.2916.1357.4616.0655.7314.2655.5714.2684.2768.6482.0066.1266.5023.1163.4721.4066.1649.8165.0749.2488.8587.8587.1285.92Ours69.4524.8668.4524.1561.9020.7758.6417.0286.1969.4683.8966.7091.2661.9991.9564.3271.2554.7968.0653.8187.5985.0990.9591.74experiments: Range-AUC-ROC (R A R), Range-AUC-PR(R A P), V</p>
<ol>
<li>Contrastive learning-based methods perform similarly on average.Taking COUTA as an example, it utilizes multiple methods to generate negative samples and leverages contrastiveFig.10.SimAD's detection performances in real-world.
001Feature0 Ground Truth1Feature0 Ground Truth6000 0.02 0.03 0.046500700075008000850090009500 Prediction (Ours) Anomaly Score (Ours) 10000 Threshold (Ours)10000 0.02 0.03 0.04110001200013000140001500016000 Anomaly Score (Ours) Prediction (Ours) Threshold (Ours)0.010.016000 0.00 0.02 0.03 0.046500700075008000850090009500 Prediction (L2 Only) Anomaly Score (L2 Only) 10000 Threshold (L2 Only)10000 0.00 0.02 0.03 0.041100012000130001400015000 Prediction (L2 Only) Anomaly Score (L2 Only) 16000 Threshold (L2 Only)0.010.016000 0.00 0.865007000750080008500900095001000010000 0.00 0.81100012000130001400015000160000.60.66000 0.0 0.2 0.46500700075008000850090009500 Prediction (Cos Only) Anomaly Score (Cos Only) 10000 Threshold (Cos Only)10000 0.0 0.2 0.41100012000130001400015000 Prediction (Cos Only) Anomaly Score (Cos Only) 16000 Threshold (Cos Only)(a) (Ours) Case 1(b) (Ours) Case 2001Feature0 Ground Truth1Feature0 Ground Truth6000 0.010 0.015 0.0206500700075008000850090009500 Prediction (AnomTrans) Anomaly Score (AnomTrans) 10000 Threshold (AnomTrans)10000 0.010 0.015 0.0201100012000130001400015000 Prediction (AnomTrans) Anomaly Score (AnomTrans) 16000 Threshold (AnomTrans)0.0050.0056000 0.00065007000750080008500900095001000010000 0.000110001200013000140001500016000(a) (AnomTrans) Case 1(b) (AnomTrans) Case 20.02 0.03 0.04Prediction (NPSR) Anomaly Score (NPSR) Threshold (NPSR)0.02 0.03 0.04Prediction (NPSR) Anomaly Score (NPSR) Threshold (NPSR)0.010.016000 0.0065007000750080008500900095001000010000 0.00110001200013000140001500016000(c) (NPSR) Case 3(d) (NPSR) Case 4</li>
</ol>
<p>TABLE XI THE
XI
TIME COSTS OF DIFFERENT ALGORITHMS.THE LOWER IS BETTER.
MethodsModel Size (MB)Train (sec)Test (sec)USAD332.0772.141.51TCN-ED0.0441.340.86NCAD0.19141.731.77AnomTrans28.2933.253.91TimesNet19.1524.293.62D3R225.101900.3715.98GPT2-Adapter241.58241.5871.24Ours114.75245.881.27
Wenming Cao (S'16) received M.Sc.degree from the School of Automation, Huazhong University of Science and Technology (HUST), Wuhan, China, 2015, and Ph.D. degree at the Department of Computer Science, City University of Hong Kong, 2019.He has been a Postdoctoral Fellow at the University of Hong Kong from 2019 to 2021.He is an associate professor with the Department of Information and Computing Science, Chongqing Jiaotong University.His research interests include data mining and machine learning.Yiyuan Yang is a DPhil student at the Department of Computer Science, University of Oxford, United Kingdom.He focuses on the field of intelligent sensing systems, time series, spatiotemporal data mining, anomaly detection, and generative models.He previously studied at the Department of Automation at Tsinghua University and interned at the Alibaba DAMO Academy and Huawei Noah's Ark Lab.Kaixiang Yang (M'21) received the B.S. degree and M.S. degree from the University of Electronic Science and Technology of China and Harbin Institute of Technology, China, in 2012 and 2015, respectively, and the Ph.D. degree from the School of Computer Science and Engineering, South China University of Technology, China, in 2020.He has been a Research Engineer with the 7th Research Institute, China Electronics Technology Group Corporation, Guangzhou, China, from 2015 to 2017, and has been a Postdoctoral Researcher with Zhejiang University from 2020 to 2021.He is now with the School of Computer Science and Engineering, South China University of Technology.His research interests include pattern recognition, machine learning, and industrial data intelligence.
Table Vii, Comparison Of Different Metrics On Three Different Synthetic Datasets, 5.48 90.54 4.60 4.72 26.31 50.25 49.91 87.98 63.50 0.06 77.35 37.85 75.62 36.02F1PA IS A POINT-ADJUSTED F1 SCORE. Demo Method F1 Acc Pre Rec F1PA AUC Aff-Pre Aff-Rec Aff-F1 NAff-F1 R A R R A P V ROC V PR Random. </p>
<p>Adaptive memory broad learning system for unsupervised time series anomaly detection. Z Zhong, Z Yu, Z Fan, C L Philip Chen, K Yang, IEEE Transactions on Neural Networks and Learning Systems. 3652025</p>
<p>A spatiotemporal deep learning approach for unsupervised anomaly detection in cloud systems. Z He, P Chen, X Li, Y Wang, G Yu, C Chen, X Li, Z Zheng, IEEE Transactions on Neural Networks and Learning Systems. 3442023</p>
<p>Correlation-aware spatial-temporal graph learning for multivariate timeseries anomaly detection. Y Zheng, H Y Koh, M Jin, L Chi, K T Phan, S Pan, Y.-P P Chen, W Xiang, IEEE Transactions on Neural Networks and Learning Systems. 3592024</p>
<p>Broad learning autoencoder with graph structure for data clustering. Z Yu, Z Zhong, K Yang, W Cao, C P Chen, IEEE Transactions on Knowledge and Data Engineering. 2023</p>
<p>A Comparative Study of Time Series Anomaly Detection Models for Industrial Control Systems. B Kim, M A Alawami, E Kim, S Oh, J Park, H Kim, Sensors. 23313102023</p>
<p>Fuzzy state-driven crosstime spatial dependence learning for multivariate timeseries anomaly detection. K Zhu, P Song, C Zhao, IEEE Transactions on Neural Networks and Learning Systems. 2024</p>
<p>A multi-scale mask convolution-based blindspot network for hyperspectral anomaly detection. Z Yang, R Zhao, X Meng, G Yang, W Sun, S Zhang, J Li, Remote Sensing. 161630362024</p>
<p>Gsead: graphical scoring estimation for hyperspectral anomaly detection. R Zhao, L Zhang, IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing. 1022016</p>
<p>Adaptive Memory Networks with Self-supervised Learning for Unsupervised Anomaly Detection. Y Zhang, J Wang, Y Chen, H Yu, T Qin, IEEE Transactions on Knowledge and Data Engineering. 4347c2022</p>
<p>Simplenet: A simple network for image anomaly detection and localization. Z Liu, Y Zhou, Y Xu, Z Wang, 2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). 202320411</p>
<p>A unified model for multi-class anomaly detection. Z You, L Cui, Y Shen, K Yang, X Lu, Y Zheng, X Le, Advances in Neural Information Processing Systems. 202235</p>
<p>Towards efficient anomaly detection using memory broad learning system. Z Zhong, K Yang, Z Yu, Y Shi, C P Chen, 2023 9th International Conference on Control Science and Systems Engineering (ICCSSE). </p>
<p>Anomaly transformer: Time series anomaly detection with association discrepancy. J Xu, H Wu, J Wang, M Long, International Conference on Learning Representations. 2021</p>
<p>An evaluation of anomaly detection and diagnosis in multivariate time series. A Garg, W Zhang, J Samaran, R Savitha, C.-S Foo, IEEE Transactions on Neural Networks and Learning Systems. 3362021</p>
<p>Towards a Rigorous Evaluation of Time-Series Anomaly Detection. S Kim, K Choi, H.-S Choi, B Lee, S Yoon, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence202236</p>
<p>Reward Once, Penalize Once: Rectifying Time Series Anomaly Detection. K Doshi, S Abudalou, Y Yilmaz, 2022 International Joint Conference on Neural Networks (IJCNN). 2022</p>
<p>Current Time Series Anomaly Detection Benchmarks are Flawed and are Creating the Illusion of Progress (Extended Abstract). R Wu, E J Keogh, 2022 IEEE 38th International Conference on Data Engineering (ICDE). Kuala Lumpur, MalaysiaIEEE2022</p>
<p>A robust background regression based score estimation algorithm for hyperspectral anomaly detection. R Zhao, B Du, L Zhang, L Zhang, ISPRS Journal of Photogrammetry and Remote Sensing. 1222016</p>
<p>USAD: UnSupervised Anomaly Detection on Multivariate Time Series. J Audibert, P Michiardi, F Guyard, S Marti, M A Zuluaga, Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining. Virtual Event CA USA. the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining. Virtual Event CA USAACM2020</p>
<p>Dcdetector: Dual attention contrastive representation learning for time series anomaly detection. Y Yang, C Zhang, T Zhou, Q Wen, L Sun, Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining. the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining2023</p>
<p>Tranad: deep transformer networks for anomaly detection in multivariate time series data. S Tuli, G Casale, N R Jennings, Proc. VLDB Endow. VLDB EndowFeb. 202215</p>
<p>Hyperspectral anomaly detection via a sparsity score estimation framework. R Zhao, B Du, L Zhang, IEEE Transactions on Geoscience and Remote Sensing. 5562017</p>
<p>Beyond background feature extraction: An anomaly detection algorithm inspired by slowly varying signal analysis. R Zhao, B Du, L Zhang, L Zhang, IEEE Transactions on Geoscience and Remote Sensing. 5432016</p>
<p>A robust nonlinear hyperspectral anomaly detection approach. R Zhao, B Du, L Zhang, IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing. 742014</p>
<p>A novel fully convolutional auto-encoder based on dual clustering and latent feature adversarial consistency for hyperspectral anomaly detection. R Zhao, Z Yang, X Meng, F Shao, Remote Sensing. 1647172024</p>
<p>Deep one-class classification. L Ruff, R Vandermeulen, N Goernitz, L Deecke, S A Siddiqui, A Binder, E Müller, M Kloft, International conference on machine learning. PMLR2018</p>
<p>Deep isolation forest for anomaly detection. H Xu, G Pang, Y Wang, Y Wang, IEEE Transactions on Knowledge and Data Engineering. 2023</p>
<p>A spectralspatial based local summation anomaly detection method for hyperspectral images. B Du, R Zhao, L Zhang, L Zhang, Signal Processing. 1242016</p>
<p>Anomaly detection using spatial and temporal information in multivariate time series. Z Tian, M Zhuo, L Liu, J Chen, S Zhou, Scientific Reports. 13144002023</p>
<p>Timesnet: Temporal 2d-variation modeling for general time series analysis. H Wu, T Hu, Y Liu, H Zhou, J Wang, M Long, The eleventh international conference on learning representations. 2022</p>
<p>Multivariate time series anomaly detection with adversarial transformer architecture in the Internet of Things. F Zeng, M Chen, C Qian, Y Wang, Y Zhou, W Tang, Future Generation Computer Systems. 1442023</p>
<p>Time Series Anomaly Detection Using Transformer-Based GAN With Two-Step Masking. A.-H Shin, S T Kim, G.-M Park, IEEE Access. 112023</p>
<p>GAN-Based Anomaly Detection for Multivariate Time Series Using Polluted Training Set. B Du, X Sun, J Ye, K Cheng, J Wang, L Sun, IEEE Transactions on Knowledge and Data Engineering. 2021</p>
<p>Time-series anomaly detection with stacked Transformer representations and 1D convolutional network. J Kim, H Kang, P Kang, Engineering Applications of Artificial Intelligence. 1201059642023</p>
<p>Calibrated one-class classification for unsupervised time series anomaly detection. H Xu, Y Wang, S Jian, Q Liao, Y Wang, G Pang, IEEE Transactions on Knowledge and Data Engineering. 36112024</p>
<p>Neural contextual anomaly detection for time series. C U Carmona, F.-X Aubet, V Flunkert, J Gasthaus, Proceedings of the Thirty-First International Joint Conference on Artificial Intelligence, IJCAI-22. L D Raedt, the Thirty-First International Joint Conference on Artificial Intelligence, IJCAI-2220227main Track</p>
<p>Contrastive autoencoder for anomaly detection in multivariate time series. H Zhou, K Yu, X Zhang, G Wu, A Yazidi, Information Sciences. 6102022</p>
<p>Contrastive predictive coding for Anomaly Detection in Multi-variate Time Series Data. T Pranavan, T Sim, A Ambikapathi, S Ramasamy, arXiv.org2022</p>
<p>Drift doesn't matter: Dynamic decomposition with diffusion reconstruction for unstable multivariate time series anomaly detection. C Wang, Z Zhuang, Q Qi, J Wang, X Wang, H Sun, J Liao, Advances in Neural Information Processing Systems. 202436</p>
<p>Imdiffusion: Imputed diffusion models for multivariate time series anomaly detection. Y Chen, C Zhang, M Ma, Y Liu, R Ding, B Li, S He, S Rajmohan, Q Lin, D Zhang, Proc. VLDB Endow. VLDB EndowNov. 202317</p>
<p>One Fits All: Power General Time Series Analysis by Pretrained LM. T Zhou, P Niu, X Wang, L Sun, R Jin, Advances in Neural Information Processing Systems. 202336355</p>
<p>Dissimilarity-preserving representation learning for oneclass time series classification. S Mauceri, J Sweeney, M Nicolau, J Mcdermott, IEEE Transactions on Neural Networks and Learning Systems. 35109622024</p>
<p>Reversible instance normalization for accurate time-series forecasting against distribution shift. T Kim, J Kim, Y Tae, C Park, J.-H Choi, J Choo, International Conference on Learning Representations. 2021</p>
<p>Llm4ts: Aligning pre-trained llms as data-efficient timeseries forecasters. C Chang, W.-Y Wang, W.-C Peng, T.-F Chen, arXiv:2308.084692024arXiv preprint</p>
<p>Attention is all you need. A Vaswani, N Shazeer, N Parmar, J Uszkoreit, L Jones, A N Gomez, L U Kaiser, I Polosukhin, Advances in Neural Information Processing Systems. I Guyon, U V Luxburg, S Bengio, H Wallach, R Fergus, S Vishwanathan, R Garnett, Curran Associates, Inc201730</p>
<p>M Jin, S Wang, L Ma, Z Chu, J Y Zhang, X Shi, P.-Y Chen, Y Liang, Y.-F Li, S Pan, arXiv:2310.01728Time-llm: Time series forecasting by reprogramming large language models. 2023arXiv preprint</p>
<p>Extracting and composing robust features with denoising autoencoders. P Vincent, H Larochelle, Y Bengio, P.-A Manzagol, Proceedings of the 25th international conference on Machine learning. the 25th international conference on Machine learning2008</p>
<p>A simple framework for contrastive learning of visual representations. T Chen, S Kornblith, M Norouzi, G Hinton, International conference on machine learning. PMLR2020</p>
<p>Exploring simple siamese representation learning. X Chen, K He, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)June 202115758</p>
<p>Local Evaluation of Time Series Anomaly Detection Algorithms. A Huet, J M Navarro, D Rossi, Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining. the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining2022</p>
<p>The ucr time series archive. H A Dau, A Bagnall, K Kamgar, C.-C M Yeh, Y Zhu, S Gharghabi, C A Ratanamahatana, E Keogh, IEEE/CAA Journal of Automatica Sinica. 662019</p>
<p>Volume under the surface: a new accuracy evaluation measure for time-series anomaly detection. J Paparrizos, P Boniol, T Palpanas, R S Tsay, A Elmore, M J Franklin, Proceedings of the VLDB Endowment. the VLDB Endowment202215</p>
<p>Nominality Score Conditioned Time Series Anomaly Detection by Point/Sequential Reconstruction. C.-Y A Lai, F.-K Sun, Z Gao, J H Lang, D Boning, Advances in Neural Information Processing Systems. 202336655</p>
<p>When model meets new normals: Test-time adaptation for unsupervised time-series anomaly detection. D Kim, S Park, J Choo, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial IntelligenceMar. 202438</p>
<p>A time series is worth 64 words: Long-term forecasting with transformers. Y Nie, N H Nguyen, P Sinthong, J Kalagnanam, The Eleventh International Conference on Learning Representations. 2023</p>
<p>Frequency-domain mlps are more effective learners in time series forecasting. K Yi, Q Zhang, W Fan, S Wang, P Wang, H He, N An, D Lian, L Cao, Z Niu, Advances in Neural Information Processing Systems. 202436</p>
<p>Detecting spacecraft anomalies using lstms and nonparametric dynamic thresholding. K Hundman, V Constantinou, C Laporte, I Colwell, T Soderstrom, Proceedings of the 24th ACM SIGKDD international conference on knowledge discovery &amp; data mining. the 24th ACM SIGKDD international conference on knowledge discovery &amp; data mining2018</p>
<p>The soil moisture active passive (smap) mission. D Entekhabi, E G Njoku, P E O'neill, K H Kellogg, W T Crow, W N Edelstein, J K Entin, S D Goodman, T J Jackson, J Johnson, Proceedings of the IEEE. the IEEE201098</p>
<p>Practical approach to asynchronous multivariate time series anomaly detection and localization. A Abdulaal, Z Liu, T Lancewicki, Proceedings of the 27th ACM SIGKDD conference on knowledge discovery &amp; data mining. the 27th ACM SIGKDD conference on knowledge discovery &amp; data mining2021</p>
<p>Current time series anomaly detection benchmarks are flawed and are creating the illusion of progress. R Wu, E J Keogh, IEEE Transactions on Knowledge and Data Engineering. 3532023</p>
<p>Navigating the metric maze: a taxonomy of evaluation metrics for anomaly detection in time series. S Sørbø, M Ruocco, Data Min. Knowl. Discov. 383Nov. 2023</p>
<p>Bootstrap your own latenta new approach to self-supervised learning. J.-B Grill, F Strub, F Altché, C Tallec, P Richemond, E Buchatskaya, C Doersch, B Avila Pires, Z Guo, M Gheshlaghi Azar, Advances in neural information processing systems. 202033</p>
<p>Deep contrastive one-class time series anomaly detection. R Wang, C Liu, X Mou, K Gao, X Guo, P Liu, T Wo, X Liu, Proceedings of the 2023 SIAM International Conference on Data Mining (SDM). the 2023 SIAM International Conference on Data Mining (SDM)</p>
<p>China and he is currently working toward the Ph.D. degree with the South China University of Technology. Guangzhou, ChinaHarbin Engineering University, Harbin,His research interests include data mining, machine learning, time series analysis, anomaly detection. and large language model (LLM</p>
<p>Zhiwen Yu, 06-M'08-SM'14Yu has authored or coauthored more than 200 refereed journal articles and international conference papers, including more than 70 articles in the journals of IEEE Transactions. His google citation is more than 10000, and hindex is 44. He is an Associate Editor of the IEEE Transactions on systems, man, and cybernetics: systems. He is a senior member of IEEE and ACM. Hong Kong2008Professor in School of Computer Science and Engineering, South China University of Technology, China. He received the Ph.D. degree from the City University of Hong Konga Member of the Council of China Computer Federation (CCF)</p>
<p>Xing Xi received the B.S. degree in 2020 from the Guangdong Baiyun University and the M.A. degree from the Guangdong University of Technology, Guangzhou, China. Current, he is currently working toward the D.E degree with the South China University of Technology. His research interests include object detection, open world and vocabulary object detection. </p>            </div>
        </div>

    </div>
</body>
</html>