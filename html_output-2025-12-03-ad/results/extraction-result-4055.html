<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-4055 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-4055</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-4055</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-95.html">extraction-schema-95</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of selective vulnerability or resistance of specific neuronal populations, cell types, layers, or regions within the visual cortex to amyloid-Œ≤ (amyloid-beta) plaques and tau protein tangles in the context of dementia or Alzheimer's disease.</div>
                <p><strong>Paper ID:</strong> paper-281496609</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2509.18568v1.pdf" target="_blank">Explainable Graph Neural Networks: Understanding Brain Connectivity and Biomarkers in Dementia</a></p>
                <p><strong>Paper Abstract:</strong> Dementia is a progressive neurodegenerative disorder with multiple etiologies, including Alzheimer's disease, Parkinson's disease, frontotemporal dementia, and vascular dementia. Its clinical and biological heterogeneity makes diagnosis and subtype differentiation highly challenging. Graph Neural Networks (GNNs) have recently shown strong potential in modeling brain connectivity, but their limited robustness, data scarcity, and lack of interpretability constrain clinical adoption. Explainable Graph Neural Networks (XGNNs) have emerged to address these barriers by combining graph-based learning with interpretability, enabling the identification of disease-relevant biomarkers, analysis of brain network disruptions, and provision of transparent insights for clinicians. This paper presents the first comprehensive review dedicated to XGNNs in dementia research. We examine their applications across Alzheimer's disease, Parkinson's disease, mild cognitive impairment, and multi-disease diagnosis. A taxonomy of explainability methods tailored for dementia-related tasks is introduced, alongside comparisons of existing models in clinical scenarios. We also highlight challenges such as limited generalizability, underexplored domains, and the integration of Large Language Models (LLMs) for early detection. By outlining both progress and open problems, this review aims to guide future work toward trustworthy, clinically meaningful, and scalable use of XGNNs in dementia research.</p>
                <p><strong>Cost:</strong> 0.012</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <p class="empty-note">No extracted data.</p>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Tracking pathophysiological processes in Alzheimer's disease: an updated hypothetical model of dynamic biomarkers. <em>(Rating: 2)</em></li>
                <li>Amyloid-PET and 18F-FDG-PET in the diagnostic investigation of Alzheimer's disease and other dementias. <em>(Rating: 2)</em></li>
                <li>Amyloid ùõΩ-protein and the genetics of Alzheimer's disease. <em>(Rating: 1)</em></li>
                <li>Neurodegenerative diseases target large-scale human brain networks. <em>(Rating: 1)</em></li>
                <li>Default-mode network activity distinguishes Alzheimer's disease from healthy aging: evidence from functional MRI. <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-4055",
    "paper_id": "paper-281496609",
    "extraction_schema_id": "extraction-schema-95",
    "extracted_data": [],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Tracking pathophysiological processes in Alzheimer's disease: an updated hypothetical model of dynamic biomarkers.",
            "rating": 2,
            "sanitized_title": "tracking_pathophysiological_processes_in_alzheimers_disease_an_updated_hypothetical_model_of_dynamic_biomarkers"
        },
        {
            "paper_title": "Amyloid-PET and 18F-FDG-PET in the diagnostic investigation of Alzheimer's disease and other dementias.",
            "rating": 2,
            "sanitized_title": "amyloidpet_and_18ffdgpet_in_the_diagnostic_investigation_of_alzheimers_disease_and_other_dementias"
        },
        {
            "paper_title": "Amyloid ùõΩ-protein and the genetics of Alzheimer's disease.",
            "rating": 1,
            "sanitized_title": "amyloid_ùõΩprotein_and_the_genetics_of_alzheimers_disease"
        },
        {
            "paper_title": "Neurodegenerative diseases target large-scale human brain networks.",
            "rating": 1,
            "sanitized_title": "neurodegenerative_diseases_target_largescale_human_brain_networks"
        },
        {
            "paper_title": "Default-mode network activity distinguishes Alzheimer's disease from healthy aging: evidence from functional MRI.",
            "rating": 1,
            "sanitized_title": "defaultmode_network_activity_distinguishes_alzheimers_disease_from_healthy_aging_evidence_from_functional_mri"
        }
    ],
    "cost": 0.011625249999999998,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Explainable Graph Neural Networks: Understanding Brain Connectivity and Biomarkers in Dementia
23 Sep 2025</p>
<p>Rmit University 0009-0008-5888-0932
Australia 0009-0002-0879-7168
Nguyen Linh 
Dan Le 0009-0008-5888-0932</p>
<p>RMIT University
Australia</p>
<p>Birla Institute of Technology and Science
Pilani</p>
<p>K K Birla Goa Campus
India</p>
<p>Federation University Australia
Australia</p>
<p>RMIT University
Australia</p>
<p>RMIT University
Australia</p>
<p>RMIT University
Australia</p>
<p>Birla Institute of Technology and Science
Pilani</p>
<p>K K Birla Goa Campus
India</p>
<p>RMIT University
Australia</p>
<p>Explainable Graph Neural Networks: Understanding Brain Connectivity and Biomarkers in Dementia
23 Sep 2025EDEA90977E9FD062EAF71AE72C96ECD7arXiv:2509.18568v1[cs.LG]CCS Concepts:Computing methodologies ‚Üí Neural networks‚Ä¢ Applied computing ‚Üí Health informaticsComputational biology Explainable Graph Neural Networks, Dementia, Health informatics, Brain connectivity
Dementia is a progressive neurodegenerative disorder with multiple etiologies, including Alzheimer's disease, Parkinson's disease, frontotemporal dementia, and vascular dementia.Its clinical and biological heterogeneity makes diagnosis and subtype differentiation highly challenging.Graph Neural Networks (GNNs) have recently shown strong potential in modeling brain connectivity, but their limited robustness, data scarcity, and lack of interpretability constrain clinical adoption.Explainable Graph Neural Networks (XGNNs) have emerged to address these barriers by combining graph-based learning with interpretability, enabling the identification of disease-relevant biomarkers, analysis of brain network disruptions, and provision of transparent insights for clinicians.This paper presents the first comprehensive review dedicated to XGNNs in dementia research.We examine their applications across Alzheimer's disease, Parkinson's disease, mild cognitive impairment, and multi-disease diagnosis.A taxonomy of explainability methods tailored for dementia-related tasks is introduced, alongside comparisons of existing models in clinical scenarios.We also highlight challenges such as limited generalizability, underexplored domains, and the integration of Large Language Models (LLMs) for early detection.By outlining both progress and open problems, this review aims to guide future work toward trustworthy, clinically meaningful, and scalable use of XGNNs in dementia research.</p>
<p>Introduction</p>
<p>Dementia, encompassing a range of conditions such as Alzheimer's disease, vascular dementia, frontotemporal dementia, and Parkinson's disease dementia, has become a pressing global health challenge.It is estimated that around fifty million people worldwide are currently living with dementia of various etiologies, a figure that is projected to triple by 2050, with the highest mortality rates occurring in low-and middle-income countries [174].In the absence of a cure, the rising prevalence of dementia places an increasing strain on healthcare systems.Early diagnosis is vital, as it enables timely interventions such as lifestyle modifications, pharmacological treatment, and cognitive therapy measures that can reduce the global incidence of dementia by as much as 40% [105].However, achieving accurate and timely diagnosis remains challenging due to the complexity and heterogeneity of clinical presentations.In this context, the integration of artificial intelligence (AI) into dementia research has significantly enhanced early detection and treatment efforts by enabling the analysis of large-scale data, predicting disease progression, supporting clinical decision-making, and reinforcing healthcare infrastructure [171].</p>
<p>Assessing cognitive function in patients with dementia is inherently complex due to the interplay between primary symptoms that directly result from brain damage and secondary manifestations reflecting the individual's adaptation to cognitive impairment.Dementia follows a biologically progressive trajectory, initially affecting specific brain regions and giving rise to memory deficits, diminished cognitive abilities, mood instability, and visual-perceptual difficulties.The prodromal phase, also referred to as mild cognitive impairment (MCI) or predementia, can often be prolonged, during which symptoms gradually intensify, including language impairments and perceptual deficits.In the final stage, dementia exerts a profound impact on daily functioning, with symptoms across different dementia types converging; this stage typically lasts one to two years [78].</p>
<p>More than fifty medical conditions have been identified as potential causes of dementia, among which Alzheimer's disease (AD) remains the most prevalent, accounting for 60-80% of cases.Frontotemporal dementia (FTD) affects approximately 60% of younger individuals aged 45 to 60, but only around 3% of older adults [122].Lewy body dementia (LwD) constitutes roughly 5% of cases, predominantly among older populations.In addition, about 3.6% of patients are diagnosed with Parkinson's disease (PD), while Parkinson's disease dementia (PDD) develops in approximately 24% of those with PD [3].Mixed or multi-etiology dementia, which refers to the coexistence of multiple pathological features, is increasingly recognized in clinical practice.Notably, over 50% of individuals diagnosed with AD also exhibit signs of FTD, vascular dementia (VaD), or other overlapping pathologies [8,35].</p>
<p>For diagnostic purposes, computational methods such as machine learning (ML) and deep learning (DL) have been employed to analyze disease patterns using medical imaging and clinical records.While these approaches have advanced dementia research, they often fall short in capturing the complex patterns of brain connectivity.Beyond the mere detection of abnormalities, it is crucial to understand how dementia affects specific brain regions and disrupts their interconnections.To address this limitation, Graph Neural Networks (GNNs) provide a more specialized solution by leveraging the inherent graph structure of brain networks.This allows them to model inter-regional relationships, structural disruptions, and changes in connectivity more effectively [183,195].Unlike convolutional neural networks (CNNs), which operate on connectome adjacency matrices but often lack specificity, GNNs are capable of learning meaningful node representations and extracting disease-relevant topological features [148].By representing brain data as graphs, GNNs enable a more precise characterization of brain connectivity, which is particularly valuable in dementia research for identifying subtypes, analyzing dynamic connectivity, and discovering potential biomarkers.</p>
<p>The application of GNNs has recently attracted considerable attention due to their strong predictive capabilities, particularly when applied to graph-structured biological data.While promising results have been achieved on smaller datasets, several challenges limit their clinical applicability.These include limited robustness and generalizability, a scarcity of labeled datasets, and potential biases arising from training on cohort-specific data.Such limitations undermine performance across diverse populations.Furthermore, dementia encompasses distinct etiologies such as PD and FTD, each with unique pathological and symptomatic profiles.The heterogeneous nature of dementia further complicates cross-cohort generalization [109].</p>
<p>In addition, debate persists regarding the effectiveness of graph-based representations in fully capturing the complexities of brain activity and in identifying appropriate methods for modeling brain connectivity.Trust and fairness are also critical considerations in healthcare, where transparent decision-making is essential to foster clinician confidence [120,127,138].A lack of interpretability can undermine this trust, which is vital for informed medical decisions [41,65].To address these concerns, Explainable Artificial Intelligence (XAI) has emerged as a promising approach to enhance model transparency and clarify the decision-making processes of complex systems.Despite these challenges, recent research underscores the potential of Explainable Graph Neural Networks (XGNNs) in improving dementia classification and prediction.</p>
<p>ACM Trans.Comput.Healthcare, Vol. 1, No. 1, Article 1. Publication date: January 2025.</p>
<p>1:4 ‚Ä¢ Niharika Tewari, Nguyen Linh Dan Le, Mujie Liu, Jing Ren, Ziqi Xu, Tabinda Sarwar, Veeky Baths, and Feng Xia</p>
<p>Related Surveys</p>
<p>Numerous studies have explored the application of machine learning and deep learning techniques in medical imaging [18,121,129,140,141,164], disease diagnosis [23], and dementia research [118,169,171], offering broad insights into model architectures and clinical applications.With the emergence of explainability in GNNs [80,184], there has been growing adoption of XGNNs in diagnosing brain disorders [22], investigating cognitive dysfunctions [114], and studying neurodegenerative diseases such as AD [13,167] and PD [77].These developments highlight the increasing need for a deeper understanding of dementia through the lens of XGNNs.As illustrated in Figure 1, the XGNN framework typically combines graph-based learning with explainability modules to provide interpretable insights into brain connectivity and disease mechanisms.</p>
<p>Despite these advances, existing reviews often lack a focused discussion on the relevance and application of XGNN models to dementia research, which limits a clear understanding of the significance of this emerging intersection.To address this gap, our study presents a comprehensive survey of XGNN approaches in the context of dementia-related disorders, with a particular focus on both post-hoc and inherently interpretable models.</p>
<p>Contributions</p>
<p>This study aims to provide readers with a clear understanding of how XGNNs are applied in dementia research.We present a comprehensive overview of current applications, associated challenges, and future research directions, with the aim of promoting the broader adoption of XGNNs in the study of dementia.To the best of our knowledge, this is the first review dedicated to the use of XGNNs for understanding brain connectivity and identifying biomarkers in dementia.The key contributions of this work are summarized as follows:</p>
<p>‚Ä¢ An exploration of the potential applications of XGNNs in dementia research.This includes individual disorders such as AD, PD, and MCI, as well as multi-disease diagnosis involving combinations of these and related conditions.‚Ä¢ A comprehensive review and categorization of recent developments in XGNN algorithms for dementia research.We introduce a taxonomy that classifies explainability techniques according to scope, methodological type, domain applicability, and output form, thereby providing a structured framework for their use across both single-and multi-disease contexts.‚Ä¢ A comparative analysis of existing XGNN models in various clinical scenarios, highlighting their diagnostic performance across distinct dementia subtypes and complex multi-disease cases.‚Ä¢ A discussion of current challenges and limitations in the application of XGNNs to dementia detection, such as underexplored domains, integration with Large Language Models (LLMs) for early detection, and strategies for enhancing diagnostic accuracy.These discussions help identify promising directions for future research.The remainder of this paper is organized as follows.Section 2 presents the preliminaries, laying the foundation for understanding the motivation behind this review.Section 3 introduces a subtype taxonomy of dementia and the review motivation, offering a classification of common dementia-related disorders and highlighting the need for explainable methods.Section 4 presents a taxonomy of XGNNs.The subsequent Sections 5, 6, 7, and 8 explore how XGNNs are applied to specific conditions, including mild cognitive impairment, Alzheimer's disease, Parkinson's disease, and multi-disease diagnosis.Section 9 reviews the public datasets used in studies, which form the empirical basis for model development and evaluation.Section 10 concludes with a discussion on open challenges and outlook, summarizing limitations and future directions.Finally, Section 11 offers concluding reflections.</p>
<p>Preliminaries 2.1 Multimodal Data</p>
<p>Accurate dementia diagnosis and subtype differentiation rely on a range of medical imaging modalities, each of which captures complementary aspects of neural structure and function:</p>
<p>‚Ä¢ Structural Magnetic Resonance Imaging (sMRI): Provides high-resolution anatomical images, allowing for the quantification of grey matter volume, cortical thickness, and white matter integrity.Structural atrophy in regions such as the hippocampus and prefrontal cortex serves as a key biomarker in conditions such as Alzheimer's disease (AD), frontotemporal dementia (FTD), and others [46].[34].These imaging modalities are often employed individually or integrated through multimodal fusion to enhance diagnostic accuracy and better characterize the complex neurodegenerative processes underlying dementia.A clear understanding of these modalities also provides the foundation for constructing brain graphs and developing explainable machine learning models for dementia research.</p>
<p>Brain Parcellation</p>
<p>To analyze regional brain properties and construct connectomes, the brain is typically parcellated into anatomically or functionally defined regions of interest (ROIs) using standardized brain atlases.Commonly adopted parcellation schemes include:</p>
<p>‚Ä¢ Automated Anatomical Labeling (AAL) atlas: A widely used structural atlas that partitions the brain into 90 regions (or 116 including the cerebellum) based on anatomical landmarks.‚Ä¢ Desikan-Killiany atlas: Derived from gyral morphology, this atlas segments the cortex into 68 regions (34 per hemisphere) and is frequently employed in FreeSurfer-based cortical thickness analysis.‚Ä¢ Schaefer atlas: A functional parcellation generated from resting-state fMRI data using gradient-weighted Markov Random Field modeling.It supports flexible resolution ranging from 100 to 1000 ROIs, aligned hierarchically with functional networks.‚Ä¢ Destrieux atlas: A high-resolution anatomical atlas based on detailed gyral and sulcal structures.It offers finer granularity than the Desikan-Killiany atlas and is particularly useful in surface-based morphometry.‚Ä¢ Harvard-Oxford atlas: A probabilistic anatomical atlas encompassing both cortical and subcortical regions.It is commonly applied in volumetric and voxel-wise analyses.‚Ä¢ SPHARM-PDM atlas: A surface-based atlas that captures shape features of subcortical structures using spherical harmonics.It is particularly valuable for morphological graph construction in shape analysis.By defining consistent ROIs, these atlases provide standardized frameworks for cross-subject comparison and enable multimodal integration, forming the basis for brain graph construction in dementia research [11,128,130</p>
<p>Graph Construction</p>
<p>Brain graphs (or brain networks) provide a compact mathematical abstraction of brain connectivity, representing ROIs as nodes and their interrelationships as edges.Formally, a brain graph is denoted as  = ( , , A), where  = { 1 ,  2 , . . .,   } represents a set of  brain regions (nodes),  denotes the set of edges, and A ‚àà R  √ó is the weighted adjacency matrix that encodes the strength or similarity of connectivity between pairs of ROIs.The construction of A depends on the imaging modality and the chosen connectivity estimation method.</p>
<p>In practice, multiple types of brain graphs can be derived from different neuroimaging modalities:</p>
<p>‚Ä¢ Functional brain graphs are typically constructed from resting-state or task-based fMRI and EEG data.</p>
<p>Here, nodes correspond to predefined ROIs, and edges reflect statistical dependencies between the neural activity time series of each ROI pair.For a given subject, let x  ‚àà R  denote the time series of ROI   over  time points.The functional connectivity (FC) between   and   is commonly estimated using similarity measures.A widely used metric is the Pearson correlation coefficient:
ùëé func ùëñ ùëó = Cov(x ùëñ , x ùëó ) ùúé (x ùëñ ) ‚Ä¢ ùúé (x ùëó ) ,(1)
where  func</p>
<p>ùëñ ùëó</p>
<p>is the edge weight in the functional adjacency matrix A func , Cov(‚Ä¢, ‚Ä¢) denotes covariance, and  (‚Ä¢) is the standard deviation.Although Pearson correlation is favored for its simplicity and interpretability, alternative FC measures-such as mutual information, spectral coherence, and phase-locking value-may be employed depending on the modality's temporal resolution [152,166].</p>
<p>‚Ä¢ Structural brain graphs are derived from structural MRI or diffusion-based imaging techniques such as DTI.In this context, edges represent physical or anatomical connections.For DTI-based graphs, tractography is used to estimate white matter tracts between ROIs, with edge weights defined by metrics such as the number of streamlines, mean fractional anisotropy (FA), or average fiber length.Alternatively, morphometric similarity networks can be constructed by computing inter-regional correlations of morphological features (e.g., cortical thickness, surface area, or volume) across subjects, producing a structural adjacency matrix A struct that reflects structural covariance [62,107].‚Ä¢ Morphological brain graphs capture shape-and geometry-based relationships, typically using structural MRI alongside methods such as SPHARM (spherical harmonics) or surface-based analysis.In these graphs, nodes still correspond to anatomical regions, while edges encode similarities in regional morphology, such as curvature profiles, sulcal depth, or hippocampal shape descriptors.These features are particularly useful for detecting disease-related structural deformations, with the resulting adjacency matrix A morph representing inter-regional morphological correlations or proximity [44,113].Overall, brain graphs provide a unified yet flexible framework for modeling different dimensions of brain organization.In dementia research, they serve as a powerful abstraction for exploring connectivity disruptions, identifying disease biomarkers, and modeling disease progression, thereby providing the foundation for graphbased machine learning approaches in dementia research.</p>
<p>Subtype Taxonomy of Dementia</p>
<p>Dementia comprises a group of neurodegenerative disorders characterized by the progressive deterioration of cognitive function, often accompanied by impairments in memory, language, attention, executive function, visuospatial abilities, and behavior.Within this spectrum, several clinically distinct subtypes have been widely recognized, each exhibiting unique symptom profiles and patterns of brain involvement.In this review, we focus on five representative subtypes: MCI, AD, VaD, FTD, and PDD.</p>
<p>Although all five subtypes are introduced to provide a comprehensive clinical and neuropathological overview, the model-focused analysis in subsequent sections primarily centers on MCI, AD, and PD.This emphasis reflects the larger and more targeted body of XGNN-related literature for these conditions.In contrast, FTD and VaD remain underrepresented in the current landscape.Accordingly, we discuss studies of these subtypes within other sections rather than dedicating separate subsections; for instance, research on subcortical ischemic vascular dementia (SIVD) is presented under non-amnestic MCI, while comparative analyses of AD and FTD appear in the multi-disease diagnosis section.</p>
<p>This structured approach maintains clarity while acknowledging the growing relevance of FTD and VaD in GNN-based dementia research.As the field evolves, future work is expected to address these underexplored subtypes more directly, thereby enriching the scope of graph-based methodologies in dementia studies.</p>
<p>Mild Cognitive Impairment</p>
<p>MCI is a clinical condition characterized by cognitive decline greater than expected for an individual's age and education level, yet not severe enough to significantly impair daily functioning.It is widely regarded as a transitional stage between normal cognitive aging and dementia, particularly AD in its amnestic form [9,10]. From an etiological perspective, MCI may arise from various mechanisms, including early neurodegenerative changes (e.g., amyloid deposition, tau pathology), cerebrovascular abnormalities, metabolic dysfunction, and psychiatric conditions such as depression or anxiety [73].Genetic predispositions, such as the presence of the APOE 4 allele, have also been linked to an elevated risk of progression from MCI to AD [135].Clinically, MCI is categorized into amnestic and non-amnestic subtypes, depending on whether memory impairment is the predominant feature.Amnestic MCI (aMCI), which primarily affects memory, is more likely to progress to AD, whereas non-amnestic MCI (naMCI) involves deficits in language, attention, or executive function and may precede other subtypes such as FTD, PDD, or VaD [48].Longitudinal studies suggest that individuals with MCI convert to dementia at an annual rate of 10-15%, although some remain stable or revert to normal cognition [90].Diagnosis typically relies on standardized cognitive screening tools such as the Montreal Cognitive Assessment (MoCA) or the Mini-Mental State Examination (MMSE), supplemented by neuropsychological assessments, with advanced neuroimaging techniques (MRI, PET) increasingly used for subtype differentiation and early risk identification.</p>
<p>Neuroanatomically, aMCI is associated with structural atrophy and metabolic dysfunction in memory-related regions including the hippocampus, entorhinal cortex, parahippocampal gyrus, posterior cingulate cortex (PCC), precuneus, and broader medial temporal lobe (MTL) [6,72].These regions overlap with the default mode network (DMN), whose early disruption is considered a hallmark of preclinical AD.In contrast, naMCI is characterized by impairments in executive, language, or visuospatial domains, with alterations commonly observed in the dorsolateral prefrontal cortex (DLPFC), inferior parietal lobule, superior temporal gyrus, and anterior cingulate cortex.In cases linked to small vessel disease or mixed pathology, subcortical structures such as the thalamus, caudate, and related white matter tracts may also be affected [158].These distinct anatomical patterns support differentiation among dementia subtypes and may guide the development of subtype-specific interventions.</p>
<p>Alzheimer's Disease</p>
<p>AD is a progressive neurodegenerative disorder and the most prevalent cause of dementia, accounting for 60-80% of cases globally.It is clinically characterized by a gradual decline across multiple cognitive domains, beginning with episodic memory and followed by impairments in language, orientation, executive function, and personality [119].Unlike MCI, AD represents a fully developed clinical syndrome with substantial impairment in daily functioning.From a pathophysiological perspective, AD is multifactorial, involving a cascade of molecular and cellular events.Hallmark pathological features include the extracellular accumulation of amyloid-beta (A) plaques, intracellular neurofibrillary tangles composed of hyperphosphorylated tau protein, synaptic loss, and widespread neuronal death [71,145].These processes disrupt network-level brain communication, particularly within memory and self-referential systems.Clinical diagnosis typically combines neuropsychological testing, MRI-based volumetrics, and amyloid/tau PET imaging to identify early-stage AD and differentiate it from non-AD dementias [73].</p>
<p>Neuroimaging and postmortem studies consistently reveal a characteristic pattern of brain atrophy and functional disconnection in AD.Early degeneration occurs in the hippocampus and medial temporal lobe, resulting in profound memory deficits.As the disease progresses, structural and metabolic alterations extend to the posterior cingulate cortex (PCC) and precuneus, which are key hubs within the DMN and support autobiographical memory, introspection, and spatial navigation-functions frequently impaired in AD [59,147].AD also affects the temporoparietal cortex, which underpins semantic knowledge and language comprehension, distinguishing it from subtypes such as FTD that typically spare this region in early stages.Moreover, disruptions in limbic-associated regions (LIM), including the amygdala and orbitofrontal cortex, contribute to behavioral symptoms such as anxiety, apathy, and emotional dysregulation [16,144].Overall, the selective vulnerability of the hippocampal-DMN-temporoparietal axis provides a reliable anatomical and functional signature that supports early diagnosis, disease staging, and the development of targeted interventions.</p>
<p>Vascular Dementia</p>
<p>VaD is the second most common form of dementia after AD and results from cerebrovascular pathology that disrupts blood flow to the brain, leading to neuronal injury and cognitive decline.Unlike neurodegenerative dementias, VaD arises from ischemic or hemorrhagic events that cause direct tissue damage or network disconnection, making it a structurally driven rather than proteinopathy-driven disorder [81,168].The etiology of VaD is highly heterogeneous, encompassing large vessel strokes, lacunar infarcts, strategic infarcts, microbleeds, cerebral small vessel disease, and chronic hypoperfusion.Risk factors include hypertension, diabetes, hyperlipidemia, atrial fibrillation, and smoking-conditions that contribute to both macrovascular and microvascular injury [132,163].Clinically, VaD does not follow a uniform progression pattern: cognitive decline often occurs in a stepwise or fluctuating manner, especially in multi-infarct types, whereas subcortical ischemic VaD may present more gradually.Patients frequently exhibit impairments in attention, processing speed, executive function, and gait, which are distinct from the early memory loss typically seen in AD [12].Moreover, VaD often coexists with neurodegenerative pathology, resulting in mixed dementia and complicating both diagnosis and disease modeling [82].</p>
<p>Clinical diagnosis of VaD involves neurocognitive testing, vascular risk profiling, and neuroimaging.Established criteria such as those of the National Institute of Neurological Disorders and Stroke and the Association Internationale pour la Recherche et l'Enseignement en Neurosciences (NINDS-AIREN), along with DSM-5 guidelines, provide clinical frameworks; however, diagnosis increasingly relies on multimodal imaging.MRI is essential for detecting white matter hyperintensities, lacunar infarcts, strategic infarcts (e.g., in the thalamus or angular gyrus), and microbleeds, while advanced techniques such as DTI and arterial spin labeling (ASL) further support the identification of microvascular damage and chronic hypoperfusion [55].Neuropathologically, VaD manifests as a network disconnection syndrome due to cumulative microstructural damage across distributed brain systems.Key affected regions include the white matter, where leukoaraiosis and demyelination disrupt interregional communication; the basal ganglia, particularly in lacunar infarcts; the thalamus, which serves as a relay hub for cortical-subcortical communication; and the frontal lobes, which are crucial for attention and executive function.Hippocampal involvement is typically less prominent than in AD, though it may become more apparent in mixed pathology cases or when perfusion deficits extend into medial temporal regions [82].This distinct spatial distribution of lesions, combined with vascular imaging biomarkers and cognitive profiles, supports differential diagnosis and the development of targeted intervention strategies for VaD.</p>
<p>Frontotemporal Dementia</p>
<p>FTD is a group of neurodegenerative disorders primarily characterized by early deterioration in behavior, personality, or language.It is recognized as the leading cause of dementia in individuals under the age of 65.Unlike AD, which predominantly presents with memory impairment, FTD manifests with executive dysfunction, social disinhibition, apathy, or progressive aphasia, depending on the subtype involved [38,137].Major variants include the behavioral variant (bvFTD), nonfluent/agrammatic variant primary progressive aphasia (nfvPPA), and semantic variant PPA (svPPA) [42].The underlying pathology is typically associated with abnormal protein accumulations, such as tau or fused in sarcoma (FUS), leading to selective neuronal loss and gliosis [143].FTD generally follows a progressive course, with marked declines in social cognition, language, and executive function.While certain subtypes may initially spare memory, widespread cognitive impairment often develops as the disease advances.In some cases, progression may involve motor neuron disease or extrapyramidal symptoms, further complicating clinical management [17].</p>
<p>Diagnosis relies on detailed clinical history and behavioral assessment, supported by structural and functional neuroimaging.MRI typically reveals focal atrophy in the frontal and anterior temporal lobes, with patterns of asymmetry depending on the subtype.For example, bvFTD commonly affects the orbitofrontal cortex, insula, and anterior cingulate cortex-regions implicated in emotion regulation and social behavior.In contrast, svPPA is associated with pronounced left-sided anterior temporal lobe atrophy, impairing language comprehension, while nfvPPA involves degeneration of the left posterior frontal lobe and supplementary motor areas, disrupting speech production and grammatical processing [136].Some FTD variants also show subcortical involvement, particularly in the basal ganglia and thalamus, especially when motor symptoms or genetic mutations are present.The relative sparing of the posterior parietal and occipital cortices further distinguishes FTD from AD and other dementias.As disease-modifying treatments remain limited, early recognition and accurate subtyping based on neuroanatomical patterns are essential for prognosis, caregiver planning, and determining eligibility for clinical trials.</p>
<p>Parkinson's Disease Dementia</p>
<p>PDD refers to the onset of dementia in individuals with a pre-existing diagnosis of PD, typically emerging after several years of motor symptoms such as bradykinesia, rigidity, and resting tremor.It is estimated that up to 80% of individuals with PD will eventually develop dementia, making cognitive decline a major non-motor complication of the disease [51].The underlying pathology of PDD is multifaceted, involving widespread neurodegeneration that extends beyond the classical dopaminergic system.While degeneration of dopaminergic neurons in the substantia nigra pars compacta accounts for motor symptoms, the spread of alpha-synuclein pathology (Lewy bodies) to limbic and neocortical regions is central to cognitive decline [52].Unlike AD, which is primarily driven by beta-amyloid and tau pathology, PDD is considered a synucleinopathy, frequently accompanied by cholinergic and noradrenergic deficits.Clinically, PDD is characterised by a distinctive cognitive profile, with early impairments in executive function, attention, and visuospatial abilities.Memory deficits tend to occur later and are typically less pronounced in the initial stages.Neuropsychiatric symptoms such as hallucinations, apathy, and fluctuating cognition are also common and can complicate disease management [100].</p>
<p>Diagnosis is based on clinical criteria, such as those proposed by the Movement Disorder Society, which require the onset of dementia at least one year after PD diagnosis to differentiate PDD from DLB. Neuropsychological assessments focusing on frontal-subcortical domains, alongside MRI or PET imaging, aid in confirming the diagnosis and excluding other causes of cognitive decline.Neuroimaging and neuropathological studies have revealed consistent patterns of regional brain involvement in PDD.Early degeneration is observed in the substantia nigra and basal ganglia, particularly the putamen and caudate nucleus, disrupting dopaminergic circuits vital for motor and cognitive integration.The thalamus, which modulates cortico-subcortical communication, is also frequently affected.As the disease progresses, pathology spreads to the prefrontal cortex, impairing executive function and working memory.Degeneration of posterior cortical regions, including the parietal and occipital lobes, contributes to visuospatial dysfunction and hallucinations, which help distinguish PDD from other dementias such as FTD or VaD [27].The distributed involvement of both subcortical nuclei and heteromodal association cortices underscores PDD as a network-level disorder, necessitating multidimensional diagnostic and therapeutic strategies.</p>
<p>As dementia encompasses a spectrum of clinically and anatomically heterogeneous conditions, XAI has emerged as a critical tool for identifying disease-specific neural signatures and supporting transparent clinical decision-making.Although subtypes share overlapping symptoms such as cognitive decline, memory impairment, and behavioural disturbances, each is characterised by distinct patterns of brain region involvement.As illustrated in Figure 2, regions such as the posterior cingulate cortex, precuneus, and prefrontal cortex are implicated in multiple forms of dementia, including AD, VaD, and PDD, suggesting partially convergent neurodegenerative processes.In contrast, areas such as the insula and Broca's area exhibit selective vulnerability in FTD, while subcortical structures like the substantia nigra and putamen are uniquely affected in PDD.</p>
<p>In this context, XAI provides a robust framework for bridging the gap between complex model decisions and clinical interpretability.By identifying the brain regions and connectivity patterns that underpin subtype-specific predictions, XAI facilitates deeper insights into disease mechanisms, enables more informed clinical decisions, and supports personalised diagnostic strategies.The coexistence of overlapping anatomical vulnerabilities and distinct regional signatures across dementia subtypes underscores the necessity for interpretable models capable of distinguishing between shared and unique biomarkers.Building on these challenges and opportunities, the following sections systematically examine recent advances in XGNN techniques applied to dementia research, with an emphasis on their role in elucidating both common and subtype-specific neuroanatomical patterns.</p>
<p>A Taxonomy of XGNN</p>
<p>For brain graphs, the granularity of interpretation can occur at multiple levels: subject-specific, population, and feature level.At the subject-specific level, the brain is represented as a graph, where connections encode network disruptions associated with dementia.At the population level, each node represents an individual subject, while edges reflect inter-subject similarities or relationships, facilitating group-level analysis and subtype discovery.At the feature level, the graph represents features such as imaging biomarkers, cognitive scores, or genetic markers, with edges denoting correlations or dependencies, often derived from measures such as Pearson correlation or mutual information.This multilevel perspective enables the investigation of feature interactions and supports disease characterisation and network modelling.</p>
<p>Building on these representations, we introduce a taxonomy of XAI methods relevant to graph-based models in the domain of dementia research.As illustrated in Figure 3, we categorise XAI approaches along four key dimensions: (1) Explanation Scope, distinguishing between global and local explanations; (2) Explanation Method, encompassing intrinsic and extrinsic techniques; (3) Domain Applicability, differentiating between model-specific and model-agnostic approaches; and (4) Mode of Explanation, referring to the modality of outputs, such as visualisations, example-based reasoning, or score-based metrics.While this framework builds upon previous work [22,129,164], we extend existing taxonomies by explicitly incorporating score-based explanations as a distinct category.This addition is particularly relevant for identifying biomedical risk factors, especially in the context of dementia, where quantifiable interpretability can support both clinical insight and model accountability.</p>
<p>XAI Methods</p>
<p>4.1.1Self-Explanation.While the terms interpretability and explainability are often used interchangeably [37], this study adopts the term Self-Explanation (S-XAI) within the context of interpretability, as S-XAI methods are inherently designed to be interpretable [66].Unlike post-hoc techniques, S-XAI approaches elucidate the internal mechanisms of AI models and intrinsically provide insights into their decision-making processes, offering transparency on how input features influence predictions.Kakkad et al. [80] categorized self-explainable methods based on information and structural constraints, while Melis et al. [7] refined the concept through the principles of fidelity, diversity, and grounding.Similarly, Velez et al. [47] introduced a framework for evaluating S-XAI methods using application-grounded, human-grounded, and functionality-grounded assessments.In the context of medical image analysis, Hou et al. [66] further categorized S-XAI techniques into input, model, and output explainability.Overall, S-XAI plays a vital role in fostering trust and transparency in AI systems, particularly in high-stakes domains such as healthcare, by providing built-in and comprehensible explanations of model behavior.</p>
<p>4.1.2Post-hoc Explanation.Post-hoc explanation methods are designed to interpret decisions of already trained models without modifying their architecture.These approaches analyse model predictions after training to reveal the underlying decision-making process, and they have been widely adopted in dementia research to highlight critical brain regions, features, and connectivity patterns.</p>
<p>Gradient-based methods rely on gradients of the model output with respect to the input to identify influential features.Representative techniques include Gradient-weighted Class Activation Mapping (Grad-CAM) [146,191], which highlights key regions or nodes contributing to predictions and has been adapted from CNNs to GNNs in cognitive disorder studies; saliency maps [151], which generate visualisations of the most important input elements; and guided backpropagation (GBP) [156,185], which refines saliency visualisations by suppressing irrelevant signals and emphasising positively contributing features.</p>
<p>Perturbation-based methods are model-agnostic approaches that explain predictions by altering the input and observing changes in the output.Key techniques include SHAP (Shapley Additive Explanations) [108], which assigns game-theoretic importance values to features and has been applied to link imaging biomarkers and cognitive measures to dementia predictions, and GNNExplainer [181], which is specifically designed for GNNs to identify explanatory subgraphs and node features driving model outputs.</p>
<p>Overall, both gradient-based [80,172] and perturbation-based [5,80] post-hoc methods play a crucial role in enhancing the interpretability of complex models.By clarifying which features or connectivity patterns influence predictions, they foster greater trust in AI-assisted dementia diagnosis and support more transparent clinical decision-making.</p>
<p>Hybrid Explanations.</p>
<p>Disease mechanisms in dementia are often complex and multifactorial, which increases the need for transparent and explainable graph models that are critical for clinical adoption.Hybrid explanation approaches are seen as promising solutions because they combine multiple XAI techniques, such as saliency maps, causal inference, and feature attribution, to capture complementary aspects of a model's behavior.These approaches help researchers gain clearer insights by linking affected regions to human-based explanations [160] and identifying which regions contribute to model predictions.By integrating various XAI methods, hybrid explanations improve reliability and robustness, foster trust in AI systems, and provide deeper insights into underlying pathological processes.</p>
<p>4.1.4Emerging Trends.While many studies have explained key terms and concepts of XAI [26,142], more recent work has focused on classifying explanation quality based on the Co-12 properties: correctness, completeness, consistency, continuity, contrastivity, covariate complexity, compactness, composition, confidence, context, coherence, and controllability [123].Schwalbe et al. [142] proposed a unified taxonomy of XAI methods by conducting a systematic survey and offering a cohesive classification of each concept.In addition, there has been an increasing emphasis on causality, which emphasizes cause-effect relationships rather than correlations.Causality provides a deeper understanding of how input data influence outcomes and yields insights into causal relations in dementia studies [30,32].Although these are not fundamental XAI concepts, they play a crucial role in ensuring the effectiveness and adaptability of explainable models.</p>
<p>Definition Formulation</p>
<p>Constructing a brain graph begins with pre-processing and aligning MRI scans to a standard atlas for automated ROI segmentation, yielding a parcellation into  discrete regions.These regions serve as the graph's nodes and define its spatial resolution.In this survey, we examine brain data at three complementary levels, subjectspecific, population-level, and feature-level-each represented as an undirected graph  (‚Ñì ) = ( (‚Ñì ) ,  (‚Ñì ) ), with an associated adjacency matrix
ùê¥ (‚Ñì ) ‚àà R |ùëâ (‚Ñì ) | √ó |ùëâ (‚Ñì ) | and node feature matrix ùëã (‚Ñì ) ‚àà R |ùëâ (‚Ñì ) | √óùëë (‚Ñì ) .
At the subject-specific level (‚Ñì = ),  ( ) = {  }  =1 denotes anatomical or functional ROIs, and the adjacency matrix is defined as
ùê¥ (ùë† ) ùëñ ùëó = ùë§ ùëñ ùëó , if (ùë£ ùëñ , ùë£ ùëó ) ‚àà ùê∏ (ùë† ) 0, otherwise ,(2)
where    may represent tract strength from DTI or functional correlation from fMRI.Each node   is associated with a feature vector   ‚àà R  , such that  ( ) aggregates these row-wise.At the population level (‚Ñì = ),  ( ) = {  }  =1 represents individual subjects, and edges encode inter-subject similarity, for instance, via a Gaussian kernel on clinical measures.This yields an adjacency matrix  ( ) ‚àà R √ó and a subject feature matrix  ( ) ‚àà R √ó ‚Ä≤ .</p>
<p>At the feature level (‚Ñì =  ),  (  ) = {  }  =1 corresponds to imaging biomarkers, cognitive scores, or genetic markers.Edges in  (  ) reflect statistical dependencies, such as Pearson correlation or mutual information, resulting in  (  ) ‚àà R  √ó , with feature-level attributes captured in  ( ) ‚àà R  √ó ‚Ä≤‚Ä≤ .</p>
<p>To process these graphs, we employ GNNs, which define a parametric mapping
ùëì ùúÉ : (ùê¥, ùëã ) ‚Ü¶ ‚Üí ùëç,(3)
where  denotes either node-level embeddings or graph-level predictions.In the message-passing paradigm, each GNN layer  = 0, . . .,  ‚àí 1 updates node embeddings as follows:
‚Ñé (ùëô+1) ùë£ = ùõæ (ùëô ) ‚Ñé (ùëô ) ùë£ , ùë¢ ‚àà N (ùë£) ùúô (ùëô ) (‚Ñé (ùëô ) ùë£ , ‚Ñé (ùëô ) ùë¢ , ùê¥ ùë£ùë¢ ) ,(4)
where ‚Ñé (0)  =   , N () = { : (, ) ‚àà } denotes the neighbourhood of ,  ( ) is the learnable message function,  ( ) is the update function, and is a permutation-invariant aggregator (e.g., sum, mean, or max).After  layers, the final node embeddings {‚Ñé ()   }  ‚àà are obtained.For graph-level outputs, a readout operation is applied:
ùëß = READOUT({‚Ñé (ùêø) ùë£ }).(5)
To enhance interpretability, we incorporate an explanation framework.Let ≈∑ =   (,  ) denote the model's output.An explainer is defined as a function
ùúô : (ùê¥, ùëã, ùëì ùúÉ , ≈∑) ‚Ü¶ ‚Üí E,(6)
where the explanation object E may include node importance scores
ùëÜ ùëâ ‚àà [0, 1] |ùëâ | , edge importance scores ùëÜ ùê∏ ‚àà [0, 1] |ùê∏ | , or feature masks ùëÄ ‚àà [0, 1] |ùëâ | √óùëë .</p>
<p>Explanation Scope</p>
<p>The scope of explanation differentiates whether it addresses the reasoning behind specific predictions (local) or provides insight into the behaviour of the overall model (global).</p>
<p>In other words,  global is derived from both the entire dataset and the trained model, and provides a summarised understanding of model behaviour across all samples.For instance, global explanation methods can identify brain regions that are consistently important across the dataset by computing average importance scores, rather than focusing on individual patients.One approach involves reporting the frequency of selected features or highlighting the top-ranked brain regions across the cohort, as demonstrated in [196], which emphasises general patterns.Another example includes the use of average CAM to visualise brain regions and assess how each node, edge, or feature contributes to the predictions of   across all  samples [14].</p>
<p>Local Explanation.</p>
<p>Local explanation provides insights into individual patients and how a model arrives at its decision for a specific case.For a single graph instance   = (  ,   ,   ,   ) with model output ≈∑ =   (  ,   ), a local explanation is an object  local () ‚àà E local () produced by
ùúô local : (ùê¥ ùëñ , ùëã ùëñ , ùëì ùúÉ , ≈∑ùëñ ) ‚àí‚Üí ùê∏ local (ùëñ).(8)
Here,  local () may include per-node importance scores   (), per-edge scores   (), or a feature mask  (), and serves to explain why   made the prediction ≈∑ on the individual graph   .An example of a local explanation involves constructing subject-specific graphs to analyse discriminative information flows related to specific pathogenic factors [148], or interpreting predictions by comparing a patient's features to those of others from different diagnostic categories [83].</p>
<p>Explanation Method</p>
<p>The distinction between intrinsic and extrinsic explanations lies in whether interpretability mechanisms are integrated during model design (intrinsic) or applied post hoc after model training (extrinsic).</p>
<p>Intrinsic Explanation.</p>
<p>Intrinsic explanations, also known as ante-hoc or model-based explanations, are designed to be inherently interpretable while producing human-understandable representations.For instance, attention weights derived from an attentive pooling mechanism are assigned to different relation types based on the model's internal structure [83].Another example involves the use of gradient information to generate heatmaps that highlight salient brain regions and specific time points, thereby providing intrinsic interpretability through the model's own decision-making process [188].</p>
<p>Extrinsic</p>
<p>Explanation.Extrinsic explanations refer to methods used to interpret and clarify the predictions of black-box models after training has been completed.For example, in one study [57], GNNExplainer was applied post hoc to identify important brain ROIs, thereby serving as an extrinsic explanation.Another instance involves the use of gradient-based methods after model training to visualise salient brain regions [14].</p>
<p>Domain Applicability</p>
<p>This category distinguishes between explanations that are tailored to a specific model architecture (specific) and those that are applicable across a range of models (agnostic).4.5.1 Model-Specific Explanation.These explanations are specific to individual models and their architectures, and therefore lack generalisability.For instance, in [43,177], the explainability is inherently tied to the model architecture itself.In particular, [177] employs contrastive pooling with a dual attention mechanism to facilitate interpretability in brain classification tasks.4.5.2Model-Agnostic Explanation.These explanations are universally applicable, regardless of the model's internal architecture.They can be employed to interpret arbitrary models without being constrained to a specific model type.Shapley Additive Explanations are model-agnostic, allowing their application across a wide range of models [187].</p>
<p>Mode of Explanation</p>
<p>The mode of explanation refers to the type of explanation generated by an explanation method.Among the reviewed approaches, explanations are typically presented in three forms: visual (e.g., heatmaps, saliency maps, or CAM), cognitive score-based, and example-based.While these categories are conceptually distinct, they often overlap in practice.For instance, a visual explanation may be paired with an example-based explanation to illustrate how the model utilises specific brain regions in its prediction while providing a human-readable rationale [83].Similarly, score-based explanations can be integrated with visual approaches by highlighting high-scoring ROIs to support disease identification [43,110].</p>
<p>4.6.1 Visual explanation.An explanation method that employs visual techniques illustrates where, how, and what the model attends to when making decisions.For instance, the study in [43] projected clusters onto the cortical surface of the brain to highlight regions associated with AD.Similarly, [188] applied saliency heatmaps to reveal which brain areas were most relevant for distinguishing between MCI and healthy individuals.4.6.2Score-based explanation.Scope-based explanations assign numerical values to features (i.e., brain regions) to reflect their importance or contribution to the model's performance.In [43], Grad-CAM was used to generate numerical importance values for each brain region, which were subsequently ranked to determine their potential as biomarkers.Similarly, [194] introduced a method in which importance probabilities were learned during model training to quantify each feature's contribution to decision-making, thereby facilitating the identification of potential imaging and genetic biomarkers.In [187], SHAP scores were employed to evaluate feature informativeness for disease classification.Features such as education level and APOE status were assigned high importance scores, highlighting their roles as risk factors in the identification of AD.</p>
<p>4.6.3</p>
<p>Example-based explanation.This type of explanation interprets the model's decision-making process through specific instances (examples), illustrating how the model responds to changes in input.For instance, [83] employs example-based explanations to elucidate the model's behaviour and demonstrate how it captures complex relationships between patients.Another application involves example-based explanations at the group level, highlighting significant regions or genes that contribute to disease classification [148].</p>
<p>Mild Cognitive Impairment</p>
<p>Recent studies on MCI have increasingly focused on identifying predictive markers and developing early diagnostic frameworks to account for its heterogeneous progression.While clinically recognized as a prodromal stage, MCI encompasses a wide spectrum of cognitive presentations and trajectories.This variability has led to a growing body of longitudinal studies exploring individual-level factors, such as baseline cognitive profiles, neuroimaging biomarkers, and genetic predisposition, that influence conversion rates to dementia [79].Figure 4 illustrates the clinical progression from MCI to dementia, highlighting the preclinical stage, the onset of mild symptoms, and the gradual decline leading to severe dementia.</p>
<p>Advanced neuroimaging techniques, including sMRI, fMRI, and PET imaging, have been employed to investigate network-level dysfunctions and regional brain changes associated with both aMCI and naMCI subtypes.These studies suggest that alterations in connectivity patterns, particularly within the default mode, salience, and executive control networks, may serve as early indicators of disease progression [101,133].The integration of imaging data with clinical and neuropsychological assessments is therefore critical for improving diagnostic accuracy and patient stratification.Moreover, data-driven methods such as graph-based models have emerged as promising tools for capturing the subtle and complex brain changes associated with MCI.Such approaches enable the modeling of inter-regional connectivity and can aid in distinguishing between stable MCI, progressive MCI, and normal aging.Importantly, explainable models are beginning to shed light on which features or brain regions are most relevant for predicting outcomes, thereby contributing to personalized and targeted intervention strategies.A summary of key studies incorporating multimodal data and computational frameworks for MCI classification is presented in Table 1.</p>
<p>Non-Amnestic MCI</p>
<p>In the context of naMCI, Liu et al. [103] proposed a multi-scale atlas-based GCN to predict cognitive outcomes in individuals with subcortical ischaemic vascular disease (SIVD), a recognized precursor of vascular dementia (VaD).The model constructs individualized brain networks from fMRI data and integrates multi-scale brain parcellation to capture hierarchical representations of brain connectivity, achieving an accuracy of 80.4% in differentiating naMCI from aMCI.To enhance interpretability, the authors employed GradCAM, a widely used post-hoc explainability technique, which provided intuitive visual explanations.Their analysis revealed that the limbic network was a key predictor for aMCI in the context of SIVD, whereas the salience and default mode networks were associated with non-cognitive impairment.These findings align with existing evidence linking vascular cognitive impairment to disruptions in the limbic network, underscoring both the model's explainability and its clinical relevance in supporting VaD diagnosis.</p>
<p>Amnestic MCI</p>
<p>Post-Hoc Explanation.</p>
<p>Studies have extensively focused on aMCI using XGNN techniques, employing both gradient-based and perturbation-based post-hoc methods.Zhang et al. [188] applied a spatiotemporal GCN combined with GradCAM on fMRI data to capture dynamic interactions across brain regions, highlighting critical areas such as the paracentral lobule, inferior occipital gyrus, and superior temporal gyrus.Guo et al. [60] introduced a region-dependent graph attention convolution on brain morphable meshes, achieving an accuracy of 82.6% in distinguishing early from late MCI.GradCAM visualizations emphasized subcortical structures such as the hippocampus, amygdala, and thalamus as pivotal for classification.He et al. [63] proposed a multimodal GCN integrating resting-state fMRI data with predictive coding, Granger causality, and sparse representation, reaching 92.2% accuracy and an AUC of 0.98 on the ADNI dataset, and identifying the precuneus, supplementary motor cortex, and cuneus as key regions.Saliency-based approaches have also been employed to classify MCI and elucidate the pathological basis of AD and its subtypes.Bi et al. [21] developed a feature aggregation GCN to model brain-gene interactions via node-to-node feature aggregation.Saliency analysis highlighted the hippocampus, superior and middle occipital gyri as critical regions, and identified LRP1B and CNTN5 as key genes associated with AD diagnosis.Built-in interpretability has further gained attention; for example, Zeng et al. [186] designed a two-phase GCN that addressed training set bias and provided real-time interpretability, although with modest accuracy (68.4%) in distinguishing stable (MCIn) from progressive MCI (MCIp).</p>
<p>GNNExplainer has been widely adopted to enhance interpretability in early AD and MCI studies.Kim et al. [84] applied GNNExplainer to a GCN integrating demographic, genetic, and neuroimaging features, predicting A positivity with an AUC of 0.86.A positivity, a crucial biomarker in AD, was linked to specific subgraphs and node attributes, with cortical thickness and APOE-4 status identified as dominant features in cognitively unimpaired individuals.Importantly, biomarker contributions varied across age groups: older cohorts prioritized amyloid PET uptake, whereas younger groups relied more on FDG-PET metabolic rates.Song et al. [154] proposed an auto-metric GNN using genetic and multimodal imaging data, achieving 94% accuracy in AD diagnosis and 87% in predicting MCI conversion.GNNExplainer highlighted the hippocampus, entorhinal cortex, and middle temporal lobe as key discriminative regions.Similarly, Gao et al. [57] applied GNNExplainer on a GNN trained with ADNI data, identifying alterations in the hippocampus, amygdala, and parahippocampal gyrus.5.2.2 Self Explanation.Self-explainable methods are designed such that interpretability is inherently embedded within the model architecture.These models generate both predictions and explanations during inference, typically by enforcing constraints such as attention mechanisms, disentangled representations, or sparse message passing.In the context of MCI and early AD, attention-based mechanisms have been particularly effective in enhancing classification performance while providing insights into disease-relevant brain regions.</p>
<p>Cai et al. [29] proposed a hypergraph GNN that integrated amyloid-PET and FDG-PET imaging to capture higher-order interactions.Qualitative analysis of hyperedges revealed recurrent propagation patterns involving key regions such as the hippocampus and parahippocampal gyrus, consistent with established AD pathology.Ma et al. [111] introduced a multi-graph cross-attention-based, region-aware fusion network that dynamically weighted heterogeneous features from multiple modalities, improving interpretability and highlighting critical temporal, frontal, and parietal regions.Bi et al. [20] advanced AD diagnosis through imaging-genetics fusion, achieving 91.5% accuracy for MCI vs. HC classification and 88.3% for brain-gene associations, with the hippocampus and entorhinal cortex identified as key biomarkers.Shang et al. [148] further developed a graph capsule convolutional network (GCCN) to predict MCI-to-AD conversion, where capsule mechanisms captured hierarchical relationships between imaging and genetic features, supporting more effective early intervention strategies.</p>
<p>Discussion</p>
<p>Early diagnosis remains a central priority in dementia research, as timely detection enables more effective clinical management and intervention strategies.Gradient-based methods such as GradCAM and model-agnostic techniques like GNNExplainer have been widely applied to aMCI, offering intuitive visual explanations and highlighting disease-relevant brain regions.In parallel, S-XAI methods demonstrate strong potential in leveraging longitudinal and multimodal data to provide inherently interpretable insights.Nevertheless, naMCI remains comparatively underexplored, highlighting the need for more targeted models that address the heterogeneity of clinically relevant subtypes.Future research directions should include advancing multimodal fusion frameworks, improving generalisability across diverse cohorts, and establishing standardised benchmarks for fair evaluation.Moreover, the refinement of explainability techniques, with validation from clinical domain experts, is essential to ensure not only methodological robustness but also trustworthiness and applicability in real-world healthcare settings.</p>
<p>Alzheimer's Disease</p>
<p>AD is the most common cause of dementia, accounting for more than half of all cases and predominantly affecting individuals over the age of 60.It is clinically characterised by progressive cognitive decline, memory impairment, and behavioural disturbances [176,179].As the disease advances, patients gradually lose independence and become increasingly reliant on assistance with daily activities.Although no curative treatment exists, pharmacological interventions can alleviate symptoms and provide temporary relief [24].In the context of AD diagnosis and progression monitoring, recent advances have employed XGNN models to improve both diagnostic accuracy and interpretability.These models enable the identification of disease-relevant brain regions and biomarkers, offering greater transparency in clinical decision-making.Table 2 summarises representative studies that integrate neuroimaging, clinical, demographic, and genetic data into graph-based frameworks, alongside XAI techniques, for AD classification and prediction.For clarity, explainable GNN approaches for AD are organised into three main categories: post-hoc methods, self-explainable methods, and hybrid approaches.This taxonomy provides a structured basis for evaluating how different explanation strategies contribute to enhancing the reliability and clinical utility of AD diagnosis.</p>
<p>Post-Hoc Explanation</p>
<p>Post-hoc explainable methods aim to interpret the predictions of trained GNN models after learning is complete.These approaches treat the model as a black box and apply external techniques, such as feature attribution (e.g., GNNExplainer), node importance ranking, or visualisation-to identify the input features, nodes, or subgraphs that most influenced a specific prediction.In the context of AD, post-hoc methods help clinicians understand which brain regions or connectivity patterns are critical for diagnosis without altering the underlying GNN architecture.</p>
<p>Several gradient-based methods have been employed to interpret brain connectivity in AD.Grad-CAM has been widely used with GCNs to highlight salient brain regions, although implementations vary across imaging modalities, graph structures, and architectures.For example, Azcona et al. [14] applied Grad-CAM to sMRI-based GCNs using cortical and subcortical triangular meshes, identifying atrophy in the inferior parietal lobule and the intermediate sulcus of Jensen.Zhang et al. [189] constructed FC networks from rs-fMRI and highlighted the DMN, sensorimotor network (SN), and visual network (VN) as biomarkers, alongside topological features mediating amyloid- and glucose metabolism.Liu et al. [104] proposed a hierarchical GCN based on multiscale FC networks from fMRI, identifying the LIM and DMN as discriminative regions.Zhou et al. [192] integrated multimodal imaging into an interpretable GCN framework for AD classification, with Grad-CAM emphasising the putamen and pallidum as biomarkers associated with cognitive scores such as the MMSE and Pearson correlation.</p>
<p>Guided backpropagation (GBP) has also been applied to highlight positively contributing input features by modifying gradient flow.Dolci et al. [46] combined sMRI, fMRI, and dMRI within a multimodal GCN to classify amyloid- (A) status, achieving 76.2% accuracy.GBP identified the hippocampus and thalamus as relevant to amyloid deposition, while highlighting modality-specific networks, including the default mode, cingulo-opercular, visual, and somatomotor networks (fMRI), as well as the frontal, parietal, and temporal lobes (dMRI).These results underscore the value of modality-aware interpretation for uncovering unknown A deposition patterns.</p>
<p>Perturbation-based methods such as SHAP have provided both global and local interpretability in AD studies, explaining node-level and clinical predictors.Wang et al. [173] applied SHAP within a dual multi-task GIN (DMT-GIN), achieving 90% accuracy and identifying the precentral and middle frontal gyri as key regions.Zhang et al. [187] used SHAP with an auto-fusion GCN, reaching 97.8% accuracy (HC vs. AD) and 96.56% (AD vs.MCI vs. HC), and identifying education and the Cogstate Brief Battery as the most influential predictors.</p>
<p>GNNExplainer has been employed to enhance interpretability by extracting subgraphs and node features that drive predictions.Gamgam et al. [56] applied GNNExplainer to a Siamese GCN using dMRI and rs-fMRI, identifying cortical regions contributing to structural and functional disruptions in AD progression, particularly in subjective cognitive impairment (SCI).Although GNNExplainer is model-agnostic, its use within a Siamese GCN highlights how tailored architectures can improve the clinical relevance of extracted explanations.</p>
<p>In summary, post-hoc methods are flexible and widely applicable, as they can be used with any pre-trained GNN without modifying its architecture.They are especially valuable when interpretability is needed after deployment.However, because they infer explanations indirectly, their outputs may not faithfully reflect a model's internal reasoning [112], raising concerns about misleading or inconsistent insights in high-stakes domains such as AD diagnosis.</p>
<p>Self Explanation</p>
<p>In the context of AD diagnosis, self-explainable GNNs highlight key brain sub-networks through interpretable attention weights, providing direct insight into disease biomarkers as part of the predictive process.This built-in interpretability is crucial for fostering trust among clinical experts, as it intrinsically validates and explains model outputs.</p>
<p>Several studies have introduced self-explainable architectures tailored to AD. Sihag et al. [150] proposed an explanation-driven covariance neural network (VNN), operating on sample covariance matrices of cortical thickness features to predict brain age.Tong et al. [162] integrated SC-FC brain network features with transfer learning to analyse FC impairments, while Klepl et al. [85] employed a gated GCN using EEG power spectral density, with graph structure learning and pooling modules for interpretable AD prediction.Attention mechanisms, first introduced by Vaswani et al. [165], have been widely adopted to learn the importance of brain connections.For example, Cai et al. [28] applied a graph transformer using multimodal MRI for brain age prediction, incorporating attention scores to assess modality influence.Xiao et al. [175] developed a dual graph convolutional network that achieved over 80% diagnostic accuracy while identifying the hippocampus and frontal white matter as biomarkers.Similarly, Kim et al. [83] introduced HetMed, a heterogeneous graph learning model with attentive pooling that highlighted clinically relevant variables such as cognitive scores, reaching Macro-F1 scores of 0.774 and 0.813 on ADNI and OASIS-3 datasets.</p>
<p>Other interpretable approaches extend beyond attention-based mechanisms.Sparse GCNs [193], attention-based fusion models [88], and spatiotemporal architectures [64,178] have demonstrated improved feature extraction and highlighted key regions such as the hippocampus, precuneus, and amygdala.Song and Yoshida [153] developed a temporal graphormer that captured disease-related FC patterns with enhanced interpretability.At the same time, studies by Bi et al. [19], Zhu et al. [196], Nguyen et al. [126], and Song et al. [155] advanced feature-and instance-level explanations, uncovering meaningful imaging-genetic associations and providing patient-specific feature attribution.Li et al. [95] further extended this by ranking influential features across cohorts to support personalised diagnostic insights.</p>
<p>In summary, self-explainable methods embed interpretability directly into the model architecture, offering more transparent and faithful explanations compared to post-hoc techniques.This integration not only fosters clinical trust but may also improve generalisability by incorporating sparsity or attention constraints [58].However, designing such models remains challenging, often involving trade-offs in model capacity and flexibility [106].</p>
<p>Hybrid Explanation</p>
<p>Hybrid explanations have been increasingly employed to enhance trust and robustness in Alzheimer's disease (AD) research by integrating multiple XAI techniques and addressing distinct aspects of disease progression.These methods combine built-in interpretability features with external post-hoc explanations, thereby improving transparency and validating model behaviour.In practice, hybrid GNNs often leverage attention mechanisms during training while applying additional explanation tools such as saliency or SHAP after training, providing both intrinsic and extrinsic interpretability.</p>
<p>Several studies have demonstrated the value of hybrid approaches.Lei et al. [93] combined saliency and CAM within a dual multilevel GNN using sMRI, genetic, and protein data, achieving 87.6% accuracy.Their model identified the inferior temporal gyrus, hippocampus, and amygdala as key regions, while canonical correlation analysis revealed risk factor correlations between 0.801 and 0.821.Tekkesinoglu and Pudas et al. [160] applied decomposition-based XAI to a GCN framework, integrating neurocognitive, genetic, and brain atrophy markers.Their approach outperformed SHAP in individual patient classification, with 71% expert validation and interpretability ratings above six.Dai et al. [43] proposed Graph-VCNet, which integrates GCNs with counterfactual causal inference on sMRI data to investigate the impact of A accumulation.Their model achieved 84% classification accuracy while enabling personalised treatment prediction and providing causal insights into disease pathways.</p>
<p>Overall, hybrid methods balance interpretability and performance by combining intrinsic explainability with post-hoc interpretive tools.They provide more comprehensive insights into model decisions and are particularly valuable for complex medical applications.However, they also inherit limitations from both paradigms, including increased model complexity and computational overhead [96].Reconciling potentially conflicting explanation outputs further introduces challenges related to consistency and interpretive reliability.</p>
<p>Discussion</p>
<p>Research on AD has demonstrated the effectiveness of XGNNs in identifying biomarkers and dysfunctional brain connectivity.Among post-hoc methods, SHAP and Grad-CAM are the most widely adopted, offering flexibility and the ability to explain GNN predictions in both spatial and feature domains.Attention-based approaches also provide effective visual explanations with competitive diagnostic performance.Hybrid methods, by combining intrinsic and extrinsic techniques, show strong potential for developing clinically grounded and human-understandable pipelines; however, only one study [160] has validated explanations using correctness as a formal evaluation metric.</p>
<p>A key limitation in the current literature is the lack of consistent evaluation measures.Most studies report conventional performance metrics such as accuracy or AUC, but these do not capture the clinical interpretability or quality of the generated explanations.To advance the field, the selection of XAI techniques should be closely aligned with task-specific objectives, whether the focus is on visualizing ROIs, identifying biomarkers, modeling population-level patterns, or supporting personalized diagnosis.Integrating multiple explanation methods and adopting standardized evaluation metrics for explanation quality will yield more trustworthy insights and facilitate broader clinical adoption.</p>
<p>Parkinson's Disease</p>
<p>Building on the clinical understanding of PDD, recent studies have increasingly investigated the disorder through neuroimaging and computational modelling.Given the distributed network-level degeneration observed in PDD, graph-based representations of brain connectivity provide a compelling framework for disease characterization and diagnosis.These methods leverage sMRI and fMRI data to construct brain graphs that capture disruptions in cortico-subcortical and heteromodal networks implicated in both motor and cognitive symptoms.The reported prevalence of PDD varies widely, ranging from 24% to 90%, depending on disease duration, cohort characteristics, and diagnostic criteria [1,2,161].Moreover, PD shares pathophysiological features with LBD, particularly disruptions in the cerebral cortex, motivating integrative approaches across related disorders [87].In clinical practice, PDD is frequently associated with neuropsychiatric symptoms such as hallucinations, cognitive fluctuations, and sleep or mood disturbances [68], which may further correlate with disruptions in specific brain regions detectable via neuroimaging.Consequently, multimodal datasets incorporating imaging, clinical scores, demographic profiles, and in some cases genetic information, have been employed to improve classification accuracy and subtype differentiation.Recent GNN research has begun integrating XAI techniques to enhance interpretability, enabling the identification of salient brain regions and network features contributing to model predictions.Table 3 summarises studies that employ these advanced computational approaches for PD diagnosis and progression prediction.</p>
<p>Post-Hoc Explanation</p>
<p>In the context of post-hoc explanation, several studies have employed saliency-based approaches to visualize SC-FC regions in the diagnosis of PD.Nerrise et al. [124] proposed an explainable geometric-weighted GAT operating on SPD matrices within a Riemannian manifold, achieving an F1-score of 76% and an AUC of 0.83 for gait severity diagnosis.Their model highlighted the involvement of the sensorimotor, salience, and visual networks.Huang et al. [69] developed a multi-task graph structure learning framework for early PD identification, reporting 95% accuracy.Saliency maps revealed key regions including the hippocampus, precentral gyrus, supplementary motor area, and insula.Zhao et al. [190] applied GNNs to voice-related EEG data for PD diagnosis, attaining</p>
<p>Discussion</p>
<p>In PD, saliency-based methods remain a dominant area of research due to their ease of integration and ability to provide visual explanations.For biomarker identification and understanding dynamic feature learning, S-XAI methods demonstrate significant promise, often balancing predictive performance with interpretability.Hybrid approaches, which combine multiple methods and incorporate causal inference, offer a more holistic understanding of disease progression, enabling more nuanced clinical insights.</p>
<p>Multi-Disease Diagnosis</p>
<p>Recent studies have demonstrated the potential of XGNNs in distinguishing between different aetiologies of dementia.The ability to discriminate among subtypes such as AD, PD, and FTD is critical, as it enables accurate diagnosis and informed treatment planning.By integrating multimodal data (e.g., MRI, fMRI, EEG), recent work has evaluated multiple dementia subtypes and elucidated their distinct brain network patterns.Such multi-disease analyses contribute to the development of more robust and interpretable GNN models that facilitate differential diagnosis, while also providing insights into the underlying pathophysiology of each condition.By capturing these distinctions, XGNNs enhance diagnostic accuracy and support neurobiological interpretation of dementia subtypes.An overview of recent multi-disease XGNN studies is presented in Table 4.</p>
<p>Evaluating AD and FTD</p>
<p>In efforts to distinguish AD from FTD, studies have employed neuroimaging-based GNN frameworks to detect disease-specific patterns.Nguyen et al. [125] proposed a deep grading framework that combines GCN with sMRI for both disease detection and differential diagnosis.Their model achieved 90.5% accuracy in differentiating dementia patients from HC, as well as in multi-class classification of AD vs. FTD vs. HC.The learned grading maps highlighted hippocampal abnormalities as salient in AD and ventromedial frontal cortex atrophy in FTD, consistent with known hallmarks of each disorder.These localized atrophy patterns provided clinicians with visual explanations of the model's decisions.Similarly, Wang et al. [170] developed a GNN incorporating selfattention and feature selection to analyze global brain-region interactions from MRI data.Their model identified significant atrophy in the amygdala, precentral gyrus, and parahippocampal gyrus in both AD and FTD compared to HC, underscoring these regions' relevance in distinguishing the two dementias.The attention weights further served as interpretive cues, highlighting brain regions most influential to the model's predictions.Together, these approaches underscore the utility of brain network-based methods for differential diagnosis.By building on these insights, XGNN models not only achieve high accuracy in classifying AD and FTD but also reveal disorder-specific network disruptions, offering clinically valuable interpretability.</p>
<p>Evaluating AD and PD</p>
<p>Distinguishing AD from PD is another important multi-disease application, as PD patients can develop cognitive impairments that may be mistaken for AD.Cao et al. [31] [177] introduced ContrastPool, a contrastive graph pooling method for classifying brain networks from rs-fMRI data across AD and PD cohorts.To address challenges such as low signal-to-noise ratios and small sample sizes, the model applied dual attention mechanisms at both ROI and subject levels.By contrasting patient and control groups during pooling, ContrastPool highlighted the most discriminative regions.It outperformed 21 state-of-the-art GNN and machine learning models, with accuracies of 67.8% on ADNI (AD vs.MCI vs. CN), 64.0% on PPMI (early PD vs. controls), and 77.5% and 75.0% on the Taowu and Neurocon PD datasets, respectively.Although these accuracies were lower-reflecting the difficulty of multi-class and multi-cohort fMRI classification-the model's interpretability was a key advantage.The posterior cingulate and precuneus were highlighted as critical in AD, while the temporal cortex was emphasised in PD, aligning with clinical evidence.Le et al. [91] proposed BrainMAP, a multimodal GCN framework that integrates fMRI and DTI through atlas-guided subgraph filtering and attention-gated fusion.The model achieved strong performance on ADNI (82.3%) and PPMI (86.2%) while maintaining low computational cost.Also, BrainMAP localized disease-relevant ROIs such as subcortical and limbic regions, providing clinically meaningful explainability in AD and PD.</p>
<p>Collectively, these studies demonstrate that XGNNs can detect subtle connectivity differences in noisy EEG and fMRI data and present them in an interpretable manner, thereby supporting differential diagnosis between a primarily cognitive disorder (AD) and a movement disorder (PD) with overlapping dementia-related symptoms.</p>
<p>Evaluating Amnestic MCI and PD</p>
<p>Beyond classic dementia diagnoses, XGNNs have also been applied to distinguish amnestic MCI (aMCI), often considered a prodromal stage of AD, from PD.This comparison is clinically valuable, as both MCI and early PD can present with mild cognitive changes.Yang et al. [180] proposed a Multimodal Dynamic GCN (MDGCN) to jointly capture SC and FC patterns from MRI and DTI data.The model employs a bilateral GCN architecture with a correspondence matrix to dynamically fuse intermodal information, linking structural and functional brain networks at the individual level.This approach accounts for disorder-specific differences in SC-FC coupling and outperformed static and unimodal baselines in classifying MCI, PD, and healthy controls.Attention-weight analysis further revealed distinct network involvement: the right posterior cingulate gyrus within the DMN emerged as a key discriminator for MCI, whereas the left somatomotor cortex was most indicative of PD.By dynamically integrating multimodal data, the MDGCN provided interpretable mappings of divergent structure-function relationships across disorders.</p>
<p>Building on multimodal fusion, Guo et al. [61] introduced a Graph-Based Fusion (GBF) framework that integrates imaging, genetic, and clinical data.The model incorporates an imaging-genetic fusion module with attention mechanisms and a multi-graph GCN for final classification.Applied to a dataset of MCI, PD, and controls, the GBF achieved 84.8% accuracy for MCI and 78.3% for PD, outperforming single-modality baselines.Attention-weight visualisation yielded biologically meaningful insights: top brain regions for MCI included the rostral middle frontal gyrus, superior frontal gyrus, inferior parietal lobule, and fusiform gyrus-areas implicated in early AD-related decline.For PD, key regions included the rostral anterior cingulate, superior temporal gyrus, superior frontal gyrus, and inferior parietal lobule.Notably, the inferior parietal lobule was salient in both groups, suggesting it may serve as a shared locus of neurodegeneration in early cognitive impairment.These findings reinforce the validity of the model's predictions by highlighting regions consistent with known MCIand PD-related pathology.</p>
<p>Discussion</p>
<p>The reviewed studies underscore that attention-based GNN architectures are particularly well suited for classifying neurodegenerative disorders, owing to their ability to learn node-level and region-specific importance.A consistent trend is the benefit of modality fusion in multi-disease models.Integrating data from functional and structural imaging, electrophysiology, genetics, and clinical measures often yields more robust classifiers than those based on a single modality.The success of Guo et al.'s [61] imaging-genetic-clinical fusion and Yang et al.'s [180] SC-FC dual GCN demonstrates that cross-domain brain network integration enhances model robustness and captures complementary disease signatures.</p>
<p>At the same time, these complex architectures highlight the importance of effective feature selection and alignment.Techniques such as correspondence matrices to link modalities or attention mechanisms to weight modality contributions are critical for mitigating noise and redundancy.As multi-centre datasets are increasingly leveraged to improve sample size, performance fluctuations across cohorts have become apparent.This underscores the necessity of domain adaptation and data harmonisation in multi-site studies.For instance, a model trained on ADNI MRI data may fail to generalise to another cohort because of differences in scanner characteristics or demographic distributions, which can lead to reduced accuracy.Overall, there is a clear shift toward explainable multimodal graph models of the brain, representing an important step toward actionable AI in clinical practice.An explainable model not only predicts, for example, "this patient likely has FTD," but also provides a neurobiological rationale, such as "because frontal and anterior temporal network connectivity is severely disrupted, whereas hippocampal connectivity is relatively preserved." Such interpretability directly supports differential diagnosis and enhances clinical decision-making.</p>
<p>Public Datasets for Dementia Research</p>
<p>Among the most widely used large-scale imaging datasets for dementia research are ADNI, OASIS, AIBL, MIRIAD, NIFD, and PPMI, each providing unique strengths for investigating neurodegenerative disorders.ADNI remains a cornerstone in Alzheimer's research, offering multimodal imaging, including structural and functional MRI together with longitudinal data that track progression from healthy controls to AD. OASIS complements this resource by providing both cross-sectional and longitudinal MRI scans, as well as clinical assessments of older adults with varying degrees of cognitive decline.Alzheimer's Disease and progression [14], [192], [104], [189], [46], [173], [187], [43], [93], [160], [150], [162], [110], [28], [175], [193], [88], [134], [178], [64], [153], [194], [76], [95], [196], [126], [19], [155], [188], [60], [63], [33], [84], [57], [21], [186], [29], [111], [20], [148], [125], [170], [177], [61], [180] Open Access Series of Imaging Studies (OASIS) [89] Structural MRI Aging, dementia, and brain structure [104], [150], [126], [155], [83], [125] Australian Imaging, Biomarkers &amp; Lifestyle (AIBL) [50] MRI, PET, Cognitive Testing Alzheimer's Disease and risk factors [126], [155], [125] Minimal Interval Resonance Imaging in Alzheimer's Disease (MIRIAD) [115] Structural MRI Alzheimer's Disease progression [126], [125] Alzheimer Neuroimaging in Frontotemporal Dementia (NIFD) [86] MRI, PET, Genetic Data, Clinical Assessments</p>
<p>Frontotemporal dementia and related disorders [125], [170] Building on these foundations, AIBL and MIRIAD incorporate PET and MRI together with genetic data, fluid biomarkers, and cognitive testing, enabling a more comprehensive investigation of AD-related risk factors.Beyond Alzheimer's disease, the NIFD dataset focuses on FTD, a less prevalent but clinically important subtype characterized by early-onset neurodegeneration.NIFD includes structural and functional imaging, genetic profiles, and clinical measures to support research into FTD progression.For Parkinson's disease, the PPMI dataset has become a key benchmark, offering sMRI, DTI, and fluid biomarkers to facilitate understanding of PD pathology.</p>
<p>The key characteristics of these datasets, including imaging modalities, targeted disease subtypes, and representative references, are summarised in Table 5.</p>
<p>Open Challenges and Outlook</p>
<p>Despite notable progress in diagnosing dementia subtypes, several open research questions remain that must be addressed to ensure the effective integration of these technologies into clinical practice.In this section, we outline key remaining challenges and present our perspectives on future directions.</p>
<p>Explainability Challenges in GNNs</p>
<p>Current benchmarks in graph neural networks lack standardised experimental settings and consistent evaluation measures [49].While explainability plays a crucial role in building trust in AI systems, only one study [160] has incorporated correctness as an explainability metric, underscoring the need for robust, quantitative measures.Approaches like Factor Graph-based Interpretable Neural Networks [98] exemplify self-explainable architectures, highlighting the potential for intrinsic explainability in GNNs.Future research should prioritise the development of standardised explainability protocols to ensure reliability.</p>
<p>Dynamic GNNs also face significant hurdles.Although spatiotemporal approaches such as temporal attention or graph saliency are increasingly applied to fMRI and EEG data to capture disease-relevant patterns [149,189], they are computationally intensive and often lack intuitive interpretability for clinicians.A particular gap lies in temporal explainability, specifically identifying when certain brain regions contribute most to predictions.Similarly, multimodal integration and nonlinear interactions remain problematic.While structural and functional connectivity fusion can capture complementary aspects of brain alterations, it remains unclear which modality drives specific predictions.XAI tools such as GNNExplainer and SHAP can highlight important nodes and edges, but their outputs are often too abstract for clinical interpretation, limiting their applicability in real-world decisionmaking.Addressing these issues will require modality-specific attribution methods and clinically meaningful explanations.</p>
<p>Causal Explanations</p>
<p>GNNs primarily yield correlation-based functional connectivity, which limits interpretability and actionable insights.The inherent characteristics of neuroimaging data, such as the lack of controlled interventions and the presence of complex dynamic interactions, make it particularly difficult to distinguish causality from correlation.Although some studies have begun integrating causal inference with GNNs [43,53,54,159], this area remains underdeveloped and computationally demanding, requiring further validation.Progress in this direction is essential to enable GNNs to provide meaningful causal explanations of brain connectivity.</p>
<p>Neuroimaging Complexity and Patient Heterogeneity</p>
<p>Neuroimaging reveals substantial heterogeneity across dementia subtypes and individual patients.Biomarkers such as hippocampal atrophy or DMN disruptions vary between dementia types and often overlap, complicating decision boundaries in GNNs.This underscores the importance of explainability to ensure that model decisions align with established anatomical and clinical markers.Moreover, diseases such as AD and PD exhibit considerable inter-subject variability, with some patients primarily driven by A pathology while others show tau or vascular abnormalities.Current models often fail to capture this diversity in patient-specific explanations.Although clustering-based methods [84] can stratify patients, they frequently lack interpretable associations with underlying neural mechanisms, while approaches such as SEHG [70] offer self-explainable GNNs that jointly optimise predictions and explanations.Future work should contextualise individual disease trajectories in light of known heterogeneity.</p>
<p>Scalability and Performance Issues</p>
<p>Explaining GNN predictions for large graphs remains computationally intensive due to operations such as subgraph sampling and methods like GNNExplainer.As graph size increases, computational costs escalate significantly, limiting real-time applicability [131].In sparse graphs, explanation faithfulness has been shown to decline by 59.9% on large datasets [4].Mitigating bias, addressing sparsity, and improving scalability are therefore essential to develop more robust and generalisable models.</p>
<p>Domain-Specific Needs</p>
<p>Generic XAI techniques often generate subgraphs or feature scores that fail to align with domain knowledge in neuroscience, reducing clinical trust.For instance, distinguishing causal mechanisms from correlations in brain connectivity remains challenging.Domain-specific models and explainers are needed to provide clinically relevant and biologically plausible explanations, thereby ensuring trustworthiness in medical contexts.</p>
<p>LLMs in Model-Level Explanations</p>
<p>Recently, studies have begun exploring the integration of large language models (LLMs) with XGNNs, as LLMs can support model-level explanations and contribute to early detection and diagnosis of dementia [96].Although still in its early stages, this line of research highlights the importance of generating clinically valid, interpretable narratives.For example, Lee et al. [92] combined speech transcription with graph-based vision models to enhance dementia diagnosis, Hu et al. [67] employed a variational regularised encoder-decoder GNN for AD risk estimation with relation importance mechanisms, and Arriba-P√©rez et al. [45] used LLMs to analyse patient dialogue for detecting early cognitive decline.These studies illustrate the promise of combining GNN reasoning with natural language explanations to improve clinical adoption.Overall, addressing these challenges, including standardisation, temporal and multimodal interpretability, causal reasoning, patient heterogeneity, scalability, domain alignment, and the integration of LLMs, will be critical for advancing explainable graph models in dementia research and ensuring their adoption in clinical practice.</p>
<p>Conclusion</p>
<p>Explainable graph neural networks (XGNNs) offer a transformative opportunity to bridge the gap between advanced machine learning methodologies and clinical applicability in dementia research.By modeling the brain as a network and integrating multimodal data, XGNNs provide powerful tools for detecting disease-relevant biomarkers, characterizing subtype-specific connectivity patterns, and supporting differential diagnosis.The interpretability enabled by these models helps overcome key barriers to trust and adoption in healthcare, allowing clinicians to better understand how predictions are generated and how they relate to neuropathology.In this review, we presented a taxonomy of XGNN techniques employed in dementia studies, organized according to their explanation parameters, and examined their applications across various dementia subtypes.We also identified major open challenges, including the lack of standardized evaluation metrics, difficulties in temporal and multimodal interpretability, limited progress in causal reasoning, patient heterogeneity, scalability constraints, and the need for domain-specific alignment.Emerging directions such as the integration of large language models (LLMs) further highlight the evolving landscape of explainable graph-based frameworks.Future research should focus on establishing rigorous evaluation protocols to ensure that XGNN-generated explanations are technically robust and ethically sound.By advancing methods that provide causal and clinically meaningful insights, explainable graph models hold the potential to transform dementia diagnosis and prognosis, enabling earlier detection, more accurate subtype differentiation, and ultimately more personalized therapeutic strategies.</p>
<p>Fig. 1 .
1
Fig. 1.Visual representation of the XGNN framework used in studies.</p>
<p>Fig. 2 .
2
Fig. 2. Brain regions affected across dementia subtypes.Each icon represents a specific subtype of dementia, and icons adjacent to a brain region indicate that the corresponding condition impacts the region.</p>
<p>Fig. 3 .
3
Fig. 3.The taxonomy of the XAI methods in dementia research.</p>
<ol>
<li>3 . 1
31
Global Explanation.Global explanation provides insights into a model's decision-making process at the dataset level.Let D = (  ,   ,   )  =1 denote a dataset of  brain graphs at a given level ‚Ñì, and let   : (,  ) ‚Ü¶ ‚Üí ≈∑ be a trained GNN.A global explanation is defined as an object  global ‚àà E global , obtained via an explainer  global : (D,   ) ‚àí‚Üí  global .</li>
</ol>
<p>Fig. 4 .
4
Fig. 4. Progression course from Mild Cognitive Impairment to Dementia.</p>
<p>Level:</p>
<p>Sub = Subject, Popln = Population.Nature of Explanation: Scope / Method / Domain / Mode.Scope: Lo = Local, Gl = Global, Both; Method: In = Intrinsic, Ex = Extrinsic; Domain: Sp = Model Specific, Ag = Agnostic; Mode: Vis = Visual, Score = Numeric, Exmpl = Example.clsfn.=classification</p>
<p>Level:</p>
<p>Sub = Subject, Popln = Population.Nature of Explanation: Scope / Method / Domain / Mode.Scope: Lo = Local, Gl = Global, Both; Method: In = Intrinsic, Ex = Extrinsic; Domain: Sp = Model Specific, Ag = Agnostic; Mode: Vis = Visual, Score = Score-based, Exmpl = Example-based.</p>
<p>‚Ä¢ Functional Magnetic Resonance Imaging (fMRI): Measures spontaneous low-frequency BOLD (Blood Oxygen Level Dependent) signal fluctuations to assess functional connectivity (FC) between brain regions.Altered FC patterns have been widely observed in MCI, AD, and PDD [162].‚Ä¢ Diffusion Tensor Imaging (DTI): Captures microstructural changes in white matter by modeling water diffusion, aiding the detection of disrupted white matter tracts and subcortical damage, particularly in VaD and early-stage PD [25].‚Ä¢ Electroencephalography (EEG): Offers high temporal resolution and reveals abnormal spectral patterns and brain rhythms associated with dementia.It is especially valuable in early-stage diagnosis and in low-resource clinical settings [75].</p>
<p>‚Ä¢ Positron Emission Tomography (PET): Includes amyloid-PET and FDG-PET, enabling direct visualization of metabolic activity and pathological protein deposition (e.g., A, tau).PET provides critical insights into underlying AD pathology</p>
<p>:6 ‚Ä¢ Niharika Tewari, Nguyen Linh Dan Le, Mujie Liu, Jing Ren, Ziqi Xu, Tabinda Sarwar, Veeky Baths, and Feng Xia</p>
<p>]. ACM Trans.Comput.Healthcare, Vol. 1, No. 1, Article 1. Publication date: January 2025.1</p>
<p>Table 1 .
1
Research work related to MCI diagnosis and prediction.
XAI MethodArchitectureModalityLevelNature of Explanation PerformanceApplicationAmnestic MCIGCN-GradCAMMRI, fMRISubBoth/In/Sp/VisACC: 89.16%, 92.45% Early diag., AD pathol-ogy [188]GATConv-MRISubBoth/In/Sp/VisACC: 82.6%Brain shape staging,Post-HocGradCAMhighest seen on eMCIExplainablevs lMCI [60]GCN-GradCAMfMRISubBoth/In/Sp/VisACC: 92.2%MCI Diagnostic accu-racy [63]GCN-GradCAMfMRIBothBoth/Ex/Sp/Vis+ExmplACC: 78.6%FC-EC analysis [33]GCN-SaliencyfMRI, SNPPoplnBoth/In/Sp/Vis+ScoreACC: 89.4%, 85%,AD/MCI86.4%subtype clsfn [21]GCN-MRI, PETPoplnBoth/In/Ag/VisAUC: 88.51%Focus onGNNExplainerAùõΩ prediction [84]GNN-fMRISubBoth/Ex/Ag/VisMAE: 5.92 ¬± 0.62Brain age gap (BAG),GNNExplainersubtype clsfn [57]GNN-MRIPoplnBoth/In/Sp/ScoreACC: 94.4%, 87.5%MCI subtype and con-GNNExplainerversion [154]GCN-Built-InMRIPoplnBoth/In/Sp/Vis+ScoreACC: 79.4%, 68.4%AD-MCI diag. and MCIsubtype clsfn [186]SelfGNN-Built-InMRI, fMRI, PETSubBoth/In/Sp/Vis+ExmplùëÖ 2 : 0.214 ¬± 0.08Early AD detectn. [182]ExplainableGNN-AttentionMRI, DWI, PETPoplnGl/In/Sp/VisACC: 68%Group discriminativepattern observed [29]GCN-AttentionfMRISubBoth/In/Sp/VisACC: 71.2%MCI biomarkerdiscovery [111]GCN-AttentionfMRI, SNPPoplnGl/In/Sp/Vis+ScoreACC: 91.5%, 88.3%Multi-view AD(MCI vs HC), (brain-pathogen mapping [20]gene)GCN-AttentionMRI, fMRI, geneticSubBoth/In/Sp/AllACC: 84.4%MCIn and MCIp predic-tion [148]Non-Amnestic MCIPost-Hoc ExplainableGCN-GradCAMfMRISubBoth/In/Sp/Vis(nMCI/aMCI) ACC: 80.4%, 79%Early VaD diag. [103]</p>
<p>Table 2 .
2
Research work related to AD diagnosis and prediction.:20 ‚Ä¢ Niharika Tewari, Nguyen Linh Dan Le, Mujie Liu, Jing Ren, Ziqi Xu, Tabinda Sarwar, Veeky Baths, and Feng Xia
XAI MethodArchitectureModalityLevelNature of Explanation PerformanceApplicationGCN-GradCAMMRISubGl/Ex/Sp/VisACC: 96.35%ROI visualization onmeshes [14]GCN-GradCAMVBM-MRI, PETsBothBoth/Both/Sp/Vis+ScoreACC: 81.8%,Biomarkers, MMSE,Post-HocPC: 0.941ADAS13 [192]ExplainableGCN-GradCAMfMRIBothBoth/Both/Sp/Vis+ScoreACC: 88.6%; 79%FC biomarkers [104]GCN-GradCAMMRI, fMRIBothBoth/Both/Sp/Vis+ScoreACC: 96%Progressionprediction [189]GCN-GBPsMRI, dMRI,SubBoth/Both/Sp/Vis+ScoreACC: 76.2 ¬± 4.0%AùõΩ statusfMRI(AùõΩ-, AùõΩ+) [46]GCN-DWI, fMRISubBoth/Both/Sp/Vis+ScoreACC: 88%AD vs SCI,GNNExplainerDisease staging [56]GIN-SHAPfMRIBothBoth/Both/Ag/ScoreACC: 90.44%FC &amp; gender clsfn [173]GCN-SHAPMRI, PET, demo.BothBoth/Both/Sp/Vis+ScoreACC: 96.70%Feature selection [187]GNN (VNN)-MRIBothBoth/In/Sp/Vis+ScoreMAE: 5.44 ¬± 0.18;Brain ageBuilt-InPC: 0.47 ¬± 0.07prediction [150]GNN-Built-InfMRIBothBoth/In/Sp/Vis+ScorePrecision: 0.79Brain disorderdiagnosis [162]GCN-Built-InEEGPoplnBoth/In/Sp/VisEC: 89.1%,EEG-basedEO: 85.4%,AD detection andEO+EC: 81.8%graph clsfn. [85]GNN-LSTMMRISubBoth/In/Sp/Vis+ScoreACC: 93.67%Longitudinal AD-Attentiondiagnosis [110]SelfGT-AttentionMRI, DTISubBoth/In/Sp/Vis+ScoreMAE: 2.71 ¬± 0.07;Estimation ofExplainableACC: 85.9%Brain age [28]GCN-AttentionMRIFeatureBoth/In/Sp/Vis+ScoreACC: 86.9%AD diagnosis [175]GCN-AttentionMRI,SubBoth/In/Sp/Vis+ScoreACC: 92.3 ¬± 2.1%AD clsfn. [193]FDG-PET, AV45GNN-AttentionMRI, PET, gene,BothBoth/In/Sp/Vis+ScoreACC: 94.2%AD clsfn. [88]clinical, bio, demo.GCN-AttentionMRIBothBoth/In/Sp/VisACC: 93.90%AD diagnosis [134]GCN-AttentionMRISubBoth/Both/Sp/VisACC: 90.73%AD diagnosis [178]GT-AttentionfMRISubBoth/Both/Sp/ScoresACC: 92.31%AD diagnosis [64]GT-AttentionfMRIBothBoth/Both/Sp/Vis+ScoreACC: 88.2%AD diagnosis [153]GCN-AttentionMRI, PET, SNPBothBoth/Both/Sp/Vis+ScorePC: 0.829 (ADAS13),AD diagnosis [194]0.771 (MMSE), 0.768(Tau)GCN-AttentionMRIBothBoth/Both/Sp/Vis+ScoreACC: 86.2% , 74.2%AD diagnosis [76]GNN-AttentionMRIPoplnBoth/In/Sp/Vis+ExmplMacro-F1:Multimodal0.205-0.851, Micro-detection [83]F1: 0.686-0.858GCN-Instance levelMRISubBoth/In/Sp/VisACC: 84.4¬±0.36%AD diagnosis [95]GCN-Feature levelMRISubGl/In/Sp/Vis+ScoreACC ‚â• 85%AD diagnosis [196]GCN-Feature levelMRIBothBoth/In/Sp/Vis+ScoreACC: 95.6% (ADNI),AD diagnosis97.5% (AIBL),and prognosis [126]93.3% (OASIS), 100%(MIRIAD)GCN-Feature levelfMRI, SNPBothBoth/Both/Sp/Vis+ScoreACC: 93.61%AD diagnosis,pathogenidentification [19]GraphSAGE-MRISubBoth/Both/Sp/VisACC: 92.1%, 91.4%AD Diagnosis [155]Feature level(Intra/Inter CV)Explanation HybridCausal Counterfactual &amp; GCN-PETBothBoth/In/Sp/Vis+ScoreACC: 84%Causal inference [43]GNN-SaliencyMRI, SNP, CSFBothBoth/Both/Sp/Vis+ScoreACC: 87.6%AD Diagnosis [93]&amp; CAMGCN-MRI, PET,BothBoth/Both/Both/Correctness: 71%Human validatedDecomposition &amp;demo., cognitive,Vis+Scoreexplanations [160]SHAPgenetic
ACM Trans.Comput.Healthcare, Vol. 1, No. 1, Article 1. Publication date: January 2025.1</p>
<p>Table 4 .
4
Research work related to Multi-disease Diagnosis and Prediction.
XAI MethodArchitectureModality LevelNature of Explanation PerformanceApplicationAD vs. FTDSelfGCN-Built-InMRIBothBoth/In/Sp/Vis+ScoreACC: 89.7%Differential diag. of AD,ExplainableFTD, CN [125]GNN-AttentionfMRISubBoth/Both/Sp/Vis+ScoreFTD: 87.22%,Dementia detectionADNI: 89.78%and diagnosis [170]AD vs. PDSelf ExplainableGNN-Built-In GNN-AttentionEEG fMRIBoth BothBoth/In/Sp/Vis+Score Both/In/Sp/Vis+ScoreACC: 97.4% TaoWu: 77.5¬±17.5, PPMI: 64.0¬±6.63, Neuro-AD/PD vs HC diag. [31] PD/AD brain network clsfn [177]con: 68.3 ¬± 20.0, ADNI:63.7¬±2.63GCN-Built-InfMRI, DTI BothBoth/In/Sp/VisADNI: ACC 82.3%;Multimodal brain dis-PPMI: ACC 86.2%ease localization [91]Amnestic MCI vs. PDSelfGCN-AttentionMRIBothBoth/Both/Sp/Vis+ScoreHC vs MCI: 84.8¬±1.92,MCI, PD clsfn [61]ExplainableHC vs PD: 78.3¬±3.19GCN-Feature LevelfMRI, DTI BothBoth/Both/Sp/Vis+ScoreMCI vs HC: 90.4¬±2.4,Brain networks forPD vs HC: 85.9¬±4.5MCI, PD [180]</p>
<p>addressed this challenge using a directed structurelearning GNN (DSL-GNN) to classify AD and PD based on EEG-derived effective brain connectivity (EBC) patterns.By integrating univariate features (power spectral densities) with multivariate EBC features, their model leveraged both local and network-level EEG biomarkers.The DSL-GNN achieved strong classification performance: 94.0% for AD vs. HC, 94.2% for PD vs. HC, and 97.4% for direct AD vs. PD classification; it also reached 93.0% in three-way AD vs. PD vs. HC discrimination.Incorporating directed connectivity, which reflects causal interactions in EEG networks, improved performance over conventional undirected GNNs.Visualisation of learned features revealed distinct disease-specific patterns: AD patients showed pronounced parietal disruptions, while PD patients exhibited temporal and frontal abnormalities, consistent with posterior cortical atrophy in AD and frontostriatal dysfunction in PD.Xu et al.</p>
<p>Table 5 .
5
A summary of publicly available neuroimaging datasets used in dementia research.
DatasetModalitiesSubtypeReferencesAlzheimer's Disease Neuroimaging Ini-MRI, fMRI, PET, Clinical As-tiative (ADNI) [74]sessments, Genetic Data, Bio-chemical Data
ACM Trans. Comput. Healthcare, Vol. 1, No. 1, Article 1. Publication date: January 2025.
ACM Trans. Comput. Healthcare, Vol. 1, No. 1, Article 1. Publication date: January 2025. 1:28 ‚Ä¢ Niharika Tewari, Nguyen Linh Dan Le, Mujie Liu, Jing Ren, Ziqi Xu, Tabinda Sarwar, Veeky Baths, and Feng Xia
90.2% accuracy and identifying the superior temporal gyrus and Broca's area as critical regions associated with speech deficits in PD patients.Self ExplanationIn the context of PD, Cui et al.[40]introduced IBGNN, an interpretable GNN equipped with a post-hoc explanation generator.The model achieved 79.55% accuracy on the PPMI dataset, outperforming conventional ML and DL approaches by identifying critical ROIs and connectivity patterns.Li et al.[94]proposed iGLCN, an interpretable graph learning model for PD diagnosis using multimodal MRI, achieving 91.6% accuracy and an AUC of 0.950 on the PPMI and Shenzhen datasets.Their model highlighted key regions such as the caudate nucleus and thalamus.Hybrid ExplainableTo diagnose PD, recent studies have adopted hybrid explainability techniques that combine intrinsic and extrinsic approaches, thereby offering more comprehensive interpretability.Safai et al.[139]proposed a framework integrating sMRI, DTI, and fMRI to construct multimodal brain connectivity networks, achieving 86% crossvalidation accuracy and 73% test accuracy.Saliency analysis and attention maps identified key brain regions such as the motor network, basal ganglia, and cerebello-thalamo-cortical network as critical for diagnosis.Ling et al.[99]introduced an explainable GNN framework that incorporated a transformer-based attention mechanism and Regional Radiomics Similarity Network (R2SN) to construct subject-level metabolic graphs.GNNExplainer was further employed to provide interpretable insights into relevant metabolic regions and connectivity patterns.Causality has also emerged as a promising approach to guide clinical decision-making, particularly in PD cases with complex motor and non-motor symptoms.Tang et al.[159]proposed a causality-driven GCN for diagnosing postural anomalies in PD using QSM imaging, where brain patches were modelled as graph nodes with edges defined by spatial proximity and texture similarity.By leveraging multi-instance learning and causal prediction invariance, their model achieved 72.93% accuracy and 76.43% AUC, outperforming traditional radiomic and deep learning methods, while identifying key regions such as the hippocampus and middle frontal gyrus.
The epidemiology of dementia associated with Parkinson's disease. Dag Aarsland, Alexander Kurz, 10.1111/j.1750-3639.2009.00369.xBrain Pathology. 202010. May 2010</p>
<p>Parkinson's disease dementia and dementia with Lewy bodies: different aspects of one entity. Dag Aarsland, Clive Londos, Ballard, International psychogeriatrics. 212009. 2009</p>
<p>A systematic review of prevalence studies of dementia in Parkinson's disease. Dag Aarsland, Julia Zaccai, Carol Brayne, 10.1002/mds.20527Movement Disorders. 202005. 2005</p>
<p>Evaluating explainability for graph neural networks. Chirag Agarwal, Owen Queen, Himabindu Lakkaraju, Marinka Zitnik, Scientific Data. 101442023. 2023</p>
<p>Towards the Unification and Robustness of Perturbation and Gradient Based Explanations. Sushant Agarwal, Shahin Jabbari, Chirag Agarwal, Sohini Upadhyay, Zhiwei Steven Wu, Himabindu Lakkaraju, arXiv:2102.10618[cs.LG2021</p>
<p>The diagnosis of mild cognitive impairment due to Alzheimer's disease: recommendations from the National Institute on Aging-Alzheimer's Association workgroups. S Marilyn, Alzheimer's &amp; Dementia. 72011. 2011</p>
<p>Towards Robust Interpretability with Self-Explaining Neural Networks. David Alvarez, -Melis , Tommi S Jaakkola, 10.5555/3327757.3327875Proceedings of the 32nd International Conference on Neural Information Processing Systems. the 32nd International Conference on Neural Information Processing SystemsRed Hook, NY, USACurran Associates, Inc2018. NeurIPS 2018NIPS '18)</p>
<p>Alzheimer's disease facts and figures. 10.1002/alz.13809Alzheimer's &amp; Dementia. 2052024. 2024. May 2024. 2024 Apr 30Alzheimer's Association</p>
<p>Alzheimer's Disease Information Website. Mild Cognitive Impairment (MCI). 2024</p>
<p>Alzheimer's Society UK. 2024. Mild Cognitive Impairment (MCI). </p>
<p>Human brain mapping: A systematic comparison of parcellation methods for the human cerebral cortex. Sofia Ira Salim Arslan, Antonios Ktena, Emma C Makropoulos, Daniel Robinson, Sarah Rueckert, Parisot, NeuroImage. 1702018. 2018</p>
<p>Diagnosis and management of dementia. Zoe Arvanitakis, Raj C Shah, David A Bennett, Jama. 3222019. 2019</p>
<p>A systematic review on machine learning and deep learning techniques in the effective diagnosis of Alzheimer's disease. Akhilesh Deep Arya, Sourabh Singh Verma, Prasun Chakarabarti, Tulika Chakrabarti, Ahmed A Elngar, Ali-Mohammad Kamali, Mohammad Nami, Brain Informatics. 10172023. 2023</p>
<p>Interpretation of Brain Morphology in Association to Alzheimer's Disease Dementia Classification Using Graph Convolutional Networks on Triangulated Meshes. A Emanuel, Pierre Azcona, Yunan Besson, Arjun Wu, Adam Punjabi, Amil Martersteck, Todd B Dravid, S Kathleen Parrish, Aggelos K Bandt, Katsaggelos, 10.1007/978-3-030-61056-2_8Proceedings of the International Workshop on Shape in Medical Imaging (ShapeMI). the International Workshop on Shape in Medical Imaging (ShapeMI)Cham, SwitzerlandSpringer2020</p>
<p>Exploring the reproducibility of functional connectivity alterations in Parkinson's disease. Liviu Badea, Mihaela Onu, Tao Wu, Adina Roceanu, Ovidiu Bajenaru, PLoS One. 12e01881962017. 2017</p>
<p>Neuropsychiatric symptoms in Alzheimer's disease are related to functional connectivity alterations in the salience network. Marcio Lf Balthazar, R S Fabr√≠cio, T√°tila M Pereira, Elvis L Lopes, Ana Da Silva, Carolina Coan, Niall W Brunno M Campos, Florindo Duncan, Georg Stella, Benito P Northoff, Damasceno, Human Brain Mapping. 352014. 2014</p>
<p>Jee Bang, Salvatore Spina, Bruce L Miller, Frontotemporal dementia. The Lancet. 2015. 2015386</p>
<p>A survey on explainable artificial intelligence (xai) techniques for visualizing deep learning models in medical imaging. Deepshikha Bhati, Fnu Neha, Md Amiruzzaman, Journal of Imaging. 102392024. 2024</p>
<p>Community Graph Convolution Neural Network for Alzheimer's Disease Classification and Pathogenetic Factors Identification. Xia-An Bi, Ke Chen, Siyu Jiang, Sheng Luo, Wenyan Zhou, Zhaoxu Xing, Luyun Xu, Zhengliang Liu, Tianming Liu, 10.1109/TNNLS.2023.3269446IEEE Transactions on Neural Networks and Learning Systems. 362025. 2025. 2025 Feb 6</p>
<p>Explainable and programmable hypergraph convolutional network for imaging genetics data fusion. Xia-An Bi, Sheng Luo, Siyu Jiang, Yu Wang, Zhaoxu Xing, Luyun Xu, Information Fusion. 1001019502023. 2023</p>
<p>Feature aggregation graph convolutional network based on imaging genetic data for diagnosis and pathogeny identification of Alzheimer's disease. Xia-An Bi, Wenyan Zhou, Sheng Luo, Yuhua Mao, Xi Hu, Bin Zeng, Luyun Xu, Briefings in bioinformatics. 231372022. 2022</p>
<p>Enhancing Brain Disease Diagnosis with XAI: A Review of Recent Studies. Nighat Bibi, Jane Courtney, Kevin Mcguinness, ACM Transactions on Computing for Healthcare. 62025. 2025</p>
<p>A comprehensive review of explainable AI for disease diagnosis. A A Biswas, 10.1016/J.ARRAY.2024.100345Array. 221003452024. Jul 2024</p>
<p>Comprehensive review on Alzheimer's disease: causes and treatment. Zeinab Breijyeh, Rafik Karaman, Molecules. 2557892020. 2020</p>
<p>. ACM Trans. Comput. Healthcare. 11January 2025Publication date</p>
<p>The European DTI Study on Dementia-A multicenter DTI and MRI study on Alzheimer's disease and mild cognitive impairment. Katharina Brueggen, Martin Michel J Grothe, Andreas Dyrba, Florian Fellgiebel, Massimo Fischer, Federica Filippi, Peter Agosta, Eva Nestor, Janusch Meisenzahl, Blautzik, Neuroimage. 1442017. 2017</p>
<p>Miles Brundage, Shahar Avin, Jasmine Wang, Haydn Belfield, Gretchen Krueger, Gillian Hadfield, Heidy Khlaaf, Jingying Yang, Helen Toner, Ruth Fong, Tegan Maharaj, arXiv:2004.07213[cs.AIToward trustworthy AI development: mechanisms for supporting verifiable claims. 2020</p>
<p>Cerebral atrophy in Parkinson's disease with and without dementia: a comparison with Alzheimer's disease, dementia with Lewy bodies and controls. Emma J Burton, Ian G Mckeith, David J Burn, David Williams, John T O' Brien, Brain. 1272004. 2004</p>
<p>Graph Transformer Geometric Learning of Brain Networks Using Multimodal MR Images for Brain Age Estimation. Hongjie Cai, Yue Gao, Manhua Liu, 10.1109/TMI.2022.3221627IEEE Transactions on Medical Imaging. 422022. 2022</p>
<p>Discovering Brain Network Dysfunction in Alzheimer's Disease Using Brain Hypergraph Neural Network. Hongmin Cai, Zhixuan Zhou, Defu Yang, Guorong Wu, Jiazhou Chen, 10.1007/978-3-031-43904-9_23Medical Image Computing and Computer Assisted Intervention -MICCAI 2023. Lecture Notes in Computer Science. ChamSpringer202314224</p>
<p>Causal relationship between dementia and delirium: Insights from a bidirectional two-sample Mendelian randomization analysis. Yongsong Cai, Jiachen Wang, Xinyi Wang, Qiling Yuan, Yan Xu, Peng Xu, Journal of Affective Disorders. 3492024. 2024</p>
<p>Dementia classification using a graph neural network on imaging of effective brain connectivity. Jun Cao, Lichao Yang, Ptolemaios Georgios Sarrigiannis, Daniel Blackburn, Yifan Zhao, Computers in Biology and Medicine. 1681077012024. 2024</p>
<p>Aditya Chattopadhyay, Piyushi Manupriya, Anirban Sarkar, Vineeth N Balasubramanian, arXiv:1902.02302[cs.LGNeural Network Attributions: A Causal Perspective. 2019</p>
<p>Guiding fusion of dynamic functional and effective connectivity in spatio-temporal graph neural network for brain disorder classification. Dongdong Chen, Mengjun Liu, Sheng Wang, Zheren Li, Lu Bai, Qian Wang, Dinggang Shen, Lichi Zhang, Knowledge-Based Systems. 3091128562025. 2025</p>
<p>Amyloid-PET and 18F-FDG-PET in the diagnostic investigation of Alzheimer's disease and other dementias. Ga√´l Ch√©telat, Javier Arbizu, Henryk Barthel, Valentina Garibotto, Ian Law, Silvia Morbelli, Elsmarieke Van De Giessen, Federica Agosta, Frederik Barkhof, David J Brooks, The Lancet Neurology. 192020. 2020</p>
<p>Pathophysiology of dementia. Kai Sin, Chin , Australian Journal for General Practitioners. 522023. 2023</p>
<p>UK Parkinson's Disease Society Brain Bank Diagnostic Criteria. C E Clarke, S Patel, N Ives, C E Rick, R Woolley, K Wheatley, M F Walker, S Zhu, R Kandiyali, G Yao, Health Technology Assessment. 202016. App1-1-App1-15NIHR Journals Library</p>
<p>A Survey of Explainable AI Terminology. Miruna- , Adriana Clinciu, Helen Hastie, 10.18653/v1/W19-8403Proceedings of the 1st Workshop on Interactive Natural Language Technology for Explainable Artificial Intelligence. Jose M Alonso, Alejandro Catala, the 1st Workshop on Interactive Natural Language Technology for Explainable Artificial IntelligenceStroudsburg, PA, USAAssociation for Computational Linguistics2019. 20194</p>
<p>Clinical, genetic and neuroimaging features of frontotemporal dementia. Convery, Mead, Rohrer, Neuropathology and Applied Neurobiology. 452019. 2019</p>
<p>Braingb: A Benchmark for Brain Network Analysis with Graph Neural Networks. Hejie Cui, Wei Dai, Yanqiao Zhu, Xuan Kan, Antonio Aodong Chen, Joshua Lukemire, Liang Zhan, Lifang He, Ying Guo, Carl Yang, 10.1109/TMI.2022.3218745IEEE Transactions on Medical Imaging. 422023. 2023</p>
<p>Interpretable Graph Neural Networks for Connectome-Based Brain Disorder Analysis. Hejie Cui, Wei Dai, Yanqiao Zhu, Xiaoxiao Li, Lifang He, Carl Yang, 10.1007/978-3-031-16452-1_36Proceedings of the International Conference on Medical Image Computing and Computer-Assisted Intervention (MICCAI). the International Conference on Medical Image Computing and Computer-Assisted Intervention (MICCAI)Cham, Cham, SwitzerlandSpringer2022</p>
<p>Chapter 5 -Machine learning in digital health, recent trends, and ongoing challenges. Nicholas Cummins, Zhao Ren, Adria Mallol-Ragolta, Bj√∂rn Schuller, 10.1016/B978-0-12-817133-2.00005-7Artificial Intelligence in Precision Health, Debmalya Barh. Cambridge, MAAcademic Press2020</p>
<p>Frontotemporal dementia: Its definition, differential diagnosis, and management. Lauren M Cycyk, Heather Harris, Wright , Aphasiology. 222008. 2008</p>
<p>Graph-Based Counterfactual Causal Inference Modeling for Neuroimaging Analysis. Haixing Dai, Mengxuan Hu, Qing Li, Lu Zhang, Lin Zhao, Dajiang Zhu, Ibai Diez, Jorge Sepulcre, Fan Zhang, Xingyu Gao, Manhua Liu, Quanzheng Li, Sheng Li, Tianming Liu, Xiang Li, 10.1007/978-3-031-47425-5_19Medical Image Computing and Computer Assisted Intervention -MICCAI 2023 Workshops: MTSAIL 2023, LEAF 2023. Vancouver, BC, Canada; Vancouver, BC, Canada; Berlin, HeidelbergSpringer-Verlag2023. AI4Treat 2023, MMMI 2023, REMIA 2023. October 8-12, 2023Conjunction with MICCAI 2023</p>
<p>Cortical surface-based analysis: I. Segmentation and surface reconstruction. Bruce Anders M Dale, Martin I Fischl, Sereno, Neuroimage. 91999. 1999</p>
<p>Explainable cognitive decline detection in free dialogues with a Machine Learning approach based on pre-trained Large Language Models. Francisco De Arriba-P√©rez, Silvia Garc√≠a-M√©ndez, Javier Otero-Mosquera, Francisco J Gonz√°lez-Casta√±o, Applied Intelligence. 542024. 2024</p>
<p>Anees Abrol, Ilaria Boscolo Galazzo, Gloria Menegaz, Vince D. Calhoun, and for the Alzheimer's Disease Neuroimaging Initiative. 2025. Multimodal MRI accurately identifies amyloid status in unbalanced co-horts in Alzheimer's disease continuum. Giorgio Dolci, Charles A Ellis, Federica Cru-Ciani, Lorenza Brusini, 10.1162/netn_a_00423Network Neuroscience. 9103 2025</p>
<p>Finale Doshi, - Velez, Been Kim, arXiv:1702.08608Towards A Rigorous Science of Interpretable Machine Learning. 2017stat.ML</p>
<p>Brittany N Dugger, Kathryn Davis, Michael Malek-Ahmadi, Joseph G Hentz, Shawn Sandhu, Thomas G Beach, Charles H Adler, Richard J Caselli, Travis A Johnson, Geidy E Serrano, Neuropathological comparisons of amnestic and nonamnestic mild cognitive impairment. 2015. 201515146</p>
<p>Benchmarking graph neural networks. Vijay Prakash Dwivedi, Chaitanya K Joshi, Anh Tuan Luu, Thomas Laurent, Yoshua Bengio, Xavier Bresson, Journal of Machine Learning Research. 242023. 2023</p>
<p>The Australian Imaging, Biomarkers and Lifestyle (AIBL) study of aging: methodology and baseline characteristics of 1112 individuals recruited for a longitudinal study of Alzheimer's disease. Kathryn A Ellis, Ashley I Bush, David Darby, Daniela De Fazio, Jonathan Foster, Peter Hudson, Nicola T Lautenschlager, Nat Lenzo, Ralph N Martins, Paul Maruff, International psychogeriatrics. 212009. 2009</p>
<p>Clinical diagnostic criteria for dementia associated with Parkinson's disease. Dag Murat Emre, Richard Aarsland, David J Brown, Charles Burn, Yoshikino Duyckaerts, Gerald Mizuno, Jeffrey Anthony Broe, Dennis W Cummings, Serge Dickson, Gauthier, Movement disorders: official journal of the Movement Disorder Society. 222007. 2007</p>
<p>Cognition deficits in Parkinson's disease: mechanisms and treatment. Congcong Fang, Longqin Lv, Shanping Mao, Huimin Dong, Baohui Liu, Parkinson's Disease. 202020769422020. 2020</p>
<p>Entropy causal graphs for multivariate time series anomaly detection. Falih Gozi Febrinanto, Kristen Moore, Chandra Thapa, Mujie Liu, Vidya Saikrishna, Jiangang Ma, Feng Xia, arXiv:2312.094782023. 2023arXiv preprint</p>
<p>Refined causal graph structure learning via curvature for brain disease classification. Falih Gozi Febrinanto, Adonia Simango, Chengpei Xu, Jingjing Zhou, Jiangang Ma, Sonika Tyagi, Feng Xia, Artificial Intelligence Review. 582222025. 2025</p>
<p>Neuroimaging in vascular cognitive impairment and dementia: a systematic review. Viviana Frantellizzi, Arianna Pani, Maria Ricci, Nicoletta Locuratolo, Francesco Fattapposta, Giuseppe De Vincentis, Journal of Alzheimer's Disease. 732020. 2020</p>
<p>Siamese Graph Convolutional Network quantifies increasing structure-function discrepancy over the cognitive decline continuum. Gurur Gamgam, Zerrin Yƒ±ldƒ±rƒ±m, Alkan Kabak√ßƒ±oƒülu, Hakan Gurvit, Tamer Demiralp, Burak Acar, 10.1016/j.cmpb.2024.108290Computer Methods and Programs in Biomedicine. 2541082902024. 2024</p>
<p>Brain Age Prediction Using the Graph Neural Network Based on Resting-State Functional MRI in Alzheimer's Disease. Jingjing Gao, Jiaxin Liu, Yuhang Xu, Dawei Peng, Zhengning Wang, 10.3389/fnins.2023.1222751Frontiers in Neuroscience. 1712227512023. 2023</p>
<p>Going beyond xai: A systematic survey for explanation-guided learning. Yuyang Gao, Siyi Gu, Junji Jiang, Sungsoo Ray Hong, Dazhou Yu, Liang Zhao, Comput. Surveys. 562024. 2024</p>
<p>Default-mode network activity distinguishes Alzheimer's disease from healthy aging: evidence from functional MRI. Gaurav Michael D Greicius, Allan L Srivastava, Vinod Reiss, Menon, Proceedings of the National Academy of Sciences. 1012004. 2004</p>
<p>Stage Detection of Mild Cognitive Impairment: Region-dependent Graph Representation Learning on Brain Morphable Meshes. Jiaqi Guo, Emanuel Azcona, Santiago Lopez-Tapia, Aggelos Katsaggelos, Proceedings of the Medical Imaging with Deep Learning (MIDL) (Proceedings of Machine Learning Research. Ipek Oguz, Jack Noble, Xiaoxiao Li, Martin Styner, Christian Baumgartner, Mirabela Rusu, Tobias Heinmann, Despina Kontos, Bennett Landman, Benoit Dawant, the Medical Imaging with Deep Learning (MIDL) ( Machine Learning ResearchZurich, SwitzerlandPMLR2024227</p>
<p>Graph-Based Fusion of Imaging, Genetic and Clinical Data for Degenerative Disease Diagnosis. Rui Guo, Hanhe Xu Tian, Stephen Lin, Hong-Dong Mckenna, Fei Li, Jin Guo, Liu, 10.1109/TCBB.2023.3335369IEEE/ACM Trans. Comput. Biol. Bioinformatics. 212023. Nov. 2023</p>
<p>Mapping the structural core of human cerebral cortex. Patric Hagmann, Leila Cammoun, Xavier Gigandet, Reto Meuli, Christopher J Honey, Olaf Van J Wedeen, Sporns, PLoS Biology. 6e1592008. 2008</p>
<p>Utilizing Graph Convolutional Networks for Identification of Mild Cognitive Impairment from Single Modal fMRI Data: A Multiconnection Pattern Combination Approach. Jie He, Peng Wang, Jun He, Chenhao Sun, Xiaowen Xu, Lei Zhang, Xin Wang, Xin Gao, 10.1093/cercor/bhae065Cerebral Cortex. 34e0652024. 2024</p>
<p>Alzheimer's Disease Neuroimaging Initiative, and et al. 2024. A spatiotemporal graph transformer approach for Alzheimer's disease diagnosis with rs-fMRI. Peng He, Zhan Shi, Yaping Cui, Ruyan Wang, Dapeng Wu, Computers in Biology and Medicine. 1781087622024</p>
<p>What do we need to build explainable AI systems for the medical domain?. Andreas Holzinger, Chris Biemann, Constantinos S Pattichis, Douglas B Kell, arXiv:1712.09923[cs.AI2017</p>
<p>Junlin Hou, Sicen Liu, Yequan Bie, Hongmei Wang, Andong Tan, Luyang Luo, Hao Chen, arXiv:2410.02331[cs.CVSelf-eXplainable AI for Medical Image Analysis: A Survey and New Outlooks. 2024</p>
<p>Self-Explainable Graph Neural Network for Alzheimer Disease and Related Dementias Risk Prediction: Algorithm Development and Validation Study. X Hu, 10.2196/54748JMIR Aging. 7e547482024. Jul 2024</p>
<p>Subjective cognitive decline in patients with Parkinson's disease: an updated review. Juan Huang, Xingxing Yuan, Lin Chen, Binbin Hu, Lijuan Jiang, Ting Shi, Hui Wang, Wei Huang, Frontiers in Aging Neuroscience. 1511170682023. 2023</p>
<p>MNC-Net: Multi-task Graph Structure Learning Based on Node Clustering for Early Parkinson's Disease Diagnosis. Liqin Huang, Xiaofang Ye, Mingjing Yang, Lin Pan, Shaohua Zheng, 10.1016/j.compbiomed.2022.106308Computers in Biology and Medicine. 1521063082023. 2023</p>
<p>SEHG: Bridging Interpretability and Prediction in Self-Explainable Heterogeneous Graph Neural Networks. Zhenhua Huang, Wenhao Zhou, Yufeng Li, Xiuyang Wu, Chengpei Xu, Junfeng Fang, Zhaohong Jia, Linyuan L√º, Xia , Proceedings of the ACM on Web Conference 2025. the ACM on Web Conference 20252025</p>
<p>Tracking pathophysiological processes in Alzheimer's disease: an updated hypothetical model of dynamic biomarkers. David S Clifford R Jack, William J Knopman, Ronald C Jagust, Michael W Petersen, Weiner, Leslie M Paul S Aisen, Prashanthi Shaw, Heather J Vemuri, Stephen D Wiste, Weigand, The Lancet Neurology. 122013. 2013</p>
<p>Hypothetical model of dynamic biomarkers of the Alzheimer's pathological cascade. David S Clifford R Jack, William J Knopman, Leslie M Jagust, Shaw, Michael W Paul S Aisen, Ronald C Weiner, John Q Petersen, Trojanowski, The Lancet Neurology. 92010. 2010</p>
<p>NIA-AA research framework: toward a biological definition of Alzheimer's disease. Clifford R Jack Jr, David A Bennett, Kaj Blennow, Maria C Carrillo, Billy Dunn, Samantha Budd Haeberlein, David M Holtzman, William Jagust, Frank Jessen, Jason Karlawish, Alzheimer's &amp; Dementia. 142018. 2018</p>
<p>The Alzheimer's disease neuroimaging initiative (ADNI): MRI methods. Clifford R Jack Jr, Matt A Bernstein, Nick C Fox, Paul Thompson, Gene Alexander, Danielle Harvey, Bret Borowski, Paula J Britson, Jennifer L Whitwell, Chadwick Ward, Journal of Magnetic Resonance Imaging: An Official Journal of the International Society for Magnetic Resonance in Medicine. 272008. 2008</p>
<p>Jaeseung Jeong, EEG dynamics in patients with Alzheimer's disease. 2004. 2004115</p>
<p>Attention based multi-task interpretable graph convolutional network for Alzheimer's disease analysis. Shunqin Jiang, Qiyuan Feng, Hengxin Li, Zhenyun Deng, Qinghong Jiang, Pattern Recognition Letters. 1802024. 2024</p>
<p>Power of Multi-Modality Variables in Predicting Parkinson's Disease Progression. Yishan Jiang, Hyung-Jeong Yang, Jahae Kim, Zhenzhou Tang, Xiukai Ruan, 10.1109/JBHI.2024.3482180IEEE Journal of Biomedical and Health Informatics. 292025. 2025</p>
<p>Johns Hopkins, Medicine , Stages of Alzheimer's Disease. 2024</p>
<p>Update on major neurocognitive disorders. Kristin C Jones, Focus. 192021. 2021</p>
<p>. J Kakkad, J Jannu, K Sharma, C Aggarwal, S Medya, A Survey on Explainability of Graph Neural Networks. 2023. Sep. 11, 2024</p>
<p>Vascular basis for brain degeneration: faltering controls and risk factors for dementia. Raj N Kalaria, Nutrition Reviews. 682010. 2010</p>
<p>Neuropathological diagnosis of vascular cognitive impairment and vascular dementia with implications for Alzheimer's disease. Raj N Kalaria, Acta Neuropathologica. 1312016. 2016</p>
<p>Heterogeneous Graph Learning for Multi-Modal Medical Data Analysis. Sein Kim, Namkyeong Lee, Junseok Lee, Dongmin Hyun, Chanyoung Park, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial IntelligencePalo Alto, California, USAAAAI Press202337</p>
<p>Personalized Explanations for Early Diagnosis of Alzheimer's Disease Using Explainable Graph Neural Networks with Population Graphs. So Yeon, Kim , Bioengineering. 107012023. 2023</p>
<p>Adaptive Gated Graph Convolutional Network for Explainable Diagnosis of Alzheimer's Disease Using EEG Data. Dominik Klepl, Fei He, Min Wu, Daniel J Blackburn, Ptolemaios Sarrigiannis, 10.1109/TNSRE.2023.3321634IEEE Transactions on Neural Systems and Rehabilitation Engineering. 312023. 2023</p>
<p>The neuroimaging initiative for frontotemporal dementia (NIFD): a multicenter study of structural MRI in behavioral variant FTD. Clifford R David S Knopman, Joel H JackJr, Bradley F Kramer, Richard J Boeve, Caselli, Mario F Neill R Graff-Radford, Bruce L Mendez, Gil D Miller, Michael W Rabinovici, Weiner, Alzheimer's &amp; Dementia. 102014. 2014</p>
<p>A Coalition to Advance Treatments for Parkinson's Disease, Dementia with Lewy Bodies, and Related Disorders. Catherine M Kopil, Angelica Asis, Clyde Campbell, Sohini Chowdhury, David T Dexter, Keith N Fargo, Karen K Lee, Helen Matthews, Angela Taylor, Yuge Xiao, Journal of Parkinson's Disease. 142024. 2024</p>
<p>Hypergraph Neural Networks with Attention-based Fusion for Multimodal Medical Data Integration and Analysis. Abhishek Kumar, Abhijieet Nashte, Amit R Porwal, Chahil Choudhary, 10.1109/ICIIP61524.2023.10537751Tabinda Sarwar, Veeky Baths, and Feng Xia Processing (ICIIP). Niharika Tewari, Nguyen Linh, Dan Le, Mujie Liu, Jing Ren, Ziqi Xu, Pune, IndiaIEEE2023. January 20251Proceedings of the Seventh International Conference on</p>
<p>Pamela J Lamontagne, Sarah Keefe, Wallace Lauren, Chengjie Xiong, Elizabeth A Grant, Krista L Moulder, John C Morris, Tammie L S Benzinger, Daniel S Marcus, 10.1016/j.jalz.2018.06.1439P3-083: OASIS-3: LONGITUDINAL NEUROIMAGING, CLINICAL, AND COGNITIVE DATASET FOR NORMAL AGING AND ALZHEIMER'S DISEASE. 2018. 201814</p>
<p>The diagnosis and management of mild cognitive impairment: a clinical review. M Kenneth, Deborah A Langa, Levine, Jama. 3122014. 2014</p>
<p>BrainMAP: Multimodal Graph Learning For Efficient Brain Disease Localization. Nguyen Linh, Dan Le, Jing Ren, Ciyuan Peng, Chengyao Xie, Bowen Li, Feng Xia, arXiv:2506.111782025. 2025arXiv preprint</p>
<p>Alzheimer's disease recognition using graph neural network by leveraging image-text similarity from vision language model. Byounghwa Lee, Jeong-Uk Bang, Hwa Jeon Song, Byung Ok Kang, Scientific Reports. 159972025. 2025</p>
<p>Alzheimer's disease diagnosis from multi-modal data via feature inductive learning and dual multilevel graph neural network. Baiying Lei, Yafeng Li, Wanyi Fu, Peng Yang, Shaobin Chen, Tianfu Wang, Xiaohua Xiao, Tianye Niu, Yu Fu, Shuqiang Wang, Medical Image Analysis. 971032132024. 2024</p>
<p>Developing a Dynamic Graph Network for Interpretable Analysis of Multi-Modal MRI Data in Parkinson's Disease Diagnosis. Fanshi Li, Zhihui Wang, Yifan Guo, Congcong Liu, Yanjie Zhu, Yihang Zhou, Jun Li, Dong Liang, Haifeng Wang, 10.1109/EMBC40787.2023.103406722023 45th Annual International Conference of the IEEE Engineering in Medicine &amp; Biology Society (EMBC). Seattle, WA, USAIEEE2023</p>
<p>Fsnet: Dual Interpretable Graph Convolutional Network for Alzheimer's Disease Analysis. Hengxin Li, Xiaoshuang Shi, Xiaofeng Zhu, Shuihua Wang, Zheng Zhang, 10.1109/TETCI.2022.3183679IEEE Transactions on Emerging Topics in Computational Intelligence. 72023. 2023</p>
<p>Can Graph Neural Networks be Adequately Explained? A Survey. Xuyan Li, Jie Wang, Zheng Yan, Comput. Surveys. 572025. 2025</p>
<p>Sino Longitudinal Study on Cognitive Decline (SILCODE): protocol for a Chinese longitudinal observational study to develop risk prediction models of conversion to mild cognitive impairment in individuals with subjective cognitive decline. Xuanyu Li, Xiaoni Wang, Li Su, Xiaochen Hu, Ying Han, BMJ open. 9e0281882019. 2019</p>
<p>Yicong Li, Kuanjiu Zhou, Shuo Yu, Qiang Zhang, Renqiang Luo, Xiaodong Li, Feng Xia, arXiv:2502.14572Factor Graph-based Interpretable Neural Networks. 2025. 2025arXiv preprint</p>
<p>Explainable graph neural network based on metabolic brain imaging for differential diagnosis of parkinsonism. Ronghua Ling, Xingxing Cen, Shaoyou Wu, Min Wang, Ying Zhang, Juanjuan Jiang, Jiaying Lu, Yingqian Liu, Chuantao Zuo, Jiehui Jiang, Frontiers in Aging Neuroscience. 1715809102025. 2025</p>
<p>Diagnostic criteria for mild cognitive impairment in Parkinson's disease: Movement Disorder Society Task Force guidelines. Irene Litvan, Jennifer G Goldman, Alexander I Tr√∂ster, Ben A Schmand, Daniel Weintraub, Brit Ronald C Petersen, Charles H Mollenhauer, Karen Adler, Caroline H Marder, Williams-Gray, Movement Disorders. 272012. 2012</p>
<p>Detection of Mild Cognitive Impairment from Language Markers with Crossmodal Augmentation. Guangliang Liu, Zhiyu Xue, Liang Zhan, Hiroko H Dodge, Jiayu Zhou, Proceedings of the Pacific Symposium on Biocomputing). the Pacific Symposium on Biocomputing)Hawaii, USA; Hackensack, NJ, USAWorld Scientific2022. January 2023Pacific Symposium on Biocomputing 2023: Kohala Coast</p>
<p>Study design and baseline characteristics of Shenzhen ageing-related disorder cohort in China. Li Liu, Wei Liu, Lulin Nie, Zhiwei Guo, Yi Luo, Weihong Chen, Weimin Liu, Feiqi Zhu, Lu Wang, Jiafei Zhang, BMJ open. 10e0343172020. 2020</p>
<p>Multiscale functional connectome abnormality predicts cognitive outcomes in subcortical ischemic vascular disease. Mianxin Liu, Yao Wang, Han Zhang, Qing Yang, Feng Shi, Yan Zhou, Dinggang Shen, Cerebral Cortex. 322022. 2022</p>
<p>Hierarchical Graph Convolutional Network Built by Multiscale Atlases for Brain Disorder Diagnosis Using Functional Connectivity. Mianxin Liu, Han Zhang, Feng Shi, Dinggang Shen, 10.1109/TNNLS.2023.3282961IEEE Transactions on Neural Networks and Learning Systems. 342023. 2023</p>
<p>Linda Teri, and Naaheed Mukadam. 2020. Dementia prevention, intervention, and care: 2020 report of the Lancet Commission. Gill Livingston, Jonathan Huntley, Andrew Sommerlad, David Ames, Clive Ballard, Sube Banerjee, Carol Brayne, Alistair Burns, Jiska Cohen-Mansfield, Claudia Cooper, Amit Sergi G Costafreda, Nick Dias, Laura N Fox, Robert Gitlin, Helen C Howard, Mika Kales, Eric B Kivim√§ki, Adesola Larson, Vasiliki Ogunniyi, Karen Orgeta, Kenneth Ritchie, Elizabeth L Rockwood, Quincy Sampson, Lon S Samus, Geir Schneider, Selbaek, The Lancet. 3962020</p>
<p>Explaining the explainers in graph neural networks: a comparative study. Antonio Longa, Steve Azzolin, Gabriele Santin, Giulia Cencetti, Pietro Li√≤, Bruno Lepri, Andrea Passerini, Comput. Surveys. 572025. 2025</p>
<p>Diffusion tensor fiber tracking of human brain connectivity: aquisition methods, reliability analysis and biological results. Nf Lori, Akbudak, Shimony, Cull, Snyder, Guillory, Conturo, NMR in Biomedicine: An International Journal Devoted to the Development and Application of Magnetic Resonance In Vivo. 152002. 2002</p>
<p>Scott Lundberg, Su-In Lee, arXiv:1705.07874[cs.AIA Unified Approach to Interpreting Model Predictions. 2017</p>
<p>Artificial intelligence for dementia-Applied models and digital health. D M Lyall, A Kormilitzin, C Lancaster, J Sousa, F Petermann-Rocha, C Buckley, E L Harshfield, M H Iveson, C R Madan, R Mcardle, D Newby, V Orgeta, E Tang, S Tamburin, L S Thakur, I Lourida, 10.1002/alz.13391Deep Dementia Phenotyping (DEMON). D J Network, J M Llewellyn, Ranson, 2023. Dec 202319</p>
<p>Attention-guided deep graph neural network for longitudinal Alzheimer's disease analysis. Junbo Ma, Xiaofeng Zhu, Defu Yang, Jiazhou Chen, Guorong Wu, Medical Image Computing and Computer Assisted Intervention-MICCAI 2020: 23rd International Conference. Lima, Peru; Cham, SwitzerlandSpringer2020. October 4-8, 2020Proceedings, Part VII 23</p>
<p>A Multi-Graph Cross-Attention-Based Region-Aware Feature Fusion Network Using Multi-Template for Brain Disorder Diagnosis. Yulan Ma, Weigang Cui, Jingyu Liu, Yuzhu Guo, Huiling Chen, Yang Li, IEEE Transactions on Medical Imaging. 4332024. March 2024</p>
<p>Post-hoc interpretability for neural nlp: A survey. Andreas Madsen, Siva Reddy, Sarath Chandar, Comput. Surveys. 552022. 2022</p>
<p>Brain multiplexes reveal morphological connectional biomarkers fingerprinting late brain dementia states. Ines Mahjoub, Mohamed Ali Mahjoub, Islem Rekik, Scientific Reports. 841032018. 2018</p>
<p>The application of eXplainable artificial intelligence in studying cognition: A scoping review. Shakran Mahmood, Colin Teo, Jeremy Sim, Wei Zhang, Jiang Muyun, Kejia Bhuvana, Tseng Teo, Jia Tsai Yeo, Balazs Lu, Gulyas, 2024. 202410</p>
<p>Ian B Malone, David Cash, Gerard R Ridgway, David G Macmanus, Sebastien Ourselin, Nick C Fox, Jonathan M Schott, MIRIAD-Public release of a multiple time point Alzheimer's MR imaging dataset. 2013. 201370</p>
<p>The Parkinson progression marker initiative (PPMI). Kenneth Marek, Danna Jennings, Shirley Lasch, Andrew Siderowf, Caroline Tanner, Tanya Simuni, Chris Coffey, Karl Kieburtz, Emily Flagg, Sohini Chowdhury, Progress in neurobiology. 952011. 2011</p>
<p>TADPOLE Challenge: Accurate Alzheimer's disease prediction through crowdsourced forecasting of future data. Neil P RƒÉzvan V Marinescu, Alexandra L Oxtoby, Esther E Young, Arthur W Bron, Michael W Toga, Frederik Weiner, Nick C Barkhof, Polina Fox, Stefan Golland, Klein, Predictive Intelligence in Medicine: Second International Workshop, PRIME 2019, Held in Conjunction with MICCAI 2019. Shenzhen, China; Cham, SwitzerlandSpringer2019. October 13. 2019</p>
<p>Interpretable machine learning for dementia: a systematic review. Sophie A Martin, Florence J Townend, Frederik Barkhof, James H Cole, Alzheimer's &amp; Dementia. 192023. 2023</p>
<p>Early-onset Alzheimer disease. Mario F Mendez, Neurologic clinics. 352017. 2017</p>
<p>Kehinde Aruleba, Ikiomoye Douglas Emmanuel, and Blessing Ogbuokiri. 2024. A survey of explainable artificial intelligence in healthcare: Concepts, applications, and challenges. Ibomoiye Domor Mienye, George Obaido, Nobert Jere, Ebikella Mienye, 10.1016/j.imu.2024.101587Informatics in Medicine Unlocked. 511015872024</p>
<p>Unveiling the black box: A systematic review of Explainable Artificial Intelligence in medical image analysis. Dost Muhammad, Malika Bendechache, 10.1016/j.csbj.2024.08.005Computational and Structural Biotechnology Journal. 242024. 2024</p>
<p>frontotemporal-disorders/what-are-frontotemporal-disorders-causes-symptoms-and-treatment Accessed. What Are Frontotemporal Disorders? Causes, Symptoms, and Treatment. 2024National Institute on Aging</p>
<p>From anecdotal evidence to quantitative evaluation methods: A systematic review on evaluating explainable ai. Meike Nauta, Jan Trienes, Shreyasi Pathak, Elisa Nguyen, Michelle Peters, Yasmin Schmitt, J√∂rg Schl√∂tterer, Maurice Van Keulen, Christin Seifert, Comput. Surveys. 552023. 2023</p>
<p>An Explainable Geometric-Weighted Graph Attention Network for Identifying Functional Networks Associated with Gait Impairment. Favour Nerrise, Qingyu Zhao, Kathleen L Poston, Kilian M Pohl, Ehsan Adeli, International Conference on Medical Image Computing and Computer-Assisted Intervention. Cham, SwitzerlandSpringer2023</p>
<p>Interpretable Differential Diagnosis for Alzheimer's Disease and Frontotemporal Dementia. Huy-Dung Nguyen, Micha√´l Cl√©ment, Boris Mansencal, Pierrick Coup√©, Medical Image Computing and Computer-Assisted Intervention -MICCAI 2022. Lecture Notes in Computer Science. Cham, SwitzerlandSpringer2022</p>
<p>Towards better interpretable and generalizable AD detection using collective artificial intelligence. Huy-Dung Nguyen, Micha√´l Cl√©ment, Boris Mansencal, Pierrick Coup√©, Computerized Medical Imaging and Graphics. 1041021712023. 2023</p>
<p>Navigating Uncertainty: A User-Perspective Survey of Trustworthiness of AI in Healthcare. Jaya Ojha, Oriana Presacan, Pedro G Lind, Eric Monteiro, Anis Yazidi, 10.1145/3716317ACM Transactions on Computing for Healthcare. 62025. May 2025</p>
<p>Disease prediction using graph convolutional networks: application to autism spectrum disorder and Alzheimer's disease. Sarah Parisot, Sofia Ira Ktena, Enzo Ferrante, Matthew Lee, Ricardo Guerrero, Ben Glocker, Daniel Rueckert, Medical Image Analysis. 482018. 2018</p>
<p>Explainable deep learning methods in medical image classification: A survey. Cristiano Patr√≠cio, Jo√£o C Neves, Lu√≠s F Teixeira, Comput. Surveys. 562023. 2023</p>
<p>Joint Structural-Functional Brain Graph Transformer. Ciyuan Peng, Huafei Huang, Tianqi Guo, Chengxuan Meng, Jingjing Zhou, Wenhong Zhao, Ruwan Tennakoon, Feng Xia, ACM Transactions on Intelligent Systems and Technology. 162025. 2025</p>
<p>Ciyuan Peng, Yuelong Huang, Qichao Dong, Shuo Yu, Feng Xia, Chengqi Zhang, Yaochu Jin, arXiv:2502.08958Biologically plausible brain graph transformer. 2025. 2025arXiv preprint</p>
<p>Neuroimaging in dementia. Clinical-radiological correlation. J √Ålvarez-Linera Prado, A Jim√©nez-Huete, Radiolog√≠a (English Edition). 612019. 2019</p>
<p>Exploiting Longitudinal Speech Sessions via Voice Assistant Systems for Early Detection of Cognitive Decline. Kristin Qi, Jiatong Shi, Caroline Summerour, John A Batsis, Xiaohui Liang, 2024 IEEE International Conference on E-health Networking, Application &amp; Services (HealthCom). Nara, JapanIEEE2024</p>
<p>A graph convolutional network based on univariate neurodegeneration biomarker for alzheimer's disease diagnosis. Zongshuai Qu, Tao Yao, Xinghui Liu, Gang Wang, IEEE Journal of Translational Engineering in Health and Medicine. 112023. 2023</p>
<p>APOE effect on Alzheimer's disease biomarkers in older adults with significant memory concern. Sungeun Shannon L Risacher, Kwangsik Kim, Tatiana Nho, Li Foroud, Ronald C Shen, Clifford R Petersen, Laurel A JackJr, Beckett, Robert A Paul S Aisen, Koeppe, Alzheimer's &amp; Dementia. 112015. 2015</p>
<p>Presymptomatic studies in genetic frontotemporal dementia. Jd Rohrer, Warren, Fox, Rossor, Revue Neurologique. 1692013. 2013</p>
<p>Neuroimaging in frontotemporal dementia. Jonathan D Rohrer, Howard J Rosen, International Review of Psychiatry. 252013. 2013</p>
<p>Fairness Challenges in the Design of Machine Learning Applications for Healthcare. Seamus Ryan, Wanling Cai, Robert Bowman, Gavin Doherty, 10.1145/3728368ACM Transactions on Computing for Healthcare. 2025. April 2025</p>
<p>Multimodal Brain Connectomics-Based Prediction of Parkinson's Disease Using Graph Attention Networks. Apoorva Safai, Nirvi Vakharia, Shweta Prasad, Jitender Saini, Apurva Shah, Abhishek Lenka, 10.3389/fnins.2021.741489Frontiers in Neuroscience. 157414892022. 2022Pramod Kumar Pal, and Madhura Ingalhalikar</p>
<p>The Role of Deep Learning in Medical Image Inpainting: A Systematic Review. Joana Cristo, Santos , Hugo Tom√°s Pereira Alexandre, Miriam Seoane Santos, Pedro Henriques Abreu, 10.1145/3712710ACM Transactions on Computing for Healthcare. 6pages2025. May 2025</p>
<p>A systematic review of Explainable Artificial Intelligence models and applications: Recent developments and future trends. A Saranya, Subhashini, Decision analytics journal. 71002302023. 2023</p>
<p>A comprehensive taxonomy for explainable artificial intelligence: a systematic survey of surveys on methods and concepts. Gesina Schwalbe, Bettina Finzel, Data Mining and Knowledge Discovery. 382024. 2024</p>
<p>Clinical, genetic and pathological heterogeneity of frontotemporal dementia: a review. Harro Seelaar, Jonathan D Rohrer, Yolande Al Pijnenburg, Nick C Fox, John C Van Swieten, Neurosurgery &amp; Psychiatry. 822011. 2011Journal of Neurology</p>
<p>Neurodegenerative diseases target large-scale human brain networks. William W Seeley, Richard K Crawford, Juan Zhou, Bruce L Miller, Michael D Greicius, Neuron. 622009. 2009</p>
<p>Amyloid ùõΩ-protein and the genetics of Alzheimer's disease. Selkoe Dennis, Journal of Biological Chemistry. 2711996. 1996</p>
<p>Grad-CAM: visual explanations from deep networks via gradient-based localization. Michael Ramprasaath R Selvaraju, Abhishek Cogswell, Ramakrishna Das, Devi Vedantam, Dhruv Parikh, Batra, International journal of computer vision. 1282020. 2020</p>
<p>Episodic memory retrieval, parietal cortex, and the default mode network: functional and topographic analyses. Carlo Sestieri, Maurizio Corbetta, Gian Luca Romani, Gordon L Shulman, Journal of Neuroscience. 312011. 2011</p>
<p>GCCN: Graph Capsule Convolutional Network for Progressive Mild Cognitive Impairment Prediction and Pathogenesis Identification Based on Imaging Genetic Data. Junliang Shang, Qi Zou, Qianqian Ren, Boxin Guan, Feng Li, Jin-Xing Liu, Yan Sun, 10.1109/JBHI.2023.3262948IEEE Journal of Biomedical and Health Informatics. 272023. 2023</p>
<p>Dynamic Graph Transformer for Brain Disorder Diagnosis. Ahsan Shehzad, Dongyu Zhang, Shuo Yu, Shagufta Abid, Feng Xia, IEEE Journal of Biomedical and Health Informatics. 2025. 2025</p>
<p>Explainable brain age prediction using covariance neural networks. Saurabh Sihag, Gonzalo Mateos, Corey Mcmillan, Alejandro Ribeiro, Advances in Neural Information Processing Systems. 362023. 2023</p>
<p>Karen Simonyan, Andrea Vedaldi, Andrew Zisserman, arXiv:1312.6034[cs.CVDeep Inside Convolutional Networks: Visualising Image Classification Models and Saliency Maps. 2014</p>
<p>Karla L Stephen M Smith, Gholamreza Miller, Matthew Salimi-Khorshidi, Christian F Webster, Thomas E Beckmann, Joseph D Nichols, Mark W Ramsey, Woolrich, Network modelling methods for FMRI. 2011. 201154</p>
<p>Temporal Graphormer and Its Interpretability: A Novel Framework for Diagnostic Decoding of Brain Disorders Using fMRI Data. Boyue Song, Shinich Yoshida, 10.1016/j.bspc.2023.107467Biomedical Signal Processing and Control. 1041074672024. 2024</p>
<p>. ACM Trans. Comput. Healthcare. 11January 2025Publication date</p>
<p>Auto-metric graph neural network based on a meta-learning strategy for the diagnosis of Alzheimer's disease. Xiaofan Song, Mingyi Mao, Xiaohua Qian, IEEE Journal of Biomedical and Health Informatics. 252021. 2021</p>
<ol>
<li>s2MRI-ADNet: An interpretable deep learning framework integrating Euclidean-graph representations of Alzheimer's disease solely from structural MRI. Magnetic Resonance Materials in Physics. Z Song, H Li, Y Zhang, C Zhu, M Jiang, L Song, Y Wang, M Ouyang, F Hu, Q Zheng, 10.1007/s10334-024-01178-3Biology and Medicine (MAGMA). 372024</li>
</ol>
<p>Jost Tobias Springenberg, Alexey Dosovitskiy, Thomas Brox, Martin Riedmiller, arXiv:1412.6806[cs.LGStriving for Simplicity: The All Convolutional Net. 2015</p>
<p>UK biobank: an open access resource for identifying the causes of a wide range of complex diseases of middle and old age. Cathie Sudlow, John Gallacher, Naomi Allen, Valerie Beral, Paul Burton, John Danesh, Paul Downey, Paul Elliott, Jane Green, Martin Landray, PLoS medicine. 12e10017792015. 2015</p>
<p>Deena J Rajesh R Tampi, Silpa Tampi, Ambreen Chandran, Megan Ghori, Durning, Mild cognitive impairment: A comprehensive review. 2015. 20154</p>
<p>A Causality-Driven Graph Convolutional Network for Postural Abnormality Diagnosis in Parkinsonians. Xinlu Tang, Rui Guo, Chencheng Zhang, Xiahai Zhuang, Xiaohua Qian, 10.1109/TMI.2023.3305378IEEE Transactions on Medical Imaging. 422023. 2023</p>
<p>Explaining graph convolutional network predictions for clinicians-An explainable AI approach to Alzheimer's disease classification. Sule Tekkesinoglu, Sara Pudas, Frontiers in Artificial Intelligence. 613346132024. 2024</p>
<p>Definition, Diagnose und Management der Parkinson-Demenz: Empfehlungen der Swiss Parkinson's Disease Dementia Study Group. Tettenborni, Vingerhoetsj, Waldvogelk, Schweiz Arch Neurol Psychiatr. 1582007. 2007</p>
<ol>
<li>fMRI-based Brain Disease Diagnosis: A Graph Network Approach. Wei Tong, Yong-Xia Li, Xiao-Yan Zhao, Qi-Qi Chen, Yu-Bing Gao, Ping Li, Edmond Q Wu, 10.1109/TMRB.2023.3270481IEEE Transactions on Medical Robotics and Bionics. 52023</li>
</ol>
<p>Vascular cognitive impairment. M Wiesje, Van Der, Ingmar Flier, Julie A Skoog, Leonardo Schneider, Vincent Pantoni, Mok, Philip Christopher Lh Chen, Scheltens, Nature Reviews Disease Primers. 42018. 2018</p>
<p>Explainable artificial intelligence (XAI) in deep learning-based medical image analysis. H M Bas, Hugo J Van Der Velden, Kenneth Ga Kuijf, Max A Gilhuijs, Viergever, Medical Image Analysis. 791024702022. 2022</p>
<p>Attention Is All You Need. Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Lukasz Kaiser, Illia Polosukhin, arXiv:1706.03762[cs.CL2023</p>
<p>Human brain networks in cognitive decline: a graph theoretical analysis of cortical connectivity from EEG data. Fabrizio Vecchio, Francesca Miraglia, Camillo Marra, Davide Quaranta, Maria Gabriella Vita, Placido Bramanti, Paolo Maria Rossini, Journal of Alzheimer's Disease. 412014. 2014</p>
<p>Explainable artificial intelligence in Alzheimer's disease classification: A systematic review. Noushath Vimbi Viswan, Mufti Shaffi, Karthikeyan Mahmud, Faizal Subramanian, Hajamohideen, Cognitive Computation. 162024. 2024</p>
<p>Aging, lifestyle and dementia. Devin Wahl, Samantha M Solon-Biet, Victoria C Cogger, Luigi Fontana, Stephen J Simpson, David G Le Couteur, Rosilene V Ribeiro, Neurobiology of disease. 1301044812019. 2019</p>
<p>Multimodal approaches and AI-driven innovations in dementia diagnosis: a systematic review. Sarita Revati M Wahul, Ambadekar, Deepesh M Dhanvijay, M Mrinai, Manisha A Dhanvijay, Varsha Dudhedia, Bhavana Gaikwad, Kanawade, Balaji Jr Pansare, Bodkhe, Gawande, Discover Artificial Intelligence. 52025. 2025</p>
<p>. Lujing Wang, Weifeng Yuan, Lu Zeng, Jie Xu, Yujie Mo, Xinxiang Zhao, Liang Peng, 10.1016/j.ipm.2022.102901Dementia Analysis from Functional Connectivity Network with Graph Neural Networks. Information Processing &amp; Management. 591029012022. 2022</p>
<p>Understanding machine learning applications in dementia research and clinical practice: a review for biomedical scientists and clinicians. Y Wang, S Liu, A G Spiteri, A L H Huynh, C Chu, C L Masters, B Goudey, Y Pan, L Jin, Alzheimer's Research &amp; Therapy. 161752024. 2024</p>
<p>Yongjie Wang, Tong Zhang, Xu Guo, Zhiqi Shen, arXiv:2403.10415[cs.AIGradient based Feature Attribution in Explainable AI: A Technical Review. 2024</p>
<p>Dynamic multi-task graph isomorphism network for classification of alzheimer's disease. Zhiqiong Wang, Zican Lin, Shuo Li, Yibo Wang, Weiying Zhong, Xinlei Wang, Junchang Xin, Applied Sciences. 1384332023. 2023</p>
<p>World Health Organization. Infographic on Dementia. 2024</p>
<p>Dual-Graph Learning Convolutional Networks for Interpretable Alzheimer's Disease Diagnosis. Tingsong Xiao, Lu Zeng, Xiaoshuang Shi, Xiaofeng Zhu, Guorong Wu, 10.1007/978-3-031-16452-1_39Proceedings of the International Conference on Medical Image Computing and Computer-Assisted Intervention (MICCAI). the International Conference on Medical Image Computing and Computer-Assisted Intervention (MICCAI)Cham, SwitzerlandSpringer2022</p>
<p>Usman Naseem, and Feng Xia. 2024. Multimodal hyperbolic graph learning for alzheimer's disease detection. Chengyao Xie, Wenhao Zhou, Ciyuan Peng, Azadeh Noori Hoshyar, Chengpei Xu, Australasian Joint Conference on Artificial Intelligence. Springer</p>
<p>Contrastive Graph Pooling for Explainable Classification of Brain Networks. Jiaxing Xu, Qingtian Bian, Xinhang Li, Aihu Zhang, Yiping Ke, Miao Qiao, Wei Zhang, Wei Khang, Jeremy Sim, Bal√°zs Guly√°s, 10.1109/TMI.2024.3392988IEEE Transactions on Medical Imaging. 432024. 2024</p>
<p>Interpretable Medical Deep Framework by Logits-Constraint Attention Guiding Graph-Based Multi-Scale Fusion for Alzheimer's Disease Analysis. Jinghao Xu, Chenxi Yuan, Xiaochuan Ma, Huifang Shang, Xiaoshuang Shi, Xiaofeng Zhu, 10.1016/j.patcog.2024.110450Pattern Recognition. 1521104502024. 2024</p>
<p>Current pathogenesis and approaches to symptom relief of the Alzheimer's disease. Le Xu, International Conference on Modern Medicine and Global Health (ICMMGH 2023). Bellingham, WA, USA202312789</p>
<p>Multi-modal Dynamic Graph Network: Coupling Structural and Functional Connectome for Disease Diagnosis and Classification. Yanwu Yang, Xutao Guo, Zhikai Chang, Chenfei Ye, Yang Xiang, Ting Ma, 10.1109/BIBM55620.2022.99956422022 IEEE International Conference on Bioinformatics and Biomedicine (BIBM). Los Alamitos, CA, USAIEEE2022</p>
<p>Rex Ying, Dylan Bourgeois, Jiaxuan You, Marinka Zitnik, Jure Leskovec, arXiv:1903.03894[cs.LGGNNExplainer: Generating Explanations for Graph Neural Networks. 2019</p>
<p>Brain-Aware Readout Layers in GNNs: Advancing Alzheimer's Early Detection and Neuroimaging. Jiwon Youn, Dong Woo Kang, Hyun Kook Lim, Mansu Kim, International Workshop on Human Brain and Artificial Intelligence. Cham, SwitzerlandSpringer2024</p>
<p>Long-range brain graph transformer. Shuo Yu, Shan Jin, Ming Li, Tabinda Sarwar, Feng Xia, Advances in Neural Information Processing Systems. 372024. 2024</p>
<p>Explainability in graph neural networks: A taxonomic survey. Haiyang Hao Yuan, Shurui Yu, Shuiwang Gui, Ji, 2022. 202245</p>
<p>Visualizing and understanding convolutional networks. D Matthew, Rob Zeiler, Fergus, Computer Vision-ECCV 2014: 13th European Conference. Zurich, Switzerland; Cham, SwitzerlandSpringer2014. September 6-12, 2014Proceedings, Part I 13</p>
<p>Graph convolutional network with sample and feature weights for Alzheimer's disease diagnosis. Lu Zeng, Hengxin Li, Tingsong Xiao, Fumin Shen, Zhi Zhong, Information Processing &amp; Management. 591029522022. 2022</p>
<p>A feature-aware multimodal framework with auto-fusion for Alzheimer's disease diagnosis. Meiwei Zhang, Qiushi Cui, Yang L√º, Wenyuan Li, Computers in Biology and Medicine. 1781087402024. 2024</p>
<p>Early Diagnosis and Biomarkers of Alzheimer's Disease Based on Spatio-temporal Graph Convolution Network. Ying Zhang, Juanjuan Jiang, Ronghua Ling, Luyao Wang, Jiehui Jiang, Min Wang, 2023 45th Annual International Conference of the IEEE Engineering in Medicine &amp; Biology Society (EMBC). Seattle, WA, USAIEEE2023</p>
<p>A novel spatiotemporal graph convolutional network framework for functional connectivity biomarkers identification of Alzheimer's disease. Ying Zhang, Le Xue, Shuoyan Zhang, Jiacheng Yang, Qi Zhang, Min Wang, Luyao Wang, Mingkai Zhang, Jiehui Jiang, Yunxia Li, Alzheimer's Research &amp; Therapy. 16602024. 2024</p>
<p>An Interpretable Model Based on Graph Learning for Diagnosis of Parkinson's Disease with Voice-Related EEG. Shuzhi Zhao, Guangyan Dai, Jingting Li, Xiaoxia Zhu, Xiyan Huang, Yongxue Li, Mingdan Tan, Lan Wang, Peng Fang, Xi Chen, Xinyue Zhang, Qiang Liu, Wei Xu, 10.1038/s41746-023-00964-2NPJ Digital Medicine. 732024. 2024</p>
<p>Learning deep features for discriminative localization. Bolei Zhou, Aditya Khosla, Agata Lapedriza, Aude Oliva, Antonio Torralba, Proceedings of the IEEE conference on computer vision and pattern recognition. the IEEE conference on computer vision and pattern recognitionSeattle, WA, USA2016</p>
<p>Interpretable Graph Convolutional Network Of Multi-Modality Brain Imaging For Alzheimer's Disease Diagnosis. Houliang Zhou, Lifang He, Yu Zhang, Li Shen, Brian Chen, 10.1109/ISBI52829.2022.97614492022 IEEE 19th International Symposium on Biomedical Imaging (ISBI). Kauai, HI, USAIEEE2022</p>
<p>Sparse interpretation of graph convolutional networks for multi-modal diagnosis of Alzheimer's disease. Houliang Zhou, Yu Zhang, Brian Y Chen, Li Shen, Lifang He, International Conference on Medical Image Computing and Computer-Assisted Intervention (MICCAI). ChamSpringer2022</p>
<p>Interpretable Graph Convolutional Network for Alzheimer's Disease Diagnosis using Multi-Modal Imaging Genetics. Houliang Zhou, Yu Zhang, Lifang He, Li Shen, Brian Y Chen, 2023 IEEE International Conference on Bioinformatics and Biomedicine (BIBM). Istanbul, TurkeyIEEE2023</p>
<p>Graph neural networks: A review of methods and applications. Jie Zhou, Ganqu Cui, Shengding Hu, Zhengyan Zhang, Cheng Yang, Zhiyuan Liu, Lifeng Wang, Changcheng Li, Maosong Sun, 10.1016/j.aiopen.2021.01.001AI Open. 12020. 2020</p>
<p>Interpretable Learning-Based Dynamic Graph Convolutional Networks for Alzheimer's Disease Analysis. Yonghua Zhu, Junbo Ma, Changan Yuan, Xiaofeng Zhu, 10.1016/j.inffus.2021.07.013Information Fusion. 772022. 2022</p>            </div>
        </div>

    </div>
</body>
</html>