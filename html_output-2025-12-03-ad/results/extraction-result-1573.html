<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-1573 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-1573</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-1573</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-31.html">extraction-schema-31</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of genetic/evolutionary algorithms that use crossover and mutation operations on code, programs, or literature to generate new solutions, with particular attention to measures of novelty, diversity, executability, and functionality.</div>
                <p><strong>Paper ID:</strong> paper-257632232</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2303.11026v1.pdf" target="_blank">A Framework for Learning Behavior Trees in Collaborative Robotic Applications</a></p>
                <p><strong>Paper Abstract:</strong> In modern industrial collaborative robotic applications, it is desirable to create robot programs automatically, intuitively, and time-efficiently. Moreover, robots need to be controlled by reactive policies to face the unpredictability of the environment they operate in. In this paper we propose a framework that combines a method that learns Behavior Trees (BTs) from demonstration with a method that evolves them with Genetic Programming (GP) for collaborative robotic applications. The main contribution of this paper is to show that by combining the two learning methods we obtain a method that allows non-expert users to semi-automatically, time-efficiently, and interactively generate BTs. We validate the framework with a series of manipulation experiments. The BT is fully learnt in simulation and then transferred to a real collaborative robot.</p>
                <p><strong>Cost:</strong> 0.009</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e1573.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e1573.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of genetic/evolutionary algorithms that use crossover and mutation operations on code, programs, or literature to generate new solutions, with particular attention to measures of novelty, diversity, executability, and functionality.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GP-BT</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Genetic Programming for Behavior Trees (GP evolving BTs)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A genetic programming system that evolves behavior trees (BTs) as tree-structured programs using subtree crossover and node-level mutations, evaluated by task execution in simulation with a fitness combining task error, tree size penalty and penalties for timeout/failure.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Genetic Programming for Behavior Trees (GP-BT)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>An evolutionary system that represents robot control policies as Behavior Trees (BTs) and evolves populations of BTs via GP. Individuals are evaluated by running them in a physics simulator and scored by a fitness function that trades off task success (Euclidean distance of objects to goal), tree complexity (node count), and penalties for timeout and failure. The system uses tournament selection, elitism, subtree crossover, and node-level mutation to generate offspring and can be seeded/boosted with BTs learned from demonstration (LfD) to accelerate convergence and avoid local optima.</td>
                        </tr>
                        <tr>
                            <td><strong>input_type</strong></td>
                            <td>programs (Behavior Trees)</td>
                        </tr>
                        <tr>
                            <td><strong>crossover_operation</strong></td>
                            <td>Subtree crossover: a random subtree is selected from each of two parent BT individuals; the selected subtree from each parent is inserted into the other parent at a random insertion point. The modular tree structure of BTs ensures subtrees can be swapped without breaking the overall representation.</td>
                        </tr>
                        <tr>
                            <td><strong>mutation_operation</strong></td>
                            <td>Node-level mutations: operations can add, delete, or change nodes. The implementation allows up to a user-specified maximum number of mutations per individual (Table I: max 3). Mutation probabilities used in experiments: add 10%, delete 50%, change 40%. Mutation may change whether a node is a control or execution node with user-selected probability; some constraints are enforced (avoid same control node on two consecutive levels, avoid child-less control nodes, avoid identical adjacent nodes). Number of mutation offspring per parent: 2.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_literature</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>uses_code</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>executability_metric</strong></td>
                            <td>Fitness function F = - Σ_{o in O} max(0, ||o - g||) - λ L - τ T - φ F, where ||o-g|| is mm Euclidean distance between object's current and goal pose, L is number of nodes (length penalty λ), T is indicator for timeout (penalty τ), and F is indicator for Failure (penalty φ). Parameter values used in experiments listed in Table I (λ=10, τ=30, φ=50).</td>
                        </tr>
                        <tr>
                            <td><strong>executability_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>diversity_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>diversity_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_executability_tradeoff</strong></td>
                            <td>The paper discusses the general trade-off between task specificity and generalizability in fitness design (i.e., overly task-specific fitness may speed convergence but reduce reusability). It does not present a quantitative tradeoff analysis between novelty and executability.</td>
                        </tr>
                        <tr>
                            <td><strong>frontier_characterization</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_or_domain</strong></td>
                            <td>Robotic manipulation / kitting tasks (stacking and placement tasks for boxes in a simulated kitting box, transferred to a real collaborative robot).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Baselines in experiments: (a) GP without demonstration seeding (GP alone), (b) BT learned from demonstration (LfD) alone, and (c) GP seeded/boosted with BTs from LfD. Prior/planner-seeded GP studied in earlier work [9] is also used conceptually as baseline.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Crossover and mutation operate on BT subtrees and node-level edits respectively; GP benefits substantially when seeded/boosted with BTs learned from demonstration (faster convergence, higher fitness, ability to escape local optima). Seeding with demonstrated BTs allows GP to recombine and further optimize demonstrated subtasks (Experiments 1–3). The authors also note design choices to promote diversity (they deliberately do not constrain mutation to nodes of same type) and to reduce search space (predefined gene pool of pick-place subtrees), but the paper provides no quantitative measures of novelty or diversity; executability/functionality is captured implicitly by the fitness function but explicit success rates or numeric executability statistics are not reported.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1573.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e1573.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of genetic/evolutionary algorithms that use crossover and mutation operations on code, programs, or literature to generate new solutions, with particular attention to measures of novelty, diversity, executability, and functionality.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GE</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Grammatical Evolution (GE)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A grammar-guided evolutionary technique that evolves genotypes (integer/bit strings) mapped via a grammar to phenotypic programs/behavior trees; mentioned as a related approach for evolving BTs in games and robotics, with known genotype-phenotype locality and analysis challenges.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Grammatical Evolution (GE)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>GE uses an evolutionary search over genotypes that are mapped via a user-defined grammar to produce executable programs (phenotypes). The grammar design encodes domain knowledge; GE has been applied to evolve BTs for games. The paper notes that GE requires domain-specific grammar engineering and that the genotype-phenotype disconnect can hinder locality and heuristics.</td>
                        </tr>
                        <tr>
                            <td><strong>input_type</strong></td>
                            <td>programs (via grammar-derived program trees / behavior trees)</td>
                        </tr>
                        <tr>
                            <td><strong>crossover_operation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>mutation_operation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uses_literature</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uses_code</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>executability_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>executability_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>diversity_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>diversity_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_executability_tradeoff</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>frontier_characterization</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_or_domain</strong></td>
                            <td>Mentioned in context of evolving behavior trees for computer games (e.g., Mario AI) and swarm/agent behaviors.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Mentioned as alternative to tree-based GP; paper cites that GE requires grammar design and has locality issues compared to direct-tree GP.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>GE is acknowledged as successful in prior work for evolving BTs in games, but the paper highlights drawbacks: increased engineering effort for grammar design and genotype-phenotype disconnect that can reduce locality and complicate analysis; GE is mentioned only in related work and not used in experiments here.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Genetic programming as a means for programming computers by natural selection <em>(Rating: 2)</em></li>
                <li>Learning Behavior Trees with Genetic Programming in Unpredictable Environments <em>(Rating: 2)</em></li>
                <li>Evolving Behaviour Trees for the Mario AI Competition Using Grammatical Evolution <em>(Rating: 2)</em></li>
                <li>Evolving Behaviour Trees for the Commercial Game DEFCON <em>(Rating: 2)</em></li>
                <li>Learning of Behavior Trees for Autonomous Agents <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-1573",
    "paper_id": "paper-257632232",
    "extraction_schema_id": "extraction-schema-31",
    "extracted_data": [
        {
            "name_short": "GP-BT",
            "name_full": "Genetic Programming for Behavior Trees (GP evolving BTs)",
            "brief_description": "A genetic programming system that evolves behavior trees (BTs) as tree-structured programs using subtree crossover and node-level mutations, evaluated by task execution in simulation with a fitness combining task error, tree size penalty and penalties for timeout/failure.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "Genetic Programming for Behavior Trees (GP-BT)",
            "system_description": "An evolutionary system that represents robot control policies as Behavior Trees (BTs) and evolves populations of BTs via GP. Individuals are evaluated by running them in a physics simulator and scored by a fitness function that trades off task success (Euclidean distance of objects to goal), tree complexity (node count), and penalties for timeout and failure. The system uses tournament selection, elitism, subtree crossover, and node-level mutation to generate offspring and can be seeded/boosted with BTs learned from demonstration (LfD) to accelerate convergence and avoid local optima.",
            "input_type": "programs (Behavior Trees)",
            "crossover_operation": "Subtree crossover: a random subtree is selected from each of two parent BT individuals; the selected subtree from each parent is inserted into the other parent at a random insertion point. The modular tree structure of BTs ensures subtrees can be swapped without breaking the overall representation.",
            "mutation_operation": "Node-level mutations: operations can add, delete, or change nodes. The implementation allows up to a user-specified maximum number of mutations per individual (Table I: max 3). Mutation probabilities used in experiments: add 10%, delete 50%, change 40%. Mutation may change whether a node is a control or execution node with user-selected probability; some constraints are enforced (avoid same control node on two consecutive levels, avoid child-less control nodes, avoid identical adjacent nodes). Number of mutation offspring per parent: 2.",
            "uses_literature": false,
            "uses_code": true,
            "novelty_metric": null,
            "novelty_results": null,
            "executability_metric": "Fitness function F = - Σ_{o in O} max(0, ||o - g||) - λ L - τ T - φ F, where ||o-g|| is mm Euclidean distance between object's current and goal pose, L is number of nodes (length penalty λ), T is indicator for timeout (penalty τ), and F is indicator for Failure (penalty φ). Parameter values used in experiments listed in Table I (λ=10, τ=30, φ=50).",
            "executability_results": null,
            "diversity_metric": null,
            "diversity_results": null,
            "novelty_executability_tradeoff": "The paper discusses the general trade-off between task specificity and generalizability in fitness design (i.e., overly task-specific fitness may speed convergence but reduce reusability). It does not present a quantitative tradeoff analysis between novelty and executability.",
            "frontier_characterization": null,
            "benchmark_or_domain": "Robotic manipulation / kitting tasks (stacking and placement tasks for boxes in a simulated kitting box, transferred to a real collaborative robot).",
            "comparison_baseline": "Baselines in experiments: (a) GP without demonstration seeding (GP alone), (b) BT learned from demonstration (LfD) alone, and (c) GP seeded/boosted with BTs from LfD. Prior/planner-seeded GP studied in earlier work [9] is also used conceptually as baseline.",
            "key_findings": "Crossover and mutation operate on BT subtrees and node-level edits respectively; GP benefits substantially when seeded/boosted with BTs learned from demonstration (faster convergence, higher fitness, ability to escape local optima). Seeding with demonstrated BTs allows GP to recombine and further optimize demonstrated subtasks (Experiments 1–3). The authors also note design choices to promote diversity (they deliberately do not constrain mutation to nodes of same type) and to reduce search space (predefined gene pool of pick-place subtrees), but the paper provides no quantitative measures of novelty or diversity; executability/functionality is captured implicitly by the fitness function but explicit success rates or numeric executability statistics are not reported.",
            "uuid": "e1573.0"
        },
        {
            "name_short": "GE",
            "name_full": "Grammatical Evolution (GE)",
            "brief_description": "A grammar-guided evolutionary technique that evolves genotypes (integer/bit strings) mapped via a grammar to phenotypic programs/behavior trees; mentioned as a related approach for evolving BTs in games and robotics, with known genotype-phenotype locality and analysis challenges.",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_name": "Grammatical Evolution (GE)",
            "system_description": "GE uses an evolutionary search over genotypes that are mapped via a user-defined grammar to produce executable programs (phenotypes). The grammar design encodes domain knowledge; GE has been applied to evolve BTs for games. The paper notes that GE requires domain-specific grammar engineering and that the genotype-phenotype disconnect can hinder locality and heuristics.",
            "input_type": "programs (via grammar-derived program trees / behavior trees)",
            "crossover_operation": null,
            "mutation_operation": null,
            "uses_literature": null,
            "uses_code": true,
            "novelty_metric": null,
            "novelty_results": null,
            "executability_metric": null,
            "executability_results": null,
            "diversity_metric": null,
            "diversity_results": null,
            "novelty_executability_tradeoff": null,
            "frontier_characterization": null,
            "benchmark_or_domain": "Mentioned in context of evolving behavior trees for computer games (e.g., Mario AI) and swarm/agent behaviors.",
            "comparison_baseline": "Mentioned as alternative to tree-based GP; paper cites that GE requires grammar design and has locality issues compared to direct-tree GP.",
            "key_findings": "GE is acknowledged as successful in prior work for evolving BTs in games, but the paper highlights drawbacks: increased engineering effort for grammar design and genotype-phenotype disconnect that can reduce locality and complicate analysis; GE is mentioned only in related work and not used in experiments here.",
            "uuid": "e1573.1"
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Genetic programming as a means for programming computers by natural selection",
            "rating": 2,
            "sanitized_title": "genetic_programming_as_a_means_for_programming_computers_by_natural_selection"
        },
        {
            "paper_title": "Learning Behavior Trees with Genetic Programming in Unpredictable Environments",
            "rating": 2,
            "sanitized_title": "learning_behavior_trees_with_genetic_programming_in_unpredictable_environments"
        },
        {
            "paper_title": "Evolving Behaviour Trees for the Mario AI Competition Using Grammatical Evolution",
            "rating": 2,
            "sanitized_title": "evolving_behaviour_trees_for_the_mario_ai_competition_using_grammatical_evolution"
        },
        {
            "paper_title": "Evolving Behaviour Trees for the Commercial Game DEFCON",
            "rating": 2,
            "sanitized_title": "evolving_behaviour_trees_for_the_commercial_game_defcon"
        },
        {
            "paper_title": "Learning of Behavior Trees for Autonomous Agents",
            "rating": 1,
            "sanitized_title": "learning_of_behavior_trees_for_autonomous_agents"
        }
    ],
    "cost": 0.00890225,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>A Framework for Learning Behavior Trees in Collaborative Robotic Applications</p>
<p>Matteo Iovino 
Jonathan Styrud 
Pietro Falco 
Christian Smith 
A Framework for Learning Behavior Trees in Collaborative Robotic Applications
Index Terms-Behavior TreesGenetic ProgrammingLearn- ing from DemonstrationCollaborative Robotics
In modern industrial collaborative robotic applications, it is desirable to create robot programs automatically, intuitively, and time-efficiently. Moreover, robots need to be controlled by reactive policies to face the unpredictability of the environment they operate in. In this paper we propose a framework that combines a method that learns Behavior Trees (BTs) from demonstration with a method that evolves them with Genetic Programming (GP) for collaborative robotic applications. The main contribution of this paper is to show that by combining the two learning methods we obtain a method that allows non-expert users to semi-automatically, time-efficiently, and interactively generate BTs. We validate the framework with a series of manipulation experiments. The BT is fully learnt in simulation and then transferred to a real collaborative robot.</p>
<p>I. INTRODUCTION</p>
<p>Modern industrial robots can solve complex tasks in controlled environments with high precision and reliability. However, trends in automation are pointing towards smaller production series with the robots program needing more frequent updates. At the same time, robots are increasingly operating in workspaces shared with humans, causing a more unpredictable environment. It is therefore desirable that new robot policies or programs can be created quickly without needing high programming skills and that the resulting programs are reactive to changes in the environment. One way to alleviate the demand for programming skills is to have the user provide input in the form of demonstrations rather than code. The contributions of this paper is a framework that combines a method that evolves Behavior Trees (BTs) with Genetic Programming (GP) with a method that learns BTs from demonstration. By combining the two methods it is possible to learn BTs in an unsupervised fashion while exploiting human experience in task solving.</p>
<p>The method allows non-expert users to semi-automatically, time-efficiently, and interactively generate BTs for manipulation tasks. The interaction is facilitated by a user interface This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible. This project is financially supported by the Swedish Foundation for Strategic Research  that allows users to start and stop the learning process at will as well as inputting demonstrations. As a result, the shortcomings of the two individual components are resolved by their combination.</p>
<p>The code repository for this paper is available online 1 .</p>
<p>II. BACKGROUND AND RELATED WORK</p>
<p>A. Behavior Trees</p>
<p>BTs are a task switching policy representation originating in the gaming industry and later transferred to robotics [1].</p>
<p>A BT is represented as a directed tree where a tick signal originates from the root and propagates down the tree with a depth-first pre-order traversal. Nodes execute only when they receive the tick signal and return one of the status signals Success, Failure, and Running. Internal nodes are called control flow nodes (polygons in Figure 1). The most common types being Sequence: runs children in a sequence, returning once all succeed or one fails, and Fallback (or Selector): runs children in a sequence, returning when one succeeds or all fail. Leaves are called execution nodes or behaviors (ovals in Figure 1) and are of type Action(!) or Condition(?). The former encode robot skills while the latter encode status checks and sensory readings, thus immediately returning Success or Failure.</p>
<p>BTs have explicit support for task hierarchy, action sequencing, and reactivity [2]. They are modular by design because every element shares the same infrastructure: every node receives the tick as input and outputs the return statuses. Moreover, modularity allows every building block to be independently tested and reused. The Running return state grants the reactivity property because a running action can be preempted by higher priority ones. BTs improve on other task plans representations, such as Finite State Machine, especially in terms of modularity and reactivity [3]- [5].</p>
<p>B. Evolving BTs with Genetic Programming</p>
<p>Genetic Programming (GP) is an unsupervised optimization algorithm that can evolve programs represented as trees [7] using the operators crossover and mutation. Individuals are evaluated by performing a task in the environment they operate in through a fitness function and selection methods that decide which individuals survive and produce offspring. GP is particularly fit to learn BTs because their modularity facilitates reproduction operations, they are a tree representation, and they can be serialized to reduce the computational effort of the evolutionary process.</p>
<p>The GP algorithm illustrated in Figure 2-bottom is based on our prior works [8], [9] and inspired by [10]. The main evolutionary steps are: 1) Reproduction: When generating the offspring, the mutation operation can add, delete, or change nodes with a user selected probability to choose a control or execution node. With crossover a random subtree is selected from each of two parent individuals and inserted in the other individual at a random point. The modularity of BTs is the key feature of this step because subtrees can be moved without compromising the logical functioning of the tree. 2) Evaluation: Each individual is run in the simulation environment and a fitness function is evaluated to assess the individual's score. The design of the fitness function has to trade-off generalizability with specificity. A fitness function that is too task specific can improve the convergence rate but it is not re-usable, thus increasing the engineering effort. Similarly to [9], we consider the Euclidean distance between objects current and goal positions, the size of the tree, the number of ticks required to run the individual, and if the BT terminates with a Success or Failure state. 3) Selection: To determine the individuals that survive to the next generation we perform tournament selection, where individuals are compared in randomly assigned pairs. Out of each pair, only the best scoring individual survives. This method grants high recombination of genes but it always keeps the best scoring individual and discards the worst one. This approach is explainable in the sense that each step of the algorithm is controllable and predictable. Moreover, it is easy to implement. The main shortcoming is the high number of learning episodes required to converge. Therefore, it benefits from a fast simulator since every individual must be tested and evaluated. In [9], we mitigated this problem by bootstrapping the GP with planned BTs solving subtasks.</p>
<p>Our approach uses similar constraints as in [11]. We avoid to use the same type of control node on two consecutive levels of the tree, conditions on the rightmost position of a sub-tree, child-less control nodes, or having identical nodes next to each other, as all these are unnecessary variations of the BT. Unlike [12], we do not constrain mutation to nodes of the same type, to increase diversity. We also let the GP algorithm find the conditions to use instead of explicitly specifying them. Some conditions that actions must always check are included within the action behaviors.</p>
<p>C. Learning BTs from Demonstration</p>
<p>Learning from Demonstration (LfD) methods allow robots to learn programs from human demonstrations [13]. This method is especially useful when users do not have enough programming skills, or writing robot programs to solve a task takes too long. Demonstrations can be given in the form of kinesthetic teaching, where the user physically moves the robot, teleoperation, where a robot is controlled through an external device-particularly useful when the robot operates in unreachable environments-and passive observation, where the robot or the human are endowed with tracking systems and the demonstrator's body motion is recorded. These methods are often intuitive and little to no training is required for the user.</p>
<p>Our method to learn BTs from demonstration proposed in [14] and schematically outlined in Figure 2-top, builds on the following steps:</p>
<p>1) The user inputs the demonstrations through the user interface as a sequence of actions that brings items in the environment from a starting to a goal configuration. For every performed action in the demonstration, we record the pose of the end-effector in the reference frame of all the relevant objects for the task as well as the type of the action performed. 2) Similar actions across different demonstrations of the same task are clustered together to infer their frame of reference. The clustering algorithm requires at least 3 demonstrations to infer the reference frame, otherwise the base frame of the robot is used as default value. 3) It is assumed that the user solves the task by the end of the demonstration. Therefore, the configuration of the items when the last action is performed is used as goal condition. Other task constraints on the order of the actions are inferred as well. 4) A planner similar to the one defined in [15] is used to automatically generate the BT with backchain design, provided that the actions are defined together with their pre-and post-conditions. With backchaining, starting from the goal, pre-conditions are iteratively expanded with actions that achieve them-those actions that have that particular condition as their post-conditions. Then, those actions' unmet pre-conditions are expanded in the same way. In [16] we extend this method to allow the robot to ask the user follow-up clarification questions if there are ambiguities in the task to solve. For instance, when there are equivalent items available for the robot to pick.</p>
<p>The main shortcoming of this method is that it does not generalize well when the task to demonstrate requires many actions. Performing several demonstrations might be tedious and source of errors, especially when combined with perception algorithms whose performance is affected by lighting conditions and object occlusion.</p>
<p>D. Related Work</p>
<p>Evolutionary approaches to learn BTs were first applied to computer games [11], [12], [17]- [21] but later years have also seen it applied to robotic applications [8], [9], [22]- [25].</p>
<p>Authors in [18], [19] successfully use Grammatical Evolution (GE). With GE, the design of the grammar requires domain knowledge and the engineering effort grows with the complexity of the task. Further, the disconnect between genotype and phenotype can make analysis and implementing heuristics difficult and hinders locality [26], [27]. In [11], [20], [21], structural and dynamic constraints were implemented in the GP, speeding up the learning by preventing the generation of undesirable trees. Similar constraints are also used in our implementation. In [12], GP was combined with a local search but this is harder to re-implement in a nondeterministic robotic scenario. Most notably, [9] presented a method to combine the results from a planner with a GP algorithm. An adaptation of that method is what we use in the proposed approach of this paper to seed the GP with the information gathered in the demonstrations.</p>
<p>There has been some previous work on combining LfD and BTs [14], [16], [28]- [31]. The method proposed in [28], [29], and [32] learns a Decision Tree (DT) to map from state space to action space. The DT is then converted into a BT using the fact that BTs generalize DTs [4]. In [30], the method directly encodes the demonstrated sequence of actions as a BT and in [31] BTs are generated by natural language instructions.</p>
<p>In [28], LfD was used to assist in creating behaviors for Non-Player Characters (NPCs) in computer games. A DT was trained as a policy choosing the NPCs next action depending on the game state. The DT was flattened into a set of rules, then simplified and translated into a BT. The BT required a final tuning of its parameters, thus limiting its usage. This was extended by [29] and improved in [32] who generalized it to use any logic minimizer on the DT. The solution is implemented on a mobile manipulator to perform a house-cleaning task. In this work, the whole action space and state space were encoded in the final tree which would then contain elements that are not used at run-time and unnecessarily complicate the structure. Further, the frame of reference was fixed in the actions which limits their reusability. The method does not make use of any previous knowledge of the behaviors and it can only execute behaviors that were demonstrated.</p>
<p>In [30] the BT was synthesized directly. An agent was trained to play the video game StarCraft from expert demonstrations. Each demonstration resulted in a sequence of actions placed under a sequence node in the BT, then all sequence nodes for each demonstration were placed under a fallback node. Finally, the BT was simplified by finding similarities between different demonstrations. This approach results in large and hard to read BTs (&gt; 50.000 nodes) and limits the reactivity as in-game actions and conditions are all put under the same Sequence node.</p>
<p>Finally, in [31] authors proposed a method for generating BTs from natural language instructions. The method parses the instruction and searches a database for trees solving the requested task. If none are found, a new tree is learned by matching the parsed expression to hand-coded primitive methods as simple BTs. Although the method allows to define a wide variety of tasks, the learned trees are hard to read and it is not clear how the method would handle tasks where the relative position of objects in the scene matters.</p>
<p>Other LfD methods learn task plans without using BTs, but instead using a Finite State Machine [33] or a Hidden Markov Model [34]. In [35] plans were created by chaining skills that have an effect that allows the next skill to be executed successfully. Chains from multiple demonstrations were combined into a skill tree with multiple chains that achieve the same goal. The main advantage of using BTs over these methods is the inherent reactivity and increased readability of BTs.</p>
<p>The method in this paper mainly builds upon [14] which in turn was built on the work of [36] and [15]. The method presented in [36] uses demonstrations to gather information on order of actions. With multiple demonstrations it can also learn to generalize instead of just repeating the demonstrations. However, the built plan is fixed and not reactive to external disturbances.</p>
<p>The later work of [15] presented a planner to iteratively build a BT. In each iteration the current tree is executed and failing pre-conditions are replaced with subtrees that execute actions with appropriate post-conditions, a method called backchaining. The BT is built at run-time and the result is therefore not deterministic and depends on the state of the environment. After that, [14] expanded on the backchaining idea while also incorporating LfD and learnt also reference frames and context of each behavior using a clustering approach, thereby making more types of tasks solvable. However, it still relies on having a planner that is able to solve the task at hand. The method of this paper combines BTs learnt from user demonstrations with ones evolved by GP in an interactive way. On a higher level, our method alternates demonstration steps with evolutionary ones. The idea is that user demonstrations can be exploited to bootstrap the GP algorithm, to edit the output from the GP, or to provide new information to the GP if the evolutionary process is stuck in local optima. For this reasons, we let users to interact with the learning framework through the user interface in Figure 3, where they can input demonstrations, start-stop-resume the GP, and visualize or run the learnt BT. We therefore have a framework that automatically generates BTs while exploiting user experience in task solving. The demonstrations are provided in simulation, by selecting the type of action to perform:</p>
<p>III. PROPOSED METHOD</p>
<p>• Pick: a drop-down menu is generated allowing the user to select the item to pick. This action will make the gripper to grasp the selected object; • Place: the user takes control of the gripper that can be teleoperated through the keyboard and moved to the desired position, as shown in Figure 4. Then, the gripper releases the grasped object. A BT generated this way to pick and place an item is shown in Figure 1.</p>
<p>For the gene pool of the GP algorithm, we combine pick and place of the same object in a single subtree that we consider as a behavior/gene (Figure 1). This is due to the fact that for every movable item (e.g. the boxes) we sample 5 target positions in the reference frame of every other item (corresponding to left, right, above, below, and on top), plus 9 target positions inside the kit box. The reason behind this design choice is to constrain the search space, and we can assume that such a list of hand-coded/learnt subtrees for standardized actions are provided beforehand. Nonetheless, the gene pool counts 61 behaviors (56 for pick and place objects plus 5 related to the gripper).</p>
<p>For the design of the fitness function, we follow the guidelines of [9]. Since the tasks consist of moving objects, we base the fitness function on the Euclidean distance between objects current and target positions. A factor λ penalizes larger trees over smaller ones thus preventing the learnt solution from bloating. Then, τ is removed from any tree that ends by timeout to prevent the GP from exploiting the fact that we interrupt the simulation of an individual after a certain amount of time. Finally, φ is removed from trees that end in Failure state. Similarly to [9], the fitness function can be thus modelled as
F = − O max(0, ||o − g||) − λL − τ T − φF(1)
where O is the set of objects with current positions o and goals g, with ||o − g|| the distance error in mm. L is the number of nodes. T is 1 if the tree ended by timeout and 0 otherwise and F is 1 if the tree ended in Failure state and 0 otherwise. The values used for the experiments of Section IV are reported in Table I. Note that the goal of the paper is to show the benefits of the combined GP and LfD approaches. By combining the two approaches, less effort is required in finding an optimal choice for the parameters through hyperparameter search. The simulation environment builds on AGX Dynamics from Algoryx 2 . In prior work [8] we designed a probabilistic state machine as simulator to make the simulation faster and the problem tractable. With AGX Dynamics instead, we can simplify the simulation environment at will. For the experiments, we idealize the robot by simulating only a gripper that can teleport directly above the target. In this way, we simulate only the physical properties that are relevant for the task, such as contacts between objects and gravity, disregarding the rest. We achieve a simulation rate that is 100 times faster than real-time when the graphics are disabled. Having the possibility to decide the levels of fidelity, allows users to test if the learnt solution also works in a model of the environment closer to reality. In this paper, we skip this step by transferring the solution directly to the real robot.</p>
<p>From what concerns the implementation, the GUI controls the simulation through processes. Therefore, it is possible to run several instances of the simulation in parallel.</p>
<p>To conclude, by combining the two methods we address the shortcomings mentioned in the previous section. 1) We obtain an interactive framework rather than a monolithic one that applies the different methods in series, as we did in [9]. 2) We are able to stop the GP algorithm at will, if for instance the fitness score doesn't improve, and input more useful data in the form of demonstrations. 3) We are able to demonstrate small subtasks and then let GP algorithm solve the full problem, thus improving the generalizability of the LfD method. 4) We are able to modify the target for the GP algorithm by inputting new demonstrations. 5) By teaching in simulation, we do not need to have access to the physical robot or to rely on the perfect functioning of a perception algorithm. In this section we support the claims made in Section III and we consider a range of simulated manipulation tasks as example for a proof of concept.</p>
<p>IV. EXPERIMENTS AND RESULTS</p>
<p>The manipulation tasks are examples of kitting tasks, where the robot has to place several items in a kit box. Kitting tasks are commonly performed by mobile manipulators where the robot navigates to collect items from shelves to place in a kit box. Here we focus on the manipulation part, and leave the navigation part for future work.</p>
<p>We perform three different experiments to highlight the strengths of our method. The workflow of the experiments is the following: 1) the user let the GP algorithm run until it converges to output a BT that solves a user-defined task; 2) the user adds another target or modifies the current one by inputting a demonstration;</p>
<p>3) the user runs the GP algorithm again but using also the BT learnt from demonstration as baseline, similarly to what what was done in earlier work [9]. For Experiments 1 and 2 the GP is stopped after 50 generations and run for another 50 after inputting the demonstration. With the simulator described in the previous section and the parameters for the GP algorithm of Table I, running 50 generations takes approximately 15 minutes. These parameters have been chosen based on our previous works on GP [8], [9]. Finally, to validate our method we transfer the solution learnt in simulation to a real robot. For the experiments we use an ABB YuMi robot.  a) Experiment 1: The goal of this experiment is to show that by inputting a demonstration, the user is able to modify the target of the task that the GP algorithm has previously solved. Neither the solution found by the GP nor the demonstration alone are sufficient to solve the modified task but only their combination. The GP has output a BT solving a different target while the demonstration shows only a limited part of the full task.</p>
<p>The target of the manipulation task is to stack two boxes in the kitting box. The robot has to place the YellowBox in the center of the KittingBox and the GreenBox on top of the YellowBox. The user then adds as a new target that the BlueBox is placed on top of the GreenBox, as shown in Figure 5a. The GP runs for 50 generations to solve the first part of the task. After the target is changed it runs for 50 generations more.</p>
<p>Results: The learnt BT for this task features a Sequence node as a root and three children subtrees like the one in Figure 1, with the appropriate values for the parameters <O>, <P>, and <F>. In Figure 6a we show the learning curve for the Experiment 1. After 50 generations ( 1300 learning episodes) the fitness score drops because we introduce a new target and the previously learnt BT is no more a good solution. In blue, the GP is boosted by a BT learnt from demonstration that performs the final step to bring the items from the old final configuration to the new one. In this case, the BT learnt from demonstration moves the BlueBox on top of the GreenBox. In red, we let the GP solve the task with updated target, without inputting any new information. The GP converges to a lower fitness score than before changing the target because it learns a larger tree. This experiment supports the findings of [9] because it shows that the GP algorithm converges faster when boosted by a solution that   solves parts of the task. Therefore, the GP algorithm benefits from solutions learnt from demonstration. Moreover, we show that the LfD method benefits from the evolutionary process because it relieves the user from demonstrating the whole task, but only the final part.</p>
<p>b) Experiment 2: In this experiment we show that a user can exploit demonstrations to achieve target configurations for the items that are not allowed by the set of behaviors available to the GP algorithm. In this case, we want to place two boxes side-by-side and place the third one on top of them in the middle, as shown in Figure 5b.</p>
<p>Results: The behavior for placing the third box in the specific target configuration of Figure 5b is not defined in the initial set of the GP behaviors. Therefore, the GP algorithm can only solve the task sub-optimally. The two sub-optimal solutions are stacking the GreenBox on top of either the yellow one or the blue one. If the user inputs demonstrations to solve the task correctly, then the learnt BT is inserted as baseline for the evolution and thus accessible to the GP for crossover and mutation. In this way, the GP can improve on the previous solution, as shown in Figure 6b. Since the difference between the correct solution and the sub-optimal ones is roughly 0.05 cm (half the size of the boxes) on the pose of the GreenBox, the improvement of the fitness score that we observe in Figure 6b is not substantial. c) Experiment 3: The goal of this experiment is to show that a user can decide to stop the execution of the GP algorithm when it gets stuck in local optima to then help it converging by inputting information in the form of a demonstration. The goal of this task is the one in Experiment 1 (Figure 5a) but instead of starting from initial random positions, the boxes are stacked in one of the tables with the wrong goal configuration. Therefore, the robot has to unstack them first and then stack them in the correct order in the KittingBox. If given enough time, the GP will eventually solve the task because in every generation there is a non-zero probability that it finds the solution. However, especially in an industrial scenario the generation of robot programs is time constrained.</p>
<p>We let the GP run for twice as many generations and twice as large population as for the previous experiments (100 generations and 32 individuals in the population, respectively). We also modify the mutation probabilities to delete and change to 30% and 60% respectively to allow the GP to explore more widely the search space.</p>
<p>Results: The GP converges to a local optima where it places the boxes in the KittingBox but not in the correct target configuration. Therefore, we stop the evolutionary process after 100 generations.</p>
<p>At this point, we perform a demonstration to show the robot how to unstack the boxes. In this case, we perform only one demonstration because it doesn't matter where the boxes are placed while unstacking. Therefore, it is enough if the robot learns to place them in its reference frame, which is the default option for the clustering step in the LfD method. We also modify the fitness function, by adding a reward for unstacking the boxes successfully. This is done by capturing the goal of the subtask the demonstration is solving and assigning a score for this intermediate configuration of the items. In this paper we do this manually, but it could easily be automated. In this way we reward the GP for using the demonstrated BT correctly. Moreover, we allow the user to decide where to insert the demonstrated BT during crossover. Since unstacking the boxes is the first step in the solving process, the demonstrated BT is inserted as first children of the root. Finally, we run the GP for another 200 generations with the demonstrated BT as baseline, but we do not use the information from the prior runs. This is motivated by the fact that we do not want the GP to rely on solutions that previously converged on local optima.</p>
<p>With the demonstrated BT, the GP is able to successfully solve the task (Figure 6c). A compacted version of the BT solving the task, where we collapsed a subtree responsible for picking and placing a box in a single behavior, is reported in Figure 7. d) Experiment 4: In this experiment we transfer the solution of Experiment 1 on a real robot. The robot is an ABB YuMi with an Azure Kinect camera. For the perception we use Aruco markers detection. Every box has a different marker in any of the faces, so that we are able to generate a reference frame for each box in its centroid. Another marker is attached to the KittingBox. In this case, we place it in a corner to avoid occlusion but we generate a reference frame at its center using offsets along the X and Y axis.</p>
<p>Results: The BT learnt in simulation can be used without modification on a real scenario to successfully solve the same   task ( Figure 8). By using a BT to control the robot, we make it reactive to changes in the environment. If an operator helps the robot in building the stack or undoes parts of it, the robot reacts by either completing the remaining steps of the tasks or redoing it, as demonstrated in more detail in [14].</p>
<p>V. CONCLUSIONS AND FUTURE WORK</p>
<p>In this paper we proposed to combine a method that evolves Behavior Trees (BTs) using Genetic Programming (GP) that we proposed in [8], with a method that learns BTs from demonstration that we proposed in [14]. We showed that the combined framework allows users with low to no programming skills to automatically, intuitively, and timeefficiently generate BTs for robotic applications. The method learns BTs in an unsupervised fashion but can exploit human experience in task solving in the form of demonstrations. We illustrated the strengths of this method in a series of simulated manipulation tasks. We transferred one of the learnt solutions to a real robot, showing that we can learn in simulation without losing generality. In this paper we targeted collaborative robotic applications but the framework can be extended to other robotic tasks, for instance industrial robotic ones, since the demonstrations and the learning process are performed in simulation.</p>
<p>As future work, we plan on applying the learning framework to mobile manipulation tasks. Moreover, we will exploit the design freedom of the simulator to define a higher level of fidelity. In this way, we propose to model faults to force the framework to learn more robust solutions. As an example, we can simulate a simple model of a mobile platform and constrain the gripper to a fixed workspace. As a consequence, if an item to pick is not reachable, the robot will have to approach it first. This framework is meant to allow non-expert programmers to generate BTs intuitively and time-efficiently. Therefore, once we have further developed the framework to tackle a wide range of mobile manipulation tasks, we aim to test its usability with an user study. We expect that the outcome of this study will give some insights on the design of the graphical user interface and guide its development.</p>
<p>Fig. 3 :
3Graphical User Interface to control the GP algorithm, the LfD framework, and to run and display the learnt BT.</p>
<p>Fig. 4 :
4Demonstration view of the simulator. The user can control the gripper with the keyboard and place the items at the desired position.</p>
<p>Fig. 5 :
5Target configurations for the experiments.</p>
<p>1: stacking boxes in the KittingBox in a specific order.(b) Experiment 2: placing boxes in a pyramid configuration in the KittingBox.</p>
<p>( c )
cExperiment 3: restacking boxes in the KittingBox in a specific order from a wrong stack configuration.</p>
<p>Fig. 6 :
6Learning curves for experiments 1 to 3 averaged on 10 runs.</p>
<p>Fig. 7 :
7BT solving the task defined in Experiment 3. First the boxes are unstacked and placed somewhere in the base frame of the robot. Then, they are stacked in the target configuration at the center of the KittingBox, as shown in Figure 5a. The white boxes represent a subtree in the form of Figure 1, where P 1,2 are the position chosen by the user in demonstration and P 3,4,5 are the position of the boxes in the configuration of Figure 5a. configuration of the task.</p>
<p>Fig. 8 :
8In Experiment 4 we transfer the solution of Experiment 1 on the real robot.</p>
<p>and by the Wallenberg AI, Autonomous Systems, and Software Program (WASP) funded by the Knut and Alice Wallenberg Foundation. The authors gratefully acknowledge this support.Fig. 1: Subtree responsible for picking the item <O> and placing it at pose <P> in the reference frame <F>.a ABB Corporate Research, Västerås, Sweden 
b Division of Robotics, Perception and Learning, KTH -Royal Institute 
of Technology, Stockholm, Sweden 
c ABB Robotics, Västerås, Sweden </p>
<p>Fallback </p>
<p><O> at <P> in <F>? 
Sequence </p>
<p>Fallback 
Place <O> at <P> in <F>! </p>
<p>In gripper <O>? 
Sequence </p>
<p>Fallback 
Pick <O>! </p>
<p>Gripper open? 
Open gripper! </p>
<p>TABLE I :
IGP parametersParameter description 
Value 
Population size 
16 
Parents selected for mutation 
12 
Number of mutation offspring per parent 
2 
Maximum number of mutations per individual 
3 
Mutation probabilities for add, delete, change 
10%, 50% and 40% 
Parents selected for crossover 
4 
Number of crossover offspring per parent 
2 
Selection method (reproduction and survival) 
Tournament selection 
Number of elites 
2 
Length penalty for each node (λ) 
10 
Penalty for ending by timeout (τ ) 
30 
Penalty for ending in Failure state (φ) 
50 </p>
<p>Sequence FallbackYellowBox at P3 in KittingBox! GreenBox at P4 in YellowBox! BlueBox at P5 in GreenBox!Boxes Unstacked? 
Sequence </p>
<p>GreenBox at P1 in base_link! 
BlueBox at P2 in base_link! </p>
<p>https://www.algoryx.se/agx-dynamics/
ACKNOWLEDGMENTSThis work was carried out in the WASP Research Arena (WARA) -Robotics, hosted by ABB Corporate Research Center in Västerås, Sweden and financially supported by the the Wallenberg AI, Autonomous Systems, and Software Program (WASP) funded by the Knut and Alice Wallenberg Foundation. The authors thank Daniel Lindmark from Algoryx for the valuable support provided with the simulator.
M Colledanchise, P Ögren, Behavior Trees in Robotics and AI : An Introduction. CRC PressM. Colledanchise and P.Ögren, Behavior Trees in Robotics and AI : An Introduction. CRC Press, Jul. 2018.</p>
<p>A survey of Behavior Trees in robotics and AI. M Iovino, E Scukins, J Styrud, P Ögren, C Smith, Robotics and Autonomous Systems. 154104096M. Iovino, E. Scukins, J. Styrud, P.Ögren, and C. Smith, "A survey of Behavior Trees in robotics and AI," Robotics and Autonomous Systems, vol. 154, p. 104096, Aug. 2022.</p>
<p>On the programming effort required to generate Behavior Trees and Finite State Machines for robotic applications. M Iovino, J Förster, P Falco, J J Chung, R Siegwart, C Smith, 2023 IEEE International Conference on Robotics and Automation (ICRA). M. Iovino, J. Förster, P. Falco, J. J. Chung, R. Siegwart, and C. Smith, "On the programming effort required to generate Behavior Trees and Finite State Machines for robotic applications," in 2023 IEEE International Conference on Robotics and Automation (ICRA), May 2023.</p>
<p>How Behavior Trees Modularize Hybrid Control Systems and Generalize Sequential Behavior Compositions, the Subsumption Architecture, and Decision Trees. M Colledanchise, P Ögren, IEEE Transactions on Robotics. 332M. Colledanchise and P.Ögren, "How Behavior Trees Modularize Hybrid Control Systems and Generalize Sequential Behavior Com- positions, the Subsumption Architecture, and Decision Trees," IEEE Transactions on Robotics, vol. 33, no. 2, pp. 372-389, Apr. 2017.</p>
<p>On Modularity in Reactive Control Architectures, with an Application to Formal Verification. O Biggar, M Zamani, I Shames, ACM Transactions on Cyber-Physical Systems. 62O. Biggar, M. Zamani, and I. Shames, "On Modularity in Reactive Control Architectures, with an Application to Formal Verification," ACM Transactions on Cyber-Physical Systems, vol. 6, no. 2, pp. 19:1- 19:36, Apr. 2022.</p>
<p>Behavior Trees for Robust Task Level Control in Robotic Applications. M Iovino, C Smith, 2022M. Iovino and C. Smith, "Behavior Trees for Robust Task Level Control in Robotic Applications," 2022.</p>
<p>Genetic Programming: An Introduction and Tutorial, with a Survey of Techniques and Applications. W Langdon, R Poli, N Mcphee, J Koza, Studies in Computational Intelligence. 115W. Langdon, R. Poli, N. Mcphee, and J. Koza, "Genetic Programming: An Introduction and Tutorial, with a Survey of Techniques and Applications," in Studies in Computational Intelligence, Jan. 1970, vol. 115, pp. 927-1028.</p>
<p>Learning Behavior Trees with Genetic Programming in Unpredictable Environments. M Iovino, J Styrud, P Falco, C Smith, 2021 IEEE International Conference on Robotics and Automation (ICRA). M. Iovino, J. Styrud, P. Falco, and C. Smith, "Learning Behavior Trees with Genetic Programming in Unpredictable Environments," in 2021 IEEE International Conference on Robotics and Automation (ICRA), May 2021, pp. 4591-4597.</p>
<p>Combining Planning and Learning of Behavior Trees for Robotic Assembly. J Styrud, M Iovino, M Norrlöf, M Björkman, C Smith, 2022 International Conference on Robotics and Automation (ICRA). J. Styrud, M. Iovino, M. Norrlöf, M. Björkman, and C. Smith, "Combining Planning and Learning of Behavior Trees for Robotic Assembly," in 2022 International Conference on Robotics and Au- tomation (ICRA), May 2022, pp. 11 511-11 517.</p>
<p>Genetic programming as a means for programming computers by natural selection. J R Koza, Statistics and Computing. 42J. R. Koza, "Genetic programming as a means for programming computers by natural selection," Statistics and Computing, vol. 4, no. 2, pp. 87-112, Jun. 1994.</p>
<p>P Mcclarron, R Ollington, I Lewis, Effect of Constraints on Evolving Behavior Trees for Game AI. P. McClarron, R. Ollington, and I. Lewis, Effect of Constraints on Evolving Behavior Trees for Game AI, Mar. 2016.</p>
<p>Learning of Behavior Trees for Autonomous Agents. M Colledanchise, R Parasuraman, P Ögren, IEEE Transactions on Games. 112M. Colledanchise, R. Parasuraman, and P.Ögren, "Learning of Be- havior Trees for Autonomous Agents," IEEE Transactions on Games, vol. 11, no. 2, pp. 183-189, Jun. 2019.</p>
<p>Recent Advances in Robot Learning from Demonstration. H Ravichandar, A S Polydoros, S Chernova, A Billard, Robotics, and Autonomous Systems. 31Annual Review of ControlH. Ravichandar, A. S. Polydoros, S. Chernova, and A. Billard, "Recent Advances in Robot Learning from Demonstration," Annual Review of Control, Robotics, and Autonomous Systems, vol. 3, no. 1, pp. 297- 330, May 2020.</p>
<p>Combining Context Awareness and Planning to Learn Behavior Trees from Demonstration. O Gustavsson, M Iovino, J Styrud, C Smith, 2022 31st IEEE International Conference on Robot and Human Interactive Communication. RO-MANO. Gustavsson, M. Iovino, J. Styrud, and C. Smith, "Combining Context Awareness and Planning to Learn Behavior Trees from Demonstration," in 2022 31st IEEE International Conference on Robot and Human Interactive Communication (RO-MAN), Aug. 2022, pp. 1153-1160.</p>
<p>Towards Blended Reactive Planning and Acting using Behavior Trees. M Colledanchise, D Almeida, P Ögren, 2019 International Conference on Robotics and Automation (ICRA). M. Colledanchise, D. Almeida, and P.Ögren, "Towards Blended Reac- tive Planning and Acting using Behavior Trees," in 2019 International Conference on Robotics and Automation (ICRA), May 2019, pp. 8839- 8845.</p>
<p>Interactive Disambiguation for Behavior Tree Execution. M Iovino, F I Dogan, I Leite, C Smith, 2022 IEEE-RAS 21st International Conference on Humanoid Robots (Humanoids). M. Iovino, F. I. Dogan, I. Leite, and C. Smith, "Interactive Dis- ambiguation for Behavior Tree Execution," in 2022 IEEE-RAS 21st International Conference on Humanoid Robots (Humanoids), Nov. 2022, pp. 82-89.</p>
<p>Evolving Behaviour Trees for the Commercial Game DEFCON. C.-U Lim, R Baumgarten, S Colton, Applications of Evolutionary Computation. Berlin, Heidelberg; Berlin HeidelbergSpringer6024C.-U. Lim, R. Baumgarten, and S. Colton, "Evolving Behaviour Trees for the Commercial Game DEFCON," in Applications of Evolutionary Computation. Berlin, Heidelberg: Springer Berlin Heidelberg, 2010, vol. 6024, pp. 100-110.</p>
<p>Evolving Behaviour Trees for the Mario AI Competition Using Grammatical Evolution," in Applications of Evolutionary Computation, ser. Lecture Notes in Computer Science. D Perez, M Nicolau, M O&apos;neill, A Brabazon, SpringerBerlin HeidelbergD. Perez, M. Nicolau, M. O'Neill, and A. Brabazon, "Evolving Behaviour Trees for the Mario AI Competition Using Grammatical Evolution," in Applications of Evolutionary Computation, ser. Lecture Notes in Computer Science. Springer Berlin Heidelberg, 2011, pp. 123-132.</p>
<p>Evolutionary Behavior Tree Approaches for Navigating Platform Games. M Nicolau, D Perez-Liebana, M O&apos;neill, A Brabazon, IEEE Transactions on Computational Intelligence and AI in Games. 93M. Nicolau, D. Perez-Liebana, M. O'Neill, and A. Brabazon, "Evo- lutionary Behavior Tree Approaches for Navigating Platform Games," IEEE Transactions on Computational Intelligence and AI in Games, vol. 9, no. 3, pp. 227-238, Sep. 2017.</p>
<p>Behavior Modeling for Autonomous Agents Based on Modified Evolving Behavior Trees. Q Zhang, K Xu, P Jiao, Q Yin, 2018 IEEE 7th Data Driven Control and Learning Systems Conference (DDCLS). Q. Zhang, K. Xu, P. Jiao, and Q. Yin, "Behavior Modeling for Autonomous Agents Based on Modified Evolving Behavior Trees," in 2018 IEEE 7th Data Driven Control and Learning Systems Conference (DDCLS), May 2018, pp. 1140-1145.</p>
<p>Learning Behavior Trees for Autonomous Agents with Hybrid Constraints Evolution. Q Zhang, J Yao, Q Yin, Y Zha, Applied Sciences. 871077Q. Zhang, J. Yao, Q. Yin, and Y. Zha, "Learning Behavior Trees for Autonomous Agents with Hybrid Constraints Evolution," Applied Sciences, vol. 8, no. 7, p. 1077, Jul. 2018.</p>
<p>Behavior Trees for Evolutionary Robotics. K Y W Scheper, S Tijmons, C C Visser, G C H E De Croon, Artificial Life. 221K. Y. W. Scheper, S. Tijmons, C. C. de Visser, and G. C. H. E. de Croon, "Behavior Trees for Evolutionary Robotics," Artificial Life, vol. 22, no. 1, pp. 23-48, Nov. 2015.</p>
<p>Evolving Behaviour Trees for Swarm Robotics. S Jones, M Studley, S Hauert, A Winfield, Distributed Autonomous Robotic Systems: The 13th International Symposium, ser. Springer Proceedings in Advanced Robotics. ChamSpringer International PublishingS. Jones, M. Studley, S. Hauert, and A. Winfield, "Evolving Behaviour Trees for Swarm Robotics," in Distributed Autonomous Robotic Sys- tems: The 13th International Symposium, ser. Springer Proceedings in Advanced Robotics. Cham: Springer International Publishing, 2018, pp. 487-501.</p>
<p>A two teraflop swarm. Frontiers Robotics AI. 5FEB--, "A two teraflop swarm," Frontiers Robotics AI, vol. 5, no. FEB, 2018.</p>
<p>Learning Swarm Behaviors using Grammatical Evolution and Behavior Trees. A Neupane, M Goodrich, Proceedings of the Twenty-Eighth International Joint Conference on Artificial Intelligence. the Twenty-Eighth International Joint Conference on Artificial IntelligenceMacao, China: International Joint Conferences on Artificial Intelligence OrganizationA. Neupane and M. Goodrich, "Learning Swarm Behaviors using Grammatical Evolution and Behavior Trees," in Proceedings of the Twenty-Eighth International Joint Conference on Artificial Intelli- gence. Macao, China: International Joint Conferences on Artificial Intelligence Organization, Aug. 2019, pp. 513-520.</p>
<p>On the Locality of Grammatical Evolution," in Genetic Programming, ser. Lecture Notes in Computer Science. F Rothlauf, M Oetzel, SpringerBerlin, HeidelbergF. Rothlauf and M. Oetzel, "On the Locality of Grammatical Evo- lution," in Genetic Programming, ser. Lecture Notes in Computer Science. Berlin, Heidelberg: Springer, 2006, pp. 320-330.</p>
<p>Evolving Instinctive Behaviour in Resource-Constrained Autonomous Agents Using Grammatical Evolution. A Hallawa, S Schug, G Iacca, G Ascheid, Applications of Evolutionary Computation, ser. Lecture Notes in Computer Science. ChamSpringer International PublishingA. Hallawa, S. Schug, G. Iacca, and G. Ascheid, "Evolving Instinctive Behaviour in Resource-Constrained Autonomous Agents Using Gram- matical Evolution," in Applications of Evolutionary Computation, ser. Lecture Notes in Computer Science. Cham: Springer International Publishing, 2020, pp. 369-383.</p>
<p>Trained Behavior Trees: Programming by Demonstration to Support AI Game Designers. I Sagredo-Olivenza, P P Gómez-Martín, M A Gómez-Martín, P A González-Calero, IEEE Transactions on Games. 111I. Sagredo-Olivenza, P. P. Gómez-Martín, M. A. Gómez-Martín, and P. A. González-Calero, "Trained Behavior Trees: Programming by Demonstration to Support AI Game Designers," IEEE Transactions on Games, vol. 11, no. 1, pp. 5-14, Mar. 2019.</p>
<p>Learning Behavior Trees From Demonstration. K French, S Wu, T Pan, Z Zhou, O C Jenkins, 2019 International Conference on Robotics and Automation (ICRA). K. French, S. Wu, T. Pan, Z. Zhou, and O. C. Jenkins, "Learning Be- havior Trees From Demonstration," in 2019 International Conference on Robotics and Automation (ICRA), May 2019, pp. 7791-7797.</p>
<p>Building behavior trees from observations in real-time strategy games. G Robertson, I Watson, 2015 International Symposium on Innovations in Intelligent SysTems and Applications (INISTA). G. Robertson and I. Watson, "Building behavior trees from observa- tions in real-time strategy games," in 2015 International Symposium on Innovations in Intelligent SysTems and Applications (INISTA), Sep. 2015, pp. 1-7.</p>
<p>Learning and Executing Re-Usable Behaviour Trees From Natural Language Instruction. G Suddrey, B Talbot, F Maire, IEEE Robotics and Automation Letters. 74G. Suddrey, B. Talbot, and F. Maire, "Learning and Executing Re- Usable Behaviour Trees From Natural Language Instruction," IEEE Robotics and Automation Letters, vol. 7, no. 4, pp. 10 643-10 650, Oct. 2022.</p>
<p>RE:BT-Espresso: Improving Interpretability and Expressivity of Behavior Trees Learned from Robot Demonstrations. A Wathieu, T R Groechel, H J Lee, C Kuo, M J Matarić, 2022 International Conference on Robotics and Automation (ICRA). A. Wathieu, T. R. Groechel, H. J. Lee, C. Kuo, and M. J. Matarić, "RE:BT-Espresso: Improving Interpretability and Expressivity of Be- havior Trees Learned from Robot Demonstrations," in 2022 Interna- tional Conference on Robotics and Automation (ICRA), May 2022, pp. 11 518-11 524.</p>
<p>Learning grounded finite-state representations from unstructured demonstrations. S Niekum, S Osentoski, G Konidaris, S Chitta, B Marthi, A G Barto, The International Journal of Robotics Research. 342S. Niekum, S. Osentoski, G. Konidaris, S. Chitta, B. Marthi, and A. G. Barto, "Learning grounded finite-state representations from unstructured demonstrations," The International Journal of Robotics Research, vol. 34, no. 2, pp. 131-157, Feb. 2015.</p>
<p>Skill acquisition from human demonstration using a hidden Markov model. G Hovland, P Sikka, B Mccarragher, Proceedings of IEEE International Conference on Robotics and Automation. IEEE International Conference on Robotics and Automation3G. Hovland, P. Sikka, and B. McCarragher, "Skill acquisition from human demonstration using a hidden Markov model," in Proceedings of IEEE International Conference on Robotics and Automation, vol. 3, Apr. 1996, pp. 2706-2711 vol.3.</p>
<p>Robot learning from demonstration by constructing skill trees. G Konidaris, S Kuindersma, R Grupen, A Barto, The International Journal of Robotics Research. 313G. Konidaris, S. Kuindersma, R. Grupen, and A. Barto, "Robot learn- ing from demonstration by constructing skill trees," The International Journal of Robotics Research, vol. 31, no. 3, pp. 360-375, Mar. 2012.</p>
<p>Robot Learning from Demonstration: A Task-level Planning Approach. S Ekvall, D Kragic, International Journal of Advanced Robotic Systems. 5333S. Ekvall and D. Kragic, "Robot Learning from Demonstration: A Task-level Planning Approach," International Journal of Advanced Robotic Systems, vol. 5, no. 3, p. 33, Sep. 2008.</p>            </div>
        </div>

    </div>
</body>
</html>