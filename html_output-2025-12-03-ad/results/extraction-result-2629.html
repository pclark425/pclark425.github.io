<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-2629 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-2629</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-2629</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-67.html">extraction-schema-67</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <p><strong>Paper ID:</strong> paper-79877a26ee5b21404a9ef928e1185ab076255782</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/79877a26ee5b21404a9ef928e1185ab076255782" target="_blank">Fast Bayesian optimization of Needle-in-a-Haystack problems using zooming memory-based initialization (ZoMBI)</a></p>
                <p><strong>Paper Venue:</strong> npj Computational Materials</p>
                <p><strong>Paper TL;DR:</strong> This paper presents a Zooming Memory-Based Initialization algorithm, entitled ZoMBI, that builds on conventional Bayesian optimization principles to quickly and efficiently optimize Needle-in-a-Haystack problems in both less time and fewer experiments.</p>
                <p><strong>Paper Abstract:</strong> Needle-in-a-Haystack problems exist across a wide range of applications including rare disease prediction, ecological resource management, fraud detection, and material property optimization. A Needle-in-a-Haystack problem arises when there is an extreme imbalance of optimum conditions relative to the size of the dataset. However, current state-of-the-art optimization algorithms are not designed with the capabilities to find solutions to these challenging multidimensional Needle-in-a-Haystack problems, resulting in slow convergence or pigeonholing into a local minimum. In this paper, we present a Zooming Memory-Based Initialization algorithm, entitled ZoMBI, that builds on conventional Bayesian optimization principles to quickly and efficiently optimize Needle-in-a-Haystack problems in both less time and fewer experiments. The ZoMBI algorithm demonstrates compute time speed-ups of 400× compared to traditional Bayesian optimization as well as efficiently discovering optima in under 100 experiments that are up to 3× more highly optimized than those discovered by similar methods.</p>
                <p><strong>Cost:</strong> 0.024</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e2629.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e2629.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ZoMBI</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Zooming Memory-Based Initialization</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An algorithm building on Bayesian optimization that iteratively 'zooms' the search bounds using the best-performing memory points and prunes low-performing historical data to reduce GP compute cost, combined with adaptive acquisition functions to avoid pigeonholing into local minima.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>ZoMBI (Zooming Memory-Based Initialization)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>ZoMBI is an active Bayesian optimization framework for 'needle-in-a-haystack' problems. Key components: (1) Memory-based zooming — retain the m best historical experiments and compute per-dimension bounds from their minima/maxima to define a tightened search box; (2) Memory pruning — discard historical points outside the zoomed region so the GP surrogate is only trained on a small, bounded set (i + up to phi points per activation); (3) Activations — repeat cycles ('alpha' activations) of: (a) initialize with i LHS samples inside the current bounds, (b) perform up to phi forward experiments retraining the GP after each new sample, (c) update memory and recompute bounds; (4) Adaptive acquisition functions — optionally use LCB Adaptive and EI Abrupt to dynamically change exploration/exploitation behavior based on sampled data quality and quantity. The algorithm therefore explicitly trades broader global sampling early for focused, high-resolution surrogate modeling in promising subregions while bounding computational expense per activation.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>General black-box optimization with demonstrations in materials discovery (auxetic and thermoelectric materials) and ecological resource management (wildfire detection); applicable to other scientific discovery tasks with extreme class imbalance.</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>Allocates experimental/computational budget in repeated cycles: (1) use m best historical points to define a smaller region to focus the next allocation; (2) within that region, allocate a fixed small initialization budget i (via LHS) plus up to phi sequential forward experiments per activation; (3) retrain GP only on retained memory and current forward points to limit compute; (4) adaptive acquisition functions decide which individual points to evaluate (maximize acquisition value) balancing exploration/exploitation based on recent performance and sample count. In short: coarse global sampling → keep top-m outcomes → zoom region → devote bounded local budget to refine and exploit.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td>Wall-clock compute time per experiment (measured), and analytic time-complexity of GP training: standard GP O(n^3) where n is cumulative experiments; ZoMBI reduces per-activation training size to O((i+phi)^3) ≈ O(phi^3) and, with repeated activations, trends to approximately constant per-experiment cost O(1) in practice.</td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td>Uses standard BO acquisition functions: Expected Improvement (EI) as explicit expected-utility measure, Lower Confidence Bound (LCB) combining mean and variance, and custom variants (EI Abrupt, LCB Adaptive) that respond to observed improvement or sample count. Thus information-driven utility is measured via EI (expected improvement) and uncertainty-weighted scores (LCB).</td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td>Several mechanisms: (a) algorithmic: zooming progressively reduces search volume to increase local exploitation resolution while still reinitializing by LHS to avoid pure local search; (b) acquisition-level: LCB Adaptive decays the exploration weight (beta * epsilon^n) as n grows to move from exploration to exploitation; EI Abrupt switches between exploitative EI and explorative LCB when recent finite differences in objective values plateau; static EI/LCB are also supported. Together these dynamically rebalance exploration vs exploitation in response to observed returns and sample count.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td>Implicit diversity promotion via (1) per-activation LHS initialization inside zoomed bounds (ensures space-filling within region), (2) EI Abrupt's switching to exploration when recent improvements plateau, and (3) LCB Adaptive's higher exploration weight early on; zooming across each dimension independently also helps avoid focusing on narrow local minima that are not aligned across dimensions. There is no explicit diversity objective (e.g., determinantal or penalized clustering), but mechanisms actively attempt to avoid pigeonholing and encourage exploration when warranted.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td>Fixed-number-of-experiments budget (demonstrated: up to 100 and up to 1000 experiments), and computational-budget constraints (wall-clock time per experiment, GP training cost).</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td>Handles budget by capping per-activation forward experiments (phi) and fixed initialization size (i), thereby bounding GP training set size and per-activation compute cost; memory pruning keeps GP training complexity small irrespective of cumulative n. The acquisition functions adapt behavior based on remaining effective budget via decay (LCB Adaptive) or plateau detection (EI Abrupt).</td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td>Defined operationally as locating the needle-like global optimum or a top-performing sample: e.g., attaining target objective values (Poisson's ratio ≈ -1.7, ZT ≈ 1.4, wildfire index ψ ≈ -3.5) or falling within the Ackley basin threshold (f(X) < 10). Breakthroughs are therefore measured by raw objective value improvement and by whether the sample falls inside the narrow optimum basin.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Reported metrics include: number of experiments to discover needle-like optima (e.g., discovered Li2NbF6 with ν≈-1.7 in ~70 experiments with LCB/LCB Adaptive), wall-clock compute time per experiment (ZoMBI ≈1 s/experiment vs standard BO >400 s/experiment at n=1000), and success on synthetic Ackley permutations (reliably finds optima when optimum hypervolume is between 0.05% and 5% for i=5). Also reported: median best running objective across ensemble runs and KDE of final sampled outcomes.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Compared against standard BO (GP+static EI/LCB), MiP-EGO (parallelized EGO), TuRBO (trust-region local BO), HEBO (NeurIPS 2020 winning BO system), and random sampling baselines.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>ZoMBI converged faster and to better optima in the tested NiaH cases: e.g., on Poisson's Ratio dataset ZoMBI (LCB/LCB Adaptive) found the global minimum in under 100 experiments while MiP-EGO and TuRBO found much worse minima (ν≈-0.20 and ν≈-0.55 respectively); compute-time per experiment at n=1000 was ≈1s for ZoMBI vs >400s for standard BO, a ≈400x speed-up. On thermoelectric dataset LCB Adaptive (ZoMBI) found ZT≈1.4 whereas competitors did not find this needle; on wildfire dataset ZoMBI variants discovered ψ≈-3.5 while others found worse minima (ψ≈-2.5).</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td>Reported ≈400x wall-clock compute-time speed-up per experiment at n=1000 relative to traditional GP-based BO; reduced number of experiments to find optima (e.g., discover material optima in <100 experiments); results up to ≈3x better final objective values compared to MiP-EGO and TuRBO in the Poisson's Ratio task (as reported).</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td>The paper analyzes tradeoffs explicitly: (1) compute vs information: pruning reduces compute but requires retaining a sufficiently informative m and initialization i to avoid missing narrow needles; (2) needle hypervolume vs initialization: ZoMBI performs reliably when needle occupies between 0.05%–5% hypervolume with i=5; narrower needles require larger initialization to avoid missing the global optimum (so there is a tradeoff between upfront sampling cost and later focused search); (3) exploration vs over-zooming: for very wide optima ZoMBI's greedy zoom can falsely focus on suboptimal regions. These analyses quantify that aggressive pruning/zooming yields compute gains but increases risk of missing extremely narrow or edge optima unless initialization is increased.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td>Key recommendations: (1) keep a small, fixed per-activation GP training budget (i + phi) and prune older data to cap compute; (2) use the m best performing points to define per-dimension zoom bounds for targeted allocation; (3) adapt acquisition hyperparameters online (e.g., decay exploration weight or switch to exploration on plateau) to balance exploration and exploitation; (4) ensure initialization size i scales with expected needle hypervolume — for extremely narrow optima increase i to avoid missing the needle; (5) cap phi to maintain low per-activation compute and repeat activations to progressively refine allocation.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Fast Bayesian optimization of Needle-in-a-Haystack problems using zooming memory-based initialization (ZoMBI)', 'publication_date_yy_mm': '2022-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2629.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e2629.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LCB Adaptive</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Lower Confidence Bound (Adaptive)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A dynamic variant of the LCB acquisition function whose exploration hyperparameter beta decays with sample count, making the acquisition progressively more exploitative as more data is collected.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>LCB Adaptive acquisition function</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>LCB Adaptive computes acquisition a(X,n;beta,epsilon) = mu(X) - epsilon^n * beta * sigma(X) for minimization, where mu and sigma are GP mean and stddev, beta is an initial exploration weight and epsilon in (0,1) controls decay rate; as n (number of experiments) increases, exploration weight decays exponentially (epsilon^n), steering sampling toward exploitation. Hyperparameters used in paper: beta=3, epsilon=0.9 (hand-tuned).</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Used inside Bayesian optimization for needle-in-a-haystack scientific discovery problems (materials and wildfire detection) to manage exploration-exploitation over sequential budget.</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>Select next experiment by maximizing the LCB Adaptive acquisition value; early iterations emphasize sigma(X) (exploration) due to large beta*epsilon^n, later iterations downweight sigma to prioritize mu(X) (exploitation). Thus resource allocation shifts from diverse exploration to concentrated exploitation as budget is expended.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td>No special computational cost metric beyond the usual GP retraining cost; used within ZoMBI where per-activation GP size is limited to bound compute.</td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td>Implicitly uses uncertainty (sigma) as a proxy for information gain; not an explicit mutual-information or entropy objective but standard LCB-style uncertainty-weighted expected utility.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td>Explicit: multiply sigma(X) by a decaying factor epsilon^n * beta so exploration contribution reduces with n, shifting allocation progressively to exploitation.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td>Promotes diversity early through a high initial beta, then reduces diversity pressure as more samples are collected; no explicit diversity objective beyond exploration weighting.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td>Sequential experiment budget (n) and per-activation bounded budgets when used within ZoMBI.</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td>Adapts exploration weight as a function of samples taken (n) to reflect decreasing remaining budget/value of exploration.</td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td>Same as the enclosing BO: breakthroughs measured by attained objective improvements (e.g., locating needle-like optima).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Within ZoMBI, LCB Adaptive achieved fast discovery (e.g., discovered Poisson's-ratio needle in under 100 experiments) and low variance across runs in some tasks; compared favorably to static LCB and EI in combination with ZoMBI.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Compared to static LCB, EI, EI Abrupt, and standard BO baselines in experiments inside ZoMBI.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>Reported to converge faster and more reliably when paired with ZoMBI than static LCB/EI in the tested NiaH problems; on Poisson's Ratio LCB Adaptive (as ZoMBI variant) reached the global minimum faster than MiP-EGO and TuRBO.</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td>Contributes to fewer wasted evaluations by reducing exploration weight over time; included in the overall ZoMBI efficiency gains (part of the <100 experiments discoveries and compute savings).</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td>LCB Adaptive embodies an explicit tradeoff: faster decay (smaller epsilon) reduces exploratory sampling sooner (risking premature exploitation), while slower decay retains exploration at higher computational cost. The paper hand-tuned epsilon and beta to balance these effects.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td>Use a relatively large initial beta and epsilon close to 1 to allow gradual decay (they used beta=3, epsilon=0.9) so the optimizer transitions slowly from exploration to exploitation rather than abruptly, particularly important for needle-in-a-haystack landscapes.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Fast Bayesian optimization of Needle-in-a-Haystack problems using zooming memory-based initialization (ZoMBI)', 'publication_date_yy_mm': '2022-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2629.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e2629.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>EI Abrupt</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Expected Improvement Abrupt-switch</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A hybrid acquisition strategy that normally uses Expected Improvement (EI) but switches abruptly to an explorative LCB-style policy when recent sampled objective values have plateaued, to escape local minima.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>EI Abrupt acquisition function</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>EI Abrupt computes either the standard EI acquisition when recent finite differences in objective values exceed a threshold (i.e., improvement is being achieved), or uses a more explorative surrogate-based score mu(X) - beta * sigma(X) when the last three sampled y-values show negligible change (|Δ{y_{n-3...n}}| ≤ eta). Hyperparameters: beta=0.1, xi=0.1 (EI’s improvement margin), eta=0 (plateau threshold). This enables dynamic switching between exploitation (EI) and exploration (LCB-like) based on empirical short-term progress.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Bayesian optimization in NiaH scientific discovery tasks where local minima/pigeonholing are common.</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>Allocates next experiments according to EI when recent sampling yields improvements, but upon detection of a plateau switches allocation to exploration-driven points (favoring larger sigma) to escape local minima; thus redirects resources away from diminishing-return local refinement toward diverse search when needed.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td>Operates within standard BO computational budgets; switching logic is computationally negligible compared to GP training.</td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td>Uses EI (expected improvement) when exploiting and an uncertainty-weighted surrogate (mu - beta*sigma) when exploring; uses recent improvements as a trigger rather than an explicit information-theoretic metric.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td>Triggered switching based on finite differences in recent y-values (plateau detection). If plateau detected, apply explorative policy; otherwise apply EI. This is an empirically reactive exploration-exploitation control.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td>Promotes diversity by switching to exploration when improvement stalls, causing selection of points with higher predictive uncertainty and thus more diverse hypotheses.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td>Sequential experiment budget; used within ZoMBI per-activation budgets.</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td>By switching only when improvement stalls, EI Abrupt conserves budget when exploitation is productive and re-allocates budget to exploration only when exploitation yields diminishing returns.</td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td>Same as BO baseline: discovery if EI or switched exploration leads to samples with markedly better objective values (needle samples).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Shown to help escape local minima in standalone BO experiments (without ZoMBI) more effectively than static LCB/EI; when combined with ZoMBI, EI Abrupt also contributed to faster convergence in some tasks and reduced variance across runs.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Compared to static EI and LCB and the LCB Adaptive variant; also tested in ZoMBI vs non-ZoMBI contexts.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>EI Abrupt could escape local minima where static EI/LCB failed; with ZoMBI, most acquisition functions (including EI Abrupt) converged to global minima faster except for the most exploitative (static EI) in some cases.</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td>Improves effective use of budget by triggering exploration only when needed, contributing to fewer wasted exploitative evaluations stuck in plateaus.</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td>Switching threshold (eta) and beta determine sensitivity: too-sensitive switching may waste explorative budget, too insensitive may delay escape from plateaus. Paper used conservative hand-tuned values (eta=0, beta=0.1) to enable occasional exploration without large deviation from exploitation.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td>Use short-window plateau detection (last 3 y-values) to decide switching; keep beta small (0.1) so exploration does not diverge excessively from promising regions while still enabling escapes from local minima.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Fast Bayesian optimization of Needle-in-a-Haystack problems using zooming memory-based initialization (ZoMBI)', 'publication_date_yy_mm': '2022-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2629.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e2629.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Memory Pruning</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Memory pruning in ZoMBI</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A mechanism within ZoMBI that discards low-performing or out-of-region historical experiments so GP surrogate training is restricted to a small, recent, and relevant dataset, bounding compute cost.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Memory pruning (ZoMBI component)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>After each activation, ZoMBI retains only the m best-performing experiments (or those inside the current zoomed bounds) and erases other historical data from memory. This ensures the GP surrogate is trained only on i (initial LHS) + up to phi forward experiments per activation, keeping the surrogate matrix sizes small and per-activation GP training cost O((i+phi)^3).</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Used inside sequential Bayesian optimization for expensive experiments/simulations to limit surrogate-training costs in long optimization runs.</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>Indirectly reallocates computational budget by freeing capacity (time/memory) that would otherwise be spent retraining on all historical data; enables more forward experiments or repeated activations under fixed wall-clock constraints.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td>Measured via wall-clock time per experiment; theoretical reduction from O(n^3) (standard cumulative GP) to O((i+phi)^3) per activation, with observed ≈400x reduction at n=1000 in experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td>No explicit information metric used to decide which points to prune beyond performance-based ranking (retain m best by objective value) and containment within zoomed bounds.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td>Pruning focuses surrogate fidelity on the promising region (exploitation) at the cost of removing some global historical context (reducing some exploratory memory). This is balanced by reinitializing with LHS inside each zoomed region and adaptive acquisition functions to maintain exploration when needed.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td>Pruning reduces diversity of the training set intentionally; diversity is maintained via LHS initialization inside zoomed bounds and the activation-resetting procedure rather than retaining broad historical diversity.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td>Computational budget (time/memory) and implicit experimental budget by enabling more effective use of limited compute per experiment.</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td>Caps GP training set size by design (i + phi), thereby bounding per-activation compute and enabling the algorithm to operate under strict per-experiment wall-clock/time budgets.</td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td>Indirect: by enabling many low-cost surrogate retrainings and focused sampling, pruning aims to increase probability of discovering needle-like breakthroughs within a fixed wall-clock budget.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Empirical: compute time per experiment for ZoMBI stayed ~1 s/experiment versus >400 s/experiment for standard BO at n=1000; overall optimization success rates improved in many tested NiaH tasks when pruning was used with zooming and adaptive acquisitions.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Compared against standard BO that retains all historical data and trains GP on cumulative n, resulting in O(n^3) cost.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>Pruning + zooming achieved ≈400x wall-clock speed-up at large n and allowed more consistent/faster discovery of optima with fewer resources; however, pruning increases risk of missing very narrow or edge optima if initialization i is insufficient.</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td>≈400x per-experiment wall-clock time reduction at n=1000 relative to standard cumulative-GP BO in reported experiments; asymptotically tends toward constant per-experiment cost over many activations.</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td>Pruning trades global historical context (which can help avoid missing distant needles) for bounded compute and denser local modeling; paper quantifies that with i=5 initialization, ZoMBI succeeds when needle hypervolume ∈ [0.05%, 5%], and failures occur for narrower needles unless i is increased.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td>Cap per-activation GP size (via phi and i) to control compute; choose m (retained memory) to be large enough to capture the plausible extent of the needle but small enough to permit fast retraining; increase initial sampling i when expecting extremely narrow optima.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Fast Bayesian optimization of Needle-in-a-Haystack problems using zooming memory-based initialization (ZoMBI)', 'publication_date_yy_mm': '2022-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2629.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e2629.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>TuRBO</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>TuRBO (Trust-region Bayesian Optimization)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A trust-region based BO approach that runs a collection of local BO instances (local GPs) within adaptive trust-regions to scale optimization in high-dimensions and focus search locally.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Scalable Global Optimization via Local Bayesian Optimization</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>TuRBO</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>TuRBO manages multiple local trust-regions each centered at a candidate and runs local BO with separate GP surrogates; trust-regions expand or contract based on recent successes, and parallel evaluations are supported. TuRBO aims to keep search local and scalable but requires multiple GP model runs, increasing compute.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>General black-box optimization, particularly high-dimensional or parallel optimization scenarios.</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>Allocates resources by maintaining several local BO runs in parallel, focusing evaluations inside active trust-regions whose sizes adapt to local progress; more compute is used due to multiple GP fits, trading compute for parallel localized search.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td>Implicitly higher due to multiple concurrent GP fits; paper notes TuRBO requires computation of several GP model runs increasing compute time.</td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td>Uses standard BO acquisition functions (e.g., LCB/EI) within each trust-region to guide local sampling; not an explicit global information-theoretic objective.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td>Trust-region adaptation (expansion/contraction) based on local improvement balances exploration (by creating/expanding regions) and exploitation (local refinement).</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td>Multiple trust-regions provide spatial diversity, but TuRBO does not enforce an explicit diversity objective beyond these local regions.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td>Parallel evaluation budgets and compute budgets (multiple GPs).</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td>Parallelizes evaluations and can run multiple local optimizers to use available compute, but at the cost of increased GP model computation.</td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td>Measured by ability to find global optima; in this paper, TuRBO found worse optima compared to ZoMBI on NiaH tasks (often trapped in local minima).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>In experiments, TuRBO often found suboptimal minima (e.g., Poisson's ratio ≈ -0.55) within 100 experiments versus ZoMBI finding ≈ -1.7.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Compared in this paper as a representative bounded-search approach against ZoMBI, MiP-EGO, HEBO, and standard BO.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>TuRBO underperformed ZoMBI and HEBO on the presented NiaH datasets in terms of objective values found within 100 experiments and exhibited larger variance across runs.</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td>TuRBO's strength is scalability and parallelism rather than compute-per-experiment reduction; the paper notes it requires more compute due to multiple GPs.</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td>TuRBO trades added compute (multiple local GPs) for better local search scalability, but this can still lead to pigeonholing into local minima in needle-like landscapes.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td>Noted as limited for NiaH problems because parallel local runs do not guarantee discovering narrow needles and increased compute may not yield corresponding increases in discovery probability.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Fast Bayesian optimization of Needle-in-a-Haystack problems using zooming memory-based initialization (ZoMBI)', 'publication_date_yy_mm': '2022-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2629.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e2629.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>MiP-EGO</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>MiP-EGO (Parallel Efficient Global Optimization)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A parallelized variant of Efficient Global Optimization (EGO) designed to discover optima faster by suggesting multiple points per iteration using derivative-free parallel strategies.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Automatic configuration of deep neural networks with parallel efficient global optimization</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>MiP-EGO</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>MiP-EGO parallelizes the classical EGO approach to propose multiple candidate evaluations in each iteration to accelerate discovery in wall-clock time; it leverages parallel function evaluations but still relies on GP surrogates and acquisition-style selection.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Black-box optimization where parallel evaluations are possible (e.g., hyperparameter tuning, materials screening).</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>Allocates a batch of parallel experiments each iteration to speed up discovery; selection aims to diversify proposals while leveraging surrogate predictions.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td>Aims to reduce wall-clock time by exploiting parallel resources; computational overhead remains in GP retraining and batch selection.</td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td>Based on EGO/EI-style expected improvement for selecting batch candidates; may use heuristics to diversify batch.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td>Batch selection blends exploration and exploitation across proposed parallel points, typically via modifications to EI or batch acquisition heuristics.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td>Batch proposal requires mechanisms to avoid redundant points; MiP-EGO includes strategies to propose complementary evaluations but details are not deeply described in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td>Wall-clock time / parallel compute resources and number of parallel evaluations per iteration.</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td>Allocates multiple parallel evaluations per iteration to utilize available compute resources and reduce wall-clock time to discovery.</td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td>Measured by number of experiments to reach high-performing samples; in this paper MiP-EGO often underperformed or matched random sampling on some NiaH tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>In the Poisson's Ratio and thermoelectric experiments, MiP-EGO found substantially worse optima than ZoMBI and sometimes performed worse than random sampling (thermoelectric example).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Compared directly to ZoMBI, TuRBO, HEBO, and standard BO in experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>MiP-EGO underperformed ZoMBI on NiaH tasks in this paper and in at least one case performed worse than random sampling.</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td>Parallelization reduces wall-clock time when parallel compute is available, but does not necessarily improve sample-efficiency for needle-like optima.</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td>Parallel batch proposals trade-off between faster wall-clock progress and possible lower per-sample information due to poor batch diversification; not always beneficial in highly imbalanced needle-like problems.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td>Parallel batch size should be chosen carefully; for needle-like, highly localized optima, naive batch strategies can waste parallel capacity if proposals are redundant or focus on local minima.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Fast Bayesian optimization of Needle-in-a-Haystack problems using zooming memory-based initialization (ZoMBI)', 'publication_date_yy_mm': '2022-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2629.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e2629.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>HEBO</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>HEBO (Hebo: sample-efficient hyperparameter optimisation)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A modern, high-performance Bayesian optimization system (NeurIPS 2020 winning entry) employing design choices for sample efficiency and robustness across diverse black-box tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>HEBO: Pushing the limits of sample-efficient hyperparameter optimisation honorary position</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>HEBO</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>HEBO is an engineered BO stack combining surrogate modeling choices, automatic handling of heteroskedastic noise, and robust acquisition strategies; designed for general-purpose hyperparameter and black-box optimization. In this paper HEBO is used as a strong baseline; it generally performs well but was sometimes outperformed by ZoMBI on needle-like tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>General black-box and hyperparameter optimization; used here as a baseline for materials and ecological optimization tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>Standard BO selection via acquisition maximization with engineering choices for robustness; allocates experiments sequentially to maximize expected utility per evaluation.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td>Standard BO computational metrics; HEBO is designed for sample-efficiency rather than extreme per-evaluation compute minimization.</td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td>Uses acquisition functions that capture expected improvement/uncertainty considerations; exact internal metrics depend on HEBO implementation components.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td>HEBO uses informed acquisition strategies and surrogate choices to balance exploration and exploitation; details beyond the scope of this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td>HEBO includes robustness measures and modeling choices to avoid degenerate sampling, which indirectly aids diversity; no explicit diversity objective described here.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td>Sequential experiment budgets; HEBO aims to be sample-efficient under small experiment budgets.</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td>Optimizes each sequential allocation with sample-efficiency heuristics; no explicit pruning strategy like ZoMBI.</td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td>Measured by best objective found under small budgets; HEBO found the Poisson's Ratio needle in experiments but typically required slightly more evaluations than ZoMBI in this paper's cases.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>HEBO discovered the Poisson's-ratio global minimum but took ≈90 experiments vs ZoMBI ≈70 in the reported trials; on thermoelectric and wildfire tasks HEBO sometimes matched or lagged ZoMBI.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Used as a state-of-the-art baseline against ZoMBI, TuRBO, MiP-EGO, and standard BO.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>HEBO generally outperformed MiP-EGO and TuRBO in the paper, and was competitive with ZoMBI but often slower to converge to the best-known needle in the tested NiaH datasets.</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td>HEBO provides good sample-efficiency; however, ZoMBI reported faster convergence and lower per-experiment compute in these needle-type problems due to zooming/pruning.</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td>HEBO trades general-purpose robustness and modeling sophistication for not explicitly bounding per-iteration surrogate cost; thus on extremely long runs its per-experiment compute can grow while ZoMBI keeps it bounded.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td>HEBO is a strong general-purpose choice when sample-efficiency is desired; for extreme needle-like tasks, augmenting BO with zoom/prune strategies (as ZoMBI does) can improve speed and reliability.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Fast Bayesian optimization of Needle-in-a-Haystack problems using zooming memory-based initialization (ZoMBI)', 'publication_date_yy_mm': '2022-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2629.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e2629.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Sparse GP</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Sparse Gaussian Processes using Pseudo-inputs / Inducing Points</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Approximate GP techniques that reduce GP training complexity by representing the posterior with m inducing/pseudo-inputs, lowering computational cost at the expense of approximation error and requiring optimization of inducing locations or variational parameters.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Sparse Gaussian Processes using Pseudo-inputs</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Sparse Gaussian Processes</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Sparse GPs reduce the cubic cost of exact GP inference by projecting data onto a small set of m inducing variables/pseudo-inputs; computational cost becomes O(m n^2) or O(m^2 n) depending on method, and variational approaches minimize KL divergence between approximate and true posterior, often requiring computationally intensive variational optimization.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Scaling surrogate models (GPs) for BO and other regression tasks with large datasets.</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>Not an allocation policy per se, but enables more evaluations by reducing per-update compute; selection of inducing points is itself an allocation/selection subproblem (where to place pseudo-inputs to capture important behavior).</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td>Reduces GP complexity from O(n^3) to costs dependent on m (e.g., O(m n^2) or lower variants); computational cost includes variational optimization of inducing points which can be nontrivial.</td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td>Variational objective often minimizes KL divergence (information-theoretic) between approximate and true posterior — implicitly an information-aware approximation.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td>Indirect: by enabling more evaluations, sparse GPs can allow more exploration, but approximation error can smooth or obscure narrow needles leading to missed breakthroughs.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td>No explicit diversity mechanism; depends on downstream acquisition used in BO.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td>Computational budget (time/memory) for surrogate training.</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td>Reduce training complexity via a small set of inducing points (m) chosen via optimization or heuristics, trading approximation accuracy for lower compute.</td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td>Approximation quality can be measured via KL divergence to full GP posterior or downstream optimization success (probability of finding the needle).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Paper notes sparse GP methods reduce compute but require variational inference which can itself be expensive; authors argue sparse/parametric surrogates may lack predictive fidelity for needle-in-a-haystack problems.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Discussed as an alternative to ZoMBI's pruning for compute reduction; contrasted with ZoMBI which retains full exact GP but on a small dataset via pruning.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>Sparse GP speeds up BO but can smooth over very narrow optima; ZoMBI's pruning + focused GP retains exact GP fidelity inside zoomed region and empirically outperformed approaches relying solely on faster surrogate approximations in NiaH tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td>Sparse GP reduces theoretical GP complexity; the paper cites variational inducing approaches and related references but emphasizes tradeoffs in predictive fidelity for needle detection.</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td>Sparse GPs trade surrogate fidelity for computational tractability; this smoothing effect can cause missed narrow optima in needle-like tasks, a central rationale for ZoMBI's alternative approach.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td>Where needles are extremely narrow, prefer exact-GP fidelity restricted to focused regions (as in ZoMBI) rather than global sparse approximations that may smooth out rare optima.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Fast Bayesian optimization of Needle-in-a-Haystack problems using zooming memory-based initialization (ZoMBI)', 'publication_date_yy_mm': '2022-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Scalable Global Optimization via Local Bayesian Optimization <em>(Rating: 2)</em></li>
                <li>Automatic configuration of deep neural networks with parallel efficient global optimization <em>(Rating: 2)</em></li>
                <li>Hebo: Pushing the limits of sample-efficient hyperparameter optimisation honorary position <em>(Rating: 2)</em></li>
                <li>Sparse Gaussian Processes using Pseudo-inputs <em>(Rating: 2)</em></li>
                <li>Entropy search for information-efficient global optimization <em>(Rating: 1)</em></li>
                <li>Fast Bayesian Optimization of Machine Learning Hyperparameters on Large Datasets <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-2629",
    "paper_id": "paper-79877a26ee5b21404a9ef928e1185ab076255782",
    "extraction_schema_id": "extraction-schema-67",
    "extracted_data": [
        {
            "name_short": "ZoMBI",
            "name_full": "Zooming Memory-Based Initialization",
            "brief_description": "An algorithm building on Bayesian optimization that iteratively 'zooms' the search bounds using the best-performing memory points and prunes low-performing historical data to reduce GP compute cost, combined with adaptive acquisition functions to avoid pigeonholing into local minima.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "ZoMBI (Zooming Memory-Based Initialization)",
            "system_description": "ZoMBI is an active Bayesian optimization framework for 'needle-in-a-haystack' problems. Key components: (1) Memory-based zooming — retain the m best historical experiments and compute per-dimension bounds from their minima/maxima to define a tightened search box; (2) Memory pruning — discard historical points outside the zoomed region so the GP surrogate is only trained on a small, bounded set (i + up to phi points per activation); (3) Activations — repeat cycles ('alpha' activations) of: (a) initialize with i LHS samples inside the current bounds, (b) perform up to phi forward experiments retraining the GP after each new sample, (c) update memory and recompute bounds; (4) Adaptive acquisition functions — optionally use LCB Adaptive and EI Abrupt to dynamically change exploration/exploitation behavior based on sampled data quality and quantity. The algorithm therefore explicitly trades broader global sampling early for focused, high-resolution surrogate modeling in promising subregions while bounding computational expense per activation.",
            "application_domain": "General black-box optimization with demonstrations in materials discovery (auxetic and thermoelectric materials) and ecological resource management (wildfire detection); applicable to other scientific discovery tasks with extreme class imbalance.",
            "resource_allocation_strategy": "Allocates experimental/computational budget in repeated cycles: (1) use m best historical points to define a smaller region to focus the next allocation; (2) within that region, allocate a fixed small initialization budget i (via LHS) plus up to phi sequential forward experiments per activation; (3) retrain GP only on retained memory and current forward points to limit compute; (4) adaptive acquisition functions decide which individual points to evaluate (maximize acquisition value) balancing exploration/exploitation based on recent performance and sample count. In short: coarse global sampling → keep top-m outcomes → zoom region → devote bounded local budget to refine and exploit.",
            "computational_cost_metric": "Wall-clock compute time per experiment (measured), and analytic time-complexity of GP training: standard GP O(n^3) where n is cumulative experiments; ZoMBI reduces per-activation training size to O((i+phi)^3) ≈ O(phi^3) and, with repeated activations, trends to approximately constant per-experiment cost O(1) in practice.",
            "information_gain_metric": "Uses standard BO acquisition functions: Expected Improvement (EI) as explicit expected-utility measure, Lower Confidence Bound (LCB) combining mean and variance, and custom variants (EI Abrupt, LCB Adaptive) that respond to observed improvement or sample count. Thus information-driven utility is measured via EI (expected improvement) and uncertainty-weighted scores (LCB).",
            "uses_information_gain": true,
            "exploration_exploitation_mechanism": "Several mechanisms: (a) algorithmic: zooming progressively reduces search volume to increase local exploitation resolution while still reinitializing by LHS to avoid pure local search; (b) acquisition-level: LCB Adaptive decays the exploration weight (beta * epsilon^n) as n grows to move from exploration to exploitation; EI Abrupt switches between exploitative EI and explorative LCB when recent finite differences in objective values plateau; static EI/LCB are also supported. Together these dynamically rebalance exploration vs exploitation in response to observed returns and sample count.",
            "diversity_mechanism": "Implicit diversity promotion via (1) per-activation LHS initialization inside zoomed bounds (ensures space-filling within region), (2) EI Abrupt's switching to exploration when recent improvements plateau, and (3) LCB Adaptive's higher exploration weight early on; zooming across each dimension independently also helps avoid focusing on narrow local minima that are not aligned across dimensions. There is no explicit diversity objective (e.g., determinantal or penalized clustering), but mechanisms actively attempt to avoid pigeonholing and encourage exploration when warranted.",
            "uses_diversity_promotion": true,
            "budget_constraint_type": "Fixed-number-of-experiments budget (demonstrated: up to 100 and up to 1000 experiments), and computational-budget constraints (wall-clock time per experiment, GP training cost).",
            "budget_constraint_handling": "Handles budget by capping per-activation forward experiments (phi) and fixed initialization size (i), thereby bounding GP training set size and per-activation compute cost; memory pruning keeps GP training complexity small irrespective of cumulative n. The acquisition functions adapt behavior based on remaining effective budget via decay (LCB Adaptive) or plateau detection (EI Abrupt).",
            "breakthrough_discovery_metric": "Defined operationally as locating the needle-like global optimum or a top-performing sample: e.g., attaining target objective values (Poisson's ratio ≈ -1.7, ZT ≈ 1.4, wildfire index ψ ≈ -3.5) or falling within the Ackley basin threshold (f(X) &lt; 10). Breakthroughs are therefore measured by raw objective value improvement and by whether the sample falls inside the narrow optimum basin.",
            "performance_metrics": "Reported metrics include: number of experiments to discover needle-like optima (e.g., discovered Li2NbF6 with ν≈-1.7 in ~70 experiments with LCB/LCB Adaptive), wall-clock compute time per experiment (ZoMBI ≈1 s/experiment vs standard BO &gt;400 s/experiment at n=1000), and success on synthetic Ackley permutations (reliably finds optima when optimum hypervolume is between 0.05% and 5% for i=5). Also reported: median best running objective across ensemble runs and KDE of final sampled outcomes.",
            "comparison_baseline": "Compared against standard BO (GP+static EI/LCB), MiP-EGO (parallelized EGO), TuRBO (trust-region local BO), HEBO (NeurIPS 2020 winning BO system), and random sampling baselines.",
            "performance_vs_baseline": "ZoMBI converged faster and to better optima in the tested NiaH cases: e.g., on Poisson's Ratio dataset ZoMBI (LCB/LCB Adaptive) found the global minimum in under 100 experiments while MiP-EGO and TuRBO found much worse minima (ν≈-0.20 and ν≈-0.55 respectively); compute-time per experiment at n=1000 was ≈1s for ZoMBI vs &gt;400s for standard BO, a ≈400x speed-up. On thermoelectric dataset LCB Adaptive (ZoMBI) found ZT≈1.4 whereas competitors did not find this needle; on wildfire dataset ZoMBI variants discovered ψ≈-3.5 while others found worse minima (ψ≈-2.5).",
            "efficiency_gain": "Reported ≈400x wall-clock compute-time speed-up per experiment at n=1000 relative to traditional GP-based BO; reduced number of experiments to find optima (e.g., discover material optima in &lt;100 experiments); results up to ≈3x better final objective values compared to MiP-EGO and TuRBO in the Poisson's Ratio task (as reported).",
            "tradeoff_analysis": "The paper analyzes tradeoffs explicitly: (1) compute vs information: pruning reduces compute but requires retaining a sufficiently informative m and initialization i to avoid missing narrow needles; (2) needle hypervolume vs initialization: ZoMBI performs reliably when needle occupies between 0.05%–5% hypervolume with i=5; narrower needles require larger initialization to avoid missing the global optimum (so there is a tradeoff between upfront sampling cost and later focused search); (3) exploration vs over-zooming: for very wide optima ZoMBI's greedy zoom can falsely focus on suboptimal regions. These analyses quantify that aggressive pruning/zooming yields compute gains but increases risk of missing extremely narrow or edge optima unless initialization is increased.",
            "optimal_allocation_findings": "Key recommendations: (1) keep a small, fixed per-activation GP training budget (i + phi) and prune older data to cap compute; (2) use the m best performing points to define per-dimension zoom bounds for targeted allocation; (3) adapt acquisition hyperparameters online (e.g., decay exploration weight or switch to exploration on plateau) to balance exploration and exploitation; (4) ensure initialization size i scales with expected needle hypervolume — for extremely narrow optima increase i to avoid missing the needle; (5) cap phi to maintain low per-activation compute and repeat activations to progressively refine allocation.",
            "uuid": "e2629.0",
            "source_info": {
                "paper_title": "Fast Bayesian optimization of Needle-in-a-Haystack problems using zooming memory-based initialization (ZoMBI)",
                "publication_date_yy_mm": "2022-08"
            }
        },
        {
            "name_short": "LCB Adaptive",
            "name_full": "Lower Confidence Bound (Adaptive)",
            "brief_description": "A dynamic variant of the LCB acquisition function whose exploration hyperparameter beta decays with sample count, making the acquisition progressively more exploitative as more data is collected.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "LCB Adaptive acquisition function",
            "system_description": "LCB Adaptive computes acquisition a(X,n;beta,epsilon) = mu(X) - epsilon^n * beta * sigma(X) for minimization, where mu and sigma are GP mean and stddev, beta is an initial exploration weight and epsilon in (0,1) controls decay rate; as n (number of experiments) increases, exploration weight decays exponentially (epsilon^n), steering sampling toward exploitation. Hyperparameters used in paper: beta=3, epsilon=0.9 (hand-tuned).",
            "application_domain": "Used inside Bayesian optimization for needle-in-a-haystack scientific discovery problems (materials and wildfire detection) to manage exploration-exploitation over sequential budget.",
            "resource_allocation_strategy": "Select next experiment by maximizing the LCB Adaptive acquisition value; early iterations emphasize sigma(X) (exploration) due to large beta*epsilon^n, later iterations downweight sigma to prioritize mu(X) (exploitation). Thus resource allocation shifts from diverse exploration to concentrated exploitation as budget is expended.",
            "computational_cost_metric": "No special computational cost metric beyond the usual GP retraining cost; used within ZoMBI where per-activation GP size is limited to bound compute.",
            "information_gain_metric": "Implicitly uses uncertainty (sigma) as a proxy for information gain; not an explicit mutual-information or entropy objective but standard LCB-style uncertainty-weighted expected utility.",
            "uses_information_gain": true,
            "exploration_exploitation_mechanism": "Explicit: multiply sigma(X) by a decaying factor epsilon^n * beta so exploration contribution reduces with n, shifting allocation progressively to exploitation.",
            "diversity_mechanism": "Promotes diversity early through a high initial beta, then reduces diversity pressure as more samples are collected; no explicit diversity objective beyond exploration weighting.",
            "uses_diversity_promotion": true,
            "budget_constraint_type": "Sequential experiment budget (n) and per-activation bounded budgets when used within ZoMBI.",
            "budget_constraint_handling": "Adapts exploration weight as a function of samples taken (n) to reflect decreasing remaining budget/value of exploration.",
            "breakthrough_discovery_metric": "Same as the enclosing BO: breakthroughs measured by attained objective improvements (e.g., locating needle-like optima).",
            "performance_metrics": "Within ZoMBI, LCB Adaptive achieved fast discovery (e.g., discovered Poisson's-ratio needle in under 100 experiments) and low variance across runs in some tasks; compared favorably to static LCB and EI in combination with ZoMBI.",
            "comparison_baseline": "Compared to static LCB, EI, EI Abrupt, and standard BO baselines in experiments inside ZoMBI.",
            "performance_vs_baseline": "Reported to converge faster and more reliably when paired with ZoMBI than static LCB/EI in the tested NiaH problems; on Poisson's Ratio LCB Adaptive (as ZoMBI variant) reached the global minimum faster than MiP-EGO and TuRBO.",
            "efficiency_gain": "Contributes to fewer wasted evaluations by reducing exploration weight over time; included in the overall ZoMBI efficiency gains (part of the &lt;100 experiments discoveries and compute savings).",
            "tradeoff_analysis": "LCB Adaptive embodies an explicit tradeoff: faster decay (smaller epsilon) reduces exploratory sampling sooner (risking premature exploitation), while slower decay retains exploration at higher computational cost. The paper hand-tuned epsilon and beta to balance these effects.",
            "optimal_allocation_findings": "Use a relatively large initial beta and epsilon close to 1 to allow gradual decay (they used beta=3, epsilon=0.9) so the optimizer transitions slowly from exploration to exploitation rather than abruptly, particularly important for needle-in-a-haystack landscapes.",
            "uuid": "e2629.1",
            "source_info": {
                "paper_title": "Fast Bayesian optimization of Needle-in-a-Haystack problems using zooming memory-based initialization (ZoMBI)",
                "publication_date_yy_mm": "2022-08"
            }
        },
        {
            "name_short": "EI Abrupt",
            "name_full": "Expected Improvement Abrupt-switch",
            "brief_description": "A hybrid acquisition strategy that normally uses Expected Improvement (EI) but switches abruptly to an explorative LCB-style policy when recent sampled objective values have plateaued, to escape local minima.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "EI Abrupt acquisition function",
            "system_description": "EI Abrupt computes either the standard EI acquisition when recent finite differences in objective values exceed a threshold (i.e., improvement is being achieved), or uses a more explorative surrogate-based score mu(X) - beta * sigma(X) when the last three sampled y-values show negligible change (|Δ{y_{n-3...n}}| ≤ eta). Hyperparameters: beta=0.1, xi=0.1 (EI’s improvement margin), eta=0 (plateau threshold). This enables dynamic switching between exploitation (EI) and exploration (LCB-like) based on empirical short-term progress.",
            "application_domain": "Bayesian optimization in NiaH scientific discovery tasks where local minima/pigeonholing are common.",
            "resource_allocation_strategy": "Allocates next experiments according to EI when recent sampling yields improvements, but upon detection of a plateau switches allocation to exploration-driven points (favoring larger sigma) to escape local minima; thus redirects resources away from diminishing-return local refinement toward diverse search when needed.",
            "computational_cost_metric": "Operates within standard BO computational budgets; switching logic is computationally negligible compared to GP training.",
            "information_gain_metric": "Uses EI (expected improvement) when exploiting and an uncertainty-weighted surrogate (mu - beta*sigma) when exploring; uses recent improvements as a trigger rather than an explicit information-theoretic metric.",
            "uses_information_gain": true,
            "exploration_exploitation_mechanism": "Triggered switching based on finite differences in recent y-values (plateau detection). If plateau detected, apply explorative policy; otherwise apply EI. This is an empirically reactive exploration-exploitation control.",
            "diversity_mechanism": "Promotes diversity by switching to exploration when improvement stalls, causing selection of points with higher predictive uncertainty and thus more diverse hypotheses.",
            "uses_diversity_promotion": true,
            "budget_constraint_type": "Sequential experiment budget; used within ZoMBI per-activation budgets.",
            "budget_constraint_handling": "By switching only when improvement stalls, EI Abrupt conserves budget when exploitation is productive and re-allocates budget to exploration only when exploitation yields diminishing returns.",
            "breakthrough_discovery_metric": "Same as BO baseline: discovery if EI or switched exploration leads to samples with markedly better objective values (needle samples).",
            "performance_metrics": "Shown to help escape local minima in standalone BO experiments (without ZoMBI) more effectively than static LCB/EI; when combined with ZoMBI, EI Abrupt also contributed to faster convergence in some tasks and reduced variance across runs.",
            "comparison_baseline": "Compared to static EI and LCB and the LCB Adaptive variant; also tested in ZoMBI vs non-ZoMBI contexts.",
            "performance_vs_baseline": "EI Abrupt could escape local minima where static EI/LCB failed; with ZoMBI, most acquisition functions (including EI Abrupt) converged to global minima faster except for the most exploitative (static EI) in some cases.",
            "efficiency_gain": "Improves effective use of budget by triggering exploration only when needed, contributing to fewer wasted exploitative evaluations stuck in plateaus.",
            "tradeoff_analysis": "Switching threshold (eta) and beta determine sensitivity: too-sensitive switching may waste explorative budget, too insensitive may delay escape from plateaus. Paper used conservative hand-tuned values (eta=0, beta=0.1) to enable occasional exploration without large deviation from exploitation.",
            "optimal_allocation_findings": "Use short-window plateau detection (last 3 y-values) to decide switching; keep beta small (0.1) so exploration does not diverge excessively from promising regions while still enabling escapes from local minima.",
            "uuid": "e2629.2",
            "source_info": {
                "paper_title": "Fast Bayesian optimization of Needle-in-a-Haystack problems using zooming memory-based initialization (ZoMBI)",
                "publication_date_yy_mm": "2022-08"
            }
        },
        {
            "name_short": "Memory Pruning",
            "name_full": "Memory pruning in ZoMBI",
            "brief_description": "A mechanism within ZoMBI that discards low-performing or out-of-region historical experiments so GP surrogate training is restricted to a small, recent, and relevant dataset, bounding compute cost.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "Memory pruning (ZoMBI component)",
            "system_description": "After each activation, ZoMBI retains only the m best-performing experiments (or those inside the current zoomed bounds) and erases other historical data from memory. This ensures the GP surrogate is trained only on i (initial LHS) + up to phi forward experiments per activation, keeping the surrogate matrix sizes small and per-activation GP training cost O((i+phi)^3).",
            "application_domain": "Used inside sequential Bayesian optimization for expensive experiments/simulations to limit surrogate-training costs in long optimization runs.",
            "resource_allocation_strategy": "Indirectly reallocates computational budget by freeing capacity (time/memory) that would otherwise be spent retraining on all historical data; enables more forward experiments or repeated activations under fixed wall-clock constraints.",
            "computational_cost_metric": "Measured via wall-clock time per experiment; theoretical reduction from O(n^3) (standard cumulative GP) to O((i+phi)^3) per activation, with observed ≈400x reduction at n=1000 in experiments.",
            "information_gain_metric": "No explicit information metric used to decide which points to prune beyond performance-based ranking (retain m best by objective value) and containment within zoomed bounds.",
            "uses_information_gain": false,
            "exploration_exploitation_mechanism": "Pruning focuses surrogate fidelity on the promising region (exploitation) at the cost of removing some global historical context (reducing some exploratory memory). This is balanced by reinitializing with LHS inside each zoomed region and adaptive acquisition functions to maintain exploration when needed.",
            "diversity_mechanism": "Pruning reduces diversity of the training set intentionally; diversity is maintained via LHS initialization inside zoomed bounds and the activation-resetting procedure rather than retaining broad historical diversity.",
            "uses_diversity_promotion": false,
            "budget_constraint_type": "Computational budget (time/memory) and implicit experimental budget by enabling more effective use of limited compute per experiment.",
            "budget_constraint_handling": "Caps GP training set size by design (i + phi), thereby bounding per-activation compute and enabling the algorithm to operate under strict per-experiment wall-clock/time budgets.",
            "breakthrough_discovery_metric": "Indirect: by enabling many low-cost surrogate retrainings and focused sampling, pruning aims to increase probability of discovering needle-like breakthroughs within a fixed wall-clock budget.",
            "performance_metrics": "Empirical: compute time per experiment for ZoMBI stayed ~1 s/experiment versus &gt;400 s/experiment for standard BO at n=1000; overall optimization success rates improved in many tested NiaH tasks when pruning was used with zooming and adaptive acquisitions.",
            "comparison_baseline": "Compared against standard BO that retains all historical data and trains GP on cumulative n, resulting in O(n^3) cost.",
            "performance_vs_baseline": "Pruning + zooming achieved ≈400x wall-clock speed-up at large n and allowed more consistent/faster discovery of optima with fewer resources; however, pruning increases risk of missing very narrow or edge optima if initialization i is insufficient.",
            "efficiency_gain": "≈400x per-experiment wall-clock time reduction at n=1000 relative to standard cumulative-GP BO in reported experiments; asymptotically tends toward constant per-experiment cost over many activations.",
            "tradeoff_analysis": "Pruning trades global historical context (which can help avoid missing distant needles) for bounded compute and denser local modeling; paper quantifies that with i=5 initialization, ZoMBI succeeds when needle hypervolume ∈ [0.05%, 5%], and failures occur for narrower needles unless i is increased.",
            "optimal_allocation_findings": "Cap per-activation GP size (via phi and i) to control compute; choose m (retained memory) to be large enough to capture the plausible extent of the needle but small enough to permit fast retraining; increase initial sampling i when expecting extremely narrow optima.",
            "uuid": "e2629.3",
            "source_info": {
                "paper_title": "Fast Bayesian optimization of Needle-in-a-Haystack problems using zooming memory-based initialization (ZoMBI)",
                "publication_date_yy_mm": "2022-08"
            }
        },
        {
            "name_short": "TuRBO",
            "name_full": "TuRBO (Trust-region Bayesian Optimization)",
            "brief_description": "A trust-region based BO approach that runs a collection of local BO instances (local GPs) within adaptive trust-regions to scale optimization in high-dimensions and focus search locally.",
            "citation_title": "Scalable Global Optimization via Local Bayesian Optimization",
            "mention_or_use": "mention",
            "system_name": "TuRBO",
            "system_description": "TuRBO manages multiple local trust-regions each centered at a candidate and runs local BO with separate GP surrogates; trust-regions expand or contract based on recent successes, and parallel evaluations are supported. TuRBO aims to keep search local and scalable but requires multiple GP model runs, increasing compute.",
            "application_domain": "General black-box optimization, particularly high-dimensional or parallel optimization scenarios.",
            "resource_allocation_strategy": "Allocates resources by maintaining several local BO runs in parallel, focusing evaluations inside active trust-regions whose sizes adapt to local progress; more compute is used due to multiple GP fits, trading compute for parallel localized search.",
            "computational_cost_metric": "Implicitly higher due to multiple concurrent GP fits; paper notes TuRBO requires computation of several GP model runs increasing compute time.",
            "information_gain_metric": "Uses standard BO acquisition functions (e.g., LCB/EI) within each trust-region to guide local sampling; not an explicit global information-theoretic objective.",
            "uses_information_gain": true,
            "exploration_exploitation_mechanism": "Trust-region adaptation (expansion/contraction) based on local improvement balances exploration (by creating/expanding regions) and exploitation (local refinement).",
            "diversity_mechanism": "Multiple trust-regions provide spatial diversity, but TuRBO does not enforce an explicit diversity objective beyond these local regions.",
            "uses_diversity_promotion": true,
            "budget_constraint_type": "Parallel evaluation budgets and compute budgets (multiple GPs).",
            "budget_constraint_handling": "Parallelizes evaluations and can run multiple local optimizers to use available compute, but at the cost of increased GP model computation.",
            "breakthrough_discovery_metric": "Measured by ability to find global optima; in this paper, TuRBO found worse optima compared to ZoMBI on NiaH tasks (often trapped in local minima).",
            "performance_metrics": "In experiments, TuRBO often found suboptimal minima (e.g., Poisson's ratio ≈ -0.55) within 100 experiments versus ZoMBI finding ≈ -1.7.",
            "comparison_baseline": "Compared in this paper as a representative bounded-search approach against ZoMBI, MiP-EGO, HEBO, and standard BO.",
            "performance_vs_baseline": "TuRBO underperformed ZoMBI and HEBO on the presented NiaH datasets in terms of objective values found within 100 experiments and exhibited larger variance across runs.",
            "efficiency_gain": "TuRBO's strength is scalability and parallelism rather than compute-per-experiment reduction; the paper notes it requires more compute due to multiple GPs.",
            "tradeoff_analysis": "TuRBO trades added compute (multiple local GPs) for better local search scalability, but this can still lead to pigeonholing into local minima in needle-like landscapes.",
            "optimal_allocation_findings": "Noted as limited for NiaH problems because parallel local runs do not guarantee discovering narrow needles and increased compute may not yield corresponding increases in discovery probability.",
            "uuid": "e2629.4",
            "source_info": {
                "paper_title": "Fast Bayesian optimization of Needle-in-a-Haystack problems using zooming memory-based initialization (ZoMBI)",
                "publication_date_yy_mm": "2022-08"
            }
        },
        {
            "name_short": "MiP-EGO",
            "name_full": "MiP-EGO (Parallel Efficient Global Optimization)",
            "brief_description": "A parallelized variant of Efficient Global Optimization (EGO) designed to discover optima faster by suggesting multiple points per iteration using derivative-free parallel strategies.",
            "citation_title": "Automatic configuration of deep neural networks with parallel efficient global optimization",
            "mention_or_use": "mention",
            "system_name": "MiP-EGO",
            "system_description": "MiP-EGO parallelizes the classical EGO approach to propose multiple candidate evaluations in each iteration to accelerate discovery in wall-clock time; it leverages parallel function evaluations but still relies on GP surrogates and acquisition-style selection.",
            "application_domain": "Black-box optimization where parallel evaluations are possible (e.g., hyperparameter tuning, materials screening).",
            "resource_allocation_strategy": "Allocates a batch of parallel experiments each iteration to speed up discovery; selection aims to diversify proposals while leveraging surrogate predictions.",
            "computational_cost_metric": "Aims to reduce wall-clock time by exploiting parallel resources; computational overhead remains in GP retraining and batch selection.",
            "information_gain_metric": "Based on EGO/EI-style expected improvement for selecting batch candidates; may use heuristics to diversify batch.",
            "uses_information_gain": true,
            "exploration_exploitation_mechanism": "Batch selection blends exploration and exploitation across proposed parallel points, typically via modifications to EI or batch acquisition heuristics.",
            "diversity_mechanism": "Batch proposal requires mechanisms to avoid redundant points; MiP-EGO includes strategies to propose complementary evaluations but details are not deeply described in this paper.",
            "uses_diversity_promotion": true,
            "budget_constraint_type": "Wall-clock time / parallel compute resources and number of parallel evaluations per iteration.",
            "budget_constraint_handling": "Allocates multiple parallel evaluations per iteration to utilize available compute resources and reduce wall-clock time to discovery.",
            "breakthrough_discovery_metric": "Measured by number of experiments to reach high-performing samples; in this paper MiP-EGO often underperformed or matched random sampling on some NiaH tasks.",
            "performance_metrics": "In the Poisson's Ratio and thermoelectric experiments, MiP-EGO found substantially worse optima than ZoMBI and sometimes performed worse than random sampling (thermoelectric example).",
            "comparison_baseline": "Compared directly to ZoMBI, TuRBO, HEBO, and standard BO in experiments.",
            "performance_vs_baseline": "MiP-EGO underperformed ZoMBI on NiaH tasks in this paper and in at least one case performed worse than random sampling.",
            "efficiency_gain": "Parallelization reduces wall-clock time when parallel compute is available, but does not necessarily improve sample-efficiency for needle-like optima.",
            "tradeoff_analysis": "Parallel batch proposals trade-off between faster wall-clock progress and possible lower per-sample information due to poor batch diversification; not always beneficial in highly imbalanced needle-like problems.",
            "optimal_allocation_findings": "Parallel batch size should be chosen carefully; for needle-like, highly localized optima, naive batch strategies can waste parallel capacity if proposals are redundant or focus on local minima.",
            "uuid": "e2629.5",
            "source_info": {
                "paper_title": "Fast Bayesian optimization of Needle-in-a-Haystack problems using zooming memory-based initialization (ZoMBI)",
                "publication_date_yy_mm": "2022-08"
            }
        },
        {
            "name_short": "HEBO",
            "name_full": "HEBO (Hebo: sample-efficient hyperparameter optimisation)",
            "brief_description": "A modern, high-performance Bayesian optimization system (NeurIPS 2020 winning entry) employing design choices for sample efficiency and robustness across diverse black-box tasks.",
            "citation_title": "HEBO: Pushing the limits of sample-efficient hyperparameter optimisation honorary position",
            "mention_or_use": "mention",
            "system_name": "HEBO",
            "system_description": "HEBO is an engineered BO stack combining surrogate modeling choices, automatic handling of heteroskedastic noise, and robust acquisition strategies; designed for general-purpose hyperparameter and black-box optimization. In this paper HEBO is used as a strong baseline; it generally performs well but was sometimes outperformed by ZoMBI on needle-like tasks.",
            "application_domain": "General black-box and hyperparameter optimization; used here as a baseline for materials and ecological optimization tasks.",
            "resource_allocation_strategy": "Standard BO selection via acquisition maximization with engineering choices for robustness; allocates experiments sequentially to maximize expected utility per evaluation.",
            "computational_cost_metric": "Standard BO computational metrics; HEBO is designed for sample-efficiency rather than extreme per-evaluation compute minimization.",
            "information_gain_metric": "Uses acquisition functions that capture expected improvement/uncertainty considerations; exact internal metrics depend on HEBO implementation components.",
            "uses_information_gain": true,
            "exploration_exploitation_mechanism": "HEBO uses informed acquisition strategies and surrogate choices to balance exploration and exploitation; details beyond the scope of this paper.",
            "diversity_mechanism": "HEBO includes robustness measures and modeling choices to avoid degenerate sampling, which indirectly aids diversity; no explicit diversity objective described here.",
            "uses_diversity_promotion": true,
            "budget_constraint_type": "Sequential experiment budgets; HEBO aims to be sample-efficient under small experiment budgets.",
            "budget_constraint_handling": "Optimizes each sequential allocation with sample-efficiency heuristics; no explicit pruning strategy like ZoMBI.",
            "breakthrough_discovery_metric": "Measured by best objective found under small budgets; HEBO found the Poisson's Ratio needle in experiments but typically required slightly more evaluations than ZoMBI in this paper's cases.",
            "performance_metrics": "HEBO discovered the Poisson's-ratio global minimum but took ≈90 experiments vs ZoMBI ≈70 in the reported trials; on thermoelectric and wildfire tasks HEBO sometimes matched or lagged ZoMBI.",
            "comparison_baseline": "Used as a state-of-the-art baseline against ZoMBI, TuRBO, MiP-EGO, and standard BO.",
            "performance_vs_baseline": "HEBO generally outperformed MiP-EGO and TuRBO in the paper, and was competitive with ZoMBI but often slower to converge to the best-known needle in the tested NiaH datasets.",
            "efficiency_gain": "HEBO provides good sample-efficiency; however, ZoMBI reported faster convergence and lower per-experiment compute in these needle-type problems due to zooming/pruning.",
            "tradeoff_analysis": "HEBO trades general-purpose robustness and modeling sophistication for not explicitly bounding per-iteration surrogate cost; thus on extremely long runs its per-experiment compute can grow while ZoMBI keeps it bounded.",
            "optimal_allocation_findings": "HEBO is a strong general-purpose choice when sample-efficiency is desired; for extreme needle-like tasks, augmenting BO with zoom/prune strategies (as ZoMBI does) can improve speed and reliability.",
            "uuid": "e2629.6",
            "source_info": {
                "paper_title": "Fast Bayesian optimization of Needle-in-a-Haystack problems using zooming memory-based initialization (ZoMBI)",
                "publication_date_yy_mm": "2022-08"
            }
        },
        {
            "name_short": "Sparse GP",
            "name_full": "Sparse Gaussian Processes using Pseudo-inputs / Inducing Points",
            "brief_description": "Approximate GP techniques that reduce GP training complexity by representing the posterior with m inducing/pseudo-inputs, lowering computational cost at the expense of approximation error and requiring optimization of inducing locations or variational parameters.",
            "citation_title": "Sparse Gaussian Processes using Pseudo-inputs",
            "mention_or_use": "mention",
            "system_name": "Sparse Gaussian Processes",
            "system_description": "Sparse GPs reduce the cubic cost of exact GP inference by projecting data onto a small set of m inducing variables/pseudo-inputs; computational cost becomes O(m n^2) or O(m^2 n) depending on method, and variational approaches minimize KL divergence between approximate and true posterior, often requiring computationally intensive variational optimization.",
            "application_domain": "Scaling surrogate models (GPs) for BO and other regression tasks with large datasets.",
            "resource_allocation_strategy": "Not an allocation policy per se, but enables more evaluations by reducing per-update compute; selection of inducing points is itself an allocation/selection subproblem (where to place pseudo-inputs to capture important behavior).",
            "computational_cost_metric": "Reduces GP complexity from O(n^3) to costs dependent on m (e.g., O(m n^2) or lower variants); computational cost includes variational optimization of inducing points which can be nontrivial.",
            "information_gain_metric": "Variational objective often minimizes KL divergence (information-theoretic) between approximate and true posterior — implicitly an information-aware approximation.",
            "uses_information_gain": true,
            "exploration_exploitation_mechanism": "Indirect: by enabling more evaluations, sparse GPs can allow more exploration, but approximation error can smooth or obscure narrow needles leading to missed breakthroughs.",
            "diversity_mechanism": "No explicit diversity mechanism; depends on downstream acquisition used in BO.",
            "uses_diversity_promotion": null,
            "budget_constraint_type": "Computational budget (time/memory) for surrogate training.",
            "budget_constraint_handling": "Reduce training complexity via a small set of inducing points (m) chosen via optimization or heuristics, trading approximation accuracy for lower compute.",
            "breakthrough_discovery_metric": "Approximation quality can be measured via KL divergence to full GP posterior or downstream optimization success (probability of finding the needle).",
            "performance_metrics": "Paper notes sparse GP methods reduce compute but require variational inference which can itself be expensive; authors argue sparse/parametric surrogates may lack predictive fidelity for needle-in-a-haystack problems.",
            "comparison_baseline": "Discussed as an alternative to ZoMBI's pruning for compute reduction; contrasted with ZoMBI which retains full exact GP but on a small dataset via pruning.",
            "performance_vs_baseline": "Sparse GP speeds up BO but can smooth over very narrow optima; ZoMBI's pruning + focused GP retains exact GP fidelity inside zoomed region and empirically outperformed approaches relying solely on faster surrogate approximations in NiaH tasks.",
            "efficiency_gain": "Sparse GP reduces theoretical GP complexity; the paper cites variational inducing approaches and related references but emphasizes tradeoffs in predictive fidelity for needle detection.",
            "tradeoff_analysis": "Sparse GPs trade surrogate fidelity for computational tractability; this smoothing effect can cause missed narrow optima in needle-like tasks, a central rationale for ZoMBI's alternative approach.",
            "optimal_allocation_findings": "Where needles are extremely narrow, prefer exact-GP fidelity restricted to focused regions (as in ZoMBI) rather than global sparse approximations that may smooth out rare optima.",
            "uuid": "e2629.7",
            "source_info": {
                "paper_title": "Fast Bayesian optimization of Needle-in-a-Haystack problems using zooming memory-based initialization (ZoMBI)",
                "publication_date_yy_mm": "2022-08"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Scalable Global Optimization via Local Bayesian Optimization",
            "rating": 2
        },
        {
            "paper_title": "Automatic configuration of deep neural networks with parallel efficient global optimization",
            "rating": 2
        },
        {
            "paper_title": "Hebo: Pushing the limits of sample-efficient hyperparameter optimisation honorary position",
            "rating": 2
        },
        {
            "paper_title": "Sparse Gaussian Processes using Pseudo-inputs",
            "rating": 2
        },
        {
            "paper_title": "Entropy search for information-efficient global optimization",
            "rating": 1
        },
        {
            "paper_title": "Fast Bayesian Optimization of Machine Learning Hyperparameters on Large Datasets",
            "rating": 1
        }
    ],
    "cost": 0.024169,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>FAST BAYESIAN OPTIMIZATION OF NEEDLE-IN-A-HAYSTACK PROBLEMS USING ZOOMING MEMORY-BASED INITIALIZATION (ZOMBI)</h1>
<p>Alexander E. Siemenn*<br>Department of Mechanical Engineering Massachusetts Institute of Technology Cambridge, MA 02139, USA asiemenn@mit.edu</p>
<h2>Qianxiao Li</h2>
<p>Department of Mathematics National University of Singapore Singapore 138602, Singapore</p>
<h2>Zekun Ren</h2>
<p>Department of Electrical and Computer Engineering Singapore-MIT Alliance for Research and Technology Singapore 138602, Singapore</p>
<h2>Xinterra</h2>
<p>Singapore 139949, Singapore</p>
<h2>Tonio Buonassisi</h2>
<p>Department of Mechanical Engineering
Massachusetts Institute of Technology
Cambridge, MA 02139, USA</p>
<h4>Abstract</h4>
<p>Needle-in-a-Haystack problems exist across a wide range of applications including rare disease prediction, ecological resource management, fraud detection, and material property optimization. A Needle-in-a-Haystack problem arises when there is an extreme imbalance of optimum conditions relative to the size of the dataset. For example, only $0.82 \%$ out of 146 k total materials in the open-access Materials Project database have a negative Poisson's ratio. However, current state-of-the-art optimization algorithms are not designed with the capabilities to find solutions to these challenging multidimensional Needle-in-a-Haystack problems, resulting in slow convergence to a global optimum or pigeonholing into a local minimum. In this paper, we present a Zooming MemoryBased Initialization algorithm, entitled ZoMBI, that builds on conventional Bayesian optimization principles to quickly and efficiently optimize Needle-in-a-Haystack problems in both less time and fewer experiments by addressing the common convergence and pigeonholing issues. ZoMBI actively extracts knowledge from the previously best-performing evaluated experiments to iteratively zoom in the sampling search bounds towards the global optimum "needle" and then prunes the memory of low-performing historical experiments to accelerate compute times by reducing the algorithm time complexity from $O\left(n^{3}\right)$ to $O\left(\phi^{3}\right)$ for $\phi$ forward experiments per activation, which trends to a constant $O(1)$ over several activations. Additionally, ZoMBI implements two custom adaptive acquisition functions to further guide the sampling of new experiments toward the global optimum. We validate the algorithm's optimization performance on three real-world datasets exhibiting Needle-in-a-Haystack problems that vary in dimensionality from 6D to 11D and further stress-test the algorithm's performance across an additional 174 analytical datasets that vary in optimum needle width, optimum distance to edges, dimensionality, and initialization conditions. The ZoMBI algorithm demonstrates compute time speed-ups of 400x compared to traditional Bayesian optimization as well as efficiently discovering optima in under 100 experiments that are up to 3 x more highly optimized than those discovered by similar methods MiP-EGO, TuRBO, and HEBO.</p>
<p>Keywords rare materials discovery $\cdot$ efficient algorithms $\cdot$ adaptive acquisition functions $\cdot$ trust regions $\cdot$ optimization $\cdot$ extremely imbalance data $\cdot$ auxetic materials $\cdot$ thermoelectric materials, $\cdot$ active learning</p>
<p>Fast Bayesian Optimization of Needle-in-a-Haystack Problems using Zooming Memory-Based Initialization</p>
<h2>1 Introduction</h2>
<p>Current optimization algorithms achieve good results on low-dimensional problems that are smooth and have wide basins of attraction. Examples of smooth manifolds with wide basins of attraction within material science include process- and recipe-optimization problems such as tuning perovskite manufacturing variables to achieve higher efficiency [1], optimizing microfluidics flow parameters to achieve ideal droplet formation [2], optimizing silver nanoparticle recipes for optical properties [3], and tuning perovskite compositions with physics-based constraints to maximize stability [4]. Optimization techniques like Bayesian optimization (BO) are well-suited to model these simple manifolds using a Gaussian Process (GP) surrogate [5, 6, 7, 8, 9]. However, the performance of this BO with a GP breaks down as the manifold complexity increases. Material property optimization problems that have high technological significance, such as discovering materials with rare properties or materials with a specific combination of properties, have search space manifolds that more closely resemble a Needle-in-a-Haystack [10], shown in Figure 1(b), rather than a smooth or convex space.</p>
<p><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Figure 1: Archetypal Manifolds in Materials Science Optimization. (a) In process optimization, there often exists a real and continuous path between each condition. This 3D projected manifold is adapted from the 6D perovskite process optimization problem by Liu et al., where $X_{1}$ is spray flow rate, $X_{2}$ is plasma voltage, and $f(X)$ is cell efficiency [1]. (b) However, in materials optimization, there are often only discrete combinations of properties that define real materials, resulting in a rough topology with extreme outliers. For example, Li_{2}NbF_{6} and Li_{2}ZrF_{6} lay close to each other in space because they have similar density, formation energy, and structure, however, they have vastly different target properties: Li_{2}NbF_{6} has a Poisson's ratio of −1.7 while Li_{2}ZrF_{6} has a Poisson's ratio of 0.3 [11]. Extreme outliers, such as Li_{2}NbF_{6}, consist of only a small fraction of the manifold hypervolume, resulting in a Needle-in-a-Haystack regime arising. This 3D projected manifold is obtained from the 6D Poisson's ratio optimization problem presented in this paper, where $X_{1}$ is density, $X_{2}$ is formation energy, and $f(X)$ is negative Poisson's ratio [12].</p>
<p>This Needle-in-a-Haystack (NiaH) problem arises when only few optimum conditions exist within the entire dataset, resulting in an extreme imbalance. Interpolating the parameter space of an imbalanced dataset with an estimation function, such as a GP, results in smoothing over the optimum or over-predicting the properties of the materials found near the optimum [13, 14, 15]. Examples of NiaH materials optimization problems include discovering auxetic materials (i.e., materials that have a highly negative Poisson's ratio, $\nu$) for energy absorptive medical devices or protective armor [16, 17, 18] and discovering materials that have a combination of high electrical conductivity and low thermal conductivity (i.e., a highly positive thermoelectric figure of merit, $ZT$) used for improving sensor technology to enable ubiquitous solid-state cooling [19, 20, 21]. Optimization of these rare material properties illustrates examples where an extreme data balance exists in the dataset because only a fraction of the total number of materials exhibit these rare properties [16, 12, 11, 22, 23]. This NiaH optimization challenge of extremely imbalanced datasets is largely applicable to many fields, not just materials science, including the fields of ecological resource management [24, 25], fraud detection [26, 27], and rare diseases [28, 27].</p>
<p>Several challenges exist for the current landscape of computational tools that inhibit effective optimization of these complex NiaH problems. Firstly, the "needle" makes up only a small percentage of the total manifold search space, resulting in a weak correlation between the measured input parameters and the target property of interest, inhibiting discovery of the region containing the needle [29, 30, 13]. This challenge requires the development of an algorithm that can more quickly determine the plausible region of the manifold where the needle exists. The second challenge for algorithms, such as BO, to optimize NiaH manifolds is in the nature of the acquisition function to pigeonhole sampling into local minima because of the narrowness of the needle's basin of attraction [31, 32]. Standard BO acquisition functions, including expected improvement (EI) [33] and lower confidence bound (LCB) [7, 14], are static sampling techniques that only adjust sampling based on the output of the surrogate model, which enacts smoothing of the needle $[13,5,6]$. To overcome this challenge, active learning-based tuning of the acquisition function hyperparameters can be implemented to improve the sampling quality and avoid pigeonholing. Lastly, there exists a computing challenge for NiaH problems where, typically, several thousands of samples must be observed to find an optimum when using an algorithm that is poorly suited to tackle NiaH manifolds [10]. The compute time of BO using a GP surrogate scales with the complexity $O\left(n^{3}\right)$, where $n$ is the number of experiments sampled, hence, the compute time of traditional BO blows up as more data is required to find the optimum [34, 35, 36, 5, 6, 37, 38]. To solve this computing challenge, an algorithm must be designed that both efficiently optimizes the space in as few experiments as possible and reduces the effect of compounding compute times over the length of the optimization procedure.
In recent literature, algorithms have been developed to address some of these challenges individually, but not all of them together. The first class of solutions bound the search space using a trust region approach to sample regions with higher probability of containing the optimum. Eriksson et al. develop TuRBO [39] that compiles a set of independent model runs, using separate GP surrogate models to compute a new, smaller search region, narrowed in on the target optimum. Regis develops TRIKE [40] that utilizes maximization of the EI acquisition function to bound a trust region containing the global optimum. Diouane et al. develop TREGO [41], which interleaves sampling between global and local search regions, where the local search regions are defined by the single best historical experiment sampled. Although these methods offer solutions to one of the three challenges presented, each method has its downfalls when optimizing NiaH problems. For example, TuRBO requires the computation of several GP model runs, which increases compute time and also does not guarantee that the needle will be resolved due to interpolation effects; TRIKE is inflexible to the use of other acquisition functions as it locks the user in to only using EI, which may pigeonhole into local minima; TREGO uses only the best sampled experiment to define its search regions, which will yield inconsistent or sub-optimal results when the needle consists of a fractional region of the manifold and single point is unlikely to land in its basin of attraction. The second class of solutions to the challenges presented in this paper are designed to decrease the computing time required to run an optimization procedure. A common method for reducing the compute time of BO with a GP surrogate is to introduce a sparse GP [5, 42, 37]. A sparse GP uses a small subset of pseudo data, often denoted as $m$, to reduce the GP time complexity from $O\left(n^{2}\right)$ to $O\left(m n^{2}\right)$ [43]. However, the process of selecting a useful subset requires minimizing the Kullback-Leibler divergence between the sparse GP and true posterior GP, which is often a computationally intensive procedure of using variational inference [44]. In addition to sparse GPs, new algorithms have been developed in literature to improve the compute time of optimization in various ways. Van Stein et al. develop MiP-EGO [45], which parallelizes the function evaluations of efficient global optimization (EGO) to discover optima faster and in fewer experiments using derivative-free computation [46]. Joy et al. [47] use directional derivatives to accelerate hyperparameter tuning by 100x and achieve higher accuracy than the FABOLAS baseline by Klein et al. [48]. Zhang et al. develop FLASH [49] to achieve optimization speed-ups of $50 \%$ by using a linear parametric model to guide algorithm search within high-dimensional spaces. Snoek et al. [15] design a neural network-based parametric model that reduces the overall time complexity of BO to $O(n)$ compared to the complexity of $O\left(n^{3}\right)$ of standard BO with a GP surrogate model. These existing methods from literature within the class of solutions for accelerating compute time are generally introducing external models necessary to perform optimization, such as neural networks, variational inference, or parametric models. While these external models do speed up compute time, they often lack the predictive capabilities to capture the weak correlation between measured input parameters and the target property of interest in NiaH problems. We illustrate this mechanism later in the paper when comparing the optimization results on two materials science NiaH problems of a fast algorithm MiP-EGO with that of TuRBO, an algorithm better suited for discovering optima within narrow basins of attraction.
Although these methods from existing literature address some of the challenges in optimizing NiaH problems, none of them have been designed specifically to quickly and efficiently discover a needle-like optimum within a haystack of suboptimal points, resulting in all of them falling short of a full solution. Therefore, in this paper, we design an algorithm that addresses all three of the challenges faced when optimizing NiaH problems by (1) zooming in the manifold search bounds iteratively and independently for each dimension based on $m$ number of best memory points to quickly converge to the plausible region containing the global optimum needle, (2) relieving compute utilization by pruning the low-performing and redundant memory points not being used to zoom in the search bounds, (3) anti-pigeonholing into local minima by using actively learned acquisition function hyperparameters to tune the exploitation-to-exploration</p>
<p><img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Figure 2: Accelerated Convergence to True Target using ZoMBI. Using a standard Bayesian optimization procedure, the discovery of a Needle-in-a-Haystack condition does not progress significantly after 10 additional experiments from the initial GP guess. However, using ZoMBI to zoom the bounds inward and prune redundant memory points, the needle-like optimum region is resolved to be accurately aligned with the true target. (a) The true target to optimize, which is a slice from the 6D Poisson's Ratio dataset, (b) The initial guess of the target function using a GP surrogate with 20 randomly sampled experiments, (c) (top) The estimated target resolved by standard BO after 10 additional experiments sampled using a greedy LCB acquisition function (β = 0.1); (bottom) the estimated target resolved by ZoMBI after 10 additional experiments sampled using the same greedy LCB acquisition function. The red memory points do not assist in resolving this target after zooming in the bounds, hence, they are pruned from memory by ZoMBI.</p>
<p>Ratio. The proposed algorithm, entitled [Zo]oming [M]emory-[B]ased [I]nitalization (ZoMBI), combines these three contributions into a method that efficiently optimizes NiaH problems quickly. Figure 2 demonstrates the accelerated convergence ability of the proposed (ZoMBI) algorithm compared to standard BO. In essence, this process of scanning broadly and then focusing in on points of interest based on memory was inspired by the way we humans solve similar problems, but stands in contrast to the way standard BO methods with static acquisition functions solve problems. We demonstrate the performance of this algorithm on three vastly different NiaH problems in materials science and ecological resource management: (1) discovery of materials with negative Poisson's ratio, (2) discovery of materials with both high electrical conductivity and low thermal conductivity, and (3) detection of environmental conditions conducive of sustaining wildfires. The performance of the proposed ZoMBI algorithm is compared against standard BO with static acquisition functions as well as against three more algorithms: (1) HEBO, the winning submission of the NeurIPS 2020 Black-Box optimization challenge [50] and one algorithm from each of the two classes of partial NiaH solutions (2) TuRBO (bounded search space) [39] and (3) MiP-EGO (faster compute) [45]. Finally, we stress-test the proposed ZoMBI algorithm across 174 additional datasets varying the optimum needle width, optimum distance to edges, dimensionality, and initialization conditions.</p>
<h2>2 Methodology</h2>
<p>In this paper, we develop two major contributions: (1) the ZoMBI algorithm and (2) adaptive learning acquisition functions. Through the combination of these two contributions, the optimum region of a NiaH manifold can be quickly discovered in fewer experiments without pigeonholing into local minima. Thus, the three challenges of optimizing NiaH problems are addressed: (1) the challenge of finding a hypervolume within the manifold that contains the needle-like optimum [29, 30, 13], (2) the challenge of the polynomially increasing compute times of BO using a GP surrogate [35, 36, 5, 6, 37, 38], (3) the challenge of avoiding pigeonholing into local minima [9, 1, 31, 32]. We demonstrate the implementation of ZoMBI on a 6D analytical Ackley function, a 6D dataset of materials with Poisson's ratios, a 6D dataset of thermoelectric materials, and an 11D dataset for wildfire detection, all of which exhibit an extreme data imbalance and a NiaH regime, and compare the performance to that of MiP-EGO [45], TuRBO [39], and HEBO [50]. For each of the three problems, the objective is to find the target value, y, with either the lowest or highest value depending on if the problem is minimization or maximization. This optimum y-value resembles a needle for each problem because</p>
<p>it is located within a narrow and steep basin of attraction. Precisely, the needle optimum for each problem has a value of $y=0$ for the Ackley function (minimization), $y=-1.7$ for Poisson's ratio dataset (minimization), $y=1.9$ for the thermoelectric merit dataset (maximization), and $y=-12$ for the wildfire detection dataset (minimization). To extend the applicability of ZoMBI optimization performance results to a wider array of applications, additional stress tests are conducted on 174 analytical datasets. First, a set of 144 analytical datasets are optimized to assess the failure and success conditions of ZoMBI on problems with extremely narrow optima and few initialization data points. Then, in the Supplemental Information, a set of 30 analytical datasets are optimized to assess the failure and success conditions of ZoMBI on problems with insufficient initialization data and cases where the global optimum is near the edge of the manifold.</p>
<h1>2.1 Zooming Memory-Based Initialization (ZoMBI) Algorithm</h1>
<p>The ZoMBI algorithm has two key features: (1) iterative inward bounding of proceeding search spaces using the $m$ number of best-performing memory points within the prior search space and (2) iterative pruning of low-performing historical search space memory. The newly computed search space bounds are unique for each dimension, such that the optimum basin of attraction of complex, non-convex NiaH manifolds can be discovered. This algorithm leverages these two key features to guide the acquisition of new data towards more optimal regions while only fitting the surrogate within the suggested optimum region to resolve more detail of the space of interest, as shown in Figure 3 and Figure 2. This process subsequently reduces the compute time significantly compared to the compute of a GP in a standard BO procedure, as shown in Figure 4.</p>
<div class="codehilite"><pre><span></span><code>Algorithm 1: Zooming Memory-Based Initialization (ZoMBI)
Input : \(\quad\) X: Set of data points \(\left\{X_{1}, X_{2}, \ldots, X_{n}\right\}\), where \(X_{j} \in \mathbb{R}^{d}\),
        y: Set of target values \(\left\{y_{1}, y_{2}, \ldots, y_{n}\right\}\) ， where \(y_{j} \in \mathbb{R}\) ，
        \(\alpha\) : Number of ZoMBI activations,
        \(\phi\) : Number of forward experiments per activation,
        \(\boldsymbol{\gamma}\) : Set of acquisition function hyperparameters \(\{\beta, \xi, \epsilon, \eta\}\) ，
        \(A F\) : An acquisition function selected by the user
</code></pre></div>

<p>Output : The next experimental condition $X_{n+1} \in \mathbb{R}^{d}$ and measured target value $y_{n+1} \in \mathbb{R}$
for $\alpha$ activations do
Compute bounds $\left{\mathcal{B}<em d="d">{d}^{l}, \mathcal{B}</em>\right} \leftarrow{\min , \max }}^{u<em d="d">{X \in \mathbf{X}^{(m)}}\left{X</em>\right}$
Initialize with $i$ LHS data points ${X}:=\left{X_{1}, X_{2}, \ldots, X_{i}\right}$, where $X_{j} \in \mathbb{R}^{d},\left[\mathcal{B}<em d="d">{d}^{l}, \mathcal{B}</em>$
Overwrite memory $\mathbf{X} \leftarrow{X}$ and $\mathbf{y} \leftarrow{y}$
for $f$ in range $(1, \phi)$ forward experiments do
Let $n=i+f$
Retrain surrogate model $\mathcal{G P}(\mathbf{X})$ using target values $\mathbf{y}$
Extract set of surrogate means $\boldsymbol{\mu}$ and variances $\boldsymbol{\sigma}$
Compute set of acquisition values $\boldsymbol{a} \leftarrow A F(\boldsymbol{\mu}, \boldsymbol{\sigma} ; \boldsymbol{\gamma})$
Find the best new experimental condition $X_{n+1} \leftarrow \arg \max (\boldsymbol{a})$
Measure target value of new experimental condition $y_{n+1}$
Append outputs to sets $\mathbf{X} . \operatorname{append}\left(X_{n+1}\right)$ and $\mathbf{y} . \operatorname{append}\left(y_{n+1}\right)$
end
end}^{u}\right]$ and target values ${y}:=\left{y_{1}, y_{2}, \ldots, y_{i}\right}$, where $y_{j} \in \mathbb{R</p>
<p>We define $m$ as the number of retained memory points during an activation of ZoMBI. The $m$ memory points are saved to memory while all other data are erased from memory. These are the historical data points that achieve the $m$ lowest (for minimization) target values, $y$, and they are used to zoom in the search bounds. Using these memory points, the multi-dimensional upper and lower bounds of the zoomed search space are computed for each dimension, $d$. Let $\mathbf{X}:=\left{X_{1}, X_{2}, \ldots, X_{n}\right}$ be a set of data points, where $X_{j} \in \mathbb{R}^{d}$. Let $f: \mathbb{R}^{d} \rightarrow \mathbb{R}$ be the objective function. We first assume that the points in $\mathbf{X}$ are in general position so that $f(\mathbf{X})$ contains unique elements. Then, for each $m \leq n$ define $\mathbf{X}^{(m)}=\left{X_{\pi(1)}, \ldots, X_{\pi(m)}\right}$ where $\pi$ is a permutation on ${1, \ldots, n}$ so that $\left{f\left(X_{\pi(j)}\right)\right}$ is in ascending order. If $f(\mathbf{X})$ contains repeated elements, we may first remove the points with repeated $f$ values and apply the definition</p>
<p>above. Then, for each $d$, the bounds are defined as:</p>
<p>$$
\begin{aligned}
\mathcal{B}<em X="X" _in="\in" _mathbf_X="\mathbf{X">{d}^{t} &amp; =\min </em>\right} \
\mathcal{B}}^{(m)}}\left{X_{d<em X="X" _in="\in" _mathbf_X="\mathbf{X">{d}^{u} &amp; =\max </em>\right}
\end{aligned}
$$}^{(m)}}\left{X_{d</p>
<p>where $\mathcal{B}<em d="d">{d}^{t}$ and $\mathcal{B}</em>}^{u}$ computed lower and lower bounds for each dimension, $d$, respectively. The bounds $\left[\mathcal{B<em d="d">{d}^{t}, \mathcal{B}</em>\right}$. These forward experiments are sampled by maximizing an acquisition value, $a \in[0,1]$, computed by a user-selected acquisition function from one of the four functions EI, EI Abrupt, LCB, and LCB Adaptive, introduced in Section 2.2. Once $i+\phi$ number of experiments are sampled, the bounds are re-constrained using the $m$ best performing experiments, $i$ new experiments are sampled from the zoomed-in space using LHS, and then the memory is pruned. The process of collecting $\phi$ forward experiments is repeated. A complete constraining-resetting iteration is denoted as an activation, $\alpha$. This iterative zooming and pruning process over several $\alpha$ significantly speeds up compute time, discussed further in Section 3.2. Implementation of ZoMBI is shown in Algorithm 1.}^{u}\right]$ constrain the proceeding acquisition of new data as well as the computation of a GP, such that sampling cannot occur outsides of the bounded region. This constraining process operates independently for each dimension, such that each dimension has a unique lower and upper bound. To initialize the algorithm with data from the constrained space, $i$ data points are sampled from the bounded region using Latin Hypercube Sampling (LHS). LHS splits a $d$-dimensional space into $i * d$ equally spaced strata, where $i$ is the number of points to sample uniformly over $d$ dimensions with low variability, unlike random sampling that has high sampling variability [51]. A GP surrogate model is retrained on these $i$ LHS points sampled from the constrained space and then for every proceeding experiment sampled from the space, denoted as a forward experiment, the surrogate model is retrained. Thus, the GP is only being trained on information within the constrained region and as the constrained region iteratively zooms inward and decreases in hypervolume, so does the region computed by the GP. This process allows for more information to be resolve within regions plausibly containing the global optimum basin of attraction. Up to $\phi$ forward experiments are sampled in serial, where $\left{X_{i}\right} \cup\left{X_{\phi}\right} \subseteq\left{X_{n</p>
<h1>2.2 Adapative Acquisition Functions</h1>
<p>Traditional BO acquisition functions, such as EI [52] and LCB [53], use the computed means and variances from a surrogate model to compute an acquisition value; maximizing this acquisition value guides sampling of the manifold [7, 33, 14]. However, these traditional acquisition functions are static, such that they do not actively use any information about the performance of previously sampled experiments to guide sampling. Hence, we implement an adaptive learning approach into the acquisition functions to develop two novel functions, EI Abrupt and LCB Adaptive, that dynamically adapt their sampling based on the quantity and quality of previously sampled experiments. In contrast to a static acquisition function, these adaptive acquisition functions are initialized with an initial set of hyperparameter values to guide their search but then tune these values as sampling progresses. The developed EI Abrupt and LCB Adaptive functions are used within the ZoMBI framework to further accelerate optimization and avoid pigeonholing, see line 9 of Algorithm 1.
LCB Adaptive builds off of previous work that also tune sampling based on the number of experiments collected, $n$ [54, 55, 56]. In this paper, we design LCB Adaptive to tune its hyperparameter to become less explorative as more samples are collected. For example, as the $n$ increases, LCB Adaptive decays its $\beta$ hyperparameter value to become less explorative and more exploitative. Specifically, this information feedback received by the function determines the contribution of both $\mu(X)$ and $\sigma(X)$ to the acquisition value, $a$. Similar to EI Abrupt, LCB Adaptive computes an acquisition value, $a \in[0,1]$, for a given $X$, wherein the $X$ with the highest $a$ is selected by the acquisition function as the next suggested experiment to measure. LCB Adaptive is implemented for a minimization problem as:</p>
<p>$$
a_{\text {LCB Adaptive }}(X, n ; \beta, \epsilon)=\mu(X)-\epsilon^{n} \beta \sigma(X)
$$</p>
<p>where $n$ is the number of experiments sampled, and $\beta=3$ and $\epsilon=0.9$ are hand-tuned initialization hyperparameters selected based on a priori domain knowledge of the function's performance on a variety of different problems. Having a large $\beta$ and an $\epsilon$ close to 1 supports a gradual decay from very explorative to very exploitative, rather than a rapid decay. In the following section (Section 3.3), the dynamic EI Abrupt and LCB Adaptive are shown to both discover optima faster and avoid pigeonholing into local minima better than their static counterparts by actively balancing the ratio of exploitation to exploration using learned information about the quality and quantity of previously sampled experiments.
EI Abrupt is a novel implementation that flips between the exploitative EI [52] and explorative LCB [53] acquisition functions based on the computed finite differences of recently evaluated experiments. For example, if the evaluated experiment $y$-values plateaus for three or more experiments in a row, EI Abrupt will abruptly switch from a greedy sampling policy to a more explorative sampling policy. Specifically, this information feedback received by the function determines if the current round of sampling should exploit the surrogate mean values, $\mu(X)$, or explore the surrogate</p>
<p>variances, $\sigma(X)$. EI Abrupt computes an acquisition value, $a \in[0,1]$, for a given $X$, wherein the $X$ with the highest $a$ is selected by the acquisition function as the next suggested experiment to measure. EI Abrupt is implemented for a minimization problems as:</p>
<p>$$
\begin{aligned}
a_{\text {EI Abrupt }}(X, y ; \beta, \xi, \eta) &amp; = \begin{cases}\left(\mu(X)-y^{<em>}-\xi\right) \Phi(Z)+\sigma(X) \psi(Z), &amp; \text { if }\left|\Delta\left{y_{n-3 \ldots n}\right}\right| \leq \eta \
\mu(X)-\beta \sigma(X), &amp; \text { otherwise }\end{cases} \
Z &amp; =\frac{\mu(X)-y^{</em>}-\xi}{\sigma(X)},
\end{aligned}
$$</p>
<p>where $y^{*}$ is the lowest measured target value thus far (i.e., the running minimum), $\Phi(\cdot)$ is the cumulative density function of the normal distribution, $\psi(\cdot)$ is the probability density function of the normal distribution, and $\left|\Delta\left{y_{n-3 \ldots n}\right}\right|$ is the absolute value of the finite differences of the set of target values of the last three sampled experiments. Moreover, $\beta=0.1, \xi=0.1$, and $\eta=0$ are hand-tuned initialization hyperparameters used for the rest of the paper for EI Abrupt. Moreover, for standard LCB and EI, $\beta=1$ and $\xi=0.1$ hyperparameters are used, respectively. These hyperparameters were selected based on a priori domain knowledge of EI Abrupt performance on a variety of different problems. The most important hyperparameter for efficient sampling is $\beta$, whose ideal value is non-obvious, but it is found that $\beta=0.1$ allows EI Abrupt to switch into an explorative sampling policy while still having a strong weight on the surrogate means, implying that exploration does not veer far.</p>
<h1>3 Demonstration of ZoMBI Mechanics</h1>
<h3>3.1 Zooming Bounds</h3>
<p><img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>Figure 3: Zooming Search Bounds. For every activation of ZoMBI, the search bounds are zoomed inward based on the prior best-performing memory points. A 4D Ackley function manifold is projected in 2D. The bounding regions of each 2D slice are illustrated by the red and orange boxes. The $\phi$ number forward experiments sampled for each activation, $\alpha$, are illustrated as black markers. The global optimum is indicated by the red region of the heatmap.</p>
<p>Zooming in the search bounds on the manifold addresses challenge number one of optimizing NiaH problems, which is the challenge of finding the general hypervolume region that contains the needle-like optimum. Figure 3 illustrates how the ZoMBI algorithm iteratively zooms in the search bounds based on the number of activations, $\alpha$. An Ackley function is used as a simulated example due to its non-convexity and needle-like global optimum [57, 58]. For each activation, $m$ prior points that achieved the lowest target values, $y$, are retained in memory and used to zoom the search bounds in. This zooming occurs independently across each dimension and is based on the minimum and maximum values of the $m$ memory points along each dimension, as shown in Equation 1. The red and orange rectangles illustrate the evolution</p>
<p>of the bounds over space and time. Initially, sampling occurs across the entire manifold for $\phi$ forward experiments per activation, shown by the black markers. However, by using the best-performing memory points to zoom in the search bounds, pigeonholing into local minima can also be avoided as the search bounds are pulled away from these trap minima and move closer towards the global minimum basin of attraction. The iterative zooming of ZoMBI does not guarantee convergence on the global optimum, but if a sufficient initialization set is obtained, convergence often gets close to the global optimum as shown across several examples in Figure 5 and Figures 8, 9, 10. Furthermore, we comprehensively demonstrate the performance limitations of ZoMBI where initializations miss extreme needle-like optima in Figure 6 and where optima are near the edges of a manifold in Figure S-4.</p>
<h1>3.2 Memory Pruning</h1>
<p><img alt="img-3.jpeg" src="img-3.jpeg" /></p>
<p>Figure 4: Wall-clock Compute Time. The compute time per experiment is illustrated for traditional BO with a GP surrogate (orange) and for ZoMBI with a GP surrogate (blue) with the $y$-axis in log-scale. Four independent trials of each method were run to optimize a 6D Ackley function with a narrow basin of attraction using an NVIDIA Tesla Volta V100 GPU [59]. Each trial of standard BO and ZoMBI is run using one of the four acquisition functions: LCB, LCB Adaptive, EI, and EI Abrupt. The averages of the trials are shown as solid orange and blue lines while the shaded regions indicate the maximum and minimum compute times bounds. The red dashed line indicates the trend of the ZoMBI compute times. The measured compute time includes the time to compute the GP surrogate model and the time to acquire an experiment from the surrogate.</p>
<p>As more experiments are amassed and committed to memory to run traditional BO by computing the GP surrogate, the compute time increases polynomially, following the $O\left(n^{3}\right)$ time complexity of GP matrix inversion [34, 5, 6, 60, 37, 38]. This complexity is unfavorable as it leads to compounding compute times as more experiments are run. Therefore, we implement a memory pruning feature into the ZoMBI algorithm that iteratively selects which prior data points to keep and which to prune from the memory during each activation, $\alpha$. Memory pruning is demonstrated to remove redundant features during the optimization procedure. Figure 2 illustrates how ZoMBI accelerates the convergence of a GP prediction to the precise location of the true. However, only data within the newly computed bounds of ZoMBI are used prediction of the true target, hence, all data outside this boundary becomes redundant and is pruned to decrease compute time.
Through memory pruning, the number of experiments used to train the GP surrogate varies between $[i, i+\phi]$ for every $\alpha$, rather than being proportional to $n$, where the number of initialization samples is fixed at $i=5$. In this paper, we use $\phi \in[0,10]$, i.e., once $\phi=10$, the activation is complete and resets to $\phi=0$. This is computationally favorable because $\left{X_{i}\right} \cup\left{X_{\phi}\right} \subseteq\left{X_{n}\right}$. Thus, for a single $\alpha$, the time complexity is $O\left((i+\phi)^{3}\right) \approx O\left(\phi^{3}\right)$, since $i$ is fixed. Furthermore, since the range of $\phi$ is capped, a non-increasing sawtooth pattern in compute time is exhibited, illustrated in Figure 4. Therefore, the compute complexity of ZoMBI trends towards $O(1)$ for $\alpha&gt;1$ as a result of the efficient memory pruning process. After collecting 1000 experiments, the compute time of traditional BO trends towards $&gt;400$ seconds per experiment, whereas for ZoMBI the compute time maintains a constant trend of approximately 1 second per experiment. Therefore, the memory pruning feature of ZoMBI accelerates the optimization compute time by over 400x at $n=1000$ and achieves further relative acceleration as $n$ increases.</p>
<h1>3.3 Anti-pigeonholing</h1>
<p>Pigeonholing into the local minima of a function occurs when an optimization algorithm has insufficient learned knowledge of the manifold topology to continue exploring potentially profitable regions or when the algorithm's hyperparameters are improperly tuned, leading to overly exploitative tendencies [1, 9]. The ZoMBI algorithm's antipigeonholing capabilities are two-fold: (1) the zooming search bounds help the acquisition function to quickly stop sampling local minima once a better performing data point is found and (2) actively learned acquisition function hyperparameters use knowledge about the domain to help exit a local minimum. Figure 5 demonstrates the antipigeonholing capabilities of ZoMBI on optimizing a 6D Ackley function with both static and dynamic acquisition functions, compared to that of traditional BO.
<img alt="img-4.jpeg" src="img-4.jpeg" /></p>
<p>Figure 5: Acquisition Function Sampling Density. The colored heatmaps indicate the regions of a 2D slice from a 6D Ackley function where sampling density is high for each respective acquisition function: (a) LCB, (b) LCB Adaptive, (c) EI, and (d) EI Abrupt. The contour lines indicate the manifold topology with local minima as the circular and pointed regions of the contours. The red "x" indicates the global minimum. For each acquisition function, the left panel shows the sampling density after $n={20,40,80}$ evaluated experiments without the use of ZoMBI while the right panel shows the sampling density after $n={20,40,80}$ evaluated experiments with the use of ZoMBI.</p>
<p>The needle-like global minimum is indicated by the red "x" and the local minima are indicated by the circular and pointed regions of the contour lines. The sampling density of each acquisition function is illustrated by the heatmap, where the darker colors indicate higher sampling density regions. The goal is to get high sampling density near the red "x". It is shown that without ZoMBI being activated, the LCB, LCB Adaptive, and EI acquisition functions all end up pigeonholing into local minima. However, EI Abrupt initially pigeonholes into a local minima but then switches from an exploitative to an explorative mode to jump out of the local minimum and converge closer to the global. Conversely, when running the optimization procedure with ZoMBI active, all of the acquisition functions except the most exploitative, EI, converge onto the global minimum fast. LCB Adaptive and EI are shown to initially start sampling towards a local minima, but as ZoMBI is iteratively activated, the search bounds zoom in closer to the global minimum. Thus, with the combination of dynamic acquisition functions and zooming search bounds, pigeonholing into sub-optimal local minima can be more readily avoided while optimizing NiaH problems, although avoidance is not guaranteed, as shown by the sampling density of EI. The combination of the three foundational features of ZoMBI, (1) zooming bounds, (2) memory pruning, and (3) anti-pigeonholing drives fast optimization of NiaH problems and in most cases, does not sacrifice the ability to converge on the global optimum.</p>
<h2>4 Experiments</h2>
<h3>4.1 Large-scale Optimum Hypervolume Analysis via Ackley Permutations</h3>
<p>Before assessing the performance of ZoMBI on the three real-world datasets, we use 144 permutations of the Ackley function to stress-test the capability of ZoMBI to discover the global optimum basin of attraction, given two varying dataset hyperparameters: (1) basin of attraction width and (2) dimensionality. The basin of attraction hypervolume is determined by both the width of the basin and the dimensionality of the manifold, hence, as the basin becomes narrower in width and as the dimensionality increases, the percentage of hypervolume space taken up by the basin decreases,</p>
<p>i.e. the optimum becomes more needle-like. The Ackley permutations have varying basin hypervolumes from 0.001% to 100% and varying manifold dimensionalities from 2D to 10D. For this experiment, we aim to determine types of manifold topologies that ZoMBI best optimizes while quantifying those limits with the Pareto front.
<img alt="img-5.jpeg" src="img-5.jpeg" /></p>
<p>Figure 6: Varying Optimum Hypervolume. (left) Depiction of decreasing optimum basin of attraction hypervolume in 1D. (right) The Pareto-optimal dataset hyperparameters for usage with the ZoMBI algorithm over 144 analytical datasets with 48 independent trials each: 12 trials for each of the four acquisition functions, LCB, LCB Adaptive, EI, and EI Abrupt, for a total of 6912 independent trials. Each analytical dataset is a permutation of the Ackley function with a different optimum basin of attraction width and manifold dimensionality. Hypervolume percent makeup is synthetically decreased both by decreasing the basin of attraction width and by increasing the manifold dimensionality. Each scatter point represents the median final minimum function evaluation after 1000 experiments across the 48 independent trials initialized with a fixed set of $i=5$ samples. The colorbar of the scatter point represents the dimensionality of the manifold tested and the error bars represent the variance across the 48 trials. The possible function values for every dataset vary between $[0,25]$, hence, for the Ackley function as further described in the supplemental Section S-1, trials achieving minimum function values $&lt;10$ are considered to have found the optimum basin of attraction while trials with function values $\geq 10$ after 1000 experiments are considered to be trapped in local minima. Both the $x$ - and $y$-axes are in log-scale.</p>
<p>Figure 6 shows the results of this large-scale optimization experiment of 48 independent trials of ZoMBI across each of the 144 unique permutations of the Ackley function dataset with varying optimum hypervolumes and dimensionality. All points below the grey-shaded region fall within the optimum basin of attraction. The red trace of the Pareto front indicates the narrowest optimum hypervolume and dimensionality conditions of a dataset that result in the best minimum function value being discovered. We show that with an initialization set of $i=5$, ZoMBI can reliably discover the global minimum region for needles as narrow as $0.05 \%$ of total hypervolume space. Moreover, as the optimum becomes narrower than $0.05 \%$ of the total hypervolume, the initialization set is no longer sufficient and ZoMBI gets trapped in local minima, as indicated by the greyed-out region. Conversely, as the optimum becomes wider than $5 \%$ of the total hypervolume, the manifold becomes flatter, expressing the greedy nature of ZoMBI to falsely zoom inward to less ideal function values than it would for narrower optimum conditions. This experiment quantifies the range of ZoMBI's Goldilocks zone to be between $0.05 \%$ and $5 \%$ optimum hypervolume. Therefore, for ideal performance, ZoMBI is best used on datasets with optimum conditions consisting of between $0.05 \%$ and $5 \%$ of the total number of conditions. This optimum hypervolume trade-off of ZoMBI is further assessed relative to other optimization methods in Figure S-3.
In the next section, three real-world datasets are optimized using ZoMBI - each of these datasets have extreme data imbalances, illustrated in 7 within the specified ideal ranges of ZoMBI performance. The 6D Poisson's Ratio dataset has an imbalance of $0.82 \%$ optimum conditions, the 6D Thermoelectric Figure of Merit dataset has an imbalance of roughly $1.32 \%$ optimum conditions, and the 11D wildfire detection dataset has an imbalance of $4.16 \%$ optimum conditions. This range of ideal performance of ZoMBI between $0.05 \%$ and $5 \%$ optimum hypervolume is facilitated by the initialization set. Hence, to improve performance for narrower optima, either the number of initialization samples must be increased, or initialization conditions should be adjusted. Additional initialization conditions experiments of ZoMBI are shown in supplemental Section S-5.</p>
<h1>4.2 6D Poisson's Ratio</h1>
<p>The first experimental dataset is 6-dimensional and consists of 146k materials from the publicly available Materials Project database with different mechanical properties, described by Poisson's Ratio, $\nu$ [12]. Only $0.82 \%$ of the total 146k materials have a negative Poisson's Ratio, $\nu&lt;0[16,12,11,17]$. Hence, for this experiment, we aim to minimize</p>
<p><img alt="img-6.jpeg" src="img-6.jpeg" /></p>
<p>Figure 7: Data Distributions of Real-world Needle-in-a-Haystack Datasets (top) The histogram distributions of the full real-world datasets with callouts for optimum conditions: (a) Poisson's Ratio with 146k materials in the dataset and $\nu_{\min }={-1.7,-1.2}$, (b) Thermoelectric Figure of Merit with 1k materials in the dataset computed by BoltzTraP [61] and $Z T_{\max }={1.4,1.9}$, (c) Wildfire Detection with 128k meteorological conditions collected over 33 months from January 2018 to September 2020 from CIMIS [62] and $\psi&lt;0$ conditions indicating those with a high likelihood of wildfire outbreaks. (bottom) The noisy, non-convex manifold topologies of each dataset generated by a random forest regression with 500 trees. Each manifold is a projected 3D slice of higher dimensional space with the $z$-axis and colorbar indicating the target property, where (a) $X_{1}$ is density and $X_{2}$ is formation energy, (b) $X_{1}$ is formation energy and $X_{2}$ is band gap, (c) $X_{1}$ is evapotranspiration and $X_{2}$ is precipitation.
$\nu$. A positive $\nu&gt;0$, describes a material that expands when a compressive load is applied to the orthogonal direction $[63,64]$. Conversely, a negative $\nu&lt;0$ describes a material that contracts rather than expands when compressed in the orthogonal direction, denoted as an auxetic material - a rare phenomenon [16, 23]. Auxetic materials with highly negative Poisson's ratios have energy absorptive properties that are ideal materials for wearable medical devices and protective armor that must absorb the energy of large impacts to keep bones from shifting or to inhibit the penetration of the protective layer $[17,18]$.</p>
<p>Figure 8 demonstrates the optimization performance of ZoMBI on the Poisson's Ratio dataset compared to MiP-EGO, TuRBO, and HEBO. The ZoMBI algorithm is run with each of the four acquisition functions: LCB, LCB Adaptive, EI, and EI Abrupt. In under 100 evaluated experiments, LCB and LCB Adaptive discover the global minimum NiaH material, $\mathrm{Li}<em 6="6">{2} \mathrm{NbF}</em>(\nu \approx-1.7)$. The variance of $\nu$ values for the final experiment across all ensemble runs is illustrated as a KDE plot for each method to highlight the sampling density and general rate of success. HEBO discovers the global minimum after ZoMBI with LCB and LCB Adaptive, however, the spread of runs for ZoMBI is narrower than that of HEBO, which indicates that for this problem, ZoMBI can more consistently discover the minimum, that is 3x lower than those discovered by MiP-EGO and TuRBO. Furthermore, the rate of convergence on Needle 1 is faster for ZoMBI than HEBO.</p>
<p>Figure 7(a) illustrates the distribution of $\nu$ values within the full dataset. The ground truth "needle" materials with the lowest $\nu$ values are $\mathrm{Li}<em 6="6">{2} \mathrm{NbF}</em>}$ with $\nu \approx-1.7$ and $\mathrm{Na<em 3="3">{2} \mathrm{CO}</em>}$ with $\nu \approx-1.2$. ZoMBI with the LCB and LCB Adaptive acquisition functions and HEBO discover $\mathrm{Li<em 6="6">{2} \mathrm{NbF}</em>}$, while ZoMBI with the EI Abrupt acquisition function discovers $\mathrm{Na<em 3="3">{2} \mathrm{CO}</em>$.</p>
<p><img alt="img-7.jpeg" src="img-7.jpeg" /></p>
<p>Figure 8: Discovery of Rare Negative Poisson's Ratio Materials. The optimization objective is to find the material with the minimum Poisson's ratio in 100 experiments from the dataset presented in Figure 7(a). The green, blue, red, and orange lines indicate the median best running evaluated sample of ZoMBI using the LCB, LCB Adaptive, EI, and EI Abrupt acquisition functions, respectively. The pink, black, and teal lines indicate the median best running evaluated sample of the methods MiP-EGO, TuRBO, and HEBO respectively. Random sampling is illustrated as a dashed grey line for benchmarking. The median for each method is taken over the best 12 independent model runs. The shaded regions indicate the variance between model runs. The cross-hatched region indicates the space discovered by standard BO methods, without the use of ZoMBI, which use the same hyperparameters as described in Section 2.2. The distribution across all 12 model runs of the final sampled experiment for each method is shown as a kernel density estimation (KDE) along the $y$-axis. The $y$-values for the needle-like optima are indicated by dashed black lines.</p>
<h1>4.3 6D Thermoelectric Figure of Merit</h1>
<p>The second experimental dataset is 6-dimensional and consists of 1 k materials with different thermal and electrical properties, described by the Thermoelectric Figure of Merit, $Z T$. Since $Z T$ values are always positive, there is no clear cutoff for what "optimum" conditions are, but with a threshold of $Z T&gt;0.8,1.32 \%$ of the total 1 k materials are considered optimum. A higher $Z T$ indicates that the material is better able to convert a thermal gradient into an electrical current [65]. Hence for this experiment, we aim to maximize ZT. Unlike Poisson's Ratio, Thermoelectric Merit is determined by a combination of several variables, rather than a single variable [65]:</p>
<p>$$
Z T=\frac{S^{2} \sigma}{\kappa} T
$$</p>
<p>where $S$ is the Seebeck coefficient, $\sigma$ is electrical conductivity, $T$ is the average temperature, and $\kappa$ is thermal conductivity. The $Z T$ is computed for each material with valid thermal and electrical properties in the Materials Project database using BoltzTraP [61]. $Z T$ is a common figure of merit used to describe the thermal-to-electrical or electrical-to-thermal conversion efficiency of thermoelectric materials [66, 67, 68, 69]. Materials with high $Z T$ values have a range of applications from usage as solid-state cooling devices to being used as sensors that when heated up, will produce an electrical signal $[19,20,21]$.</p>
<p><img alt="img-8.jpeg" src="img-8.jpeg" /></p>
<p>Figure 9: Discovery of Rare Positive Thermoelectric Figure of Merit Materials. The optimization objective is to find the material with the maximum Thermoelectric Figure of Merit in 100 experiments from the dataset presented in Figure 7(b). The green, blue, red, and orange lines indicate the median best running evaluated sample of ZoMBI using the LCB, LCB Adaptive, EI, and EI Abrupt acquisition functions, respectively. The pink, black, and teal lines indicate the median best running evaluated sample of the methods MiP-EGO, TuRBO, and HEBO respectively. Random sampling is illustrated as a dashed grey line for benchmarking. The median for each method is taken over the best 12 independent model runs. The shaded regions indicate the variance between model runs. The cross-hatched region indicates the space discovered by standard BO methods, without the use of ZoMBI, which use the same hyperparameters as described in Section 2.2. The distribution across all 12 model runs of the final sampled experiment for each method is shown as a kernel density estimation (KDE) along the $y$-axis. The $y$-values for the needle-like optima are indicated by dashed black lines.</p>
<p>Figure 9 demonstrates the optimization performance of ZoMBI on the Thermoelectric Figure of Merit dataset compared to MiP-EGO, TuRBO, and HEBO. In this experiment, although none of the tested methods are able to discover the maximum needle, LCB Adaptive discovers the second highest needle-in-a-haystack material, $\mathrm{Na}<em 3="3">{4} \mathrm{Al}</em>} \mathrm{Ge<em 12="12">{3} \mathrm{IO}</em>(Z T \approx 1.4)$ in under 100 experiments. Neither HEBO, TuRBO, nor MiP-EGO are capable of discovering any needle-like $Z T$ optima and MiP-EGO performs worse than random sampling in this experiment. The wide variance across runs for ZoMBI and HEBO, shown in the KDE plots, indicate that both methods operate relatively explorative to discover maxima in this topology. Ultimately, this experiment demonstrates that ZoMBI can optimize material objective functions that have a complex combination of variables (Equation 4) with roughly 2 x better performance than HEBO.
Figure 7(b) illustrates the distribution of $Z T$ values within the full dataset. The ground truth "needle" materials with the highest $Z T$ values are $\mathrm{Sr}<em 6="6">{4} \mathrm{Al}</em>} \mathrm{SO<em 4="4">{12}$ with $Z T \approx 1.9$ and $\mathrm{Na}</em>} \mathrm{Al<em 3="3">{3} \mathrm{Ge}</em>} \mathrm{IO<em 4="4">{12}$ with $Z T \approx 1.4$. ZoMBI with the LCB Adaptive acquisition function is the only method that discovers one of these needles, $\mathrm{Na}</em>} \mathrm{Al<em 3="3">{3} \mathrm{Ge}</em>$.} \mathrm{IO}_{12</p>
<h1>4.4 11D Wildfire Detection</h1>
<p>The third experimental dataset is 11-dimensional and consists of 128 k meteorological conditions and an index, $\psi$, that determines whether the set of conditions has a high likelihood of generating or sustaining a wildfire in the state of California - publicly available from the California Irrigation Management Information System (CIMIS) weather stations [62]. Only $4.16 \%$ of the total 128 k meteorological conditions have a negative wildfire detection index, $\psi&lt;0$. A highly negative $\psi$ indicates a high risk of wildfires. Hence, for this experiment, we aim to minimize $\psi$, to best detect</p>
<p><img alt="img-9.jpeg" src="img-9.jpeg" /></p>
<p>Figure 10: Detection of Environmental Conditions with Wildfire Risk. The optimization objective is to find the meteorological conditions with the minimum wildfire detection index, $\psi$, in 100 experiments from the dataset presented in Figure 7(c). Conditions with $\psi&lt;0$ have the highest risk of sustaining wildfire. The green, blue, red, and orange lines indicate the median best running evaluated sample of ZoMBI using the LCB, LCB Adaptive, EI, and EI Abrupt acquisition functions, respectively. The pink, black, and teal lines indicate the median best running evaluated sample of the methods MiP-EGO, TuRBO, and HEBO respectively. Random sampling is illustrated as a dashed grey line for benchmarking. The median for each method is taken over the best 12 independent model runs. The shaded regions indicate the variance between model runs. The cross-hatched region indicates the space discovered by standard BO methods, without the use of ZoMBI, which use the same hyperparameters as described in Section 2.2. The distribution across all 12 model runs of the final sampled experiment for each method is shown as a kernel density estimation (KDE) along the $y$-axis. The $y$-values for the needle-like optima are indicated by dashed black lines.
meteorological conditions at high risk of wildfires. The dataset spans over two years of data collected from 2018 to 2020, during which over 2500 wildfires have occurred, burning over 24 million acres of land [70]. In California, temperature and precipitation alone are poor indicators for wildfire outbreaks (see Figure S-1(c)), resulting in researchers using computer-vision methods or convolutions of many meteorological variables to reliably detect wildfire conditions instead $[25,70]$. Thus, there is a high need for algorithmic support to aid humans in early wildfire detection.
Figure 10 demonstrates the optimization performance of ZoMBI on the Wildfire Detection dataset compared to MiP-EGO, TuRBO, and HEBO. In this experiment, LCB Adaptive, EI, and HEBO discover the lowest index value, $\psi \approx-3.5$, for detecting wildfires based on a high-dimensional convolution of ten meteorological variables. TuRBO and MiP-EGO also discover a low index value, $\psi \approx-2.5$, however, these methods have widely distributed variances, as shown by the KDE plots, indicating inconsistent optimization results given only 100 sampled experiments. Similarly, HEBO has high variance across model runs while the LCB Adaptive and EI ZoMBI methods have a tight distribution, indicating more reliable optimization results with a higher rate of success. Furthermore, ZoMBI methods achieve a faster rate of convergence than HEBO onto the Needle 1 optimum, similar to the optimization results on the Poisson's Ratio dataset in Section 4.2.
Figure 7(c) illustrates the distribution of $\psi$ values within the full dataset. The ground truth "needle" conditions for detecting wildfires are those with the most negative detection index values, $\psi$. Although ZoMBI with the LCB Adaptive and EI acquisition functions as well as HEBO discover the lowest needle-like $\psi$ conditions after 100 sampled experiments, none of the tested methods are able to find the global $\psi_{\min } \approx-12$. These results imply that, even for ZoMBI, with a narrow enough needle-like optimum, the LHS initialization of $i=5$ experiments, may not be sufficient. In the next section, we stress-test this hypothesis on ZoMBI.</p>
<p>Fast Bayesian Optimization of Needle-in-a-Haystack Problems using Zooming Memory-Based Initialization</p>
<h1>5 Summary \&amp; Conclusions</h1>
<p>In this paper, we proposed the [Zo]oming [M]emory-[B]ased [I]nitalization (ZoMBI) algorithm that builds on the principles of Bayesian optimization to accelerate the optimization of Needle-in-a-Haystack problems by two-fold, firstly by requiring fewer experiments to achieve better optimum faster than existing MiP-EGO [45], TuRBO [39], and HEBO [50] on a variety of real-world applications, and secondly by pruning the memory of low-performing historical experiments to speed-up compute time. The ZoMBI algorithm convergences onto narrow and sharp optima quickly in Needle-in-a-Haystack datasets by (1) using the values of the $m$ best performing previously sampled memory points to iteratively zoom in the search bounds of the manifold uniquely on each dimension and (2) implementing two custom acquisition functions, LCB Adaptive and EI Abrupt, that adapt their hyperparameters to tune sampling of new experimental conditions based on learned information from the surrogate model. The main contributions of this algorithm solve three fundamental challenges of optimizing non-convex Needle-in-a-Haystack problems: (1) the challenge of locating the hypervolume region of the manifold containing the narrow global optimum basin of attraction $[29,30,13]$ is alleviated by introducing iterative search bounds based on learned knowledge of the manifold; (2) the challenge of polynomially increasing compute times of BO using a GP surrogate $[34,35,36,5,6,37,38]$ is addressed by actively pruning the retained memory of the algorithm after each activation, $\alpha$, in turn, reducing the time complexity from $O\left(n^{2}\right)$ to $O\left(\phi^{3}\right)$ for $\phi$ forward experiments per activation, $\alpha$, which trends to a constant $O(1)$ when $\alpha&gt;1$; (3) unwanted pigeonholing into local minima $[31,32,5,6]$ is avoided by both the zooming mechanics of ZoMBI as well as using the two acquisition functions developed in this paper, LCB Adaptive and EI Abrupt, that tune their hyperparameters through adaptive learning. By developing the ZoMBI algorithm to solve these challenges, it becomes possible to quickly and efficiently find optimal solutions to complex Needle-in-a-Haystack problems in fewer experiments.</p>
<p>Solving a Needle-in-a-Haystack problem that arises from extremely imbalanced data is a significant challenge that has important implications in science and engineering, especially within the field of materials science [10, 29]. In this paper, we use ZoMBI to discover the optimum materials in two real-world materials science Needle-in-a-Haystack datasets where only a small fraction of the entire search space consists of the target optimum conditions. For breadth, we also extend our analysis to a third real-world dataset but for ecological resource management with the objective of discovering the environmental conditions that have a high likelihood of sustaining wildfires for early detection of wildfires. In the first materials dataset, we discover a material with a highly negative Poisson's ratio, $\nu,[12,11]$; in the second materials dataset, we discover a material with a highly positive thermoelectric figure of merit, $Z T$ [61, 12], both rare material properties; and in the third dataset for ecological resource management, we discover a set of environmental conditions with a highly negative wildfire detection index, $\psi[62,25,70]$. For the first dataset, both the ZoMBI algorithm with the LCB and LCB Adaptive custom acquisition functions and HEBO [50] discover the material with the minimum $\nu \approx-1.7$, however, the ZoMBI methods converge on this minimum in only 70 experiments while HEBO takes 90 experiments. TuRBO [39] and MiP-EGO [45] only discover materials with $\nu \approx-0.55$ and $\nu \approx-0.20$, respectively. For the second dataset, the ZoMBI algorithm with the LCB Adaptive custom acquisition function discovers the material with the maximum $Z T \approx 1.4$, while HEBO [50], TuRBO [39], and MiP-EGO [45] only discover $Z T \approx 0.78$, $Z T \approx 0.65$, and $Z T \approx 0.45$, respectively. For the third dataset the ZoMBI algorithm with all acquisition functions and HEBO [50] discover a minimum $\psi \approx-3$, while TuRBO [39] and MiP-EGO [45] both only discover $\psi \approx-2$. However, the ZoMBI methods converge on the minimum faster and with less variance. In general, we note HEBO [50] outperforms the other benchmark methods, TuRBO [39] and MiP-EGO [45]. Thus, for future investigation, we believe the performance of ZoMBI may be further improved by running optimization within the latent space of a variational autoencoder, similar to HEBO [71, 72]. Overall, these results demonstrate that the ZoMBI algorithm is more well-suited to tackle various real-world Needle-in-a-Haystack optimization problems than current methods, however, ZoMBI has performance limitations for extremely narrow optima when instantiated with an insufficient initialization set. Therefore to assess these limitations, we stress tested ZoMBI on an additional 174 analytical datasets with varying optimum needle widths, optimum distance to edges, dimensionality, and initialization conditions. These results concluded that with a fixed initialization set of 5 samples, ZoMBI has ideal performance on datasets with needle-like optima consisting of between $0.05 \%-5 \%$ of total hypervolume space. Furthermore, by extending the range of the initialization set, ZoMBI is capable of discovering global minima that lay on the absolute edge of a manifold's limits. Thus, in these certain cases, convergence to a global optimum using ZoMBI is not guaranteed, but with slight modifications based on some a priori domain knowledge of the optimization landscape, ZoMBI produces high-performance and low-variance results.
Ultimately, the significance of developing the ZoMBI algorithm is to quickly and efficiently tackle difficult Needle-in-a-Haystack optimization problems in extremely imbalanced datasets. In this paper, we showcased the ability of the developed algorithm to discover rare materials and conditions with highly-optimized properties in a short period of time using few experiments. Discovering rare materials quickly and efficiently enables widespread access to a new range of materials applications from engineering high-performance medical devices to ubiquitous solid-state cooling systems $[17,18,19,20,10,21]$. However, the application space for ZoMBI to accelerate the efficient discovery of</p>
<p>highly-optimized solutions extends past materials science and is generally applicable for many Needle-in-a-Haystack problems, including those found in ecological resource management [24, 25], fraud detection [26, 27], and rare disease prediction [28, 27]. We aim for this contribution to support the elimination of the time and resource barriers previously inhibiting the throughput of optimizing complex and challenging Needle-in-a-Haystack problems across a broad range of application spaces.</p>
<h1>Acknowledgements</h1>
<p>Basita Das is thanked for help in naming the algorithm. Xiaonan Wang is thanked for initial discussions for this study. John Dagdelen, Hongbin Zhang, and Shyam Dwaraknath are thanked for discussion of and reference to different Needle-in-a-Haystack problems within materials science. The authors acknowledge the MIT SuperCloud and Lincoln Laboratory Supercomputing Center for providing HPC resources that have contributed to the research results reported within this paper. This material is based upon the work supported by the U.S. Department of Energy's Office of Energy Efficiency and Renewable Energy (EERE) under the Solar Energy Technology Office (SETO) award number DE-EE0009366.</p>
<h2>Data Availability</h2>
<p>Implementation of the ZoMBI algorithm, the experimental dataset analyzed during the current study, the simulated data and labeled data supporting the findings of this study, and the data comprising the figures in this paper are all available in the following GitHub repository: https://github.com/PV-Lab/ZoMBI.</p>
<h2>Author Contributions</h2>
<p>A.E.S., Z.R., and T.B. conceived of and designed the study. Q.L. and T.B. provided guidance on machine learning methods, benchmark functions, and datasets. A.E.S. and Z.R. wrote the code. A.E.S. performed the machine learning modeling and analysis. A.E.S. wrote the paper, while all co-authors reviewed the manuscript.</p>
<h2>Conflicts of Interest</h2>
<p>Although our laboratory has IP filed covering photovoltaic technologies and materials informatics broadly, we do not envision a direct COI with this study, the content of which is open sourced. Two of the authors (Z.R. and T.B.) own equity in Xinterra Pte Ltd, which applies machine learning to accelerate novel materials development.</p>
<h2>References</h2>
<p>[1] Zhe Liu, Nicholas Rolston, Austin C. Flick, Thomas W. Colburn, Zekun Ren, Reinhold H. Dauskardt, and Tonio Buonassisi. Machine learning with knowledge constraints for process optimization of open-air perovskite solar cell manufacturing. Joule, 6(4):834-849, 2022.
[2] Alexander E. Siemenn, Evyatar Shaulsky, Matthew Beveridge, Tonio Buonassisi, Sara M. Hashmi, and Iddo Drori. A Machine Learning and Computer Vision Approach to Rapidly Optimize Multiscale Droplet Generation. ACS Applied Materials \&amp; Interfaces, 14(3):4668-4679, 2022.
[3] Flore Mekki-Berrada, Zekun Ren, Tan Huang, Wai Kuan Wong, Fang Zheng, Jiaxun Xie, Isaac Parker Siyu Tian, Senthilnath Jayavelu, Zackaria Mahfoud, Daniil Bash, Kedar Hippalgaonkar, Saif Khan, Tonio Buonassisi, Qianxiao Li, and Xiaonan Wang. Two-step machine learning enables optimized nanoparticle synthesis. npj Computational Materials 2021 7:1, 7(1):1-10, 2021.
[4] Shijing Sun, Armi Tiihonen, Felipe Oviedo, Zhe Liu, Janak Thapa, Yicheng Zhao, Noor Titan P. Hartono, Anuj Goyal, Thomas Heumueller, Clio Batali, Alex Encinas, Jason J. Yoo, Ruipeng Li, Zekun Ren, I. Marius Peters, Christoph J. Brabec, Moungi G. Bawendi, Vladan Stevanovic, John Fisher, and Tonio Buonassisi. A data fusion approach to optimize compositional stability of halide perovskites. Matter, 4(4):1305-1322, 2021.
[5] Edward Snelson and Zoubin Ghahramani. Sparse Gaussian Processes using Pseudo-inputs. In Y Weiss, B Schölkopf, and J Platt, editors, Advances in Neural Information Processing Systems, volume 18. MIT Press, 2005.</p>
<p>[6] Carl Edward Rasmussen and Christopher K. I. Williams. Gaussian Processes for Machine Learning. The MIT Press, 2005.
[7] Eric Brochu, Vlad M. Cora, and Nando de Freitas. A Tutorial on Bayesian Optimization of Expensive Cost Functions, with Application to Active User Modeling and Hierarchical Reinforcement Learning. 2010.
[8] Jasper Snoek, Hugo Larochelle, and Ryan P Adams. Practical Bayesian Optimization Of Machine Learning Algorithms. pages 1-12, 2001.
[9] Qiaohao Liang, Aldair E. Gongora, Zekun Ren, Armi Tiihonen, Zhe Liu, Shijing Sun, James R. Deneault, Daniil Bash, Flore Mekki-Berrada, Saif A. Khan, Kedar Hippalgaonkar, Benji Maruyama, Keith A. Brown, John Fisher, and Tonio Buonassisi. Benchmarking the performance of Bayesian optimization across multiple experimental materials science domains. npj Computational Materials 2021 7:1, 7(1):1-10, 2021.
[10] Yoolhee Kim, Edward Kim, Erin Antono, Bryce Meredig, and Julia Ling. Machine-learned metrics for predicting the likelihood of success in materials discovery. npj Computational Materials, 6(131), 2020.
[11] Maarten De Jong, Wei Chen, Thomas Angsten, Anubhav Jain, Randy Notestine, Anthony Gamst, Marcel Sluiter, Chaitanya Krishna Ande, Sybrand Van Der Zwaag, Jose J. Plata, Cormac Toher, Stefano Curtarolo, Gerbrand Ceder, Kristin A. Persson, and Mark Asta. Charting the complete elastic properties of inorganic crystalline compounds. Scientific Data, 2(1):1-13, 2015.
[12] Anubhav Jain, Shyue Ping Ong, Geoffroy Hautier, Wei Chen, William Davidson Richards, Stephen Dacek, Shreyas Cholia, Dan Gunter, David Skinner, Gerbrand Ceder, and Kristin A. Persson. Commentary: The Materials Project: A materials genome approach to accelerating materials innovation. APL Materials, 1(1):011002, 2013.
[13] Ioan Andricioaei and John E Straub. Finding the needle in the haystack: Algorithms for conformational optimization. Computers in Physics, 10:449, 1996.
[14] Matthias Seeger. Gaussian processes for machine learning. International journal of neural systems, 14(2):69-106, 2004.
[15] Jasper Snoek, Oren Ripped, Kevin Swersky, Ryan Kiros, Nadathur Satish, Narayanan Sundaram, Md Mostofa Ali Patwary, Prabhat, and Ryan P. Adams. Scalable Bayesian optimization using deep neural networks. 32nd International Conference on Machine Learning, ICML 2015, 3:2161-2170, 2015.
[16] John Dagdelen, Joseph Montoya, Maarten De Jong, and Kristin Persson. Computational prediction of new auxetic materials. Nature Communications, 8(1):1-8, 2017.
[17] Krishna Kumar Saxena, Raj Das, and Emilio P. Calius. Three Decades of Auxetics Research Materials with Negative Poisson's Ratio: A Review. Advanced Engineering Materials, 18(11):1847-1870, 2016.
[18] Q Liu. Literature Review: Materials with Negative Poisson's Ratios and Potential Applications to Aerospace and Defense. Technical report, Australian Government Department of Defense, 2006.
[19] Wael A Salah and Mai Abuhelwa. Review of Thermoelectric Cooling Devices Recent Applications. Journal of Engineering Science and Technology, 15(1):455-476, 2020.
[20] Ran He, Gabi Schierning, and Kornelius Nielsch. Thermoelectric Devices: A Review of Devices, Architectures, and Contact Optimization. Advanced Materials Technologies, 3(4):1700256, 2018.
[21] Jun Mao, Gang Chen, and Zhifeng Ren. Thermoelectric cooling materials. Nature Materials, 20(4):454-461, 2020.
[22] Amir Yeganeh-Haeri, Donald J. Weidner, and John B. Parise. Elasticity of $\alpha$-Cristobalite: A Silicon Dioxide with a Negative Poisson's Ratio. Science, 257(5070):650-652, 1992.
[23] Rod Lakes and K. W. Wojciechowski. Negative compressibility, negative Poisson's ratio, and stability. Physica Status Solidi (B) Basic Research, 245(3):545-551, 2008.
[24] Lisa J Rew, Bruce D Maxwell, Frank L Dougher, and Richard Aspinall. Searching for a needle in a haystack: evaluating survey methods for non-indigenous plant species. National Park Biological Invasions, 8:523-539, 2006.
[25] Abdelmalek Bouguettaya, Hafed Zarzour, Amine Mohammed Taberkit, and Ahmed Kechida. A review on early wildfire detection from unmanned aerial vehicles using deep learning-based computer vision algorithms. Signal Processing, 190:108309, 2022.
[26] Wei Wei, Jinjiu Li, Longbing Cao, Yuming Ou, Jiahang Chen, W Wei, J Li, L Cao, Y Ou, and J Chen. Effective detection of sophisticated online banking fraud on extremely imbalanced data. World Wide Web, 16(4):449-475, 2012.</p>
<p>[27] Neil G Marchant and Benjamin I P Rubinstein. Needle in a Haystack: Label-Efficient Evaluation under Extreme Class Imbalance. KDD '21, August 14-18, 2021, Virtual Event, Singapore, page 11, 2021.
[28] Mohammed Khalilia, Sounak Chakraborty, and Mihail Popescu. Predicting disease risks from highly imbalanced data using random forest. BMC Medical Informatics and Decision Making, 11(1):1-13, 2011.
[29] Koby Crammer and Gal Chechik. A Needle in a Haystack: Local One-Class Optimization. Proceedings of the 21st International Conference on Machine Learning, Banff, Canada, 2004.
[30] Haixiang Liu, Yuanming Hu, Bo Zhu, Wojciech Matusik, and Eftychios Sifakis. Narrow-Band Topology Optimization on a Sparsely Populated Grid. ACM Transactions on Graphics, 37(6):1-14, 2018.
[31] Helena E. Nusse and James A. Yorke. Basins of Attraction. Science, 271(5254):1376-1380, 1996.
[32] George Datseris and Alexandre Wagemakers. Effortless estimation of basins of attraction. Chaos: An Interdisciplinary Journal of Nonlinear Science, 32(2):023104, 2022.
[33] Philipp Hennig and Christian J. Schuler. Entropy search for information-efficient global optimization. Journal of Machine Learning Research, 13:1809-1837, 2012.
[34] Belyaev Mikhail, Burnaev Evgeny, and Kapushev Yermek. Exact Inference for Gaussian Process Regression in case of Big Data with the Cartesian Product Structure. 2014.
[35] Cheng Li, Sunil Gupta, Santu Rana, Vu Nguyen, Svetha Venkatesh, and Alistair Shilton. High Dimensional Bayesian Optimization Using Dropout. Proceedings of the 26th International Joint Conference on Artificial Intelligence, IJCAI, 2017.
[36] Zi Wang, Chengtao Li, Stefanie Jegelka, and Pushmeet Kohli. Batched High-dimensional Bayesian Optimization via Structural Kernel Learning. Proceedings of the 34th International Conference on Machine Learning, Sydney, Australia, PMLR, 70, 2017.
[37] Thang D Bui, Josiah Yan, and Richard E Turner. A Unifying Framework for Gaussian Process Pseudo-Point Approximations using Power Expectation Propagation. Journal of Machine Learning Research, 18:1-72, 2017.
[38] Gongjin Lan, Jakub M Tomczak, Diederik M Roijers, and A E Eiben. Time Efficiency in Optimization with a Bayesian-Evolutionary Algorithm. 2020.
[39] David Eriksson, Michael Pearce, Jacob R Gardner, Ryan Turner, and Matthias Poloczek. Scalable Global Optimization via Local Bayesian Optimization. 2020.
[40] Rommel G. Regis. Trust regions in Kriging-based optimization with expected improvement. Engineering Optimization, 48(6):1037-1059, 2015.
[41] Y Diouane, V Picheny, R Le Riche, A Scotto, and Di Perrotolo. TREGO: a Trust-Region Framework for Efficient Global Optimization. 2021.
[42] Michalis Titsias. Variational learning of inducing variables in sparse gaussian processes. In David van Dyk and Max Welling, editors, Proceedings of the Twelth International Conference on Artificial Intelligence and Statistics, volume 5 of Proceedings of Machine Learning Research, pages 567-574, Hilton Clearwater Beach Resort, Clearwater Beach, Florida USA, 16-18 Apr 2009. PMLR.
[43] Felix Leibfried, Vincent Dutordoir, S T John, and Nicolas Durrande. A Tutorial on Sparse Gaussian Processes and Variational Inference. 2021.
[44] R. E. Turner and M. Sahani. Two problems with variational expectation maximisation for time-series models. In D. Barber, T. Cemgil, and S. Chiappa, editors, Bayesian Time series models, chapter 5, pages 109-130. Cambridge University Press, 2011.
[45] Bas van Stein, Hao Wang, and Thomas Back. Automatic configuration of deep neural networks with parallel efficient global optimization. In 2019 International Joint Conference on Neural Networks (IJCNN), pages 1-7. IEEE, 2019.
[46] Donald R Jones, Matthias Schonlau, and William J Welch. Efficient Global Optimization of Expensive Black-Box Functions. Journal of Global Optimization, 13:455-492, 1998.
[47] Tinu Theckel Joy, Santu Rana, Sunil Gupta, and Svetha Venkatesh. Fast hyperparameter tuning using Bayesian optimization with directional derivatives. Knowledge-Based Systems, 205:106247, 2020.
[48] Aaron Klein, Stefan Falkner, Simon Bartels, Philipp Hennig, and Frank Hutter. Fast Bayesian Optimization of Machine Learning Hyperparameters on Large Datasets. 2017.
[49] Yuyu Zhang, Mohammad Taha Bahadori, Hang Su, and Jimeng Sun. FLASH: Fast Bayesian Optimization for Data Analytic Pipelines. Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, 2016.</p>
<p>[50] Alexander I Cowen-Rivers, Wenlong Lyu, Rasul Tutunov, Zhi Wang, Antoine Grosnit, Ryan Rhys Griffiths, Alexandre Max Maravel, Hao Jianye, Jun Wang, Jan Peters, and Haitham Bou-Ammar. Hebo: Pushing the limits of sample-efficient hyperparameter optimisation honorary position. Journal of Artificial Intelligence Research, $70: 1-15,2021$.
[51] M. D. McKay, R. J. Beckman, and W. J. Conover. A comparison of three methods for selecting values of input variables in the analysis of output from a computer code. Technometrics, 42(1):55-61, 2000.
[52] V. R. Šaltenis. One method of multiextremum optimization. Artomatika i Vychislitel'naya Tekhnika (Automatic Control and Computer Sciences), pages 33-38, 1971.
[53] Peter Auer. Using confidence bounds for exploitation-exploration trade-offs. Journal of Machine Learning Research, 3:397-422, 2002.
[54] Niranjan Srinivas, Andreas Krause, Sham Kakade, and Matthias Seeger. Gaussian process optimization in the bandit setting: No regret and experimental design. Proceedings of the 27th International Conference on Machine Learning, Haifa, Israel, 2010, pages 1015-1022, 2010.
[55] Florian Häse, Loïc M. Roch, Christoph Kreisbeck, and Alán Aspuru-Guzik. Phoenics: A bayesian optimizer for chemistry. ACS Central Science, 4:1134-1145, 2018.
[56] Florian Häse, Matteo Aldeghi, Riley J. Hickman, Loïc M. Roch, and Alán Aspuru-Guzik. Gryffin: An algorithm for bayesian optimization of categorical variables informed by expert knowledge. Applied Physics Reviews, 8:031406, 72021.
[57] D H Ackley. A connectionist machine for genetic hillclimbing. 1987.
[58] E P Adorio. MVF - Multivariate Test Functions Library in C for Unconstrained Global Optimization, 2005.
[59] Albert Reuther, Jeremy Kepner, Chansup Byun, Siddharth Samsi, William Arcand, David Bestor, Bill Bergeron, Vijay Gadepally, Michael Houle, Matthew Hubbell, Michael Jones, Anna Klein, Lauren Milechin, Julia Mullen, Andrew Prout, Antonio Rosa, Charles Yee, and Peter Michaleas. Interactive supercomputing on 40,000 cores for machine learning and data analysis. In 2018 IEEE High Performance extreme Computing Conference (HPEC), pages 1-6. IEEE, 2018.
[60] Elon S Correa and Jonathan L Shapiro. Model Complexity vs. Performance in the Bayesian Optimization Algorithm. In T P Runarsson, H-G Beyer, E Burke, J J Merelo-Guervos, L D Whitley, and X Yao, editors, Parallel Problem Solving from Nature, pages 998-1007. Springer, 2006.
[61] Georg K.H. Madsen and David J. Singh. BoltzTraP. A code for calculating band-structure dependent quantities. Computer Physics Communications, 175(1):67-71, 2006.
[62] Gurjot Kohli, Christine M. Lee, Joshua B. Fisher, Gregory Halverson, Evan Variano, Yufang Jin, Daniel Carney, Brenton A. Wilder, and Alicia M. Kinoshita. Ecostress and cimis: A comparison of potential and reference evapotranspiration in riverside county, california. Remote Sensing 2020, Vol. 12, Page 4126, 12:4126, 2020.
[63] Hoss Belyadi, Ebrahim Fathi, and Fatemeh Belyadi. Rock mechanical properties and in situ stresses. Hydraulic Fracturing in Unconventional Reservoirs, pages 215-231, 2019.
[64] Yuriy M. Poplavko. Mechanical properties of solids. Electronic Materials, pages 71-93, 2019.
[65] B. Hinterleitner, I. Knapp, M. Poneder, Yongpeng Shi, H. Müller, G. Eguchi, C. Eisenmenger-Sittner, M. StögerPollach, Y. Kakefuda, N. Kawamoto, Q. Guo, T. Baba, T. Mori, Sami Ullah, Xing Qiu Chen, and E. Bauer. Thermoelectric performance of a metastable thin-film Heusler alloy. Nature, 576(7785):85-90, 2019.
[66] Hee Seok Kim, Weishu Liu, Gang Chen, Ching Wu Chu, and Zhifeng Ren. Relationship between thermoelectric figure of merit and energy conversion efficiency. Proceedings of the National Academy of Sciences of the United States of America, 112(27):8205-8210, 2015.
[67] Wei Hsin Chen, Po Hua Wu, Xiao Dong Wang, and Yu Li Lin. Power output and efficiency of a thermoelectric generator under temperature control. Energy Conversion and Management, 127:404-415, 2016.
[68] H. Julian Goldsmid. Bismuth telluride and its alloys as materials for thermoelectric generation. Materials, 7(4):2577-2592, 2014.
[69] Pedro M. Rodrigo, Alvaro Valera, Eduardo F. Fernandez, and Florencia M. Almonacid. Annual Energy Harvesting of Passively Cooled Hybrid Thermoelectric Generator-Concentrator Photovoltaic Modules. IEEE Journal of Photovoltaics, 9(6):1652-1660, 2019.
[70] Ankita Mohapatra and Timothy Trinh. Early wildfire detection technologies in practice - a review. Sustainability 2022, Vol. 14, Page 12270, 14:12270, 2022.</p>
<p>[71] Natalie Maus, Haydn T. Jones, Juston S. Moore, Matt J. Kusner, John Bradshaw, and Jacob R. Gardner. Local latent space bayesian optimization over structured inputs. 2022.
[72] Antoine Grosnit, Alexandre Max Maraval, Rasul Tutunov, Ryan-Rhys Griffiths, Huawei Noah, Ark Lab, Alexander I Cowen-Rivers, Lin Yang Huawei Noah, Ark Lab Lin Zhu Huawei Noah, Ark Lab Wenlong Lyu Huawei Noah, Ark Lab Zhitang Chen Huawei Noah, Ark Lab Jun Wang, Jan Peters, and Haitham Bou Ammar. High-dimensional bayesian optimisation with variational autoencoders and deep metric learning. 2021.</p>
<h1>Supporting Information: <br> Fast Bayesian Optimization of Needle-in-a-Haystack Problems using Zooming Memory-Based Initialization (ZoMBI)</h1>
<p>Alexander E. Siemenn ${ }^{\star, \dagger}$, Zekun Ren ${ }^{\ddagger}$, Qianxiao Li ${ }^{\text {M }}$, Tonio Buonassisi ${ }^{\dagger}$<br>$\dagger$ Department of Mechanical Engineering, Massachusetts Institute of Technology, Cambridge, MA 02139, USA<br>$\ddagger$ Department of Electrical and Computer Engineering, Singapore-MIT Alliance for Research and Technology, Singapore 138602, Singapore<br>M Department of Mathematics, National University of Singapore, Singapore 138602, Singapore<br>*Corresponding author: asiemenn@mit.edu</p>
<h2>S-1 Ackley Function Description</h2>
<p>The Ackley function is an analytical function used in this paper to simulate a Needle-in-a-Haystack problem and is capable of having dimensionality between 1-dimension and $d$-dimensions. The global minimum or "the needle" is challenging to discover in few experiments because the percentage of space made up by the global basin of attraction decreases exponentially with dimensionality. The basin of attraction is the region containing the global minimum that once discovered, can be simply descended to the discover the global minimum. As the $b$ value of the Ackley function increases, the basin of attraction region narrows. In addition to having this needle-like global minimum, the Ackley function also has many local minima, generating a non-convex response surface. This response surface of the Ackley function is quantified through the following equation [57]:</p>
<p>$$
f(X)=-a \exp \left(-b \sqrt{\frac{1}{d} \sum_{i=1}^{d} X_{i}^{2}}\right)-\exp \left(\frac{1}{d} \sum_{i=1}^{d} \cos \left(c X_{i}\right)\right)+a+\exp (1)
$$</p>
<p>where $a$ determines the connectivity of local minima, $b$ determines the width of the global minimum basin of attraction, $c$ determines the periodicity of the local minima, and $d$ is the number of dimensions. For this paper, the Ackley functions used have minima connectivity of $a=20$ and high minima periodicity of $c=\pi$ with $b$ and $d$ varying for most applications, but generally $b=0.5, d=5$. The response variable, $f(X) \in \mathbb{R}:[0,25]$ with the global minimum at $f(X)=0$ and the basin of attraction existing between $0 \leq f(X)&lt;10$.</p>
<h2>S-2 Dataset Variables and Descriptions</h2>
<p>In this paper, we provide analyses of three real-world datasets: (1) Poisson's Ratio [12, 11], (2) Thermoelectric Merit [61], and (3) Wildfire Detection [62]. The Poisson's Ratio dataset has a sample size of $N=146,232$ experimental and simulated materials, publicly available from the Materials Project database [12]. For this paper, we select five real-valued material variables to optimize Poisson's Ratio over, these variables are shown in Table S-1. The feature importance ranking of these variables with the target variable is shown in Figure S-1(a). The target variable, Poisson's Ratio is measured directly or computed using Density Functional Theory (DFT) from the stress, elasticity, and strain tensors, $\sigma_{i j}, C_{i j k l}$, and $\epsilon_{k l}[11]$ :</p>
<p>$$
\left[\begin{array}{l}
\sigma_{1} \
\sigma_{2} \
\sigma_{3} \
\sigma_{4} \
\sigma_{5} \
\sigma_{6}
\end{array}\right]=\left[\begin{array}{llllll}
C_{11} &amp; C_{12} &amp; C_{13} &amp; C_{14} &amp; C_{15} &amp; C_{16} \
C_{12} &amp; C_{22} &amp; C_{23} &amp; C_{24} &amp; C_{25} &amp; C_{26} \
C_{13} &amp; C_{23} &amp; C_{33} &amp; C_{34} &amp; C_{35} &amp; C_{36} \
C_{14} &amp; C_{24} &amp; C_{34} &amp; C_{44} &amp; C_{45} &amp; C_{46} \
C_{15} &amp; C_{25} &amp; C_{35} &amp; C_{45} &amp; C_{55} &amp; C_{56} \
C_{16} &amp; C_{26} &amp; C_{36} &amp; C_{46} &amp; C_{56} &amp; C_{66}
\end{array}\right]\left[\begin{array}{c}
\epsilon_{1} \
\epsilon_{2} \
\epsilon_{3} \
2 \epsilon_{4} \
2 \epsilon_{5} \
2 \epsilon_{6}
\end{array}\right]
$$</p>
<p>The Thermoelectric Merit dataset has a sample size of $N=1,063$ experimental and simulated materials, publicly available from the Materials Project database [12]. For this paper, we select five real-valued material variables to optimize Thermoelectric Merit over, these variables are shown in Table S-2. The feature importance ranking of these variables with the target variable is shown in Figure S-1(b). The target variable, Thermoelectric Merit is computed from</p>            </div>
        </div>

    </div>
</body>
</html>