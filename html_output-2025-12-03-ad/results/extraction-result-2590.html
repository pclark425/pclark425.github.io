<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-2590 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-2590</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-2590</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-67.html">extraction-schema-67</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <p><strong>Paper ID:</strong> paper-1150f9289c6151506e3f7cf0e6ebbcfd49f1dace</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/1150f9289c6151506e3f7cf0e6ebbcfd49f1dace" target="_blank">Active Learning with Statistical Models</a></p>
                <p><strong>Paper Venue:</strong> Neural Information Processing Systems</p>
                <p><strong>Paper TL;DR:</strong> This work shows how the same principles may be used to select data for two alternative, statistically-based learning architectures: mixtures of Gaussians and locally weighted regression.</p>
                <p><strong>Paper Abstract:</strong> For many types of learners one can compute the statistically "optimal" way to select data. We review how these techniques have been used with feedforward neural networks [MacKay, 1992; Cohn, 1994]. We then show how the same principles may be used to select data for two alternative, statistically-based learning architectures: mixtures of Gaussians and locally weighted regression. While the techniques for neural networks are expensive and approximate, the techniques for mixtures of Gaussians and locally weighted regression are both efficient and accurate.</p>
                <p><strong>Cost:</strong> 0.014</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e2590.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e2590.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>VarMin-AL (Mixture)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Variance-minimizing Active Learning with Mixtures of Gaussians</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An active learning method that selects new queries by minimizing the expected reduction in the learner's predictive variance, implemented concretely for a mixture-of-Gaussians joint density model with closed-form updates for expected variance after adding a candidate point.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Variance-minimizing active learning (mixture of Gaussians)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Build a joint density P(x,y) with a finite mixture of Gaussians (EM to fit parameters). For any candidate input \tilde{x} compute the model's predicted distribution P(\tilde{y}|\tilde{x}) (a mixture of Gaussians) and then compute in closed form the expected new predictive variance at reference inputs after hypothetically adding (\tilde{x},\tilde{y}) and updating component sufficient statistics (support n_i, means, covariances). The expected post-query variance is integrated over reference points drawn from P(x) and candidate \tilde{x} is chosen to minimize this integrated expected variance; hillclimbing on the derivative of the expected variance is offered for continuous domains.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Supervised function approximation tasks (demonstrated on robot arm kinematics, Arm2D); applicable to domains where data acquisition is expensive or dangerous (industrial experiments, sensor placement, robotics).</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>Greedy sequential selection: at each step evaluate candidate inputs and pick the single input \tilde{x} that minimizes the expected integrated model variance after incorporating that point. Candidate selection in experiments was done by sampling a set of random candidates per iteration (64 candidates) and evaluating the closed-form expected variance for each across a set of reference points (64). Optionally, hillclimb on the derivative of the expected variance to find local optima in continuous action spaces.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td>Wall-clock time per operation reported (training time and per-reference / per-candidate evaluation times); Table 1 gives training time = 3.9 + 0.05 m ms (m = number of training points), evaluating a single reference point costs ~15000 μs, evaluating a candidate per reference point costs ~1300 μs on a Sparc 10; correction factor computing (Equation 8) accounts for ~half of training time.</td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td>Expected reduction in predictive variance, i.e., the expected post-query model variance integrated over reference inputs drawn from P(x); computed in closed form per Gaussian component and mixed according to component weights h_i.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td>No explicit multi-armed-bandit mechanism; exploration vs exploitation is governed implicitly by the expected-variance objective: queries that yield the largest expected global reduction in model variance are selected. This tends to query regions where the model is most uncertain (exploration) but weighted by P(x) and by how much variance reduction benefits predictions (which can favor exploitation of high-probability regions). Continuous-domain hillclimbing on the expected-variance derivative is used to find locally optimal queries.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td>Not explicit. Diversity arises indirectly through (a) evaluating expectation of variance over a set of reference points drawn from P(x), and (b) sampling candidate sets randomly each iteration (experiments used 64 random candidates). There is no explicit penalty or constraint to force diversity among chosen queries across iterations.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td>Number of experiments / cost per example (sequential budget of queries); computational budget/time (cost to compute the optimal query) is also considered.</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td>Greedy single-query optimization under an implicit per-query selection cost: the method assumes expensive data so it invests computation to choose the most informative next point. In practice the candidate set size and number of reference points control time per selection; hillclimbing reduces candidate enumeration when needed.</td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td>None defined. The paper focuses on reducing predictive error/variance rather than an explicit breakthrough or novelty score.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Reported metrics are predictive mean squared error (MSE) and model variance evaluated on independent reference points. For the Mixture-of-Gaussians on Arm2D with 60 Gaussians and 1% input noise: estimated model variance and MSE learning curves show the variance-minimizing learner has significantly lower variance than random sampling; MSE of the variance-minimizing learner is consistently about 1/3 that of the randomly sampling learner (i.e., ~67% relative reduction in MSE) across experiments (averaged over runs). Computation times per Table 1 (Sparc 10): training time 3.9 + 0.05 m ms, evaluating a reference point ~15000 μs, evaluating a candidate per reference per reference point ~1300 μs.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Random sampling (selecting new inputs uniformly at random from P(x)); results compared also qualitatively to earlier neural-network OED approaches (MacKay, Cohn) but experiments used random sampling as the empirical baseline.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>Mixture-of-Gaussians active selection yields substantially lower variance and MSE compared to random selection; specifically, MSE is approximately one-third that of random sampling over the tasks reported.</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td>Empirical efficiency: approximately 67% reduction in MSE relative to random sampling on the Arm2D task (i.e., MSE ≈ 1/3 of baseline). Additional efficiency from producing a parsimonious training set that reduces prediction time is noted qualitatively.</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td>Paper discusses the tradeoff between computational cost of selecting an optimal query and potential savings in expensive data acquisition: when data points are costly (time/money), it is beneficial to spend computation to optimize queries; when data are cheap, computational cost may outweigh gains. Also discusses bias vs variance tradeoff: current criterion minimizes variance only and can leave bias unaddressed; future work suggested to jointly minimize bias and variance. No quantitative Pareto frontier between cost and information gain is given.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td>Key insights: selecting queries that minimize expected integrated predictive variance dramatically reduces required labeled examples and MSE compared to random sampling; the mixture-of-Gaussians model permits closed-form, efficient computation of expected variance-change, enabling practical active learning; in high-dimensional spaces candidate-sampling or gradient-based hillclimbing on the expected-variance derivative are suggested to find useful queries efficiently; computational overhead is worthwhile when data acquisition is expensive.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Active Learning with Statistical Models', 'publication_date_yy_mm': '1996-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2590.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e2590.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>VarMin-AL (LOESS)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Variance-minimizing Active Learning with Locally Weighted Regression (LOESS)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An active learning method that chooses queries to minimize expected predictive variance when using locally weighted (memory-based) regression; expected-post-query variance expressions are available in closed form allowing efficient evaluation per candidate.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Variance-minimizing active learning (locally weighted regression / LOESS)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Use a LOESS-style locally weighted linear regression at each reference x with a kernel h(x-x_i)=exp(-k(x-x_i)^2). For a candidate \tilde{x}, compute the kernel weight \tilde{h} and obtain closed-form expressions for the expected updated sufficient statistics (n, means, covariances) and thus the expected post-query predictive variance at each reference point. Integrate (Monte Carlo over reference points) and choose the candidate that minimizes the integrated expected variance. Kernel smoothing parameter k can be set per-reference by minimizing estimated predictive variance (variance-based criterion) or by cross-validation.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Supervised function approximation and control problems requiring real-time predictions (demonstrated on robot arm kinematics Arm2D); memory-based control (robot juggling cited as prior work).</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>Greedy sequential selection of the next input to label by evaluating closed-form expected reduction in predictive variance for each candidate across reference points; candidates sampled randomly (or found via hillclimb in continuous spaces). Kernel support n and prediction cost depend on dataset size, so the strategy prefers points that both reduce variance and maintain parsimonious training sets.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td>Wall-clock time per operation on Sparc 10 reported in Table 1: evaluating a single reference point costs 92 + 9.7 m μs and evaluating a candidate per reference point costs 58 + 0.16 m μs (m = number of training examples). Example in text: with 100 training points, 64 reference points and 64 candidate points, selection time ≈ 0.3 s.</td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td>Expected reduction in predictive variance (expected post-query predictive variance integrated over reference points); for LOESS the mean and variance of P(\tilde{y}|\tilde{x}) are explicit, enabling closed-form expectation.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td>No explicit bandit algorithm; selection is driven by maximizing expected variance reduction which implicitly favors querying high-uncertainty regions (exploration) while weighting by how variance reduction impacts predictions (which can induce exploitation). The smoothing parameter k (kernel width) is set by minimizing estimated predictive variance, which itself balances local vs global fitting.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td>No explicit diversity-promoting penalty. Diversity arises indirectly via sampling candidates randomly each iteration and evaluating expected variance over a set of reference points drawn from P(x).</td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td>Number of labeled examples (sequential queries); also computational time per selection (wall-clock) is considered as an implicit budget.</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td>Greedy per-query optimization under the assumption that examples are costly; computational cost can be controlled by the number of reference points and candidates evaluated, or by using hillclimbing instead of full candidate enumeration. LOESS has cheaper per-query computation than mixture training as there is no training phase but per-prediction cost grows with dataset size.</td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td>None defined; method optimizes predictive performance (variance/MSE) rather than explicit novelty or breakthrough scores.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Reported metrics: predictive MSE and model variance on independent reference points. In Arm2D experiments LOESS with variance-minimizing selection achieved significantly lower variance and MSE than random sampling and outperformed both the mixture-of-Gaussians and previously reported neural networks on the same task. Computation example: selection time with 100 training points and 64 reference and candidate points ≈ 0.3 s (Sparc 10). Table 1 quantifies per-reference and per-candidate times as above.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Random sampling (uniform selection of new inputs); compared qualitatively to mixture-of-Gaussians and previously published neural network active learning results.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>LOESS active selection yields significantly lower variance and MSE than random sampling; in the experiments it also outperformed the mixture-of-Gaussians and neural-network approaches on Arm2D (no single-number MSE ratio is provided in text for LOESS, but learning curves show clear improvements).</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td>Empirical: substantial reductions in MSE and variance relative to random sampling; selection time example shows that choosing informative points can be computed in sub-second time in the experimental setting (0.3 s for the given example). No single aggregated % efficiency number provided beyond empirical plots.</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td>Paper discusses tradeoffs between kernel width (k) choices: decreasing k (more global) increases n (support) reducing variance via n but increases conditional variance σ_{y|x}^2, so an optimal k minimizes estimated predictive variance. Also discusses computational cost vs data cost: LOESS selection is computationally cheaper than mixture retraining and suitable for control applications; prediction cost grows with dataset size, making parsimonious selected datasets advantageous.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td>Selecting queries that minimize expected predictive variance for LOESS produces faster learning (lower MSE and variance) than random sampling; an automatic, variance-based method to set the kernel smoothing parameter k helps balance bias-variance locally, and the closed-form expected-variance updates allow efficient sequential query selection. Parsimonious training sets produced by active selection reduce future prediction cost.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Active Learning with Statistical Models', 'publication_date_yy_mm': '1996-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2590.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e2590.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of systems or methods for automated scientific discovery, experimental design, or active learning that involve resource allocation decisions, balancing computational costs against information gain, breakthrough potential, and hypothesis diversity.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>NN-OED</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Neural Network Optimal Experiment Design (variance-based)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An application of optimal experimental design to feedforward neural networks where candidate queries are chosen to minimize an approximate expected predictive variance computed via a second-order Taylor expansion around the network parameters.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Information-based objective functions for active data selection</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Neural network optimal experiment design (OED) via expected variance reduction</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Approximate the predictive variance of a trained neural network at input x by S^2 (∂ŷ/∂w)^T (∂^2 S^2/∂w^2)^{-1} (∂ŷ/∂w), using a Gaussian noise assumption and second-order Taylor expansion around the maximum-likelihood weights. Compute expected post-query variance in closed form under Gaussian P(y|x) assumptions and select inputs that minimize the integrated expected variance. The expectation is differentiable with respect to candidate inputs, permitting gradient-based search for optimal queries.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>General supervised learning and function approximation; prior work used it for exploration in neural networks (cited but not experimentally used in this paper).</td>
                        </tr>
                        <tr>
                            <td><strong>resource_allocation_strategy</strong></td>
                            <td>Greedy sequential selection by minimizing approximate expected integrated predictive variance; leverages differentiability to hillclimb on candidate inputs.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost_metric</strong></td>
                            <td>Computational cost dominated by inversion of a |w| x |w| Hessian matrix per candidate and retraining when incorporating new examples; costs described qualitatively (matrix inversion and retraining expensive).</td>
                        </tr>
                        <tr>
                            <td><strong>information_gain_metric</strong></td>
                            <td>Approximate expected reduction in predictive variance (derived from the network's parameter covariance approximation), equivalent to an information-based objective under Gaussian noise assumptions.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_information_gain</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>exploration_exploitation_mechanism</strong></td>
                            <td>Driven entirely by expected-variance minimization; differentiability allows continuous search for queries that most reduce model uncertainty—implicitly trades exploration of uncertain regions vs exploitation of high-impact areas via the integrated variance objective.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_mechanism</strong></td>
                            <td>No explicit diversity promotion is described; selection focuses solely on the variance-reduction objective.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_diversity_promotion</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_type</strong></td>
                            <td>Computational resources and time (matrix inversion and retraining cost) and number/cost of data acquisitions.</td>
                        </tr>
                        <tr>
                            <td><strong>budget_constraint_handling</strong></td>
                            <td>The paper notes this approach is computationally expensive (matrix inversions and expensive retraining), suggesting it may be impractical for some real-time settings; alternatives (sampling-based approximations, Markov-chain sampling cited Paass & Kindermann) are referenced to address cost.</td>
                        </tr>
                        <tr>
                            <td><strong>breakthrough_discovery_metric</strong></td>
                            <td>Not defined in this context.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Not evaluated experimentally in this paper; prior references (MacKay, Cohn) report empirical benefits but this paper only reviews the approach and contrasts its computational expense with the closed-form efficient alternatives (mixture and LOESS).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Discussed conceptually relative to random sampling and to the mixture/LOESS methods presented in this paper; no experimental baseline in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_vs_baseline</strong></td>
                            <td>Paper states the neural-network OED approach can work well on some problems but is computationally expensive and relies on approximations (Taylor expansion and Gaussian noise assumptions); no quantitative comparison in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_gain</strong></td>
                            <td>No empirical efficiency numbers in this paper; computational cost is presented as a limiting factor relative to mixture-of-Gaussians and LOESS methods.</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoff_analysis</strong></td>
                            <td>Paper highlights the tradeoff: neural-network OED can provide statistically optimal queries under its assumptions but at high computational cost and reliance on approximations; alternative statistical models (mixture-of-Gaussians, LOESS) allow efficient and accurate closed-form expected-variance computation without the heavy matrix inversions or retraining costs.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_allocation_findings</strong></td>
                            <td>Conclusion: neural-network OED is principled and differentiable, but its computational expense and approximations make it less practical than the mixture and LOESS variance-minimization techniques developed and used in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Active Learning with Statistical Models', 'publication_date_yy_mm': '1996-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Information-based objective functions for active data selection <em>(Rating: 2)</em></li>
                <li>Improving generalization with active learning <em>(Rating: 2)</em></li>
                <li>Theory of Optimal Experiments <em>(Rating: 2)</em></li>
                <li>Neural network exploration using optimal experiment design <em>(Rating: 1)</em></li>
                <li>Bayesian classification <em>(Rating: 1)</em></li>
                <li>Training connectionist networks with queries and selective sampling <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-2590",
    "paper_id": "paper-1150f9289c6151506e3f7cf0e6ebbcfd49f1dace",
    "extraction_schema_id": "extraction-schema-67",
    "extracted_data": [
        {
            "name_short": "VarMin-AL (Mixture)",
            "name_full": "Variance-minimizing Active Learning with Mixtures of Gaussians",
            "brief_description": "An active learning method that selects new queries by minimizing the expected reduction in the learner's predictive variance, implemented concretely for a mixture-of-Gaussians joint density model with closed-form updates for expected variance after adding a candidate point.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "Variance-minimizing active learning (mixture of Gaussians)",
            "system_description": "Build a joint density P(x,y) with a finite mixture of Gaussians (EM to fit parameters). For any candidate input \\tilde{x} compute the model's predicted distribution P(\\tilde{y}|\\tilde{x}) (a mixture of Gaussians) and then compute in closed form the expected new predictive variance at reference inputs after hypothetically adding (\\tilde{x},\\tilde{y}) and updating component sufficient statistics (support n_i, means, covariances). The expected post-query variance is integrated over reference points drawn from P(x) and candidate \\tilde{x} is chosen to minimize this integrated expected variance; hillclimbing on the derivative of the expected variance is offered for continuous domains.",
            "application_domain": "Supervised function approximation tasks (demonstrated on robot arm kinematics, Arm2D); applicable to domains where data acquisition is expensive or dangerous (industrial experiments, sensor placement, robotics).",
            "resource_allocation_strategy": "Greedy sequential selection: at each step evaluate candidate inputs and pick the single input \\tilde{x} that minimizes the expected integrated model variance after incorporating that point. Candidate selection in experiments was done by sampling a set of random candidates per iteration (64 candidates) and evaluating the closed-form expected variance for each across a set of reference points (64). Optionally, hillclimb on the derivative of the expected variance to find local optima in continuous action spaces.",
            "computational_cost_metric": "Wall-clock time per operation reported (training time and per-reference / per-candidate evaluation times); Table 1 gives training time = 3.9 + 0.05 m ms (m = number of training points), evaluating a single reference point costs ~15000 μs, evaluating a candidate per reference point costs ~1300 μs on a Sparc 10; correction factor computing (Equation 8) accounts for ~half of training time.",
            "information_gain_metric": "Expected reduction in predictive variance, i.e., the expected post-query model variance integrated over reference inputs drawn from P(x); computed in closed form per Gaussian component and mixed according to component weights h_i.",
            "uses_information_gain": true,
            "exploration_exploitation_mechanism": "No explicit multi-armed-bandit mechanism; exploration vs exploitation is governed implicitly by the expected-variance objective: queries that yield the largest expected global reduction in model variance are selected. This tends to query regions where the model is most uncertain (exploration) but weighted by P(x) and by how much variance reduction benefits predictions (which can favor exploitation of high-probability regions). Continuous-domain hillclimbing on the expected-variance derivative is used to find locally optimal queries.",
            "diversity_mechanism": "Not explicit. Diversity arises indirectly through (a) evaluating expectation of variance over a set of reference points drawn from P(x), and (b) sampling candidate sets randomly each iteration (experiments used 64 random candidates). There is no explicit penalty or constraint to force diversity among chosen queries across iterations.",
            "uses_diversity_promotion": false,
            "budget_constraint_type": "Number of experiments / cost per example (sequential budget of queries); computational budget/time (cost to compute the optimal query) is also considered.",
            "budget_constraint_handling": "Greedy single-query optimization under an implicit per-query selection cost: the method assumes expensive data so it invests computation to choose the most informative next point. In practice the candidate set size and number of reference points control time per selection; hillclimbing reduces candidate enumeration when needed.",
            "breakthrough_discovery_metric": "None defined. The paper focuses on reducing predictive error/variance rather than an explicit breakthrough or novelty score.",
            "performance_metrics": "Reported metrics are predictive mean squared error (MSE) and model variance evaluated on independent reference points. For the Mixture-of-Gaussians on Arm2D with 60 Gaussians and 1% input noise: estimated model variance and MSE learning curves show the variance-minimizing learner has significantly lower variance than random sampling; MSE of the variance-minimizing learner is consistently about 1/3 that of the randomly sampling learner (i.e., ~67% relative reduction in MSE) across experiments (averaged over runs). Computation times per Table 1 (Sparc 10): training time 3.9 + 0.05 m ms, evaluating a reference point ~15000 μs, evaluating a candidate per reference per reference point ~1300 μs.",
            "comparison_baseline": "Random sampling (selecting new inputs uniformly at random from P(x)); results compared also qualitatively to earlier neural-network OED approaches (MacKay, Cohn) but experiments used random sampling as the empirical baseline.",
            "performance_vs_baseline": "Mixture-of-Gaussians active selection yields substantially lower variance and MSE compared to random selection; specifically, MSE is approximately one-third that of random sampling over the tasks reported.",
            "efficiency_gain": "Empirical efficiency: approximately 67% reduction in MSE relative to random sampling on the Arm2D task (i.e., MSE ≈ 1/3 of baseline). Additional efficiency from producing a parsimonious training set that reduces prediction time is noted qualitatively.",
            "tradeoff_analysis": "Paper discusses the tradeoff between computational cost of selecting an optimal query and potential savings in expensive data acquisition: when data points are costly (time/money), it is beneficial to spend computation to optimize queries; when data are cheap, computational cost may outweigh gains. Also discusses bias vs variance tradeoff: current criterion minimizes variance only and can leave bias unaddressed; future work suggested to jointly minimize bias and variance. No quantitative Pareto frontier between cost and information gain is given.",
            "optimal_allocation_findings": "Key insights: selecting queries that minimize expected integrated predictive variance dramatically reduces required labeled examples and MSE compared to random sampling; the mixture-of-Gaussians model permits closed-form, efficient computation of expected variance-change, enabling practical active learning; in high-dimensional spaces candidate-sampling or gradient-based hillclimbing on the expected-variance derivative are suggested to find useful queries efficiently; computational overhead is worthwhile when data acquisition is expensive.",
            "uuid": "e2590.0",
            "source_info": {
                "paper_title": "Active Learning with Statistical Models",
                "publication_date_yy_mm": "1996-02"
            }
        },
        {
            "name_short": "VarMin-AL (LOESS)",
            "name_full": "Variance-minimizing Active Learning with Locally Weighted Regression (LOESS)",
            "brief_description": "An active learning method that chooses queries to minimize expected predictive variance when using locally weighted (memory-based) regression; expected-post-query variance expressions are available in closed form allowing efficient evaluation per candidate.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "Variance-minimizing active learning (locally weighted regression / LOESS)",
            "system_description": "Use a LOESS-style locally weighted linear regression at each reference x with a kernel h(x-x_i)=exp(-k(x-x_i)^2). For a candidate \\tilde{x}, compute the kernel weight \\tilde{h} and obtain closed-form expressions for the expected updated sufficient statistics (n, means, covariances) and thus the expected post-query predictive variance at each reference point. Integrate (Monte Carlo over reference points) and choose the candidate that minimizes the integrated expected variance. Kernel smoothing parameter k can be set per-reference by minimizing estimated predictive variance (variance-based criterion) or by cross-validation.",
            "application_domain": "Supervised function approximation and control problems requiring real-time predictions (demonstrated on robot arm kinematics Arm2D); memory-based control (robot juggling cited as prior work).",
            "resource_allocation_strategy": "Greedy sequential selection of the next input to label by evaluating closed-form expected reduction in predictive variance for each candidate across reference points; candidates sampled randomly (or found via hillclimb in continuous spaces). Kernel support n and prediction cost depend on dataset size, so the strategy prefers points that both reduce variance and maintain parsimonious training sets.",
            "computational_cost_metric": "Wall-clock time per operation on Sparc 10 reported in Table 1: evaluating a single reference point costs 92 + 9.7 m μs and evaluating a candidate per reference point costs 58 + 0.16 m μs (m = number of training examples). Example in text: with 100 training points, 64 reference points and 64 candidate points, selection time ≈ 0.3 s.",
            "information_gain_metric": "Expected reduction in predictive variance (expected post-query predictive variance integrated over reference points); for LOESS the mean and variance of P(\\tilde{y}|\\tilde{x}) are explicit, enabling closed-form expectation.",
            "uses_information_gain": true,
            "exploration_exploitation_mechanism": "No explicit bandit algorithm; selection is driven by maximizing expected variance reduction which implicitly favors querying high-uncertainty regions (exploration) while weighting by how variance reduction impacts predictions (which can induce exploitation). The smoothing parameter k (kernel width) is set by minimizing estimated predictive variance, which itself balances local vs global fitting.",
            "diversity_mechanism": "No explicit diversity-promoting penalty. Diversity arises indirectly via sampling candidates randomly each iteration and evaluating expected variance over a set of reference points drawn from P(x).",
            "uses_diversity_promotion": false,
            "budget_constraint_type": "Number of labeled examples (sequential queries); also computational time per selection (wall-clock) is considered as an implicit budget.",
            "budget_constraint_handling": "Greedy per-query optimization under the assumption that examples are costly; computational cost can be controlled by the number of reference points and candidates evaluated, or by using hillclimbing instead of full candidate enumeration. LOESS has cheaper per-query computation than mixture training as there is no training phase but per-prediction cost grows with dataset size.",
            "breakthrough_discovery_metric": "None defined; method optimizes predictive performance (variance/MSE) rather than explicit novelty or breakthrough scores.",
            "performance_metrics": "Reported metrics: predictive MSE and model variance on independent reference points. In Arm2D experiments LOESS with variance-minimizing selection achieved significantly lower variance and MSE than random sampling and outperformed both the mixture-of-Gaussians and previously reported neural networks on the same task. Computation example: selection time with 100 training points and 64 reference and candidate points ≈ 0.3 s (Sparc 10). Table 1 quantifies per-reference and per-candidate times as above.",
            "comparison_baseline": "Random sampling (uniform selection of new inputs); compared qualitatively to mixture-of-Gaussians and previously published neural network active learning results.",
            "performance_vs_baseline": "LOESS active selection yields significantly lower variance and MSE than random sampling; in the experiments it also outperformed the mixture-of-Gaussians and neural-network approaches on Arm2D (no single-number MSE ratio is provided in text for LOESS, but learning curves show clear improvements).",
            "efficiency_gain": "Empirical: substantial reductions in MSE and variance relative to random sampling; selection time example shows that choosing informative points can be computed in sub-second time in the experimental setting (0.3 s for the given example). No single aggregated % efficiency number provided beyond empirical plots.",
            "tradeoff_analysis": "Paper discusses tradeoffs between kernel width (k) choices: decreasing k (more global) increases n (support) reducing variance via n but increases conditional variance σ_{y|x}^2, so an optimal k minimizes estimated predictive variance. Also discusses computational cost vs data cost: LOESS selection is computationally cheaper than mixture retraining and suitable for control applications; prediction cost grows with dataset size, making parsimonious selected datasets advantageous.",
            "optimal_allocation_findings": "Selecting queries that minimize expected predictive variance for LOESS produces faster learning (lower MSE and variance) than random sampling; an automatic, variance-based method to set the kernel smoothing parameter k helps balance bias-variance locally, and the closed-form expected-variance updates allow efficient sequential query selection. Parsimonious training sets produced by active selection reduce future prediction cost.",
            "uuid": "e2590.1",
            "source_info": {
                "paper_title": "Active Learning with Statistical Models",
                "publication_date_yy_mm": "1996-02"
            }
        },
        {
            "name_short": "NN-OED",
            "name_full": "Neural Network Optimal Experiment Design (variance-based)",
            "brief_description": "An application of optimal experimental design to feedforward neural networks where candidate queries are chosen to minimize an approximate expected predictive variance computed via a second-order Taylor expansion around the network parameters.",
            "citation_title": "Information-based objective functions for active data selection",
            "mention_or_use": "mention",
            "system_name": "Neural network optimal experiment design (OED) via expected variance reduction",
            "system_description": "Approximate the predictive variance of a trained neural network at input x by S^2 (∂ŷ/∂w)^T (∂^2 S^2/∂w^2)^{-1} (∂ŷ/∂w), using a Gaussian noise assumption and second-order Taylor expansion around the maximum-likelihood weights. Compute expected post-query variance in closed form under Gaussian P(y|x) assumptions and select inputs that minimize the integrated expected variance. The expectation is differentiable with respect to candidate inputs, permitting gradient-based search for optimal queries.",
            "application_domain": "General supervised learning and function approximation; prior work used it for exploration in neural networks (cited but not experimentally used in this paper).",
            "resource_allocation_strategy": "Greedy sequential selection by minimizing approximate expected integrated predictive variance; leverages differentiability to hillclimb on candidate inputs.",
            "computational_cost_metric": "Computational cost dominated by inversion of a |w| x |w| Hessian matrix per candidate and retraining when incorporating new examples; costs described qualitatively (matrix inversion and retraining expensive).",
            "information_gain_metric": "Approximate expected reduction in predictive variance (derived from the network's parameter covariance approximation), equivalent to an information-based objective under Gaussian noise assumptions.",
            "uses_information_gain": true,
            "exploration_exploitation_mechanism": "Driven entirely by expected-variance minimization; differentiability allows continuous search for queries that most reduce model uncertainty—implicitly trades exploration of uncertain regions vs exploitation of high-impact areas via the integrated variance objective.",
            "diversity_mechanism": "No explicit diversity promotion is described; selection focuses solely on the variance-reduction objective.",
            "uses_diversity_promotion": false,
            "budget_constraint_type": "Computational resources and time (matrix inversion and retraining cost) and number/cost of data acquisitions.",
            "budget_constraint_handling": "The paper notes this approach is computationally expensive (matrix inversions and expensive retraining), suggesting it may be impractical for some real-time settings; alternatives (sampling-based approximations, Markov-chain sampling cited Paass & Kindermann) are referenced to address cost.",
            "breakthrough_discovery_metric": "Not defined in this context.",
            "performance_metrics": "Not evaluated experimentally in this paper; prior references (MacKay, Cohn) report empirical benefits but this paper only reviews the approach and contrasts its computational expense with the closed-form efficient alternatives (mixture and LOESS).",
            "comparison_baseline": "Discussed conceptually relative to random sampling and to the mixture/LOESS methods presented in this paper; no experimental baseline in this paper.",
            "performance_vs_baseline": "Paper states the neural-network OED approach can work well on some problems but is computationally expensive and relies on approximations (Taylor expansion and Gaussian noise assumptions); no quantitative comparison in this paper.",
            "efficiency_gain": "No empirical efficiency numbers in this paper; computational cost is presented as a limiting factor relative to mixture-of-Gaussians and LOESS methods.",
            "tradeoff_analysis": "Paper highlights the tradeoff: neural-network OED can provide statistically optimal queries under its assumptions but at high computational cost and reliance on approximations; alternative statistical models (mixture-of-Gaussians, LOESS) allow efficient and accurate closed-form expected-variance computation without the heavy matrix inversions or retraining costs.",
            "optimal_allocation_findings": "Conclusion: neural-network OED is principled and differentiable, but its computational expense and approximations make it less practical than the mixture and LOESS variance-minimization techniques developed and used in this paper.",
            "uuid": "e2590.2",
            "source_info": {
                "paper_title": "Active Learning with Statistical Models",
                "publication_date_yy_mm": "1996-02"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Information-based objective functions for active data selection",
            "rating": 2
        },
        {
            "paper_title": "Improving generalization with active learning",
            "rating": 2
        },
        {
            "paper_title": "Theory of Optimal Experiments",
            "rating": 2
        },
        {
            "paper_title": "Neural network exploration using optimal experiment design",
            "rating": 1
        },
        {
            "paper_title": "Bayesian classification",
            "rating": 1
        },
        {
            "paper_title": "Training connectionist networks with queries and selective sampling",
            "rating": 1
        }
    ],
    "cost": 0.01422825,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>Active Learning with Statistical Models</h1>
<p>David A. Cohn<br>Zoubin Ghahramani<br>Michael I. Jordan<br>Cohn@HARLEQUIN.COM<br>Zoubin@CS.TORONTO.EDU<br>JORDAN@PSYCHE.MIT.EDU</p>
<p>Center for Biological and Computational Learning
Dept. of Brain and Cognitive Sciences
Massachusetts Institute of Technology
Cambridge, MA 02139 USA</p>
<h4>Abstract</h4>
<p>For many types of machine learning algorithms, one can compute the statistically "optimal" way to select training data. In this paper, we review how optimal data selection techniques have been used with feedforward neural networks. We then show how the same principles may be used to select data for two alternative, statistically-based learning architectures: mixtures of Gaussians and locally weighted regression. While the techniques for neural networks are computationally expensive and approximate, the techniques for mixtures of Gaussians and locally weighted regression are both efficient and accurate. Empirically, we observe that the optimality criterion sharply decreases the number of training examples the learner needs in order to achieve good performance.</p>
<h2>1. Introduction</h2>
<p>The goal of machine learning is to create systems that can improve their performance at some task as they acquire experience or data. In many natural learning tasks, this experience or data is gained interactively, by taking actions, making queries, or doing experiments. Most machine learning research, however, treats the learner as a passive recipient of data to be processed. This "passive" approach ignores the fact that, in many situations, the learner's most powerful tool is its ability to act, to gather data, and to influence the world it is trying to understand. Active learning is the study of how to use this ability effectively.</p>
<p>Formally, active learning studies the closed-loop phenomenon of a learner selecting actions or making queries that influence what data are added to its training set. Examples include selecting joint angles or torques to learn the kinematics or dynamics of a robot arm, selecting locations for sensor measurements to identify and locate buried hazardous wastes, or querying a human expert to classify an unknown word in a natural language understanding problem.</p>
<p>When actions/queries are selected properly, the data requirements for some problems decrease drastically, and some NP-complete learning problems become polynomial in computation time (Angluin, 1988; Baum \&amp; Lang, 1991). In practice, active learning offers its greatest rewards in situations where data are expensive or difficult to obtain, or when the environment is complex or dangerous. In industrial settings each training point may take days to gather and cost thousands of dollars; a method for optimally selecting these points could offer enormous savings in time and money.</p>
<p>There are a number of different goals which one may wish to achieve using active learning. One is optimization, where the learner performs experiments to find a set of inputs that maximize some response variable. An example of the optimization problem would be finding the operating parameters that maximize the output of a steel mill or candy factory. There is an extensive literature on optimization, examining both cases where the learner has some prior knowledge of the parameterized functional form and cases where the learner has no such knowledge; the latter case is generally of greater interest to machine learning practitioners. The favored technique for this kind of optimization is usually a form of response surface methodology (Box \&amp; Draper, 1987), which performs experiments that guide hill-climbing through the input space.</p>
<p>A related problem exists in the field of adaptive control, where one must learn a control policy by taking actions. In control problems, one faces the complication that the value of a specific action may not be known until many time steps after it is taken. Also, in control (as in optimization), one is usually concerned with the performing well during the learning task and must trade of exploitation of the current policy for exploration which may improve it. The subfield of dual control (Fe'ldbaum, 1965) is specifically concerned with finding an optimal balance of exploration and control while learning.</p>
<p>In this paper, we will restrict ourselves to examining the problem of supervised learning: based on a set of potentially noisy training examples $\mathcal{D}=\left{\left(x_{i}, y_{i}\right)\right}<em i="i">{i=1}^{m}$, where $x</em> \in Y$, we wish to learn a general mapping $X \rightarrow Y$. In robot control, the mapping may be state $\times$ action $\rightarrow$ new state; in hazard location it may be sensor reading $\rightarrow$ target position. In contrast to the goals of optimization and control, the goal of supervised learning is to be able to efficiently and accurately predict $y$ for a given $x$.} \in X$ and $y_{i</p>
<p>In active learning situations, the learner itself is responsible for acquiring the training set. Here, we assume it can iteratively select a new input $\tilde{x}$ (possibly from a constrained set), observe the resulting output $\tilde{y}$, and incorporate the new example $(\tilde{x}, \tilde{y})$ into its training set. This contrasts with related work by Plutowski and White (1993), which is concerned with filtering an existing data set. In our case, $\tilde{x}$ may be thought of as a query, experiment, or action, depending on the research field and problem domain. The question we will be concerned with is how to choose which $\tilde{x}$ to try next.</p>
<p>There are many heuristics for choosing $\tilde{x}$, including choosing places where we don't have data (Whitehead, 1991), where we perform poorly (Linden \&amp; Weber, 1993), where we have low confidence (Thrun \&amp; Möller, 1992), where we expect it to change our model (Cohn, Atlas, \&amp; Ladner, 1990, 1994), and where we previously found data that resulted in learning (Schmidhuber \&amp; Storck, 1993). In this paper we will consider how one may select $\tilde{x}$ in a statistically "optimal" manner for some classes of machine learning algorithms. We first briefly review how the statistical approach can be applied to neural networks, as described in earlier work (MacKay, 1992; Cohn, 1994). Then, in Sections 3 and 4 we consider two alternative, statistically-based learning architectures: mixtures of Gaussians and locally weighted regression. Section 5 presents the empirical results of applying statistically-based active learning to these architectures. While optimal data selection for a neural network is computationally expensive and approximate, we find that optimal data selection for the two statistical models is efficient and accurate.</p>
<h1>2. Active Learning - A Statistical Approach</h1>
<p>We begin by defining $P(x, y)$ to be the unknown joint distribution over $x$ and $y$, and $P(x)$ to be the known marginal distribution of $x$ (commonly called the input distribution). We denote the learner's output on input $x$, given training set $\mathcal{D}$ as $\hat{y}(x ; \mathcal{D}) .{ }^{1}$ We can then write the expected error of the learner as follows:</p>
<p>$$
\int_{x} E_{T}\left[(\hat{y}(x ; \mathcal{D})-y(x))^{2} \mid x\right] P(x) d x
$$</p>
<p>where $E_{T}[\cdot]$ denotes expectation over $P(y \mid x)$ and over training sets $\mathcal{D}$. The expectation inside the integral may be decomposed as follows (Geman, Bienenstock, \&amp; Doursat, 1992):</p>
<p>$$
\begin{aligned}
E_{T}\left[(\hat{y}(x ; \mathcal{D})-y(x))^{2} \mid x\right]= &amp; E\left[(y(x)-E[y \mid x])^{2}\right] \
&amp; +\left(E_{\mathcal{D}}[\hat{y}(x ; \mathcal{D})]-E[y \mid x]\right)^{2} \
&amp; +E_{\mathcal{D}}\left[\left(\hat{y}(x ; \mathcal{D})-E_{\mathcal{D}}[\hat{y}(x ; \mathcal{D})])^{2}\right]\right.
\end{aligned}
$$</p>
<p>where $E_{\mathcal{D}}[\cdot]$ denotes the expectation over training sets $\mathcal{D}$ and the remaining expectations on the right-hand side are expectations with respect to the conditional density $P(y \mid x)$. It is important to remember here that in the case of active learning, the distribution of $\mathcal{D}$ may differ substantially from the joint distribution $P(x, y)$.</p>
<p>The first term in Equation 2 is the variance of $y$ given $x$ - it is the noise in the distribution, and does not depend on the learner or on the training data. The second term is the learner's squared bias, and the third is its variance; these last two terms comprise the mean squared error of the learner with respect to the regression function $E[y \mid x]$. When the second term of Equation 2 is zero, we say that the learner is unbiased. We shall assume that the learners considered in this paper are approximately unbiased; that is, that their squared bias is negligible when compared with their overall mean squared error. Thus we focus on algorithms that minimize the learner's error by minimizing its variance:</p>
<p>$$
\sigma_{\hat{y}}^{2} \equiv \sigma_{\hat{y}}^{2}(x)=E_{\mathcal{D}}\left[(\hat{y}(x ; \mathcal{D})-E_{\mathcal{D}}[\hat{y}(x ; \mathcal{D})])^{2}\right]
$$</p>
<p>(For readability, we will drop the explicit dependence on $x$ and $\mathcal{D}$ - unless denoted otherwise, $\hat{y}$ and $\sigma_{\hat{y}}^{2}$ are functions of $x$ and $\mathcal{D}$.) In an active learning setting, we will have chosen the $x$-component of our training set $\mathcal{D}$; we indicate this by rewriting Equation 3 as</p>
<p>$$
\sigma_{\hat{y}}^{2}=\left\langle(\hat{y}-\langle\hat{y}\rangle)^{2}\right\rangle
$$</p>
<p>where $\langle\cdot\rangle$ denotes $E_{\mathcal{D}}[\cdot]$ given a fixed $x$-component of $\mathcal{D}$. When a new input $\tilde{x}$ is selected and queried, and the resulting $(\tilde{x}, \tilde{y})$ added to the training set, $\sigma_{\hat{y}}^{2}$ should change. We will denote the expectation (over values of $\hat{y}$ ) of the learner's new variance as</p>
<p>$$
\left\langle\tilde{\sigma}<em _mathcal_D="\mathcal{D">{\hat{y}}^{2}\right\rangle=E</em>\right]
$$} \cup(\tilde{x}, \tilde{y})}\left[\sigma_{\hat{y}}^{2} \mid \tilde{x</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<h1>2.1 Selecting Data to Minimize Learner Variance</h1>
<p>In this paper we consider algorithms for active learning which select data in an attempt to minimize the value of Equation 4, integrated over $X$. Intuitively, the minimization proceeds as follows: we assume that we have an estimate of $\sigma_{y}^{2}$, the variance of the learner at $x$. If, for some new input $\tilde{x}$, we knew the conditional distribution $P(\tilde{y} \mid \tilde{x})$, we could compute an estimate of the learner's new variance at $x$ given an additional example at $\tilde{x}$. While the true distribution $P(\tilde{y} \mid \tilde{x})$ is unknown, many learning architectures let us approximate it by giving us estimates of its mean and variance. Using the estimated distribution of $\tilde{y}$, we can estimate $\left\langle\tilde{\sigma}_{\tilde{y}}^{2}\right\rangle$, the expected variance of the learner after querying at $\tilde{x}$.</p>
<p>Given the estimate of $\left\langle\tilde{\sigma}<em _tilde_y="\tilde{y">{\tilde{y}}^{2}\right\rangle$, which applies to a given $x$ and a given query $\tilde{x}$, we must integrate $x$ over the input distribution to compute the integrated average variance of the learner. In practice, we will compute a Monte Carlo approximation of this integral, evaluating $\left\langle\tilde{\sigma}</em>$ that minimizes the average expected variance over the reference points, we have a solid statistical basis for choosing new examples.}}^{2}\right\rangle$ at a number of reference points drawn according to $P(x)$. By querying an $\tilde{x</p>
<h3>2.2 Example: Active Learning with a Neural Network</h3>
<p>In this section we review the use of techniques from Optimal Experiment Design (OED) to minimize the estimated variance of a neural network (Fedorov, 1972; MacKay, 1992; Cohn, 1994). We will assume we have been given a learner $\hat{y}=f_{\hat{w}}()$, a training set $\mathcal{D}=\left{\left(x_{i}, y_{i}\right)\right}_{i=1}^{m}$ and a parameter vector estimate $\hat{w}$ that maximizes some likelihood measure given $\mathcal{D}$. If, for example, one assumes that the data were produced by a process whose structure matches that of the network, and that noise in the process outputs is normal and independently identically distributed, then the negative log likelihood of $\hat{w}$ given $\mathcal{D}$ is proportional to</p>
<p>$$
S^{2}=\frac{1}{m} \sum_{i=1}^{m}\left(y_{i}-\hat{y}\left(x_{i}\right)\right)^{2}
$$</p>
<p>The maximum likelihood estimate for $\hat{w}$ is that which minimizes $S^{2}$.
The estimated output variance of the network is</p>
<p>$$
\sigma_{y}^{2} \approx S^{2}\left(\frac{\partial \hat{y}(x)}{\partial w}\right)^{T}\left(\frac{\partial^{2} S^{2}}{\partial w^{2}}\right)^{-1}\left(\frac{\partial \hat{y}(x)}{\partial w}\right), \text { (MacKay, 1992) }
$$</p>
<p>where the true variance is approximated by a second-order Taylor series expansion around $S^{2}$. This estimate makes the assumption that $\partial \hat{y} / \partial w$ is locally linear. Combined with the assumption that $P(y \mid x)$ is Gaussian with constant variance for all $x$, one can derive a closed form expression for $\left\langle\tilde{\sigma}_{\tilde{y}}^{2}\right\rangle$. See Cohn (1994) for details.</p>
<p>In practice, $\partial \hat{y} / \partial w$ may be highly nonlinear, and $P(y \mid x)$ may be far from Gaussian; in spite of this, empirical results show that it works well on some problems (Cohn, 1994). It has the advantage of being grounded in statistics, and is optimal given the assumptions. Furthermore, the expectation is differentiable with respect to $\tilde{x}$. As such, it is applicable in continuous domains with continuous action spaces, and allows hillclimbing to find the $\tilde{x}$ that minimizes the expected model variance.</p>
<p>For neural networks, however, this approach has many disadvantages. In addition to relying on simplifications and assumptions which hold only approximately, the process is computationally expensive. Computing the variance estimate requires inversion of a $|w| \times|w|$ matrix for each new example, and incorporating new examples into the network requires expensive retraining. Paass and Kindermann (1995) discuss a Markov-chain based sampling approach which addresses some of these problems. In the rest of this paper, we consider two "non-neural" machine learning architectures that are much more amenable to optimal data selection.</p>
<h1>3. Mixtures of Gaussians</h1>
<p>The mixture of Gaussians model is a powerful estimation and prediction technique with roots in the statistics literature (Titterington, Smith, \&amp; Makov, 1985); it has, over the last few years, been adopted by researchers in machine learning (Cheeseman et al., 1988; Nowlan, 1991; Specht, 1991; Ghahramani \&amp; Jordan, 1994). The model assumes that the data are produced by a mixture of $N$ multivariate Gaussians $g_{i}$, for $i=1, \ldots, N$ (see Figure 1).</p>
<p>In the context of learning from random examples, one begins by producing a joint density estimate over the input/output space $X \times Y$ based on the training set $\mathcal{D}$. The EM algorithm (Dempster, Laird, \&amp; Rubin, 1977) can be used to efficiently find a locally optimal fit of the Gaussians to the data. It is then straightforward to compute $\hat{y}$ given $x$ by conditioning the joint distribution on $x$ and taking the expected value.
<img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Figure 1: Using a mixture of Gaussians to compute $\hat{y}$. The Gaussians model the data density. Predictions are made by mixing the conditional expectations of each Gaussian given the input $x$.</p>
<p>One benefit of learning with a mixture of Gaussians is that there is no fixed distinction between inputs and outputs - one may specify any subset of the input-output dimensions, and compute expectations on the remaining dimensions. If one has learned a forward model of the dynamics of a robot arm, for example, conditioning on the outputs automatically gives a model of the arm's inverse dynamics. With the mixture model, it is also straightforward to compute the mode of the output, rather than its mean, which obviates many of the problems of learning direct inverse models (Ghahramani \&amp; Jordan, 1994).</p>
<p>For each Gaussian $g_{i}$ we will denote the input/output means as $\mu_{x, i}$ and $\mu_{y, i}$ and variances and covariances as $\sigma_{x, i}^{2}, \sigma_{y, i}^{2}$ and $\sigma_{x y, i}$ respectively. We can then express the probability of point $(x, y)$, given $g_{i}$ as</p>
<p>$$
P(x, y \mid i)=\frac{1}{2 \pi \sqrt{\left|\Sigma_{i}\right|}} \exp \left[-\frac{1}{2}\left(\mathbf{x}-\mu_{i}\right)^{T} \Sigma_{i}^{-1}\left(\mathbf{x}-\mu_{i}\right)\right]
$$</p>
<p>where we have defined</p>
<p>$$
\mathbf{x}=\left[\begin{array}{l}
x \
y
\end{array}\right] \quad \mu_{i}=\left[\begin{array}{l}
\mu_{x, i} \
\mu_{y, i}
\end{array}\right] \quad \Sigma_{i}=\left[\begin{array}{cc}
\sigma_{x, i}^{2} &amp; \sigma_{x y, i} \
\sigma_{x y, i} &amp; \sigma_{y, i}^{2}
\end{array}\right]
$$</p>
<p>In practice, the true means and variances will be unknown, but can be estimated from data via the EM algorithm. The (estimated) conditional variance of $y$ given $x$ is then</p>
<p>$$
\sigma_{y \mid x, i}^{2}=\sigma_{y, i}^{2}-\frac{\sigma_{x y, i}^{2}}{\sigma_{x, i}^{2}}
$$</p>
<p>and the conditional expectation $\hat{y}<em _hat_y="\hat{y">{i}$ and variance $\sigma</em>$ given $x$ are:}, i}^{2</p>
<p>$$
\hat{y}<em i="i" y_="y,">{i}=\mu</em>\right)
$$}+\frac{\sigma_{x y, i}}{\sigma_{x, i}^{2}}\left(x-\mu_{x, i}\right), \quad \sigma_{\hat{y}, i}^{2}=\frac{\sigma_{y \mid x, i}^{2}}{n_{i}}\left(1+\frac{\left(x-\mu_{x, i}\right)^{2}}{\sigma_{x, i}^{2}</p>
<p>Here, $n_{i}$ is the amount of "support" for the Gaussian $g_{i}$ in the training data. It can be computed as</p>
<p>$$
n_{i}=\sum_{j=1}^{m} \frac{P\left(x_{j}, y_{j} \mid i\right)}{\sum_{k=1}^{N} P\left(x_{j}, y_{j} \mid k\right)}
$$</p>
<p>The expectations and variances in Equation 6 are mixed according to the probability that $g_{i}$ has of being responsible for $x$, prior to observing $y$ :</p>
<p>$$
h_{i} \equiv h_{i}(x)=\frac{P(x \mid i)}{\sum_{j=1}^{N} P(x \mid j)}
$$</p>
<p>where</p>
<p>$$
P(x \mid i)=\frac{1}{\sqrt{2 \pi \sigma_{x, i}^{2}}} \exp \left[-\frac{\left(x-\mu_{x, i}\right)^{2}}{2 \sigma_{x, i}^{2}}\right]
$$</p>
<p>For input $x$ then, the conditional expectation $\hat{y}$ of the resulting mixture and its variance may be written:</p>
<p>$$
\hat{y}=\sum_{i=1}^{N} h_{i} \hat{y}<em _hat_y="\hat{y">{i}, \quad \sigma</em>\right)
$$}}^{2}=\sum_{i=1}^{N} \frac{h_{i}^{2} \sigma_{y \mid x, i}^{2}}{n_{i}}\left(1+\frac{\left(x-\mu_{x, i}\right)^{2}}{\sigma_{x, i}^{2}</p>
<p>where we have assumed that the $\hat{y}<em _hat_y="\hat{y">{i}$ are independent in calculating $\sigma</em>$ would be the mode, and a preferable measure of uncertainty would be the (unmixed) variance of the individual Gaussians.}}^{2}$. Both of these terms can be computed efficiently in closed form. It is also worth noting that $\sigma_{\hat{y}}^{2}$ is only one of many variance measures we might be interested in. If, for example, our mapping is stochastically multivalued (that is, if the Gaussians overlapped significantly in the $x$ dimension), we may wish our prediction $\hat{y}$ to reflect the most likely $y$ value. In this case, $\hat{y</p>
<h1>3.1 Active Learning with a Mixture of Gaussians</h1>
<p>In the context of active learning, we are assuming that the input distribution $P(x)$ is known. With a mixture of Gaussians, one interpretation of this assumption is that we know $\mu_{x, i}$ and $\sigma_{x, i}^{2}$ for each Gaussian. In that case, our application of EM will estimate only $\mu_{y, i}, \sigma_{y, i}^{2}$, and $\sigma_{x y, i}$.</p>
<p>Generally however, knowing the input distribution will not correspond to knowing the actual $\mu_{x, i}$ and $\sigma_{x, i}^{2}$ for each Gaussian. We may simply know, for example, that $P(x)$ is uniform, or can be approximated by some set of sampled inputs. In such cases, we must use EM to estimate $\mu_{x, i}$ and $\sigma_{x, i}^{2}$ in addition to the parameters involving $y$. If we simply estimate these values from the training data, though, we will be estimating the joint distribution of $P(\tilde{x}, y \mid i)$ instead of $P(x, y \mid i)$. To obtain a proper estimate, we must correct Equation 5 as follows:</p>
<p>$$
P(x, y \mid i)=P(\tilde{x}, y \mid i) \frac{P(x \mid i)}{P(\tilde{x} \mid i)}
$$</p>
<p>Here, $P(\tilde{x} \mid i)$ is computed by applying Equation 7 given the mean and $x$ variance of the training data, and $P(x \mid i)$ is computed by applying the same equation using the mean and $x$ variance of a set of reference data drawn according to $P(x)$.</p>
<p>If our goal in active learning is to minimize variance, we should select training examples $\tilde{x}$ to minimize $\left\langle\hat{\sigma}<em _tilde_y="\tilde{y">{\tilde{y}}^{2}\right\rangle$. With a mixture of Gaussians, we can compute $\left\langle\hat{\sigma}</em>$ is explicit:}}^{2}\right\rangle$ efficiently. The model's estimated distribution of $\tilde{y}$ given $\tilde{x</p>
<p>$$
P(\tilde{y} \mid \tilde{x})=\sum_{i=1}^{N} \tilde{h}<em i="1">{i} P(\tilde{y} \mid \tilde{x}, i)=\sum</em>}^{N} \tilde{h<em i="i">{i} \mathcal{N}\left(\hat{y}</em>)\right)
$$}(\tilde{x}), \sigma_{y \mid x, i}^{2}(\tilde{x</p>
<p>where $\tilde{h}<em i="i">{i} \equiv h</em>$. The new expectations combine to form the learner's new expected variance}(\tilde{x})$, and $\mathcal{N}\left(\mu, \sigma^{2}\right)$ denotes the normal distribution with mean $\mu$ and variance $\sigma^{2}$. Given this, we can model the change in each $g_{i}$ separately, calculating its expected variance given a new point sampled from $P(\tilde{y} \mid \tilde{x}, i)$ and weight this change by $\tilde{h}_{i</p>
<p>$$
\left\langle\hat{\sigma}<em i="1">{\tilde{y}}^{2}\right\rangle=\sum</em>}^{N} \frac{h_{i}^{2}\left\langle\hat{\sigma<em i="i">{y \mid x, i}^{2}\right\rangle}{n</em>}+\tilde{h<em i="i" x_="x,">{i}}\left(1+\frac{\left(x-\mu</em>\right)
$$}\right)^{2}}{\sigma_{x, i}^{2}</p>
<p>where the expectation can be computed exactly in closed form:</p>
<p>$$
\begin{aligned}
&amp; \left\langle\hat{\sigma}<em i="i">{y, i}^{2}\right\rangle=\frac{n</em>} \sigma_{y, i}^{2}}{n_{i}+\tilde{h<em i="i">{i}}+\frac{n</em>} \tilde{h<em _mid="\mid" _tilde_x="\tilde{x" y="y">{i}\left(\sigma</em>}, i}^{2}+\left(\hat{y<em i="i" y_="y,">{i}(\tilde{x})-\mu</em>}\right)^{2}\right)}{\left(n_{i}+\tilde{h<em _mid="\mid" i="i" x_="x," y="y">{i}\right)^{2}}, \quad\left\langle\hat{\sigma}</em>}^{2}\right\rangle=\left\langle\hat{\sigma<em i="i" x="x" y_="y,">{y, i}^{2}\right\rangle-\frac{\left\langle\hat{\sigma}</em> \
&amp; \left\langle\hat{\sigma}}^{2}\right\rangle}{\sigma_{x, i}^{2}<em i="i">{x y, i}\right\rangle=\frac{n</em>} \sigma_{x y, i}}{n_{i}+\tilde{h<em i="i">{i}}+\frac{n</em>} \tilde{h<em i="i" x_="x,">{i}\left(\tilde{x}-\mu</em>}\right)\left(\hat{y<em i="i" y_="y,">{i}(\tilde{x})-\mu</em>}\right)}{\left(n_{i}+\tilde{h<em i="i" x="x" y_="y,">{i}\right)^{2}}, \quad\left\langle\hat{\sigma}</em>}^{2}\right\rangle=\left\langle\hat{\sigma<em i="i">{x y, i}\right\rangle^{2}+\frac{n</em>}^{2} \tilde{h<em _mid="\mid" _tilde_x="\tilde{x" y="y">{i}^{2} \sigma</em>
\end{aligned}
$$}, i}^{2}\left(\tilde{x}-\mu_{x, i}\right)^{2}}{\left(n_{i}+\tilde{h}_{i}\right)^{4}</p>
<p>If, as discussed earlier, we are also estimating $\mu_{x, i}$ and $\sigma_{x, i}^{2}$, we must take into account the effect of the new example on those estimates, and must replace $\mu_{x, i}$ and $\sigma_{x, i}^{2}$ in the above equations with</p>
<p>$$
\tilde{\mu}<em i="i">{x, i}=\frac{n</em>} \mu_{x, i}+\tilde{h<em i="i">{i} \tilde{x}}{n</em>}+\tilde{h<em i="i" x_="x,">{i}}, \quad \tilde{\sigma}</em>}^{2}=\frac{n_{i} \sigma_{x, i}^{2}}{n_{i}+\tilde{h<em i="i">{i}}+\frac{n</em>} \tilde{h<em i="i" x_="x,">{i}\left(\tilde{x}-\mu</em>
$$}\right)^{2}}{\left(n_{i}+\tilde{h}_{i}\right)^{2}</p>
<p>We can use Equation 9 to guide active learning. By evaluating the expected new variance over a reference set given candidate $\tilde{x}$, we can select the $\tilde{x}$ giving the lowest expected model variance. Note that in high-dimensional spaces, it may be necessary to evaluate an excessive number of candidate points to get good coverage of the potential query space. In these cases, it is more efficient to differentiate Equation 9 and hillclimb on $\partial\left\langle\tilde{\sigma}_{\tilde{y}}^{2}\right\rangle / \partial \tilde{x}$ to find a locally maximal $\tilde{x}$. See, for example, (Cohn, 1994).</p>
<h1>4. Locally Weighted Regression</h1>
<p>Model-based methods, such as neural networks and the mixture of Gaussians, use the data to build a parameterized model. After training, the model is used for predictions and the data are generally discarded. In contrast, "memory-based" methods are non-parametric approaches that explicitly retain the training data, and use it each time a prediction needs to be made. Locally weighted regression (LWR) is a memory-based method that performs a regression around a point of interest using only training data that are "local" to that point. One recent study demonstrated that LWR was suitable for real-time control by constructing an LWR-based system that learned a difficult juggling task (Schaal \&amp; Atkeson, 1994).
<img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Figure 2: In locally weighted regression, points are weighted by proximity to the current $x$ in question using a kernel. A regression is then computed using the weighted points.</p>
<p>We consider here a form of locally weighted regression that is a variant of the LOESS model (Cleveland, Devlin, \&amp; Grosse, 1988). The LOESS model performs a linear regression on points in the data set, weighted by a kernel centered at $x$ (see Figure 2). The kernel shape is a design parameter for which there are many possible choices: the original LOESS model uses a "tricubic" kernel; in our experiments we have used a Gaussian</p>
<p>$$
h_{i}(x) \equiv h\left(x-x_{i}\right)=\exp \left(-k\left(x-x_{i}\right)^{2}\right)
$$</p>
<p>where $k$ is a smoothing parameter. In Section 4.1 we will describe several methods for automatically setting $k$.</p>
<p><img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>Figure 3: The estimator variance is minimized when the kernel includes as many training points as can be accommodated by the model. Here the linear LOESS model is shown. Too large a kernel includes points that degrade the fit; too small a kernel neglects points that increase confidence in the fit.</p>
<p>For brevity, we will drop the argument $x$ for $h_{i}(x)$, and define $n=\sum_{i} h_{i}$. We can then write the estimated means and covariances as:</p>
<p>$$
\begin{aligned}
&amp; \mu_{x}=\frac{\sum_{i} h_{i} x_{i}}{n}, \sigma_{x}^{2}=\frac{\sum_{i} h_{i}\left(x_{i}-\mu_{x}\right)^{2}}{n}, \sigma_{x y}=\frac{\sum_{i} h_{i}\left(x_{i}-\mu_{x}\right)\left(y_{i}-\mu_{y}\right)}{n} \
&amp; \mu_{y}=\frac{\sum_{i} h_{i} y_{i}}{n}, \sigma_{y}^{2}=\frac{\sum_{i} h_{i}\left(y_{i}-\mu_{y}\right)^{2}}{n}, \sigma_{y \mid x}^{2}=\sigma_{y}^{2}-\frac{\sigma_{x y}^{2}}{\sigma_{x}^{2}}
\end{aligned}
$$</p>
<p>We use the data covariances to express the conditional expectations and their estimated variances:</p>
<p>$$
\hat{y}=\mu_{y}+\frac{\sigma_{x y}}{\sigma_{x}^{2}}\left(x-\mu_{x}\right), \quad \sigma_{\hat{y}}^{2}=\frac{\sigma_{y \mid x}^{2}}{n^{2}}\left(\sum_{i} h_{i}^{2}+\frac{\left(x-\mu_{x}\right)^{2}}{\sigma_{x}^{2}} \sum_{i} h_{i}^{2} \frac{\left(x_{i}-\mu_{x}\right)^{2}}{\sigma_{x}^{2}}\right)
$$</p>
<h1>4.1 Setting the Smoothing Parameter $k$</h1>
<p>There are a number of ways one can set $k$, the smoothing parameter. The method used by Cleveland et al. (1988) is to set $k$ such that the reference point being predicted has a predetermined amount of support, that is, $k$ is set so that $n$ is close to some target value. This has the disadvantage of requiring assumptions about the noise and smoothness of the function being learned. Another technique, used by Schaal and Atkeson (1994), sets $k$ to minimize the crossvalidated error on the training set. A disadvantage of this technique is that it assumes the distribution of the training set is representative of $P(x)$, which it may not be in an active learning situation. A third method, also described by Schaal and Atkeson (1994), is to set $k$ so as to minimize the estimate of $\sigma_{\hat{y}}^{2}$ at the reference points. As $k$ decreases, the regression becomes more global. The total weight $n$ will increase (which decreases $\sigma_{y}^{2}$ ), but so will the conditional variance $\sigma_{y \mid x}^{2}$ (which increases $\sigma_{y}^{2}$ ). At some value of $k$, these two quantities will balance to produce a minimum estimated variance (see Figure 3). This estimate can be computed for arbitrary reference points in the domain,</p>
<p>and the user has the option of using either a different $k$ for each reference point or a single global $k$ that minimizes the average $\sigma_{y}^{2}$ over all reference points. Empirically, we found that the variance-based method gave the best performance.</p>
<h1>4.2 Active Learning with Locally Weighted Regression</h1>
<p>As with the mixture of Gaussians, we want to select $\tilde{x}$ to minimize $\left\langle\tilde{\sigma}<em _mid="\mid" _tilde_x="\tilde{x" y="y">{y}^{2}\right\rangle$. To do this, we must estimate the mean and variance of $P(\hat{y} \mid \tilde{x})$. With locally weighted regression, these are explicit: the mean is $\hat{y}(\tilde{x})$ and the variance is $\sigma</em>$ by the kernel we can compute these expectations exactly in closed form. For the LOESS model, the learner's expected new variance is}}^{2}$. The estimate of $\left\langle\tilde{\sigma}_{y}^{2}\right\rangle$ is also explicit. Defining $\tilde{h}$ as the weight assigned to $\tilde{x</p>
<p>$$
\left\langle\tilde{\sigma}<em _mid="\mid" x="x" y="y">{y}^{2}\right\rangle=\frac{\left\langle\tilde{\sigma}</em>}^{2}\right\rangle}{(n+\tilde{h})^{2}}\left[\sum_{i} h_{i}^{2}+\tilde{h}^{2}+\frac{\left(x-\tilde{\mu<em x="x">{x}\right)^{2}}{\tilde{\sigma}</em>}^{2}}\left(\sum_{i} h_{i}^{2} \frac{\left(x_{i}-\tilde{\mu<em x="x">{x}\right)^{2}}{\tilde{\sigma}</em>}^{2}}+\tilde{h}^{2} \frac{\left(\tilde{x}-\tilde{\mu<em x="x">{x}\right)^{2}}{\tilde{\sigma}</em>\right)\right]
$$}^{2}</p>
<p>Note that, since $\sum_{i} h_{i}^{2}\left(x_{i}-\mu_{x}\right)^{2}=\sum_{i} h_{i}^{2} x_{i}^{2}+\mu_{x}^{2} \sum_{i} h_{i}^{2}-2 \mu_{x} \sum_{i} h_{i}^{2} x_{i}$, the new expectation of Equation 11 may be efficiently computed by caching the values of $\sum_{i} h_{i}^{2} x_{i}^{2}$ and $\sum_{i} h_{i}^{2} x_{i}$. This obviates the need to recompute the entire sum for each new candidate point. The component expectations in Equation 11 are computed as follows:</p>
<p>$$
\begin{aligned}
\left\langle\tilde{\sigma}<em y="y">{y \mid x}^{2}\right\rangle=\left\langle\tilde{\sigma}</em>}^{2}\right\rangle-\frac{\left\langle\tilde{\sigma<em x="x">{x y}^{2}\right\rangle}{\tilde{\sigma}</em>}^{2}}, &amp; \left\langle\tilde{\sigma<em y="y">{y}^{2}\right\rangle=\frac{n \sigma</em> \
\tilde{\mu}}^{2}}{n+\tilde{h}}+\frac{n \tilde{h}\left(\sigma_{y \mid \tilde{x}}^{2}+\left(\hat{y}(\tilde{x})-\mu_{y}\right)^{2}\right)}{(n+\tilde{h})^{2}<em x="x">{x}=\frac{n \mu</em>}+\tilde{h} \tilde{x}}{n+\tilde{h}}, &amp; \left\langle\tilde{\sigma<em x="x" y="y">{x y}\right\rangle=\frac{n \sigma</em> \
\tilde{\sigma}}}{n+\tilde{h}}+\frac{n \tilde{h}\left(\tilde{x}-\mu_{x}\right)\left(\hat{y}(\tilde{x})-\mu_{y}\right)}{(n+\tilde{h})^{2}<em x="x">{x}^{2}=\frac{n \sigma</em>}^{2}}{n+\tilde{h}}+\frac{n \tilde{h}\left(\tilde{x}-\mu_{x}\right)^{2}}{(n+\tilde{h})^{2}}, &amp; \left\langle\tilde{\sigma<em x="x" y="y">{x y}^{2}\right\rangle=\left\langle\tilde{\sigma}</em>
\end{aligned}
$$}\right\rangle^{2}+\frac{n^{2} \tilde{h}^{2} \sigma_{y \mid \tilde{x}}^{2}\left(\tilde{x}-\mu_{x}\right)^{2}}{(n+\tilde{h})^{4}</p>
<p>Just as with the mixture of Gaussians, we can use the expectation in Equation 11 to guide active learning.</p>
<h2>5. Experimental Results</h2>
<p>For an experimental testbed, we used the "Arm2D" problem described by Cohn (1994). The task is to learn the kinematics of a toy 2-degree-of-freedom robot arm (see Figure 4). The inputs are joint angles $\left(\Theta_{1}, \Theta_{2}\right)$, and the outputs are the Cartesian coordinates of the tip $\left(X_{1}, X_{2}\right)$. One of the implicit assumptions of both models described here is that the noise is Gaussian in the output dimensions. To test the robustness of the algorithm to this assumption, we ran experiments using no noise, using additive Gaussian noise in the outputs, and using additive Gaussian noise in the inputs. The results of each were comparable; we report here the results using additive Gaussian noise in the inputs. Gaussian input noise corresponds to the case where the arm effectors or joint angle sensors are noisy, and results in non-Gaussian errors in the learner's outputs. The input distribution $P(x)$ is assumed to be uniform.</p>
<p>We compared the performance of the variance-minimizing criterion by comparing the learning curves of a learner using the criterion with that of one learning from random</p>
<p><img alt="img-3.jpeg" src="img-3.jpeg" /></p>
<p>Figure 4: The arm kinematics problem. The learner attempts to predict tip position given a set of joint angles $\left(\theta_{1}, \theta_{2}\right)$.
samples. The learning curves plot the mean squared error and variance of the learner as its training set size increases. The curves are created by starting with an initial sample, measuring the learner's mean squared error or estimated variance on a set of "reference" points (independent of the training set), selecting and adding a new example to the training set, retraining the learner on the augmented set, and repeating.</p>
<p>On each step, the variance-minimizing learner chose a set of 64 unlabeled reference points drawn from input distribution $P(x)$. It then selected a query $\tilde{x}=\left(\theta_{1}, \theta_{2}\right)$ that it estimated would minimize $\left\langle\tilde{\sigma}_{y \mid x}^{2}\right\rangle$ over the reference set. In the experiments reported here, the best $\tilde{x}$ was selected from another set of 64 "candidate" points drawn at random on each iteration. ${ }^{2}$</p>
<h1>5.1 Experiments with Mixtures of Gaussians</h1>
<p>With the mixtures of Gaussians model, there are three design parameters that must be considered - the number of Gaussians, their initial placement, and the number of iterations of the EM algorithm. We set these parameters by optimizing them on the learner using random examples, then used the same settings on the learner using the varianceminimization criterion. Parameters were set as follows: Models with fewer Gaussians have the obvious advantage of requiring less storage space and computation. Intuitively, a small model should also have the advantage of avoiding overfitting, which is thought to occur in systems with extraneous parameters. Empirically, as we increased the number of Gaussians, generalization improved monotonically with diminishing returns (for a fixed training set size and number of EM iterations). The test error of the larger models generally matched that of the smaller models on small training sets (where overfitting would be a concern), and continued to decrease on large training sets where the smaller networks "bottomed out." We therefore preferred the larger mixtures, and report here our results with mixtures of 60 Gaussians. We selected initial placement of the Gaussians randomly, chosen uniformly from the smallest hypercube containing all current training examples. We arbitrarily chose the</p>
<p><sup id="fnref2:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>identity matrix as an initial covariance matrix. The learner was surprisingly sensitive to the number of EM iterations. We examined a range of 5 to 40 iterations of the EM algorithm per step. Small numbers of iterations (5-10) appear insufficent to allow convergence with large training sets, while large numbers of iterations (30-40) degraded performance on small training sets. An ideal training regime would employ some form of regularization, or would examine the degree of change between iterations to detect convergence; in our experiments, however, we settled on a fixed regime of 20 iterations per step.
<img alt="img-4.jpeg" src="img-4.jpeg" /></p>
<p>Figure 5: Variance and MSE learning curves for mixture of 60 Gaussians trained on the Arm2D domain. Dotted lines denote standard error for average of 10 runs, each started with one initial random example.</p>
<p>Figure 5 plots the variance and MSE learning curves for a mixture of 60 Gaussians trained on the Arm2D domain with $1 \%$ input noise added. The estimated model variance using the variance-minimizing criterion is significantly better than that of the learner selecting data at random. The mean squared error, however, exhibits even greater improvement, with an error that is consistently $1 / 3$ that of the randomly sampling learner.</p>
<h1>5.2 Experiments with LOESS Regression</h1>
<p>With LOESS, the design parameters are the the size and shape of the kernel. As described earlier, we arbitrarily chose to work with a Gaussian kernel; we used the variance-based method for automatically selecting the kernel size.</p>
<p>In the case of LOESS, both the variance and the MSE of the learner using the varianceminimizing criterion are significantly lower than those of the learner selecting data randomly. It is worth noting that on the Arm2D domain, this form of locally weighted regression also significantly outperforms both the mixture of Gaussians and the neural networks discussed by Cohn (1994).</p>
<p><img alt="img-5.jpeg" src="img-5.jpeg" /></p>
<p>Figure 6: Variance and MSE learning curves for LOESS model trained on the Arm2D domain. Dotted lines denote standard error for average of 60 runs, each started with a single initial random example.</p>
<h1>5.3 Computation Time</h1>
<p>One obvious concern about the criterion described here is its computational cost. In situations where obtaining new examples may take days and cost thousands of dollars, it is clearly wise to expend computation to ensure that those examples are as useful as possible. In other situations, however, new data may be relatively inexpensive, so the computational cost of finding optimal examples must be considered.</p>
<p>Table 1 summarizes the computation times for the two learning algorithms discussed in this paper. ${ }^{3}$ Note that, with the mixture of Gaussians, training time depends linearly on the number of examples, but prediction time is independent. Conversely, with locally weighted regression, there is no "training time" per se, but the cost of additional examples accrues when predictions are made using the training set.</p>
<p>While the training time incurred by the mixture of Gaussians may make it infeasible for selecting optimal action learning actions in realtime control, it is certainly fast enough to be used in many applications. Optimized, parallel implementations will also enhance its utility. ${ }^{4}$ Locally weighted regression is certainly fast enough for many control applications, and may be made faster still by optimized, parallel implementations. It is worth noting</p>
<p><sup id="fnref3:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<table>
<thead>
<tr>
<th style="text-align: left;"></th>
<th style="text-align: left;">Training</th>
<th style="text-align: left;">Evaluating Reference</th>
<th style="text-align: left;">Evaluating Candidates</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Mixture</td>
<td style="text-align: left;">$3.9+0.05 m \mathrm{sec}$</td>
<td style="text-align: left;">$15000 \mu \mathrm{sec}$</td>
<td style="text-align: left;">$1300 \mu \mathrm{sec}$</td>
</tr>
<tr>
<td style="text-align: left;">LOESS</td>
<td style="text-align: left;">-</td>
<td style="text-align: left;">$92+9.7 m \mu \mathrm{sec}$</td>
<td style="text-align: left;">$58+0.16 m \mu \mathrm{sec}$</td>
</tr>
</tbody>
</table>
<p>Table 1: Computation times on a Sparc 10 as a function of training set size $m$. Mixture model had 60 Gaussians trained for 20 iterations. Reference times are per reference point; candidate times are per candidate point per reference point.
that, since the prediction speed of these learners depends on their training set size, optimal data selection is doubly important, as it creates a parsimonious training set that allows faster predictions on future points.</p>
<h1>6. Discussion</h1>
<p>Mixtures of Gaussians and locally weighted regression are two statistical models that offer elegant representations and efficient learning algorithms. In this paper we have shown that they also offer the opportunity to perform active learning in an efficient and statistically correct manner. The criteria derived here can be computed cheaply and, for problems tested, demonstrate good predictive power. In industrial settings, where gathering a single data point may take days and cost thousands of dollars, the techniques described here have the potential for enormous savings.</p>
<p>In this paper, we have only considered function approximation problems. Problems requiring classification could be handled analogously with the appropriate models. For learning classification with a mixture model, one would select examples so as to maximize discriminability between Gaussians; for locally weighted regression, one would use a logistic regression instead of the linear one considered here (Weisberg, 1985).</p>
<p>Our future work will proceed in several directions. The most important is active bias minimization. As noted in Section 2, the learner's error is composed of both bias and variance. The variance-minimizing strategy examined here ignores the bias component, which can lead to significant errors when the learner's bias is non-negligible. Work in progress examines effective ways of measuring and optimally eliminating bias (Cohn, 1995); future work will examine how to jointly minimize both bias and variance to produce a criterion that truly minimizes the learner's expected error.</p>
<p>Another direction for future research is the derivation of variance- (and bias-) minimizing techniques for other statistical learning models. Of particular interest is the class of models known as "belief networks" or "Bayesian networks" (Pearl, 1988; Heckerman, Geiger, \&amp; Chickering, 1994). These models have the advantage of allowing inclusion of domain knowledge and prior constraints while still adhering to a statistically sound framework. Current research in belief networks focuses on algorithms for efficient inference and learning; it would be an important step to derive the proper criteria for learning actively with these models.</p>
<h1>Appendix A. Notation</h1>
<table>
<thead>
<tr>
<th style="text-align: center;"></th>
<th style="text-align: center;">General</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">$X$</td>
<td style="text-align: center;">input space</td>
</tr>
<tr>
<td style="text-align: center;">$Y$</td>
<td style="text-align: center;">output space</td>
</tr>
<tr>
<td style="text-align: center;">$x$</td>
<td style="text-align: center;">an arbitrary point in the input space</td>
</tr>
<tr>
<td style="text-align: center;">$y$</td>
<td style="text-align: center;">true output value corresponding to input $x$</td>
</tr>
<tr>
<td style="text-align: center;">$\hat{y}$</td>
<td style="text-align: center;">predicted output value corresponding to input $x$</td>
</tr>
<tr>
<td style="text-align: center;">$x_{i}$</td>
<td style="text-align: center;">"input" part of example $i$</td>
</tr>
<tr>
<td style="text-align: center;">$y_{i}$</td>
<td style="text-align: center;">"output" part of example $i$</td>
</tr>
<tr>
<td style="text-align: center;">$m$</td>
<td style="text-align: center;">the number of examples in the training set</td>
</tr>
<tr>
<td style="text-align: center;">$\tilde{x}$</td>
<td style="text-align: center;">specified input of a query</td>
</tr>
<tr>
<td style="text-align: center;">$\tilde{y}$</td>
<td style="text-align: center;">the (possibly not yet known) output of query $\tilde{x}$</td>
</tr>
<tr>
<td style="text-align: center;">$\sigma_{\tilde{y}}^{2}$</td>
<td style="text-align: center;">estimated variance of $\hat{y}$</td>
</tr>
<tr>
<td style="text-align: center;">$\hat{\sigma}_{\hat{y}}^{2}$</td>
<td style="text-align: center;">new variance of $\hat{y}$, after example $(\tilde{x}, \tilde{y})$ has been added</td>
</tr>
<tr>
<td style="text-align: center;">$\left\langle\hat{\sigma}_{\hat{y}}^{2}\right\rangle$</td>
<td style="text-align: center;">the expected value of $\hat{\sigma}_{\hat{y}}^{2}$</td>
</tr>
<tr>
<td style="text-align: center;">$P(x)$</td>
<td style="text-align: center;">the (known) natural distribution over $x$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Neural Network</td>
</tr>
<tr>
<td style="text-align: center;">$w$</td>
<td style="text-align: center;">a weight vector for a neural network</td>
</tr>
<tr>
<td style="text-align: center;">$\hat{w}$</td>
<td style="text-align: center;">estimated "best" $w$ given a training set</td>
</tr>
<tr>
<td style="text-align: center;">$f_{\hat{w}}()$</td>
<td style="text-align: center;">function computed by neural network given $\hat{w}$</td>
</tr>
<tr>
<td style="text-align: center;">$S^{2}$</td>
<td style="text-align: center;">average estimated noise in data, used as an estimate for $\sigma_{y}^{2}$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Mixture of Gaussians</td>
</tr>
<tr>
<td style="text-align: center;">$N$</td>
<td style="text-align: center;">total number of Gaussians</td>
</tr>
<tr>
<td style="text-align: center;">$g_{i}$</td>
<td style="text-align: center;">Gaussian number $i$</td>
</tr>
<tr>
<td style="text-align: center;">$n_{i}$</td>
<td style="text-align: center;">total point weighting attributed to Gaussian $i$</td>
</tr>
<tr>
<td style="text-align: center;">$\mu_{x, i}$</td>
<td style="text-align: center;">estimated $x$ mean of Gaussian $i$</td>
</tr>
<tr>
<td style="text-align: center;">$\mu_{y, i}$</td>
<td style="text-align: center;">estimated $y$ mean of Gaussian $i$</td>
</tr>
<tr>
<td style="text-align: center;">$\sigma_{x, i}^{2}$</td>
<td style="text-align: center;">estimated $x$ variance of Gaussian $i$</td>
</tr>
<tr>
<td style="text-align: center;">$\sigma_{y, i}^{2}$</td>
<td style="text-align: center;">estimated $y$ variance of Gaussian $i$</td>
</tr>
<tr>
<td style="text-align: center;">$\sigma_{x y, i}$</td>
<td style="text-align: center;">estimated $x y$ covariance of Gaussian $i$</td>
</tr>
<tr>
<td style="text-align: center;">$\sigma_{y \mid x, i}^{2}$</td>
<td style="text-align: center;">estimated $y$ variance of Gaussian $i$, given $x$</td>
</tr>
<tr>
<td style="text-align: center;">$P(x, y \mid i)$</td>
<td style="text-align: center;">joint distribution of input-output pair given Gaussian $i$</td>
</tr>
<tr>
<td style="text-align: center;">$P(x \mid i)$</td>
<td style="text-align: center;">distribution $x$ being given Gaussian $i$</td>
</tr>
<tr>
<td style="text-align: center;">$h_{i}$</td>
<td style="text-align: center;">weight of a given point that is attributed to Gaussian $i$</td>
</tr>
<tr>
<td style="text-align: center;">$\hat{h}_{i}$</td>
<td style="text-align: center;">weight of new point $(\tilde{x}, \tilde{y})$ that is attributed to Gaussian $i$</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Locally Weighted Regression</td>
</tr>
<tr>
<td style="text-align: center;">$k$</td>
<td style="text-align: center;">kernel smoothing parameter</td>
</tr>
<tr>
<td style="text-align: center;">$h_{i}$</td>
<td style="text-align: center;">weight given to example $i$ by kernel centered at $x$</td>
</tr>
<tr>
<td style="text-align: center;">$n$</td>
<td style="text-align: center;">sum of weights given to all points by kernel</td>
</tr>
<tr>
<td style="text-align: center;">$\mu_{x}$</td>
<td style="text-align: center;">mean of inputs, weighted by kernel centered at $x$</td>
</tr>
<tr>
<td style="text-align: center;">$\mu_{y}$</td>
<td style="text-align: center;">mean of outputs, weighted by kernel centered at $x$</td>
</tr>
<tr>
<td style="text-align: center;">$\hat{h}$</td>
<td style="text-align: center;">weight of new point $(\tilde{x}, \tilde{y})$ given kernel centered at $x$</td>
</tr>
</tbody>
</table>
<h1>Acknowledgements</h1>
<p>David Cohn's current address is: Harlequin, Inc., One Cambridge Center, Cambridge, MA 02142 USA. Zoubin Ghahramani's current address is: Department of Computer Science, University of Toronto, Toronto, Ontario M5S 1A4 CANADA. This work was funded by NSF grant CDA-9309300, the McDonnell-Pew Foundation, ATR Human Information Processing Laboratories and Siemens Corporate Research. We are deeply indebted to Michael Titterington and Jim Kay, whose careful attention and continued kind help allowed us to make several corrections to an earlier version of this paper.</p>
<h2>References</h2>
<p>Angluin, D. (1988). Queries and concept learning. Machine Learning, 2, 319-342.
Baum, E., \&amp; Lang, K. (1991). Neural network algorithms that learn in polynomial time from examples and queries. IEEE Trans. Neural Networks, 2.</p>
<p>Box, G., \&amp; Draper, N. (1987). Empirical model-building and response surfaces. Wiley.
Cheeseman, P., Self, M., Kelly, J., Taylor, W., Freeman, D., \&amp; Stutz, J. (1988). Bayesian classification. In AAAI 88, The 7th National Conference on Artificial Intelligence, pp. 607-611. AAAI Press.</p>
<p>Cleveland, W., Devlin, S., \&amp; Grosse, E. (1988). Regression by local fitting. Journal of Econometrics, 37, 87-114.</p>
<p>Cohn, D. (1994). Neural network exploration using optimal experiment design. In Cowan, J., Tesauro, G., \&amp; Alspector, J. (Eds.), Advances in Neural Information Processing Systems 6. Morgan Kaufmann. Expanded version available as MIT AI Lab memo 1491 by anonymous ftp to publications.ai.mit.edu.</p>
<p>Cohn, D. (1995). Minimizing statistical bias with queries. AI Lab memo AIM1552, Massachusetts Institute of Technology. Available by anonymous ftp from publications.ai.mit.edu.</p>
<p>Cohn, D., Atlas, L., \&amp; Ladner, R. (1990). Training connectionist networks with queries and selective sampling. In Touretzky, D. (Ed.), Advances in Neural Information Processing Systems 2. Morgan Kaufmann.</p>
<p>Cohn, D., Atlas, L., \&amp; Ladner, R. (1994). Improving generalization with active learning. Machine Learning, 5(2), 201-221.</p>
<p>Dempster, A., Laird, N., \&amp; Rubin, D. (1977). Maximum likelihood from incomplete data via the EM algorithm. J. Royal Statistical Society Series B, 39, 1-38.</p>
<p>Fedorov, V. (1972). Theory of Optimal Experiments. Academic Press.
Fe’ldbaum, A. A. (1965). Optimal control systems. Academic Press, New York, NY.</p>
<p>Geman, S., Bienenstock, E., \&amp; Doursat, R. (1992). Neural networks and the bias/variance dilemma. Neural Computation, 4, 1-58.</p>
<p>Ghahramani, Z., \&amp; Jordan, M. (1994). Supervised learning from incomplete data via an EM approach. In Cowan, J., Tesauro, G., \&amp; Alspector, J. (Eds.), Advances in Neural Information Processing Systems 6. Morgan Kaufmann.</p>
<p>Heckerman, D., Geiger, D., \&amp; Chickering, D. (1994). Learning Bayesian networks: the combination of knowledge and statistical data. Tech report MSR-TR-94-09, Microsoft.</p>
<p>Linden, A., \&amp; Weber, F. (1993). Implementing inner drive by competence reflection. In Roitblat, H. (Ed.), Proceedings of the 2nd International Conference on Simulation of Adaptive Behavior. MIT Press, Cambridge, MA.</p>
<p>MacKay, D. J. (1992). Information-based objective functions for active data selection. Neural Computation, 4(4), 590-604.</p>
<p>Nowlan, S. (1991). Soft competitive adaptation: Neural network learning algorithms based on fitting statistical mixtures. Tech report CS-91-126, Carnegie Mellon University.</p>
<p>Paass, G., \&amp; Kindermann, J. (1995). Bayesian query construction for neural network models. In Tesauro, G., Touretzky, D., \&amp; Leen, T. (Eds.), Advances in Neural Information Processing Systems 7. MIT Press.</p>
<p>Pearl, J. (1988). Probablistic Reasoning in Intelligent Systems. Morgan Kaufmann.
Plutowski, M., \&amp; White, H. (1993). Selecting concise training sets from clean data. IEEE Transactions on Neural Networks, 4, 305-318.</p>
<p>Schaal, S., \&amp; Atkeson, C. (1994). Robot juggling: An implementation of memory-based learning. Control Systems, 14, 57-71.</p>
<p>Schmidhuber, J., \&amp; Storck, J. (1993). Reinforcement driven information acquisition in nondeterministic environments. Tech report, Fakultät für Informatik, Technische Universität München.</p>
<p>Specht, D. (1991). A general regression neural network. IEEE Trans. Neural Networks, $2(6), 568-576$.</p>
<p>Thrun, S., \&amp; Möller, K. (1992). Active exploration in dynamic environments. In Moody, J., Hanson, S., \&amp; Lippmann, R. (Eds.), Advances in Neural Information Processing Systems 4. Morgan Kaufmann.</p>
<p>Titterington, D., Smith, A., \&amp; Makov, U. (1985). Statistical Analysis of Finite Mixture Distributions. Wiley.</p>
<p>Weisberg, S. (1985). Applied Linear Regression. Wiley.
Whitehead, S. (1991). A study of cooperative mechanisms for faster reinforcement learning. Technical report CS-365, University of Rochester, Rochester, NY.</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<ol>
<li>The times reported are "per reference point" and "per candidate per reference point"; overall time must be computed from the number of candidates and reference points examined. In the case of the LOESS model, for example, with 100 training points, 64 reference points and 64 candidate points, the time required to select an action would be $(58+0.16 \times 100) \times 4096 \mu$ seconds, or about 0.3 seconds.</li>
<li>It is worth mentioning that approximately half of the training time for the mixture of Gaussians is spent computing the correction factor in Equation 8. Without the correction, the learner still computes $P(g \mid x)$, but does so by modeling the training set distribution rather than the reference distribution. We have found however, that for the problems examined, the performance of such "uncorrected" learners does not differ appreciably from that of the "corrected" learners.</li>
</ol>
<p><a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref3:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>