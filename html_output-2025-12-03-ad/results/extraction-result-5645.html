<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-5645 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-5645</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-5645</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-115.html">extraction-schema-115</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or structured/tabular data, including details of the models, methods, datasets, types of anomalies, performance, and comparisons to traditional methods.</div>
                <p><strong>Paper ID:</strong> paper-270045460</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2405.15370v1.pdf" target="_blank">Large Language Models can Deliver Accurate and Interpretable Time Series Anomaly Detection</a></p>
                <p><strong>Paper Abstract:</strong> Time series anomaly detection (TSAD) plays a crucial role in various industries by identifying atypical patterns that deviate from standard trends, thereby maintaining system integrity and enabling prompt response measures. Traditional TSAD models, which often rely on deep learning, require extensive training data and operate as black boxes, lacking interpretability for detected anomalies. To address these challenges, we propose LLMAD, a novel TSAD method that employs Large Language Models (LLMs) to deliver accurate and interpretable TSAD results. LLMAD innovatively applies LLMs for in-context anomaly detection by retrieving both positive and negative similar time series segments, significantly enhancing LLMs' effectiveness. Furthermore, LLMAD employs the Anomaly Detection Chain-of-Thought (AnoCoT) approach to mimic expert logic for its decision-making process. This method further enhances its performance and enables LLMAD to provide explanations for their detections through versatile perspectives, which are particularly important for user decision-making. Experiments on three datasets indicate that our LLMAD achieves detection performance comparable to state-of-the-art deep learning methods while offering remarkable interpretability for detections. To the best of our knowledge, this is the first work that directly employs LLMs for TSAD.</p>
                <p><strong>Cost:</strong> 0.016</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e5645.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e5645.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or structured/tabular data, including details of the models, methods, datasets, types of anomalies, performance, and comparisons to traditional methods.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LLMAD</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Large Language Model Anomaly Detection (LLMAD)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A prompt-based, few-shot framework that uses pretrained LLMs (primarily GPT-4) for point-wise time series anomaly detection by retrieving similar normal/abnormal examples (ICL) and applying an Anomaly Detection Chain-of-Thought (AnoCoT) for expert-like stepwise reasoning and interpretable natural-language explanations.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-4 (GPT-4-1106-preview / GPT-4-turbo-1106)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Pretrained generative transformer LLM used as an inference engine with prompt engineering (no fine-tuning). Uses few-shot in-context learning examples and chain-of-thought style prompts (AnoCoT). API-based call (GPT-4-turbo variant for cost/latency evaluation).</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_detection_method</strong></td>
                            <td>Prompt-based few-shot in-context learning (ICL) with retrieved positive (anomalous) and negative (normal) examples, Anomaly Detection Chain-of-Thought (AnoCoT) prompting for step-wise expert reasoning, preprocessing (rescaling, index tabularization), and windowed evaluation; outputs anomaly indices, anomaly type, alarm level, and textual explanations. No LLM fine-tuning.</td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Univariate time series (converted to tabular Index-Value format; sequences/windows of time series data)</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>Point and segment anomalies including SingleSpike, SingleDip, MultipleSpikes, MultipleDips, PersistentLevelShiftUp/Down, TransientLevelShiftUp/Down (eight types defined)</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td>KPI, WSD, Yahoo (public TSAD benchmarks)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Best F1 and Delayed F1. Reported LLMAD: KPI Best F1 0.843 / Delayed F1 0.667; WSD Best F1 0.711 / Delayed F1 0.401; Yahoo Best F1 0.724 / Delayed F1 0.695; Average Best F1 0.759 / Average Delayed F1 0.588.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Compared to a range of statistical and deep-learning baselines (SPOT, SRCNN, DONUT, VQRAE, AnoTransfer, Informer, TFAD, Anomaly-Transformer, and LLMTIME), LLMAD achieved the best average Best F1 across datasets and second-best average Delayed F1. It substantially outperformed LLMTIME (a zero-shot LLM forecasting baseline) and many classical/statistical methods, while matching or exceeding several SOTA DL detectors on Best F1.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Higher inference latency and API cost compared to lightweight/traditional detectors; window-size limitations (can miss very long-duration anomalies spanning many windows); reliance on well-crafted prompts and injected domain knowledge (requires one-time expert involvement); some datasets' annotation conventions (e.g., only marking a single critical point in a level shift) can reduce measured precision; near-real-time constraints may be problematic.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Large Language Models can Deliver Accurate and Interpretable Time Series Anomaly Detection', 'publication_date_yy_mm': '2024-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5645.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e5645.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or structured/tabular data, including details of the models, methods, datasets, types of anomalies, performance, and comparisons to traditional methods.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>AnoCoT</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Anomaly Detection Chain-of-Thought (AnoCoT)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A domain-tailored Chain-of-Thought prompting strategy that injects judgment rules, anomaly-type definitions, and alarm-level criteria into LLM prompts and enforces an expert-like three-step inference (global trend, local anomaly, reassessment) to improve detection accuracy and produce interpretable explanations.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Used with foundation LLMs (GPT-4 primarily) as a prompting technique rather than a standalone model</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Prompt engineering technique: structured stepwise reasoning + explicit textual domain knowledge injected into prompts to guide LLM inference.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_detection_method</strong></td>
                            <td>Chain-of-Thought style prompting with domain-knowledge injection (judgment rules, anomaly type definitions, alarm criteria) to elicit stepwise reasoning and produce both detection decisions and human-readable explanations; used in a few-shot ICL context.</td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Univariate time series (sequences/windows)</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>Same set defined for LLMAD (spikes, dips, persistent/transient level shifts, multiple occurrences)</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td>KPI, WSD, Yahoo (used within LLMAD experiments)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Ablation results: CoT (standard chain-of-thought) improved Best F1 by ~9.5% on average vs. no-CoT; AnoCoT (domain-injected CoT) further improved Best F1 by ~6.2% over standard CoT. Human eval: AnoCoT improved explanation usefulness by 13.4% and readability by 3.5% vs standard CoT (averages across raters).</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Compared to no-CoT and standard CoT within the same LLMAD pipeline — AnoCoT produced higher Best F1 and better human-judged explanation quality.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Adds modest additional token usage and latency (<100 tokens extra and a few seconds increase); effectiveness depends on quality and completeness of injected domain knowledge and carefully designed step definitions.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Large Language Models can Deliver Accurate and Interpretable Time Series Anomaly Detection', 'publication_date_yy_mm': '2024-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5645.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e5645.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or structured/tabular data, including details of the models, methods, datasets, types of anomalies, performance, and comparisons to traditional methods.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Time-series ICL + FastDTW retrieval</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Time Series In-Context Learning with FastDTW-based retrieval</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A retrieval-augmented few-shot strategy that finds top-k similar normal and anomalous historical time series using FastDTW and supplies them as examples for LLM in-context learning to better delineate normal vs anomalous patterns.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Used with LLM inference (GPT-4) as a retrieval/ICL component</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>FastDTW (approximate Dynamic Time Warping) used to compute similarity between series for retrieval; retrieved series are embedded as few-shot examples into LLM prompts to activate ICL.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_detection_method</strong></td>
                            <td>Few-shot prompt-based detection where K_positive most-similar anomalous series and K_negative most-similar normal series are retrieved via FastDTW and included in the prompt as demonstrations for the LLM (dynamic retrieval preferred over fixed examples).</td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Univariate time series (sequences/windows), stored in a time series example database</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>Used to teach the LLM the signal patterns for the same anomaly types (spikes, dips, level shifts etc.)</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td>KPI, WSD, Yahoo (used in LLMAD experiments)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Ablation/Table 3: ICL (few-shot) significantly boosts Best F1 and Delayed F1 vs zero-shot. Dynamic retrieval outperforms fixed samples. Best observed trade-off: 2 positive (anomalous) / 1 negative (normal) examples provided good performance (performance increase flattens beyond ~2 pos/1 neg). Specific table values: e.g., Dynamic 2 pos/1 neg for KPI Best F1 0.843 / Delayed 0.667 (LLMAD overall).</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Enables LLM to outperform zero-shot LLM approaches (e.g., LLMTIME) and close the gap with SOTA trained detectors by providing dataset-specific context; dynamic retrieved examples perform better than static few-shot examples.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Computational cost of FastDTW retrieval for very large databases (although FastDTW is faster than full DTW); retrieval quality depends on database breadth (anomalies are rare so anomaly DB is pooled across subsets); excessive examples may be redundant and increase token/latency cost.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Large Language Models can Deliver Accurate and Interpretable Time Series Anomaly Detection', 'publication_date_yy_mm': '2024-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5645.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e5645.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or structured/tabular data, including details of the models, methods, datasets, types of anomalies, performance, and comparisons to traditional methods.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GPT-4 (as used)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>GPT-4 (GPT-4-1106-preview / GPT-4-turbo-1106 used in experiments)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>The primary foundation LLM used in LLMAD experiments; selected for strong instruction-following, reasoning, and domain-knowledge capabilities, and produced the best detection and interpretability results among tested LLMs.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-4 (GPT-4-1106-preview / GPT-4-turbo-1106)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Large pretrained transformer language model from OpenAI used via API; no parameter counts disclosed in paper; tuned via prompt engineering (temperature, top-p, top-k search in grid search hyperparameters) but not fine-tuned on time series data.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_detection_method</strong></td>
                            <td>Prompt-based few-shot inference with ICL and AnoCoT; LLM outputs anomaly indices, types, alarm levels, and natural-language explanations; used as-is (zero-shot/few-shot), no fine-tuning.</td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Univariate time series converted to tabular Index-Value format</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>Same eight anomaly types defined in LLMAD</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td>KPI, WSD, Yahoo</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Table 4 results: GPT-4 Best F1 / Delayed F1 by dataset — WSD 0.716 / 0.409; KPI 0.843 / 0.667; Yahoo 0.724 / 0.695 (these are the GPT-4 LLMAD configurations reported).</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Outperformed GPT-3.5 and Llama-3-70B-instruct in the LLMAD pipeline; GPT-4 was required to reach the highest-quality detection and classification (e.g., anomaly-type classification Acc >90% on some datasets).</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Model parameterization and internal mechanics not disclosed; inference cost and latency higher than smaller LLMs; performance depends on prompt and retrieval quality.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Large Language Models can Deliver Accurate and Interpretable Time Series Anomaly Detection', 'publication_date_yy_mm': '2024-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5645.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e5645.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or structured/tabular data, including details of the models, methods, datasets, types of anomalies, performance, and comparisons to traditional methods.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LLMTIME (baseline)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>LLMTime (zero-shot LLM forecasting baseline)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A baseline that applies LLMs for zero-shot time series forecasting and uses the forecast error as anomaly signal; included for comparison and found to perform poorly in direct anomaly detection tasks relative to LLMAD.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>LLM-based zero-shot forecaster (referred to as LLMTime in paper)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Zero-shot method using an LLM to forecast time series (no retrieval/ICL/CoT specialized prompting for anomaly detection) and using prediction residuals as anomaly indicators.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_detection_method</strong></td>
                            <td>Zero-shot forecast + thresholding of prediction error as anomaly signal (no dataset-tailored ICL or chain-of-thought prompting).</td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Univariate time series (sequences)</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>General anomaly points (not specialized to spike/shift taxonomy); relies on forecasting errors to flag anomalies.</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td>KPI, WSD, Yahoo (evaluated as baseline)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Table 2: LLMTIME reported low performance — KPI Best F1 0.333 / Delayed 0.194; WSD Best F1 0.029 / Delayed 0.022; Yahoo Best F1 0.023 / Delayed 0.023; Average Best F1 0.128 / Average Delayed F1 0.080.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Significantly underperformed compared to LLMAD and many traditional/deep-learning anomaly detectors, demonstrating that naive LLM forecasting + residual thresholding is insufficient without ICL/retrieval and domain-specific CoT prompting.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Poor anomaly detection performance when using LLMs only for forecasting and applying residuals naïvely; lacks interpretability and dataset context, and is sensitive to forecasting quality.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Large Language Models can Deliver Accurate and Interpretable Time Series Anomaly Detection', 'publication_date_yy_mm': '2024-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e5645.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e5645.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of using language models for detecting anomalies in lists, sequences, or structured/tabular data, including details of the models, methods, datasets, types of anomalies, performance, and comparisons to traditional methods.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GPT-3.5 & Llama-3-70B (ablations)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>GPT-3.5-turbo and Llama-3-70B-Instruct (foundation LLMs tested in ablations)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Alternative LLM inference engines tested in ablation studies; both were integrated into the same LLMAD pipeline but produced lower detection and classification performance compared to GPT-4.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-3.5-turbo; Llama-3-70B-Instruct</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>GPT-3.5: smaller OpenAI LLM variant (API used). Llama-3-70B-Instruct: 70B-parameter instruction-tuned Llama variant (used locally or via available endpoints). Both were used with same prompts/hyperparameter grid search as LLMAD ablations.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>GPT-3.5: unspecified here; Llama-3-70B-Instruct: ~70B (approximate)</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_detection_method</strong></td>
                            <td>Same LLMAD pipeline (prompt-based ICL + AnoCoT) but different foundation LLMs for inference.</td>
                        </tr>
                        <tr>
                            <td><strong>data_type</strong></td>
                            <td>Univariate time series (sequences)</td>
                        </tr>
                        <tr>
                            <td><strong>anomaly_type</strong></td>
                            <td>Same taxonomy as LLMAD</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td>KPI, WSD, Yahoo</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Table 4: Llama-3-70B Best F1 results: KPI 0.701 / Delayed 0.289; WSD 0.360 / Delayed 0.264; Yahoo 0.490 / Delayed 0.471. GPT-3.5 Best F1: KPI 0.409 / Delayed 0.134; WSD 0.233 / Delayed 0.069; Yahoo 0.204 / Delayed 0.194. (All lower than GPT-4 in LLMAD configuration.)</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Both underperformed GPT-4 within the same pipeline; Llama-3-70B outperformed GPT-3.5 but neither reached GPT-4 levels, indicating model capability matters for TSAD with LLM prompting.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Lower reasoning/instruction-following and domain-integration capabilities than GPT-4 resulted in worse detection and interpretation quality; suggests sensitivity to foundation model choice.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Large Language Models can Deliver Accurate and Interpretable Time Series Anomaly Detection', 'publication_date_yy_mm': '2024-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Time-llm: Time series forecasting by reprogramming large language models. <em>(Rating: 2)</em></li>
                <li>Large Language Models are zero-shot time series forecasters. <em>(Rating: 2)</em></li>
                <li>Time Series Anomaly Detection Based on Language Model. <em>(Rating: 2)</em></li>
                <li>One fits all: Power general time series analysis by pretrained lm. <em>(Rating: 1)</em></li>
                <li>Large models for time series and spatio-temporal data: A survey and outlook. <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-5645",
    "paper_id": "paper-270045460",
    "extraction_schema_id": "extraction-schema-115",
    "extracted_data": [
        {
            "name_short": "LLMAD",
            "name_full": "Large Language Model Anomaly Detection (LLMAD)",
            "brief_description": "A prompt-based, few-shot framework that uses pretrained LLMs (primarily GPT-4) for point-wise time series anomaly detection by retrieving similar normal/abnormal examples (ICL) and applying an Anomaly Detection Chain-of-Thought (AnoCoT) for expert-like stepwise reasoning and interpretable natural-language explanations.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "GPT-4 (GPT-4-1106-preview / GPT-4-turbo-1106)",
            "model_description": "Pretrained generative transformer LLM used as an inference engine with prompt engineering (no fine-tuning). Uses few-shot in-context learning examples and chain-of-thought style prompts (AnoCoT). API-based call (GPT-4-turbo variant for cost/latency evaluation).",
            "model_size": null,
            "anomaly_detection_method": "Prompt-based few-shot in-context learning (ICL) with retrieved positive (anomalous) and negative (normal) examples, Anomaly Detection Chain-of-Thought (AnoCoT) prompting for step-wise expert reasoning, preprocessing (rescaling, index tabularization), and windowed evaluation; outputs anomaly indices, anomaly type, alarm level, and textual explanations. No LLM fine-tuning.",
            "data_type": "Univariate time series (converted to tabular Index-Value format; sequences/windows of time series data)",
            "anomaly_type": "Point and segment anomalies including SingleSpike, SingleDip, MultipleSpikes, MultipleDips, PersistentLevelShiftUp/Down, TransientLevelShiftUp/Down (eight types defined)",
            "dataset_name": "KPI, WSD, Yahoo (public TSAD benchmarks)",
            "performance_metrics": "Best F1 and Delayed F1. Reported LLMAD: KPI Best F1 0.843 / Delayed F1 0.667; WSD Best F1 0.711 / Delayed F1 0.401; Yahoo Best F1 0.724 / Delayed F1 0.695; Average Best F1 0.759 / Average Delayed F1 0.588.",
            "baseline_comparison": "Compared to a range of statistical and deep-learning baselines (SPOT, SRCNN, DONUT, VQRAE, AnoTransfer, Informer, TFAD, Anomaly-Transformer, and LLMTIME), LLMAD achieved the best average Best F1 across datasets and second-best average Delayed F1. It substantially outperformed LLMTIME (a zero-shot LLM forecasting baseline) and many classical/statistical methods, while matching or exceeding several SOTA DL detectors on Best F1.",
            "limitations_or_failure_cases": "Higher inference latency and API cost compared to lightweight/traditional detectors; window-size limitations (can miss very long-duration anomalies spanning many windows); reliance on well-crafted prompts and injected domain knowledge (requires one-time expert involvement); some datasets' annotation conventions (e.g., only marking a single critical point in a level shift) can reduce measured precision; near-real-time constraints may be problematic.",
            "uuid": "e5645.0",
            "source_info": {
                "paper_title": "Large Language Models can Deliver Accurate and Interpretable Time Series Anomaly Detection",
                "publication_date_yy_mm": "2024-05"
            }
        },
        {
            "name_short": "AnoCoT",
            "name_full": "Anomaly Detection Chain-of-Thought (AnoCoT)",
            "brief_description": "A domain-tailored Chain-of-Thought prompting strategy that injects judgment rules, anomaly-type definitions, and alarm-level criteria into LLM prompts and enforces an expert-like three-step inference (global trend, local anomaly, reassessment) to improve detection accuracy and produce interpretable explanations.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "Used with foundation LLMs (GPT-4 primarily) as a prompting technique rather than a standalone model",
            "model_description": "Prompt engineering technique: structured stepwise reasoning + explicit textual domain knowledge injected into prompts to guide LLM inference.",
            "model_size": null,
            "anomaly_detection_method": "Chain-of-Thought style prompting with domain-knowledge injection (judgment rules, anomaly type definitions, alarm criteria) to elicit stepwise reasoning and produce both detection decisions and human-readable explanations; used in a few-shot ICL context.",
            "data_type": "Univariate time series (sequences/windows)",
            "anomaly_type": "Same set defined for LLMAD (spikes, dips, persistent/transient level shifts, multiple occurrences)",
            "dataset_name": "KPI, WSD, Yahoo (used within LLMAD experiments)",
            "performance_metrics": "Ablation results: CoT (standard chain-of-thought) improved Best F1 by ~9.5% on average vs. no-CoT; AnoCoT (domain-injected CoT) further improved Best F1 by ~6.2% over standard CoT. Human eval: AnoCoT improved explanation usefulness by 13.4% and readability by 3.5% vs standard CoT (averages across raters).",
            "baseline_comparison": "Compared to no-CoT and standard CoT within the same LLMAD pipeline — AnoCoT produced higher Best F1 and better human-judged explanation quality.",
            "limitations_or_failure_cases": "Adds modest additional token usage and latency (&lt;100 tokens extra and a few seconds increase); effectiveness depends on quality and completeness of injected domain knowledge and carefully designed step definitions.",
            "uuid": "e5645.1",
            "source_info": {
                "paper_title": "Large Language Models can Deliver Accurate and Interpretable Time Series Anomaly Detection",
                "publication_date_yy_mm": "2024-05"
            }
        },
        {
            "name_short": "Time-series ICL + FastDTW retrieval",
            "name_full": "Time Series In-Context Learning with FastDTW-based retrieval",
            "brief_description": "A retrieval-augmented few-shot strategy that finds top-k similar normal and anomalous historical time series using FastDTW and supplies them as examples for LLM in-context learning to better delineate normal vs anomalous patterns.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "Used with LLM inference (GPT-4) as a retrieval/ICL component",
            "model_description": "FastDTW (approximate Dynamic Time Warping) used to compute similarity between series for retrieval; retrieved series are embedded as few-shot examples into LLM prompts to activate ICL.",
            "model_size": null,
            "anomaly_detection_method": "Few-shot prompt-based detection where K_positive most-similar anomalous series and K_negative most-similar normal series are retrieved via FastDTW and included in the prompt as demonstrations for the LLM (dynamic retrieval preferred over fixed examples).",
            "data_type": "Univariate time series (sequences/windows), stored in a time series example database",
            "anomaly_type": "Used to teach the LLM the signal patterns for the same anomaly types (spikes, dips, level shifts etc.)",
            "dataset_name": "KPI, WSD, Yahoo (used in LLMAD experiments)",
            "performance_metrics": "Ablation/Table 3: ICL (few-shot) significantly boosts Best F1 and Delayed F1 vs zero-shot. Dynamic retrieval outperforms fixed samples. Best observed trade-off: 2 positive (anomalous) / 1 negative (normal) examples provided good performance (performance increase flattens beyond ~2 pos/1 neg). Specific table values: e.g., Dynamic 2 pos/1 neg for KPI Best F1 0.843 / Delayed 0.667 (LLMAD overall).",
            "baseline_comparison": "Enables LLM to outperform zero-shot LLM approaches (e.g., LLMTIME) and close the gap with SOTA trained detectors by providing dataset-specific context; dynamic retrieved examples perform better than static few-shot examples.",
            "limitations_or_failure_cases": "Computational cost of FastDTW retrieval for very large databases (although FastDTW is faster than full DTW); retrieval quality depends on database breadth (anomalies are rare so anomaly DB is pooled across subsets); excessive examples may be redundant and increase token/latency cost.",
            "uuid": "e5645.2",
            "source_info": {
                "paper_title": "Large Language Models can Deliver Accurate and Interpretable Time Series Anomaly Detection",
                "publication_date_yy_mm": "2024-05"
            }
        },
        {
            "name_short": "GPT-4 (as used)",
            "name_full": "GPT-4 (GPT-4-1106-preview / GPT-4-turbo-1106 used in experiments)",
            "brief_description": "The primary foundation LLM used in LLMAD experiments; selected for strong instruction-following, reasoning, and domain-knowledge capabilities, and produced the best detection and interpretability results among tested LLMs.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "GPT-4 (GPT-4-1106-preview / GPT-4-turbo-1106)",
            "model_description": "Large pretrained transformer language model from OpenAI used via API; no parameter counts disclosed in paper; tuned via prompt engineering (temperature, top-p, top-k search in grid search hyperparameters) but not fine-tuned on time series data.",
            "model_size": null,
            "anomaly_detection_method": "Prompt-based few-shot inference with ICL and AnoCoT; LLM outputs anomaly indices, types, alarm levels, and natural-language explanations; used as-is (zero-shot/few-shot), no fine-tuning.",
            "data_type": "Univariate time series converted to tabular Index-Value format",
            "anomaly_type": "Same eight anomaly types defined in LLMAD",
            "dataset_name": "KPI, WSD, Yahoo",
            "performance_metrics": "Table 4 results: GPT-4 Best F1 / Delayed F1 by dataset — WSD 0.716 / 0.409; KPI 0.843 / 0.667; Yahoo 0.724 / 0.695 (these are the GPT-4 LLMAD configurations reported).",
            "baseline_comparison": "Outperformed GPT-3.5 and Llama-3-70B-instruct in the LLMAD pipeline; GPT-4 was required to reach the highest-quality detection and classification (e.g., anomaly-type classification Acc &gt;90% on some datasets).",
            "limitations_or_failure_cases": "Model parameterization and internal mechanics not disclosed; inference cost and latency higher than smaller LLMs; performance depends on prompt and retrieval quality.",
            "uuid": "e5645.3",
            "source_info": {
                "paper_title": "Large Language Models can Deliver Accurate and Interpretable Time Series Anomaly Detection",
                "publication_date_yy_mm": "2024-05"
            }
        },
        {
            "name_short": "LLMTIME (baseline)",
            "name_full": "LLMTime (zero-shot LLM forecasting baseline)",
            "brief_description": "A baseline that applies LLMs for zero-shot time series forecasting and uses the forecast error as anomaly signal; included for comparison and found to perform poorly in direct anomaly detection tasks relative to LLMAD.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "LLM-based zero-shot forecaster (referred to as LLMTime in paper)",
            "model_description": "Zero-shot method using an LLM to forecast time series (no retrieval/ICL/CoT specialized prompting for anomaly detection) and using prediction residuals as anomaly indicators.",
            "model_size": null,
            "anomaly_detection_method": "Zero-shot forecast + thresholding of prediction error as anomaly signal (no dataset-tailored ICL or chain-of-thought prompting).",
            "data_type": "Univariate time series (sequences)",
            "anomaly_type": "General anomaly points (not specialized to spike/shift taxonomy); relies on forecasting errors to flag anomalies.",
            "dataset_name": "KPI, WSD, Yahoo (evaluated as baseline)",
            "performance_metrics": "Table 2: LLMTIME reported low performance — KPI Best F1 0.333 / Delayed 0.194; WSD Best F1 0.029 / Delayed 0.022; Yahoo Best F1 0.023 / Delayed 0.023; Average Best F1 0.128 / Average Delayed F1 0.080.",
            "baseline_comparison": "Significantly underperformed compared to LLMAD and many traditional/deep-learning anomaly detectors, demonstrating that naive LLM forecasting + residual thresholding is insufficient without ICL/retrieval and domain-specific CoT prompting.",
            "limitations_or_failure_cases": "Poor anomaly detection performance when using LLMs only for forecasting and applying residuals naïvely; lacks interpretability and dataset context, and is sensitive to forecasting quality.",
            "uuid": "e5645.4",
            "source_info": {
                "paper_title": "Large Language Models can Deliver Accurate and Interpretable Time Series Anomaly Detection",
                "publication_date_yy_mm": "2024-05"
            }
        },
        {
            "name_short": "GPT-3.5 & Llama-3-70B (ablations)",
            "name_full": "GPT-3.5-turbo and Llama-3-70B-Instruct (foundation LLMs tested in ablations)",
            "brief_description": "Alternative LLM inference engines tested in ablation studies; both were integrated into the same LLMAD pipeline but produced lower detection and classification performance compared to GPT-4.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "GPT-3.5-turbo; Llama-3-70B-Instruct",
            "model_description": "GPT-3.5: smaller OpenAI LLM variant (API used). Llama-3-70B-Instruct: 70B-parameter instruction-tuned Llama variant (used locally or via available endpoints). Both were used with same prompts/hyperparameter grid search as LLMAD ablations.",
            "model_size": "GPT-3.5: unspecified here; Llama-3-70B-Instruct: ~70B (approximate)",
            "anomaly_detection_method": "Same LLMAD pipeline (prompt-based ICL + AnoCoT) but different foundation LLMs for inference.",
            "data_type": "Univariate time series (sequences)",
            "anomaly_type": "Same taxonomy as LLMAD",
            "dataset_name": "KPI, WSD, Yahoo",
            "performance_metrics": "Table 4: Llama-3-70B Best F1 results: KPI 0.701 / Delayed 0.289; WSD 0.360 / Delayed 0.264; Yahoo 0.490 / Delayed 0.471. GPT-3.5 Best F1: KPI 0.409 / Delayed 0.134; WSD 0.233 / Delayed 0.069; Yahoo 0.204 / Delayed 0.194. (All lower than GPT-4 in LLMAD configuration.)",
            "baseline_comparison": "Both underperformed GPT-4 within the same pipeline; Llama-3-70B outperformed GPT-3.5 but neither reached GPT-4 levels, indicating model capability matters for TSAD with LLM prompting.",
            "limitations_or_failure_cases": "Lower reasoning/instruction-following and domain-integration capabilities than GPT-4 resulted in worse detection and interpretation quality; suggests sensitivity to foundation model choice.",
            "uuid": "e5645.5",
            "source_info": {
                "paper_title": "Large Language Models can Deliver Accurate and Interpretable Time Series Anomaly Detection",
                "publication_date_yy_mm": "2024-05"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Time-llm: Time series forecasting by reprogramming large language models.",
            "rating": 2,
            "sanitized_title": "timellm_time_series_forecasting_by_reprogramming_large_language_models"
        },
        {
            "paper_title": "Large Language Models are zero-shot time series forecasters.",
            "rating": 2,
            "sanitized_title": "large_language_models_are_zeroshot_time_series_forecasters"
        },
        {
            "paper_title": "Time Series Anomaly Detection Based on Language Model.",
            "rating": 2,
            "sanitized_title": "time_series_anomaly_detection_based_on_language_model"
        },
        {
            "paper_title": "One fits all: Power general time series analysis by pretrained lm.",
            "rating": 1,
            "sanitized_title": "one_fits_all_power_general_time_series_analysis_by_pretrained_lm"
        },
        {
            "paper_title": "Large models for time series and spatio-temporal data: A survey and outlook.",
            "rating": 1,
            "sanitized_title": "large_models_for_time_series_and_spatiotemporal_data_a_survey_and_outlook"
        }
    ],
    "cost": 0.01644675,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Large Language Models can Deliver Accurate and Interpretable Time Series Anomaly Detection
24 May 2024</p>
<p>Jun Liu 
Chaoyun Zhang 
Microsoft China 
Jiaxu Qian 
Minghua Ma 
Si Qin 
Chetan Bansal 
Qingwei Lin 
Saravan Rajmohan 
Dongmei Zhang </p>
<p>University of Chinese Academy of Sciences China</p>
<p>Zhejiang University of Technology</p>
<p>MicrosoftUSA</p>
<p>MicrosoftUSA</p>
<p>MicrosoftUSA</p>
<p>Large Language Models can Deliver Accurate and Interpretable Time Series Anomaly Detection
24 May 202428C1BD27F9CAE923BA88E219B6BC5D07arXiv:2405.15370v1[cs.CL]Time Series Anomaly DetectionLLMInterprebility
Time series anomaly detection (TSAD) plays a crucial role in various industries by identifying atypical patterns that deviate from standard trends, thereby maintaining system integrity and enabling prompt response measures.Traditional TSAD models, which often rely on deep learning, require extensive training data and operate as black boxes, lacking interpretability for detected anomalies.To address these challenges, we propose LLMAD, a novel TSAD method that employs Large Language Models (LLMs) to deliver accurate and interpretable TSAD results.LLMAD innovatively applies LLMs for few-shot anomaly detection by retrieving and leveraging both positive and negative similar time series segments, significantly enhancing LLMs' effectiveness.Furthermore, LLMAD employs the Anomaly Detection Chain-of-Thought (AnoCoT) approach to mimic expert logic for its decision-making process.This method further enhances its performance and enables LLMAD to provide explanations for their detections through versatile, customized perspectives, which are particularly important for user decision-making.Experiments on three datasets indicate that our LLMAD achieves detection performance comparable to state-of-the-art deep learning methods while offering remarkable interpretability for detections.To the best of our knowledge, this is the first work that directly employs LLMs for TSAD.</p>
<p>INTRODUCTION</p>
<p>In the data-driven landscape of contemporary industries, time series data holds a pivotal role across various sectors, including financial market fluctuations [2], manufacturing production line monitoring [16], and internet traffic analysis [9].The examination and understanding of time series data are invaluable for maintaining operational stability, mitigating potential financial risks, and ensuring cybersecurity.Time Series Anomaly Detection (TSAD) is a critical task within these applications, aimed at identifying atypical points or patterns in the data stream that may lead to system malfunctions, market disruptions, or security threats, [4,8,23,36] etc..By providing alerting signals, TSAD contributes to maintaining operational efficiency and minimizing disruptions [18,36].This process is particularly facilitated when the interpretation of anomaly information is readily available [33,39].</p>
<p>Deep learning-based anomaly detectors have recently gained prominence in the TSAD domain, primarily due to their high detection accuracy, which ensures reliability [4,30,49,52].However, achieving this level of performance necessitates massive training data for learning, requiring significant data collection efforts.Moreover, such detectors typically only provide detected anomalous points, functioning as black boxes and failing to offer additional interpretation, such as anomaly type, emergency level, and textual anomaly reports in natural language.Such information is however particularly crucial for understanding the underlying reasons behind detected anomalies and for gaining the trust of domain experts who rely on these models for decision-making [3,17].Generating these human-readable reports often demands substantial manual analysis, involving consultation of historical data and handbooks, which is both time-consuming and requires specialized knowledge, as illustrated in Figure 1 (a).Consequently, the usability of deep learning anomaly detectors in practical applications is limited.</p>
<p>The remarkable achievements of Large Language Models (LLMs) [1] in various domains [11,50,51] have led to their application in time series tasks, garnering significant attention [14,56].LLMs are pretrained with diverse textual data, including numerical time series [22], and excel in in-context learning (ICL) with only a few-shot examples [7,23,32].They are also adept at providing more interpretable, human-readable explanations for their predictions and can be customized for specific domains.These attributes make LLMs particularly suitable for the TSAD domain, where high interpretability is highly desirable.As illustrated in Figure1, deep learning-based detectors (as shown in Figure1 (a)) necessitate considerable human effort to obtain interpretable anomaly reports, whereas LLMs (as shown in Figure1 (b)) can directly output the required information alongside their predictions without human intervention.LLMs can provide anomaly points, anomaly types, alarm levels, and explanations by integrating relevant knowledge directly into the prompts, such as data background information and anomaly detection rules.This integration allows predictions to align more closely with domain-specific requirements for TSAD.</p>
<p>Applying LLMs directly to TSAD poses several challenges.Anomaly detection requires an in-depth understanding and background knowledge of the data in order to distinguish between normal fluctuations and genuine anomalies.Achieving this distinction becomes difficult if decision boundaries are not properly provided or if domain knowledge is insufficient.Moreover, the quality of interpretability is intimately connected to the method's comprehension of the data, as a more profound understanding of the data results in more accurate explanations that are consistent with the data's background and patterns.This calls for the integration of domain knowledge from human expertise into LLMs to augment their understanding of the data.</p>
<p>To harness the power of LLMs while addressing these challenges, we introduce LLMAD, an LLM-based anomaly detection framework specifically tailored for TSAD, offering high accuracy and interpretability.LLMAD builds upon existing pretrained LLMs to generate anomaly predictions and explanations without the need for fine-tuning with time series data.To enable LLMAD to acquire better knowledge of the data, it retrieves both normal and abnormal patterns from history as input to activate the In-Context Learning (ICL) [5], thereby enabling accurate anomaly prediction with few shots.Furthermore, LLMAD employs Anomaly Detection Chain of Thoughts (AnoCoT) prompting [43] to incorporate domain knowledge tailored to TSAD, which improves its prediction performance while providing more logical and human-readable interpretations.With these techniques, LLMAD can not only accurately detect anomaly points but also offer explanations for its reasoning process and classifications of key components, such as anomaly type and alarm level, providing valuable insights for decision-making.</p>
<p>We conduct experiments on three mainstream public datasets for the task of TSAD [27,28,54].The results suggest that our LLMAD achieves comparable accuracy performance with state-of-the-art (SOTA) deep learning-based detectors.Importantly, LLMAD can further deliver useful and readable interpretable results, including anomaly type, alarm level classification, and explanation, at a low cost, as evaluated by domain experts.These outcomes cannot be achieved by traditional methods.Overall, this paper makes the following contributions:</p>
<p>(1) We introduce LLMAD, a novel framework based on LLMs, which accurately conducts point-wise TSAD while providing comprehensive interpretation of its predictions to facilitate decision-making.(2) We inject data background and domain knowledge into LL-MAD via time-series In-Context Learning (ICL) and AnoCoT to enhance TSAD performance and interpretation quality.(3) We conduct extensive experiments on three public datasets.</p>
<p>Both quantitative and human evaluations suggest that LLMAD delivers highly accurate TSAD while providing useful and readable interpretative results at a low cost.</p>
<p>To the best of our knowledge, we are the first to employ LLMs to directly perform TSAD without fine-tuning, delivering interpretable results.</p>
<p>PRELIMINARY</p>
<p>In this section, we provide an overview of TSAD and its interpretability.</p>
<p>Time Series Anomaly Detection</p>
<p>Anomaly detection, also referred to as outlier detection, is an analytical process aimed at identifying a single point or a sequence of points that exhibit significant deviations from the typical patterns or norms [10].A univariate time series is defined as:
𝑇 = {𝑥 𝑖 | 𝑖 ∈ [1, 𝑛]}(1)
where   denotes the data value at time , within the interval [1, 𝑛].</p>
<p>The objective of anomaly detection is to identify instances of abnormal behavior (either normal or anomalous) at each time step.The result of an anomaly detection algorithm is represented as:
𝑌 = {𝑦 𝑖 | 𝑖 ∈ [1, 𝑛]}(2)
where   ∈ {0, 1} serves as a binary indicator, with 0 indicating normality and 1 signifying abnormality.</p>
<p>Interpretability for Time Series Anomaly Detection</p>
<p>Interpretability in TSAD is crucial for transforming raw data insights into actionable intelligence [17].An interpretable TSAD system not only identifies anomalies but also provides explanations that can be understood by humans, facilitating informed decisionmaking and root cause analysis [7,41].In this paper, we employ three key aspects of interpretability for TSAD, which are discussed below: text explanations [47], anomaly types and alarm levels [17].</p>
<p>(1) Text Explanations: Text explanations involve providing humanreadable descriptions that clarify why a particular data point or sequence is considered anomalous.These explanations are essential for users who may not have deep technical expertise but need to understand the nature of an anomaly to respond appropriately.</p>
<p>(</p>
<p>Interpretable TSAD</p>
<p>AnoCoT</p>
<p>Step-wise Inference understanding the anomaly's context within the broader system behavior.</p>
<p>AnoCoT Prompt</p>
<p>ICL examples</p>
<p>Prompt Construction</p>
<p>(3) Alarm Levels: Alarm levels indicate the severity of detected anomalies, guiding immediate attention and resources to the most critical issues.By assigning a severity level to each detected anomaly, organizations can triage responses, allocate resources, and prioritize more effectively.</p>
<p>Leveraging the above information beyond anomaly prediction enables users to make better-informed decisions, take appropriate actions, and make reasonable judgments.This can be achieved automatically with LLMAD, whereas it is challenging for traditional black-box methods.</p>
<p>THE DESIGN OF LLMAD</p>
<p>We provide an overview of our proposed LLMAD in Section 3.1 and elaborate on its components in the subsequent subsections.</p>
<p>LLMAD in a Nutshell</p>
<p>We present an overview of LLMAD in Figure 2. LLMAD builds upon a time series database to retrieve similar examples for the model and employs AnoCoT prompting to inject domain knowledge into LLMs, helping it grasp the background of the time series data without the need for fine-tuning.The model then uses this information to predict anomaly points and provide interpretations.</p>
<p>Upon receiving the input time series, the data undergoes normalization and preprocessing to convert it into a tabular format suitable for LLM processing.LLMAD then retrieves similar data samples, including both normal and abnormal data, from the time series databases into its inputs to help differentiate between the two data types (Section 3.3).Then, it employs the AnoCoT to inject domain knowledge of anomaly rules, types, and alarm levels tailored to the specific dataset and constructs the prompts fed into the LLM (Section 3.4).With this information, LLMAD predicts the anomaly points, along with their types, alarm levels, and textual explanations to provide comprehensive interpretations (Section 3.5).We detail each component in the following subsections.</p>
<p>Time Series Data Preprocessing</p>
<p>Since LLMs are not primarily designed for numerical data, we conduct several data preprocessing steps on the time series to make them suitable for LLM input and improve the performance for TSAD.These steps include rescaling and indexing.</p>
<p>Rescaling: To reduce tokens in LLM when the inputs are very large or high decimal places, we scale fractional values in integers with a certain number of significant digits [14].We apply the following affine transformation to each element   in a time series:
𝑥 ′ 𝑡 = 1000 × (𝑥 𝑡 − 𝑏) 𝑎 (3)
Here, ⌊•⌉ is the rounding to integral operator, and  is the 95 th upper percentile of the data subset.
𝑏 = min 𝑥 𝑡 − 𝛽 (max 𝑥 𝑡 − min 𝑥 𝑡 ),(4)
where min   and max   are the 1 st and 99 th percentiles, respectively, and  is a scaling parameter.This scaling ensures that the values are integral and robust to outliers, making the input more suitable for LLMs in terms of understanding and token saving.</p>
<p>Value Indexing: The primary goal of TSAD is to identify the exact data index of anomalous points.Therefore, we reformat the data values with numerical indices in a tabular format as follows:
Index Value 1 𝑣𝑎𝑙𝑢𝑒1 2 𝑣𝑎𝑙𝑢𝑒2 • • • • • •
This correspondence assigns unique indices to each data value in the time series, thus facilitating LLMs to output point-wise anomalies with their indices as identifiers, meeting the primary requirements of TSAD.</p>
<p>Time Series In-Context Learning</p>
<p>The objective of an anomaly detection system is to delineate a distinct boundary between normal and abnormal data.Nevertheless, establishing such criteria poses a challenge due to the varying anomaly patterns across different datasets, necessitating substantial background and domain-specific knowledge.Deep learning-based detectors attempt to uncover this boundary by utilizing extensive training data, which results in a highly inefficient process.In contrast, LLMs have already undergone training with massive datasets, encompassing numerical time series, thereby requiring only a limited number of demonstrations to activate and apply their domain knowledge in the realm of TSAD.This methodology, referred to as In-Context Learning (ICL), has demonstrated its efficacy in numerous applications.</p>
<p>We apply the similar ICL in LLMAD to address the challenges in TSAD, where we build a time series database that store both normal and abnormal data for retrieval.When receiving an input time series, we find both top- similar normal and abnormal samples in the database, to establish a boundary between normal and abnormal data with them.We illustrate this process in Figure 3.</p>
<p>Construction and Retrieval of Databases.We first collect both normal and abnormal time series data and retrieve examples from them individually.The normal time series database, denoted as S, comprises normal time series derived from the same dataset.In contrast, the anomaly database, denoted as Ŝ, is assembled from all abnormal time series sources across different subsets within the dataset to expand the variety and quantity of anomaly types, due to the rareness of abnormal data.</p>
<p>Finding Similar Time Series.Identifying similar time series differs from the methods employed for textual data, where fixedlength vectors are embedded and cosine similarity is utilized as a measurement [48].For time series analysis, methods like embedding combined with cosine similarity are less favorable because they often require training data to generate meaningful embeddings and might not robustly account for temporal shifts and distortions between sequences [42].In contrast, Dynamic Time Warping (DTW) [24] and its optimized version FastDTW [35], directly address these issues by explicitly aligning sequences by matching temporal variations and patterns, even if the sequences vary in speed or are out of phase.</p>
<p>The DTW algorithm [24] utilizes a dynamic programming approach to determine the optimal alignment between sequences, which minimizes the overall distance.This method results in a time complexity of  ( 2 ), where  represents the number of data points.For lengthy sequences and large databases, this complexity becomes computationally prohibitive and inefficient for retrieval purposes.To address this issue, we employ the FastDTW algorithm [35], which reduces the time complexity to approximately  () by implementing a multi-level approach.The algorithm initiates by calculating DTW at a coarser resolution to establish a preliminary alignment.Subsequently, it refines this alignment at progressively finer resolutions, significantly decreasing the number of required calculations.The mathematical foundation of FastDTW is illustrated in the following recursive formula:
𝐷 FastDTW (𝑇 1 ,𝑇 2 ) = 𝐷 (𝐿 1 , 𝐿 2 )(5)
 (, ) ≈ min { ( − 1,  − 1),  ( − 1, ),  (,  − 1)} +  (, ) (6) Here,  FastDTW ( 1 , 2 ) denotes the FastDTW distance between time series  1 , with length  1 , and time series  2 , with length  2 . (, ) represents the approximate cumulative distance between two sequences up to the  th and  th elements, respectively, while  (, ) signifies the distance between the  th element of the first sequence and the  th element of the second sequence.This approximation approach maximizes the matching accuracy while significantly reducing the complexity, making it more suitable for time series retrieval in large databases.</p>
<p>In-Context Learning.With the time series database constructed, LLMAD retrieves the most similar  1 normal time series and the  2 anomalous time series from S and Ŝ to a target time series data  by leveraging the FastDTW algorithm for similarity computation:
K = { S𝑖 : 𝑖 ∈ argmin 𝐾 1 𝑖 {𝐷 FastDTW (𝑇 , S𝑖 )}}(7)K = { Ŝ𝑖 : 𝑖 ∈ argmin 𝐾 2 𝑖 {𝐷 FastDTW (𝑇 , Ŝ𝑖 )}}(8)
Here, K and K are the actual sets of  1 most similar normal and  2 most similar anomalous time series to  , respectively.Incorporating the retrieved similar normal and abnormal data from historical records into the prompt of the LLMs enhances the ICL capability (see Figure 4).This provides a comprehensive representation of the data background, anomaly patterns, and distinctions tailored to a specific time series dataset.Consequently, the detection performance of the proposed method, denoted as LLMAD, is improved without the necessity for fine-tuning, as demonstrated in many applications [12,19,51].</p>
<p>Anomaly Detection Chain of Thoughts</p>
<p>The CoT prompting technique guides LLMs to perform step-by-step reasoning, thereby enhancing the quality and consistency of the inference process [43].We adapt this approach to the domain of TSAD by introducing the Anomaly Detection Chain of Thoughts (AnoCoT), which is specifically designed to address the context and logical thinking requirements for both anomaly detection and -<strong>LevelShiftUp</strong> The data shifts to a higher value and maintains that level consistently, do not return to the original baseline.</p>
<p>interpretation. This adaptation encompasses two key components: Domain Knowledge Injection and Expert</p>
<p>Step-Wise Inference.We show the overall prompt structure that encloses AnoCoT in Figure 4. Domain Knowledge Injection Domain knowledge comprises the specialized insights and expertise pertinent to a specific domain or dataset in the context of TSAD.This knowledge encompasses three main aspects: (i) judgment rules, (ii) anomaly type definitions, and (iii) criteria for alarm levels.Judgment rules assist in establishing criteria that distinguish normal from abnormal patterns, tailored to a particular data background.This helps clarify the boundary between normal and abnormal data [13,29].Anomaly type definitions and criteria for alarm levels serve as background knowledge of the anomalies, which not only improve the model's judgment but also contribute to the interpretability for subsequent use.The injected domain knowledge varies based on the context of the data, allowing users to tailor it to their specific needs and enhancing the flexibility of the approach.</p>
<p>By incorporating comprehensive domain knowledge, LLMs are better equipped to enhance their TSAD capabilities and adapt to specific data sets.This integration of expert knowledge allows the LLMs to generate more accurate and contextually relevant results, improving the overall performance and interpretability of the anomaly detection process.Expert Step-Wise Inference With the domain knowledge, the AnoCoT method unfolds the inference in three distinct steps tailored to the TSAD.The first step involves a global trend assessment, which analyzes the overall trend within the time series, identifying potential indicators of gradual deterioration, such as level shifts.The second step conducts local anomaly assessment, is specifically designed to detect abrupt anomalies occurring on a smaller scale, such as spikes, which may signal sudden incidents.The third step takes reassessment, entails a re-evaluation of the anomalies identified in the preceding steps.Given the inherent infrequency of true anomalies and the high occurrence of false positives in extensive models, this step is indispensable.</p>
<p>The step-wise inference design emulates the logical reasoning of expert engineers, which substantially enhances the accuracy of TSAD and the quality of interpretability.This approach allows the model to better mimic human decision-making processes, resulting in more reliable and easily understandable anomaly detection outcomes.</p>
<p>Interpretable TSAD</p>
<p>Interpretability plays a crucial role in TSAD since it provides valuable information for decision-making.The proposed method LL-MAD, generates a comprehensive anomaly report in natural language to assist users in this regard.The report encompasses three key aspects: (i) anomaly explanation, (ii) anomaly type classification, and (iii) alarm level classification.</p>
<p>Anomaly Explanation In the anomaly explanation component, LLMAD utilizes the AnoCoT to generate a step-wise explanation for its inference.This explanation synthesizes insights from an initial global trend assessment, which contextualizes anomalies within the broader data landscape, and detailed local anomaly assessments that identify specific irregularities, such as sudden spikes and reevaluation results.This approach emulates the logical thinking flow of a human expert, which not only captures the most pertinent points for decision-making but also produces a human-readable report in natural language using LLMs.Such interpretability is not achievable with traditional TSAD methods.</p>
<p>Anomaly Type Classification The identification of specific anomaly types can furnish engineers with additional information for pinpointing the root cause of issues [4].For example, abrupt anomalies, such as spikes, signify sudden incidents, while trend anomalies, like level shifts up, indicate deterioration.Although existing time series anomaly detection research focuses on identifying statistical anomalies, it often overlooks the classification of anomaly types.</p>
<p>In our study, we have recognized eight distinct and common anomaly types [44], as illustrated in Figure 5, by conducting a</p>
<p>Single Spike</p>
<p>One brief, sharp rise in data value followed by an immediate return to the baseline.</p>
<p>Single Dip</p>
<p>One brief, sharp drop in data value followed by an immediate return to the baseline.</p>
<p>Multiple Spikes</p>
<p>Several brief, sharp rises in data value, each followed by a return to the baseline.</p>
<p>Multiple Dips</p>
<p>Persistent Level Shift Up</p>
<p>Persistent Level Shift Down</p>
<p>Transient Level Shift Up</p>
<p>Transient Level Shift Down</p>
<p>Several brief, sharp drops in data value, each followed by a return to the baseline.</p>
<p>The data shifts to a higher value and maintains that level consistently, do not return to the original baseline.</p>
<p>The data shi:s to a lower value and maintains that level consistently, do not return to the original baseline.</p>
<p>The data temporarily shifts to a higher value and then returns to the original baseline, anomaly maintains for at least 5 data points.</p>
<p>The data temporarily shifts to a lower value and then returns to the original baseline, anomaly maintains for at least 5 data points.</p>
<p>Anomaly Type Description Example</p>
<p>Figure Alarm Level Classification Alarm levels represent the severity or urgency of detected anomalies, typically characterized by their potential impact on the system or process.Three distinct degrees of alarm levels have been established: Warning, Important and Urgent/Error.The "Warning" level signifies minor deviations that do not necessitate immediate action, while the "Important" level indicates conditions that could potentially escalate into future problems or cause system stress but are not immediately hazardous.In contrast, the "Urgent/Error" levels emphasize critical issues that demand immediate attention.These levels are defined in conjunction with the data context, and their prediction proves highly beneficial for subsequent decision-making and prioritization [52].</p>
<p>ANOMALY DETECTION PERFORMANCE</p>
<p>In this section, we first evaluate the TSAD performance of LLMAD by examining the TSAD accuracy.The details of each dataset are presented in Table 1 1 .To assess the performance of TSAD, we selected the final 50% of data from the Yahoo dataset and 5% of data from both the KPI and WSD datasets as the test set.For the baseline models, we use the first 50% of the data in each datasets for training and model selection.</p>
<p>Baseline Models.We compare our proposed LLMAD against a diverse set of state-of-the-art TSAD methods, categorized by their detection mechanisms and typical applications.These include:</p>
<p>• SPOT [37]: A statistical method grounded in extreme value theory, ideal for outlier detection in univariate data streams.• SRCNN [34]: A supervised learning approach that uses convolutional neural networks to leverage spatial dependencies.</p>
<p>• DONUT [45]: An unsupervised anomaly method utilizing variational autoencoder to denoise the anomalies and further learn the robust representation of normal patterns.• VQRAE [25]: An unsupervised anomaly method that uses detection variational quasi-recurrent autoencoders.</p>
<p>• AnoTransfer [54]: An approach that enhances the VAE framework with transfer learning to adapt quickly to different settings in an unsupervised manner.• Informer [55]: A predictive model that utilizes advanced attention mechanisms and transformer architectures to forecast and detect deviations from normal sequences.• TFAD [53]: A method that integrates traditional feature engineering with anomaly detection strategies in a supervised learning framework.</p>
<p>0 0 1 1 1 0 1 1 1 0 • Anomaly-Transformer [46]: An unsupervised method that leverages the transformer architecture with an anomaly-attention mechanism to compute the association discrepancy.
1 0 0 1 1 0 0 0 1 0 Truth Predict 1 0 1 1 1 0 1 1 1 0 1 0 1 1 1 0 0 0 0 0 Adjusted Delay adjusted
• LLMTime [14]: A zero-shot LLM-based method to forecast time series, and we use the prediction error as anomaly signals.This comprehensive comparison spans from traditional statistical approaches to cutting-edge deep learning models, ensuring a thorough analysis of their efficacy in anomaly detection within timeseries data.We evaluated the performance of the baseline models by adhering to their original code repository and configuration settings.In the case of our LLMAD, we chose GPT-4-1106-preview as the primary language modeling model.</p>
<p>Evaluation Metrics.In practical applications, operators prioritize the detection of continuous anomalous segments in time-series data over point-wise anomaly detection, which involves classifying each individual data point as an anomaly.This shift in focus is attributed to the significant impact that anomalous segments can potentially have.To address these specific needs, our research employs two metrics: Best F1 and Delayed F1, drawing inspiration from DONUT [45] and SRCNN [34], respectively.</p>
<p>The Best F1 is designed to measure the peak F1 score that a model can achieve across different thresholds, incorporating a point adjustment strategy.This provides a benchmark for the optimal performance capability of the model under ideal conditions.In LLMAD, we adjust the threshold by considering the number of detected anomaly points as a variable.Delayed F1 score caters to the practical necessity of prompt anomaly detection by introducing a delay threshold, denoted as .If an anomaly segment is identified after surpassing this threshold , it is deemed as undetected.This metric modifies predictions by considering a specific delay.The example shown in Figure 6, where the delay  = 1, the second anomaly segment is prolonged to encompass three points due to the delay adjustment, whereas the third segment is overlooked because its detection calls for two-time intervals, exceeding the maximum delay threshold of 1.This approach balances the importance of swift detection against the imperative of maintaining detection accuracy, a balance that is especially crucial in scenarios where prompt detection can significantly reduce potential risks or losses.For the WSD and KPI, the delay is configured at 7, and for Yahoo datasets, it is set to 3.</p>
<p>Performance Comparison</p>
<p>In Table 2, we report the results for Best F1 and Delayed F1 on different datasets and methods.Observe that LLMAD on average achieves the best performance on Best F1 and second-best performance on Delayed F1 across the three datasets, underscoring its superior performance in accuracy and timeliness.These results suggest that the LLM based approach can deliver reliable TSAD compared to traditional methods, opening a new methodology for the TSAD domain.</p>
<p>Examining the breakdown performance, LLMAD ranks in the top three for both F1 and Delayed F1 for all datasets, demonstrating its robust performance.The performance of various baseline methods on datasets exhibits variance.For instance, SPOT generally underperforms across most datasets due to its erroneous treatment of outliers as anomalies, which do not always manifest in such a manner.Anomaly Transformer achieves commendable results in terms of the highest Best F1 on most datasets but demonstrates a low Delayed F1.It detects anomalies based on their relation to nearby points, effectively capturing correlations only when the anomalous points are relatively central within a window.On the other hand, LLMTIME, which also employs LLM for prediction and uses the error as an anomaly indicator, has very low performance.This observation suggests the superior pipeline of LLMAD.By introducing ICL and AnoCoT, LLMAD utilizes LLM more effectively, making it more suitable for the TSAD task.</p>
<p>It has been observed that LLMAD does not always achieve the best results in certain datasets.For instance, in the KPI dataset, this is due to the presence of long-duration anomalies that may extend across multiple windows.As a result, LLMAD may struggle in these cases due to the limitation of window size, while other methods are trained on the entire dataset and have incorporated such long-term knowledge.In the case of the Yahoo dataset, TFAD performs better.We have noticed that the dataset annotations sometimes only mark critical anomaly points, such as the point of a level shift, without indicating subsequent sustained anomalies.Consequently, LLMAD may identify the sustained values post-shift as anomalies, leading to slightly lower precision.Nevertheless, LLMAD still ranks among the top three baselines in these two datasets and the best on average, making it a reliable method.</p>
<p>Ablation Analysis</p>
<p>To delve into the effect of individual components in LLMAD, we explore the impact of three distinct factors: (i) in-context learning, (ii) chain-of-thoughts prompting, (iii) the injection of domain knowledge, and (iv) the foundation LLM inference engine.</p>
<p>In-Context</p>
<p>Learning.First, we evaluate the effectiveness of ICL in LLMAD along two dimensions: (i) whether to retrieve samples dynamically, use fixed ones, or not use ICL at all (zero-shot [26]), and (ii) the number of positive (anomaly) and negative (normal) samples used for ICL.</p>
<p>Table 3 presents the performance comparison of different ICL settings in LLMAD using GPT-4.Observe that using few-shot ICL can significantly boost the performance of TSAD, regardless of whether the samples are fixed or dynamic.This demonstrates the superiority of ICL.By providing demonstrations via examples, LL-MAD establishes a clearer boundary between normal and abnormal patterns, boosting its performance.On the other hand, it appears that using samples retrieved dynamically achieves better performance than fixed ones.This suggests that using similar samples can better help LLMs distinguish ambiguous cases.Taking a closer look at the effect of the number of samples retrieved, it appears that the performance of LLMAD increases with the number of samples, but this increase becomes flattened if more than 2 positive/1 negative samples are provided.This observation makes sense, as more samples can, to some extent, provide rich patterns and information for LLMAD, but continually increasing the number of samples may lead to repetitive information.Using the setting of 2 positive/1 negative samples can be a good trade-off between complexity and performance.</p>
<p>Chain-of-Thoughts</p>
<p>Prompting.Now we move to evaluate the effectiveness of our AnoCoT by comparing its performance with LLMAD without CoT and standard CoT (asking LLM to think step-by-step), as shown in Figure 7.As expected, CoT can significantly improve the performance of TSAD in terms of Best F1 on all datasets, while our AnoCoT, which incorporates domain knowledge and follows the logical thinking of experts, can further boost the performance to a greater level.On average, CoT improves the Best F1 by 9.5%, and using AnoCoT can further improve CoT by 6.2%, which is a substantial boost.This improvement can be attributed to the fact that as LLMs infer like humans, using step-wise thinking combined with injecting domain expertise leads to improved performance in TSAD.</p>
<p>Domain Knowledge Injection.</p>
<p>We also delve into the effectiveness of domain knowledge to see how its injection can help with TSAD.Table 5 shows the impact of removing one of the domain knowledge components defined in Section 3.4.Observe that removing any domain knowledge component will lead to a performance drop, as expected.The drop is most significant in the absence of specific judgment rules.This underscores the importance of defining textual rules for LLM's understanding of the definition of anomalies.</p>
<p>Although type and alarm level do not directly provide guidance for TSAD, they are also important, as they act as side information to deliver the context of the task.This enhances the ability of LLMAD, making it more sophisticated in the task.</p>
<p>Foundation LLM.</p>
<p>Finally, we evaluated the performance of LLMAD using different LLM engines to compare their divergence.Table 4 shows the results for GPT-3.5 [6], GPT-4 [1], and Llama-3-70B-Instruct [31].It can be observed that GPT-4 outperforms the other two models significantly in all datasets, while Llama-3-70B-Instruct demonstrates superior performance compared to GPT-3.5.Considering that the TSAD task is heavily dependent on domain-specific knowledge and the ability to follow instructions and comprehend content, only GPT-4 fulfills the necessary criteria.This underscores the vital role of advanced LLM models in accomplishing such tasks.</p>
<p>INTERPRETABILITY EVALUATION</p>
<p>We proceed to analyze the quality of anomaly interpretations generated by LLMAD from three distinct perspectives: anomaly explanation, anomaly type classification, and the incorporation of urgency level into the anomaly explanation for joint analysis.</p>
<p>Experiment Setup</p>
<p>The original dataset is solely labeled with anomaly points and lacks ground truth information for interpretability evaluation.To address this limitation, we employ LLMAD to generate output for each type of interpretation and enlist the expertise of 5 DevOps engineers to manually assess the quality of interpretation in each case.With an average of 3 years of TSAD experience, these engineers offer a well-rounded perspective on the evaluation process.</p>
<p>Explanation Evaluation Setup.</p>
<p>We combine the evaluation of anomaly explanation and urgency level, as assessing the urgency level independently, without the context and accompanying interpretation, proves to be challenging.To thoroughly assess these aspects of LLMAD's performance, we adopt two primary criteria: usefulness and readability [29].Usefulness refers to the effectiveness and relevance of an explanation in practical applications, with a score range between 1 and 5. Readability focuses on the clarity and ease of understanding of the explanation, scored between 1 and 3.More details on each score can be found in Appendix C.These criteria are crucial for determining how effectively the explanations generated by LLMAD contribute to an improved understanding of detected anomalies and provide actionable insights.We randomly selected 100 anomaly cases in total from the three datasets for human evaluation and compared the performance of the GPT-4 version of LLMAD using standard CoT and AnoCoT methods.In addition to the mean and standard deviation (std) scores from each rater, we also provide the evaluation of High Incidence Proportion (HIP) [29], which calculates the percentage of evaluations surpassing a satisfying performance threshold.The threshold is set at a score of 4 for usefulness and 2 for readability.</p>
<p>Anomaly Type Classification</p>
<p>Setup.We also randomly selected 100 anomalous samples in total to manually evaluate the performance of anomaly type classification.Each sample was asked to be labeled with one or multiple types of anomalies.To evaluate the classification performance, we employ two metrics: Acc (anyhit) [57] and Micro F1 [15].Acc (any-hit) calculates the ratio of correctly predicted anomaly types to the total number of samples.A type prediction is considered a "hit" if it matches any human label.Micro F1 is a metric that aggregates the contributions of all classes to compute the average metric.This makes it robust to class imbalance and emphasizes the importance of correctly classifying each instance. .By using these metrics, we can effectively assess the performance of LLMAD in classifying anomaly types.</p>
<p>Evaluation Results</p>
<p>Explanation Evaluation. Table 6 presents a comparison of</p>
<p>AnoCoT and standard CoT based on human evaluation of anomaly explanations generated by LLMAD.It can be observed that AnoCoT outperforms standard CoT in terms of both usefulness and readability across all raters, with an average increase of 13.4% in usefulness and 3.5% in readability.This result suggests that AnoCoT, which incorporates domain knowledge for TSAD and follows expert reasoning flow, consistently provides better quality explanations for anomaly prediction, delivering more insightful, detailed, useful, and user-friendly information for engineers in decision-making processes.Furthermore, AnoCoT achieves 72.37% and 97.11% HIP for usefulness and readability, respectively, indicating that LLMAD can deliver satisfactory explanations for a majority of samples, making it practical for real industry scenarios.Overall, these findings suggest that AnoCoT not only enhances the performance of TSAD but also improves the transparency and interpretability of the anomaly detection process, making it a highly valuable addition to the task.</p>
<p>Anomaly Classification Evaluation.</p>
<p>In Table 7, we present the performance comparison of anomaly classification across three datasets for different LLM models 2 .It can be observed that GPT-4 consistently outperforms other baselines as the most reliable model for anomaly classification across all datasets.It achieves over 90% accuracy on WSD and Yahoo datasets, and 79% on the KPI dataset, while also obtaining high Micro F1 scores for all datasets.This performance is remarkable, given that the samples are not labeled with anomaly type labels.GPT-4 can accurately classify anomalies based solely on the textual description of types, which demonstrates its remarkable interaction-following ability.This high performance suggests that LLMAD can deliver excellent anomaly classification quality to assist interpretable TSAD and decision-making processes.However, this advantage is limited to GPT-4.The task poses high requirements on the LLM model, as confirmed in Section 4.3.4.</p>
<p>Anomaly Prediction Explanation</p>
<p>Anomaly Type: TransientLevelShiftUp Alarm Level: Urgent/Error Explanation text:</p>
<p>Step 1 global: Data up to point 116 falls within the typical range when compared to historical normal data.Starts to increase substantially from point 117, reaching an extreme high at 154.</p>
<p>Step 2 local: Sustained high values from point 117 to 158 with peaks well above the historical norm, indicating an anomaly.Post-point 158, values return to normal levels.</p>
<p>Step 3 recheck: Reassessment confirms the anomaly between points 117 and 158, as the values deviate significantly from the norm and follow the defined rules for anomalies.</p>
<p>Anomaly Type: SingleSpike Alarm Level: Warning Explanation text:</p>
<p>Step 1 global: Global analysis of the recent 400 data points shows expected variability within normal ranges.</p>
<p>Step</p>
<p>Case Study</p>
<p>We present two case studies in Figure 8 to demonstrate how LLMAD successfully identifies and delivers interpretable TSAD results.Case 1: Transient Level Shift Detection In the first case study, we observe that the data exhibits a sudden and significant increase in data values, starting at point 117 and peaking at point 154.LL-MAD successfully identifies this pattern as a "Transient Level Shift Up" anomaly and captures the event range.This classification was enhanced by a comprehensive analysis that included: (i) A global assessment confirming that the shift was well above historical norms.(ii) A local trend analysis showing deviation from normal behaviors.(iii) A recheck validating the anomaly by demonstrating that the peak values deviated substantially from typical data trends.Such interpretations are helpful and clear for engineers to localize the event and take further actions, highlighting the practical value of LLMAD in providing interpretable TSAD results.</p>
<p>Case 2: Singular Data Spike Detection The second case study presents a time series with regular fluctuations, where some peak values exceed normal ranges.LLMAD successfully detects these 2 "Acc" indicates the Acc (any-hit) metric Generates a useful and human-readable report.This enhances the system's usability for operators without specialized data science knowledge.Since the deviation is not significant, LLMAD assigns this case a "Warning" level.This classification not only identifies issues but also aids in prioritizing system responses, ensuring that resources are allocated effectively and that operators can act on the most critical anomalies first.Overall, these two practical demonstrations show LLMAD's value in providing interpretable TSAD results and facilitating informed decision-making.</p>
<p>COST AND LATENCY ANALYSIS</p>
<p>It is well-known that LLMs have a considerable number of parameters, which may result in high inference latency.In this section, we evaluate these aspects to provide essential information regarding the overhead of employing the proposed method, LLMAD.We utilize the GPT-4-turbo-1106 model as the base and its variants under two methodologies: standard CoT and AnoCoT.Both methodologies were tested with a window length of 400, collecting data at a rate of one point per minute, consistent with the highest sampling rate in the WSD dataset among the three.In contrast, the sampling rates for the Yahoo and KPI datasets are one hour and 1 to 5 minutes, respectively.</p>
<p>We present the evaluation results in Table 8.The mean and standard deviation (Std) values are computed across all samples from three datasets.We first compare the token usage between AnoCoT and CoT.It can be observed that AnoCoT introduces a minor increase in input and output tokens (&lt; 100) compared to CoT.A higher output token count implies a more comprehensive interpretation.Considering the improvements in both TSAD performance and interpretability, this additional token usage is justifiable.The proposed AnoCoT method requires, on average, 14.91 seconds for calling the GPT-4 API and 17.03 seconds for the total time per request.Given that each request handles 400 data points, corresponding to over a 6-hour time window, such latency is negligible.</p>
<p>Financial Cost Estimation: Daily costs were calculated based on the number of API calls needed to sample one data point per minute over 24 hours.In the non-overlapping setting, we computed the average token usage per day and determined the cost using the price of GPT-4-turbo-1106 3 .The daily operational costs were approximately $0.18 for AnoCoT and $0.17 for standard CoT.Extrapolating these figures to an annual perspective, the cost amounts to approximately $65.70 for AnoCoT and $62.05 for standard CoT annually.AnoCoT offers more detailed outputs, it does so at the cost of higher token usage and longer processing times.Despite these variances, the annual costs for both methodologies remain moderate, reinforcing the viability of LLMAD for long-term deployment in TSAD tasks, particularly when interpretability is a crucial requirement.</p>
<p>RELATED WORK</p>
<p>In this section, we review relevant research practices in TSAD and the use of LLMs for time series analysis.</p>
<p>Time Series Anomaly Detection</p>
<p>Time series anomaly detection utilizes a broad range of methodologies.Among these, SPOT [37] applies extreme value theory to detect anomalies in data streams by examining the statistical tails where extreme values are more likely to occur.As a representative supervised learning approach, SRCNN [34] combines spectral with a CNN architecture to create an effective classifier for TSAD.TFAD [53] incorporates time-frequency analysis within a decomposition framework to improve detection capabilities.Unsupervised methods are also popular in this area.For example, Donut [45] uses a variational autoencoder to detect anomalies in seasonal KPIs.Imdiffusion [8] leverages diffusion models to reconstruct time series and uses imputation error as the anomaly identifier.</p>
<p>While these approaches may perform well in specific scenarios, they usually require massive amounts of data for training and lack interpretability, which is particularly important in the TSAD domain.</p>
<p>Large Language Models for Time Series</p>
<p>LLMs have increasingly demonstrated their potential in the field of time series analysis [21,38].Time-LLM [20] has activated LLM capabilities in time series through a novel embedding method that aligns data tokenization and encoding, as well as creating prompts to guide LLMs in time series analysis.LLMTime [14] has shown that LLMs can effectively conduct zero-shot time series forecasting with appropriate pre-processing.Several research studies leverage LLMs to provide interpretable time series analysis.For example, the study [47] experiments with zero-shot/few-shot inference using GPT-4 and instruction-based fine-tuning with Llama [40] to generate explainable forecasts.Research in [22] suggests using LLMs to provide accountability and transparency for time series analysis.</p>
<p>Although this area is becoming more robust, using LLMs for TSAD remains unexplored.We are pioneers in this direction, aiming to deliver accurate and interpretable TSAD using LLMs.</p>
<p>LIMITATIONS</p>
<p>Although LLMAD excels in both accuracy and interpretability, it exhibits several limitations.In general, LLMAD has higher inference latency and cost compared to traditional methods due to its reliance on LLMs.In scenarios that require real-time inference, LLMAD may not be the most suitable choice.However, considering the cost analysis provided in Section 6, the latency and cost are highly acceptable if the data sample size is not too large.Furthermore, LLMAD offers the remarkable additional benefit of interpretability, which cannot be provided by traditional methods</p>
<p>In addition, while our experiments demonstrate the effectiveness of LLMAD across multiple TSAD datasets, they rely on wellcrafted prompts.Creating these prompts benefits from accurate domain knowledge, which ideally should be provided by experienced engineers.This knowledge is necessary to ensure good TSAD performance and interpretability.However, this requirement is a one-time effort, as LLMAD can automatically generate output anomalies and explanations without further human involvement once the domain knowledge has been incorporated.This characteristic makes LLMAD a practical and valuable method for a wide range of applications, balancing the need for expert input with the advantages of automated analysis and interpretation.</p>
<p>CONCLUSION</p>
<p>In this paper, we introduced LLMAD, a novel approach leveraging LLMs to deliver accurate and interpretable time series anomaly detection with low cost.LLMAD retrieves similar samples from historical data to enable ICL to contextualize the dataset and the task of TSAD.It also uses AnoCoT to inject domain knowledge tailored to a specific dataset and instructs LLMAD to think like a human expert for TSAD.These techniques significantly improve the performance and quality of interpretability of TSAD, making the task more effective.Our experimental results on public datasets demonstrate that LLMAD not only achieves competitive performance compared to state-of-the-art methods in terms of Best F1 but also excels in providing comprehensive interpretable insights for further decision-making through human evaluation.This level of interpretability is not achievable by traditional approaches.To the best of our knowledge, we are the pioneers in directly using LLMs for the task of TSAD.-PersistentLevelShiftUp: The data shifts to a higher value and maintains that level consistently, do not return to the original baseline.-Urgent/Error: This category is for values that represent a severe risk, potentially causing immediate damage or harm across all event types whether increases, decreases, spikes, dips, or multiple occurrences.</p>
<p>-Important: Allocated for moderate value changes (both increases and decreases) that could escalate to future problems or system stress but are not immediately hazardous.This also covers upward transient level shifts that concern system longevity and potential failure indications from downward shifts.</p>
<p>-Warning: Used for noticeable deviations from the norm that are not yet critical but merit close monitoring.This includes single spikes and dips that are moderate in nature, as well as multiple non-critical spikes and level shifts that are significant but not yet dangerous.11.The briefExplanation must comprise a explicit three-step analysis results utilizing precise data (do not only repeat the rule):</p>
<p>-Step 1: Assess the overall trend to ascertain if it aligns with expected patterns, thereby identifying any overarching anomalies.</p>
<p>-Step 2: Determine if there is any local data segment with any continuous low or high values compared to the normal data sequence.</p>
<p>-Step 3: Reassess the identified points to confirm their anomalous nature, given the rarity of true anomalies.12. Provide responses in a strict JSON format suitable for direct parsing, without any additional textual commentary.##Response Format { "briefExplanation": {"step1_global": analysis reason, "step2_local": analysis reason, "step3_reassess": analysis reason}, "is_anomaly": false/true, "anomalies": []/[index1, index2, index3, ...], "reason_for_anomaly_type": "no"/"reason for anomaly type", "anomaly_type": "no"/"classification of main anomaly",(only one) "reason_for_alarm_level": "no"/"reason for alarm level", "alarm_level": "no"/"Urgent/Error"/"Important"/"Warning",(only one) } ##Data Please analyze the latest data with the highest level of diligence and caution: -Historical normal data sequence: {normal_data} -Historical anomaly data sequence(<em>XXX</em> is anomaly point), {anomaly_data} -The latest {data_len} data points for evaluation: {data} Table 12: The prompt for KPI dataset.</p>
<h2>Instructions</h2>
<p>Determine if there are any anomalies in the provided AIOPS flow data sequence.##Following Rules: 1.A data point is considered an anomaly if it is part of a sequence of at least one consecutive anomalous points or continues to plummet or surge abruptly.2. Given that the vast majority of data points are expected to be no anomaly, Anomalies are exceedingly rare and should only be identified with absolute certainty.3. Normal data may exhibit volatility, which should not be mistaken for anomalies.4. Mislabeling normal data as an anomaly can lead to catastrophic failures.Exercise extreme caution.False positives are unacceptable.5.If do not have 100 percent confidence that data is an anomaly, do not flag it as an anomaly.6.The output of anomaly intervals needs to be accurately located and should not be excessively long.7. anomaly_type should be one of the following: -PersistentLevelShiftUp: The data shifts to a higher value and maintains that level consistently, do not return to the original baseline.like 1 2 1 2 1 2 <em>500</em> <em>480</em> <em>510</em> <em>500</em> <em>500</em> -PersistentLevelShiftDown: The data shifts to a lower value and maintains that level consistently, do not return to the original baseline.like 1 2 1 2 <em>-100</em> <em>-102</em> <em>-104</em> <em>-110</em> <em>-110</em> -TransientLevelShiftUp: The data temporarily shifts to a higher value and then returning to the original baseline, the anomaly maintains for at least 5 data points and return to baseline like 1 2 1 2 1 2 <em>500</em> <em>500</em> <em>499</em> <em>510</em> <em>500</em> 1 2 1 2 -TransientLevelShiftDown: The data temporarily shifts to a lower value and then returning to the original baseline, the anomaly maintains for at least 5 data points return to baseline like 1 2 1 2 <em>-100</em> <em>-102</em> <em>-104</em> <em>-110</em> <em>-100</em> 1 2 1 2 -SingleSpike: A brief, sharp rise in data value followed by an immediate return to the baseline.like 1 2 1 2 1 2 <em>200</em> <em>500</em> 1 2 -SingleDip: A brief, sharp drop in data value followed by an immediate return to the baseline.like 1 2 1 2 <em>-500</em> <em>-200</em> 1 2 1 2 -MultipleSpikes: Several brief, sharp rises in data value, each followed by a return to the baseline.like 1 2 <em>500</em> 3 2 <em>510</em> <em>200</em> 1 2 <em>480</em> 1 2 -MultipleDips: Several brief, sharp drops in data value, each followed by a return to the baseline.like 1 2 <em>-100</em> 3 2 <em>-110</em> <em>-200</em> 1 2 <em>-120</em> 1 2 8. alarm_level should be one of the following: -Urgent/Error: This category is for values that represent a severe risk, potentially causing immediate damage or harm across all event types whether increases, decreases, spikes, dips, or multiple occurrences.</p>
<p>-Important: Allocated for moderate value changes (both increases and decreases) that could escalate to future problems or system stress but are not immediately hazardous.This also covers upward transient level shifts that concern system longevity and potential failure indications from downward shifts.-Warning: Used for noticeable deviations from the norm that are not yet critical but merit close monitoring.This includes single spikes and dips that are moderate in nature, as well as multiple non-critical spikes and level shifts that are significant but not yet dangerous.9.The briefExplanation must comprise a explicit three-step analysis utilizing precise data (do not only repeat the rule): -Step 1: Assess the overall trend to ascertain if it aligns with expected patterns, thereby identifying any overarching anomalies.-Step 2: Examine the local data segments to detect any specific deviations or anomalies.-Step 3: Reassess the identified points to confirm their anomalous nature, given the rarity of true anomalies.This step ensures that the detected points are not merely normal fluctuations or seasonal variations.10.Provide responses in a strict JSON format suitable for direct parsing, without any additional textual commentary.##Response Format { "briefExplanation": {"step1_global": analysis reason, "step2_local": analysis reason, "step3_reassess": analysis reason}, "is_anomaly": false/true, "anomalies": []/[index1, index2, index3, ...], "reason_for_anomaly_type": "no"/"reason for anomaly type", "anomaly_type": "no"/"classification of main anomaly",(only one) "reason_for_alarm_level": "no"/"reason for alarm level", "alarm_level": "no"/"Urgent/Error"/"Important"/"Warning",(only one) } ##Data Please analyze the latest data with the highest level of diligence and caution: -Historical normal data sequence: {normal_data} -Historical anomaly data sequence(<em>XXX</em> is anomaly point), {anomaly_data} -The latest {data_len} data points for evaluation: {data} Table 13: The prompt for Yahoo A3Benchmark, A4Benchmark, and Synthetic sub-datasets.</p>
<h2>Instructions</h2>
<p>Determine if there are any anomalies in the provided AIOPS flow data sequence.##Following Rules: 1.A data point is considered an anomaly if it is part of a sequence of at least one consecutive anomalous points or continues to plummet or surge abruptly.2. Typically, anomalies are outliers such as spikes and dips, which are often isolated points.Be aware that there may be multiple anomalies present; you should identify all possible anomalous data points.3. Given that the vast majority of data points are expected to be no anomaly, Anomalies are exceedingly rare and should only be identified with absolute certainty.4. Mislabeling normal data as an anomaly can lead to catastrophic failures.Exercise extreme caution.False positives are unacceptable.5.If do not have 100 percent confidence that data is an anomaly, do not flag it as an anomaly.6.The output of anomaly intervals needs to be accurately located and should not be excessively long.7. anomaly_type should be one of the following: -SingleSpike: A brief, sharp rise in data value followed by an immediate return to the baseline.like 1 2 1 2 1 2 <em>200</em> <em>500</em> 1 2 -SingleDip: A brief, sharp drop in data value followed by an immediate return to the baseline.like 1 2 1 2 <em>-500</em> <em>-200</em> 1 2 1 2 8. alarm_level should be one of the following: -Urgent/Error: This category is for values that represent a severe risk, potentially causing immediate damage or harm across all event types whether increases, decreases, spikes, dips, or multiple occurrences.</p>
<p>-Important: Allocated for moderate value changes (both increases and decreases) that could escalate to future problems or system stress but are not immediately hazardous.This also covers upward transient level shifts that concern system longevity and potential failure indications from downward shifts.</p>
<p>-Warning: Used for noticeable deviations from the norm that are not yet critical but merit close monitoring.This includes single spikes and dips that are moderate in nature, as well as multiple non-critical spikes and level shifts that are significant but not yet dangerous.9.The briefExplanation must comprise a explicit two-step analysis results utilizing precise data (do not only repeat the rule): -Step 1: Examine the local data point to detect any specific deviations or anomalies.You should identify all possible anomalous data points.</p>
<p>-Step 2: Reassess the identified points to confirm their anomalous nature, given the rarity of true anomalies.10.Provide responses in a strict JSON format suitable for direct parsing, without any additional textual commentary.##Response Format { "briefExplanation": {"step1_local": analysis reason, "step2_reasses": analysis reason}, "is_anomaly": false/true, "anomalies": []/[index1, index2, index3, ...], "reason_for_anomaly_type": "no"/"reason for anomaly type", "anomaly_type": "no"/"classification of main anomaly", "reason_for_alarm_level": "no"/"reason for alarm level", "alarm_level": "no"/"Urgent/Error"/"Important"/"Warning" } ##Data Please analyze the latest data with the highest level of diligence and caution: -Historical normal data sequence: {normal_data} -Historical anomaly data sequence(<em>XXX</em> is anomaly point), {anomaly_data} -The latest {data_len} data points for evaluation: {data} Table 14: The prompt for Yahoo real subset ##Instructions: Determine if there are any anomalies in the provided AIOPS flow data sequence.##Following Rules: 1.A data point is considered an anomaly if it is part of a sequence of at least one consecutive anomalous points or continues to plummet or surge abruptly.2. A data point is considered an anomaly if it is identified as a continuous low/high value anomaly if it remains below/above a predefined normal threshold for a prolonged duration, deviating from the anticipated norm.3. Given that the vast majority of data points are expected to be no anomaly, Anomalies are exceedingly rare and should only be identified with absolute certainty.4. Normal data may exhibit volatility, which should not be mistaken for anomalies.5. Mislabeling normal data as an anomaly can lead to catastrophic failures.Exercise extreme caution.False positives are unacceptable.6.If do not have high percent confidence that data is an anomaly, do not flag it as an anomaly.7. The output of anomaly intervals needs to be accurately located and should not be excessively long.8.The number of abnormal intervals within a detection range can not exceed 3. 9. anomaly_type should be one of the following: -PersistentLevelShiftUp The data shifts to a higher value and maintains that level consistently, do not return to the original baseline.-Urgent/Error This category is for values that represent a severe risk, potentially causing immediate damage or harm across all event types whether increases, decreases, spikes, dips, or multiple occurrences.</p>
<p>-Important Allocated for moderate value changes (both increases and decreases) that could escalate to future problems or system stress but are not immediately hazardous.This also covers upward transient level shifts that concern system longevity and potential failure indications from downward shifts.-Warning Used for noticeable deviations from the norm that are not yet critical but merit close monitoring.This includes single spikes and dips that are moderate in nature, as well as multiple non-critical spikes and level shifts that are significant but not yet dangerous.11.The briefExplanation must comprise a explicit three-step analysis results utilizing precise data (do not only repeat the rule): -Step 1: Assess the overall trend to ascertain if it aligns with expected patterns, thereby identifying any overarching anomalies.</p>
<p>-Step 2: Determine if there is any local data segment with any continuous low or high values compared to the normal data sequence.</p>
<p>-Step 3: Reassess the identified points to confirm their anomalous nature, given the rarity of true anomalies.12. Provide responses in a strict JSON format suitable for direct parsing, without any additional textual commentary.##Response Format: { "briefExplanation": {"step1_global": analysis reason, "step2_local": analysis reason, "step3_reassess": analysis reason}, "is_anomaly": false/true, "anomalies": []/[index1, index2, index3, ...], "reason_for_anomaly_type": "no"/"reason for anomaly type", "anomaly_type": "no"/"classification of main anomaly",(only one) "reason_for_alarm_level": "no"/"reason for alarm level", "alarm_level": "no"/"Urgent/Error"/"Important"/"Warning",(only one) } ##Data: Please analyze the latest data with the highest level of diligence and caution: -Historical normal data sequence: {normal_data} -Historical anomaly data sequence(<em>XXX</em> is anomaly point), {anomaly_data} -The latest {data_len} data points for evaluation: {data}</p>
<p>Figure 1 :
1
Figure 1: Time series anomaly detection for traditional deep learning methods and LLMs.</p>
<p>) Anomaly Types: Classifying anomalies into different types (e.g., spike, shift up) enhances the interpretability of TSAD by categorizing unusual patterns based on their characteristics and potential implications.This classification helps in prioritizing responses and</p>
<p>Figure 2 :
2
Figure 2: The overview of LLMAD.</p>
<p>Figure 3 :
3
Figure 3: Construction of Time Series Retrieval Databases and Time Series Retrieval.</p>
<p>like <code>1 2 1 2 1 2 *500* *480* -**LevelShiftDown** The data shifts to a lower value and maintains that level consistently, do not return to the original baseline.like</code>1 2 1 2 <em>-100</em> <em>-102</em> Àlarm Levels Definition: <strong>Urgent/Error</strong>: This category is for values that represent a severe risk, potentially causing immediate damage.<strong>Important</strong>: …, <strong>Warning</strong>:… Chain of Thought Prompting: -Step 1: Assess the overall trend to ascertain if it aligns with expected patterns, thereby identifying any overarching anomalies.-Step 2: Examine the local data segments to detect any specific deviations or anomalies.-Step 3: Reassess the identified points to confirm their anomalous nature, given the rarity of true anomalies.This step ensures that the detected points are not merely normal fluctuations or seasonal variations.In-context Prompting: Please analyze the latest data with the highest level of diligence and caution: Historical normal data sequence: <code>{normal_data}</code>.Historical anomaly data sequence(<em>XXX</em> is anomaly point): <code>{anomaly_data}</code>.The latest <code>{data_len}</code> data points for evaluation: `{data}F igure 4: The overall structure of the prompt.</p>
<p>Figure 6 :
6
Figure 6: An illustration of the delay F1.</p>
<p>Figure 7 :
7
Figure 7: Performance comparison of different prompting schemes.</p>
<p>Figure 8 :
8
Figure 8: Two case study of anomaly interpretation delivered by LLMAD.</p>
<p>Figure 9 :
9
Figure 9: Visualization of anomaly detection results and retrieved ICL data for the Yahoo datase.</p>
<p>like 1 2
2
1 2 1 2 <em>500</em> <em>480</em> <em>510</em> <em>500</em> <em>500</em> -PersistentLevelShiftDown: The data shifts to a lower value and maintains that level consistently, do not return to the original baseline.like 1 2 1 2 <em>-100</em> <em>-102</em> <em>-104</em> <em>-110</em> <em>-110</em> -TransientLevelShiftUp: The data temporarily shifts to a higher value and then returning to the original baseline, the anomaly maintains for at least 5 data points.like 1 2 1 2 1 2 <em>500</em> <em>500</em> <em>499</em> <em>510</em> <em>500</em> 1 2 1 2 -TransientLevelShiftDown: The data temporarily shifts to a lower value and then returning to the original baseline, the anomaly maintains for at least 5 data points.like 1 2 1 2 <em>-100</em> <em>-102</em> <em>-104</em> <em>-110</em> <em>-100</em> 1 2 1 2 -SingleSpike: A brief, sharp rise in data value followed by an immediate return to the baseline.like 1 2 1 2 1 2 <em>200</em> <em>500</em> 1 2 -SingleDip: A brief, sharp drop in data value followed by an immediate return to the baseline.like 1 2 1 2 <em>-500</em> <em>-200</em> 1 2 1 2 -MultipleSpikes: Several brief, sharp rises in data value, each followed by a return to the baseline.like 1 2 <em>500</em> 3 2 <em>510</em> <em>200</em> 1 2 <em>480</em> 1 2 -MultipleDips: Several brief, sharp drops in data value, each followed by a return to the baseline.like 1 2 <em>-100</em> 3 2 <em>-110</em> <em>-200</em> 1 2 <em>-120</em> 1 2 10. alarm_level should be one of the following:</p>
<p>like 1 2 1 2 1 2 <em>500</em> <em>480</em> <em>510</em> <em>500</em> <em>500</em> -PersistentLevelShiftDown The data shifts to a lower value and maintains that level consistently, do not return to the original baseline.like 1 2 1 2 <em>-100</em> <em>-102</em> <em>-104</em> <em>-110</em> <em>-110</em> -TransientLevelShiftUp The data temporarily shifts to a higher value and then returning to the original baseline, the anomaly maintains for at least 5 data points.like 1 2 1 2 1 2 <em>500</em> <em>500</em> <em>499</em> <em>510</em> <em>500</em> 1 2 1 2 -TransientLevelShiftDown The data temporarily shifts to a lower value and then returning to the original baseline, the anomaly maintains for at least 5 data points.like 1 2 1 2 <em>-100</em> <em>-102</em> <em>-104</em> <em>-110</em> <em>-100</em> 1 2 1 2 SingleSpike A brief, sharp rise in data value followed by an immediate return to the baseline.like 1 2 1 2 1 2 <em>200</em> <em>500</em> 1 2 SingleDip A brief, sharp drop in data value followed by an immediate return to the baseline.like 1 2 1 2 <em>-500</em> <em>-200</em> 1 2 1 2 MultipleSpikes Several brief, sharp rises in data value, each followed by a return to the baseline.like 1 2 <em>500</em> 3 2 <em>510</em> <em>200</em> 1 2 <em>480</em> 1 2 -MultipleDips Several brief, sharp drops in data value, each followed by a return to the baseline.like 1 2 <em>-100</em> 3 2 <em>-110</em> <em>-200</em> 1 2 <em>-120</em> 1 2 10. alarm_level should be one of the following:</p>
<p>The Structure of Prompt Task Description:</p>
<p>Determine if there are any anomalies in the provided AIOPS flow data sequence.
Domain Knowledge:Jugdment Rules:1. A data point is considered an anomaly if it is part of a sequence of at least one consecutive anomalous points or continues to plummet or surge abruptly.2. Anomalies are exceedingly rare and should only be identified with absolute certainty…….Anomaly Types Definition:</p>
<p>Table 1 :
1
The statistics of time series anomaly detection dataset employed in the experiments.Dataset All Points Test Points Anomalies Real * Synthetic * This dataset primarily consists of Key Performance Indicators (KPIs) from internet company business monitoring, such as website traffic and server CPU usage rates.These data are crucial for real-time monitoring of system health.• Yahoo [27]: Released by Yahoo Labs, this dataset includes both real-world and synthetic time series data suitable for anomaly detection and predictive model assessment.It encompasses a variety of anomaly types, such as point anomalies and contextual anomalies, providing a rich testing ground for algorithms.
KPI6,198,513309,9252.35%✓✗Yahoo738,866369,4330.71%✓✓WSD7,898,005394,9001.56%✓✗4.1 Experiment SetupDataset. We utilized three univariate time series datasets com-monly employed in TSAD, to evaluate the performance. Theseinclude:• KPI [28]:
[54]D[54]: This dataset focuses on anomaly detection in Web service performance indicators, such as response times and error rates.The data aids in monitoring the quality of Web services, quickly identifying issues like service delays and functional failures.</p>
<p>Table 2 :
2
The overall experimental results across three TSAD datasets.Bold numbers denote the best performance among all models, underlined signify the second-best performance.
KPIWSDYahooAverageMethodBest F1 Delayed F1 Best F1 Delayed F1 Best F1 Delayed F1 Best F1 Delayed F1SPOT0.2690.2690.2730.2730.4170.4170.3200.320SRCNN0.6170.4880.2860.2310.2510.1980.3850.306DONUT0.3820.2940.2240.1410.2150.2150.2740.217VQRAE0.2720.1370.1790.1890.5100.4920.3200.273Anotransfer0.6850.4610.6740.3790.5670.4960.6420.445Informer0.8590.7150.5340.3700.7070.6710.7000.585TFAD0.7510.6310.6440.3960.7790.7750.7250.601Anomaly Transformer0.9180.3360.6700.0920.2740.0290.6210.152LLMTIME0.3330.1940.0290.0220.0230.0230.1280.080LLMAD0.8430.6670.7110.4010.7240.6950.7590.588</p>
<p>Table 3 :
3
Performance comparison of different settings of ICL.
WSDKPIYahooSampleNumberBest F1 Delayed F1 Best F1 Delayed F1 Best F1 Delayed F11 pos0.5480.3040.7560.3050.6020.6021 neg0.5950.3270.7680.4310.6220.622Dynamic1 pos/1 neg0.6530.3350.8160.6410.6790.6552 pos/1 neg0.7110.4010.8430.6670.7240.6954 pos/1 neg0.7160.4090.8120.6970.6910.669Fixed4 pos/1 neg0.5470.3510.7330.2830.6380.602Zero-shot-0.5120.2700.7110.2770.5740.5630.4 0.6 0.8 1.0 F1 Score0.535 No CoT 0.670 CoT AnoCoT0.7160.6540.7810.8430.6210.6450.7240.20.0WSDKPI DatasetYahoo</p>
<p>Table 4 :
4
Comparison of LLMAD on using different LLMs.
WSDKPIYahooModelBest F1 Delayed F1 Best F1 Delayed F1 Best F1 Delayed F1Llama-3-70B0.3600.2640.7010.2890.4900.471GPT-3.50.2330.0690.4090.1340.2040.194GPT-40.7160.4090.8430.6670.7240.695</p>
<p>Table 5 :
5
Ablation studies for domain knowledge injection.
MethodWSDKPIYahooBest F1 Delayed F1 Best F1 Delayed F1 Best F1 Delayed F1LLMAD0.7160.4090.8430.6670.7240.695-w/o rule0.4230.2280.6520.3830.5550.550-w/o type0.5650.3780.7750.4490.6430.631-w/o level0.6960.3530.8100.6280.7000.688</p>
<p>Table 6 :
6
Results of human evaluation for explanation generated by LLMAD.
AnoCoTStandard CoTRatersUsefulnessReadabilityUsefulnessReadabilityMean StdHIPMean StdHIPMean StdHIPMean StdHIPRater14.450.95 78.35%2.980.14 100.00%3.851.56 62.89%2.930.30 98.97%Rater24.220.93 76.29%2.370.63 91.75%3.791.03 63.92%2.050.55 87.63%Rater34.090.98 79.38%2.940.24 100.00%3.570.86 56.70%2.940.24 100.00%Rater43.801.04 64.95%2.310.47 98.97%3.291.43 49.48%2.300.66 88.66%Rater53.751.23 62.89%2.700.62 94.85%3.411.19 47.42%2.650.52 97.81%Average4.061.03 72.37%2.660.42 97.11%3.581.21 56.08%2.570.45 94.61%</p>
<p>2 local: Identified data point 63 as a high spike (706) compared to surrounding values of 462 and 329, point 111 as a high spike (724) compared to 478 and 368, point 146 as a high spike (645) compared to 403 and 284, point 192 as a deep dip (66) compared to 341 and 321, and point 251 as a high spike (670) compared to 320 and 393.Step 3 recheck: Upon reassessing, data point 63, 111, 146, 192, and 251 are determined as anomalies because they significantly deviate from the trend and neighboring points.No other points exhibit this extreme behavior and the high spikes align with historical anomaly examples provided.</p>
<p>Table 7 :
7
Results of the evaluation for anomaly type classification.
WSDKPIYahooModelAcc  *  Micro F1 Acc  *  Micro F1 Acc  *  Micro F1Llama-3-70B 0.3790.4000.2860.2500.6000.552GPT-3.50.3100.3210.1430.1630.3750.380GPT-40.9000.7760.7900.6470.9300.804</p>
<p>Table 8 :
8
Cost and latency analysis for LLMAD.
AnoCoTCoTCost ItemsMean Std MeanStdInput Tokens4,208 6464,115652Output Tokens281 12218990API Calling Time (s)14.91 7.5910.525.07Total Time (s)17.03 7.7113.34 11.26Daily Cost (USD)0.18 0.040.170.03spikes, which could indicate critical transient events. In its expla-nation, LLMAD Pinpoints the specific anomalous points, Deliversreasoning steps by comparing them with normal patterns, and</p>
<p>Table 11 :
11
The prompt for WSD dataset.##InstructionsDetermineif there are any anomalies in the provided AIOPS flow data sequence.##Following Rules: 1.A data point is considered an anomaly if it is part of a sequence of at least one consecutive anomalous points or continues to plummet or surge abruptly.2. A data point is considered an anomaly if it is identified as a continuous low/high value anomaly if it remains below/above a predefined normal threshold for a prolonged duration, deviating from the anticipated norm.3. Given that the vast majority of data points are expected to be no anomaly, Anomalies are exceedingly rare and should only be identified with absolute certainty.4. Normal data may exhibit volatility, which should not be mistaken for anomalies.5. Mislabeling normal data as an anomaly can lead to catastrophic failures.Exercise extreme caution.False positives are unacceptable.6.If do not have 100 percent confidence that data is an anomaly, do not flag it as an anomaly.7. The output of anomaly intervals needs to be accurately located and should not be excessively long.8.The number of abnormal intervals within a detection range can not exceed 3. 9. anomaly_type should be one of the following:</p>
<p>"Real" indicates datasets derived from real-world data sources. "Synthetic" denotes datasets that have been artificially created to include specific anomalies.
 OpenAI. (2024). Pricing. Retrieved from https://openai.com/pricing. Specifically, the cost is $0.01 per 1,000 tokens for input and $0.03 per 1,000 tokens for output.
A IMPLEMENTATION DETAILS A.1 Hyperparameters GPT-4: We use GPT-4-1106-preview as our baseline model for the main and ablation experiments.A grid search is performed over  ∈ [0.8, 0.95, 0.99],  ∈ [0, 0.05, 0.15], with a temperature of 0.7.GPT-3.5:We use GPT-3.5-turbo and perform a grid search over  ∈ [0.8, 0.95, 0.99],  ∈ [0, 0.05, 0.15], with a temperature of 0.7.Llama: We select the Llama-3-70B-instruct version as the comparison model and perform a grid search over  ∈ [0.8, 0.95, 0.99],  ∈ [0, 0.05, 0.15], with a temperature of 1.0.B VISUALIZATION RESULTSFigure9presents visualizations of LLMAD's predictions (a GPT-4-based model) and retrieval results on the Yahoo datasets for a subset of each time series set.C INTERPRETABILITY EVALUATION CRITERIATo comprehensively evaluate the explanation text generating by LLMAD, we adopt usefulness and readability as the primary criteria.These criteria are instrumental in assessing how the explanations generated by LLMAD facilitate a better understanding and actionable insights into detected anomalies.Specifically,(1) Usefulness: This criterion evaluates the extent to which the model's explanations contribute to the accurate and efficient resolution of anomalies.Explanations are scored on a scale from 1 (incorrect and irrelevant) to 5 (correct, detailed, and clear), with higher scores indicating that the explanation effectively assists in diagnosing and resolving anomalies, as well as accurately determining the urgency level.(2) Readability: This criterion assesses the ease with which users can comprehend the explanations, focusing on their humanreadability.This factor is essential for ensuring that the insights are both accessible and actionable.It is measured on a scale from 1 (difficult to understand) to 3 (high quality), with higher scores signifying enhanced clarity and ease of comprehension.The aforementioned criteria, usefulness and readability, are widely employed for LLM evaluation due to their significance in assessing the practicality and accessibility of generated explanations.A high usefulness score suggests that the explanations are accurate and beneficial for decision-making processes.Likewise, a high readability score indicates that the information is user-friendly, thereby improving operational efficiency by facilitating a better comprehension of the explanations and underlying reasoning.D DETAILED PROMPTDifferent datasets have varying definitions of anomalies.Based on the feature of each dataset, we made specific adjustments to the base prompt in Figure4.D.1 WSD datasetsThe TSAD prompt for the WSD dataset is shown in Table11.D.2 KPI datasetsThe TSAD prompt for the KPI dataset is shown in Table12.D.3 Yahoo datasetsGiven that the Yahoo dataset comprises multiple sub-datasets, we developed two prompts.The first prompt is tailored for the Yahoo real dataset and is analogous to the prompts used for KPI and WSD, as detailed in Table13.The second prompt is designed for the A3Benchmark, A4Benchmark, and synthetic sub-datasets.In these sub-datasets, most anomalies are local; therefore, we focus exclusively on detecting single spikes and single dips, omitting the global step from AnoCoT, as illustrated in Table14.
Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, arXiv:2303.08774Shyamal Anadkat, et al. 2023. Gpt-4 technical report. 2023arXiv preprint</p>
<p>Anomaly detection on big data in financial markets. Mohiuddin Ahmed, Nazim Choudhury, Shahadat Uddin, Proceedings of the 2017 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining. the 2017 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining2017. 2017</p>
<p>Toward explainable deep neural network based anomaly detection. Kasun Amarasinghe, Kevin Kenney, Milos Manic, 2018 11th international conference on human system interaction (HSI). IEEE2018</p>
<p>A review on outlier/anomaly detection in time series data. Ane Blázquez-García, Angel Conde, Usue Mori, Jose A Lozano, ACM Computing Surveys (CSUR). 542021. 2021</p>
<p>Language models are few-shot learners. Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Advances in neural information processing systems. 332020. 2020</p>
<p>Tom B Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, arXiv:2005.14165[cs.CL]Ilya Sutskever, and Dario Amodei. 2020. Language Models are Few-Shot Learners. Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford</p>
<p>Automatic root cause analysis via large language models for cloud incidents. Yinfang Chen, Huaibing Xie, Minghua Ma, Yu Kang, Xin Gao, Liu Shi, Yunjie Cao, Xuedong Gao, Ming Hao Fan, Wen, Proceedings of the Nineteenth European Conference on Computer Systems. the Nineteenth European Conference on Computer Systems2024</p>
<p>ImDiffusion: Imputed Diffusion Models for Multivariate Time Series Anomaly Detection. Yuhang Chen, Chaoyun Zhang, Minghua Ma, Yudong Liu, Ruomeng Ding, Bowen Li, Shilin He, Saravan Rajmohan, Qingwei Lin, Dongmei Zhang, Proceedings of the VLDB Endowment. the VLDB Endowment2023. 202317</p>
<p>Anomaly detection for IoT time-series data: A survey. Göksel Andrew A Cook, Zhong Mısırlı, Fan, IEEE Internet of Things Journal. 72019. 2019</p>
<p>Time Series Anomaly Detection Based on Language Model. Weixia Dang, Biyu Zhou, Weigang Zhang, Songlin Hu, Proceedings of the Eleventh ACM International Conference on Future Energy Systems. the Eleventh ACM International Conference on Future Energy Systems2020</p>
<p>Everything of thoughts: Defying the law of penrose triangle for thought generation. Ruomeng Ding, Chaoyun Zhang, Lu Wang, Yong Xu, Minghua Ma, Wei Zhang, Si Qin, Saravan Rajmohan, Qingwei Lin, Dongmei Zhang, arXiv:2311.042542023. 2023arXiv preprint</p>
<p>Qingxiu Dong, Lei Li, Damai Dai, Ce Zheng, Zhiyong Wu, Baobao Chang, Xu Sun, Jingjing Xu, Zhifang Sui, arXiv:2301.00234A survey on in-context learning. 2022. 2022arXiv preprint</p>
<p>Jinglong Gao, Xiao Ding, Bing Qin, Ting Liu, arXiv:2305.07375Is chatgpt a good causal reasoner? a comprehensive evaluation. 2023. 2023arXiv preprint</p>
<p>Large language models are zero-shot time series forecasters. Nate Gruver, Marc Finzi, Shikai Qiu, Andrew G Wilson, Advances in Neural Information Processing Systems. 362024. 2024</p>
<p>The elements of statistical learning: data mining, inference, and prediction. Trevor Hastie, Robert Tibshirani, Jerome H Friedman, Jerome H Friedman, 2009Springer2</p>
<p>Unsupervised online anomaly detection on multivariate sensing time series data for smart manufacturing. Ruei-Jie Hsieh, Jerry Chou, Chih-Hsiang Ho, 2019 IEEE 12th conference on service-oriented computing and applications (SOCA). IEEE2019</p>
<p>Exathlon: A benchmark for explainable anomaly detection over time series. Vincent Jacob, Fei Song, Arnaud Stiegler, Bijan Rad, Yanlei Diao, Nesime Tatbul, arXiv:2010.050732020. 2020arXiv preprint</p>
<p>Exathlon: a benchmark for explainable anomaly detection over time series. Vincent Jacob, Fei Song, Arnaud Stiegler, Bijan Rad, Yanlei Diao, Nesime Tatbul, Proceedings of the VLDB Endowment. 142021. 2021</p>
<p>Xpert: Empowering incident management with query recommendations via large language models. Yuxuan Jiang, Chaoyun Zhang, Shilin He, Zhihao Yang, Minghua Ma, Si Qin, Yu Kang, Yingnong Dang, Saravan Rajmohan, Qingwei Lin, Proceedings of the IEEE/ACM 46th International Conference on Software Engineering. the IEEE/ACM 46th International Conference on Software Engineering2024</p>
<p>Ming Jin, Shiyu Wang, Lintao Ma, Zhixuan Chu, James Y Zhang, Xiaoming Shi, Pin-Yu Chen, Yuxuan Liang, Yuan-Fang Li, Shirui Pan, arXiv:2310.01728Time-llm: Time series forecasting by reprogramming large language models. 2023. 2023arXiv preprint</p>
<p>Large models for time series and spatio-temporal data: A survey and outlook. Ming Jin, Qingsong Wen, Yuxuan Liang, Chaoli Zhang, Siqiao Xue, Xue Wang, James Zhang, Yi Wang, Haifeng Chen, Xiaoli Li, arXiv:2310.101962023. 2023arXiv preprint</p>
<p>Ming Jin, Yifan Zhang, Wei Chen, Kexin Zhang, Yuxuan Liang, Bin Yang, Jindong Wang, Shirui Pan, Qingsong Wen, arXiv:2402.02713Position Paper: What Can Large Language Models Tell Us about Time Series Analysis. 2024. 2024arXiv preprint</p>
<p>Assess and Summarize: Improve Outage Understanding with Large Language Models. Pengxiang Jin, Shenglin Zhang, Minghua Ma, Haozhe Li, Yu Kang, Liqun Li, Yudong Liu, Bo Qiao, Chaoyun Zhang, Pu Zhao, Proceedings of the Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering. the Joint European Software Engineering Conference and Symposium on the Foundations of Software EngineeringESEC/FSE2023</p>
<p>Exact indexing of dynamic time warping. Eamonn Keogh, Ann Chotirat, Ratanamahatana, Knowledge and information systems. 72005. 2005</p>
<p>Anomaly detection in time series with robust variational quasi-recurrent autoencoders. Tung Kieu, Bin Yang, Chenjuan Guo, Razvan-Gabriel Cirstea, Yan Zhao, Yale Song, Christian S Jensen, 2022 IEEE 38th International Conference on Data Engineering (ICDE). IEEE2022</p>
<p>Large language models are zero-shot reasoners. Takeshi Kojima, Shane Shixiang, Machel Gu, Yutaka Reid, Yusuke Matsuo, Iwasawa, Advances in neural information processing systems. 352022. 2022</p>
<p>A benchmark dataset for time series anomaly detection. Nikolay Laptev, Saeed Amizadeh, Youssef Billawala, 2015. 2015von Yahoo Research</p>
<p>Zeyan Li, Nengwen Zhao, Shenglin Zhang, Yongqian Sun, Pengfei Chen, Xidao Wen, Minghua Ma, Dan Pei, arXiv:2208.03938Constructing large-scale real-world benchmark datasets for aiops. 2022. 2022arXiv preprint</p>
<p>Yilun Liu, Shimin Tao, Weibin Meng, Jingyu Wang, Wenbing Ma, Yanqing Zhao, Yuhang Chen, Hao Yang, Yanfei Jiang, Xun Chen, arXiv:2308.07610Logprompt: Prompt engineering towards zero-shot and interpretable log analysis. 2023. 2023arXiv preprint</p>
<p>Robust and rapid adaption for concept drift in software system anomaly detection. Minghua Ma, Shenglin Zhang, Dan Pei, Xin Huang, Hongwei Dai, 2018 IEEE 29th International Symposium on Software Reliability Engineering (ISSRE). IEEE2018</p>
<p>Introducing Meta Llama 3: The Most Capable Openly Available LLM to Date. Meta. 2024</p>
<p>Sewon Min, Xinxi Lyu, Ari Holtzman, Mikel Artetxe, Mike Lewis, Hannaneh Hajishirzi, Luke Zettlemoyer, arXiv:2202.12837Rethinking the role of demonstrations: What makes in-context learning work?. 2022. 2022arXiv preprint</p>
<p>Explainable anomaly detection on high-dimensional time series data. Bijan Rad, Fei Song, Vincent Jacob, Yanlei Diao, Proceedings of the 15th ACM International Conference on Distributed and Event-based Systems. the 15th ACM International Conference on Distributed and Event-based Systems2021</p>
<p>Time-series anomaly detection service at microsoft. Bixiong Hansheng Ren, Yujing Xu, Chao Wang, Congrui Yi, Xiaoyu Huang, Tony Kou, Mao Xing, Jie Yang, Qi Tong, Zhang, Proceedings of the 25th ACM SIGKDD international conference on knowledge discovery &amp; data mining. the 25th ACM SIGKDD international conference on knowledge discovery &amp; data mining2019</p>
<p>FastDTW: Toward accurate dynamic time warping in linear time and space. Stan Salvador, Philip Chan, KDD workshop on mining temporal and sequential data. Seattle, Washington20046</p>
<p>Anomaly detection in time series: a comprehensive evaluation. Sebastian Schmidl, Phillip Wenig, Thorsten Papenbrock, Proceedings of the VLDB Endowment. the VLDB Endowment2022. 202215</p>
<p>Anomaly detection in streams with extreme value theory. Alban Siffer, Pierre-Alain Fouque, Alexandre Termier, Christine Largouet, Proceedings of the 23rd ACM SIGKDD international conference on knowledge discovery and data mining. the 23rd ACM SIGKDD international conference on knowledge discovery and data mining2017</p>
<p>Large Language Models for Forecasting and Anomaly Detection: A Systematic Literature Review. Jing Su, Chufeng Jiang, Xin Jin, Yuxin Qiao, Tingsong Xiao, Hongda Ma, Rong Wei, Zhi Jing, Jiajun Xu, Junhong Lin, arXiv:2402.103502024. 2024arXiv preprint</p>
<p>GRUbased interpretable multivariate time series anomaly detection in industrial control system. Chaofan Tang, Lijuan Xu, Bo Yang, Yongwei Tang, Dawei Zhao, Computers &amp; Security. 1271030942023. 2023</p>
<p>Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, arXiv:2307.09288Shruti Bhosale, et al. 2023. Llama 2: Open foundation and fine-tuned chat models. 2023arXiv preprint</p>
<p>Root Cause Analysis for Microservice Systems via Hierarchical Reinforcement Learning from Human Feedback. Lu Wang, Chaoyun Zhang, Ruomeng Ding, Yong Xu, Qihang Chen, Wentao Zou, Qingjun Chen, Meng Zhang, Xuedong Gao, Hao Fan, Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining. the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining2023</p>
<p>Experimental comparison of representation methods and distance measures for time series data. Xiaoyue Wang, Abdullah Mueen, Hui Ding, Goce Trajcevski, Peter Scheuermann, Eamonn Keogh, Data Mining and Knowledge Discovery. 262013. 2013</p>
<p>Chain-of-thought prompting elicits reasoning in large language models. Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Denny Quoc V Le, Zhou, Advances in neural information processing systems. 352022. 2022</p>
<p>Identifying rootcause metrics for incident diagnosis in online service systems. Canhua Wu, Nengwen Zhao, Lixin Wang, Xiaoqin Yang, Shining Li, Ming Zhang, Xing Jin, Xidao Wen, Xiaohui Nie, Wenchi Zhang, 2021 IEEE 32nd International Symposium on Software Reliability Engineering (ISSRE). IEEE2021</p>
<p>Unsupervised anomaly detection via variational auto-encoder for seasonal kpis in web applications. Haowen Xu, Wenxiao Chen, Nengwen Zhao, Zeyan Li, Jiahao Bu, Zhihan Li, Ying Liu, Youjian Zhao, Dan Pei, Yang Feng, Proceedings of the 2018 world wide web conference. the 2018 world wide web conference2018</p>
<p>Anomaly transformer: Time series anomaly detection with association discrepancy. Jiehui Xu, Haixu Wu, Jianmin Wang, Mingsheng Long, arXiv:2110.026422021. 2021arXiv preprint</p>
<p>Xinli Yu, Zheng Chen, Yuan Ling, Shujing Dong, Zongyi Liu, Yanbin Lu, arXiv:2306.11025Temporal Data Meets LLM-Explainable Financial Time Series Forecasting. 2023. 2023arXiv preprint</p>
<p>Embedding-based query language models. Hamed Zamani, Bruce Croft, Proceedings of the 2016 ACM international conference on the theory of information retrieval. the 2016 ACM international conference on the theory of information retrieval2016</p>
<p>TraceArk: Towards Actionable Performance Anomaly Alerting for Online Service Systems. Zhengran Zeng, Yuqun Zhang, Yong Xu, Minghua Ma, Bo Qiao, Wentao Zou, Qingjun Chen, Meng Zhang, Xu Zhang, Hongyu Zhang, 2023 IEEE/ACM 45th International Conference on Software Engineering: Software Engineering in Practice (ICSE-SEIP). IEEE2023</p>
<p>Chaoyun Zhang, Liqun Li, Shilin He, Xu Zhang, Bo Qiao, Si Qin, Minghua Ma, Yu Kang, Qingwei Lin, Saravan Rajmohan, arXiv:2402.07939UFO: A UI-Focused Agent for Windows OS Interaction. 2024. 2024arXiv preprint</p>
<p>Chaoyun Zhang, Zicheng Ma, Yuhao Wu, Shilin He, Si Qin, Minghua Ma, Xiaoting Qin, Yu Kang, Yuyi Liang, Xiaoyu Gou, arXiv:2403.15157AllHands: Ask Me Anything on Large-scale Verbatim Feedback via Large Language Models. 2024. 2024arXiv preprint</p>
<p>A deep neural network for unsupervised anomaly detection and diagnosis in multivariate time series data. Chuxu Zhang, Dongjin Song, Yuncong Chen, Xinyang Feng, Cristian Lumezanu, Wei Cheng, Jingchao Ni, Bo Zong, Haifeng Chen, Nitesh V Chawla, Proceedings of the AAAI conference on artificial intelligence. the AAAI conference on artificial intelligence201933</p>
<p>TFAD: A decomposition time series anomaly detection architecture with time-frequency analysis. Chaoli Zhang, Tian Zhou, Qingsong Wen, Liang Sun, Proceedings of the 31st ACM International Conference on Information &amp; Knowledge Management. the 31st ACM International Conference on Information &amp; Knowledge Management2022</p>
<p>Efficient kpi anomaly detection through transfer learning for large-scale web services. Shenglin Zhang, Zhenyu Zhong, Dongwen Li, Qiliang Fan, Yongqian Sun, Man Zhu, Yuzhi Zhang, Dan Pei, Jiyan Sun, Yinlong Liu, IEEE Journal on Selected Areas in Communications. 402022. 2022</p>
<p>Informer: Beyond efficient transformer for long sequence time-series forecasting. Haoyi Zhou, Shanghang Zhang, Jieqi Peng, Shuai Zhang, Jianxin Li, Hui Xiong, Wancai Zhang, Proceedings of the AAAI conference on artificial intelligence. the AAAI conference on artificial intelligence202135</p>
<p>One fits all: Power general time series analysis by pretrained lm. Tian Zhou, Peisong Niu, Liang Sun, Rong Jin, Advances in neural information processing systems. 362024. 2024</p>
<p>Multiinstance multi-label learning. Zhi-Hua Zhou, Min-Ling Zhang, Sheng-Jun Huang, Yu-Feng Li, Artificial Intelligence. 1762012. 2012</p>            </div>
        </div>

    </div>
</body>
</html>