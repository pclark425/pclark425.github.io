<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-6864 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-6864</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-6864</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-132.html">extraction-schema-132</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how large language models are used to synthesize novel chemical compounds for specific applications, including model details, generation methods, target applications, chemical representations, evaluation metrics, constraints, integration with external tools, datasets, reported performance, experimental validation, and reported challenges or limitations.</div>
                <p><strong>Paper ID:</strong> paper-268350146</p>
                <p><strong>Paper Title:</strong> Analysis and prediction in SCR experiments using GPT-4 with an effective chain-of-thought prompting strategy</p>
                <p><strong>Paper Abstract:</strong> Summary This study explores the use of large language models (LLMs) in interpreting and predicting experimental outcomes based on given experimental variables, leveraging the human-like reasoning and inference capabilities of LLMs, using selective catalytic reduction of NOx with NH3 as a case study. We implement the chain of thought (CoT) concept to formulate logical steps for uncovering connections within the data, introducing an “Ordered-and-Structured” CoT (OSCoT) prompting strategy. We compare the OSCoT strategy with the more conventional “One-Pot” CoT (OPCoT) approach and with human experts. We demonstrate that GPT-4, equipped with this new OSCoT prompting strategy, outperforms the other two settings and accurately predicts experimental outcomes and provides intuitive reasoning for its predictions.</p>
                <p><strong>Cost:</strong> 0.017</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e6864.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e6864.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how large language models are used to synthesize novel chemical compounds for specific applications, including model details, generation methods, target applications, chemical representations, evaluation metrics, constraints, integration with external tools, datasets, reported performance, experimental validation, and reported challenges or limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GPT-4</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Generative Pre-trained Transformer 4</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A large pretrained language model accessed via OpenAI API and applied in this study to analyze structured tabular experimental data and predict binary catalytic outcomes using chain-of-thought prompting (OSCoT/OPCoT), achieving substantially better performance than the sampled human experts.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-4</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>large pretrained LLM (API-accessed, chat assistant)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>training_data_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>generation_method</strong></td>
                            <td>In-context learning with chain-of-thought prompting (Ordered-and-Structured CoT and One-Pot CoT); temperature set to 0 for deterministic outputs</td>
                        </tr>
                        <tr>
                            <td><strong>chemical_representation</strong></td>
                            <td>Structured tabular experimental data (JSON-like records of experiments: catalyst composition, synthesis parameters, reaction conditions, outcomes); not SMILES/SELFIES/InChI</td>
                        </tr>
                        <tr>
                            <td><strong>target_application</strong></td>
                            <td>Analysis and prediction of catalytic performance (NH3-SCR NOx conversion) for Ce-based binary and ternary metal-oxide composites; interpretation/rationalization of experimental data</td>
                        </tr>
                        <tr>
                            <td><strong>constraints_used</strong></td>
                            <td>Token/context length limitations (careful sample selection and batching); temperature=0; batches designed so only one experimental parameter varied per batch (ordering by feature importance)</td>
                        </tr>
                        <tr>
                            <td><strong>integration_with_external_tools</strong></td>
                            <td>Used interpretable ML (XGB + SHAP from prior work) to derive feature importance that determined batch ordering for OSCoT; accessed via OpenAI API; no external quantum/docking/retrosynthesis tools reported</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_used</strong></td>
                            <td>Curated dataset of 1,838 unique NH3-SCR experiments on Ce-based metal-oxide composites (binary and ternary). Training in runs used batches of 48 samples; evaluation used 50 held-out samples per test.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td>Binary classification accuracy for Positive/Negative outcomes (Positive defined as NOx conversion >= 95%); CoT quality metrics for generated chains ('disobedience', 'helpfulness', 'honesty'); average/maximum/minimum accuracies across runs</td>
                        </tr>
                        <tr>
                            <td><strong>reported_results</strong></td>
                            <td>OSCoT-GPT4 average prediction accuracies for the six binary CeM1 composites: 71.6%, 74.0%, 64.2%, 60.0%, 67.6%, 65.6% (per-composite averages); maximum accuracies reached up to 85% for some composites; OSCoT-GPT4 outperformed OPCoT-GPT4 and OSCoT-GPT3.5 in most cases and outperformed four sampled human experts (experts' accuracies ranged ~51%–66%).</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_validation</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>challenges_or_limitations</strong></td>
                            <td>Context/token length limitations of the model; reduced extrapolation performance when moving from binary to ternary systems (unclear prioritization of conflicting associations); GPT-3.5 malfunctioned when overloaded (>~3,000 tokens in OP approach); study limited to GPT-series models and to tabular data context.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Analysis and prediction in SCR experiments using GPT-4 with an effective chain-of-thought prompting strategy', 'publication_date_yy_mm': '2024-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6864.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e6864.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how large language models are used to synthesize novel chemical compounds for specific applications, including model details, generation methods, target applications, chemical representations, evaluation metrics, constraints, integration with external tools, datasets, reported performance, experimental validation, and reported challenges or limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GPT-3.5-turbo-16k</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>GPT-3.5-turbo with 16k token context (OpenAI)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A GPT-3.5-series chat model evaluated in this study alongside GPT-4 for CoT generation and prediction on tabular catalysis data; it showed failures under some prompting strategies and context loads.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-3.5-turbo-16k</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>large pretrained LLM (API-accessed, chat assistant)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>training_data_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>generation_method</strong></td>
                            <td>In-context learning with chain-of-thought prompting (OPCoT and OSCoT tested); temperature set to 0</td>
                        </tr>
                        <tr>
                            <td><strong>chemical_representation</strong></td>
                            <td>Structured tabular experimental data (JSON-like); not molecular string generation</td>
                        </tr>
                        <tr>
                            <td><strong>target_application</strong></td>
                            <td>Analysis and prediction of catalytic performance (NH3-SCR) in the study</td>
                        </tr>
                        <tr>
                            <td><strong>constraints_used</strong></td>
                            <td>Observed to malfunction when overloaded with more than ~3,000 input tokens in the OP approach; temperature=0</td>
                        </tr>
                        <tr>
                            <td><strong>integration_with_external_tools</strong></td>
                            <td>None reported beyond OpenAI API usage and the same feature-importance-driven batching process</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_used</strong></td>
                            <td>Same curated dataset of 1,838 NH3-SCR experiments; training batches of 48 samples</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td>Prediction accuracy (binary Positive/Negative classification) and CoT quality metrics</td>
                        </tr>
                        <tr>
                            <td><strong>reported_results</strong></td>
                            <td>OSCoT-GPT3.5 included in some comparisons but generally outperformed by OSCoT-GPT4; GPT-3.5 malfunctioned under UM2/OP prompting and when context exceeded ~3,000 tokens (leading to exclusion from some comparisons).</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_validation</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>challenges_or_limitations</strong></td>
                            <td>Lower robustness than GPT-4 under the tested CoT prompting strategies; context-length sensitivity and failure modes under high token loads.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Analysis and prediction in SCR experiments using GPT-4 with an effective chain-of-thought prompting strategy', 'publication_date_yy_mm': '2024-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6864.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e6864.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how large language models are used to synthesize novel chemical compounds for specific applications, including model details, generation methods, target applications, chemical representations, evaluation metrics, constraints, integration with external tools, datasets, reported performance, experimental validation, and reported challenges or limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>OSCoT</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Ordered-and-Structured Chain-of-Thought prompting</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A prompting strategy introduced in this paper that divides tabular experimental data into batches ordered by feature importance and sequentially elicits intermediate CoTs that build on prior steps, improving reasoning on complex multi-variable tabular chemistry data.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>chain-of-thought prompting / prompt engineering strategy</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>training_data_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>generation_method</strong></td>
                            <td>Batchwise sequential CoT generation: data are batched so that within each batch only one experimental parameter varies substantially; each batch elicits a CoT which is then used as context for the next batch (iterative CoT refinement)</td>
                        </tr>
                        <tr>
                            <td><strong>chemical_representation</strong></td>
                            <td>Tabular experimental data (JSON-like keys and values for experimental variables and outcomes)</td>
                        </tr>
                        <tr>
                            <td><strong>target_application</strong></td>
                            <td>Interpreting tabular experimental chemistry data and predicting experimental outcomes (demonstrated for NH3-SCR catalysis); designed to improve LLM reasoning on structured data</td>
                        </tr>
                        <tr>
                            <td><strong>constraints_used</strong></td>
                            <td>Batch design based on feature importance (from ML interpretation) so only one parameter varies in each batch; placement of crucial prompts at head and tail ('head-tail' tactic) to mitigate LLM 'lost in the middle' behavior; mindful token budgeting</td>
                        </tr>
                        <tr>
                            <td><strong>integration_with_external_tools</strong></td>
                            <td>Leveraged feature importance computed by interpretable ML (XGB + SHAP) to decide batch ordering</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_used</strong></td>
                            <td>Applied to the curated 1,838-sample Ce-based NH3-SCR dataset in this study; training batches of 48 samples per run</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td>Prediction accuracy for categorical NOx conversion classification; CoT quality metrics ('disobedience', 'helpfulness', 'honesty') when evaluating generated reasoning</td>
                        </tr>
                        <tr>
                            <td><strong>reported_results</strong></td>
                            <td>OSCoT-GPT4 achieved higher average and minimum accuracies across binary CeM1 composites versus OPCoT; reported per-composite averages (71.6%, 74.0%, 64.2%, 60.0%, 67.6%, 65.6%) and maxima up to 85% in some cases; OSCoT showed better robustness across runs.</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_validation</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>challenges_or_limitations</strong></td>
                            <td>Requires prior feature-importance information or heuristics to design batches; sensitive to token/context limits; evaluated only on GPT-series models in this study; may not generalize without careful batch construction.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Analysis and prediction in SCR experiments using GPT-4 with an effective chain-of-thought prompting strategy', 'publication_date_yy_mm': '2024-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6864.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e6864.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how large language models are used to synthesize novel chemical compounds for specific applications, including model details, generation methods, target applications, chemical representations, evaluation metrics, constraints, integration with external tools, datasets, reported performance, experimental validation, and reported challenges or limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ChemCrow</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>ChemCrow: Augmenting large-language models with chemistry tools</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A GPT-4-based chemistry tool mentioned in the paper that structures sequential prompts to guide the model through multi-step chemical tasks (from drug design to synthesis), effectively coupling LLM reasoning with task workflows.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>ChemCrow: Augmenting large-language models with chemistry tools</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-4 (as reported in the cited work)</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>tool-using agent / GPT-4-based chemistry assistant</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>training_data_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>generation_method</strong></td>
                            <td>Sequential prompting and task decomposition to guide the LLM through multi-step chemical tasks; described as aligning actions with end goals</td>
                        </tr>
                        <tr>
                            <td><strong>chemical_representation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>target_application</strong></td>
                            <td>General chemical tasks including drug design and synthesis planning</td>
                        </tr>
                        <tr>
                            <td><strong>constraints_used</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>integration_with_external_tools</strong></td>
                            <td>Described as augmenting LLMs with chemistry tools (implies integration with external calculators/planners), though specifics are not provided in this paper</td>
                        </tr>
                        <tr>
                            <td><strong>dataset_used</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reported_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>experimental_validation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>challenges_or_limitations</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Analysis and prediction in SCR experiments using GPT-4 with an effective chain-of-thought prompting strategy', 'publication_date_yy_mm': '2024-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6864.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e6864.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how large language models are used to synthesize novel chemical compounds for specific applications, including model details, generation methods, target applications, chemical representations, evaluation metrics, constraints, integration with external tools, datasets, reported performance, experimental validation, and reported challenges or limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GPT-4 Reticular Chemist</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>A GPT-4 Reticular Chemist for Guiding MOF Discovery</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A cited work that used GPT-4 in a cooperative workflow with human experts to guide the discovery of novel metal-organic frameworks (MOFs), reportedly leading to the synthesis of a series of MOFs using distinct strategies and conditions.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>A GPT-4 Reticular Chemist for Guiding MOF Discovery</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-4</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>large pretrained LLM used in human-in-the-loop discovery workflow</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>training_data_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>generation_method</strong></td>
                            <td>Cooperative human–LLM workflow (GPT-4 guided suggestions interpreted and acted on by human experts)</td>
                        </tr>
                        <tr>
                            <td><strong>chemical_representation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>target_application</strong></td>
                            <td>MOF discovery / materials design</td>
                        </tr>
                        <tr>
                            <td><strong>constraints_used</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>integration_with_external_tools</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>dataset_used</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reported_results</strong></td>
                            <td>Reported discovery and experimental synthesis of a series of MOFs guided by the GPT-4-enabled workflow (as stated in this paper's introduction).</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_validation</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>challenges_or_limitations</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Analysis and prediction in SCR experiments using GPT-4 with an effective chain-of-thought prompting strategy', 'publication_date_yy_mm': '2024-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6864.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e6864.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how large language models are used to synthesize novel chemical compounds for specific applications, including model details, generation methods, target applications, chemical representations, evaluation metrics, constraints, integration with external tools, datasets, reported performance, experimental validation, and reported challenges or limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Fine-tuned GPT-3 (molecular properties)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Fine-Tuning GPT-3 for Machine Learning Electronic and Functional Properties of Organic Molecules</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A cited work reporting that task-specific fine-tuning of GPT-3 yielded highly predictive models for chemistry ML tasks—sometimes surpassing dedicated ML models—suggesting LLMs can be adapted for molecular property prediction.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Fine-Tuning GPT-3 for Machine Learning Electronic and Functional Properties of Organic Molecules</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-3 (fine-tuned)</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>fine-tuned large language model</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>training_data_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>generation_method</strong></td>
                            <td>Task-specific fine-tuning for supervised prediction tasks</td>
                        </tr>
                        <tr>
                            <td><strong>chemical_representation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>target_application</strong></td>
                            <td>Predicting electronic and functional properties of organic molecules</td>
                        </tr>
                        <tr>
                            <td><strong>constraints_used</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>integration_with_external_tools</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>dataset_used</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td>Comparative predictive performance vs dedicated ML models (metrics not specified in this paper)</td>
                        </tr>
                        <tr>
                            <td><strong>reported_results</strong></td>
                            <td>Reported to often surpass the performance of dedicated ML models for the tasks mentioned (no numeric values provided in this paper).</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_validation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>challenges_or_limitations</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Analysis and prediction in SCR experiments using GPT-4 with an effective chain-of-thought prompting strategy', 'publication_date_yy_mm': '2024-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6864.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e6864.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how large language models are used to synthesize novel chemical compounds for specific applications, including model details, generation methods, target applications, chemical representations, evaluation metrics, constraints, integration with external tools, datasets, reported performance, experimental validation, and reported challenges or limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ChatGPT Chemistry Assistant (MOF)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>ChatGPT Chemistry Assistant for Text Mining and Prediction of MOF Synthesis</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A cited preprint that used ChatGPT / GPT-family models as an assistant for literature text mining and predicting MOF synthesis conditions, illustrating LLM application to materials synthesis prediction tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>ChatGPT Chemistry Assistant for Text Mining and Prediction of MOF Synthesis</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>ChatGPT / GPT-family (as reported)</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>training_data_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>generation_method</strong></td>
                            <td>Text-mining and predictive assistance via LLM prompts (details not specified here)</td>
                        </tr>
                        <tr>
                            <td><strong>chemical_representation</strong></td>
                            <td>Textual descriptions of synthesis conditions (rather than molecular strings)</td>
                        </tr>
                        <tr>
                            <td><strong>target_application</strong></td>
                            <td>Prediction of MOF synthesis conditions / literature mining for MOF discovery</td>
                        </tr>
                        <tr>
                            <td><strong>constraints_used</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>integration_with_external_tools</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>dataset_used</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reported_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>experimental_validation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>challenges_or_limitations</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Analysis and prediction in SCR experiments using GPT-4 with an effective chain-of-thought prompting strategy', 'publication_date_yy_mm': '2024-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>A GPT-4 Reticular Chemist for Guiding MOF Discovery <em>(Rating: 2)</em></li>
                <li>ChemCrow: Augmenting large-language models with chemistry tools <em>(Rating: 2)</em></li>
                <li>ChatGPT Chemistry Assistant for Text Mining and Prediction of MOF Synthesis <em>(Rating: 2)</em></li>
                <li>Fine-Tuning GPT-3 for Machine Learning Electronic and Functional Properties of Organic Molecules <em>(Rating: 2)</em></li>
                <li>Autonomous chemical research with large language models <em>(Rating: 2)</em></li>
                <li>Large language models for chemistry robotics <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-6864",
    "paper_id": "paper-268350146",
    "extraction_schema_id": "extraction-schema-132",
    "extracted_data": [
        {
            "name_short": "GPT-4",
            "name_full": "Generative Pre-trained Transformer 4",
            "brief_description": "A large pretrained language model accessed via OpenAI API and applied in this study to analyze structured tabular experimental data and predict binary catalytic outcomes using chain-of-thought prompting (OSCoT/OPCoT), achieving substantially better performance than the sampled human experts.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "GPT-4",
            "model_type": "large pretrained LLM (API-accessed, chat assistant)",
            "model_size": null,
            "training_data_description": null,
            "generation_method": "In-context learning with chain-of-thought prompting (Ordered-and-Structured CoT and One-Pot CoT); temperature set to 0 for deterministic outputs",
            "chemical_representation": "Structured tabular experimental data (JSON-like records of experiments: catalyst composition, synthesis parameters, reaction conditions, outcomes); not SMILES/SELFIES/InChI",
            "target_application": "Analysis and prediction of catalytic performance (NH3-SCR NOx conversion) for Ce-based binary and ternary metal-oxide composites; interpretation/rationalization of experimental data",
            "constraints_used": "Token/context length limitations (careful sample selection and batching); temperature=0; batches designed so only one experimental parameter varied per batch (ordering by feature importance)",
            "integration_with_external_tools": "Used interpretable ML (XGB + SHAP from prior work) to derive feature importance that determined batch ordering for OSCoT; accessed via OpenAI API; no external quantum/docking/retrosynthesis tools reported",
            "dataset_used": "Curated dataset of 1,838 unique NH3-SCR experiments on Ce-based metal-oxide composites (binary and ternary). Training in runs used batches of 48 samples; evaluation used 50 held-out samples per test.",
            "evaluation_metrics": "Binary classification accuracy for Positive/Negative outcomes (Positive defined as NOx conversion &gt;= 95%); CoT quality metrics for generated chains ('disobedience', 'helpfulness', 'honesty'); average/maximum/minimum accuracies across runs",
            "reported_results": "OSCoT-GPT4 average prediction accuracies for the six binary CeM1 composites: 71.6%, 74.0%, 64.2%, 60.0%, 67.6%, 65.6% (per-composite averages); maximum accuracies reached up to 85% for some composites; OSCoT-GPT4 outperformed OPCoT-GPT4 and OSCoT-GPT3.5 in most cases and outperformed four sampled human experts (experts' accuracies ranged ~51%–66%).",
            "experimental_validation": false,
            "challenges_or_limitations": "Context/token length limitations of the model; reduced extrapolation performance when moving from binary to ternary systems (unclear prioritization of conflicting associations); GPT-3.5 malfunctioned when overloaded (&gt;~3,000 tokens in OP approach); study limited to GPT-series models and to tabular data context.",
            "uuid": "e6864.0",
            "source_info": {
                "paper_title": "Analysis and prediction in SCR experiments using GPT-4 with an effective chain-of-thought prompting strategy",
                "publication_date_yy_mm": "2024-03"
            }
        },
        {
            "name_short": "GPT-3.5-turbo-16k",
            "name_full": "GPT-3.5-turbo with 16k token context (OpenAI)",
            "brief_description": "A GPT-3.5-series chat model evaluated in this study alongside GPT-4 for CoT generation and prediction on tabular catalysis data; it showed failures under some prompting strategies and context loads.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "GPT-3.5-turbo-16k",
            "model_type": "large pretrained LLM (API-accessed, chat assistant)",
            "model_size": null,
            "training_data_description": null,
            "generation_method": "In-context learning with chain-of-thought prompting (OPCoT and OSCoT tested); temperature set to 0",
            "chemical_representation": "Structured tabular experimental data (JSON-like); not molecular string generation",
            "target_application": "Analysis and prediction of catalytic performance (NH3-SCR) in the study",
            "constraints_used": "Observed to malfunction when overloaded with more than ~3,000 input tokens in the OP approach; temperature=0",
            "integration_with_external_tools": "None reported beyond OpenAI API usage and the same feature-importance-driven batching process",
            "dataset_used": "Same curated dataset of 1,838 NH3-SCR experiments; training batches of 48 samples",
            "evaluation_metrics": "Prediction accuracy (binary Positive/Negative classification) and CoT quality metrics",
            "reported_results": "OSCoT-GPT3.5 included in some comparisons but generally outperformed by OSCoT-GPT4; GPT-3.5 malfunctioned under UM2/OP prompting and when context exceeded ~3,000 tokens (leading to exclusion from some comparisons).",
            "experimental_validation": false,
            "challenges_or_limitations": "Lower robustness than GPT-4 under the tested CoT prompting strategies; context-length sensitivity and failure modes under high token loads.",
            "uuid": "e6864.1",
            "source_info": {
                "paper_title": "Analysis and prediction in SCR experiments using GPT-4 with an effective chain-of-thought prompting strategy",
                "publication_date_yy_mm": "2024-03"
            }
        },
        {
            "name_short": "OSCoT",
            "name_full": "Ordered-and-Structured Chain-of-Thought prompting",
            "brief_description": "A prompting strategy introduced in this paper that divides tabular experimental data into batches ordered by feature importance and sequentially elicits intermediate CoTs that build on prior steps, improving reasoning on complex multi-variable tabular chemistry data.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": null,
            "model_type": "chain-of-thought prompting / prompt engineering strategy",
            "model_size": null,
            "training_data_description": null,
            "generation_method": "Batchwise sequential CoT generation: data are batched so that within each batch only one experimental parameter varies substantially; each batch elicits a CoT which is then used as context for the next batch (iterative CoT refinement)",
            "chemical_representation": "Tabular experimental data (JSON-like keys and values for experimental variables and outcomes)",
            "target_application": "Interpreting tabular experimental chemistry data and predicting experimental outcomes (demonstrated for NH3-SCR catalysis); designed to improve LLM reasoning on structured data",
            "constraints_used": "Batch design based on feature importance (from ML interpretation) so only one parameter varies in each batch; placement of crucial prompts at head and tail ('head-tail' tactic) to mitigate LLM 'lost in the middle' behavior; mindful token budgeting",
            "integration_with_external_tools": "Leveraged feature importance computed by interpretable ML (XGB + SHAP) to decide batch ordering",
            "dataset_used": "Applied to the curated 1,838-sample Ce-based NH3-SCR dataset in this study; training batches of 48 samples per run",
            "evaluation_metrics": "Prediction accuracy for categorical NOx conversion classification; CoT quality metrics ('disobedience', 'helpfulness', 'honesty') when evaluating generated reasoning",
            "reported_results": "OSCoT-GPT4 achieved higher average and minimum accuracies across binary CeM1 composites versus OPCoT; reported per-composite averages (71.6%, 74.0%, 64.2%, 60.0%, 67.6%, 65.6%) and maxima up to 85% in some cases; OSCoT showed better robustness across runs.",
            "experimental_validation": false,
            "challenges_or_limitations": "Requires prior feature-importance information or heuristics to design batches; sensitive to token/context limits; evaluated only on GPT-series models in this study; may not generalize without careful batch construction.",
            "uuid": "e6864.2",
            "source_info": {
                "paper_title": "Analysis and prediction in SCR experiments using GPT-4 with an effective chain-of-thought prompting strategy",
                "publication_date_yy_mm": "2024-03"
            }
        },
        {
            "name_short": "ChemCrow",
            "name_full": "ChemCrow: Augmenting large-language models with chemistry tools",
            "brief_description": "A GPT-4-based chemistry tool mentioned in the paper that structures sequential prompts to guide the model through multi-step chemical tasks (from drug design to synthesis), effectively coupling LLM reasoning with task workflows.",
            "citation_title": "ChemCrow: Augmenting large-language models with chemistry tools",
            "mention_or_use": "mention",
            "model_name": "GPT-4 (as reported in the cited work)",
            "model_type": "tool-using agent / GPT-4-based chemistry assistant",
            "model_size": null,
            "training_data_description": null,
            "generation_method": "Sequential prompting and task decomposition to guide the LLM through multi-step chemical tasks; described as aligning actions with end goals",
            "chemical_representation": null,
            "target_application": "General chemical tasks including drug design and synthesis planning",
            "constraints_used": null,
            "integration_with_external_tools": "Described as augmenting LLMs with chemistry tools (implies integration with external calculators/planners), though specifics are not provided in this paper",
            "dataset_used": null,
            "evaluation_metrics": null,
            "reported_results": null,
            "experimental_validation": null,
            "challenges_or_limitations": null,
            "uuid": "e6864.3",
            "source_info": {
                "paper_title": "Analysis and prediction in SCR experiments using GPT-4 with an effective chain-of-thought prompting strategy",
                "publication_date_yy_mm": "2024-03"
            }
        },
        {
            "name_short": "GPT-4 Reticular Chemist",
            "name_full": "A GPT-4 Reticular Chemist for Guiding MOF Discovery",
            "brief_description": "A cited work that used GPT-4 in a cooperative workflow with human experts to guide the discovery of novel metal-organic frameworks (MOFs), reportedly leading to the synthesis of a series of MOFs using distinct strategies and conditions.",
            "citation_title": "A GPT-4 Reticular Chemist for Guiding MOF Discovery",
            "mention_or_use": "mention",
            "model_name": "GPT-4",
            "model_type": "large pretrained LLM used in human-in-the-loop discovery workflow",
            "model_size": null,
            "training_data_description": null,
            "generation_method": "Cooperative human–LLM workflow (GPT-4 guided suggestions interpreted and acted on by human experts)",
            "chemical_representation": null,
            "target_application": "MOF discovery / materials design",
            "constraints_used": null,
            "integration_with_external_tools": null,
            "dataset_used": null,
            "evaluation_metrics": null,
            "reported_results": "Reported discovery and experimental synthesis of a series of MOFs guided by the GPT-4-enabled workflow (as stated in this paper's introduction).",
            "experimental_validation": true,
            "challenges_or_limitations": null,
            "uuid": "e6864.4",
            "source_info": {
                "paper_title": "Analysis and prediction in SCR experiments using GPT-4 with an effective chain-of-thought prompting strategy",
                "publication_date_yy_mm": "2024-03"
            }
        },
        {
            "name_short": "Fine-tuned GPT-3 (molecular properties)",
            "name_full": "Fine-Tuning GPT-3 for Machine Learning Electronic and Functional Properties of Organic Molecules",
            "brief_description": "A cited work reporting that task-specific fine-tuning of GPT-3 yielded highly predictive models for chemistry ML tasks—sometimes surpassing dedicated ML models—suggesting LLMs can be adapted for molecular property prediction.",
            "citation_title": "Fine-Tuning GPT-3 for Machine Learning Electronic and Functional Properties of Organic Molecules",
            "mention_or_use": "mention",
            "model_name": "GPT-3 (fine-tuned)",
            "model_type": "fine-tuned large language model",
            "model_size": null,
            "training_data_description": null,
            "generation_method": "Task-specific fine-tuning for supervised prediction tasks",
            "chemical_representation": null,
            "target_application": "Predicting electronic and functional properties of organic molecules",
            "constraints_used": null,
            "integration_with_external_tools": null,
            "dataset_used": null,
            "evaluation_metrics": "Comparative predictive performance vs dedicated ML models (metrics not specified in this paper)",
            "reported_results": "Reported to often surpass the performance of dedicated ML models for the tasks mentioned (no numeric values provided in this paper).",
            "experimental_validation": null,
            "challenges_or_limitations": null,
            "uuid": "e6864.5",
            "source_info": {
                "paper_title": "Analysis and prediction in SCR experiments using GPT-4 with an effective chain-of-thought prompting strategy",
                "publication_date_yy_mm": "2024-03"
            }
        },
        {
            "name_short": "ChatGPT Chemistry Assistant (MOF)",
            "name_full": "ChatGPT Chemistry Assistant for Text Mining and Prediction of MOF Synthesis",
            "brief_description": "A cited preprint that used ChatGPT / GPT-family models as an assistant for literature text mining and predicting MOF synthesis conditions, illustrating LLM application to materials synthesis prediction tasks.",
            "citation_title": "ChatGPT Chemistry Assistant for Text Mining and Prediction of MOF Synthesis",
            "mention_or_use": "mention",
            "model_name": "ChatGPT / GPT-family (as reported)",
            "model_type": null,
            "model_size": null,
            "training_data_description": null,
            "generation_method": "Text-mining and predictive assistance via LLM prompts (details not specified here)",
            "chemical_representation": "Textual descriptions of synthesis conditions (rather than molecular strings)",
            "target_application": "Prediction of MOF synthesis conditions / literature mining for MOF discovery",
            "constraints_used": null,
            "integration_with_external_tools": null,
            "dataset_used": null,
            "evaluation_metrics": null,
            "reported_results": null,
            "experimental_validation": null,
            "challenges_or_limitations": null,
            "uuid": "e6864.6",
            "source_info": {
                "paper_title": "Analysis and prediction in SCR experiments using GPT-4 with an effective chain-of-thought prompting strategy",
                "publication_date_yy_mm": "2024-03"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "A GPT-4 Reticular Chemist for Guiding MOF Discovery",
            "rating": 2,
            "sanitized_title": "a_gpt4_reticular_chemist_for_guiding_mof_discovery"
        },
        {
            "paper_title": "ChemCrow: Augmenting large-language models with chemistry tools",
            "rating": 2,
            "sanitized_title": "chemcrow_augmenting_largelanguage_models_with_chemistry_tools"
        },
        {
            "paper_title": "ChatGPT Chemistry Assistant for Text Mining and Prediction of MOF Synthesis",
            "rating": 2,
            "sanitized_title": "chatgpt_chemistry_assistant_for_text_mining_and_prediction_of_mof_synthesis"
        },
        {
            "paper_title": "Fine-Tuning GPT-3 for Machine Learning Electronic and Functional Properties of Organic Molecules",
            "rating": 2,
            "sanitized_title": "finetuning_gpt3_for_machine_learning_electronic_and_functional_properties_of_organic_molecules"
        },
        {
            "paper_title": "Autonomous chemical research with large language models",
            "rating": 2,
            "sanitized_title": "autonomous_chemical_research_with_large_language_models"
        },
        {
            "paper_title": "Large language models for chemistry robotics",
            "rating": 1,
            "sanitized_title": "large_language_models_for_chemistry_robotics"
        }
    ],
    "cost": 0.017097,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Analysis and prediction in SCR experiments using GPT-4 with an effective chain-of-thought prompting strategy</p>
<p>Muyu Lu 
School of Energy and Environmental Engineering
University of Science and Technology Beijing
100083BeijingP.R. China</p>
<p>Fengyu Gao 
School of Energy and Environmental Engineering
University of Science and Technology Beijing
100083BeijingP.R. China</p>
<p>Xiaolong Tang txiaolong@126.com 
School of Energy and Environmental Engineering
University of Science and Technology Beijing
100083BeijingP.R. China</p>
<p>Linjiang Chen l.j.chen@bham.ac.uk 
School of Chemistry and School of Computer Science
University of Birmingham
B15 2TTBirminghamUK</p>
<p>Key Laboratory of Precision and Intelligent Chemistry
University of Science and Technology of China
230026HefeiAnhuiChina</p>
<p>Fengyu Gao
Xiaolong Tang, Linjiang Chen</p>
<p>Analysis and prediction in SCR experiments using GPT-4 with an effective chain-of-thought prompting strategy
5FC71D819384E70FB370FCF821296AFC10.1016/j.isci.2024.109451
HighlightsApplication of a large language model (LLM) in chemistry tasks A new chain-of-thought prompting strategy focusing on formulating logical steps An LLM-powered assistant that interprets, predicts, and rationalizes experimental data</p>
<p>INTRODUCTION</p>
<p>The emergence of the latest large language models (LLMs), notably GPT-3 and GPT-4, 1,2 is transforming the landscape of human-computer interaction, revolutionizing a wide range of personal and professional tasks through advanced artificial intelligence (AI) capabilities. 3,4These LLMs, trained on vast amounts of text data, are capable of generating human-like text, answering common-sense questions, and even performing tasks that require understanding and reasoning. 5,6LLMs can provide textual content creation and offer personalized interactions and recommendations. 7Their proficiency extends to tasks that require inferential reasoning, such as answering questions, solving mathematical problems, 8 and even passing bar examinations. 9Moreover, the impact of LLMs is evident in the realm of academic research.LLMs, like GPT-4, have the potential to streamline the literature review process by efficiently summarizing vast academic resources, extracting insights from the literature, and facilitating the generation of innovative research ideas. 10y enabling the analysis of extensive textual data, these models may uncover overlooked themes or patterns, offering fresh perspectives on existing research. 11LMs have started showing the potential to revolutionize chemistry by accelerating research and discovery in collaboration with human chemists.For instance, GPT-4 has been used in the discovery of new metal-organic frameworks (MOFs) through a cooperative workflow with human experts.This synergy enabled the discovery of a series of MOFs, each synthesized using unique strategies and conditions. 12In the broader landscape, LLM-empowered AI tools and agents are making strides in organic synthesis, drug discovery, and materials design.ChemCrow, 13 a GPT-4-based chemistry tool, exemplifies this.It streamlines reasoning for various chemical tasks, from drug design to synthesis.By sequentially prompting GPT-4, ChemCrow guides the model through the task, aligning actions with the end goal.This tool not only aids expert chemists but also simplifies access to chemical knowledge for novices.Moreover, task-specific fine-tuning of GPT-3 has been shown to yield highly effective and predictive models for a range of chemistry machine-learning (ML) tasks, often surpassing the performance of dedicated ML models specifically developed for these tasks. 14n this study, we hypothesize that GPT-4's language understanding capabilities, when combined with its strengths in pattern recognition and inferential reasoning, might enable effective analysis and interpretation of knowledge specific to a research topic or scientific domain.Our focus is on structured data rather than texts directly presented in scientific publications; in essence, we are not evaluating GPT-4's text mining capabilities.Instead, we aim to assess GPT-4's proficiency in recognizing patterns within structured data, which allows it to discern and capitalize on underlying trends.Such pattern recognition is invaluable when analyzing experimental variables and their associated outcomes.Furthermore, we seek to determine if GPT-4's ability for inferential reasoning enables it to make well-founded predictions based on the provided information and to assess the robustness of its rationale behind those predictions.</p>
<p>ll OPEN ACCESS</p>
<p>RESULTS</p>
<p>Binary CeM 1 metal-oxide composites</p>
<p>To prepare representative training data, rational selection by custom search (Table S2) from the dataset was conducted five runs, each generating a batch of 48 samples that covered six types of binary CeM 1 metal-oxide catalysts (M 1 = Ti, Mn, W, Sn, Mo, or Fe).The selected samples were then integrated into UM1 and UM2, respectively, to generate OP-and OS-CoT, using both GPT-3.5 and GPT-4.We evaluated the effectiveness of UM1 and UM2 in generating CoTs from GPT-3.5 and GPT-4 against three common metrics for assessing the performance of LLMs: 'disobedience', 'helpfulness', and 'honesty'.Detailed analyses are shown in Figures S4 and S5.Notably, we observed that GPT-3.5 malfunctioned when using UM2 in trying to generate OPCoT, leading to its exclusion from comparison.We examined the optimal number of input tokens for GPT-3.5-turbo-16k, as illustrated in Figure S6, revealing that it began to malfunction when burdened with more than 3,000 tokens in the OP approach.Finally, three combinations-OPCoT-GPT4, OSCoT-GPT4, and OSCoT-GPT3.5-wereincorporated into UM3 to infer the experimental performance of CeM 1 metal-oxide composites samples in five runs.</p>
<p>OP-and OS-CoTs were used to guide GPT-3.5 and GPT-4 to infer the experimental performance of each of the CeM 1 samples.As depicted in Figures 1A-1F, the average prediction accuracies of OSCoT-GPT4 for the six different binary composites reached 71.6%, 74%, 64.2%, 60%, 67.6%, and 65.6%, respectively.The maximum prediction accuracies for them reached 82%, 85%, 69%, 67%, 71%, and 73%, respectively.OSCoT-GPT4 consistently outperformed both OPCoT-GPT4 and OSCoT-GPT3.5 with the only exceptions of the maximum and average accuracy values for CeFe, for which other two combinations were more effective.Notably, the minimum accuracy values of OSCoT-GPT4 were the higher than the other two CoT-GPT combinations for all six CeM 1 samples.</p>
<p>Predicting catalysis outcomes poses a significant challenge due to the complexity and multi-step nature of the process.The reasoning route, generated by the OS prompting strategy (Figures 2 and 3), is particularly valuable in this context as it facilitates structured problem-solving.By breaking down the intricate task of catalysis prediction into smaller, logical steps, OSCoT mimics human reasoning, leading to improved understanding and interpretation of the problem.This structured reasoning not only makes the GPT-4's thought process more transparent but also enhances trust in its outputs.Additionally, implementing OSCoT-GPT4 in predicting catalysis can serve as an enhanced form of training, encouraging models to develop a deeper level of understanding and process information in a more nuanced, human-like manner.</p>
<p>Extrapolation to ternary CeM 1 M 2 metal-oxide composites</p>
<p>Next, we assessed the performance of the GPT-4, using OSCoT, in predicting outcomes for ternary composites of metal oxides by learning from experiments involving only binary composites.Specifically, we trained a GPT-4 on experiments involving CeM 1 and CeM 2 (M 1 , M 2 = Ti, Mn, W, Sn, Mo, or Fe; M 1 s M 2 ), following the same OSCoT-GPT4 training procedure as described above.We then evaluated this GPT-4's prediction performance for experiments involving the corresponding ternary CeM 1 M 2 composites.This process was independently repeated five times, each instance yielding a unique OSCoT-GPT4.Each time was trained with a distinct batch of 48 experiments for CeM 1 and another for CeM 2 , both batches being rationally selected.</p>
<p>We can partially attribute the observed extrapolation performance of the GPT-4 Assistant to its use of associations between specific metals and experimental variables in making predictions.Specifically, the GPT-4 Assistant appears to have constructed a knowledge graph from the For all composite types (A-F), five independent runs were conducted, each using one of the five batches of 48 samples for training.Prediction accuracies were evaluated using 50 samples randomly selected from the dataset, which were distinct from the training samples.The average, maximum, and minimum prediction accuracy values for each composite type were determined across the five runs.</p>
<p>binary training data, linking certain combinations of input variables to either high or low catalytic performances.When making predictions for ternary metal-oxide composites, it considered such associations.However, what remains unclear from the current data and results is the way the GPT-4 Assistant prioritizes these associations, particularly when they conflict.This uncertainty might partly account for the GPT-4 Assistant's reduced predictive performance with ternary systems, where little is known about the interplay and interactions among various metalsother than individual metals each with Ce-as represented on the knowledge graph derived from binary systems.To gain some interpretability, one could consider methods related to information geometry, which offer a structured and mathematical framework to comprehend how information is processed and represented within AI models.</p>
<p>Figure 4 presents results for eight ternary CeM 1 M 2 composites, divided into two groups: CeMnM 2 (M 2 = W, Ti, Sn, or Fe) and CeTiM 2 (M 2 = W, Sn, Mo, or Fe).We focused on these eight, out of the 15 possible permutations of CeM 1 M 2 , considering the prevalence of their corresponding binary counterparts in the dataset.For each specific CeM 1 M 2 composite, 50 experiments involving it were used to evaluate the prediction performance of the GPT-4 trained on the corresponding binary systems.Stoichiometry, as the molar ratio between the metal oxides (binary or ternary), was a variable in all cases.</p>
<p>Figure 4A shows the results of the five independent runs for each of the eight ternary systems.Notably, the GPT-4, all using the OSCoT prompting strategy, exhibited significantly different levels of prediction performance for the various ternary systems.For CeMnFe, CeMnTi, and CeTiFe, the OSCoT-GPT4 consistently yielded high prediction accuracies for the 50 ternary systems, after analyzing only the corresponding binary counterparts (48 CeM 1 + 48 CeM 2 ).In contrast, the OSCoTs-GPT4 intended for predicting CeTiSn and CeTiMo demonstrated poor performance.For CeMnW, they generated in the five independent runs showed markedly varied prediction performances.Figure 4B provides a statistical summary of the run-specific accuracies for each ternary system.Upon detailed analysis of the various OSCoTs-GPT4 with respect to the systems in Figure 4A, we could attribute the differing levels of prediction performance for the ternary systems to the varying prediction performances of the OSCoTs-GPT4 for the binary systems they were trained to analyze.For instance, the OSCoTs-GPT4 intended for CeMnFe exhibited high prediction performances for CeMn and CeFe, while the ones for CeTiMo demonstrated poor performance for CeTi and CeMo.</p>
<p>Comparison with human experts</p>
<p>To gauge the performance of the various combinations of CoTs-GPT, as described in the preceding sections, we conducted a survey involving four human experts to assess their performance on the same prediction tasks.All four experts were postgraduate research students specializing in NH 3 -SCR catalysis and had experience in synthesizing metal-oxide composites and measuring their performances for NH 3 -SCR catalysis.First, we asked Experts 1-3 to predict experimental outcomes-i.e., whether the NO x conversion would be above (Positive) or below (Negative) 95%-for 50 experiments involving binary metal-oxide composites; in Figure 5A, these results are designated as 'Without Training'.In these 50 experiments, the type of CeM 1 , its stoichiometry, synthesis conditions, and catalysis reaction conditions were all variables, though certain experiments shared the same values for certain variables.Expert 1 performed the best, attaining a In the OP method, all data points from the table are simultaneously processed to form a single CoT (termed OPCoT).Conversely, in the OS method, table data points are batched according to feature rank hierarchy, with each batch sequentially giving rise to intermediate CoTs.Each CoT incrementally builds upon the logic of the preceding one, representing a progressive development of understanding.The OSCoT materializes through iterative processing of all data point batches.The small chain icon represents the integration of messages, indicating, for example, that a connection between user_message and data points, along with the intermediate OSCoT, integrates these elements into the corresponding user message, thereby solidifying the foundation for subsequent OSCoT iterations.Table S1 details the full names of the abbreviations.prediction accuracy of 66%, while Experts 2 and 3 attained prediction accuracies of 51% and 56%, respectively, only marginally better than random guess.</p>
<p>Subsequently, after providing Experts 1-3 with the correct answers for these 50 experiments, they were given another set of 50 different experiments to predict.Their performances, denoted as 'After Training' in Figure 5A, interestingly showed no gains; in fact, Expert 1's performance appreciably worsened.Post-prediction, Experts 1-3 were interviewed and asked to summarize their rationales.As shown in Figure 5C, all three Experts applied relatively simple rules, considering no more than a couple of experimental variables.Their strategies were as follows:</p>
<p>(1) focusing on a small set of experiments to identify correlations between the experimental variables and the outcomes or (2) trying to identify a few key experimental variables that significantly influenced the outcomes when altered.While both strategies appear sensible and intuitive, they highlight the challenges humans encounter when analyzing multi-variable problems in sizable datasets.Specifically, correlations significant for a small dataset may not apply to a larger dataset.Similarly, factors that seem significant across the entire dataset may not aid in individual predictions, as the combination and balance of different factors can play an equally, or even more, important role.</p>
<p>Similar observations and conclusions were drawn when Experts 1-3 were asked to make predictions for experiments involving ternary metal-oxide composites (Figure 5B).The variation in prediction performances among the different Experts, as well as the differences in their performance across the various tasks, seem to suggest a strong element of guessing.This is not entirely unexpected, considering the challenge of retaining and processing information from tens of experiments and then applying any discerned rules and correlations to an entirely new set of experiments.An additional expert, Expert 4, who possessed similar experience in the research topic as Experts 1-3, was explicitly instructed to consider multiple experimental variables when approaching the prediction tasks (Figure 5C).Expert 4 was provided with the same sets of experiments for training, as well as the same sets for prediction, as were given to Experts 1-3.Among the four experts, Expert 4 performed the most poorly for both binary and ternary systems.</p>
<p>All four experts' performances were inferior to those of the GPT-4 using OSCoT, as discussed above (Figures 1 and 4).There are several factors that could have contributed to this.The sampling of just four human experts is far from adequate for establishing a comprehensive baseline of human performance on the prediction tasks.Nonetheless, LLMs like GPT-4 may outperform humans in predicting outcomes for complex, multi-variable chemistry experiments for several reasons.First, LLMs possess remarkable data processing capacity, allowing them to analyze and utilize information from lots of experiments simultaneously, a task that is challenging for humans.Second, LLMs consistently apply rules and patterns across datasets without experiencing cognitive fatigue or bias, in contrast to humans who might get overwhelmed by the volume or complexity of the data.Furthermore, LLMs are not susceptible to cognitive biases that can affect human analysis and conclusions.Their ability to detect subtle patterns in diverse and extensive datasets enables them to make more accurate predictions in intricate scenarios.Finally, LLMs benefit from rapid iterative learning, adapting and improving at a pace faster than the typical learning curve of human experts.Overall, the immense data processing capabilities, consistent and objective analysis, and rapid learning and pattern detection of LLMs make them well-equipped for complex tasks such as predicting outcomes in NH 3 -SCR catalysis experiments.</p>
<p>DISCUSSION</p>
<p>This study reveals that, by employing an effective OSCoT prompting strategy, GPT-4 achieved notable prediction accuracies regarding the performance of binary CeM 1 metal-oxide composite samples.The average prediction accuracies ranged from 60% to 74%, with peaks (A and B) Decomposing the complex task into general, manageable tasks, and splitting and reinforcing them to ensure thorough analysis.(C) Putting the analyzed datapoints in the rear of the messages.In Python, the f-string format employs curly braces {} to insert the content within variables into the string.Here, we use angle brackets &lt;&gt; as separators for generated sentences or paragraphs.Additionally, the variable delimiter adopted here is ''##''.</p>
<p>reaching up to 85%, outperforming human experts.These results were made possible by the OSCoT strategy's ability to break down intricate problems into sequential, manageable steps, enhancing the model's understanding and interpretation of complex tabular data.Extending the generated OSCoT by the binary CeM 1 samples to reason the performance of ternary CeM 1 M 2 samples, we observed a varied predictive performance, with some composites like CeMnFe and CeTiFe showing high accuracy, illustrating GPT-4's ability to extrapolate from binary to ternary systems.These findings demonstrate the intricate relationship between variables and causal outcomes in our curated dataset, solidifying the deductive connections implied by our table data through the application of a reasoning CoT.</p>
<p>The comparative analysis with human experts has further highlighted the advantages of employing LLMs in chemistry research.In contrast to human capabilities, LLMs like GPT-4, despite facing context length limitations, are significantly less affected by cognitive biases and are not easily overwhelmed by the immense volume and intricacy of tabular data.They demonstrate exceptional data processing prowess, reflecting some level of reasoning ability, a task that poses a considerable challenge for human experts.Moreover, their uniform application of rules and identification of patterns within table data, combined with their rapid learning and adaptability, equip them to discern subtle correlations amidst varied datasets.This leads to more precise predictions in complex research scenarios.</p>
<p>In this study, we investigated the application of GPT-4, coupled with our proposed OSCoT prompting strategy, to analyze experimental data concerning the variables and outcomes of a specific catalysis.We illustrated GPT-4's adeptness at unraveling intricate, multi-variable correlations within the catalysis.Broadly speaking, an experimental workflow may include several stages: synthesis, characterization, testing, data analysis, iteration of these processes, and/or others.][17][18][19] Looking ahead, advanced LLM techniques like Retrieval Augmented Generation (RAG) 20 will continue to enhance human-LLM collaboration on user-defined tasks.For instance, RAG facilitates the seamless incorporation of user-specified datasets, allowing for efficient access to knowledge relevant to the user's queries.LLM implementation frameworks, such as LangChain, simplify the development of RAG-based chatbots. 21These enabling techniques and their ongoing improvements will promote broader, more effective, and deeper integration of LLMs into chemistry research.They hold the promise of transforming various research tasks, including, but not limited to, the automation of labor-intensive activities like literature mining, interpretation of experimental results, and directing robotic operations.</p>
<p>Limitations of the study</p>
<p>This study investigated the capabilities of LLMs in analyzing experimental data and making predictions on related experiments, in comparison with human chemists during the post-analysis phase of chemical research.Specifically, it introduced an efficient prompt engineering technique named OSCoT for tabular data.Despite its contributions, the study has certain limitations.The method was evaluated using the state-of-the-art GPT-series models and has not been extended to other less advanced models.Furthermore, the concept of chain of thought was utilized to aid in the interpretation of tabular data.However, there remains scope for development in this area, as tabular data are inherently more complex to understand than plain text.</p>
<p>STAR+METHODS</p>
<p>Detailed methods are provided in the online version of this paper and include the following: enabling LLMs to process complex tasks through rational and logical reasoning.It breaks down intricate tasks into manageable, sequential steps.Few-shot CoTs can be used to assist LLMs in tasks that demand a consistent and logical progression, such as common-sense reasoning.In the realm of zero-shot learning, heuristic prompts like "Let's think step by step" have been shown to effectively encourage LLMs to 'think aloud', thereby enhancing their problem-solving capabilities. 23Further advancements include Automatic CoT (Auto-CoT) 24 and self-consistency. 25Auto-CoT simplifies the process of generating question sampling or reasoning paths, while self-consistency aims to improve the reliability and coherence of LLM outputs.These advancements mark significant progress in enhancing the performance and practicality of LLMs.
d KEY RESOURCES TABLE
The application of CoT lies in the interpreted feature importance in the tabular data that embodies clear deductive relationships between experimental parameters and causal catalytic performance.GPT-4-powered analysis is expected to reveal patterns that signify the varying levels of influence of different experimental factors in NH 3 -SCR catalysis.In this analysis, each inference step within the CoT reasoning paths is analogized to the evaluation of a specific experimental variable in catalysis, providing a structured approach to understanding the data.The results of this analysis are presented as CoTs, making the reasoning process and conclusions transparent.Our aim is to develop targeted prompting strategies for GPT-4 to enhance its ability to recognize patterns in structured data and produce outputs formatted as CoTs.These strategies are designed to guide GPT-4 in systematically identifying and interpreting the statistical relationship in the tabular data.</p>
<p>One-pot vs. ordered-and-structured CoT prompting LLMs often struggle with processing excessive context, necessitating careful planning in the provision of context for enhanced performance. 26dditionally, systematic review or self-reflection can significantly contribute to overall effectiveness. 27Bearing these considerations in mind, the full features of experiments in tabular form was divided into batches.In this study, the categorization process is determined by feature importance derived from machine learning interpretation.Indeed, the sequence of batch input can also be influenced by feature importance, as identified through heuristic knowledge or statistical techniques such as correlation analysis.The goal was to ensure that, within each batch, only one experimental parameter varied significantly, while all other parameters remained nearly constant across the samples.For example, in batch X, all data points (i.e., experiments) featured almost identical synthesis and catalysis conditions but varied in the compositions of the catalysts.These batches, each emphasizing a single varying experimental parameter, were then sequentially presented to GPT-4.This approach augmented GPT-4's analysis depth for individual experimental parameters, ultimately facilitating the generation of more optimal CoTs.</p>
<p>The batchwise, sequential approach is hereafter termed the ''Ordered-and-Structured'' (OS)-CoT prompting strategy.It was compared with a ''One-Pot'' (OP) prompting strategy, where all data points were inputted simultaneously.The implementation of both CoT prompting strategies is depicted in Figure 2. The OPCoT approach creates a single CoT in at once by using all available data points.In contrast, the OSCoT approach sequentially generates multiple CoTs.As each new batch of data points is introduced, a fresh CoT is created, incorporating the reasoning from the preceding CoT developed in the previous batch.Consequently, the CoTs formed by the OSCoT approach, each building upon the insights of the last.</p>
<p>Prompts for the generation and application of CoTs</p>
<p>In the web-based ChatGPT user interface, chat sessions are facilitated through user-initiated messages.In this study, we focused not on the ChatGPT interface but rather on using OpenAI's application programming interface (API).In the context of the API, it is necessary to format messages as dialogues involving typically two participant roles: the User (or the API Client) and the Assistant (the AI Model).The User is the entity, either a person or another system, that sends requests to the API.These requests, or user inputs, are what the AI model responds to.The Assistant, on the other hand, is the role played by the AI, such as GPT-4, generating responses based on the User's input.Here, we evaluate and compare the performances of both GPT-4 and GPT-3.5 (GPT-3.5-turbo-16k).Notably, we have set the ''temperature'' hyperparameter, which influences the model's prediction randomness, to zero to ensure the most consistent output as possible for the same input.</p>
<p>The effectiveness of LLM-generated responses heavily relies on the quality of task-directive prompts within in-context learning across multiple conversations.Our approach involves integrating various tactics to generate querying prompts.Figure 3 illustrates the user messages designated as UM1, which were used for OSCoT generation.Figure S1 depicts the user messages for OPCoT generation, designated as UM2.Figures S2 and S3 demonstrate the utilization of CoTs to predict the experimental performance of CeM 1 and CeM 1 M 2 samples, respectively, with user messages designated as UM3 and UM4.Additionally, given the token limitations inherent in GPT models, where both assistant (i.e., GPT) and user messages contribute to the token input capacity, careful selection of data samples is crucial.The protocol for the rational selection process and the computation of token utilization are detailed in the Supporting Information.</p>
<p>Before eliciting CoTs, careful configuration of in-context content is necessary to guide the cognitive processes of LLMs.The initial interaction with UM1, as shown in Figure 3, demonstrates the use of distinct tactics for establishing this setup, identical to those employed for OPCoT generation using UM2, as presented in Figure S1.Tactics I-IV were utilized for the prompts providing ''Clear Instructions.''GPT-4, initially agnostic to roles, can adopt a specific role when prompted.Consequently, we assigned the role of an NH 3 -SCR catalysis expert to GPT-4 for target-oriented tasks using the 'persona' tactic (I).This was followed by clarifying the input content to enhance GPT-4's focus on data points (II).Subsequently, we emphasized generating CoTs with consistent, generalized, and quantitative characteristics to establish a foundation for subsequent inferences (III).Next, we eliminated unnecessary information and requested reformatted output to streamline the process and enhance output quality (IV).</p>
<p>Tactics a-c serve the role of ''Decomposing Complex Tasks.''In particular, we outlined the overall task (a) and then broke it down into several simpler component parts to facilitate the generation of CoTs (b).The subsequent user message implemented the 'head-tail' tactic (c), placing the most crucial prompts at the beginning and end of the message.This tactic was employed to append data points at the end during each iteration of CoT generation, as LLMs tend to 'lose focus in the middle' with lengthy contextual input. 28or using CoTs to infer experimental performance, the initial interaction of UM3 or UM4 (as depicted in Figures S2 and S3, respectively) in the front-user message for context-aware adaptation employed tactics I, II, IV, and a.These tactics were used to establish the role of the NH 3 -SCR expert, specify input material, define output's structure and format, and outline the general objective.Data points and CoTs were placed at the end of messages as part of tactic c.Additionally, we employed a cautious tactic termed ''allocating thinking'' (d), crucial for conducting comprehensive analysis prior to making decisions.This tactic enhances the use of ''loud thinking,'' considering all reasoning paths of CoTs.It also moderates the pace of text completion and prevents exceeding the rate limits, which could lead to execution errors if the server is queried too quickly.</p>
<p>Figure 1 .
1
Figure 1.Comparison of the three CoT-GPT combinations in predicting experimental NO x conversion outcomes for the six binary CeM 1 composites samplesFor all composite types (A-F), five independent runs were conducted, each using one of the five batches of 48 samples for training.Prediction accuracies were evaluated using 50 samples randomly selected from the dataset, which were distinct from the training samples.The average, maximum, and minimum prediction accuracy values for each composite type were determined across the five runs.</p>
<p>Figure 2 .
2
Figure2.Illustration of CoT generation using the ''One-Pot'' and ''Ordered-and-Structured'' approaches In the OP method, all data points from the table are simultaneously processed to form a single CoT (termed OPCoT).Conversely, in the OS method, table data points are batched according to feature rank hierarchy, with each batch sequentially giving rise to intermediate CoTs.Each CoT incrementally builds upon the logic of the preceding one, representing a progressive development of understanding.The OSCoT materializes through iterative processing of all data point batches.The small chain icon represents the integration of messages, indicating, for example, that a connection between user_message and data points, along with the intermediate OSCoT, integrates these elements into the corresponding user message, thereby solidifying the foundation for subsequent OSCoT iterations.TableS1details the full names of the abbreviations.</p>
<p>Figure 3 .
3
Figure 3. Illustration of structured prompting tactics used to direct the reasoning process for OSCoT generation within user message 1 (UM1) I: Establishing the persona of the expert expected to analyze the data; II: Providing detailed instructions for input data, including the format and specific observations to note; III: Emphasizing the importance of focusing on relevant details; IV: Dictating the desired output, its structure, and word limit.(Aand B) Decomposing the complex task into general, manageable tasks, and splitting and reinforcing them to ensure thorough analysis.(C) Putting the analyzed datapoints in the rear of the messages.In Python, the f-string format employs curly braces {} to insert the content within variables into the string.Here, we use angle brackets &lt;&gt; as separators for generated sentences or paragraphs.Additionally, the variable delimiter adopted here is ''##''.</p>
<p>Figure 4 .
4
Figure 4. Prediction accuracies for different ternary CeM 1 M 2 composites by GPT Assistants after analyzing only the corresponding binary counterparts (A) Run-specific accuracy results from five independent runs for each ternary case.(B) Statistical summaries of the corresponding results in (A), with bars indicating the average of the accuracy values from the five runs and error bars representing the standard deviation of these accuracy values.</p>
<p>iScience 27, 109451, April 19, 2024
iScience 27, 109451,April 19, 2024<br />
Data and code availabilityThe authors declare that data supporting the findings of this study are available if requested.All python codes used in this study are available at https://github.com/MUYU-LU/OSCoT.SUPPLEMENTAL INFORMATIONSupplemental information can be found online at https://doi.org/10.1016/j.isci.2024.109451.ACKNOWLEDGMENTSWe gratefully acknowledge funding from the National Natural Science Foundation of China (U20A20130DECLARATION OF INTERESTSThe authors declare no competing interests.Received: November 6, 2023 Revised: January 26, 2024STAR+METHODS KEY RESOURCES TABLE RESOURCE AVAILABILITYLead contactFurther information and requests for resources should be directed to and will be fulfilled by the lead contact, Linjiang Chen (l.j.chen@bham.ac.uk).Materials availabilityThis study did not generate new unique reagents.METHODS DETAILSThe chemistry context and a case study of NH 3 -SCR catalysis Specifically, we assess the effectiveness of prompting GPT-4 to analyze and interpret experimental tabular data pertaining to a clearly defined chemistry problem.This knowledge involves variables from experiments-such as conditions and parameters-and their corresponding outcomes, all derived from the existing body of literature.The structured experimental data, akin to a JSON format, characterised by keys with corresponding values in either text or numerical form, is rendered to GPT-4.GPT-4 is then prompted to interpret this data, predict the expected experimental outcome based on specified features sets, and explain its prediction.This is informed by our recent success in discovering Ce-based metal-oxide composites for selective catalytic reduction of nitrogen oxides with ammonia,22facilitated by interpretable machine learning (ML).In that investigation, utilizing SHapley Additive exPlanations (SHAP) methods to interpret the Extreme Gradient Boosting (XGB) ensemble model trained by 5654 samples detailed various aspects and corresponding NO x conversion collected from literature brings underscoring influence of variables like reaction temperature and metal elements.The feature importance of these features can be seen as orders of analysis on features, thus embodying deductive relationship in the reasonings paths.For this purpose, we curated a dataset from existing literature, comprising 1838 unique experiments on NH 3 -SCR using Ce-based metaloxide composites.This dataset encompasses experimental variables such as the catalyst composition (binary and ternary Ce-based metaloxide composites, CeM 1 and CeM 1 M 2 (M 1 , M 2 = metal element; M 1 s M 2 ), synthesis parameters, reaction conditions, and experimental NO x conversion outcomes.We adopted a threshold of 95% NO x conversion to categorize outcomes as ''Positive'' or ''Negative''.We designed to evolve variables in the tabular data within the dataset curated here in the reasoning chain to verify whether the GPT-4 can better interpret data and make predictions.In specific, we engaged GPT-4 with the tabular data using Chain-of-Thought (CoT) in an ordered and batchwise and atonce manner.The context length of memory of GPT-4 is much longer than human and therefore we evaluated CoT prompting strategies against the performances of human chemists in predicting for the same experiments.These were critically assessed against our domain expertise and the prevailing consensus in the subject field, offering a comprehensive evaluation of GPT-4's and the chemists' predictive and reasoning capabilities.Background knowledge of chain-of-thought (CoT) promptingLLMs are adept at conducting "zero-shot" learning, leveraging knowledge from their extensive training datasets to respond to queries without needing specific prior examples.However, these models often encounter challenges in complex tasks that require advanced reasoning and planning.To overcome these hurdles, various strategies such as "few-shot" prompting and other advanced techniques have been introduced to bolster their capabilities.23The "Chain of Thought" (CoT) strategy,5
Language models are few-shot learners. T Brown, B Mann, N Ryder, M Subbiah, J D Kaplan, P Dhariwal, A Neelakantan, P Shyam, G Sastry, A Askell, Adv. Neural Inf. Process. Syst. 332020</p>
<p>GPT-4. Openai, 10.48550/arXiv.2303.087742023Preprint at arXiv</p>
<p>A comprehensive survey of ai-generated content (aigc): A history of generative ai from gan to chatgpt. Y Cao, S Li, Y Liu, Z Yan, Y Dai, P S Yu, L Sun, 10.48550/arXiv.2303.042262023Preprint at arXiv</p>
<p>ChatGPT and Open-AI Models: A Preliminary Review. K I Roumeliotis, N D Tselikas, Future Internet. 151922023</p>
<p>Chain of thought prompting elicits reasoning in large language models. J Wei, X Wang, D Schuurmans, M Bosma, E Chi, Q Le, D Zhou, 10.48550/arXiv.2201.119032022Preprint at arXiv</p>
<p>H Liu, R Ning, Z Teng, J Liu, Q Zhou, Y Zhang, 10.48550/arXiv.2304.03439Evaluating the logical reasoning ability of chatgpt and gpt-4. Preprint at arXiv. 2023</p>
<p>M Fraiwan, N Khasawneh, 10.48550/arXiv.2305.00237A Review of ChatGPT Applications in Education, Marketing, Software Engineering, and Healthcare: Benefits, Drawbacks, and Research Directions. 2023Preprint at arXiv</p>
<p>Improving mathematical reasoning with process supervision. Openai, 2023</p>
<p>. D M Katz, M J Bommarito, S Gao, P Arredondo, 2023Gpt-4 passes the bar exam. Available at SSRN 4389233</p>
<p>ChatGPT and environmental research. J.-J Zhu, J Jiang, M Yang, Z J Ren, Environ. Sci. Technol. 572023</p>
<p>Is GPT-4 a Good Data Analyst. L Cheng, X Li, Bing , L , 10.48550/arXiv.2305.150382023Preprint at arXiv</p>
<p>ChatGPT Chemistry Assistant for Text Mining and Prediction of MOF Synthesis. Z Zheng, O Zhang, C Borgs, J T Chayes, O M Yaghi, 10.1021/jacs.3c058192023Preprint at arXiv</p>
<p>ChemCrow: Augmenting large-language models with chemistry tools. A M Bran, S Cox, A D White, P Schwaller, 10.48550/arXiv.2304.053762023Preprint at arXiv</p>
<p>Fine-Tuning GPT-3 for Machine Learning Electronic and Functional Properties of Organic Molecules. Z Xie, X Evangelopoulos, O ¨ Omar, A Troisi, A I Cooper, L Chen, 2023</p>
<p>A GPT-4 Reticular Chemist for Guiding MOF Discovery. Z Zheng, Z Rong, N Rampal, C Borgs, J T Chayes, O M Yaghi, Angew. Chem. Int. Ed. 622023. e202311983</p>
<p>ChatGPT Research Group for Optimizing the Crystallinity of MOFs and COFs. Z Zheng, O Zhang, H L Nguyen, N Rampal, A H Alawadhi, Z Rong, T Head-Gordon, C Borgs, J T Chayes, O M Yaghi, 10.1021/acscentsci.3c01087ACS Cent. Sci. 92023</p>
<p>Shaping the Water-Harvesting Behavior of Metal-Organic Frameworks Aided by Fine-Tuned GPT Models. Z Zheng, A H Alawadhi, S Chheda, S E Neumann, N Rampal, S Liu, H L Nguyen, Y.-H Lin, Z Rong, J I Siepmann, 10.1021/jacs.3c12086J. Am. Chem. Soc. 1452023</p>
<p>Autonomous chemical research with large language models. D A Boiko, R Macknight, B Kline, G Gomes, Nature. 6242023</p>
<p>Large language models for chemistry robotics. N Yoshikawa, M Skreta, K Darvish, S Arellano-Rubach, Z Ji, L Bjørn Kristensen, A Z Li, Y Zhao, H Xu, A Kuramshin, Aut. Robots. 2023</p>
<p>Retrieval-augmented generation for knowledge-intensive nlp tasks. P Lewis, E Perez, A Piktus, F Petroni, V Karpukhin, N Goyal, H Ku ¨ttler, M Lewis, W.-T Yih, T Rockta ¨schel, Adv. Neural Inf. Process. Syst. 332020</p>
<p>Knowledge-Driven Experimental Discovery of Ce-Based Metal Oxide Composites for Selective Catalytic Reduction of NO x with NH 3 through Interpretable Machine Learning. M Lu, F Gao, Y Tan, H Yi, Y Gui, Y Xu, Y Wang, Y Zhou, X Tang, L Chen, 10.1021/acsami.3c18490ACS Appl. Mater. Interfaces. 162024</p>
<p>Large language models are zero-shot reasoners. T Kojima, S S Gu, M Reid, Y Matsuo, Y Iwasawa, Adv. Neural Inf. Process. Syst. 352022</p>
<p>Automatic chain of thought prompting in large language models. Z Zhang, A Zhang, M Li, A Smola, 10.48550/arXiv.2210.034932022Preprint at arXiv</p>
<p>Self-consistency improves chain of thought reasoning in language models. X Wang, J Wei, D Schuurmans, Q Le, E Chi, S Narang, A Chowdhery, D Zhou, 10.48550/arXiv.2203.111712022Preprint at arXiv</p>
<p>Least-tomost prompting enables complex reasoning in large language models. D Zhou, N Scha ¨rli, L Hou, J Wei, N Scales, X Wang, D Schuurmans, C Cui, O Bousquet, Q Le, 10.48550/arXiv.2205.106252022Preprint at arXiv</p>
<p>Reflexion: an autonomous agent with dynamic memory and self-reflection. N Shinn, B Labash, A Gopinath, 10.48550/arXiv.2303.113662023Preprint at arXiv</p>
<p>Lost in the Middle: How Language Models Use Long Contexts. N F Liu, K Lin, J Hewitt, A Paranjape, M Bevilacqua, F Petroni, P Liang, 10.48550/arXiv.2307.031722023Preprint at arXiv</p>            </div>
        </div>

    </div>
</body>
</html>