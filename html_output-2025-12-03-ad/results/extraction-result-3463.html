<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-3463 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-3463</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-3463</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-80.html">extraction-schema-80</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of functional-level theories or models of how conceptual knowledge is represented in the brain, including descriptions of the representational format, supporting evidence, counter-evidence, and comparisons between theories.</div>
                <p><strong>Paper ID:</strong> paper-267364904</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2402.00591v3.pdf" target="_blank">Sandra - A Neuro-Symbolic Reasoner Based On Descriptions And Situations</a></p>
                <p><strong>Paper Abstract:</strong> This paper presents sandra , a neuro-symbolic rea-soner combining vectorial representations with deductive reasoning. Sandra builds a vector space constrained by an ontology and performs reasoning over it. The geometric nature of the reasoner allows its combination with neural networks, bridging the gap with symbolic knowledge representations. Sandra is based on the Description and Situation (DnS) ontology design pattern, a formalization of frame semantics. Given a set of facts (a situation) it allows to infer all possible perspectives (descriptions) that can provide a plausible interpretation for it, even in presence of incomplete information. We prove that our method is correct with respect to the DnS model. We experiment with two different tasks and their standard benchmarks, demonstrating that, without increasing complexity, sandra (i) outperforms all the baselines (ii) provides interpretability in the classification process, and (iii) allows control over the vector space, which is designed a priori.</p>
                <p><strong>Cost:</strong> 0.015</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e3463.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e3463.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of functional-level theories or models of how conceptual knowledge is represented in the brain, including descriptions of the representational format, supporting evidence, counter-evidence, and comparisons between theories.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>DnS</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Description and Situation (DnS) ontology design pattern</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A formalization of frame semantics where 'descriptions' (intensional perspectives/theories) and 'situations' (extensional sets of facts/entities) are first-order entities; a situation satisfies a description when its entities can be classified by the roles of the description.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>DnS (frame-based description/situation representation)</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Conceptual knowledge is structured as n-ary relations: descriptions are sets of roles (a schema or perspective) and situations are sets (or nested sets) of entities; satisfaction is a relation between situations and descriptions. In Sandra this is implemented functionally by mapping descriptions/roles to basis vectors and descriptions to subspaces, and situations to vectors that are linear combinations of role vectors.</td>
                        </tr>
                        <tr>
                            <td><strong>level_of_analysis</strong></td>
                            <td>functional</td>
                        </tr>
                        <tr>
                            <td><strong>supporting_evidence</strong></td>
                            <td>The paper gives formal theorems (Theorems 1–3) proving correctness of the DnS→vector-space mapping (linear independence of role vectors, equivalence between a situation satisfying a description and its vector lying in the description's subspace). Empirical support comes from two benchmarks (I-RAVEN and Rotated-FashionMNIST) where constraining learned representations by a DnS-based space improved accuracy/interpretability relative to baselines.</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence_or_challenges</strong></td>
                            <td>Dependence on availability and design of a DnS-compatible ontology (manual engineering effort); potential backward inconsistency when transforming arbitrary ontologies into DnS (reification risks); computational cost scales linearly with ontology size so large ontologies may be expensive; current method cannot invert f_s to recover which entity instantiates which role.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_theories</strong></td>
                            <td>Contrasted with pure logic-based symbolic reasoning (which is sound/complete but intolerant of inconsistent/conflicting descriptions and poor with partial data) and with neural network embeddings (which handle unstructured data but may violate formal models or miss some plausible descriptions). DnS is used as the formal intensional layer that Sandra maps into a geometric vector-space representation.</td>
                        </tr>
                        <tr>
                            <td><strong>notable_limitations_or_open_questions</strong></td>
                            <td>How to construct DnS representations from arbitrary ontologies formally (isomorphism conditions), how to compactly represent very large ontologies (exploit hierarchy), how to recover entity-to-role bindings from vectors, and how ontology design choices affect downstream ML performance.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Sandra - A Neuro-Symbolic Reasoner Based On Descriptions And Situations', 'publication_date_yy_mm': '2024-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3463.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e3463.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of functional-level theories or models of how conceptual knowledge is represented in the brain, including descriptions of the representational format, supporting evidence, counter-evidence, and comparisons between theories.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>sandra</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>sandra - a neuro-symbolic reasoner based on descriptions and situations</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A neuro-symbolic architecture that maps a DnS ontology into a geometric vector space where each description is a subspace spanned by role vectors; a neural network is trained to place observed situations into that space so one can deduce (probabilistically and deductively) which descriptions the situation satisfies.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>Vector-space DnS representation (sandra)</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Concepts/descriptions are implemented as linear subspaces of a vector space whose basis vectors correspond to roles/descriptions derived from an ontology; situations map to vectors (linear combinations of role vectors). Satisfaction is determined by checking whether the situation vector lies in a description subspace (or by coefficients >0); probabilistic satisfaction is computed from counts of nonzero coefficients and approximated via ReLU for differentiability.</td>
                        </tr>
                        <tr>
                            <td><strong>level_of_analysis</strong></td>
                            <td>functional</td>
                        </tr>
                        <tr>
                            <td><strong>supporting_evidence</strong></td>
                            <td>Formal proofs in the paper show linear independence of role vectors and equivalence of vector-subspace membership to logical satisfaction; empirical experiments on I-RAVEN and Rotated-FashionMNIST indicate that integrating sandra (a regularizer constraining latent vectors to ontology-derived subspaces) yields equal or improved accuracy, improved interpretability (inferred descriptions explain predictions), and control over learned vector geometry.</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence_or_challenges</strong></td>
                            <td>Practical limitations noted: dependency on a hand-crafted DnS ontology, scalability concerns as the ontology grows (dimensionality and f_s complexity), potential mismatch when converting other ontology patterns to DnS (possible backward inconsistency), and the current inability to reconstruct original situation-level bindings from the vector encoding.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_theories</strong></td>
                            <td>Sandra is explicitly compared to (1) logic-based symbolic reasoning: retains deductive interpretability but avoids hard inconsistency by allowing multiple (possibly conflicting) descriptions to be probabilistically satisfied; (2) neural network embeddings: combines their ability to ingest unstructured data with ontology-constrained geometry to reduce sensitivity to noise; (3) prior neuro-symbolic methods: unlike many prior approaches that still assume consistency and probabilistic logical frameworks, sandra permits perspective multiplicity and partial-data tolerance.</td>
                        </tr>
                        <tr>
                            <td><strong>notable_limitations_or_open_questions</strong></td>
                            <td>Which ontology design patterns best support sandra; formal properties of mapping arbitrary ontologies into DnS; whether more compact/ hierarchical encodings are possible; sensitivity to choice of smoothing/activation functions (they use ReLU as a differentiable proxy for Heaviside); and how sandra behaves with more complex ontologies and other ML architectures.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Sandra - A Neuro-Symbolic Reasoner Based On Descriptions And Situations', 'publication_date_yy_mm': '2024-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3463.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e3463.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of functional-level theories or models of how conceptual knowledge is represented in the brain, including descriptions of the representational format, supporting evidence, counter-evidence, and comparisons between theories.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ConceptualSpaces</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Conceptual spaces (Gärdenfors, 2004)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A geometric theory of concepts that represents concepts as convex regions in a metric/quality-dimensional space, serving as an intermediate layer between subsymbolic and symbolic representations.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Conceptual Spaces: The Geometry of Thought</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>Conceptual spaces (geometric regions)</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Concepts are regions (often convex) in a continuous, interpretable space whose axes are quality dimensions; similarity and conceptual relations correspond to geometric relations in that space.</td>
                        </tr>
                        <tr>
                            <td><strong>level_of_analysis</strong></td>
                            <td>functional</td>
                        </tr>
                        <tr>
                            <td><strong>supporting_evidence</strong></td>
                            <td>The paper cites conceptual spaces as the inspiration for using geometric representations as an intermediate level between sub-symbolic neural encodings and symbolic ontologies; conceptual spaces have been influential for explaining graded membership, similarity-based effects, and prototype-like phenomena (general cognitive literature).</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence_or_challenges</strong></td>
                            <td>The paper cites Bouraoui et al. (2022) describing two major issues: (1) deriving region-based representations from real-world data is hard, and (2) conceptual spaces are not naturally suited for representing relational knowledge. The authors argue their DnS→vector-space approach plus neural approximators overcomes these two limitations.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_theories</strong></td>
                            <td>Sandra is said to 'follow the intuition of conceptual spaces' but instead of approximating an ontology as regions, sandra uses the ontology to define a vector space with subspaces for descriptions—claiming this avoids the two cited conceptual-space limitations. Conceptual spaces are thus compared as a motivating, but incomplete, alternative.</td>
                        </tr>
                        <tr>
                            <td><strong>notable_limitations_or_open_questions</strong></td>
                            <td>How to derive interpretable region representations from high-dimensional empirical data, and how to naturally encode relational/multi-ary structure within conceptual-space frameworks; whether hybrid methods (like sandra) systematically solve these issues across domains.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Sandra - A Neuro-Symbolic Reasoner Based On Descriptions And Situations', 'publication_date_yy_mm': '2024-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3463.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e3463.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of functional-level theories or models of how conceptual knowledge is represented in the brain, including descriptions of the representational format, supporting evidence, counter-evidence, and comparisons between theories.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>SymbolicLogic</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Logic-based symbolic representations (ontologies, OWL/Description Logic)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Formal symbolic models where concepts/classes and relations are expressed with logical axioms enabling sound and complete deductive inference; widely used in KR and ontology engineering.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>Symbolic (logical/ontological) representation</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Concepts are discrete symbols (classes/predicates) and relations expressed via logical axioms (e.g., Description Logic/OWL); inference is deductive and exact: class subsumption, instance checking, and logical entailment determine conceptual classification.</td>
                        </tr>
                        <tr>
                            <td><strong>level_of_analysis</strong></td>
                            <td>functional</td>
                        </tr>
                        <tr>
                            <td><strong>supporting_evidence</strong></td>
                            <td>The paper emphasizes benefits: clear formal models of descriptions, soundness and completeness of inference, and extensive use in ontology projects (cites OWL/DL-based uses). The DnS pattern itself is an ontological formalization used in the method.</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence_or_challenges</strong></td>
                            <td>Rigid consistency assumptions make it impossible or undesirable to assign multiple, conflicting descriptions to the same situation (inconsistency leads to logical contradictions). Logic-based approaches also require well-structured, compliant extensional data (expensive manual curation), and they handle partial/incomplete data poorly without special extensions.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_theories</strong></td>
                            <td>Contrast with neural network embeddings: symbolic methods excel at formal guarantees and explicit structure but lack tolerance to noisy or partial data; neural methods handle unstructured data and noise but lack deductive completeness and may violate formal constraints. Sandra aims to bridge these via a vector-space derived from ontologies.</td>
                        </tr>
                        <tr>
                            <td><strong>notable_limitations_or_open_questions</strong></td>
                            <td>How to relax or reinterpret consistency assumptions to allow multiple perspectives; how to integrate symbolic axioms into differentiable architectures without losing soundness; and how to scale symbolic representations when used as constraints for learned continuous representations.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Sandra - A Neuro-Symbolic Reasoner Based On Descriptions And Situations', 'publication_date_yy_mm': '2024-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3463.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e3463.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of functional-level theories or models of how conceptual knowledge is represented in the brain, including descriptions of the representational format, supporting evidence, counter-evidence, and comparisons between theories.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>NeuralNNs</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Distributed neural network representations (deep embeddings)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Learned continuous high-dimensional vectors (embeddings) produced by neural networks that encode features of inputs (images, text) and support classification and generalization from examples.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>Distributed neural representations (embeddings)</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Concepts and categories are encoded as patterns of activation across many units (continuous vectors); similarity and classification are based on geometric relations in embedding spaces learned from data.</td>
                        </tr>
                        <tr>
                            <td><strong>level_of_analysis</strong></td>
                            <td>functional</td>
                        </tr>
                        <tr>
                            <td><strong>supporting_evidence</strong></td>
                            <td>Neural networks can ingest unstructured multimodal data and produce useful features for downstream tasks; the paper relies on CNNs/MLPs/LSTMs to produce situation-approximating vectors that sandra projects into the ontology-derived space, and notes empirical success on benchmarks.</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence_or_challenges</strong></td>
                            <td>Neural models may require large labeled datasets (including examples of descriptions/perspectives), can produce outputs incompatible with formal symbolic models (missing plausible descriptions), and lack deductive completeness and guaranteed interpretability without additional structure.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_theories</strong></td>
                            <td>Placed opposite symbolic logic: neural methods are flexible and robust to noise but do not enforce formal constraints; hybrid neuro-symbolic approaches (including sandra) attempt to keep benefits of both. The paper argues sandra reduces neural sensitivity by constraining representations into ontology-derived geometry.</td>
                        </tr>
                        <tr>
                            <td><strong>notable_limitations_or_open_questions</strong></td>
                            <td>Extent to which ontological constraints harm or help representation learning across tasks, how to choose architecture/activation functions for best integration, and how to ensure learned embeddings retain invertible links to original symbolic entities.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Sandra - A Neuro-Symbolic Reasoner Based On Descriptions And Situations', 'publication_date_yy_mm': '2024-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3463.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e3463.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of functional-level theories or models of how conceptual knowledge is represented in the brain, including descriptions of the representational format, supporting evidence, counter-evidence, and comparisons between theories.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>NeuroSymbolic</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Neuro-symbolic hybrid approaches</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A family of methods combining neural (sub-symbolic) learning with symbolic logical structures to obtain both flexible perception from data and structured, interpretable reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>theory_name</strong></td>
                            <td>Neuro-symbolic hybrid representation</td>
                        </tr>
                        <tr>
                            <td><strong>theory_description</strong></td>
                            <td>Hybrid representations pair continuous learned embeddings (for perception/features) with symbolic structures/rules (for explicit reasoning); integration can be via constrained embeddings, differentiable logic layers, or neural predicates in probabilistic logic.</td>
                        </tr>
                        <tr>
                            <td><strong>level_of_analysis</strong></td>
                            <td>functional</td>
                        </tr>
                        <tr>
                            <td><strong>supporting_evidence</strong></td>
                            <td>Prior works (Manhaeve et al., Geh et al., van Krieken et al.) demonstrate improved task performance and some forms of interpretable reasoning by combining neural perception with symbolic reasoning; the paper positions sandra in this family and shows empirical gains when sandra constrains neural representations.</td>
                        </tr>
                        <tr>
                            <td><strong>counter_evidence_or_challenges</strong></td>
                            <td>Many prior neuro-symbolic systems still assume global consistency and are tied to probabilistic logic frameworks that do not tolerate inconsistent/conflicting perspectives well. Integration often raises computational/complexity challenges and depends on careful design of interfaces between symbolic and neural parts.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_other_theories</strong></td>
                            <td>Compared to pure symbolic or pure neural methods, neuro-symbolic approaches aim to get the best of both; sandra claims a distinctive advantage by formalizing DnS in a differentiable vector-space that permits multiple (possibly conflicting) descriptions to be probabilistically satisfied, addressing a particular shortcoming of many neuro-symbolic systems.</td>
                        </tr>
                        <tr>
                            <td><strong>notable_limitations_or_open_questions</strong></td>
                            <td>How to handle inconsistency and partial data robustly across neuro-symbolic systems, which integration patterns scale best, and how design choices (e.g., choice of smoothing approximations like ReLU vs. logistic) affect learning and interpretability.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Sandra - A Neuro-Symbolic Reasoner Based On Descriptions And Situations', 'publication_date_yy_mm': '2024-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Conceptual Spaces: The Geometry of Thought <em>(Rating: 2)</em></li>
                <li>Description and Situation (DnS) pattern / Formalization (Gangemi and Mika, 2003) <em>(Rating: 2)</em></li>
                <li>On implementing conceptual spaces and their limitations (Bouraoui et al., 2022) <em>(Rating: 2)</em></li>
                <li>DeepProbLog / ProbLog extensions with neural predicates (Manhaeve et al., 2018) <em>(Rating: 1)</em></li>
                <li>Neuro-symbolic methods combining ASP and neural networks (Geh et al., 2023) <em>(Rating: 1)</em></li>
                <li>Logic Tensor Networks (Chen et al., 2021) <em>(Rating: 1)</em></li>
                <li>Frame semantics and Fillmore's work (Fillmore, 2006) <em>(Rating: 1)</em></li>
                <li>A framework for representing knowledge (Minsky, 1974) <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-3463",
    "paper_id": "paper-267364904",
    "extraction_schema_id": "extraction-schema-80",
    "extracted_data": [
        {
            "name_short": "DnS",
            "name_full": "Description and Situation (DnS) ontology design pattern",
            "brief_description": "A formalization of frame semantics where 'descriptions' (intensional perspectives/theories) and 'situations' (extensional sets of facts/entities) are first-order entities; a situation satisfies a description when its entities can be classified by the roles of the description.",
            "citation_title": "",
            "mention_or_use": "use",
            "theory_name": "DnS (frame-based description/situation representation)",
            "theory_description": "Conceptual knowledge is structured as n-ary relations: descriptions are sets of roles (a schema or perspective) and situations are sets (or nested sets) of entities; satisfaction is a relation between situations and descriptions. In Sandra this is implemented functionally by mapping descriptions/roles to basis vectors and descriptions to subspaces, and situations to vectors that are linear combinations of role vectors.",
            "level_of_analysis": "functional",
            "supporting_evidence": "The paper gives formal theorems (Theorems 1–3) proving correctness of the DnS→vector-space mapping (linear independence of role vectors, equivalence between a situation satisfying a description and its vector lying in the description's subspace). Empirical support comes from two benchmarks (I-RAVEN and Rotated-FashionMNIST) where constraining learned representations by a DnS-based space improved accuracy/interpretability relative to baselines.",
            "counter_evidence_or_challenges": "Dependence on availability and design of a DnS-compatible ontology (manual engineering effort); potential backward inconsistency when transforming arbitrary ontologies into DnS (reification risks); computational cost scales linearly with ontology size so large ontologies may be expensive; current method cannot invert f_s to recover which entity instantiates which role.",
            "comparison_to_other_theories": "Contrasted with pure logic-based symbolic reasoning (which is sound/complete but intolerant of inconsistent/conflicting descriptions and poor with partial data) and with neural network embeddings (which handle unstructured data but may violate formal models or miss some plausible descriptions). DnS is used as the formal intensional layer that Sandra maps into a geometric vector-space representation.",
            "notable_limitations_or_open_questions": "How to construct DnS representations from arbitrary ontologies formally (isomorphism conditions), how to compactly represent very large ontologies (exploit hierarchy), how to recover entity-to-role bindings from vectors, and how ontology design choices affect downstream ML performance.",
            "uuid": "e3463.0",
            "source_info": {
                "paper_title": "Sandra - A Neuro-Symbolic Reasoner Based On Descriptions And Situations",
                "publication_date_yy_mm": "2024-02"
            }
        },
        {
            "name_short": "sandra",
            "name_full": "sandra - a neuro-symbolic reasoner based on descriptions and situations",
            "brief_description": "A neuro-symbolic architecture that maps a DnS ontology into a geometric vector space where each description is a subspace spanned by role vectors; a neural network is trained to place observed situations into that space so one can deduce (probabilistically and deductively) which descriptions the situation satisfies.",
            "citation_title": "here",
            "mention_or_use": "use",
            "theory_name": "Vector-space DnS representation (sandra)",
            "theory_description": "Concepts/descriptions are implemented as linear subspaces of a vector space whose basis vectors correspond to roles/descriptions derived from an ontology; situations map to vectors (linear combinations of role vectors). Satisfaction is determined by checking whether the situation vector lies in a description subspace (or by coefficients &gt;0); probabilistic satisfaction is computed from counts of nonzero coefficients and approximated via ReLU for differentiability.",
            "level_of_analysis": "functional",
            "supporting_evidence": "Formal proofs in the paper show linear independence of role vectors and equivalence of vector-subspace membership to logical satisfaction; empirical experiments on I-RAVEN and Rotated-FashionMNIST indicate that integrating sandra (a regularizer constraining latent vectors to ontology-derived subspaces) yields equal or improved accuracy, improved interpretability (inferred descriptions explain predictions), and control over learned vector geometry.",
            "counter_evidence_or_challenges": "Practical limitations noted: dependency on a hand-crafted DnS ontology, scalability concerns as the ontology grows (dimensionality and f_s complexity), potential mismatch when converting other ontology patterns to DnS (possible backward inconsistency), and the current inability to reconstruct original situation-level bindings from the vector encoding.",
            "comparison_to_other_theories": "Sandra is explicitly compared to (1) logic-based symbolic reasoning: retains deductive interpretability but avoids hard inconsistency by allowing multiple (possibly conflicting) descriptions to be probabilistically satisfied; (2) neural network embeddings: combines their ability to ingest unstructured data with ontology-constrained geometry to reduce sensitivity to noise; (3) prior neuro-symbolic methods: unlike many prior approaches that still assume consistency and probabilistic logical frameworks, sandra permits perspective multiplicity and partial-data tolerance.",
            "notable_limitations_or_open_questions": "Which ontology design patterns best support sandra; formal properties of mapping arbitrary ontologies into DnS; whether more compact/ hierarchical encodings are possible; sensitivity to choice of smoothing/activation functions (they use ReLU as a differentiable proxy for Heaviside); and how sandra behaves with more complex ontologies and other ML architectures.",
            "uuid": "e3463.1",
            "source_info": {
                "paper_title": "Sandra - A Neuro-Symbolic Reasoner Based On Descriptions And Situations",
                "publication_date_yy_mm": "2024-02"
            }
        },
        {
            "name_short": "ConceptualSpaces",
            "name_full": "Conceptual spaces (Gärdenfors, 2004)",
            "brief_description": "A geometric theory of concepts that represents concepts as convex regions in a metric/quality-dimensional space, serving as an intermediate layer between subsymbolic and symbolic representations.",
            "citation_title": "Conceptual Spaces: The Geometry of Thought",
            "mention_or_use": "mention",
            "theory_name": "Conceptual spaces (geometric regions)",
            "theory_description": "Concepts are regions (often convex) in a continuous, interpretable space whose axes are quality dimensions; similarity and conceptual relations correspond to geometric relations in that space.",
            "level_of_analysis": "functional",
            "supporting_evidence": "The paper cites conceptual spaces as the inspiration for using geometric representations as an intermediate level between sub-symbolic neural encodings and symbolic ontologies; conceptual spaces have been influential for explaining graded membership, similarity-based effects, and prototype-like phenomena (general cognitive literature).",
            "counter_evidence_or_challenges": "The paper cites Bouraoui et al. (2022) describing two major issues: (1) deriving region-based representations from real-world data is hard, and (2) conceptual spaces are not naturally suited for representing relational knowledge. The authors argue their DnS→vector-space approach plus neural approximators overcomes these two limitations.",
            "comparison_to_other_theories": "Sandra is said to 'follow the intuition of conceptual spaces' but instead of approximating an ontology as regions, sandra uses the ontology to define a vector space with subspaces for descriptions—claiming this avoids the two cited conceptual-space limitations. Conceptual spaces are thus compared as a motivating, but incomplete, alternative.",
            "notable_limitations_or_open_questions": "How to derive interpretable region representations from high-dimensional empirical data, and how to naturally encode relational/multi-ary structure within conceptual-space frameworks; whether hybrid methods (like sandra) systematically solve these issues across domains.",
            "uuid": "e3463.2",
            "source_info": {
                "paper_title": "Sandra - A Neuro-Symbolic Reasoner Based On Descriptions And Situations",
                "publication_date_yy_mm": "2024-02"
            }
        },
        {
            "name_short": "SymbolicLogic",
            "name_full": "Logic-based symbolic representations (ontologies, OWL/Description Logic)",
            "brief_description": "Formal symbolic models where concepts/classes and relations are expressed with logical axioms enabling sound and complete deductive inference; widely used in KR and ontology engineering.",
            "citation_title": "",
            "mention_or_use": "use",
            "theory_name": "Symbolic (logical/ontological) representation",
            "theory_description": "Concepts are discrete symbols (classes/predicates) and relations expressed via logical axioms (e.g., Description Logic/OWL); inference is deductive and exact: class subsumption, instance checking, and logical entailment determine conceptual classification.",
            "level_of_analysis": "functional",
            "supporting_evidence": "The paper emphasizes benefits: clear formal models of descriptions, soundness and completeness of inference, and extensive use in ontology projects (cites OWL/DL-based uses). The DnS pattern itself is an ontological formalization used in the method.",
            "counter_evidence_or_challenges": "Rigid consistency assumptions make it impossible or undesirable to assign multiple, conflicting descriptions to the same situation (inconsistency leads to logical contradictions). Logic-based approaches also require well-structured, compliant extensional data (expensive manual curation), and they handle partial/incomplete data poorly without special extensions.",
            "comparison_to_other_theories": "Contrast with neural network embeddings: symbolic methods excel at formal guarantees and explicit structure but lack tolerance to noisy or partial data; neural methods handle unstructured data and noise but lack deductive completeness and may violate formal constraints. Sandra aims to bridge these via a vector-space derived from ontologies.",
            "notable_limitations_or_open_questions": "How to relax or reinterpret consistency assumptions to allow multiple perspectives; how to integrate symbolic axioms into differentiable architectures without losing soundness; and how to scale symbolic representations when used as constraints for learned continuous representations.",
            "uuid": "e3463.3",
            "source_info": {
                "paper_title": "Sandra - A Neuro-Symbolic Reasoner Based On Descriptions And Situations",
                "publication_date_yy_mm": "2024-02"
            }
        },
        {
            "name_short": "NeuralNNs",
            "name_full": "Distributed neural network representations (deep embeddings)",
            "brief_description": "Learned continuous high-dimensional vectors (embeddings) produced by neural networks that encode features of inputs (images, text) and support classification and generalization from examples.",
            "citation_title": "",
            "mention_or_use": "use",
            "theory_name": "Distributed neural representations (embeddings)",
            "theory_description": "Concepts and categories are encoded as patterns of activation across many units (continuous vectors); similarity and classification are based on geometric relations in embedding spaces learned from data.",
            "level_of_analysis": "functional",
            "supporting_evidence": "Neural networks can ingest unstructured multimodal data and produce useful features for downstream tasks; the paper relies on CNNs/MLPs/LSTMs to produce situation-approximating vectors that sandra projects into the ontology-derived space, and notes empirical success on benchmarks.",
            "counter_evidence_or_challenges": "Neural models may require large labeled datasets (including examples of descriptions/perspectives), can produce outputs incompatible with formal symbolic models (missing plausible descriptions), and lack deductive completeness and guaranteed interpretability without additional structure.",
            "comparison_to_other_theories": "Placed opposite symbolic logic: neural methods are flexible and robust to noise but do not enforce formal constraints; hybrid neuro-symbolic approaches (including sandra) attempt to keep benefits of both. The paper argues sandra reduces neural sensitivity by constraining representations into ontology-derived geometry.",
            "notable_limitations_or_open_questions": "Extent to which ontological constraints harm or help representation learning across tasks, how to choose architecture/activation functions for best integration, and how to ensure learned embeddings retain invertible links to original symbolic entities.",
            "uuid": "e3463.4",
            "source_info": {
                "paper_title": "Sandra - A Neuro-Symbolic Reasoner Based On Descriptions And Situations",
                "publication_date_yy_mm": "2024-02"
            }
        },
        {
            "name_short": "NeuroSymbolic",
            "name_full": "Neuro-symbolic hybrid approaches",
            "brief_description": "A family of methods combining neural (sub-symbolic) learning with symbolic logical structures to obtain both flexible perception from data and structured, interpretable reasoning.",
            "citation_title": "",
            "mention_or_use": "mention",
            "theory_name": "Neuro-symbolic hybrid representation",
            "theory_description": "Hybrid representations pair continuous learned embeddings (for perception/features) with symbolic structures/rules (for explicit reasoning); integration can be via constrained embeddings, differentiable logic layers, or neural predicates in probabilistic logic.",
            "level_of_analysis": "functional",
            "supporting_evidence": "Prior works (Manhaeve et al., Geh et al., van Krieken et al.) demonstrate improved task performance and some forms of interpretable reasoning by combining neural perception with symbolic reasoning; the paper positions sandra in this family and shows empirical gains when sandra constrains neural representations.",
            "counter_evidence_or_challenges": "Many prior neuro-symbolic systems still assume global consistency and are tied to probabilistic logic frameworks that do not tolerate inconsistent/conflicting perspectives well. Integration often raises computational/complexity challenges and depends on careful design of interfaces between symbolic and neural parts.",
            "comparison_to_other_theories": "Compared to pure symbolic or pure neural methods, neuro-symbolic approaches aim to get the best of both; sandra claims a distinctive advantage by formalizing DnS in a differentiable vector-space that permits multiple (possibly conflicting) descriptions to be probabilistically satisfied, addressing a particular shortcoming of many neuro-symbolic systems.",
            "notable_limitations_or_open_questions": "How to handle inconsistency and partial data robustly across neuro-symbolic systems, which integration patterns scale best, and how design choices (e.g., choice of smoothing approximations like ReLU vs. logistic) affect learning and interpretability.",
            "uuid": "e3463.5",
            "source_info": {
                "paper_title": "Sandra - A Neuro-Symbolic Reasoner Based On Descriptions And Situations",
                "publication_date_yy_mm": "2024-02"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Conceptual Spaces: The Geometry of Thought",
            "rating": 2,
            "sanitized_title": "conceptual_spaces_the_geometry_of_thought"
        },
        {
            "paper_title": "Description and Situation (DnS) pattern / Formalization (Gangemi and Mika, 2003)",
            "rating": 2,
            "sanitized_title": "description_and_situation_dns_pattern_formalization_gangemi_and_mika_2003"
        },
        {
            "paper_title": "On implementing conceptual spaces and their limitations (Bouraoui et al., 2022)",
            "rating": 2,
            "sanitized_title": "on_implementing_conceptual_spaces_and_their_limitations_bouraoui_et_al_2022"
        },
        {
            "paper_title": "DeepProbLog / ProbLog extensions with neural predicates (Manhaeve et al., 2018)",
            "rating": 1,
            "sanitized_title": "deepproblog_problog_extensions_with_neural_predicates_manhaeve_et_al_2018"
        },
        {
            "paper_title": "Neuro-symbolic methods combining ASP and neural networks (Geh et al., 2023)",
            "rating": 1,
            "sanitized_title": "neurosymbolic_methods_combining_asp_and_neural_networks_geh_et_al_2023"
        },
        {
            "paper_title": "Logic Tensor Networks (Chen et al., 2021)",
            "rating": 1,
            "sanitized_title": "logic_tensor_networks_chen_et_al_2021"
        },
        {
            "paper_title": "Frame semantics and Fillmore's work (Fillmore, 2006)",
            "rating": 1,
            "sanitized_title": "frame_semantics_and_fillmores_work_fillmore_2006"
        },
        {
            "paper_title": "A framework for representing knowledge (Minsky, 1974)",
            "rating": 1,
            "sanitized_title": "a_framework_for_representing_knowledge_minsky_1974"
        }
    ],
    "cost": 0.0145945,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Sandra -A Neuro-Symbolic Reasoner Based On Descriptions And Situations
25 Mar 2024</p>
<p>Nicolas Lazzari nicolas.lazzari3@unibo.it 
University of Bologna</p>
<p>Stefano De Giorgis stefano.degiorgis2@unibo.it 
University of Bologna</p>
<p>Aldo Gangemi aldo.gangemi@unibo.it 
University of Bologna</p>
<p>Valentina Presutti valentina.presutti@unibo.it 
University of Bologna</p>
<p>Sandra -A Neuro-Symbolic Reasoner Based On Descriptions And Situations
25 Mar 2024C3C6262082EDD9DD2CBA6E4E990C48B4arXiv:2402.00591v3[cs.AI]
This paper presents sandra, a neuro-symbolic reasoner combining vectorial representations with deductive reasoning.Sandra builds a vector space constrained by an ontology and performs reasoning over it.The geometric nature of the reasoner allows its combination with neural networks, bridging the gap with symbolic knowledge representations.Sandra is based on the Description and Situation (DnS) ontology design pattern, a formalization of frame semantics.Given a set of facts (a situation) it allows to infer all possible perspectives (descriptions) that can provide a plausible interpretation for it, even in presence of incomplete information.We prove that our method is correct with respect to the DnS model.We experiment with two different tasks and their standard benchmarks, demonstrating that, without increasing complexity, sandra (i) outperforms all the baselines (ii) provides interpretability in the classification process, and (iii) allows control over the vector space, which is designed a priori.</p>
<p>Introduction</p>
<p>Reasoning on perspectives is relevant in many contexts and applications.In very rigorous domains such as medicine or jurisprudence, the same case can be interpreted through more than one description: a patient's situation can be analyzed through different diagnostic hypotheses; a legal state of affairs can be interpreted by applying different, possibly conflicting, norms.In storytelling techniques, spin doctors can frame the same topic in different ways to support alternative political scenarios: "Conservatives claim that we need relief from taxes vs. Democrats claim that taxes are investments for us."[Vossen and Fokkens, 2022].</p>
<p>Informally, a set of facts (situation) can be described through more than one -potentially conflicting -perspective, which can be inferred even in presence of partial data.This paper proposes a method and a neuro-symbolic reasoner, named sandra, able to infer all perspectives that are plausible descriptions for a given situation.Associating different plausible descriptions to a situation requires the capability to reason at both the intensional and the extensional level, i.e., with both concepts and facts, posing a challenge on how to formally represent the knowledge required, as well as on the reasoning technique to apply.</p>
<p>From a knowledge representation perspective, the Description and Situation (DnS) [Gangemi and Mika, 2003] ontology design pattern addresses this problem.DnS provides a formalization of frame semantics, generalizing over Fillmore's [Fillmore and others, 2006] and Minsky's [Minsky, 1974] proposals.It has been largely used in many ontology projects (mainly using its OWL formalization) [Scherp et al., 2009;Boyan Brodaric and Femke Reitsma and Yi Qiang, 2008;Porzel and Cangalovic, 2020;Bikakis et al., 2021].DnS defines a general vocabulary for n-ary relations, introducing the concepts of description and situation.A situation is a set of facts, as it is described by an observer, involving a set of entities.In Figure 1 a situation involving three entities is represented: Bob, ENCOM, and Laptop.A description is a perspective (a theory, a schema) defining concepts that can classify, hence interpret, the entities observed in a situation.In Figure 1 two descriptions are represented, Commerce buy and Contest winning.With DnS, both descriptions and situations are formalized as first-order entities in an ontology, therefore potentially enabling reasoning over them both at the intensional (description) and extensional (situation) level, in the same domain of discourse.In DnS terms, we say that a situation s satisfies a description d, when d is a plausible or correct interpretation of s.In Figure 1 both descriptions (Commerce buy and Contest winning) are satisfied by the situation s 1 involving Bob, ENCOM, and Laptop, even if they are conceptually incompatible.A perspectivebased reasoner shall be able to detect this conceptual difference and yet infer both satisfies relations.</p>
<p>To the best of our knowledge, this behaviour is unobtainable with existing logic-based reasoners.Within a traditional logic approach, conflicting concepts (such as Commerce buy and Contest winning) are correctly modelled as disjoint classes.Therefore, classifying the situation from the example of Figure 1 in both descriptions would lead to an inconsistency.Furthermore, no classification would be provided if the extensional data available is partial.Fuzzy reasoners, such as [Kamide, 2022], may be more tolerant but would show the same problem (inconsistency) adding an issue of possible undecidability.Logic-based representations and reasoning have also benefits: a clear, formal model of descriptions is defined and the inference is always sound and complete with respect to that model.At the same time, the data representing situations must be structured and compliant with such model, requiring significant effort.</p>
<p>Neural Network models are a solution to both obtaining an approximate classification, and being able to inject any type of data (images, text, etc.), not only structured data.Nevertheless, they may need a large sample including both descriptions and situations, and the results may be incompatible with the formal model, for example it might happen that only some of the plausible descriptions are retrieved.In short, logic reasoning lacks inconsistency and partial-data-tolerant deductions, while neural network models lack the completeness of deductive inference.</p>
<p>Neuro-symbolic methods, such as [Manhaeve et al., 2018;Geh et al., 2023;van Krieken et al., 2022], combine important benefits of logic-based and approximate reasoning, and (very important) they can ingest unstructured data.Nevertheless, they rely on the same consistency assumption, which is undesirable in a perspective-reasoning scenario.</p>
<p>The approach proposed in this research (sandra) relies on the neuro-symbolic paradigm but addresses this issue.It formalizes and implements the inference of the satisfies relation between situations and descriptions and, at the same time, it provides a probability score and a deductive, interpretable inference.</p>
<p>It includes: (i) a theoretical framework formalizing DnS in a differentiable and probabilistic fashion, which we prove to be correct with respect to DnS.It creates a vector space V isomorphic to a DnS-based ontology (defining a set of descriptions); (ii) the implementation of a neuro-symbolic architecture, where the neural network is constrained to position any detected situation (from any source type) in one or more subspaces of V , each corresponding to a description defined in the ontology.The intuition is that this constraint makes the network less prone to noise.Our formulation allows efficient inference in the DnS domain.Our hypothesis is that by constraining the representation learning process to a DnS-based ontology we can perform perspective-based reasoning without performance loss or increase of computational complexity.</p>
<p>To evaluate our hypothesis we experiment our method on two different tasks: visual reasoning on the I-RAVEN benchmark [Hu et al., 2021] and domain generalization on Fashion-MNIST [Xiao et al., 2017].For each task, we asses the influence of adding sandra to a standard baseline model and find increased performances with polynomial complexity1 .</p>
<p>Our contribution can be summarized as follows: 1.A correct differentiable probabilistic formalization of DnS; 2. A neuro-symbolic reasoner that combines deductive and inductive reasoning to classify arbitrary situations extracted by a neural network into the descriptions (perspectives) that can plausibly interpret them.</p>
<p>The rest of the paper provides a formalization of DnS (Section 2) and of our method (Section 3).Section 4 describes our experiments and results, which are further discussed, along with future work in Section 5. Section 6 discusses relevant related work, while Section 7 concludes the paper.</p>
<p>Descriptions &amp; Situations</p>
<p>In DnS, descriptions and situations are n-ary relations.We refer to the arguments of a description as roles, and to those of a situation as entities.For example, in Figure 1, Business, Consumer, and Item are the roles of the Commerce buy description, while ENCOM, Bob, and Laptop are the entities of the situation s 1 .A situation s satisfies a description d, if each entity of s can be classified by one role of d2 .</p>
<p>A formalization of DnS in First Order Logic is given in [Gangemi and Mika, 2003].We extend it to allow roles as n-ary relations and provide here the resulting formal semantics.With O a DnS-based ontology, we define D as the set of descriptions in the ontology, with R the set of roles and E the set of entities and assume that D
∪ R ∪ E ⊂ O. Definition 1. A description d is a set d = {r 1 , • • • , r n } ∈ D with r i ∈ R ∪ (D − {d}).
In Figure 2, Refund = {Consumer, Business, Item} ∈ D. Notice that descriptions can be used as roles as well.</p>
<p>For instance, Customer care policy = {Commerce buy, Refund, Reason} ∈ D, where Commerce buy, Refund ∈ D.
Definition 2. A situation s is a set s = (e 1 , • • • , e n ) ∈ S with e i ∈ D ∪ R ∪ E ∪ S.
For example, the set {Bob, ENCOM, Laptop} of Figure 2 is a situation.</p>
<p>A situation can also involve other situations as its entities.For example, in Figure 2 In Figure 2 the situation s = {Bob, ENCOM, Laptop} satisfies the descriptions Commerce buy and Contest winning.Both descriptions are perspectives from which s can be interpreted.</p>
<p>Assuming that O asserts that Consumer, Business ⊆ Agent (i.e.Agent is a broader role than Consumer and Business), we have that Commercial transaction |= s as well, since the two roles are also Agents.
Corollary 1. Given d, d ′ ∈ D with d ′ ⊆ d and s ∈ S then d ′ |= s ⇒ d |= s.
Corollary 1 trivially follows from definition 3. Definition 3 states the condition such that a perspective is valid for a situation.However, a description can be a plausible perspective for a situation even if only some of its roles are fulfilled.In this case, we say that a description nearly satisfies a situation, written as d |=s.Definition 4 (near-satisfaction).With d ∈ D and s ∈ S,
d |=s ⇔ ∃r ∈ d.(∃e ∈ s.e ∈ r) ∨ (∃s ′ ∈ s.r |= s ′ )
From Definition 4 it follows that if a situation satisfies a description, then it also nearly-satisfies it.The corollary trivially follows from Definitions 3 and 4.</p>
<p>Method</p>
<p>With reference to Section 2 we define a vector space V over the field R with dim(V ) = |R ∪ D|.For each description d ∈ D a subspace V d is identified by its roles.Assuming that v s is a vector representing s ∈ S and that d |= s with d ∈ D, the intuition following from Definition 3 (and 4) is that v s must be defined by (some) entities classified by the roles in D that identify the subspace V d .</p>
<p>In this section, we describe how a subspace V d is defined and how to deduce when a description is (nearly-)satisfied by a situation.Notation-wise, we assume that s ∈ S and for some d ∈ D, V d is the subspace associated with d and B d is a spanning set of V d .Subspace definition The set B d , defined as
B d = {b 1 , • • • , b n } is a(f d ). Given x ∈ D ∪ R, f d : D ∪ R → V is defined as f d (x) = ϕ(x) + 1 [x∈D] r∈x f d (r) where ϕ(x) = [1 [x⊆y1] || • • • ||1 [x⊆yn] ] with y 1 , • • • , y n ∈ R∪ D and n = |D ∪ R|.
The function ϕ(x) considers D ∪ R as an ordered set with n = |D ∪ R| elements.It creates a vector of dimension n where the i th element is 1 if x is equal or a subset of the i th element in D ∪ R. For example, consider
D ∪ R = {Agent, Item, Consumer, • • • } with |D ∪ R| = 10 and Consumer ⊆ Agent as in Figure 2. Then f d (Agent) = ϕ(a) = [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], f d (Consumer) = ϕ(d) = [1, 0, 1, 0, 0, 0, 0, 0, 0, 0] and f d (Commercial transaction) = ϕ(Agent) + ϕ(Item) = [1, 1, 0, 0, 0, 0, 0, 0, 0, 0]. Theorem 1. Given a description d ∈ D, the vectors in B = {f d (r 1 ), • • • , f d (r n )} with r 1 , • • • , r n ∈ d are linearly independent.
Proof.Without loss of generality, assume that O is converted to a Directed Acyclic Graph (DAG) where edges connect descriptions to their roles.Consider
α 1 f d (x 1 )+• • •+α n f d (x n ) with x 1 ̸ = • • • ̸ = x n ∈ R ∪ D and α 1 , • • • , α n ∈ R. Each term α i f d (x i ) = r∈Xi α i ϕ(r)
where X i is the union of x i \ D and of the roles recursively collected from the nested descriptions in x i .Since ϕ is positive-definite and injective (∃x.ϕ
(x) = a ̸ = b = ϕ(x) → ∃ŷ.1 [x⊆ŷ] ̸ = 1 [x⊆ŷ] → ⊥) then α 1 f d (x 1 )+• • •+α n f d (x n ) = 0 ⇔ α 1 = • • • = α n = 0. Thus, f d (x 1 ), • • • , f d (x n ) are linearly independent.
By taking B d as the spanning set of V d , it forms a basis of the subspace associated with the description d.It will be possible to represent a situation s that satisfy d as a linear combination of the vectors in B d .Situation encoding Given the definition of the subspace V d , the intuition is that its vectors are those representing all the situations s such that d |= s.To obtain v s ∈ V , the vector representation of s, we introduce the function f s , which maps a situation s ∈ S into a vector.
Definition 6 (B d and V d ). Given a description d ∈ D, V has a subspace V d spanned by the basis B d = {f d (r 1 ), • • • , f d (r n )} with r 1 , • • • , r n ∈ d.
Definition 7. Given s ∈ S, e ∈ E and r ∈ R, and with ψ : E → R defined such that e ∈ r ⇒ ψ(e) = r, the function
f s : S → V is defined as f s (s) = e∈s f s (e) if e ∈ S f d (ψ(e)) otherwise
The function ψ can be implemented by a deductive reasoner (e.g.[Glimm et al., 2014]) or provided externally.</p>
<p>The vector v s produced by the function f s is the aggregation of the vector representation of the roles that classifies the entities in s and its nested situations.Nested situations are recursively converted into a vector using the same function f s .For example from Figure 2 Item).Note that from Definition 5 it follows that f s is a positive definite function, i.e. f s (x) ≥ 0 ∀s ∈ S, since ϕ is positive definite.We model the satisfaction of a description as a multinomial probability distribution, hence the probability that s satisfies d is
, f s ({Bob, ENCOM, Laptop}) = f d (Consumer) + f d (Business) + f d (</p>
<p>Description satisfaction
p(d |= s) = |d| i=0 1 [&gt;0] (x) i |d|(1)
Definition 8. Given d ∈ D, s ∈ S we say that s nearlysatisfies d with probability p, written as
d |= ps, if p(d |= s) = p.
Given Definition 8, we can now state Theorem 3, which generalizes Theorem 2 to nearly-satisfied descriptions according to Definition 4.
Theorem 3. With s ∈ S, d ∈ D then (i) d |= ps ⇒ d |=s with p = p(d |= s) &gt; 0; (ii) d |= 1 s ⇒ d |= s; (iii) d |= 0 s ⇒ d ̸ |= s.
Proof.(i) d |= ps then, according to Definition 8, there is some r ∈ d such that, given the coefficient i that corresponds to r in x, (x) i &gt; 0. Hence v s is a linear combination of f d (r).Similarly to proof of Theorem 2, given Definition 7 it can be proven that exists e ∈ s with e ∈ r.Thus, from Definition 4, d |=s.Theorem 3 enables a crucial property of our formalization: to infer to which degree a description is satisfied by a situation, while retaining correctness with respect to Definitions 3 (satisfaction) and 4 (near-satisfaction).
(ii) d |= 1 s then |d| i=0 1 [&gt;0] (x) i = 1 and v s is linear combi- nation of
dP-sandra (Differentiable P-sandra) By virtue of Theorem 3, the process of deducing which descriptions are satisfied (or nearly-satisfied) by a situation is a function
H : V → R |D| , with H(s) = [p(d 1 |= s)∥ • • • ∥p(d n |= s)] (2) with d 1 , • • • , d n ∈ D.
H is differentiable with respect to the input vector v s (it is composition of differentiable functions) and in particular
∇H = [δ(v s )∥ • • • ∥δ(v s ))] where δ is Dirac's delta and d 1 , • • • , d n ∈ D.
Due to the use of the Heaviside function, the gradient is zero everywhere except for the descriptions with probability zero, since δ(x) = 0 ∀x ̸ = 0.This prevents an effective use of H in Machine Learning methods that rely on gradients to learn the model's parameters, such as in Deep Learning, where the back-propagation algorithm is used [Le-Cun et al., 2015].</p>
<p>To overcome this issue, we replace the Heaviside function 1 [&gt;0] (x) with the ReLU function [Glorot et al., 2011].We argue, without any loss in generality, that the behaviour of the ReLU function is comparable to the Heaviside function in our setting, since ReLU (x) &gt; 0 ⇔ x &gt; 0. Indeed, we can interpret the ReLU function as a smooth version of 1 &gt;0 (x).Other functions could be used for the same purpose, such as continuous approximations of the Heaviside function, tanh, logistic function etc.In this case, we rely on ReLU since empirically it suffers less from the exploding/vanishing gradient problem.Nonetheless, we will perform a systematic assessment of other functions in the future, as different functions might lead to different useful properties.</p>
<p>Neuro-symbolic integration</p>
<p>Since dP-sandra is differentiable with respect to its input vector, it can be used as a standard neural network layer.We define the function H by replacing the Heaviside function in H (as defined in Equation 2) with the ReLU function.The function H allows a seamless integration of a DnS-based ontology O within any arbitrary neural network N N .</p>
<p>The N N approximates the function f s from a nonstructured source.Consider x the output of a neural network, for instance the features extracted by a Convolutional Neural Network (CNN) from an image or the embedding of a sentence computed by a Transformer, then the N N approximates the result of f s (x) as if x was created from a structured source.</p>
<p>Hence, we can check if the situation represented by x satisfies d by relying on Definition 1.Moreover, since H is fully differentiable with respect to its input, it is possible to define an objective function that optimizes the output of the N N such that the representation learned for x lies in V d as if it was produced by f s .</p>
<p>We highlight that our experiments (c.f.Section 4) show that the representation learned by N N (a vector x originating from any source) approximates the vector representation of a situation s manually curated for modeling or representing that source, such as in a Knowledge Graph.This provides us with a means to interpret the intermediate output of the N N , and better understand its internal representation, without influencing the process to solve the down-stream task.For ex-ample, given the image of a lung X-ray, sandra infers all the possible diagnoses without compromising the freedom of the model to formulate the final prediction.</p>
<p>Experiments</p>
<p>We experiment the integration of dP-sandra in different neural network architectures.Our goal is to assess whether sandra allows to perform perspective-based reasoning without any performance loss or increase in computational complexity, as hyphotesized in Section 1.We test our method on two benchmarks: I-RAVEN [Hu et al., 2021], a visual reasoning task, and RotatedFashionMNIST, a domain generalisation task based on FashionMNIST [Xiao et al., 2017].The choice of the tasks is motivated by the suitability of the data to be modeled according to DnS with a reasonable effort.All the experiments have been trained with the AdamW optimizer on a NVIDIA RTX3090 with 24Gb of RAM.</p>
<p>Visual Reasoning</p>
<p>The I-RAVEN dataset, based on Raven Progressive Matrices (RPMs) is a repository of images for visual reasoning tasks, designed to examine abstract reasoning capabilities in neural networks [Hu et al., 2021].An RPM is a 3 × 3 grid of images where the last image has been removed.The task is to predict the removed image among 8 possible alternatives [Małkiński and Mańdziuk, 2022].Each image might be composed of multiple (nested) figures, which are simple geometric shapes where the color, size and rotation are varied [Hu et al., 2021].Recent approaches frame the task as a classification problem and tailor the model to the RPM problem.This has been done by structuring the models such that the relationship between the images is captured [Santoro et al., 2017;Barrett et al., 2018;Zhang et al., 2019a;He et al., 2023] or by reasoning upon the extracted visual features through neuro-symbolic methods [Xu et al., 2023;Hersche et al., 2023].Our approach extends the baseline model proposed by [Zhang et al., 2019a] with sandra.The baseline model is composed by an LSTM that combines the visual features extracted by a CNN on each image.Details on the architecture are in the Appendix 3 .We integrate sandra within the baseline model by adding a linear layer W that projects the representation obtained by the CNN in the vector space V .W is meant to approximate the function f s .</p>
<p>Given an image within an RPM, s R is the situation extracted from the XML provided by the dataset accordingly to Definition 1 (c.f.Appendix for details on the extraction process) and x the vector representing the visual features of the image extracted by the CNN.We approximate f s (s R ) by minimizing the binary cross entropy
L BCE ( Ĥ(f s (s)), Ĥ(ReLU (W x))(3)
where H is computed as explained in Section 3.1.Our model classifies an image using linear regression on x∥ Ĥ(ReLU (W x)).The loss function is hence
L = L CE + L BCE ( Ĥ(ReLU (W x)), H(f s (s)))(4)
3 Included in the additional material.where L CE is the cross-entropy loss as defined in [Zhang et al., 2019a].</p>
<p>Our approach radically differs from the others since, by relying on sandra, the visual features extracted from an image are geometrically constrained such that it is possible to infer valid descriptions from them.The model learns to accurately classify an image, while capturing the semantics of the ontology in its internal representation.The influence of sandra is a regularization with respect to a DnS-based ontology.We manually compile a DnS-based ontology (detailed in Appendix) that models the RAVEN dataset.Each image is then converted into a situation compliant to the ontology.Relying on sandra allows the inference of which shapes are contained within a figure.A comparison of sandra with the baseline is shown in Table 1a, we report the of number of parameters of the network (first column) and accuracy (the other columns) of the classification.Each model has been trained using a batch size of 32, a learning rate of 0.001 and the gradient is clipped to have a norm ≤ 0.5.The results show that integrating sandra does not compromise performances (improving them in some cases) nor it requires a significant increase in the number of parameters.We also compare sandra with other approaches tailored for this task and for the sake of space, the comparison is reported in the Appendix.We remark that, despite its generality, our method is competitive with other methods4 .</p>
<p>Domain Generalization</p>
<p>The domain generalization task aims at testing how a model is able to learn representations that are independent of a specific domain, i.e. they are effective on distributions never seen during the training process [Zhou et al., 2022].This includes, for example, correctly classifying images seen from a different angle than the one in the training set.Many approaches have been investigated, from learning representations that specifically tackles the problem [Mahajan et al., 2021], to different training techniques [Vedantam et al., 2021].A wide selection of architectures and techniques is analysed in [Zhou et al., 2023].Similarly to [Mahajan et al., 2021], we rely on the Rotated-FashionMNIST (R-FMNIST) dataset.R-FMNIST is an image classification task where the training images are rotated in three configurations: The first image has a high probability of satisfying the FootWear description, which is reasonable considering the target label.In the second image, we can understand that the wrong classification is associated with the similar probability given to the LowerBodyClothes and UpperBodyClothes descriptions, leading to an unreliable result.are rotated by {0 • , 90 • }.
A = {30 • , 45 • }, B ≡ A ∪ {60 • }, C ≡ B ∪ {15 • , 75 • }. The testing set images
The final prediction is computed using linear regression over the features extracted by a CNN or a MLP.The architectures are described in the Appendix.We manually create a DnS-based ontology, detailed in the Appendix, that models the dataset.Table 1b describes the results in terms of number of parameters of the network (in the caption) and accuracy of the classification.Each model has been trained with a batch size of 32 and a fixed learning rate of 1e −4 .The use of sandra proves to be beneficial also in this experiment even though the images of R-FMNIST are only described with a single label, leading to a fairly simple ontology.</p>
<p>These experiments allow us to empirically show the sandra improves the interpretability of the model and of its results, as addressed in Section 3. Figure 3 shows the effect of sandra in the interpretation of two images, one correctly labeled and one misclassified.By looking at the inferred descriptions, it is possible to interpret the motivation of the mistake.</p>
<p>Discussion and Future Works</p>
<p>Sandra approaches the problem of reasoning on different persepectives by formalizing DnS in a vector space.Through the formulation described in Section 3 it is possible to infer the descriptions satisfied by a situation.Most importantly, it is possible to quantify the degree of satisfiability as a probability distribution, enabling the inference of valid interpretations of a situation regardless of their compatibility and of the amount of information available.This is an important aspect that finds application in many domains where rigorous reasoning with limited information is a key requirement such as robotics, medicine or jurisprudence.We discuss some limitations and interesting aspects that are worth further investigation.DnS-shape Compatibility Sandra's dependency on DnS ontologies, which underpins V , presents a non-trivial limitation.This is relevant if one wants to integrate it with ontologies using different (if any) ODP.However, we argue that it is possible to find an isomorphism between any arbitrary ontology and a DnS ontology.Informally, we can use reification.Each binary predicate (property) p can become a class expressing a n-ary relation, whose arguments are its domain and range.Any axiom involving the property p can be reified as a description including p as role.When reversed -as expected -this transformation may be backward inconsistent, since the inferred satisfied descriptions may correspond to disjoint classes in the original ontology.We will explore how to formally define such isomorphic transformation, alongside its properties and limitations.Another consideration is that the existence of an ontology compatible with DnS does not always guarantee improved performance.We need further research to identify the most effective DnS transformation patterns for integration with sandra.We plan to study sandra's behavior with other ontologies, particularly with complex ones, to find correlations between ontology design solutions and sandra's performance.Ontology Complexity and Scalability Another issue is the inherent computational complexity.The function f s is linear in space with the dimension of the ontology.While this might seem an ideal condition, as the ontology gets more complex (e.g.thousands of descriptions) this might result in a large overhead, especially if f s is approximated through a neural network.Further research is required to identify if it is possible to obtain more compact representations, for instance by exploiting the hierarchical structure of the ontology or by exploring methods that pre-process the ontology removing nonessential elements.Methodological Improvements The definitions of f d and f s might be improved to obtain additional useful properties.For instance, our current method overlooks a procedure to retrieve the original situation s from f s .This precludes useful outcomes, such as uniquely identifying which entity of s has been classified by which role in d.An interesting approach is to extend the method of Section 3 to some parts of Description Logic as well.In that case, it might be possible to benefit from additional features that have been formalized in the ontology but that are unexploited since they are missing in the DnS pattern.Neurosymbolic integration The results of Section 4 provide a positive insight on how sandra can be beneficial to neural architectures.Nonetheless, the variance in performance gains between different tasks requires a systematic analysis, in order to better understand which kind of architectures can benefit the most from sandra and how they should be integrated.Investigating the ODPs that lead to increased performances is an important step towards tighter integration be-tween Machine Learning (ML) and Knowledge Representation (KR).Notably, this aspect has the potential to catalyse a novel paradigm in the realm of KR, since different ML techniques might behave differently with different ontologies.</p>
<p>Related Works</p>
<p>The idea of using geometric representation for cognitive theory was originally proposed by Peter Gärdenfors [2004] as an intermediate representation layer between sub-symbolic and symbolic knowledge.A conceptual space depicts concepts as convex regions.Each region is shaped by the attributes that characterise that concept.Our method follows the intuition of conceptual spaces.Two main problems on conceptual spaces are highlighted by [Bouraoui et al., 2022].One is the derivation of region-based representations for concepts that is difficult when data comes from real-world scenarios; another issue is that the representations in conceptual spaces are not amenable to expressing relational knowledge.Given the integration of a neural network as a situation approximator, as proposed in Section 3.1, and the DnS formalization ( Section 2), our method overcomes both limitations.Other approaches that implement conceptual spaces, such as [Bouraoui et al., 2022], propose to interpret embeddings as conceptual spaces.Others approximate ontologies based on their graph representation or rely on specific neural architectures, like Logic Tensor Networks to obtain deductive inferences [Chen et al., 2021;Ebrahimi et al., 2021].Differently to these approaches, our representation is not an approximation of the ontology.The ontology is used to obtain a vector space in which concepts are represented.This is similar to the approach described in [ Özc ¸ep et al., 2020], where geometrical properties are exploited to obtain sound knowledge representation methods.</p>
<p>Other related approaches integrate symbolic representations in geometrical spaces to support reasoning such as in [Geh et al., 2023] where the authors complement Answer Set Programming with neural networks; in [Manhaeve et al., 2018] ProbLog is extended to the use of neural predicates; and [van Krieken et al., 2022] implements approximate logical inference.These approaches are inherently dependent on probabilistic logic, suffering from a lack of inconsistency tolerance.</p>
<p>Conclusion</p>
<p>We contribute a novel neuro-symbolic approach named sandra to address perspective-based reasoning based on the DnS ontology design pattern.Our experiments show that sandra brings benefits to the representation learning process without loss of performances or increase in computational complexity.</p>
<p>Each RPM configurations is modeled as a situation.The situation is compiled starting from the original XML generated alongside the images, which contains structured information on the RPM such as the specific composition of each panel.</p>
<p>We use SPARQL Anything [Asprino et al., 2022] to interpret and transform the XML data into situations, serialized in RDF using Turtle notation [Beckett et al., 2014].SPARQL Anything is a querying tool for Semantic Web reengineering.It allows users to query several data formats with the SPARQL query language.Through the use of the CONSTRUCT clause it is possible to compile a Knowledge Graph from the data formats supported by it.</p>
<p>The complexity of the ontology accommodates various meta-levels of deductions pertaining to different situations.For example, according to the above description, we add the axiom rv:hasComponent some rv: The I-RAVEN ontology models a description by declaring universal restrictions on the classes representing a role.This is done through the use of the rdfs:subClassOf predicate.For instance, rv:FT5 rdfs:subClassOf some rv:T5, which translates to (rv:FT5) ⊑ ∀(rdfs:subClassOf).(rv:T5) in Description Logic.In total, the ontology contains 144 classes (|D ∪ R| = 144).Table 5 provides a detailed description of all the descriptions and roles in the ontology.</p>
<p>Model Architecture</p>
<p>The model's architecture used for the visual reasoning experiments is a straightforward CNN followed by a single-layer LSTM.The last hidden state of the LSTM is used to perform the classification using a linear classification head.The architecture is described in detail in Table 2 Comparison with state of the art models In Table 6 a comparison of the results of Section 4 with recent works is reported.An estimate of the number of parameters is also described.Sandra performs better than the baseline but is outperformed by the other approaches.We remark that the other approaches are optimized to solve the I-RAVEN task and, differently to the baseline and to our method, they implement an architecture that considers all the nuances of the task (e.g.explicitly modeling panels on the same row).As already mentioned, outperforming specific solutions to the I-RAVEN task is out of scope of our research, rather we want to demonstrate that sandra is a competitive generalized reasoner, which is supported by its performance results against the baseline.</p>
<p>A.2 Domain Generalisation</p>
<p>In this section we describe the ontology developed for Fash-ionMNIST (Section A.2) and the architectures used for the experiments (Section A.2.The code to reproduce the experiments is available at https://anonymous.4open.science/r/sandra-fashionmnist-EEF0/. The original Fashion-MNIST dataset provides 10 labels, one per each type of clothes: T-shirt/top, Trousers, Pullover, Dress, Coat, Sandal, Shirt, Sneaker, Bag, and Ankle boot.No further semantics is provided about the entities, therefore the ontology developed for FashionMNIST is a straightforward representation modeled after intuitive and common-sense features of the clothes represented in the dataset.</p>
<p>Fashion-MNIST ontology</p>
<p>We re-engineer the Fashion-MNIST dataset to represent its intensional layer.The 10 types of clothes are represented as rdfs:subClassOf four top classes: :FootWear, :LowerBodyClothes, :UpperBodyClothes, and :Accessories.The semantics is introduced in the ontology via several object properties, listed in Table 7.</p>
<p>For example, the description :Pullover ∈ D has roles :LongSleeves, :Neckhole ∈ R and it is expressed as a subclass of :UpperBodyClothes ∈ D.</p>
<p>Model's architecture</p>
<p>For the domain generalisation experiments two baseline architectures have been used: a straightforward CNN followed by a linear classification head, described in</p>
<p>Figure 1 :
1
Figure 1: Example of two descriptions (Commerce buy and Contest winning) that are satisfied by a situation that involves the entities Bob, ENCOM, Laptop.The two descriptions define the same roles, hence they provide two different perspectives from which the situation can be interpreted.</p>
<p>Figure 2 :
2
Figure 2: Examples of some descriptions and situations alongside the conversion of a situation into V to detect the satisfied descriptions.The process of deducing which descriptions are satisfied by fs is shown on the right.</p>
<p>Corollary 2 .
2
With d ∈ D and s ∈ S, d |= s ⇒ d |=s</p>
<p>basis for the subspace V d , i.e. the vectors in B d form a minimal spanning set of V d .Hence every v ∈ V d can be expressed as a linear combination (a weighted sum) of the vectors in B d [Meyer and Stewart, 2023].Given Definitions 3 and 4, it follows that the vectors in B d must originate from the description d and its roles r ∈ d.We define f d as the function that converts each description d ∈ D to a vector f d (d) ∈ B d .Informally, f d (d) is obtained by recursively aggregating the vector representations v r of the roles r ∈ d.A function ϕ computes v r ensuring that f d (d) ∈ B d and that v r reflects subsumption relations between roles.Definition 5</p>
<p>It follows from Definition 5 that for any d ∈ D, B d can be computed in polynomial time O(|D| 2 ).The proof follows from Definition 5: by converting O to a DAG, for each description we have to loop through every other description in the worst case.</p>
<p>Given Theorem 1 and function f s , we can check whether the vector representation v s lies in the subspace V d by checking whether v s is linear combination of the vectors in B d .Consider A d as the |R ∪ D| × |d| matrix whose row-space is B d (i.e. the rows are formed by the vectors b ∈ B d ).The solution x to the linear system A d x = v s contains the coefficients to obtain the vector v s as the linear combination of the vectors b ∈ B d .With A + d the Moore-Penrose pseudo-inverse of A d , the unique solution x = A + d v s always exists, since the rows of A d are linearly independent by definition [Meyer and Stewart, 2023].If x i ̸ = 0 for all x i ∈ x then v s is linear combination of the vectors in B d meaning that v s ∈ V d .Since B d is directly defined after the roles of d (Definition 5), then the roles each role in d must classify an entity in s.Based on this, we define how to deduce the descriptions satisfied by s according to Definition 3. Theorem 2. Given s ∈ S, d ∈ D, and v s = f s (s) we have that d |= s ⇔ v s ∈ V d Proof.With d |= s, then ∀r ∈ d ∃e ∈ s.ψ(e) = r (i.e.exists an e ∈ s classified by r for all r ∈ d).If e ∈ S, then r ∈ D and r |= e.Given Definition 7 (f s ), v s = f s (s) is obtained by aggregating the encoding of the roles that classify the individuals of s.Hence v s ∈ V d , since it is linear combination of B d by construction.Thus, d |= s ⇒ v s ∈ V d .To prove that v s ∈ V d ⇒ d |= s, assume that v s ∈ V d .Hence, v s is linear combination of B d .Given Definition 7, ∀r ∈ d ∃e ∈ s. ψ(e) ∈ r ∨ r |= e.It follows from Definition 3 (description satisfaction) that d |= s.Thus, d |= s ⇔ f s (s) ∈ V d .P-sandra (Probabilistic sandra) According to Theorem 2 each element of the vector x (with x = A + d v s ) indicates the presence (or absence) of an entity e ∈ s with e ∈ r and r ∈ d.By applying the Heaviside function 1 [&gt;0] to x we can interpret it as a boolean vector.</p>
<p>the vector representation of all the roles r ∈ d.Thus, d |= s follows from Theorem 2. (iii) d |= 0 s then |d| i=0 1 [&gt;0] (x) i = 0 and v s can not be expressed as a linear combination of any of the vector representation of the roles r ∈ d.Thus, d ̸ |= s follows from Theorem 2.</p>
<p>Figure 3 :
3
Figure 3: Example of two images and the descriptions they satisfy.The first image has a high probability of satisfying the FootWear description, which is reasonable considering the target label.In the second image, we can understand that the wrong classification is associated with the similar probability given to the LowerBodyClothes and UpperBodyClothes descriptions, leading to an unreliable result.</p>
<p>Figure to the rv:Panel class.This results in Panel being a description (rv:Panel ∈ D) that includes the description rv:Figure (rv:Figure ∈ D and rv:Figure ∈ rv:Panel).:Figure is modeled as a description which includes the roles :Angle, :Color and :Size.In order to model the semantics within the I-RAVEN dataset and to allow for better understanding of the data, we model the combinatorial permutation of figures within panels as descriptions as well.For instance, a figure containing a circle satisfies the description rv:FT5 ∈ D, with rv:T5 ∈ rv:FT5.The role rv:T5 ∈ R is instantiated in a situation if the situation (i.e. the figure) contains a circle.</p>
<p>D Sequence of 3 panels on a row rv:hasPanel some rv:Panel rv:Panel D Represents each of the 9 panels in an RPM (16 if considering the 8 alternatives to choose from) as shown in Figure 4 rv:hasNumberValue some rv:Number, rv:hasComponent some rv:Figure Classes of the form rv:PFXY where X ∈ {rv:A, rv:C, rv:S, rv:T} and Y depends on X.For example, rv:A refers to the angle with X ∈ {0, 1, 2, 3, 4, 5, 6, 7}.D Implements the possible permutations of elements composing and qualifying the panel rv:hasComponent some rv:PXY rv:Figure D Represents each figure in each panel.As shown in Figure 4 a figure can vary for several dimensions (color, shape, etc.) rv:hasAngle some rv:Angle, rv:hasColor some rv:Color, rv:hasShape some rv:Shape, rv:hasSize some rv:Size rv:Number R Represents the number of the panel in the RPM.rv:Color R Represents the color of a figure.There are 10 possible color variations, expressed via 10 subclasses of the rv:Color class.rv:Shape R Represents the shape of a figure.There are 5 possible shapes, modeled as subclasses: rv:Triangle, rv:Square, rv:Pentagon, rv:Hexagon, and rv:Circle.rv:Angle R Represents the angle orientation of a figure.There are 8 possible orientations, expressed as subclasses of the rv:Angle class.rv:Size R Represents the size of a figure.There are 6 possible sizes, expressed as subclasses of the rv:Size class.</p>
<p>Alice bought a Laptop from ENCOM, ENCOM received it back from Alice and a Battery-Defect reason is specified.Both Alice buying and ENCOM receiving the Laptop are two separate situations that are part of another situation, which also involves BatteryDefect.When a description d explains a situation s, we say that s satisfies d, written as d |= s.
, the sets = {{ENCOM, Alice, Laptop},{Alice, ENCOM, Laptop},{BatteryDefect}}represents a situation in which Definition 3 (satisfaction). With d ∈ D and s ∈ Sd |= s ⇔ ∀r ∈ d.(∃e ∈ s.e ∈ r) ∨ (∃s ′ ∈ s.r |= s ′ )</p>
<p>Table 1 :
1
Results on the accuracy in R-FMNIST benchmark.The parameters in the CNN are 30k and 85.6k using sandra while 268.7k and 278k using sandra in the MLP.Experimental results.
ModelABC#ParamsC2×23×3 O-IC O-IGL-RU-DCNN16.02 17.21 43.13Baseline205k26.85 14.55 12.15 12.313.4 11.85 13.15sandra 15.74 18.62 52.49sandra275k45.75 16.15 14.114.8 14.85 13.05 13.15MLP14.56 16.64 31.34sandra 16.96 18.11 32.88(b)
(a) Results on the accuracy in the I-RAVEN dataset.Number of parameters of the baseline (first column) is compared with the addition of sandra.The remaining columns refer to the specific configuration of the I-RAVEN dataset (number of shapes and their position).</p>
<p>Table 2 :
2
. 3x3 conv., 16 filters, 2 stride, BN, ReLU 3x3 conv., 16 filters, 2 stride, BN, ReLU 3x3 conv., 16 filters, 2 stride, BN, ReLU 3x3 conv., 16 filters, 2 stride, BN, ReLU Linear layer for projection in sandra's V Architecture used for the experiments in the I-RAVEN dataset.
LSTM, 1 layer, 128 hidden dimensionLinear layerTotal of 205 K parametersTotal of 275 K parameters with sandra</p>
<p>Table 3
3, and an</p>
<p>Table 3 :
3
CNN architecture used for the experiments in the Rotated-FashionMNIST dataset.Linear layer, 256 hidden dimension, ReLU Linear layer, 256 hidden dimension, ReLU Linear layer for projection in sandra's V Linear layer Total of 268.7 K parameters Total of 278 K parameters with sandra</p>
<p>Table 4 :
4
MLP architecture used for the experiments in the Rotated-FashionMNIST dataset.</p>
<p>Table 5 :
5
Detailed description of each class in the I-RAVEN ontology.The Set column describes the type of each description, the purpose comments on the class while the axiomatisation is reported using Manchester syntax[Horridge and Patel-Schneider, 2009].</p>
<h1>ParamsC2×23×3 O-IC O-IGL-RU-DBaseline [Zhang et al., 2019a]205k26.85 14.55 12.15 12.313.4 11.85 13.15WReN [Santoro et al., 2018]&gt; 1.5M29.426.823.522.521.521.921.4ResNet [Zhang et al., 2019a]&gt; 25M44.729.327.946.235.851.247.4ResNet + DRT [Zhang et al., 2019a]&gt; 25M46.528.827.34634.250.149.8LEN [Zheng et al., 2019]&gt; 5M56.431.729.752.131.744.144.2CoPINet [Zhang et al., 2019b]&gt; 5M54.436.831.952.242.851.952.5DCNet [Zhuo and Kankanhalli, 2021]&gt; 5M57.834.135.55742.958.560NCD [Zhuo et al., 2021]&gt; 11M6031.23062.43958.957.2SRAN [Hu et al., 2021]&gt; 33M78.250.142.468.246.370.170.3PrAE [Zhang et al., 2021]  †&gt; 150k90.5 85.35 45.60 74.799.799.597.4ConViT [He et al., 2023]&gt; 5M99.996.275.599.499.699.587.3[Hersche et al., 2023]  †&gt; 11M10099.597.110010010096.4Baseline + sandra275k45.75 16.15 14.114.8 14.85 13.05 13.15</h1>
<p>Table 6 :
6
Results on the accuracy in the I-RAVEN dataset.The number of parameters for related works is a rough estimation based on the architecture used -e.g.we assume that when using a ResNet18 the model will have at least 11M parameters.It serves as a comparison between the number of parameters of the implemented baseline and those on related works.Results are retrieved from the corresponding papers.Models with † include the use of external solvers, such as planning algorithms.
F-MNIST propertyPurposeManchester syntax axiom example:coversExpresses which part of the body is:Dress :covers somecovered by a piece of clothing, if any:WholeBody, :Sandal :coverssome :Feet:hasClosureExpresses the type of closure of the:Coat :hasClosure somepiece of clothing (e.g. zip, buttons,:ButtonClosurelaces, etc.), if any:hasShapeExpresses if the entity covers entirely:Sandal :hasShapethe body part or if it leaves some un-some :OpenShape,covered parts:Sneaker :hasShape some:ClosedShape:hasSleevesExpresses the entity's kind of sleeves,:Pullover :hasSleevesif anysome :LongSleeves,:T-shirt top :hasSleevessome :ShortSleeves:wearingContextExpresses the prototypical context in:AnkleBoot :wearingContextwhich a certain entity can be wornsome :FormalContext,:T-shirt top:wearingContext some:InformalContext:wearingPointExpresses the part of the body from:Coat :wearingPoint somewhich an item of clothing is first worn:SleevesHole,:Pullover:wearingPoint some:NeckHole</p>
<p>Table 7 :
7
Details of each property used to axiomatize each description in the ontology.Axioms examples can be seen in the Axiomatization column, written in Manchester syntax [Horridge and Patel-Schneider, 2009].</p>
<p>In time and space with respect to the number of entities within an ontology.
In the original formalization of DnS this is called maximal satisfaction. We capture all possible types of satisfaction although the terminology is simplified.
We remind that our primary goal is to test our hypothesis rather than solving the downstream task.
Available at https://github.com/husheng12345/SRAN/
AcknowledgmentsThis project has received funding from the FAIR -Future Artificial Intelligence Research foundation as part of the grant agreement MUR n. 341 and from the European Union's Horizon 2020 research and innovation programme under grant agreement No 101004746.AppendixThe Appendix provides the details omitted from the manuscript due to space limitations and the links to the implementations to reproduce the results.In Section A we explain in details the architectures and ontologies used in Section 4 (experiments).The python implementation of sandra is available at https://anonymous.4open.science/r/sandra-C3D3/.A ExperimentsThis section provides additional details on the experiments performed in Section 4. Section A.1 describes the model's architecture and the ontology used in Section 4.1.Section A.2 we describes the models' architectures and the ontology used in Section A.2.A.1 Visual ReasoningThe original I-RAVEN dataset includes three main types of entities: Matrices, Panels, andI-RAVEN ontologyWe reverse-engineer the I-RAVEN conceptual module to model the I-RAVEN intensional layer.We define the set of components that can appear in an image (see Figure4) based on the I-RAVEN official code 5 .We model a set of descriptions based on these components.
Knowledge graph construction with a fac ¸ade: A unified method to access heterogeneous data sources on the web. Asprino, ACM Trans. Internet Technol. 2022. 2022</p>
<p>Eric Prud'hommeaux, and Gavin Carothers. Rdf 1.1 turtle. World Wide Web Consortium. Barrett, A challenge for historical research: Making data fair using a collaborative ontology management environment. Carola Eschenbach, Michael, Boyan Brodaric and Femke Reitsma and Yi Qiang2018. 2018. 2014. 2014. 2021. jan 2021. 2022. 200812Semant. Web. SKIing with DOLCE : toward an e-Science knowledge infrastructure</p>
<p>Igor Cataneo Silveira, Denis Deratani Mauá, and Fabio Gagliardi Cozman. dpasp: A comprehensive differentiable probabilistic answer set programming environment for neurosymbolic learning and reasoning. Chen Gruninger, arXiv:2308.02944Proceedings of the Fourteenth International Conference on Artificial Intelligence and Statistics, AISTATS 2011. Geoffrey J Gordon, David B Dunson, Miroslav Dudík, the Fourteenth International Conference on Artificial Intelligence and Statistics, AISTATS 2011Fort Lauderdale, USAJMLR.org2008. 2021. 2021. 2021. 2006. 2006. 2003. 2004. 2004. 2023. 2014. 2011. April 11-13, 2011. 2011183arXiv preprintJMLR Proceedings</p>
<p>Hierarchical convit with attention-based relational reasoner for visual analogical reasoning. He, Thirteenth Symposium on Educational Advances in Artificial Intelligence, EAAI 2023. Sheng Hu, Yuqing Ma, Xianglong Liu, Yanlu Wei, Shihao Bai, Washington, DC, USAAAAI Press2023. February 7-14, 2023. 2023. 2023. 2023. 2009. 2021. 20212023W3C Working Group NoteProceedings of the AAAI Conference on Artificial Intelligence</p>
<p>Małkiński and Mańdziuk, 2022] Mikołaj Małkiński and Jacek Mańdziuk. Deep learning methods for abstract visual reasoning: A survey on raven's progressive matrices. Norihiro Kamide, Kamide ; Lecun, arXiv:2201.12382Proceedings of the 14th International Conference on Agents and Artificial Intelligence, ICAART 2022. Robin Manhaeve, Sebastijan Dumancic, Angelika Kimmig, Thomas Demeester, Luc De, Raedt , the 14th International Conference on Agents and Artificial Intelligence, ICAART 2022Meyer and Stewart2022. February 3-5, 2022. 2022. 2015. 2015. 2021. 2021. 2022. 2018. 2018. 2023. 19743arXiv preprintAdvances in neural information processing systems. Matrix analysis and applied linear algebra. SIAM, 2023. [Minsky, 1974] Marvin Minsky. A framework for representing knowledge</p>
<p>Cone semantics for logics with negation. Özc ¸ep, Özgür Lütfü Özc ¸ep, Mena Leemhuis. 2020. 2020IJCAI</p>
<p>Robert Porzel and Vanja Sophie Cangalovic. What say you: An ontological representation of imperative meaning for human-robot interaction. Cangalovic Porzel, Joint Ontology Workshops. 2020. 2020</p>
<p>F-a model of events based on the foundational ontology dolce+dns ultralight. Santoro, Proceedings of the Fifth International Conference on Knowledge Capture, K-CAP '09. Ansgar Scherp, Thomas Franz, Carsten Saathoff, Steffen Staab, the Fifth International Conference on Knowledge Capture, K-CAP '09Stockholmsmässan, Stockholm, Sweden; New York, NY, USAAssociation for Computing Machinery2017. 2017. 2018. July 10-15, 2018. 2018. 200980Proceedings of the 35th International Conference on Machine Learning, ICML 2018</p>
<p>An empirical investigation of domain generalization with empirical risk minimizers. Van Krieken, arXiv:2212.12393Advances in Neural Information Processing Systems 34: Annual Conference on Neural Information Processing Systems 2021, NeurIPS 2021. Aurelio Marc, Alina Ranzato, Yann N Beygelzimer, Percy Dauphin, Jennifer Wortman Liang, Vaughan, Cambridge University Press2022. 2022. 2021. December 6-14, 2021. 2021. 2022arXiv preprintStudies in Natural Language Processing</p>
<p>Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms. Xiao , arXiv:2308.029442017. 2017arXiv preprint</p>
<p>Abstract visual reasoning: An algebraic approach for solving raven's progressive matrices. Xu, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. the IEEE/CVF Conference on Computer Vision and Pattern Recognition2023. 2023</p>
<p>RAVEN: A dataset for relational and analogical visual reasoning. Zhang, Advances in Neural Information Processing Systems 32: Annual Conference on Neural Information Processing Systems 2019. M Hanna, Hugo Wallach, Alina Larochelle, Beygelzimer, Emily B Florence D'alché-Buc, Roman Fox, Garnett, Long Beach, CA, USA; NeurIPS; BC, Canada2019a. June 16-20, 2019. 2019. 2019b. 2019. December 8-14, 2019. 2019Vancouver</p>
<p>Abstract spatial-temporal reasoning via probabilistic abduction and execution. Zhang, Advances in Neural Information Processing Systems 32: Annual Conference on Neural Information Processing Systems. M Hanna, Hugo Wallach, Alina Larochelle, Beygelzimer, Emily B Florence D'alché-Buc, Roman Fox, Garnett, NeurIPS; Vancouver, BC, CanadaComputer Vision Foundation / IEEE2021. June 19-25, 2021. 2021. 2019. 2019. 2019. December 8-14, 2019. 2019. 2022. 2022IEEE Transactions on Pattern Analysis and Machine Intelligence</p>
<p>Unsupervised abstract reasoning for raven's problem matrices. Zhou, 9th International Conference on Learning Representations, ICLR 2021, Virtual Event, Austria. 2023. 2023. May 3-7, 2021. OpenReview.net, 2021. 202145IEEE Trans. Image Process.</p>            </div>
        </div>

    </div>
</body>
</html>