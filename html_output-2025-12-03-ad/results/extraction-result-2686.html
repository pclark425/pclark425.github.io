<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-2686 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-2686</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-2686</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-68.html">extraction-schema-68</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI systems or methods that generate scientific hypotheses, evaluate hypothesis quality, validate scientific claims, detect hallucinations, or quantify uncertainty in scientific reasoning.</div>
                <p><strong>Paper ID:</strong> paper-747dff7b9cd0d6feb16c340b684b1923034e8777</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/747dff7b9cd0d6feb16c340b684b1923034e8777" target="_blank">GrEDeL: A Knowledge Graph Embedding Based Method for Drug Discovery From Biomedical Literatures</a></p>
                <p><strong>Paper Venue:</strong> IEEE Access</p>
                <p><strong>Paper TL;DR:</strong> A biomedical knowledge graph embedding-based recurrent neural network method called GrEDeL, which discovers potential drugs for diseases by mining published biomedical literature, which could be a supplementary method for the current traditional drug discovery methods.</p>
                <p><strong>Paper Abstract:</strong> Drug discovery is the process by which new candidate medications are discovered. Developing a new drug is a lengthy, complex, and expensive process. Here, in this paper, we propose a biomedical knowledge graph embedding-based recurrent neural network method called GrEDeL, which discovers potential drugs for diseases by mining published biomedical literature. GrEDeL first builds a biomedical knowledge graph by exploiting the relations extracted from biomedical abstracts. Then, the graph data are converted into a low dimensional space by leveraging the knowledge graph embedding methods. After that, a recurrent neural network model is trained by the known drug therapies which are represented by graph embeddings. Finally, it uses the learned model to discover candidate drugs for diseases of interest from biomedical literature. The experimental results show that our method could not only effectively discover new drugs by mining literature, but also could provide the corresponding mechanism of actions for the candidate drugs. It could be a supplementary method for the current traditional drug discovery methods.</p>
                <p><strong>Cost:</strong> 0.026</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e2686.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e2686.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI systems or methods that generate scientific hypotheses, evaluate hypothesis quality, validate scientific claims, detect hallucinations, or quantify uncertainty in scientific reasoning.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GrEDeL</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Graph Embedding based Deep Learning (GrEDeL)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A pipeline that constructs a semantic biomedical knowledge graph from SemRep-extracted predications, embeds the graph (Semantic Graph + Type Graph) with TransE, and trains an LSTM to score drug–target–disease sequential paths to produce literature-based drug discovery hypotheses and putative mechanisms of action.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>GrEDeL</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>End-to-end pipeline: (1) use SemRep to extract subject-relation-object predications from PubMed abstracts and build a knowledge graph that distinguishes UMLS semantic types (Semantic Graph, SG) and a Type Graph (TG); (2) train TransE embeddings separately on SG and TG to obtain dense vector representations of entities and relations; (3) represent candidate drug→...→disease paths (drug-target-disease sequences of length ≤4) as concatenations of SG and TG embeddings for each element; (4) feed the sequence of embedding vectors into an LSTM (hidden dimension tuned to 100, dropout 0.5) trained with cross-entropy loss and Adam optimizer (mini-batch size 500) via backpropagation through time; (5) score candidate drug-target-disease hypotheses using the LSTM output probability p(y|X) and aggregate path scores by taking the maximum over all paths for a candidate drug to produce a ranked set of hypotheses and an extracted mechanistic path as an explanation.</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>knowledge graph-based + deep learning (TransE + LSTM)</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>medicine/biomedical (drug discovery, pharmacology)</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_generation_method</strong></td>
                            <td>Enumerate KG paths connecting drug → target → disease (path exploration up to length 4) and score each path with an LSTM trained on positive drug-target-disease triplets (from TTD) versus negative sampled triplets; hypotheses are candidate drug–disease treatments with associated mechanistic paths.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>plausibility_assessment_method</strong></td>
                            <td>Plausibility is encouraged by: (a) filtering out paths containing broad/conceptual semantic types (e.g., 'Animal', 'Manufactured Object') to avoid non-specific chains; (b) using KG-derived semantic type features (Type Graph embeddings) so sequences follow plausible semantic type patterns; and (c) scoring with an LSTM trained on real drug-target-disease instances to prefer patterns similar to known mechanisms.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_plausibility_balance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_quality_metrics</strong></td>
                            <td>Model outputs probability p(y|X). Quality is quantified using precision, recall, F1 (cross-validation: Precision 0.881, Recall 0.971, F1 0.924), and for rediscovery ranking tasks: mean rank (27.05) and Hits@10 (33.04%). Link-prediction (TransE) evaluation reported Mean Ranks and Hits@10 for embedding quality (e.g., Hits@10 up to 29.8% with 100k triplets).</td>
                        </tr>
                        <tr>
                            <td><strong>pre_experiment_evaluation</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>validation_mechanism</strong></td>
                            <td>Computational validation: 10-fold cross-validation on constructed positive/negative path instances (balanced sets), link-prediction evaluation of TransE embeddings, and a drug rediscovery benchmark using 115 gold standard drug–disease cases from TTD with randomized candidate sets (mean rank and Hits@10 reported). Also qualitative case studies presenting predicted mechanisms; no wet-lab experimental validation reported.</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_measures</strong></td>
                            <td>Datasets and tools reported (PubMed abstracts up to 2013, SemRep, UMLS semantic network, Therapeutic Target Database); hyperparameter ranges and selected values provided (Table 7); implementation in TensorFlow and source code repository URL provided in paper (https://github.com/ShengtianSang/GrEDeL).</td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_prevention_method</strong></td>
                            <td>Indirect prevention via data-quality filters: remove predications that appear only once, filter out paths containing broad/conceptual semantic types; rely on supervised training against TTD positives to reduce spurious associations. No explicit hallucination-detection algorithm reported.</td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance_testing</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification_method</strong></td>
                            <td>Model produces a probability score p(y|X) (sigmoid of final output) as a confidence measure; dropout used during training for regularization but not explicitly used for uncertainty quantification (no Bayesian/ensemble/CI reported).</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_dataset</strong></td>
                            <td>PubMed (predications extracted by SemRep), UMLS Semantic Network (semantic types/relations), Therapeutic Target Database (TTD) used as gold-standard positives; SemKG derived from these sources used for training/testing.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Cross-validation: Precision=0.881, Recall=0.971, F1=0.924 (GrEDeL S G+T G with LSTM). Rediscovery test: Not Found=0, Mean Ranks=27.05, Hits@10=33.04%. TransE link-prediction (SG embeddings) reported Mean Ranks ranging 305→108 and Hits@10 9.4%→29.8% as dataset size increased (5k→100k triplets).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td>GrEDeL outperformed classical baselines in cross-validation: Logistic Regression (P:0.715,R:0.889,F1:0.791), Random Forest (P:0.742,R:0.750,F1:0.743), SVM (P:0.622,R:0.766,F1:0.635). In rediscovery tasks GrEDeL (Mean Rank 27.05, Hits@10 33.04%) outperformed NRWRH (Mean Rank 32.17, Hits@10 26.09%), TP-NRWRH (31.13, 27.83%), Malas (37.68, 24.34%), Bakalb (29.44, 31.30%), and SemaTyP (29.87, 30.58%).</td>
                        </tr>
                        <tr>
                            <td><strong>validated_on_real_science</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>novel_discoveries</strong></td>
                            <td>Paper reports rediscovery of known drug–disease associations and presents case-study hypotheses (candidate drugs and putative mechanisms of action) for diseases; no novel discoveries were experimentally (wet-lab or clinical) validated within the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Relies on SemRep extraction quality; KG contains false positive relations despite filtering; TransE has limitations handling 1-to-n and n-to-n relations; possible overlap in path-derived positive instances can bias cross-validation; no explicit hallucination detection or principled uncertainty quantification; no wet-lab validation reported.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2686.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e2686.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI systems or methods that generate scientific hypotheses, evaluate hypothesis quality, validate scientific claims, detect hallucinations, or quantify uncertainty in scientific reasoning.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>SemRep</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>SemRep (semantic predication extractor)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An NLP system that extracts semantic predications (subject–relation–object) from biomedical text, assigning UMLS concepts and semantic types to entities and relations; used here to build the biomedical knowledge graph from PubMed abstracts.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>The interaction of domain knowledge and linguistic structure in natural language processing: Interpreting hypernymic propositions in biomedical text</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>SemRep</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Rule- and knowledge-based natural language processing system that identifies UMLS concepts and semantic relations (predications) in biomedical free text, producing triples of the form (subject|semantic_type relation|relation_type object|semantic_type). In this work SemRep outputs predications that form the nodes/edges of the knowledge graph.</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>biomedical NLP / relation extraction</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>biomedical text mining / knowledge extraction</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_generation_method</strong></td>
                            <td>SemRep itself does not generate hypotheses; it supplies structured predications that downstream LBD systems (e.g., GrEDeL) use to assemble hypothesis paths.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>plausibility_assessment_method</strong></td>
                            <td>Provides semantic typing (UMLS semantic types) that downstream systems use to filter broad concepts and prefer semantically coherent paths.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_plausibility_balance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_quality_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>pre_experiment_evaluation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validation_mechanism</strong></td>
                            <td>SemRep has its own evaluation in prior work, but in this paper the authors filtered predications that appear only once to improve precision.</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_measures</strong></td>
                            <td>Tool is identified and referenced; semantic type annotations used are standard UMLS resources.</td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_prevention_method</strong></td>
                            <td>Filtering low-frequency predications (appearing once) to reduce noise in the KG.</td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance_testing</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_dataset</strong></td>
                            <td>Applied to PubMed abstracts (predications extracted); uses UMLS for concept/semantic typing.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validated_on_real_science</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>novel_discoveries</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>SemRep output contains false positives; downstream method performance depends on SemRep extraction quality (authors highlight this as a limitation).</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2686.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e2686.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI systems or methods that generate scientific hypotheses, evaluate hypothesis quality, validate scientific claims, detect hallucinations, or quantify uncertainty in scientific reasoning.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>TransE</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>TransE (Translating Embeddings for Modeling Multi-relational Data)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A knowledge-graph embedding method that represents entities and relations as vectors and models relations as translations in vector space (h + r ≈ t); used here to embed both the Semantic Graph and Type Graph.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Translating embeddings for modeling multi-relational data</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>TransE</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Embedding method minimizing margin-based ranking loss: for each true triple (e1,r,e2) and corrupted triple (e1',r,e2'), optimize a margin γ and distance d( e1 + r, e2 ) using L1 norm and SGD/Adam to produce dense vector representations of entities and relations. Separate embeddings trained for SG and TG; entity/relation embeddings concatenated for downstream LSTM input.</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>knowledge graph embedding</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>knowledge representation for biomedicine</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_generation_method</strong></td>
                            <td>TransE does not directly generate hypotheses; it provides dense features that enable downstream sequence models to score candidate hypotheses and perform link prediction.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>plausibility_assessment_method</strong></td>
                            <td>Embedding preserves graph structure and relation semantics, indirectly aiding plausibility via learned geometric relations.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_plausibility_balance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_quality_metrics</strong></td>
                            <td>Evaluated by link-prediction protocols: Mean Rank and Hits@10 (e.g., Hits@10 up to 29.8% on 100k triplets).</td>
                        </tr>
                        <tr>
                            <td><strong>pre_experiment_evaluation</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>validation_mechanism</strong></td>
                            <td>Standard link-prediction evaluation: corrupt tail/head, rank scores, report mean rank and Hits@10.</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_measures</strong></td>
                            <td>Embedding dimension (100), margin γ=1, training/test split protocol and evaluation described.</td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_prevention_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance_testing</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_dataset</strong></td>
                            <td>Subsets of the constructed Semantic Graph from PubMed predications (various sizes 5k–100k triplets) used for link-prediction evaluation.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Reported Mean Ranks and Hits@10 as embedding dataset size increased: (5k) Mean Rank 305 Hits@10 9.4%; (100k) Mean Rank 108 Hits@10 29.8%.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validated_on_real_science</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>novel_discoveries</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>TransE handles 1-to-1 relations well but has known weaknesses with 1-to-n and n-to-n relations; authors note this as a limitation for biomedical KG.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2686.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e2686.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI systems or methods that generate scientific hypotheses, evaluate hypothesis quality, validate scientific claims, detect hallucinations, or quantify uncertainty in scientific reasoning.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LSTM component</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Long Short-Term Memory neural network (LSTM)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An RNN architecture that models sequential dependencies using gated memory cells; used in GrEDeL to learn dependencies across entities in drug–target–disease sequential paths and to output a probability score for candidate hypotheses.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Long short-term memory</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>LSTM sequence classifier</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Single-layer LSTM that processes sequences of concatenated SG+TG embedding vectors for each path element; gates (input, forget, output) control memory c_t, and hidden state h_t used to compute final sigmoid probability via a fully connected layer; trained with cross-entropy loss, Adam optimizer, dropout on non-recurrent connections, and backpropagation through time. Hyperparameters tuned (cell dim 100, dropout 0.5).</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>recurrent neural network (LSTM)</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>applied machine learning for biomedical knowledge discovery</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_generation_method</strong></td>
                            <td>Scores KG-derived sequences to rank candidate hypotheses; the LSTM is the discriminative model that assigns plausibility probabilities to candidate paths.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>plausibility_assessment_method</strong></td>
                            <td>Learns from known positive examples (TTD) to discriminate plausible mechanistic sequences from negative/random sequences.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_plausibility_balance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_quality_metrics</strong></td>
                            <td>Output probability p(y|X); overall system metrics reported (precision, recall, F1).</td>
                        </tr>
                        <tr>
                            <td><strong>pre_experiment_evaluation</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>validation_mechanism</strong></td>
                            <td>Cross-validation and rediscovery benchmarks described above.</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_measures</strong></td>
                            <td>Hyperparameter ranges and selected values provided (Table 7); implementation details (TensorFlow 1.1.0) reported.</td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_prevention_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance_testing</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification_method</strong></td>
                            <td>Outputs probabilistic scores (sigmoid). No Bayesian LSTM or ensemble uncertainty measures described.</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_dataset</strong></td>
                            <td>Same TTD-derived training/testing path instances and KG embeddings used by GrEDeL.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>When used within GrEDeL, LSTM-based model achieved Precision 0.881, Recall 0.971, F1 0.924 (best configuration).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td>LSTM-based GrEDeL outperformed vanilla RNN and MLP variants in experiments (vanilla RNN and MLP had lower F-scores).</td>
                        </tr>
                        <tr>
                            <td><strong>validated_on_real_science</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>novel_discoveries</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>No explicit probabilistic calibration or uncertainty intervals beyond raw sigmoid scores; reliance on supervised positives may bias toward known mechanistic patterns.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2686.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e2686.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI systems or methods that generate scientific hypotheses, evaluate hypothesis quality, validate scientific claims, detect hallucinations, or quantify uncertainty in scientific reasoning.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ABC model / co-occurrence</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Swanson's ABC model and co-occurrence based Literature-Based Discovery (LBD)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Classic literature-based discovery approach that hypothesizes an A–C relationship if A→B and B→C are supported in literature (Swanson paradigm); co-occurrence methods use term co-occurrence as a proxy for relationships.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Fish oil, Raynaud's syndrome, and undiscovered public knowledge</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>ABC model / co-occurrence methods</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Unsupervised hypothesis-generation approach: identify intermediate concept(s) B that connect entities A and C via literature associations (co-occurrence or semantic predications); the combination suggests an A–C hypothesis (e.g., drug-disease link). Co-occurrence methods treat co-mention frequency as a relation; ABC provides a minimal explanation via shared B nodes.</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>literature-based discovery (unsupervised co-occurrence / rule-based)</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>biomedical literature mining</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_generation_method</strong></td>
                            <td>Generate A–C hypotheses by finding B where (A,B) and (B,C) relations/co-occurrences exist in literature corpora.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>plausibility_assessment_method</strong></td>
                            <td>Plausibility sometimes assessed by semantic types of B or manual expert review; ABC provides a simple mechanistic bridge B as an explanatory factor.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_plausibility_balance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_quality_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>pre_experiment_evaluation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validation_mechanism</strong></td>
                            <td>Historically validated via follow-up clinical studies in some cases (e.g., Swanson example), but in this paper ABC is discussed as background and its limitations (lack of logical explanation for co-occurrence) are noted.</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_measures</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_prevention_method</strong></td>
                            <td>Not intrinsic; co-occurrence methods prone to false positives because co-occurrence does not imply causal/meaningful relation.</td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance_testing</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_dataset</strong></td>
                            <td>Historical literature corpora (e.g., MEDLINE/PubMed) are used in ABC analyses.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td>Paper cites ABC/co-occurrence methods as baseline LBD approaches and discusses their limitations compared to semantic and KG-based approaches.</td>
                        </tr>
                        <tr>
                            <td><strong>validated_on_real_science</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>novel_discoveries</strong></td>
                            <td>Swanson's original discoveries (fish oil and Raynaud's) are classic examples (cited in paper), but ABC in this paper is only background.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Co-occurrence lacks logical explanation and yields many false positives; ABC paradigm limits discovery to simple 2-step bridges (A-B-C) and may miss complex multi-hop associations.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2686.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e2686.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI systems or methods that generate scientific hypotheses, evaluate hypothesis quality, validate scientific claims, detect hallucinations, or quantify uncertainty in scientific reasoning.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Malas et al. method</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Malas's semantic knowledge graph drug repurposing method</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A knowledge-graph feature–based method that predicts drug–disease associations using engineered KG features such as number of intermediate concepts, semantic category counts, and predicates connecting drug–disease pairs.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Drug repurposing using a semantic knowledge graph</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Malas et al. KG-feature model</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Extract features from KG for a candidate drug–disease pair: total number of intermediate concepts, number of distinct semantic categories among intermediates, and types of predicates linking the pair; use these features in a supervised classifier to predict association probability.</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>knowledge graph feature engineering + supervised classifier</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>biomedical drug repurposing</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_generation_method</strong></td>
                            <td>Score and rank candidate drug–disease pairs using engineered KG path features and a predictive model.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>plausibility_assessment_method</strong></td>
                            <td>Plausibility derived from interpretable KG features (e.g., semantic categories and predicates) which provide explainability for predictions.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_plausibility_balance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_quality_metrics</strong></td>
                            <td>Evaluated using rediscovery mean rank and Hits@10 (reported in paper: Mean Rank 37.68, Hits@10 24.34% on the rediscovery benchmark).</td>
                        </tr>
                        <tr>
                            <td><strong>pre_experiment_evaluation</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>validation_mechanism</strong></td>
                            <td>Rediscovery test against TTD gold standards (same benchmark used in current paper).</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_measures</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_prevention_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance_testing</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_dataset</strong></td>
                            <td>Applied to the constructed biomedical KG and evaluated on TTD rediscovery cases.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Rediscovery: Not Found=52, Mean Rank=37.68, Hits@10=24.34% (reported in Table 8 of this paper).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td>Compared against random-walk, Bakalb, SemaTyP and GrEDeL in this paper; underperformed relative to GrEDeL and some RWA variants.</td>
                        </tr>
                        <tr>
                            <td><strong>validated_on_real_science</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>novel_discoveries</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Considers only single-intermediate features and may miss complex multi-hop dependencies; missed 52 gold-standard drugs in rediscovery test.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2686.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e2686.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI systems or methods that generate scientific hypotheses, evaluate hypothesis quality, validate scientific claims, detect hallucinations, or quantify uncertainty in scientific reasoning.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Bakalb's method</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Bakalb et al. path-feature logistic regression method</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A method that enumerates simple paths connecting biomedical entities in a KG and uses these paths as features for a logistic regression model to predict treatment and causative relations.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Exploiting semantic patterns over biomedical knowledge graphs for predicting treatment and causative relations</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Bakalb path-feature LR</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Extract all simple paths (up to a certain length, e.g., ≤3) between drug and disease nodes; represent each candidate by features derived from these paths and train logistic regression to predict associations. Provides interpretable path-based explanations.</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>knowledge graph path features + logistic regression</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>biomedical relation prediction (drug–disease, causative relations)</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_generation_method</strong></td>
                            <td>Enumerate paths connecting drug and disease and score candidate pairs with a logistic regression trained on path features.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>plausibility_assessment_method</strong></td>
                            <td>Plausibility via explicit path features that serve as mechanistic explanations.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_plausibility_balance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_quality_metrics</strong></td>
                            <td>Rediscovery metrics reported in this paper: Not Found=4, Mean Rank=29.44, Hits@10=31.30%.</td>
                        </tr>
                        <tr>
                            <td><strong>pre_experiment_evaluation</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>validation_mechanism</strong></td>
                            <td>Rediscovery benchmark against TTD gold standards.</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_measures</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_prevention_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance_testing</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_dataset</strong></td>
                            <td>Constructed KG from PubMed predications; TTD rediscovery test.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Rediscovery: Not Found=4, Mean Rank=29.44, Hits@10=31.30% (Table 8).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td>Performed well among KG-based baselines but slightly worse than GrEDeL on mean rank and Hits@10.</td>
                        </tr>
                        <tr>
                            <td><strong>validated_on_real_science</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>novel_discoveries</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Considers only paths up to a limited length (≤3 in their setup) and therefore can miss longer multi-hop mechanisms; logistic regression does not model sequence order/dependencies explicitly.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2686.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e2686.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI systems or methods that generate scientific hypotheses, evaluate hypothesis quality, validate scientific claims, detect hallucinations, or quantify uncertainty in scientific reasoning.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>SemaTyP</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>SemaTyP (Sematic Type based inference method)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A knowledge-graph–based literature-mining method that scores drug–disease associations by exploiting the distribution of semantic types of entities along connecting paths to infer potential therapies.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Sematyp: A knowledge graph based literature mining method for drug discovery</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>SemaTyP</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Aggregates semantic-type distributions along paths between drug and disease in a biomedical KG and uses these distributions to score candidate drug–disease associations; emphasizes semantic-type patterns as predictors of therapeutic relationships.</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>knowledge graph semantic-type pattern method</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>biomedical literature-based discovery</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_generation_method</strong></td>
                            <td>Enumerate paths between drug and disease and compute scores based on the distribution of UMLS semantic types encountered, producing ranked hypotheses.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>plausibility_assessment_method</strong></td>
                            <td>Plausibility derived from semantic-type pattern conformity (e.g., drug-INHIBITS-protein-STIMULATES-disease is a plausible pattern).</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_plausibility_balance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_quality_metrics</strong></td>
                            <td>Rediscovery performance reported here: Not Found=0, Mean Rank=29.87, Hits@10=30.58%.</td>
                        </tr>
                        <tr>
                            <td><strong>pre_experiment_evaluation</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>validation_mechanism</strong></td>
                            <td>Rediscovery test on TTD gold standard cases.</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_measures</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_prevention_method</strong></td>
                            <td>Use of semantic-type filters and patterns to reduce implausible chains.</td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance_testing</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_dataset</strong></td>
                            <td>KG from PubMed predications and TTD for evaluation.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Rediscovery: Not Found=0, Mean Rank=29.87, Hits@10=30.58% (Table 8).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td>Beat some RWA variants; slightly worse than GrEDeL in mean rank and Hits@10.</td>
                        </tr>
                        <tr>
                            <td><strong>validated_on_real_science</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>novel_discoveries</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Relies on semantic-type distributions which may not capture detailed multi-step mechanistic dependencies or the order of entities.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2686.8">
                <h3 class="extraction-instance">Extracted Data Instance 8 (e2686.8)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI systems or methods that generate scientific hypotheses, evaluate hypothesis quality, validate scientific claims, detect hallucinations, or quantify uncertainty in scientific reasoning.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Random-walk based methods (NRWRH / TP-NRWRH / RWA)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Random Walk with Restart variants (basic RWA, NRWRH, TP-NRWRH)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Graph-based ranking methods that propagate scores through the knowledge graph starting from candidate drugs (or known nodes) using random walk processes with restart; used to score drug–disease associations for rediscovery.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Drug-target interaction prediction by random walk on the heterogeneous network</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Random-walk with restart (RWA / NRWRH / TP-NRWRH)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Start random walks at a candidate drug node and propagate probability mass across the heterogeneous KG for a specified expected number of steps; NRWRH applies random walk on a heterogeneous network incorporating semantic types; TP-NRWRH uses a two-pass random walk to improve coverage. Scores represent proximity/relatedness between drug and disease nodes and are used to rank candidates.</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>graph propagation / random-walk-based</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>biomedical network analysis / drug repurposing</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_generation_method</strong></td>
                            <td>Generate ranked hypotheses by computing reachability/proximity scores (random-walk steady-state or truncated-step scores) from candidate drugs to disease nodes.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>plausibility_assessment_method</strong></td>
                            <td>Plausibility based on graph proximity and semantic-type-aware propagation (NRWRH/TP-NRWRH incorporate semantic types).</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_plausibility_balance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_quality_metrics</strong></td>
                            <td>Rediscovery metrics reported for several step settings: example RWA_3 Mean Rank=30.33 Hits@10=23.48%; NRWRH Mean Rank=32.17 Hits@10=26.09%; TP-NRWRH Mean Rank=31.13 Hits@10=27.83%.</td>
                        </tr>
                        <tr>
                            <td><strong>pre_experiment_evaluation</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>validation_mechanism</strong></td>
                            <td>Rediscovery benchmark and ranking evaluation against TTD gold standards; 'Not Found' counts when methods cannot reach the disease within chosen steps.</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_measures</strong></td>
                            <td>Expected step counts and algorithm variants documented; baselines run following recommended settings from original papers.</td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_prevention_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance_testing</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification_method</strong></td>
                            <td>Scores are proximity probabilities or steady-state weights and serve as confidence signals; no calibrated uncertainty intervals reported.</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_dataset</strong></td>
                            <td>Constructed KG; TTD rediscovery benchmark (115 gold standard cases subset used in this paper).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Table 8 reports multiple RWA variants: RWA_1 Mean Rank=90.82 Hits@10=17.39% (Not Found=93) up to RWA_6 Mean Rank=39.14 Hits@10=11.30%; NRWRH Mean Rank=32.17 Hits@10=26.09%; TP-NRWRH Mean Rank=31.13 Hits@10=27.83%.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td>NRWRH/TP-NRWRH generally outperform simple RWA with small step counts but in this paper are outperformed by GrEDeL.</td>
                        </tr>
                        <tr>
                            <td><strong>validated_on_real_science</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>novel_discoveries</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Coverage depends on walk length; too short walks miss candidates (Not Found high), too long walks dilute scores and lower ranking; semantic information incorporation necessary for good performance (hence NRWRH/TP-NRWRH).</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2686.9">
                <h3 class="extraction-instance">Extracted Data Instance 9 (e2686.9)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI systems or methods that generate scientific hypotheses, evaluate hypothesis quality, validate scientific claims, detect hallucinations, or quantify uncertainty in scientific reasoning.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Classical ML baselines</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Logistic Regression / Random Forest / Support Vector Machine baselines</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Standard supervised classifiers that take concatenated KG embedding vectors (SG + TG embeddings) representing paths as input features and predict binary drug–disease association labels; used for comparison in cross-validation.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>LR / RF / SVM classifiers on KG embedding features</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Construct feature vectors for each path by concatenating SG and TG TransE embeddings of each entity/relation in the path; train standard classifiers (logistic regression, random forest, SVM) on positive/negative labeled path instances to predict associations.</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>classical supervised machine learning (feature-based)</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>biomedical relation prediction</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_generation_method</strong></td>
                            <td>Produce scores/probabilities for candidate paths/drug–disease pairs via classifier predictions and rank candidates accordingly.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>plausibility_assessment_method</strong></td>
                            <td>Plausibility via use of KG-derived embedding features trained on known positives.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_plausibility_balance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_quality_metrics</strong></td>
                            <td>Cross-validation metrics reported: LR P:0.715 R:0.889 F1:0.791; RF P:0.742 R:0.750 F1:0.743; SVM P:0.622 R:0.766 F1:0.635 (Table 3).</td>
                        </tr>
                        <tr>
                            <td><strong>pre_experiment_evaluation</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>validation_mechanism</strong></td>
                            <td>Ten-fold cross-validation on balanced positive/negative path instances derived from TTD and KG.</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_measures</strong></td>
                            <td>Implementations based on scikit-learn; feature construction and hyperparameter search ranges described in paper.</td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_prevention_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance_testing</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification_method</strong></td>
                            <td>Classifiers output probabilities or scores (e.g., LR probabilities, RF vote fractions), used as confidence measures; no calibrated uncertainty intervals reported.</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_dataset</strong></td>
                            <td>TTD-derived positive/negative path instances and KG embeddings from PubMed predications.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>See above cross-validation numbers.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td>These baselines were outperformed by the GrEDeL LSTM model in F1 and overall ranking performance.</td>
                        </tr>
                        <tr>
                            <td><strong>validated_on_real_science</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>novel_discoveries</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Do not model sequence order/dependencies explicitly (unlike RNN/LSTM); may require more parameters (MLP) and overfit without sequence modeling.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Sematyp: A knowledge graph based literature mining method for drug discovery <em>(Rating: 2)</em></li>
                <li>Drug repurposing using a semantic knowledge graph <em>(Rating: 2)</em></li>
                <li>Exploiting semantic patterns over biomedical knowledge graphs for predicting treatment and causative relations <em>(Rating: 2)</em></li>
                <li>Drug-target interaction prediction by random walk on the heterogeneous network <em>(Rating: 2)</em></li>
                <li>Inferring new indications for approved drugs via random walk on drug-disease heterogenous networks <em>(Rating: 2)</em></li>
                <li>Translating embeddings for modeling multi-relational data <em>(Rating: 2)</em></li>
                <li>The interaction of domain knowledge and linguistic structure in natural language processing: Interpreting hypernymic propositions in biomedical text <em>(Rating: 1)</em></li>
                <li>Fish oil, Raynaud's syndrome, and undiscovered public knowledge <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-2686",
    "paper_id": "paper-747dff7b9cd0d6feb16c340b684b1923034e8777",
    "extraction_schema_id": "extraction-schema-68",
    "extracted_data": [
        {
            "name_short": "GrEDeL",
            "name_full": "Graph Embedding based Deep Learning (GrEDeL)",
            "brief_description": "A pipeline that constructs a semantic biomedical knowledge graph from SemRep-extracted predications, embeds the graph (Semantic Graph + Type Graph) with TransE, and trains an LSTM to score drug–target–disease sequential paths to produce literature-based drug discovery hypotheses and putative mechanisms of action.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "GrEDeL",
            "system_description": "End-to-end pipeline: (1) use SemRep to extract subject-relation-object predications from PubMed abstracts and build a knowledge graph that distinguishes UMLS semantic types (Semantic Graph, SG) and a Type Graph (TG); (2) train TransE embeddings separately on SG and TG to obtain dense vector representations of entities and relations; (3) represent candidate drug→...→disease paths (drug-target-disease sequences of length ≤4) as concatenations of SG and TG embeddings for each element; (4) feed the sequence of embedding vectors into an LSTM (hidden dimension tuned to 100, dropout 0.5) trained with cross-entropy loss and Adam optimizer (mini-batch size 500) via backpropagation through time; (5) score candidate drug-target-disease hypotheses using the LSTM output probability p(y|X) and aggregate path scores by taking the maximum over all paths for a candidate drug to produce a ranked set of hypotheses and an extracted mechanistic path as an explanation.",
            "system_type": "knowledge graph-based + deep learning (TransE + LSTM)",
            "scientific_domain": "medicine/biomedical (drug discovery, pharmacology)",
            "hypothesis_generation_method": "Enumerate KG paths connecting drug → target → disease (path exploration up to length 4) and score each path with an LSTM trained on positive drug-target-disease triplets (from TTD) versus negative sampled triplets; hypotheses are candidate drug–disease treatments with associated mechanistic paths.",
            "novelty_assessment_method": null,
            "plausibility_assessment_method": "Plausibility is encouraged by: (a) filtering out paths containing broad/conceptual semantic types (e.g., 'Animal', 'Manufactured Object') to avoid non-specific chains; (b) using KG-derived semantic type features (Type Graph embeddings) so sequences follow plausible semantic type patterns; and (c) scoring with an LSTM trained on real drug-target-disease instances to prefer patterns similar to known mechanisms.",
            "novelty_plausibility_balance": null,
            "hypothesis_quality_metrics": "Model outputs probability p(y|X). Quality is quantified using precision, recall, F1 (cross-validation: Precision 0.881, Recall 0.971, F1 0.924), and for rediscovery ranking tasks: mean rank (27.05) and Hits@10 (33.04%). Link-prediction (TransE) evaluation reported Mean Ranks and Hits@10 for embedding quality (e.g., Hits@10 up to 29.8% with 100k triplets).",
            "pre_experiment_evaluation": true,
            "validation_mechanism": "Computational validation: 10-fold cross-validation on constructed positive/negative path instances (balanced sets), link-prediction evaluation of TransE embeddings, and a drug rediscovery benchmark using 115 gold standard drug–disease cases from TTD with randomized candidate sets (mean rank and Hits@10 reported). Also qualitative case studies presenting predicted mechanisms; no wet-lab experimental validation reported.",
            "reproducibility_measures": "Datasets and tools reported (PubMed abstracts up to 2013, SemRep, UMLS semantic network, Therapeutic Target Database); hyperparameter ranges and selected values provided (Table 7); implementation in TensorFlow and source code repository URL provided in paper (https://github.com/ShengtianSang/GrEDeL).",
            "hallucination_prevention_method": "Indirect prevention via data-quality filters: remove predications that appear only once, filter out paths containing broad/conceptual semantic types; rely on supervised training against TTD positives to reduce spurious associations. No explicit hallucination-detection algorithm reported.",
            "hallucination_detection_method": null,
            "hallucination_rate": null,
            "statistical_significance_testing": null,
            "uncertainty_quantification_method": "Model produces a probability score p(y|X) (sigmoid of final output) as a confidence measure; dropout used during training for regularization but not explicitly used for uncertainty quantification (no Bayesian/ensemble/CI reported).",
            "benchmark_dataset": "PubMed (predications extracted by SemRep), UMLS Semantic Network (semantic types/relations), Therapeutic Target Database (TTD) used as gold-standard positives; SemKG derived from these sources used for training/testing.",
            "performance_metrics": "Cross-validation: Precision=0.881, Recall=0.971, F1=0.924 (GrEDeL S G+T G with LSTM). Rediscovery test: Not Found=0, Mean Ranks=27.05, Hits@10=33.04%. TransE link-prediction (SG embeddings) reported Mean Ranks ranging 305→108 and Hits@10 9.4%→29.8% as dataset size increased (5k→100k triplets).",
            "comparison_with_baseline": "GrEDeL outperformed classical baselines in cross-validation: Logistic Regression (P:0.715,R:0.889,F1:0.791), Random Forest (P:0.742,R:0.750,F1:0.743), SVM (P:0.622,R:0.766,F1:0.635). In rediscovery tasks GrEDeL (Mean Rank 27.05, Hits@10 33.04%) outperformed NRWRH (Mean Rank 32.17, Hits@10 26.09%), TP-NRWRH (31.13, 27.83%), Malas (37.68, 24.34%), Bakalb (29.44, 31.30%), and SemaTyP (29.87, 30.58%).",
            "validated_on_real_science": true,
            "novel_discoveries": "Paper reports rediscovery of known drug–disease associations and presents case-study hypotheses (candidate drugs and putative mechanisms of action) for diseases; no novel discoveries were experimentally (wet-lab or clinical) validated within the paper.",
            "limitations": "Relies on SemRep extraction quality; KG contains false positive relations despite filtering; TransE has limitations handling 1-to-n and n-to-n relations; possible overlap in path-derived positive instances can bias cross-validation; no explicit hallucination detection or principled uncertainty quantification; no wet-lab validation reported.",
            "uuid": "e2686.0"
        },
        {
            "name_short": "SemRep",
            "name_full": "SemRep (semantic predication extractor)",
            "brief_description": "An NLP system that extracts semantic predications (subject–relation–object) from biomedical text, assigning UMLS concepts and semantic types to entities and relations; used here to build the biomedical knowledge graph from PubMed abstracts.",
            "citation_title": "The interaction of domain knowledge and linguistic structure in natural language processing: Interpreting hypernymic propositions in biomedical text",
            "mention_or_use": "use",
            "system_name": "SemRep",
            "system_description": "Rule- and knowledge-based natural language processing system that identifies UMLS concepts and semantic relations (predications) in biomedical free text, producing triples of the form (subject|semantic_type relation|relation_type object|semantic_type). In this work SemRep outputs predications that form the nodes/edges of the knowledge graph.",
            "system_type": "biomedical NLP / relation extraction",
            "scientific_domain": "biomedical text mining / knowledge extraction",
            "hypothesis_generation_method": "SemRep itself does not generate hypotheses; it supplies structured predications that downstream LBD systems (e.g., GrEDeL) use to assemble hypothesis paths.",
            "novelty_assessment_method": null,
            "plausibility_assessment_method": "Provides semantic typing (UMLS semantic types) that downstream systems use to filter broad concepts and prefer semantically coherent paths.",
            "novelty_plausibility_balance": null,
            "hypothesis_quality_metrics": null,
            "pre_experiment_evaluation": null,
            "validation_mechanism": "SemRep has its own evaluation in prior work, but in this paper the authors filtered predications that appear only once to improve precision.",
            "reproducibility_measures": "Tool is identified and referenced; semantic type annotations used are standard UMLS resources.",
            "hallucination_prevention_method": "Filtering low-frequency predications (appearing once) to reduce noise in the KG.",
            "hallucination_detection_method": null,
            "hallucination_rate": null,
            "statistical_significance_testing": null,
            "uncertainty_quantification_method": null,
            "benchmark_dataset": "Applied to PubMed abstracts (predications extracted); uses UMLS for concept/semantic typing.",
            "performance_metrics": null,
            "comparison_with_baseline": null,
            "validated_on_real_science": true,
            "novel_discoveries": null,
            "limitations": "SemRep output contains false positives; downstream method performance depends on SemRep extraction quality (authors highlight this as a limitation).",
            "uuid": "e2686.1"
        },
        {
            "name_short": "TransE",
            "name_full": "TransE (Translating Embeddings for Modeling Multi-relational Data)",
            "brief_description": "A knowledge-graph embedding method that represents entities and relations as vectors and models relations as translations in vector space (h + r ≈ t); used here to embed both the Semantic Graph and Type Graph.",
            "citation_title": "Translating embeddings for modeling multi-relational data",
            "mention_or_use": "use",
            "system_name": "TransE",
            "system_description": "Embedding method minimizing margin-based ranking loss: for each true triple (e1,r,e2) and corrupted triple (e1',r,e2'), optimize a margin γ and distance d( e1 + r, e2 ) using L1 norm and SGD/Adam to produce dense vector representations of entities and relations. Separate embeddings trained for SG and TG; entity/relation embeddings concatenated for downstream LSTM input.",
            "system_type": "knowledge graph embedding",
            "scientific_domain": "knowledge representation for biomedicine",
            "hypothesis_generation_method": "TransE does not directly generate hypotheses; it provides dense features that enable downstream sequence models to score candidate hypotheses and perform link prediction.",
            "novelty_assessment_method": null,
            "plausibility_assessment_method": "Embedding preserves graph structure and relation semantics, indirectly aiding plausibility via learned geometric relations.",
            "novelty_plausibility_balance": null,
            "hypothesis_quality_metrics": "Evaluated by link-prediction protocols: Mean Rank and Hits@10 (e.g., Hits@10 up to 29.8% on 100k triplets).",
            "pre_experiment_evaluation": true,
            "validation_mechanism": "Standard link-prediction evaluation: corrupt tail/head, rank scores, report mean rank and Hits@10.",
            "reproducibility_measures": "Embedding dimension (100), margin γ=1, training/test split protocol and evaluation described.",
            "hallucination_prevention_method": null,
            "hallucination_detection_method": null,
            "hallucination_rate": null,
            "statistical_significance_testing": null,
            "uncertainty_quantification_method": null,
            "benchmark_dataset": "Subsets of the constructed Semantic Graph from PubMed predications (various sizes 5k–100k triplets) used for link-prediction evaluation.",
            "performance_metrics": "Reported Mean Ranks and Hits@10 as embedding dataset size increased: (5k) Mean Rank 305 Hits@10 9.4%; (100k) Mean Rank 108 Hits@10 29.8%.",
            "comparison_with_baseline": null,
            "validated_on_real_science": true,
            "novel_discoveries": null,
            "limitations": "TransE handles 1-to-1 relations well but has known weaknesses with 1-to-n and n-to-n relations; authors note this as a limitation for biomedical KG.",
            "uuid": "e2686.2"
        },
        {
            "name_short": "LSTM component",
            "name_full": "Long Short-Term Memory neural network (LSTM)",
            "brief_description": "An RNN architecture that models sequential dependencies using gated memory cells; used in GrEDeL to learn dependencies across entities in drug–target–disease sequential paths and to output a probability score for candidate hypotheses.",
            "citation_title": "Long short-term memory",
            "mention_or_use": "use",
            "system_name": "LSTM sequence classifier",
            "system_description": "Single-layer LSTM that processes sequences of concatenated SG+TG embedding vectors for each path element; gates (input, forget, output) control memory c_t, and hidden state h_t used to compute final sigmoid probability via a fully connected layer; trained with cross-entropy loss, Adam optimizer, dropout on non-recurrent connections, and backpropagation through time. Hyperparameters tuned (cell dim 100, dropout 0.5).",
            "system_type": "recurrent neural network (LSTM)",
            "scientific_domain": "applied machine learning for biomedical knowledge discovery",
            "hypothesis_generation_method": "Scores KG-derived sequences to rank candidate hypotheses; the LSTM is the discriminative model that assigns plausibility probabilities to candidate paths.",
            "novelty_assessment_method": null,
            "plausibility_assessment_method": "Learns from known positive examples (TTD) to discriminate plausible mechanistic sequences from negative/random sequences.",
            "novelty_plausibility_balance": null,
            "hypothesis_quality_metrics": "Output probability p(y|X); overall system metrics reported (precision, recall, F1).",
            "pre_experiment_evaluation": true,
            "validation_mechanism": "Cross-validation and rediscovery benchmarks described above.",
            "reproducibility_measures": "Hyperparameter ranges and selected values provided (Table 7); implementation details (TensorFlow 1.1.0) reported.",
            "hallucination_prevention_method": null,
            "hallucination_detection_method": null,
            "hallucination_rate": null,
            "statistical_significance_testing": null,
            "uncertainty_quantification_method": "Outputs probabilistic scores (sigmoid). No Bayesian LSTM or ensemble uncertainty measures described.",
            "benchmark_dataset": "Same TTD-derived training/testing path instances and KG embeddings used by GrEDeL.",
            "performance_metrics": "When used within GrEDeL, LSTM-based model achieved Precision 0.881, Recall 0.971, F1 0.924 (best configuration).",
            "comparison_with_baseline": "LSTM-based GrEDeL outperformed vanilla RNN and MLP variants in experiments (vanilla RNN and MLP had lower F-scores).",
            "validated_on_real_science": true,
            "novel_discoveries": null,
            "limitations": "No explicit probabilistic calibration or uncertainty intervals beyond raw sigmoid scores; reliance on supervised positives may bias toward known mechanistic patterns.",
            "uuid": "e2686.3"
        },
        {
            "name_short": "ABC model / co-occurrence",
            "name_full": "Swanson's ABC model and co-occurrence based Literature-Based Discovery (LBD)",
            "brief_description": "Classic literature-based discovery approach that hypothesizes an A–C relationship if A→B and B→C are supported in literature (Swanson paradigm); co-occurrence methods use term co-occurrence as a proxy for relationships.",
            "citation_title": "Fish oil, Raynaud's syndrome, and undiscovered public knowledge",
            "mention_or_use": "mention",
            "system_name": "ABC model / co-occurrence methods",
            "system_description": "Unsupervised hypothesis-generation approach: identify intermediate concept(s) B that connect entities A and C via literature associations (co-occurrence or semantic predications); the combination suggests an A–C hypothesis (e.g., drug-disease link). Co-occurrence methods treat co-mention frequency as a relation; ABC provides a minimal explanation via shared B nodes.",
            "system_type": "literature-based discovery (unsupervised co-occurrence / rule-based)",
            "scientific_domain": "biomedical literature mining",
            "hypothesis_generation_method": "Generate A–C hypotheses by finding B where (A,B) and (B,C) relations/co-occurrences exist in literature corpora.",
            "novelty_assessment_method": null,
            "plausibility_assessment_method": "Plausibility sometimes assessed by semantic types of B or manual expert review; ABC provides a simple mechanistic bridge B as an explanatory factor.",
            "novelty_plausibility_balance": null,
            "hypothesis_quality_metrics": null,
            "pre_experiment_evaluation": null,
            "validation_mechanism": "Historically validated via follow-up clinical studies in some cases (e.g., Swanson example), but in this paper ABC is discussed as background and its limitations (lack of logical explanation for co-occurrence) are noted.",
            "reproducibility_measures": null,
            "hallucination_prevention_method": "Not intrinsic; co-occurrence methods prone to false positives because co-occurrence does not imply causal/meaningful relation.",
            "hallucination_detection_method": null,
            "hallucination_rate": null,
            "statistical_significance_testing": null,
            "uncertainty_quantification_method": null,
            "benchmark_dataset": "Historical literature corpora (e.g., MEDLINE/PubMed) are used in ABC analyses.",
            "performance_metrics": null,
            "comparison_with_baseline": "Paper cites ABC/co-occurrence methods as baseline LBD approaches and discusses their limitations compared to semantic and KG-based approaches.",
            "validated_on_real_science": true,
            "novel_discoveries": "Swanson's original discoveries (fish oil and Raynaud's) are classic examples (cited in paper), but ABC in this paper is only background.",
            "limitations": "Co-occurrence lacks logical explanation and yields many false positives; ABC paradigm limits discovery to simple 2-step bridges (A-B-C) and may miss complex multi-hop associations.",
            "uuid": "e2686.4"
        },
        {
            "name_short": "Malas et al. method",
            "name_full": "Malas's semantic knowledge graph drug repurposing method",
            "brief_description": "A knowledge-graph feature–based method that predicts drug–disease associations using engineered KG features such as number of intermediate concepts, semantic category counts, and predicates connecting drug–disease pairs.",
            "citation_title": "Drug repurposing using a semantic knowledge graph",
            "mention_or_use": "use",
            "system_name": "Malas et al. KG-feature model",
            "system_description": "Extract features from KG for a candidate drug–disease pair: total number of intermediate concepts, number of distinct semantic categories among intermediates, and types of predicates linking the pair; use these features in a supervised classifier to predict association probability.",
            "system_type": "knowledge graph feature engineering + supervised classifier",
            "scientific_domain": "biomedical drug repurposing",
            "hypothesis_generation_method": "Score and rank candidate drug–disease pairs using engineered KG path features and a predictive model.",
            "novelty_assessment_method": null,
            "plausibility_assessment_method": "Plausibility derived from interpretable KG features (e.g., semantic categories and predicates) which provide explainability for predictions.",
            "novelty_plausibility_balance": null,
            "hypothesis_quality_metrics": "Evaluated using rediscovery mean rank and Hits@10 (reported in paper: Mean Rank 37.68, Hits@10 24.34% on the rediscovery benchmark).",
            "pre_experiment_evaluation": true,
            "validation_mechanism": "Rediscovery test against TTD gold standards (same benchmark used in current paper).",
            "reproducibility_measures": null,
            "hallucination_prevention_method": null,
            "hallucination_detection_method": null,
            "hallucination_rate": null,
            "statistical_significance_testing": null,
            "uncertainty_quantification_method": null,
            "benchmark_dataset": "Applied to the constructed biomedical KG and evaluated on TTD rediscovery cases.",
            "performance_metrics": "Rediscovery: Not Found=52, Mean Rank=37.68, Hits@10=24.34% (reported in Table 8 of this paper).",
            "comparison_with_baseline": "Compared against random-walk, Bakalb, SemaTyP and GrEDeL in this paper; underperformed relative to GrEDeL and some RWA variants.",
            "validated_on_real_science": true,
            "novel_discoveries": null,
            "limitations": "Considers only single-intermediate features and may miss complex multi-hop dependencies; missed 52 gold-standard drugs in rediscovery test.",
            "uuid": "e2686.5"
        },
        {
            "name_short": "Bakalb's method",
            "name_full": "Bakalb et al. path-feature logistic regression method",
            "brief_description": "A method that enumerates simple paths connecting biomedical entities in a KG and uses these paths as features for a logistic regression model to predict treatment and causative relations.",
            "citation_title": "Exploiting semantic patterns over biomedical knowledge graphs for predicting treatment and causative relations",
            "mention_or_use": "use",
            "system_name": "Bakalb path-feature LR",
            "system_description": "Extract all simple paths (up to a certain length, e.g., ≤3) between drug and disease nodes; represent each candidate by features derived from these paths and train logistic regression to predict associations. Provides interpretable path-based explanations.",
            "system_type": "knowledge graph path features + logistic regression",
            "scientific_domain": "biomedical relation prediction (drug–disease, causative relations)",
            "hypothesis_generation_method": "Enumerate paths connecting drug and disease and score candidate pairs with a logistic regression trained on path features.",
            "novelty_assessment_method": null,
            "plausibility_assessment_method": "Plausibility via explicit path features that serve as mechanistic explanations.",
            "novelty_plausibility_balance": null,
            "hypothesis_quality_metrics": "Rediscovery metrics reported in this paper: Not Found=4, Mean Rank=29.44, Hits@10=31.30%.",
            "pre_experiment_evaluation": true,
            "validation_mechanism": "Rediscovery benchmark against TTD gold standards.",
            "reproducibility_measures": null,
            "hallucination_prevention_method": null,
            "hallucination_detection_method": null,
            "hallucination_rate": null,
            "statistical_significance_testing": null,
            "uncertainty_quantification_method": null,
            "benchmark_dataset": "Constructed KG from PubMed predications; TTD rediscovery test.",
            "performance_metrics": "Rediscovery: Not Found=4, Mean Rank=29.44, Hits@10=31.30% (Table 8).",
            "comparison_with_baseline": "Performed well among KG-based baselines but slightly worse than GrEDeL on mean rank and Hits@10.",
            "validated_on_real_science": true,
            "novel_discoveries": null,
            "limitations": "Considers only paths up to a limited length (≤3 in their setup) and therefore can miss longer multi-hop mechanisms; logistic regression does not model sequence order/dependencies explicitly.",
            "uuid": "e2686.6"
        },
        {
            "name_short": "SemaTyP",
            "name_full": "SemaTyP (Sematic Type based inference method)",
            "brief_description": "A knowledge-graph–based literature-mining method that scores drug–disease associations by exploiting the distribution of semantic types of entities along connecting paths to infer potential therapies.",
            "citation_title": "Sematyp: A knowledge graph based literature mining method for drug discovery",
            "mention_or_use": "use",
            "system_name": "SemaTyP",
            "system_description": "Aggregates semantic-type distributions along paths between drug and disease in a biomedical KG and uses these distributions to score candidate drug–disease associations; emphasizes semantic-type patterns as predictors of therapeutic relationships.",
            "system_type": "knowledge graph semantic-type pattern method",
            "scientific_domain": "biomedical literature-based discovery",
            "hypothesis_generation_method": "Enumerate paths between drug and disease and compute scores based on the distribution of UMLS semantic types encountered, producing ranked hypotheses.",
            "novelty_assessment_method": null,
            "plausibility_assessment_method": "Plausibility derived from semantic-type pattern conformity (e.g., drug-INHIBITS-protein-STIMULATES-disease is a plausible pattern).",
            "novelty_plausibility_balance": null,
            "hypothesis_quality_metrics": "Rediscovery performance reported here: Not Found=0, Mean Rank=29.87, Hits@10=30.58%.",
            "pre_experiment_evaluation": true,
            "validation_mechanism": "Rediscovery test on TTD gold standard cases.",
            "reproducibility_measures": null,
            "hallucination_prevention_method": "Use of semantic-type filters and patterns to reduce implausible chains.",
            "hallucination_detection_method": null,
            "hallucination_rate": null,
            "statistical_significance_testing": null,
            "uncertainty_quantification_method": null,
            "benchmark_dataset": "KG from PubMed predications and TTD for evaluation.",
            "performance_metrics": "Rediscovery: Not Found=0, Mean Rank=29.87, Hits@10=30.58% (Table 8).",
            "comparison_with_baseline": "Beat some RWA variants; slightly worse than GrEDeL in mean rank and Hits@10.",
            "validated_on_real_science": true,
            "novel_discoveries": null,
            "limitations": "Relies on semantic-type distributions which may not capture detailed multi-step mechanistic dependencies or the order of entities.",
            "uuid": "e2686.7"
        },
        {
            "name_short": "Random-walk based methods (NRWRH / TP-NRWRH / RWA)",
            "name_full": "Random Walk with Restart variants (basic RWA, NRWRH, TP-NRWRH)",
            "brief_description": "Graph-based ranking methods that propagate scores through the knowledge graph starting from candidate drugs (or known nodes) using random walk processes with restart; used to score drug–disease associations for rediscovery.",
            "citation_title": "Drug-target interaction prediction by random walk on the heterogeneous network",
            "mention_or_use": "use",
            "system_name": "Random-walk with restart (RWA / NRWRH / TP-NRWRH)",
            "system_description": "Start random walks at a candidate drug node and propagate probability mass across the heterogeneous KG for a specified expected number of steps; NRWRH applies random walk on a heterogeneous network incorporating semantic types; TP-NRWRH uses a two-pass random walk to improve coverage. Scores represent proximity/relatedness between drug and disease nodes and are used to rank candidates.",
            "system_type": "graph propagation / random-walk-based",
            "scientific_domain": "biomedical network analysis / drug repurposing",
            "hypothesis_generation_method": "Generate ranked hypotheses by computing reachability/proximity scores (random-walk steady-state or truncated-step scores) from candidate drugs to disease nodes.",
            "novelty_assessment_method": null,
            "plausibility_assessment_method": "Plausibility based on graph proximity and semantic-type-aware propagation (NRWRH/TP-NRWRH incorporate semantic types).",
            "novelty_plausibility_balance": null,
            "hypothesis_quality_metrics": "Rediscovery metrics reported for several step settings: example RWA_3 Mean Rank=30.33 Hits@10=23.48%; NRWRH Mean Rank=32.17 Hits@10=26.09%; TP-NRWRH Mean Rank=31.13 Hits@10=27.83%.",
            "pre_experiment_evaluation": true,
            "validation_mechanism": "Rediscovery benchmark and ranking evaluation against TTD gold standards; 'Not Found' counts when methods cannot reach the disease within chosen steps.",
            "reproducibility_measures": "Expected step counts and algorithm variants documented; baselines run following recommended settings from original papers.",
            "hallucination_prevention_method": null,
            "hallucination_detection_method": null,
            "hallucination_rate": null,
            "statistical_significance_testing": null,
            "uncertainty_quantification_method": "Scores are proximity probabilities or steady-state weights and serve as confidence signals; no calibrated uncertainty intervals reported.",
            "benchmark_dataset": "Constructed KG; TTD rediscovery benchmark (115 gold standard cases subset used in this paper).",
            "performance_metrics": "Table 8 reports multiple RWA variants: RWA_1 Mean Rank=90.82 Hits@10=17.39% (Not Found=93) up to RWA_6 Mean Rank=39.14 Hits@10=11.30%; NRWRH Mean Rank=32.17 Hits@10=26.09%; TP-NRWRH Mean Rank=31.13 Hits@10=27.83%.",
            "comparison_with_baseline": "NRWRH/TP-NRWRH generally outperform simple RWA with small step counts but in this paper are outperformed by GrEDeL.",
            "validated_on_real_science": true,
            "novel_discoveries": null,
            "limitations": "Coverage depends on walk length; too short walks miss candidates (Not Found high), too long walks dilute scores and lower ranking; semantic information incorporation necessary for good performance (hence NRWRH/TP-NRWRH).",
            "uuid": "e2686.8"
        },
        {
            "name_short": "Classical ML baselines",
            "name_full": "Logistic Regression / Random Forest / Support Vector Machine baselines",
            "brief_description": "Standard supervised classifiers that take concatenated KG embedding vectors (SG + TG embeddings) representing paths as input features and predict binary drug–disease association labels; used for comparison in cross-validation.",
            "citation_title": "",
            "mention_or_use": "use",
            "system_name": "LR / RF / SVM classifiers on KG embedding features",
            "system_description": "Construct feature vectors for each path by concatenating SG and TG TransE embeddings of each entity/relation in the path; train standard classifiers (logistic regression, random forest, SVM) on positive/negative labeled path instances to predict associations.",
            "system_type": "classical supervised machine learning (feature-based)",
            "scientific_domain": "biomedical relation prediction",
            "hypothesis_generation_method": "Produce scores/probabilities for candidate paths/drug–disease pairs via classifier predictions and rank candidates accordingly.",
            "novelty_assessment_method": null,
            "plausibility_assessment_method": "Plausibility via use of KG-derived embedding features trained on known positives.",
            "novelty_plausibility_balance": null,
            "hypothesis_quality_metrics": "Cross-validation metrics reported: LR P:0.715 R:0.889 F1:0.791; RF P:0.742 R:0.750 F1:0.743; SVM P:0.622 R:0.766 F1:0.635 (Table 3).",
            "pre_experiment_evaluation": true,
            "validation_mechanism": "Ten-fold cross-validation on balanced positive/negative path instances derived from TTD and KG.",
            "reproducibility_measures": "Implementations based on scikit-learn; feature construction and hyperparameter search ranges described in paper.",
            "hallucination_prevention_method": null,
            "hallucination_detection_method": null,
            "hallucination_rate": null,
            "statistical_significance_testing": null,
            "uncertainty_quantification_method": "Classifiers output probabilities or scores (e.g., LR probabilities, RF vote fractions), used as confidence measures; no calibrated uncertainty intervals reported.",
            "benchmark_dataset": "TTD-derived positive/negative path instances and KG embeddings from PubMed predications.",
            "performance_metrics": "See above cross-validation numbers.",
            "comparison_with_baseline": "These baselines were outperformed by the GrEDeL LSTM model in F1 and overall ranking performance.",
            "validated_on_real_science": true,
            "novel_discoveries": null,
            "limitations": "Do not model sequence order/dependencies explicitly (unlike RNN/LSTM); may require more parameters (MLP) and overfit without sequence modeling.",
            "uuid": "e2686.9"
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Sematyp: A knowledge graph based literature mining method for drug discovery",
            "rating": 2
        },
        {
            "paper_title": "Drug repurposing using a semantic knowledge graph",
            "rating": 2
        },
        {
            "paper_title": "Exploiting semantic patterns over biomedical knowledge graphs for predicting treatment and causative relations",
            "rating": 2
        },
        {
            "paper_title": "Drug-target interaction prediction by random walk on the heterogeneous network",
            "rating": 2
        },
        {
            "paper_title": "Inferring new indications for approved drugs via random walk on drug-disease heterogenous networks",
            "rating": 2
        },
        {
            "paper_title": "Translating embeddings for modeling multi-relational data",
            "rating": 2
        },
        {
            "paper_title": "The interaction of domain knowledge and linguistic structure in natural language processing: Interpreting hypernymic propositions in biomedical text",
            "rating": 1
        },
        {
            "paper_title": "Fish oil, Raynaud's syndrome, and undiscovered public knowledge",
            "rating": 1
        }
    ],
    "cost": 0.02593925,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>GrEDeL: A Knowledge Graph Embedding Based Method for Drug Discovery From Biomedical Literatures</h1>
<p>SHENGTIAN SANG ${ }^{\ominus 1}$, ZHIHAO YANG ${ }^{\ominus 1}$, XIAOXIA LIU ${ }^{1}$, LEI WANG ${ }^{2}$, HONGFEI LIN ${ }^{\ominus 1}$, JIAN WANG ${ }^{1}$, AND MICHEL DUMONTIER ${ }^{3}$<br>${ }^{1}$ College of Computer Science and Technology, Dalian University of Technology, Dalian 116023, China<br>${ }^{2}$ Beijing Institute of Health Administration and Medical Information, Beijing 100191, China<br>${ }^{3}$ Institute of Data Science, Maastricht University, 6229 ER Maastricht, The Netherlands<br>Corresponding authors: Zhihao Yang (yangzh@dlut.edu.cn) and Lei Wang (wangleibihami@gmail.com)</p>
<p>This work was supported in part by the National Key Research and Development Program of China under Grant 2016YFC0901902, in part by the Natural Science Foundation of China under Grant 61272373, Grant 61572102, and Grant 61572098, and in part by the Trans-Century Training Program Foundation for the Talents by the Ministry of Education of China under Grant NCET-13-0084.</p>
<h4>Abstract</h4>
<p>Drug discovery is the process by which new candidate medications are discovered. Developing a new drug is a lengthy, complex, and expensive process. Here, in this paper, we propose a biomedical knowledge graph embedding-based recurrent neural network method called GrEDeL, which discovers potential drugs for diseases by mining published biomedical literature. GrEDeL first builds a biomedical knowledge graph by exploiting the relations extracted from biomedical abstracts. Then, the graph data are converted into a low dimensional space by leveraging the knowledge graph embedding methods. After that, a recurrent neural network model is trained by the known drug therapies which are represented by graph embeddings. Finally, it uses the learned model to discover candidate drugs for diseases of interest from biomedical literature. The experimental results show that our method could not only effectively discover new drugs by mining literature, but also could provide the corresponding mechanism of actions for the candidate drugs. It could be a supplementary method for the current traditional drug discovery methods.</p>
<p>INDEX TERMS Drug discovery, biomedical knowledge graph, recurrent neural network, deep learning.</p>
<h2>I. INTRODUCTION</h2>
<p>Drug discovery is defined as the process whereby a drug candidate or lead compound is identified and partially validated for the treatment of a specific disease [1]. It is a lengthy and expensive process, which is estimated to take 14 years and cost approximately $\$ 1.8$ billion for developing one drug [2]. In contrast, literature based discovery (LBD) is a much less time-consuming and expensive approach to identify new drugs for indications [3]. It has been successfully applied in the field of biomedicine [4]. The LBD was pioneered by Don R. Swanson (1924-2012) who found dietary fish oils (A) might be used to treat Raynaud's disease (C) based on their shared connections to blood viscosity (B) in literature [5]. This hypothesis was clinically confirmed by DiGiacomo et al. two years later [6]. Swanson's method is called the ABC model which hypothesizes the combination of two separately published premises "A implies B" and "B implies C" indicates a relationship between A and C. Since
then, a series of automatic ABC model based methods have been introduced to discover drugs from literature [7]-[9]. Cooccurrence methods are the basic ABC model based literature mining techniques which directly use co-occurrences in text as relationships between terms [9]. Directly using co-occurrences could capture all possible relations in text. However, the main issue of co-occurrence methods is that the extracted relationships lack logical explanations [10]. Furthermore, some extracted pairs of entities with high cooccurrence frequency could be completely uncorrelated actually [11]. In order to solve the problem, many sophisticated semantic models have been developed, which employ natural language processing methods to determine what constitutes a relationship [12], [13]. In addition, Hristovski et al. [14] introduced discovery patterns which serve as an effective filtering method that reduces the number of false positive discoveries and also supports explanation of discoveries. Although semantic models increase the precision of linking,</p>
<p>the major limitation of above semantic models is that more complex associations will go undetected due to semantic models are restricted to the ABC paradigm [3]. More recently, a series of literature mining methods have utilized knowledge graph to discover complex associations. Cameron et al. [15] introduced an automatic subgraph model which first clusters semantic paths in a semantic graph and then elucidates the latent associations between biomedical entities by the corresponding clusters. Malas et al. [16] leverage knowledge graph features such as the total number of intermediate concepts, the number of different semantic categories, and the predicates connecting a drug-disease pair to predict novel drug-disease associations. Bakalb and Talari [17] exploit simple paths connecting biomedical entities as features of logistic regression model to discover drugs. In our previous work, we introduced a biomedical knowledge graph based inference method - SemaTyP - which exploits the distribution of semantic types of entities to discover drug therapies [18]. The limitations of above knowledge graph based methods are: Cameron's method is mainly used to explain the associations between drug and disease, rather than discover new drugs. Malas' method can not find complex associations between drugs and diseases. Bakalb's method and SemaTyP can not capture the dependencies of entities in the drug-targetdisease associations due to the logistic regression model does not consider the order of entities in the associations. In addition, the two methods can not provide the detailed drug mechanism of action. Besides the above methods, recently, significant amount of research attentions have been drawn to leverage various deep learning based approaches in the field of drug discovery [19]-[21]. However, these methods focus on identifying interactions between known drugs and targets from existing biomedical databases without considering the known knowledge contained in the huge amount of biomedical literature. In conclusion, although literaturebased discovery is a powerful paradigm with potential to complement traditional drug discovery methods, there is still considerable room for improvement in mining literature for new drug therapies.</p>
<p>In this paper, we propose a biomedical knowledge Graph Embedding based Deep Learning method - GrEDeL - to discover potential drugs from literature. Firstly, a biomedical knowledge graph was constructed with the relations extracted from PubMed abstracts. Compared with our previous work [18], the biomedical knowledge graph constructed in this work differentiates semantic types of entities. Secondly, we proposed to use the knowledge graph embedding method to convert the knowledge graph into low dimensional vector space. The embeddings of entities and relations could not only preserve the structures of the knowledge graph but also capture the semantic information of entities and relations. After that a Long Short-Term Memory Networks (LSTM) model was trained by known drug therapies from Therapeutic Target Database. Finally, the trained model was used to discover potential drugs from literature. The experimental results show that our method could not only discover
drugs for diseases of interest, but also could provide corresponding potential mechanism of actions for the candidate drugs.</p>
<p>Our contributions are two-fold:</p>
<ul>
<li>We are the first to consider the process of literaturebased discovery as a series analysis problem.</li>
<li>We propose a knowledge graph based deep learning framework for LBD. To the best of our knowledge, this is the first method that employs deep learning method combined with knowledge graph for drug discovery. Additionally, we demonstrate the usefulness of graph embedding-based features for predicting potential drugdisease associations.
The rest of this paper is organized as follows. Section II introduces the related data and tools used in our work. In Section III, we present the details of the proposed method. Subsequently, we describe different evaluation metrics used in this paper and the experimental results in Section IV. Section V is the discussion part and Section VI presents our conclusion.</li>
</ul>
<h2>II. RELATED MATERIALS</h2>
<h2>A. DATABASE</h2>
<p>1) PubMed DATABASE</p>
<p>PubMed comprises citations for biomedical literature from MEDLINE and life science journals. Currently, PubMed contains over 26 million biomedical abstracts, which represents an enormous corpus that could be used for drug discovery [3]. The knowledge graph used in this work was constructed with the relations extracted from the PubMed abstracts.</p>
<h2>2) UMLS SEMANTIC NETWORK</h2>
<p>The Unified Medical Language System (UMLS) semantic network consists of 133 semantic types that provide a consistent categorization of all concepts represented in the UMLS Metathesaurus, and 54 semantic relations that exist between semantic types [22], [23].</p>
<h2>3) THERAPEUTIC TARGET DATABASE</h2>
<p>Therapeutic Target Database (TTD) is a database which provides information about the known and explored therapeutic protein and nucleic acid targets, the targeted disease, pathway information and the corresponding drugs directed at each of these targets [24]. In this work, we constructed the training and test data sets by utilizing the drug-disease associations in TTD.</p>
<h2>B. RELATED TOOLS AND TECHNIQUES</h2>
<p>1) SemRep</p>
<p>SemRep is a program that extracts semantic predications from biomedical free text [25]. Predications consist of a subject argument, an object argument, and the relation that binds them. For example, from the sentence "Hydrocortisone increased slow wave sleep activity.", SemRep extracts a predication:</p>
<ul>
<li>Hydrocortisone|phsu increase|AUGMENTS Sleep, Slow-Wave|phsu</li>
</ul>
<p>SemRep assigns a UMLS semantic type to the entity and relation (the black bold abbreviation on the right of ' $\mid$ '). For example, 'phsu' represents 'Pharmacologic Substance'. In this paper, the abbreviations are used to represent UMLS semantic types.</p>
<h2>2) KNOWLEDGE GRAPH</h2>
<p>Knowledge graphs (KGs) about entities, their properties, and the relationships between entities, have become an important asset for semantic search, analytics, and smart recommendations over Web contents and other kinds of big data. Notable knowledge graph systems include Freebase [26], DBpedia [27], YAGO [28] and many others. In the biomedical domain, KG such as the Gene Ontology and the Disease Ontology are prominent examples of the rich knowledge that are digitally available. In our previous work, we constructed a biomedical knowledge graph SemKG - covering a wide range of terminology in multiple biomedical domains [18]. However, in SemKG, the same entity with different semantic types is considered to be the same one. In this work, we constructed a biomedical knowledge graph which differentiates semantic types of entity and relations.</p>
<h2>3) KNOWLEDGE GRAPH EMBEDDING</h2>
<p>Graph embedding methods convert the graph data into a low dimensional space in which the graph structural information and graph properties are maximally preserved [29]. Let $h$, $r, t$ denote head, tail and relation of one edge in knowledge graph, knowledge graph embedding methods follow a common assumption $\mathbf{h}<em r="r">{r}+\mathbf{r} \approx \mathbf{t}</em>}$, where $\mathbf{h<em r="r">{r}$ and $\mathbf{t}</em>$ are either the original vectors of $h$ and $t$, or the transformed vectors under a certain transformation with respect to $r$. The forerunner TransE [30] is adopted in this work as the knowledge graph embedding method for converting entities and relations of knowledge graph into vectors.</p>
<h2>4) RECURRENT NEURAL NETWORK</h2>
<p>Recurrent Neural Networks (RNNs) are, in general, good at capturing temporal dependencies in data and hence are effective in many time-series analysis applications [31]. However, RNNs have trouble learning time-dependencies more than a few time steps long [32] and suffer from severe overfitting problems [33]. To learn long-term dependencies, an alternative RNN architecture, Long Short Term Memory (LSTM), has been proposed to solve the long term dependency problem [34]. In addition, dropout technique which drops out units (hidden and visible) in a neural network was used to solve the overfitting problems of RNNs [33]. In this paper, we propose a LSTM-based RNN model which incorporates the drug-target-disease sequential data and the structures of knowledge graph to discover drugs from literature.</p>
<p><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>FIGURE 1. An illustration of constructing knowledge graph. There are two relations extracted by SemRep on the top of the figure. The figure shows the same entity (hydrocortisone) with different UMLS semantic types (horm and phsu) is considered as different nodes in the graph.</p>
<h2>III. METHOD</h2>
<p>Here, we consider the process of drug discovery as a drug-target-disease sequential data analysis problem. For example, the process by which chlorpromazine functions to produce a pharmacological effect on cardiac hypertrophy is as follows [35]:
chlorpromazine $\rightarrow$ INHIBITS $\rightarrow$ calmodulin
calmodulin $\rightarrow$ STIMULATES $\rightarrow$ calcineurin
calcineurin $\rightarrow$ CAUSES $\rightarrow$ cardiac hypertrophy
The chlorpromazine acts on cardiac hypertrophy through a series of entities. Since RNNs are well-suited for analyzing sequential data, we proposed a LSTM-based RNN model to predict drug-target-disease associations.</p>
<p>In this section, we first present the biomedical knowledge graph constructed in this study. Then, we introduce a novel approach called GrEDeL which integrates knowledge graph embeddings and LSTM model to score potential associations between drugs and diseases. After that, the trained drug discovery model is implemented to discover potential drugs for diseases.</p>
<h2>A. CONSTRUCTION OF BIOMEDICAL KNOWLEDGE GRAPH</h2>
<p>For constructing a biomedical knowledge graph, we first employed SemRep to extract predications from PubMed abstracts, then the predications were used to build the knowledge graph. Figure 1 is an illustration of constructing the knowledge graph, it shows that the same entity with different semantic types is considered as different nodes in the knowledge graph. In this paper, $E=\left{e_{1}, e_{2}, \ldots, e_{N}\right}$ denotes entities (an entity is a UMLS Metathesaurus concept) of the knowledge graph, $R=\left{r_{1}, r_{2}, \ldots, r_{M}\right}$ denotes the relations between entities and $T=\left{t_{1}, t_{2}, \ldots, t_{K}\right}$ is the set of semantic types of entities and relations. The elements of $T$ are all from the UMLS semantic network.</p>
<h2>B. PREPARATION OF TRAINING DATA</h2>
<p>Given a knowledge graph KG, a path $\pi$ is defined as a sequence of predications $e_{0} r_{0} e_{1} r_{1} e_{2} r_{2} \ldots$. In this work, a gold standard case is represented as drug-target-disease triple, which means the drug can treat the disease by</p>
<p><img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>FIGURE 2. The framework of GrEDeL. The blue circle denotes entity and the purple node denotes the entity's corresponding semantic type.
acting on the target. We first employed the path exploring method described in our previous work to construct training data [18]. More concretely, we obtained $\pi^{\ell}=$ $\rho\left(\right.$ drug $<em i="i">{i} \rightarrow$ disease $</em> ;$ target $<em i="i">{i}, \ell$ ), which encodes all the paths of length $\ell$ reaching node disease ${ }</em>$ from source node drug $<em i="i">{i}$ and crossing node target $</em>}$. Then $\pi^{\ell}=\left{\pi_{1}^{\ell}, \pi_{2}^{\ell}, \pi_{3}^{\ell}, \pi_{4}^{\ell} \ldots\right}$ is the set of all $\ell$ length paths. In addition, the paths in $\pi^{\ell}$ containing broad concept entities [10] are discarded. An entity $e_{i}$ is considered as a broad concept entity when the type of $e_{i}$ belongs to broad semantic types, because that the path containing broad concept entities can not express the drug mechanism of action for the particular disease. For example, the type of $e_{i}$ in $\pi=e_{0} r_{0} \ldots e_{i} \ldots r_{\ell-1} e_{\ell}$ is "Animal (anim)" or "Manufactured Object (mnob)", then path is filtered out. After that, all paths in $\boldsymbol{\mathcal { I }}=\left{\pi^{2}, \pi^{3} \ldots \pi^{\ell}\right}$ are considered as positive training data. Similarly, we constructed negative data set by exploring false cases drug ${ <em i="i">{i}^{\prime}$-target $</em>}^{\prime}$-disease ${ <em j="j">{j}^{\prime}$. Each false case denotes that the drug ${ }</em>}^{\prime}$ has no therapeutic effect on the disease ${ <em j="j">{j}^{\prime}$ or the corresponding drug target is not the target $</em>$.}^{\prime</p>
<h2>C. GRAPH EMBEDDING-BASED LSTM DRUG DISCOVERY MODEL</h2>
<p>Given a path $\pi_{i}^{\ell}=e_{0} r_{0} e_{1} r_{1} \ldots r_{\ell-1} e_{\ell}$ where $e_{0}$ indicates a drug and $e_{\ell}$ indicates a disease. The objective of our model is to predict the probability of the association between a potential drug and the disease of interest:</p>
<p>$$
p\left(y \mid \pi_{i}^{\ell}\right)=D\left(g\left(\pi_{i}^{\ell}\right), \theta\right)
$$</p>
<p>where $p\left(y=1 \mid \pi_{i}^{\ell}\right)$ is the probability of the candidate drug for treating the disease and $D($.$) represents any kind of discriminative model with trainable parameter \theta . g($.$) is a function for graph embedding feature extraction. Figure 2 is an illustration of our model.</p>
<h2>1) GRAPH EMBEDDING BASED FEATURE EXTRACTION</h2>
<p>As input $\pi_{i}^{l}$ is represented as a series of entity names, it is difficult to investigate the relation between entities. Thus, we applied TransE to the input $\pi_{i}^{l}$ to learn more dense representations. In TransE, if a relationship ( $e_{\text {head }}, r, e_{\text {tail }}$ ) holds, then the embedding of $e_{\text {tail }}$ should be close to the embedding of $e_{\text {head }}$ plus the embedding of $r$. To obtain both the graph structural information and the relations between semantic types, the biomedical knowledge graph was transformed into two graphs - Semantic Graph ( $S G$ ) and Type Graph ( $T G$ ). Semantic Graph contains entities and relations. Type Graph contains semantic types of entities and relations. In addition, $x_{i}$ represents element of $\pi_{i}^{\ell}=e_{0} r_{0} e_{1} r_{1} \ldots r_{\ell-1} e_{\ell}$ ( $x_{i}$ could be either an entity $e$ or relation $r$ ), then each element $x_{i}$ of $\pi_{i}^{l}$ is embedded as follows:</p>
<p>$$
\mathbf{x}<em i="i">{i}=g\left(x</em>\right)<em i="i">{S G} \bowtie g\left(x</em>
$$}\right)_{T G</p>
<p>where $g($.$) is a function for graph embedding based feature$ extraction and symbol $\bowtie$ is concatenation of two vectors. To learn the vector embeddings of the entities and relations in the Semantic Graph (the process of $g\left(x_{i}\right)<em _left_e__1="\left(e_{1">{S G}$ ), we minimize the loss function $L$ over the training set $S$ and $S^{\prime}$ :
$L=\sum</em>}, r, e_{2}\right) \in S} \sum_{\left(e_{1}^{\prime}, r, e_{2}^{\prime}\right) \in S^{\prime}}\left[\gamma+d\left(\mathbf{e<em _mathbf_2="\mathbf{2">{\mathbf{1}}+\mathbf{r}, \mathbf{e}</em>}}\right)-d\left(\mathbf{e<em _mathbf_2="\mathbf{2">{\mathbf{1}}^{\prime}+\mathbf{r}, \mathbf{e}</em>\right)\right]}}^{\prime<em _mathbf_1="\mathbf{1">{+}$
where bold font indicates vector embedding of the corresponding element (For example, $\mathbf{e}</em>]}}$ is the embedding of $e_{1}$ ). In addition, $[\mathrm{x<em 1="1">{+}$denotes the positive part of $\mathrm{x}, d$ is $L</em>$ does not appear in $S$ ):}$-norm and $\gamma&gt;0$ is a margin hyperparameter. The positive training set $S_{\left(e_{1}, r, e_{2}\right)}$ contains all the triplets $\left(e_{1}, r, e_{2}\right)$ in Semantic Graph, and the negative training set $S^{\prime}$ is constructed by replacing $e_{1}$ or $e_{2}$ of triplets in $S$ with a random entity (each triplet of $S^{\prime</p>
<p>$$
S_{\left(e_{1}, r, e_{2}\right)}^{\prime}=\left{\left(e_{1}^{\prime}, r, e_{2}\right) \mid e_{1}^{\prime} \in E\right} \cup\left{\left(e_{1}+r, e_{2}^{\prime}\right) \mid e_{2}^{\prime} \in E\right}
$$</p>
<p>The optimization procedure is carried out by stochastic gradient descent and the process of embedding the Type Graph $\left(g\left(x_{i}\right)<em i="i">{T G}\right)$ is same as $g\left(x</em>\right)<em e="e">{S G}$. The theoretical number of parameters for training TransE is $O\left(n</em>$ is the number of entities and relations, respectively, and $k$ is the dimension of graph embedding vector.} k+n_{r} k\right)$, where $n_{e}$ and $n_{r</p>
<p>After obtaining embedding $\mathbf{x}<em i="i">{i}$ of $x</em>$ is given as follows:}$, new input matrix $\mathbf{X}$ for $\pi_{i}^{l</p>
<p>$$
\mathbf{X}<em i="i">{\pi</em>
$$}^{l}}=\bigcup_{x_{i} \in \pi_{i}^{l}} \mathbf{x}_{i</p>
<p>The $\pi_{i}^{\ell}$ is converted into a $\left(L_{S G}+L_{T G}\right) * \ell$ matrix, where $L_{S G}$ and $L_{T G}$ are the length of SG and TG embedding vector, respectively. The left part of Figure 2 illustrates the process of graph embedding based feature extraction. We found that concatenation of the embedding vectors of an entity and its semantic type could give a slight improvement of the performance for drug discovery, this will be further discussed in the result section.</p>
<h2>2) MODEL DESCRIPTION</h2>
<p>We employed a recurrent neural network with long short term memory model to capture the dependencies between entities of drug-disease associations. Considering a single hidden layer network in which $x_{t}, h_{t}$ and $y_{t}$ denote the input, hidden and output layer neuron outputs, respectively, a general</p>
<p>recurrent network can be described as:</p>
<p>$$
h_{t}=\sigma\left(W_{x h} x_{t}+W_{h h} h_{t-1}+b_{h}\right)
$$</p>
<p>where, $W_{x h}, W_{h h}$ and $b_{h}$ are the weight matrices across different connections and $\sigma$ is a basic sigmoid function $(\sigma(x)=$ $\left.\frac{1}{1+e^{-x}}\right)$. Note that $h_{0}=e_{0}$ for our task. The dimension of fully connected layer in Figure 2 is $T^{*} 1$, where $T$ is the hidden layer dimension of RNN model. The probability for the $d r u g_{i}$ -target $<em i="i">{i}$-disease $</em>$ is given as follows:}$ association $\pi_{i}^{\ell</p>
<p>$$
p\left(y_{j}=1 \mid \mathbf{X}\right)=\sigma\left(V_{h \ell} h_{\ell}\right)
$$</p>
<p>where $\mathbf{X}$ represents the embeddings of input $\pi_{i}^{\ell} . V_{h \ell}$ is the fully connected output layer, the dimension of $V_{h \ell}$ is $1^{*} H, H$ is the dimension of hidden layer, respectively. Since RNNs have difficulties learning long-range dependencies, we adopted a LSTM as the drug discovery model in our experiment. LSTMs are explicitly designed to avoid the long-term dependency problem. It solves the gradient vanishing and exploding problem by introducing memory cell and forget gate. The LSTM is constructed as follows:</p>
<p>$$
\begin{aligned}
&amp; i_{t}=\sigma\left(W_{x i} x_{t}+W_{h i} h_{t-1}+b_{i}\right) \
&amp; f_{t}=\sigma\left(W_{x f} x_{t}+W_{h f} h_{t-1}+b_{f}\right) \
&amp; o_{t}=\sigma\left(W_{x o} x_{t}+W_{h o} h_{t-1}+b_{o}\right) \
&amp; g_{t}=\tanh \left(W_{x g} x_{t}+W_{h g} h_{t-1}+b_{g}\right) \
&amp; c_{t}=f_{t} \odot c_{t-1}+i_{t} \odot g_{t} \
&amp; h_{t}=o_{t} \odot \tanh \left(c_{t}\right)
\end{aligned}
$$</p>
<p>where $i_{t}, f_{t}$ and $o_{t}$ are input gate, forget gate and output gate, respectively. The current cell state $c_{t}$ will be generated by calculating the weighted sum using both previous cell state and current information generated by the cell. Trainable parameters are the weight matrices $W_{<em>}$ and $b_{</em>} . \odot$ denotes element-wise multiplication. After obtaining the hidden state of LSTM, probability for drug-disease association is calculated as Equation 7.</p>
<p>We added a dropout layer to the non recurrent part of the LSTM to mitigate overfitting problem when training our model. Finally, we defined and optimized a cross entropy loss function $L(\theta)$ as follows:</p>
<p>$$
L(\theta)=-\frac{1}{n} \sum_{i=1}^{n} \gamma \ln \left(p\left(y \mid \mathbf{X}<em i="i">{i}\right)\right)+(1-y) \ln \left(1-p\left(y \mid \mathbf{X}</em>\right)\right)
$$</p>
<p>where y is 1 or 0 . Our model was trained with back propagation through time [36].</p>
<h2>D. IMPLEMENTATION FOR DRUG DISCOVERY</h2>
<p>The trained LSTM model was used for discovering potential drugs for the disease of interest. To evaluate a potential treatment drug ${ }<em _potential="{potential" _text="\text">{\text {potential }}$-target ${ }</em>}}$-disease, first a set of paths $\mathbb{\pi<em _potential="{potential" _text="\text">{\text {potential }}=\left{\rho\left(\right.\right.$ drug $</em> \rightarrow$ disease; target $}<em _potential="{potential" _text="\text">{\text {potential }}, 2 \ldots \ell)}$ were obtained. Then the score of the drug $</em>$ is calculated as:}</p>
<p>$$
\operatorname{score}\left(\text { drug }<em _pi__i="\pi_{i">{\text {potential }}\right)=\max </em>} \in \mathbb{\pi<em i="i">{\text {potential }}} D\left(g\left(\pi</em>\right), \theta\right)
$$</p>
<p><img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>FIGURE 3. The features used in the comparing methods is the concatenation of the graph embedding vectors of training case.</p>
<p>Since the treatment of the disease is unknown, all pharmaceuticals could be potential drugs for one specific disease. Then all possible drugs were tested as candidate drugs for treating disease. Finally, we ranked all the candidate drugs by their scores.</p>
<h2>E. BASELINE METHODS</h2>
<p>To evaluate the performance of our method, we conducted ten-fold cross-validation and drug rediscovery test.</p>
<h2>1) BASELINE METHODS FOR CROSS VALIDATION</h2>
<p>Recently, numerous machine learning methods have been applied to predict drug target interactions [37]. The commonly used machine learning methods take drug target pairs as input, and the output of the methods is whether there is an interaction between a drug target pair. The most applied and successful machine learning models are binary classifiers such as logistic regression (LR), random forest (RF) [38] and support vector machine (SVM) [39]. Here, we used the most applied models as our baseline models for cross validation. The baseline models and our model used for the evaluations are as follows:</p>
<ul>
<li>Logistic Regression (LR).</li>
<li>Random Forest (RF).</li>
<li>Support Vector Machine (SVM).</li>
<li>GrEDeL: our proposed graph embedding based LSTM model.
Features for the competitive methods were constructed in the same way as our model. The features of one element in drug-disease association is the concatenation of Semantic Graph embedding and Type Graph embedding. Figure 3 is an illustration of features used in the competitive methods. As shown in Figure 3, the input vector of the methods (LR, RF and SVM) is the concatenation of the graph embedding vectors of the training case.</li>
</ul>
<h2>2) BASELINE METHODS FOR DRUG REDISCOVERY</h2>
<p>In this test, we compared our method with basic random walk method, two graph-based drug repositioning methods NRWRH [40] and TP-NRWRH [41] - and three state-of-theart knowledge graph based drug discovery methods Malas's method [16], Bakalb's method [17] and SemaTyP [18].</p>
<p><img alt="img-3.jpeg" src="img-3.jpeg" /></p>
<p>FIGURE 4. An illustration of RWA-based methods for drug discovery.</p>
<p>Specifically, NRWRH and TP-NRWRH are both graph-based random walk with restart algorithms [42]. NRWRH is a network-based random walk with restart method for inferring potential drug-target interactions. TP-NRWRH improves NRWRH by introducing a two-pass random walk algorithm. The process of discovering candidate drugs for disease; by RWA-based methods is as follows: First, the RWA algorithm starts from the drug $<em _potential="{potential" _text="\text">{\text {potential }}$ point and the expected number of steps is set to n . Then, the drug $</em>$, RWA-based methods score all drugs for the disease of interest. At last, all candidate drugs could be ranked by their scores. Figure 4 illustrates an example of evaluating "chlorpromazine" to be the treatment of "cardiachypertrophy". The left part of Figure 4 is a weighted semantic graph. The right part of Figure 4 presents the results of basic RWA method with starting point "chlorpromazine". It shows that when the expected number of step is 1 , the score of "chlorpromazine" is 0 due to "chlorpromazine" can not reach "cardiachypertrophy" in one step. Similarly, the score of "chlorpromazine"-"cardiachypertrophy" association is 0.0825 which is assigned by step_2 RWA. As shown in Figure 4, the highest score of "chlorpromazine" for treating "cardiachypertrophy" is 0.697 when the step of RWA is set to 4 .}}$-disease; association could be scored by the RWA-based methods. After that, for each disease $_{i</p>
<p>In addition, Malas's method leverages knowledge graph features such as the total number of intermediate concepts, the number of different semantic categories, and the predicates connecting a drug-disease pair to predict novel drugdisease associations [16]. Bakalb's method exploits all the paths connecting biomedical entities as features of logistic regression model to discover drugs [17]. SemaTyP is a knowledge graph based drug discovery method which exploits the distribution of semantic types of entities to score drug $_{\text {potential }}$-disease; association [18].</p>
<h2>IV. RESULTS</h2>
<p>In this section, we firstly introduce the biomedical knowledge graph and training data. Then we evaluate the performance of graph embedding method on link predication test. After that, our method was evaluated on cross-validation and drug rediscovery test separately. In addition, case studies are conducted to confirm the ability of our model to find potential drugs for diseases.</p>
<p>TABLE 1. The description of biomedical knowledge graph.</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Materials</th>
<th style="text-align: center;">Number</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">PubMed abstracts</td>
<td style="text-align: center;">22,769,789</td>
</tr>
<tr>
<td style="text-align: center;">predications</td>
<td style="text-align: center;">$39,133,975$</td>
</tr>
<tr>
<td style="text-align: center;">selected predications</td>
<td style="text-align: center;">$17,651,279$</td>
</tr>
<tr>
<td style="text-align: center;">entities of knowledge graph</td>
<td style="text-align: center;">$1,067,092$</td>
</tr>
<tr>
<td style="text-align: center;">relations of knowledge graph</td>
<td style="text-align: center;">$14,419,744$</td>
</tr>
<tr>
<td style="text-align: center;">entity types</td>
<td style="text-align: center;">133</td>
</tr>
<tr>
<td style="text-align: center;">relation types</td>
<td style="text-align: center;">52</td>
</tr>
</tbody>
</table>
<p>TABLE 2. The broad concept entity list for filtering.</p>
<table>
<thead>
<tr>
<th style="text-align: left;"></th>
<th style="text-align: left;"></th>
<th style="text-align: left;">Broad concept entities</th>
<th style="text-align: left;"></th>
<th style="text-align: left;"></th>
<th style="text-align: left;"></th>
<th style="text-align: left;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">plnt</td>
<td style="text-align: left;">alga</td>
<td style="text-align: left;">fngs</td>
<td style="text-align: left;">virs</td>
<td style="text-align: left;">rich</td>
<td style="text-align: left;">bact</td>
<td style="text-align: left;">arch</td>
</tr>
<tr>
<td style="text-align: left;">anim</td>
<td style="text-align: left;">imrt</td>
<td style="text-align: left;">vtht</td>
<td style="text-align: left;">amph</td>
<td style="text-align: left;">bird</td>
<td style="text-align: left;">fish</td>
<td style="text-align: left;">rept</td>
</tr>
<tr>
<td style="text-align: left;">mamm</td>
<td style="text-align: left;">hamn</td>
<td style="text-align: left;">anst</td>
<td style="text-align: left;">emst</td>
<td style="text-align: left;">cgab</td>
<td style="text-align: left;">acab</td>
<td style="text-align: left;">ffas</td>
</tr>
<tr>
<td style="text-align: left;">bdsy</td>
<td style="text-align: left;">evnt</td>
<td style="text-align: left;">acty</td>
<td style="text-align: left;">bhvr</td>
<td style="text-align: left;">socb</td>
<td style="text-align: left;">inbe</td>
<td style="text-align: left;">dora</td>
</tr>
<tr>
<td style="text-align: left;">ocac</td>
<td style="text-align: left;">hlca</td>
<td style="text-align: left;">lbpr</td>
<td style="text-align: left;">diap</td>
<td style="text-align: left;">topp</td>
<td style="text-align: left;">resa</td>
<td style="text-align: left;">mbrt</td>
</tr>
<tr>
<td style="text-align: left;">gora</td>
<td style="text-align: left;">edac</td>
<td style="text-align: left;">mcha</td>
<td style="text-align: left;">phpr</td>
<td style="text-align: left;">hcpp</td>
<td style="text-align: left;">eehu</td>
<td style="text-align: left;">npop</td>
</tr>
<tr>
<td style="text-align: left;">phob</td>
<td style="text-align: left;">mnob</td>
<td style="text-align: left;">medd</td>
<td style="text-align: left;">resd</td>
<td style="text-align: left;">cnce</td>
<td style="text-align: left;">idcn</td>
<td style="text-align: left;">tmco</td>
</tr>
<tr>
<td style="text-align: left;">qlco</td>
<td style="text-align: left;">qnco</td>
<td style="text-align: left;">spco</td>
<td style="text-align: left;">geoa</td>
<td style="text-align: left;">ocdi</td>
<td style="text-align: left;">bmod</td>
<td style="text-align: left;">orgt</td>
</tr>
<tr>
<td style="text-align: left;">hcro</td>
<td style="text-align: left;">pros</td>
<td style="text-align: left;">shro</td>
<td style="text-align: left;">grup</td>
<td style="text-align: left;">prog</td>
<td style="text-align: left;">popg</td>
<td style="text-align: left;">famg</td>
</tr>
<tr>
<td style="text-align: left;">aggp</td>
<td style="text-align: left;">podg</td>
<td style="text-align: left;">grpa</td>
<td style="text-align: left;">food</td>
<td style="text-align: left;">sosy</td>
<td style="text-align: left;">anab</td>
<td style="text-align: left;">neop</td>
</tr>
</tbody>
</table>
<h2>A. THE BIOMEIDCAL KNOWLEDGE GRAPH AND TRAINING DATA</h2>
<p>The biomedical knowledge graph is constructed by extracting predications from the abstracts published in PubMed before June 1, 2013. In addition, in order to ensure the accuracy of extracted predication, we filtered out the predications that only appear once. Table 1 presents the details of the biomedical knowledge graph constructed in our work.</p>
<p>For building training set, on one side, we selected 7,144 drug-target-disease triplets from TTD as true cases. Then following the process in Section III-B, we obtained $6,188,265$ positive training data. The $\ell$ was set to 4 as described in our previous work. The broad concept entities used are listed in Table 2. On the other side, we randomly constructed a set of drug $<em _random="{random" _text="\text">{\text {random }}$-target $</em>$-disease $}<em _random="{random" _text="\text">{\text {random }}$ cases for building false training data. Specifically, we kept the drug $</em>$-target $}<em _random="{random" _text="\text">{\text {random }}$-disease $</em>$ triplets that do not exist in TTD as false cases. In order to balance the positive and negative training data, $6,188,265$ negative training data were obtained by the the same process of constructing the positive training data.}</p>
<h2>B. KNOWLEDGE GRAPH EMBEDDING</h2>
<p>For evaluating the performance of knowledge graph embedding, we use the same evaluation protocols as in [30]. We selected subset of 'predications' which constructs the knowledge graph to evaluate graph embedding model. For each subset, $90 \%$ of the data were randomly selected as training data and the other $10 \%$ were test data. For each test triplet $\left(e_{\text {head }}, r, e_{\text {tail }}\right)$, the $e_{\text {tail }}$ is removed and replaced by each of the entities of test set. The dissimilarities of new triplets are first computed and then sorted by ascending order; the rank of the correct entity $e_{\text {tail }}$ is finally stored. Then the mean of those predicted ranks and hits@10 are reported.</p>
<p>TABLE 3. The performance of different models.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Methods</th>
<th style="text-align: left;">Precision</th>
<th style="text-align: left;">Recall</th>
<th style="text-align: left;">F-score</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">LR</td>
<td style="text-align: left;">0.715</td>
<td style="text-align: left;">0.889</td>
<td style="text-align: left;">0.791</td>
</tr>
<tr>
<td style="text-align: left;">RF</td>
<td style="text-align: left;">0.742</td>
<td style="text-align: left;">0.750</td>
<td style="text-align: left;">0.743</td>
</tr>
<tr>
<td style="text-align: left;">SVM</td>
<td style="text-align: left;">0.622</td>
<td style="text-align: left;">0.766</td>
<td style="text-align: left;">0.635</td>
</tr>
<tr>
<td style="text-align: left;">GrEDeL $_{M L P _2}$</td>
<td style="text-align: left;">0.699</td>
<td style="text-align: left;">0.896</td>
<td style="text-align: left;">0.785</td>
</tr>
<tr>
<td style="text-align: left;">GrEDeL $_{M L P _3}$</td>
<td style="text-align: left;">0.707</td>
<td style="text-align: left;">0.901</td>
<td style="text-align: left;">0.792</td>
</tr>
<tr>
<td style="text-align: left;">GrEDeL $_{M L P _4}$</td>
<td style="text-align: left;">0.715</td>
<td style="text-align: left;">0.889</td>
<td style="text-align: left;">0.793</td>
</tr>
<tr>
<td style="text-align: left;">GrEDeL $_{M L P _5}$</td>
<td style="text-align: left;">0.711</td>
<td style="text-align: left;">0.903</td>
<td style="text-align: left;">0.796</td>
</tr>
<tr>
<td style="text-align: left;">GrEDeL $_{R N N}$</td>
<td style="text-align: left;">0.819</td>
<td style="text-align: left;">0.938</td>
<td style="text-align: left;">0.874</td>
</tr>
<tr>
<td style="text-align: left;">GrEDeL</td>
<td style="text-align: left;">$\mathbf{0 . 8 8 1}$</td>
<td style="text-align: left;">$\mathbf{0 . 9 7 1}$</td>
<td style="text-align: left;">$\mathbf{0 . 9 2 4}$</td>
</tr>
</tbody>
</table>
<p>TABLE 4. Performance of knowledge graph embedding method.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Dataset</th>
<th style="text-align: left;">5,000</th>
<th style="text-align: left;">10,000</th>
<th style="text-align: left;">20,000</th>
<th style="text-align: left;">40,000</th>
<th style="text-align: left;">100,000</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Mean Ranks</td>
<td style="text-align: left;">305</td>
<td style="text-align: left;">261</td>
<td style="text-align: left;">176</td>
<td style="text-align: left;">122</td>
<td style="text-align: left;">108</td>
</tr>
<tr>
<td style="text-align: left;">Hits@10 (\%)</td>
<td style="text-align: left;">9.4</td>
<td style="text-align: left;">15.7</td>
<td style="text-align: left;">22.6</td>
<td style="text-align: left;">27.1</td>
<td style="text-align: left;">29.8</td>
</tr>
</tbody>
</table>
<p>TABLE 5. Example of link prediction results.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">INPUT ( $e_{\text {head }}$ and $r$ )</th>
<th style="text-align: left;">PREDICTED $e_{\text {tail }}$</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Cysteine STIMULATE</td>
<td style="text-align: left;">beta-Lactams, bathocuproine disulfonate,</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">hydrogen peroxide, Pheomelanin, N-</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">Methylaspartate, aspartic acid receptor, de-</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">oxyhemoglobin, IL2, Cyclic GMP, Anti-</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">neoplastic Agents</td>
</tr>
<tr>
<td style="text-align: left;">Alteplase INHIBITS</td>
<td style="text-align: left;">Cycloheximide, Urokinase, Plasminogen</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">Activator Inhibitor 1, Thromboxane-A</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">Synthase, Alteplase, alpha 1-Antitrypsin,</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">FASTK Gene, Thromboxane A2 Recep-</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">tor, Plasminogen Inactivators, Antithrom-</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">bin III</td>
</tr>
<tr>
<td style="text-align: left;">Heparin AUGMENTS</td>
<td style="text-align: left;">Megakaryocytopoiesis, thrombin activity,</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">Antiinflammatory Effect, growth factor</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">binding, anti-toxin activity, IgG binding,</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">Hemostatic function, Osteoclastic resorp-</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">tion, Nitrous oxide concentration, Tyro-</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">sine Phosphorylation</td>
</tr>
</tbody>
</table>
<p>The dimension of embedding was set to 100 and $\gamma=1$. Table 4 shows the results of embeddings of Semantic Graph, the 'Dataset' row represents the number of triplets selected from Semantic Graph. Table 5 presents three examples of link predication results: given the entity $e_{\text {head }}$ and the relation $r$, graph embedding method predicts the entity $e_{\text {tail }}$. The 'PREDICATED $e_{\text {tail }}$ ' column shows the top predicated $e_{\text {tail }}$ entities, the entity in bold is the known $e_{\text {tail }}$ entity. The results shows that graph embedding method could capture dependencies between entities and relations.</p>
<h2>C. TEN-FOLD CROSS VALIDATION</h2>
<p>We conducted ten-fold cross validations to evaluate the performance of the proposed GrEDeL against other three baseline methods in terms of commonly used measure: Precision, Recall and F-score. The dataset were split into ten subsets with equal size, and the positive and negative data in each subset is balanced. In particular, each subset does not share the same drug-disease pairs as other subsets in order to avoid overestimation of the training accuracy. Then each subset was taken in turn as a test set and other nine subsets were taken as input to run the methods. The average prediction accuracies</p>
<p>TABLE 6. The performance of GrEDeL with different knowledge graph embedding based features.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Methods</th>
<th style="text-align: left;">Precision</th>
<th style="text-align: left;">Recall</th>
<th style="text-align: left;">F-score</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">GrEDeL $_{\text {random }}$</td>
<td style="text-align: left;">0.608</td>
<td style="text-align: left;">0.759</td>
<td style="text-align: left;">0.68</td>
</tr>
<tr>
<td style="text-align: left;">GrEDeL $_{T G}$</td>
<td style="text-align: left;">0.773</td>
<td style="text-align: left;">0.824</td>
<td style="text-align: left;">0.797</td>
</tr>
<tr>
<td style="text-align: left;">GrEDeL $_{S G}$</td>
<td style="text-align: left;">0.819</td>
<td style="text-align: left;">$\mathbf{0 . 9 9 2}$</td>
<td style="text-align: left;">0.897</td>
</tr>
<tr>
<td style="text-align: left;">GrEDeL $_{S G+O G}$</td>
<td style="text-align: left;">$\mathbf{0 . 8 8 1}$</td>
<td style="text-align: left;">0.971</td>
<td style="text-align: left;">$\mathbf{0 . 9 2 4}$</td>
</tr>
</tbody>
</table>
<p>over the test subsets were regarded as overall performance measures.</p>
<p>Table 3 shows that GrEDeL outperforms LR, RF and SVM models. We argue that our method can effectively capture temporal dependencies in drug-disease sequences. To further investigate the impact of each components in GrEDeL model, performances of GrEDeL with various graph embedding-based features are reported in Table 3. Random embedding (GrEDeL $<em G="G" S="S">{\text {random }}$ ), Semantic Graph embedding only ( $\mathrm{GrEDeL}</em>$ ) and Type Graph embedding only (GrEDeL $<em _random="{random" _text="\text">{T G}$ ) based models were proposed to evaluate the performance of GrEDeL. Specifically, GrEDeL $</em>$ model uses the random embeddings for entities and relations, GrEDeL $}<em G="G" T="T">{S G}$ only uses semantic graph embedding for entities and relations (where the $\mathrm{L}</em>}=0$ ) and similarly, $\mathrm{L<em G="G" T="T">{S G}$ of GrEDeL $</em>$ is 0 . Table 3 shows that although GrEDeL $<em G="G" T="T">{T G}$ model only adopts type graph embeddings for the representation of knowledge graph, it still has reasonable performances. The reason is that the embedding of type graph could learn the rules of relations between entity types. This is similar as defining a semantic type pattern - such as drug-INHIBITES-protein-STIMULATESdisease - which could be used to select drug-disease associations based on their semantic types. However, there are only 133 entity types and 52 relation types in our knowledge graph (Table 1), which results in that GrEDeL $</em>}$ model can not differentiate different entities with the same semantic type. In addition, Table 3 shows that the semantic graph embedding based GrEDeL model ( $\mathrm{GrEDeL<em G="G" G_T="G+T" S="S">{S G}$ ) has significantly boosted the performance. What's more, knowledge graph embedding $\left(\mathrm{GrEDeL}</em>\right)$ outperforms other methods, the reason may be that knowledge graph embedding not only considers structure of knowledge graph but also preserves the information of semantic types. The graph embedding features capture rich information about the graph and entity-entity relations.</p>
<p>In additon, we replaced the LSTM of GrEDeL with other deep learning methods such as MLP (Multi-Layer Perceptron) and vanilla RNN in order to explore the influence of deep learning parts for GrEDeL. Table 3 presents the results and the $N$ in $\operatorname{GrEDeL}_{M L P _N}$ is the number of hidden layers of MLP. The number of parameters of MLP and RNN is $N *$ $n^{2}+n k+n m$ and $n^{2}+n k+n m$, respectively. Where $k, n$ and $m$ is the dimension of input layer, hidden layer and output layer, respectively. Table 7 shows the best performing dimension of hidden layer of MLP and RNN is 100 and 50, respectively. Although the total number of parameters of MLP is more than four times that of RNN, Table 3 shows the vanilla RNN based GrEDeL outperforms MLP based GrEDeL. The reason is that</p>
<p>TABLE 7. Validation hyper parameters. Steps of each range and selected values are shown.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Methods</th>
<th style="text-align: left;">Range</th>
<th style="text-align: left;">Step</th>
<th style="text-align: left;">Optimal</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">LSTM cell dimension</td>
<td style="text-align: left;">$[25-150]$</td>
<td style="text-align: left;">25</td>
<td style="text-align: left;">100</td>
</tr>
<tr>
<td style="text-align: left;">LSTM dropout</td>
<td style="text-align: left;">$[0.3-0.8]$</td>
<td style="text-align: left;">0.05</td>
<td style="text-align: left;">0.5</td>
</tr>
<tr>
<td style="text-align: left;">Hidden layer dimension of GrEDeL</td>
<td style="text-align: left;">$[10-100]$</td>
<td style="text-align: left;">10</td>
<td style="text-align: left;">30</td>
</tr>
<tr>
<td style="text-align: left;">$\mathrm{L}_{S G}$</td>
<td style="text-align: left;">$[25-100]$</td>
<td style="text-align: left;">25</td>
<td style="text-align: left;">100</td>
</tr>
<tr>
<td style="text-align: left;">$\mathrm{L}_{T G}$</td>
<td style="text-align: left;">$[10-50]$</td>
<td style="text-align: left;">10</td>
<td style="text-align: left;">10</td>
</tr>
<tr>
<td style="text-align: left;">Hidden layer dimension of MLP</td>
<td style="text-align: left;">$[10-100]$</td>
<td style="text-align: left;">100</td>
<td style="text-align: left;">100</td>
</tr>
<tr>
<td style="text-align: left;">Hidden layer dimension of RNN</td>
<td style="text-align: left;">$[10-100]$</td>
<td style="text-align: left;">10</td>
<td style="text-align: left;">50</td>
</tr>
</tbody>
</table>
<p>GrEDeL works well not because of deep learning structure but because of sequential characteristic. The performance improvement could come from sequential characteristics of RNN-based methods. In addition, LSTM based GrEDeL achieves better performances than vanilla RNN based method due to LSTM could learn long-term dependent relationships in the drug-target-disease associations.</p>
<p>We validated 5 different hyper parameters of our model (as shown in Table 7). Best performing parameter set on validation phase was used for the GrEDeL model. The Adam optimizer [43] was used for optimizing GrEDeL and the learning rate decay was set to 0.99 for every 100 iterations. Additionally, mini batch of size 500 was used. Implementations of LR, RF and SVM is based on Sklearn library.</p>
<h2>D. DRUG REDISCOVERY TEST</h2>
<p>We conducted drug rediscovery test to evaluate the performance of our method in discovering drugs for diseases of interest. Here, we adopted the same drug-disease relationships as used in our previous work for drug rediscovery test. In particular, in the path obtaining process of this work, we filtered out the paths between drug and disease that containing broad concepts. After the path exploring process, there are only 115 of the 360 standard relationships used in our previous work have paths in the knowledge graph. Then we used the 115 drug-disease relationships as gold standard cases for drug rediscovery test. For each gold standard cases, TTD has reported that the drug could treat the disease, but the corresponding drug targets are not clear. For evaluation, we used the same ranking procedure as described in [18]. Specifically, for each gold standard $d r u g_{i}$-disease $<em i="i">{i}$, we randomly selected other 100 drugs (including chemical entities and new biologic entities) from TTD as potential drugs for treating disease $</em>$. Then drug discovery models scored all the 101 drugs for treating the disease $<em i="i">{i}$. Lastly, the average ranking of standard drugs (mean ranks) among all the standard cases and the proportion of known drugs ranked in the top 10 (Hits@10) were reported to evaluate the performance of the models. For RWA-based methods (NRWRH and TP-NRWRH), if the standard $d r u g</em>$ of disease $<em i="i">{i}$ is not found by the drug discovery model, then the $d r u g</em>$ is scored 0 and the corresponding ranking is 101 . What's more, for SemaTyP and GrEDeL, we selected 5,785 targets from TTD as candidates drug targets for constructing drug $<em _candidate="{candidate" _text="\text">{i}$-target $</em>$ associations.}}$-disease $_{i</p>
<p>TABLE 8. Performance of discovering drugs for disease.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Method</th>
<th style="text-align: left;">Not Found</th>
<th style="text-align: left;">Mean Ranks</th>
<th style="text-align: left;">Hits@10 (\%)</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">RWA_1</td>
<td style="text-align: left;">93</td>
<td style="text-align: left;">90.82</td>
<td style="text-align: left;">17.39</td>
</tr>
<tr>
<td style="text-align: left;">RWA_2</td>
<td style="text-align: left;">52</td>
<td style="text-align: left;">44.31</td>
<td style="text-align: left;">24.46</td>
</tr>
<tr>
<td style="text-align: left;">RWA_3</td>
<td style="text-align: left;">4</td>
<td style="text-align: left;">30.33</td>
<td style="text-align: left;">23.48</td>
</tr>
<tr>
<td style="text-align: left;">RWA_4</td>
<td style="text-align: left;">0</td>
<td style="text-align: left;">33.84</td>
<td style="text-align: left;">18.26</td>
</tr>
<tr>
<td style="text-align: left;">RWA_5</td>
<td style="text-align: left;">0</td>
<td style="text-align: left;">35.27</td>
<td style="text-align: left;">14.78</td>
</tr>
<tr>
<td style="text-align: left;">RWA_6</td>
<td style="text-align: left;">0</td>
<td style="text-align: left;">39.14</td>
<td style="text-align: left;">11.30</td>
</tr>
<tr>
<td style="text-align: left;">Malas's Method [16]</td>
<td style="text-align: left;">52</td>
<td style="text-align: left;">37.68</td>
<td style="text-align: left;">24.34</td>
</tr>
<tr>
<td style="text-align: left;">NRWRH [40]</td>
<td style="text-align: left;">26</td>
<td style="text-align: left;">32.17</td>
<td style="text-align: left;">26.09</td>
</tr>
<tr>
<td style="text-align: left;">TP-NRWRH [41]</td>
<td style="text-align: left;">19</td>
<td style="text-align: left;">31.13</td>
<td style="text-align: left;">27.83</td>
</tr>
<tr>
<td style="text-align: left;">Bakalb's Method [17]</td>
<td style="text-align: left;">4</td>
<td style="text-align: left;">29.44</td>
<td style="text-align: left;">31.30</td>
</tr>
<tr>
<td style="text-align: left;">SemaTyP [18]</td>
<td style="text-align: left;">0</td>
<td style="text-align: left;">29.87</td>
<td style="text-align: left;">30.58</td>
</tr>
<tr>
<td style="text-align: left;">GrEDeL</td>
<td style="text-align: left;">0</td>
<td style="text-align: left;">$\mathbf{2 7 . 0 5}$</td>
<td style="text-align: left;">$\mathbf{3 3 . 0 4}$</td>
</tr>
</tbody>
</table>
<p>In our experiments, all competitive methods (NRWRH, TP-NRWRH, Malas's method, Bakalb's method and SemaTyP) follow the recommended settings reported in their papers and the expected number of step of the basic RWA method was set from 1 to 6 . The overall results of drug rediscovery are presented in Table 8. The "Not Found" denotes the number of gold standard drugs which are not discovered by the corresponding method. "RWA_n" denotes the basic random walk algorithm with $n$ steps.</p>
<p>For "Not found", we find that increasing the number of steps improves the performance of basic RWA method. The reason is that the RWA with more steps could cover more entities. For instance, as shown in Table 8, 93 golden standard drugs are not discovered by RWA_1, this is because there are only 22 (115-93) golden standard drugs directly connect to their corresponding diseases in the knowledge graph. As the number of steps increases, basic RWA method could discover more drugs. Table 8 shows that the basic RWA methods could find all drugs when the number of steps exceeds 3 . It is due to the fact that in the knowledge graph of our experiments, all golden standard drugs and their corresponding diseases can be connected by a path of length 4 . As we can see from Table 8, there are 52 and 4 drugs were missed by Malas's method and Bakalb's method, respectively. This reason is Malas's method considers one intermediate between drug and disease and Bakalb's method just considers all paths of length $\leq 3$. Table 8 shows NRWRH and TP-NRWRH achieve poor performance than some basic RWA methods with respect to "Not found" metric. The primary reason is that, NRWRH and TP-NRWRH are both random walk with restart algorithms, which may result in that some disease nodes can not be reached by the golden standard drugs within desired steps. Moreover, Table 8 shows SemaTyP and GrEDeL rediscover all drugs for the diseases, as both methods could explore all paths of lengths 3 to 6 .</p>
<p>Table 8 shows RWA_1 achieves the worst result (90.82) in terms of "Mean Ranks". For the reason that most of the drugs ( 93 drugs) have not been found by this method. In addition, RWA_2 dramatically improves the performance as RWA with 2 steps could discover more drugs than that of RWA_1 method. As the number of steps increases, the</p>
<p>TABLE 9. Case studies of drug discovery.</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Disease</th>
<th style="text-align: center;">Drug</th>
<th style="text-align: center;">Ranking</th>
<th style="text-align: center;">Score</th>
<th style="text-align: center;">Mechanism of Action</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">cardiovascular disease</td>
<td style="text-align: center;">ioxaglate</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0.57</td>
<td style="text-align: center;">ioxaglate DISRUPTS platelet aggregation AFFECTS signal transduction pathway AFFECTS cardiovascular disease</td>
</tr>
<tr>
<td style="text-align: center;">inflammatory disease</td>
<td style="text-align: center;">sb-612111</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0.69</td>
<td style="text-align: center;">sb-612111 NEG_AFFECTS consumption AFFECTS bone metabolism AFFECTS rheumatoid arthritis PROCESS_OF inflammatory disease</td>
</tr>
<tr>
<td style="text-align: center;">dementia</td>
<td style="text-align: center;">rx-77368</td>
<td style="text-align: center;">9</td>
<td style="text-align: center;">0.51</td>
<td style="text-align: center;">rx-77368 NEG_AFFECTS blood flow AFFECTS hsf1 AFFECTS disease COEXISTS_WITH dementia</td>
</tr>
<tr>
<td style="text-align: center;">mood disorder</td>
<td style="text-align: center;">mcpp</td>
<td style="text-align: center;">4</td>
<td style="text-align: center;">0.28</td>
<td style="text-align: center;">mcpp COEXISTS_WITH cortisol DISRUPTS telomere LOCATION_OF disease COEXISTS_WITH mood disorder</td>
</tr>
<tr>
<td style="text-align: center;">pain</td>
<td style="text-align: center;">dpi-3290</td>
<td style="text-align: center;">9</td>
<td style="text-align: center;">0.44</td>
<td style="text-align: center;">pi-3290 DISRUPTS tension COEXISTS_WITH pe CAUSES symptom PROCESS_OF pain</td>
</tr>
<tr>
<td style="text-align: center;">cancer</td>
<td style="text-align: center;">$\operatorname{tr}-2$</td>
<td style="text-align: center;">10</td>
<td style="text-align: center;">0.13</td>
<td style="text-align: center;">tr-2 INTERACTS_WITH cyclosporine ISA p-glycoprotein AFFECTS tissue LOCATION_OF cancer</td>
</tr>
</tbody>
</table>
<p>performance in terms of "Mean Ranks" can be further improved. For the basic RWA methods, Table 8 shows RWA_3 reaches the best performance (30.33). However, the performance decreases as the number of steps continues to grow. This is because the larger number of steps allows the RWA method to find more candidate drugs, which in turn leads to a lower ranking of the golden standard drugs. Table 8 shows that NRWRH and TP-NRWRH outperform all basic RWA methods. This is because both NRWRH and TP-NRWRH incorporate semantic types of entity besides the graph structure information. Similarly, Table 8 shows SemaTyP further improves the performance by making full use of semantic information of knowledge graph. In addition, Malas's method achieves poor performance (37.68) in terms of "Mean Ranks", this is due to there are 52 drugs were missed by the method.</p>
<p>For "Hits@10", RWA_2 outperforms other basic RWA methods (24.46\%). As shown in Table 8, although the performance decreases slightly when the step increases to 3 ( $23.48 \%$ ), continuously increasing the number of steps of RWA will cause significantly performance degradation. Furthermore, Table 8 shows NRWRH and TP-NRWRH achieve better performances than all basic RWA methods. Compared with the results obtained by RWA-based methods, Bakalb's method and SemaTyP achieve better performance in terms of "Hits@10" metric.</p>
<p>Table 8 shows our method, GrEDeL, outperforms all counterparts on all metrics (The "Mean Ranks" and "Hits@10" is 27.05 and $33.04 \%$, respectively). The main reasons are: 1) GrEDeL makes full use of both semantic information and structure of graph: the graph embedding features capture more information of the biomedical knowledge graph than other competitive methods. 2) GrEDeL considers the process of literature based discovery as a series analysis problem. By using recurrent neural network, GrEDeL can learn the dependencies among entities of drug-disease associations.</p>
<p>We are the first to consider the process of literature based discovery as a series analysis problem.</p>
<h2>E. CASE STUDY</h2>
<p>In this section, we conducted six case studies to show the efficacy of our approach (Table 9). The scores in the table are the probability indicating whether there is a relationship between a drug and a disease. Since the drug mechanism of actions are unknown, the associations obtained by our model was adopted to verify the hypotheses. For each disease of interest, GrEDeL predicts both the potential drugs and the corresponding drug targets simultaneously. For example, TTD has reported that ioxaglate is one known drug for cardiovascular disease, but the drug mechanism is still unknown. GrEDeL ranks ioxaglate as the 1st potential drug for treating cardiovascular disease. What's more, our method also provides corresponding mechanism of action of ioxaglate, Table 9 shows that ioxaglate acts on cardiovascular disease by disrupting platelet aggregation which affects the signal transduction pathway in cardiovascular disease. Other examples: rx-77368 is predicated to treat dementia by acting on hsf. $\operatorname{Tr}-2$ is predicated to treat cancer by acting on p-glycoprotein, etc. The cases in Table 9 show our method has the potential to discover drugs as well as their corresponding drug targets. However, the drug mechanism of actions generated by LBD must then be verified by human judgment and with experimental methods or clinical studies, depending on the nature of the discovery [44].</p>
<h2>F. COMPLEXITY</h2>
<p>Our experiments were conducted on a PC with 4 Intel(R) Xeon(R) CPU E5-2609 of 2.4 GHz and 8GB internal memory, the LSTM was implemented in TensorFlow 1.1.0 with GPU (CUDA 8.0.61) support. The source code of our implementation was released at. ${ }^{1}$ Table 10 shows the time needed</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>TABLE 10. Running time (in hours), the number in left column is the length of graph embedding.</p>
<table>
<thead>
<tr>
<th style="text-align: center;">graph embedding dimension</th>
<th style="text-align: center;">running time</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">$\mathrm{SG}<em 10="10">{25}+T G</em>$</td>
<td style="text-align: center;">4.6</td>
</tr>
<tr>
<td style="text-align: center;">$\mathrm{SG}<em 20="20">{50}+T G</em>$</td>
<td style="text-align: center;">11.2</td>
</tr>
<tr>
<td style="text-align: center;">$\mathrm{SG}<em 30="30">{75}+T G</em>$</td>
<td style="text-align: center;">15.3</td>
</tr>
<tr>
<td style="text-align: center;">$\mathrm{SG}<em 10="10">{100}+T G</em>$</td>
<td style="text-align: center;">16.1</td>
</tr>
<tr>
<td style="text-align: center;">$\mathrm{SG}<em 50="50">{100}+T G</em>$</td>
<td style="text-align: center;">27.3</td>
</tr>
</tbody>
</table>
<p>for training of the GrEDeL in terms of the different graph embedding dimensions (the sum of the length of SG embedding and TG embedding). The first column in Table 10 is the dimension of graph embedding and the second column show the total running time for training GrEDeL. The dimension of hidden layer in LSTM was adopted the optimal setting in Table 7.</p>
<p>The running time for drug discovery depends on the total number of candidate drugs and corresponding drug targets. In this work, 100 candidate drugs and 5,785 targets (a protein, peptide or nucleic acid) extracted from TTD were used to construct candidate drug-target-disease associations for a given disease of interest. The average running time for processing one drug-target-disease association is 12 ms .</p>
<h2>V. DISCUSSION</h2>
<p>As far as we know, this is the first method that incorporates biomedical knowledge graph, knowledge graph embedding, as well as deep learning methods to discover drugs from literature. Our overall approach however, has several limitations: 1) The construction of our biomedical knowledge graph relies heavily on effective natural language processing tool (SemRep). Although we filtered out all isolated predications in order to improve the quality of the biomedical knowledge graph, there are still a large number of false positive relations existing in the knowledge graph, which in turn leads to our method inferring lower-quality results. 2) The positive training data constructed in our work consist of instances corresponding to paths extracted from the KG. However, the instances may correspond to overlapping paths. This could introduce bias to the ten-fold cross validation evaluation as an instance appearing on the training set could be very similar (due to the overlap) to another instance that is used in the test set, and thus lead to an overestimation of the performance. 3) The TransE is adopted in our method for knowledge graph embedding. It only achieves promising results in handling 1-to-1 relations. However, the biomedical knowledge graph also contains some 1-to-n and n-to-n relations.</p>
<p>In future work, we would like to develop high-quality NLP tools, in particular, biomedical NLP tools, to improve the quality of the biomedical knowledge graph. Additionally, other graph embedding methods could be used for capturing multi-mapping relations between entities.</p>
<h2>VI. CONCLUSION</h2>
<p>In this paper we have introduced a framework to jointly utilize knowledge graph and deep learning methods for discovering
drugs from literature. The experimental results show that our method can effectively discover potential drugs and their corresponding mechanism of actions. It could be a supplementary method for current drug discovery methods, which could improve the successfulness in discovering new medicine for currently incurable diseases.</p>
<h2>REFERENCES</h2>
<p>[1] R. Goulding and E. Marden, "An overview of drug discovery and drug development," OHI Del., vol. 1, 2009.
[2] S. Morgan, P. Grootendorst, J. Lexchin, C. Cunningham, and D. Greyson, "The cost of drug development: A systematic review," Health Policy, vol. 100, no. 1, pp. 4-17, 2011.
[3] A. Korhonen et al., "Improving literature-based discovery with advanced text mining," in Computational Intelligence Methods for Bioinformatics and Biostatistics (Lecture Notes in Computer Science), vol. 8623. Springer, 2014, pp. 89-98.
[4] D. Gubiani, I. Petrič, E. Fabbretti, and T. Urbančič, "Mining scientific literature about ageing to support better understanding and treatment of degenerative diseases," Tech. Rep., 2015.
[5] D. R. Swanson, "Fish oil, Raynaud's syndrome, and undiscovered public knowledge," Perspect. Biol. Med., vol. 30, no. 1, pp. 7-18, 1986.
[6] R. A. Digiacomo, J. M. Kremer, and D. M. Shah, "Fish-oil dietary supplementation in patients with Raynaud's phenomenon: A double-blind, controlled, prospective study," Amer. J. Med., vol. 86, no. 2, pp. 158-164, 1989.
[7] R. K. Lindsay and M. D. Gordon, "Literature-based discovery by lexical statistics," J. Assoc. Inf. Sci. Technol., vol. 50, no. 7, pp. 574-587, 1999.
[8] M. D. Gordon and R. K. Lindsay, "Toward discovery support systems: A replication, re-examination, and extension of Swanson's work on literature-based discovery of a connection between Raynaud's and fish oil," J. Assoc. Inf. Sci. Technol., vol. 47, no. 2, pp. 116-128, 1996.
[9] M. Weeber, H. Klein, L. T. W. de Jong-van den Berg, and R. Vos, "Using concepts in literature-based discovery: Simulating Swanson's Raynaudfish oil and migraine-magnesium discoveries," J. Assoc. Inf. Sci. Technol., vol. 52, no. 7, pp. 548-557, 2001.
[10] S. Sang, Z. Yang, Z. Li, and H. Lin, "Supervised learning based hypothesis generation from biomedical literature," BioMed Res. Int., vol. 2015, May 2015, Art. no. 698527.
[11] S. Henry and B. T. Mcinnes, "Literature based discovery: Models, methods, and trends," J. Biomed. Inform., vol. 74, pp. 20-32, Oct. 2017.
[12] D. Hristovski, C. Friedman, T. C. Rindflesch, and B. Peterlin, "Exploiting semantic relations for literature-based discovery," in Proc. Annu. Symp. AMIA. Bethesda, MD, USA: American Medical Informatics Association, 2006, p. 349.
[13] M. Rastegar-Mojarad, R. K. Elayavilli, D. Li, R. Prasad, and H. Liu, "A new method for prioritizing drug repositioning candidates extracted by literature-based discovery," in Proc. IEEE Int. Conf. Bioinf. Biomed., Nov. 2015, pp. 669-674.
[14] C. B. Ahlers, D. Hristovski, H. Kilicoglu, and T. C. Rindflesch, "Using the literature-based discovery paradigm to investigate drug mechanisms," in Proc. AMIA Annu. Symp. Bethesda, MD, USA: American Medical Informatics Association, 2007, pp. 6-10.
[15] D. Cameron, R. Kavuluru, T. C. Rindflesch, A. P. Sheth, K. Thirunarayan, and O. Bodenreider, "Context-driven automatic subgraph creation for literature-based discovery," J. Biomed. Inform., vol. 54, pp. 141-157, Apr. 2015.
[16] T. B. Malas et al., "Drug repurposing using a semantic knowledge graph," Tech. Rep.
[17] G. Bakal, G. Bakal, E. V. Kakani, and R. Kavuluru, "Exploiting semantic patterns over biomedical knowledge graphs for predicting treatment and causative relations," J. Biomed. Inform., vol. 82, pp. 189-199, Jun. 2018.
[18] S. Sang, Z. Yang, L. Wang, X. Liu, H. Lin, and J. Wang, "Sematyp: A knowledge graph based literature mining method for drug discovery," BMC Bioinf., vol. 19, no. 1, p. 193, 2018.
[19] I. I. Baskin, D. Winkler, and I. V. Tetko, "A renaissance of neural networks in drug discovery," Expert Opinion Drug Discovery, vol. 11, no. 8, pp. 785-795, 2016.</p>
<p>[20] P.-W. Keith, C. C. Chan, and Z.-H. You, "Large-scale prediction of drugtarget interactions from deep representations," in Proc. Int. Joint Conf. Neural Netw. (IJCNN), Jul. 2016, pp. 1236-1243.
[21] H. Chen, O. Engkvist, Y. Wang, M. Olivecrona, and T. Blaschke, "The rise of deep learning in drug discovery," Drug Discovery Today, vol. 23, no. 6, pp. 1241-1250, 2018.
[22] D. A. B. Lindberg, B. L. Humphreys, and A. T. McCray, "The unified medical language system," Methods Inf. Med., vol. 32, no. 04, pp. 281-291, 1993.
[23] A. T. McCray, "The UMLS semantic network," in Proc. Annu. Symp. Comput. Appl. Med. Care. Bethesda, MD, USA: American Medical Informatics Association, 1989, pp. 503-507.
[24] X. Chen, Z. L. Ji, and Y. Z. Chen, "TTD: Therapeutic target database," Nucleic Acids Res., vol. 30, no. 1, pp. 412-415, 2002.
[25] T. C. Rindflesch and M. Fiszman, "The interaction of domain knowledge and linguistic structure in natural language processing: Interpreting hypernymic propositions in biomedical text," J. Biomed. Inform., vol. 36, no. 6, pp. 462-477, 2003.
[26] K. Bollacker, C. Evans, P. Paritosh, T. Sturge, and J. Taylor, "Freebase: A collaboratively created graph database for structuring human knowledge," in Proc. ACM SIGMOD Int. Conf. Manage. Data, 2008, pp. 1247-1250.
[27] C. Bizer et al., "DBpedia-A crystallization point for the Web of data," J. Web Semantics, vol. 7, no. 3, pp. 154-165, 2009.
[28] J. Hoffart, F. M. Suchanek, K. Berberich, E. Lewis-Kelham, G. De Melo, and G. Weikum, "Yago2: Exploring and querying world knowledge in time, space, context, and many languages," in Proc. ACM 20th Int. Conf. Companion World Wide Web, 2011, pp. 229-232.
[29] H. Cai, V. W. Zheng, and K. C.-C. Chang. (2017). "A comprehensive survey of graph embedding: Problems, techniques and applications." [Online]. Available: https://arxiv.org/abs/1709.07604
[30] A. Bordes, N. Usunier, A. Garcia-Duran, J. Weston, and O. Yakhnenko, "Translating embeddings for modeling multi-relational data," in Proc. Adv. Neural Inf. Process. Syst., 2013, pp. 2787-2795.
[31] M. Hinken and P. Stagge, "Recurrent neural networks for time series classification," Neurocomputing, vol. 50, pp. 223-235, Jan. 2003.
[32] Y. Bengio, P. Simard, and P. Frasconi, "Learning long-term dependencies with gradient descent is difficult," IEEE Trans. Neural Netw., vol. 5, no. 2, pp. 157-166, Mar. 1994.
[33] W. Zaremba, I. Sutskever, and O. Vinyals. (2014). "Recurrent neural network regularization." [Online]. Available: https://arxiv.org/abs/1409.2329
[34] S. Hochreiter and J. Schmidhuber, "Long short-term memory," Neural Comput., vol. 9, no. 8, pp. 1735-1780, 1997.
[35] J. D. Wren, R. Bekeredjian, J. A. Stewart, R. V. Shohet, and H. R. Garner, "Knowledge discovery by automated identification and ranking of implicit relationships," Bioinformatics, vol. 20, no. 3, pp. 389-398, 2004.
[36] P. J. Werbos, "Backpropagation through time: What it does and how to do it," Proc. IEEE, vol. 78, no. 10, pp. 1550-1560, Oct. 1990.
[37] M. Wen et al., "Deep-learning-based drug-target interaction prediction," J. Proteome Res., vol. 16, no. 4, pp. 1401-1409, 2017.
[38] D.-S. Cao et al., "Computational prediction of drug-target interactions using chemical, biological, and network features," Mol. Inform., vol. 33, no. 10, pp. 669-681, 2014.
[39] E. Byvatov, U. Fechner, J. Sadowski, and G. Schneider, "Comparison of support vector machine and artificial neural network systems for drug/nondrug classification," J. Chem. Inf. Model., vol. 43, no. 6, pp. 1882-1889, 2003.
[40] X. Chen, M.-X. Liu, and G.-Y. Yan, "Drug-target interaction prediction by random walk on the heterogeneous network," Mol. BioSyst., vol. 8, no. 7, pp. 1970-1978, 2012.
[41] H. Liu, Y. Song, J. Guan, L. Luo, and Z. Zhuang, "Inferring new indications for approved drugs via random walk on drug-disease heterogenous networks," BMC Bioinf., vol. 17, no. 17, p. 539, 2016.
[42] M. Gori, A. Pacci, V. Roma, and I. Siena, "ItemRank: A random-walk based scoring algorithm for recommender engines," in Proc. IJCAI, vol. 7, Jan. 2007, pp. 2766-2771.
[43] D. P. Kingma and L. J. Ba, "A method for stochastic optimization," in Proc. Int. Conf. Learn. Represent. (ICLR), 2015, p. 13.
[44] D. Hristovski, T. Rindflesch, and B. Peterlin, "Using literature-based discovery to identify novel therapeutic approaches," Cardiovascular Hematolog. Agents Medicinal Chem. (Formerly Current Medicinal Chem.-Cardiovascular Hematolog. Agents), vol. 11, no. 1, pp. 14-24, 2013.
<img alt="img-4.jpeg" src="img-4.jpeg" /></p>
<p>SHENGTIAN SANG is currently pursuing the Ph.D. degree with the College of Computer Science and Technology, Dalian University of Technology, Dalian, China. His research interests include literature-based discovery, knowledge graph, and data mining.
<img alt="img-5.jpeg" src="img-5.jpeg" /></p>
<p>ZHIHAO YANG received the B.Sc., M.Sc., and Ph.D. degrees from the Dalian University of Technology, China, in 1997, 2003, and 2008, respectively. He is currently a Professor with the School of Computer Science and Technology, Dalian University of Technology. He has published over 30 research papers on topics in biomedical literature data mining. His current research interests include biomedical literature data mining, natural language processing, and machine learning. His research projects are funded by the National Natural Science Foundation of China and the Major State Research Development Program of China.
<img alt="img-6.jpeg" src="img-6.jpeg" /></p>
<p>XIAOXIA LIU is currently pursuing the Ph.D. degree with the College of Computer Science and Technology, Dalian University of Technology, Dalian, China. Her research interests include network science, data mining, and bioinformatics.
<img alt="img-7.jpeg" src="img-7.jpeg" /></p>
<p>LEI WANG received the Ph.D. degree from the Beijing Institute of Health Administration and Medical Information, China, in 2006. She is currently a Professor with the Beijing Institute of Health Administration and Medical Information. Her current research interests include biomedical literature data mining, medical science and technology information, and science and technology development strategy. She has published over 20 research papers and four monographs. Her research projects are funded by the National Natural Science Foundation of China and the Major State Research Development Program of China.
<img alt="img-8.jpeg" src="img-8.jpeg" /></p>
<p>HONGFEI LIN received the B.Sc. degree from Northeastern Normal University, in 1983, the M.Sc. degree from the Dalian University of Technology, in 1992, and the Ph.D. degree from Northeastern University, in 2000. He is currently a Professor with the School of Computer Science and Technology, Dalian University of Technology. He has published over 100 research papers in various journals, conferences, and books. His research interests include information retrieval, text mining, natural language processing, and effective computing. In recent years, he has focused on text mining for biomedical literatures.</p>
<p><img alt="img-9.jpeg" src="img-9.jpeg" /></p>
<p>JIAN WANG received the B.Sc., M.Sc., and Ph.D. degrees from the Dalian University of Technology, China, in 1997, 2003, and 2008, respectively. She is currently a Professor with the School of Computer Science and Technology, Dalian University of Technology. She has published over 30 research papers on topics in biomedical literature data mining. Her current research interests include biomedical literature data mining, natural language processing, and machine learning.
<img alt="img-10.jpeg" src="img-10.jpeg" /></p>
<p>MICHEL DUMONTIER was an Associate Professor of medicine (biomedical informatics) with the Stanford University School of Medicine, and also an Associate Professor of bioinformatics with Carleton University. He is currently a Distinguished Professor of data science with Maastricht University. He is best known for his work in biomedical ontologies, linked data, and biomedical knowledge discovery. His research has been funded by the Natural Sciences and Engineering Research Council, the Canada Foundation for Innovation, Mitacs Canada, the Ontario Ministry of Research, Innovation and Science, CANARIE, and the US National Institutes of Health. He has an h-index of over 30 and has authored over 125 scientific publications in journals and conferences. His research focuses on methods to represent knowledge on the web, with applications for drug discovery and personalized medicine.</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>${ }^{1}$ https://github.com/ShengtianSang/GrEDeL&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>