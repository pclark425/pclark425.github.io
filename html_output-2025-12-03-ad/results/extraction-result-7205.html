<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-7205 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-7205</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-7205</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-135.html">extraction-schema-135</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of graph-to-text representations used to convert graphs into textual sequences for language model training, including their description, encoding method, properties, datasets, models, evaluation metrics, performance outcomes, and any reported advantages or limitations.</div>
                <p><strong>Paper ID:</strong> paper-258740923</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2305.10037v3.pdf" target="_blank">Can Language Models Solve Graph Problems in Natural Language?</a></p>
                <p><strong>Paper Abstract:</strong> Large language models (LLMs) are increasingly adopted for a variety of tasks with implicit graphical structures, such as planning in robotics, multi-hop question answering or knowledge probing, structured commonsense reasoning, and more. While LLMs have advanced the state-of-the-art on these tasks with structure implications, whether LLMs could explicitly process textual descriptions of graphs and structures, map them to grounded conceptual spaces, and perform structured operations remains underexplored. To this end, we propose NLGraph (Natural Language Graph), a comprehensive benchmark of graph-based problem solving designed in natural language. NLGraph contains 29,370 problems, covering eight graph reasoning tasks with varying complexity from simple tasks such as connectivity and shortest path up to complex problems such as maximum flow and simulating graph neural networks. We evaluate LLMs (GPT-3/4) with various prompting approaches on the NLGraph benchmark and find that 1) language models do demonstrate preliminary graph reasoning abilities, 2) the benefit of advanced prompting and in-context learning diminishes on more complex graph problems, while 3) LLMs are also (un)surprisingly brittle in the face of spurious correlations in graph and problem settings. We then propose Build-a-Graph Prompting and Algorithmic Prompting, two instruction-based approaches to enhance LLMs in solving natural language graph problems. Build-a-Graph and Algorithmic prompting improve the performance of LLMs on NLGraph by 3.07% to 16.85% across multiple tasks and settings, while how to solve the most complicated graph reasoning tasks in our setup with language models remains an open research question. The NLGraph benchmark and evaluation code are available at https://github.com/Arthur-Heng/NLGraph.</p>
                <p><strong>Cost:</strong> 0.018</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e7205.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e7205.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of graph-to-text representations used to convert graphs into textual sequences for language model training, including their description, encoding method, properties, datasets, models, evaluation metrics, performance outcomes, and any reported advantages or limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Edge‑list (undirected, unweighted)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Textual edge‑list representation for undirected unweighted graphs</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Graphs are serialized into natural language by listing node indices and explicit edge tuples (i,j) in the prompt (e.g., "The nodes are numbered from 0 to 5, and the edges are: (3,4) (3,5) ..."). This representation is used across multiple NLGraph tasks (connectivity, cycle, Hamilton path, etc.).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>representation_name</strong></td>
                            <td>Edge-list (undirected, unweighted)</td>
                        </tr>
                        <tr>
                            <td><strong>representation_description</strong></td>
                            <td>A sequential natural-language encoding that states node numbering and then enumerates undirected edges as parenthesized node pairs (i,j) separated by spaces or commas; prompts often begin with a clarifying sentence such as "In an undirected graph, (i,j) means that node i and node j are connected with an undirected edge."</td>
                        </tr>
                        <tr>
                            <td><strong>representation_type</strong></td>
                            <td>sequential, token-based, lossless (when full node/edge set provided)</td>
                        </tr>
                        <tr>
                            <td><strong>encoding_method</strong></td>
                            <td>edge-list ordering (as given by the graph generator) — no specific traversal; edges are listed verbatim in text</td>
                        </tr>
                        <tr>
                            <td><strong>canonicalization</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>average_token_length</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td>NLGraph (standard and extended)</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Connectivity, Cycle, Hamilton Path, Topological Sort (undirected variants), general graph reasoning tasks</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>TEXT-DAVINCI-003 (default); also evaluated with GPT-3.5-TURBO, CODE-DAVINCI-002, GPT-4</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Large autoregressive language models (OpenAI text/code GPT variants). TEXT-DAVINCI-003 used as default evaluation model (black-box LLM), with temperature set to 0 for most prompts.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>Accuracy (↑) for true/false and validity; exact match for solution generation; partial-credit metrics where applicable</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>LLMs using these textual edge-list prompts achieved performance substantially above RANDOM on simple tasks: e.g., 37.33% to 57.82% higher than random baseline on connectivity and cycle tasks (with COT/COT+SC prompting). Exact values vary by task and prompting method.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_on_training</strong></td>
                            <td>Used as test-time prompts rather than pre-training; this representation enabled evaluation of LLM graph reasoning in natural-language form and demonstrated that LLMs can exploit explicitly listed edges to answer structural queries.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Sensitive to spurious correlations and prompt phraseology; LLMs can rely on non-structural cues (e.g., node mention frequency) rather than true traversal reasoning; not robust to increases in graph scale or to special cases (chain/clique) where simple heuristics fail.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_other</strong></td>
                            <td>Compared to other NLGraph encodings (e.g., weighted/typed edge variants), the basic edge-list is straightforward and sufficient for simple tasks but shows brittleness on harder algorithmic problems; see city/road instantiation and BAG augmentation experiments for contrasts.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Can Language Models Solve Graph Problems in Natural Language?', 'publication_date_yy_mm': '2023-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7205.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e7205.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of graph-to-text representations used to convert graphs into textual sequences for language model training, including their description, encoding method, properties, datasets, models, evaluation metrics, performance outcomes, and any reported advantages or limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Edge‑list (weighted)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Textual edge‑list representation with edge weights</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Graphs with numeric edge attributes (weights) are described in natural language by enumerating edges with associated weights in phrase form (e.g., "an edge between node 0 and node 1 with weight 3"). Used primarily for shortest-path tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>representation_name</strong></td>
                            <td>Weighted edge-list (natural language)</td>
                        </tr>
                        <tr>
                            <td><strong>representation_description</strong></td>
                            <td>Sequential NL serialization that lists edges along with numeric weight attributes using short, repeated English clauses (e.g., "An edge between node 0 and node 4 with weight 4, an edge between node 0 and node 3 with weight 3, ...").</td>
                        </tr>
                        <tr>
                            <td><strong>representation_type</strong></td>
                            <td>sequential, token-based, lossless (when all weights provided)</td>
                        </tr>
                        <tr>
                            <td><strong>encoding_method</strong></td>
                            <td>edge-list plus attribute-first serialization (edges paired with weight attributes in the natural-language sentence order produced by generator)</td>
                        </tr>
                        <tr>
                            <td><strong>canonicalization</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>average_token_length</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td>NLGraph (shortest path subsets, easy/medium/hard)</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Shortest Path (and any weight-dependent graph tasks)</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>TEXT-DAVINCI-003 (default); also GPT-3.5-TURBO, GPT-4, CODE-DAVINCI-002</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Autoregressive LLMs prompted with full natural-language weighted edge descriptions; chain-of-thought and other prompting methods applied.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>Exact match for optimal shortest path; partial-credit PC = 1/rank_i for non-optimal but valid solutions; also plain accuracy for path validity</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>LLMs achieved significant gains over RANDOM for shortest-path on easy/medium settings (e.g., COT and COT+SC gave 22.81% to 62.83% higher than RANDOM in some configurations); exact numbers depend on difficulty subset and prompting. Build-a-Graph prompting improved shortest-path accuracy by up to ~16.85% in reported experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_on_training</strong></td>
                            <td>Naively encoding weights in NL enables LLMs to perform path reasoning in natural language prompts; used to measure LLM ability rather than to train models.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Model accuracy drops as shortest-path length increases (sensitivity to scale); LLMs sometimes generate many tokens (verbosity) and can mis-rank paths; partial-credit metrics show degraded optimality on harder instances. Prompt instantiation (e.g., using 'city/road/distance') can alter performance (improves easy but can hurt hard cases).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_other</strong></td>
                            <td>Compared to unweighted edge-list, weighted lists require arithmetic/aggregation in reasoning and show larger gaps between simple and complex cases; Algorithmic and BAG prompting help but gains diminish on harder problems.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Can Language Models Solve Graph Problems in Natural Language?', 'publication_date_yy_mm': '2023-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7205.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e7205.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of graph-to-text representations used to convert graphs into textual sequences for language model training, including their description, encoding method, properties, datasets, models, evaluation metrics, performance outcomes, and any reported advantages or limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Directed capacity edge‑list</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Textual edge‑list with direction and capacity attributes (for flow)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Directed graphs with capacity attributes are encoded in natural language by listing directed edges and their capacities (e.g., "an edge from node 1 to node 0 with capacity 10"), used for maximum flow tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>representation_name</strong></td>
                            <td>Directed edge-list with capacities</td>
                        </tr>
                        <tr>
                            <td><strong>representation_description</strong></td>
                            <td>Sequential NL serialization enumerating directed edges and numeric capacity attributes in clause form (e.g., "an edge from node u to node v with capacity c").</td>
                        </tr>
                        <tr>
                            <td><strong>representation_type</strong></td>
                            <td>sequential, token-based, lossless (when the full capacity-labeled graph is provided)</td>
                        </tr>
                        <tr>
                            <td><strong>encoding_method</strong></td>
                            <td>edge-list ordering with attribute association (direction + capacity), as generated by the random graph generator</td>
                        </tr>
                        <tr>
                            <td><strong>canonicalization</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>average_token_length</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td>NLGraph (maximum flow tasks, easy/hard subsets)</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Maximum Flow</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>TEXT-DAVINCI-003 (default); GPT-3.5-TURBO; GPT-4</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Black-box LLMs prompted with directed capacity edge descriptions; evaluations used chain-of-thought, few-shot, and other prompting variants.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>Exact match for optimal plan; partial-credit PC = t/s (ratio of LLM solution flow t to optimal s) with 0 if t > s; accuracy for validity</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>LLMs showed mixed results: FEW-SHOT often outperformed COT+SC on maximum flow (paper reports FEW-SHOT > COT+SC on easy and hard subsets). Partial-credit scores (Table 10) show e.g., ZERO-SHOT PC ~25.65 on easy and ~10.37 on hard, with variations by prompting.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_on_training</strong></td>
                            <td>Encoding capacities in NL allowed evaluation of LLMs' ability to plan flow; Algorithmic prompting had limited effect on harder flow problems.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Very challenging for LLMs: advanced prompting sometimes ineffective or counterproductive; partial-credit indicates LLMs often produce suboptimal flows and can 'guess' solutions that appear high for some prompting variants but fail under self-consistency.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_other</strong></td>
                            <td>Compared against other prompting strategies, FEW-SHOT sometimes outperforms algorithmic/COT variants here, indicating LLMs struggle to produce reliable intermediate algorithmic steps on capacity-based directed tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Can Language Models Solve Graph Problems in Natural Language?', 'publication_date_yy_mm': '2023-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7205.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e7205.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of graph-to-text representations used to convert graphs into textual sequences for language model training, including their description, encoding method, properties, datasets, models, evaluation metrics, performance outcomes, and any reported advantages or limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Node embedding list (GNN input)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Textual list of per-node numerical embeddings for GNN simulation tasks</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Node features/embeddings are serialized inline in natural language (e.g., "Embeddings: node 0: [1,1], node 1: [0,1], ..."), and a textual rule describes the GNN update (e.g., sum of neighbors), asking the model to compute updated embeddings.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>representation_name</strong></td>
                            <td>Node-embedding list (vector serialization)</td>
                        </tr>
                        <tr>
                            <td><strong>representation_description</strong></td>
                            <td>A token-based natural-language serialization listing each node's vector embedding, typically as bracketed numeric lists per node, plus a textual specification of the message-passing/update rule (e.g., x_i^(l+1) = sum_{j in N_i} x_j^(l)).</td>
                        </tr>
                        <tr>
                            <td><strong>representation_type</strong></td>
                            <td>sequential, token-based, (potentially) lossless (if vectors are fully and exactly listed)</td>
                        </tr>
                        <tr>
                            <td><strong>encoding_method</strong></td>
                            <td>attribute-first serialization: node identifiers followed by explicit vector values in textual bracket notation; the update rule is provided in prose/math-like text</td>
                        </tr>
                        <tr>
                            <td><strong>canonicalization</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>average_token_length</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td>NLGraph (GNN simulation task)</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Graph Neural Network simulation / one-layer message passing</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>TEXT-DAVINCI-003 (default); CODE-DAVINCI-002; GPT-3.5-TURBO, GPT-4 (qualitative)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Autoregressive LLMs prompted to perform numeric vector addition according to the specified neighborhood sums.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>Exact match for node embedding outputs; partial-credit metrics: PC = percentage of nodes with correct embedding; RE = average relative error across embedding values</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>Chain-of-thought prompting substantially improved GNN simulation metrics (paper reports e.g., PC increased from ~13.61 in ZERO-SHOT to ~64.55 with COT in one table snapshot; RE and ACC also improved), indicating better numerical/structured reasoning with COT for this representation.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_on_training</strong></td>
                            <td>Used at test-time to probe LLMs' ability to perform vector arithmetic and message passing when graph and embeddings are provided in NL; COT markedly improved exact-match and partial-credit metrics for this task.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Numeric precision and formatting are sensitive; LLMs may produce verbosity or tokenization-induced numeric errors; vector operations scale poorly as embedding dimension and graph size increase; no canonical numeric formatting enforced in paper.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_other</strong></td>
                            <td>Compared to purely structural edge-list tasks, embedding lists require localized arithmetic and numerical fidelity; COT helps more here than in some combinatorial tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Can Language Models Solve Graph Problems in Natural Language?', 'publication_date_yy_mm': '2023-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7205.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e7205.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of graph-to-text representations used to convert graphs into textual sequences for language model training, including their description, encoding method, properties, datasets, models, evaluation metrics, performance outcomes, and any reported advantages or limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Real-world instantiation (city/road/distance)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Natural-language rephrasing of graph elements into domain-specific objects (cities/roads/distances)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A representation variant that replaces abstract graph vocabulary (nodes/edges/weights) with concrete, real-world terms (cities, roads, distances) to test whether grounding affects model performance.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>representation_name</strong></td>
                            <td>Domain‑instantiated graph description (city/road/distance)</td>
                        </tr>
                        <tr>
                            <td><strong>representation_description</strong></td>
                            <td>Same underlying graph encoded as natural language, but with node/edge/weight words replaced by domain terms ("node"->"city", "edge"->"road", "weight"->"distance"), preserving structural information but altering surface tokens.</td>
                        </tr>
                        <tr>
                            <td><strong>representation_type</strong></td>
                            <td>sequential, token-based, lossless (semantically equivalent if mapping is direct)</td>
                        </tr>
                        <tr>
                            <td><strong>encoding_method</strong></td>
                            <td>edge-list or weighted edge-list serialized with alternative lexical items</td>
                        </tr>
                        <tr>
                            <td><strong>canonicalization</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>average_token_length</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td>NLGraph (shortest path experiments; ablation in Appendix D)</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Shortest Path (comparison / robustness checks)</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>TEXT-DAVINCI-003</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Default LLM used to compare sensitivity to lexical instantiation of graph elements.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>Accuracy / exact match (same as shortest-path metrics)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>Paper reports mixed effects: model performance improved on the easy subset but dropped on the hard subset when using city/road/distance vocabulary versus abstract node/edge wording (Table 9), indicating lexical grounding changes difficulty in a non-uniform way.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_on_training</strong></td>
                            <td>No training effect — used as a prompt-variant to probe robustness; shows that surface lexical choices impact LLM reasoning in graph tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Instantiating graphs with domain-specific words can either help (by providing familiar concepts) or hurt (by changing prompt distribution relative to model pretraining); sensitivity is inconsistent across difficulty levels.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_other</strong></td>
                            <td>Compared against the abstract node/edge wording, the real-world instantiation can improve easy-case performance but degrade on hard cases, showing that representation wording matters for LLMs.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Can Language Models Solve Graph Problems in Natural Language?', 'publication_date_yy_mm': '2023-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7205.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e7205.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of graph-to-text representations used to convert graphs into textual sequences for language model training, including their description, encoding method, properties, datasets, models, evaluation metrics, performance outcomes, and any reported advantages or limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Build‑a‑Graph (BAG) prompting</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Build-a-Graph instruction-based prompting augmentation</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An instruction-level augmentation appended to graph descriptions that asks the LLM to first 'construct a graph with the nodes and edges' to encourage grounding the textual graph into an implicit conceptual representation before answering.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>representation_name</strong></td>
                            <td>Instructional augmentation: Build-a-Graph (BAG)</td>
                        </tr>
                        <tr>
                            <td><strong>representation_description</strong></td>
                            <td>Not a different serialization of the graph per se, but a short natural-language instruction appended to the graph description (e.g., "Let's construct a graph with the nodes and edges first.") intended to give the model a 'buffer zone' to internalize the structure.</td>
                        </tr>
                        <tr>
                            <td><strong>representation_type</strong></td>
                            <td>instructional augmentation (sequential + token-based)</td>
                        </tr>
                        <tr>
                            <td><strong>encoding_method</strong></td>
                            <td>append fixed natural-language instruction after the graph text; followed by the question</td>
                        </tr>
                        <tr>
                            <td><strong>canonicalization</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>average_token_length</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td>NLGraph (cycle, shortest path, other chosen tasks)</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Various NLGraph tasks (used as prompt augmentation)</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>TEXT-DAVINCI-003 (default); evaluated in combination with COT and few-shot</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Black-box LLMs prompted with BAG instruction plus the usual graph textualization and optional exemplars/COT.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>Accuracy, exact match, partial-credit PC</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>BAG prompting yielded performance gains on easier tasks (cycle, shortest path): reported improvement range of ~3.07% to 16.85% across tasks and settings (Table 5); BAG typically outperformed control instruction variants (e.g., sequences of dots or unrelated instructions).</td>
                        </tr>
                        <tr>
                            <td><strong>impact_on_training</strong></td>
                            <td>Acts at prompt-time to improve grounding; empirically improves LLM outputs on several easier graph tasks without model retraining.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Ineffective or marginal on the most complex tasks (e.g., Hamilton path); improvement might be partly due to additional computation/latency rather than semantic content, though ablations (dot placeholders and other instruction variants) indicate BAG's specific language helps more than length alone.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_other</strong></td>
                            <td>Outperforms generic 'think step-by-step' style or dot placeholders in many settings; compared to Algorithmic Prompting it is complementary — BAG helps grounding while Algorithmic Prompting provides procedural guidance.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Can Language Models Solve Graph Problems in Natural Language?', 'publication_date_yy_mm': '2023-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e7205.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e7205.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of graph-to-text representations used to convert graphs into textual sequences for language model training, including their description, encoding method, properties, datasets, models, evaluation metrics, performance outcomes, and any reported advantages or limitations.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Algorithmic Prompting</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Algorithmic instruction augmentation (recite relevant algorithm)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A prompting augmentation that prepends a brief description of an appropriate algorithm (e.g., "We can use a Depth‑First Search (DFS) algorithm...") before examples or the query to encourage procedural reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>representation_name</strong></td>
                            <td>Instructional augmentation: Algorithmic Prompting</td>
                        </tr>
                        <tr>
                            <td><strong>representation_description</strong></td>
                            <td>Prepend a short algorithmic sketch or stepwise description (in natural language) for the targeted graph task prior to in-context exemplars or the problem so the LLM 'recites' the procedure before solving.</td>
                        </tr>
                        <tr>
                            <td><strong>representation_type</strong></td>
                            <td>instructional augmentation (sequential + token-based)</td>
                        </tr>
                        <tr>
                            <td><strong>encoding_method</strong></td>
                            <td>prepend algorithm-recap sentences (e.g., describe DFS or Dijkstra) before examples or question in the prompt</td>
                        </tr>
                        <tr>
                            <td><strong>canonicalization</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>average_token_length</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>dataset_name</strong></td>
                            <td>NLGraph (shortest path, cycle, other tasks)</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Various NLGraph tasks (used as prompt augmentation)</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>TEXT-DAVINCI-003 (default); other LLMs in ablation</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Autoregressive LLMs provided with algorithmic text to encourage correct intermediate steps.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>Accuracy, exact match, partial-credit PC</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>Algorithmic prompting yielded improvements on easier tasks and helped in some settings, but gains were smaller or inconsistent on complex tasks; combined with COT sometimes produced modest gains (see Table 5).</td>
                        </tr>
                        <tr>
                            <td><strong>impact_on_training</strong></td>
                            <td>Prompt-time intervention that can nudge LLMs towards algorithmic solutions without fine-tuning; empowers generation of more structured intermediate steps on some problems.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Often ineffective or counterproductive on more complex graph reasoning tasks (topological sort, Hamilton path); LLMs may fail to learn/generate the correct intermediate steps despite being recited the algorithm.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_other</strong></td>
                            <td>Compared to BAG, Algorithmic Prompting focuses on procedural recall rather than grounding; jointly applied they can yield further gains on easier tasks but do not solve complex combinatorial failures.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Can Language Models Solve Graph Problems in Natural Language?', 'publication_date_yy_mm': '2023-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Mapping language models to grounded conceptual spaces <em>(Rating: 2)</em></li>
                <li>Language models of code are few-shot commonsense learners <em>(Rating: 2)</em></li>
                <li>Exploring the potential of large language models (llms) in learning on graphs <em>(Rating: 2)</em></li>
                <li>Teaching algorithmic reasoning via in-context learning <em>(Rating: 1)</em></li>
                <li>Recitation-augmented language models <em>(Rating: 1)</em></li>
                <li>Learning dynamic belief graphs to generalize on text-based games <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-7205",
    "paper_id": "paper-258740923",
    "extraction_schema_id": "extraction-schema-135",
    "extracted_data": [
        {
            "name_short": "Edge‑list (undirected, unweighted)",
            "name_full": "Textual edge‑list representation for undirected unweighted graphs",
            "brief_description": "Graphs are serialized into natural language by listing node indices and explicit edge tuples (i,j) in the prompt (e.g., \"The nodes are numbered from 0 to 5, and the edges are: (3,4) (3,5) ...\"). This representation is used across multiple NLGraph tasks (connectivity, cycle, Hamilton path, etc.).",
            "citation_title": "here",
            "mention_or_use": "use",
            "representation_name": "Edge-list (undirected, unweighted)",
            "representation_description": "A sequential natural-language encoding that states node numbering and then enumerates undirected edges as parenthesized node pairs (i,j) separated by spaces or commas; prompts often begin with a clarifying sentence such as \"In an undirected graph, (i,j) means that node i and node j are connected with an undirected edge.\"",
            "representation_type": "sequential, token-based, lossless (when full node/edge set provided)",
            "encoding_method": "edge-list ordering (as given by the graph generator) — no specific traversal; edges are listed verbatim in text",
            "canonicalization": null,
            "average_token_length": null,
            "dataset_name": "NLGraph (standard and extended)",
            "task_name": "Connectivity, Cycle, Hamilton Path, Topological Sort (undirected variants), general graph reasoning tasks",
            "model_name": "TEXT-DAVINCI-003 (default); also evaluated with GPT-3.5-TURBO, CODE-DAVINCI-002, GPT-4",
            "model_description": "Large autoregressive language models (OpenAI text/code GPT variants). TEXT-DAVINCI-003 used as default evaluation model (black-box LLM), with temperature set to 0 for most prompts.",
            "performance_metric": "Accuracy (↑) for true/false and validity; exact match for solution generation; partial-credit metrics where applicable",
            "performance_value": "LLMs using these textual edge-list prompts achieved performance substantially above RANDOM on simple tasks: e.g., 37.33% to 57.82% higher than random baseline on connectivity and cycle tasks (with COT/COT+SC prompting). Exact values vary by task and prompting method.",
            "impact_on_training": "Used as test-time prompts rather than pre-training; this representation enabled evaluation of LLM graph reasoning in natural-language form and demonstrated that LLMs can exploit explicitly listed edges to answer structural queries.",
            "limitations": "Sensitive to spurious correlations and prompt phraseology; LLMs can rely on non-structural cues (e.g., node mention frequency) rather than true traversal reasoning; not robust to increases in graph scale or to special cases (chain/clique) where simple heuristics fail.",
            "comparison_with_other": "Compared to other NLGraph encodings (e.g., weighted/typed edge variants), the basic edge-list is straightforward and sufficient for simple tasks but shows brittleness on harder algorithmic problems; see city/road instantiation and BAG augmentation experiments for contrasts.",
            "uuid": "e7205.0",
            "source_info": {
                "paper_title": "Can Language Models Solve Graph Problems in Natural Language?",
                "publication_date_yy_mm": "2023-05"
            }
        },
        {
            "name_short": "Edge‑list (weighted)",
            "name_full": "Textual edge‑list representation with edge weights",
            "brief_description": "Graphs with numeric edge attributes (weights) are described in natural language by enumerating edges with associated weights in phrase form (e.g., \"an edge between node 0 and node 1 with weight 3\"). Used primarily for shortest-path tasks.",
            "citation_title": "here",
            "mention_or_use": "use",
            "representation_name": "Weighted edge-list (natural language)",
            "representation_description": "Sequential NL serialization that lists edges along with numeric weight attributes using short, repeated English clauses (e.g., \"An edge between node 0 and node 4 with weight 4, an edge between node 0 and node 3 with weight 3, ...\").",
            "representation_type": "sequential, token-based, lossless (when all weights provided)",
            "encoding_method": "edge-list plus attribute-first serialization (edges paired with weight attributes in the natural-language sentence order produced by generator)",
            "canonicalization": null,
            "average_token_length": null,
            "dataset_name": "NLGraph (shortest path subsets, easy/medium/hard)",
            "task_name": "Shortest Path (and any weight-dependent graph tasks)",
            "model_name": "TEXT-DAVINCI-003 (default); also GPT-3.5-TURBO, GPT-4, CODE-DAVINCI-002",
            "model_description": "Autoregressive LLMs prompted with full natural-language weighted edge descriptions; chain-of-thought and other prompting methods applied.",
            "performance_metric": "Exact match for optimal shortest path; partial-credit PC = 1/rank_i for non-optimal but valid solutions; also plain accuracy for path validity",
            "performance_value": "LLMs achieved significant gains over RANDOM for shortest-path on easy/medium settings (e.g., COT and COT+SC gave 22.81% to 62.83% higher than RANDOM in some configurations); exact numbers depend on difficulty subset and prompting. Build-a-Graph prompting improved shortest-path accuracy by up to ~16.85% in reported experiments.",
            "impact_on_training": "Naively encoding weights in NL enables LLMs to perform path reasoning in natural language prompts; used to measure LLM ability rather than to train models.",
            "limitations": "Model accuracy drops as shortest-path length increases (sensitivity to scale); LLMs sometimes generate many tokens (verbosity) and can mis-rank paths; partial-credit metrics show degraded optimality on harder instances. Prompt instantiation (e.g., using 'city/road/distance') can alter performance (improves easy but can hurt hard cases).",
            "comparison_with_other": "Compared to unweighted edge-list, weighted lists require arithmetic/aggregation in reasoning and show larger gaps between simple and complex cases; Algorithmic and BAG prompting help but gains diminish on harder problems.",
            "uuid": "e7205.1",
            "source_info": {
                "paper_title": "Can Language Models Solve Graph Problems in Natural Language?",
                "publication_date_yy_mm": "2023-05"
            }
        },
        {
            "name_short": "Directed capacity edge‑list",
            "name_full": "Textual edge‑list with direction and capacity attributes (for flow)",
            "brief_description": "Directed graphs with capacity attributes are encoded in natural language by listing directed edges and their capacities (e.g., \"an edge from node 1 to node 0 with capacity 10\"), used for maximum flow tasks.",
            "citation_title": "here",
            "mention_or_use": "use",
            "representation_name": "Directed edge-list with capacities",
            "representation_description": "Sequential NL serialization enumerating directed edges and numeric capacity attributes in clause form (e.g., \"an edge from node u to node v with capacity c\").",
            "representation_type": "sequential, token-based, lossless (when the full capacity-labeled graph is provided)",
            "encoding_method": "edge-list ordering with attribute association (direction + capacity), as generated by the random graph generator",
            "canonicalization": null,
            "average_token_length": null,
            "dataset_name": "NLGraph (maximum flow tasks, easy/hard subsets)",
            "task_name": "Maximum Flow",
            "model_name": "TEXT-DAVINCI-003 (default); GPT-3.5-TURBO; GPT-4",
            "model_description": "Black-box LLMs prompted with directed capacity edge descriptions; evaluations used chain-of-thought, few-shot, and other prompting variants.",
            "performance_metric": "Exact match for optimal plan; partial-credit PC = t/s (ratio of LLM solution flow t to optimal s) with 0 if t &gt; s; accuracy for validity",
            "performance_value": "LLMs showed mixed results: FEW-SHOT often outperformed COT+SC on maximum flow (paper reports FEW-SHOT &gt; COT+SC on easy and hard subsets). Partial-credit scores (Table 10) show e.g., ZERO-SHOT PC ~25.65 on easy and ~10.37 on hard, with variations by prompting.",
            "impact_on_training": "Encoding capacities in NL allowed evaluation of LLMs' ability to plan flow; Algorithmic prompting had limited effect on harder flow problems.",
            "limitations": "Very challenging for LLMs: advanced prompting sometimes ineffective or counterproductive; partial-credit indicates LLMs often produce suboptimal flows and can 'guess' solutions that appear high for some prompting variants but fail under self-consistency.",
            "comparison_with_other": "Compared against other prompting strategies, FEW-SHOT sometimes outperforms algorithmic/COT variants here, indicating LLMs struggle to produce reliable intermediate algorithmic steps on capacity-based directed tasks.",
            "uuid": "e7205.2",
            "source_info": {
                "paper_title": "Can Language Models Solve Graph Problems in Natural Language?",
                "publication_date_yy_mm": "2023-05"
            }
        },
        {
            "name_short": "Node embedding list (GNN input)",
            "name_full": "Textual list of per-node numerical embeddings for GNN simulation tasks",
            "brief_description": "Node features/embeddings are serialized inline in natural language (e.g., \"Embeddings: node 0: [1,1], node 1: [0,1], ...\"), and a textual rule describes the GNN update (e.g., sum of neighbors), asking the model to compute updated embeddings.",
            "citation_title": "here",
            "mention_or_use": "use",
            "representation_name": "Node-embedding list (vector serialization)",
            "representation_description": "A token-based natural-language serialization listing each node's vector embedding, typically as bracketed numeric lists per node, plus a textual specification of the message-passing/update rule (e.g., x_i^(l+1) = sum_{j in N_i} x_j^(l)).",
            "representation_type": "sequential, token-based, (potentially) lossless (if vectors are fully and exactly listed)",
            "encoding_method": "attribute-first serialization: node identifiers followed by explicit vector values in textual bracket notation; the update rule is provided in prose/math-like text",
            "canonicalization": null,
            "average_token_length": null,
            "dataset_name": "NLGraph (GNN simulation task)",
            "task_name": "Graph Neural Network simulation / one-layer message passing",
            "model_name": "TEXT-DAVINCI-003 (default); CODE-DAVINCI-002; GPT-3.5-TURBO, GPT-4 (qualitative)",
            "model_description": "Autoregressive LLMs prompted to perform numeric vector addition according to the specified neighborhood sums.",
            "performance_metric": "Exact match for node embedding outputs; partial-credit metrics: PC = percentage of nodes with correct embedding; RE = average relative error across embedding values",
            "performance_value": "Chain-of-thought prompting substantially improved GNN simulation metrics (paper reports e.g., PC increased from ~13.61 in ZERO-SHOT to ~64.55 with COT in one table snapshot; RE and ACC also improved), indicating better numerical/structured reasoning with COT for this representation.",
            "impact_on_training": "Used at test-time to probe LLMs' ability to perform vector arithmetic and message passing when graph and embeddings are provided in NL; COT markedly improved exact-match and partial-credit metrics for this task.",
            "limitations": "Numeric precision and formatting are sensitive; LLMs may produce verbosity or tokenization-induced numeric errors; vector operations scale poorly as embedding dimension and graph size increase; no canonical numeric formatting enforced in paper.",
            "comparison_with_other": "Compared to purely structural edge-list tasks, embedding lists require localized arithmetic and numerical fidelity; COT helps more here than in some combinatorial tasks.",
            "uuid": "e7205.3",
            "source_info": {
                "paper_title": "Can Language Models Solve Graph Problems in Natural Language?",
                "publication_date_yy_mm": "2023-05"
            }
        },
        {
            "name_short": "Real-world instantiation (city/road/distance)",
            "name_full": "Natural-language rephrasing of graph elements into domain-specific objects (cities/roads/distances)",
            "brief_description": "A representation variant that replaces abstract graph vocabulary (nodes/edges/weights) with concrete, real-world terms (cities, roads, distances) to test whether grounding affects model performance.",
            "citation_title": "here",
            "mention_or_use": "use",
            "representation_name": "Domain‑instantiated graph description (city/road/distance)",
            "representation_description": "Same underlying graph encoded as natural language, but with node/edge/weight words replaced by domain terms (\"node\"-&gt;\"city\", \"edge\"-&gt;\"road\", \"weight\"-&gt;\"distance\"), preserving structural information but altering surface tokens.",
            "representation_type": "sequential, token-based, lossless (semantically equivalent if mapping is direct)",
            "encoding_method": "edge-list or weighted edge-list serialized with alternative lexical items",
            "canonicalization": null,
            "average_token_length": null,
            "dataset_name": "NLGraph (shortest path experiments; ablation in Appendix D)",
            "task_name": "Shortest Path (comparison / robustness checks)",
            "model_name": "TEXT-DAVINCI-003",
            "model_description": "Default LLM used to compare sensitivity to lexical instantiation of graph elements.",
            "performance_metric": "Accuracy / exact match (same as shortest-path metrics)",
            "performance_value": "Paper reports mixed effects: model performance improved on the easy subset but dropped on the hard subset when using city/road/distance vocabulary versus abstract node/edge wording (Table 9), indicating lexical grounding changes difficulty in a non-uniform way.",
            "impact_on_training": "No training effect — used as a prompt-variant to probe robustness; shows that surface lexical choices impact LLM reasoning in graph tasks.",
            "limitations": "Instantiating graphs with domain-specific words can either help (by providing familiar concepts) or hurt (by changing prompt distribution relative to model pretraining); sensitivity is inconsistent across difficulty levels.",
            "comparison_with_other": "Compared against the abstract node/edge wording, the real-world instantiation can improve easy-case performance but degrade on hard cases, showing that representation wording matters for LLMs.",
            "uuid": "e7205.4",
            "source_info": {
                "paper_title": "Can Language Models Solve Graph Problems in Natural Language?",
                "publication_date_yy_mm": "2023-05"
            }
        },
        {
            "name_short": "Build‑a‑Graph (BAG) prompting",
            "name_full": "Build-a-Graph instruction-based prompting augmentation",
            "brief_description": "An instruction-level augmentation appended to graph descriptions that asks the LLM to first 'construct a graph with the nodes and edges' to encourage grounding the textual graph into an implicit conceptual representation before answering.",
            "citation_title": "here",
            "mention_or_use": "use",
            "representation_name": "Instructional augmentation: Build-a-Graph (BAG)",
            "representation_description": "Not a different serialization of the graph per se, but a short natural-language instruction appended to the graph description (e.g., \"Let's construct a graph with the nodes and edges first.\") intended to give the model a 'buffer zone' to internalize the structure.",
            "representation_type": "instructional augmentation (sequential + token-based)",
            "encoding_method": "append fixed natural-language instruction after the graph text; followed by the question",
            "canonicalization": null,
            "average_token_length": null,
            "dataset_name": "NLGraph (cycle, shortest path, other chosen tasks)",
            "task_name": "Various NLGraph tasks (used as prompt augmentation)",
            "model_name": "TEXT-DAVINCI-003 (default); evaluated in combination with COT and few-shot",
            "model_description": "Black-box LLMs prompted with BAG instruction plus the usual graph textualization and optional exemplars/COT.",
            "performance_metric": "Accuracy, exact match, partial-credit PC",
            "performance_value": "BAG prompting yielded performance gains on easier tasks (cycle, shortest path): reported improvement range of ~3.07% to 16.85% across tasks and settings (Table 5); BAG typically outperformed control instruction variants (e.g., sequences of dots or unrelated instructions).",
            "impact_on_training": "Acts at prompt-time to improve grounding; empirically improves LLM outputs on several easier graph tasks without model retraining.",
            "limitations": "Ineffective or marginal on the most complex tasks (e.g., Hamilton path); improvement might be partly due to additional computation/latency rather than semantic content, though ablations (dot placeholders and other instruction variants) indicate BAG's specific language helps more than length alone.",
            "comparison_with_other": "Outperforms generic 'think step-by-step' style or dot placeholders in many settings; compared to Algorithmic Prompting it is complementary — BAG helps grounding while Algorithmic Prompting provides procedural guidance.",
            "uuid": "e7205.5",
            "source_info": {
                "paper_title": "Can Language Models Solve Graph Problems in Natural Language?",
                "publication_date_yy_mm": "2023-05"
            }
        },
        {
            "name_short": "Algorithmic Prompting",
            "name_full": "Algorithmic instruction augmentation (recite relevant algorithm)",
            "brief_description": "A prompting augmentation that prepends a brief description of an appropriate algorithm (e.g., \"We can use a Depth‑First Search (DFS) algorithm...\") before examples or the query to encourage procedural reasoning.",
            "citation_title": "here",
            "mention_or_use": "use",
            "representation_name": "Instructional augmentation: Algorithmic Prompting",
            "representation_description": "Prepend a short algorithmic sketch or stepwise description (in natural language) for the targeted graph task prior to in-context exemplars or the problem so the LLM 'recites' the procedure before solving.",
            "representation_type": "instructional augmentation (sequential + token-based)",
            "encoding_method": "prepend algorithm-recap sentences (e.g., describe DFS or Dijkstra) before examples or question in the prompt",
            "canonicalization": null,
            "average_token_length": null,
            "dataset_name": "NLGraph (shortest path, cycle, other tasks)",
            "task_name": "Various NLGraph tasks (used as prompt augmentation)",
            "model_name": "TEXT-DAVINCI-003 (default); other LLMs in ablation",
            "model_description": "Autoregressive LLMs provided with algorithmic text to encourage correct intermediate steps.",
            "performance_metric": "Accuracy, exact match, partial-credit PC",
            "performance_value": "Algorithmic prompting yielded improvements on easier tasks and helped in some settings, but gains were smaller or inconsistent on complex tasks; combined with COT sometimes produced modest gains (see Table 5).",
            "impact_on_training": "Prompt-time intervention that can nudge LLMs towards algorithmic solutions without fine-tuning; empowers generation of more structured intermediate steps on some problems.",
            "limitations": "Often ineffective or counterproductive on more complex graph reasoning tasks (topological sort, Hamilton path); LLMs may fail to learn/generate the correct intermediate steps despite being recited the algorithm.",
            "comparison_with_other": "Compared to BAG, Algorithmic Prompting focuses on procedural recall rather than grounding; jointly applied they can yield further gains on easier tasks but do not solve complex combinatorial failures.",
            "uuid": "e7205.6",
            "source_info": {
                "paper_title": "Can Language Models Solve Graph Problems in Natural Language?",
                "publication_date_yy_mm": "2023-05"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Mapping language models to grounded conceptual spaces",
            "rating": 2
        },
        {
            "paper_title": "Language models of code are few-shot commonsense learners",
            "rating": 2
        },
        {
            "paper_title": "Exploring the potential of large language models (llms) in learning on graphs",
            "rating": 2
        },
        {
            "paper_title": "Teaching algorithmic reasoning via in-context learning",
            "rating": 1
        },
        {
            "paper_title": "Recitation-augmented language models",
            "rating": 1
        },
        {
            "paper_title": "Learning dynamic belief graphs to generalize on text-based games",
            "rating": 1
        }
    ],
    "cost": 0.01819275,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Can Language Models Solve Graph Problems in Natural Language?
6 Jan 2024</p>
<p>Heng Wang 
Xi'an Jiaotong University</p>
<p>Shangbin Feng shangbin@cs.washington.edu 
University of Washington</p>
<p>Tianxing He 
University of Washington</p>
<p>Zhaoxuan Tan 
University of Notre Dame</p>
<p>Xiaochuang Han 
University of Washington</p>
<p>Yulia Tsvetkov 
University of Washington</p>
<p>Can Language Models Solve Graph Problems in Natural Language?
6 Jan 20247024759FCD7ED1897B394240DFBCAEE9arXiv:2305.10037v3[cs.CL]
Large language models (LLMs) are increasingly adopted for a variety of tasks with implicit graphical structures, such as planning in robotics, multi-hop question answering or knowledge probing, structured commonsense reasoning, and more.While LLMs have advanced the state-of-the-art on these tasks with structure implications, whether LLMs could explicitly process textual descriptions of graphs and structures, map them to grounded conceptual spaces, and perform structured operations remains underexplored.To this end, we propose NLGraph (Natural Language Graph), a comprehensive benchmark of graph-based problem solving designed in natural language.NLGraph contains 29,370 problems, covering eight graph reasoning tasks with varying complexity from simple tasks such as connectivity and shortest path up to complex problems such as maximum flow and simulating graph neural networks.We evaluate LLMs (GPT-3/4) with various prompting approaches on the NLGraph benchmark and find that 1) language models do demonstrate preliminary graph reasoning abilities, 2) the benefit of advanced prompting and in-context learning diminishes on more complex graph problems, while 3) LLMs are also (un)surprisingly brittle in the face of spurious correlations in graph and problem settings.We then propose Build-a-Graph Prompting and Algorithmic Prompting, two instruction-based approaches to enhance LLMs in solving natural language graph problems.Build-a-Graph and Algorithmic prompting improve the performance of LLMs on NLGraph by 3.07% to 16.85% across multiple tasks and settings, while how to solve the most complicated graph reasoning tasks in our setup with language models remains an open research question.The NLGraph benchmark and evaluation code are available at https://github.com/Arthur-Heng/NLGraph.</p>
<p>Introduction</p>
<p>Originally designed for textual data, large language models (LLMs) are increasingly leveraged for tasks beyond language processing.In robotics and planning, LLMs are adopted to guide agents through structured environments [Huang et al., 2022, Andreas, 2022].In theory-of-mind reasoning, LLMs are required to maintain and update local and global graphs that reflect the beliefs of different characters [Adhikari et al., 2020, Ammanabrolu andRiedl, 2021].In structured commonsense reasoning, LLMs are expected to generate graph-based action plans to achieve objectives with diversified prerequisites [Tandon et al., 2019, Madaan et al., 2022].In multi-hop question answering, LLMs implicitly find connections and paths among a vast network of entities and concepts [Creswell et al., 2023].Together these works demonstrate that LLMs are widely adopted for tasks with implicit graphical structures while achieving preliminary success.However, one underlying yet crucial question remains underexplored: Can LLMs reason with graphs?More concretely, are LLMs capable of mapping textual descriptions of graphs and structures to grounded conceptual spaces and solving 1. LLMs do possess preliminary graph reasoning abilities.Specifically, large language models demonstrate an impressive level of performance that is 37.33% to 57.82% above the random baseline on simple graph reasoning tasks such as connectivity, cycle, and shortest path.With chain-of-thought prompting, LLMs could generate intermediate steps that are sound and accurate while further improving task performance.2. The benefit of advanced prompting methods diminishes with complex problems.On one hand, chain-of-thought [Wei et al., 2022], least-to-most [Zhou et al., 2023], and self-consistency [Wang et al., 2023] successfully enhance the graph reasoning abilities of LLMs on simple tasks such as cycle and shortest path.On the other hand, these approaches are mostly ineffective, even counterproductive in certain settings, on more complex graph reasoning problems such as topological sort and Hamilton path.3. Learning from examples did not happen on complex graph reasoning problems.While in-context learning is widely credited for teaching LLMs to learn from examples [Brown et al., 2020], its benefit on more advanced graph reasoning tasks is unclear: Few-shot in-context learning fails to improve over zero-shot prompting across multiple tasks, while increasing the number of exemplars may even be counterproductive for tasks such as Hamilton path.4. LLMs are (un)surprisingly brittle to spurious correlations in problem settings.We find that in two special cases in the connectivity task (chain and clique), LLMs perform much worse than the general dataset with a performance drop of more than 40% across various settings.This indicates that large language models are implicitly relying on certain spurious correlations (for example, use node mention frequency to determine connectivity), falling short of performing robust structured reasoning in graph-based contexts.</p>
<p>To improve large language models as better graph reasoners, we propose two instruction-based prompting approaches to better elicit the graph reasoning abilities of large language models.Builda-Graph prompting encourages LLMs to map the textual descriptions of graphs and structures to grounded conceptual spaces [Patel and Pavlick, 2022] before tackling the specific problem through a one-sentence instruction, while Algorithmic prompting instructs LLMs to revisit the algorithmic steps for a given task before learning from in-context exemplars.Experiments demonstrate that builda-graph and algorithmic prompting successfully empower LLMs to better tackle graph reasoning problems, resulting in 3.07% to 16.85% performance gains across multiple tasks, while the most complicated graph reasoning problems remain an open research question.</p>
<p>The NLGraph Benchmark</p>
<p>To examine whether language models are capable of reasoning with graphs and structures, we curate and propose the Natural Language Graph (NLGraph) benchmark.Specifically, we first employ a random graph generator to generate graphs and structures while controlling for the network size, graph sparsity, and more.We then adopt the generated graphs as bases to synthetically generate problems for eight graph-based reasoning tasks with varying algorithmic difficulties.We control for</p>
<p>In an undirected graph, (i,j) means that node i and node j are connected with an undirected edge.</p>
<p>The nodes are numbered from 0 to 5, and the edges are: (3,4) (3,5) (1,0) (2,5) (2,0) Q: Is there a cycle in this graph?</p>
<p>Cycle</p>
<p>In a directed graph with 5 nodes numbered from 0 to 4: node 0 should be visited before node 4, ... Q: Can all the nodes be visited?Give the solution.</p>
<p>Topological Sort</p>
<p>In an undirected graph, the nodes are numbered from 0 to 4, and the edges are: an edge between node 0 and node 1 with weight 2, ... Q: Give the shortest path from node 0 to node 4.</p>
<p>Shortest Path</p>
<p>In a directed graph, the nodes are numbered from 0 to 3, and the edges are: an edge from node 1 to node 0 with capacity 10, an edge from node 0 to node 2 with capacity 6, an edge from node 2 to node 3 with capacity 4. Q: What is the maximum flow from node 1 to node 3?</p>
<p>Maximum Flow</p>
<p>There are 4 job applicants numbered from 0 to 3, and 5 jobs numbered from 0 to 4. Each applicant is interested in some of the jobs.Each job can only accept one applicant and a job applicant can be appointed for only one job.</p>
<p>Applicant 0 is interested in job 4, ... Q: Find an assignment of jobs to applicants in such that the maximum number of applicants find the job they are interested in.</p>
<p>Bipartite Graph Matching</p>
<p>In an undirected graph, (i,j) means that node i and node j are connected with an undirected edge.</p>
<p>The nodes are numbered from 0 to 4, and the edges are: (4,2) (0,4) (4,3) (0,1) (0,2) (4,1) (2,3) Q: Is there a path in this graph that visits every node exactly once?If yes, give the path.Note that in a path, adjacent nodes must be connected with edges.In an undirected graph, the nodes are numbered from 0 to 4, and every node has an embedding.(i,j) means that node i and node j are connected with an undirected edge.Embeddings: node 0: [1,1], …</p>
<p>The edges are: (0,1) ... In a simple graph convolution layer, each node's embedding is updated by the sum of its neighbors' embeddings.</p>
<p>Q: What's the embedding of each node after one layer of simple graph convolution layer?
8. GNN 3 2 0 1 4 1 1 1 1 0 1 0 1 0 1 0 1 1 1 1 1 0 1 0 1 3 2 0 1 4 1 1 0 1 0 1 1 1 0 1 3 2 0 1 4 3 2 0 1 4
Figure 1: Overview of the NLGraph Benchmark, featuring eight tasks with varying complexity.We show an intuitive figure representing each task along with the example natural language prompts being passed to the LLMs.</p>
<p>problem difficulty within each of the eight tasks, resulting in easy, medium, and hard subsets in each graph reasoning task to enable difficulty scaling and fine-grained analysis.</p>
<p>Random Graph Generator</p>
<p>We first employ a general-purpose random graph generator to generate base graphs while using the number of nodes and graph density to control for complexity.Formally, to generate a graph G = {V, E} where V and E denote the set of nodes and edges, we specify the number of nodes n, thus V = {v 1 , v 2 , . . ., v n }, and |V| = n.We then specify the edge probability p such that all the edges are generated according to P (e ij ∈ E) = p, where e ij is an edge from v i to v j .The edges could be directed or undirected depending on the task.We use varying n and p values to control for the complexity of the random graph structure.Building on top of these generated base graphs, we also adopt graph edits and other difficulty control factors tailored for each task.</p>
<p>Tasks</p>
<p>Armed with the general-purpose random graph generator, we adapt the synthetically generated graphs to eight graph reasoning tasks with varying complexity and describe the problem setups in natural language.Specifically, we first generate easy, medium, and hard subsets of base graphs for each task by controlling for node amount and graph sparsity.We then adapt or edit the base graphs for each task and design queries accordingly.We present an overview of the NLGraph benchmark with specific natural language instructions in Figure 1.</p>
<p>• Task 1: Connectivity In an undirected graph G = {V, E}, two nodes u and v are connected if there exists a sequence of edges from node u to node v in E. We randomly select two nodes in the base graphs u, v ∈ V to ask whether node u and node v are connected with a true/false question.We retain a balanced set of questions where half of the node pairs are connected and the other half are not connected by discarding additional questions.• Task 2: Cycle In an undirected graph G = {V, E}, a cycle is a non-empty trail (e 1 , e 2 , . . ., e n ) with a node sequence (v 1 , v 2 , . . ., v n , v 1 ).We present an undirected graph G = {V, E} to ask whether there exists a cycle through true/false questions.We retain base graphs without cycles as the False subset, while we randomly add edges to these base graphs to generate graphs with cycles as the True subset.We retain a balanced set of cyclic and noncyclic graphs in the dataset.• Task 3: Topological Sort A topological sort of a directed graph is a linear ordering of its nodes such that for every directed edge (u, v) from node u to node v, u comes before v in the ordering.The task is to find a valid topological sort given a directed graph and there could be multiple valid solutions.We ask LLMs to generate a valid topological sort for the given directed graph and employ an external program to examine its correctness.• Task 4: Shortest Path The shortest path between two nodes is the path with the sum of edge weights minimized.Given an undirected graph G = {V, E}, a positive weight w for each edge, and two nodes u and v, the task is to find the shortest path between node u and node v and its corresponding path length.We filter the generated base graphs by specifying that the number of nodes on the correct shortest path is as least ℓ, where ℓ is chosen from ℓ min to ℓ max for each question to sever as an additional difficulty control measure.We adopt two metrics: exact match, where the LLM solution is a valid path and optimal, and partial credit, where the LLM solution is valid and is the rank i -th shortest among all the possible paths (i.e. the number of shorter paths plus one).</p>
<p>The partial credit score for each problem can be formulated as PC = 1/rank i .• Task 5: Maximum Flow Let G = {V, E} be a network with two nodes s, t ∈ V being the source and the sink.Each edge is associated with a capacity c, the maximum amount of flow that can pass through the edge.We ask LLMs to generate a plan to route as much flow as possible from the source to the sink.We evaluate in both exact match with the optimal plan and partial credit for this task, where partial credit can be formulated as
PC = t/s, if t ≤ s 0, if t &gt; s
, where s is the flow value under the optimal plan, and t is the flow value of the solution generated by LLMs.• Task 6: Bipartite Graph Matching In an undirected graph G = {V, E}, a matching is a set of edges without common nodes.A bipartite graph is a graph whose nodes can be divided into two disjoint sets U and V, and in each set no nodes are adjacent to each other.Given a bipartite graph, the task is to find the matching that maximizes the number of edges.We use an external program to evaluate whether the solution generated by LLMs is valid and optimal.• Task 7: Hamilton Path In an undirected graph, a Hamilton path is a path that visits every node exactly once.Given an undirected graph G = {V, E}, the task is to find a valid Hamilton path.We filter generated base graphs to ensure that at least one valid Hamilton path exists and use an external program to evaluate the LLM solution.• Task 8: Graph Neural Networks Given an undirected graph G = {V, E}, and a two-dimension node embedding x i for each node, the task is to perform ℓ layers of message passing, i.e. to update the node embedding with the sum of all the neighbors' embeddings.Formally, x
(ℓ+1) i = j∈Ni x (ℓ)
j where N i denotes the neighborhood of node i and (ℓ) denotes the ℓ-th layer.We use an exact match with the correct node embeddings and two types of partial credits for this task.Specifically, the first partial credit is the percentage of the nodes whose embedding is correct (PC), and the second is the average of all the values' relative errors for the standard answer (RE).The relative error is formulated as RE = |x−y| max(x,y) , where x is the value generated by LLMs and y is the value in the standard answer, averaged across all embedding dimensions.</p>
<p>Benchmark Statistics</p>
<p>Using the above methodology, we generate the NLGraph benchmark with 5,902 problems in a standard version and 29,370 problems in an extended version.Intuitively easier tasks, including connectivity, cycle, and topological sort problems, are further divided into easy, medium, and hard subsets based on graph size, sparsity, among other difficulty control factors.More algorithmically advanced tasks, including shortest path, maximum flow, bipartite graph matching, Hamilton path, and graph neural networks problems, are divided into easy and hard subsets.We present benchmark statistics in Table 1.Accuracy (whether the true/false answer is correct, whether the proposed solution is valid) is the default evaluation metric, while tasks 4, task 5, and task 8 have additional partial-credit metrics aforementioned.We envision NLGraph as a comprehensive testbed for graph and structured reasoning for large language models.</p>
<p>Experimental Settings</p>
<p>Based on the NLGraph benchmark, we aim to investigate whether language models can solve graph algorithm problems in natural language by evaluating large language models and different prompting approaches.</p>
<p>Baselines We adopt a wide range of prompting approaches as baselines.Specifically, zero-shot prompting (ZERO-SHOT), few-shot in-context learning (FEW-SHOT) [Brown et al., 2020], chain-ofthought prompting (COT) [Wei et al., 2022], zero-shot chain-of-thought (0-COT) [Kojima et al., 2022], least-to-most (LTM) [Zhou et al., 2023], and self-consistency (SC) [Wang et al., 2023] are leveraged to tackle various graph reasoning tasks in the NLGraph benchmark.</p>
<p>We also adopt a RANDOM baseline: for true/false questions such as connectivity and cycle, we use RANDOM to denote a baseline that randomly selects an answer from true and false with an expected accuracy of 50%; For the shortest path task, RANDOM denotes a baseline that randomly selects a valid path between the query node pair.For the maximum flow task, RANDOM denotes a baseline that randomly selects a value between 0 and the sum of all the edges' capacities.The performance comparison between different prompting techniques and the RANDOM baseline could indicate whether LLMs are capable of performing graph reasoning instead of giving randomly generated answers.</p>
<p>Models and Settings</p>
<p>We use TEXT-DAVINCI-003 as the default large language model, while we also evaluate three additional LLMs (GPT-3.5-TURBO,CODE-DAVINCI-002, and GPT-4), presenting results in Appendix E. For all baselines except self-consistency, we set temperature τ = 0; For self-consistency prompting, we sample five chain-of-thought responses with temperature τ = 0.7.</p>
<p>For few-shot prompting techniques (i.e., FEW-SHOT, COT, LTM, and COT+SC), the input prompt includes k exemplars selected from the extended version before the problem of interest.For the connectivity task and cycle task, we set k to 4, for the GNN task, we set k to 1 due to the context size limit, while for other tasks k is 5.We evaluate LLMs and various prompting techniques on the standard set of NLGraph due to monetary costs, while we encourage future research to leverage the extended version for enhanced evaluation.</p>
<p>Results</p>
<p>LLMs Have (Preliminary) Graph Reasoning Abilities</p>
<p>We first find that on intuitively simple graph reasoning tasks, large language models achieve impressive performance and demonstrate preliminary graph reasoning abilities.As demonstrated in Table 2, LLM performance on the connectivity, cycle, and shortest path tasks is significantly better than the RANDOM baseline, indicating that LLMs are not giving random answers and they do have preliminary graph reasoning abilities.In the first two tasks with true/false questions, LLM performance is 37.33% to 57.82% higher than random with COT or COT+SC prompting.The performance is also impressive FEW-SHOT prompting outperforms COT+SC prompting on both easy and hard subsets, suggesting that LLMs fall short of generating valid intermediate steps to solve the more complex graph reasoning problem.Together these results demonstrate that advanced prompting is ineffective for advanced graph reasoning.</p>
<p>in the ZERO-SHOT setting, as the accuracy is 33.81% and 23.33% higher on the connectivity and shortest path task than random even without any exemplars and chain-of-thought reasoning.Though the shortest path is intuitively harder than the first two true/false tasks since it requires generating the specific shortest path in the response, LLM combined with COT and COT+SC achieves an accuracy 22.81% to 62.83% higher than RANDOM.Together these results demonstrate that large language models do possess preliminary abilities to process graphs and structures in input texts.Table 2 shows that advanced prompting techniques such as chain-of-thought [Wei et al., 2022] and self-consistency [Wang et al., 2023] successfully improve performance on simple graph reasoning tasks.For the task of simulating graph neural networks (Table 3), chainof-thought also significantly improves model performance.However, these approaches can be ineffective, even counterproductive on more complex graph reasoning tasks.From the results on the topological sort and maximum flow task (Figure 2), we observe that COT, COT+SC, and LTM prompting generally underperform FEW-SHOT prompting.We believe this may be because LLMs fail to learn the correct way to generate intermediate steps in the face of complex graph reasoning tasks.This casts doubt on the generalizability of COT, LTM, and self-consistency to more advanced graph reasoning problems.</p>
<p>Mixed</p>
<p>In-Context Learning Can be Counterproductive</p>
<p>Although in-context learning is widely attributed to teaching LLMs to learn from in-context exemplars [Brown et al., 2020], we observe that few-shot in-context learning fails to improve LLM performance over complex graph reasoning problems.For tasks such as Hamilton path and bipartite graph matching (Figure 3), zero-shot prompting generally outperforms few-shot learning with in-context exemplars.The results suggest that LLMs fail to learn from the in-context exemplars when the problem involves hundreds of graph-based reasoning steps.In-context exemplars might even distract large language models, evident in that few-shot learning underperforms zero-shot learning by 1.00% to 10.48% on Hamilton path and bipartite graph matching.We further study the correlation between the number of exemplars and model performance on the Hamilton path task.As illustrated in Figure 4, when the number of exemplars increases, model performance is not trending up, and the performance is consistently lower than zero-shot prompting.These results further suggest that in-context learning could be counterproductive in complex structured reasoning.When more in-context exemplars are introduced, model performance is not trending up and is consistently lower than zero-shot prompting in both difficulty settings.</p>
<p>LLMs are (Un)surprisingly Brittle</p>
<p>Although large language models achieved performance that is significantly better than random on simple graph reasoning tasks ( §4.1), we hypothesize that LLMs may be able to reach the correct answer by leveraging certain spurious correlations.For example, on the connectivity task, since nodes with higher degrees are more frequently mentioned and they are more likely to be connected, LLMs might just be counting node mentions instead of actually finding paths.</p>
<p>To this end, we design two special cases (chain and clique) for the connectivity task that are the exact opposite of the spurious correlation.</p>
<p>Chain We firstly generate a graph with k components, where each components is a chain.Formally, G = {V, E} can be divided into subgraphs G 1 , G 2 , . . ., G k , where subgraph G i consists of a chain of nodes and edges v i1 , e i1 , v i2 , e i2 , . . ., e iti , v iti .We then randomly select query node pairs that are at the two ends of a chain, i.e. v i1 and v iti .These nodes only have a degree of one but they are actually connected through the chain structure.We curate a chain dataset with 120 examples.</p>
<p>Clique We first generate a graph with k densely connected subgraphs.Formally, G = {V, E} can be divided into subgraphs G 1 , G 2 , . . ., G k , where subgraph G i is generated by the random graph generator ( §2.1) with a high edge probability p ∈ {0.7, 1.0}.We then randomly select query node pairs with each pair in two different densely connected subgraphs, G i and G j (i ̸ = j).These nodes are associated with a large number of edges and thus are frequently mentioned in the natural language prompt, but they belong to two different subgraphs and are not connected.We curate a clique dataset with 120 examples.</p>
<p>We evaluate LLMs with different prompting approaches on the two special cases and compare performances with the general connectivity task in Table 4. LLM performs much worse than ordinary Algorithmic Prompting Build-a-Graph Prompting <in-context exemplar> In an undirected graph, the nodes are numbered from 0 to 4, and the edges are: an edge between node 0 and node 4 with weight 4, … Let's construct a graph with the nodes and edges first.</p>
<p>Q: Give the shortest path from node 0 to node 2. A: All the paths from node 0 to node 2 are: 0,3,2 with a total weight of 3 + 1 = 4, 0,1,4,2 with a total weight of 3 + 4 + 2 = 9, 0,4,3,2 with a total weight of 4 + 1 + 1 = 6.The weight of path 0,3,2 is the smallest, so the shortest path from node 0 to node 2 is 0,3,2 with a total weight of 4.</p>
<p>We can use a Depth-First Search (DFS) algorithm to find the shortest path between two given nodes in an undirected graph.The basic idea is to start at one of the nodes and use DFS to explore all of its adjacent nodes.At each node, you can keep track of the distance it takes to reach that node from the starting node.Once you have explored all the adjacent nodes, you can backtrack and pick the node which has the shortest distance to reach the destination node.</p>
<p><in-context exemplar> In an undirected graph, the nodes are numbered from 0 to 4, and the edges are: an edge between node 0 and node 4 with weight 4, ... Q: Give the shortest path from node 0 to node 2. A: All the paths from node 0 to node 2 are: 0,3,2 with a total weight of 3 + 1 = 4, 0,1,4,2 with a total weight of 3 + 4 + 2 = 9, 0,4,3,2 with a total weight of 4 + 1 + 1 = 6.The weight of path 0,3,2 is the smallest, so the shortest path from node 0 to node 2 is 0,3,2 with a total weight of 4. <in-context exemplar> In an undirected graph, the nodes are numbered from 0 to 4, and the edges are: an edge between node 0 and node 4 with weight 4, an edge between node 0 and node 3 with weight 3, an edge between node 0 and node 1 with weight 3, ... Q: Give the shortest path from node 0 to node 2. cases with a performance drop of more than 40% across various settings.This suggests that LLMs are indeed (un)surprisingly vulnerable to spurious correlations in structured reasoning.</p>
<p>Standard Prompting</p>
<p>Making Language Models Better Graph Reasoners</p>
<p>Methodology</p>
<p>We propose two instruction-based prompting techniques that improve the graph reasoning ability of LLMs, which can be used together with in-context learning and chain-of-thought prompting.</p>
<p>Build-a-Graph Prompting (BAG) We hypothesize that it might be helpful to map the textual descriptions of graphs to grounded conceptual spaces [Patel et al., 2021] before tackling the specific problem, i.e. visualizing the graph structure on an implicit mental sketchpad.To this end, we propose to use instruction-based prompting by appending "Let's construct a graph with the nodes and edges first."after the textual description of the graph is explicitly given.We envision this straightforward instruction would provide LLMs with the buffer zone to digest graph information, map them to grounded conceptual spaces, and better prepare for the incoming query.</p>
<p>Algorithmic Prompting We hypothesize that in order to generate sound and accurate solutions, LLMs would benefit from revisiting and reciting the relevant algorithm for a given task [Sun et al., 2023].To this end, we propose to first prepend the algorithm details before the in-context examples by adding "We can use a Depth-First Search (DFS) algorithm . . ." for the shortest path task.We similarly provide the algorithm descriptions of other graph reasoning tasks in their respective prompts.We envision algorithmic prompting as empowering LLMs with a general understanding of how to solve the problem before actually solving it.</p>
<p>We illustrate our proposed build-a-graph prompting and algorithmic prompting in Figure 5.In the following, we use these two approaches together with chain-of-thought prompting and evaluate on three representative tasks in the NLGraph benchmark with varying difficulties.</p>
<p>Results</p>
<p>Table 5 shows the results of our proposed prompting methods on three representative tasks with varying complexity.On the two easier tasks, cycle and shortest path, our instruction-based prompting methods resulted in a 3.07% to 16.85% performance gain across the two tasks.However, on the more complex task, Hamilton path, the two natural language instructions are largely ineffective.The result suggests that the two simple instruction-based prompting techniques successfully improve LLMs' graph reasoning abilities on relatively easy graph reasoning tasks, while how to make LLMs better where LLMs are given a natural language input and then asked to generate a graph such as an event graph [Tandon et al., 2019], a reasoning-graph [Madaan et al., 2021] or an argument explanation graph [Saha et al., 2021], Madaan et al. [2022] find that a code language model (CODEX) with tasks framed as code generation tasks outperforms other strong LMs.In multi-hop question answering or knowledge probing, LLMs implicitly find connections and paths among a vast network of entities and concepts [Creswell et al., 2023, Yu et al., 2022, Zhang et al., 2022a, He et al., 2021].Recently, Chen et al. [2023] explore the potential of LLMs on the graph node classification task.Together these works demonstrate that LLMs are increasingly adopted for tasks and settings with implicit graphs and structures, while whether LLMs are robust at graph reasoning remains underexplored and may hinder the progress of these structure-aware applications.In this work, we propose the NLGraph benchmark as a comprehensive testbed towards evaluating the graph reasoning abilities of large language models.</p>
<p>LLMs for few-shot reasoning.There is a long line of work on evaluating LLMs' reasoning ability in an in-context learning setting, including arithmetic reasoning, logical reasoning, common sense reasoning, and more.Particularly, simple math problem datasets such as AQUA Ling et al. [2017], GSM8K [Cobbe et al., 2021], and SVAMP [Patel et al., 2021] are used for evaluating arithmetic reasoning [He-Yueya et al., 2023, Touvron et al., 2023, Shi et al., 2023].Welleck et al. [2021] developed NaturalProofs, a multi-domain dataset for studying mathematical reasoning in natural language, while Welleck et al. [2022] study LLMs' ability to generate the next step in mathematical proof and generate full proofs.LLMs have also been evaluated on logical reasoning tasks, including symbolic tasks like Coin Flip and Last Letter Concatenation [Wei et al., 2022] and Logic Grid Puzzle on the BIG-BENCH [Srivastava et al., 2023].Commonsense reasoning datasets [Talmor et al., 2019, Geva et al., 2021] are also proposed to evaluate large language models.Most relevant to our work, various proposals to evaluate and augment the algorithm reasoning abilities of large language models are explored [Zhou et al., 2022, Lee and Kim, 2023, Zelikman et al., 2023, Liu et al., 2023].In this work, we focus on evaluating and enhancing LLMs on graph-based reasoning and algorithmic tasks inspired by the increasing usage of LLMs in tasks with implicit graphs and structures.</p>
<p>Conclusion</p>
<p>In this work, we investigate whether LLMs are capable of explicit graph reasoning, i.e., solving graph algorithm problems in natural language, across various problem categories and prompting techniques.</p>
<p>To this end, we curate the NLGraph benchmark, a comprehensive test bed of graph-based reasoning in natural language, with 29,370 problems covering eight tasks with varying complexity.By evaluating LLMs and prompting approaches on the NLGraph benchmark, we find that 1) LLMs do possess preliminary graph reasoning abilities, 2) the benefit of advanced prompting and in-context learning may diminish on complex reasoning tasks, while 3) LLMs are brittle to spurious correlations in problem settings.We then propose Build-a-Graph and Algorithmic Prompting, two simple instructionbased approaches that bring notable performance gains across multiple tasks.Improving LLMs' graph reasoning abilities on complex and nuanced graph reasoning tasks remains an open research question, and we encourage future work to develop upon our proposed NLGraph benchmark.</p>
<p>A Discussion</p>
<p>NLP tasks and graph tasks alignment.Originally designed for processing language, LLMs are increasingly adopted for NLP tasks with structural implications.For instance, structured commonsense reasoning is similar to topological sort in that they both need to find a solution satisfying diversified constraints between entities.In the belief state graph in theory-of-mind [Adhikari et al., 2020, Ammanabrolu andRiedl, 2021], the final task is to determine the connectivity of nodes, which corresponds to the connectivity task.In multi-hop question answering [Creswell et al., 2023], LLMs implicitly find connections and paths among a vast network of entities and concepts, which resembles the shortest path task and connectivity task.However, we acknowledge that not all graph reasoning tasks in the NLGraph benchmark are clearly aligned with certain applications, thus advanced graph reasoning tasks in the NLGraph benchmark could also be viewed as a test of language model reasoning ability.</p>
<p>The NLGraph benchmark envisioned as reasoning benchmark.In addition to evaluating graph reasoning abilities, the NLGraph benchmark can also be viewed as a structural benchmark to evaluate language model reasoning.While ample LM reasoning datasets exist [Cobbe et al., 2021, Patel et al., 2021, Talmor et al., 2019], it is difficult to avoid train-test overlap since problems such as grade school math [Cobbe et al., 2021] and commonsense reasoning [Talmor et al., 2019] might be readily available in pretraining corpora, making it less convincing for evaluating reasoning abilities.On the contrary, the synthetic graph reasoning problems and their answers are highly unlikely to have exact matches in the training corpora, which makes NLGraph a more robust benchmark towards evaluating language model reasoning.</p>
<p>Fine-tuning to elicit graph reasoning abilities.To further study the graphical thinking abilities of LLMs, we envision fine-tuning as a possible direction for future work.We plan to fine-tune language models on the chain-of-thought reasoning process towards graph-based tasks on both single-and multi-task settings to see if fine-tuning might lead to enhanced graph reasoning abilities.</p>
<p>B Limitations</p>
<p>Tasks in NLGraph benchmark are not complete.While we have incorporated eight graph reasoning tasks with varying complexity in the NLGraph benchmark, there are many more important graph algorithms that test different levels of graph reasoning abilities.It might also be interesting to see how LLMs perform on other graph tasks such as finding the Eulerian path, the minimum spanning tree, and the cut-edge.</p>
<p>Language models that we evaluate are not complete.We only consider four black-box LLMs, TEXT-DAVINCI-003, CODE-DAVINCI-002, GPT-3.5-TURBO, and GPT-4 in our experiments.Since we will make the NLGraph benchmark publicly available, we leave it to future work on evaluating the graph reasoning abilities of other open-source LLMs.</p>
<p>Limited dataset size.Due to monetary costs, we only evaluate LLMs on the standard version of the NLGraph benchmark which has 5,902 problems throughout the paper.We believe evaluating LLMs on the extended version of the NLGraph benchmark, with 5x more problems, may bring stronger proof to the findings we present.</p>
<p>Methods for improving graph reasoning abilities.The two prompting methods we present are simple instruction-based approaches, which work on easy graph reasoning problems to varying extents.However, on more complex graph reasoning problems, as the overall graph reasoning abilities of LLMs are limited, the instruction-based methods seem to have only marginal effects.In future work, we hope to investigate methods such as asking LLMs to generate and execute code, or simulating steps of algorithmic solutions while maintaining the state variables.</p>
<p>C NLGraph Details</p>
<p>In</p>
<p>D Analysis</p>
<p>Instruction variants To further study the effect of BAG prompting and ALGORITHMIC prompting, we replace the instructions with only a sequence of dots (...) equal to the number of characters in the instruction.This is to investigate whether the improved performance is attributed to the natural language instructions or simply increased computation.We also replace the BAG prompting with three other instructions not directly related to graph problems, specifically, Let's think step by step (INSTRUCTION 1), Examine each detail carefully (INSTRUCTION 2), Think it through systematically (INSTRUCTION 3).As illustrated in Table 7, the BAG prompting method generally outperforms the instruction variants, indicating the effectiveness of this method.</p>
<p>Graph definition variants</p>
<p>We study how replacing the abstract descriptions of graphs with realworld objects would impact model performance.Specifically, for the shortest path task, we change all the "node"s into "city"s, "edge"s into "road"s, and "weight"s into "distance"s.As shown in Table 9, the model performance improves on the easy subset but drops on the hard subset.While language models are indeed sensitive to the specific instantiations of the graph description, the results are mixed as to which is easier or harder.LLMs are brittle to problem scales For the shortest path task, we study the correlation between model performance and the number of nodes on the optimal shortest path.We group problems by the shortest path length and present results in Figure 6 for the COT approach, which shows that the accuracy steadily drops when the number of nodes on the shortest path increases.While the reasoning process towards finding the shortest paths stays the same for optimal solutions with varying lengths, large language models are not robust to changes in graph scales and problem settings.</p>
<p>In-context exemplars and test difficulty We investigate the model performance when the incontext exemplars and test difficulty vary.For the cycle task, we write chain-of-thought solutions for problems selected from the medium and hard subsets, and evaluate TEXT-DAVINCI-003 on the cycle task with the two prompts.We present the results in Figure 7.The performance drops when the exemplar difficulty increases, indicating that LLM struggles to learn from exemplars with more difficulty.</p>
<p>Method</p>
<p>Partial credit for the maximum flow task</p>
<p>We provide partial credit for the maximum flow task in Table 10.The performance generally has the same trend as the results provided in Figure 2. Though on the hard subsets, the performance of COT is the highest, we believe this is more like guessing, as when COT is combined with self-consistency, the performance drops significantly.</p>
<p>E Additional Large Language Models E.1 CODE-DAVINCI-002 Results</p>
<p>We evaluate CODE-DAVINCI-002 on cycle, shortest path, and Hamilton path.The results are provided in Table 8.The findings are mostly similar to TEXT-DAVINCI-003: language models are preliminary graph reasoners on easy tasks while the benefit of in-context learning and advanced prompting is limited on more complex problems.However, in the COT and COT+SC settings, CODE-DAVINCI-002 generates too many tokens before reaching the final answer, so we do not present the results in Table 8.</p>
<p>E.2 OPT Results</p>
<p>We fine-tune OPT-2.7B[Zhang et al., 2022b] and evaluate the model on the NLGraph benchmark.</p>
<p>We randomly divide the standard version of the NLGraph benchmark into 4902 training problems and 1,000 test problems.We generate zero-shot solutions for the training problems, combine the solutions with the problems, and attain nine corpus of text (i.e. one for each task and one that concatenating all the text).We then fine-tune OPT on the nine corpus separately.However, we find that fine-tuning did not elicit the graph reasoning abilities of OPT-2.7B: the generated text is mostly meaningless, falling short of answering questions and following formats.We leave it to future work on fine-tuning larger language models to elicit graph reasoning abilities due to our limitations in computational resources.</p>
<p>E.3 Qualitative Analaysis with GPT-3.5-TURBO and GPT-4</p>
<p>Due to monetary costs, we only conduct qualitative analysis on GPT-3.5-TURBO and GPT-4 with 19 representative problems across the eight tasks.We provide the results in Table 11, Table 12, Table 13, Table 14, Table 15.Results demonstrate that while GPT-4 does present better graph reasoning abilities, it is still far from being a robust reasoner towards graph-based problems.</p>
<p>Table 11: Results of GPT-3.5-TURBO and GPT-4 on 19 cases (#1 to #6 example) through the eight tasks.We omitted the COT in-context exemplars in the table.</p>
<p>Question GPT-3.5-TURBOGPT-4</p>
<p>Determine if there is a path between two nodes in the graph.Note that (i,j) means that node i and node j are connected with an undirected edge.Graph: (0,4) (1,3) (1,2) (1,6) (2,5) (2,6) (3,5) (5,6) Q: Is there a path between node 4 and node 5?</p>
<p>Node 4 is not directly connected to node 5, but we can follow the path: 4-&gt;0-&gt;6-&gt;2-&gt;5, so the answer is yes.</p>
<p>Node 4 is only connected to node 0, which does not have any connections to the other nodes in the graph.Node 5 is in the connected block consisting of nodes 1, 2, 3, 5, and 6.Node 4 and node 5 are not in the same connected block, so the answer is no.</p>
<p>Determine if there is a path between two nodes in the graph.Note that (i,j) means that node i and node j are connected with an undirected edge.Graph: (0,3) (0,5) (0,11) (0,8
) (0,6) (0,1) (1,10) (1,3) (1,5) (1,9) (1,6) (1,2) (2,10) (2,3) (2,5) (2,9) (2,8) (2,7) (2,6) (2,13) (3,9) (3,11) (3,8) (3,7) (4,12)
(5,10) (5,9) (5,8) (5,7) (5,6) (6,10) (6,9) (6,11) (6,8) (7,10) (7,11) (7,8) (7,13) (8,10) (8,11) (8,13) (9,10) (9,11) (9,13) (10,11) (10,13) Q: Is there a path between node 6 and node 3?</p>
<p>Node 6 is connected to node 0, node 0 is connected to node 3. We can follow the path: 6-&gt;0-&gt;3, so the answer is yes.</p>
<p>A: Node 6 is connected to node 2, node 2 is connected to node 3. We can follow the path: 6-&gt;2-&gt;3, so the answer is yes.</p>
<p>In an undirected graph, (i,j) means that node i and node j are connected with an undirected edge.The nodes are numbered from 0 to 7, and the edges are: (2,4) (0,3) (1,2) (5,7) (1,5) (6,5) (1,0) Q: Is there a cycle in this graph?</p>
<p>The edges (1,2), (2,4), (4,0), (0,3), (3,1) form a cycle, so yes, there is a cycle in this graph.</p>
<p>The edges (1,0), (1,2), (1,5), (6,5), (5,7) do not form a cycle.However, the edges (1,0), (1,2), (2,4) do form a cycle.So yes, there is a cycle in this graph.</p>
<p>In an undirected graph, (i,j) means that node i and node j are connected with an undirected edge.The nodes are numbered from 0 to 7, and the edges are: (1,7) (0,6) (1,3) (4,5) (1,0) (0,4) (0,2) (7,2) Q: Is there a cycle in this graph?</p>
<p>The edges (0,6), (</p>
<p>form a cycle, so yes, there is a cycle in this graph.</p>
<p>The edges (1,7), (7,2), (2,0), (0,1) form a cycle, so yes, there is a cycle in this graph.</p>
<p>All the paths from node 3 to node 0 are: 3,2,0 with a total weight of 2 + 2 = 4, 3,2,4,1,0 with a total weight of 3 + 4 + 1 = 8, 3,2,4,0 with a total weight of 3 + 1 = 4, 3,1,4,0 with a total weight of 4 + 4 + 1 = 9, 3,1,2,0 with a total weight of 4 + 4 + 2 = 10, 3,5,2,0 with a total weight of 2 + 2 + 2 = 6, 3,5,4,0 with a total weight of 2 + 2 + 1 = 5.The weight of path 3,2,0 and 3,5,4,0 is the smallest, so the shortest path from node 3 to node 0 is either 3,2,0 or 3,5,4,0, both with a total weight of 4.</p>
<p>All the paths from node 3 to node 0 are: 3,2,0 with a total weight of 1 + 2 = 3, 3,1,2,0 with a total weight of 4 + 4 + 2 = 10, 3,4,0 with a total weight of 3 + 1 = 4, 3,4,2,0 with a total weight of 3 + 3 + 2 = 8, 3,5,2,0 with a total weight of 2 + 2 + 2 = 6, 3,5,4,0 with a total weight of 2 + 2 + 1 = 5.The weight of path 3,2,0 is the smallest, so the shortest path from node 3 to node 0 is 3,2,0 with a total weight of 3.</p>
<p>In an undirected graph, the nodes are numbered from 0 to 4, and the edges are: An edge between node 1 and node 0 with weight 1, An edge between node 2 and node 0 with weight 1, An edge between node 4 and node 1 with weight 1, An edge between node 1 and node 2 with weight 3, An edge between node 2 and node 3 with weight 3. Q: Give the shortest path from node 3 to node 1.</p>
<p>All the paths from node 3 to node 1 are: 3,2,1 with a total weight of 3 + 3 = 6, 3,2,0,1 with a total weight of 1 + 1 + 1 = 3, 3,2,1,0,1 with a total weight of 3 + 1 + 1 + 1 = 6, 3,2,0,1,4,1 with a total weight of 1 + 1 + 1 + 1 + 1 = 5.The weight of path 3,2,0,1 is the smallest, so the shortest path from node 3 to node 1 is 3,2,0,1 with a total weight of 3.</p>
<p>All the paths from node 3 to node 1 are: 3,2,1 with a total weight of 3 + Table 12: Results of GPT-3.5-TURBO and GPT-4 on 19 cases (#7 to #9 example ) through the eight tasks.We omitted the COT in-context exemplars in the table.</p>
<p>Question GPT-3.5-TURBOGPT-4</p>
<p>In an undirected graph, the nodes are numbered from 0 to 6, and the edges are: An edge between node 0 and node 2 with weight 1, An edge between node 3 and node 0 with weight 4, An edge between node 5 and node 0 with weight 2, An edge between node 4 and node 0 with weight 3, An edge between node 0 and node 1 with weight 4, An edge between node 0 and node 6 with weight 2, An edge between node 2 and node 1 with weight 2, An edge between node 3 and node 1 with weight 3, An edge between node 4 and node 1 with weight 3, An edge between node 1 and node 6 with weight 2, An edge between node 2 and node 5 with weight 4, An edge between node 2 and node 4 with weight 3, An edge between node 6 and node 2 with weight 2, An edge between node 3 and node 5 with weight 1, An edge between node 4 and node 3 with weight 2, An edge between node 3 and node 6 with weight 4, An edge between node 4 and node 5 with weight 3, An edge between node 4 and node 6 with weight 1, An edge between node 6 and node 5 with weight 2. Q: Give the shortest path from node 2 to node 3.</p>
<p>All the paths from node 2 to node 3 are: 2,0,3 with a total weight of 1 + 4 = 5, 2,1,3 with a total weight of 2 + 3 = 5, 2,4,3 with a total weight of 3 + 2 = 5.The weight of path 2,0,3 is the smallest, so the shortest path from node 2 to node 3 is 2,0,3 with a total weight of 5.</p>
<p>All the paths from node 2 to node 3 are: 2,0,3 with a total weight of 1 + 4 = 5, 2,1,3 with a total weight of 2 + 3 = 5, 2,1,0,3 with a total weight of 2 + 4 + 4 = 10, 2,1,6,3 with a total weight of 2 + 2 + 4 = 8, 2,4,3 with a total weight of 3 + 2 = 5, 2,4,0,3 with a total weight of 3 + 3 + 4 = 10, 2,4,1,3 with a total weight of 3 + 3 + 3 = 9, 2,4,1,0,3 with a total weight of 3 + 3 + 4 + 4 = 14, 2,4,1,6,3 with a total weight of 3 + 3 + 2 + 4 = 12, 2,5,0,3 with a total weight of 4 + 2 + 4 = 10, 2,5,4,3 with a total weight of 4 + 5 + 2 = 11, 2,5,4,0,3 with a total weight of 4 + 5 + 3 + 4 = 16, 2,5,4,1,3 with a total weight of 4 + 5 + 3 + 3 = 15, 2,5,6,3 with a total weight of 4 + 6 + 4 = 14, 2,6,1,3 with a total weight of 2 + 2 + 3 = 7, 2,6,1,0,3 with a total weight of 2 + 2 + 4 + 4 = 12, 2,6,5,0,3 with a total weight of 2 + 5 + 2 + 4 = 13, 2,6,5,4,3 with a total weight of 2 + 5 + 5 + 2 = 14.The weight of paths 2,0,3, 2,1,3, and 2,4,3 is the smallest.So, there are three shortest paths from node 2 to node 3, which are 2,0,3; 2,1,3; and 2,4,3, each with a total weight of 5.</p>
<p>In a directed graph with 5 nodes numbered from 0 to 4: node 2 should be visited before node 4 node 2 should be visited before node 1 node 2 should be visited before node 0 node 4 should be visited before node 1 node 4 should be visited before node 0 Q: Can all the nodes be visited?Give the solution.This is not possible as there is a cycle between nodes 0, 1, and 4. Node 2 cannot be visited before nodes 0, 1, and 4, and nodes 0, 1, and 4 cannot be visited before node 2. Therefore, it is not possible to visit all the nodes in this graph.</p>
<p>Since no nodes are required to be visited before node 2 and node 3, node 2 and node 3 can be visited first.Since visiting node 4 requires visiting node 2 first, after node 2 is visited, node 4 can be visited.Since visiting node 0 requires visiting node 2, node 4 first, after node 2 and node 4 are visited, node 0 can be visited.Since visiting node 1 requires visiting node 2, node 4 first, after node 2 and node 4 are visited, node 1 can be visited.So the solution is: 2,3,4,0,1.</p>
<p>In a directed graph with 5 nodes numbered from 0 to 4: node 0 should be visited before node 1 node 1 should be visited before node 2 node 3 should be visited before node 1 node 3 should be visited before node 2 node 4 should be visited before node 3 node 4 should be visited before node 0 node 4 should be visited before node 1 Q: Can all the nodes be visited?Give the solution.</p>
<p>This graph has a cycle, which means it is not possible to visit all nodes in a valid order.Specifically, there is a cycle between nodes 1, 2, and 3, which cannot be resolved based on the given constraints.</p>
<p>Since no nodes are required to be visited before node 4, node 4 can be visited first.Since visiting node 0 and node 3 requires visiting node 4 first, after node 4 is visited, node 0 and node 3 can be visited.Since visiting node 1 requires visiting node 0 and node 3 first, after node 0 and node 3 are visited, node 1 can be visited.Since visiting node 2 requires visiting node 1 and node 3 first, after node 1 and node 3 are visited, node 2 can be visited.So the solution is: 4,0,3,1,2.</p>
<p>Table 13: Results of GPT-3.5-TURBO and GPT-4 on 19 cases (#10 to #12 example ) through the eight tasks.We omitted the COT in-context exemplars in the table.</p>
<p>Question GPT-3.5-TURBOGPT-4</p>
<p>In a directed graph with 6 nodes numbered from 0 to 5: node 0 should be visited before node 5 node 0 should be visited before node 1 node 2 should be visited before node 1 node 3 should be visited before node 0 node 3 should be visited before node 5 node 3 should be visited In a directed graph, the nodes are numbered from 0 to 5, and the edges are: an edge from node 1 to node 3 with capacity 4, an edge from node 1 to node 0 with capacity 9, an edge from node 2 to node 1 with capacity 4, an edge from node 3 to node 1 with capacity 4, an edge from node 4 to node 3 with capacity 1, an edge from node 4 to node 5 with capacity 2, an edge from node 5 to node 1 with capacity 4, an edge from node 5 to node 0 with capacity 7. Q: What is the maximum flow from node 4 to node 0?</p>
<p>There is no path from node 4 to node 0, so the maximum flow from node 4 to node 0 is 0.</p>
<p>From the source (node 4), we can send 1 unit of flow to node 3, and 2 units of flow to node 5. 1 unit of flow arrives at node 3, then we can send 1 unit of flow from node 3 to node 1. 2 units of flow arrive at node 5, then we can send 2 units of flow from node 5 to node 0. 1 unit of flow arrives at node 1, then we can send 1 unit of flow from node 1 to node 0. The total unit of flow arrives at node 0 is 3.So the maximum flow from node 4 to node 0 is 3.</p>
<p>In a directed graph, the nodes are numbered from 0 to 7, and the edges are: an edge from node 0 to node 6 with capacity 1, an edge from node 0 to node 7 with capacity 10, an edge from node 2 to node 1 with capacity 9, an edge from node 2 to node 7 with capacity 8, an edge from node 3 to node 1 with capacity 9, an edge from node 3 to node 6 with capacity 10, an edge from node 3 to node 4 with capacity 7, an edge from node 4 to node 6 with capacity 1, an edge from node 5 to node 3 with capacity 7, an edge from node 5 to node 2 with capacity 9, an edge from node 6 to node 4 with capacity 1, an edge from node 7 to node 5 with capacity 8, an edge from node 7 to node 6 with capacity 5. Q: What is the maximum flow from node 2 to node 4?</p>
<p>From the source (node 2), we can send 8 units of flow to node 7, and 9 units of flow to node 1. 8 units of flow arrive at node 7, then we can send 5 units of flow from node 7 to node 6, and 3 units of flow from node 7 to node 5. 9 units of flow arrive at node 1, then we can send 9 units of flow from node 3 to node 1. 9 units of flow arrive at node 6, then we can send 1 unit of flow from node 6 to node 4. 7 units of flow arrive at node 3, then we can send 7 units of flow from node 3 to node 4. The total unit of flow arrives at node 4 is 8.So the maximum flow from node 2 to node 4 is 8.</p>
<p>From the source (node 2), we can send 9 units of flow to node 1, and 8 units of flow to node 7. 9 units of flow arrive at node 1, then we can send 9 units of flow from node 1 to node 3. 8 units of flow arrive at node 7, then we can send 8 units of flow from node 7 to node 5, and 5 units of flow from node 7 to node 6. 8 units of flow arrive at node 5, then we can send 7 units of flow from node 5 to node 3, and 1 unit of flow from node 5 to node 2. 14 units of flow arrive at node 3, then we can send 14 units of flow from node 3 to node 4. The total unit of flow arrives at node 4 is 14.So the maximum flow from node 2 to node 4 is 14.</p>
<p>Table 14: Results of GPT-3.5-TURBO and GPT-4 on 19 cases (#13 to #16 example ) through the eight tasks.We omitted the COT in-context exemplars in the table.</p>
<p>Question GPT-3.5-TURBOGPT-4</p>
<p>In a directed graph, the nodes are numbered from 0 to 7, and the edges are: an edge from node 0 to node 6 with capacity 9, an edge from node 0 to node 3 with capacity 7, an edge from node 1 to node 7 with capacity 8, an edge from node 1 to node 2 with capacity 3, an edge from node 2 to node 7 with capacity 7, an edge from node 2 to node 4 with capacity 5, an edge from node 3 to node 5 with capacity 7, an edge from node 3 to node 1 with capacity 8, an edge from node 4 to node 0 with capacity 3, an edge from node 5 to node 7 with capacity 5, an edge from node 6 to node 5 with capacity 6, an edge from node 6 to node 7 with capacity 6, an edge from node 6 to node 0 with capacity 9, an edge from node 7 to node 4 with capacity 4, an edge from node 7 to node 1 with capacity 8. Q: What is the maximum flow from node 1 to node 6?</p>
<p>There is no path from node 1 to node 6 in this graph, so the maximum flow from node 1 to node 6 is 0.</p>
<p>From the source (node 1), we can send 8 units of flow to node 7, and 3 units of flow to node 2. 8 units of flow arrive at node 7, then we can send 4 units of flow from node 7 to node 4, and 4 units of flow from node 7 to node 1. 4 units of flow arrive at node 4, then we can send 3 units of flow from node 4 to node 0. 3 units of flow arrive at node 0, then we can send 3 units of flow from node 0 to node 6. 3 units of flow arrive at node 2, then we can send 3 units of flow from node 2 to node 4. 3 units of flow arrive at node 4, then we can send 3 units of flow from node 4 to node 0. 3 units of flow arrive at node 0, then we can send 3 units of flow from node 0 to node 6.The total unit of flow arrives at node 6 is 6.So the maximum flow from node 1 to node 6 is 6.</p>
<p>In an undirected graph, (i,j) means that node i and node j are connected with an undirected edge.The nodes are numbered from 0 to 6, and the edges are: (4,3) (6,5) (5,1) (3,0) (2,4) (1,0) (5,2) (4,0) (2,3) (0,2) (6,2) Q: Is there a path in this graph that visits every node exactly once?If yes, give the path.Note that in a path, adjacent nodes must be connected with edges.</p>
<p>No, there is no path that visits every node exactly once.This graph contains two disconnected components: 0,1,2,3,4 and 5,6.It is not possible to visit all nodes in a single path because there is no edge connecting the two components.</p>
<p>Yes.We can start at node 3.As node 3 is connected with node 0, and node 0 is not visited, we can then visit node 0. As node 0 is connected with node 1, and node 1 is not visited, we can then visit node 1.As node 1 is connected with node 5, and node 5 is not visited, we can then visit node 5.As node 5 is connected with node 6, and node 6 is not visited, we can then visit node 6.As node 6 is connected with node 2, and node 2 is not visited, we can then visit node 2. As node 2 is connected with node 4, and node 4 is not visited, we can then visit node 4. The path can be: 3, 0, 1, 5, 6, 2, 4.</p>
<p>In an undirected graph, (i,j) means that node i and node j are connected with an undirected edge.The nodes are numbered from 0 to 4, and the edges are: (1,3) (1,2) (4,3) (2,0) (0,4) (0,1) Q: Is there a path in this graph that visits every node exactly once?If yes, give the path.Note that in a path, adjacent nodes must be connected with edges.</p>
<p>No, there is no path in this graph that visits every node exactly once.This is because node 1 has degree 2, meaning it is connected to two other nodes.</p>
<p>In order to visit every node exactly once, we would need to start and end at node 1, but once we leave node 1, we cannot return to it without visiting another node twice.Therefore, it is impossible to find a path that visits every node exactly once in this graph.</p>
<p>Yes.We can start at node 0. As node 0 is connected with node 1, and node 1 is not visited, we can then visit node 1.As node 1 is connected with node 3, and node 3 is not visited, we can then visit node 3.As node 3 is connected with node 4, and node 4 is not visited, we can then visit node 4. As node 4 is connected with node 2, and node 2 is not visited, we can then visit node 2. The path can be: 0,1,3,4,2.</p>
<p>There are 4 job applicants numbered from 0 to 3, and 2 jobs numbered from 0 to 1.Each applicant is interested in some of the jobs.Each job can only accept one applicant and a job applicant can be appointed for only one job.Applicant 0 is interested in job 1. Applicant 2 is interested in job 0. Applicant 0 is interested in job 0. Applicant 2 is interested in job 1. Applicant 3 is interested in job 1. Applicant 3 is interested in job 0. Applicant 1 is interested in job 0. Q: Find an assignment of jobs to applicants in such that the maximum number of applicants find the job they are interested in.</p>
<p>Applicant 0 is interested in job 0, job 1.</p>
<p>Applicant 1 is interested in job 0. Applicant 2 is interested in job 0, job 1. Applicant 3 is interested in job 0, job 1.</p>
<p>We can make the following assignments: applicant 0: job 1 applicant 2: job 0 applicant 3: job 1 3 applicants can find the job they are interested in.</p>
<p>Applicant 0 is interested in job 0, job 1.</p>
<p>Applicant 1 is interested in job 0. Applicant 2 is interested in job 0, job 1. Applicant 3 is interested in job 0, job 1.</p>
<p>We can make the following assignments: applicant 0: job 0 applicant 1: -(no job available) applicant 2: job 1 applicant 3: -(no job available) 2 applicants can find the job they are interested in.</p>
<p>Table 15: Results of GPT-3.5-TURBO and GPT-4 on 19 cases (#17 to #19 example ) through the eight tasks.We omitted the COT in-context exemplars in the table.</p>
<p>Question GPT-3.5-TURBOGPT-4</p>
<p>There are 5 job applicants numbered from 0 to 4, and 6 jobs numbered from 0 to 5. Each applicant is interested in some of the jobs.Each job can only accept one applicant and a job applicant can be appointed for only one job.Applicant 0 is interested in job 3. Applicant 4 is interested in job 5. Applicant 4 is interested in job 4. Applicant 3 is interested in job 0. Applicant 0 is interested in job 5. Applicant 1 is interested in job 0. Applicant 0 is interested in job 2. Applicant 0 is interested in job 4. Applicant 4 is interested in job 0. Applicant 4 is interested in job 2. Applicant 2 is interested in job 3. Q: Find an assignment of jobs to applicants in such that the maximum number of applicants find the job they are interested in.</p>
<p>Applicant 0 is interested in job 2, job 3, job 4, job 5. Applicant 1 is interested in job 0. Applicant 2 is interested in job 3. Applicant 3 is interested in job 0. Applicant 4 is interested in job 0, job 2, job 4, job 5. We can make the following assignments: applicant 0: job 5 applicant 1: job 0 applicant 2: job 3 applicant 3: job 0 applicant 4: job 2 5 applicants can find the job they are interested in.</p>
<p>Applicant 0 is interested in job 2, job 3, job 4, job 5. Applicant 1 is interested in job 0. Applicant 2 is interested in job 3. Applicant 3 is interested in job 0. Applicant 4 is interested in job 0, job 2, job 4, job 5. We can make the following assignments: applicant 0: job 3 applicant 1: job 0 applicant 4: job 4 3 applicants can find the job they are interested in.</p>
<p>n an undirected graph, the nodes are numbered from 0 to 5, and every node has an embedding.(i,j) means that node i and node j are connected with an undirected edge.</p>
<p>Embeddings: node 0:</p>
<p>Figure 2 :
2
Figure 2: (left) Model performance on the topological sort task.COT, LTM, and self-consistency are mostly ineffective on this problem.(right) Model performance on the maximum flow task.FEW-SHOT prompting outperforms COT+SC prompting on both easy and hard subsets, suggesting that LLMs fall short of generating valid intermediate steps to solve the more complex graph reasoning problem.Together these results demonstrate that advanced prompting is ineffective for advanced graph reasoning.</p>
<p>Figure 3 :
3
Figure 3: (left) Model performance on the Hamilton path task.ZERO-SHOT prompting consistently outperforms all other prompting techniques.(right) Model performance on the bipartite graph matching task.The effect of in-context learning and advanced prompting is also mostly marginal in this complex graph reasoning problem.Together these results demonstrate that in-context learning can be counterproductive in advanced graph reasoning problems.</p>
<p>Figure 4 :
4
Figure 4: Model performance on the Hamilton path task with an increasing amount of exemplars.When more in-context exemplars are introduced, model performance is not trending up and is consistently lower than zero-shot prompting in both difficulty settings.</p>
<p>Figure 5 :
5
Figure 5: Overview of Build-a-Graph prompting and Algorithmic prompting, aiming to make LLMs better at reasoning with graphs by encouraging conceptual grounding and algorithmic reflection.Red underline indicates our proposed instructions while green background indicates LLMs' generation.</p>
<p>Figure 6 :Figure 7 :
67
Figure 6: Model performance for the shortest path task with different numbers of nodes on the shortest path.The performance steadily drops when the path length increases.</p>
<p>graph convolution layer, each node's embedding is updated by the sum of its neighbors' embeddings.Q: What's the embedding of each node after one layer of simple graph convolution layer?Layer 1: node 0: sum of embeddings of node 1, node 5, [0,1] + [0,1] = [0,2].node 1: sum of embeddings of node 0, node 4, node 5, [1,1] + [0,0] + [0,1] = [1,2].node 2: sum of embeddings of node 4sum of embeddings of node 1, node 5, [0,1] + [0,1] = [0,2].node 1: sum of embeddings of node 0, node 4, node 5, [1,1] + [0,0] + [0,1] = [1,2].node2: sum of embeddings of node 4graph, the nodes are numbered from 0 to 7, and every node has an embedding.(i,j) means that node i and node j are connected with an undirected edgegraph convolution layer, each node's embedding is updated by the sum of its neighbors' embeddings.Q: What's the embedding of each node after one layer of simple graph convolution layer?Layer 1: node 0: sum of embeddings of node 3, node 4, node 6, [1,1] + [1,1] + [1,0] = [3,2].node 1: sum of embeddings of node 4, [1,1] = [1,1].node 2: sum of embeddings of node 3, node 5, node 6, [1,1] + [0[2,1] node 3: [2,1] node 4: [1,2] node 5: [5,3] node 6: [3,2] node 7: [0,0]</p>
<p>Table 1 :
1
Statistics of the NLGraph benchmark.We use A / B to indicate that there are A and B problems in the standard and extended set of NLGraph.SPEC.denotes difficulty specifications.
SubsetConnect.CycleTopo. Sort Shortest Path Max. Flow Bipartite Graph Hamilton PathGNNs# EASY352 / 730150 / 300180 / 360180 / 360150 / 300300 / 600150 / 300100 / 200SPEC.n: 5-10n: 5-10n: 5-10n: 5-10n: 5-10n: 6-20n: 5-10n: 5-8# MEDIUM 1,200 / 8,580 600 / 1,800 150 / 1,350/////SPEC.n: 11-25n: 11-25n: 11-25/////# HARD680 / 7,090400 / 2,000 200 / 1,200200 / 1,200200 / 1,200210 / 1,260200 / 600140 / 840SPEC.n: 26-35n: 26-35n: 26-35n: 11-20n: 11-20n: 17-33n: 11-20n: 9-15</p>
<p>Table 3 :
3ZERO-SHOT13.610.0020.04FEW-SHOT20.040.0037.83COT64.5531.0014.340-COT13.850.0044.55COT+SC63.9228.0013.28
Results with Advanced Prompting Method PC (↑) ACC (↑) RE (↓) Model performance on the task of simulating graph neural networks.PC and RE are two partial credit metrics introduced in §2.2.Chainof-thought prompting significantly improves the model performance across all metrics.</p>
<p>Table 4 :
4
Model performance on the chain and clique subset of the connectivity task.Large language models indeed rely on spurious correlations in problem settings, evident in the reduced performance on the two special cases compared to the general connectivity task.</p>
<p>Table 5 :
5
Sclar et al. [2023]dl [2021]nectivity, cycle, and shortest path tasks with our proposed BAG and ALGORITHM prompting.On the two easier tasks, cycle and shortest path, our instructionbased prompting techniques resulted in a 3.07% to 16.85% performance gain across the two tasks.More complex graph reasoning tasks such as Hamilton path remain an open research question.atreasoningoncomplexgraphreasoningproblemsremainsanopenresearchquestion.We further explore different variants of the instructions in Appendix D. The NLGraph benchmark also empowers the evaluation of future instructions and solutions towards making LLMs better graph reasoners.6RelatedWorkLLMsfortaskswithimplicitgraphicalstructures.Previous works explored the use of LLMs on tasks with implicit graph structures:Huang et al. [2022]find that LLMs have the ability to ground high-level tasks (e.g."make breakfast") to a set of actionable steps (e.g."open fridge") in structured synthetic environments.Valmeekam et al. [2022]explore the possibility of using LLMs for commonsense planning.In theory-of-mind reasoning,Adhikari et al. [2020],Ammanabrolu and Riedl [2021],Sclar et al. [2023]maintain and update structured world representations as the world state change to operate in interactive and situated environments.In structured commonsense reasoning,
MethodCycleShortest PathHamilton PathEasy Medium Hard Avg. Easy Hard Easy (PC) Hard (PC) Avg. Easy Hard Avg.COT84.6763.3353.25 66.75 63.89 29.5076.8435.7951.51 40.00 8.00 24.00COT+BAG86.0069.3362.00 72.44 67.78 33.5079.2042.5655.76 38.67 6.00 22.34COT+ALGORITHM 77.3374.0064.00 71.78 63.89 28.0076.0638.7051.66 36.67 7.50 22.09</p>
<p>Table 6
6SubsetConnect.CycleTopo. SortShortest PathMaximum FlowBipartite Graph Hamilton PathGNNs# EASYp: 0.3, 0.7, 1.0 m: 1-4 p: 0.3, 0.5, 0.7 p: 0.5, 0.7, 0.9; w: 1-4; ℓ: 2-6 p: 0.2, 0.3; c: 1-10p: 0.3-0.7p: 0.4, 0.6p: 0.4; ℓ: 1# MEDIUM p: 0.3, 0.7, 1.0 m: 1-4 p: 0.3, 0.5, 0.7/////# HARDp: 0.3, 0.7m: 1-4p: 0.3, 0.5p: 0.2, 0.25; w: 1-10; ℓ: 2-6p: 0.25; c: 1-20p: 0.2-0.6p: 0.4, 0.6p: 0.2; ℓ: 1
, we provide the details of the NLGraph benchmark including edge probabilities and specific values of parameters mentioned in §2.2.</p>
<p>Table 6 :
6
Details of the NLGraph benchmark.p denotes the edge probability.Other characters have the same meaning mentioned in §2.2.
MethodShortest PathEasy Hard Easy (PC) Hard (PC)BAG67.78 33.5079.2042.56BAG-DOT65.00 29.0075.5537.18ALGORITHMIC-DOT 66.67 31.0078.2739.68INSTRUCTION #166.22 32.5078.1840.32INSTRUCTION #267.78 28.5077.3237.06INSTRUCTION #367.78 30.5079.5637.89</p>
<p>Table 7 :
7
The results of variants of instructions on the shortest path task.The BAG prompting approach achieves the best performance across three of the four settings.</p>
<p>Table 8 :
8
The results of CODE-DAVINCI-002 on the cycle, shortest path, and Hamilton path task.
MethodCycleShortest PathHamilton PathEasy Medium Hard Easy Hard Easy (PC) Hard (PC) EasyHardRANDOM50.0050.0050.00 50.00 50.006.076.690.000.00FEW-SHOT58.0050.0049.75 39.44 28.5055.1037.6336.677.00COT60.6766.8369.00 41.11/45.00/50.00 12.00COT+SC59.3352.6753.75 42.22/49.26/34.005.00MethodShortest PathEasy Hard Easy (PC) Hard (PC)RANDOM50.00 50.006.076.69ZERO-SHOT29.40 14.0047.5320.13FEW-SHOT41.11 20.5058.7829.28COT73.33 28.0082.5735.500-COT6.672.0065.4051.95COT+SC72.78 27.0083.5035.19</p>
<p>Table 9 :
9
Model performance when graph descriptions are changed into cities, roads, and distances on the shortest path task.</p>
<p>Table 10 :
10
Partial credit for the maximum flow task.
Easy HardZERO-SHOT25.65 10.37FEW-SHOT24.83 12.37COT16.99 22.070-COT17.41 7.04COT+SC9.888.62
In an undirected graph, the nodes are numbered from 0 to 5, and the edges are: An edge between node 2 and node 0 with weight 2, An edge between node 0 and node 4 with weight 1, An edge between node 1 and node 2 with weight 4, An edge between node 1 and node 3 with weight 4, An edge between node 4 and node 1 with weight 4, An edge between node 2 and node 3 with weight 1, An edge between node 2 and node 5 with weight 2, An edge between node 2 and node 4 with weight 3, An edge between node 5 and node 3 with weight 2, An edge between node 3 and node 4 with weight 3, An edge between node 4 and node 5 with weight 2. Q: Give the shortest path from node 3 to node 0.
= 6, 3,2,0,1 with a total weight of 3 + 1 + 1 = 5. The weight of path 3,2,0,1 is the smallest, so the shortest path from node 3 to node 1 is 3,2,0,1 with a total weight of 5.
AcknowledgementsWe would like to thank the reviewers, the area chair, Jiacheng Liu, Minnan Luo, and members of the UW NLP Group for their comments and feedback.This material is funded by the DARPA Grant under Contract No. HR001120C0124.We also gratefully acknowledge support from NSF CAREER Grant No. IIS2142739, the Alfred P. Sloan Foundation Fellowship, and NSF grant No. IIS2203097.Any opinions, findings and conclusions or recommendations expressed in this material are those of the authors and do not necessarily state or reflect those of the United States Government or any agency thereof.
Language models as zero-shot planners: Extracting actionable knowledge for embodied agents. Wenlong Huang, Pieter Abbeel, Deepak Pathak, Igor Mordatch, International Conference on Machine Learning. PMLR2022</p>
<p>Language models as agent models. Jacob Andreas, Findings of the Association for Computational Linguistics: EMNLP 2022. Abu Dhabi, United Arab EmiratesAssociation for Computational LinguisticsDecember 2022</p>
<p>Learning dynamic belief graphs to generalize on text-based games. Ashutosh Adhikari, Xingdi Yuan, Marc-Alexandre Côté, Mikuláš Zelinka, Marc-Antoine Rondeau, Romain Laroche, Pascal Poupart, Jian Tang, Adam Trischler, Will Hamilton, Advances in Neural Information Processing Systems. 202033</p>
<p>Learning knowledge graph-based world models of textual environments. Prithviraj Ammanabrolu, Mark Riedl, Advances in Neural Information Processing Systems. A Beygelzimer, Y Dauphin, P Liang, J Wortman Vaughan, 2021</p>
<p>reasoning over procedural text. Niket Tandon, Bhavana Dalvi, Keisuke Sakaguchi, Peter Clark, Antoine Bosselut, 10.18653/v1/D19-1629Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP). the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)Hong Kong, ChinaAssociation for Computational LinguisticsNovember 2019WIQA: A dataset for "what if</p>
<p>Language models of code are few-shot commonsense learners. Aman Madaan, Shuyan Zhou, Uri Alon, Yiming Yang, Graham Neubig, Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing. the 2022 Conference on Empirical Methods in Natural Language ProcessingAbu Dhabi, United Arab EmiratesAssociation for Computational LinguisticsDecember 2022</p>
<p>Selection-inference: Exploiting large language models for interpretable logical reasoning. Antonia Creswell, Murray Shanahan, Irina Higgins, The Eleventh International Conference on Learning Representations. 2023</p>
<p>Language models are few-shot learners. Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Advances in neural information processing systems. 202033</p>
<p>Training language models to follow instructions with human feedback. Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, Advances in Neural Information Processing Systems. 202235</p>
<p>Sébastien Bubeck, Varun Chandrasekaran, Ronen Eldan, Johannes Gehrke, Eric Horvitz, Ece Kamar, Peter Lee, Yin Tat Lee, Yuanzhi Li, Scott Lundberg, arXiv:2303.12712Sparks of artificial general intelligence: Early experiments with gpt-4. 2023arXiv preprint</p>
<p>Chain of thought prompting elicits reasoning in large language models. Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed H Chi, Denny Quoc V Le, Zhou, Advances in Neural Information Processing Systems. Alice H Oh, Alekh Agarwal, Danielle Belgrave, Kyunghyun Cho, 2022</p>
<p>Large language models are zero-shot reasoners. Takeshi Kojima, Shane Shixiang, Machel Gu, Yutaka Reid, Yusuke Matsuo, Iwasawa, Advances in Neural Information Processing Systems. Alice H Oh, Alekh Agarwal, Danielle Belgrave, Kyunghyun Cho, 2022</p>
<p>Least-to-most prompting enables complex reasoning in large language models. Denny Zhou, Nathanael Schärli, Le Hou, Jason Wei, Nathan Scales, Xuezhi Wang, Dale Schuurmans, Claire Cui, Olivier Bousquet, Ed H Quoc V Le, Chi, The Eleventh International Conference on Learning Representations. 2023</p>
<p>Self-consistency improves chain of thought reasoning in language models. Xuezhi Wang, Jason Wei, Dale Schuurmans, Ed H Quoc V Le, Sharan Chi, Aakanksha Narang, Denny Chowdhery, Zhou, The Eleventh International Conference on Learning Representations. 2023</p>
<p>Mapping language models to grounded conceptual spaces. Roma Patel, Ellie Pavlick, International Conference on Learning Representations. 2022</p>
<p>Are NLP models really able to solve simple math word problems?. Arkil Patel, Satwik Bhattamishra, Navin Goyal, doi: 10.18653Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language TechnologiesAssociation for Computational LinguisticsJune 2021</p>
<p>URL. </p>
<p>Recitation-augmented language models. Zhiqing Sun, Xuezhi Wang, Yi Tay, Yiming Yang, Denny Zhou, The Eleventh International Conference on Learning Representations. 2023</p>
<p>Large language models still can't plan (a benchmark for LLMs on planning and reasoning about change). Karthik Valmeekam, Alberto Olmo, Sarath Sreedharan, Subbarao Kambhampati, NeurIPS 2022 Foundation Models for Decision Making Workshop. 2022</p>
<p>Minding language models' (lack of) theory of mind: A plug-and-play multi-character belief tracker. Melanie Sclar, Sachin Kumar, Peter West, Alane Suhr, Yejin Choi, Yulia Tsvetkov, 10.18653/v1/2023.acl-long.780Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics. Long Papers. the 61st Annual Meeting of the Association for Computational LinguisticsToronto, CanadaAssociation for Computational LinguisticsJuly 20231</p>
<p>Could you give me a hint ? generating inference graphs for defeasible reasoning. Aman Madaan, Dheeraj Rajagopal, Niket Tandon, Yiming Yang, Eduard Hovy, 10.18653/v1/2021.findings-acl.456Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021. Association for Computational LinguisticsAugust 2021</p>
<p>ExplaGraphs: An explanation graph generation task for structured commonsense reasoning. Swarnadeep Saha, Prateek Yadav, Lisa Bauer, Mohit Bansal, 10.18653/v1/2021.emnlp-main.609Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing. the 2021 Conference on Empirical Methods in Natural Language ProcessingDominican RepublicAssociation for Computational LinguisticsNovember 2021Online and Punta Cana</p>
<p>Crepe: Open-domain question answering with false presuppositions. Xinyan Velocity, Yu , Sewon Min, Luke Zettlemoyer, Hannaneh Hajishirzi, arXiv:2211.172572022arXiv preprint</p>
<p>GreaseLM: Graph REASoning enhanced language models. Xikun Zhang, Antoine Bosselut, Michihiro Yasunaga, Hongyu Ren, Percy Liang, Christopher D Manning, Jure Leskovec, International Conference on Learning Representations. 2022a</p>
<p>An empirical study on few-shot knowledge probing for pretrained language models. Tianxing He, Kyunghyun Cho, James Glass, 2021</p>
<p>Exploring the potential of large language models (llms) in learning on graphs. Zhikai Chen, Haitao Mao, Hang Li, Wei Jin, Hongzhi Wen, Xiaochi Wei, Shuaiqiang Wang, Dawei Yin, Wenqi Fan, Hui Liu, arXiv:2307.033932023arXiv preprint</p>
<p>Program induction by rationale generation: Learning to solve and explain algebraic word problems. Wang Ling, Dani Yogatama, Chris Dyer, Phil Blunsom, 10.18653/v1/P17-1015Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics. Long Papers. the 55th Annual Meeting of the Association for Computational LinguisticsVancouver, CanadaAssociation for Computational LinguisticsJuly 20171</p>
<p>Training verifiers to solve math word problems. Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, arXiv:2110.141682021arXiv preprint</p>
<p>Solving math word problems by combining language models with symbolic solvers. Joy He-Yueya, Gabriel Poesia, Rose E Wang, Noah D Goodman, arXiv:2304.091022023arXiv preprint</p>
<p>Thibaut Hugo Touvron, Gautier Lavril, Xavier Izacard, Marie-Anne Martinet, Timothée Lachaux, Baptiste Lacroix, Naman Rozière, Eric Goyal, Hambro, arXiv:2302.13971Faisal Azhar, et al. Llama: Open and efficient foundation language models. 2023arXiv preprint</p>
<p>Large language models can be easily distracted by irrelevant context. Freda Shi, Xinyun Chen, Kanishka Misra, Nathan Scales, David Dohan, Ed H Chi, Nathanael Schärli, Denny Zhou, International Conference on Machine Learning. PMLR2023</p>
<p>Naturalproofs: Mathematical theorem proving in natural language. Sean Welleck, Jiacheng Liu, Ronan Le Bras, Hannaneh Hajishirzi, Yejin Choi, Kyunghyun Cho, Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track (Round 1). 2021</p>
<p>Naturalprover: Grounded mathematical proof generation with language models. Sean Welleck, Jiacheng Liu, Ximing Lu, Hannaneh Hajishirzi, Yejin Choi, Advances in Neural Information Processing Systems. Alice H Oh, Alekh Agarwal, Danielle Belgrave, Kyunghyun Cho, 2022</p>
<p>Beyond the imitation game: Quantifying and extrapolating the capabilities of language models. Aarohi Srivastava, Abhinav Rastogi, Abhishek Rao, Abu Awal, Md Shoeb, Abubakar Abid, Adam Fisch, Adam Adam R Brown, Aditya Santoro, Adrià Gupta, Garriga-Alonso, Transactions on Machine Learning Research. 2023</p>
<p>CommonsenseQA: A question answering challenge targeting commonsense knowledge. Alon Talmor, Jonathan Herzig, Nicholas Lourie, Jonathan Berant, 10.18653/v1/N19-1421Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. Long and Short Papers. the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language TechnologiesMinneapolis, MinnesotaAssociation for Computational LinguisticsJune 20191</p>
<p>Did Aristotle Use a Laptop? A Question Answering Benchmark with Implicit Reasoning Strategies. Mor Geva, Daniel Khashabi, Elad Segal, Tushar Khot, Dan Roth, Jonathan Berant, Transactions of the Association for Computational Linguistics2021</p>
<p>Teaching algorithmic reasoning via in-context learning. Hattie Zhou, Azade Nova, Hugo Larochelle, Aaron Courville, Behnam Neyshabur, Hanie Sedghi, arXiv:2211.090662022arXiv preprint</p>
<p>Recursion of thought: A divide-and-conquer approach to multicontext reasoning with language models. Soochan Lee, Gunhee Kim, 10.18653/v1/2023.findings-acl.40Findings of the Association for Computational Linguistics: ACL 2023. Toronto, CanadaAssociation for Computational LinguisticsJuly 2023</p>
<p>Parsel: A (de-) compositional framework for algorithmic reasoning with language models. Eric Zelikman, Qian Huang, Gabriel Poesia, Nick Noah D Goodman, Haber, arXiv:2212.105612023arXiv preprint</p>
<p>Code execution with pre-trained language models. Chenxiao Liu, Shuai Lu, Weizhu Chen, Daxin Jiang, Alexey Svyatkovskiy, Shengyu Fu, Neel Sundaresan, Nan Duan, 10.18653/v1/2023.findings-acl.308Findings of the Association for Computational Linguistics: ACL 2023. Toronto, CanadaAssociation for Computational LinguisticsJuly 2023</p>
<p>Opt: Open pre-trained transformer language models. Susan Zhang, Stephen Roller, Naman Goyal, Mikel Artetxe, Moya Chen, Shuohui Chen, Christopher Dewan, Mona Diab, Xian Li, Xi Victoria Lin, arXiv:2205.010682022barXiv preprint</p>            </div>
        </div>

    </div>
</body>
</html>