<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-9532 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-9532</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-9532</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-165.html">extraction-schema-165</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being used to distill, extract, or synthesize qualitative laws, principles, or generalizable rules from large numbers of scholarly input papers, including details of the methods, domains, evaluation, and results.</div>
                <p><strong>Paper ID:</strong> paper-274192664</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2411.14473v4.pdf" target="_blank">Large Language Model for Qualitative Research: A Systematic Mapping Study</a></p>
                <p><strong>Paper Abstract:</strong> .</p>
                <p><strong>Cost:</strong> 0.014</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e9532.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e9532.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being used to distill, extract, or synthesize qualitative laws, principles, or generalizable rules from large numbers of scholarly input papers, including details of the methods, domains, evaluation, and results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ChatGPT-4 (SMS use)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>ChatGPT 4.0 (OpenAI)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>The authors used ChatGPT 4.0 to automate data extraction (DE1–DE16) and translation during this systematic mapping, accelerating identification/selection of candidate studies and producing structured extraction outputs that were then manually verified.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_name</strong></td>
                            <td>ChatGPT 4.0 (GPT-4 family)</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_description</strong></td>
                            <td>Paid OpenAI conversational LLM (GPT-4 family). No model size or architectural details are specified in the paper; the authors did not report any fine-tuning—use was via prompt engineering with iterative prompt versions archived on Zenodo.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Systematic literature mapping / qualitative meta-research</td>
                        </tr>
                        <tr>
                            <td><strong>input_corpus_description</strong></td>
                            <td>Initial retrieval of 354 candidate records across Scopus, ACM DL, IEEE Xplore, Web of Science, SBC Open Lib, and arXiv; ChatGPT was employed in the data-extraction stage on the studies analyzed (final included set = 8 studies) and for translation of texts into English.</td>
                        </tr>
                        <tr>
                            <td><strong>qualitative_law_type</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>qualitative_law_example</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>extraction_methodology</strong></td>
                            <td>Prompt-engineered conversational queries aligned to predefined data-extraction criteria (DE1–DE16). Iterative prompt refinement was performed; outputs subject to manual checking and full-text reading when ambiguous. Prompts were published on Zenodo to support reproducibility.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method</strong></td>
                            <td>Human verification and manual review: all model outputs were checked by researchers; ambiguous cases triggered full article rereads. The authors used test articles with known responses to validate prompt alignment (construct validation). No formal, published quantitative evaluation of the SMS extraction step (e.g., precision/recall) is reported for the authors' use of ChatGPT.</td>
                        </tr>
                        <tr>
                            <td><strong>results_summary</strong></td>
                            <td>Authors report ChatGPT significantly accelerated the identification/selection and structured extraction tasks and supported translations; however, all extractions were subsequently verified by humans. The paper emphasizes efficiency gains but does not provide quantitative extraction-performance metrics for the SMS use.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td>No quantitative baseline comparison reported for the SMS extraction workflow (no measured human-only vs LLM-assisted extraction metrics published in this paper); instead the authors relied on manual verification as quality control.</td>
                        </tr>
                        <tr>
                            <td><strong>reported_limitations</strong></td>
                            <td>Potential superficiality and loss of deep contextual understanding when relying on LLM outputs; risk of confirmation bias when LLMs are used both to extract data and to evaluate LLM effectiveness; dependence on high-quality prompt engineering; exclusion of studies without prompt descriptions (DE11) may bias results.</td>
                        </tr>
                        <tr>
                            <td><strong>bias_or_hallucination_issues</strong></td>
                            <td>Paper explicitly notes risks of hallucinations and model bias and flags reproducibility concerns due to model evolution; mitigation was human verification and manual rereading when doubts arose.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Large Language Model for Qualitative Research: A Systematic Mapping Study', 'publication_date_yy_mm': '2025-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9532.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e9532.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being used to distill, extract, or synthesize qualitative laws, principles, or generalizable rules from large numbers of scholarly input papers, including details of the methods, domains, evaluation, and results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ChatExtract (Polak & Morgan)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>ChatExtract — Extracting accurate materials data from research papers with conversational language models and prompt engineering</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A pipeline leveraging conversational LLMs (e.g., GPT-4) and prompt engineering to extract structured materials-science data from research papers; cited in this SMS as achieving high precision and recall.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Extracting accurate materials data from research papers with conversational language models and prompt engineering</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_name</strong></td>
                            <td>GPT-4 (conversational usage)</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_description</strong></td>
                            <td>Conversational GPT-4 family model used via prompt engineering; the SMS reference does not provide internal model-size or fine-tuning details for ChatExtract.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Materials science — extraction of materials experimental/measurement data from research articles</td>
                        </tr>
                        <tr>
                            <td><strong>input_corpus_description</strong></td>
                            <td>Research papers in the materials domain (the SMS references the work but does not state the exact corpus size or filtering used in Polak & Morgan's experiments).</td>
                        </tr>
                        <tr>
                            <td><strong>qualitative_law_type</strong></td>
                            <td>Structured data extraction (materials properties and experimental metadata) enabling downstream synthesis of materials relationships</td>
                        </tr>
                        <tr>
                            <td><strong>qualitative_law_example</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>extraction_methodology</strong></td>
                            <td>Conversational LLM driven extraction with prompt engineering (the method is named ChatExtract); details in the original paper are cited but not reproduced in the SMS.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method</strong></td>
                            <td>Reported quantitative evaluation using precision and recall metrics (the SMS cites results 'close to 90% precision and recall'). The SMS does not reproduce the full evaluation protocol.</td>
                        </tr>
                        <tr>
                            <td><strong>results_summary</strong></td>
                            <td>Cited result: ChatExtract achieved close to 90% precision and recall for extracting materials data from research papers, indicating conversational LLMs with careful prompt engineering can extract structured scientific data effectively according to the cited study.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td>Not specified in the SMS (the SMS only reports the precision/recall numbers from the cited paper without detailing baseline comparisons).</td>
                        </tr>
                        <tr>
                            <td><strong>reported_limitations</strong></td>
                            <td>The SMS does not enumerate the original study's limitations; more general limitations (from the mapping) include need for prompt engineering and risks of hallucination and context-misinterpretation.</td>
                        </tr>
                        <tr>
                            <td><strong>bias_or_hallucination_issues</strong></td>
                            <td>Not detailed for this cited method in the SMS; the mapping warns generally about hallucinations and biases for LLM-based extraction methods.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Large Language Model for Qualitative Research: A Systematic Mapping Study', 'publication_date_yy_mm': '2025-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e9532.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e9532.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of large language models (LLMs) being used to distill, extract, or synthesize qualitative laws, principles, or generalizable rules from large numbers of scholarly input papers, including details of the methods, domains, evaluation, and results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ChatGPT screening (Syriani et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Screening articles for systematic reviews with ChatGPT</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Study cited in the SMS that evaluated ChatGPT to automate article screening in systematic reviews and reported promising accuracy.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Screening articles for systematic reviews with ChatGPT</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_name</strong></td>
                            <td>ChatGPT (version unspecified in SMS)</td>
                        </tr>
                        <tr>
                            <td><strong>llm_model_description</strong></td>
                            <td>Conversational ChatGPT model; the SMS does not specify model version or model-size details for this cited work.</td>
                        </tr>
                        <tr>
                            <td><strong>application_domain</strong></td>
                            <td>Systematic review screening / meta-research</td>
                        </tr>
                        <tr>
                            <td><strong>input_corpus_description</strong></td>
                            <td>Candidate articles for systematic reviews (the SMS does not provide exact corpus size from the cited study).</td>
                        </tr>
                        <tr>
                            <td><strong>qualitative_law_type</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>qualitative_law_example</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>extraction_methodology</strong></td>
                            <td>Automated screening/classification of candidate articles using ChatGPT prompts; the SMS cites the use but does not give the screening prompt specifics.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_method</strong></td>
                            <td>Reported evaluation metric: accuracy (cited value = 82%). Specifics of test set, annotators, or baselines are not provided in the SMS.</td>
                        </tr>
                        <tr>
                            <td><strong>results_summary</strong></td>
                            <td>Cited outcome: ChatGPT achieved approximately 82% accuracy in automating article screening, indicating promise for reducing manual screening workload though not full parity with humans per the SMS description.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_baseline</strong></td>
                            <td>Implicit comparison to human screening (accuracy reported); the SMS does not provide further quantitative baselines or error analyses from the cited study.</td>
                        </tr>
                        <tr>
                            <td><strong>reported_limitations</strong></td>
                            <td>The SMS does not list study-specific limitations for Syriani et al.; mapping-level concerns apply (need for human oversight, risk of missing nuanced inclusion/exclusion rationale).</td>
                        </tr>
                        <tr>
                            <td><strong>bias_or_hallucination_issues</strong></td>
                            <td>Not specifically described for the cited screening study in the SMS, but the mapping flags hallucination and bias risks for LLM applications generally.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Large Language Model for Qualitative Research: A Systematic Mapping Study', 'publication_date_yy_mm': '2025-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Extracting accurate materials data from research papers with conversational language models and prompt engineering <em>(Rating: 2)</em></li>
                <li>Screening articles for systematic reviews with ChatGPT <em>(Rating: 2)</em></li>
                <li>CollabCoder: A Lower-barrier, Rigorous Workflow for Inductive Collaborative Qualitative Analysis with Large Language Models <em>(Rating: 1)</em></li>
                <li>Inductive thematic analysis of healthcare qualitative interviews using open-source large language models: How does it compare to traditional methods? <em>(Rating: 1)</em></li>
                <li>Performing an inductive thematic analysis of semistructured interviews with a large language model: An exploration and provocation on the limits of the approach <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-9532",
    "paper_id": "paper-274192664",
    "extraction_schema_id": "extraction-schema-165",
    "extracted_data": [
        {
            "name_short": "ChatGPT-4 (SMS use)",
            "name_full": "ChatGPT 4.0 (OpenAI)",
            "brief_description": "The authors used ChatGPT 4.0 to automate data extraction (DE1–DE16) and translation during this systematic mapping, accelerating identification/selection of candidate studies and producing structured extraction outputs that were then manually verified.",
            "citation_title": "here",
            "mention_or_use": "use",
            "llm_model_name": "ChatGPT 4.0 (GPT-4 family)",
            "llm_model_description": "Paid OpenAI conversational LLM (GPT-4 family). No model size or architectural details are specified in the paper; the authors did not report any fine-tuning—use was via prompt engineering with iterative prompt versions archived on Zenodo.",
            "application_domain": "Systematic literature mapping / qualitative meta-research",
            "input_corpus_description": "Initial retrieval of 354 candidate records across Scopus, ACM DL, IEEE Xplore, Web of Science, SBC Open Lib, and arXiv; ChatGPT was employed in the data-extraction stage on the studies analyzed (final included set = 8 studies) and for translation of texts into English.",
            "qualitative_law_type": null,
            "qualitative_law_example": null,
            "extraction_methodology": "Prompt-engineered conversational queries aligned to predefined data-extraction criteria (DE1–DE16). Iterative prompt refinement was performed; outputs subject to manual checking and full-text reading when ambiguous. Prompts were published on Zenodo to support reproducibility.",
            "evaluation_method": "Human verification and manual review: all model outputs were checked by researchers; ambiguous cases triggered full article rereads. The authors used test articles with known responses to validate prompt alignment (construct validation). No formal, published quantitative evaluation of the SMS extraction step (e.g., precision/recall) is reported for the authors' use of ChatGPT.",
            "results_summary": "Authors report ChatGPT significantly accelerated the identification/selection and structured extraction tasks and supported translations; however, all extractions were subsequently verified by humans. The paper emphasizes efficiency gains but does not provide quantitative extraction-performance metrics for the SMS use.",
            "comparison_to_baseline": "No quantitative baseline comparison reported for the SMS extraction workflow (no measured human-only vs LLM-assisted extraction metrics published in this paper); instead the authors relied on manual verification as quality control.",
            "reported_limitations": "Potential superficiality and loss of deep contextual understanding when relying on LLM outputs; risk of confirmation bias when LLMs are used both to extract data and to evaluate LLM effectiveness; dependence on high-quality prompt engineering; exclusion of studies without prompt descriptions (DE11) may bias results.",
            "bias_or_hallucination_issues": "Paper explicitly notes risks of hallucinations and model bias and flags reproducibility concerns due to model evolution; mitigation was human verification and manual rereading when doubts arose.",
            "uuid": "e9532.0",
            "source_info": {
                "paper_title": "Large Language Model for Qualitative Research: A Systematic Mapping Study",
                "publication_date_yy_mm": "2025-05"
            }
        },
        {
            "name_short": "ChatExtract (Polak & Morgan)",
            "name_full": "ChatExtract — Extracting accurate materials data from research papers with conversational language models and prompt engineering",
            "brief_description": "A pipeline leveraging conversational LLMs (e.g., GPT-4) and prompt engineering to extract structured materials-science data from research papers; cited in this SMS as achieving high precision and recall.",
            "citation_title": "Extracting accurate materials data from research papers with conversational language models and prompt engineering",
            "mention_or_use": "mention",
            "llm_model_name": "GPT-4 (conversational usage)",
            "llm_model_description": "Conversational GPT-4 family model used via prompt engineering; the SMS reference does not provide internal model-size or fine-tuning details for ChatExtract.",
            "application_domain": "Materials science — extraction of materials experimental/measurement data from research articles",
            "input_corpus_description": "Research papers in the materials domain (the SMS references the work but does not state the exact corpus size or filtering used in Polak & Morgan's experiments).",
            "qualitative_law_type": "Structured data extraction (materials properties and experimental metadata) enabling downstream synthesis of materials relationships",
            "qualitative_law_example": null,
            "extraction_methodology": "Conversational LLM driven extraction with prompt engineering (the method is named ChatExtract); details in the original paper are cited but not reproduced in the SMS.",
            "evaluation_method": "Reported quantitative evaluation using precision and recall metrics (the SMS cites results 'close to 90% precision and recall'). The SMS does not reproduce the full evaluation protocol.",
            "results_summary": "Cited result: ChatExtract achieved close to 90% precision and recall for extracting materials data from research papers, indicating conversational LLMs with careful prompt engineering can extract structured scientific data effectively according to the cited study.",
            "comparison_to_baseline": "Not specified in the SMS (the SMS only reports the precision/recall numbers from the cited paper without detailing baseline comparisons).",
            "reported_limitations": "The SMS does not enumerate the original study's limitations; more general limitations (from the mapping) include need for prompt engineering and risks of hallucination and context-misinterpretation.",
            "bias_or_hallucination_issues": "Not detailed for this cited method in the SMS; the mapping warns generally about hallucinations and biases for LLM-based extraction methods.",
            "uuid": "e9532.1",
            "source_info": {
                "paper_title": "Large Language Model for Qualitative Research: A Systematic Mapping Study",
                "publication_date_yy_mm": "2025-05"
            }
        },
        {
            "name_short": "ChatGPT screening (Syriani et al.)",
            "name_full": "Screening articles for systematic reviews with ChatGPT",
            "brief_description": "Study cited in the SMS that evaluated ChatGPT to automate article screening in systematic reviews and reported promising accuracy.",
            "citation_title": "Screening articles for systematic reviews with ChatGPT",
            "mention_or_use": "mention",
            "llm_model_name": "ChatGPT (version unspecified in SMS)",
            "llm_model_description": "Conversational ChatGPT model; the SMS does not specify model version or model-size details for this cited work.",
            "application_domain": "Systematic review screening / meta-research",
            "input_corpus_description": "Candidate articles for systematic reviews (the SMS does not provide exact corpus size from the cited study).",
            "qualitative_law_type": null,
            "qualitative_law_example": null,
            "extraction_methodology": "Automated screening/classification of candidate articles using ChatGPT prompts; the SMS cites the use but does not give the screening prompt specifics.",
            "evaluation_method": "Reported evaluation metric: accuracy (cited value = 82%). Specifics of test set, annotators, or baselines are not provided in the SMS.",
            "results_summary": "Cited outcome: ChatGPT achieved approximately 82% accuracy in automating article screening, indicating promise for reducing manual screening workload though not full parity with humans per the SMS description.",
            "comparison_to_baseline": "Implicit comparison to human screening (accuracy reported); the SMS does not provide further quantitative baselines or error analyses from the cited study.",
            "reported_limitations": "The SMS does not list study-specific limitations for Syriani et al.; mapping-level concerns apply (need for human oversight, risk of missing nuanced inclusion/exclusion rationale).",
            "bias_or_hallucination_issues": "Not specifically described for the cited screening study in the SMS, but the mapping flags hallucination and bias risks for LLM applications generally.",
            "uuid": "e9532.2",
            "source_info": {
                "paper_title": "Large Language Model for Qualitative Research: A Systematic Mapping Study",
                "publication_date_yy_mm": "2025-05"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Extracting accurate materials data from research papers with conversational language models and prompt engineering",
            "rating": 2,
            "sanitized_title": "extracting_accurate_materials_data_from_research_papers_with_conversational_language_models_and_prompt_engineering"
        },
        {
            "paper_title": "Screening articles for systematic reviews with ChatGPT",
            "rating": 2,
            "sanitized_title": "screening_articles_for_systematic_reviews_with_chatgpt"
        },
        {
            "paper_title": "CollabCoder: A Lower-barrier, Rigorous Workflow for Inductive Collaborative Qualitative Analysis with Large Language Models",
            "rating": 1,
            "sanitized_title": "collabcoder_a_lowerbarrier_rigorous_workflow_for_inductive_collaborative_qualitative_analysis_with_large_language_models"
        },
        {
            "paper_title": "Inductive thematic analysis of healthcare qualitative interviews using open-source large language models: How does it compare to traditional methods?",
            "rating": 1,
            "sanitized_title": "inductive_thematic_analysis_of_healthcare_qualitative_interviews_using_opensource_large_language_models_how_does_it_compare_to_traditional_methods"
        },
        {
            "paper_title": "Performing an inductive thematic analysis of semistructured interviews with a large language model: An exploration and provocation on the limits of the approach",
            "rating": 1,
            "sanitized_title": "performing_an_inductive_thematic_analysis_of_semistructured_interviews_with_a_large_language_model_an_exploration_and_provocation_on_the_limits_of_the_approach"
        }
    ],
    "cost": 0.01358,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Large Language Model for Qualitative Research: A Systematic Mapping Study
6 Mar 2025</p>
<p>Cauã Ferreira Barros 
Informatics Institute Federal University of Goiás Goiânia
Brazil</p>
<p>Bruna Borges Azevedo brunabazevedo@discente.ufg.br 
Informatics Institute Federal University of Goiás Goiânia
Brazil</p>
<p>Valdemar Vicente valdemarneto@ufg.br 
Informatics Institute Federal University of Goiás Goiânia
Brazil</p>
<p>Graciano Neto 
Informatics Institute Federal University of Goiás Goiânia
Brazil</p>
<p>Mohamad Kassab mkassab@bu.edu 
Boston University
BostonUSA</p>
<p>Marcos Kalinowski kalinowski@inf.puc-rio.br 
Pontifical Catholic University of Rio de Janeiro Rio de Janeiro
Brazil</p>
<p>Hugo Alexandre 
Informatics Institute Federal University of Goiás Goiânia
Brazil</p>
<p>D Do Nascimento 
Informatics Institute Federal University of Goiás Goiânia
Brazil</p>
<p>Michelle C G S P Bandeira 
Faculty of Science and Technology
Federal University of Goiás Aparecida de Goiânia
Brazil</p>
<p>Large Language Model for Qualitative Research: A Systematic Mapping Study
6 Mar 2025C5CBCD9B0AA4FE1EB66818532C664D58arXiv:2411.14473v4[cs.CL]Qualitative ResearchQualitative AnalysisLarge Language ModelLLMSoftware Engineering
The exponential growth of text-based data in domains such as healthcare, education, and social sciences has outpaced the capacity of traditional qualitative analysis methods, which are time-intensive and prone to subjectivity.Large Language Models (LLMs), powered by advanced generative AI, have emerged as transformative tools capable of automating and enhancing qualitative analysis.This study systematically maps the literature on the use of LLMs for qualitative research, exploring their application contexts, configurations, methodologies, and evaluation metrics.Findings reveal that LLMs are utilized across diverse fields, demonstrating the potential to automate processes traditionally requiring extensive human input.However, challenges such as reliance on prompt engineering, occasional inaccuracies, and contextual limitations remain significant barriers.This research highlights opportunities for integrating LLMs with human expertise, improving model robustness, and refining evaluation methodologies.By synthesizing trends and identifying research gaps, this study aims to guide future innovations in the application of LLMs for qualitative analysis.</p>
<p>I. INTRODUCTION</p>
<p>The presence of Artificial Intelligence (AI) has been intensifying in supporting various human activities.Generative AI, particularly Large Language Models (LLMs), has demonstrated significant potential for automating complex processes by processing and generating human-like text [1], [2], [3].These models are trained on extensive textual data and designed to identify complex patterns in natural language, making them versatile tools for tasks such as machine translation, summarization, text editing, chatbot assistance, and even software code generation [4], [5].</p>
<p>One of the most promising applications of LLMs is in qualitative analysis, a research approach focused on exploring and interpreting data to uncover patterns, themes, and categories.Traditional qualitative analysis methods, such as grounded theory or thematic analysis, often require intensive human effort and are prone to subjectivity [6], [7].Moreover, these methods struggle with scalability, particularly when analyzing large datasets, such as hundreds of interviews or millions of social media posts.LLMs offer transformative solutions to these challenges, automating processes like open coding and theme extraction while providing consistent and reproducible outputs [8], [9].</p>
<p>The integration of LLMs into qualitative research presents transformative opportunities and challenges, particularly in domains such as Software Engineering (SE).As highlighted by Bano et al. [10], LLMs have the potential to address longstanding challenges in qualitative research, such as the time-consuming nature of manual analysis, inconsistencies in interpretation by multiple simultaneous researchers, and scalability limitations.While LLMs can assist in automating tasks such as coding, theme identification, and pattern recognition, they also raise critical concerns related to contextual understanding, reproducibility, and ethical implications.These insights underscore the urgent need for systematic investigations into the use of LLMs in qualitative research.</p>
<p>The main contribution of this paper is to report the results of a systematic mapping aimed at analyzing the state of the art on the use of LLMs in qualitative analysis, with the goal of identifying trends, research gaps, and opportunities for future investigations.This study seeks to provide valuable insights for researchers looking to integrate LLMs into their qualitative analysis processes, guiding them toward works that offer detailed prompt data and information on their effectiveness.In doing so, the paper not only provides a comprehensive overview of the state of the art but also highlights the potential of these technologies to transform how large volumes of textual data are processed and interpreted.</p>
<p>This paper is structured as follows: Section II provides a brief background on qualitative analysis and LLMs.Section III describes the systematic mapping protocol and results.Section IV presents a summary of contributions and research opportunities.Section V discusses the threats to validity.</p>
<p>Section VI presents the main conclusions.Finally, Section VII presents the take away lessons.</p>
<p>II. BACKGROUND A. Limitations of Traditional Qualitative Methods</p>
<p>While qualitative research methods, such as grounded theory or thematic analysis, provide valuable insights into complex phenomena, they face significant challenges.For instance, manual coding and categorization processes are notoriously labor-intensive, often requiring weeks or even months of effort to analyze large datasets effectively [6].Additionally, these methods are prone to subjectivity, as researchers' biases can unconsciously influence coding decisions, impacting the reliability and validity of findings [7].</p>
<p>Moreover, traditional methods struggle with scalability.For example, analyzing hundreds of interviews or millions of social media posts in real time is impractical for human analysts.These limitations hinder the efficiency and breadth of qualitative analysis, particularly in rapidly evolving fields like software engineering or healthcare.</p>
<p>B. Capabilities of LLMs in Overcoming Limitations</p>
<p>LLMs offer transformative solutions to many challenges faced by traditional qualitative research methods.LLMs, such as GPT-4, LLaMA, and ChatGPT, are generative AI systems trained on vast datasets, enabling them to process and generate human-like text [4], [5].By leveraging billions of parameters, these models excel in identifying patterns, performing thematic analysis, and automating coding processes.</p>
<p>• Automation of Coding: LLMs can rapidly process and analyze text, performing open and axial coding in minutes.For example, ChatGPT has been employed to analyze qualitative survey responses, extracting key themes such as student satisfaction and resource accessibility in educational research [11], [12].• Reducing Subjectivity: While human coding is prone to inconsistency, LLMs provide consistent and reproducible outputs, especially when fine-tuned or used with standardized prompts [8].However, their adaptability and evolution over time may impact reproducibility.This minimizes bias and ensures greater reliability in qualitative findings, though care must be taken to account for potential variability in outputs across different versions of the models.• Scalability and Speed: Unlike human analysts, LLMs can handle vast amounts of unstructured data efficiently.For example, in healthcare studies, LLMs have been used to process patient feedback, identifying recurring themes in hours rather than weeks [9].</p>
<p>C. Illustrative Examples</p>
<p>The following examples demonstrate the transformative potential of LLMs:</p>
<p>• Healthcare Case Study: In a study analyzing patient feedback, an open-source LLM was fine-tuned to perform inductive thematic analysis, identifying critical concerns like delays in care and communication breakdowns [9].This process significantly reduced the time required for analysis while maintainiong accuracy.• Education Use Case: ChatGPT was used to categorize open-ended survey responses from students, identifying patterns such as dissatisfaction with online learning platforms and preferences for in-person classes [11].</p>
<p>The automated approach streamlined analysis, allowing researchers to focus on interpreting results.</p>
<p>D. Motivation for this Study</p>
<p>Despite their potential, LLMs face limitations that must be addressed for optimal application in qualitative research.For example, they are highly dependent on well-structured prompts, which, if poorly designed, can lead to inaccurate or incomplete outputs [13], [9].Additionally, LLMs can generate "hallucinations"-fabricated responses that lack basis in the data [14].These challenges highlight the need for systematic studies to explore best practices, identify gaps, and refine methodologies for integrating LLMs into qualitative research.</p>
<p>This study aims to fill this gap by systematically mapping the current state of the art in LLM applications for qualitative research.By analyzing existing studies, this research identifies trends, challenges, and opportunities, providing a roadmap for researchers seeking to leverage LLMs effectively in their workflows.</p>
<p>The study by Lec ¸a et al. [15] also converges in this direction by presenting a systematic mapping to investigate how LLMs are typically used in qualitative analysis and how they can be applied in Software Engineering research.Their study and this study complement each other in several aspects.However, while Lec ¸a et al. [15] explore benefits (e.g., support in theme and pattern identification and flexibility for researchers) and limitations (e.g., ethical concerns and privacy), this study focuses specifically on the effectiveness of LLMs and the evaluation methods used, including specific metrics and criteria.Together, these studies provide a comprehensive perspective mapping the state of the art as a guide for future work and offering an analysis of the contextual implications and challenges in using these technologies.Both contribute to the understanding and applicability of LLMs in qualitative analysis.</p>
<p>III. SYSTEMATIC MAPPING STUDY (SMS)</p>
<p>The structure adopted in this systematic mapping study was developed in accordance with the guidelines proposed by Kitchenham and Charters [16].The main stages carried out include planning, conducting and reporting.</p>
<p>Parsif.al1 was used as a support tool for planning, conducting, and reporting the systematic mapping study, enabling the documentation and execution of the protocol.</p>
<p>A. Planning</p>
<p>The objective of this systematic mapping study was to identify the state of the art regarding the relationship between LLMs and qualitative analysis.Thus, the studies of interest include those that assess the application of LLMs in conducting qualitative analyses.Consequently, research questions and the corresponding protocol were established.</p>
<p>B. Search Strategy</p>
<p>A generic search string was developed using the keywords "LLM" and "Qualitative Analysis".These keywords were connected using the logical operator AND, while their synonyms were linked with the OR operator.The terms in the search string were selected to ensure broader coverage of relevant studies.The string was tested in various configurations on the Scopus database, and after a calibration process, the final version defined was:</p>
<p>("LLM" OR "LLMs" OR "Large Language Model" OR "Large Language Models") AND ("Qualitative Analysis"</p>
<p>OR "Qualitative Research" OR "Grounded Theory")</p>
<p>In addition to Scopus2 , searches using the search string were also conducted in the ACM Digital Library3 , IEEExplore4 , Web of Science5 , and SBC Open Lib databases 6 .The searches were carried out during the months of September and October 2024, using filters applied to titles, abstracts, and keywords.No restrictions were placed on the starting publication year.In total, 354 studies were retrieved.</p>
<p>Considering the emerging nature of the research topic and the likelihood of relevant studies not yet undergoing peer review, the Arxiv7 database was also explored using keywords directly, without applying the search string.Arxiv papers were carefully considered due to their potential to provide early access to significant studies that are not yet indexed in major digital libraries like Scopus.Including these papers ensured a comprehensive exploration of the state of the art in LLMs for qualitative analysis.</p>
<p>C. Selection Criteria</p>
<p>Subsequently, selection criteria were established to support the proper identification of relevant studies for this systematic mapping.Titles, abstracts, and keywords were read and analyzed, with the selection criteria outlined in Table I (where IC refers to Inclusion Criteria, and EC refers to Exclusion Criteria).</p>
<p>It is important to note that EC1 is presented as the direct inversion of IC1 to emphasize the mutual exclusivity of these criteria, ensuring clarity in identifying studies that analyze the application of LLMs in qualitative analysis.The remaining exclusion criteria (EC2, EC3 and EC4) were defined independently to address specific attributes of the studies, such as language, accessibility, or type of publication.</p>
<p>ID Description</p>
<p>IC1</p>
<p>The study analyzes the application of LLMs in qualitative analysis.EC1</p>
<p>The study does not analyze the application of LLMs in qualitative analysis.EC2</p>
<p>The study is not written in Portuguese or English.EC3</p>
<p>The study is not openly accessible or available through institutional access.EC4</p>
<p>The study is not a primary study.</p>
<p>D. Data Extraction</p>
<p>A questionnaire was developed to guide the data extraction process.This extraction criterion (DE, which refers to data extraction) is designed to address the research questions (RQ) defined in the study.The questions in the extraction form contain pre-defined response options to ensure consistency in data collection.Table II   The criteria (DE1 to DE16) were used to compose the prompt, and ChatGPT8 was employed in the data extraction stage of the studies analyzed in this systematic mapping.Polak and Morgan [12] reported results close to 90% precision and recall for their proposed method, named ChatExtract, which leverages LLMs like GPT-4 in the data extraction process.Syriani, David, and Kumar [14] highlighted in their findings that the use of ChatGPT for automating the article screening process in systematic reviews shows promising potential, achieving an accuracy of 82%.</p>
<p>Regarding data extraction DE7, open-ended responses were obtained, which involved manual content analysis, as well as consulting the full original text to clarify any potential doubts.</p>
<p>E. Conducting</p>
<p>Figure 1 illustrates the steps followed in the study selection process, starting from the execution of the search string across the databases.A total of 354 studies were retrieved, distributed as follows: 20 from the ACM Digital Library, 30 from IEEExplore, 78 from Web of Science, 32 from SBC Open Lib, 193 from Scopus, and 1 from Arxiv.Subsequently, a refinement process was conducted to select the final set of studies.First, duplicate studies were removed, resulting in 253 studies.Next, inclusion and exclusion criteria were applied based on the reading of titles and abstracts, reducing the total to 34 studies.In the following stage, only studies available for download were included, which further reduced the count to 21.The study [20] was a special case.It was retrieved but was excluded due to lack of full-text access.However, in January 2025, the authors published the complete version on ArXiv.We opted to manually include the study to complement the mapping.</p>
<p>If a study did not fully meet the response for criterion DE1 (i.e., the response was "no" or "partially"), the remaining criteria were not evaluated, and the study was excluded.Additionally, if a study did not meet criterion DE11 ("no"), it was excluded for not describing the prompt engineering used, which is essential to ensure reproducibility.</p>
<p>At the end of this process, 8 studies remained, for which comprehensive data extraction was conducted.Table III presents all the studies that were included in this systematic mapping.</p>
<p>F. Results</p>
<p>The analysis revealed that 75% of the included studies (6 out of 8) were published in 2024, with the remaining two in 2023.This reflects the recent emergence of LLMs in qualitative analysis and the growing interest of the scientific community in this field.</p>
<p>Regarding publication venues, most studies were concentrated in healthcare, education, and cultural studies, with no works identified in Software Engineering (SE).This gap is notable given the potential of LLMs to assist in SE tasks such as requirements engineering and user feedback analysis.A possible reason for this absence is the early-stage adoption of LLMs in SE.Future research could explore their integration in SE-specific venues, assessing their impact on traditionally manual processes.</p>
<p>RQ1: What is the context in which LLMs have been applied to support qualitative analysis?</p>
<p>Studies on the use of LLMs for qualitative analysis are concentrated in fields such as healthcare [8], [9], education [14], [17], [13], cultural studies [19], and technological applications [18].</p>
<p>Regarding the primary objectives, three studies evaluated the potential of LLMs to automate qualitative analysis [14], [17], [13].The study [20] proposed CollabCoder, a workflow integrating LLMs into collaborative qualitative analysis, assisting in code suggestion, discussions, and codebook development.Other studies focused on fully automating qualitative data analysis [8], [19], while [18], [9] compared LLM-assisted qualitative analysis with traditional methods.</p>
<p>RQ2: What LLM model and configuration were used, and which data sources were utilized?</p>
<p>The studies examined various LLM models, including Chat-GPT [8], [18], [13], [20], LLaMA-2 [9], ATLAS.TI [14], BERT [17] and Sabiá-2 medium [19].About 50% of the studies made adjustments or adaptations to the models for analysis [14], [8], [17], [9].However, study [20] used ChatGPT without fine-tuning, relying solely on prompt engineering to assist in qualitative coding.</p>
<p>Regarding data sources, most studies analyzed interviews [14], [9], [13], followed by documents [8], [17], including [20], which used book reviews as qualitative textual data.Other studies examined social media (app user reviews) [18] and song lyrics [19].</p>
<p>RQ3: How was the LLM used to conduct qualitative analysis, and what techniques or methodologies were applied?</p>
<p>All included studies applied techniques and/or methodologies for qualitative analysis, also detailing the prompt engineering used.Theme extraction was combined with content analysis in two studies [14], [18], while others integrated open coding and theme extraction [9], [13].Two studies combined categorization and theme extraction, with one adopting the Grounded Theory approach [8] and the other using content analysis [17].Study [20] followed an inductive approach, structuring open coding and theme extraction within a collaborative workflow based on Grounded Theory and Thematic Analysis.Study [19] tested three techniques: categorization, theme extraction, and topic extraction.</p>
<p>LLM application methods varied among studies.Three employed prompt-based instruction [18], [9], [13].Study [19] combined prompt engineering with automated extraction using BERT, while [17] exclusively used automated extraction with BERT.In [20], ChatGPT provided automated code suggestions, facilitated coder discussions, and assisted in developing final code groupings within an AI-assisted workflow.Other studies applied automated extraction via ATLAS.TI, linked to specific techniques [14], or conducted model training [8].</p>
<p>RQ4: How was the effectiveness of the LLM evaluated, and what were the main results?</p>
<p>All seven included studies compared LLM-assisted qualitative analysis with traditional methods.In [14], [8], [17], [9], [13], results were considered equivalent to traditional methods.Study [19] reported superior performance for LLMs, whereas [18] found LLM-assisted analysis to be less effective, particularly compared to human analysis.Study [20] assessed effectiveness through a user study comparing CollabCoder with Atlas.tiWeb, revealing that CollabCoder improved efficiency by streamlining coder discussions and decision-making while maintaining high agreement rates.Participants also reported a lower learning curve and better workflow support compared to Atlas.tiWeb.</p>
<p>The metrics used to evaluate performance included comparisons between LLM-assisted analysis and human analysis [14], [18], [9], [13], comparisons with human analysis and accuracy [17], and comparisons involving human analysis, accuracy, F1 Score, and precision [8], [19].In [20], the evaluation included metrics such as Cohen's Kappa and Agreement Rate to assess coder consensus, demonstrating that the system facilitated alignment and reduced disagreement in the coding process.</p>
<p>RQ5: What limitations and future research directions were reported?</p>
<p>All studies identified specific limitations in using LLMs for qualitative analysis.One limitation mentioned was the reliance on well-structured prompts for accurate results [9], [13].Another recurring limitation was the tendency of LLMs to generate "hallucinations", producing responses without clear justification from the data [14], [13].Additionally, inherent model biases were noted, particularly when dealing with sensitive information [9].Other limitations included difficulties in assigning topics to subjective expressions [19], lack of context sensitivity and emotional nuance [18], and restrictions in interpreting complex meanings [13].Study [8] also highlighted excessive response over-segmentation and overcategorization.In [20], challenges were reported in achieving coder consensus when dealing with ambiguous data, requiring human intervention for nuanced interpretations.</p>
<p>Further limitations included difficulties in broader and more detailed categorization, leading to a loss of specific details important by human researchers [14], as well as inconsistencies in zero-shot classifications [19].Another concern was the "echo chamber" effect, with LLMs reproducing pretrained patterns [18].Study [20] also highlighted challenges in maintaining coder independence while fostering collaboration, along with risks of premature influence from LLM-generated coding suggestions that could bias human coders.</p>
<p>Regarding recommendations for LLM usage, studies [14], [9], [13] propose that LLMs serve as aids rather than replacements for human analysts, particularly in categorization, with researchers retaining final interpretative authority.Other works emphasize the importance of human collaboration and LLMs role in enhancing accuracy and validity [18], [13].Study [20] suggests leveraging LLMs to structure and refine codebooks while ensuring human coders make final decisions.It also stresses the need for greater user control over AI-generated suggestions to prevent over-reliance on automated coding.</p>
<p>For future research, there is broad agreement on the need to refine prompt engineering techniques and explore more advanced architectures to enhance LLMs' textual understanding [17], [18], [19], [13].Increasing training data volume is also recommended to improve accuracy [17], along with fine-tuning pre-trained models for better topic assignments [19].Study [20] suggests optimizing prompt design to enhance AI-assisted code generation, refining interaction models for better coder collaboration and include integrating multimodal.Additional research directions include enhancing LLM capabilities to capture semantic and subjective nuances [14].Study [9] suggestes that expanding open-source models for cost reduction and accessibility, and developing more user-friendly interfaces for researchers.</p>
<p>IV. SUMMARY OF CONTRIBUTIONS AND RESEARCH OPPORTUNITIES</p>
<p>This section summarizes the main findings and contributions of this study, as well as the research opportunities identified.The key contributions include:</p>
<p>Mapping of the field:This study provides an overview of the use of LLMs in qualitative analysis, covering various aspects such as: (i) application contexts, (ii) LLM models and data sources, (iii) techniques and methodologies adopted, (iv) metrics used to evaluate effectiveness, and (v) limitations and research opportunities in the current state of the art.</p>
<p>This mapping focused on studies that reported LLM applications for qualitative analysis, detailing the prompt engineering employed-an essential factor for ensuring reproducibility.The findings highlight the recent nature of this field, reflected in the relatively low number of included studies, most of which were published in 2023 and 2024.</p>
<p>However, several research opportunities emerged.While LLMs exhibit performance comparable to or even superior to traditional methods in some cases, improvements are still needed.A key issue is their reliance on well-structured prompts, necessitating further exploration of approaches that enhance LLMs' textual understanding, allowing for greater flexibility in qualitative analyses.</p>
<p>Additionally, opportunities exist to investigate new architectures and techniques that improve the capture of semantic and subjective nuances, ensuring more precise and robust analyses.Another promising direction involves methods to mitigate "hallucinations" and biases, such as fine-tuning models or employing validation and filtering techniques.The development of user-friendly interfaces for researchers without AI expertise is also a relevant area of exploration.Finally, establishing a standardized and robust evaluation metric capable of capturing the complexity of qualitative analysis performed by LLMs represents a significant avenue for future research.</p>
<p>V. THREATS TO VALIDITY</p>
<p>A concern when using LLMs to automate the selection of studies is the potential loss of knowledge that would normally be acquired during a full reading of the articles.Manual reviews allow researchers to better understand the field of study, identifying nuances and contexts that may go unnoticed in an automated analysis.This acquired knowledge can positively influence the quality of the analysis.To mitigate this risk, we conducted additional checks through comprehensive readings of the articles to clarify any doubts, ensuring a more solid and well-founded understanding.</p>
<p>Another concern is the dichotomy in using LLMs both for data extraction and for investigating their effectiveness in qualitative research, which could create a potential conflict of interest.This may lead to confirmation bias, where the use of the LLM influences results in a way that favors its own application.To ensure the objectivity and integrity of the study, we took rigorous measures, relying on solid references from the analyzed articles to ensure that conclusions were based on evidence and not merely on the inferences generated by the model.</p>
<p>Another limitation concerns the lack of combination with other techniques in the systematic mapping, such as snowballing.Including this technique could contribute to identifying additional relevant studies.According to Wohlin et al. [21], when snowballing is combined with database searches, the review shows a significant increase in the identification of primary studies, allowing gaps left by strategies based solely on database searches to be filled.The absence of this approach may have led to the oversight of relevant articles and represents an opportunity to improve the study.</p>
<p>Other factors that may have influenced the results presented in this systematic mapping include threats to data validity, as well as internal, external, and construct validity.</p>
<p>Data Validity: One concern related to data validity is that ChatGPT may exhibit a certain level of superficiality.While robust, it lacks the deep contextual understanding that a human researcher can achieve.This may result in information being extracted incompletely or without sufficient analytical depth.To mitigate this threat, we adopted a manual review approach.Whenever doubts arose regarding the accuracy of the information provided by the model, a full reading of the articles was conducted.This procedure aimed to ensure that critical information was not overlooked, thus providing a more accurate and contextualized analysis.</p>
<p>The decision to exclude studies that did not describe prompt engineering (DE11) reflects the critical need to ensure replicability in this systematic mapping.Given that the use of LLMs for qualitative analysis is a relatively new area of study, detailed descriptions of methodologies, including prompt engineering, are crucial for enabling comparisons and understanding results across studies.However, we recognize that this criterion may have restricted the number of included studies, particularly during the early stages of research in this field.Future iterations of this study could consider less restrictive criteria during the screening phase, enabling a broader analysis that includes studies with incomplete methodological details.This approach could provide valuable insights into the evolution of LLM applications for qualitative analysis.</p>
<p>Internal Validity: Since two researchers were involved in the article selection process, there is a risk that inclusion criteria might vary due to individual biases.Differences in interpretation could affect the consistency of study selection.To mitigate this threat, we established standardized selection criteria, requiring that articles specifically focus on the use of LLMs for qualitative analysis.In cases of uncertainty, the researchers held joint discussions to reach a consensus, ensuring greater uniformity in the selection process.</p>
<p>External Validity: Generalizing the results is crucial to ensure that the conclusions of this study can be applied to different contexts and diverse populations.To address this concern, studies were selected from various fields, including healthcare, education, technology, and others.This selection aimed to assess whether the techniques used and the results obtained would be replicable across multiple domains.Through this approach, we sought to demonstrate that the conclusions presented have the potential to be generalized beyond the initial scope of the study, thereby enhancing their applicability and relevance in various contexts.</p>
<p>Construct Validity: A critical issue involves whether the tools and methods used truly capture the concepts under investigation.To ensure that the prompts used were aligned with the research objectives, we adopted an iterative prompt engineering process in which different versions were tested and refined.These versions were made available on Zenodo9 to promote greater transparency.Additionally, test articles with known responses were used to validate whether the model's outputs were consistent with expectations.This procedure provided greater confidence that ChatGPT correctly interpreted the questions and returned responses aligned with the study's objectives.</p>
<p>VI. CONCLUSION</p>
<p>This paper presented a SMS on the use of LLMs in qualitative analyses, aiming to explore the state of the art in this area.Overall, the analysis of the studies revealed that most publications are recent (2023-2024), indicating that the field is still in its early stages but showing growing interest.</p>
<p>This study provides an overview of the field, addressing various dimensions such as contexts, LLM models, data sources, techniques and methodologies, metrics, limitations, and opportunities.The applications span areas like healthcare, education, culture, and technology, with objectives ranging from automating qualitative analysis to comparing results with traditional methods.Several models were utilized, with a predominance of adjustments made to LLMs to enhance outcomes.The effectiveness of LLMs was mostly evaluated as equivalent to traditional methods, though some limitations were identified, such as the dependence on prompts and the risk of biases.</p>
<p>As future work, we plan to develop a method using LLMs to automate the qualitative analysis process, particularly focusing on the coding stages, by exploring new architectures applied in different tools.For this new method, we also aim to incorporate improvements in prompt engineering techniques to achieve greater accuracy and robustness.The integration of LLMs into structured qualitative analysis workflows also presents an interesting direction for future research, as it may enhance coder agreement and decision-making in collaborative settings.</p>
<p>With continued advancements in this field, it is expected that LLMs may, in the future, play an even more significant role in qualitative analysis, becoming an indispensable tool for researchers dealing with large volumes of textual data.</p>
<p>VII. TAKE AWAY LESSONS</p>
<p>The systematic mapping study provides valuable insights into the application of LLMs for qualitative analysis.Based on the evidence from the analyzed articles, several key takeaways emerge:</p>
<p>A. Most Effective LLM According to the Evidence ChatGPT and its variations (e.g., GPT-4) were the most frequently cited models in the included studies.These models demonstrated superior capabilities for tasks such as open coding and theme extraction when compared to other LLMs, such as LLaMA-2 or Atlas.TI [8], [18], [13].</p>
<p>B. Capabilities and Current Limitations</p>
<p>Open Coding: LLMs like ChatGPT are effective in automating the open coding process, rapidly identifying themes and patterns in textual data [14], [8].</p>
<p>Axial Coding and Visualization: Tasks like axial coding and generating graphical representations (e.g., mind maps and visual models in Atlas.TI) still require user intervention.LLMs cannot yet perform complex integrations or visualizations that demand contextual and nuanced decision-making.</p>
<p>Efficiency Gains: A key finding highlights LLMs' potential to drastically reduce qualitative coding time.For instance, Mathis et al. [9] reported that LLMs shortened coding from weeks to hours, demonstrating their transformative impact on qualitative research workflows.</p>
<p>C. Best Practices and Future Directions</p>
<p>While LLMs offer substantial benefits, their effective use requires structured prompts and careful oversight.Researchers should leverage LLMs for automation-friendly tasks, such as initial coding and theme identification, while reserving interpretative or creative processes for human analysts.Advances in LLM architectures and prompt engineering may further expand their role in complex stages of qualitative analysis.</p>
<p>Fig. 1 .
1
Fig. 1.Study selection process.</p>
<p>presents the extraction criteria (DE) and maps each one to the corresponding research questions (RQ).</p>
<p>https://parsif.al/
http://www.scopus.com
https://dl.acm.org/
https://ieeexplore.ieee.org/
http://www.isiknowledge.com
https://sol.sbc.org.br/busca/
https://arxiv.org/
https://chatgpt.com/
https://doi.org/10.5281/zenodo.14177022
ACKNOWLEDGMENTThe authors thank ChatGPT 4.0 (paid version) for its support in data extraction for this systematic mapping.The model significantly accelerated the identification and selection of relevant articles.It was also used for text translation into English, followed by manual review to ensure accuracy and clarity.All translations and extractions were later verified by human reviewers for spelling, grammar, and data consistency.Thanks to CNPq (grant 312275/2023-4), FAPERJ (grant number E-26/204.256/2024),and Stone Co (funded research project 1006) for financial support.
Artificial intelligence: a modern approach. S J Russell, P Norvig, 2016Pearson</p>
<p>ChatGPT: A comprehensive review on background, applications, key challenges, bias, ethics, limitations and future scope. P P Ray, Internet of Things and Cyber-Physical Systems. 32023</p>
<p>GPT-4). Chatgpt Openai, 2024. Sep. 24, 2024OpenAISan Francisco</p>
<p>A Survey of Large Language Models. W X Zhao, arXiv:2303.18223arXiv preprint</p>
<p>A comprehensive overview of large language models. H Naveed, arXiv:2307.064352023arXiv preprint</p>
<p>Basics of qualitative research: Techniques and procedures for developing grounded theory. J Corbin, A Strauss, 2014Sage Publications</p>
<p>Constructing grounded theory: A practical guide through qualitative analysis. K Charmaz, 2006</p>
<p>Coding Open-Ended Responses using Pseudo Response Generation by Large Language Models. Y Zenimoto, R Hasegawa, T Utsuro, M Yoshioka, N Kando, Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies20244Student Research Workshop)</p>
<p>Inductive thematic analysis of healthcare qualitative interviews using open-source large language models: How does it compare to traditional methods?. W S Mathis, S Zhao, N Pratt, J Weleff, S De Paoli, Computer Methods and Programs in Biomedicine. 2551083562024</p>
<p>Large language models for qualitative research in software engineering: exploring opportunities and challenges. M Bano, R Hoda, D Zowghi, C Treude, Automated Software Engineering. 3112024Springer</p>
<p>Screening articles for systematic reviews with ChatGPT. E Syriani, I David, G Kumar, Journal of Computer Languages. 1012872024</p>
<p>Extracting accurate materials data from research papers with conversational language models and prompt engineering. M P Polak, D Morgan, 10.1038/s41467-024-45914-8Nature Communications. 1515692024</p>
<p>Performing an inductive thematic analysis of semistructured interviews with a large language model: An exploration and provocation on the limits of the approach. S De Paoli, Social Science Computer Review. 4242024</p>
<p>Artificial Intelligence and content analysis: the large language models (LLMs) and the automatized categorization. A C Carius, A J Teixeira, 2024AI &amp; Society</p>
<p>Applications and Implications of Large Language Models in Qualitative Analysis: A New Frontier for Empirical Software Engineering. M De, M Lec ¸a, L Valenc ¸a, R Santos, R De, S Santos, 2024arXiv preprint</p>
<p>Guidelines for Performing Systematic Literature Reviews in Software Engineering. B Kitchenham, S Charters, EBSE 2007-0012007Keele University Keele, UK; Durham University: Durham, UKTechnical Report</p>
<p>Deep Learning Models for Analyzing Social Construction of Knowledge Online. C N Gunawardena, Y Chen, N Flor, D Sánchez, Online Learning. 202327</p>
<p>Exploring Qualitative Research Using LLMs. M Bano, D Zowghi, J Whittle, arXiv:2306.132982023arXiv preprint</p>
<p>LLMusic: Topic Modeling in Song Lyrics Combining LLM, Prompt Engineering, and BERTopic" (LLMusic: Modelagem de tópicos em letras de músicas combinando LLM, Engenharia de Prompt e BERTopic. J D Y Rojas, K Becker, 10.5753/sbbd_estendido.2024.243767Workshop de Teses e Dissertac ¸ões (WTDBD) -Simpósio Brasileiro de Banco de Dados (SBBD). Florianópolis/SC, Porto AlegreSociedade Brasileira de Computac ¸ão202439</p>
<p>Perrault. J Gao, Y Guo, G Lim, T Zhang, Z Zhang, T J , .-J Li, S T , CollabCoder: A Lower-barrier, Rigorous Workflow for Inductive Collaborative Qualitative Analysis with Large Language Models. 2024arXiv preprint</p>
<p>Successful combination of database search and snowballing for identification of primary studies in systematic literature studies. C Wohlin, M Kalinowski, K R Felizardo, E Mendes, 10.1016/j.infsof.2022.106908Information and Software Technology. 1472022</p>            </div>
        </div>

    </div>
</body>
</html>