<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-560 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-560</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-560</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-16.html">extraction-schema-16</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of experimental methods, techniques, or procedures being transferred, adapted, or applied from one scientific domain or context to another scientific domain or context, including details about the transfer process and outcomes.</div>
                <p><strong>Paper ID:</strong> paper-b41de530f4e44926eb4d54f61403011a6d8b3e41</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/b41de530f4e44926eb4d54f61403011a6d8b3e41" target="_blank">Data augmentation of wearable sensor data for parkinson’s disease monitoring using convolutional neural networks</a></p>
                <p><strong>Paper Venue:</strong> International Conference on Multimodal Interaction</p>
                <p><strong>Paper TL;DR:</strong> The proposed methods and CNNs are applied to the classification of the motor state of Parkinson’s Disease patients, which is challenging due to small dataset size, noisy labels, and large intra-class variability.</p>
                <p><strong>Paper Abstract:</strong> While convolutional neural networks (CNNs) have been successfully applied to many challenging classification applications, they typically require large datasets for training. When the availability of labeled data is limited, data augmentation is a critical preprocessing step for CNNs. However, data augmentation for wearable sensor data has not been deeply investigated yet. In this paper, various data augmentation methods for wearable sensor data are proposed. The proposed methods and CNNs are applied to the classification of the motor state of Parkinson’s Disease patients, which is challenging due to small dataset size, noisy labels, and large intra-class variability. Appropriate augmentation improves the classification performance from 77.54% to 86.88%.</p>
                <p><strong>Cost:</strong> 0.013</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e560.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e560.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of experimental methods, techniques, or procedures being transferred, adapted, or applied from one scientific domain or context to another scientific domain or context, including details about the transfer process and outcomes.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>CNN → Wearable PD</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Convolutional Neural Networks applied to wearable accelerometer data for Parkinson's Disease motor state classification</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Application and adaptation of deep convolutional neural networks (CNNs), originally popularized in computer vision, to classify bradykinesia vs. dyskinesia from wrist-worn accelerometer time-series in daily-living conditions.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Data Augmentation of Wearable Sensor Data for Parkinson's Disease Monitoring using Convolutional Neural Networks</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_name</strong></td>
                            <td>Convolutional Neural Network classification (7-layer, strided convs with GAP)</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_description</strong></td>
                            <td>A 7-layer deep convolutional neural network was trained on 58-second (6960-sample) tri-axial accelerometer windows to classify PD motor state. Each conv layer is followed by batch normalization and ReLU; strided convolutions (filters of sizes 4x1, 4x1, 3x1, 3x3, 2x3, 2x3, 2x3) progressively reduce the temporal dimensionality from 6960x3 to 48x1. Inter-axis convolution (XYZ) is performed in later layers to learn cross-axis features. A Global Average Pooling (GAP) layer replaces fully-connected layers to reduce parameter count appropriate for small datasets. Training used 400 epochs and 5-fold subject-wise cross-validation.</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_type</strong></td>
                            <td>computational method / machine learning classification</td>
                        </tr>
                        <tr>
                            <td><strong>source_domain</strong></td>
                            <td>computer vision / deep learning</td>
                        </tr>
                        <tr>
                            <td><strong>target_domain</strong></td>
                            <td>wearable sensing / clinical movement monitoring (Parkinson's Disease)</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_type</strong></td>
                            <td>adapted/modified for new context</td>
                        </tr>
                        <tr>
                            <td><strong>modifications_made</strong></td>
                            <td>Network architecture made deeper but sparse (7 layers) with strided convolutions to reduce parameters; inter-axis convolutions introduced in later layers to capture 3-axis accelerometer coupling; GAP used instead of fully-connected layers to limit overfitting on a small dataset; training regime and input preprocessing (resampling to 120 Hz, fixed 58 s windows) tailored to wearable accelerometer signals.</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_success</strong></td>
                            <td>successful - baseline CNN (without augmentation) achieved test accuracy 77.54% on 25 patients (5-fold CV). When combined with appropriate data augmentation (Rot+Perm+TimeW) the pipeline achieved 86.88% test accuracy, indicating a successful transfer when adapted.</td>
                        </tr>
                        <tr>
                            <td><strong>barriers_encountered</strong></td>
                            <td>Limited labelled data (25 patients), noisy labels and intra-class variability in signals; risk of overfitting due to many parameters; need to preserve label semantics under augmentation; irregular sampling handled by resampling.</td>
                        </tr>
                        <tr>
                            <td><strong>facilitating_factors</strong></td>
                            <td>Similarity of pattern-recognition goals between vision and time-series classification; availability of accelerometer data in fixed-length windows; implementation of regularization strategies (GAP, batch-norm) and domain-specific preprocessing (resampling) facilitated transfer.</td>
                        </tr>
                        <tr>
                            <td><strong>contextual_requirements</strong></td>
                            <td>Subject-wise cross-validation to assess generalization; resampling to 120 Hz; clinical expert labels for 1-minute windows; sufficient compute to train CNNs for 400 epochs; domain expertise to design label-preserving augmentations.</td>
                        </tr>
                        <tr>
                            <td><strong>generalizability</strong></td>
                            <td>Moderately high within wearable time-series classification tasks: approach (CNN + architectural adaptations + augmentation) is likely applicable to other wearable sensing classification problems, but requires task-specific choices (window length, augmentation types) and care about label preservation.</td>
                        </tr>
                        <tr>
                            <td><strong>knowledge_type</strong></td>
                            <td>explicit procedural steps and instrumental/technical skills (architecture design, training regimen, preprocessing), with some interpretive framing about label-preserving transformations</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Data augmentation of wearable sensor data for parkinson’s disease monitoring using convolutional neural networks', 'publication_date_yy_mm': '2017-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e560.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e560.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of experimental methods, techniques, or procedures being transferred, adapted, or applied from one scientific domain or context to another scientific domain or context, including details about the transfer process and outcomes.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Image/Speech Aug → Wearables</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Image and speech data augmentation techniques adapted to wearable sensor time-series</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Adoption and adaptation of common augmentation transformations (jittering, scaling, cropping, rotation, warping/permutation) from image and speech domains to tri-axial accelerometer wearable sensor data to increase effective training set size.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Data Augmentation of Wearable Sensor Data for Parkinson's Disease Monitoring using Convolutional Neural Networks</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_name</strong></td>
                            <td>Label-preserving data augmentation (jittering, scaling, cropping, rotation, magnitude-warping, time-warping, permutation)</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_description</strong></td>
                            <td>A set of transformations applied to 58-second tri-axial accelerometer windows: additive Gaussian noise (jittering with per-sample STD drawn from N(0,0.03)), multiplicative scaling (scalar drawn from N(1,0.1)), random cropping/window slicing, arbitrary 3D rotations (random rotation matrix per instance), permutation (slice window into N equal-length segments with N sampled and randomly permute segments), magnitude-warping (convolution with smooth curve near 1 using random sinusoidal curves), and time-warping (smoothly distort time intervals using random sinusoidal curves). Combinations of these augmentations were also used.</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_type</strong></td>
                            <td>data augmentation / data-preprocessing technique</td>
                        </tr>
                        <tr>
                            <td><strong>source_domain</strong></td>
                            <td>image recognition and speech/time-series augmentation</td>
                        </tr>
                        <tr>
                            <td><strong>target_domain</strong></td>
                            <td>wearable sensor time-series for clinical PD monitoring</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_type</strong></td>
                            <td>adapted/modified for new context</td>
                        </tr>
                        <tr>
                            <td><strong>modifications_made</strong></td>
                            <td>Parameter choices and implementations adjusted for accelerometer time-series: resampling to 120 Hz, per-instance random parameter sampling (e.g., jitter STD, scaling mean/STD), permutation implemented by slicing into 1–5 segments and permuting, rotations implemented as arbitrary 3D rotation matrices to simulate sensor placement variability, magnitude- and time-warping implemented using random sinusoidal curves suitable for temporal signals rather than pixel-space transforms.</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_success</strong></td>
                            <td>partially successful - some augmentations (rotation, permutation, time-warping) improved test accuracy (baseline CNN 77.54% → Rot 82.62%, Perm 81.16%, TimeW 82.00%); combinations achieved best (Rot+Perm+TimeW = 86.88%). Other augmentations failed or degraded performance (jittering ~77.52%, scaling 79.46%, magnitude-warping 79.33%, cropping 73.58%) because they changed label-relevant signal properties.</td>
                        </tr>
                        <tr>
                            <td><strong>barriers_encountered</strong></td>
                            <td>Label preservation is not obvious for wearable data — some transforms (scaling, magnitude changes, jitter) altered clinically relevant signal intensity or introduced artifacts resembling dyskinesia; cropping can remove events and change labels; choosing augmentation parameters required domain knowledge.</td>
                        </tr>
                        <tr>
                            <td><strong>facilitating_factors</strong></td>
                            <td>Recognition that certain invariances (sensor orientation, temporal location of events) hold in wearable data allowed selection of rotation and temporal perturbation augmentations; ability to implement per-instance randomized transforms; availability of clinical labels to validate effects.</td>
                        </tr>
                        <tr>
                            <td><strong>contextual_requirements</strong></td>
                            <td>Careful selection and tuning of augmentation parameters to avoid altering labels; domain expertise to decide which transforms are label-preserving; dataset segmentation conventions (fixed 58 s windows) informed permutation/time-warping design.</td>
                        </tr>
                        <tr>
                            <td><strong>generalizability</strong></td>
                            <td>Transferable to other wearable sensor tasks where invariances (sensor pose, event location) exist, but augmentations that alter signal magnitude or fine temporal structure may not generalize; requires per-task validation.</td>
                        </tr>
                        <tr>
                            <td><strong>knowledge_type</strong></td>
                            <td>explicit procedural steps (how to implement each augmentation) combined with tacit domain knowledge about which transforms preserve labels</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Data augmentation of wearable sensor data for parkinson’s disease monitoring using convolutional neural networks', 'publication_date_yy_mm': '2017-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e560.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e560.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of experimental methods, techniques, or procedures being transferred, adapted, or applied from one scientific domain or context to another scientific domain or context, including details about the transfer process and outcomes.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Permutation / TimeW</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Permutation and time-warping (time-series augmentation) adapted for wearable accelerometer windows</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Temporal perturbation methods implemented to change the positions of events within fixed-length windows by segment slicing and smooth temporal distortion, improving robustness to arbitrary window segmentation.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Data Augmentation of Wearable Sensor Data for Parkinson's Disease Monitoring using Convolutional Neural Networks</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_name</strong></td>
                            <td>Permutation (Perm) and Time-Warping (TimeW) augmentations</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_description</strong></td>
                            <td>Permutation: slice a single 58-second window into N equal-length segments (N sampled from distribution, values 1–5 used) and randomly permute the segments to form a new window, thereby changing temporal locations of events. Time-warping: smoothly distort time intervals between samples by applying a smooth random time-mapping (implemented via random sinusoidal curves) to shift temporal locations continuously without abrupt discontinuities.</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_type</strong></td>
                            <td>data augmentation / temporal perturbation</td>
                        </tr>
                        <tr>
                            <td><strong>source_domain</strong></td>
                            <td>time-series augmentation / signal processing (inspired by window-slicing/window-warping literature)</td>
                        </tr>
                        <tr>
                            <td><strong>target_domain</strong></td>
                            <td>wearable accelerometer signals for PD motor state classification</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_type</strong></td>
                            <td>adapted/modified for new context</td>
                        </tr>
                        <tr>
                            <td><strong>modifications_made</strong></td>
                            <td>N chosen from a rounded positive Gaussian draw (STD 5.0) to determine segment count; sinusoidal random curves for time-warping tuned to preserve short-timescale morphology while displacing event locations; implemented to preserve label semantics for motor-state classification.</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_success</strong></td>
                            <td>successful - Perm achieved test accuracy 81.16%, TimeW achieved 82.00% (baseline CNN 77.54%); used in combination with rotation to reach 86.88%.</td>
                        </tr>
                        <tr>
                            <td><strong>barriers_encountered</strong></td>
                            <td>If segments/cropping capture event-free regions, label may change; inappropriate warp amplitudes/frequencies could distort clinically relevant temporal features;</td>
                        </tr>
                        <tr>
                            <td><strong>facilitating_factors</strong></td>
                            <td>Arbitrary fixed-length windowing in dataset meant event location was not semantically informative — permutation and warping directly target that invariance; ability to synthesize smooth warps kept signals realistic.</td>
                        </tr>
                        <tr>
                            <td><strong>contextual_requirements</strong></td>
                            <td>Choice of segment counts and warp parameters required validation against label preservation; resampled, uniformly sampled data and sufficient window length (58 s) to allow safe permutation without destroying signal content.</td>
                        </tr>
                        <tr>
                            <td><strong>generalizability</strong></td>
                            <td>Likely generalizable to other wearable/time-series tasks where event timing within windows is arbitrary; less appropriate when absolute timing or fine temporal structure is label-defining.</td>
                        </tr>
                        <tr>
                            <td><strong>knowledge_type</strong></td>
                            <td>explicit procedural steps and tacit task-specific knowledge about temporal invariances</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Data augmentation of wearable sensor data for parkinson’s disease monitoring using convolutional neural networks', 'publication_date_yy_mm': '2017-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e560.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e560.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of experimental methods, techniques, or procedures being transferred, adapted, or applied from one scientific domain or context to another scientific domain or context, including details about the transfer process and outcomes.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Rotation Augmentation</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>3D rotation augmentation to simulate sensor placement variability</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Applying arbitrary 3D rotations to tri-axial accelerometer windows to emulate different sensor orientations and upside-down placements across participants, thereby enforcing orientation-invariance in the classifier.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Data Augmentation of Wearable Sensor Data for Parkinson's Disease Monitoring using Convolutional Neural Networks</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_name</strong></td>
                            <td>Rotation (Rot) augmentation for accelerometer axes</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_description</strong></td>
                            <td>For each sample window, an arbitrary 3x3 rotation matrix is generated and applied to the tri-axial accelerometer data to simulate different device orientations; this can invert signs or mix axis contributions, reflecting natural variability in wristband placement.</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_type</strong></td>
                            <td>data augmentation / synthetic perturbation</td>
                        </tr>
                        <tr>
                            <td><strong>source_domain</strong></td>
                            <td>image augmentation (geometric transforms) / 3D signal simulation</td>
                        </tr>
                        <tr>
                            <td><strong>target_domain</strong></td>
                            <td>wearable accelerometer data for PD monitoring</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_type</strong></td>
                            <td>adapted/modified for new context</td>
                        </tr>
                        <tr>
                            <td><strong>modifications_made</strong></td>
                            <td>Rotation is implemented in 3D sensor coordinate space rather than 2D image plane; rotation matrices are randomly sampled per-instance to represent arbitrary placement differences rather than constrained image rotations.</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_success</strong></td>
                            <td>successful - rotation alone improved test accuracy from baseline 77.54% to 82.62%; when combined with permutation and time-warping produced the best result (Rot+Perm+TimeW = 86.88%).</td>
                        </tr>
                        <tr>
                            <td><strong>barriers_encountered</strong></td>
                            <td>Must ensure rotation does not inadvertently alter label-relevant directional information if task depends on absolute orientation; requires correct handling of gravity component if present (paper used acceleration without further preprocessing).</td>
                        </tr>
                        <tr>
                            <td><strong>facilitating_factors</strong></td>
                            <td>Sensor-placement variability is a known real-world source of variation; rotation directly models this phenomenon making it an effective augmentation; ready implementation as linear algebra operation on axis vectors.</td>
                        </tr>
                        <tr>
                            <td><strong>contextual_requirements</strong></td>
                            <td>Tri-axial accelerometer data with consistent sampling; domain understanding that orientation changes do not change motor-state label; random rotation generator per-instance.</td>
                        </tr>
                        <tr>
                            <td><strong>generalizability</strong></td>
                            <td>Highly generalizable to other inertial/wearable sensor tasks where sensor pose varies across users, less appropriate for tasks where absolute orientation is diagnostic.</td>
                        </tr>
                        <tr>
                            <td><strong>knowledge_type</strong></td>
                            <td>explicit procedural steps (how to generate/apply rotations) plus interpretive understanding of sensor-placement invariance</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Data augmentation of wearable sensor data for parkinson’s disease monitoring using convolutional neural networks', 'publication_date_yy_mm': '2017-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e560.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e560.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of experimental methods, techniques, or procedures being transferred, adapted, or applied from one scientific domain or context to another scientific domain or context, including details about the transfer process and outcomes.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GAP for Small Data</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Global Average Pooling (GAP) layer usage to reduce parameters for small wearable datasets</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Replacement of fully-connected classification layers with a global average pooling layer to drastically reduce model parameters and lower overfitting risk when training CNNs on small wearable datasets.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Data Augmentation of Wearable Sensor Data for Parkinson's Disease Monitoring using Convolutional Neural Networks</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_name</strong></td>
                            <td>Global Average Pooling (GAP) as classifier head</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_description</strong></td>
                            <td>After the final convolutional layer, apply global average pooling across temporal feature maps to produce a compact feature vector, which is then used for classification instead of traditional dense fully-connected layers; this reduces trainable parameters and provides spatial/temporal invariance.</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_type</strong></td>
                            <td>architectural modification / regularization technique</td>
                        </tr>
                        <tr>
                            <td><strong>source_domain</strong></td>
                            <td>deep learning / computer vision (Network In Network literature)</td>
                        </tr>
                        <tr>
                            <td><strong>target_domain</strong></td>
                            <td>wearable sensor CNN architectures for clinical classification</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_type</strong></td>
                            <td>direct application with contextual tuning</td>
                        </tr>
                        <tr>
                            <td><strong>modifications_made</strong></td>
                            <td>Applied GAP in a 1D temporal convolutional stack for accelerometer signals (temporal pooling) rather than 2D spatial pooling used in images; integrated with batch-norm and ReLU layers for stable training.</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_success</strong></td>
                            <td>successful - enabled construction of a CNN with fewer parameters suitable for small-scale PD dataset; baseline CNN with GAP achieved 77.54% test accuracy and trained successfully without overfitting as much as fully-connected alternatives would likely have.</td>
                        </tr>
                        <tr>
                            <td><strong>barriers_encountered</strong></td>
                            <td>GAP reduces representational capacity which may limit learning of very complex decision boundaries if more data were available; requires convolutional final maps to be sufficiently informative.</td>
                        </tr>
                        <tr>
                            <td><strong>facilitating_factors</strong></td>
                            <td>Direct analogy between spatial pooling in images and temporal pooling in time-series; need to reduce parameter count for small dataset made GAP attractive.</td>
                        </tr>
                        <tr>
                            <td><strong>contextual_requirements</strong></td>
                            <td>Sufficient depth in convolutional layers to generate useful feature maps before pooling; careful architecture design to ensure final feature maps capture discriminative patterns.</td>
                        </tr>
                        <tr>
                            <td><strong>generalizability</strong></td>
                            <td>Generalizable across other small-data time-series classification tasks where overfitting is a concern; GAP is a broadly applicable architectural choice.</td>
                        </tr>
                        <tr>
                            <td><strong>knowledge_type</strong></td>
                            <td>explicit procedural knowledge (architectural choice and implementation details)</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Data augmentation of wearable sensor data for parkinson’s disease monitoring using convolutional neural networks', 'publication_date_yy_mm': '2017-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Data Augmentation for Time Series Classification using Convolutional Neural Networks <em>(Rating: 2)</em></li>
                <li>Data Augmentation for Deep Neural Network Acoustic Modeling <em>(Rating: 2)</em></li>
                <li>Return of the Devil in the Details: Delving Deep into Convolutional Nets <em>(Rating: 1)</em></li>
                <li>PD Disease State Assessment in Naturalistic Environments Using Deep Learning <em>(Rating: 2)</em></li>
                <li>Network In Network <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-560",
    "paper_id": "paper-b41de530f4e44926eb4d54f61403011a6d8b3e41",
    "extraction_schema_id": "extraction-schema-16",
    "extracted_data": [
        {
            "name_short": "CNN → Wearable PD",
            "name_full": "Convolutional Neural Networks applied to wearable accelerometer data for Parkinson's Disease motor state classification",
            "brief_description": "Application and adaptation of deep convolutional neural networks (CNNs), originally popularized in computer vision, to classify bradykinesia vs. dyskinesia from wrist-worn accelerometer time-series in daily-living conditions.",
            "citation_title": "Data Augmentation of Wearable Sensor Data for Parkinson's Disease Monitoring using Convolutional Neural Networks",
            "mention_or_use": "use",
            "procedure_name": "Convolutional Neural Network classification (7-layer, strided convs with GAP)",
            "procedure_description": "A 7-layer deep convolutional neural network was trained on 58-second (6960-sample) tri-axial accelerometer windows to classify PD motor state. Each conv layer is followed by batch normalization and ReLU; strided convolutions (filters of sizes 4x1, 4x1, 3x1, 3x3, 2x3, 2x3, 2x3) progressively reduce the temporal dimensionality from 6960x3 to 48x1. Inter-axis convolution (XYZ) is performed in later layers to learn cross-axis features. A Global Average Pooling (GAP) layer replaces fully-connected layers to reduce parameter count appropriate for small datasets. Training used 400 epochs and 5-fold subject-wise cross-validation.",
            "procedure_type": "computational method / machine learning classification",
            "source_domain": "computer vision / deep learning",
            "target_domain": "wearable sensing / clinical movement monitoring (Parkinson's Disease)",
            "transfer_type": "adapted/modified for new context",
            "modifications_made": "Network architecture made deeper but sparse (7 layers) with strided convolutions to reduce parameters; inter-axis convolutions introduced in later layers to capture 3-axis accelerometer coupling; GAP used instead of fully-connected layers to limit overfitting on a small dataset; training regime and input preprocessing (resampling to 120 Hz, fixed 58 s windows) tailored to wearable accelerometer signals.",
            "transfer_success": "successful - baseline CNN (without augmentation) achieved test accuracy 77.54% on 25 patients (5-fold CV). When combined with appropriate data augmentation (Rot+Perm+TimeW) the pipeline achieved 86.88% test accuracy, indicating a successful transfer when adapted.",
            "barriers_encountered": "Limited labelled data (25 patients), noisy labels and intra-class variability in signals; risk of overfitting due to many parameters; need to preserve label semantics under augmentation; irregular sampling handled by resampling.",
            "facilitating_factors": "Similarity of pattern-recognition goals between vision and time-series classification; availability of accelerometer data in fixed-length windows; implementation of regularization strategies (GAP, batch-norm) and domain-specific preprocessing (resampling) facilitated transfer.",
            "contextual_requirements": "Subject-wise cross-validation to assess generalization; resampling to 120 Hz; clinical expert labels for 1-minute windows; sufficient compute to train CNNs for 400 epochs; domain expertise to design label-preserving augmentations.",
            "generalizability": "Moderately high within wearable time-series classification tasks: approach (CNN + architectural adaptations + augmentation) is likely applicable to other wearable sensing classification problems, but requires task-specific choices (window length, augmentation types) and care about label preservation.",
            "knowledge_type": "explicit procedural steps and instrumental/technical skills (architecture design, training regimen, preprocessing), with some interpretive framing about label-preserving transformations",
            "uuid": "e560.0",
            "source_info": {
                "paper_title": "Data augmentation of wearable sensor data for parkinson’s disease monitoring using convolutional neural networks",
                "publication_date_yy_mm": "2017-06"
            }
        },
        {
            "name_short": "Image/Speech Aug → Wearables",
            "name_full": "Image and speech data augmentation techniques adapted to wearable sensor time-series",
            "brief_description": "Adoption and adaptation of common augmentation transformations (jittering, scaling, cropping, rotation, warping/permutation) from image and speech domains to tri-axial accelerometer wearable sensor data to increase effective training set size.",
            "citation_title": "Data Augmentation of Wearable Sensor Data for Parkinson's Disease Monitoring using Convolutional Neural Networks",
            "mention_or_use": "use",
            "procedure_name": "Label-preserving data augmentation (jittering, scaling, cropping, rotation, magnitude-warping, time-warping, permutation)",
            "procedure_description": "A set of transformations applied to 58-second tri-axial accelerometer windows: additive Gaussian noise (jittering with per-sample STD drawn from N(0,0.03)), multiplicative scaling (scalar drawn from N(1,0.1)), random cropping/window slicing, arbitrary 3D rotations (random rotation matrix per instance), permutation (slice window into N equal-length segments with N sampled and randomly permute segments), magnitude-warping (convolution with smooth curve near 1 using random sinusoidal curves), and time-warping (smoothly distort time intervals using random sinusoidal curves). Combinations of these augmentations were also used.",
            "procedure_type": "data augmentation / data-preprocessing technique",
            "source_domain": "image recognition and speech/time-series augmentation",
            "target_domain": "wearable sensor time-series for clinical PD monitoring",
            "transfer_type": "adapted/modified for new context",
            "modifications_made": "Parameter choices and implementations adjusted for accelerometer time-series: resampling to 120 Hz, per-instance random parameter sampling (e.g., jitter STD, scaling mean/STD), permutation implemented by slicing into 1–5 segments and permuting, rotations implemented as arbitrary 3D rotation matrices to simulate sensor placement variability, magnitude- and time-warping implemented using random sinusoidal curves suitable for temporal signals rather than pixel-space transforms.",
            "transfer_success": "partially successful - some augmentations (rotation, permutation, time-warping) improved test accuracy (baseline CNN 77.54% → Rot 82.62%, Perm 81.16%, TimeW 82.00%); combinations achieved best (Rot+Perm+TimeW = 86.88%). Other augmentations failed or degraded performance (jittering ~77.52%, scaling 79.46%, magnitude-warping 79.33%, cropping 73.58%) because they changed label-relevant signal properties.",
            "barriers_encountered": "Label preservation is not obvious for wearable data — some transforms (scaling, magnitude changes, jitter) altered clinically relevant signal intensity or introduced artifacts resembling dyskinesia; cropping can remove events and change labels; choosing augmentation parameters required domain knowledge.",
            "facilitating_factors": "Recognition that certain invariances (sensor orientation, temporal location of events) hold in wearable data allowed selection of rotation and temporal perturbation augmentations; ability to implement per-instance randomized transforms; availability of clinical labels to validate effects.",
            "contextual_requirements": "Careful selection and tuning of augmentation parameters to avoid altering labels; domain expertise to decide which transforms are label-preserving; dataset segmentation conventions (fixed 58 s windows) informed permutation/time-warping design.",
            "generalizability": "Transferable to other wearable sensor tasks where invariances (sensor pose, event location) exist, but augmentations that alter signal magnitude or fine temporal structure may not generalize; requires per-task validation.",
            "knowledge_type": "explicit procedural steps (how to implement each augmentation) combined with tacit domain knowledge about which transforms preserve labels",
            "uuid": "e560.1",
            "source_info": {
                "paper_title": "Data augmentation of wearable sensor data for parkinson’s disease monitoring using convolutional neural networks",
                "publication_date_yy_mm": "2017-06"
            }
        },
        {
            "name_short": "Permutation / TimeW",
            "name_full": "Permutation and time-warping (time-series augmentation) adapted for wearable accelerometer windows",
            "brief_description": "Temporal perturbation methods implemented to change the positions of events within fixed-length windows by segment slicing and smooth temporal distortion, improving robustness to arbitrary window segmentation.",
            "citation_title": "Data Augmentation of Wearable Sensor Data for Parkinson's Disease Monitoring using Convolutional Neural Networks",
            "mention_or_use": "use",
            "procedure_name": "Permutation (Perm) and Time-Warping (TimeW) augmentations",
            "procedure_description": "Permutation: slice a single 58-second window into N equal-length segments (N sampled from distribution, values 1–5 used) and randomly permute the segments to form a new window, thereby changing temporal locations of events. Time-warping: smoothly distort time intervals between samples by applying a smooth random time-mapping (implemented via random sinusoidal curves) to shift temporal locations continuously without abrupt discontinuities.",
            "procedure_type": "data augmentation / temporal perturbation",
            "source_domain": "time-series augmentation / signal processing (inspired by window-slicing/window-warping literature)",
            "target_domain": "wearable accelerometer signals for PD motor state classification",
            "transfer_type": "adapted/modified for new context",
            "modifications_made": "N chosen from a rounded positive Gaussian draw (STD 5.0) to determine segment count; sinusoidal random curves for time-warping tuned to preserve short-timescale morphology while displacing event locations; implemented to preserve label semantics for motor-state classification.",
            "transfer_success": "successful - Perm achieved test accuracy 81.16%, TimeW achieved 82.00% (baseline CNN 77.54%); used in combination with rotation to reach 86.88%.",
            "barriers_encountered": "If segments/cropping capture event-free regions, label may change; inappropriate warp amplitudes/frequencies could distort clinically relevant temporal features;",
            "facilitating_factors": "Arbitrary fixed-length windowing in dataset meant event location was not semantically informative — permutation and warping directly target that invariance; ability to synthesize smooth warps kept signals realistic.",
            "contextual_requirements": "Choice of segment counts and warp parameters required validation against label preservation; resampled, uniformly sampled data and sufficient window length (58 s) to allow safe permutation without destroying signal content.",
            "generalizability": "Likely generalizable to other wearable/time-series tasks where event timing within windows is arbitrary; less appropriate when absolute timing or fine temporal structure is label-defining.",
            "knowledge_type": "explicit procedural steps and tacit task-specific knowledge about temporal invariances",
            "uuid": "e560.2",
            "source_info": {
                "paper_title": "Data augmentation of wearable sensor data for parkinson’s disease monitoring using convolutional neural networks",
                "publication_date_yy_mm": "2017-06"
            }
        },
        {
            "name_short": "Rotation Augmentation",
            "name_full": "3D rotation augmentation to simulate sensor placement variability",
            "brief_description": "Applying arbitrary 3D rotations to tri-axial accelerometer windows to emulate different sensor orientations and upside-down placements across participants, thereby enforcing orientation-invariance in the classifier.",
            "citation_title": "Data Augmentation of Wearable Sensor Data for Parkinson's Disease Monitoring using Convolutional Neural Networks",
            "mention_or_use": "use",
            "procedure_name": "Rotation (Rot) augmentation for accelerometer axes",
            "procedure_description": "For each sample window, an arbitrary 3x3 rotation matrix is generated and applied to the tri-axial accelerometer data to simulate different device orientations; this can invert signs or mix axis contributions, reflecting natural variability in wristband placement.",
            "procedure_type": "data augmentation / synthetic perturbation",
            "source_domain": "image augmentation (geometric transforms) / 3D signal simulation",
            "target_domain": "wearable accelerometer data for PD monitoring",
            "transfer_type": "adapted/modified for new context",
            "modifications_made": "Rotation is implemented in 3D sensor coordinate space rather than 2D image plane; rotation matrices are randomly sampled per-instance to represent arbitrary placement differences rather than constrained image rotations.",
            "transfer_success": "successful - rotation alone improved test accuracy from baseline 77.54% to 82.62%; when combined with permutation and time-warping produced the best result (Rot+Perm+TimeW = 86.88%).",
            "barriers_encountered": "Must ensure rotation does not inadvertently alter label-relevant directional information if task depends on absolute orientation; requires correct handling of gravity component if present (paper used acceleration without further preprocessing).",
            "facilitating_factors": "Sensor-placement variability is a known real-world source of variation; rotation directly models this phenomenon making it an effective augmentation; ready implementation as linear algebra operation on axis vectors.",
            "contextual_requirements": "Tri-axial accelerometer data with consistent sampling; domain understanding that orientation changes do not change motor-state label; random rotation generator per-instance.",
            "generalizability": "Highly generalizable to other inertial/wearable sensor tasks where sensor pose varies across users, less appropriate for tasks where absolute orientation is diagnostic.",
            "knowledge_type": "explicit procedural steps (how to generate/apply rotations) plus interpretive understanding of sensor-placement invariance",
            "uuid": "e560.3",
            "source_info": {
                "paper_title": "Data augmentation of wearable sensor data for parkinson’s disease monitoring using convolutional neural networks",
                "publication_date_yy_mm": "2017-06"
            }
        },
        {
            "name_short": "GAP for Small Data",
            "name_full": "Global Average Pooling (GAP) layer usage to reduce parameters for small wearable datasets",
            "brief_description": "Replacement of fully-connected classification layers with a global average pooling layer to drastically reduce model parameters and lower overfitting risk when training CNNs on small wearable datasets.",
            "citation_title": "Data Augmentation of Wearable Sensor Data for Parkinson's Disease Monitoring using Convolutional Neural Networks",
            "mention_or_use": "use",
            "procedure_name": "Global Average Pooling (GAP) as classifier head",
            "procedure_description": "After the final convolutional layer, apply global average pooling across temporal feature maps to produce a compact feature vector, which is then used for classification instead of traditional dense fully-connected layers; this reduces trainable parameters and provides spatial/temporal invariance.",
            "procedure_type": "architectural modification / regularization technique",
            "source_domain": "deep learning / computer vision (Network In Network literature)",
            "target_domain": "wearable sensor CNN architectures for clinical classification",
            "transfer_type": "direct application with contextual tuning",
            "modifications_made": "Applied GAP in a 1D temporal convolutional stack for accelerometer signals (temporal pooling) rather than 2D spatial pooling used in images; integrated with batch-norm and ReLU layers for stable training.",
            "transfer_success": "successful - enabled construction of a CNN with fewer parameters suitable for small-scale PD dataset; baseline CNN with GAP achieved 77.54% test accuracy and trained successfully without overfitting as much as fully-connected alternatives would likely have.",
            "barriers_encountered": "GAP reduces representational capacity which may limit learning of very complex decision boundaries if more data were available; requires convolutional final maps to be sufficiently informative.",
            "facilitating_factors": "Direct analogy between spatial pooling in images and temporal pooling in time-series; need to reduce parameter count for small dataset made GAP attractive.",
            "contextual_requirements": "Sufficient depth in convolutional layers to generate useful feature maps before pooling; careful architecture design to ensure final feature maps capture discriminative patterns.",
            "generalizability": "Generalizable across other small-data time-series classification tasks where overfitting is a concern; GAP is a broadly applicable architectural choice.",
            "knowledge_type": "explicit procedural knowledge (architectural choice and implementation details)",
            "uuid": "e560.4",
            "source_info": {
                "paper_title": "Data augmentation of wearable sensor data for parkinson’s disease monitoring using convolutional neural networks",
                "publication_date_yy_mm": "2017-06"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Data Augmentation for Time Series Classification using Convolutional Neural Networks",
            "rating": 2
        },
        {
            "paper_title": "Data Augmentation for Deep Neural Network Acoustic Modeling",
            "rating": 2
        },
        {
            "paper_title": "Return of the Devil in the Details: Delving Deep into Convolutional Nets",
            "rating": 1
        },
        {
            "paper_title": "PD Disease State Assessment in Naturalistic Environments Using Deep Learning",
            "rating": 2
        },
        {
            "paper_title": "Network In Network",
            "rating": 1
        }
    ],
    "cost": 0.012789249999999999,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>Data Augmentation of Wearable Sensor Data for Parkinson's Disease Monitoring using Convolutional Neural Networks*</h1>
<p>Terry T. Um<br>University of Waterloo<br>Canada<br>terry.t.um@gmail.com<br>Satoshi Endo, Muriel Lang, Sandra Hirche<br>Technical University of Munich<br>Germany<br>{s.endo,muriel.lang,hirche}@tum.de</p>
<p>Franz M. J. Pfister<br>Ludwig-Maximilians-Univ. München<br>Germany<br>fmj.pfister@me.com<br>Urban Fietzek<br>Schön Klinik München Schwabing<br>Germany<br>urban.fietzek@schoen-kliniken.de</p>
<p>Daniel Pichler<br>Technical University of Munich<br>Germany<br>daniel.pichler@tum.de<br>Dana Kulić<br>University of Waterloo<br>Canada<br>dana.kulic@uwaterloo.ca</p>
<h4>Abstract</h4>
<p>While convolutional neural networks (CNNs) have been successfully applied to many challenging classification applications, they typically require large datasets for training. When the availability of labeled data is limited, data augmentation is a critical preprocessing step for CNNs. However, data augmentation for wearable sensor data has not been deeply investigated yet.</p>
<p>In this paper, various data augmentation methods for wearable sensor data are proposed. The proposed methods and CNNs are applied to the classification of the motor state of Parkinson's Disease patients, which is challenging due to small dataset size, noisy labels, and large intra-class variability. Appropriate augmentation improves the classification performance from $77.54 \%$ to $86.88 \%$.</p>
<h2>CCS CONCEPTS</h2>
<ul>
<li>Computing methodologies $\rightarrow$ Supervised learning by classification; $\cdot$ Applied computing $\rightarrow$ Consumer health;</li>
</ul>
<h2>KEYWORDS</h2>
<p>Data augmentation; wearable sensor; convolutional neural networks; Parkinson's disease; health monitoring</p>
<h2>ACM Reference Format:</h2>
<p>Terry T. Um, Franz M. J. Pfister, Daniel Pichler, Satoshi Endo, Muriel Lang, Sandra Hirche, Urban Fietzek, and Dana Kulić. 2017. Data Augmentation of Wearable Sensor Data for Parkinson's Disease Monitoring using Convolutional Neural Networks. In Proceedings of 19th ACM International Conference on Multimodal Interaction (ICMI'17). ACM, New York, NY, USA, 5 pages. https://doi.org/10.1145/3136755.3136817</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<h2>1 INTRODUCTION</h2>
<p>In recent years, convolutional neural networks (CNNs) have shown excellent performance on classification problems when large-scale labeled datasets are available (e.g. [9, 20]). However, it is challenging to apply CNNs to problems where only small labelled datasets are available. For example, collecting and labeling a large amount of medical data is often difficult. As a result, it is challenging to apply CNNs to small-scale medical data.</p>
<p>Data augmentation leverages limited data by transforming the existing samples to create new ones. A key challenge for data augmentation is to generate new data that maintains the correct label, which typically requires domain knowledge. However, it is not obvious how to carry out label-preserving augmentation in some domains, e.g., wearable sensor data. For example, scaling of the acceleration data may change their labels because some labels are differentiated by the intensity of motion.</p>
<p>In this paper, the problem of classifying the motor state of Parkinson's disease (PD) patients is tackled using CNNs. PD motor state classification is a challenging task due to noisy labels, irrelevant motion interference, large variability over patients, and limited availability of the labelled data. In this paper, we propose data augmentation methods for wearable sensor data and successfully tackle the challenging PD classification task using CNNs.</p>
<p>The contributions of the paper can be summarized as follows:</p>
<ul>
<li>Application of CNNs to the task of PD motor state classification, using a clinician-labeled dataset of 30 PD patients ( 25 patient's data are exploited) in daily-living conditions.</li>
<li>A set of approaches for data augmentation of wearable sensor datasets for CNN-based classification.</li>
<li>Experimental comparison of proposed data augmentation methods.</li>
</ul>
<h2>2 RELATED WORK</h2>
<p>Most PD patients experience motor fluctuations, which are characterized by phases of bradykinesia, i.e. underscaled and slow movement, and dyskinesia, i.e. overflowing spontaneous movement [17]. Dopaminergic treatment can alleviate symptoms of bradykinesia while its over-treatment can cause dyskinesia. Thus, an accurate evaluation of a patient's phenomenology is needed for determining the right dose of medication. Current PD motor state evaluation</p>
<p><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Figure 1: (a) and (b) show typical examples of bradykinesia and dyskinesia in a 1 min window while (c) and (d) show atypical patterns. The blue, red, green represent X,Y,Z signals from the accelerometer, respectively.
methods rely on patient self-reports and visual observation by the clinician [17].</p>
<p>Researchers have proposed automating the evaluation with wearable sensors (e.g. [5, 19]). However, most approaches to date have been limited to standardized motor tasks in clinical settings [18]. To enable automated evaluation of PD motor states which covers a wide range of PD symptoms across patients, a large amount of wearable sensor data in daily-living conditions is needed [4]. Deep learning (DL) approaches [15] provide a promising methodology to deal with the large variability of PD data [5, 8, 13]. Given the difficulty in collecting such large datasets, data augmentation is needed [6].</p>
<p>Data augmentation is an indispensable preprocessing step for achieving peak performance in DL approaches (e.g. [9, 12]). For augmenting time-series data, Le Guennec et al. [14] used window slicing and window warping methods, which extracts multiple small-size windows from a single window and lengthens/shortens a part of the window data, respectively. Unlike data augmentations for image [2] and speech recognition [3], however, data augmentation for wearable sensor data has not been systematically investigated yet to the best of our knowledge. In this paper, we propose various data augmentation methods that enable the classification of PD motor states from wearable data and evaluate them using CNN.</p>
<h2>3 PD MOTOR STATE CLASSIFICATION</h2>
<h3>3.1 Challenges in PD Data</h3>
<p>We consider two frequent PD motor states: bradykinesia, which is characterized by decreased movement speed and may be accompanied by tremor, and dyskinesia, which is characterized by involuntary extremity movements. Figure 1 illustrates exemplar one minute data windows of both motor states, from a single accelerometer worn on the wrist of PD patients. Bradykinesia data typically appear as constant signals indicating less movement (Fig 1(a)) while dyskinesia data consist of fluctuating movements (Fig 1(b)).</p>
<p>However, there are a significant number of examples that deviate from the stereotypical expressions. For example, bradykinesia accompanied by tremor can show fluctuating signals which look like a dyskinesia state (Fig 1(c)). On the other hand, dyskinesia with voluntary suppression can show constant signals which look like a bradykinesia state (Fig 1(d)).</p>
<p>There are several factors that can cause an apparent disagreement between the observed data pattern and the expert label. First, if the body of the patient indicates, e.g., a dyskinesia state, but the hand which wears the wearable sensor does not move because the patient is, e.g., holding a chair for suppressing the symptom, the assigned label based on the overall body expression will be mismatched with the recorded data from the wearable device. Also, the expert rater typically rates the symptoms for a fixed length window, but arbitrary segmentation into fixed length windows may not result in single motor state windows. Furthermore, the interference of voluntary movements, e.g., waving the hand, can make bradykinesia states look like dyskinesia, and, e.g, voluntary rest, appear like bradykinesia. Finally, bradykinesia accompanied by tremor can also can make it difficult to distinguish between bradykinesia and dyskinesia.</p>
<p>The factors described above introduce noisy labels, and lead to large intra-class variability and significant overlap between two classes. As a result, it makes the PD motor state classification more challenging, particularly given a small amount of data.</p>
<h3>3.2 Data Augmentation Methods for Wearable Sensor Data</h3>
<p>Data augmentation can be viewed as an injection of prior knowledge about the invariant properties of the data against certain transformations. Augmented data can cover unexplored input space, prevent overfitting, and improve the generalization ability of a DL model [6]. In image recognition, it is well-known that minor changes due to jittering, scaling, cropping, warping and rotating do not alter the data labels because they are likely to happen in real world observations. However, label-preserving transformations for wearable sensor data are not obvious and intuitively recognizable (Fig 2).</p>
<p>One factor that can introduce label-invariant variability of wearable sensor data are differences in sensor placement between participants. For example, an upside-down placement of the sensor can invert the sign of the sensor readings without changing the labels. Therefore, augmentation by applying arbitrary rotations (Rot) to the existing data can be used as a way of simulating different sensor placements.</p>
<p>Another factor that can introduce variability is the temporal location of activity events, e.g., tremor, in the window. Since the fixed size window segmentation is arbitrary, the location of the observed symptom in the window does not have any meaning. Thus, we may augment data by perturbing the location of the windows or events.</p>
<p>Permutation (Perm) is a simple way to randomly perturb the temporal location of within-window events. To perturb the location of the data in a single window, we first slice the data into $N$ samelength segments, with N ranging from 1 to 5 , and randomly permute the segments to create a new window. Time-warping (TimeW) is another way to perturb the temporal location. By smoothly distorting the time intervals between samples, the temporal locations of the samples can be changed using time-warping.</p>
<p>Small changes in magnitude may preserve the labels, depending on the target task. Scaling (Scale) changes the magnitude of the data in a window by multiplying by a random scalar, while</p>
<p><img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Figure 2: Various data augmentations that are used in the experiments: jittering, scaling, rotating, permutating, magnitudewarping, time-warping methods. Combinations of various data augmentations can also be applied.
magnitude-warping (MagW) changes the magnitude of each sample by convolving the data window with a smooth curve varying around one. In addition, jittering (Jitter) is also considered as a way of simulating additive sensor noise. These data augmentation methods may increase robustness against multiplicative and additive noise and improve performance.</p>
<p>Lastly, cropping (Crop), which is similar to image cropping or window slicing in [14], is applied for diminishing the dependency on event locations. Note that cropping can capture an event-free region, which might change the label. Also, note that cropping with random locations over epochs will eventually converge to a sliding window method with arbitrary stride sizes.</p>
<p>In a nutshell, jittering, scaling, cropping, rotating, permutating, magnitude-warping and time-warping methods are applied for augmenting wearable sensor data. In the next section, the performance of PD motor state classification with the proposed data augmentation methods is evaluated using CNNs.</p>
<h2>4 EXPERIMENTS</h2>
<h3>4.1 Data Preparation</h3>
<p>A dataset of 30 patients' motor states was collected using Microsoft Band 2 [1] in daily-living conditions without requesting specific motor tasks ${ }^{1}$. The 30 PD patients are $67 \pm 10$ years old, median Hoehn \&amp; Yahr stage 2, average disease duration $11 \pm 5$ years, and MoCA points $26 \pm 3$. Among them, 25 patient's data are used for this research and each one minute interval is labeled by a clinical expert. The data are collected at a frequency of 62.5 Hz and resampled to 120 Hz to deal with sampling irregularities. The first 58 -seconds of data ( 6960 samples) from each one minute window is used to make same-length instances.</p>
<p>Similar to previous works (e.g. [19], [7], [8], [5]) acceleration data only are used for the PD motor state classification. Also, nosymptom data are removed to simplify the problem and focus on characterizing data augmentation methods. Data collected during walking, laying and eating activities are also removed due to limited observation of movement during these activities. Note that no other preprocessing, e.g., data normalization or smoothing, is applied because they may confound the data label and subsequent results.</p>
<p>The resulting dataset consists of 3530 min ( 58.8 hours) of bradykinesia and dyskinesia data. For cross-validation, the 25 PD patients</p>
<p><sup id="fnref2:0"><a class="footnote-ref" href="#fn:0">1</a></sup><img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>Figure 3: 7-layer CNN with a global average pooling (GAP). The 7-layer CNN consists of 16-32-64-64-64-64-64 feature maps which reduce the size of the inputs to $2319^{<em>} 3,772^{</em>} 3$, $385^{<em>} 3,193^{</em>} 3,97^{<em>} 3,49^{</em>} 3,48^{*} 1$, respectively.
are divided into five subject groups. The performance of PD motor state classification is reported in Section 4.3 using the average values of 5 -fold cross-validation results.</p>
<h3>4.2 The CNN Architecture</h3>
<p>In this research, CNNs are used for PD motor state classification. CNNs are more suitable for small-scale datasets than long shortterm memories (LSTMs) [10] because CNNs generally use a smaller number of parameters compared to fully-connected LSTMs. Deep and sparse 7-layer CNNs (Figure 3) are employed to capture the large variability of the small-scale PD data.</p>
<p>A convolutional layer, a batch normalization layer [11], and an activation layer using rectified units (ReLUs) form a single convolutional layer of the 7-layer CNN. With strided convolutions using $4^{<em>} 1,4^{</em>} 1,3^{<em>} 1,3^{</em>} 3,2^{<em>} 3,2^{</em>} 3,2^{<em>} 3$ convolution filters, the sizes of the inputs are reduced from $6960^{</em>} 3$ to $48^{*} 1$ over layers (Figure 3). Note that XYZ signals of the accelerometer are convolved in layers $4,5,6$ and 7 to capture inter-vector-component features. For reducing the number of parameters for small-scale datasets, a global averaging pooling (GAP) layer [16] is applied at the end instead of fully-connected layers.</p>
<h3>4.3 Results</h3>
<p>Classification of PD motor states is performed using the CNN with the various data augmentation methods. For baseline results, a support vector machine (SVM) with an RBF kernel is applied to 540 dimensional statistical features: mean, variance, skewness, kurtosis,</p>
<p>Table 1: The results of PD motor state classification with various data augmentation methods. R,P,T,M represent Rot, Perm, TimeW, MagW, respectively.</p>
<table>
<thead>
<tr>
<th style="text-align: left;"></th>
<th style="text-align: center;">SVM</th>
<th style="text-align: center;">CNN</th>
<th style="text-align: center;">Jitter</th>
<th style="text-align: center;">Scale</th>
<th style="text-align: center;">Crop</th>
<th style="text-align: center;">Rot</th>
<th style="text-align: center;">Perm</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Train</td>
<td style="text-align: center;">98.82</td>
<td style="text-align: center;">99.92</td>
<td style="text-align: center;">99.78</td>
<td style="text-align: center;">99.84</td>
<td style="text-align: center;">65.77</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">99.33</td>
</tr>
<tr>
<td style="text-align: left;">Test</td>
<td style="text-align: center;">70.72</td>
<td style="text-align: center;">77.54</td>
<td style="text-align: center;">77.52</td>
<td style="text-align: center;">79.46</td>
<td style="text-align: center;">73.58</td>
<td style="text-align: center;">$\mathbf{8 2 . 6 2}$</td>
<td style="text-align: center;">81.16</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: center;">MagW</td>
<td style="text-align: center;">TimeW</td>
<td style="text-align: center;">P,T</td>
<td style="text-align: center;">R,P</td>
<td style="text-align: center;">R,T</td>
<td style="text-align: center;">R,P,T</td>
<td style="text-align: center;">R,P,T,M</td>
</tr>
<tr>
<td style="text-align: left;">Train</td>
<td style="text-align: center;">100.0</td>
<td style="text-align: center;">94.67</td>
<td style="text-align: center;">96.63</td>
<td style="text-align: center;">99.08</td>
<td style="text-align: center;">94.70</td>
<td style="text-align: center;">94.43</td>
<td style="text-align: center;">94.20</td>
</tr>
<tr>
<td style="text-align: left;">Test</td>
<td style="text-align: center;">79.33</td>
<td style="text-align: center;">82.00</td>
<td style="text-align: center;">81.75</td>
<td style="text-align: center;">$\mathbf{8 6 . 7 6}$</td>
<td style="text-align: center;">85.01</td>
<td style="text-align: center;">$\mathbf{8 6 . 8 8}$</td>
<td style="text-align: center;">85.60</td>
</tr>
</tbody>
</table>
<p><img alt="img-3.jpeg" src="img-3.jpeg" /></p>
<p>Figure 4: Training curves for CNN, Rot, Perm, TimeW, Rot+Perm and Rot+Perm+TimeW methods. The curves of Rot+Perm+TimeW shows slow training improvement and a better generalization performance.
and maximum values are extracted from 1 min data using 5 and 10-sec sliding windows. Also, a CNN is applied to raw 1 min data without data augmentation for baseline comparison. All experiments except for the SVM are performed for 400 epochs and the median values from the last 10 epoch results are used for averaging the 5 -fold cross-validation results.</p>
<p>Different random parameter values are applied for data augmentation. For jittering, a standard deviation (STD) value is sampled from a Gaussian distribution with 0.03 STD, and 1 min of Gaussian noise is generated using the sampled STD value. For scaling, a random scalar is sampled from a Gaussian distribution with a mean of 1 and 0.1 STD. For rotation, an arbitrary rotation matrix is generated for each instance. For permutation, a random integer $N$ is determined by rounding a positive value sampled from a Gaussian distribution with 5.0 STD. For magnitude-warping and time-warping, random sinusoidal curves are generated using arbitrary amplitude, frequency, and phase values. The implemented code for the proposed data augmentation methods is available online: https://github. com/terryum/Data-Augmentation-For-Wearable-Sensor-Data</p>
<p>The main results are presented in Table 1. Jittering fails to improve the performance of PD motor state classification because it introduces rapid fluctuations which look similar to dyskinesia. Cropping also fails because it drops the information of $2 / 3$ window samples, which could be a critical loss given the small dataset. Cropping of an event-free region also hinders the learning process and can be a cause of the poor performance. Scaling and magnitudewarping also fail because changing of the intensity of the signal may alter the labels.
<img alt="img-4.jpeg" src="img-4.jpeg" /></p>
<p>Figure 5: Randomly selected 40 incorrect mispredictions from the Fold-1 results of Rot+Perm+TimeW experiment. Fluctuating signals from bradykinesia (white) and constant signals from dyskinesia (yellow) are often misclassified.</p>
<p>On the other hand, rotation, permutation, and time-warping methods improve the performance of PD motor state classification. The best performance among the single data augmentation methods is achieved by rotation. Permutation and time-warping also provide performance improvements by perturbing the temporal locations of samples. These results indicate that the major sources of variability are different sensor placements between participants and event locations in an arbitrarily segmented window. The proposed rotation, permutation, and time-warping methods effectively compensate the unnecessary variations and improve the performance by $3.6-5.1 \%$ accuracy.</p>
<p>Combinations of various data augmentation methods show better performance than that of a single data augmentation method. The combinations of Rot+Perm and Rot+TimeW show better performance than the baseline of CNN by 7.5-9.2\%. The best performance is achieved by Rot+Perm+TimeW with $86.88 \%$ accuracy. These results indicate that rotation can be used to alleviate sensor pose variability while either permutation or time-warping can be employed for addressing the variability of temporal locations of events in a window.</p>
<p>Training curves of the experiments are depicted in Fig 4. The Rot+Perm+TimeW curve shows slow training improvement and a better generalization performance than others thanks to the regularization effect provided by the data augmentation. Some of the failed predictions are presented in Fig 5. From the figure, it can be observed that CNNs often misclassify fluctuating bradykinesia and constant dyskinesia data, which can be considered as seeminglynoisy labels as described in Section 3.1.</p>
<h2>5 CONCLUSION</h2>
<p>In this paper, an automatic classification algorithm for PD motor state monitoring is developed based on wearable sensor data. PD motor state classification is a challenging task because of large inter-class variability, noisy labels, interference by irrelevant motion signals and limited data availability. The challenging PD task is successfully tackled using a 7-layer CNN and the proposed data augmentation methods. The combination of rotational and permutational data augmentation methods improves the baseline performance of $77.52 \%$ accuracy to $86.88 \%$. Systematic experiments with various data augmentation methods provide a direction towards a general approach for augmentation for wearable sensor data.</p>
<h2>REFERENCES</h2>
<p>[1] Microsoft Band 2. 2015. https://www.microsoft.com/microsoft-band/
[2] Ken Chatfield, Karen Simonyan, Andrea Vedaldi, and Andrew Zisserman. 2014. Return of the Devil in the Details: Delving Deep into Convolutional Nets. CoRR abs/1405.3531 (2014).
[3] Xiaodong Cui, Vaibhava Goel, and Brian Kingsbury. 2015. Data Augmentation for Deep Neural Network Acoustic Modeling. IEEE/ACM Trans. Audio, Speech and Lang. Proc. 23, 9 (Sept. 2015), 1469-1477.
[4] Silvia Del Din, Alan Godfrey, Claudia Mazzà, Sue Lord, and Lynn Rochester. 2016. Free-living monitoring of Parkinson's disease: Lessons from the field. Movement Disorders 31, 9 (2016), 1293-1313.
[5] Bjoern M. Eskofier, Sunghoon I. Lee, Jean-Francois Daneault, Fatemeh N. Golubchi, Gabriela Ferreira-Carvalho, Gloria Vergara-Diaz, Stefano Sapienza, Gianluca Costante, Jochen Klucken, Thomas Kautz, and Paolo Bonato. 2016. Recent machine learning advancements in sensor-based mobility analysis: Deep learning for Parkinson's disease assessment. In 2016 38th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC). 655-658.
[6] Ian Goodfellow, Yoshua Bengio, and Aaron Courville. 2016. Deep Learning. MIT Press.
[7] Robert I. Griffiths, Katya Kotschet, Sian Arfon, Zheng Ming Xu, William Johnson, John Drago, Andrew Evans, Peter Kempster, Sanjay Raghav, and Malcolm K. Horne. 2012. Automated assessment of bradykinesia and dyskinesia in Parkinson's disease. Journal of Parkinson's disease 2, 1 (2012), 47-55.
[8] Nils Y. Hammerla, James M. Fisher, Peter Andras, Lynn Rochester, Richard Walker, and Thomas Plotz. 2015. PD Disease State Assessment in Naturalistic Environments Using Deep Learning. In Proceedings of the Twenty-Ninth AAAI Conference on Artificial Intelligence (AAAI'15). AAAI Press, 1742-1748.
[9] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. 2015. Deep Residual Learning for Image Recognition. CoRR abs/1512.03385 (2015). http://arxiv.org/ abs/1512.03385
[10] Sepp Hochreiter and Jörgen Schmidhuber. 1997. Long Short-Term Memory. Neural Computation 9, 8 (Nov 1997), 1735-1780.
[11] Sergey Ioffe and Christian Szegedy. 2015. Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift. ArXiv e-prints
(Feb. 2015). arXiv:cs.LG/1502.03167
[12] Alex Krizhevsky, Ilya Sutskever, and Geoffrey E. Hinton. 2012. ImageNet Classification with Deep Convolutional Neural Networks. In Advances in Neural Information Processing Systems 25, F. Pereira, C. J. C. Burges, L. Bottou, and K. Q. Weinberger (Eds.). Curran Associates, Inc., 1097-1105.
[13] Ken J. Kubota, Jason A. Chen, and Max A. Little. 2016. Machine learning for large-scale wearable sensor data in Parkinson's disease: Concepts, promises, pitfalls, and futures. Movement Disorders 31, 9 (2016), 1314-1326.
[14] Arthur Le Guennec, Simon Malinowski, and Romain Tavenard. 2016. Data Augmentation for Time Series Classification using Convolutional Neural Networks. In ECML/PKDD Workshop on Advanced Analytics and Learning on Temporal Data. Riva Del Garda, Italy. https://halshs.archives-ouvertes.fr/halshs-01357973
[15] Yann LeCun, Yoshua Bengio, and Geoffrey Hinton. 2015. Deep learning. Nature 521, 7553 (28 May 2015), 436-444. Insight.
[16] Min Lin, Qiang Chen, and Shuicheng Yan. 2013. Network In Network. ArXiv e-prints (Dec. 2013). arXiv:1312.4400
[17] Joāo Massano and Kailash P. Bhatia. 2012. Clinical Approach to Parkinson's Disease: Features, Diagnosis, and Principles of Management. Cold Spring Harb Perspect Med 2, 6 (Jun 2012), a008870.
[18] Christiana Ossig, Angelo Antonini, Carsten Buhmann, Joseph Classen, Ilona Csoti, Björn Falkenburger, Michael Schwarz, Jürgen Winkler, and Alexander Storch. 2016. Wearable sensor-based objective assessment of motor symptoms in Parkinson's disease. Journal of Neural Transmission 123, 1 (2016), 57-64.
[19] Shyamal Patel, Konrad Lorincz, Richard Hughes, Nancy Huggins, John Growdon, David Standaert, Metin Akay, Jennifer Dy, Matt Welsh, and Paolo Bonato. 2009. Monitoring Motor Fluctuations in Patients With Parkinson's Disease Using Wearable Sensors. IEEE Transactions on Information Technology in Biomedicine 13, 6 (Nov 2009), 864-873.
[20] Terry Taewoong Um, Vahid Babakeshizadeh, and Dana Kulic. 2017. Exercise Motion Classification from Large-Scale Wearable Sensor Data Using Convolutional Neural Networks. In 2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS). 1-6.</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>${ }^{1}$ The study was approved by the ethics committee of Technical University of Munich (Az. 234/16 S).&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>