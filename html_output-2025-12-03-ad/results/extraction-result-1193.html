<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-1193 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-1193</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-1193</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-26.html">extraction-schema-26</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of automated systems making scientific discoveries, including how these discoveries are characterized as incremental or transformational, and how they are evaluated and validated.</div>
                <p><strong>Paper ID:</strong> paper-258461620</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2305.02251v2.pdf" target="_blank">Automated Scientific Discovery: From Equation Discovery to Autonomous Discovery Systems</a></p>
                <p><strong>Paper Abstract:</strong> The paper surveys automated scientific discovery, from equation discovery and symbolic regression to autonomous discovery systems and agents. It discusses the individual approaches from a "big picture" perspective and in context, but also discusses open issues and recent topics like the various roles of deep neural networks in this area, aiding in the discovery of human-interpretable knowledge. Further, we will present closed-loop scientific discovery systems, starting with the pioneering work on the Adam system up to current efforts in fields from material science to astronomy. Finally, we will elaborate on autonomy from a machine learning perspective, but also in analogy to the autonomy levels in autonomous driving. The maximal level, level five, is defined to require no human intervention at all in the production of scientific knowledge. Achieving this is one step towards solving the Nobel Turing Grand Challenge to develop AI Scientists: AI systems capable of making Nobel-quality scientific discoveries highly autonomously at a level comparable, and possibly superior, to the best human scientists by 2050.</p>
                <p><strong>Cost:</strong> 0.017</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e1193.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e1193.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of automated systems making scientific discoveries, including how these discoveries are characterized as incremental or transformational, and how they are evaluated and validated.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Adam</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Adam (Robot Scientist)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A pioneering closed-loop robot scientist that automated cycles of hypothesis generation, experimental planning and laboratory execution to identify gene–function relationships in yeast, integrating a Prolog knowledge base with laboratory robotics.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>The automation of science.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Adam</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>A laboratory automation and AI system combining knowledge-based reasoning (Prolog knowledge base), abduction for hypothesis formation, experiment planning, and robotic lab execution (freezer, liquid handlers, plate readers, robot arms). It measured outcomes (yeast growth) with optical sensors and iterated the hypothesis–test cycle autonomously within its constrained domain (functional genomics of yeast).</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_domain</strong></td>
                            <td>Functional genomics / Molecular biology (yeast)</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_description</strong></td>
                            <td>Adam identified six genes encoding orphan enzymes in Saccharomyces cerevisiae by forming abduced hypotheses from bioinformatic data and then automatically executing growth experiments to test candidate gene–enzyme assignments.</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_type</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>discovery_type_justification</strong></td>
                            <td>The paper reports Adam's concrete discoveries (six gene assignments) but does not label them as incremental or transformational; it presents them as examples of successful autonomous discovery within a constrained domain.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_methods</strong></td>
                            <td>Evaluation reported in the paper is experimental: hypotheses produced by Adam were evaluated by carrying out automated wet-lab experiments (yeast growth assays) and measuring outcomes via optical sensors. More generally, the survey frames evaluation for such systems in terms of scope (which scientific steps are automated), supervision (ground-truth or reward signals available), data modalities, and open-endedness; for Adam specifically, success is judged by experimentally demonstrated correct gene–function assignments.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_approaches</strong></td>
                            <td>Experimental wet-lab validation: candidate gene–enzyme relationships were tested by the system's designed experiments and assessed via measured yeast growth responses. The discoveries are validated by laboratory evidence (the experiments Adam executed) and subsequent reporting in the literature (peer-reviewed publication).</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment</strong></td>
                            <td>Novelty is assessed by whether the gene–enzyme mappings were previously unknown. The survey treats Adam's identifications as 'new knowledge' because they assigned genes to previously orphan reactions; novelty is thus determined by comparison to existing curated knowledge bases and literature at the time.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_metrics</strong></td>
                            <td>Reported impact is qualitative in the survey (discovery of 6 genes); no numerical success rate or statistical metric for overall performance is provided in this survey. Impact is described in terms of concrete novel assignments and the ability to close the hypothesis–experiment loop.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_human_discoveries</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_details</strong></td>
                            <td>The paper discusses Adam as a pioneering autonomous system and contrasts automated reproducibility and throughput benefits with manual human experiments, but does not provide quantitative head-to-head performance comparisons to human scientists for the specific discoveries.</td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td>The survey states Adam identified six genes (successful cases) but does not provide a numeric overall success rate or false-positive/false-negative rates for its hypotheses across all attempted cases.</td>
                        </tr>
                        <tr>
                            <td><strong>challenges_limitations</strong></td>
                            <td>Limitations include narrow domain scope (functional genomics in yeast), limited types of experiments the system could design/execute, and the broader gap between closed-loop lab automation and systems that can create entirely new theories or measurement devices.</td>
                        </tr>
                        <tr>
                            <td><strong>has_incremental_transformational_comparison</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Automated Scientific Discovery: From Equation Discovery to Autonomous Discovery Systems', 'publication_date_yy_mm': '2023-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1193.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e1193.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of automated systems making scientific discoveries, including how these discoveries are characterized as incremental or transformational, and how they are evaluated and validated.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Eve</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Eve (Robot Scientist for drug discovery)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A laboratory automation system that combines active learning with Gaussian process regression to screen chemical libraries and identify candidate compounds for repurposing, demonstrated in drug repositioning against tropical diseases.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Cheaper faster drug development validated by the repositioning of drugs against neglected tropical diseases.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Eve</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>An AI-driven self-driving lab system using active learning and Gaussian process regression (GPR) to build QSAR models mapping compound descriptors to biological activity; the learned model acts as a (noisy) oracle to select compounds to assay, balancing exploration and exploitation, with robotic execution of high-throughput screens.</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_domain</strong></td>
                            <td>Drug discovery / Pharmacology (tropical diseases)</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_description</strong></td>
                            <td>Eve discovered that certain existing compounds (notably the anti-cancer compound TNP-470) could be repurposed to act against Plasmodium vivax, found via iterative QSAR modeling, candidate selection, and experimental testing.</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_type</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>discovery_type_justification</strong></td>
                            <td>The survey reports Eve's repurposing results as validated discoveries but does not explicitly characterize them as incremental versus transformational; they are presented as successful applications of autonomous screening and hypothesis testing.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_methods</strong></td>
                            <td>Evaluation combined model-based selection performance (QSAR predictive performance using GPR), experimental hit rates from high-throughput assays, and downstream biological validation of activity. The survey cites the repositioning paper which frames the contribution as demonstrating 'cheaper, faster' drug development (practical efficiency metrics) rather than formal statistical discovery-rate metrics in this survey.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_approaches</strong></td>
                            <td>Experimental validation via wet-lab high-throughput screening of candidate compounds selected by Eve, and demonstration of biological activity against target organisms (e.g., parasite assays confirming TNP-470 activity). The published work cited reports validation by experimental assays and downstream analysis.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment</strong></td>
                            <td>Novelty is assessed by whether activity against the targeted pathogen was previously known; discovery of repurposing candidates is novel when prior literature does not report the activity. The survey references the peer-reviewed repositioning paper as validation of novelty.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_metrics</strong></td>
                            <td>Survey-level impact claims emphasize efficiency (cheaper and faster discovery) and successful repurposing examples; no specific numerical generalization rates are provided in the survey text (the cited papers include hit rates and cost/time claims but those numbers are not reproduced here).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_human_discoveries</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_details</strong></td>
                            <td>The survey notes Eve increased productivity and enabled discoveries (repurposing) that were experimentally validated, and suggests AI Scientists can be less biased and more reproducible than human experiments, but does not give direct numerical comparisons between Eve and human screening campaigns.</td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td>The survey does not report an overall numeric success rate; the specific repositioning example (TNP-470 against P. vivax) is reported as a validated hit, but overall hit rates or false-discovery rates are not provided in the survey.</td>
                        </tr>
                        <tr>
                            <td><strong>challenges_limitations</strong></td>
                            <td>Limitations include restricted experiment types the platform can execute, dependency on available compound pools and assay types, and the general challenges of experimental design and integrating novel assays into robotic pipelines.</td>
                        </tr>
                        <tr>
                            <td><strong>has_incremental_transformational_comparison</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Automated Scientific Discovery: From Equation Discovery to Autonomous Discovery Systems', 'publication_date_yy_mm': '2023-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1193.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e1193.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of automated systems making scientific discoveries, including how these discoveries are characterized as incremental or transformational, and how they are evaluated and validated.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>BACON</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>BACON (series: BACON.1 to BACON.5)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Early production-system-based equation discovery system that searched for empirical laws by testing for constancy among constructed terms (ratios, products, etc.), with features such as symmetry and conservation detection.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Bacon: A production system that discovers empirical laws.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>BACON</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>A rule-based production-system approach to equation discovery that forms candidate terms (e.g., ratios, products), tests for approximate constancy under a ceteris-paribus assumption, uses tolerance parameters for noise handling, and incrementally constructs more complex expressions (BACON.1–BACON.5 added symmetries, divisors, conservation laws).</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_domain</strong></td>
                            <td>Physics / empirical law discovery (general)</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_description</strong></td>
                            <td>BACON-style systems rediscovered known empirical laws such as Kepler's third law in examples by iteratively constructing candidate terms and identifying constants; the approach is demonstrated on synthetic and empirical datasets in early AI discovery work.</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_type</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>discovery_type_justification</strong></td>
                            <td>The survey presents BACON as an early example of automated rediscovery of known laws; it is not explicitly labeled incremental or transformational in the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_methods</strong></td>
                            <td>Evaluation typically by successful recovery (rediscovery) of known analytic laws from provided datasets (e.g., Kepler's law). The approach uses tolerance thresholds for noise and constructs terms until a near-constant value is found, which serves as an evaluation signal.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_approaches</strong></td>
                            <td>Validation is comparison to known closed-form equations (i.e., checking whether the discovered expression matches a known law) and robustness checks under noise tolerance parameters.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment</strong></td>
                            <td>Often assessed by whether the system recovers known laws (rediscovery) or constructs previously unknown algebraic relations; BACON historically served to demonstrate method capability rather than producing unprecedented transformational discoveries.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_metrics</strong></td>
                            <td>Measured by success in rediscovery tasks (qualitative) and the complexity/conciseness of derived expressions; no quantitative rates are provided in the survey.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_human_discoveries</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_details</strong></td>
                            <td>The paper discusses BACON historically and conceptually but does not present direct performance comparisons to human scientists.</td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td>No numeric success rate is reported in the survey; success is illustrated via example rediscoveries (e.g., Kepler's law).</td>
                        </tr>
                        <tr>
                            <td><strong>challenges_limitations</strong></td>
                            <td>Assumes ceteris paribus (holding other variables constant), limited noise handling (via tolerance parameter), and is constrained by the need for controlled data and low-dimensional problems.</td>
                        </tr>
                        <tr>
                            <td><strong>has_incremental_transformational_comparison</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Automated Scientific Discovery: From Equation Discovery to Autonomous Discovery Systems', 'publication_date_yy_mm': '2023-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1193.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e1193.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of automated systems making scientific discoveries, including how these discoveries are characterized as incremental or transformational, and how they are evaluated and validated.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>FAHRENHEIT (Zytkow)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>FAHRENHEIT (robotic chemistry/equation discovery coupling by Jan Zytkow)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An early coupling of real electrochemistry experiments with an equation-discovery system to automatically derive empirical relations, and later used in robotic rediscovery of Galileo's incline-plane equation while accounting for empirical error.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Automated discovery in a chemistry laboratory.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>FAHRENHEIT (as used by Zytkow et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>A system that couples laboratory experimental apparatus (electrochemistry experiments, robotic data collection) with equation-discovery algorithms (FAHRENHEIT) to produce candidate empirical equations from robot-collected data, and that can account for empirical error in rediscovery tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_domain</strong></td>
                            <td>Chemistry / Physics (empirical law discovery)</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_description</strong></td>
                            <td>FAHRENHEIT-assisted robotic experiments were used to discover empirical relations from electrochemistry experiments and to rediscover Galileo's equation for objects rolling on an inclined plane, with explicit handling of empirical error.</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_type</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>discovery_type_justification</strong></td>
                            <td>Presented as successful automated rediscovery and empirical equation derivation; the survey does not call these discoveries transformational versus incremental.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_methods</strong></td>
                            <td>Evaluation by whether the system-derived equations match known physical laws (rediscovery) and by assessing fit quality given empirical noise; the survey highlights the inclusion of empirical error in the rediscovery task as an important evaluation factor.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_approaches</strong></td>
                            <td>Validation via robot-collected experimental data and comparison of derived equations to the known analytic form (e.g., Galileo's equation), with attention to empirical error and robustness to noise.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment</strong></td>
                            <td>Often framed as rediscovery (demonstrating capability) rather than novel discoveries; novelty measured by whether derived equations were previously known.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_metrics</strong></td>
                            <td>Qualitative demonstration of capability to couple experiment and equation discovery; the survey does not provide numeric impact metrics for FAHRENHEIT experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_human_discoveries</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_details</strong></td>
                            <td>The survey references Zytkow's work to show early integration of lab automation and equation discovery but does not provide numerical comparisons to human performance.</td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td>No overall numeric success rate provided; success illustrated by case studies and rediscovery experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>challenges_limitations</strong></td>
                            <td>Limitations include experiment scope, handling of empirical error, and the need to integrate experimental logistics with equation-discovery algorithms.</td>
                        </tr>
                        <tr>
                            <td><strong>has_incremental_transformational_comparison</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Automated Scientific Discovery: From Equation Discovery to Autonomous Discovery Systems', 'publication_date_yy_mm': '2023-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1193.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e1193.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of automated systems making scientific discoveries, including how these discoveries are characterized as incremental or transformational, and how they are evaluated and validated.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Schmidt & Lipson SR</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Symbolic regression for natural laws (Schmidt & Lipson)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A landmark symbolic regression approach that used genetic programming to distill free-form natural laws from measured data, demonstrating automated recovery of interpretable physical relations.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Distilling free-form natural laws from experimental data.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Symbolic regression (Schmidt & Lipson approach)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>A genetic-programming-based symbolic regression system that searches expression trees/operators to find compact analytic expressions that fit measured data, emphasizing human-interpretable natural laws recovered from experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_domain</strong></td>
                            <td>Physics / general natural laws discovery</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_description</strong></td>
                            <td>Demonstrated recovery of known physical relations and discovery of interpretable analytic expressions (natural laws) from experimental time-series data using symbolic regression techniques.</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_type</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>discovery_type_justification</strong></td>
                            <td>Presented as recovery (and in some cases discovery) of natural laws using symbolic regression; the paper does not explicitly categorize these as incremental or transformational within the survey.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_methods</strong></td>
                            <td>Evaluation by symbolic fidelity to known laws (did the system recover known analytic expressions), predictive accuracy on held-out data, and parsimony/complexity trade-offs (often via Pareto fronts). Later systems discussed in the survey add measures like MEDL (MDL-inspired) instead of RMSE to balance complexity and error.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_approaches</strong></td>
                            <td>Validation via comparison to established analytic laws (rediscovery), predictive validation on held-out experimental data, and peer-reviewed publication of results.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment</strong></td>
                            <td>Novelty judged by whether a discovered equation corresponds to previously unknown relations; many demonstrations are rediscoveries to validate method capability rather than claims of paradigm-shifting novel science.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_metrics</strong></td>
                            <td>Metrics include fit error (RMSE or MDL-inspired scores), expression complexity (for Pareto-optimal trade-offs), and success at recovering ground-truth expressions in benchmark tasks; the survey does not list single numeric values for these metrics for Schmidt & Lipson.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_human_discoveries</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_details</strong></td>
                            <td>The survey situates symbolic regression as a method that can produce human-interpretable laws and notes its historical success in rediscovering known laws; it does not provide quantified comparisons to individual human discoveries.</td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td>No aggregate numeric success rate provided in the survey; success is evidenced by examples and benchmark tasks in the literature.</td>
                        </tr>
                        <tr>
                            <td><strong>challenges_limitations</strong></td>
                            <td>Challenges include brittleness of equations to small syntactic changes, overfitting vs complexity trade-offs, scaling to high-dimensional systems, and the need to relate discovered equations to existing theory.</td>
                        </tr>
                        <tr>
                            <td><strong>has_incremental_transformational_comparison</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Automated Scientific Discovery: From Equation Discovery to Autonomous Discovery Systems', 'publication_date_yy_mm': '2023-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1193.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e1193.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of automated systems making scientific discoveries, including how these discoveries are characterized as incremental or transformational, and how they are evaluated and validated.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Robot Scientist (general)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Robot Scientists / AI Scientists / Autonomous Discovery Systems (general category)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A class of closed-loop systems that generate hypotheses, design experiments, execute them with laboratory automation, analyze results, and iterate; exemplified by systems such as Adam, Eve and subsequent third-generation robot scientists.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Robot Scientist (general)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Systems that aim to automate all or parts of the scientific method: hypothesis generation (abduction/induction), experimental design (deduction/planning), robotic execution of experiments, automated data analysis, and iteration. Architectures combine knowledge representation, statistical/ML models (e.g., GPR, active learning), planning modules, and physical lab robotics.</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_domain</strong></td>
                            <td>Multiple domains (biomedicine, chemistry, materials, astronomy, physics) as implemented in domain-specific robot scientists</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_description</strong></td>
                            <td>As a class, Robot Scientists have produced rediscoveries of known laws, identification of biological functions (Adam: gene–enzyme assignments), and drug repurposing hits (Eve: TNP-470), among other domain-specific findings; they automate the closed-loop cycle and digitally curate the entire process.</td>
                        </tr>
                        <tr>
                            <td><strong>discovery_type</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>discovery_type_justification</strong></td>
                            <td>The survey frames robot scientists as having potential for transformational impact (see Nobel Turing Grand Challenge) but does not categorize specific reported discoveries uniformly as incremental or transformational; the text distinguishes potential future transformational capability (Nobel-quality discoveries) from the current state (domain-limited discoveries).</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_methods</strong></td>
                            <td>The survey proposes multi-faceted evaluation dimensions: supervision (type/strength of ground truth), data modalities, scope (which scientific steps are included: question, hypothesis, design, execution, analysis, communication), and open-endedness. It lists concrete benchmarks/testbeds (Nguyen, Feynman, Matbench, ScienceWorld, DiscoveryWorld, Science-Gym, DiscoveryBench, BoxingGym, etc.) and metrics including symbolic accuracy (for equation discovery), expected information gain (for experimental design), task completion (ScienceWorld), and predictive performance of derived models.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_approaches</strong></td>
                            <td>Validation methods include: (1) experimental validation (robot-executed assays demonstrating activity or function), (2) comparison to known results (rediscovery tasks), (3) reproducibility tests (robotic repetition of published experiments, e.g., referenced reproducibility studies), (4) benchmark-based evaluation (symbolic benchmarks, simulation environments), and (5) peer-reviewed publication of results. The survey emphasizes that validation depends on which parts of the cycle are automated.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment</strong></td>
                            <td>Novelty is assessed by (a) whether derived hypotheses/equations are previously unknown, (b) successful experimental confirmation of novel claims, and (c) the degree of open-endedness of the benchmark (ability to handle previously unexplained phenomena). The survey warns that many demonstrations are rediscoveries intended to validate capability rather than novel paradigm-shifting findings.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_metrics</strong></td>
                            <td>Impact is measured variably: number of validated novel findings (e.g., Adam's 6 gene assignments), successful drug repositionings, improvements in throughput/efficiency ('cheaper, faster' claims), reproducibility statistics in robot-driven replication studies, symbolic accuracy and complexity trade-offs on benchmarks, and success on interactive discovery environments. The survey itself does not standardize a single numeric impact metric.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_human_discoveries</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_details</strong></td>
                            <td>The survey compares robot scientists conceptually to human scientists in autonomy and skill (analogy to driving autonomy levels), discussing the aspiration to reach 'Nobel-quality' discoveries comparable to top human scientists by 2050 (Nobel Turing Grand Challenge). It notes advantages (efficiency, reproducibility, robustness) and the lack of current systems with human-level generality; no direct quantitative head-to-head performance numbers are provided.</td>
                        </tr>
                        <tr>
                            <td><strong>success_rate</strong></td>
                            <td>No single success rate is reported for the class. Examples include concrete validated outcomes (Adam's 6 gene assignments; Eve's repositioning examples). The survey highlights lack of broad numeric reporting and calls for benchmarked evaluation across supervision, modality, scope, and open-endedness.</td>
                        </tr>
                        <tr>
                            <td><strong>challenges_limitations</strong></td>
                            <td>Key challenges: (1) automated design of novel experiments (formalizing lab equipment and general experimental compilers), (2) integration with diverse laboratory robotics and logistics, (3) formation of entirely new hypotheses/theories and creation of measurement devices, (4) limited experiment types in existing systems, (5) issues of data provenance and potential prior exposure in foundation-model-based methods, (6) relating discovered equations to existing theory and interpretability, and (7) scaling discovery methods to high-dimensional systems.</td>
                        </tr>
                        <tr>
                            <td><strong>has_incremental_transformational_comparison</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Automated Scientific Discovery: From Equation Discovery to Autonomous Discovery Systems', 'publication_date_yy_mm': '2023-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>The automation of science. <em>(Rating: 2)</em></li>
                <li>Cheaper faster drug development validated by the repositioning of drugs against neglected tropical diseases. <em>(Rating: 2)</em></li>
                <li>Automated discovery in a chemistry laboratory. <em>(Rating: 2)</em></li>
                <li>Distilling free-form natural laws from experimental data. <em>(Rating: 2)</em></li>
                <li>Bacon: A production system that discovers empirical laws. <em>(Rating: 2)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-1193",
    "paper_id": "paper-258461620",
    "extraction_schema_id": "extraction-schema-26",
    "extracted_data": [
        {
            "name_short": "Adam",
            "name_full": "Adam (Robot Scientist)",
            "brief_description": "A pioneering closed-loop robot scientist that automated cycles of hypothesis generation, experimental planning and laboratory execution to identify gene–function relationships in yeast, integrating a Prolog knowledge base with laboratory robotics.",
            "citation_title": "The automation of science.",
            "mention_or_use": "mention",
            "system_name": "Adam",
            "system_description": "A laboratory automation and AI system combining knowledge-based reasoning (Prolog knowledge base), abduction for hypothesis formation, experiment planning, and robotic lab execution (freezer, liquid handlers, plate readers, robot arms). It measured outcomes (yeast growth) with optical sensors and iterated the hypothesis–test cycle autonomously within its constrained domain (functional genomics of yeast).",
            "discovery_domain": "Functional genomics / Molecular biology (yeast)",
            "discovery_description": "Adam identified six genes encoding orphan enzymes in Saccharomyces cerevisiae by forming abduced hypotheses from bioinformatic data and then automatically executing growth experiments to test candidate gene–enzyme assignments.",
            "discovery_type": null,
            "discovery_type_justification": "The paper reports Adam's concrete discoveries (six gene assignments) but does not label them as incremental or transformational; it presents them as examples of successful autonomous discovery within a constrained domain.",
            "evaluation_methods": "Evaluation reported in the paper is experimental: hypotheses produced by Adam were evaluated by carrying out automated wet-lab experiments (yeast growth assays) and measuring outcomes via optical sensors. More generally, the survey frames evaluation for such systems in terms of scope (which scientific steps are automated), supervision (ground-truth or reward signals available), data modalities, and open-endedness; for Adam specifically, success is judged by experimentally demonstrated correct gene–function assignments.",
            "validation_approaches": "Experimental wet-lab validation: candidate gene–enzyme relationships were tested by the system's designed experiments and assessed via measured yeast growth responses. The discoveries are validated by laboratory evidence (the experiments Adam executed) and subsequent reporting in the literature (peer-reviewed publication).",
            "novelty_assessment": "Novelty is assessed by whether the gene–enzyme mappings were previously unknown. The survey treats Adam's identifications as 'new knowledge' because they assigned genes to previously orphan reactions; novelty is thus determined by comparison to existing curated knowledge bases and literature at the time.",
            "impact_metrics": "Reported impact is qualitative in the survey (discovery of 6 genes); no numerical success rate or statistical metric for overall performance is provided in this survey. Impact is described in terms of concrete novel assignments and the ability to close the hypothesis–experiment loop.",
            "comparison_to_human_discoveries": null,
            "comparison_details": "The paper discusses Adam as a pioneering autonomous system and contrasts automated reproducibility and throughput benefits with manual human experiments, but does not provide quantitative head-to-head performance comparisons to human scientists for the specific discoveries.",
            "success_rate": "The survey states Adam identified six genes (successful cases) but does not provide a numeric overall success rate or false-positive/false-negative rates for its hypotheses across all attempted cases.",
            "challenges_limitations": "Limitations include narrow domain scope (functional genomics in yeast), limited types of experiments the system could design/execute, and the broader gap between closed-loop lab automation and systems that can create entirely new theories or measurement devices.",
            "has_incremental_transformational_comparison": false,
            "uuid": "e1193.0",
            "source_info": {
                "paper_title": "Automated Scientific Discovery: From Equation Discovery to Autonomous Discovery Systems",
                "publication_date_yy_mm": "2023-05"
            }
        },
        {
            "name_short": "Eve",
            "name_full": "Eve (Robot Scientist for drug discovery)",
            "brief_description": "A laboratory automation system that combines active learning with Gaussian process regression to screen chemical libraries and identify candidate compounds for repurposing, demonstrated in drug repositioning against tropical diseases.",
            "citation_title": "Cheaper faster drug development validated by the repositioning of drugs against neglected tropical diseases.",
            "mention_or_use": "mention",
            "system_name": "Eve",
            "system_description": "An AI-driven self-driving lab system using active learning and Gaussian process regression (GPR) to build QSAR models mapping compound descriptors to biological activity; the learned model acts as a (noisy) oracle to select compounds to assay, balancing exploration and exploitation, with robotic execution of high-throughput screens.",
            "discovery_domain": "Drug discovery / Pharmacology (tropical diseases)",
            "discovery_description": "Eve discovered that certain existing compounds (notably the anti-cancer compound TNP-470) could be repurposed to act against Plasmodium vivax, found via iterative QSAR modeling, candidate selection, and experimental testing.",
            "discovery_type": null,
            "discovery_type_justification": "The survey reports Eve's repurposing results as validated discoveries but does not explicitly characterize them as incremental versus transformational; they are presented as successful applications of autonomous screening and hypothesis testing.",
            "evaluation_methods": "Evaluation combined model-based selection performance (QSAR predictive performance using GPR), experimental hit rates from high-throughput assays, and downstream biological validation of activity. The survey cites the repositioning paper which frames the contribution as demonstrating 'cheaper, faster' drug development (practical efficiency metrics) rather than formal statistical discovery-rate metrics in this survey.",
            "validation_approaches": "Experimental validation via wet-lab high-throughput screening of candidate compounds selected by Eve, and demonstration of biological activity against target organisms (e.g., parasite assays confirming TNP-470 activity). The published work cited reports validation by experimental assays and downstream analysis.",
            "novelty_assessment": "Novelty is assessed by whether activity against the targeted pathogen was previously known; discovery of repurposing candidates is novel when prior literature does not report the activity. The survey references the peer-reviewed repositioning paper as validation of novelty.",
            "impact_metrics": "Survey-level impact claims emphasize efficiency (cheaper and faster discovery) and successful repurposing examples; no specific numerical generalization rates are provided in the survey text (the cited papers include hit rates and cost/time claims but those numbers are not reproduced here).",
            "comparison_to_human_discoveries": null,
            "comparison_details": "The survey notes Eve increased productivity and enabled discoveries (repurposing) that were experimentally validated, and suggests AI Scientists can be less biased and more reproducible than human experiments, but does not give direct numerical comparisons between Eve and human screening campaigns.",
            "success_rate": "The survey does not report an overall numeric success rate; the specific repositioning example (TNP-470 against P. vivax) is reported as a validated hit, but overall hit rates or false-discovery rates are not provided in the survey.",
            "challenges_limitations": "Limitations include restricted experiment types the platform can execute, dependency on available compound pools and assay types, and the general challenges of experimental design and integrating novel assays into robotic pipelines.",
            "has_incremental_transformational_comparison": false,
            "uuid": "e1193.1",
            "source_info": {
                "paper_title": "Automated Scientific Discovery: From Equation Discovery to Autonomous Discovery Systems",
                "publication_date_yy_mm": "2023-05"
            }
        },
        {
            "name_short": "BACON",
            "name_full": "BACON (series: BACON.1 to BACON.5)",
            "brief_description": "Early production-system-based equation discovery system that searched for empirical laws by testing for constancy among constructed terms (ratios, products, etc.), with features such as symmetry and conservation detection.",
            "citation_title": "Bacon: A production system that discovers empirical laws.",
            "mention_or_use": "mention",
            "system_name": "BACON",
            "system_description": "A rule-based production-system approach to equation discovery that forms candidate terms (e.g., ratios, products), tests for approximate constancy under a ceteris-paribus assumption, uses tolerance parameters for noise handling, and incrementally constructs more complex expressions (BACON.1–BACON.5 added symmetries, divisors, conservation laws).",
            "discovery_domain": "Physics / empirical law discovery (general)",
            "discovery_description": "BACON-style systems rediscovered known empirical laws such as Kepler's third law in examples by iteratively constructing candidate terms and identifying constants; the approach is demonstrated on synthetic and empirical datasets in early AI discovery work.",
            "discovery_type": null,
            "discovery_type_justification": "The survey presents BACON as an early example of automated rediscovery of known laws; it is not explicitly labeled incremental or transformational in the paper.",
            "evaluation_methods": "Evaluation typically by successful recovery (rediscovery) of known analytic laws from provided datasets (e.g., Kepler's law). The approach uses tolerance thresholds for noise and constructs terms until a near-constant value is found, which serves as an evaluation signal.",
            "validation_approaches": "Validation is comparison to known closed-form equations (i.e., checking whether the discovered expression matches a known law) and robustness checks under noise tolerance parameters.",
            "novelty_assessment": "Often assessed by whether the system recovers known laws (rediscovery) or constructs previously unknown algebraic relations; BACON historically served to demonstrate method capability rather than producing unprecedented transformational discoveries.",
            "impact_metrics": "Measured by success in rediscovery tasks (qualitative) and the complexity/conciseness of derived expressions; no quantitative rates are provided in the survey.",
            "comparison_to_human_discoveries": null,
            "comparison_details": "The paper discusses BACON historically and conceptually but does not present direct performance comparisons to human scientists.",
            "success_rate": "No numeric success rate is reported in the survey; success is illustrated via example rediscoveries (e.g., Kepler's law).",
            "challenges_limitations": "Assumes ceteris paribus (holding other variables constant), limited noise handling (via tolerance parameter), and is constrained by the need for controlled data and low-dimensional problems.",
            "has_incremental_transformational_comparison": false,
            "uuid": "e1193.2",
            "source_info": {
                "paper_title": "Automated Scientific Discovery: From Equation Discovery to Autonomous Discovery Systems",
                "publication_date_yy_mm": "2023-05"
            }
        },
        {
            "name_short": "FAHRENHEIT (Zytkow)",
            "name_full": "FAHRENHEIT (robotic chemistry/equation discovery coupling by Jan Zytkow)",
            "brief_description": "An early coupling of real electrochemistry experiments with an equation-discovery system to automatically derive empirical relations, and later used in robotic rediscovery of Galileo's incline-plane equation while accounting for empirical error.",
            "citation_title": "Automated discovery in a chemistry laboratory.",
            "mention_or_use": "mention",
            "system_name": "FAHRENHEIT (as used by Zytkow et al.)",
            "system_description": "A system that couples laboratory experimental apparatus (electrochemistry experiments, robotic data collection) with equation-discovery algorithms (FAHRENHEIT) to produce candidate empirical equations from robot-collected data, and that can account for empirical error in rediscovery tasks.",
            "discovery_domain": "Chemistry / Physics (empirical law discovery)",
            "discovery_description": "FAHRENHEIT-assisted robotic experiments were used to discover empirical relations from electrochemistry experiments and to rediscover Galileo's equation for objects rolling on an inclined plane, with explicit handling of empirical error.",
            "discovery_type": null,
            "discovery_type_justification": "Presented as successful automated rediscovery and empirical equation derivation; the survey does not call these discoveries transformational versus incremental.",
            "evaluation_methods": "Evaluation by whether the system-derived equations match known physical laws (rediscovery) and by assessing fit quality given empirical noise; the survey highlights the inclusion of empirical error in the rediscovery task as an important evaluation factor.",
            "validation_approaches": "Validation via robot-collected experimental data and comparison of derived equations to the known analytic form (e.g., Galileo's equation), with attention to empirical error and robustness to noise.",
            "novelty_assessment": "Often framed as rediscovery (demonstrating capability) rather than novel discoveries; novelty measured by whether derived equations were previously known.",
            "impact_metrics": "Qualitative demonstration of capability to couple experiment and equation discovery; the survey does not provide numeric impact metrics for FAHRENHEIT experiments.",
            "comparison_to_human_discoveries": null,
            "comparison_details": "The survey references Zytkow's work to show early integration of lab automation and equation discovery but does not provide numerical comparisons to human performance.",
            "success_rate": "No overall numeric success rate provided; success illustrated by case studies and rediscovery experiments.",
            "challenges_limitations": "Limitations include experiment scope, handling of empirical error, and the need to integrate experimental logistics with equation-discovery algorithms.",
            "has_incremental_transformational_comparison": false,
            "uuid": "e1193.3",
            "source_info": {
                "paper_title": "Automated Scientific Discovery: From Equation Discovery to Autonomous Discovery Systems",
                "publication_date_yy_mm": "2023-05"
            }
        },
        {
            "name_short": "Schmidt & Lipson SR",
            "name_full": "Symbolic regression for natural laws (Schmidt & Lipson)",
            "brief_description": "A landmark symbolic regression approach that used genetic programming to distill free-form natural laws from measured data, demonstrating automated recovery of interpretable physical relations.",
            "citation_title": "Distilling free-form natural laws from experimental data.",
            "mention_or_use": "mention",
            "system_name": "Symbolic regression (Schmidt & Lipson approach)",
            "system_description": "A genetic-programming-based symbolic regression system that searches expression trees/operators to find compact analytic expressions that fit measured data, emphasizing human-interpretable natural laws recovered from experiments.",
            "discovery_domain": "Physics / general natural laws discovery",
            "discovery_description": "Demonstrated recovery of known physical relations and discovery of interpretable analytic expressions (natural laws) from experimental time-series data using symbolic regression techniques.",
            "discovery_type": null,
            "discovery_type_justification": "Presented as recovery (and in some cases discovery) of natural laws using symbolic regression; the paper does not explicitly categorize these as incremental or transformational within the survey.",
            "evaluation_methods": "Evaluation by symbolic fidelity to known laws (did the system recover known analytic expressions), predictive accuracy on held-out data, and parsimony/complexity trade-offs (often via Pareto fronts). Later systems discussed in the survey add measures like MEDL (MDL-inspired) instead of RMSE to balance complexity and error.",
            "validation_approaches": "Validation via comparison to established analytic laws (rediscovery), predictive validation on held-out experimental data, and peer-reviewed publication of results.",
            "novelty_assessment": "Novelty judged by whether a discovered equation corresponds to previously unknown relations; many demonstrations are rediscoveries to validate method capability rather than claims of paradigm-shifting novel science.",
            "impact_metrics": "Metrics include fit error (RMSE or MDL-inspired scores), expression complexity (for Pareto-optimal trade-offs), and success at recovering ground-truth expressions in benchmark tasks; the survey does not list single numeric values for these metrics for Schmidt & Lipson.",
            "comparison_to_human_discoveries": null,
            "comparison_details": "The survey situates symbolic regression as a method that can produce human-interpretable laws and notes its historical success in rediscovering known laws; it does not provide quantified comparisons to individual human discoveries.",
            "success_rate": "No aggregate numeric success rate provided in the survey; success is evidenced by examples and benchmark tasks in the literature.",
            "challenges_limitations": "Challenges include brittleness of equations to small syntactic changes, overfitting vs complexity trade-offs, scaling to high-dimensional systems, and the need to relate discovered equations to existing theory.",
            "has_incremental_transformational_comparison": false,
            "uuid": "e1193.4",
            "source_info": {
                "paper_title": "Automated Scientific Discovery: From Equation Discovery to Autonomous Discovery Systems",
                "publication_date_yy_mm": "2023-05"
            }
        },
        {
            "name_short": "Robot Scientist (general)",
            "name_full": "Robot Scientists / AI Scientists / Autonomous Discovery Systems (general category)",
            "brief_description": "A class of closed-loop systems that generate hypotheses, design experiments, execute them with laboratory automation, analyze results, and iterate; exemplified by systems such as Adam, Eve and subsequent third-generation robot scientists.",
            "citation_title": "here",
            "mention_or_use": "mention",
            "system_name": "Robot Scientist (general)",
            "system_description": "Systems that aim to automate all or parts of the scientific method: hypothesis generation (abduction/induction), experimental design (deduction/planning), robotic execution of experiments, automated data analysis, and iteration. Architectures combine knowledge representation, statistical/ML models (e.g., GPR, active learning), planning modules, and physical lab robotics.",
            "discovery_domain": "Multiple domains (biomedicine, chemistry, materials, astronomy, physics) as implemented in domain-specific robot scientists",
            "discovery_description": "As a class, Robot Scientists have produced rediscoveries of known laws, identification of biological functions (Adam: gene–enzyme assignments), and drug repurposing hits (Eve: TNP-470), among other domain-specific findings; they automate the closed-loop cycle and digitally curate the entire process.",
            "discovery_type": null,
            "discovery_type_justification": "The survey frames robot scientists as having potential for transformational impact (see Nobel Turing Grand Challenge) but does not categorize specific reported discoveries uniformly as incremental or transformational; the text distinguishes potential future transformational capability (Nobel-quality discoveries) from the current state (domain-limited discoveries).",
            "evaluation_methods": "The survey proposes multi-faceted evaluation dimensions: supervision (type/strength of ground truth), data modalities, scope (which scientific steps are included: question, hypothesis, design, execution, analysis, communication), and open-endedness. It lists concrete benchmarks/testbeds (Nguyen, Feynman, Matbench, ScienceWorld, DiscoveryWorld, Science-Gym, DiscoveryBench, BoxingGym, etc.) and metrics including symbolic accuracy (for equation discovery), expected information gain (for experimental design), task completion (ScienceWorld), and predictive performance of derived models.",
            "validation_approaches": "Validation methods include: (1) experimental validation (robot-executed assays demonstrating activity or function), (2) comparison to known results (rediscovery tasks), (3) reproducibility tests (robotic repetition of published experiments, e.g., referenced reproducibility studies), (4) benchmark-based evaluation (symbolic benchmarks, simulation environments), and (5) peer-reviewed publication of results. The survey emphasizes that validation depends on which parts of the cycle are automated.",
            "novelty_assessment": "Novelty is assessed by (a) whether derived hypotheses/equations are previously unknown, (b) successful experimental confirmation of novel claims, and (c) the degree of open-endedness of the benchmark (ability to handle previously unexplained phenomena). The survey warns that many demonstrations are rediscoveries intended to validate capability rather than novel paradigm-shifting findings.",
            "impact_metrics": "Impact is measured variably: number of validated novel findings (e.g., Adam's 6 gene assignments), successful drug repositionings, improvements in throughput/efficiency ('cheaper, faster' claims), reproducibility statistics in robot-driven replication studies, symbolic accuracy and complexity trade-offs on benchmarks, and success on interactive discovery environments. The survey itself does not standardize a single numeric impact metric.",
            "comparison_to_human_discoveries": true,
            "comparison_details": "The survey compares robot scientists conceptually to human scientists in autonomy and skill (analogy to driving autonomy levels), discussing the aspiration to reach 'Nobel-quality' discoveries comparable to top human scientists by 2050 (Nobel Turing Grand Challenge). It notes advantages (efficiency, reproducibility, robustness) and the lack of current systems with human-level generality; no direct quantitative head-to-head performance numbers are provided.",
            "success_rate": "No single success rate is reported for the class. Examples include concrete validated outcomes (Adam's 6 gene assignments; Eve's repositioning examples). The survey highlights lack of broad numeric reporting and calls for benchmarked evaluation across supervision, modality, scope, and open-endedness.",
            "challenges_limitations": "Key challenges: (1) automated design of novel experiments (formalizing lab equipment and general experimental compilers), (2) integration with diverse laboratory robotics and logistics, (3) formation of entirely new hypotheses/theories and creation of measurement devices, (4) limited experiment types in existing systems, (5) issues of data provenance and potential prior exposure in foundation-model-based methods, (6) relating discovered equations to existing theory and interpretability, and (7) scaling discovery methods to high-dimensional systems.",
            "has_incremental_transformational_comparison": true,
            "uuid": "e1193.5",
            "source_info": {
                "paper_title": "Automated Scientific Discovery: From Equation Discovery to Autonomous Discovery Systems",
                "publication_date_yy_mm": "2023-05"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "The automation of science.",
            "rating": 2,
            "sanitized_title": "the_automation_of_science"
        },
        {
            "paper_title": "Cheaper faster drug development validated by the repositioning of drugs against neglected tropical diseases.",
            "rating": 2,
            "sanitized_title": "cheaper_faster_drug_development_validated_by_the_repositioning_of_drugs_against_neglected_tropical_diseases"
        },
        {
            "paper_title": "Automated discovery in a chemistry laboratory.",
            "rating": 2,
            "sanitized_title": "automated_discovery_in_a_chemistry_laboratory"
        },
        {
            "paper_title": "Distilling free-form natural laws from experimental data.",
            "rating": 2,
            "sanitized_title": "distilling_freeform_natural_laws_from_experimental_data"
        },
        {
            "paper_title": "Bacon: A production system that discovers empirical laws.",
            "rating": 2,
            "sanitized_title": "bacon_a_production_system_that_discovers_empirical_laws"
        }
    ],
    "cost": 0.0174665,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Automated Scientific Discovery: From Equation Discovery to Autonomous Discovery Systems
26 May 2025</p>
<p>Stefan Kramer 
Computer Science Department
Johannes Gutenberg University Mainz
Saarstrasse 2155116MainzGermany</p>
<p>Mattia Cerrato mcerrato@uni-mainz.de 
Jannis Brugger jannis.brugger@tu-darmstadt.de 
hessian.AI
Karolinenpl. 564289Darmstadt, DarmstadtTUGermany</p>
<p>Sašo Džeroski saso.dzeroski@ijs.si 
Dept. of Knowledge Technologies
Jozef Stefan Institute
Jamova cesta 391000LjubljanaSlovenia</p>
<p>Ross D King 
Data Science and AI
Chalmers University of Technology
Chalmersgatan 441296GöteborgSweden</p>
<p>Department of Chemical Engineering and Biotechnology
University of Cambridge
Philippa Fawcett Drive, Cambridge WestCB3 0ASUnited Kingdom</p>
<p>Automated Scientific Discovery: From Equation Discovery to Autonomous Discovery Systems
26 May 2025AE248F4F879C6B6F93DFF263C3D0037DarXiv:2305.02251v2[cs.AI]
The paper surveys automated scientific discovery, from equation discovery and symbolic regression to autonomous discovery systems and agents.It discusses the individual approaches from a "big picture" perspective and in context, but also discusses open issues and recent topics like the various roles of deep neural networks in this area, aiding in the discovery of human-interpretable knowledge.Further, we will present closed-loop scientific discovery systems, starting with the pioneering work on the Adam system up to current efforts in fields from material science to astronomy.Finally, we will elaborate on autonomy from a machine learning perspective, but also in analogy to the autonomy levels in autonomous driving.The maximal level, level five, is defined to require no human intervention at all in the production of scientific knowledge.Achieving this is one step towards solving the Nobel Turing Grand Challenge to develop AI Scientists: AI systems capable of making Nobel-quality scientific discoveries highly autonomously at a level comparable, and possibly superior, to the best human scientists by 2050.</p>
<p>Introduction</p>
<p>The automated discovery of scientific knowledge has always been on the agenda of artificial intelligence research, and prominently so since the end of the 1970s [1,2].Scientific knowledge takes many forms: In many cases, the scientific process begins with collecting and classifying objects, and creating taxonomies of classes of objects.The more a scientific discipline advances, the more it tends to strive to describe the phenomena quantitatively, for better explanation and prediction.By far the most commonly used representation for describing systems of interest is in the form of mathematical equations, in particular differential equations.Thus, the automated discovery of equations from data has been established as a family of methods within and partly outside artificial intelligence: it runs under the heading of equation discovery [1,3] as well as symbolic regression [4].</p>
<p>The goal in many application domains of equation discovery and symbolic regression is to learn a human-understandable model of the system dynamics in the form of (mostly ordinary) differential equations. 1One important aspect of scientific discovery is that the resulting models need to be in principle interpretable. 2 Thus, the goal is not optimization (e.g., of properties in material science or drug development), but to develop understanding.</p>
<p>An important part of the literature on automated scientific discovery [2,5] discusses the topic from a cognitive science point of view (what are or could be the reasoning processes leading to certain discoveries?) and thus also a historical reconstruction of the processes.This is relevant, because today's AIs for scientific discovery also have to start from the same principles to enable discoveries in completely new application domains.While this can be viewed on the symbolic level only, many of today's approaches also consider the subsymbolic level to aid the process: neural networks of various sorts can play a vital role in guiding the search, providing valuable information to the discovery agent, or turning low-level sensory information into high-level information that can be used for symbolic reasoning.</p>
<p>Finally, the question of autonomy of the discovery agents arises.While early systems assumed a table of input data is given by a human user, approaches with more autonomy on the side of the discovery agent are becoming more common.The approach became prominent with the development of the first robot scientist world-wide, Adam [6], that automated cycles of hypothesis generation and testing in the field of functional genomics.Meanwhile, the third generation of robot scientists is being developed.The degrees of autonomy of a discovery agent may range from completely passive, i.e., supervised learning, via active learning [7] to reinforcement learning [8].</p>
<p>Considering the above, this paper aims to give an overview of automated scientific discovery from a conceptual point of view, spanning the whole field from the generation of scientific knowledge, mainly in the form of equations, to automation and autonony in robot scientists or self-driving labs.It does not just enumerate approaches, but discusses central conceptual aspects and open issues that need to addressed in future systems.Particular attention is paid to the role of neural networks in the process: Fig. 1 Overview of the two realms of automated scientific discovery: (i) the discovery and communication of human-interpretable knowledge in a representation used by scientists in the field, e.g., equations (right-hand side) and (ii) autonomy and automation in science (left-hand slide).Approaches integrating both are currently rare.</p>
<p>either for representation learning, for search in neural-guided equation discovery, or in neural operators, which abandon interpretability altogether.Discussing two main aspects of automated scientific discovery side by side in one paper, (i) the discovery of interpretable scientific knowledge in the form of equation on the one hand and (ii) automation/autonomy on the other (see Figure 1), we identify a major research gap: systems that run autonomously, but are able to communicate results in formalisms used by scientists, so that interventions are possible, such as hints for search, the provision of goals and values, and the embedding of findings in bigger theories.Very few systems exist in this space, however, we would like mention the pioneering work of Jan Zytkow, who coupled real electrochemistry experiments with the FAHRENHEIT system for equation discovery [9], and later proposed a robotic system for the rediscovery of Galileo's equation of objects rolling down an inclined plane, again with the help of FAHRENHEIT, but already taking into account empirical error [10].</p>
<p>The paper is structured as follows: In Section 2, we will review equation discovery and symbolic regression from the beginnings to the current state of the art, with a list of open problems.In Section 3, we discuss the representations used in current scientific discovery and, in particular, how neural networks can be employed to learn representations for the discovery process and how dynamics can be learned directly by neural operators.The topic of Section 4 is closed-loop scientific discovery, with recent progress in the field.Section 5 discusses different levels of autonomy.An overview of benchmarks and testbeds is given in Section 6, before we conclude in Section 7.</p>
<p>The survey paper is different from existing papers in many ways: Makke and Chawla [11] presented a thorough survey of symbolic regression (SR) and equation discovery (ED).Our survey covers both SR/ED and automation/autonomy, so it is broader in scope.Also, it appears more conceptual and with a stronger focus on interesting open issues.Further, in the present paper the discussion of the various uses of neural networks appears both more extensive and deeper.In a recent study, Musslick et al. [12] discuss primarily the limitations of autmated scientific discovery, with a focus on societal and ethical implications (e.g., the value alignment of robot scientists with human scientists).It discusses what should not be done, but also what potentially cannot be done.The latter is, of course, harder to argue, as it involves a forecast of the further progress of the field of artificial intelligence in general.Arguments likes the paradox of automation hold, others concerning the computational complexity of scientific discovery require more investigation.Another recent survey by Gao et al. [13] focuses on life sciences exclusively and discusses everything in terms of agentic AI, which is both not our emphasis here.Two recent papers by Pat Langley [14,15] are both related, but at the same time different.The first of them [14] discusses the so far distinct notions of "agents of exploration" and "agents of discocery".Langley argues for a synthesis of the two, such that agents can both explore and discover in remote areas, like in space or in the deep sea.Although conceptually relevant (imagine a versatile scientific agent that explores a lab environment and discovers new concepts and laws along the way), the main thrust of the paper is clearly different.In the more recent paper [15], Langley describes an integration effort different from the one shown above: In the paper, he envisages a tight integration and coupling of the various phases of scientific discovery, from the discovery of taxonomic knowledge via qualitative models to quantitative and causal models.It is argued that this integration is important, but has not been achieved before.We believe that, while interresting, this is of a different nature than the integration between the discovery of scientific, human-interpretable knowledge, and automation and autonomy in robot scientists or self-driving labs (see Figure 1).</p>
<p>From BACON to Modern Equation Discovery</p>
<p>and Symbolic Regression</p>
<p>History and Current Approaches</p>
<p>The first system for the discovery of equations based on data was BACON by Pat Langley [1], represented in Figure 2. The first version of BACON was developed into a series of following systems, BACON.2 to BACON.5, with increasingly complex functionality [2].The basic philosophy behind the book by Langley et al. was that scientific discovery, even in its most intricate ways, is essentially problem solving.This even applies to the search for new problems, new representations, and new measurement devices.In the case of the BACON systems, the idea was applied to the discovery of equations.BACON.1 to BACON.5 were implemented on the basis of PRISM, a system for the representation and inference of production rules.The BACON systems relied on the observation of the correlation of pairs of variables, when everything else is being held constant (ceteris paribus).This is a strong assumption, as it will in many cases not be possible to control all other variables in an experiment.Also, interestingly, BACON has a flavor of active learning, since users are requested to record data, if they are not available yet.One interesting feature of BACON is the construction of new terms, e.g., ratios or products of existing terms, by production rules.In this way, Fig. 2 (a) BACON [1,2] (b) Example of context-free grammar guiding the search for equations in the Lagramge system [16] (c) A probabilistic context-free grammar as used in ProGED [17] (d) Symbolic regression [18] it takes advantage of the structure of the search space, which is rarely ever attempted in current systems.Noise handling is achieved by some tolerance parameter, which establishes that a value of a variable (constructed or initially given) is constant, even though it varies within a certain range.BACON.2 to BACON.5 included advanced features for symmetries, common divisors, and conservation laws, amongst others.Fig. 1(a) shows the derivation of Kepler's third law D 3 /P 2 = k by a sequence of newly constructed terms, until a -more or less -constant value is found.</p>
<p>The next generation of equation discovery systems was not restricted to keeping all but a pair of variables fixed, but was able to handle observational data.In addition, it was able to learn models of dynamical systems in the form of ordinary differential equations (ODEs).Lagrange [3] computes all derivatives up to a pre-defined order, then generates products of up to a maximum of variables, before it calculates a simple linear regression to generate a candidate equation.More recently, this approach has been taken up in the SINDY system [19], which applies sparse (instead of simple) linear regression.In the meantime, the method has been extended to capture nonlinear dynamics by shallow recurrent decoder networks (SINDy-SHRED) [20].The successor of Lagrange, named Lagramge [16], was a milestone in equation discovery, as it introduced the use of domain knowledge in addition to data: It was the first system to use a context-free grammar (CFG) to guide the search for systems of equations.Grammars are a way for domain experts to use prior knowledge and let that knowledge guide the search for equations.In this way, Lagramge was able to solve problems that the predecessor Lagrange was not able to solve, for instance, the problem of two poles on a cart.An example CFG for Lagramge is shown in Figure 1(b).Lagramge GSAT [21] improves Lagramge by a bundle of modifications: first, it uses a search procedure similar to GSAT (random restart hillclimbing) to randomize search; further, it employs a one-step look-ahead and a momentum to make the search less erratic.Washio &amp; Motoda [22] further improved the methods by also taking into account units and scale types as constraints.Dimensional units are also considered for use in ProGED [17,23], which is based on the idea of using probabilistic CFGs to represent the search space and sample from it.An example is given in Fig. 1(c), where both the rules and the probabilities associated with the rules (p and q) are shown.These probabilities can be fixed, but can also be learned from corpora of equations [24].Sampling candidate equations from probabilistic CFGs enables easy parallelization: batches of sampled equations can be distributed to nodes and evaluated in an embarrassingly parallel way.</p>
<p>Symbolic regression, a development parallel to the development of equation discovery, was originally based on genetic programming (GP): the term was introduced by Koza [4].Typical systems of symbolic regression work on an operator tree or DAG representation of equations (see Fig. 1(d)).These trees are modified by a set of possible operations, such as crossover between subtrees of two trees (equations), mutations, substitutions of variables by constants, or, vice versa, substitutions of constants by variables.Schmidt &amp; Lipson [18] used symbolic regression to discover natural laws from measured data.Symbolic regression approaches were used early on to discover ODEs [25] and used ideas from grammar-based genetic programming to consider domain-specific knowledge, paving the way for systems that use both data and domain knowledge in equation discovery, such as Lagramge, Lagramge2.0[26], IPM [27] and Prob-MoT [28].The last three use process-based formalism to represent models and domain knowledge.</p>
<p>The Bayesian machine scientist [29] establishes the plausibility of models using explicit approximations to the exact marginal posterior over models and establishes its prior expectations about models by learning from a large empirical set of mathematical expressions.The space of equations is explored via Markov Chain Monte Carlo (MCMC), with specific moves for mathematical expression sampling.</p>
<p>PySR [30] is a fast, effective and popular approach to symbolic regression.It is based on genetic programming and outputs one solution per complexity class (from simple to complex equations).PySR is frequently found to be well-performing in practice.It has a Python front-end and delegates numerical computations to Julia.Using Julia "under the hood" and heuristics to avoid redundancy, it is able to explore a large number of candidates in a relatively short period of time, giving it a competitive advantage in many situations.In the meantime, version 1.4 of PySR is available with template expressions and version 1.5 with mini-batching, which further improves practical applicability.</p>
<p>Recent work by Boris Krämer and collaborators [31] has advanced the use of quadratic models for data-driven discovery of dynamical systems governed by partial differential equations (PDEs).In particular, they explore transformations of nonlinear PDEs into quadratic form, which enables the application of structure-preserving reduced-order modeling and symbolic regression techniques.The approach facilitates the use of quadratic latent variable models that retain interpretability and allow for efficient training on noisy and sparse data.The usefulness of the approach has been demonstrated in areas such as fluid dynamics and plasma modeling.</p>
<p>Symbolic regression and equation discovery are currently limited to systems with only few variables.Xue et al. [32] address this problem by identifying control variables, which can be varied to discover the dynamics of a system in "controlled experiments" step by step.The approach is still based on genetic programming.A precondition of its use is evidently the existence of such variables, which is not always the case.In practical applications and real systems, the set of control variables is not equal to the set of variables that should appear in an equation.Thus, that mapping has to be learned first.Nevertheless, the idea of actively using control variables to reduce complexity is valuable and could be a key to making ED/SR practically applicable to large and complex sytems.</p>
<p>In recent years, a new field of research has emerged that focuses on how neural networks can be used in equation discovery.To provide an overview, we divide the works into three categories.The categories are: (i) NN as a supporting module in the equation discovery system (EDS), (ii) NN as the main component of the EDS, and finally, (iii) foundation models as EDS.We discuss the three categories in consecutive order.</p>
<p>AI Feynman 2.0 [33] is a recent symbolic regression approach that aims to improve its predecessor (a) by structuring the search space by building the equation in meaningful increments and (b) making it more noise-tolerant.The first goal is achieved by graph modularity, i.e., constructing the equations by so-called graph modules.It should be noted that, in doing so, it is one of the few approaches that takes advantage of the structure of the search space (instead of just brute-force search, sampling or "blind" randomized traversal).The second goal is achieved by employing an MDLinspired evaluation function instead of the RMSE.This function is called MEDL in Feynman 2.0.Using MEDL, effective pruning can be developed, because the complexity of the equation can be balanced against its error.Lusch et al. [34] apply an auto-encoder structure to find a coordination transformation for a differential equation that maps the nonlinear original problem to linear embedding.Following the idea of an autencoder, Mežnar et al. [35] embed equations in a low-dimensional latent space and use this smooth latent space to suggest new equations based on genetic programming.Mundhenk et al. [36] use a Recurrent Neural Network (RNN) to seed a genetic programming algorithm, and the genetic algorithm results are used to train the RNN.While the previous works use a subsymbolic component to simplify the original problems, the following articles use neural networks as main component.</p>
<p>Deep Symbolic Regression (DSR) [37] addresses the problem of GP approaches with finding solutions for larger problems.It employs a recurrent neural network to build an equation tree step by step.As the objective function (of fitting a low-error equation) is not differentiable, a reinforcement learning approach is proposed.More specifically, DSR employs a risk-seeking policy gradient, which maximizes the best-case performance, not the average-case performance.NeSymReS [38], SymbolicGPT [39], and E2E [40], use a transformer-based architecture to predict the equation on a token level.The main difference is the embedding architecture of the data set.MGMT [41] compares different embedding methods and shows their influence on the prior of the guiding network.Additionally, the work shows that supervised learning is beneficial compared to reinforcement learning for the architectures considered.TPSR [42] and DGSR-MCTS [43], combine a transformer-based architecture with a Monte Carlo Tree Search (MCTS).In the second paper, the network suggests how to mutate the current equation.Another approach is to train a specialized end-to-end differentiable network and parser it after the training with gradient descent to an equation.EQL ÷ [44] or Kolmogorov Arnold networks (KAN) [45] are examples for this approach.</p>
<p>Large language models (LLMs) have also impacted the field of equation discovery.Foundation models such as GPT-4 have the advantage that after the initial learning, they only need to be adapted to the equation discovery domain through fine-tuning or prompt design.In addition, they have been shown to retain background knowledge from the initial training, and the user can add domain knowledge through prompts.In-Context Symbolic Regression ICSR [46], and Sharlin et al. [47] employ a foundation model to produce initial equations.These equations are then tested on the data set.The fitness score and other measures, such as complexity, are calculated externally and then fed back to the model with the task of refining the solutions.LLM-SR [48] follows the same idea but represents equations as programs and uses comments in the program to make the discovered equation better understandable.Meyerson et al. [49] use a foundation model to perform genetic programming (mutation, crossover, etc.) through prompts.The foundation model-based equation discovery systems show promising results, but the extent to which the initial training influences the test results</p>
<p>has not yet been sufficiently investigated, as the standard benchmarks (see below) are included in the initial training.</p>
<p>Open Problems</p>
<p>In equation discovery and symbolic regression, a few open problems can be identified:</p>
<p>• It remains hard to exploit structure in the space of equations to guide the search to promising parts of the search space.Opportunities for pruning would also be helpful.• At least in the case of differential equations, fitting the model is the most expensive part.Ways of stopping the fitting process if it turns out to be unpromising would save a lot of computation time.• Equations are "brittle": properties of differential equations can change dramatically with only little syntactic modifications.Minor changes can lead to no solutions, one solution, or many solutions.• Most approaches struggle with a dimensionality of the problem higher than a very small number of variables.• Overfitting avoidance and regularization: The syntactic complexity of an equation does not necessarily correspond to the complexity of the function in the feature space.Meaningful ways to approximate or bound complexity would be helpful.• For the approaches based on foundation models, it is unclear how the results can generalize to new, previously unseen problems.Data provenance is an issue: It is unclear whether the models have seen some of the equations before in training.Many of the approaches are based on embeddings of datasets.It is, at this point, not clear, what the best way is to embed a dataset for a foundation model for symbolic regression.• Relating discovered equations to existing theory or making the equations consistent with it remains a big challenge.Quite related, it is not clear whether or how "understanding of the physical meaning" of variables can be achieved.</p>
<p>3 Representation Learning in Scientific Discovery</p>
<p>Representation Learning of the Input</p>
<p>The standard representation of data for scientific discovery is tabular data (see, e.g., also the tables in the book by Langley et al. [2] and Figure 1(a)).However, recent years have seen a surge of papers that use neural networks as an intermediate representation to aid in the discovery of models.</p>
<p>One notable example is the work of Miles Cranmer and Shirley Ho [50], who proposed Graph Neural Networks (GNNs) as an intermediate representation.GNNs were used to learn about the interaction of objects, in terms of, for example, forces that act upon each other.Classical examples include n-body problems or, more specifically, orbital mechanics-the motion of planets and other larger objects in our solar system.The nodes in the graph represent the objects, which are annotated by feature vectors representing the properties of the objects.The edges in the graph represent the interactions between the objects and are annotated by properties that partially depend on those of the objects.For example, one may consider the masses of planets as properties of the nodes, and the distance and gravitational force between the objects as properties of the edges.When learning GNNs, typically, so-called node models ϕ v are updated depending on the edge models ϕ e of neighboring edges and, alternatingly, the edge models ϕ e are updated based on the node models ϕ n of the nodes that the edges connect.Update steps are frequently framed as message passing, and pooling functions aggregate input from multiple edges connected to one node.GNNs usually can be trained end-to-end, but are not guaranteed to converge.</p>
<p>In the application domain that was given as an example, orbital mechanics, the input to the system are (x, y, z) coordinates of the Sun, all planets, and all moons with a mass above 10 18 kg.Data from 1980 to 2013 were used with time intervals of 30 minutes each, with the first 30 years for training and the last 3 years for validation.</p>
<p>Garcon et al. [51] proposed a method to predict known physical parameters and discover new ones from oscillating time series (Figure 4).The method is trained on a large set of synthetic time series.The latent parameters used to generate the monochromatic sine waves are the carrier frequency, F c , and phase ϕ (which is mapped for technical reasons to two separate parameters, sin(ϕ) and cos(ϕ)), in addition to the coherence time τ .The AM and FM sine waves are generated by adding a modulation function to the carrier.The modulation function's latent parameters are the modulation frequency F m and amplitude I m .Noise is linearly added to the pure signals by sampling the Gaussian distribution.AM/FM signals with minimum I m reduce to decaying monochromatic sine waves and reach 100% modulation with maximum I m .These latent parameter ranges are wide enough such that they would encompass many foreseeable real-world signals.Figure 3 shows the neural network architecture used to predict the latent parameters, with an autoencoder-type subnetwork to support the prediction.The method can be used to discover new parameters (not just predict known ones) and reconstruct equations producing input time series.</p>
<p>The situation is clearly more complex when the observations are given as videos instead of tabular data.Chen et al. [52]   current state-of-the-approach to computing latent variables is to define an autoencoder with a bottleneck layer of the right dimension.The dimension should be large enough to allow faithful reconstruction by the decoder, but small enough so that the latent variables are non-redundant.The goal of the proposed method is to have the number of dimensions (i.e., the number of neural state variables) as close as possible to the degrees of freedom of the observations in the videos.In technical terms, the number of dimensions should be close to the so-called intrinsic dimension (ID), which is the minimum number of independent variables needed to fully describe the state of a dynamical system.Various methods from manifold learning, for instance the one by Levina and Bickel [53], are known to efficiently calculate an estimate of the intrinsic dimension.It would be tempting to calculate the intrinsic dimension for the videos and then use it as the bottleneck size of an autoencoder to come up with the latent variables.However, practically, information becomes blurry at much larger bottleneck sizes than the ID already.Therefore, Chen et al. take a two-step approach and define two autoencoders, one regular and one that maps the latent variables of the first to further ID latent variables.These are the neural state variables that can be used for downstream analysis.The approach has not yet been made explainable for scientific discovery.</p>
<p>Fig. 4 Neural network architecture of model that extracts known and unknown physical parameters from oscillating time series [51].</p>
<p>Generally speaking, neural networks are used in this domain for • making the data sparse in the sense of removing small to negligible interactions [50],</p>
<p>• a change of representation (e.g., from coordinates to distances depending on some variables [50]), • data augmentation (to sample arbitrarily large data from the neural network and also smooth the data in that way [5,50]), • the prediction of important parameters to be used in equations directly [51], and • extracting latent variables from low-level input representations (e.g., neural state variables from videos [52]).</p>
<p>Representation Learning of the Dynamics and Beyond</p>
<p>Neural operators [54] can learn to map the current state of a system to the next state.This can be done for systems that evolve over space or time and especially for systems for which partial differential equations (PDEs) are too difficult to solve.Neural operators are, however, not restricted to mapping from one state to the next over time: They can learn general functional mappings between various types of inputs and outputs, e.g., inititial conditions to solutions or, even more generally, function-tofunction mappings (like DeepONet [55] or Fourier Neural Operators [56]).The latter learn mappings between functions, not just states over time, for instance, they can map a boundary condition (a function) to a solution (another function), which might involve non-temporal variables.Advantages are, amongst others, speed and flexibility (they are not hard to apply from one problem to the next).Neural operators like DeepONet or Fourier Neural Operators are, like other neural networks, black-box models.</p>
<p>Open Problems</p>
<p>Several open problems remain for representation learning of the inputs or learning functional mappings using neural networks:</p>
<p>• It is currently not well-investigated how learned representations can be aligned with representations that are interpretable by humans.• While neural operators can find accurate approximations to the solution of a PDE, understanding how they arrived at that solution is not straightforward.Visualizations, sensitivity analyses, and methods from explainable AI can alleviate some of the problems.</p>
<p>4 Closed-loop Scientific Discovery</p>
<p>Main Concepts, History and Advantages</p>
<p>The cutting edge of applying AI to science are "AI Scientists" (aka "Robot Scientists", "Self-driving Labs", "Autonomous Discovery systems", "Machine Scientists", etc.).These AI systems area capable of the closed-loop automation of scientific research.AI Scientists were named in 2025 by Nature as the "number one technology to watch" [57].AI Scientists automatically originate hypotheses to explain observations (abduction/induction), devise experiments to test these hypotheses (deduction), physically run the experiments using laboratory robotics, analyze and interpret the results to change the probability of hypotheses, and then repeat the cycle.In other words, they aim to automate all or parts of the scientific method, as shown (simplistically) in Figure 5.As the experiments are conceived and executed automatically by computer, it is possible to completely capture and digitally curate all aspects of the scientific process, making science more reproducible [6].</p>
<p>The first contribution describing a largely autonomous system which discovered new knowledge was due to Ross D. King and his group [6], who developed the Adam robot scientist (see Figure 6).Adam identified 6 genes encoding orphan enzymes in yeast (Saccharomyces cerevisiae), i.e., enzymes which catalyze reactions occurring in  yeast for which the encoding genes were not known at the time.The system was provided with a freezer, liquid handlers, plate readers, robot arms, and further actuators, enabling yeast cultivation experiments lasting as long as 5 days.Yeast growth was measured via optical sensors.On the software side, Adam was provided with an extensive Prolog knowledge base describing known facts about yeast metabolism.Hypotheses were formed by abduction, enabled by a combination of bioinformatic software and databases, after which an experiment planning module was responsible for selecting metabolites to be inserted in the yeast's growth medium.</p>
<p>Another successful example of laboratory automation is Eve.Originally developed for high-throughput drug screening [58], the system was then instrumental in discovering that several existing drugs could be repurposed to prevent tropical diseases [59].Most prominently, it found that an anti-cancer compound (TNP-470) could be employed against the parasite Plasmodium vivax, whose bite is the most frequent cause of recurring malaria.The system is able to hypothesize and test quantitative structure-activity relationships (QSARs) via a combination of active learning and Gaussian process regression (GPR).GPR is employed to learn a QSAR f mapping the characteristics of compounds to a response variable indicating the strength of the biological activity; then, the obtained function f is employed as a noisy oracle to select K compounds out of a pool of possible candidates.Exploration and exploitation is balanced.This two-step process may be repeated until enough candidates are obtained.In the meantime, the third generation of robot scientists is being developed.</p>
<p>AI Scientists have a number of relevant advantages, besides being able to discover new knowledge in a way that may be less biased than a human scientist:</p>
<p>• Efficiency: AI Scientists are increasing the productivity of science.They can work cheaper, faster, more accurately, and longer than humans [60].They can also be easily multiplied.• Reproducibility: Biomedical science is facing a "reproducibility crisis".AI Scientists have the potential to ameliorate this problem, as they describe experiments in far greater detail and semantic clarity than human scientists, and robots execute experimental protocols more accurately than human scientists [61].• Robustness: The Covid-19 pandemic clearly demonstrated the vital importance of biomedical research and the critical need to maintain research continuity [62].AI Scientists are increasingly being applied to multiple scientific domains (ranging from quantum mechanics to astronomy, from chemistry to medicine), see Table 1.</p>
<p>Open Problems</p>
<p>Three of the current main limitations of AI Scientists are (i) the design of novel experiments, (ii) integration with laboratory robotics, and (iii) the formation of completely new hypotheses and theories.The central task that faces every experimental scientist is the design of novel experiments to test a hypothesis.The abstract problem is given (1) a hypothesis, and (2) a set of laboratory equipment, output (3) a protocol to test the hypothesis using the equipment.Relatively little AI research has focussed on this aspect of automating science.N.B. that this task is different in kind from the task of traditional "experimental design", it also different from deciding, from a set of given experiments, the most efficient (in terms of time/money) to test a set of hypotheses.In all the existing AI Scientists systems that we are aware off the type of experiment that can be executed are limited to a small stereotypical set.For the design of novel experiments to be possible it will be necessary to formalise general scientific knowledge, as well as knowledge about the functionality of laboratory equipment, and experimental protocols.It is also necessary to develop inference and planning engines to generate the new experiments, as well as to develop compilers to translate generated experiments into executable protocols on specific laboratory automation.</p>
<p>Historically, laboratory automation has been driven by the desire to run large numbers of related laboratory experiments, especially in the pharmaceutical and clinical analysis industries.It is now a thriving multibillion dollar industry [63].The first use of AI to control laboratory equipment was probably that of Zytkow et al. [9] (see above).The technology of laboratory automation is steadily advancing, and robots can now carry out most (but not all) of the tasks that humans can do in the laboratory.Such laboratory automation is increasing the productivity of science as robots can work cheaper, faster, more accurately, and for longer (24/7) than humans, they can also be more easily increased/reduced in number.Laboratory automation still has many limitations.Robots typically today operate in protective boxes and are hard to program by bench scientists; logistics tasks are generally performed by lab technicians and scientists, with humans tending the robots for consumables; laboratory automation is expensive in capital to build and maintain -requiring specialised staff.Research in laboratory automation has been largely divorced from AI robotics research -which has mainly focused on the problem of mobile robots.Almost all laboratory robots are fixed in place, although there is growing interest in mobile robot assistants [62].</p>
<p>Hypothesis formation needs to be supported by a variety of AI and ML methods, from knowledge representation to active learning and reinforcement learning.The creation of a whole new theory, with theoretical terms and new measurement devices, is at least one level of complexity harder and has not been addressed yet at all.</p>
<p>Autonomy</p>
<p>One key aspect of AI Scientists is their degree of autonomy.One approach to measuring autonomy is to use the classification of degrees of autonomy in self-driving cars as [63].The approach taken here is similar, Table 2 describes five levels of autonomy.Beyond levels of autonomy are levels of skill.All human drivers are autonomous, but very few are skillful enough drivers to win a Formula 1 race.Among human scientists there are also levels of skill, with few human scientists being skillful enough to win Nobel prize.AI scientists are improving in autonomy and skill.Extrapolating this trend it is likely that advances in technology and our understanding of science will drive the development of ever-smarter AI Scientists.The Physics Nobel Frank Wilczek said that "in 100 years' time the best physicist will be a machine" [64].In Closed-loop automation.The full cycle of discovery is automated in a restricted domain.</p>
<p>See Table 1.</p>
<p>High Automation</p>
<p>Closed-loop automation.Multiple scientific domains.Limited ability to set its own goals.</p>
<p>No existing system.</p>
<p>Full Automation</p>
<p>All aspects of science are automated and no human intervention is required.</p>
<p>No existing system.</p>
<p>February 2020 a workshop was held in London to kick-off the Nobel Turing Grand Challenge to develop: AI systems capable of making Nobel-quality scientific discoveries highly autonomously at a level comparable, and possibly superior, to the best human scientists by 2050 [65].If the Nobel Turing Grand Challenge is achieved this would clearly transform the World, it would be possible to have instead of a few Nobel prize winning ideas a year, hundreds, thousands, millions, ...</p>
<p>Evaluation and Testbeds</p>
<p>The evaluation of an autonomous discovery system is intrinsically tied to the levels of autonomy displayed by the methodology at hand and which steps of the scientific process are to be automatized and the level of autonomy being evaluated (Figure 5 and Table 2).Equation discovery methods may help in automating the analysis of experiments by providing human-readable knowledge, while systems with physical actuators may be evaluated in their ability to execute experimental protocols.Thus, evaluation methodologies and benchmarks in the area have different characteristics in terms of supervision, data modalities, scope and open-endedness.We define these properties in the following, and give a table of existing methods for evaluation in Table 3. Supervision.Supervision refers to the nature of the ground truth or reward signals provided to the autonomous discovery system during training and evaluation.Depending on the degree of autonomy assessed, supervision may range from explicit labels or predefined objectives to feedback signals (rewards in the Reinforcement Learning sense [8]).The type and quantity of supervision significantly affect the evaluation outcome, as they directly influence the system's capability to navigate scientific exploration autonomously.</p>
<p>Data Modalities.Data modalities encompass the types and formats of data available for evaluation, such as pixel-based images, textual descriptions, numerical tables, or structured representations of experimental observations.The choice of modality greatly impacts the complexity and applicability of autonomous systems, as certain data forms inherently require more sophisticated methods for interpretation, abstraction, and knowledge extraction (see Section 3).Evaluating systems across diverse data modalities helps in understanding their flexibility, generalizability, and robustness in real-world scientific scenarios.</p>
<p>Scope.Scope defines which specific phases of the scientific discovery process the evaluation benchmark addresses.This includes one or more of the six distinct steps: scientific question formulation, hypothesis generation, experimental design, execution of experiments, data analysis and communication.</p>
<p>Open-endedness.Open-endedness characterizes whether the benchmark or evaluation method includes previously unexplained data, phenomena lacking known mathematical descriptions, or allows the formulation of novel scientific questions.An open-ended benchmark challenges autonomous discovery systems to demonstrate genuine exploratory capabilities, creativity, and adaptability, rather than merely replicating existing knowledge.</p>
<p>We now move to introducing benchmark and testbeds while discussing their potential in the autonomous discovery setting.We will not offer here an exhaustive survey of symbolic regression benchmarks.</p>
<p>Available Benchmarks</p>
<p>Nguyen Benchmark Suite [66] is a widely-used collection of symbolic regression problems introduced specifically to evaluate genetic programming (GP) methods.It consists of synthetic mathematical equations designed with varying complexity and structure, aiming to assess the ability of GP algorithms to accurately recover symbolic expressions from numerical data.Each task provides numerical input-output pairs generated from known symbolic formulas.The benchmark primarily evaluates one-shot analysis of already collected experimental data.</p>
<p>Feynman [67] provides a comprehensive symbolic regression benchmark inspired by fundamental physics equations from the Feynman Lectures on Physics.This dataset includes 120 symbolic regression tasks covering a diverse range of physics phenomena, from classical mechanics to electromagnetism.</p>
<p>Matbench [68] is a supervised machine-learning benchmark containing 13 prediction tasks related to materials science.The dataset consists of structured data representing chemical formulas and crystalline structures, with tasks that involve predicting material properties such as band gap or elastic moduli.It is particularly suited for evaluating analysis capabilities and hypothesis generation for material properties from compositional and structural data.While each task is narrowly defined with a fixed prediction goal, collectively, they support evaluating broad generalizability across material science domains.</p>
<p>SCP-116K [69] is a large-scale textual dataset comprising problem-solution pairs extracted from higher education science textbooks and other academic sources, totaling 116,000 entries.It is designed primarily for supervised training and evaluation of models on scientific reasoning, question answering, and hypothesis generation from textual data.While each problem-solution pair is relatively constrained in scope, the dataset's scale and diversity across scientific disciplines provides opportunities for broader generalization and transfer learning evaluation.</p>
<p>The Well [70] is a comprehensive collection of physics simulation datasets, explicitly constructed for machine learning model training and benchmarking in physics-informed learning.It contains diverse simulation data spanning fluid dynamics, astrophysics, plasma physics, and more.These simulations allow evaluation of models' abilities in hypothesis generation, scientific analysis, and predictive modeling in physics.Its broad diversity and complexity may be employed in open-ended exploration of scientific hypotheses through computational experimentation.</p>
<p>ScienceWorld [71] is a publicly available reinforcement learning environment designed to evaluate an AI agent's capacity for grounded scientific reasoning in a simulated laboratory context.The benchmark contains 30 interactive text-based tasks, such as converting substances between states of matter.Evaluation relies on binary task completion within limited simulator steps, making it suitable for assessing agents' (abstract, text-based) experimental execution capabilities in a weakly supervised, text-based modality.</p>
<p>DiscoveryWorld [72] is an open-source, highly interactive environment designed to benchmark complete cycles of scientific discovery, including hypothesis generation, experimental design, execution, and analysis.The general setting is akin to a 2D roleplaying game to be played on a grid.It provides agents with quests, subquests and various tasks to be completed to make progress.</p>
<p>ChemGymRL [73] provides a suite of customizable, publicly accessible reinforcement learning environments simulating chemistry laboratory experiments.Each virtual "bench" simulates distinct chemical procedures such as synthesis or titration.Agents receive structured numeric data representing chemical states and perform sequential lab actions.The library emphasizes experimental design and execution with reward signals, but allows for extension to e.g.new chemical reactions.</p>
<p>DiscoveryBench [74] is a publicly accessible benchmark focusing on data-driven scientific discovery tasks using multimodal data (tabular data and textual descriptions).It comprises over a thousand real-world and synthetic tasks spanning various scientific domains.Evaluation of agent-generated hypotheses is performed using LLMbased facet analysis, which allows for some open-endedness in the tasks considered.DiscoveryBench primarily targets hypothesis generation and data analysis.</p>
<p>BoxingGym [75] provides publicly available, interactive simulation environments for benchmarking autonomous experimental design and scientific model discovery.The benchmark covers multiple scientific domains through generative probabilistic models.Evaluation metrics include expected information gain for experimental quality and predictive power of agent-generated scientific models.The environment is numeric and textual in data modalities and promotes open-ended exploration.</p>
<p>Science-Gym [76] is a publicly released Gym-compatible benchmark designed to evaluate autonomous equation discovery in simulated physical and epidemiological environments.Agents interactively select experimental parameters to generate data, subsequently performing symbolic regression to derive underlying scientific equations.Evaluation assesses the symbolic accuracy of discovered equations, providing a structured yet open-ended setting emphasizing experimental execution and analytical reasoning.Open Catalyst 2020 (OC20) [77] provides a large-scale benchmark for catalysis research, encompassing over a million atomic structure relaxations generated via density functional theory (DFT) calculations.It offers structured atomic 3D data for supervised machine learning tasks aimed at predicting energies and molecular interactions relevant to catalytic processes.OC20 primarily evaluates data-driven analysis and indirectly supports hypothesis-driven experimental design, particularly aiding in computational screening of catalytic materials.While individually each task has a fixed objective, its expansive dataset encourages robust and generalizable modeling approaches.</p>
<p>Conclusion</p>
<p>This paper is an attempt at giving a survey of research on automated scientific discovery, from discovering equations to autonomous discovery systems or agents.In doing so, it takes a broad perspective on the topic, which is necessary to understand the individual efforts in context.The article covers the beginnings of the fields to very recent approaches, understanding that we still have a long way of putting everything together to create human-level autonomous scientists.Human-level autonomous scientists should, ultimately, be able to produce whole new theories, along with theoretical terms and measurement devices, which can be communicated to humans and interpreted in the light of other, existing theories.At this point, autonomous discovery systems are focused primarily on "closing the loop" and lab automation, and not so much on generating human-interpretable knowledge, like (differential) equations.Vice versa, computational approaches to scientific discovery, e.g., for equation discovery and symbolic regression, do not have the "embodiment" in autonomous systems in their focus yet.Ultimately, these currently disparate efforts have to grow together.Finally, it should be noted that artificial intelligence has a role also in so far unexplored areas, like the design of experiments, where much of human ingenuity is currently still needed.</p>
<p>Fig. 3
3
Fig. 3 Workflow of Cranmer et al. [50]: GNNs as an intermediate representation to support or enable the learning process</p>
<p>Fig. 5
5
Fig. 5 Six steps of the scientific process.</p>
<p>Fig. 6
6
Fig.6The robot scientist Adam.</p>
<p>Table 3
3
Benchmark Categorization by Evaluation Properties.In the Scope column, we take D = experimental Design, E = Experimental Execution, H = Hypothesis formation, A = Analysis of results, Q = research Question formation.</p>
<p>presented a solution based on what they call neural state variables.Neural state variables are essentially latent variables.The</p>
<p>Table 1
1
Robot Scientists by Discipline, Name, and Country
DisciplineNameCountryDrug DiscoveryEveSwedenDrug DiscoveryRecursionUSDrug DiscoveryLilly Life Sciences Studio labUSDrug DiscoveryXtaIPiChinaChemistryUK Centre for Rapid Online Analysis of ReactionsUKChemistryroboRXN at IBMSwitzerlandChemistryphactor™USChemistryPharmacy on Demand (PoD)USChemistryMolecule Maker InstituteUSChemistryAI-ChemistChinaChemistryA self-optimizing reactorUSChemistryChemputerUKChemistryLapkin GroupUKChemistryRoboChemNetherlandsMaterialsKebotixUSMaterialsAutonomous Research System (ARES)USMaterialsRobot ChemistUKMaterialsAcceleration ConsortiumCanadaMaterialsBrookhavenUSMaterialsSARAUSMaterialsAI-ChemistChinaMaterialsA-LabUSMaterialsMatterhornUKMaterialsARC -Exciton ScienceAustraliaMaterialsGormleyUSCatalysisRealCatFranceCatalysisSwissCAT+SwitzerlandMetallurgyACCMETEUMaterialsBIG-MAPEUCell BiologyLabdroidsJapanCell BiologyMurphy LabUSMechanical Eng.Creative Machines LabUSProtein DesignMolcureJapanProtein DesignLabGeniusUKSystems BiologyGenesisSwedenMaterials/BiologyArgonne Autonomous DiscoveryUSQuantum PhysicsMELVINGermanyMedicineAutomation ScienceSingapore</p>
<p>Table 2
2
Six levels of autonomy in scientific discovery analogously to autonomy levels in autonomous driving
LevelSummaryNarrativeExample0No automationTraditional human science before the-advent of computers.1MachineThe use of computers to automate anMost current applica-assistanceaspect of science, e.g. analysing data.tions of ML.2PartialAn important aspect of the discovery cycleAlphaFold 2, Real-timeAutomationis fully automated.weather forecasting3ConditionalAutomation
The underlying data are most frequently temporal.
If a model cannot be communicated to a community of researchers, it hardly qualifies as scientific, as communication is an indispensable part of the scientific endeavor.</p>
<p>Bacon: A production system that discovers empirical laws. P Langley, Proceedings of the 5th International Joint Conference on Artificial Intelligence (IJCAI 1977). the 5th International Joint Conference on Artificial Intelligence (IJCAI 1977)1977344</p>
<p>Scientific Discovery: Computational Explorations of the Creative Process. P W Langley, H A Simon, G Bradshaw, J M Zytkow, 1987MIT PressCambridge, MA, USA</p>
<p>Discovering dynamics. S Džeroski, L Todorovski, Proceedings of the Tenth International Conference on Machine Learning. the Tenth International Conference on Machine LearningAmherst, MA, USAMorgan Kaufmann1993</p>
<p>Genetic programming as a means for programming computers by natural selection. J R Koza, Statistics and Computing. 41994</p>
<p>Z Li, J Ji, Y Zhang, 10.48550/arXiv.2111.12210arXiv:2111.12210From kepler to newton: Explainable ai for science. 2021arXiv preprint</p>
<p>The automation of science. R D King, J Rowland, S G Oliver, M Young, W Aubrey, E Byrne, M Liakata, M Markham, P Pir, L N Soldatova, A Sparkes, K E Whelan, A Clare, Science. 32459232009</p>
<p>Active learning with statistical models. D A Cohn, Z Ghahramani, M I Jordan, Journal of Artificial Intelligence Research. 41996</p>
<p>Reinforcement Learning: An Introduction. R Sutton, A Barto, 2018MIT PressCambridge, MA, USA</p>
<p>Automated discovery in a chemistry laboratory. J M Zytkow, J Zhu, A Hussam, Proceedings of the 8th National Conference on Artificial Intelligence (AAAI 1990). the 8th National Conference on Artificial Intelligence (AAAI 1990)Boston, MA, USAAAAI Press / MIT Press1990</p>
<p>Discovering empirical equations from robotcollected data. K.-M Huang, J M Zytkow, Proceedings of the 10th International Symposium on Foundations of Intelligent Systems (ISMIS 1997). the 10th International Symposium on Foundations of Intelligent Systems (ISMIS 1997)Charlotte, North Carolina, USASpringer1997</p>
<p>Interpretable scientific discovery with symbolic regression: a reviews. N Makke, S Chawla, Artificial Intelligence Review. 5722024</p>
<p>. S Musslick, L K Bartlett, S H Chandramouli, M Dubova, F Gobet, T L Griffiths, J Hullman, R D King, J N Kutz, C G Lucas, S Mahesh, </p>
<p>Automating the practice of science: Opportunities, challenges, and implications. F Pestilli, S J Sloman, W R Holmes, PNAS. 12252025</p>
<p>Empowering biomedical discovery with ai agents. S Gao, A Fang, Y Huang, V Giunchiglia, A Noori, J R Schwarz, Y Ektefaie, J Kondic, M Zitnik, Cell. 187222024</p>
<p>Agents of exploration and discovery. P Langley, AI Magazine. 4242022</p>
<p>Integrated systems for computational scientific discovery. P Langley, Proceedings of the Thirty-Eighth AAAI Conference on Artificial Intelligence (AAAI-24). the Thirty-Eighth AAAI Conference on Artificial Intelligence (AAAI-24)Vancouver, CanadaAAAI Press2024</p>
<p>Declarative bias in equation discovery. L Todorovski, S Džeroski, Proceedings of the Fourteenth International Conference on Machine Learning. the Fourteenth International Conference on Machine LearningSan Francisco, CAMorgan Kaufmann1997</p>
<p>Probabilistic grammars for equation discovery. J Brence, L Todorovski, S Džeroski, Knowledge Based Systems. 2241070772021</p>
<p>Distilling free-form natural laws from experimental data. M Schmidt, H Lipson, Science. 32459232009</p>
<p>Discovering governing equations from data by sparse identification of nonlinear dynamical systems. S L Brunton, J L Proctor, J N Kutz, PNAS. 1132016</p>
<p>Sparse identification of nonlinear dynamics and Koopman operators with Shallow Recurrent Decoder Networks. M L Gao, J P Williams, J N Kutz, 2025</p>
<p>Equation discovery for model identification in respiratory mechanics of the mechanically ventilated human lung. S Ganzert, J Guttmann, D Steinmann, S Kramer, Proceedings of the 13th International Conference on Discovery Science (DS 2010). the 13th International Conference on Discovery Science (DS 2010)Berlin; HeidelbergSpringer2010</p>
<p>Discovering admissible models of complex systems based on scale-types and identity constraints. T Washio, H Motoda, Proceedings of the Fifteenth International Joint Conference on Artificial Intelligence (IJCAI 1997). the Fifteenth International Joint Conference on Artificial Intelligence (IJCAI 1997)1997</p>
<p>Dimensionally consistent equation discovery through probabilistic attribute grammars. J Brence, L Todorovski, S Džeroski, Information Sciences. 2023</p>
<p>Learning the probabilities in probabilistic context-free grammars for arithmetical expressions from equation corpora. M Chaushevska, L Todorovski, J Brence, S Džeroski, Proceedings of the Slovenian Conference on Artificial Intelligence. the Slovenian Conference on Artificial Intelligence2022</p>
<p>Discovering dynamics with genetic programming. S Džeroski, I Petrovski, Proceedings of the Seventh European Conference on Machine Learning. the Seventh European Conference on Machine LearningBerlin; HeidelbergSpringer1994</p>
<p>Integrating knowledge-driven and data-driven approaches to modeling. L Todorovski, S Džeroski, Ecological Modelling. 1942006</p>
<p>Inductive process modeling. W Bridewell, P Langley, L Todorovski, S Džeroski, Machine Learning. 712008</p>
<p>The influence of parameter fitting methods on model structure selection in automated modeling of aquatic ecosystems. D Čerepnalkoski, K Taškova, L Todorovski, N Atanasova, S Džeroski, Ecological Modelling. 452012</p>
<p>A bayesian machine scientist to aid in the solution of challenging scientific problems. R Guimerà, I Reichardt, A Aguilar-Mogas, F A Massucci, M Miranda, J Pallarès, M Sales-Pardo, Science Advances. 669712020</p>
<p>Interpretable machine learning for science with pysr and symbolicregression. M D Cranmer, abs/2305.01582 (2023) 2305.01582</p>
<p>Exact and optimal quadratization of nonlinear finite-dimensional non-autonomous dynamical systems. A Bychkov, I Issan, G Pogudin, B Krämer, SIAM Journal on Applied Dynamical Systems. 2312024</p>
<p>Symbolic regression via control variable genetic programming. N Jiang, Y Xue, Proc. of the European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases (ECML PKDD 2023). of the European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases (ECML PKDD 2023)</p>
<p>. Springer, 2023Berlin, Heidelberg</p>
<p>Ai feynman 2.0: Pareto-optimal symbolic regression exploiting graph modularity. S.-M Udrescu, A Tan, J Feng, O Neto, T Wu, M Tegmark, Advances in Neural Information Processing Systems. 332020</p>
<p>Deep learning for universal linear embeddings of nonlinear dynamics. B Lusch, J N Kutz, S L Brunton, Nature communications. 9149502018</p>
<p>Efficient generator of mathematical expressions for symbolic regression. S Mežnar, S Džeroski, L Todorovski, Machine Learning. 112112023</p>
<p>Symbolic regression via neural-guided genetic programming population seeding. T N Mundhenk, M Landajuela, R Glatt, C P Santiago, D M Faissol, B K Petersen, arXiv:2111.000532021arXiv preprint</p>
<p>Deep symbolic regression: Recovering mathematical expressions from data via risk-seeking policy gradients. B K Petersen, M L Larma, T N Mundhenk, C P Santiago, S K Kim, J T Kim, Proceedings of the 9th International Conference on Learning Representations. the 9th International Conference on Learning Representations2021ICLR 2021</p>
<p>Neural symbolic regression that scales. L Biggio, T Bendinelli, A Neitz, A Lucchi, G Parascandolo, Proceedings of the 38th International Conference on Machine Learning, ICML 2021. M Meila, T Zhang, the 38th International Conference on Machine Learning, ICML 2021PMLR, Virtual event18-24 July 2021. 2021139Virtual Event. Proceedings of Machine Learning Research</p>
<p>M Valipour, B You, M Panju, A Ghodsi, 10.48550/arXiv.2106.14131arXiv.arXiv:2106.14131[cs]version:1SymbolicGPT: A Generative Transformer Model for Symbolic Regression. 2021</p>
<p>End-to-end symbolic regression with transformers. P Kamienny, S Ascoli, G Lample, F Charton, S Koyejo, S Mohamed, A Agarwal, D Belgrave, K Cho, Advances in Neural Information Processing Systems 35: Annual Conference on Neural Information Processing Systems. A Oh, NeurIPS; New Orleans, LA, USA2022. 2022. November 28 -December 9, 2022. 2022</p>
<p>Neural-Guided Equation Discovery. J Brugger, M Cerrato, D Richter, C Derstroff, D Maninger, M Mezini, S Kramer, 2025</p>
<p>Transformer-based Planning for Symbolic Regression. P Shojaee, K Meidani, A B Farimani, C K Reddy, 10.48550/ARXIV.2303.068332023-08-09Publisher: arXiv Version Number: 4. 2023</p>
<p>Deep generative symbolic regression with monte-carlo-tree-search. P Kamienny, G Lample, S Lamprier, M Virgolin, International Conference on Machine Learning, ICML 2023. A Krause, E Brunskill, K Cho, B Engelhardt, S Sabato, J Scarlett, Honolulu, Hawaii, USAPMLRJuly 2023. 2023202Proceedings of Machine Learning Research</p>
<p>Learning Equations for Extrapolation and Control. S Sahoo, C Lampert, G Martius, Proceedings of the 35th International Conference on Machine Learning. the 35th International Conference on Machine LearningStockholm, SwedenPMLR2018</p>
<p>. Z Liu, Y Wang, S Vaidya, F Ruehle, J Halverson, M Soljačić, T Y Hou, M Tegmark, arXiv:2404.197562024Kan: Kolmogorov-arnold networksarXiv preprint</p>
<p>In-Context Symbolic Regression: Leveraging Large Language Models for Function Discovery. M Merler, K Haitsiukevich, N Dainese, P Marttinen, 10.18653/v1/2024.acl-srw.49Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics. the 62nd Annual Meeting of the Association for Computational LinguisticsBangkok, Thailand20244Student Research Workshop)</p>
<p>In Context Learning and Reasoning for Symbolic Regression with Large Language Models. S Sharlin, T R Josephson, 10.48550/ARXIV.2410.17448arXiv. Version Number: 22024</p>
<p>LLM-SR: Scientific Equation Discovery via Programming with Large Language Models. P Shojaee, K Meidani, S Gupta, A B Farimani, C K Reddy, 10.48550/ARXIV.2404.18400arXiv. Version Number: 22024</p>
<p>E Meyerson, M J Nelson, H Bradley, A Gaier, A Moradi, A K Hoover, J Lehman, 10.48550/ARXIV.2302.12170Language Model Crossover: Variation through Few-Shot Prompting. arXiv. Version Number. 20233</p>
<p>Discovering symbolic models from deep learning with inductive biases. M D Cranmer, A Sanchez-Gonzalez, P W Battaglia, R Xu, K Cranmer, D N Spergel, S Ho, Advances in Neural Information Processing Systems. 332020</p>
<p>Deep neural networks to recover unknown physical parameters from oscillating time series. A Garcon, J Vexler, D Budker, S Kramer, PLoS ONE. 1752684392022</p>
<p>Automated discovery of fundamental variables hidden in experimental data. B Chen, K Huang, S Raghupathi, I Chandratreya, Q Du, H Lipson, Nature Computational Science. 22022</p>
<p>Maximum likelihood estimation of intrinsic dimension. E Levina, P J Bickel, Advances in Neural Information Processing Systems. 200417</p>
<p>Neural operator: Learning maps between function spaces with applications to pdes. N Kovachki, Z Li, B Liu, K Azizzadenesheli, K Bhattacharya, A M Stuart, A Anandkumar, Journal of Machine Learning Research. 242023</p>
<p>Learning nonlinear operators via deeponet based on the universal approximation theorem of operators. L Lu, P Jin, G Pang, Z Zhang, G E Karniadakis, Nature Machine Intelligence. 332021</p>
<p>Fourier neural operator for parametric partial differential equations. Z Li, N B Kovachki, K Azizzadenesheli, B Liu, K Bhattacharya, A M Stuart, A Anandkumar, Proceedings of the 9th International Conference on Learning Representations. the 9th International Conference on Learning Representations2021ICLR 2021</p>
<p>Self-driving laboratories, advanced immunotherapies and five more technologies to watch in 2025. M Eisenstein, 10.1038/d41586-025-00075-6Nature. 6372025</p>
<p>Towards robot scientists for autonomous scientific discovery. A Sparkes, W Aubrey, E Byrne, A Clare, M N Khan, M Liakata, M Markham, J Rowland, L N Soldatova, K E Whelan, M Young, R D King, Automated Experimentation. 212021</p>
<p>Cheaper faster drug development validated by the repositioning of drugs against neglected tropical diseases. K Williams, E Bilsland, A Sparkes, W Aubrey, M Young, L N Soldatova, K D Grave, J Ramon, M Clare, W Sirawaraporn, S G Oliver, R D King, Journal of the Royal Society Interface. 12104201412892015</p>
<p>Cheaper faster drug development validated by the repositioning of drugs against neglected tropical diseases. K Williams, E Bilsland, A Sparkes, W Aubrey, M Young, L N Soldatova, K De Grave, J Ramon, M Clare, W Sirawaraporn, S G Oliver, R D King, 10.1098/rsif.2014.1289Journal of the Royal Society Interface. 12104201412892015</p>
<p>Testing the reproducibility and robustness of the cancer biology literature by robot. K Roper, A Abdel-Rehim, S Hubbard, M Carpenter, A Rzhetsky, L N Soldatova, R D King, 10.1098/rsif.2021.0821Journal of the Royal Society Interface. 19189202108212022</p>
<p>A mobile robotic chemist. B Burger, P M Maffettone, V V Gusev, C M Aitchison, Y Bai, X Wang, X Li, B M Alston, B Li, R Clowes, N Rankin, B Harris, R S Sprick, A I Cooper, 10.1038/s41586-020-2442-2Nature. 58378152020</p>
<p>Robot scientists: From adam to eve to genesis. R King, O Peter, P Courtney, Artificial Intelligence in Science: Challenges, Opportunities and the Future of Research. T Science, O Innovation, ParisOECD Publishing2023</p>
<p>Fantastic Realities: 49 Mind Journeys and a Trip to Stockholm. F Wilczek, B Devine, 2006World ScientificSingapore</p>
<p>Nobel turing challenge: Creating the engine for scientific discovery. H Kitano, Systems Biology and Applications. 7292021</p>
<p>Semanticallybased crossover in genetic programming: application to real-valued symbolic regression. N Q Uy, N X Hoai, M O'neill, R I Mckay, E Galván-López, Genetic Programming and Evolvable Machines. 122011</p>
<p>Ai feynman: A physics-inspired method for symbolic regression. S.-M Udrescu, M Tegmark, Science advances. 61626312020</p>
<p>Benchmarking materials property prediction methods: the matbench test set and automatminer reference algorithm. A Dunn, Q Wang, A Ganose, D Dopp, A Jain, Computational Materials. 61382020</p>
<p>SCP-116K: A High-Quality Problem-Solution Dataset and a Generalized Pipeline for Automated Extraction in the Higher Education Science Domain. D Lu, X Tan, R Xu, T Yao, C Qu, W Chu, Y Xu, Y Qi, 2025</p>
<p>The well: a large-scale collection of diverse physics simulations for machine learning. R Ohana, M Mccabe, L T Meyer, R Morel, F J Agocs, M Beneitez, M Berger, B Burkhart, S B Dalziel, D B Fielding, D Fortunato, J A Goldberg, K Hirashima, Y.-F Jiang, R Kerswell, S Maddu, J M Miller, P Mukhopadhyay, S S Nixon, J Shen, R Watteaux, B R Blancard, .-S Rozet, F Parker, L H Cranmer, M Ho, S , The Thirty-eight Conference on Neural Information Processing Systems Datasets and Benchmarks Track. 2024</p>
<p>ScienceWorld: Is your Agent Smarter than a 5th Grader?. R Wang, P Jansen, M.-A Côté, P Ammanabrolu, 2022</p>
<p>P E Jansen, DiscoveryWorld: A Virtual Environment for Developing and Evaluating Automated Scientific Discovery Agents. 2024</p>
<p>Chemgymrl: A customizable interactive framework for reinforcement learning for digital chemistry. C Beeler, S G Subramanian, K Sprague, M Baula, N Chatti, A Dawit, X Li, N Paquin, M Shahen, Z Yang, C Bellinger, M Crowley, I Tamblyn, 10.1039/D3DD00183KDigital Discovery. 32024</p>
<p>DiscoveryBench: Towards Data-Driven Discovery with Large Language Models. B P Majumder, H Surana, D Agarwal, B Dalvi Mishra, A Meena, A Prakhar, T Vora, T Khot, A Sabharwal, P Clark, Dataset and code available on GitHub. 2024</p>
<p>BoxingGym: Benchmarking Progress in Automated Experimental Design and Model Discovery. K Gandhi, M Y Li, L Goodyear, L Li, A Bhaskar, M Zaman, N D Goodman, 2025Project page with environments</p>
<p>Science-Gym: A simple testbed for ai-driven scientific discovery. M Cerrato, N Schmitt, L Baur, E Finkelstein, S Jukic, L Münzel, F P Paul, P Pfannes, B Rohr, J Schellenberg, P Wolf, S Kramer, 10.1007/978-3-031-78977-9_15Proceedings of the 26th International Conference on Discovery Science (DS). Lecture Notes in Computer Science. the 26th International Conference on Discovery Science (DS)Pisa, ItalySpringer202415243Gym-compatible simulation library for physics/epidemiology scenarios</p>
<p>The open catalyst 2020 (oc20) dataset and community challenges. L E Chanussot, ACS Catalysis. 11102021</p>            </div>
        </div>

    </div>
</body>
</html>