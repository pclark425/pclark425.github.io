<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-5036 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-5036</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-5036</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-106.html">extraction-schema-106</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models (LLMs or neural language models) being used to solve puzzle games that require spatial knowledge (such as Sudoku or other spatial reasoning tasks). Include details about the models, the puzzles, the mechanisms or strategies used, performance metrics, evidence of spatial reasoning, limitations, and comparisons.</div>
                <p><strong>Paper ID:</strong> paper-229678739</p>
                <p><strong>Paper Title:</strong> <a href="https://arxiv.org/pdf/2012.13635v4.pdf" target="_blank">Logic Tensor Networks</a></p>
                <p><strong>Paper Abstract:</strong> Artificial Intelligence agents are required to learn from their surroundings and to reason about the knowledge that has been learned in order to make decisions. While state-of-the-art learning from data typically uses sub-symbolic distributed representations, reasoning is normally useful at a higher level of abstraction with the use of a first-order logic language for knowledge representation. As a result, attempts at combining symbolic AI and neural computation into neural-symbolic systems have been on the increase. In this paper, we present Logic Tensor Networks (LTN), a neurosymbolic formalism and computational model that supports learning and reasoning through the introduction of a many-valued, end-to-end differentiable first-order logic called Real Logic as a representation language for deep learning. We show that LTN provides a uniform language for the specification and the computation of several AI tasks such as data clustering, multi-label classification, relational learning, query answering, semi-supervised learning, regression and embedding learning. We implement and illustrate each of the above tasks with a number of simple explanatory examples using TensorFlow 2. Keywords: Neurosymbolic AI, Deep Learning and Reasoning, Many-valued Logic.</p>
                <p><strong>Cost:</strong> 0.011</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <p class="empty-note">No extracted data.</p>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <p class="empty-note">No potentially relevant new papers extracted.</p>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-5036",
    "paper_id": "paper-229678739",
    "extraction_schema_id": "extraction-schema-106",
    "extracted_data": [],
    "potentially_relevant_new_papers": [],
    "cost": 0.01112675,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Logic Tensor Networks</p>
<p>Samy Badreddine 
Sony Computer Science Laboratories Inc
3-14-13 Higashigotanda141-0022TokyoJapan</p>
<p>Sony AI Inc
1-7-1 Konan108-0075TokyoJapan</p>
<p>Fondazione Bruno Kessler
Via Sommarive 1838123TrentoItaly</p>
<p>Artur D&apos;avila Garcez 
University of London
EC1V 0HBCity, Northampton Square, LondonUnited Kingdom</p>
<p>Luciano Serafini 
Fondazione Bruno Kessler
Via Sommarive 1838123TrentoItaly</p>
<p>Michael Spranger 
Sony Computer Science Laboratories Inc
3-14-13 Higashigotanda141-0022TokyoJapan</p>
<p>Sony AI Inc
1-7-1 Konan108-0075TokyoJapan</p>
<p>Logic Tensor Networks
Neurosymbolic AIDeep Learning and ReasoningMany-valued Logics
Attempts at combining logic and neural networks into neurosymbolic approaches have been on the increase in recent years. In a neurosymbolic system, symbolic knowledge assists deep learning, which typically uses a sub-symbolic distributed representation, to learn and reason at a higher level of abstraction. We present Logic Tensor Networks (LTN), a neurosymbolic framework that supports querying, learning and reasoning with both rich data and abstract knowledge about the world. LTN introduces a fully differentiable logical language, called Real Logic, whereby the elements of a first-order logic signature are grounded onto data using neural computational graphs and first-order fuzzy logic semantics. We show that LTN provides a uniform language to represent and compute efficiently many of the most important AI tasks such as multi-label classification, relational learning, data clustering, semi-supervised learning, regression, embedding learning and query answering. We implement and illustrate each of the above tasks with several simple explanatory examples using TensorFlow 2. The results indicate that LTN can be a general and powerful framework for neurosymbolic AI.</p>
<p>Introduction</p>
<p>Artificial Intelligence (AI) agents are required to learn from their surroundings and reason about what has been learned to make decisions, act in the world, or react to various stimuli. The latest Machine Learning (ML) has adopted mostly a pure sub-symbolic learning approach. Using distributed representations of entities, the latest ML performs quick decision-making without building a comprehensible model of the world. While achieving impressive results in computer vision, natural language, game playing, and multimodal learning, such approaches are known to be data inefficient and to struggle at out-of-distribution generalization. Although the use of appropriate inductive biases can alleviate such shortcomings, in general, sub-symbolic models lack comprehensibility. By contrast, symbolic AI is based on rich, high-level representations of the world that use human-readable symbols. By rich knowledge, we refer to logical representations which are more expressive than propositional logic or propositional probabilistic approaches, and which can express knowledge using full first-order logic, including universal and existential quantification (@x and Dy), arbitrary n-ary relations over variables, e.g. Rpx, y, z, . . . q, and function symbols, e.g. fatherOfpxq, x`y, etc. Symbolic AI has achieved success at theorem proving, logical inference, and verification. However, it also has shortcomings when dealing with incomplete knowledge. It can be inefficient with large amounts of inaccurate data and lack robustness to outliers. Purely symbolic decision algorithms usually have high computational complexity making them impractical for the real world. It is now clear that the predominant approach to ML, where learning is based on recognizing the latent structures hidden in the data, is insufficient and may benefit from symbolic AI [17]. In this context, neurosymbolic AI, which stems from neural networks and symbolic AI, attempts to combine the strength of both paradigms (see [16,40,54] for recent surveys). That is to say, combine reasoning with complex representations of knowledge (knowledge-bases, semantic networks, ontologies, trees, and graphs) with learning from complex data (images, time series, sensorimotor data, natural language). Consequently, a main challenge for neurosymbolic AI is the grounding of symbols, including constants, functional and relational symbols, into real data, which is akin to the longstanding symbol grounding problem [30].</p>
<p>Logic Tensor Networks (LTN) are a neurosymbolic framework and computational model that supports learning and reasoning about data with rich knowledge. In LTN, one can represent and effectively compute the most important tasks of deep learning with a fully differentiable firstorder logic language, called Real Logic, which adopts infinitely many truth-values in the interval [0,1] [22,25]. In particular, LTN supports the specification and computation of the following AI tasks uniformly using the same language: data clustering, classification, relational learning, query answering, semi-supervised learning, regression, and embedding learning.</p>
<p>LTN and Real Logic were first introduced in [62]. Since then, LTN has been applied to different AI tasks involving perception, learning, and reasoning about relational knowledge. In [18,19], LTN was applied to semantic image interpretation whereby relational knowledge about objects was injected into deep networks for object relationship detection. In [6], LTN was evaluated on its capacity to perform reasoning about ontological knowledge. Furthermore, [7] shows how LTN can be used to learn an embedding of concepts into a latent real space by taking into consideration ontological knowledge about such concepts. In [3], LTN is used to annotate a reinforcement learning environment with prior knowledge and incorporate latent information into an agent. In [42], authors embed LTN in a state-of-the-art convolutional object detector. Extensions and generalizations of LTN have also been proposed in the past years, such as LYRICS [47] and Differentiable Fuzzy Logic (DFL) [68,69]. LYRICS provides an input language allowing one to define background knowledge using a first-order logic where predicate and function symbols are grounded onto any computational graph. DFL analyzes how a large collection of fuzzy logic operators behave in a differentiable learning setting. DFL also introduces new semantics for fuzzy logic implications called sigmoidal implications, and it shows that such semantics outperform other semantics in several semi-supervised machine learning tasks.</p>
<p>This paper provides a thorough description of the full formalism and several extensions of LTN. We show using an extensive set of explanatory examples, how LTN can be applied to solve many ML tasks with the help of logical knowledge. In particular, the earlier versions of LTN have been extended with: (1) Explicit domain declaration: constants, variables, functions and predicates are now domain typed (e.g. the constants John and Paris can be from the domain of person and city, respectively). The definition of structured domains is also possible (e.g. the domain couple can be defined as the Cartesian product of two domains of persons); (2) Guarded quantifiers: guarded universal and existential quantifiers now allow the user to limit the quantification to the elements that satisfy some Boolean condition, e.g. @x : agepxq ă 10 pplaysPianopxq Ñ enfantProdigepxqq restricts the quantification to the cases where age is lower than 10; (3) Diagonal quantification: Diagonal quantification allows the user to write statements about specific tuples extracted in order from n variables. For example, if the variables capital and country both have k instances such that the i-th instance of capital corresponds to the i-th instance of country, one can write @Diagpcapital, countryq capitalOfpcapital, countryq.</p>
<p>Inspired by the work of [69], this paper also extends the product t-norm configuration of LTN with the generalized mean aggregator, and it introduces solutions to the vanishing or exploding gradient problems. Finally, the paper formally defines a semantic approach to refutation-based reasoning in Real Logic to verify if a statement is a logical consequence of a knowledge base. Example 4.8 proves that this new approach can better capture logical consequences compared to simply querying unknown formulas after learning (as done in [6]).</p>
<p>The new version of LTN has been implemented in TensorFlow 2 [1]. Both the LTN library and the code for the examples used in this paper are available at https://github.com/ logictensornetworks/logictensornetworks.</p>
<p>The remainder of the paper is organized as follows: In Section 2, we define and illustrate Real Logic as a fully-differentiable first-order logic. In Section 3, we specify learning and reasoning in Real Logic and its modeling into deep networks with Logic Tensor Networks (LTN). In Section 4, we illustrate the reach of LTN by investigating a range of learning problems from clustering to embedding learning. In Section 5, we place LTN in the context of the latest related work in neurosymbolic AI. In Section 6 we conclude and discuss directions for future work. The Appendix contains information about the implementation of LTN in TensorFlow 2, experimental set-ups, the different options for the differentiable logic operators, and a study of their relationship with gradient computations.</p>
<p>Real Logic</p>
<p>Syntax</p>
<p>Real Logic forms the basis of Logic Tensor Networks. Real Logic is defined on a first-order language L with a signature that contains a set C of constant symbols (objects), a set F of functional symbols, a set P of relational symbols (predicates), and a set X of variable symbols. L-formulas allow us to specify relational knowledge with variables, e.g. the atomic formula is_friendpv 1 , v 2 q may state that the person v 1 is a friend of the person v 2 , the formula @x@ypis_friendpx, yq Ñ is_friendpy, xqq states that the relation is_friend is symmetric, and the formula @xpDypItalianpxq^is_friendpx, yqqq states that every person has a friend that is Italian. Since we are interested in learning and reasoning in real-world scenarios where degrees of truth are often fuzzy and exceptions are present, formulas can be partially true, and therefore we adopt fuzzy semantics.</p>
<p>Objects can be of different types. Similarly, functions and predicates are typed. Therefore, we assume there exists a non-empty set of symbols D called domain symbols. To assign types to the elements of L we introduce the functions D, D in and D out such that:</p>
<p>• D : X Y C Ñ D. Intuitively, Dpxq and Dpcq returns the domain of a variable x or a constant c.</p>
<p>• D in : F Y P Ñ D˚, where D˚is the Kleene star of D, that is the set of all finite sequences of symbols in D. Intuitively, D in pf q and D in ppq returns the domains of the arguments of a function f or a predicate p. If f takes two arguments (for example, f px, yq), D in pf q returns two domains, one per argument.</p>
<p>• D out : F Ñ D. Intuitively, D out pf q returns the range of a function symbol.</p>
<p>Real Logic may also contain propositional variables, as follows: if P is a 0-ary predicate with D in pP q "</p>
<p>(the empty sequence of domains) then P is a propositional variable (an atom with truth-value in the interval [0,1]).</p>
<p>A term is constructed recursively in the usual way from constant symbols, variables, and function symbols. An expression formed by applying a predicate symbol to an appropriate number of terms with appropriate domains is called an atomic formula, which evaluates to true or false in classical logic and a number in r0, 1s in the case of Real Logic. We define the set of terms of the language as follows:</p>
<p>• each element t of X Y C is a term of the domain Dptq;</p>
<p>• if t i is a term of domain Dpt i q for 1 ď i ď n then t 1 t 2 . . . t n (the sequence composed of t 1 followed by t 2 and so on, up to t n ) is a term of the domain Dpt 1 qDpt 2 q . . . Dpt n q;</p>
<p>• if t is a term of the domain D in pf q then f ptq is a term of the domain D out pf q.</p>
<p>We allow the following set of formula in L:</p>
<p>• t 1 " t 2 is an atomic formula for any terms t 1 and t 2 with Dpt 1 q " Dpt 2 q;</p>
<p>• pptq is an atomic formula if Dptq " D in ppq;</p>
<p>• If φ and ψ are formula and x 1 , . . . , x n are n distinct variable symbols then˛φ, φ˝ψ and Qx 1 . . . x n φ are formula, where˛is a unary connective,˝is a binary connective and Q is a quantifier.</p>
<p>We use˛P t u (negation),˝P t^, _, Ñ, Øu (conjunction, disjunction, implication and biconditional, respectively) and Q P t@, Du (universal and existential, respectively). </p>
<p>Example 1. Let</p>
<p>Semantics of Real Logic</p>
<p>The semantics of Real Logic departs from the standard abstract semantics of First-order Logic (FOL). In Real Logic, domains are interpreted concretely by tensors in the real field. 1 Every object denoted by constants, variables, and terms, is interpreted as a tensor of real values. Functions are interpreted as real functions or tensor operations. Predicates are interpreted as functions or tensor operations projecting onto a value in the interval r0, 1s.</p>
<p>To emphasize the fact that in Real Logic symbols are grounded onto real-valued features, we use the term grounding, denoted by G, in place of interpretation 2 . Notice that this is different from the common use of the term grounding in logic, which indicates the operation of replacing the variables of a term or formula with constants or terms containing no variables. To avoid confusion, we use the synonym instantiation for this purpose. G associates a tensor of real numbers to any term of L, and a real number in the interval r0, 1s to any formula φ of L. Intuitively, Gptq are the numeric features of the objects denoted by t, and Gpφq represents the system's degree of confidence in the truth of φ; the higher the value, the higher the confidence.</p>
<p>Grounding domains and the signature</p>
<p>A grounding for a logical language L on the set of domains D provides the interpretation of both the domain symbols in D and the non-logical symbols in L.
Definition 1. A grounding G associates to each domain D P D a set GpDq Ď Ť n1...n d PN˚R n1ˆ¨¨¨ˆn d .
For every D 1 . . . D n P D˚, GpD 1 . . . D n q "
Ś n i"1 GpD i q, that is GpD 1 q Ś GpD 2 q Ś ... Ś GpD n q.
Notice that the elements in GpDq may be tensors of any rank d and any dimensions n 1ˆ¨¨¨ˆnd , A grounding assigns to each constant symbol c, a tensor Gpcq in the domain GpDpcqq; It assigns to a variable x a finite sequence of tensors d 1 . . . d k , each in GpDpxqq. These tensors represent the instances of x. Differently from in FOL where a variable is assigned to a single value of the domain of interpretations at a time, in Real Logic a variable is assigned to a sequence of values in its domain, the k examples of x. A grounding assigns to a function symbol f a function taking tensors from GpD in pf qq as input, and producing a tensor in GpD out pf qq as output. Finally, a grounding assigns to a predicate symbol p a function taking tensors from GpD in ppqq as input, and producing a truth-value in the interval r0, 1s as output.</p>
<p>Definition 2.</p>
<p>A grounding G of L is a function defined on the signature of L that satisfies the following conditions:
1. Gpxq " d 1 . . . d k P Ś k i"1
GpDpxqq for every variable symbol x P X , with k P N0 . Notice that Gpxq is a sequence and not a set, meaning that the same value of GpDpxqq can occur multiple times in Gpxq, as is usual in a Machine Learning data set with "attributes" and "values"; 2. Gpf q P GpD in pf qq Ñ GpD out pf qq for every function symbol f P F;</p>
<ol>
<li>Gppq P GpD in ppqq Ñ r0, 1s for every predicate symbol p P P.</li>
</ol>
<p>If a grounding depends on a set of parameters θ, we denote it as G θ p¨q or Gp¨| θq interchangeably. Section 4 describes how such parameters can be learned using the concept of satisfiability.</p>
<p>Grounding terms and atomic formulas</p>
<p>We now extend the definition of grounding to all first-order terms and atomic formulas. Before formally defining these groundings, we describe on a high level what happens when grounding terms that contain free variables. 4 Let x be a variable that denotes people. As explained in Definition 2, x is grounded as an explicit sequence of k instances (k " |Gpxq|). Consequently, a term heightpxq is also grounded in k height values, each corresponding to one instance. We can generalize to expressions with multiple free variables, as shown in Example 3.</p>
<p>In the formal definition below, instead of considering a single term at a time, it is convenient to consider sequences of terms t " t 1 t 2 . . . t k and define the grounding on t (with the definition of the grounding of a single term being derived as a special case). The fact that the sequence of terms t contains n distinct variables x 1 , . . . , x n is denoted by tpx 1 , . . . , x n q. The grounding of tpx 1 , . . . , x n q, denoted by Gptpx 1 , . . . , x n qq, is a tensor with n corresponding axes, one for each free variable, defined as follows: Definition 3. Let tpx 1 , . . . , x n q be a sequence t 1 . . . t m of m terms containing n distinct variables x 1 , . . . , x n . Let each term t i in t contain n i variables x ji1 , . . . , x jin i .</p>
<p>• Gptq is a tensor with dimensions p|Gpx 1 q|, . . . , |Gpx n q|q such that the element of this tensor indexed by k 1 , . . . , k n , written as Gptq k1...kn , is equal to the concatenation of Gpt i q kj i1 ...kj in i for 1 ď i ď m;</p>
<p>• Gpf ptqq i1...in " Gpf qpGptq i1...in q, i.e. the element-wise application of Gpf q to Gptq;</p>
<p>• Gppptqq i1...in " GppqpGptq i1...in q, i.e. the element-wise application of Gppq to Gptq.</p>
<p>If term t i contains n i variables x j1 , . . . , x jn i selected from x 1 , . . . , x n then Gpt i q kj 1 ...kj n i can be obtained from Gptq i1...in with an appropriate mapping of indices i to k. and indicate dimensions associated with the free variables x and y. A tensor representing a term that includes a free variable x will have an axis . One can index to obtain results calculated using each of the v 1 , v 2 or v 3 values of x. In our graphical convention, the depth of the boxes indicates that the tensor can have feature dimensions (refer to the end of Example 3).</p>
<p>Example 3.</p>
<p>Suppose that L contains the variables x and y, the function f , the predicate p and the set of domains D " tV, W u. Let Dpxq " V , Dpyq " W , D in pf q " V W , D out pf q " W and Dppq " V W . In what follows, an example of the grounding of L and D is shown on the left, and the grounding of some examples of possible terms and atomic formulas is shown on the right.
GpV q " RG pW q " RǴ pxq " v 1 , v 2 , v 3 Gpyq " w 1 , w 2 Gppq : x, y Þ Ñ σpx<code>yq Gpf q : x, y Þ Ñ x¨y Gpf px, yqq "¨v 1¨w1 v 1¨w2 v 2¨w1 v 2¨w2 v 3¨w1 v 3¨w2‚ Gpppx, f px, yqqq "¨σ pv1</code>v1¨w1q σpv1<code>v1¨w2q σpv2</code>v2¨w1q σpv2<code>v2¨w2q σpv3</code>v3¨w1q σpv3`v3¨w2q‚
Notice the dimensions of the results. Gpf px, yqq and Gpppx, f px, yqqq return |Gpxq|ˆ|Gpyq| " 3ˆ2 values, one for each combination of individuals that occur in the variables. For functions, we can have additional dimensions associated to the output domain. Let us suppose a different grounding such that GpD out pf qq " R m . Then the dimensions of Gpf px, yqq would have been |Gpxq|ˆ|Gpyq|ˆm, where |Gpxq|ˆ|Gpyq| are the dimensions for indexing the free variables and m are dimensions associated to the output domain of f . Let us call the latter feature dimensions, as captioned in Figure 1. Notice that Gpppx, f px, yqqq will always return a tensor with the exact dimensions |Gpxq|ˆ|Gpyq|ˆ1 because, under any grounding, a predicate always returns a value in r0, 1s. Therefore, as the "feature dimensions" of predicates is always 1, we choose to "squeeze it" and not to represent it in our graphical convention (see Figure 1, the box output by the predicate has no depth). Figure 2: Illustration of an element-wise operator implementing conjunction (ppxq^qpyq). We assume that x and y are two different variables. The result has one number in the interval r0, 1s to every combination of individuals from Gpxq and Gpyq.</p>
<p>Connectives and Quantifiers</p>
<p>The semantics of the connectives is defined according to the semantics of first-order fuzzy logic [28]. Conjunction (^), disjunction (_), implication (Ñ) and negation ( ) are associated, respectively, with a t-norm (T ), a t-conorm (S), a fuzzy implication (I) and a fuzzy negation (N ) operation FuzzyOp P tT, S, I, N u. Definitions of some common fuzzy operators are presented in Appendix B. Let φ and ψ be two formulas with free variables x 1 , . . . , x m and y 1 , . . . , y n , respectively. Let us assume that the first k variables are common to φ and ψ. Recall that˛and˝denote the set of unary and binary connectives, respectively. Formally:
Gp˛φq i1,...,im " FuzzyOpp˛qpGpφq i1,...,im q (1) Gpφ˝ψq i1,...,i m<code>n´k " FuzzyOpp˝qpGpφq i1,...,i k ,i k</code>1 ,...,im Gpψq i1,...,i k ,im<code>1,...,i m</code>n´k q(2)
In (2), pi 1 , . . . , i k q denote the indices of the k common variables, pi k<code>1 , . . . , i m q denote the indices of the m´k variables appearing only in φ, and pi m</code>1 , . . . , i m<code>n´k q denote the indices of the n´k variables appearing only in ψ. Intuitively, Gpφ˝ψq is a tensor whose elements are obtained by applying FuzzyOpp˝q element-wise to every combination of individuals from x 1 , . . . , x m and y 1 , . . . , y n (see Figure 2). The semantics of the quantifiers (t@, Du) is defined with the use of aggregation. Let Agg be a symmetric and continuous aggregation operator, Agg : Ť nPN r0, 1s n Ñ r0, 1s. An analysis of suitable aggregation operators is presented in Appendix Appendix B. For every formula φ containing x 1 , . . . , x n free variables, suppose, without loss of generality, that quantification applies to the first h variables. We shall therefore apply Agg to the first h axes of Gpφq, as follows:
GpQx 1 , . . . , x h pφqq i h</code>1 ,...,in " AggpQq i1"1,...,|Gpx1q| . . . i h "1,...,|Gpx h q| Gpφq i1,...,i h ,i h`1 ,...,in(3)
where AggpQq is the aggregation operator associated with the quantifier Q. Intuitively, we obtain GpQx 1 , . . . , x h pφqq by reducing the dimensions associated with x 1 , . . . , x h using the operator AggpQq (see Figure 3). Notice that the above grounded semantics can assign different meanings to the three formulas:</p>
<p>@xy<code>φpx, yq˘@x</code>@y<code>φpx, yq˘˘@y</code>@x<code>φpx, yq˘8 The semantics of the three formulas will coincide if the aggregation operator is bi-symmetric. LTN also allows the following form of quantification, here called diagonal quantification (Diag):
GpQ Diagpx 1 , . . . , x h qpφqq i h</code>1 ,...,in " AggpQq i"1,...,min 1ďjďh |Gpxj q| Gpφq i,...,i,i h`1 ,...,in(4)
Diagpx 1 , . . . , x h q quantifies over specific tuples such that the i-th tuple contains the i-th instance of each of the variables in the argument of Diag, under the assumption that all variables in the argument are grounded onto sequences with the same number of instances. Diagpx 1 , . . . , x h q is called diagonal quantification because it quantifies over the diagonal of Gpφq along the axes associated with x 1 ...x h , although in practice only the diagonal is built and not the entire Gpφq, as shown in Figure 4. For example, given a data set with samples x and target labels y, if looking to write a statement ppx, yq that holds true for each pair of sample and label, one can write @Diagpx, yq ppx, yq given that |Gpxq| " |Gpyq|. As another example, given two variables x and y whose groundings contain 10 instances of x and y each, the expression @Diagpx, yq ppx, yq produces 10 results such that the i-th result corresponds to the i-th instances of each grounding. Without Diag, the expression would be evaluated for all 10ˆ10 combinations of the elements in Gpxq and Gpyq. 5 Diag will find much application in the examples and experiments to follow.</p>
<p>Guarded Quantifiers</p>
<p>In many situations, one may wish to quantify over a set of elements of a domain whose grounding satisfy some condition. In particular, one may wish to express such condition using formulas of the language of the form: @y pDx : agepxq ą agepyq pparentpx, yqqq</p>
<p>The grounding of such a formula is obtained by aggregating the values of parentpx, yq only for the instances of x that satisfy the condition agepxq ą agepyq, that is: Figure 4: Diagonal Quantification: Diagpx 1 , x 2 q quantifies over specific tuples only, such that the i-th tuple contains the i-th instances of the variables x 1 and x 2 in the groundings Gpx 1 q and Gpx 2 q, respectively. Diagpx 1 , x 2 q assumes, therefore, that x 1 and x 2 have the same number of instances as in the case of samples x 1 and their labels x 2 in a typical supervised learning tasks. The evaluation of which tuple is safe is purely symbolic and non-differentiable. Guarded quantifiers operate over only a subset of the variables, when this symbolic knowledge is crisp and available. More generally, in what follows, m is a symbol representing the condition, which we shall call a mask, and Gpmq associates a function 6 returning a Boolean to m.   (6) Notice that the semantics of a guarded sentence @x : mpxqpφpxqq is different than the semantics of @xpmpxq Ñ φpxqq. In crisp and traditional FOL, the two statements would be equivalent. In Real Logic, they can give different results. Let Gpxq be a sequence of 3 values, Gpmpxqq " p0, 1, 1q and Gpφpxqq " p0.2, 0.7, 0.8q. Only the second and third instances of x are safe, that is, are in the masked subset. Let Ñ be defined using the Reichenbach operator I R pa, bq " 1´a<code>ab and @ be defined using the mean operator. We have Gp@xpmpxq Ñ φpxqqq " 1</code>0.7`0.  </p>
<p>Stable Product Real Logic</p>
<p>It has been shown in [69] that not all first-order fuzzy logic semantics are equally suited for gradient-descent optimization. Many fuzzy logic operators can lead to vanishing or exploding gradients. Some operators are also single-passing, in that they propagate gradients to only one input at a time.</p>
<dl>
<dt>In general, the best performing symmetric configuration 7 for the connectives uses the product t-norm T P for conjunction, its dual t-conorm S P for disjunction, standard negation N S , and the Reichenbach implication I R (the corresponding S-Implication to the above operators). This subset of Real Logic where the grounding of the connectives is restricted to the product configuration is called Product Real Logic in [69]. Given a and b two truth-values in r0, 1s:</dt>
<dd>
<p>N S paq " 1´a (7) : T P pa, bq " ab (8) _ : S P pa, bq " a<code>b´ab (9) Ñ: I R pa, bq " 1´a</code>ab (10) Appropriate aggregators for D and @ are the generalized mean A pM with p ě 1 to approximate the existential quantification, and the generalized mean w.r.t. the error A pM E with p ě 1 to approximate the universal quantification. They can be understood as a smooth maximum and a smooth minimum, respectively. Given n truth-values a 1 , . . . , a n all in r0, 1s: D : A pM pa 1 , . . . , a n q "ˆ1 n
n ÿ i"1 a p i˙1 p p ě 1(11)
@ : A pM E pa 1 , . . . , a n q " 1´ˆ1 n
n ÿ i"1 p1´a i q p˙1 p p ě 1(12)
A pM E measures the power of the deviation of each value from the ground truth 1. With p " 2, it is equivalent to 1´RMSEpa, 1q, where RMSE is the root-mean-square error, a is the vector of truth-values and 1 is a vector of 1's.</p>
</dd>
</dl>
<p>The intuition behind the choice of p is that the higher that p is, the more weight that A pM (resp. A pM E ) will give to true (resp. false) truth-values, converging to the max (resp. min) operator. Therefore, the value of p can be seen as a hyper-parameter as it offers flexibility to account for outliers in the data depending on the application.</p>
<p>Nevertheless, Product Real Logic still has the following gradient problems: T P pa, bq has vanishing gradients on the edge case a " b " 0; S P pa, bq has vanishing gradients on the edge case a " b " 1; I R pa, bq has vanishing gradients on the edge case a " 0,b " 1; A pM pa 1 , . . . , a n q has exploding gradients when ř i pa i q p tends to 0; A pM E pa 1 , . . . , a n q has exploding gradients when ř i p1´a i q p tends to 0 (see Appendix C for details).</p>
<p>To address these problems, we define the projections π 0 and π 1 below with an arbitrarily small positive real number: π 0 : r0, 1s Ñs0, 1s : a Ñ p1´ qa` (13) π 1 : r0, 1s Ñ r0, 1r: a Ñ p1´ qa (14) We then derive the following stable operators to produce what we call the Stable Product Real Logic configuration:
N 1 S paq " N S paq (15) T 1 P pa, bq " T P pπ 0 paq, π 0 pbqq (16) S 1 P pa, bq " S P pπ 1 paq, π 1 pbqq (17) I 1 R pa, bq " I R pπ 0 paq, π 1 pbqq (18) A 1
pM pa 1 , . . . , a n q " A pM pπ 0 pa 1 q, . . . , π 0 pa n qq p ě 1
(19) A 1
pM E pa 1 , . . . , a n q " A pM E pπ 1 pa 1 q, . . . , π 1 pa n qq p ě 1</p>
<p>It is important noting that the conjunction operator in stable product semantics is not a T-norm 8 . T 1 P pa, bq does not satisfy identity in r0, 1r since for any 0 ď a ă 1, T 1 P pa, 1q " p1´ qa` ‰ a, although can be chosen arbitrarily small. In the experimental evaluations reported in Section 4, we find that the adoption of the stable product semantics is an important practical step to improve the numerical stability of the learning system.</p>
<p>Learning, Reasoning, and Querying in Real Logic</p>
<p>In Real Logic, one can define the tasks of learning, reasoning and query-answering. Given a Real Logic theory that represents the knowledge of an agent at a given time, learning is the task of making generalizations from specific observations obtained from data. This is often called inductive inference. Reasoning is the task of deriving what knowledge follows from the facts which are currently known. Query answering is the task of evaluating the truth value of a certain logical expression (called a query), or finding the set of objects in the data that evaluate a certain expression to true. In what follows, we define and exemplify each of these tasks. To do so, we first need to specify which types of knowledge can be represented in Real Logic.</p>
<p>Representing Knowledge with Real Logic</p>
<p>In logic-based knowledge representation systems, knowledge is represented by logical formulas whose intended meanings are propositions about a domain of interest. The connection between the symbols occurring in the formulas and what holds in the domain is not represented in the knowledge base and is left implicit since it does not have any effect on the logic computations. In Real Logic, by contrast, the connection between the symbols and the domain is represented explicitly in the language by the grounding G, which plays an important role in both learning and reasoning. G is an integral part of the knowledge represented by Real Logic. A Real Logic knowledge base is therefore defined by the formulas of the logical language and knowledge about the domain in the form of groundings obtained from data. The following types of knowledge can be represented in Real Logic.</p>
<p>Knowledge through symbol groundings</p>
<p>Boundaries for domain grounding. These are constraints specifying that the value of a certain logical expression must be within a certain range. For instance, one may specify that the domain D must be interpreted in the r0, 1s hyper-cube or in the standard n-simplex, i.e. the set d 1 , . . . , d n P pR`q n such that
ř i d i " 1.
Other intuitive examples of range constraints include the elements of the domain "colour" grounded onto points in r0, 1s 3 such that every element is associated with the triplet of values pR, G, Bq with R, G, B P r0, 1s, or the range of a function agepxq as an integer between 0 and 100.</p>
<p>Explicit definition of grounding for symbols. Knowledge can be more strictly incorporated by fix-</p>
<p>ing the grounding of some symbols. If a constant c denotes an object with known features v c P R n , we can fix its grounding Gpcq " v c . Training data that consists in a set of n data items such as n images (or tuples known as training examples) can be specified in Real Logic by n constants, e.g. img 1 , img 2 , . . . , img n , and by their groundings, e.g. Gpimg 1 q " , Gpimg 2 q " , . . . , Gpimg n q " . These can be gathered in a variable imgs.</p>
<p>A binary predicate sim that measures the similarity of two objects can be grounded as, e.g., a cosine similarity function of two vectors v and w, pv, wq Þ Ñ v¨w ||v|| ||w|| . The output layer of the neural network associated with a multi-class single-label predicate P px, classq can be a softmax function normalizing the output such that it guarantees exclusive classification, i.e. ř i P px, iq " 1. 9 Grounding of constants and functions allows the computation of the grounding of their results. If, for example, Gptranspq is the function that transposes a matrix then Gptransppimg 1 qq " .</p>
<p>Parametric definition of grounding for symbols.</p>
<p>Here, the exact grounding of a symbol σ is not known, but it is known that it can be obtained by finding a set of real-valued parameters, that is, via learning. To emphasize this fact, we adopt the notation Gpσq " Gpσ | θ σ q where θ σ is the set of parameter values that determines the value of Gpσq. The typical example of parametric grounding for constants is the learning of an embedding. Let embpword | θ emb q be a word embedding with parameters θ emb which takes as input a word and returns its embedding in R n . If the words of a vocabulary W " tw 1 , . . . , w |W | u are constant symbols, their groundings Gpw i | θ emb q are defined parametrically w.r.t. θ emb as embpw i | θ emb q. An example of parametric grounding for a function symbol f is to assume that Gpf q is a linear function such that Gpf q :
R m Ñ R n maps each v P R m into A f v`b f , with A f a matrix of real numbers and b a vector of real numbers. In this case, Gpf q " Gpf | θ f q, where θ f " tA f , b f u.
Finally, the grounding of a predicate symbol can be given, for example, by a neural network N with parameters θ N . As an example, consider a neural network N trained for image classification into n classes: cat, dog, horse, etc. N takes as input a vector v of pixel values and produces as output a vector y " py cat , y dog , y horse , . . . q in r0, 1s n such that y " N pv | θ N q, where y c is the probability that input image v is of class c. In case classes are, alternatively, chosen to be represented by unary predicate symbols such as catpvq, dogpvq, horsepvq,. . . then
Gpcatpvqq " N pv | θ N q cat , Gpdogpvqq " N pv | θ N q dog , Gphorsepvqq " N pv | θ N q horse , etc.</p>
<p>Knowledge through formulas</p>
<p>Factual propositions. Knowledge about the properties of specific objects in the domain is represented, as usual, by logical propositions, as exemplified below: Suppose that it is known that img 1 is a number eight, img 2 is a number nine, and img n is a number two. This can be represented by adding the following facts to the knowledge-base: ninepimg 1 q, eightpimg 2 q, . . . , twopimg n q. Supervised learning, that is, learning with the use of training examples which include target values (labelled data), is specified in Real Logic by combining grounding definitions and factual propositions. For example, the fact that an image is a positive example for the class nine and a negative example for the class eight is specified by defining Gpimg 1 q " alongside the propositions ninepimg 1 q and eightpimg 1 q. Notice how semi-supervision can be specified naturally in Real Logic by adding propositions containing disjunctions, e.g. eightpimg 1 q _ ninepimg 1 q, which state that img 1 is either an eight or a nine (or both). Finally, relational learning can be achieved by relating logically multiple objects (defined as constants or variables or even as more complex sequences of terms) such as e.g.: ninepimg 1 q Ñ ninepimg 2 q (if img 1 is a nine then img 2 is not a nine) or ninepimgq Ñ eightpimgq (if an image is a nine then it is not an eight). The use of more complex knowledge including the use of variables such as img above is the topic of generalized propositions, discussed next.</p>
<p>Generalized propositions.</p>
<p>General knowledge about all or some of the objects of some domains can be specified in Real Logic by using first-order logic formulas with quantified variables. This general type of knowledge allows one to specify arbitrary constraints on the groundings independently from the specific data available. It allows one to specify, in a concise way, knowledge that holds true for all the objects of a domain. This is especially useful in Machine Learning in the semi-supervised and unsupervised settings, where there is no specific knowledge about a single individual. For example, as part of a task of multi-label classification with constraints on the labels [12], a positive label constraint may express that if an example is labelled with l 1 , . . . , l k then it should also be labelled with l k<code>1 . This can be specified in Real Logic with a universally quantified formula: @x pl 1 pxq^¨¨¨^l k pxq Ñ l k</code>1 pxqq. 10 Another example of soft constraints used in Statistical Relational Learning associates the labels of related examples. For instance, in Markov Logic Networks [55], as part of the well-known</p>
<p>Smokers and Friends example, people who are smokers are associated by the friendship relation. In Real Logic, the formula @xy ppsmokespxq^friendpx, yqq Ñ smokespyqq would be used to encode the soft constraint that friends of smokers are normally smokers.</p>
<p>Knowledge through fuzzy semantics</p>
<p>Definition for operators. The grounding of a formula φ depends on the operators approximating the connectives and quantifiers that appear in φ. Different operators give different interpretations of the satisfaction associated with the formula. For instance, the operator A pM E pa 1 , . . . , a n q that approximates universal quantification can be understood as a smooth minimum. It depends on a hyper-parameter p (the exponent used in the generalized mean). If p " 1 then A pM E pa 1 , . . . , a n q corresponds to the arithmetic mean. As p increases, given the same input, the value of the universally quantified formula will decrease as A pM E converges to the min operator. To define how strictly the universal quantification should be interpreted in each proposition, one can use different values of p for different propositions of the knowledge base. For instance, a formula @x P pxq where A pM E is used with a low value for p will in fact denote that P holds for some x, whereas a formula @x Qpxq with a higher p may denote that Q holds for most x.</p>
<p>Satisfiability</p>
<p>In summary, a Real Logic knowledge-base has three components: the first describes knowledge about the grounding of symbols (domains, constants, variables, functions, and predicate symbols); the second is a set of closed logical formulas describing factual propositions and general knowledge; the third lies in the operators and the hyperparameters used to evaluate each formula. The definition that follows formalizes this notion.</p>
<p>Definition 4 (Theory/Knowledge-base).</p>
<p>A theory of Real Logic is a triple T " K, Gp¨| θq, Θ , where K is a set of closed first-order logic formulas defined on the set of symbols S " D Y X Y C Y F Y P denoting, respectively, domains, variables, constants, function and predicate symbols; Gp¨| θq is a parametric grounding for all the symbols s P S and all the logical operators; and Θ " tΘ s u sPS is the hypothesis space for each set of parameters θ s associated with symbol s.</p>
<p>Learning and reasoning in a Real Logic theory are both associated with searching and applying the set of values of parameters θ from the hypothesis space Θ that maximize the satisfaction of the formulas in K. We use the term grounded theory, denoted by K, G θ , to refer to a Real Logic theory with a specific set of learned parameter values. This idea shares some similarity with the weighted MAX-SAT problem [43], where the weights for formulas in K are given by their fuzzy truth-values obtained by choosing the parameter values of the grounding. To define this optimization problem, we aggregate the truth-values of all the formulas in K by selecting a formula aggregating operator SatAgg : r0, 1s˚Ñ r0, 1s.</p>
<p>Definition 5.</p>
<p>The satisfiability of a theory T " K, G θ with respect to the aggregating operator SatAgg is defined as SatAgg φPK G θ pφq.</p>
<p>Learning</p>
<p>Given a Real Logic theory T " pK, Gp¨| θq, Θq, learning is the process of searching for the set of parameter values θ˚that maximize the satisfiability of T w.r.t. a given aggregator:
θ˚" argmax θPΘ SatAgg φPK G θ pφq
Notice that with this general formulation, one can learn the grounding of constants, functions, and predicates. The learning of the grounding of constants corresponds to the learning of embeddings. The learning of the grounding of functions corresponds to the learning of generative models or a regression task. Finally, the learning of the grounding of predicates corresponds to a classification task in Machine Learning.</p>
<p>In some cases, it is useful to impose some regularization (as done customarily in ML) on the set of parameters θ, thus encoding a preference on the hypothesis space Θ, such as a preference for smaller parameter values. In this case, learning is defined as follows:</p>
<p>θ˚" argmax θPΘ˜S atAgg φPK G θ pφq´λRpθqw here λ P R`is the regularization parameter and R is a regularization function, e.g. L 1 or L 2 regularization, that is, L 1 pθq " ř θPθ |θ| and L 2 pθq " ř θPθ θ 2 . LTN can generalize and extrapolate when querying formulas grounded with unseen data (for example, new individuals from a domain), using knowledge learned with previous groundings (for example, re-using a trained predicate). This is explained in Section 3.3.</p>
<p>Querying</p>
<p>Given a grounded theory T " pK, G θ q, query answering allows one to check if a certain fact is true (or, more precisely, by how much it is true since in Real Logic truth-values are real numbers in the interval [0,1]). There are various types of queries that can be asked of a grounded theory.</p>
<p>A first type of query is called truth queries. Any formula in the language of T can be a truth query. The answer to a truth query φ q is the truth value of φ q obtained by computing its grounding, i.e. G θ pφ q q. Notice that, if φ q is a closed formula, the answer is a scalar in r0, 1s denoting the truthvalue of φ q according to G θ . if φ q contains n free variables x 1 , . . . , x n , the answer to the query is a tensor of order n such that the component indexed by i 1 . . . i n is the truth-value of φ q evaluated in G θ px 1 q i1 , . . . , G θ px n q in .</p>
<p>The second type of query is called value queries. Any term in the language of T can be a value query. The answer to a value query t q is a tensor of real numbers obtained by computing the grounding of the term, i.e. G θ pt q q. Analogously to truth queries, the answer to a value query is a "tensor of tensors" if t q contains variables. Using value queries, one can inspect how a constant or a term, more generally, is embedded in the manifold.</p>
<p>The third type of query is called generalization truth queries. With generalization truth queries, we are interested in knowing the truth-values of formulas when these are applied to a new (unseen) set of objects of a domain, such as a validation or a test set of examples typically used in the evaluation of machine learning systems. A generalization truth query is a pair pφ q pxq, U q, where φ q is a formula with a free variable x and U " pu p1q , . . . , u pkq q is a set of unseen examples whose dimensions are compatible with those of the domain of x. The answer to the query pφ q pxq, U q is G θ pφ q pxqq for x taking each value u piq , 1 ď i ď k, in U . The result of this query is therefore a vector of |U | truth-values corresponding to the evaluation of φ q on new data u p1q , . . . , u pkq .</p>
<p>The fourth and final type of query is generalization value queries. These are analogous to generalization truth queries with the difference that they evaluate a term t q pxq, and not a formula, on new data U . The result, therefore, is a vector of |U | values corresponding to the evaluation of the trained model on a regression task using test data U .</p>
<p>Reasoning 3.4.1. Logical consequence in Real Logic</p>
<p>From a pure logic perspective, reasoning is the task of verifying if a formula is a logical consequence of a set of formulas. This can be achieved semantically using model theory (|ù) or syntactically via a proof theory ($). To characterize reasoning in Real Logic, we adapt the notion of logical consequence for fuzzy logic provided in [9]: A formula φ is a fuzzy logical consequence of a finite set of formulas Γ, in symbols Γ |ù φ if for every fuzzy interpretation f , if all the formulas in Γ are true (i.e. evaluate to 1) in f then φ is true in f . In other words, every model of Γ is a model of φ. A direct application of this definition to Real Logic is not practical since in most practical cases the level of satisfiability of a grounded theory pK, G θ q will not be equal to 1. We therefore define an interval rq, 1s with 1 2 ă q ă 1 and assume that a formula is true if its truth-value is in the interval rq, 1s. This leads to the following definition: Definition 6. A closed formula φ is a logical consequence of a knowledge-base pK, Gp¨| θq, Θq, in symbols pK, Gp¨| θq, Θq |ù q φ, if, for every grounded theory K, G θ , if SatAggpK, G θ q ě q then G θ pφq ě q.</p>
<p>Reasoning by optimization</p>
<p>Logical consequence by direct application of Definition 6 requires querying the truth value of φ for a potentially infinite set of groundings. Therefore, we consider in practice the following directions:</p>
<p>Reasoning Option 1 (Querying after learning). This is approximate logical inference by considering only the grounded theories that maximally satisfy pK, Gp¨| θq, Θq. We therefore define that φ is a brave logical consequence of a Real Logic knowledge-base pK, Gp¨| θq, Θq if G θ˚p φq ě q for all the θs uch that:</p>
<p>θ˚" argmax θ SatAggpK, G θ q and SatAggpK, G θ˚q ě q</p>
<p>The objective is to find all θ˚that optimally satisfy the knowledge base and to measure if they also satisfy φ. One can search for such θ˚by running multiple optimizations with the objective function of Section 3.2. This approach is somewhat naive. Even if we run the optimization multiple times with multiple parameter initializations (to, hopefully, reach different optima in the search space), the obtained groundings may not be representative of other optimal or close-to-optimal groundings. In Section 4.8, we give an example that shows the limitations of this approach and motivates the next one.</p>
<p>Reasoning Option 2 (Proof by Refutation). Here, we reason by refutation and search for a counterexample to the logical consequence by introducing an alternative search objective. Normally, according to Definition 6, one tries to verify that: 11
for all θ P Θ, if G θ pKq ě q then G θ pφq ě q.(21)
Instead, we solve the dual problem:</p>
<p>there exists θ P Θ such that G θ pKq ě q and G θ pφq ă q.</p>
<p>If Eq. (22) is true then a counterexample to Eq. (21) has been found and the logical consequence does not hold. If Eq. (22) is false then no counterexample to Eq. (21) has been found and the logical consequence is assumed to hold true. A search for such parameters θ (the counterexample) can be performed by minimizing G θ pφq while imposing a constraint that seeks to invalidate results where G θ pKq ă q. We therefore define:
penaltypG θ , qq " # c if G θ pKq ă q, 0 otherwise, where c ą 1. 12
Given G˚such that:
G˚" argmin G θ pG θ pφq`penaltypG θ , qqq(23)
• If G˚pKq ă q : Then for all G θ , G θ pKq ă q and therefore pK, Gp¨| θq, Θq |ù q φ.</p>
<p>• If G˚pKq ě q and G˚pφq ě q : Then for all G θ with G θ pKq ě q, we have that G θ pφq ě G˚pφq ě q and therefore pK, Gp¨| θq, Θq |ù q φ.</p>
<p>• If G˚pKq ě q and G˚pφq ă q : Then pK, Gp¨| θq, Θq * q φ.</p>
<p>Clearly, Equation (23) cannot be used as an objective function for gradient-descent due to null derivatives. Therefore, we propose to approximate the penalty function with the soft constraint:
elupα, βpq´G θ pKqqq " # βpq´G θ pKqq if G θ pKq ď q, αpe q´G θ pKq´1 q otherwise,
where α ě 0 and β ě 0 are hyper-parameters (see Figure 6). When G θ pKq ă q, the penalty is linear in q´G θ pKq with a slope of β. Setting β high, the gradients for G θ pKq will be high in absolute value if the knowledge-base is not satisfied. When G θ pKq ą q, the penalty is a negative exponential that converges to´α. Setting α low but non-zero seeks to ensure that the gradients do not vanish when the penalty should not apply (when the knowledge-base is satisfied). We obtain the following approximate objective function:
G˚" argmin G θ pG θ pφq`elupα, βpq´G θ pKqqq(24)
Section 4.8 will illustrate the use of reasoning by refutation with an example in comparison with reasoning as querying after learning. Of course, other forms of reasoning are possible, not least that adopted in [6], but a direct comparison is outside the scope of this paper and left as future work.</p>
<p>The Reach of Logic Tensor Networks</p>
<p>The objective of this section is to show how the language of Real Logic can be used to specify a number of tasks that involve learning from data and reasoning. Examples of such tasks are classification, regression, clustering, and link prediction. The solution of a problem specified in Real Logic is obtained by interpreting such a specification in Logic Tensor Networks. The LTN library implements Real Logic in Tensorflow 2 [1] and is available from GitHub 13 . Every logical operator is grounded using Tensorflow primitives such that LTN implements directly a Tensorflow graph. Due to Tensorflow built-in optimization, LTN is relatively efficient while providing the expressive power of first-order logic. Details on the implementation of the examples described in this section are reported in Appendix A. The implementation of the examples presented here is also available from the LTN repository on GitHub. Except when stated otherwise, the results reported are the average result over 10 runs using a 95% confidence interval. Every example uses a stable real product configuration to approximate the Real Logic operators and the Adam optimizer [35] with a learning rate of 0.001. Table A.3 in the Appendix gives an overview of the network architectures used to obtain the results reported in this section.</p>
<p>Binary Classification</p>
<p>The simplest machine learning task is binary classification. Suppose that one wants to learn a binary classifier A for a set of points in r0, 1s 2 . Suppose that a set of positive and negative training examples is given. LTN uses the following language and grounding:</p>
<p>Domains:</p>
<p>points (denoting the examples).</p>
<p>Variables:</p>
<p>x`for the positive examples. x´for the negative examples.</p>
<p>x for all examples. Dpxq " Dpx`q " Dpx´q " points.</p>
<p>Predicates:</p>
<p>Apxq for the trainable classifier. D in pAq " points.</p>
<p>Axioms:
@x<code>Apx</code>q (25) @x´ Apx´q(26)
Grounding:
Gppointsq " r0, 1s 2 . Gpxq P r0, 1s mˆ2 (Gpxq is a sequence of m points, that is, m examples). Gpx`q " d P Gpxq | d´p0.5, 0.5q ă 0.09 . 14 Gpx´q " d P Gpxq | d´p0.5, 0.5q ě 0.09 . 15 GpA | θq : x Þ Ñ sigmoidpMLP θ pxqq,
where MLP is a Multilayer Perceptron with a single output neuron, whose parameters θ are to be learned 16 .</p>
<p>Learning:</p>
<p>Let us define D the data set of all examples. The objective function with K " t@x<code>Apx</code>q, @x´ Apx´qu is given by argmax θPΘ SatAgg φPK G θ,xÐD pφq. 17 In practice, the optimizer uses the following loss function:
L " p1´SatAgg φPK G θ,xÐB pφqq
where B is a mini-batch sampled from D. 18 The objective and loss functions depend on the following hyper-parameters:</p>
<p>• the choice of fuzzy logic operator semantics used to approximate each connective and quantifier, • the choice of hyper-parameters underlying the operators, such as the value of the exponent p in any generalized mean, • the choice of formula aggregator function.</p>
<p>Using the stable product configuration to approximate connectives and quantifiers, and p " 2 for every occurrence of A pM E , and using for the formula aggregator also A pM E with p " 2, yields the following satisfaction equation:
SatAgg φPK G θ pφq "1´1 2´1´´1´´1 |Gpx<code>q| ÿ vPGpx</code>q<code>1´s igmoidpMLP θ pvqq˘2¯1 2¨21´´1´´1 |Gpx´q| ÿ vPGpx´q</code>s igmoidpMLP θ pvqq˘2¯1 2¨2¯¯1 2
14 Gpx<code>q are, by definition in this example, the training examples with Euclidean distance to the center p0.5, 0.5q smaller than the threshold of 0.09. 15 Gpx´q are, by definition, the training examples with Euclidean distance to the centre p0.5, 0.5q larger or equal to the threshold of 0.09. 16 sigmoidpxq " 1 1</code>e´x 17 The notation G xÐD pφpxqq means that the variable x is grounded with the data D (that is, Gpxq :" D) when grounding φpxq. 18 As usual in ML, while it is possible to compute the loss function and gradients over the entire data set, it is preferred to use mini-batches of the examples. The computational graph of Figure 7 shows SatAgg φPK G θ pφqq as used with the above loss function.</p>
<p>We are therefore interested in learning the parameters θ of the MLP used to model the binary classifier. We sample 100 data points uniformly from r0, 1s 2 to populate the data set of positive and negative examples. The data set was split into 50 data points for training and 50 points for testing. The training was carried out for a fixed number of 1000 epochs using backpropagation with the Adam optimizer [35] with a batch size of 64 examples. Figure 8 shows the classification accuracy and satisfaction level of the LTN on both training and test sets averaged over 10 runs using a 95% confidence interval. The accuracy shown is the ratio of examples correctly classified, with an example deemed as being positive if the classifier outputs a value higher than 0.5.</p>
<p>Notice that a model can reach an accuracy of 100% while satisfaction of the knowledge base is yet not maximized. For example, if the threshold for an example to be deemed as positive is 0.7, all examples may be classified correctly with a confidence score of 0.7. In that case, while the accuracy is already maximized, the satisfaction of @x<code>Apx</code>q would still be 0.7, and can still improve until the confidence for every sample reaches 1.0.</p>
<p>This first example, although straightforward, illustrates step-by-step the process of using LTN in a simple setting. Notice that, according to the nomenclature of Section 3.3, measuring accuracy amounts to querying the truth query (respectively, the generalization truth query) Apxq for all the examples of the training set (respectively, test set) and comparing the results with the classification threshold. In Figure 9, we show the results of such queries Apxq after optimization. Next, we show how the LTN language can be used to solve progressively more complex problems by combining learning and reasoning.</p>
<p>Multi-Class Single-Label Classification</p>
<p>The natural extension of binary classification is a multi-class classification task. We first approach multi-class single-label classification, which assumes that each example is assigned to one and only one label.</p>
<p>For illustration purposes, we use the Iris flower data set [20], which consists of classification into three mutually exclusive classes; call these A, B, and C. While one could train three unary predicates Apxq, Bpxq and Cpxq, it turns out to be more effective if this problem is modeled by a single binary predicate P px, lq, where l is a variable denoting a multi-class label, in this case,  Due to the random initializations, accuracy and satisfiability start on average at 0.5 with performance increasing rapidly after a few epochs. classes A, B or C. This syntax allows one to write statements quantifying over the classes, e.g. @xpDlpP px, lqqq. Since the classes are mutually exclusive, the output layer of the MLP representing P px, lq will be a softmax layer, instead of a sigmoid function, to ensure the exclusivity constraint on satisfiability scores. 19 . The problem can be specified as follows:</p>
<p>Domains:</p>
<p>items, denoting the examples from the Iris flower data set. labels, denoting the class labels.</p>
<p>Variables:
x A , x B , x C for the positive examples of classes A, B, C.
x for all examples. Dpx A q " Dpx B q " Dpx C q " Dpxq " items.</p>
<p>Constants:</p>
<p>l A , l B , l C , the labels of classes A (Iris setosa), B (Iris virginica), C (Iris versicolor), respectively. Dpl A q " Dpl B q " Dpl C q " labels.</p>
<p>Predicates:</p>
<p>P px, lq denoting the fact that item x is classified as l. D in pP q " items, labels.</p>
<p>Axioms:
@x A P px A , l A q (27) @x B P px B , l B q (28) @x C P px C , l C q(29)
Notice that rules about exclusiveness such as @xpP px, l A q Ñ p P px, l B q^ P px, l C qqq are not included since such constraints are already imposed by the grounding of P below, more specifically the softmax function. </p>
<p>Grounding:</p>
<p>Gpitemsq " R 4 , items are described by 4 features: the length and the width of the sepals and petals, in centimeters. Gplabelsq " N 3 , we use a one-hot encoding to represent classes.
Gpx A q P R m1ˆ4 , that is, Gpx A q is a sequence of m 1 examples of class A. Gpx B q P R m2ˆ4 , Gpx B q is a sequence of m 2 examples of class B. Gpx C q P R m3ˆ4 , Gpx C q is a sequence of m 3 examples of class C. Gpxq P R pm1<code>m2</code>m3qˆ4 ,
Gpxq is a sequence of all the examples. Gpl A q " r1, 0, 0s, Gpl B q " r0, 1, 0s, Gpl C q " r0, 0, 1s. GpP | θq : x, l Þ Ñ l J¨s oftmaxpMLP θ pxqq, where the MLP has three output neurons corresponding to as many classes, and¨denotes the dot product as a way of selecting an output for GpP | θq; multiplying the MLP's output by the one-hot vector l J gives the truth degree corresponding to the class denoted by l.</p>
<p>Learning:</p>
<p>The logical operators and connectives are approximated using the stable product configuration with p " 2 for A pM E . For the formula aggregator, A pM E is used also with p " 2.</p>
<p>The computational graph of Figure 10 illustrates how SatAgg φPK G θ pφq is obtained. If U denotes batches sampled from the data set of all examples, the loss function (to minimize) is: It is worth contrasting the choice of using a binary predicate pP px, lqq in this example with the option of using multiple unary predicates pl A pxq, l B pxq, l C pxqq, one for each class. Notice how each predicate is normally associated with an output neuron. In the case of the unary predicates, the networks would be disjoint (or modular), whereas weight-sharing takes place with the use of the binary predicate. Since l is instantiated into l A , l B , l C , in practice P px, lq becomes P px, l A q, P px, l B q, P px, l C q, which is implemented via three output neurons to which a softmax function applies.
L " 1´SatAgg φPK G θ,xÐB pφq.</p>
<p>Multi-Class Multi-Label Classification</p>
<p>We now turn to multi-label classification, whereby multiple labels can be assigned to each example. As a first example of the reach of LTNs, we shall see how the previous example can be extended naturally using LTN to account for multiple labels, not always a trivial extension for most ML algorithms. The standard approach to the multi-label problem is to provide explicit negative examples for each class. By contrast, LTN can use background knowledge to relate classes directly  to each other, thus becoming a powerful tool in the case of the multi-label problem when typically the labeled data is scarce. We explore the Leptograpsus crabs data set [10] consisting of 200 examples of 5 morphological measurements of 50 crabs. The task is to classify the crabs according to their color and sex. There are four labels: blue, orange, male, and female. The color labels are mutually exclusive, and so are the labels for sex. LTN will be used to specify such information logically.</p>
<p>Domains:</p>
<p>items denoting the examples from the crabs dataset. labels denoting the class labels.</p>
<p>Variables:</p>
<p>x blue , x orange , x male , x female for the positive examples of each class.</p>
<p>x, used to denote all the examples. Dpx blue q " Dpx orange q " Dpx male q " Dpx female q " Dpxq " items.</p>
<p>Constants:</p>
<p>l blue , l orange , l male , l female (the labels for each class). Dpl blue q " Dpl orange q " Dpl male q " Dpl female q " labels.</p>
<p>Predicates:</p>
<p>P px, lq, denotes the fact that item x is labelled as l. D in pP q " items, labels.</p>
<p>Axioms:</p>
<p>@x blue P px blue , l blue q (30) @x orange P px orange , l orange q (31) @x male P px male , l male q (32) @x female P px female , l female q (33) @x pP px, l blue q^P px, l orange qq (34) @x pP px, l male q^P px, l female qq</p>
<p>Notice how logical rules 34 and 35 above represent the mutual exclusion of the labels on colour and sex, respectively. As a result, negative examples are not used explicitly in this specification.</p>
<p>Grounding:</p>
<p>Gpitemsq " R 5 ; the examples from the data set are described using 5 features. Gplabelsq " N 4 ; one-hot vectors are used to represent class labels. 21 Gpx blue q P R m1ˆ5 , Gpx orange q P R m2ˆ5 , Gpx male q P R m3ˆ5 , Gpx female q P R m4ˆ5 . These sequences are not mutually-exclusive, one example can for instance be in both x blue and x male . Gpl blue q " r1, 0, 0, 0s, Gpl orange q " r0, 1, 0, 0s,Gpl male q " r0, 0, 1, 0s,Gpl female q " r0, 0, 0, 1s.</p>
<p>GpP | θq : x, l Þ Ñ l J¨s igmoidpMLP θ pxqq, with the MLP having four output neurons corresponding to as many classes. As before,¨denotes the dot product which selects a single output. By contrast with the previous example, notice the use of a sigmoid function instead of a softmax function.</p>
<p>Learning:</p>
<p>As before, the fuzzy logic operators and connectives are approximated using the stable product configuration with p " 2 for A pM E , and for the formula aggregator, A pM E is also used with p " 2. Figure 12 shows the result of the Adam optimizer using backpropagation trained with batches of 64 examples. This time, the accuracy is defined as 1´HL, where HL is the average Hamming loss, i.e. the fraction of labels predicted incorrectly, with a classification threshold of 0.5 (given an example u, if the model outputs a value greater than 0.5 for class C then u is deemed as belonging to class C). The rightmost graph in Figure 12 illustrates how LTN learns the constraint that a crab cannot have both blue and orange color, which is discussed in more detail in what follows.</p>
<p>Querying:</p>
<p>To illustrate the learning of constraints by LTN, we have queried three formulas that were not explicitly part of the knowledge-base, over time during learning:
φ 1 : @x pP px, l blue q Ñ P px, l orange qq (36) φ 2 :
@x pP px, l blue q Ñ P px, l orange qq (37) φ 3 : @x pP px, l blue q Ñ P px, l male qq</p>
<p>For querying, we use p " 5 when approximating the universal quantifiers with A pM E . A higher p denotes a stricter universal quantification with a stronger focus on outliers (see Section 2.4). 22 We should expect φ 1 to hold true (every blue crab cannot be orange and vice-versa 23 , and we should expect φ 2 (every blue crab is also orange) and φ 3 (every blue crab is male) to be false. The results are reported in the rightmost plot of Figure 12. Prior to training, the truth-values of φ 1 to φ 3 are non-informative. During training one can see, with the maximization of the satisfaction of the knowledge-base, a trend towards the satisfaction of φ 1 , and an opposite trend of φ 2 and φ 3 towards false.</p>
<p>Semi-Supervised Pattern recognition</p>
<p>Let us now explore two, more elaborate, classification tasks, which showcase the benefit of using logical reasoning alongside machine learning. With these two examples, we also aim to provide a more direct comparison with a related neurosymbolic system DeepProbLog [41]. The benchmark examples below were introduced in the DeepProbLog paper [41]. 22 Training should usually not focus on outliers, as optimizers would struggle to generalize and tend to get stuck in local minima. However, when querying φ 1 ,φ 2 ,φ 3 , we wish to be more careful about the interpretation of our statement. See also 3.1.3. 23 Notice how, strictly speaking, other colours remain possible since the prior knowledge did not specify the bi-conditional: @x pP px, l blue q Ø P px, lorangeqq Single Digits Addition: Consider the predicate additionpX, Y, Nq, where X and Y are images of digits (the MNIST data set will be used), and N is a natural number corresponding to the sum of these digits. This predicate should return an estimate of the validity of the addition. For instance, additionp , , 11q is a valid addition; additionp , , 5q is not.</p>
<p>Multi Digits Addition:</p>
<p>The experiment is extended to numbers with more than one digit. Consider the predicate additionprX 1 , X 2 s, rY 1 , Y 2 s, Nq. rX 1 , X 2 s and rY 1 , Y 2 s are lists of images of digits, representing two multi-digit numbers; N is a natural number corresponding to the sum of the two multi-digit numbers. For instance, additionpr , s, r , s, 130q is a valid addition; additionpr , s, r , s, 26q is not.</p>
<p>A natural neurosymbolic approach is to seek to learn a single-digit classifier and benefit from knowledge readily available about the properties of addition in this case. For instance, suppose that a predicate digitpx, dq gives the likelihood of an image x being of digit d. A definition for additionp , , 11q in LTN is:
Dd 1 , d 2 : d 1`d2 " 11 pdigitp , d 1 q^digitp , d 2 qq
In [41], the above task is made more complicated by not providing labels for the single-digit images during training. Instead, training takes place on pairs of images with labels made available for the result only, that is, the sum of the individual labels. The single-digit classifier is not explicitly trained by itself; its output is a piece of latent information that is used by the logic. However, this does not pose a problem for end-to-end neurosymbolic systems such as LTN or DeepProbLog for which the gradients can propagate through the logical structures.</p>
<p>We start by illustrating a LTN theory that can be used to learn the predicate digit. The specification of the theory below is for the single digit addition example, although it can be extended easily to the multiple digits case.</p>
<p>Domains:</p>
<p>images, denoting the MNIST digit images, results, denoting the integers that label the results of the additions, digits, denoting the digits from 0 to 9.</p>
<p>Variables:</p>
<p>x, y, ranging over the MNIST images in the data, n for the labels, i.e. the result of each addition, d 1 , d 2 ranging over digits.</p>
<p>Dpxq " Dpyq " images, Dpnq " results, Dpd 1 q " Dpd 2 q " digits.</p>
<p>Predicates:</p>
<p>digitpx, dq for the single digit classifier, where d is a term denoting a digit constant or a digit variable. The classifier should return the probability of an image x being of digit d. D in pdigitq " images, digits.</p>
<p>Axioms:</p>
<p>Single Digit Addition:</p>
<p>@Diagpx, y, nq
pDd 1 , d 2 : d 1<code>d2 " n (39) pdigitpx, d 1 q^digitpy, d 2 qqq
Multiple Digit Addition:
@Diagpx 1 , x 2 , y 1 , y 2 , nq pDd 1 , d 2 , d 3 , d 4 : 10d 1</code>d2<code>1 0d 3</code>d4 " n (40) pdigitpx 1 , d 1 q^digitpx 2 , d 2 q^digitpy 1 , d 3 q^digitpy 2 , d 4 qqq
Notice the use of Diag: when grounding x,y,n with three sequences of values, the i-th examples of each variable are matching. That is, pGpxq i , Gpyq i , Gpnq i q is a tuple from our dataset of valid additions. Using the diagonal quantification, LTN aggregates pairs of images and their corresponding result, rather than any combination of images and results.</p>
<p>Notice also the guarded quantification: by quantifying only on the latent "digit labels" (i.e. d 1 ,d 2 , . . . ) that can add up to the result label (n, given in the dataset), we incorporate symbolic information into the system. For example, in (39), if n " 3, the only valid tuples pd 1 , d 2 q are p0, 3q, p3, 0q, p1, 2q, p2, 1q. Gradients will only backpropagate to these values.</p>
<p>Grounding:</p>
<p>Gpimagesq " r0, 1s 28ˆ28ˆ1 . The MNIST data set has images of 28 by 28 pixels. The images are grayscale and have just one channel. The RGB pixel values from 0 to 255 of the MNIST data set are converted to the range r0, 1s. Gpresultsq " N.</p>
<p>Gpdigitsq " t0, 1, . . . , 9u. Gpxq P r0, 1s mˆ28ˆ28ˆ1 , Gpyq P r0, 1s mˆ28ˆ28ˆ1 , Gpnq P N m . 24 Gpd 1 q " Gpd 2 q " 0, 1, . . . , 9 . Gpdigit | θq : x, d Þ Ñ onehotpdq J¨s oftmaxpCNN θ pxqq, where CNN is a Convolutional Neural Network with 10 output neurons for each class. Notice that, in contrast with the previous examples, d is an integer label; onehotpdq converts it into a one-hot label.</p>
<p>Learning:</p>
<p>The computational graph of Figure 13 shows the objective function for the satisfiability of the knowledge base. A stable product configuration is used with hyper-parameter p " 2 of the operator A pM E for universal quantification (@). Let p D denote the exponent hyper-parameter used in the generalized mean A pM for existential quantification (D). Three scenarios are investigated and compared in the Multiple Digit experiment ( Figure 15):</p>
<ol>
<li>p D " 1 throughout the entire experiment, 2. p D " 2 throughout the entire experiment, or 3. p D follows a schedule, changing from p " 1 to p " 6 gradually with the number of training epochs.</li>
</ol>
<p>In the Single Digit experiment, only the last scenario above (schedule) is investigated ( Figure  14).</p>
<p>We train to maximize satisfiability by using batches of 32 examples of image pairs, labeled by the result of their addition. As done in [41], the experimental results vary the number of examples in the training set to emphasize the generalization abilities of a neurosymbolic approach. Accuracy is measured by predicting the digit values using the predicate digit and reporting the ratio of examples for which the addition is correct. A comparison is made with the same baseline method used in [41]: given a pair of MNIST images, a non-pre-trained CNN outputs embeddings for each image (Siamese neural network). The embeddings are provided as input to dense layers that classify the addition into one of the 19 (respectively, 199) possible results of the Single Digit Addition (respectively, Multiple Digit Addition) experiments. The baseline is trained using a cross-entropy loss between the labels and the predictions. As expected, such a standard deep learning approach struggles with the task without the provision of symbolic meaning about intermediate parts of the problem.</p>
<p>Experimentally, we find that the optimizer for the neurosymbolic system gets stuck in a local optimum at the initialization in about 1 out of 5 runs. We, therefore, present the results on an average of the 10 best outcomes out of 15 runs of each algorithm (that is, for the baseline as well). The examples of digit pairs selected from the full MNIST data set are randomized at each run. Figure 15 shows that the use of p D " 2 from the start produces poor results. A higher value for p D in A pM weighs up the instances with a higher truth-value (see also Appendix C for a discussion). Starting already with a high value for p D , the classes with a higher initial truthvalue for a given example will have higher gradients and be prioritized for training, which does not make practical sense when randomly initializing the predicates. Increasing p D by following a schedule is the most promising approach. In this particular example, p D " 1 is also shown to be adequate purely from a learning perspective. However, p D " 1 implements a simple average which does not account for the meaning of D well; the resulting satisfaction value is not meaningful within a reasoning perspective. Table 1 shows that the training and test times of LTN are of the same order of magnitude as those of the CNN baselines. Table 2 shows that LTN reaches similar accuracy as that reported by DeepProbLog.</p>
<p>one-hot selection    </p>
<p>Regression</p>
<p>Another important problem in Machine Learning is regression where a relationship is estimated between one independent variable X and a continuous dependent variable Y . The essence of regression is, therefore, to approximate a function f pxq " y by a function f˚, given examples px i , y i q such that f px i q " y i . In LTN one can model a regression task by defining f˚as a learnable function whose parameter values are constrained by data. Additionally, a regression task requires a notion of equality. We, therefore, define the predicate eq as a smooth version of the symbol " to turn the constraint f px i q " y i into a smooth optimization problem.</p>
<p>In this example, we explore regression using a problem from a real estate data set 25 with 414 examples, each described in terms of 6 real-numbered features: the transaction date (converted to a float), the age of the house, the distance to the nearest station, the number of convenience stores in the vicinity, and the latitude and longitude coordinates. The model has to predict the house price per unit area.</p>
<p>Domains:</p>
<p>samples, denoting the houses and their features. prices, denoting the house prices.</p>
<p>Variables:</p>
<p>x for the samples. y for the prices. Dpxq " samples. Dpyq " prices. </p>
<p>Functions:</p>
<p>f˚pxq, the regression function to be learned. D in pf˚q " samples, D out pf˚q " prices.</p>
<p>Predicates: eqpy 1 , y 2 q, a smooth equality predicate that measures how similar y 1 and y 2 are. D in peqq " prices, prices.</p>
<p>Axioms:</p>
<p>@Diagpx, yq eqpf˚pxq, yq</p>
<p>Notice again the use of Diag: when grounding x and y onto sequences of values, this is done by obeying a one-to-one correspondence between the sequences. In other words, we aggregate pairs of corresponding samples and prices, instead of any combination thereof.</p>
<p>Grounding:</p>
<p>Gpsamplesq " R 6 . Gppricesq " R. Gpxq P R mˆ6 , Gpyq P R mˆ1 . Notice that this specification refers to the same number m of examples for x and y due to the above one-to-one correspondence obtained with the use of Diag. Gpeqpu, vqq " exp`´α b ř j pu j´vj q 2˘, where the hyper-parameter α is a real number that scales how strict the smooth equality is. 26 In our experiments, we use α " 0.05. Gpf˚pxq | θq " MLP θ pxq, where MLP θ is a multilayer perceptron which ends in one neuron corresponding to a price prediction, with a linear output layer (no activation function).</p>
<p>Learning:</p>
<p>The theory is constrained by the parameters of the model of f˚. LTN is used to estimate such parameters by maximizing the satisfaction of the knowledge-base, in the usual way. Approximating @ using A pM E with p " 2, as before, we randomly split the data set into 330 examples for training and 84 examples for testing. Figure 16 shows the satisfaction level over 500 epochs. We also plot the Root Mean Squared Error (RMSE) between the predicted prices and the labels (i.e. actual prices, also known as target values). We visualize in Figure 17 the strong correlation between actual and predicted prices at the end of one of the runs.</p>
<p>Unsupervised Learning (Clustering)</p>
<p>In unsupervised learning, labels are either not available or are not used for learning. Clustering is a form of unsupervised learning whereby, without labels, the data is characterized by constraints 26 Intuitively, the smooth equality is expp´α dpu, vqq, where dpu, vq is the Euclidean distance between u and v. It produces a 1 if the distance is zero; as the distance increases, the result decreases exponentially towards 0. In case an exponential decrease is undesirable, one can adopt the following alternative equation: eqpu, vq " alone. LTN can formulate such constraints, such as:</p>
<p>• clusters should be disjoint,</p>
<p>• every example should be assigned to a cluster,</p>
<p>• a cluster should not be empty,</p>
<p>• if the points are near, they should belong to the same cluster,</p>
<p>• if the points are far, they should belong to different clusters, etc.</p>
<p>Domains:</p>
<p>points, denoting the data to cluster. points_pairs, denoting pairs of examples. clusters, denoting the cluster.</p>
<p>Variables:</p>
<p>x, y for all points.</p>
<p>Dpxq " Dpyq " points.</p>
<p>Dpcq " clusters.</p>
<p>Predicates:</p>
<p>Cpx, cq, the truth degree of a given point belonging in a given cluster. D in pCq " points, clusters.</p>
<p>Axioms:</p>
<p>@x Dc Cpx, cq (42) @c Dx Cpx, cq (43) @pc, x, y : |x´y| ă th close q pCpx, cq Ø Cpy, cqq (44) @pc, x, y : |x´y| ą th distant q pCpx, cq^Cpy, cqq</p>
<p>Notice the use of guarded quantifiers: all the pairs of points with Euclidean distance lower (resp. higher) than a value th close (resp. th distant ) should belong in the same cluster (resp. should not). th close and th distant are arbitrary threshold values that define some of the closest and most distant pairs of points. In our example, they are set to, respectively, 0.2 and 1.0. As done in the example of Section 4.2, the clustering predicate has mutually exclusive satisfiability scores for each cluster using a softmax layer. Therefore, there is no explicit constraint about clusters being disjoint.</p>
<p>Grounding:</p>
<p>Gppointsq " r´1, 1s 2 .</p>
<p>Gpclustersq " N 4 , we use one-hot vectors to represent a choice of 4 clusters. Gpxq P r´1, 1s mˆ2 , that is, x is a sequence of m points. Gpyq " Gpxq. th close " 0.2, th distant " 1.0.</p>
<p>Gpcq " r1, 0, 0, 0s, r0, 1, 0, 0s, r0, 0, 1, 0s, r0, 0, 0, 1s . GpC | θq : x, c Þ Ñ c J¨s oftmaxpMLP θ pxqq, where MLP has 4 output neurons corresponding to the 4 clusters. </p>
<p>Learning:</p>
<p>We use the stable real product configuration to approximate the logical operators. For @, we use A pM E with p " 4. For D, we use A pM with p " 1 during the first 100 epochs, and p " 6 thereafter, as a simplified version of the schedule used in Section 4.4. The formula aggregator is approximated by A pM E with p " 2. The model is trained for a total of 1000 epochs using the Adam optimizer, which is sufficient for LTN to solve the clustering problem shown in Figure 18. Ground-truth data for this task was generated artificially by creating 4 centers, and generating 50 random samples from a multivariate Gaussian distribution around each center. The trained LTN achieves a satisfaction level of the clustering constraints of 0.857.</p>
<p>Learning Embeddings with LTN</p>
<p>A classic example of Statistical Relational Learning is the smokers-friends-cancer example introduced in [55]. Below, we show how this example can be formalized in LTN using semisupervised embedding learning.</p>
<p>There are 14 people divided into two groups ta, b, . . . , hu and ti, j, . . . , nu. Within each group, there is complete knowledge about smoking habits. In the first group, there is complete knowledge about who has and who does not have cancer. Knowledge about the friendship relation is complete within each group only if symmetry is assumed, that is, @x, y pf riendspx, yq Ñ f riendspy, xqq.</p>
<p>Otherwise, knowledge about friendship is incomplete in that it may be known that e.g. a is a friend of b, and it may be not known whether b is a friend of a. Finally, there is general knowledge about smoking, friendship, and cancer, namely that smoking causes cancer, friendship is normally symmetric and anti-reflexive, everyone has a friend, and smoking propagates (actively or passively) among friends. All this knowledge is represented in the axioms further below.</p>
<p>Domains:</p>
<p>people, to denote the individuals.</p>
<p>Constants:</p>
<p>a, b, . . . , h, i, j, . . . , n, the 14 individuals. Our goal is to learn an adequate embedding for each constant.</p>
<p>Dpaq " Dpbq "¨¨¨" Dpnq " people.</p>
<p>Variables:</p>
<p>x,y ranging over the individuals. Dpxq " Dpyq " people.</p>
<p>Predicates:</p>
<p>Spxq for smokes, F px, yq for friends, Cpxq for cancer. DpSq " DpCq " people. DpF q " people, people.</p>
<p>Axioms:</p>
<p>Let X 1 " ta, b, . . . , hu and X 2 " ti, j, . . . , nu be the two groups of individuals. Let S " ta, e, f, g, j, nu be the smokers; knowledge is complete in both groups. Let C " ta, eu be the individuals with cancer; knowledge is complete in X 1 only. Let F " tpa, bq, pa, eq, pa, f q, pa, gq, pb, cq, pc, dq, pe, f q, pg, hq, pi, jq, pj, mq, pk, lq, pm, nqu be the set of friendship relations; knowledge is complete if assuming symmetry. These facts are illustrated in Figure 20a. We have the following axioms:
F pu, vq for pu, vq P F (46) F pu, vq for pu, vq R F, u ą v (47) Spuq for u P S (48) Spuq for u P pX 1 Y X 2 qzS (49) Cpuq for u P C (50) Cpuq for u P X 1 zC (51) @x F px, xq (52) @x, y pF px, yq Ñ F py, xqq (53) @xDy F px, yq (54) @x, y ppF px, yq^Spxqq Ñ Spyqq (55) @x pSpxq Ñ Cpxqq (56) @x p Cpxq Ñ Spxqq(57)
Notice that the knowledge base is not satisfiable in the strict logical sense of the word. For instance, f is said to smoke but not to have cancer, which is inconsistent with the rule @x pSpxq Ñ Cpxqq. Hence, it is important to adopt a fuzzy approach as done with MLN or a many-valued fuzzy logic interpretation as done with LTN.</p>
<p>Grounding:</p>
<p>Gppeopleq " R 5 . The model is expected to learn embeddings in R 5 . Gpa | θq " v θ paq, . . . , Gpn | θq " v θ pnq. Every individual is associated with a vector of 5 real numbers. The embedding is initialized randomly uniformly. Gpx | θq " Gpy | θq " v θ paq, . . . , v θ pnq . GpS | θq : x Þ Ñ sigmoidpMLP_S θ pxqq, where MLP_S θ has 1 output neuron. GpF | θq : x, y Þ Ñ sigmoidpMLP_F θ px, yqq, where MLP_F θ has 1 output neuron. GpC | θq : x Þ Ñ sigmoidpMLP_C θ pxqq, where MLP_C θ has 1 output neuron. The MLP models for S, F , C are kept simple, so that most of the learning is focused on the embedding.</p>
<p>Learning:</p>
<p>We use the stable real product configuration to approximate the operators. For @, we use A pM E with p " 2 for all the rules, except for rules (52) and (53), where we use p " 6. The intuition behind this choice of p is that no outliers are to be accepted for the friendship relation since it is expected to be symmetric and anti-reflexive, but outliers are accepted for the other rules. For D, we use A pM with p " 1 during the first 200 epochs of training, and p " 6 thereafter, with the same motivation as that of the schedule used in Section 4.4. The formula aggregator is approximated by A pM E with p " 2. Figure 19 shows the satisfiability over 1000 epochs of training. At the end of one of these runs, we query Spxq, F px, yq, Cpxq for each individual; the results are shown in Figure 20b. We also plot the principal components of the learned embeddings [51] in Figure 21. The friendship relations are learned as expected: (56) "smoking implies cancer" is inferred for group 2 even though such information was not present in the knowledge base. For group 1, the given facts for smoking and cancer for the individuals f and g are slightly altered, as these were inconsistent with the rules. (the rule for smoking propagating via friendship (55) is incompatible with many of the given facts). Increasing the satisfaction of this rule would require decreasing the overall satisfaction of the knowledge base, which explains why it is partly ignored by LTN during training. Finally, it is interesting to note that the principal components for the learned embeddings seem to be linearly separable for the smoking and cancer classifiers (c.f. Figure 21, top right and bottom right plots).</p>
<p>Querying:</p>
<p>To illustrate querying in LTN, we query over time two formulas that are not present in the knowledge-base:
φ 1 : @p :Cppq Ñ Sppq (58) φ 2 : @p, q :pCppq _ Cpqqq Ñ F pp, qq(59)
We use p " 5 when approximating @ since the impact of an outlier at querying time should be seen as more important than at learning time. It can be seen that as the grounding approaches satisfiability of the knowledge-base, φ 1 approaches true, whereas φ 2 approaches false (c.f. Figure 20a).   </p>
<p>Reasoning in LTN</p>
<p>The essence of reasoning is to find out if a closed formula φ is the logical consequence of a knowledge-base pK, G θ , Θq. Section 3.4 introduced two approaches to this problem in LTN:</p>
<p>• By simply querying after learning 27 one seeks to verify if for the grounded theories that maximally satisfy K, the grounding of φ gives a truth-value greater than a threshold q. This often requires checking an infinite number of groundings. Instead, the user approximates the search for these grounded theories by running the optimization a fixed number of times only.</p>
<p>• Reasoning by refutation one seeks to find out a counter-example: a grounding that satisfies the knowledge-base K but not the formula φ given the threshold q. A search is performed here using a different objective function.</p>
<p>We now demonstrate that reasoning by refutation is the preferred option using a simple example where we seek to find out whether pA _ Bq |ù q A.</p>
<p>Propositional Variables:</p>
<p>The symbols A and B denote two propositionial variables.</p>
<p>Axioms:</p>
<p>A _ B (60) 27 Here, learning refers to Section 3.2, which is optimizing using the satisfaction of the knowledge base as an objective. </p>
<p>Grounding:</p>
<p>GpAq " a, GpBq " b, where a and b are two real-valued parameters. The set of parameters is therefore θ " ta, bu. At initialization, a " b " 0.</p>
<p>We use the probabilistic-sum S P to approximate _, resulting in the following satisfiability measure: 28 G θ pKq " G θ pA _ Bq " a`b´ab.</p>
<p>There are infinite global optima maximizing the satisfiability of the theory, as any G θ such that G θ pAq " 1 (resp. G θ pBq " 1) gives a satisfiability G θ pKq " 1 for any value of G θ pBq (resp. G θ pAq). As expected, the following groundings are examples of global optima:
G 1 : G 1 pAq " 1, G 1 pBq " 1, G 1 pKq " 1, G 2 : G 2 pAq " 1, G 2 pBq " 0, G 2 pKq " 1,
G 3 : G 3 pAq " 0, G 3 pBq " 1, G 3 pKq " 1.</p>
<p>Reasoning:</p>
<p>pA _ Bq |ù q A? That is, given the threshold q " 0.95, does every G θ such that G θ pKq ě q verify G θ pφq ě q. Immediately, one can notice that this is not the case. For instance, the grounding G 3 is a counter-example.</p>
<p>If one simply reasons by querying multiple groundings after learning with the usual objective argmax pG θ q G θ pKq, the results will all converge to G 1 : BG θ pKq Ba " 1´b and BG θ pKq Bb " 1´a. Every run of the optimizer will increase a and b simultaneously until they reach the optimum a " b " 1. Because the grid search always converges to the same point, no counter-example is found and the logical consequence is mistakenly assumed true. This is illustrated in Figure  22.</p>
<p>Reasoning by refutation, however, the objective function has an incentive to find a counterexample with A, as illustrated in Figure 23. LTN converges to the optimum G 3 , which refutes the logical consequence.  Figure 23: Reasoning by refutation: one run of the optimizer with objective G˚" argmin G θ pG θ pφq`elupα, βpq´G θ pKqqq, q " 0.95, α " 0.05, β " 10. In the first training epochs, the directed search prioritizes the satisfaction of the knowledge base. Then, the minimization of G θ pφq starts to weigh in more and the search focuses on finding a counter-example. Eventually, the run converges to the optimum G 3 , which refutes the logical consequence.</p>
<p>Related Work</p>
<p>The past years have seen considerable work aiming to integrate symbolic systems and neural networks. We shall focus on work whose objective is to build computational models that integrate deep learning and logical reasoning into a so-called end-to-end (fully differentiable) architecture. We summarize a categorization in Figure 24 where the class containing LTN is further expanded into three sub-classes. The sub-class highlighted in red is the one that contains LTN. The reason why one may wish to combine symbolic AI and neural networks into a neurosymbolic AI system may vary, c.f. [17] for a recent comprehensive overview of approaches and challenges for neurosymbolic AI.</p>
<p>Neural architectures for logical reasoning</p>
<p>These use neural networks to perform (probabilistic) inference on logical theories. Early work in this direction has shown correspondences between various logical-symbolic systems and neural network models [27,32,52,63,65]. They have also highlighted the limits of current neural networks as models for knowledge representation. In a nutshell, current neural networks (including deep learning) have been shown capable of representing propositional logic, nonmonotonic logic programming, propositional modal logic, and fragments of first-order logic, but not full first-order or higher-order logic. Recently, there has been a resurgence of interest in the topic with many proposals emerging [13,48,53]. In [13], each clause of a Stochastic Logic Program is converted into a factor graph with reasoning becoming differentiable so that it can be implemented by deep networks. In [49], a differentiable unification algorithm is introduced with theorem proving sought to be carried out inside the neural network. Furthermore, in [11,49] neural networks are used to learn reasoning strategies and logical rule induction.</p>
<p>Reasoning with LTN (Section 3.4) is reminiscent of this category, given that knowledge is not represented in a traditional logical language but in Real Logic.</p>
<p>Logical specification of neural network architectures</p>
<p>Here the goal is to use a logical language to specify the architecture of a neural network. Examples include [13,24,26,56,66]. In [26], the languages of extended logic programming (logic programs with negation by failure) and answer set programming are used as background knowledge to set up the initial architecture and set of weights of a recurrent neural network, which is subsequently trained from data using backpropagation. In [24], first-order logic programs in the form of Horn clauses are used to define a neural network that can solve Inductive Logic Programming tasks, starting from the most specific hypotheses covering the set of examples. Lifted relational neural networks [66] is a declarative framework where a Datalog program is used as a compact specification of a diverse range of existing advanced neural architectures, with a particular focus on Graph Neural Networks (GNNs) and their generalizations. In [56] a weighted Real Logic is introduced and used to specify neurons in a highly modular neural network that resembles a tree structure, whereby neurons with different activation functions are used to implement the different logic operators.</p>
<p>To some extent, it is also possible to specify neural architectures using logic in LTN. For example, a user can define a classifier P px, yq as the formula P px, yq " pQpx, yq^Rpyqq _ Spx, yq. GpP q becomes a computational graph that combines the sub-architectures GpQq, GpRq, and GpSq according to the syntax of the logical formula.</p>
<p>Neurosymbolic architectures for the integration of inductive learning and deductive reasoning</p>
<p>These architectures seek to enable the integration of inductive and deductive reasoning in a unique fully differentiable framework [15,23,41,46,47]. The systems that belong to this class combine a neural component with a logical component. The former consists of one or more neural networks, the latter provides a set of algorithms for performing logical tasks such as model checking, satisfiability, and logical consequence. These two components are tightly integrated so that learning and inference in the neural component are influenced by reasoning in the logical component and vice versa. Logic Tensor Networks belong to this category. Neurosymbolic architectures for integrating learning and reasoning can be further separated into three sub-classes:</p>
<ol>
<li>
<p>Approaches that introduce additional layers to the neural network to encode logical constraints which modify the predictions of the network. This sub-class includes Deep Logic Models [46] and Knowledge Enhanced Neural Networks [15].</p>
</li>
<li>
<p>Approaches that integrate logical knowledge as additional constraints in the objective function or loss function used to train the neural network (LTN and [23,33,47]).</p>
</li>
<li>
<p>Approaches that apply (differentiable) logical inference to compute the consequences of the predictions made by a set of base neural networks. Examples of this sub-class are DeepProblog [41] and Abductive Learning [14].</p>
</li>
</ol>
<p>In what follows, we revise recent neurosymbolic architectures in the same class as LTN: Integrating learning and reasoning.</p>
<p>Systems that modify the predictions of a base neural network:. Among the approaches that modify the predictions of the neural network using logical constraints are Deep Logic Models [46] and Knowledge Enhanced Neural Networks [15]. Deep Logic Models (DLM) are a general architecture for learning with constraints. Here, we will consider the special case where constraints are expressed by logical formulas. In this case, a DLM predicts the truth-values of a set of n ground atoms of a domain ∆ " ta 1 , . . . , a k u. It consists of two models: a neural network f px | wq which takes as input the features x of the elements of ∆ and produces as output an evaluation f for all the ground atoms, i.e. f P r0, 1s n , and a probability distribution ppy | f , λq which is modeled by an undirected graphical model of the exponential family with each logical constraint characterized by a clique that contains the ground atoms, rather similarly to GNNs. The model returns the assignment to</p>
<p>Neuro-symbolic architectures</p>
<p>Neural architectures for logical reasoning [13,27,31,48,53,57,71] Architectures integrating learning and reasoning</p>
<p>Modify the predictions of a neural network using logical knowledge [15,46] Encode the satisfiability of logical knowledge in the loss function: LTN and [23,33,47,72] Use of logical knowledge in addition to neural predictions [14,41] Logical specification of neural networks: LTN and [24,26,56,66]  the atoms that maximize the weighted truth-value of the constraints and minimize the difference between the prediction of the neural network and a target value y. Formally:
DLMpx | λ, wq " argmax y˜ÿ c λ c Φ c py c q´1 2 ||y´f px | wq|| 2Ȩ
ach Φ c py c q corresponds to a ground propositional formula which is evaluated w.r.t. the target truth assignment y, and λ c is the weight associated with formula Φ c . Intuitively, the upper model (the undirected graphical model) should modify the prediction of the lower model (the neural network) minimally to satisfy the constraints. f and y are truth-values of all the ground atoms obtained from the constraints appearing in the upper model in the domain specified by the data input.</p>
<p>Similar to LTN, DLM evaluates constraints using fuzzy semantics. However, it considers only propositional connectives, whereas universal and existential quantifiers are supported in LTN.</p>
<p>Inference in DLM requires maximizing the prediction of the model, which might be prohibitive in the presence of a large number of instances. In LTN, inference involves only a forward pass through the neural component which is rather simple and can be carried out in parallel. However, in DLM the weight associated with constraints can be learned, while in LTN they are specified in the background knowledge.</p>
<p>The approach taken in Knowledge Enhanced Neural Networks (KENN) [15] is similar to that of DLM. Starting from the predictions y " f nn px | wq made by a base neural network f nn p¨| wq, KENN adds a knowledge enhancer, which is a function that modifies y based on a set of weighted constraints formulated in terms of clauses. The formal model can be specified as follows:
KENNpx | λ, wq " σpf 1 nn px | wq`ÿ c λ c¨p softmaxpsignpcq d f 1 nn px | wqq d signpcqqq
where f 1 nn px | wq are the pre-activations of f nn px | wq, signpcq is a vector of the same dimension of y containing 1,´1 and´8, such that signpcq i " 1 (resp. signpcq i "´1) if the i-th atom occurs positively (resp. negatively) in c, or´8 otherwise, and d is the element-wise product. KENN learns the weights λ of the clauses in the background knowledge and the base network parameters w by minimizing some standard loss, (e.g. cross-entropy) on a set of training data. If the training data is inconsistent with the constraint, the weight of the constraint will be close to zero. This intuitively implies that the latent knowledge present in the data is preferred to the knowledge specified in the constraints. In LTN, instead, training data and logical constraints are represented uniformly with a formula, and we require that they are both satisfied. A second difference between KENN and LTN is the language: while LTN supports constraints written in full first-order logic, constraints in KENN are limited to universally quantified clauses.</p>
<p>Systems that add knowledge to a neural network by adding a term to the loss function:. In [33], a framework is proposed that learns simultaneously from labeled data and logical rules. The proposed architecture is made of a student network f nn and a teacher network, denoted by q. The student network is trained to do the actual predictions, while the teacher network encodes the information of the logical rules. The transfer of information from the teacher to the student network is done by defining a joint loss L for both networks as a convex combination of the loss of the student and the teacher. Ifỹ " f nn px | wq is the prediction of the student network for input x, the loss is defined as:</p>
<p>p1´πq¨L py,ỹq`π¨L pqpỹ | xq,ỹq where qpỹ | xq " exp p´ř c λ c p1´φ c px,ỹqqq measures how much the predictionsỹ satisfy the constraints encoded in the set of clauses tλ c : φ c u cPC . Training is iterative. At every iteration, the parameters of the student network are optimized to minimize the loss that takes into account the feedback of the teacher network on the predictions from the previous step. The main difference between this approach and LTN is how the constraints are encoded in the loss. LTN integrates the constraints in the network and optimizes directly their satisfiability with no need for additional training data. Furthermore, the constraints proposed in [33] are universally quantified formulas only.</p>
<p>The approach adopted by L [47] is analogous to the first version of LTN [61]. Logical constraints are translated into a loss function that measures the (negative) satisfiability level of the network. Differently from LTN, formulas in L can be associated with weights that are hyperparameters. In [47], a logarithmic loss function is also used when the product t-norm is adopted. Notice that weights can also be added (indirectly) to LTN by introducing a 0-ary predicate p w to represent a constraint of the form p w^φ . An advantage of this approach would be that the weights could be learned.</p>
<p>In [72], a neural network computes the probability of some events being true. The neural network should satisfy a set of propositional logic constraints on its output. These constraints are compiled into arithmetic circuits for weighted model counting, which are then used to compute a loss function. The loss function then captures how close the neural network is to satisfying the propositional logic constraints.</p>
<p>Systems that apply logical reasoning on the predictions of a base neural network:. The most notable architecture in this category is DeepProblog [41]. DeepProblog extends the ProbLog framework for probabilistic logic programming to allow the computation of probabilistic evidence from neural networks. A ProbLog program is a logic program where facts and rules can be associated with probability values. Such values can be learned. Inference in ProbLog to answer a query q is performed by knowledge compilation into a function ppq | λq that computes the probability that q is true according to the logic program with relative frequencies λ. In DeepProbLog, a neural network f nn that outputs a probability distribution t " pt 1 , . . . , t n q over a set of atoms a " pa 1 , . . . , a n q is integrated into ProbLog by extending the logic program with a and the respective probabilities t. The probability of a query q is then given by p 1 pq | λ, f nn px | wqq, where x is the input of f nn and p 1 is the function corresponding to the logic program extended with a. Given a set of queries q, input vectors x and ground-truths y for all the queries, training is performed by minimizing a loss function that measures the distance between the probabilities predicted by the logic program and the ground-truths, as follows:</p>
<p>L py, p 1 pq | λ, f nn px | wqqq</p>
<p>The most important difference between DeepProbLog and LTN concerns the logic on which they are based. DeepProbLog adopts probabilistic logic programming. The output of the base neural network is interpreted as the probability of certain atoms being true. LTN instead is based on many-valued logic. The predictions of the base neural network are interpreted as fuzzy truthvalues (though previous work [67] also formalizes Real Logic as handling probabilities with relaxed constraints). This difference of logic leads to the second main difference between LTN and Deep-Problog: their inference mechanism. DeepProblog performs probabilistic inference (based on model counting) while LTN inference consists of computing the truth-value of a formula starting from the truth-values of its atomic components. The two types of inference are incomparable. However, computing the fuzzy truth-value of a formula is more efficient than model counting, resulting in a more scalable inference task that allows LTN to use full first-order logic with function symbols. In DeepProblog, to perform probabilistic inference, a closed-world assumption is made and a function-free language is used. Typically, DeepProbLog clauses are compiled into Sentential Decision Diagrams (SDDs) to accelerate inference considerably [36], although the compilation step of clauses into the SDD circuit is still costly. An approach that extends the predictions of a base neural network using abductive reasoning is [14]. Given a neural network f nn px | wq that produces a crisp output y P t0, 1u n for n predicates p 1 , . . . , p n and background knowledge in the form of a logic program p, parameters w of f nn are learned alongside a set of additional rules ∆ C that define a new concept C w.r.t. p 1 , . . . , p n such that, for every object o with features x o :
p Y f nn px o | wq Y ∆ C |ù Cpoq if o is an instance of C p Y f nn px o | wq Y ∆ C |ù Cpoq if o is not an instance of C(62)
The task is solved by iterating the following three steps:</p>
<ol>
<li>
<p>Given the predictions of the neural network tf nn px o | wqu oPO on the set O of training objects, search for the best ∆ C that maximize the number of objects for which (62) holds;</p>
</li>
<li>
<p>For each object o, compute by abduction on p Y ∆ C , the explanation p 1 poq;</p>
</li>
<li>
<p>Retrain f nn with the training set tx o , p 1 poqu oPO .</p>
</li>
</ol>
<p>Differently from LTN, in [14] the optimization is done separately in an iterative way. The semantics of the logic is crisp, neither fuzzy nor probabilistic, and therefore not fully differentiable. Abductive reasoning is adopted, which is a potentially relevant addition for comparison with symbolic ML and Inductive Logic Programming approaches [50].</p>
<p>Various other loosely-coupled approaches have been proposed recently such as [44], where image classification is carried out by a neural network in combination with reasoning from text data for concept learning at a higher level of abstraction than what is normally possible with pixel data alone. The proliferation of such approaches has prompted Henry Kautz to propose a taxonomy for neurosymbolic AI in [34] (also discussed in [17]), including recent work combining neural networks with graphical models and graph neural networks [4,40,58], statistical relational learning [21,55], and even verification of neural multi-agent systems [2,8].</p>
<p>Conclusions and Future Work</p>
<p>In this paper, we have specified the theory and exemplified the reach of Logic Tensor Networks as a model and system for neurosymbolic AI. LTN is capable of combining approximate reasoning and deep learning, knowledge and data.</p>
<p>For ML practitioners, learning in LTN (see Section 3.2) can be understood as optimizing under first-order logic constraints relaxed into a loss function. For logic practitioners, learning is similar to inductive inference: given a theory, learning makes generalizations from specific observations obtained from data. Compared to other neuro-symbolic architectures (see Section 5), the LTN framework has useful properties for gradient-based optimization (see Section 2.4) and a syntax that supports many traditional ML tasks and their inductive biases (see Section 4), all while remaining computationally efficient (see Table 1). Section 3.4 discussed reasoning in LTN. Reasoning is normally under-specified within neural networks. Logical reasoning is the task of proving if some knowledge follows from the facts which are currently known. It is traditionally achieved semantically using model theory or syntactically via a proof system. The current LTN framework approaches reasoning semantically, although it should be possible to use LTN and querying alongside a proof system. When reasoning by refutation in LTN, to find out if a statement φ is a logical consequence of given data and knowledgebase K, a proof by refutation attempts to find a semantic counterexample where φ and K are satisfied. If the search fails then φ is assumed to hold. This approach is efficient in LTN when we allow for a direct search to find counterexamples via gradient-descent optimization. It is assumed that φ, the statement to prove or disprove, is known. Future work could explore automatically inducing which statement φ to consider, possibly using syntactical reasoning in the process.</p>
<p>The paper formalizes Real Logic, the language supporting LTN. The semantics of Real Logic are close to the semantics of Fuzzy FOL with the following major differences: 1) Real Logic domains are typed and restricted to real numbers and real-valued tensors, 2) Real Logic variables are sequences of fixed length, whereas FOL variables are a placeholder for any individual in a domain, 3) Real Logic relations relations are interpreted as mathematical functions, whereas Fuzzy Logic relations are interpreted as fuzzy set membership functions. Concerning the semantics of connectives and quantifiers, some LTN implementations correspond to semantics for t-norm fuzzy logic, but not all. For example, the conjunction operator in stable product semantics is not a t-norm, as pointed out at the end of Section 2.4.</p>
<p>Integrative neural-symbolic approaches are known for either seeking to bring neurons into a symbolic system (neurons into symbols) [41] or to bring symbols into a neural network (symbols into neurons) [60]. LTN adopts the latter approach but maintaining a close link between the symbols and their grounding into the neural network. The discussion around these two optionsneurons into symbols vs. symbols into neurons -is likely to take center stage in the debate around neurosymbolic AI in the next decade. LTN and related approaches are well placed to play an important role in this debate by offering a rich logical language tightly coupled with an efficient distributed implementation into TensorFlow computational graphs.</p>
<p>The close connection between first-order logic and its implementation in LTN makes LTN very suitable as a model for the neural-symbolic cycle [27,29], which seeks to translate between neural and symbolic representations. Such translations can take place at the level of the structure of a neural network, given a symbolic language [27], or at the level of the loss functions, as done by LTN and related approaches [13,45,46]. LTN opens up a number of promising avenues for further research:</p>
<p>Firstly, a continual learning approach might allow one to start with very little knowledge, build up and validate knowledge over time by querying the LTN network. Translations to and from neural and symbolic representations will enable reasoning also to take place at the symbolic level (e.g. alongside a proof system), as proposed recently in [70] with the goal of improving fairness of the network model.</p>
<p>Secondly, LTN should be compared in large-scale practical use cases with other recent efforts to add structure to neural networks such as the neuro-symbolic concept learner [44] and high-level capsules which were used recently to learn the part-of relation [38], similarly to how LTN was used for semantic image interpretation in [19].</p>
<p>Finally, LTN should also be compared with Tensor Product Representations, e.g. [59], which show that state-of-the-art recurrent neural networks may fail at simple question-answering tasks, despite achieving very high accuracy. Efforts in the area of transfer learning, mostly in computer vision, which seek to model systematicity could also be considered a benchmark [5]. Experiments using fewer data and therefore lower energy consumption, out-of-distribution extrapolation, and knowledge-based transfer are all potentially suitable areas of application for LTN as a framework for neurosymbolic AI based on learning from data and compositional knowledge.</p>
<p>Appendix A. Implementation Details</p>
<p>The LTN library is implemented in Tensorflow 2 [1] and is available from GitHub 29 . Every logical operator is grounded using Tensorflow primitives. The LTN code implements directly a Tensorflow graph. Due to Tensorflow built-in optimization, LTN is relatively efficient while providing the expressive power of FOL. Table A. 3 shows an overview of the network architectures used to obtain the results of the examples in Section 4. The LTN repository includes the code for these examples. Except if explicitly mentioned otherwise, the reported results are averaged over 10 runs using a 95% confidence interval. Every example uses a stable real product configuration to approximate Real Logic operators, and the Adam optimizer [35] with a learning rate of 0.001 to train the parameters. : layer ends with an elu activation Densepnq : regular fully-connected layer of n units Dropoutprq : dropout layer with rate r Convpf, kq : 2D convolution layer with f filters and a kernel of size k MPpw, hq : max pooling operation with a wˆh pooling window MNISTConv : Convp6, 5q˚, MPp2, 2q, Convp16, 5q˚, MPp2, 2q, Densep100qT able A.3: Overview of the neural network architectures used in each example. Notice that in the examples, the networks are usually used with some additional layer(s) to ground symbols. For instance, in experiment 4.2, in GpP q : x, l Þ Ñ l J softmaxpMLPpxqq, the softmax layer normalizes the raw predictions of MLP to probabilities in r0, 1s, and the multiplication with the one-hot label l selects the probability for one given class.  Following are other common aggregators:</p>
<p>A M px 1 , . . . , x n q " 1 n n ÿ i"1</p>
<p>x i (mean)</p>
<p>A pM px 1 , . . . , x n q "ˆ1 n n ÿ i"1</p>
<p>x p i˙1 p (p-mean)</p>
<p>A pM E px 1 , . . . , x n q "1´ˆ1 n n ÿ i"1 p1´x i q p˙1 p (p-mean error)</p>
<p>Where A pM is the generalized mean, and A pM E can be understood as the generalized mean measured w.r.t. the errors. That is, A pM E measures the power of the deviation of each value from the ground truth 1. A few particular values of p yield special cases of aggregators. Notably:</p>
<p>• lim pÑ`8 A pM px 1 , . . . , x n q " maxpx 1 , . . . , x n q,</p>
<p>• lim pÑ´8 A pM px 1 , . . . , x n q " minpx 1 , . . . , x n q,</p>
<p>• lim pÑ`8 A pM E px 1 , . . . , x n q " minpx 1 , . . . , x n q,</p>
<p>• lim pÑ´8 A pM E px 1 , . . . , x n q " maxpx 1 , . . . , x n q.</p>
<p>These "smooth" min (resp. max) approximators are good candidates for @ (resp. D) in a fuzzy context. The value of p leaves more or less room for outliers depending on the use case and its needs. Note that A pM E and A pM are related in the same way that D and @ are related using the definition D " @ , where would be approximated by the standard negation.</p>
<p>We propose to use A pM E with p ě 1 to approximate @ and A pM with p ě 1 to approximate D. When p ě 1, these operators resemble the l p norm of a vector u " pu 1 , u 2 , . . . , u n q, where }u} p " p|u 1 | p<code>| u 2 | p</code>¨¨¨`| u n | p q 1{p . In our case, many properties of the l p norm can apply to A pM (positive homogeneity, triangular inequality, ...).</p>
<p>Single-Passing</p>
<p>Vanishing Exploding</p>
<p>Goedel (mininum) T M ,S M I KD I G Goguen (product) T P ,S P () I R () I KD () Łukasiewicz T L , S L I Luk Table C.7: Gradient problems for some binary connectives. () means that the problem only appears on an edge case.</p>
<p>Single-Passing</p>
<p>Vanishing Exploding tioned gradient problems:
A T M /A S M A T P /A S P A T L /A S L A pM () A pM E ()
π 0 pxq " p1´ qx<code>(C.1) π 1 pxq " p1´ qx (C.2) N S pxq " 1´x (C.3) T 1 P px, yq " π 0 pxqπ 0 pyq (C.4) S 1 P px, yq " π 1 pxq</code>π 1 pyq´π 1 pxqπ 1 pyq (C.5) I 1 R px, yq " 1´π 0 pxq`π 0 pxqπ 1 pyq (C.6) A 1 pM px 1 , . . . , x n q "ˆ1 n n ÿ i"1 π 0 px i q p˙1 p p ě 1 (C.7)</p>
<p>A 1 pM E px 1 , . . . , y n q " 1´ˆ1 n n ÿ i"1 p1´π 1 px i qq p˙1 p p ě 1 (C.8) N S is the operator for negation, T 1 P for conjunction, S 1 P for disjunction, I 1 P for implication, A 1 pM for existential aggregation, A 1 pM E for universal aggregation.</p>
<p>Figure 1 :
1Illustration of Example 3:</p>
<p>Figure 3 :
3Illustration of an aggregation operation implementing quantification (@yDx) over variables x and y. We assume that x and y have different domains. The result is a single number in the interval [0,1].</p>
<p>...,|Gpxq| s.t. GpagepxqqiąGpagepyqqjGpparentpx, yqq i,j</p>
<p>GpQ x 1
1, . . . , x h : mpx 1 , . . . , x n qpφqq i h`1 ,...,in def " AggpQq i1"1,...,|Gpx1q|. . .</p>
<p>i h "1,...,|Gpx h q| s.t. GpmqpGpx1qi 1 ,...,Gpxnqi n q Gpφq i1,...,i h ,i h`1 ,...,in</p>
<p>8 3 "
30.833 . . . whereas Gp@x : mpxqpφpxqqq " 0.7`0.8 2 " 0.75. Also, in the computational graph of the guarded sentence, there are no gradients attached to the instances that do not verify the mask. Similarly, the semantics of Dx : mpxqpφpxqq is not equivalent to that of Dxpmpxq^φpxqq.</p>
<p>Figure 5 :
5Example of Guarded Quantification: One can filter out elements of the various domains that do not satisfy some condition before the aggregation operators for @ and D are applied.</p>
<p>Figure 6 :
6elupα, βxq where α ě 0 and β ě 0 are hyper-parameters. The function elupα, βpq´G θ pKqqq with α low and β high is a soft constraint for penaltypG θ , qq suitable for learning.</p>
<p>Figure 7 :
7Symbolic Tensor Computational Graph for the Binary Classification Example. In the figure, Gx`and Gxá re inputs to the network G θ pAq and the dotted lines indicate the propagation of activation from each input through the network, which produces two outputs.</p>
<p>Figure 8 :
8Binary Classification task (training and test set performance): Average accuracy (left) and satisfiability (right).</p>
<p>Figure 9 :
9Binary Classification task (querying the trained predicate Apxq): It is interesting to see how Apxq could be appropriately named as denoting the inside of the central region shown in the figure, and therefore Apxq represents the outside of the region.</p>
<p>Figure 11
11shows the result of training with the Adam optimizer with batches of 64 examples. Accuracy measures the ratio of examples correctly classified, with example x labeled as argmax l pP px, lqq. 20 Classification accuracy reaches an average value near 1.0 for both the training and test data after some 100 epochs. Satisfaction levels of the Iris flower predictions continue to increase for the rest of the training (500 epochs) to more than 0.8.</p>
<p>Figure 10 :
10Symbolic Tensor Computational Graph for the Multi-Class Single-Label Problem. As before, the dotted lines in the figure indicate the propagation of activation from each input through the network, in this case producing three outputs.</p>
<p>Figure 11 :
11Multi-Class Single-Label Classification: Classification accuracy (left) and satisfaction level (right).</p>
<p>Figure 12 :
12Multi-Class Multi-Label Classification: Classification Accuracy (left), Satisfiability level (middle), and Querying of Constraints (right).</p>
<p>Figure 13 :
13Symbolic Tensor Computational Graph for the Single Digit Addition task. Notice that the figure does not depict accurate dimensions for the tensors; Gpxq and Gpyq are in fact 4D tensors of dimensions mˆ28ˆ28ˆ1. Computing results with the variables d 1 or d 2 corresponds to the addition of a further axes of dimension 10.</p>
<p>Figure 14 :
14Single Digit Addition Task: Accuracy and satisfiability results (top) and results in the presence of fewer examples (bottom) in comparison with standard Deep Learning using a CNN (blue lines).</p>
<p>Figure 15 :
15p sched. (train) LTN p sched. (test) LTN p = 1 (train) LTN p = 1 (test) LTN p = 2 (train) LTN p = 2 (test) MultipleDigit Addition Task: Accuracy and satisfiability results (top) and results in the presence of fewer examples (bottom) in comparison with standard Deep Learning using a CNN (blue lines).</p>
<p>Figure 16 :Figure 17 :
1617Regression task: RMSE and satisfaction level over time. Visualization of LTN solving a regression problem.</p>
<p>Figure 18 :
18LTN solving a clustering problem by constraint optimization: ground-truth (top) and querying of each cluster C0, C1, C2 and C3, in turn.</p>
<p>Figure 19 :
19Smoker-Friends-Cancer example: Satisfiability levels during training (left) and truth-values of queries φ 1 and φ 2 over time (right). facts in the knowledge-base: axioms for smokers and cancer for individuals a to n (left), friendship relations in group 1 (middle), and friendship relations in group 2 (right). all the truth-values using LTN after training: smokers and cancer (left), friendship relations (middle and right).</p>
<p>Figure 20 :
20Smoker-Friends-Cancer example: Illustration of the facts before and after training.</p>
<p>Figure 21 :
21Smoker-Friends-Cancer example: learned embeddings showing the result of applying PCA on the individuals (top left); truth-values of smokes and cancer predicates for each embedding (top and bottom right); illustration of the friendship relations which are satisfied after learning (bottom left).</p>
<p>Figure 22 :
22Querying after learning: 10 runs of the optimizer with objective G˚" argmax G θ pG θ pKqq. All runs converge to the optimum G 1 ; the grid search misses the counter-example.</p>
<p>Figure 24 :
24Three classes of neurosymbolic approaches with Architectures Integrating Learning and Reasoning further subdivided into three sub-classes, with LTN belonging to the sub-class highlighted in red.</p>
<p>Town denote the domain of towns in the world and People denote the domain of living people. Suppose that L contains the constant symbols Alice, Bob and Charlie of domain People, and Rome and Seoul of domain Town. Let x be a variable of domain People and u be a variable of domain Town. The term x, u (i.e. the sequence x followed by u) has domain People, Town which denotes the Cartesian product between People and Town (PeopleŚTown). Alice, Rome is interpreted as an element of the domain People, Town. Let lives_in be a predicate with input domain D in plives_inq " People, Town. lives_inpAlice, Romeq is a well-formed expression, whereas lives_inpBob, Charlieq is not.</p>
<p>as N˚denotes the Kleene star of N. 3 Example 2. Let digit_images denote a domain of images of handwritten digits. If we use images of 256ˆ256 RGB pixels, then Gpdigit_imagesq Ď R 256ˆ256ˆ3 . Let us consider the predicate is_digitp , 8q. The terms , 8 have domains digit_images, digits. Any input to the predicate is a tuple in Gpdigit_images, digitsq " Gpdigit_imagesqˆGpdigitsq.</p>
<p>Table 1 :
1The computation time of training and test steps on the single and multiple digit addition tasks, measured on a computer with a single Nvidia Tesla V100 GPU and averaged over 1000 steps. Each step operates on a batch of 32 examples. The computational efficiency of the LTN and the CNN baseline systems are of the same order of magnitude.(Single Digits) </p>
<p>(Multi Digits) 
Model 
Train 
Test 
Train 
Test 
baseline 
2.72˘0.23ms 1.45˘0.21ms 3.87˘0.24ms 2.10˘0.30ms 
LTN 
5.36˘0.25ms 3.44˘0.39ms 8.51˘0.72ms 5.72˘0.57ms </p>
<p>Number of training examples 
(Single Digits) 
(Multi Digits) 
Model 
30 000 
3 000 
15 000 
1 500 
baseline 
95.95˘0.27 70.59˘1.45 47.19˘0.69 2.07˘0.12 
LTN 
98.04˘0.13 93.49˘0.28 95.37˘0.29 88.21˘0.63 
DeepProbLog 
97.20˘0.45 92.18˘1.57 95.16˘1.70 87.21˘1.92 </p>
<p>Table 2 :
2Accuracy (in %) on the test set: comparison of the final results obtained with LTN and those reported with DeepProbLog[41]. Although it is difficult to compare directly the results over time (the frameworks are implemented in different libraries), while achieving similar computational efficiency as the CNN baseline, LTN also reaches similar accuracy as that reported by DeepProbLog.</p>
<p>Table B .
B6: Common properties for different configurations</p>
<p>Table C .
C8: Gradient problems for some aggregators. () means that the problem only appears on an edge case.
In the rest of the paper, we commonly use "tensor" to designate "tensor in the real field".
An interpretation is an assignment of truth-values true or false, or in the case of Real Logic a value in [0,1], to a formula. A model is an interpretation that maps a formula to true 3 A tensor of rank 0 corresponds to a scalar, a tensor of rank 1 to a vector, a tensor of rank 2 to a matrix and so forth, in the usual way.
We assume the usual syntactic definition of free and bound variables in FOL. A variable is free if it is not bound by a quantifier (@, D).
Notice how Diag is not simply "syntactic sugar" for creating a new variable pairs_xy by stacking pairs of examples from Gpxq and Gpyq. If the groundings of x and y have incompatible ranks (for instance, if x denotes images and y denotes their labels), stacking them in a tensor Gppairs_xyq is non-trivial, requiring several reshaping operations.
In some edge cases, a masking may produce an empty sequence, e.g. if for some value of Gpyq, there is no value in Gpxq that satisfies agepxq ą agepyq, we resort to the concept of an empty semantics: @ returns 1 and D returns 0.
We define a symmetric configuration as a set of fuzzy operators such that conjunction and disjunction are defined by a t-norm and its dual t-conorm, respectively, and the implication operator is derived from such conjunction or disjunction operators and standard negation (c.f. Appendix B for details). In[69], van Krieken et al. also analyze non-symmetric configurations and even operators that do not strictly verify fuzzy logic semantics.
Recall that a T-norm is a function T : r0, 1sˆr0, 1s Ñ r0, 1s satisfying commutativity, monotonicity, associativity and identity, that is, T pa, 1q " a.
Notice that softmax is often used as the last layer in neural networks to turn logits into a probability distribution. However, we do not use the softmax function as such here. Instead, we use it here to enforce an exclusivity constraint on satisfiability scores.
This can also be specified using a guarded quantifier @x : ppl 1 pxq^¨¨¨^l k pxqq ą thq l k`1 pxq where th is a threshold value in r0, 1s.
For simplicity, we temporarily define the notation GpKq :" SatAgg φPK pK, Gq.
In the objective function, G˚should satisfy G˚pKq ě q before reducing G˚pφq because the penalty c which is greater than 1 is higher than any potential reduction in Gpφq which is smaller or equal to 1. 13 https://github.com/logictensornetworks/logictensornetworks
softmaxpxq " e x i { ř j e x j
This is also known as top-1 accuracy, as proposed in[39]. Cross-entropy results ř pt logpyqq could have been reported here as is common with the use of softmax, although it is worth noting that, of course, the loss function used by LTN is different.
There are two possible approaches here: either each item is labeled with one multi-hot encoding or each item is labeled with several one-hot encodings. The latter approach was used in this example.
Notice the use of the same number m of examples for each of these variables as they are supposed to match one-to-one due to the use of Diag.
https://www.kaggle.com/quantbruce/real-estate-price-prediction
We use the notation GpKq :" SatAgg φPK pK, Gq.
https://github.com/logictensornetworks/logictensornetworks
AcknowledgementWe would like to thank Benedikt Wagner for his comments and a number of productive discussions on continual learning, knowledge extraction and reasoning in LTNs.Appendix B. Fuzzy Operators and PropertiesThis appendix presents the most common operators used in fuzzy logic literature and some noteworthy properties[28,37,64,69].Appendix B.1. Negation Definition 7. A negation is a function N : r0, 1s Ñ r0, 1s that at least satisfies: N1. Boundary conditions: N p0q " 1 and N p1q " 0, N2. Monotonically decreasing: @px, yq P r0, 1s 2 , x ď y Ñ N pxq ě N pyq.Moreover, a negation is said to be strict if N is continuous and strictly decreasing. A negation is said to be strong if @x P r0, 1s, N pN pxqq " x.We commonly use the standard strict and strong negation N S paq " 1´a.Appendix B.2. ConjunctionDefinition 8. A conjuction is a function C : r0, 1s 2 Ñ r0, 1s that at least satisfies: C1. boundary conditions: Cp0, 0q " Cp0, 1q " Cp1, 0q " 0 and Cp1, 1q " 1, C2. monotonically increasing: @px, y, zq P r0, 1s 3 , if x ď y, then Cpx, zq ď Cpy, zq and Cpz, xq ď Cpz, yq.In fuzzy logic, t-norms are widely used to model conjunction operators.Definition 9.A t-norm (triangular norm) is a function t : r0, 1s 2 Ñ r0, 1s that at least satisifies:T1. boundary conditions: T px, 1q " x, T2. monotonically increasing, T3. commutative, T4. associative.Example 4.Three commonly used t-norms are: I1. boundary Conditions: Ip0, 0q " Ip0, 1q " Ip1, 1q " 1 and Ip1, 0q " 0 Definition 14. There are two main classes of implications generated from the fuzzy logic operators for negation, conjunction and disjunction.S-ImplicationsStrong implications are defined using x Ñ y " x _ y (material implication).R-ImplicationsResiduated implications are defined using x Ñ y " suptz P r0, 1s | x^z ď yu. One way of understanding this approach is a generalization of modus ponens: the consequent is at least as true as the (fuzzy) conjunction of the antecedent and the implication.Table B.5. A1. Apx 1 , . . . , x n q ď Apy 1 , ..., y n q whenever x i ď y i for all i P t1, . . . , nu,Kleene-DienesA2.Apxq " x forall x P r0, 1s, A3. Ap0, . . . , 0q " 0 and Ap1, . . . , 1q " 1.Example 7.Candidates for universal quantification @ can be obtained using t-norms with A T px i q "x i and A T px 1 , . . . , x n q " T px 1 , A T px 2 , . . . , x n qq:A T M px 1 , . . . , x n q " minpx 1 , . . . , x n q (minimum)A T P px 1 , . . . , x n q " n ź i"1x i (product)Similarly, candidates for existential quantification D can be obtained using s-norms with A S px i q " x i and A S px 1 , . . . , x n q " Spx 1 , A S px 2 , . . . , x n qq:[69]show that some operators used in Fuzzy Logics are unsuitable for use in a differentiable learning setting. Three types of gradient problems commonly arise in fuzzy logic operators.Appendix C. Analyzing Gradients of Generalized Mean AggregatorsSingle-PassingThe derivatives of some operators are non-null for only one argument. The gradients propagate to only one input at a time.Vanishing GradientsThe gradients vanish on some part of the domain. The learning does not update inputs that are in the vanishing domain.Exploding Gradients Large error gradients accumulate and result in unstable updates.Tables C.7 and C.8 summarize their conclusions for the most common operators. Also, we underline here exploding gradients issues that arise experimentally in A pM and A pM E , which are not in the original report. Given the truth values of n propositions px 1 , . . . , x n q in r0, 1s n :The partial derivatives are BA pM px1,...,xnq BxiWhen p ą 1, the operator weights more for inputs with a higher true value -i.e. their partial derivative is also higher -and suits for existential quantification. When p ă 1, the operator weights more for inputs with a lower true value and suits for universal quantification.Exploding Gradients When p ą 1, if ř n j"1 x p j Ñ 0, thenˆř2.A pM E px 1 , . . . , x n q " 1´ˆ1 nThe partial derivatives are BA pM E px1,...,xnq Bxi " 1 n 1 pˆř n j"1 p1´x j q p˙1 p´1 p1´x i q p´1 . When p ą 1, the operator weights more for inputs with a lower true value -i.e. their partial derivative is also higher -and suits for universal quantification. When p ă 1, the operator weights more for inputs with a higher true value and suits for existential quantification.Exploding GradientsWhen p ą 1, if ř n j"1 p1´x j q p Ñ 0, thenˆř n j"1 p1´x j q p˙1 p´1 Ñ 8 and the gradients explode. When p ă 1, if 1´x i Ñ 0, then p1´x i q p´1 Ñ 8.We propose the following stable product configuration that does not have any of the aforemen-
TensorFlow: Large-scale machine learning on heterogeneous systems. Martín Abadi, Ashish Agarwal, Paul Barham, Eugene Brevdo, Zhifeng Chen, Craig Citro, Greg S Corrado, Andy Davis, Jeffrey Dean, Matthieu Devin, Sanjay Ghemawat, Ian Goodfellow, Andrew Harp, Geoffrey Irving, Michael Isard, Yangqing Jia, Rafal Jozefowicz, Lukasz Kaiser, Manjunath Kudlur, Josh Levenberg, Dandelion Mané. Kunal Talwar, Paul Tucker, Vincent Vanhoucke, Vĳay Vasudevan, Fernanda ViégasYuan Yu, and Xiaoqiang ZhengOriol Vinyals. Software available from tensorflow.orgMartín Abadi, Ashish Agarwal, Paul Barham, Eugene Brevdo, Zhifeng Chen, Craig Citro, Greg S. Corrado, Andy Davis, Jeffrey Dean, Matthieu Devin, Sanjay Ghemawat, Ian Good- fellow, Andrew Harp, Geoffrey Irving, Michael Isard, Yangqing Jia, Rafal Jozefowicz, Lukasz Kaiser, Manjunath Kudlur, Josh Levenberg, Dandelion Mané, Rajat Monga, Sherry Moore, Derek Murray, Chris Olah, Mike Schuster, Jonathon Shlens, Benoit Steiner, Ilya Sutskever, Ku- nal Talwar, Paul Tucker, Vincent Vanhoucke, Vĳay Vasudevan, Fernanda Viégas, Oriol Vinyals, Pete Warden, Martin Wattenberg, Martin Wicke, Yuan Yu, and Xiaoqiang Zheng. TensorFlow: Large-scale machine learning on heterogeneous systems, 2015. Software available from ten- sorflow.org.</p>
<p>Verifying strategic abilities of neural multi-agent systems. Michael Akintunde, Elena Botoeva, Panagiotis Kouvaros, Alessio Lomuscio, Proceedings of 17th International Conference on Principles of Knowledge Representation and Reasoning. 17th International Conference on Principles of Knowledge Representation and ReasoningKR2020, Rhodes, GreeceMichael Akintunde, Elena Botoeva, Panagiotis Kouvaros, and Alessio Lomuscio. Verifying strategic abilities of neural multi-agent systems. In Proceedings of 17th International Conference on Principles of Knowledge Representation and Reasoning, KR2020, Rhodes, Greece, September 2020.</p>
<p>Injecting Prior Knowledge for Transfer Learning into Reinforcement Learning Algorithms using Logic Tensor Networks. Samy Badreddine, Michael Spranger, arXiv:1906.06576arXiv: 1906.06576cs, statSamy Badreddine and Michael Spranger. Injecting Prior Knowledge for Transfer Learning into Reinforcement Learning Algorithms using Logic Tensor Networks. arXiv:1906.06576 [cs, stat], June 2019. arXiv: 1906.06576.</p>
<p>Interaction networks for learning about objects, relations and physics. Peter Battaglia, Razvan Pascanu, Matthew Lai, Danilo Jimenez Rezende, Koray Kavukcuoglu, Proceedings of the 30th International Conference on Neural Information Processing Systems, NIPS'16. the 30th International Conference on Neural Information Processing Systems, NIPS'16USACurran Associates IncPeter Battaglia, Razvan Pascanu, Matthew Lai, Danilo Jimenez Rezende, and Koray kavukcuoglu. Interaction networks for learning about objects, relations and physics. In Proceedings of the 30th International Conference on Neural Information Processing Systems, NIPS'16, pages 4509-4517, USA, 2016. Curran Associates Inc.</p>
<p>A meta-transfer objective for learning to disentangle causal mechanisms. Yoshua Bengio, Tristan Deleu, Nasim Rahaman, Nan Rosemary Ke, Sebastien Lachapelle, Olexa Bilaniuk, Anirudh Goyal, Christopher Pal, International Conference on Learning Representations. Yoshua Bengio, Tristan Deleu, Nasim Rahaman, Nan Rosemary Ke, Sebastien Lachapelle, Olexa Bilaniuk, Anirudh Goyal, and Christopher Pal. A meta-transfer objective for learning to disentangle causal mechanisms. In International Conference on Learning Representations, 2020.</p>
<p>On the capabilities of logic tensor networks for deductive reasoning. Federico Bianchi, Pascal Hitzler, Proceedings of the AAAI 2019 Spring Symposium on Combining Machine Learning with Knowledge Engineering. the AAAI 2019 Spring Symposium on Combining Machine Learning with Knowledge EngineeringPalo Alto, California, USA; Palo Alto, California, USAAAAI-MAKE 2019) Stanford University ; Stanford UniversityFederico Bianchi and Pascal Hitzler. On the capabilities of logic tensor networks for deductive reasoning. In Proceedings of the AAAI 2019 Spring Symposium on Combining Machine Learning with Knowledge Engineering (AAAI-MAKE 2019) Stanford University, Palo Alto, California, USA, March 25-27, 2019., Stanford University, Palo Alto, California, USA, March 25-27, 2019., 2019.</p>
<p>Complementing logical reasoning with sub-symbolic commonsense. Federico Bianchi, Matteo Palmonari, Pascal Hitzler, Luciano Serafini, International Joint Conference on Rules and Reasoning. SpringerFederico Bianchi, Matteo Palmonari, Pascal Hitzler, and Luciano Serafini. Complementing logical reasoning with sub-symbolic commonsense. In International Joint Conference on Rules and Reasoning, pages 161-170. Springer, 2019.</p>
<p>Learning and representing temporal knowledge in recurrent networks. Rafael Borges, Artur D&apos;avila Garcez, Luís Lamb, IEEE Neural Networks Council. 22Rafael Borges, Artur d'Avila Garcez, and Luís Lamb. Learning and representing temporal knowledge in recurrent networks. IEEE transactions on neural networks / a publication of the IEEE Neural Networks Council, 22:2409-21, 12 2011.</p>
<p>Introduction to mathematical fuzzy logic. Liber Běhounek, Petr Cintula, Petr Hájek, Handbook of Mathematical Fuzzy Logic. Petr Cintula, Petr Hájek, and Carles NogueraCollege Publications1Liber Běhounek, Petr Cintula, and Petr Hájek. Introduction to mathematical fuzzy logic. In Petr Cintula, Petr Hájek, and Carles Noguera, editors, Handbook of Mathematical Fuzzy Logic, Volume 1, volume 37 of Studies in Logic, Mathematical Logic and Foundations, pages 1-102. College Publications, 2011.</p>
<p>A multivariate study of variation in two species of rock crab of the genus Leptograpsus. N A Campbell, R J Mahon, Australian Journal of Zoology. 223CSIRO PUBLISHINGN. A. Campbell and R. J. Mahon. A multivariate study of variation in two species of rock crab of the genus Leptograpsus. Australian Journal of Zoology, 22(3):417-425, 1974. Publisher: CSIRO PUBLISHING.</p>
<p>Logical rule induction and theory learning using neural theorem proving. Andres Campero, Aldo Pareja, Tim Klinger, Josh Tenenbaum, Sebastian Riedel, abs/1809.02193CoRRAndres Campero, Aldo Pareja, Tim Klinger, Josh Tenenbaum, and Sebastian Riedel. Logical rule induction and theory learning using neural theorem proving. CoRR, abs/1809.02193, 2018.</p>
<p>Improving multi-label classification performance by label constraints. Benhui Chen, Xuefen Hong, Lihua Duan, Jinglu Hu, The 2013 International Joint Conference on Neural Networks (ĲCNN). IEEEBenhui Chen, Xuefen Hong, Lihua Duan, and Jinglu Hu. Improving multi-label classification performance by label constraints. In The 2013 International Joint Conference on Neural Networks (ĲCNN), pages 1-5. IEEE, 2013.</p>
<p>Tensorlog: A probabilistic database implemented using deep-learning infrastructure. William W Cohen, Fan Yang, Kathryn Mazaitis, J. Artif. Intell. Res. 67William W. Cohen, Fan Yang, and Kathryn Mazaitis. Tensorlog: A probabilistic database implemented using deep-learning infrastructure. J. Artif. Intell. Res., 67:285-325, 2020.</p>
<p>Bridging machine learning and logical reasoning by abductive learning. W.-Z Dai, Q Xu, Y Yu, Z.-H Zhou, Proceedings of the 33rd International Conference on Neural Information Processing Systems, NeurIPS'19. the 33rd International Conference on Neural Information Processing Systems, NeurIPS'19USACurran Associates IncW.-Z. Dai, Q. Xu, Y. Yu, and Z.-H. Zhou. Bridging machine learning and logical reasoning by abductive learning. In Proceedings of the 33rd International Conference on Neural Information Processing Systems, NeurIPS'19, USA, 2019. Curran Associates Inc.</p>
<p>Knowledge enhanced neural networks. Alessandro Daniele, Luciano Serafini, Pacific Rim International Conference on Artificial Intelligence. SpringerAlessandro Daniele and Luciano Serafini. Knowledge enhanced neural networks. In Pacific Rim International Conference on Artificial Intelligence, pages 542-554. Springer, 2019.</p>
<p>Neural-symbolic computing: An effective methodology for principled integration of machine learning and reasoning. Artur D&apos;avila Garcez, Marco Gori, C Luís, Luciano Lamb, Michael Serafini, Son N Spranger, Tran, FLAP. 64Artur d'Avila Garcez, Marco Gori, Luís C. Lamb, Luciano Serafini, Michael Spranger, and Son N. Tran. Neural-symbolic computing: An effective methodology for principled integration of machine learning and reasoning. FLAP, 6(4):611-632, 2019.</p>
<p>Neurosymbolic AI: The 3rd wave. Artur D&apos;avila Garcez, Luis C Lamb, Artur d'Avila Garcez and Luis C. Lamb. Neurosymbolic AI: The 3rd wave, 2020.</p>
<p>Compensating supervision incompleteness with prior knowledge in semantic image interpretation. Ivan Donadello, Luciano Serafini, 2019 International Joint Conference on Neural Networks (ĲCNN). IEEEIvan Donadello and Luciano Serafini. Compensating supervision incompleteness with prior knowledge in semantic image interpretation. In 2019 International Joint Conference on Neural Networks (ĲCNN), pages 1-8. IEEE, 2019.</p>
<p>Logic tensor networks for semantic image interpretation. Ivan Donadello, Luciano Serafini, Artur D&apos;avila Garcez, Proceedings of the Twenty-Sixth International Joint Conference on Artificial Intelligence, ĲCAI-17. the Twenty-Sixth International Joint Conference on Artificial Intelligence, ĲCAI-17Ivan Donadello, Luciano Serafini, and Artur d'Avila Garcez. Logic tensor networks for se- mantic image interpretation. In Proceedings of the Twenty-Sixth International Joint Conference on Artificial Intelligence, ĲCAI-17, pages 1596-1602, 2017.</p>
<p>UCI machine learning repository. Dheeru Dua, Casey Graff, Dheeru Dua and Casey Graff. UCI machine learning repository, 2017.</p>
<p>Learning explanatory rules from noisy data. Richard Evans, Edward Grefenstette, J. Artif. Intell. Res. 61Richard Evans and Edward Grefenstette. Learning explanatory rules from noisy data. J. Artif. Intell. Res., 61:1-64, 2018.</p>
<p>Foundations of reasoning with uncertainty via real-valued logics. Ronald Fagin, Ryan Riegel, Alexander Gray, Ronald Fagin, Ryan Riegel, and Alexander Gray. Foundations of reasoning with uncertainty via real-valued logics, 2020.</p>
<p>Dl2: Training and querying neural networks with logic. Marc Fischer, Mislav Balunovic, Dana Drachsler-Cohen, Timon Gehr, Ce Zhang, Martin Vechev, International Conference on Machine Learning. Marc Fischer, Mislav Balunovic, Dana Drachsler-Cohen, Timon Gehr, Ce Zhang, and Martin Vechev. Dl2: Training and querying neural networks with logic. In International Conference on Machine Learning, pages 1931-1941, 2019.</p>
<p>Fast relational learning using bottom clause propositionalization with artificial neural networks. Manoel Franca, Gerson Zaverucha, Artur D&apos;avila Garcez, Machine Learning. 94Manoel Franca, Gerson Zaverucha, and Artur d'Avila Garcez. Fast relational learning using bottom clause propositionalization with artificial neural networks. Machine Learning, 94:81- 104, 01 2014.</p>
<p>The Many Valued and Nonmonotonic Turn in Logic. Dov M Gabbay, John Woods, Elsevier8of Handbook of the History of LogicDov M. Gabbay and John Woods, editors. The Many Valued and Nonmonotonic Turn in Logic, volume 8 of Handbook of the History of Logic. Elsevier, 2007.</p>
<p>Artur D&apos;avila Garcez, Dov M Gabbay, Krysia B Broda, Neural-Symbolic Learning System: Foundations and Applications. Berlin, HeidelbergSpringer-VerlagArtur d'Avila Garcez, Dov M. Gabbay, and Krysia B. Broda. Neural-Symbolic Learning System: Foundations and Applications. Springer-Verlag, Berlin, Heidelberg, 2002.</p>
<p>Artur D&apos;avila Garcez, Lus C Lamb, Dov M Gabbay, Neural-Symbolic Cognitive Reasoning. Springer Publishing CompanyIncorporated, 1 editionArtur d'Avila Garcez, Lus C. Lamb, and Dov M. Gabbay. Neural-Symbolic Cognitive Reasoning. Springer Publishing Company, Incorporated, 1 edition, 2008.</p>
<p>Metamathematics of Fuzzy Logic. Petr Hajek, Kluwer Academic PublishersPetr Hajek. Metamathematics of Fuzzy Logic. Kluwer Academic Publishers, 1998.</p>
<p>Perspectives of Neural-Symbolic Integration. Barbara Hammer and Pascal HitzlerSpringerBarbara Hammer and Pascal Hitzler, editors. Perspectives of Neural-Symbolic Integration, vol- ume 77 of Studies in Computational Intelligence. Springer, 2007.</p>
<p>The symbol grounding problem. Stevan Harnad, Physica D: Nonlinear Phenomena. 421-3Stevan Harnad. The symbol grounding problem. Physica D: Nonlinear Phenomena, 42(1-3):335- 346, 1990.</p>
<p>Ontology reasoning with deep neural networks. Patrick Hohenecker, Thomas Lukasiewicz, Journal of Artificial Intelligence Research. 68Patrick Hohenecker and Thomas Lukasiewicz. Ontology reasoning with deep neural net- works. Journal of Artificial Intelligence Research, 68:503-540, 2020.</p>
<p>CHCL -A connectionist infernce system. Steffen Hölldobler, Franz J Kurfess, Parallelization in Inference Systems, International Workshop. Bertram Fronhöfer and Graham WrightsonDagstuhl Castle, GermanySpringer590ProceedingsSteffen Hölldobler and Franz J. Kurfess. CHCL -A connectionist infernce system. In Bertram Fronhöfer and Graham Wrightson, editors, Parallelization in Inference Systems, International Workshop, Dagstuhl Castle, Germany, December 17-18, 1990, Proceedings, volume 590 of Lecture Notes in Computer Science, pages 318-342. Springer, 1990.</p>
<p>Harnessing deep neural networks with logic rules. Zhiting Hu, Xuezhe Ma, Zhengzhong Liu, Eduard Hovy, Eric Xing, Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics. the 54th Annual Meeting of the Association for Computational LinguisticsBerlin, GermanyAssociation for Computational Linguistics1Zhiting Hu, Xuezhe Ma, Zhengzhong Liu, Eduard Hovy, and Eric Xing. Harnessing deep neural networks with logic rules. In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 2410-2420, Berlin, Germany, August 2016. Association for Computational Linguistics.</p>
<p>The Third AI Summer. Henry Kautz, Thirtyfourth AAAI Conference on Artificial Intelligence. New York, NYHenry Kautz. The Third AI Summer, AAAI Robert S. Engelmore Memorial Lecture, Thirty- fourth AAAI Conference on Artificial Intelligence, New York, NY, February 10, 2020.</p>
<p>Adam: A Method for Stochastic Optimization. P Diederik, Jimmy Kingma, Ba, arXiv:1412.6980arXiv: 1412.6980Diederik P. Kingma and Jimmy Ba. Adam: A Method for Stochastic Optimization. arXiv:1412.6980 [cs], January 2017. arXiv: 1412.6980.</p>
<p>Probabilistic sentential decision diagrams. Doga Kisa, Guy Van Den, Arthur Broeck, Adnan Choi, Darwiche, Proceedings of the 14th International Conference on Principles of Knowledge Representation and Reasoning (KR). the 14th International Conference on Principles of Knowledge Representation and Reasoning (KR)Doga Kisa, Guy Van den Broeck, Arthur Choi, and Adnan Darwiche. Probabilistic sentential decision diagrams. In Proceedings of the 14th International Conference on Principles of Knowledge Representation and Reasoning (KR), July 2014.</p>
<p>Triangular Norms. Erich Peter Klement, Radko Mesiar, Endre Pap, Trends in Logic. 8SpringerErich Peter Klement, Radko Mesiar, and Endre Pap. Triangular Norms, volume 8 of Trends in Logic. Springer Netherlands, Dordrecht, 2000.</p>
<p>Stacked capsule autoencoders. Adam Kosiorek, Sara Sabour, Yee Whye Teh, Geoffrey E Hinton, Advances in Neural Information Processing Systems. H. Wallach, H. Larochelle, A. Beygelzimer, F. d Alché-Buc, E. Fox, and R. GarnettCurran Associates, Inc32Adam Kosiorek, Sara Sabour, Yee Whye Teh, and Geoffrey E Hinton. Stacked capsule autoen- coders. In H. Wallach, H. Larochelle, A. Beygelzimer, F. d Alché-Buc, E. Fox, and R. Garnett, editors, Advances in Neural Information Processing Systems 32, pages 15512-15522. Curran As- sociates, Inc., 2019.</p>
<p>Imagenet classification with deep convolutional neural networks. Alex Krizhevsky, Ilya Sutskever, Geoffrey E Hinton, Proceedings of the 25th International Conference on Neural Information Processing Systems. the 25th International Conference on Neural Information Processing SystemsRed Hook, NY, USACurran Associates Inc1Alex Krizhevsky, Ilya Sutskever, and Geoffrey E. Hinton. Imagenet classification with deep convolutional neural networks. In Proceedings of the 25th International Conference on Neural Information Processing Systems -Volume 1, NIPS'12, page 1097-1105, Red Hook, NY, USA, 2012. Curran Associates Inc.</p>
<p>Graph neural networks meet neural-symbolic computing: A survey and perspective. C Luís, Artur D&apos;avila Lamb, Marco Garcez, Marcelo O R Gori, Pedro H C Prates, Moshe Y Avelar, Vardi, Proceedings of the Twenty-Ninth International Joint Conference on Artificial Intelligence. Christian Bessierethe Twenty-Ninth International Joint Conference on Artificial IntelligenceYokohama, Japan2020postponed due to the Corona pandemic. ĳcai.orgLuís C. Lamb, Artur d'Avila Garcez, Marco Gori, Marcelo O. R. Prates, Pedro H. C. Avelar, and Moshe Y. Vardi. Graph neural networks meet neural-symbolic computing: A survey and perspective. In Christian Bessiere, editor, Proceedings of the Twenty-Ninth International Joint Conference on Artificial Intelligence, ĲCAI 2020 [scheduled for July 2020, Yokohama, Japan, postponed due to the Corona pandemic], pages 4877-4884. ĳcai.org, 2020.</p>
<p>Deepproblog: Neural probabilistic logic programming. Robin Manhaeve, Sebastĳan Dumancic, Angelika Kimmig, Thomas Demeester, Luc De Raedt, Proceedings of the 32nd International Conference on Neural Information Processing Systems, NeurIPS'18. the 32nd International Conference on Neural Information Processing Systems, NeurIPS'18USACurran Associates IncRobin Manhaeve, Sebastĳan Dumancic, Angelika Kimmig, Thomas Demeester, and Luc De Raedt. Deepproblog: Neural probabilistic logic programming. In Proceedings of the 32nd International Conference on Neural Information Processing Systems, NeurIPS'18, pages 3753-3763, USA, 2018. Curran Associates Inc.</p>
<p>Faster-LTN: a neuro-symbolic, end-to-end object detection architecture. Francesco Manigrasso, Davide Filomeno, Lia Miro, Fabrizio Morra, Lamberti, arXiv:2107.01877Francesco Manigrasso, Filomeno Davide Miro, Lia Morra, and Fabrizio Lamberti. Faster-LTN: a neuro-symbolic, end-to-end object detection architecture. arXiv:2107.01877 [cs], July 2021.</p>
<p>Algorithms for weighted boolean optimization. Vasco Manquinho, Joao Marques-Silva, Jordi Planes, International conference on theory and applications of satisfiability testing. SpringerVasco Manquinho, Joao Marques-Silva, and Jordi Planes. Algorithms for weighted boolean optimization. In International conference on theory and applications of satisfiability testing, pages 495-508. Springer, 2009.</p>
<p>The neurosymbolic concept learner: Interpreting scenes, words, and sentences from natural supervision. Jiayuan Mao, Chuang Gan, Pushmeet Kohli, Joshua B Tenenbaum, Jiajun Wu, abs/1904.12584CoRRJiayuan Mao, Chuang Gan, Pushmeet Kohli, Joshua B. Tenenbaum, and Jiajun Wu. The neuro- symbolic concept learner: Interpreting scenes, words, and sentences from natural supervision. CoRR, abs/1904.12584, 2019.</p>
<p>Constraintbased visual generation. Giuseppe Marra, Francesco Giannini, Michelangelo Diligenti, Marco Gori, Artificial Neural Networks and Machine Learning -ICANN 2019: Image Processing -28th International Conference on Artificial Neural Networks. Igor V. Tetko, Vera Kurková, Pavel Karpov, and Fabian J. TheisMunich, GermanySpringer11729Proceedings, Part IIIGiuseppe Marra, Francesco Giannini, Michelangelo Diligenti, and Marco Gori. Constraint- based visual generation. In Igor V. Tetko, Vera Kurková, Pavel Karpov, and Fabian J. Theis, editors, Artificial Neural Networks and Machine Learning -ICANN 2019: Image Processing -28th International Conference on Artificial Neural Networks, Munich, Germany, September 17-19, 2019, Proceedings, Part III, volume 11729 of Lecture Notes in Computer Science, pages 565-577. Springer, 2019.</p>
<p>Integrating learning and reasoning with deep logic models. Giuseppe Marra, Francesco Giannini, Michelangelo Diligenti, Marco Gori, Machine Learning and Knowledge Discovery in Databases -European Conference, ECML PKDD 2019. Würzburg, Germany11907Proceedings, Part IIGiuseppe Marra, Francesco Giannini, Michelangelo Diligenti, and Marco Gori. Integrating learning and reasoning with deep logic models. In Machine Learning and Knowledge Discovery in Databases -European Conference, ECML PKDD 2019, Würzburg, Germany, September 16-20, 2019, Proceedings, Part II, volume 11907 of Lecture Notes in Computer Science, pages 517-532.</p>
<p>. Springer, Springer, 2019.</p>
<p>Lyrics: A general interface layer to integrate logic inference and deep learning. Giuseppe Marra, Francesco Giannini, Michelangelo Diligenti, Marco Gori, Joint European Conference on Machine Learning and Knowledge Discovery in Databases. SpringerGiuseppe Marra, Francesco Giannini, Michelangelo Diligenti, and Marco Gori. Lyrics: A gen- eral interface layer to integrate logic inference and deep learning. In Joint European Conference on Machine Learning and Knowledge Discovery in Databases, pages 283-298. Springer, 2019.</p>
<p>Giuseppe Marra, Ondřej Kuželka, arXiv:1905.13462Neural markov logic networks. arXiv preprintGiuseppe Marra and Ondřej Kuželka. Neural markov logic networks. arXiv preprint arXiv:1905.13462, 2019.</p>
<p>Learning reasoning strategies in end-to-end differentiable proving. Pasquale Minervini, Sebastian Riedel, Pontus Stenetorp, Edward Grefenstette, Tim Rocktäschel, Pasquale Minervini, Sebastian Riedel, Pontus Stenetorp, Edward Grefenstette, and Tim Rock- täschel. Learning reasoning strategies in end-to-end differentiable proving, 2020.</p>
<p>Metainterpretive learning: Application to grammatical inference. H Stephen, Dianhuan Muggleton, Niels Lin, Alireza Pahlavi, Tamaddoni-Nezhad, Mach. Learn. 941Stephen H. Muggleton, Dianhuan Lin, Niels Pahlavi, and Alireza Tamaddoni-Nezhad. Meta- interpretive learning: Application to grammatical inference. Mach. Learn., 94(1):25-49, January 2014.</p>
<p>on lines and planes of closest fit to systems of points in space. The London, Edinburgh, and Dublin Philosophical Magazine. Karl Pearson, Liii, Journal of Science. 211Karl Pearson. Liii. on lines and planes of closest fit to systems of points in space. The London, Edinburgh, and Dublin Philosophical Magazine and Journal of Science, 2(11):559-572, 1901.</p>
<p>Gadi Pinkas. Reasoning, nonmonotonicity and learning in connectionist networks that capture propositional knowledge. Artif. Intell. 772Gadi Pinkas. Reasoning, nonmonotonicity and learning in connectionist networks that capture propositional knowledge. Artif. Intell., 77(2):203-247, 1995.</p>
<p>Probabilistic logic neural networks for reasoning. Meng Qu, Jian Tang, Advances in Neural Information Processing Systems. Meng Qu and Jian Tang. Probabilistic logic neural networks for reasoning. In Advances in Neural Information Processing Systems, pages 7712-7722, 2019.</p>
<p>From statistical relational to neuro-symbolic artificial intelligence. Sebastĳan Luc De Raedt, Robin Dumančić, Giuseppe Manhaeve, Marra, Luc De Raedt, Sebastĳan Dumančić, Robin Manhaeve, and Giuseppe Marra. From statistical relational to neuro-symbolic artificial intelligence, 2020.</p>
<p>Markov logic networks. Matthew Richardson, Pedro Domingos, Mach. Learn. 621-2Matthew Richardson and Pedro Domingos. Markov logic networks. Mach. Learn., 62(1-2):107- 136, February 2006.</p>
<p>Ismail Yunus Akhalwaya. Ryan Riegel, Alexander Gray, Francois Luus, Naweed Khan, Ndivhuwo Makondo ; Haifeng Qian, Ronald Fagin, Francisco Barahona, Udit Sharma, arXiv:2006.13155arXiv: 2006.13155Shajith Ikbal, Hima Karanam, Sumit Neelam, Ankita Likhyani, and Santosh Srivastava. Logical Neural Networks. Ryan Riegel, Alexander Gray, Francois Luus, Naweed Khan, Ndivhuwo Makondo, Is- mail Yunus Akhalwaya, Haifeng Qian, Ronald Fagin, Francisco Barahona, Udit Sharma, Sha- jith Ikbal, Hima Karanam, Sumit Neelam, Ankita Likhyani, and Santosh Srivastava. Logical Neural Networks. arXiv:2006.13155 [cs], June 2020. arXiv: 2006.13155.</p>
<p>End-to-end differentiable proving. Tim Rocktäschel, Sebastian Riedel, Advances in Neural Information Processing Systems. Tim Rocktäschel and Sebastian Riedel. End-to-end differentiable proving. In Advances in Neural Information Processing Systems, pages 3788-3800, 2017.</p>
<p>Ah Chung Tsoi, Markus Hagenbuchner, and Gabriele Monfardini. The graph neural network model. Franco Scarselli, Marco Gori, Trans. Neur. Netw. 201Franco Scarselli, Marco Gori, Ah Chung Tsoi, Markus Hagenbuchner, and Gabriele Monfar- dini. The graph neural network model. Trans. Neur. Netw., 20(1):61-80, January 2009.</p>
<p>Learning to reason with third-order tensor products. Imanol Schlag, Jürgen Schmidhuber, abs/1811.12143CoRRImanol Schlag and Jürgen Schmidhuber. Learning to reason with third-order tensor products. CoRR, abs/1811.12143, 2018.</p>
<p>Enhancing the transformer with explicit relational encoding for math problem solving. Imanol Schlag, Paul Smolensky, Roland Fernandez, Nebojsa Jojic, Jürgen Schmidhuber, Jianfeng Gao, abs/1910.06611CoRRImanol Schlag, Paul Smolensky, Roland Fernandez, Nebojsa Jojic, Jürgen Schmidhuber, and Jianfeng Gao. Enhancing the transformer with explicit relational encoding for math problem solving. CoRR, abs/1910.06611, 2019.</p>
<p>Logic tensor networks: Deep learning and logical reasoning from data and knowledge. Luciano Serafini, Artur D&apos;avila Garcez, arXiv:1606.04422arXiv preprintLuciano Serafini and Artur d'Avila Garcez. Logic tensor networks: Deep learning and logical reasoning from data and knowledge. arXiv preprint arXiv:1606.04422, 2016.</p>
<p>Learning and reasoning with logic tensor networks. Luciano Serafini, Artur D&apos;avila Garcez, Conference of the Italian Association for Artificial Intelligence. SpringerLuciano Serafini and Artur d'Avila Garcez. Learning and reasoning with logic tensor networks. In Conference of the Italian Association for Artificial Intelligence, pages 334-348. Springer, 2016.</p>
<p>Advances in SHRUTI-A neurally motivated model of relational knowledge representation and rapid inference using temporal synchrony. Lokendra Shastri, Appl. Intell. 111Lokendra Shastri. Advances in SHRUTI-A neurally motivated model of relational knowledge representation and rapid inference using temporal synchrony. Appl. Intell., 11(1):79-108, 1999.</p>
<p>A deep study of fuzzy implications. Yun Shi, Ghent UniversityPhD thesisYun Shi. A deep study of fuzzy implications. PhD thesis, Ghent University, 2009.</p>
<p>The Harmonic Mind: From Neural Computation to Optimality-Theoretic GrammarVolume I: Cognitive Architecture (Bradford Books). Paul Smolensky, Géraldine Legendre, The MIT PressPaul Smolensky and Géraldine Legendre. The Harmonic Mind: From Neural Computation to Optimality-Theoretic GrammarVolume I: Cognitive Architecture (Bradford Books). The MIT Press, 2006.</p>
<p>Lifted relational neural networks: Efficient learning of latent relational structures. Gustav Sourek, Vojtech Aschenbrenner, Filip Zelezny, Steven Schockaert, Ondrej Kuzelka, Journal of Artificial Intelligence Research. 62Gustav Sourek, Vojtech Aschenbrenner, Filip Zelezny, Steven Schockaert, and Ondrej Kuzelka. Lifted relational neural networks: Efficient learning of latent relational structures. Journal of Artificial Intelligence Research, 62:69-100, 2018.</p>
<p>Emile Van Krieken, Erman Acar, Frank Van Harmelen, arXiv:1908.04700arXiv: 1908.04700Semi-Supervised Learning using Differentiable Reasoning. Emile van Krieken, Erman Acar, and Frank van Harmelen. Semi-Supervised Learning using Differentiable Reasoning. arXiv:1908.04700 [cs], August 2019. arXiv: 1908.04700.</p>
<p>Analyzing Differentiable Fuzzy Implications. Emile Van Krieken, Erman Acar, Frank Van Harmelen, Proceedings of the 17th International Conference on Principles of Knowledge Representation and Reasoning. the 17th International Conference on Principles of Knowledge Representation and Reasoning9Emile van Krieken, Erman Acar, and Frank van Harmelen. Analyzing Differentiable Fuzzy Implications. In Proceedings of the 17th International Conference on Principles of Knowledge Repre- sentation and Reasoning, pages 893-903, 9 2020.</p>
<p>Emile Van Krieken, Erman Acar, Frank Van Harmelen, arXiv:2002.06100arXiv: 2002.06100Analyzing Differentiable Fuzzy Logic Operators. Emile van Krieken, Erman Acar, and Frank van Harmelen. Analyzing Differentiable Fuzzy Logic Operators. arXiv:2002.06100 [cs], February 2020. arXiv: 2002.06100.</p>
<p>Neural-Symbolic Integration for Fairness in AI. Benedikt Wagner, Artur D&apos;avila Garcez, Proceedings of the AAAI Spring Symposium: Combining Machine Learning with Knowledge Engineering 2021. the AAAI Spring Symposium: Combining Machine Learning with Knowledge Engineering 202114Benedikt Wagner and Artur d'Avila Garcez. Neural-Symbolic Integration for Fairness in AI. Proceedings of the AAAI Spring Symposium: Combining Machine Learning with Knowledge Engineering 2021, page 14, 2021.</p>
<p>Satnet: Bridging deep learning and logical reasoning using a differentiable satisfiability solver. Po-Wei Wang, L Priya, Bryan Donti, Zico Wilder, Kolter, arXiv:1905.12149arXiv preprintPo-Wei Wang, Priya L Donti, Bryan Wilder, and Zico Kolter. Satnet: Bridging deep learning and logical reasoning using a differentiable satisfiability solver. arXiv preprint arXiv:1905.12149, 2019.</p>
<p>A Semantic Loss Function for Deep Learning with Symbolic Knowledge. Jingyi Xu, Zilu Zhang, Tal Friedman, Yitao Liang, Guy Broeck, PMLRInternational Conference on Machine Learning. Jingyi Xu, Zilu Zhang, Tal Friedman, Yitao Liang, and Guy Broeck. A Semantic Loss Function for Deep Learning with Symbolic Knowledge. In International Conference on Machine Learning, pages 5502-5511. PMLR, July 2018. ISSN: 2640-3498.</p>
<p>Disjunction Definition 10. A disjunction is a function D : r0, 1s 2 Ñ r0. B Appendix, 1s that at least satisfies: D1. boundary conditions: Dp0, 0q " 0 and Dp0, 1q " Dp1, 0q " Dp1, 1q " 1Appendix B.3. Disjunction Definition 10. A disjunction is a function D : r0, 1s 2 Ñ r0, 1s that at least satisfies: D1. boundary conditions: Dp0, 0q " 0 and Dp0, 1q " Dp1, 0q " Dp1, 1q " 1,</p>
<p>D2. monotonically increasing: @px, y, zq P r0, 1s 3 , if x ď y, then Dpx, zq ď Dpy, zq and Dpz. xq ď Dpz, yqD2. monotonically increasing: @px, y, zq P r0, 1s 3 , if x ď y, then Dpx, zq ď Dpy, zq and Dpz, xq ď Dpz, yq.</p>
<p>Disjunctions in fuzzy logic are often modeled with t-conorms. Disjunctions in fuzzy logic are often modeled with t-conorms.</p>
<p>. S P Px, yq "x<code>y´x¨y (probabilistic sumS P px, yq "x</code>y´x¨y (probabilistic sum)</p>
<p>. S L Px, yq " minpx<code>y, 1q (ŁukasiewiczS L px, yq " minpx</code>y, 1q (Łukasiewicz)</p>
<p>Note that the only distributive pair of t-norm and t-conorm is T M and S M -that is, distributivity of the t-norm over the t-conorm, and inversely. Note that the only distributive pair of t-norm and t-conorm is T M and S M -that is, distributivity of the t-norm over the t-conorm, and inversely.</p>
<p>The N -dual t-conorm S of a t-norm T w.r.t. a strict fuzzy negation N is defined as: @px, yq P r0, 1s 2 , Spx, yq " N pT pN pxq. Definition 12. N pyqqq. (B.1Definition 12. The N -dual t-conorm S of a t-norm T w.r.t. a strict fuzzy negation N is defined as: @px, yq P r0, 1s 2 , Spx, yq " N pT pN pxq, N pyqqq. (B.1)</p>
<p>If N is a strong negation, we also get: @px, yq P r0, 1s 2 , T px, yq " N pSpN pxq, N pyqqq. (B.2) Name Ipx. yq " S-Implication R-ImplicationIf N is a strong negation, we also get: @px, yq P r0, 1s 2 , T px, yq " N pSpN pxq, N pyqqq. (B.2) Name Ipx, yq " S-Implication R-Implication</p>            </div>
        </div>

    </div>
</body>
</html>