<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-1261 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-1261</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-1261</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-27.html">extraction-schema-27</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of world models used in AI systems, including details about their fidelity, interpretability, computational efficiency, and task-specific utility.</div>
                <p><strong>Paper ID:</strong> paper-259342816</p>
                <p><strong>Paper Title:</strong> Facing off World Model Backbones: RNNs, Transformers, and S4</p>
                <p><strong>Paper Abstract:</strong> World models are a fundamental component in model-based reinforcement learning (MBRL) agents. To perform temporally extended and consistent simulations of the future in partially observable environments, world models need to possess long-term memory. However, state-of-the-art MBRL agents, such as Dreamer, predominantly employ recurrent neural networks (RNNs) as their world model backbone, which have limited memory capacity. In this paper, we seek to explore alternative world model backbones for improving long-term memory. In particular, we investigate the effectiveness of Transformers and Structured State Space Sequence (S4) models, motivated by their remarkable ability to capture long-range dependencies in low-dimensional sequences and their complementary strengths. We propose S4WM, the first S4-based world model that can generate high-dimensional image sequences through latent imagination. Furthermore, we extensively compare RNN-, Transformer-, and S4-based world models across four sets of environments, which we have specifically tailored to assess crucial memory capabilities of world models, including long-term imagination, context-dependent recall, reward prediction, and memory-based reasoning. Our findings demonstrate that S4WM outperforms Transformer-based world models in terms of long-term memory, while exhibiting greater efficiency during training and imagination. These results pave the way for the development of stronger MBRL agents.</p>
                <p><strong>Cost:</strong> 0.035</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e1261.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e1261.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of world models used in AI systems, including details about their fidelity, interpretability, computational efficiency, and task-specific utility.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>S4WM</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>S4-based World Model (S4WM)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A latent-variable visual world model introduced in this paper that embeds high-dimensional images into compact stochastic latents and models their temporal dynamics using stacks of parallelizable State Space Model (PSSM) blocks (instantiated with S4), enabling fully parallel training and recurrent imagination.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>S4WM</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Probabilistic latent world model: CNN encoder produces per-step posterior sufficient statistics for discrete categorical latent z_t; a stack of PSSM/S4 blocks encodes history of (z, a) into embeddings h_t; priors and likelihoods are MLPs on h_t; decoder reconstructs images from concat[h_t, z_t]. Training via variational inference (ELBO) with factorized posterior by default; supports a Full-Posterior variant. Parallelizable training and recurrent single-step generation (imagination).</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>latent world model (PSSM/S4 backbone)</td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>Visual model-based reinforcement learning (partially observable 3D mazes and 2D MiniGrid variants; long-horizon imagination, recall, reward prediction, memory-based reasoning; DMLab comparison)</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_metric</strong></td>
                            <td>Reconstruction & generation MSE per step (MSE), reward prediction accuracy (%), offline probing metrics (classification accuracy / MSE), perceptual metrics for DMLab (PSNR, SSIM, LPIPS).</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_performance</strong></td>
                            <td>Long-term imagination Gen MSE: Two Rooms Gen MSE=7.3, Four Rooms Gen MSE=4.0, Ten Rooms Gen MSE=24.4 (Table 1). Reward-prediction (imagination) accuracy 100.0% across tested Distracting Memory widths (Table 2). Memory-based reasoning Gen MSE: Three Keys=0.04, Five Keys=0.27, Seven Keys=0.10 (Table 3). DMLab: PSNR=20.6, SSIM=0.667, LPIPS=0.196 (Table 8).</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_assessment</strong></td>
                            <td>Mostly a black-box neural latent model; imagined frames are visualized for qualitative interpretability. Standard probing (concat[h_t, z_t]) underperforms RNN baselines at some probing tasks, indicating h_t carries more local/time-step information; S4 internal hidden state s_t likely carries more global info but is high-dimensional, complicating use for probing.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_method</strong></td>
                            <td>Visual inspection of generated image rollouts; offline probing networks (MLP) trained on latent embeddings concat[h_t, z_t]; ablation comparing factorized vs full-posterior. No symbolic/extractive interpretability used.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost</strong></td>
                            <td>Parallelizable training (fast); instantiated experiments on a single NVIDIA RTX A6000. Training is reported as the fastest among compared backbones; imagination (recurrent generation) is slower than RNN baseline. Decoder decoding all steps in parallel dominates memory usage. Exact param counts vary by instantiation (paper matched models to comparable parameter counts).</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_comparison</strong></td>
                            <td>Trains much faster than RSSM-TBTT and comparable to Transformer-based TSSM-XL due to parallel training; imagination throughput lower — RSSM-TBTT achieves ~10x higher imagination throughput than S4WM; S4WM has sub-quadratic complexity vs Transformer's quadratic (theoretical advantage).</td>
                        </tr>
                        <tr>
                            <td><strong>task_performance</strong></td>
                            <td>Outperforms RSSM-TBTT and TSSM-XL on long-term imagination (better Gen MSE up to 500 steps), context-dependent recall in longer contexts, reward prediction within imagination (100% accuracy), and memory-based reasoning; in skill-level MPC planning, S4WM achieved 100% success on Three/ Five/Seven-Keys tasks (Table 7).</td>
                        </tr>
                        <tr>
                            <td><strong>task_utility_analysis</strong></td>
                            <td>High latent-generation fidelity translates to effective task utility: accurate long-horizon imagination yields accurate reward predictions and perfect offline planning success in tested tasks. Limitations: in very long episodes (Ten Rooms; context length 1101, query 900) all models struggle — S4WM better but still limited.</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoffs_observed</strong></td>
                            <td>S4WM achieves superior long-term fidelity and fast parallel training but pays in imagination throughput (slower recurrent generation) compared to RNNs. Adding MLPs inside S4 blocks improves generation quality at some computational cost. Full-posterior improves long-horizon performance but is more computationally expensive. Compared to Transformers: S4WM superior for long-range memory; Transformers sometimes better at context-dependent retrieval for short contexts but scale poorly (quadratic) unless using cache.</td>
                        </tr>
                        <tr>
                            <td><strong>design_choices</strong></td>
                            <td>Latent discrete categorical codes with straight-through gradients; factorized posterior (parallel) by default with optional Full-Posterior S4WM variant; stacked S4 blocks with MLPs between layers; use of KL balancing (α=0.8); CNN encoder/decoder; supports replacement of S4 by other PSSMs (e.g., S5).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Compared directly in experiments: S4WM > TSSM-XL and RSSM-TBTT on long-term imagination (lower Gen MSE), better reward-imagination accuracy (100%), better memory-reasoning Gen MSE, and stronger planning (MPC success). Trains faster than RSSM-TBTT and comparable to TSSM-XL; imagination throughput worse than RSSM-TBTT. On Memory Maze probing RSSM-TBTT > S4WM with concat[h_t,z_t], but S5-instantiation of S4WM (S5WM) outperforms RSSM.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_configuration</strong></td>
                            <td>Paper recommendations: keep MLPs in S4 blocks (S4WM-No-MLP degrades performance); consider Full-Posterior when longer episodes demand more capacity (better but costlier); instantiating S4WM with S5 (S5WM) improves probing and imagination — promising configuration. Use PSSM variants (S4/S5) depending on trade-off between hidden-state dimension (interpretability/probing) and compute.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Facing off World Model Backbones: RNNs, Transformers, and S4', 'publication_date_yy_mm': '2023-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1261.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e1261.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of world models used in AI systems, including details about their fidelity, interpretability, computational efficiency, and task-specific utility.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>RSSM-TBTT</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Recurrent State-Space Model (RSSM) trained with Truncated Backpropagation Through Time (RSSM-TBTT)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An RNN-based latent world model (RSSM) used as baseline; it compresses past latents and actions with a GRU into deterministic encoding h_t and predicts stochastic latent z_t priors/likelihoods; training with TBTT improves its long-term memory relative to naive RNN training.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Learning latent dynamics for planning from pixels</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>RSSM-TBTT</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Latent world model with deterministic recurrent core (GRU) h_t = GRU(h_{t-1}, MLP(concat[z_{t-1}, a_t])) plus stochastic latent z_t; decoder uses concat[h_t, z_t] to reconstruct observations; trained with variational inference and truncated backpropagation through time to enhance long-range memory.</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>latent world model (RNN backbone)</td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>Visual MBRL on partially observable 3D mazes and 2D MiniGrid tasks used in the paper (same domains as S4WM/TSSM-XL).</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_metric</strong></td>
                            <td>Reconstruction & generation MSE, reward prediction accuracy, offline probing accuracy/MSE.</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_performance</strong></td>
                            <td>Long-term imagination Gen MSE: Two Rooms Gen MSE=2.21, Four Rooms Gen MSE=19.4, Ten Rooms Gen MSE=23.1 (Table 1). Reward-prediction (imagination) accuracies ~49–52% (close to random) across Distracting Memory widths (Table 2). Memory-reasoning Gen MSEs: Three Keys=5.16, Five Keys=6.36, Seven Keys=6.28 (Table 3). Offline probing on Memory Maze: Walls Acc 95.0% (9×9), 81.7% (15×15); Objects MSE 5.4 (9×9), 32.6 (15×15) (Table 6).</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_assessment</strong></td>
                            <td>More interpretable for downstream probing: h_t encodes global information and when used in probing concat[h_t, z_t] yields strong probing accuracy; latent trajectories and h_t are used to probe walls/objects states.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_method</strong></td>
                            <td>Offline probing networks (MLP) trained on concat[h_t, z_t] to evaluate representation utility for downstream tasks (Memory Maze probing). Visualization of imagined rollouts for qualitative analysis.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost</strong></td>
                            <td>Sequential training (RNN) — more memory-efficient during training than parallel methods; imagination (single-step recurrent generation) is very fast: reported ~10x higher imagination throughput than S4WM and TSSM-XL. Training is slower than parallelized S4WM/TSSM-XL per paper (Figure 3).</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_comparison</strong></td>
                            <td>More memory-efficient at training; much faster during imagination (throughput) — roughly 10× higher than S4WM/TSSM-XL. However, training speed is slower due to sequential processing, and long-range fidelity is limited by vanishing-gradients/limited memory capacity.</td>
                        </tr>
                        <tr>
                            <td><strong>task_performance</strong></td>
                            <td>Performs poorly on long-horizon imagination and reward prediction within imagination (fails reward imagining tasks), and underperforms S4WM on MPC planning success; strong in probing tasks for representation utility (Memory Maze walls accuracy high).</td>
                        </tr>
                        <tr>
                            <td><strong>task_utility_analysis</strong></td>
                            <td>Although RSSM-TBTT representations are useful for certain offline probing/classification tasks (walls accuracy high), its limited long-term generative fidelity harms reward-imagination and planning utility, demonstrating that good retrospective representations don't necessarily translate to good imagined futures for planning.</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoffs_observed</strong></td>
                            <td>High imagination throughput and good probing performance vs poor long-horizon generation and reward-imagination accuracy; memory-efficiency vs limited long-range capacity. TBTT mitigates but does not eliminate long-term failures.</td>
                        </tr>
                        <tr>
                            <td><strong>design_choices</strong></td>
                            <td>GRU-based deterministic core (h_t), stochastic latents z_t, use of TBTT for improved memory, concat[h_t, z_t] as embedding for decoder and probes.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Compared to S4WM: faster imagination but worse long-term generation, reward prediction and planning; compared to TSSM-XL: generally worse at long-range tasks but better in imagination throughput and some probing metrics.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_configuration</strong></td>
                            <td>Paper finds TBTT helps long-term memory (RSSM-TBTT variant used) but still inferior to PSSM-based S4WM for very long horizons; recommended where imagination throughput and memory-efficiency are prioritized over ultra-long-range fidelity.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Facing off World Model Backbones: RNNs, Transformers, and S4', 'publication_date_yy_mm': '2023-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1261.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e1261.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of world models used in AI systems, including details about their fidelity, interpretability, computational efficiency, and task-specific utility.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>TSSM-XL</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Transformer-based State-Space Model with Transformer-XL (TSSM-XL / TransDreamer variant)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A Transformer-backed latent world model baseline that uses self-attention (Transformer) to compute priors over latents; to handle longer sequences the paper uses a Transformer-XL style caching mechanism (cache length m) to extend context while avoiding full quadratic cost on entire episode.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>TransDreamer: Reinforcement learning with Transformer world models</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>TSSM-XL</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Latent-variable world model where the prior p(z_t|...) is produced by stacked Transformer blocks over history embeddings g_{1:t} = MLP(concat[z_{t-1}, a_t]). Uses Transformer-XL style recurrence (segment caching) to extend context length (cache length m is a key hyperparameter). Posterior factorized per time step in experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>latent world model (Transformer backbone)</td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>Visual MBRL on partially observable mazes and MiniGrid tasks in the paper; evaluated up to very long sequences (up to 2000 steps experimentally).</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_metric</strong></td>
                            <td>Generation & reconstruction MSE per step, reward-prediction accuracy (inference & imagination), memory-recall MSE, DMLab perceptual metrics in comparison.</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_performance</strong></td>
                            <td>Long-term imagination Gen MSE: Two Rooms Gen MSE=2.92, Four Rooms Gen MSE=24.4, Ten Rooms Gen MSE=60.4 (Table 1). Reward-prediction imagination accuracy ~51% (Table 2). Memory-reasoning Gen MSE: Three Keys=1.27, Five Keys=0.36, Seven Keys=0.29 (Table 3). DMLab comparison not provided directly for TSSM-XL but cache length impacts recall quality.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_assessment</strong></td>
                            <td>Transformer attention mechanisms provide potential to inspect attention patterns (not explicitly used here); shown empirically to be better than S4 at context-dependent operations in some low-dimensional tasks and short-context recall (Two Rooms).</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_method</strong></td>
                            <td>No explicit attention visualization reported; context-dependent recall evaluated quantitatively and qualitatively; cache ablations performed (varying m) to study context effect.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost</strong></td>
                            <td>Parallelizable training (faster than RSSM); quadratic self-attention costs limit practical full-sequence usage, so cache length m trades off memory/time. Training speed comparable to S4WM for chosen m=128; larger caches increase training/memory and slow imagination.</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_comparison</strong></td>
                            <td>Trains much faster than RSSM-TBTT and comparable to S4WM; suffers from quadratic attention cost if long caches used; with cache m=128 chosen as compromise to match S4WM speed/memory in experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>task_performance</strong></td>
                            <td>Excels at short-context context-dependent recall (Two Rooms) and can perform well when cache size is increased (m up to 512 improves recall), but fails at reward prediction within imagination and degrades quickly on very long generation tasks (Four Rooms and Ten Rooms).</td>
                        </tr>
                        <tr>
                            <td><strong>task_utility_analysis</strong></td>
                            <td>Transformer backbone helps context-dependent retrieval when the necessary context is within its cache; however, quadratic scaling and limited effective cache make it hard to imagine extremely long horizons reliably, reducing utility for long-horizon planning unless expensive cache sizes are used.</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoffs_observed</strong></td>
                            <td>Better short-range/context operations vs high compute and memory for long context; increasing cache length m improves performance but slows training and imagination and increases memory consumption; still worse than S4WM for long-horizon generation quality.</td>
                        </tr>
                        <tr>
                            <td><strong>design_choices</strong></td>
                            <td>Transformer-XL style cache (m) to extend context while avoiding feeding entire sequence; factorized per-step posterior; same CNN encoder/decoder and discrete latents as other models to ensure fair comparison.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Compared to S4WM: TSSM-XL sometimes better for short-context recall but worse for long-term imagination and for reward prediction within imagination. Compared to RSSM-TBTT: faster training but lower imagination throughput; better short-term recall in some cases.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_configuration</strong></td>
                            <td>Paper used cache length m=128 as compromise (closest to S4WM in speed/memory). Increasing cache to m=512 improves context-dependent recall (Ten Rooms teleport) but at increased compute/memory cost.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Facing off World Model Backbones: RNNs, Transformers, and S4', 'publication_date_yy_mm': '2023-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1261.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e1261.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of world models used in AI systems, including details about their fidelity, interpretability, computational efficiency, and task-specific utility.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>S5WM</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>S5-based World Model (S5WM)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An instantiation of the S4WM framework using S5 layers (an S4 variant) that yields improved imagination and better low-dimensional probing utility due to more compact hidden states.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>S5WM</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Identical generative/latent architecture as S4WM but replaces S4 layers with S5 layers (a PSSM variant) which produce hidden states s_t of smaller dimension (comparable to h_t), enabling more effective offline probing and improved imagination fidelity in experiments reported in the appendix.</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>latent world model (PSSM / S5 backbone)</td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>Same visual MBRL benchmark set as S4WM; Memory Maze probing and long-term imagination tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_metric</strong></td>
                            <td>Generation & reconstruction MSE, offline probing accuracy/MSE.</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_performance</strong></td>
                            <td>Long-term imagination (Table 9): Two Rooms Gen MSE=0.6 (Recon 1.51), Four Rooms Gen MSE=9.2 (Recon 1.31), Ten Rooms Gen MSE=59.2 (Recon 1.31). Memory Maze probing: Walls Acc 98.3% (9×9), 81.8% (15×15); Objects MSE 1.82 (9×9), 25.3 (15×15) — S5WM outperforms RSSM-TBTT on 9×9 probing (Table 6 & text).</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_assessment</strong></td>
                            <td>More amenable to probing/interpretation than S4WM because S5 hidden state s_t has a smaller dimensionality similar to h_t, allowing concat[s_t, z_t] to be used by probing networks effectively.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_method</strong></td>
                            <td>Offline probing network (MLP) applied to concat[s_t, z_t] to measure how well hidden states encode task-relevant information.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost</strong></td>
                            <td>Similar training paradigm as S4WM; reported to improve imagination quality with modest changes. Exact compute trade-offs not numerically detailed, but S5 instantiation presented as promising with no prohibitive extra cost reported.</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_comparison</strong></td>
                            <td>Paper reports S5WM yields better probing and better imagination than S4WM in some tasks (Table 9, Appendix D) — suggests similar or slightly higher efficiency with better utility, but exact wall-clock comparisons for S5WM vs S4WM not detailed.</td>
                        </tr>
                        <tr>
                            <td><strong>task_performance</strong></td>
                            <td>Improves offline probing performance markedly (outperforms RSSM-TBTT on 9×9 Memory Maze probing) and shows better long-term imagination than S4WM in some settings documented in Appendix G.</td>
                        </tr>
                        <tr>
                            <td><strong>task_utility_analysis</strong></td>
                            <td>S5WM's more compact hidden states improve downstream probing and thus interpretation; improved imagination suggests this configuration may give better planning utility while retaining parallel training benefits.</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoffs_observed</strong></td>
                            <td>S5 yields better interpretability/probing without losing the long-range advantages of PSSMs, although Ten Rooms remains challenging; paper suggests potential but acknowledges more investigation needed.</td>
                        </tr>
                        <tr>
                            <td><strong>design_choices</strong></td>
                            <td>Replace S4 layers with S5 layers inside S4WM framework; extract S5 hidden states for probing; otherwise same latent/CNN/ELBO training choices.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>S5WM outperforms RSSM-TBTT on the Memory Maze probing benchmark and shows improved imagination over S4WM in reported comparisons; remains competitive against Transformer baselines for long-range tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_configuration</strong></td>
                            <td>Paper suggests S5WM is a promising instantiation of S4WM for balancing interpretability (compact s_t), fidelity, and planning utility; using S5 in S4WM + extracting s_t for probes recommended for downstream probing tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Facing off World Model Backbones: RNNs, Transformers, and S4', 'publication_date_yy_mm': '2023-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1261.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e1261.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of world models used in AI systems, including details about their fidelity, interpretability, computational efficiency, and task-specific utility.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>DreamerV3 (implementation)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>DreamerV3 (implementation details and reference used in paper)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An existing family of latent world-model-based RL agents; the paper uses DreamerV3 implementation details as a common engineering baseline (e.g., encoder/decoder, discrete latents, KL balancing) for fair comparisons.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>DreamerV3 (implementation basis)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Dreamer-style latent world model design choices (CNN encoder/decoder, categorical latents in discrete latent variants, ELBO training, KL balancing) used as implementation and hyperparameter inspirations; not the experimental target but used to ensure fair architecture baselines.</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>latent world model (implementation baseline)</td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>Used as implementation/hyperparameter baseline for visual MBRL tasks in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_metric</strong></td>
                            <td>Not directly evaluated as separate model in paper; used to implement probing and training choices.</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_performance</strong></td>
                            <td>Not reported as a standalone experimental model here.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_assessment</strong></td>
                            <td>Not discussed in detail; used for training/encoder-decoder design consistency.</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_method</strong></td>
                            <td>N/A (implementation basis)</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost</strong></td>
                            <td>N/A (implementation basis); paper used similar training schedules and architectures to keep comparisons fair.</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_comparison</strong></td>
                            <td>N/A</td>
                        </tr>
                        <tr>
                            <td><strong>task_performance</strong></td>
                            <td>N/A</td>
                        </tr>
                        <tr>
                            <td><strong>task_utility_analysis</strong></td>
                            <td>N/A</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoffs_observed</strong></td>
                            <td>N/A</td>
                        </tr>
                        <tr>
                            <td><strong>design_choices</strong></td>
                            <td>Used discrete categorical latents optimized with straight-through gradients; KL balancing and CNN encoder/decoder with layernorm/SiLU following DreamerV3 style.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>N/A (implementation details to ensure fair comparison across backbones).</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_configuration</strong></td>
                            <td>N/A</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Facing off World Model Backbones: RNNs, Transformers, and S4', 'publication_date_yy_mm': '2023-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1261.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e1261.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of world models used in AI systems, including details about their fidelity, interpretability, computational efficiency, and task-specific utility.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>TECO / other comparison models</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>TECO (and other prior world-model baselines: Clockwork VAE, Latent FDM)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>External prior works for long-term video/world-modeling used for comparison on DMLab (TECO best in cited table, S4WM close despite fewer parameters); TECO uses pretrained VQGAN encoder/decoder while S4WM uses jointly trained CNNs.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>TECO (referenced as TECO in paper)</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>TECO / Clockwork VAE / Latent FDM</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Prior long-term video/world-modeling approaches: TECO uses pretrained VQGAN and Transformer-style architectures for video prediction; Clockwork VAE and Latent FDM are other generative video models (diffusion-based or hierarchical VAE).</td>
                        </tr>
                        <tr>
                            <td><strong>model_type</strong></td>
                            <td>latent / generative world models (various architectures)</td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>Long-term video prediction / world-modeling on DMLab (TECO evaluation protocol) and related generative tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_metric</strong></td>
                            <td>Perceptual metrics: PSNR, SSIM, LPIPS, and number of parameters.</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_performance</strong></td>
                            <td>Table 8 reports comparative numbers: CW-VAE PSNR=12.6 SSIM=0.372 LPIPS=0.465; Latent FDM PSNR=17.8 SSIM=0.588 LPIPS=0.222; TECO PSNR=21.9 SSIM=0.703 LPIPS=0.157; S4WM PSNR=20.6 SSIM=0.667 LPIPS=0.196 (Table 8).</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_assessment</strong></td>
                            <td>Not discussed in this paper; varied across the referenced works (e.g., VQGAN-based pipelines more modular, diffusion models less interpretable).</td>
                        </tr>
                        <tr>
                            <td><strong>interpretability_method</strong></td>
                            <td>Not discussed here.</td>
                        </tr>
                        <tr>
                            <td><strong>computational_cost</strong></td>
                            <td>TECO much larger number of parameters (169M) compared to S4WM (41M) per Table 8; S4WM achieves close quality with fewer parameters.</td>
                        </tr>
                        <tr>
                            <td><strong>efficiency_comparison</strong></td>
                            <td>S4WM achieves near-TECO generation metrics with substantially fewer parameters (41M vs 169M) per the DMLab comparison (Table 8).</td>
                        </tr>
                        <tr>
                            <td><strong>task_performance</strong></td>
                            <td>TECO best on DMLab perceptual metrics; S4WM close and better than Clockwork VAE and Latent FDM given far fewer parameters.</td>
                        </tr>
                        <tr>
                            <td><strong>task_utility_analysis</strong></td>
                            <td>Shows S4WM's generalization of PSSMs to high-dimensional images is competitive with larger, pretrained-encoder based video models in DMLab, suggesting practical utility for compact models.</td>
                        </tr>
                        <tr>
                            <td><strong>tradeoffs_observed</strong></td>
                            <td>Pretrained VQGAN+Transformer (TECO) yields the best perceptual scores but at a heavy parameter/compute cost; S4WM reaches near performance with fewer params and simpler joint training.</td>
                        </tr>
                        <tr>
                            <td><strong>design_choices</strong></td>
                            <td>These prior models use different encoder-decoder strategies (pretrained VQGAN vs jointly trained CNN) and model families (diffusion, hierarchical VAEs, transformers).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Paper positions S4WM as a compact, jointly trained alternative that approaches TECO quality while being much smaller, and outperforms Clockwork VAE and Latent FDM in the provided metrics.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_configuration</strong></td>
                            <td>Not directly specified for these external models in this paper; S4WM presented as an efficient alternative.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Facing off World Model Backbones: RNNs, Transformers, and S4', 'publication_date_yy_mm': '2023-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Efficiently modeling long sequences with structured state spaces <em>(Rating: 2)</em></li>
                <li>Transformer-XL: Attentive language models beyond a fixed-length context <em>(Rating: 2)</em></li>
                <li>TransDreamer: Reinforcement learning with Transformer world models <em>(Rating: 2)</em></li>
                <li>Learning latent dynamics for planning from pixels <em>(Rating: 2)</em></li>
                <li>Evaluating long-term memory in 3D mazes <em>(Rating: 1)</em></li>
                <li>Structured state space models for in-context reinforcement learning <em>(Rating: 1)</em></li>
                <li>Decision S4: Efficient sequence-based RL via state spaces layers <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-1261",
    "paper_id": "paper-259342816",
    "extraction_schema_id": "extraction-schema-27",
    "extracted_data": [
        {
            "name_short": "S4WM",
            "name_full": "S4-based World Model (S4WM)",
            "brief_description": "A latent-variable visual world model introduced in this paper that embeds high-dimensional images into compact stochastic latents and models their temporal dynamics using stacks of parallelizable State Space Model (PSSM) blocks (instantiated with S4), enabling fully parallel training and recurrent imagination.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "S4WM",
            "model_description": "Probabilistic latent world model: CNN encoder produces per-step posterior sufficient statistics for discrete categorical latent z_t; a stack of PSSM/S4 blocks encodes history of (z, a) into embeddings h_t; priors and likelihoods are MLPs on h_t; decoder reconstructs images from concat[h_t, z_t]. Training via variational inference (ELBO) with factorized posterior by default; supports a Full-Posterior variant. Parallelizable training and recurrent single-step generation (imagination).",
            "model_type": "latent world model (PSSM/S4 backbone)",
            "task_domain": "Visual model-based reinforcement learning (partially observable 3D mazes and 2D MiniGrid variants; long-horizon imagination, recall, reward prediction, memory-based reasoning; DMLab comparison)",
            "fidelity_metric": "Reconstruction & generation MSE per step (MSE), reward prediction accuracy (%), offline probing metrics (classification accuracy / MSE), perceptual metrics for DMLab (PSNR, SSIM, LPIPS).",
            "fidelity_performance": "Long-term imagination Gen MSE: Two Rooms Gen MSE=7.3, Four Rooms Gen MSE=4.0, Ten Rooms Gen MSE=24.4 (Table 1). Reward-prediction (imagination) accuracy 100.0% across tested Distracting Memory widths (Table 2). Memory-based reasoning Gen MSE: Three Keys=0.04, Five Keys=0.27, Seven Keys=0.10 (Table 3). DMLab: PSNR=20.6, SSIM=0.667, LPIPS=0.196 (Table 8).",
            "interpretability_assessment": "Mostly a black-box neural latent model; imagined frames are visualized for qualitative interpretability. Standard probing (concat[h_t, z_t]) underperforms RNN baselines at some probing tasks, indicating h_t carries more local/time-step information; S4 internal hidden state s_t likely carries more global info but is high-dimensional, complicating use for probing.",
            "interpretability_method": "Visual inspection of generated image rollouts; offline probing networks (MLP) trained on latent embeddings concat[h_t, z_t]; ablation comparing factorized vs full-posterior. No symbolic/extractive interpretability used.",
            "computational_cost": "Parallelizable training (fast); instantiated experiments on a single NVIDIA RTX A6000. Training is reported as the fastest among compared backbones; imagination (recurrent generation) is slower than RNN baseline. Decoder decoding all steps in parallel dominates memory usage. Exact param counts vary by instantiation (paper matched models to comparable parameter counts).",
            "efficiency_comparison": "Trains much faster than RSSM-TBTT and comparable to Transformer-based TSSM-XL due to parallel training; imagination throughput lower — RSSM-TBTT achieves ~10x higher imagination throughput than S4WM; S4WM has sub-quadratic complexity vs Transformer's quadratic (theoretical advantage).",
            "task_performance": "Outperforms RSSM-TBTT and TSSM-XL on long-term imagination (better Gen MSE up to 500 steps), context-dependent recall in longer contexts, reward prediction within imagination (100% accuracy), and memory-based reasoning; in skill-level MPC planning, S4WM achieved 100% success on Three/ Five/Seven-Keys tasks (Table 7).",
            "task_utility_analysis": "High latent-generation fidelity translates to effective task utility: accurate long-horizon imagination yields accurate reward predictions and perfect offline planning success in tested tasks. Limitations: in very long episodes (Ten Rooms; context length 1101, query 900) all models struggle — S4WM better but still limited.",
            "tradeoffs_observed": "S4WM achieves superior long-term fidelity and fast parallel training but pays in imagination throughput (slower recurrent generation) compared to RNNs. Adding MLPs inside S4 blocks improves generation quality at some computational cost. Full-posterior improves long-horizon performance but is more computationally expensive. Compared to Transformers: S4WM superior for long-range memory; Transformers sometimes better at context-dependent retrieval for short contexts but scale poorly (quadratic) unless using cache.",
            "design_choices": "Latent discrete categorical codes with straight-through gradients; factorized posterior (parallel) by default with optional Full-Posterior S4WM variant; stacked S4 blocks with MLPs between layers; use of KL balancing (α=0.8); CNN encoder/decoder; supports replacement of S4 by other PSSMs (e.g., S5).",
            "comparison_to_alternatives": "Compared directly in experiments: S4WM &gt; TSSM-XL and RSSM-TBTT on long-term imagination (lower Gen MSE), better reward-imagination accuracy (100%), better memory-reasoning Gen MSE, and stronger planning (MPC success). Trains faster than RSSM-TBTT and comparable to TSSM-XL; imagination throughput worse than RSSM-TBTT. On Memory Maze probing RSSM-TBTT &gt; S4WM with concat[h_t,z_t], but S5-instantiation of S4WM (S5WM) outperforms RSSM.",
            "optimal_configuration": "Paper recommendations: keep MLPs in S4 blocks (S4WM-No-MLP degrades performance); consider Full-Posterior when longer episodes demand more capacity (better but costlier); instantiating S4WM with S5 (S5WM) improves probing and imagination — promising configuration. Use PSSM variants (S4/S5) depending on trade-off between hidden-state dimension (interpretability/probing) and compute.",
            "uuid": "e1261.0",
            "source_info": {
                "paper_title": "Facing off World Model Backbones: RNNs, Transformers, and S4",
                "publication_date_yy_mm": "2023-07"
            }
        },
        {
            "name_short": "RSSM-TBTT",
            "name_full": "Recurrent State-Space Model (RSSM) trained with Truncated Backpropagation Through Time (RSSM-TBTT)",
            "brief_description": "An RNN-based latent world model (RSSM) used as baseline; it compresses past latents and actions with a GRU into deterministic encoding h_t and predicts stochastic latent z_t priors/likelihoods; training with TBTT improves its long-term memory relative to naive RNN training.",
            "citation_title": "Learning latent dynamics for planning from pixels",
            "mention_or_use": "use",
            "model_name": "RSSM-TBTT",
            "model_description": "Latent world model with deterministic recurrent core (GRU) h_t = GRU(h_{t-1}, MLP(concat[z_{t-1}, a_t])) plus stochastic latent z_t; decoder uses concat[h_t, z_t] to reconstruct observations; trained with variational inference and truncated backpropagation through time to enhance long-range memory.",
            "model_type": "latent world model (RNN backbone)",
            "task_domain": "Visual MBRL on partially observable 3D mazes and 2D MiniGrid tasks used in the paper (same domains as S4WM/TSSM-XL).",
            "fidelity_metric": "Reconstruction & generation MSE, reward prediction accuracy, offline probing accuracy/MSE.",
            "fidelity_performance": "Long-term imagination Gen MSE: Two Rooms Gen MSE=2.21, Four Rooms Gen MSE=19.4, Ten Rooms Gen MSE=23.1 (Table 1). Reward-prediction (imagination) accuracies ~49–52% (close to random) across Distracting Memory widths (Table 2). Memory-reasoning Gen MSEs: Three Keys=5.16, Five Keys=6.36, Seven Keys=6.28 (Table 3). Offline probing on Memory Maze: Walls Acc 95.0% (9×9), 81.7% (15×15); Objects MSE 5.4 (9×9), 32.6 (15×15) (Table 6).",
            "interpretability_assessment": "More interpretable for downstream probing: h_t encodes global information and when used in probing concat[h_t, z_t] yields strong probing accuracy; latent trajectories and h_t are used to probe walls/objects states.",
            "interpretability_method": "Offline probing networks (MLP) trained on concat[h_t, z_t] to evaluate representation utility for downstream tasks (Memory Maze probing). Visualization of imagined rollouts for qualitative analysis.",
            "computational_cost": "Sequential training (RNN) — more memory-efficient during training than parallel methods; imagination (single-step recurrent generation) is very fast: reported ~10x higher imagination throughput than S4WM and TSSM-XL. Training is slower than parallelized S4WM/TSSM-XL per paper (Figure 3).",
            "efficiency_comparison": "More memory-efficient at training; much faster during imagination (throughput) — roughly 10× higher than S4WM/TSSM-XL. However, training speed is slower due to sequential processing, and long-range fidelity is limited by vanishing-gradients/limited memory capacity.",
            "task_performance": "Performs poorly on long-horizon imagination and reward prediction within imagination (fails reward imagining tasks), and underperforms S4WM on MPC planning success; strong in probing tasks for representation utility (Memory Maze walls accuracy high).",
            "task_utility_analysis": "Although RSSM-TBTT representations are useful for certain offline probing/classification tasks (walls accuracy high), its limited long-term generative fidelity harms reward-imagination and planning utility, demonstrating that good retrospective representations don't necessarily translate to good imagined futures for planning.",
            "tradeoffs_observed": "High imagination throughput and good probing performance vs poor long-horizon generation and reward-imagination accuracy; memory-efficiency vs limited long-range capacity. TBTT mitigates but does not eliminate long-term failures.",
            "design_choices": "GRU-based deterministic core (h_t), stochastic latents z_t, use of TBTT for improved memory, concat[h_t, z_t] as embedding for decoder and probes.",
            "comparison_to_alternatives": "Compared to S4WM: faster imagination but worse long-term generation, reward prediction and planning; compared to TSSM-XL: generally worse at long-range tasks but better in imagination throughput and some probing metrics.",
            "optimal_configuration": "Paper finds TBTT helps long-term memory (RSSM-TBTT variant used) but still inferior to PSSM-based S4WM for very long horizons; recommended where imagination throughput and memory-efficiency are prioritized over ultra-long-range fidelity.",
            "uuid": "e1261.1",
            "source_info": {
                "paper_title": "Facing off World Model Backbones: RNNs, Transformers, and S4",
                "publication_date_yy_mm": "2023-07"
            }
        },
        {
            "name_short": "TSSM-XL",
            "name_full": "Transformer-based State-Space Model with Transformer-XL (TSSM-XL / TransDreamer variant)",
            "brief_description": "A Transformer-backed latent world model baseline that uses self-attention (Transformer) to compute priors over latents; to handle longer sequences the paper uses a Transformer-XL style caching mechanism (cache length m) to extend context while avoiding full quadratic cost on entire episode.",
            "citation_title": "TransDreamer: Reinforcement learning with Transformer world models",
            "mention_or_use": "use",
            "model_name": "TSSM-XL",
            "model_description": "Latent-variable world model where the prior p(z_t|...) is produced by stacked Transformer blocks over history embeddings g_{1:t} = MLP(concat[z_{t-1}, a_t]). Uses Transformer-XL style recurrence (segment caching) to extend context length (cache length m is a key hyperparameter). Posterior factorized per time step in experiments.",
            "model_type": "latent world model (Transformer backbone)",
            "task_domain": "Visual MBRL on partially observable mazes and MiniGrid tasks in the paper; evaluated up to very long sequences (up to 2000 steps experimentally).",
            "fidelity_metric": "Generation & reconstruction MSE per step, reward-prediction accuracy (inference & imagination), memory-recall MSE, DMLab perceptual metrics in comparison.",
            "fidelity_performance": "Long-term imagination Gen MSE: Two Rooms Gen MSE=2.92, Four Rooms Gen MSE=24.4, Ten Rooms Gen MSE=60.4 (Table 1). Reward-prediction imagination accuracy ~51% (Table 2). Memory-reasoning Gen MSE: Three Keys=1.27, Five Keys=0.36, Seven Keys=0.29 (Table 3). DMLab comparison not provided directly for TSSM-XL but cache length impacts recall quality.",
            "interpretability_assessment": "Transformer attention mechanisms provide potential to inspect attention patterns (not explicitly used here); shown empirically to be better than S4 at context-dependent operations in some low-dimensional tasks and short-context recall (Two Rooms).",
            "interpretability_method": "No explicit attention visualization reported; context-dependent recall evaluated quantitatively and qualitatively; cache ablations performed (varying m) to study context effect.",
            "computational_cost": "Parallelizable training (faster than RSSM); quadratic self-attention costs limit practical full-sequence usage, so cache length m trades off memory/time. Training speed comparable to S4WM for chosen m=128; larger caches increase training/memory and slow imagination.",
            "efficiency_comparison": "Trains much faster than RSSM-TBTT and comparable to S4WM; suffers from quadratic attention cost if long caches used; with cache m=128 chosen as compromise to match S4WM speed/memory in experiments.",
            "task_performance": "Excels at short-context context-dependent recall (Two Rooms) and can perform well when cache size is increased (m up to 512 improves recall), but fails at reward prediction within imagination and degrades quickly on very long generation tasks (Four Rooms and Ten Rooms).",
            "task_utility_analysis": "Transformer backbone helps context-dependent retrieval when the necessary context is within its cache; however, quadratic scaling and limited effective cache make it hard to imagine extremely long horizons reliably, reducing utility for long-horizon planning unless expensive cache sizes are used.",
            "tradeoffs_observed": "Better short-range/context operations vs high compute and memory for long context; increasing cache length m improves performance but slows training and imagination and increases memory consumption; still worse than S4WM for long-horizon generation quality.",
            "design_choices": "Transformer-XL style cache (m) to extend context while avoiding feeding entire sequence; factorized per-step posterior; same CNN encoder/decoder and discrete latents as other models to ensure fair comparison.",
            "comparison_to_alternatives": "Compared to S4WM: TSSM-XL sometimes better for short-context recall but worse for long-term imagination and for reward prediction within imagination. Compared to RSSM-TBTT: faster training but lower imagination throughput; better short-term recall in some cases.",
            "optimal_configuration": "Paper used cache length m=128 as compromise (closest to S4WM in speed/memory). Increasing cache to m=512 improves context-dependent recall (Ten Rooms teleport) but at increased compute/memory cost.",
            "uuid": "e1261.2",
            "source_info": {
                "paper_title": "Facing off World Model Backbones: RNNs, Transformers, and S4",
                "publication_date_yy_mm": "2023-07"
            }
        },
        {
            "name_short": "S5WM",
            "name_full": "S5-based World Model (S5WM)",
            "brief_description": "An instantiation of the S4WM framework using S5 layers (an S4 variant) that yields improved imagination and better low-dimensional probing utility due to more compact hidden states.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "S5WM",
            "model_description": "Identical generative/latent architecture as S4WM but replaces S4 layers with S5 layers (a PSSM variant) which produce hidden states s_t of smaller dimension (comparable to h_t), enabling more effective offline probing and improved imagination fidelity in experiments reported in the appendix.",
            "model_type": "latent world model (PSSM / S5 backbone)",
            "task_domain": "Same visual MBRL benchmark set as S4WM; Memory Maze probing and long-term imagination tasks.",
            "fidelity_metric": "Generation & reconstruction MSE, offline probing accuracy/MSE.",
            "fidelity_performance": "Long-term imagination (Table 9): Two Rooms Gen MSE=0.6 (Recon 1.51), Four Rooms Gen MSE=9.2 (Recon 1.31), Ten Rooms Gen MSE=59.2 (Recon 1.31). Memory Maze probing: Walls Acc 98.3% (9×9), 81.8% (15×15); Objects MSE 1.82 (9×9), 25.3 (15×15) — S5WM outperforms RSSM-TBTT on 9×9 probing (Table 6 & text).",
            "interpretability_assessment": "More amenable to probing/interpretation than S4WM because S5 hidden state s_t has a smaller dimensionality similar to h_t, allowing concat[s_t, z_t] to be used by probing networks effectively.",
            "interpretability_method": "Offline probing network (MLP) applied to concat[s_t, z_t] to measure how well hidden states encode task-relevant information.",
            "computational_cost": "Similar training paradigm as S4WM; reported to improve imagination quality with modest changes. Exact compute trade-offs not numerically detailed, but S5 instantiation presented as promising with no prohibitive extra cost reported.",
            "efficiency_comparison": "Paper reports S5WM yields better probing and better imagination than S4WM in some tasks (Table 9, Appendix D) — suggests similar or slightly higher efficiency with better utility, but exact wall-clock comparisons for S5WM vs S4WM not detailed.",
            "task_performance": "Improves offline probing performance markedly (outperforms RSSM-TBTT on 9×9 Memory Maze probing) and shows better long-term imagination than S4WM in some settings documented in Appendix G.",
            "task_utility_analysis": "S5WM's more compact hidden states improve downstream probing and thus interpretation; improved imagination suggests this configuration may give better planning utility while retaining parallel training benefits.",
            "tradeoffs_observed": "S5 yields better interpretability/probing without losing the long-range advantages of PSSMs, although Ten Rooms remains challenging; paper suggests potential but acknowledges more investigation needed.",
            "design_choices": "Replace S4 layers with S5 layers inside S4WM framework; extract S5 hidden states for probing; otherwise same latent/CNN/ELBO training choices.",
            "comparison_to_alternatives": "S5WM outperforms RSSM-TBTT on the Memory Maze probing benchmark and shows improved imagination over S4WM in reported comparisons; remains competitive against Transformer baselines for long-range tasks.",
            "optimal_configuration": "Paper suggests S5WM is a promising instantiation of S4WM for balancing interpretability (compact s_t), fidelity, and planning utility; using S5 in S4WM + extracting s_t for probes recommended for downstream probing tasks.",
            "uuid": "e1261.3",
            "source_info": {
                "paper_title": "Facing off World Model Backbones: RNNs, Transformers, and S4",
                "publication_date_yy_mm": "2023-07"
            }
        },
        {
            "name_short": "DreamerV3 (implementation)",
            "name_full": "DreamerV3 (implementation details and reference used in paper)",
            "brief_description": "An existing family of latent world-model-based RL agents; the paper uses DreamerV3 implementation details as a common engineering baseline (e.g., encoder/decoder, discrete latents, KL balancing) for fair comparisons.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "DreamerV3 (implementation basis)",
            "model_description": "Dreamer-style latent world model design choices (CNN encoder/decoder, categorical latents in discrete latent variants, ELBO training, KL balancing) used as implementation and hyperparameter inspirations; not the experimental target but used to ensure fair architecture baselines.",
            "model_type": "latent world model (implementation baseline)",
            "task_domain": "Used as implementation/hyperparameter baseline for visual MBRL tasks in this paper.",
            "fidelity_metric": "Not directly evaluated as separate model in paper; used to implement probing and training choices.",
            "fidelity_performance": "Not reported as a standalone experimental model here.",
            "interpretability_assessment": "Not discussed in detail; used for training/encoder-decoder design consistency.",
            "interpretability_method": "N/A (implementation basis)",
            "computational_cost": "N/A (implementation basis); paper used similar training schedules and architectures to keep comparisons fair.",
            "efficiency_comparison": "N/A",
            "task_performance": "N/A",
            "task_utility_analysis": "N/A",
            "tradeoffs_observed": "N/A",
            "design_choices": "Used discrete categorical latents optimized with straight-through gradients; KL balancing and CNN encoder/decoder with layernorm/SiLU following DreamerV3 style.",
            "comparison_to_alternatives": "N/A (implementation details to ensure fair comparison across backbones).",
            "optimal_configuration": "N/A",
            "uuid": "e1261.4",
            "source_info": {
                "paper_title": "Facing off World Model Backbones: RNNs, Transformers, and S4",
                "publication_date_yy_mm": "2023-07"
            }
        },
        {
            "name_short": "TECO / other comparison models",
            "name_full": "TECO (and other prior world-model baselines: Clockwork VAE, Latent FDM)",
            "brief_description": "External prior works for long-term video/world-modeling used for comparison on DMLab (TECO best in cited table, S4WM close despite fewer parameters); TECO uses pretrained VQGAN encoder/decoder while S4WM uses jointly trained CNNs.",
            "citation_title": "TECO (referenced as TECO in paper)",
            "mention_or_use": "mention",
            "model_name": "TECO / Clockwork VAE / Latent FDM",
            "model_description": "Prior long-term video/world-modeling approaches: TECO uses pretrained VQGAN and Transformer-style architectures for video prediction; Clockwork VAE and Latent FDM are other generative video models (diffusion-based or hierarchical VAE).",
            "model_type": "latent / generative world models (various architectures)",
            "task_domain": "Long-term video prediction / world-modeling on DMLab (TECO evaluation protocol) and related generative tasks.",
            "fidelity_metric": "Perceptual metrics: PSNR, SSIM, LPIPS, and number of parameters.",
            "fidelity_performance": "Table 8 reports comparative numbers: CW-VAE PSNR=12.6 SSIM=0.372 LPIPS=0.465; Latent FDM PSNR=17.8 SSIM=0.588 LPIPS=0.222; TECO PSNR=21.9 SSIM=0.703 LPIPS=0.157; S4WM PSNR=20.6 SSIM=0.667 LPIPS=0.196 (Table 8).",
            "interpretability_assessment": "Not discussed in this paper; varied across the referenced works (e.g., VQGAN-based pipelines more modular, diffusion models less interpretable).",
            "interpretability_method": "Not discussed here.",
            "computational_cost": "TECO much larger number of parameters (169M) compared to S4WM (41M) per Table 8; S4WM achieves close quality with fewer parameters.",
            "efficiency_comparison": "S4WM achieves near-TECO generation metrics with substantially fewer parameters (41M vs 169M) per the DMLab comparison (Table 8).",
            "task_performance": "TECO best on DMLab perceptual metrics; S4WM close and better than Clockwork VAE and Latent FDM given far fewer parameters.",
            "task_utility_analysis": "Shows S4WM's generalization of PSSMs to high-dimensional images is competitive with larger, pretrained-encoder based video models in DMLab, suggesting practical utility for compact models.",
            "tradeoffs_observed": "Pretrained VQGAN+Transformer (TECO) yields the best perceptual scores but at a heavy parameter/compute cost; S4WM reaches near performance with fewer params and simpler joint training.",
            "design_choices": "These prior models use different encoder-decoder strategies (pretrained VQGAN vs jointly trained CNN) and model families (diffusion, hierarchical VAEs, transformers).",
            "comparison_to_alternatives": "Paper positions S4WM as a compact, jointly trained alternative that approaches TECO quality while being much smaller, and outperforms Clockwork VAE and Latent FDM in the provided metrics.",
            "optimal_configuration": "Not directly specified for these external models in this paper; S4WM presented as an efficient alternative.",
            "uuid": "e1261.5",
            "source_info": {
                "paper_title": "Facing off World Model Backbones: RNNs, Transformers, and S4",
                "publication_date_yy_mm": "2023-07"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Efficiently modeling long sequences with structured state spaces",
            "rating": 2,
            "sanitized_title": "efficiently_modeling_long_sequences_with_structured_state_spaces"
        },
        {
            "paper_title": "Transformer-XL: Attentive language models beyond a fixed-length context",
            "rating": 2,
            "sanitized_title": "transformerxl_attentive_language_models_beyond_a_fixedlength_context"
        },
        {
            "paper_title": "TransDreamer: Reinforcement learning with Transformer world models",
            "rating": 2,
            "sanitized_title": "transdreamer_reinforcement_learning_with_transformer_world_models"
        },
        {
            "paper_title": "Learning latent dynamics for planning from pixels",
            "rating": 2,
            "sanitized_title": "learning_latent_dynamics_for_planning_from_pixels"
        },
        {
            "paper_title": "Evaluating long-term memory in 3D mazes",
            "rating": 1,
            "sanitized_title": "evaluating_longterm_memory_in_3d_mazes"
        },
        {
            "paper_title": "Structured state space models for in-context reinforcement learning",
            "rating": 1,
            "sanitized_title": "structured_state_space_models_for_incontext_reinforcement_learning"
        },
        {
            "paper_title": "Decision S4: Efficient sequence-based RL via state spaces layers",
            "rating": 1,
            "sanitized_title": "decision_s4_efficient_sequencebased_rl_via_state_spaces_layers"
        }
    ],
    "cost": 0.035023,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Facing Off World Model Backbones: RNNs, Transformers, and S4</p>
<p>Fei Deng fei.deng@rutgers.edu 
Rutgers University</p>
<p>Junyeong Park 
Rutgers University</p>
<p>Sungjin Ahn sungjin.ahn@kaist.ac.kr 
Rutgers University</p>
<p>Facing Off World Model Backbones: RNNs, Transformers, and S4
6956AF2FDA9E7930D1E94E82D28C75E8
World models are a fundamental component in model-based reinforcement learning (MBRL).To perform temporally extended and consistent simulations of the future in partially observable environments, world models need to possess long-term memory.However, state-of-the-art MBRL agents, such as Dreamer, predominantly employ recurrent neural networks (RNNs) as their world model backbone, which have limited memory capacity.In this paper, we seek to explore alternative world model backbones for improving long-term memory.In particular, we investigate the effectiveness of Transformers and Structured State Space Sequence (S4) models, motivated by their remarkable ability to capture long-range dependencies in low-dimensional sequences and their complementary strengths.We propose S4WM, the first world model compatible with parallelizable SSMs including S4 and its variants.By incorporating latent variable modeling, S4WM can efficiently generate high-dimensional image sequences through latent imagination.Furthermore, we extensively compare RNN-, Transformer-, and S4-based world models across four sets of environments, which we have tailored to assess crucial memory capabilities of world models, including long-term imagination, context-dependent recall, reward prediction, and memory-based reasoning.Our findings demonstrate that S4WM outperforms Transformer-based world models in terms of long-term memory, while exhibiting greater efficiency during training and imagination.These results pave the way for the development of stronger MBRL agents.</p>
<p>Introduction</p>
<p>The human brain is frequently compared to a machine whose primary function is to construct models of the world, enabling us to predict, plan, and react to our environment effectively [51,39].These mental representations, referred to as world models, are integral to essential cognitive functions like decision-making and problem-solving.Similarly, one of the pivotal tasks in artificial intelligence (AI) systems that aim for human-like cognition is the development of analogous world models.</p>
<p>Model-Based Reinforcement Learning (MBRL) [42] has emerged as a promising approach that builds world models through interaction with the environment.As a fundamental component of MBRL, these world models empower artificial agents to anticipate the consequences of their actions and plan accordingly, leading to various advantages.Notably, MBRL offers superior sample efficiency, mitigating the high data requirements commonly associated with model-free methods.Moreover, MBRL exhibits enhanced exploration, transferability, safety, and explainability [42], making it well-suited for complex and dynamic environments where model-free methods tend to struggle.</p>
<p>The effectiveness and characteristics of world models crucially depend on their backbone neural network architecture.In particular, the backbone architecture dictates the model's capabilities of capturing long-term dependencies and handling stochasticity in the environment.Additionally, it affects the compactness of memory footprint and the speed of future prediction rollouts.Furthermore, in visual MBRL that finds extensive practical applications, the backbone architecture holds even greater significance than it does in state-based MBRL.This is due to the need to deal with highdimensional, unstructured, and temporal observations.Nevertheless, choosing the appropriate backbone architecture for visual MBRL has become a considerable challenge due to the rapidly evolving landscape of deep architectures for temporal sequence modeling.This includes the recent advancements in major backbone architecture classes, notably Transformers [61,5] and the Structured State Space Sequence models such as S4 [21] and S5 [57].</p>
<p>Traditionally, Recurrent Neural Networks (RNNs) [7,33] have been the go-to backbone architecture, thanks to their efficient use of computational resources in processing sequential data.However, RNNs tend to suffer from vanishing gradient issues [49], limiting their long-term memory capacity.Recently, Transformers [61] have demonstrated superior sequence modeling capabilities in multiple domains, including natural language processing and computer vision [12].Their self-attention mechanism grants direct access to all previous time steps, thereby enhancing long-term memory.Moreover, Transformers offer parallel trainability and exhibit faster training speeds than RNNs.However, their quadratic complexity and slow generation speed pose challenges when dealing with very long sequences.To address these limitations, the S4 model has been proposed, offering both parallel training and recurrent generation with sub-quadratic complexity.In the Long Range Arena [59] benchmark consisting of low-dimensional sequence modeling tasks, the S4 model outperforms many Transformer variants in both task performance and computational efficiency.</p>
<p>In this paper, we present two primary contributions.Firstly, we introduce S4WM, the first and general world model framework that is compatible with any Parallelizable SSMs (PSSMs) including S4, S5, and other S4 variants.This is a significant development since it was unclear whether the S4 model would be effective as a high-dimensional visual world model, and if so, how this could be achieved.To this end, we instantiate the S4WM with the S4 architecture to manage high-dimensional image sequences, and propose its probabilistic latent variable modeling framework based on variational inference.Secondly, we conduct the first empirical comparative study on the three major backbone architectures for visual world modeling-RNNs, Transformers, and S4.Our results show that S4WM outperforms RNNs and Transformers across multiple memory-demanding tasks, including long-term imagination, context-dependent recall, reward prediction, and memory-based reasoning.In terms of speed, S4WM trains the fastest, while RNNs exhibit significantly higher imagination throughput.We believe that by shedding light on the strengths and weaknesses of these backbones, our study contributes to a deeper understanding that can guide researchers and practitioners in selecting suitable architectures, and potentially inspire the development of novel approaches in this field.</p>
<p>Related Work</p>
<p>Structured State Space Sequence (S4) Model.Originally introduced in [21], S4 is a sequence modeling framework that solves all tasks in the Long Range Arena [59] for the first time.At its core is a structured parameterization of State Space Models (SSMs) that allows efficient computation and exhibits superior performance in capturing long-range dependencies both theoretically and empirically.However, the mathematical background of S4 is quite involved.To address this, a few recent works seek to simplify, understand, and improve S4 [23,20,40,22,57,24,47].It has been discovered that S4 and Transformers have complementary strengths [70,40,15,34,24].For example, Transformers can be better at capturing local (short-range) information and performing context-dependent operations.Therefore, hybrid architectures have been proposed to achieve the best of both worlds.Furthermore, S4 and its variants have found applications in various domains, such as image and video classification [43,36,34,62], audio generation [17], time-series generation [69], language modeling [70,15,40], and model-free reinforcement learning [10,38].Our study introduces the first world model compatible with S4 and its variants (more generally, parallelizable SSMs) for improving long-term memory in MBRL.We also investigate the strengths and weaknesses of S4 and Transformers in the context of world model learning.</p>
<p>World Models.World models [25] are typically implemented as dynamics models of the environment that enable the agent to plan into the future and learn policies from imagined trajectories.RNNs have been the predominant backbone architecture of world models.A notable example is RSSM [28], which has been widely used in both reconstruction-based [29-31, 65, 56, 16, 35, 63, 64, 68] and reconstruction-free [44-46, 11, 26] MBRL agents.With the advent of Transformers [61], recent works have also explored using Transformers as the world model backbone [5,41,54].While Transformers are less prone to vanishing gradients [49] than RNNs, their quadratic complexity limits their applicability to long sequences.For example, recent works [41,54] use a short imagination horizon of ∼20 steps.In contrast, S4WM can successfully imagine hundreds of steps into the future with sub-quadratic complexity.We also develop an improved Transformer-based world model that can deal with long sequences by employing Transformer-XL [9].</p>
<p>Agent Memory Benchmarks.While many RL benchmarks feature partially observable environments, they tend to evaluate multiple agent capabilities simultaneously [2,8,27] (e.g., exploration and modular skill learning), and may be solvable with a moderate memory capacity [14,48].Additionally, some benchmarks are designed for model-free agents [66,37,52], and may contain stochastic dynamics that are not controlled by the agents, making it hard to separately assess the memory capacity of world models.The recently proposed Memory Maze [50] focuses on measuring long-term memory and provides benchmark results for model-based agents.We build upon Memory Maze and introduce additional environments and tasks to probe a wider range of memory capabilities.Another recent work, TECO [67], also introduces datasets and a Transformer-based model for evaluating and improving long-term video prediction.Our work has a different focus than TECO in that we stress test models on extremely long sequences (up to 2000 steps), while TECO considers more visually complex environments, with sequence lengths capped at 300.Our experiment setup allows using relatively lightweight models to tackle significant challenges involving long-term memory.We include a comparison with TECO in Appendix F.</p>
<p>Background</p>
<p>S4 [21] and its variants [20,40,57,15] are specialized parameterizations of linear state space models.We first present relevant background on linear state space models, and then introduce the S4 model.</p>
<p>Linear State Space Models (SSMs) are a widely used sequence model that defines a mapping from a 1-D input signal u(t) to a 1-D output signal y(t).They can be discretized into a sequence-to-sequence mapping by a step size ∆.The continuous-time and discrete-time SSMs can be described as:</p>
<p>(continuous-time)</p>
<p>s ′ (t) = As(t) + Bu(t) y(t) = Cs(t) + Du(t) , (discrete-time)
s k = As k−1 + Bu k y k = Cs k + Du k .(1)
Here, the vectors s(t) and s k are the internal hidden state of the SSM, and the discrete-time matrices A, B, C, D can be computed from their continuous-time counterparts A, B, C, D and the step size ∆.We will primarily deal with the discrete-time SSMs, which allow efficient autoregressive generation like RNNs due to the recurrence in s k .</p>
<p>Unlike RNNs, however, linear SSMs can offer parallelizable computation like Transformers.That is, given the input sequence u 1:T , the output sequence y 1:T can be computed in parallel across time steps by a discrete convolution [21] or a parallel associative scan [57,4].In this work, we define the class of Parallelizable SSMs (PSSMs) to be the SSMs that provide the following interface for both parallel and single-step computation:</p>
<p>(parallel) y 1:T , s T = PSSM(u 1:T , s 0 ) , (single step) y k , s k = PSSM(u k , s k−1 ) ,</p>
<p>where the inputs u k and outputs y k can be vectors.</p>
<p>The S4 model aims to use SSMs for deep sequence modeling, where the matrices A, B, C, D and the step size ∆ are learnable parameters to be optimized by gradient descent.Because SSMs involve computing powers of A, which is in general expensive and can lead to the exploding/vanishing gradients problem [49], SSMs with a randomly initialized A perform very poorly in practice [19].</p>
<p>To address these problems, S4 parameterizes A as a Diagonal Plus Low-Rank (DPLR) matrix [21,17]: A = Λ − P P * , where Λ is a diagonal matrix, P is typically a column vector (with rank 1), and P * is the conjugate transpose of P .This parameterization allows efficient computation of powers of A, f / H J H M U k j K o B w r N T Q s R P w M i y B E U 7 z m p s q m m A y x W M 6 1 F T g i C o v W 2 T P r X O t j K w w l v o J s B b q 7 4 0 M R 0 r N o 0 B P F i H V q l e I / 3 n D F M I 7 L 2 M i S Y E K s j w U p t y C 2 C q K s E Z M U g J 8 r g k m k u m s F p l g i Q n o u m q 6 B G f 1 y + u k d 9 l 0 b p r X D 1 e N V r u s o
4 p O 0 R m 6 Q A 6 6 R S 3 U R h 3 U R Q T N 0 D N 6 R W 9 G b r w Y 7 8 b H c r R i l D s n 6 A + M z x + N o 5 T O &lt; / l a t e x i t &gt; x1 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " F 6 b w m M O g z m e w T q v M C B F i N K + X W M s = " &gt; A A A B / n i c b V A 9 S w N B E J 2 L X z F + R S 1 t F o N g F e 7 E q G X A J m U E 8 w H J E f Y 2 e 8 m S 3 b 1 j d 0 8 I x 4 G / w V Z r O 7 H 1 r 1 j 6 T 9 w k V 5 j E B w O P 9 2 a Y m R f E n G n j u t 9 O Y W N z a 3 u n u F v a 2 z 8 4 P C o f n 7 R 1 l C h C W y T i k e o G W F P O J G 0 Z Z j j t x o p i E X D a C S b 3 M 7 / z R J V m k X w 0 0 5 j 6 A o 8 k C x n B x k r d f i D S c T b w B u W K W 3 X n Q O v E y 0 k F c j Q H 5 Z / + M C K J o N I Q j r X u e W 5 s / B Q r w w i n W a m f a B p j M s E j 2 r N U Y k G 1 n 8 7 v z d C F V Y Y o j J Q t a d B c / T u R Y q H 1 V A S 2 U 2 A z 1 q v e T P z P 6 y U m v P N T J u P E U E k W i 8 K E I x O h 2 f N o y B Q l h k 8 t w U Q x e y s i Y 6 w w M T a i p S 2 B y G w m 3 m o C 6 6 R 9 V f V u q r W H 6 0 q 9 k a d T h D M 4 h 0 v w 4 B b q 0 I A m t I A A h x d 4 h T f n 2 X l 3 P p z P R W v B y W d O Y Q n O 1 y / F e J a L &lt; / l a t e x i t &gt; h1 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " Q x d / u 7 Q W P L 3 U + y c 4 a h 9 T t I X E x C w = " &gt; A A A C A n i c b V D L S s N A F L 2 p r 1 p f V Z d u B o v g q i T i a 1 l w 0 2 U F + 4 A m l M l 0 0 g 6 d T M L M R C w h O 7 / B r a 7 d i V t / x K V / 4 q T N w r Y e u H A 4 5 1 7 u 4 f g x Z 0 r b 9 r d V W l v f 2 N w q b 1 d 2 d v f 2 D 6 q H R x 0 V J Z L Q N o l 4 J H s + V p Q z Q d u a a U 5 7 s a Q 4 9 D n t + p O 7 3 O 8 + U q l Y J B 7 0 N K Z e i E e C B Y x g b S T X D b E e + 0 H 6 l A 3 s Q b V m 1 + 0 Z 0 C p x C l K D A q 1 B 9 c c d R i Q J q d C E Y 6 X 6 j h 1 r L 8 V S M 8 J p V n E T R W N M J n h E + 4 Y K H F L l p b P M G T o z y h A F k T Q j N J q p f y 9 S H C o 1 D X 2 z m W d U y 1 4 u / u f 1 E x 3 c e i k T c a K p I P N H Q c K R j l B e A B o y S Y n m U 0 M w k c x k R W S M J S b a 1 L T w x Q 8 z 0 4 m z 3 M A q 6 V z U n e v 6 1 f 1 l r d E s 2 i n D C Z z C O T h w A w 1 o Q g v a Q C C G F 3 i F N + v Z e r c + r M / 5 a s k q b o 5 h A d b X L x S a m G U = &lt; / l a t e x i t &gt; x0 Enc &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " K E Q t t H w 0 h I 5 X j T M / s 4 k L R + 4 2 7 A 0 = " &gt; A A A C A n i c b V D L S s N A F L 2 p r 1 p f V Z d u B o v g q i T i a 1 l w 0 2 U F + 4 A m l M l 0 0 g 6 d T M L M R K g h O 7 / B r a 7 d i V t / x K V / 4 q T N w r Y e u H A 4 5 1 7 u 4 f g x Z 0 r b 9 r d V W l v f 2 N w q b 1 d 2 d v f 2 D 6 q H R x 0 V J Z L Q N o l 4 J H s + V p Q z Q d u a a U 5 7 s a Q 4 9 D n t + p O 7 3 O 8 + U q l Y J B 7 0 N K Z e i E e C B Y x g b S T X D b E e + 0 H 6 l A 3 s Q b V m 1 + 0 Z 0 C p x C l K D A q 1 B 9 c c d R i Q J q d C E Y 6 X 6 j h 1 r L 8 V S M 8 J p V n E T R W N M J n h E + 4 Y K H F L l p b P M G T o z y h A F k T Q j N J q p f y 9 S H C o 1 D X 2 z m W d U y 1 4 u / u f 1 E x 3 c e i k T c a K p I P N H Q c K R j l B e A B o y S Y n m U 0 M w k c x k R W S M J S b a 1 L T w x Q 8 z 0 4 m z 3 M A q 6 V z U n e v 6 1 f 1 l r d E s 2 i n D C Z z C O T h w A w 1 o Q g v a Q C C G F 3 i F N + v Z e r c + r M / 5 a s k q b o 5 h A d b X L x f G m G c = &lt; / l a t e x i t &gt; z0 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 6 S p V b 0 R q H / o Z 9 T y G + l M 1 F A S Z V k Y = " &gt; A A A B / n i c b V A 9 S w N B E J 2 L X z F + R S 1 t F o N g F e 7 E q G X A J m U E 8 w H J E f Y 2 e 8 m S 3 b 1 j d 0 8 I x 4 G / w V Z r O 7 H 1 r 1 j 6 T 9 w k V 5 j E B w O P 9 2 a Y m R f E n G n j u t 9 O Y W N z a 3 u n u F v a 2 z 8 4 P C o f n 7 R 1 l C h C W y T i k e o G W F P O J G 0 Z Z j j t x o p i E X D a C S b 3 M 7 / z R J V m k X w 0 0 5 j 6 A o 8 k C x n B x k r d f i B S n A 2 8 Q b n i V t 0 5 0 D r x c l K B H M 1 B + a c / j E g i q D S E Y 6 1 7 n h s b P 8 X K M M J p V u o n m s a Y T P C I 9 i y V W F D t p / N 7 M 3 R h l S E K I 2 V L G j R X / 0 6 k W G g 9 F Y H t F N i M 9 a o 3 E / / z e o k J 7 / y U y T g x V J L F o j D h y E R o 9 j w a M k W J 4 V N L M F H M 3 o r I G C t M j I 1 o a U s g M p u J t 5 r A O m l f V b 2 b a u 3 h u l J v 5 O k U 4 Q z O 4 R I 8 u I U 6 N K A J L S D A 4 Q V e 4 c 1 5 d t 6 d D + d z 0 V p w 8 p l T W I L z 9 Q u 6 X p a E &lt; / l a t e x i t &gt; a1 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " K a p M a I 9 6 k R G F G T + S f b x H h G K J 1 a w = " &gt; A A A C C n i c b V D L S s N A F J 3 4 r P U V 6 9 L N Y B F c l a T 4 W h b c d F n B P q A J Z T K d t E N n J m F m I i 0 h f + A 3 u N W 1 O 3 H r T 7 j 0 T 5 y 0 W d j W A x c O 5 9 z L P Z w g Z l R p x / m 2 N j a 3 t n d 2 S 3 v l / Y P D o 2 P 7 p N J R U S I x a e O I R b I X I E U Y F a S t q W a k F 0 u C e M B I N 5 j c 5 3 7 3 i U h F I / G o Z z H x O R o J G l K M t J E G d s U b I 5 1 6 H O l x E K b T L B v U B 3 b V q T l z w H X i F q Q K C r Q G 9 o 8 3 j H D C i d C Y I a X 6 r h N r P 0 V S U 8 x I V v Y S R W K E J 2 h E + o Y K x I n y 0 3 n 2 D F 4 Y Z Q j D S J o R G s 7 V v x c p 4 k r N e G A 2 8 5 B q 1 c v F / 7 x + o s M 7 P 6 U i T j Q R e P E o T B j U E c y L g E M q C d Z s Z g j C k p q s E I + R R F i b u p a + B D w z n b i r D a y T T r 3 m 3 t S u H 6 6 q j W b R T g m c g X N w C V x w C x q g C V q g D T C Y g h f w C t 6 s Z + v d + r A + F 6 s b V n F z C p Z g f f 0 C n p + b Z Q = = &lt; / l a t e x i t &gt; x2 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " T b G 7 2 g f 4 V x u S j h Z c A R w w / D U d v 5 g = " &gt; A A A B / n i c b V D L S g N B E O y N r x h f U Y 9 e B o P g K e w G X 8 e A l x w j m A c k S 5 i d z C Z D Z m a X m V k h L A t + g 1 c 9 e x O v / o p H / 8 R J s g e T W N B Q V H X T 3 R X E n G n j u t 9 O Y W N z a 3 u n u F v a 2 z 8 4 P C o f n 7 R 1 l C h C W y T i k e o G W F P O J G 0 Z Z j j t x o p i E X D a C S b 3 M 7 / z R J V m k X w 0 0 5 j 6 A o 8 k C x n B x k r d f i D S c T a o D c o V t + r O g d a J l 5 M K 5 G g O y j / 9 Y U Q S Q a U h H G v d 8 9 z Y + C l W h h F O s 1 I / 0 T T G Z I J H t G e p x I J q P 5 3 f m 6 E L q w x R G C l b 0 q C 5 + n c i x U L r q Q h s p 8 B m r F e 9 m f i f 1 0 t M e O e n T M a J o Z I s F o U J R y Z C s + f R k C l K D J 9 a g o l i 9 l Z E x l h h Y m x E S 1 s C k d l M v N U E 1 k m 7 V v V u q t c P V 5 V 6 I 0 + n C G d w D p f g w S 3 U o Q F N a A E B D i / w C m / O s / P u f D i f i 9 a C k 8 + c w h K c r 1 / H C 5 a M &lt; / l a t e x i t &gt; h2 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " f 3 g k h J W 1 r v K 2 g W g m 7 c v 3 D j 6 k c G A = " &gt; A A A C A n i c b V D L S s N A F L 2 p r 1 p f V Z d u B o v g q i T i a 1 l w 0 2 U F + 4 A m l M l 0 0 g 6 d T M L M R C w h O 7 / B r a 7 d i V t / x K V / 4 q T N w r Y e u H A 4 5 1 7 u 4 f g x Z 0 r b 9 r d V W l v f 2 N w q b 1 d 2 d v f 2 D 6 q H R x 0 V J Z L Q N o l 4 J H s + V p Q z Q d u a a U 5 7 s a Q 4 9 D n t + p O 7 3 O 8 + U q l Y J B 7 0 N K Z e i E e C B Y x g b S T X D b E e + 0 H 6 l A 2 c Q b V m 1 + 0 Z 0 C p x C l K D A q 1 B 9 c c d R i Q J q d C E Y 6 X 6 j h 1 r L 8 V S M 8 J p V n E T R W N M J n h E + 4 Y K H F L l p b P M G T o z y h A F k T Q j N J q p f y 9 S H C o 1 D X 2 z m W d U y 1 4 u / u f 1 E x 3 c e i k T c a K p I P N H Q c K R j l B e A B o y S Y n m U 0 M w k c x k R W S M J S b a 1 L T w x Q 8 z 0 4 m z 3 M A q 6 V z U n e v 6 1 f 1 l r d E s 2 i n D C Z z C O T h w A w 1 o Q g v a Q C C G F 3 i F N + v Z e r c + r M / 5 a s k q b o 5 h A d b X L x Y t m G Y = &lt; / l a t e x i t &gt; x1 Enc &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " w + Y g W R E R C X e z q 9 d b 0 k H / V 6 1 f M / Q = " &gt; A A A C A n i c b V D L S s N A F L 2 p r 1 p f V Z d u B o v g q i T i a 1 l w 0 2 U F + 4 A m l M l 0 0 g 6 d T M L M R K g h O 7 / B r a 7 d i V t / x K V / 4 q T N w r Y e u H A 4 5 1 7 u 4 f g x Z 0 r b 9 r d V W l v f 2 N w q b 1 d 2 d v f 2 D 6 q H R x 0 V J Z L Q N o l 4 J H s + V p Q z Q d u a a U 5 7 s a Q 4 9 D n t + p O 7 3 O 8 + U q l Y J B 7 0 N K Z e i E e C B Y x g b S T X D b E e + 0 H 6 l A 2 c Q b V m 1 + 0 Z 0 C p x C l K D A q 1 B 9 c c d R i Q J q d C E Y 6 X 6 j h 1 r L 8 V S M 8 J p V n E T R W N M J n h E + 4 Y K H F L l p b P M G T o z y h A F k T Q j N J q p f y 9 S H C o 1 D X 2 z m W d U y 1 4 u / u f 1 E x 3 c e i k T c a K p I P N H Q c K R j l B e A B o y S Y n m U 0 M w k c x k R W S M J S b a 1 L T w x Q 8 z 0 4 m z 3 M A q 6 V z U n e v 6 1 f 1 l r d E s 2 i n D C Z z C O T h w A w 1 o Q g v a Q C C G F 3 i F N + v Z e r c + r M / 5 a s k q b o 5 h A d b X L x l Z m G g = &lt; / l a t e x i t &gt; z1 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " b 0 a g k e q G o o S b Y A g 7 K h / C + z u Q 5 / k = " &gt; A A A B / n i c b V D L S g N B E O y N r x h f U Y 9 e B o P g K e w G X 8 e A l x w j m A c k S 5 i d z C Z D Z m a X m V k h L A t + g 1 c 9 e x O v / o p H / 8 R J s g e T W N B Q V H X T 3 R X E n G n j u t 9 O Y W N z a 3 u n u F v a 2 z 8 4 P C o f n 7 R 1 l C h C W y T i k e o G W F P O J G 0 Z Z j j t x o p i E X D a C S b 3 M 7 / z R J V m k X w 0 0 5 j 6 A o 8 k C x n B x k r d f i B S n A 1 q g 3 L F r b p z o H X i 5 a Q C O Z q D 8 k 9 / G J F E U G k I x 1 r 3 P D c 2 f o q V Y Y T T r N R P N I 0 x m e A R 7 V k q s a D a T + f 3 Z u j C K k M U R s q W N G i u / p 1 I s d B 6 K g L b K b A Z 6 1 V v J v 7 n 9 R I T 3 v k p k 3 F i q C S L R W H C k Y n Q 7 H k 0 Z I o S w 6 e W Y K K Y v R W R M V a Y G B v R 0 p Z A Z D Y T b z W B d d K u V b 2 b 6 v X D VX f J l z e y M l X a q N G o L M = " &gt; A A A C A n i c b V D L S s N A F L 3 x W e u r 6 t J N s A i u S l J 8 L Q t u u q x g H 9 C E M p l O 2 q E z k z A z E U v I z m 9 w q 2 t 3 4 t Y f c e m f O G m z s K 0 H L h z O u Z d 7 O E H M q N K O 8 2 2 t r W 9 s b m 2 X d s q 7 e / s H h 5 W j 4 4 6 K E o l J G 0 c s k r 0 A K c K o I G 1 N N S O 9 W B L E A 0 a 6 w e Q u 9 7 u P R C o a i Q c 9 j Y n P 0 U j Q k G K k j e R 5 H O l x E K Z P 2 a A + q F S d m j O D v U r c g l S h Q G t Q + f G G E U 4 4 E R o z p F T f d W L t p 0 h q i h n J y l 6 i S I z w B I 1 I 3 1 C B O F F + O s u c 2 e d G G d p h J M 0 I b c / U v x c p 4 k p N e W A 2 8 4 x q 2 c v F / 7 x + o s N b P 6 U i T j Q R e P 4 o T J i t I z s v w B 5 S S b B m U 0 M Q l t R k t f E Y S Y S 1 q W n h S 8 A z 0 4 m 7 3 M A q 6 d R r 7 n X t 6 v 6 y 2 m g W 7 Z T g F M 7 g A l y 4 g Q Y 0 o Q V t w B D D C 7 z C m / V s v V s f 1 u d 8 d c 0 q b k 5 g A d b X L x f A m G c = &lt; / l a t e x i t &gt; x2
Enc &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " H 1 J i G i + A p 3 N a N q q y p e P 8 u Q
C o U x w = " &gt; A A A C A n i c b V D L S s N A F L 3 x W e u r 6 t J N s A i u S l J 8 L Q t u u q x g H 9 C E M p l O 2 q E z k z A z E W r I z m 9 w q 2 t 3 4 t Y f c e m f O G m z s K 0 H L h z O u Z d 7 O E H M q N K O 8 2 2 t r W 9 s b m 2 X d s q 7 e / s H h 5 W j 4 4 6 K E o l J G 0 c s k r 0 A K c K o I G 1 N N S O 9 W B L E A 0 a 6 w e Q u 9 7 u P R C o a i Q c 9 j Y n P 0 U j Q k G K k j e R 5 H O l x E K Z P 2 a A + q F S d m j O D v U r c g l S h Q G t Q + f G G E U 4 4 E R o z p F T f d W L t p 0 h q i h n J y l 6 i S I z w B I 1 I 3 1 C B O F F + O s u c 2 e d G G d p h J M 0 I b c / U v x c p 4 k p N e W A 2 8 4 x q 2 c v F / 7 x + o s N b P 6 U i T j Q R e P 4 o T J i t I z s v w B 5 S S b B m U 0 M Q l t R k t f E Y S Y S 1 q W n h S 8 A z 0 4 m 7 3 M A q 6 d R r 7 n X t 6 v 6 y 2 m g W 7 Z T g F M 7 g A l y 4 g Q Y 0 o Q V t w B D D C 7 z C m / V s v V s f 1 u d 8 d c 0 q b k 5 g A d b X L x r s m G k = &lt; / l a t e x i t &gt; z2 Prior Posterior S4 Blocks (parallel) &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " Q x d / u 7 Q W P L 3 U + y c 4 a h 9 T t I X E x C w = " &gt; A A A C A n i c b V D L S s N A F L 2 p r 1 p f V Z d u B o v g q i T i a 1 l w 0 2 U F + 4 A m l M l 0 0 g 6 d T M L M R C w h O 7 / B r a 7 d i V t / x K V / 4 q T N w r Y e u H A 4 5 1 7 u 4 f g x Z 0 r b 9 r d V W l v f 2 N w q b 1 d 2 d v f 2 D 6 q H R x 0 V J Z L Q N o l 4 J H s + V p Q z Q d u a a U 5 7 s a Q 4 9 D n t + p O 7 3 O 8 + U q l Y J B 7 0 N K Z e i E e C B Y x g b S T X D b E e + 0 H 6 l A 3 s Q b V m 1 + 0 Z 0 C p x C l K D A q 1 B 9 c c d R i Q J q d C E Y 6 X 6 j h 1 r L 8 V S M 8 J p V n E T R W N M J n h E + 4 Y K H F L l p b P M G T o z y h A F k T Q j N J q p f y 9 S H C o 1 D X 2 z m W d U y 1 4 u / u f 1 E x 3 c e i k T c a K p I P N H Q c K R j l B e A B o y S Y n m U 0 M w k c x k R W S M J S b a 1 L T w x Q 8 z 0 4 m z 3 M A q 6 V z U n e v 6 1 f 1 l r d E s 2 i n D C Z z C O T h w A w 1 o Q g v a Q C C G F 3 i F N + v Z e r c + r M / 5 a s k q b o 5 h A d b X L x S a m G U = &lt; / l a t e x i t &gt; x0 Enc &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " K E Q t t H w 0 h I 5 X j T M / s 4 k L R + 4 2 7 A 0 = " &gt; A A A C A n i c b V D L S s N A F L 2 p r 1 p f V Z d u B o v g q i T i a 1 l w 0 2 U F + 4 A m l M l 0 0 g 6 d T M L M R K g h O 7 / B r a 7 d i V t / x K V / 4 q T N w r Y e u H A 4 5 1 7 u 4 f g x Z 0 r b 9 r d V W l v f 2 N w q b 1 d 2 d v f 2 D 6 q H R x 0 V J Z L Q N o l 4 J H s + V p Q z Q d u a a U 5 7 s a Q 4 9 D n t + p O 7 3 O 8 + U q l Y J B 7 0 N K Z e i E e C B Y x g b S T X D b E e + 0 H 6 l A 3 s Q b V m 1 + 0 Z 0 C p x C l K D A q 1 B 9 c c d R i Q J q d C E Y 6 X 6 j h 1 r L 8 V S M 8 J p V n E T R W N M J n h E + 4 Y K H F L l p b P M G T o z y h A F k T Q j N J q p f y 9 S H C o 1 D X 2 z m W d U y 1 4 u / u f 1 E x 3 c e i k T c a K p I P N H Q c K R j l B e A B o y S Y n m U 0 M w k c x k R W S M J S b a 1 L T w x Q 8 z 0 4 m z 3 M A q 6 V z U n e v 6 1 f 1 l r d E s 2 i n D C Z z C O T h w A w 1 o Q g v a Q C C G F 3 i F N + v Z e r c + r M / 5 a s k q b o 5 h A d b X L x f G m G c = &lt; / l a t e x i t &gt; z0 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 6 S p V b 0 R q H / o Z 9 T y G + l M 1 F A S Z V k Y = " &gt; A A A B / n i c b V A 9 S w N B E J 2 L X z F + R S 1 t F o N g F e 7 E q G X A J m U E 8 w H J E f Y 2 e 8 m S 3 b 1 j d 0 8 I x 4 G / w V Z r O 7 H 1 r 1 j 6 T 9 w k V 5 j E B w O P 9 2 a Y m R f E n G n j u t 9 O Y W N z a 3 u n u F v a 2 z 8 4 P C o f n 7 R 1 l C h C W y T i k e o G W F P O J G 0 Z Z j j t x o p i E X D a C S b 3 M 7 / z R J V m k X w 0 0 5 j 6 A o 8 k C x n B x k r d f i B S n A 2 8 Q b n i V t 0 5 0 D r x c l K B H M 1 B + a c / j E g i q D S E Y 6 1 7 n h s b P 8 X K M M J p V u o n m s a Y T P C I 9 i y V W F D t p / N 7 M 3 R h l S E K I 2 V L G j R X / 0 6 k W G g 9 F Y H t F N i M 9 a o 3 E / / z e o k J 7 / y U y T g x V J L F o j D h y E R o 9 j w a M k W J 4 V N L M F H M 3 o r I G C t M j I 1 o a U s g M p u J t 5 r A O m l f V b 2 b a u 3 h u l J v 5 O k U 4 Q z O 4 R I 8 u I U 6 N K A J L S D A 4 Q V e 4 c 1 5 d t 6 d D + d z 0 V p w 8 p l T W I L z 9 Q u 6 X p a E &lt; / l a t e x i t &gt; a1 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " f 3 g k h J W 1 r v K 2 g W g m 7 c v 3 D j 6 k c G A = " &gt; A A A C A n i c b V D L S s N A F L 2 p r 1 p f V Z d u B o v g q i T i a 1 l w 0 2 U F + 4 A m l M l 0 0 g 6 d T M L M R C w h O 7 / B r a 7 d i V t / x K V / 4 q T N w r Y e u H A 4 5 1 7 u 4 f g x Z 0 r b 9 r d V W l v f 2 N w q b 1 d 2 d v f 2 D 6 q H R x 0 V J Z L Q N o l 4 J H s + V p Q z Q d u a a U 5 7 s a Q 4 9 D n t + p O 7 3 O 8 + U q l Y J B 7 0 N K Z e i E e C B Y x g b S T X D b E e + 0 H 6 l A 2 c Q b V m 1 + 0 Z 0 C p x C l K D A q 1 B 9 c c d R i Q J q d C E Y 6 X 6 j h 1 r L 8 V S M 8 J p V n E T R W N M J n h E + 4 Y K H F L l p b P M G T o z y h A F k T Q j N J q p f y 9 S H C o 1 D X 2 z m W d U y 1 4 u / u f 1 E x 3 c e i k T c a K p I P N H Q c K R j l B e A B o y S Y n m U 0 M w k c x k R W S M J S b a 1 L T w x Q 8 z 0 4 m z 3 M A q 6 V z U n e v 6 1 f 1 l r d E s 2 i n D C Z z C O T h w A w 1 o Q g v a Q C C G F 3 i F N + v Z e r c + r M / 5 a s k q b o 5 h A d b X L x Y t m G Y = &lt; / l a t e x i t &gt; x1 Enc &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " w + Y g W R E R C X e z q 9 d b 0 k H / V 6 1 f M / Q = " &gt; A A A C A n i c b V D L S s N A F L 2 p r 1 p f V Z d u B o v g q i T i a 1 l w 0 2 U F + 4 A m l M l 0 0 g 6 d T M L M R K g h O 7 / B r a 7 d i V t / x K V / 4 q T N w r Y e u H A 4 5 1 7 u 4 f g x Z 0 r b 9 r d V W l v f 2 N w q b 1 d 2 d v f 2 D 6 q H R x 0 V J Z L Q N o l 4 J H s + V p Q z Q d u a a U 5 7 s a Q 4 9 D n t + p O 7 3 O 8 + U q l Y J B 7 0 N K Z e i E e C B Y x g b S T X D b E e + 0 H 6 l A 2 c Q b V m 1 + 0 Z 0 C p x C l K D A q 1 B 9 c c d R i Q J q d C E Y 6 X 6 j h 1 r L 8 V S M 8 J p V n E T R W N M J n h E + 4 Y K H F L l p b P M G T o z y h A F k T Q j N J q p f y 9 S H C o 1 D X 2 z m W d U y 1 4 u / u f 1 E x 3 c e i k T c a K p I P N H Q c K R j l B e A B o y S Y n m U 0 M w k c x k R W S M J S b a 1 L T w x Q 8 z 0 4 m z 3 M A q 6 V z U n e v 6 1 f 1 l r d E s 2 i n D C Z z C O T h w A w 1 o Q g v a Q C C G F 3 i F N + v Z e r c + r M / 5 a s k q b o 5 h A d b X L x l Z m G g = &lt; / l a t e x i t &gt; z1 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " b 0 a g k e q G o o S b Y A g 7 K h / C + z u Q 5 / k = " &gt; A A A B / n i c b V D L S g N B E O y N r x h f U Y 9 e B o P g K e w G X 8 e A l x w j m A c k S 5 i d z C Z D Z m a X m V k h L A t + g 1 c 9 e x O v / o p H / 8 R J s g e T W N B Q V H X T 3 R X E n G n j u t 9 O Y W N z a 3 u n u F v a 2 z 8 4 P C o f n 7 R 1 l C h C W y T i k e o G W F P O J G 0 Z Z j j t x o p i E X D a C S b 3 M 7 / z R J V m k X w 0 0 5 j 6 A o 8 k C x n B x k r d f i B S n A 1 q g 3 L F r b p z o H X i 5 a Q C O Z q D 8 k 9 / G J F E U G k I x 1 r 3 P D c 2 f o q V Y Y T T r N R P N I 0 x m e A R 7 V k q s a D a T + f 3 Z u j C K k M U R s q W N G i u / p 1 I s d B 6 K g L b K b A Z 6 1 V v J v 7 n 9 R I T 3 v k p k 3 F i q C S L R W H C k Y n Q 7 H k 0 Z I o S w 6 e W Y K K Y v R W R M V a Y G B v R 0 p Z A Z D Y T b z W B d d K u V b 2 b 6 v X D Vi U h F I / G o Z z H x O R o J G l K M t J E G d s U b I 5 1 6 H O l x E K b T L B v U B 3 b V q T l z w H X i F q Q K C r Q G 9 o 8 3 j H D C i d C Y I a X 6 r h N r P 0 V S U 8 x I V v Y S R W K E J 2 h E + o Y K x I n y 0 3 n 2 D F 4 Y Z Q j D S J o R G s 7 V v x c p 4 k r N e G A 2 8 5 B q 1 c v F / 7 x + o s M 7 P 6 U i T j Q R e P E o T B j U E c y L g E M q C d Z s Z g j C k p q s E I + R R F i b u p a + B D w z n b i r D a y T T r 3 m 3 t S u H 6 6 q j W b R T g m c g X N w C V x w C x q g C V q g D T C Y g h f w C t 6 s Z + v d + r A + F 6 s b V n F z C p Z g f f 0 C n p + b Z Q = = &lt; / l a t e x i t &gt; x2 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " T b G 7 2 g f 4 V x u S j h Z c A R w w / D U d v 5 g = " &gt; A A A B / n i c b V D L S g N B E O y N r x h f U Y 9 e B o P g K e w G X 8 e A l x w j m A c k S 5 i d z C Z D Z m a X m V k h L A t + g 1 c 9 e x O v / o p H / 8 R J s g e T W N B Q V H X T 3 R X E n G n j u t 9 O Y W N z a 3 u n u F v a 2 z 8 4 P C o f n 7 R 1 l C h C W y T i k e o G W F P O J G 0 Z Z j j t x o p i E X D a C S b 3 M 7 / z R J V m k X w 0 0 5 j 6 A o 8 k C x n B x k r d f i D S c T a o D c o V t + r O g d a J l 5 M K 5 G g O y j / 9 Y U Q S Q a U h H G v d 8 9 z Y + C l W h h F O s 1 I / 0 T T G Z I J H t G e p x I J q P 5 3 f m 6 E L q w x R G C l b 0 q C 5 + n c i x U L r q Q h s p 8 B m r F e 9 m f i f 1 0 t M e O e n T M a J o Z I s F o U J R y Z C s + f R k C l K D J 9 a g o l i 9 l Z E x l h h Y m x E S 1 s C k d l M v N U E 1 k m 7 V v V u q t c P V 5 V 6 I 0 + n C G d w D p f g w S 3 U o Q F N a A E B D i / w C m / O s / P u f D i f i 9 a C k 8 + c w h K c r 1 / H C 5 a M &lt; / l a t e x i t &gt; h2
S4 Blocks (single step) &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " A 8 C t g r l M R A P / y r C / s y h
V + l W z o B Y = " &gt; A A A B / n i c b V D L S g N B E O y N r x h f U Y 9 e B o P g K e z 6 P g a 8 5 B j B P C B Z w u x k N h k y M 7 v M z A p h W f A b v O r Z m 3 j 1 V z z 6 J 0 6 S P Z j E g o a i q p v u r i D m T B v X / X Y K a + s b m 1 v F 7 d L O 7 t 7 + Q f n w q K W j R B H a J B G P V C f A m n I m a d M w w 2 k n V h S L g N N 2 M L 6 f + u 0 n q j S L 5 K O Z x N Q X e C h Z y A g 2 V u r 0 A p H i r H / Z L 1 f c q j s D W i V e T i q Q o 9 E v / / Q G E U k E l Y Z w r H X X c 2 P j p 1 g Z R j j N S r 1 E 0 x i T M R 7 S r q U S C 6 r 9 d H Z v h s 6 s M k B h p G x J g 2 b q 3 4 k U C 6 0 n I r C d A p u R X v a m 4 n 9 e N z H h n Z 8 y G S e G S j J f F C Y c m Q h N n 0 c D p i g x f G I J J o r Z W x E Z Y Y W J s R E t b A l E Z j P x l h N Y J a 2 L q n d T v X 6 4 q t T q e T p F O I F T O A c P b q E G d W h A E w h w e I F X e H O e n X f n w / m c t x a c f O Y Y F u B 8 / Q K 9 h J a G &lt; / l a t e x i t &gt; a3 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " C g / w l M Y / l G v f O E 7 I w y S / O g 6 A G g w = " &gt; A A A C C n i c b V D L S s N A F J 3 4 r P U V 6 9 L N Y B F c l c T 3 s u C m y w r 2 A U 0 o k + m k H T o z C T M T a Q n 5 A 7 / B r a 7 d i V t / w q V / 4 q T N w r Y e u H A 4 5 1 7 u 4 Q Q x o 0 o 7 z r e 1 t r 6 x u b V d 2 i n v 7 u 0 f H N p H l b a K E o l J C 0 c s k t 0 A K c K o I C 1 N N S P d W B L E A 0 Y 6 w f g + 9 z t P R C o a i U c 9 j Y n P 0 V D Q k G K k j d S 3 K 9 4 I 6 d T j S I + C M J 1 k W f + y b 1 e d m j M D X C V u Q a q g Q L N v / 3 i D C C e c C I 0 Z U q r n O r H 2 U y Q 1 x Y x k Z S 9 R J E Z 4 j I a k Z 6 h A n C g / n W X P 4 J l R B j C M p B m h 4 U z 9 e 5 E i r t S U B 2 Y z D 6 m W v V z 8 z + s l O r z z U y r i R B O B 5 4 / C h E E d w b w I O K C S Y M 2 m h i A s q c k K 8 Q h J h L W p a + F L w D P T i b v c w C p p X 9 T c m 9 r 1 w 1 W 1 3 i j a K Y E T c A r O g Q t u Q R 0 0 Q B O 0 A A Y T 8 A J e w Z v 1 b L 1 b H 9 b n f H X N K m 6 O w Q K s r 1 + g M p t m &lt; / l a t e x i t &gt; x3
&lt; l a t e x i t s h a 1 _ b a s e 6 4 = " P f o X X i z u w 2 2 X O w 4 N t 2 K g + j 4 l t j E = " &gt; A A A B / n i c b V D L S g N B E O y N r x h f U Y 9 e B o P g K e z 6 P g a 8 5 B j B P C B Z w u &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " r q U K g m M V y / v g n T c 2 + k 3 Z e J Q y 2 r 4 = "
x k N h k y M 7 v M z A p h W f A b v O r Z m 3 j 1 V z z 6 J 0 6 S P Z j E g o a i q p v u r i D m T B v X / X Y K a + s b m 1 v F 7 d L O 7 t 7 + Q f n w q K W j R B H a J B G P V C f A m n I m a d M w w 2 k n V h S L g N N 2 M L 6 f + u 0 n q j S L 5 K O Z x N Q X e C h Z y A g 2 V u r 0 A p G O s v 5 l v 1 x x q + 4 M a J V 4 O a l A j k a / / N M b R C Q R V B r C s d Z d z 4 2 N n 2 J l G O E 0 K / U S T W N M x n h I u 5 Z K L K j 2 0 9 m 9 G T q z y g C F k b I l D Z q p f y d S L L S e i M B 2 C m x G e t m b i v 9 5 3 c S E d 3 7 K Z J w Y K s l 8 U Z h w Z C I 0 f R 4 N m K L E 8 I k l m C h m b 0 V k h B U m x k a 0 s C U Q m c 3 E W 0 5 g l b Q u q t 5 N 9 f r h q l K r 5 + k U 4 Q R O 4 R w 8 u I U a 1 K E B T S D A 4 Q V e&gt; A A A B / n i c b V D L S g N B E O y N r x h f U Y 9 e B o P g K e x K f B w D X n K M Y B 6 Q L G F 2 M p s M m Z l d Z m a F s C z 4 D V 7 1 7 E 2 8 + i s e / R M n y R 5 M Y k F D U d V N d 1 c Q c 6 a N 6 3 4 7 h Y 3 N r e 2 d 4 m 5 p b / / g 8 K h 8 f N L W U a I I b Z G I R 6 o b Y E 0 5 k 7 R l m O G 0 G y u K R c B p J 5 j c z / z O E 1 W a R f L R T G P q C z y S L G Q E G y t 1 + 4 F I c T a o D c o V t + r O g d a J l 5 M K 5 G g O y j / 9 Y U Q S Q a U h H G v d 8 9 z Y + C l W h h F O s 1 I / 0 T T G Z I J H t G e p x I J q P 5 3 f m 6 E L q w x R G C l b 0 q C 5 + n c i x U L r q Q h s p 8 B m r F e 9 m f i f 1 0 t M e O e n T M a J o Z I s F o U J R y Z C s + f R k C l K D J 9 a g o l i 9 l Z E x l h h Y m x E S 1 s C k d l M v N U E 1 k n 7 q u r d V K 8 f a p V 6 I 0 + n C G d w D p f g w S 3 U o Q F N a A E B D i / w C m / O s / P u f D i f i 9 a C k 8 + c w h K c r 1 + / F 5 a H &lt; / l a t e x i t &gt; a4 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " b / D u Q 4 t h T 4 r u D r H 9 I v n F w E F v W 1 E = " &gt; A A A C C n i c b V D L S s N A F J 3 U V 6 2 v W J d u B o v g q i T i a 1 l w 0 2 U F + 4 A m l M l 0 0 g 6 d m Y S Z i b S E / I H f 4 F b X 7 s S t P + H S P 3 H S Z m F b D 1 w 4 n H M v 9 3 C C m F G l H e f b K m 1 s b m 3 v l H c r e / s H h 0 f 2 c b W j o k R i 0 s Y R i 2 Q v Q I o w K k h b U 8 1 I L 5 Y E 8 Y C R b j C 5 z / 3 u E 5 G K R u J R z 2 L i c z Q S N K Q Y a S M N 7 K o 3 R j r 1 O N L j I E y n W T a 4 G t g 1 p + 7 M A d e J W 5 A a K N A a 2 D / e M M I J J 0 J j h p T q u 0 6 s / R R J T T E j W c V L F I k R n q A R 6 R s q E C f K T + f Z M 3 h u l C E M I 2 l G a D h X / 1 6 k i C s 1 4 4 H Z z E O q V S 8 X / / P 6 i Q 7 v / J S K O N F E 4 M W j M G F Q R z A v A g 6 p J F i z m S E I S 2 q y Q j x G E m F t 6 l r 6 E v D M d O K u N r B O O p d 1 9 6 Z + / X B V a z S L d s r g F J y B C + C C W 9 A A T d A C b Y D B F L y A V / B m P V v v 1 o f 1 u V g t W c X N C V i C 9 f U L o c W b Z w = = &lt; / l a t e x i t &gt; x4 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " I h 6 m e H 1 U m f y j R K W C / 1 T m M + m N H N U = " &gt; A A A B / n i c b V D L S g N B E O y N r x h f U Y 9 e B o P g K e x K f B w D X n K M Y B 6 Q L G F 2 M p s M m Z l d Z m a F s C z 4 D V 7 1 7 E 2 8 + i s e / R M n y R 5 M Y k F D U d V N d 1 c Q c 6 a N 6 3 4 7 h Y 3 N r e 2 d 4 m 5 p b / / g 8 K h 8 f N L W U a I I b Z G I R 6 o b Y E 0 5 k 7 R l m O G 0 G y u K R c B p J 5 j c z / z O E 1 W a R f L R T G P q C z y S L G Q E G y t 1 + 4 F I x 9 m g N i h X 3 K o 7 B 1 o n X k 4 q k K M 5 K P / 0 h x F J B J W G c K x 1 z 3 N j 4 6 d Y G U Y 4 z U r 9 R N M Y k w k e 0 Z 6 l E g u q / X R + b 4 Y u r D J E Y a R s S Y P m 6 t + J F A u t p y K w n Q K b s V 7 1 Z u J / X i 8 x 4 Z 2 f M h k n h k q y W B Q m H J k I z Z 5 H Q 6 Y o M X x q C S a K 2 V s R G W O F i b E R L W 0 J R G Y z 8 V Y T W C f t q 6 p 3 U 7 1 + q F X q j T y d I p z B O V y C B 7 d Q h w Y 0 o Q U E O L z A K 7 w 5 z 8 6 7 8 + F 8 L l o L T j 5 z C k t w v n 4 B y j G W j g = = &lt; / l a t e x i t &gt; h4 Generation &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " k b B z a Z s h d t 4 f I G h M t t y c K e f r X Q k = " &gt; A A A B / H i c b V D L S g N B E O y N r x h f U Y 9 e B o P g K e y K r 2 P A S 4 4 R z A O S J c z O z i Z j Z m a X m V k h L P E b v O r Z m 3 j 1 X z z 6 J 0 6 S P Z j E g o a i q p v u r i D h T B v X / X Y K a + s b m 1 v F 7 d L O 7 t 7 + Q f n w q K X j V B H a J D G P V S f A m n I m a d M w w 2 k n U R S L g N N 2 M L q b + u 0 n q j S L 5 Y M Z J 9 Q X e C B Z x A g 2 V m r 1 S B g b 3 S 9 X 3 K o 7 A 1 o l X k 4 q k K P R L / / 0 w p i k g k p D O N a 6 6 7 m J 8 T O s D C O c T k q 9 V N M E k x E e 0 K 6 l E g u q / W x 2 7 Q S d W S V E U a x s S Y N m 6 t + J D A u t x y K w n Q K b o V 7 2 p u J / X j c 1 0 a 2 f M Z m k h k o y X x S l H J k Y T V 9 H I V O U G D 6 2 B B P F 7 K 2 I D L H C x N i A F r Y E Y m I z 8 Z Y T W C W t i 6 p 3 X b 2 6 v 6 z U 6 n k 6 R T i B U z g H D 2 6 g B n V o Q B M I P M I L v M K b 8 + y 8 O x / O 5 7 y 1 4 O Q z x 7 A A 5 + s X d s + V 1 Q = = &lt; / l a t e x i t &gt; • • • Next Step Prediction Dec Dec Dec Dec Dec &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " w + Y g W R E R C X e z q 9 d b 0 k H / V 6 1 f M / Q = " &gt; A A A C A n i c b V D L S s N A F L 2 p r 1 p f V Z d u B o v g q i T i a 1 l w 0 2 U F + 4 A m l M l 0 0 g 6 d T M L M R K g h O 7 / B r a 7 d i V t / x K V / 4 q T N w r Y e u H A 4 5 1 7 u 4 f g x Z 0 r b 9 r d V W l v f 2 N w q b 1 d 2 d v f 2 D 6 q H R x 0 V J Z L Q N o l 4 J H s + V p Q z Q d u a a U 5 7 s a Q 4 9 D n t + p O 7 3 O 8 + U q l Y J B 7 0 N K Z e i E e C B Y x g b S T X D b E e + 0 H 6 l A 2 c Q b V m 1 + 0 Z 0 C p x C l K D A q 1 B 9 c c d R i Q J q d C E Y 6 X 6 j h 1 r L 8 V S M 8 J p V n E T R W N M J n h E + 4 Y K H F L l p b P M G T o z y h A F k T Q j N J q p f y 9 S H C o 1 D X 2 z m W d U y 1 4 u / u f 1 E x 3 c e i k T c a K p I P N H Q c K R j l B e A B o y S Y n m U 0 M w k c x k R W S M J S b a 1 L T w x Q 8 z 0 4 m z 3 M A q 6 V z U n e v 6 1 f 1 l r d E s 2 i n D C Z z C O T h w A w 1 o Q g v a Q C C G F 3 i F N + v Z e r c + r M / 5 a s k q b o 5 h A d b X L x l Z m G g = &lt; / l a t e x i t &gt; z1 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " H 1 J i G i + A p 3 N a N q q y p e P 8 u Q C o U x w = " &gt; A A A C A n i c b V D L S s N A F L 3 x W e u r 6 t J N s A i u S l J 8 L Q t u u q x g H 9 C E M p l O 2 q E z k z A z E W r I z m 9 w q 2 t 3 4 t Y f c e m f O G m z s K 0 H L h z O u Z d 7 O E H M q N K O 8 2 2 t r W 9 s b m 2 X d s q 7 e / s H h 5 W j 4 4 6 K E o l J G 0 c s k r 0 A K c K o I G 1 N N S O 9 W B L E A 0 a 6 w e Q u 9 7 u P R C o a i Q c 9 j Y n P 0 U j Q k G K k j e R 5 H O l x E K Z P 2 a A + q F S d m j O D v U r c g l S h Q G t Q + f G G E U 4 4 E R o z p F T f d W L t p 0 h q i h n J y l 6 i S I z w B I 1 I 3 1 C B O F F + O s u c 2 e d G G d p h J M 0 I b c / U v x c p 4 k p N e W A 2 8 4 x q 2 c v F / 7 x + o s N b P 6 U i T j Q R e P 4 o T J i t I z s v w B 5 S S b B m U 0 M Q l t R k t f E Y S Y S 1 q W n h S 8 A z 0 4 m 7 3 M A q 6 d R r 7 n X t 6 v 6 y 2 m g W 7 Z T g F M 7 g A l y 4 g Q Y 0 o Q V t w B D D C 7 z C m / V s v V s f 1 u d 8 d c 0 q b k 5 g A d b X L x r s m G k = &lt; / l a t e x i t &gt; z2 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " H 1 J i G i + A p 3 N a N q q y p e P 8 u Q C o U x w = " &gt; A A A C A n i c b V D L S s N A F L 3 x W e u r 6 t J N s A i u S l J 8 L Q t u u q x g H 9 C E M p l O 2 q E z k z A z E W r I z m 9 w q 2 t 3 4 t Y f c e m f O G m z s K 0 H L h z O u Z d 7 O E H M q N K O 8 2 2 t r W 9 s b m 2 X d s q 7 e / s H h 5 W j 4 4 6 K E o l J G 0 c s k r 0 A K c K o I G 1 N N S O 9 W B L E A 0 a 6 w e Q u 9 7 u P R C o a i Q c 9 j Y n P 0 U j Q k G K k j e R 5 H O l x E K Z P 2 a A + q F S d m j O D v U r c g l S h Q G t Q + f G G E U 4 4 E R o z p F T f d W L t p 0 h q i h n J y l 6 i S I z w B I 1 I 3 1 C B O F F + O s u c 2 e d G G d p h J M 0 I b c / U v x c p 4 k p N e W A 2 8 4 x q 2 c v F / 7 x + o s N b P 6 U i T j Q R e P 4 o T J i t I z s v w B 5 S S b B m U 0 M Q l t R k t f E Y S Y S 1 q W n h S 8 A z 0 4 m 7 3 M A q 6 d R r 7 n X t 6 v 6 y 2 m g W 7 Z T g F M 7 g A l y 4 g Q Y 0 o Q V t w B D D C 7 z C m / V s v V s f 1 u d 8 d c 0 q b k 5 g A d b X L x r s m G k = &lt; / l a t e x i t &gt; z2 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " H 1 J i G i + A p 3 N a N q q y p e P 8 u Q C o U x w = " &gt; A A A C A n i c b V D L S s N A F L 3 x W e u r 6 t J N s A i u S l J 8 L Q t u u q x g H 9 C E M p l O 2 q E z k z A z E W r I z m 9 w q 2 t 3 4 t Y f c e m f O G m z s K 0 H L h z O u Z d 7 O E H M q N K O 8 2 2 t r W 9 s b m 2 X d s q 7 e / s H h 5 W j 4 4 6 K E o l J G 0 c s k r 0 A K c K o I G 1 N N S O 9 W B L E A 0 a 6 w e Q u 9 7 u P R C o a i Q c 9 j Y n P 0 U j Q k G K k j e R 5 H O l x E K Z P 2 a A + q F S d m j O D v U r c g l S h Q G t Q + f G G E U 4 4 E R o z p F T f d W L t p 0 h q i h n J y l 6 i S I z w B I 1 I 3 1 C B O F F + O s u c 2 e d G G d p h J M 0 I b c / U v x c p 4 k p N e W A 2 8 4 x q 2 c v F / 7 x + o s N b P 6 U i T j Q R e P 4 o T J i t I z s v w B 5 S S b B m U 0 M Q l t R k t f E Y S Y S 1 q W n h S 8 A z 0 4 m 7 3 M A q 6 d R r 7 n X t 6 v 6 y 2 m g W 7 Z T g F M 7 g A l y 4 g Q Y 0 o Q V t w B D D C 7 z C m / V s v V s f 1 u d 8 d c 0 q b k 5 g A d b X L x r s m G k = &lt; / l a t e x i t &gt; z2 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " z 8 7 F V 2 d U c t g x t B R 0 q 0 i e Y z X B 6 o g = " &gt; A A A B 8 3 i c b V D L S g M x F L 3 j s 9 Z X 1 a W b Y B F c l R n f y 4 K b L i v Y B 3 S G k k k z b W g m E 5 K M U I f + h h s X i r j 1 Z 9 z 5 N 2 b a W W j r g c D h n H u 5 J y e U n G n j u t / O y u r a + s Z m a a u 8 v b O 7 t 1 8 5 O G z r J F W E t k j C E 9 U N s a a c C d o y z H D a l Y r i O O S 0 E 4 7 v c r / z S J V m i X g w E 0 m D G A 8 F i x j B x k q + H 2 M z C q P s a d q / 6 F e q b s 2 d A S 0 T r y B V K N D s V 7 7 8 Q U L S m A p D O N a 6 5 7 n S B B l W h h F O p 2 U / 1 V R i M s Z D 2 r N U 4 J j q I J t l n q J T q w x Q l C j 7 h E E z 9 f d G h m O t J 3 F o J / O M e t H L x f + 8 X m q i 2 y B j Q q a G C j I / F K U c m Q T l B a A B U 5 Q Y P r E E E 8 V s V k R G W G F i b E 1 l W 4 K 3 + O V l 0 j 6 v e d e 1 q / v L a r 1 R 1 F G C Y z i B M / D g B u r Q g C a 0 g I C E Z 3 i F N y d 1 X p x 3 5 2 M + u u I U O 0 f w B 8 7 n D z W E k d Q = &lt; / l a t e x i t &gt; z3 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " z 8 7 F V 2 d U c t g x t B R 0 q 0 i e Y z X B 6 o g = " &gt; A A A B 8 3 i c b V D L S g M x F L 3 j s 9 Z X 1 a W b Y B F c l R n f y 4 K b L i v Y B 3 S G k k k z b W g m E 5 K M U I f + h h s X i r j 1 Z 9 z 5 N 2 b a W W j r g c D h n H u 5 J y e U n G n j u t / O y u r a + s Z m a a u 8 v b O 7 t 1 8 5 O G z r J F W E t k j C E 9 U N s a a c C d o y z H D a l Y r i O O S 0 E 4 7 v c r / z S J V m i X g w E 0 m D G A 8 F i x j B x k q + H 2 M z C q P s a d q / 6 F e q b s 2 d A S 0 T r y B V K N D s V 7 7 8 Q U L S m A p D O N a 6 5 7 n S B B l W h h F O p 2 U / 1 V R i M s Z D 2 r N U 4 J j q I J t l n q J T q w x Q l C j 7 h E E z 9 f d G h m O t J 3 F o J / O M e t H L x f + 8 X m q i 2 y B j Q q a G C j I / F K U c m Q T l B a A B U 5 Q Y P r E E E 8 V s V k R G W G F i b E 1 l W 4 K 3 + O V l 0 j 6 v e d e 1 q / v L a r 1 R 1 F G C Y z i B M / D g B u r Q g C a 0 g I C E Z 3 i F N y d 1 X p x 3 5 2 M + u u I U O 0 f w B 8 7 n D z W E k d Q = &lt; / l a t e x i t &gt; z3 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " n t Y / 2 1 + 5 l I p R + a P t Q m Q 8 K y S f e 3 s = " &gt; A A A B 8 3 i c b V D L S g M x F L 2 p r 1 p f V Z d u g k V w V W b E 1 7 L g p s s K 9 g G d o W T S T B u a y Q x J R q h D f 8 O N C 0 X c + j P u / B s z 7 S y 0 9 U D g c M 6 9 3 J M T J I J r 4 z j f q L S 2 v r G 5 V d 6 u 7 O z u 7 R 9 U D 4 8 6 O k 4 V Z W 0 a i 1 j 1 A q K Z 4 J K 1 D T e C 9 R L F S B Q I 1 g 0 m d 7 n f f W R K 8 1 g + m G n C / I i M J A 8 5 J c Z K n h c R M w 7 C 7 G k 2 u B x U a 0 7 d m Q O v E r c g N S j Q G l S / v G F M 0 4 h J Q w X R u u 8 6 i f E z o g y n g s 0 q X q p Z Q u i E j F j f U k k i p v 1 s n n m G z 6 w y x G G s 7 J M G z 9 X f G x m J t J 5 G g Z 3 M M + p l L x f / 8 / q p C W / 9 j M s k N U z S x a E w F d j E O C 8 A D 7 l i 1 I i p J Y Q q b r N i O i a K U G N r q t g S 3 O U v r 5 L O R d 2 9 r l / d X 9 Y a z a K O M p z A K Z y D C z f Q g C a 0 o A 0 U E n i G V 3 h D K X p B 7 + h j M V p C x c 4 x / A H 6 / A E 3 C J H V &lt; / l a t e x i t &gt; z4 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " Q 4 h e u U F k l Y i X j z k i 7 q 4 T 1 Q H + Y L c = " &gt; A A A C A H i c b V D L S g M x F L 3 j s 9 Z X 1 a W b Y B E E o c y I r 2 X B j S u p Y B / Y D i W T Z t r Q J D M k G a E M 3 f g N b n X t T t z 6 J y 7 9 E z P t L G z r g c D h n H u 5 J y e I O d P G d b + d p e W V 1 b X 1 w k Z x c 2 t 7 Z 7 e 0 t 9 / Q U a I I r Z O I R 6 o V Y E 0 5 k 7 R u m O G 0 F S u K R c B p M x j e Z H 7 z i S r N I v l g R j H 1 B e 5 L F j K C j Z U e O w K b Q R C m p + N u q e x W 3 A n Q I v F y U o Y c t W 7 p p 9 O L S C K o N I R j r d u e G x s / x c o w w u m 4 2 E k 0 j T E Z 4 j 5 t W y q x o N p P J 4 n H 6 N g q P R R G y j 5 p 0 E T 9 u 5 F i o f V I B H Y y S 6 j n v U z 8 z 2 s n J r z 2 U y b j x F B J p o f C h C M T o e z 7 q M c U J Y a P L M F E M Z s V k Q F W m B h b 0 s y V Q G S d e P M N L J L G W c W 7 r F z c n 5 e r d 3 k 7 B T i E I z g B D 6 6 g C r d Q g z o Q k P A C r / D m P D v v z o f z O R 1 d c v K d A 5 i B 8 / U L a M K X e w = = &lt; / l a t e x i t &gt; + LayerNorm S4 Linear LayerNorm S4 Linear &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " Q 4 h e u U F k l Y i X j z k i 7 q 4 T 1 Q H + Y L c = " &gt; A A A C A H i c b V D L S g M x F L 3 j s 9 Z X 1 a W b Y B E E o c y I r 2 X B j S u p Y B / Y D i W T Z t r Q J D M k G a E M 3 f g N b n X t T t z 6 J y 7 9 E z P t L G z r g c D h n H u 5 J y e I O d P G d b + d p e W V 1 b X 1 w k Z x c 2 t 7 Z 7 e 0 t 9 / Q U a I I r Z O I R 6 o V Y E 0 5 k 7 R u m O G 0 F S u K R c B p M x j e Z H 7 z i S r N I v l g R j H 1 B e 5 L F j K C j Z U e O w K b Q R C m p + N u q e x W 3 A n Q I v F y U o Y c t W 7 p p 9 O L S C K o N I R j r d u e G x s / x c o w w u m 4 2 E k 0 j T E Z 4 j 5 t W y q x o N p P J 4 n H 6 N g q P R R G y j 5 p 0 E T 9 u 5 F i o f V I B H Y y S 6 j n v U z 8 z 2 s n J r z 2 U y b j x F B J p o f C h C M T o e z 7 q M c U J Y a P L M F E M Z s V k Q F W m B h b 0 s y V Q G S d e P M N L J L G W c W 7 r F z c n 5 e r d 3 k 7 B T i E I z g B D 6 6 g C r d Q g z o Q k P A C r / D m P D v v z o f z O R 1 d c v K d A 5 i B 8 / U L a M K X e w = = &lt; / l a t e x i t &gt; + LayerNorm MLP &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " Q 4 h e u U F k l Y i X j z k i 7 q 4 T 1 Q H + Y L c = " &gt; A A A C A H i c b V D L S g M x F L 3 j s 9 Z X 1 a W b Y B E E o c y I r 2 X B j S u p Y B / Y D i W T Z t r Q J D M k G a E M 3 f g N b n X t T t z 6 J y 7 9 E z P t L G z r g c D h n H u 5 J y e I O d P G d b + d p e W V 1 b X 1 w k Z x c 2 t 7 Z 7 e 0 t 9 / Q U a I I r Z O I R 6 o V Y E 0 5 k 7 R u m O G 0 F S u K R c B p M x j e Z H 7 z i S r N I v l g R j H 1 B e 5 L F j K C j Z U e O w K b Q R C m p + N u q e x W 3 A n Q I v F y U o Y c t W 7 p p 9 O L S C K o N I R j r d u e G x s / x c o w w u m 4 2 E k 0 j T E Z 4 j 5 t W y q x o N p P J 4 n H 6 N g q P R R G y j 5 p 0 E T 9 u 5 F i o f V I B H Y y S 6 j n v U z 8 z 2 s n J r z 2 U y b j x F B J p o f C h C M T o e z 7 q M c U J Y a P L M F E M Z s V k Q F W m B h b 0 s y V Q G S d e P M N L J L G W c W 7 r F z c n 5 e r d 3 k 7 B T i E I z g B D 6 6 g C r d Q g z o Q k P A C r / D m P D v v z o f z O R 1 d c v K d A 5 i B 8 / U L a M K X e w = = &lt; / l a t e x i t &gt; + Figure 1:
We propose S4WM, the first S4-based world model for improving long-term memory.S4WM efficiently models the long-range dependencies of environment dynamics in a compact latent space, using a stack of S4 blocks.This crucially allows fully parallelized training and fast recurrent latent imagination.S4WM is a general framework that is compatible with any parallelizable SSM including S5 and other S4 variants.</p>
<p>Algorithm 1 S4WM Training</p>
<p>Input: (x 0 , a 1 , x 1 , . . ., a T , x T ) ▷ Obtain posterior latents 1: for time step t = 0, . . ., T parallel do 2:
z t ∼ q(z t | x t ) =z t ∼ q(z t | x t ) = Encoder(x t ) 3: g t+1 = MLP(concat[z t , a t+1 ]) 4: end for 5: h 1:C+1 , s C+1 = S4Blocks(g 1:C+1 , s 0 ) ▷ Imagine in latent space 6: z C+1 ∼ p(z C+1 | z 0:C , a 1:C+1 ) = MLP(h C+1 ) 7:
for query step t = C + 2, . . ., T do 8: xt = Decoder(concat[h t , z t ]) 14: end for while also including the HiPPO matrices [18], which are theoretically derived based on continuoustime memorization and empirically shown to better capture long-range dependencies.In practice, S4 initializes A to the HiPPO matrix.To cope with vector-valued inputs and outputs (i.e., u k , y k ∈ R H ), S4 makes H copies of the SSM, each operating on one dimension, and mixes the outputs by a position-wise linear layer.Follow-up works further simplify the parameterization of A to a diagonal matrix [20], and use a multi-input, multi-output SSM for vector-valued sequences [57].
g t = MLP(concat[z t−1 , a t ])</p>
<p>S4WM: A General World Model for Parallelizable SSMs</p>
<p>We consider an agent interacting with a partially observable environment.At each time step t, the agent receives an image observation x t .It then chooses an action a t+1 based on its policy, and receives the next observation x t+1 .For simplicity, we omit the reward here.</p>
<p>We aim to model p(x 1:T | x 0 , a 1:T ), the distribution of future observations given the action sequence.We note that it is not required to model p(x 0 ), as world model imagination is typically conditioned on at least one observation.While S4 and its variants have shown remarkable abilities to model long-range dependencies, they operate directly in the observation space.For example, S4 models images as sequences of pixels, and directly learns the dependencies among individual pixels.This is hard to scale to high-dimensional sequences, such as the sequences of images that we aim to model.Inspired by RSSM [28], we propose S4WM, the first PSSM-based world model that learns the environment dynamics in a compact latent space.This not only allows fast parallelizable training, but also enables efficient modeling of long-range dependencies in the latent space.Importantly, S4WM is a general framework that can incorporate not only the specific S4 model [21] but also any PSSM defined by Equation ( 2), including S5 [57] and other variants [20,40,15].It models the observations and state transitions through a probabilistic generative process:
p(x 1:T | x 0 , a 1:T ) = p(z 0 | x 0 ) T t=1 p(x t | z ≤t , a ≤t ) p(z t | z &lt;t , a ≤t ) dz 0:T ,(3)
where z 0:T are the stochastic latent states.We note that computing the likelihood p(x t | z ≤t , a ≤t ) and the prior p(z t | z &lt;t , a ≤t ) requires extracting relevant information from the history (z &lt;t , a ≤t ).Therefore, it is crucial to maintain a long-term memory of the history.To this end, we use a stack of PSSM blocks to encode the history (z &lt;t , a ≤t ) into an embedding vector h t for each t.This can be done in parallel during training and sequentially during imagination:
(parallel) h 1:T , s T = PSSM_Blocks(g 1:T , s 0 ) ,(4)(single step) h t , s t = PSSM_Blocks(g t , s t−1 ) .(5)
Here,
g t = MLP(concat[z t−1 , a t ]
) is the input to the PSSM blocks, s t is the collection of all internal hidden states, and h t is the final output.In our experiments, we use S4 blocks (shown in Figure 1 Right), a particular instantiation of the PSSM blocks using the S4 model.We find that adding the final MLP in each S4 block can improve generation quality (see Appendix B.1 for an ablation and Figure 21 for a detailed illustration of S4 block architecture).</p>
<p>After obtaining h t , we use it to compute the sufficient statistics of the prior and likelihood:
p(z t | z &lt;t , a ≤t ) = MLP(h t ) , (6) p(x t | z ≤t , a ≤t ) = N (x t , 1) , xt = Decoder(concat[h t , z t ]) .(7)
For training, we use variational inference.The approximate posterior is defined as:
q(z 0:T | x 0:T , a 1:T ) = T t=0 q(z t | x t ) , where q(z 0 | x 0 ) = p(z 0 | x 0 ) .(8)
We use a CNN encoder to compute the sufficient statistics of the posterior from image observations.This allows all posterior samples z 0:T to be obtained in parallel, thereby fully leveraging the parallel computation ability offered by PSSMs during training.We also provide an alternative design of the posterior in Appendix B.1.It is conditioned on the full history, and can obtain better generation quality at the cost of more computation.</p>
<p>The training objective is to maximize the evidence lower bound (ELBO):
log p(x 1:T | x 0 , a 1:T ) ≥ E q T t=1 log p(x t | z ≤t , a ≤t ) − L KL q(z t | x t ), p(z t | z &lt;t , a ≤t ) .(9)
In our experiments, we instantiate S4WM using the S4 model [21].Figure 1 provides an illustration of training and imagination procedures, and Algorithms 1 and 2 provide detailed descriptions.Hyperparameters and further implementation details can be found in Appendix J.</p>
<p>Experiments</p>
<p>Environments</p>
<p>Unlike previous works [14,48,37,52] that primarily evaluate the final performance of model-free agents on memory-demanding tasks, we seek to understand the memory capabilities of world models in model-based agents in terms of long-term imagination, context-dependent recall, reward prediction, and memory-based reasoning.We believe that our investigation provides more insights than the final performance alone, and paves the way for model-based agents with improved memory.</p>
<p>To this end, we develop a diverse set of environments shown in Figure 2, each targeting a specific memory capability.The environments are based on the 3D Memory Maze [50] and the 2D Mini-Grid [6], both with partial observations.The world models are learned from an offline dataset collected by a scripted policy for each environment.This allows the world models to be evaluated independently of the policy learning algorithms.</p>
<p>Specifically, for each episode, the environment is regenerated.To simplify the evaluation of world model imagination, we design the data collecting policy to consist of a context phase and a query phase.In the context phase, the policy fully traverses the environment, while in the query phase, the policy revisits some parts of the environment.For evaluation, we use unseen episodes collected by the same policy as training.The world model observes the context phase, and is then evaluated on its imagination given the action sequence in the query phase.Because the environments are deterministic and have moderate visual complexity, and the context phase fully reveals the information of the environment, it suffices to use the mean squared error (MSE) as our main evaluation metric.</p>
<p>In the following, we first motivate our choice of the baselines through a comparison of speed and memory consumption, and then introduce and present the results for each environment in detail.</p>
<p>Baselines</p>
<p>RSSM-TBTT.RSSM [28] is an RNN-based world model backbone used in state-of-the-art MBRL agents [29][30][31].Recently, [50] show that training RSSM with truncated backpropagation through time (TBTT) can lead to better long-term memory ability.We follow their implementation and denote the model as RSSM-TBTT.TSSM-XL.TSSM [5] is the first Transformer-based world model for improving long-term memory.</p>
<p>It was originally evaluated on sequences of length ∼100.In this paper, we seek to evaluate on much longer sequences (up to 2000 steps), and it is impractical to feed the entire sequence to the vanilla Transformer [61].Therefore, we use Transformer-XL [9] as the backbone and denote the model as TSSM-XL.It divides the full sequence into chunks, and maintains a cache of the intermediate hidden states from processed chunks.This cache serves as an extended context that allows modeling longer-term dependencies.</p>
<p>Speed and Memory Usage.We note that the cache length m is a crucial hyperparameter of TSSM-XL.A larger m can potentially improve the memory capacity, at the cost of slower training and higher memory consumption.To ensure a fair comparison in our experiments in the next few sections, we first investigate the speed and memory usage of S4WM, RSSM-TBTT, and TSSM-XL with several m values.Details can be found in Appendix I.As shown in Figure 3, S4WM and TSSM-XL trains much faster than RSSM-TBTT due to their parallel computation during training, while RSSM-TBTT is much more memory-efficient.For imagination, RSSM-TBTT achieves ∼10× throughput compared to S4WM and TSSM-XL.While S4WM also uses recurrence during imagination, its multi-layered recurrence structure with MLPs in between slows down its performance.As for memory usage, the decoder takes up most of the memory decoding all steps in parallel, leading to similar memory consumption of all models.</p>
<p>Based on our investigation, TSSM-XL with a cache length m = 128 is the closest to S4WM in terms of speed and memory usage.Therefore, we use TSSM-XL with m = 128 for all subsequent experiments.We provide a more thorough investigation with larger cache lengths in Appendix B.2.</p>
<p>Long-Term Imagination</p>
<p>The ability of world models to perform long-term imagination is crucial to long-horizon planning.While many RL benchmarks can be tackled with short-term imagination of ∼15 steps [31], here we seek to understand the long-term imagination capability of world models and explore their limits by letting the world models imagine hundreds of steps into the future.We provide up to 20 observations after the teleport as additional contexts.TSSM-XL performs the best in the Two Rooms environment where the context phase is short, and is able to recall successfully without additional observations.When the context phase is longer, S4WM performs the best.</p>
<p>To this end, we develop three environments with increasing difficulty, namely Two Rooms, Four Rooms, and Ten Rooms, based on the 3D Memory Maze [50].The top-down views are shown in Figure 2. In the context phase, the data collecting policy starts from a random room, sequentially traverses all rooms, and returns to the starting room.In the query phase, the policy revisits each room in the same order as the context phase.</p>
<p>As shown in Table 1, all models obtain good reconstruction, while S4WM is much better in the Two Rooms and Four Rooms environment for long-term generation up to 500 steps.We demonstrate the superior generation quality of S4WM in Figure 4.All models are able to capture the high-level maze layout.However, RSSM-TBTT and TSSM-XL make many mistakes in details such as wall colors, object colors, and object positions, while S4WM is able to generate much more accurately, with only minor errors in object positions.We further show the per step generation MSE in Figure 5. S4WM is able to maintain a relatively good generation quality for up to 500 steps, while RSSM-TBTT and TSSM-XL make large generation errors even within 50 steps.We notice a periodic drop in the generation MSE.This is when the agent moves from one room to another through a narrow corridor where the action sequence is less diverse.</p>
<p>We also find that all models struggle in the Ten Rooms environment where the context length is 1101 and the query length is 900.This likely reaches the sequence modeling limits of the S4 model, and we leave the investigation of more sophisticated model architectures to future work.</p>
<p>Context-Dependent Recall</p>
<p>Humans are able to recall past events in great detail.This has been compared to "mental time travel" [60,58,37].Motivated by this, we develop a "teleport" version of the Two Rooms, Four Rooms, and Ten Rooms environments.After the initial context phase, the agent is teleported to a random point in history, and is asked to recall what happened from that point onwards, given the exact same action sequence that the agent took.</p>
<p>To succeed in this task, the agent needs to figure out where it is teleported by comparing the new observations received after the teleport to its own memory of the past.In other words, the content  to recall depends on the new observations.Transformers have been shown to be better than S4 at performing such context-dependent operations in low-dimensional sequence manipulation tasks [24] and synthetic language modeling tasks [15].We investigate this in the context of world model learning, with high-dimensional image inputs.</p>
<p>To help the model retrieve the correct events in history, we provide up to 20 observations after the teleport as additional contexts.The generation MSE of the recall is reported in Figure 6.TSSM-XL performs the best in the Two Rooms environment where the context phase is short, and is able to recall successfully without additional observations.When the context phase is longer as in Four Rooms and Ten Rooms, S4WM performs the best.We visually show the recall quality with 20 observations after the teleport in Figure 18.In the Two Rooms environment, both TSSM-XL and S4WM are able to recall accurately.However, only S4WM is able to maintain such recall quality in the more challenging Four Rooms environment.</p>
<p>Reward Prediction</p>
<p>To facilitate policy learning within imagination, world models need to accurately predict the rewards.</p>
<p>In this section, we evaluate the reward prediction accuracy over long time horizons.To decouple the challenges posed by 3D environments from long-term reward prediction, we use the visually simpler 2D MiniGrid [6] environment.</p>
<p>Specifically, we develop the Distracting Memory environment, which is more challenging than the original MiniGird Memory environment, due to distractors of random colors being placed in the hallway.A top-down view is shown in Figure 2.Each episode terminates when the agent reaches one of the squares on the right.A reward of 1 is given if the square reached is of the same color as the square in the room on the left.Otherwise, no reward is given.In the context phase, the data collecting policy starts in the middle of the hallway, then traverses the hallway and returns to the starting position.In the query phase, the policy goes to one of the two squares on the right uniformly at random.To accurately predict the reward, the world model must learn to ignore the distractors while keeping track of the agent's position.</p>
<p>We report two types of reward prediction accuracy in Table 2.The inference accuracy is measured when the model takes the full sequence of observations as input (including both the context and the query phases).This evaluates the model's ability to capture long-range dependencies independently of the imagination quality.In contrast, the imagination accuracy is evaluated within the model's imagination, conditioned on the observations in the context phase and additionally the action sequence in the query phase.Our results show that only S4WM is able to accurately predict rewards within imagination.TSSM-XL has limited success when observing the full sequence, but fails to imagine future rewards accurately.RSSM-TBTT completely fails, and its reward prediction is close to random guessing.Our visualization of model imagination in Figure 7 reveals that the failure of TSSM-XL and RSSM-TBTT is mainly due to their inability to keep track of the agent's position.</p>
<p>Memory-Based Reasoning</p>
<p>In the previous experiments, the model's memory of the environment can largely be kept fixed after the context phase.In this section, we explore the setting where the memory needs to be frequently updated in order to reason about the future.</p>
<p>We develop the Multi Doors Keys environment, where the agent collects keys to unlock doors.A top-down view is shown in Figure 2.Each time a door is unlocked, the corresponding key will be consumed, so it cannot be used to unlock other doors of the same color.The agent is allowed to possess multiple keys.In the context phase, the agent visits all keys and doors without picking up any keys.In the query phase, the agent attempts to unlock two random doors after picking up each key.After all keys are picked up, the agent will try to unlock each door once again.To successfully predict the outcome when the agent attempts to unlock a door, the world model must constantly update its memory when a key is picked up or consumed.</p>
<p>Since the environment is visually simple, we find the generation MSE to be a good indicator of how well the model predicts the future door states.As reported in Table 3 and visually shown in Figure 19, S4WM performs well on all environments, demonstrating its ability to keep updating the memory, while both RSSM-TBTT and TSSM-XL struggle.</p>
<p>Conclusion</p>
<p>In this paper, we introduced S4WM, the first PSSM-based visual world model that effectively expands the long-range sequence modeling ability of S4 and its variants from low-dimensional inputs to high-dimensional images.Furthermore, we presented the first comparative investigation of major world model backbones in a diverse set of environments specifically designed to evaluate critical memory capabilities.Our findings demonstrate the superior performance of S4WM over RNNs and Transformers across multiple tasks, including long-term imagination, context-dependent recall, reward prediction, and memory-based reasoning.</p>
<p>Limitations and Future Work.We primarily focused on visually simple and deterministic environments to limit the computation cost and simplify the evaluation process.Future work could explore more sophisticated model architectures and proper evaluation metrics for complex and stochastic environments.In addition, we mainly evaluated imagination quality and did not test world models in conjunction with policy learning.Future work could develop and thoroughly test MBRL agents based on S4WM.To demonstrate the potential of S4WM for policy learning, we provide offline probing results in Appendix D and conduct a skill-level MPC experiment in Appendix E. We find that S4WM outperforms RSSM in offline probing when it is instantiated with S5, and leads to higher task success rates when used for planning.In Appendix G, we additionally demonstrate that the long-term imagination quality can be further improved by instantiating S4WM with S5, showing the potential of our general S4WM framework for incorporating more advanced parallelizable SSMs.</p>
<p>A Environment and Dataset Details</p>
<p>For each 3D environment (i.e., Two Rooms, Four Rooms, and Ten Rooms), we generate 30K trajectories using a scripted policy, of which 28K are used for training, 1K for validation, and 1K for testing.For each 2D environment (i.e., Distracting Memory and Multi Doors Keys), we generate 10K trajectories using a scripted policy, of which 8K are used for training, 1K for validation, and 1K for testing.All reported results are obtained from the test trajectories, using the model checkpoints that achieve the best validation loss.The image observations are of size 64×64×3 for 3D environments, and 40×40×3 for 2D environments.</p>
<p>B Ablation Study</p>
<p>In this section, we investigate alternative architectural choices for S4WM and different cache lengths m for TSSM-XL.We conduct these ablation studies on the Four Rooms and Ten Rooms environments.</p>
<p>B.1 Alternative Architectures of S4WM</p>
<p>S4WM-Full-Posterior.In our main experiments, we have chosen to use the factorized posterior
q(z 0:T | x 0:T , a 1:T ) = T t=0 q(z t | x t )(10)
for simplicity and parallel training ability.However, we note that it is possible to condition on the full history while maintaining the parallel training ability:
q(z 0:T | x 0:T , a 1:T ) = T t=0 q(z t | x ≤t , a ≤t ) .(11)
We illustrate this architecture in Figure 8.Here, we first use a CNN encoder to obtain a deterministic embedding e t for each image observation x t , and then use a stack of S4 blocks to encode the history and compute the sufficient statistics of the posterior for all t in parallel:</p>
<p>q(z t | x ≤t , a ≤t ) = MLP(h t ) , h 0:T , s T = S4Blocks(g 0:T , s −1 ) , g t = MLP(concat[e t , a t ]) .</p>
<p>(12) We have defined the dummy action a 0 = ∅ ∅ ∅ and the initial S4 hidden state s −1 , which are both implemented as vectors of all zeros.We note that the S4 blocks in the posterior are not shared with those in the prior.S4WM-No-MLP.In our implementation, each S4 block consists of two S4 layers and one MLP.We note that the MLP is not used in the original S4 [21] for the Long Range Arena tasks [59], but is commonly used in language modeling and audio generation [17].Hence, we consider a model variant without the MLP in the S4 blocks to investigate the importance of this MLP in world model learning.</p>
<p>Results.We report results on the non-teleport Four Rooms and Ten Rooms environments in Table 4 and Figures 9 and 10. Results on teleport environments are reported in Figures 11 and 12.We also show a comparison of speed and memory usage in Figure 13.Our results suggest that S4WM-Full-Posterior performs similarly as S4WM on the Four Rooms environment, and becomes better in the more challenging Ten Rooms environment where the episode length is longer.However, it is more computationally demanding than S4WM during training.In contrast, while S4WM-No-MLP is the most computationally efficient, its performance is much worse than S4WM, indicating the importance of the MLP in S4 blocks to both long-term imagination and context-dependent recall.</p>
<p>Training</p>
<p>S4 Blocks (parallel)</p>
<p>&lt; l a t e x i t s h a 1 _ b a s e 6 4 = "
7 b O M E Q s I 3 l 5 h U 0 E U u t Z N F O / g r L s = " &gt; A A A B + 3 i c b V D L S s N A F J 3 U V 6 2 v W J d u g k V w V R L x t S y 4 6 b K C f U A T w m Q 6 a Y d O J m H m R l p C f s W N C 0 X c + i P u / B s n b R b a e m D g c M 6 9 3 D M n S D h T Y N v f R m V j c 2 t 7 p 7 p b 2 9 s / O D w y j + s 9 F a e S 0 C 6 J e S w H A V a U M 0 G 7 w I D T Q S I p j g J O + 8 H 0 v v D 7 T 1 Q q F o t H m C f U i / B Y s J A R D F r y z b o 7 w Z C 5 E Y Z J E G a z P P c d 3 2 z Y T X s B a 5 0 4 J W m g E h 3 f / H J H M U k j K o B w r N T Q s R P w M i y B E U 7 z m p s q m m A y x W M 6 1 F T g i C o v W 2 T P r X O t j K w w l v o J s B b q 7 4 0 M R 0 r N o 0 B P F i H V q l e I / 3 n D F M I 7 L 2 M i S Y E K s j w U p t y C 2 C q K s E Z M U g J 8 r g k m k u m s F p l g i Q n o u m q 6 B G f 1 y + u k d 9 l 0 b p r X D 1 e N V r u s o 4 p O 0 R m 6 Q A 6 6 R S 3 U R h 3 U R Q T N 0 D N 6 R W 9 G b r w Y 7 8 b H c r R i l D s n 6 A + M z x + N o 5 T O &lt; / l a t e x i t &gt; x1 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " F 6 b w m M O g z m e w T q v M C B F i N K + X W M s = " &gt; A A A B / n i c b V A 9 S w N B E J 2 L X z F + R S 1 t F o N g F e 7 E q G X A J m U E 8 w H J E f Y 2 e 8 m S 3 b 1 j d 0 8 I x 4 G / w V Z r O 7 H 1 r 1 j 6 T 9 w k V 5 j E B w O P 9 2 a Y m R f E n G n j u t 9 O Y W N z a 3 u n u F v a 2 z 8 4 P C o f n 7 R 1 l C h C W y T i k e o G W F P O J G 0 Z Z j j t x o p i E X D a C S b 3 M 7 / z R J V m k X w 0 0 5 j 6 A o 8 k C x n B x k r d f i D S c T b w B u W K W 3 X n Q O v E y 0 k F c j Q H 5 Z / + M C K J o N I Q j r X u e W 5 s / B Q r w w i n W a m f a B p j M s E j 2 r N U Y k G 1 n 8 7 v z d C F V Y Y o j J Q t a d B c / T u R Y q H 1 V A S 2 U 2 A z 1 q v e T P z P 6 y U m v P N T J u P E U E k W i 8 K E I x O h 2 f N o y B Q l h k 8 t w U Q x e y s i Y 6 w w M T a i p S 2 B y G w m 3 m o C 6 6 R 9 V f V u q r W H 6 0 q 9 k a d T h D M 4 h 0 v w 4 B b q 0 I A m t I A A h x d 4 h T f n 2 X l 3 P p z P R W v B y W d O Y Q n O 1 y / F e J a L &lt; / l a t e x i t &gt; h1 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " K E Q t t H w 0 h I 5 X j T M / s 4 k L R + 4 2 7 A 0 = " &gt; A A A C A n i c b V D L S s N A F L 2 p r 1 p f V Z d u B o v g q i T i a 1 l w 0 2 U F + 4 A m l M l 0 0 g 6 d T M L M R K g h O 7 / B r a 7 d i V t / x K V / 4 q T N w r Y e u H A 4 5 1 7 u 4 f g x Z 0 r b 9 r d V W l v f 2 N w q b 1 d 2 d v f 2 D 6 q H R x 0 V J Z L Q N o l 4 J H s + V p Q z Q d u a a U 5 7 s a Q 4 9 D n t + p O 7 3 O 8 + U q l Y J B 7 0 N K Z e i E e C B Y x g b S T X D b E e + 0 H 6 l A 3 s Q b V m 1 + 0 Z 0 C p x C l K D A q 1 B 9 c c d R i Q J q d C E Y 6 X 6 j h 1 r L 8 V S M 8 J p V n E T R W N M J n h E + 4 Y K H F L l p b P M G T o z y h A F k T Q j N J q p f y 9 S H C o 1 D X 2 z m W d U y 1 4 u / u f 1 E x 3 c e i k T c a K p I P N H Q c K R j l B e A B o y S Y n m U 0 M w k c x k R W S M J S b a 1 L T w x Q 8 z 0 4 m z 3 M A q 6 V z U n e v 6 1 f 1 l r d E s 2 i n D C Z z C O T h w A w 1 o Q g v a Q C C G F 3 i F N + v Z e r c + r M / 5 a s k q b o 5 h A d b X L x f G m G c = &lt; / l a t e x i t &gt; z 0 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 6 S p V b 0 R q H / o Z 9 T y G + l M 1 F A S Z V k Y = " &gt; A A A B / n i c b V A 9 S w N B E J 2 L X z F + R S 1 t F o N g F e 7 E q G X A J m U E 8 w H J E f Y 2 e 8 m S 3 b 1 j d 0 8 I x 4 G / w V Z r O 7 H 1 r 1 j 6 T 9 w k V 5 j E B w O P 9 2 a Y m R f E n G n j u t 9 O Y W N z a 3 u n u F v a 2 z 8 4 P C o f n 7 R 1 l C h C W y T i k e o G W F P O J G 0 Z Z j j t x o p i E X D a C S b 3 M 7 / z R J V m k X w 0 0 5 j 6 A o 8 k C x n B x k r d f i B S n A 2 8 Q b n i V t 0 5 0 D r x c l K B H M 1 B + a c / j E g i q D S E Y 6 1 7 n h s b P 8 X K M M J p V u o n m s a Y T P C I 9 i y V W F D t p / N 7 M 3 R h l S E K I 2 V L G j R X / 0 6 k W G g 9 F Y H t F N i M 9 a o 3 E / / z e o k J 7 / y U y T g x V J L F o j D h y E R o 9 j w a M k W J 4 V N L M F H M 3 o r I G C t M j I 1 o a U s g M p u J t 5 r A O m l f V b 2 b a u 3 h u l J v 5 O k U 4 Q z O 4 R I 8 u I U 6 N K A J L S D A 4 Q V e 4 c 1 5 d t 6 d D + d z 0 V p w 8 p l T W I L z 9 Q u 6 X p a E &lt; / l a t e x i t &gt; a1 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " K a p M a I 9 6 k R G F G T + S f b x H h G K J 1 a w = " &gt; A A A C C n i c b V D L S s N A F J 3 4 r P U V 6 9 L N Y B F c l a T 4 W h b c d F n B P q A J Z T K d t E N n J m F m I i 0 h f + A 3 u N W 1 O 3 H r T 7 j 0 T 5 y 0 W d j W A x c O 5 9 z L P Z w g Z l R p x / m 2 N j a 3 t n d 2 S 3 v l / Y P D o 2 P 7 p N J R U S I x a e O I R b I X I E U Y F a S t q W a k F 0 u C e M B I N 5 j c 5 3 7 3 i U h F I / G o Z z H x O R o J G l K M t J E G d s U b I 5 1 6 H O l x E K b T L B v U B 3 b V q T l z w H X i F q Q K C r Q G 9 o 8 3 j H D C i d C Y I a X 6 r h N r P 0 V S U 8 x I V v Y S R W K E J 2 h E + o Y K x I n y 0 3 n 2 D F 4 Y Z Q j D S J o R G s 7 V v x c p 4 k r N e G A 2 8 5 B q 1 c v F / 7 x + o s M 7 P 6 U i T j Q R e P E o T B j U E c y L g E M q C d Z s Z g j C k p q s E I + R R F i b u p a + B D w z n b i r D a y T T r 3 m 3 t S u H 6 6 q j W b R T g m c g X N w C V x w C x q g C V q g D T C Y g h f w C t 6 s Z + v d + r A + F 6 s b V n F z C p Z g f f 0 C n p + b Z Q = = &lt; / l a t e x i t &gt; x2 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " T b G 7 2 g f 4 V x u S j h Z c A R w w / D U d v 5 g = " &gt; A A A B / n i c b V D L S g N B E O y N r x h f U Y 9 e B o P g K e w G X 8 e A l x w j m A c k S 5 i d z C Z D Z m a X m V k h L A t + g 1 c 9 e x O v / o p H / 8 R J s g e T W N B Q V H X T 3 R X E n G n j u t 9 O Y W N z a 3 u n u F v a 2 z 8 4 P C o f n 7 R 1 l C h C W y T i k e o G W F P O J G 0 Z Z j j t x o p i E X D a C S b 3 M 7 / z R J V m k X w 0 0 5 j 6 A o 8 k C x n B x k r d f i D S c T a o D c o V t + r O g d a J l 5 M K 5 G g O y j / 9 Y U Q S Q a U h H G v d 8 9 z Y + C l W h h F O s 1 I / 0 T T G Z I J H t G e p x I J q P 5 3 f m 6 E L q w x R G C l b 0 q C 5 + n c i x U L r q Q h s p 8 B m r F e 9 m f i f 1 0 t M e O e n T M a J o Z I s F o U J R y Z C s + f R k C l K D J 9 a g o l i 9 l Z E x l h h Y m x E S 1 s C k d l M v N U E 1 k m 7 V v V u q t c P V 5 V 6 I 0 + n C G d w D p f g w S 3 U o Q F N a A E B D i / w C m / O s / P u f D i f i 9 a C k 8 + c w h K c r 1 / H C 5 a M &lt; / l a t e x i t &gt; h2 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " w + Y g W R E R C X e z q 9 d b 0 k H / V 6 1 f M / Q = " &gt; A A A C A n i c b V D L S s N A F L 2 p r 1 p f V Z d u B o v g q i T i a 1 l w 0 2 U F + 4 A m l M l 0 0 g 6 d T M L M R K g h O 7 / B r a 7 d i V t / x K V / 4 q T N w r Y e u H A 4 5 1 7 u 4 f g x Z 0 r b 9 r d V W l v f 2 N w q b 1 d 2 d v f 2 D 6 q H R x 0 V J Z L Q N o l 4 J H s + V p Q z Q d u a a U 5 7 s a Q 4 9 D n t + p O 7 3 O 8 + U q l Y J B 7 0 N K Z e i E e C B Y x g b S T X D b E e + 0 H 6 l A 2 c Q b V m 1 + 0 Z 0 C p x C l K D A q 1 B 9 c c d R i Q J q d C E Y 6 X 6 j h 1 r L 8 V S M 8 J p V n E T R W N M J n h E + 4 Y K H F L l p b P M G T o z y h A F k T Q j N J q p f y 9 S H C o 1 D X 2 z m W d U y 1 4 u / u f 1 E x 3 c e i k T c a K p I P N H Q c K R j l B e A B o y S Y n m U 0 M w k c x k R W S M J S b a 1 L T w x Q 8 z 0 4 m z 3 M A q 6 V z U n e v 6 1 f 1 l r d E s 2 i n D C Z z C O T h w A w 1 o Q g v a Q C C G F 3 i F N + v Z e r c + r M / 5 a s k q b o 5 h A d b X L x l Z m G g = &lt; / l a t e x i t &gt; z 1 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " b 0 a g k e q G o o S b Y A g 7 K h / C + z u Q 5 / k = " &gt; A A A B / n i c b V D L S g N B E O y N r x h f U Y 9 e B o P g K e w G X 8 e A l x w j m A c k S 5 i d z C Z D Z m a X m V k h L A t + g 1 c 9 e x O v / o p H / 8 R J s g e T W N B Q V H X T 3 R X E n G n j u t 9 O Y W N z a 3 u n u F v a 2 z 8 4 P C o f n 7 R 1 l C h C W y T i k e o G W F P O J G 0 Z Z j j t x o p i E X D a C S b 3 M 7 / z R J V m k X w 0 0 5 j 6 A o 8 k C x n B x k r d f i B S n A 1 q g 3 L F r b p z o H X i 5 a Q C O Z q D 8 k 9 / G J F E U G k I x 1 r 3 P D c 2 f o q V Y Y T T r N R P N I 0 x m e A R 7 V k q s a D a T + f 3 Z u j C K k M U R s q W N G i u / p 1 I s d B 6 K g L b K b A Z 6 1 V v J v 7 n 9 R I T 3 v k p k 3 F i q C S L R W H C k Y n Q 7 H k 0 Z I o S w 6 e W Y K K Y v R W R M V a Y G B v R 0 p Z A Z D Y T b z W B d d K u V b 2 b 6 v X D V a X e</p>
<p>y N M p w h m c w y V 4 c A t 1 a E A T W k C</p>
<p>A w w u 8 w p v z 7 L w 7 H 8 7 n o r X g 5 D O n s A T n 6 x e 7 8 Z a F &lt; / l a t e x i t &gt; a2 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " H 1 J i G i + A p 3 N a N q q y p e P 8 u Q
C o U x w = " &gt; A A A C A n i c b V D L S s N A F L 3 x W e u r 6 t J N s A i u S l J 8 L Q t u u q x g H 9 C E M p l O 2 q E z k z A z E W r I z m 9 w q 2 t 3 4 t Y f c e m f O G m z s K 0 H L h z O u Z d 7 O E H M q N K O 8 2 2 t r W 9 s b m 2 X d s q 7 e / s H h 5 W j 4 4 6 K E o l J G 0 c s k r 0 A K c K o I G 1 N N S O 9 W B L E A 0 a 6 w e Q u 9 7 u P R C o a i Q c 9 j Y n P 0 U j Q k G K k j e R 5 H O l x E K Z P 2 a A + q F S d m j O D v U r c g l S h Q G t Q + f G G E U 4 4 E R o z p F T f d W L t p 0 h q i h n J y l 6 i S I z w B I 1 I 3 1 C B O F F + O s u c 2 e d G G d p h J M 0 I b c / U v x c p 4 k p N e W A 2 8 4 x q 2 c v F / 7 x + o s N b P 6 U i T j Q R e P 4 o T J i t I z s v w B 5 S S b B m U 0 M Q l t R k t f E Y S Y S 1 q W n h S 8 A z 0 4 m 7 3 M A q 6 d R r 7 n X t 6 v 6 y 2 m g W 7 Z T g F M 7 g A l y 4 g Q Y 0 o Q V t w B D D C 7 z C m / V s v V s f 1 u d 8 d c 0 q b k 5 g A d b X L x r s m G k = &lt; / l a t e x i t &gt; z 2 Prior Posterior Next Step Prediction Dec Dec &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " w + Y g W R E R C X e z q 9 d b 0 k H / V 6 1 f M / Q = " &gt; A A A C A n i c b V D L S s N A F L 2 p r 1 p f V Z d u B o v g q i T i a 1 l w 0 2 U F + 4 A m l M l 0 0 g 6 d T M L M R K g h O 7 / B r a 7 d i V t / x K V / 4 q T N w r Y e u H A 4 5 1 7 u 4 f g x Z 0 r b 9 r d V W l v f 2 N w q b 1 d 2 d v f 2 D 6 q H R x 0 V J Z L Q N o l 4 J H s + V p Q z Q d u a a U 5 7 s a Q 4 9 D n t + p O 7 3 O 8 + U q l Y J B 7 0 N K Z e i E e C B Y x g b S T X D b E e + 0 H 6 l A 2 c Q b V m 1 + 0 Z 0 C p x C l K D A q 1 B 9 c c d R i Q J q d C E Y 6 X 6 j h 1 r L 8 V S M 8 J p V n E T R W N M J n h E + 4 Y K H F L l p b P M G T o z y h A F k T Q j N J q p f y 9 S H C o 1 D X 2 z m W d U y 1 4 u / u f 1 E x 3 c e i k T c a K p I P N H Q c K R j l B e A B o y S Y n m U 0 M w k c x k R W S M J S b a 1 L T w x Q 8 z 0 4 m z 3 M A q 6 V z U n e v 6 1 f 1 l r d E s 2 i n D C Z z C O T h w A w 1 o Q g v a Q C C G F 3 i F N + v Z e r c + r M / 5 a s k q b o 5 h A d b X L x l Z m G g = &lt; / l a t e x i t &gt; z 1
&lt; l a t e x i t s h a 1 _ b a s e 6 4 = " H 1 J i G i + A p 3 N a N q q y p e P 8 u Q
C o U x w = " &gt; A A A C A n i c b V D L S s N A F L 3 x W e u r 6 t J N s A i u S l J 8 L Q t u u q x g H 9 C E M p l O 2 q E z k z A z E W r I z m 9 w q 2 t 3 4 t Y f c e m f O G m z s K 0 H L h z O u Z d 7 O E H M q N K O 8 2 2 t r W 9 s b m 2 X d s q 7 e / s H h 5 W j 4 4 6 K E o l J G 0 c s k r 0 A K c K o I G 1 N N S O 9 W B L E A 0 a 6 w e Q u 9 7 u P R C o a i Q c 9 j Y n P 0 U j Q k G K k j e R 5 H O l x E K Z P 2 a A + q F S d m j O D v U r c g l S h Q G t Q + f G G E U 4 4 E R o z p F T f d W L t p 0 h q i h n J y l 6 i S I z w B I 1 I 3 1 C B O F F + O s u c 2 e d G G d p h J M 0 I b c / U v x c p 4 k p N e W A 2 8 4 x q 2 c v F / 7 x + o s N b P 6 U i T j Q R e P 4 o T J i t I z s v w B 5 S S b B m U 0 M Q l t R k t f E Y S Y S 1 q W n h S 8 A z 0 4 m 7 3 M A q 6 d R r 7 n X t 6 v 6 y 2 m g W 7 Z T g F M 7 g A l y 4 g Q Y 0 o Q V t w B D D C 7 z C m / V s v V s f 1 u d 8 d c 0 q b k 5 g A d b X L x r s m G k = &lt; / l a t e x i t &gt; z 2 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " Q x d / u 7 Q W P L 3 U + y c 4 a h 9 T t I X E x C w = " &gt; A A A C A n i c b V D L S s N A F L 2 p r 1 p f V Z d u B o v g q i T i a 1 l w 0 2 U F + 4 A m l M l 0 0 g 6 d T M L M R C w h O 7 / B r a 7 d i V t / x K V / 4 q T N w r Y e u H A 4 5 1 7 u 4 f g x Z 0 r b 9 r d V W l v f 2 N w q b 1 d 2 d v f 2 D 6 q H R x 0 V J Z L Q N o l 4 J H s + V p Q z Q d u a a U 5 7 s a Q 4 9 D n t + p O 7 3 O 8 + U q l Y J B 7 0 N K Z e i E e C B Y x g b S T X D b E e + 0 H 6 l A 3 s Q b V m 1 + 0 Z 0 C p x C l K D A q 1 B 9 c c d R i Q J q d C E Y 6 X 6 j h 1 r L 8 V S M 8 J p V n E T R W N M J n h E + 4 Y K H F L l p b P M G T o z y h A F k T Q j N J q p f y 9 S H C o 1 D X 2 z m W d U y 1 4 u / u f 1 E x 3 c e i k T c a K p I P N H Q c K R j l B e A B o y S Y n m U 0 M w k c x k R W S M J S b a 1 L T w x Q 8 z 0 4 m z 3 M A q 6 V z U n e v 6 1 f 1 l r d E s 2 i n D C Z z C O T h w A w 1 o Q g v a Q C C G F 3 i F N + v Z e r c + r M / 5 a s k q b o 5 h A d b X L x S a m G U = &lt; / l a t e x i t &gt; x 0 Enc &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " f 3 g k h J W 1 r v K 2 g W g m 7 c v 3 D j 6 k c G A = " &gt; A A A C A n i c b V D L S s N A F L 2 p r 1 p f V Z d u B o v g q i T i a 1 l w 0 2 U F + 4 A m l M l 0 0 g 6 d T M L M R C w h O 7 / B r a 7 d i V t / x K V / 4 q T N w r Y e u H A 4 5 1 7 u 4 f g x Z 0 r b 9 r d V W l v f 2 N w q b 1 d 2 d v f 2 D 6 q H R x 0 V J Z L Q N o l 4 J H s + V p Q z Q d u a a U 5 7 s a Q 4 9 D n t + p O 7 3 O 8 + U q l Y J B 7 0 N K Z e i E e C B Y x g b S T X D b E e + 0 H 6 l A 2 c Q b V m 1 + 0 Z 0 C p x C l K D A q 1 B 9 c c d R i Q J q d C E Y 6 X 6 j h 1 r L 8 V S M 8 J p V n E T R W N M J n h E + 4 Y K H F L l p b P M G T o z y h A F k T Q j N J q p f y 9 S H C o 1 D X 2 z m W d U y 1 4 u / u f 1 E x 3 c e i k T c a K p I P N H Q c K R j l B e A B o y S Y n m U 0 M w k c x k R W S M J S b a 1 L T w x Q 8 z 0 4 m z 3 M A q 6 V z U n e v 6 1 f 1 l r d E s 2 i n D C Z z C O T h w A w 1 o Q g v a Q C C G F 3 i F N + v Z e r c + r M / 5 a s k q b o 5 h A d b X L x Y t m G Y = &lt; / l a t e x i t &gt; x 1 Enc &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " z d k S R 6 7 g 7 7 X f J l z e y M l X a q N G o L M = " &gt; A A A C A n i c b V D L S s N A F L 3 x W e u r 6 t J N s A i u S l J 8 L Q t u u q x g H 9 C E M p l O 2 q E z k z A z E U v I z m 9 w q 2 t 3 4 t Y f c e m f O G m z s K 0 H L h z O u Z d 7 O E H M q N K O 8 2 2 t r W 9 s b m 2 X d s q 7 e / s H h 5 W j 4 4 6 K E o l J G 0 c s k r 0 A K c K o I G 1 N N S O 9 W B L E A 0 a 6 w e Q u 9 7 u P R C o a i Q c 9 j Y n P 0 U j Q k G K k j e R 5 H O l x E K Z P 2 a A + q F S d m j O D v U r c g l S h Q G t Q + f G G E U 4 4 E R o z p F T f d W L t p 0 h q i h n J y l 6 i S I z w B I 1 I 3 1 C B O F F + O s u c 2 e d G G d p h J M 0 I b c / U v x c p 4 k p N e W A 2 8 4 x q 2 c v F / 7 x + o s N b P 6 U i T j Q R e P 4 o T J i t I z s v w B 5 S S b B m U 0 M Q l t R k t f E Y S Y S 1 q W n h S 8 A z 0 4 m 7 3 M A q 6 d R r 7 n X t 6 v 6 y 2 m g W 7 Z T g F M 7 g A l y 4 g Q Y 0 o Q V t w B D D C 7 z C m / V s v V s f 1 u d 8 d c 0 q b k 5 g A d b X L x f A m G c = &lt; / l a t e x i t &gt;
x 2</p>
<p>Enc</p>
<p>S4 Blocks (parallel)</p>
<p>&lt; l a t e x i t s h a 1 _ b a s e 6 4 = " I 4 I 3 Y l p g b w b 9 j q z + u h &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " z w P h f q P K p 1
1 C K J 8 L y u E = " &gt; A A A B / n i c b V A 9 S w N B E J 2 L X z F + R S 1 t D o N g F e 7 E r z J g o W U E E w P J E f Y 2 c 8 m S 3 b 1 j d 0 8 I R 8 D f Y K u 1 n d j 6 V y z 9 J 2 6 S K 0 z i g 4 H H e z P M z A s T z r T x v G + n s L K 6 t r 5 R 3 C x t b e / s 7 p X 3 D 5 o 6 T h X F B o 1 5 r F o h 0 c i Z x I Z h h m M r U U h E y P E x H N 5 M / M c n V J r F 8 s G M E g w E 6 U s W M U q M l V q d U G Q 4 7 n r d c s W r e l O 4 y 8 T P S Q V y 1 L v l n 0 4 v p q l A a S g n W r d 9 L z F B R p R h l O O 4 1 E k 1 J o Q O S R / b l k o i U A f Z 9 N 6 x e 2 K V n h v F y p Y 0 7 l T 9 O 5 E R o f V I h L Z T E D P Q i 9 5 E / M 9 r p y a 6 D j I m k 9 S g p L N F U c p d E 7 u T 5 9 0 e U 0 g N H 1 l C q G L 2 V p c O i C L U 2 I j m t o R i b D P x F x N Y J s 2 z q n 9 Z v b g / r 9 R u 8 3 S K c A T H c A o + X E E N 7 q A O D a D A 4 Q V e 4 c+ M + 5 f p I e V n u + t R V T g = " &gt; A A A B / n i c b V A 9 S w N B E J 2 L X z F + R S 1 t D o N g F e 7 E r z J g o W U E E w P J E f Y 2 c 8 m S 3 b 1 j d 0 8 I R 8 D f Y K u 1 n d j 6 V y z 9 J 2 6 S K 0 z i g 4 H H e z P M z A s T z r T x v G + n s L K 6 t r 5 R 3 C x t b e / s 7 p X 3 D 5 o 6 T h X F B o 1 5 r F o h 0 c i Z x I Z h h m M r U U h E y P E x H N 5 M / M c n V J r F 8 s G M E g w E 6 U s W M U q M l V q d U G Q 4 7 v r d c s W r e l O 4 y 8 T P S Q V y 1 L v l n 0 4 v p q l A a S g n W r d 9 L z F B R p R h l O O 4 1 E k 1 J o Q O S R / b l k o i U A f Z 9 N 6 x e 2 K V n h v F y p Y 0 7 l T 9 O 5 E R o f V I h L Z T E D P Q i 9 5 E / M 9 r p y a 6 D j I m k 9 S g p L N F U c p d E 7 u T 5 9 0 e U 0 g N H 1 l C q G L 2 V p c O i C L U 2 I j m t o R i b D P x F x N Y J s 2 z q n 9 Z v b g / r 9 R u 8 3 S K c A T H c A o + X E E N 7 q A O D a D A 4 Q V e 4 c+ P G r p K F G E N k n E I 9 U J s K a c S d o 0 z H D a i R X F I u C 0 H Y x v p 3 7 7 i S r N I v l o J j H 1 B R 5 K F j K C j Z U 6 v U C k N O v X + u W K W 3 V n Q K v E y 0 k F c j T 6 5 Z / e I C K J o N I Q j r X u e m 5 s / B Q r w w i n W a m X a B p j M s Z D 2 r V U Y k G 1 n 8 7 u z d C Z V Q Y o j J Q t a d B M / T u R Y q H 1 R A S 2 U 2 A z 0 s v e V P z P 6 y Y m v P F T J u P E U E n m i 8 K E I x O h 6 f N o w B Q l h k 8 s w U Q x e y s i I 6 w w M T a i h S 2 B y G w m 3 n I C q 6 R V q 3 p X 1 c u H i 0 r 9 L k + n C C d w C u f g w T X U 4 R 4 a 0 A Q C H F 7 g F d 6 c Z + f d + X A + 5 6 0 F J 5 8 5 h g U 4 X 7 / B / J a I &lt; / l a t e x i t &gt; e 2 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " w S o X J O k v E t C u 2 O A W 5 j k C U t I Q t K s = " &gt; A A A C C H i c b V D L S s N A F J 3 U V 6 2 v q E s 3 g 0 V w V R L x t S y 4 0 G U F + 4 A m l M l 0 0 g 6 d R 5 i Z F E r o D / g N b n X t T t z 6 F y 7 9 E y d t F r b 1 w I X D O f d y L i d K G N X G 8 7 6 d 0 t r 6 x u Z W e b u y s 7 u 3 f + A e H r W 0 T B U m T S y Z V J 0 I a c K o I E 1 D D S O d R B H E I 0 b a 0 e g u 9 9 t j o j S V 4 s l M E h J y N B A 0 p h g Z K / V c N 4 h 4 F o y R E t I M q R h M e 2 7 V q 3 k z w F X i F 6 Q K C j R 6 7 k / Q l z j l R B j M k N Z d 3 0 t M m C F l K G Z k W g l S T R K E R 2 h A u p Y K x I k O s 9 n n U 3 h m l T 6 M p b I j D J y p f y 8 y x L W e 8 M h u c m S G e t n L x f + 8 b m r i 2 z C j I k k N E X g e F K c M G g n z G m C f K o I N m 1 i C s K L 2 V 4 i H S C F s b F k L K R H P O / G X G 1 g l r Y u a f 1 2 7 e r y s 1 u + L d s r g B J y C c + C D G 1 A H D 6 A B m g C D M X g B r + D N e X b
e n Q / n c 7 5 a c o q b Y 7 A A 5 + s X S N q a r w = = &lt; / l a t e x i t &gt; ???</p>
<p>&lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 6 S p
V b 0 R q H / o Z 9 T y G + l M 1 F A S Z V k Y = " &gt; A A A B / n i c b V A 9 S w N B E J 2 L X z F + R S 1 t F o N g F e 7 E q G X A J m U E 8 w H J E f Y 2 e 8 m S 3 b 1 j d 0 8 I x 4 G / w V Z r O 7 H 1 r 1 j 6 T 9 w k V 5 j E B w O P 9 2 a Y m R f E n G n j u t 9 O Y W N z a 3 u n u F v a 2 z 8 4 P C o f n 7 R 1 l C h C W y T i k e o G W F P O J G 0 Z Z j j t x o p i E X D a C S b 3 M 7 / z R J V m k X w 0 0 5 j 6 A o 8 k C x n B x k r d f i B S n A 2 8 Q b n i V t 0 5 0 D r x c l K B H M 1 B + a c / j E g i q D S E Y 6 1 7 n h s b P 8 X K M M J p V u o n m s a Y T P C I 9 i y V W F D t p / N 7 M 3 R h l S E K I 2 V L G j R X / 0 6 k W G g 9 F Y H t F N i M 9 a o 3 E / / z e o k J 7 / y U y T g x V J L F o j D h y E R o 9 j w a M k W J 4 V N L M F H M 3 o r I G C t M j I 1 o a U s g M p u J t 5 r A O m l f V b 2 b a u 3 h u l J v 5 O k U 4 Q z O 4 R I 8 u I U 6 N K A J L S D A 4 Q V e 4 c 1 5 d t 6 d D + d z 0 V p w 8 p l T W I L z 9 Q u 6 X p a E &lt; / l a t e x i t &gt; a1 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " b 0 a g k e q G o o S b Y A g 7 K h / C + z u Q 5 / k = " &gt; A A A B / n i c b V D L S g N B E O y N r x h f U Y 9 e B o P g K e w G X 8 e A l x w j m A c k S 5 i d z C Z D Z m a X m V k h L A t + g 1 c 9 e x O v / o p H / 8 R J s g e T W N B Q V H X T 3 R X E n G n j u t 9 O Y W N z a 3 u n u F v a 2 z 8 4 P C o f n 7 R 1 l C h C W y T i k e o G W F P O J G 0 Z Z j j t x o p i E X D a C S b 3 M 7 / z R J V m k X w 0 0 5 j 6 A o 8 k C x n B x k r d f i B S n A 1 q g 3 L F r b p z o H X i 5 a Q C O Z q D 8 k 9 / G J F E U G k I x 1 r 3 P D c 2 f o q V Y Y T T r N R P N I 0 x m e A R 7 V k q s a D a T + f 3 Z u j C K k M U R s q W N G i u / p 1 I s d B 6 K g L b K b A Z 6 1 V v J v 7 n 9 R I T 3 v k p k 3 F i q C S L R W H C k Y n Q 7 H k 0 Z I o S w 6 e W Y K K Y v R W R M V a Y G B v R 0 p Z A Z D Y T b z W B d d K u V b 2 b 6 v X D V a X e y N M p w h m c w y V 4 c A t 1 a E A T W k C A w w u 8 w p v z 7 L w 7 H 8 7 n o r X g 5 D O n s A T n 6 x e 7 8 Z a F &lt; / l a t e x i t &gt; a2 Imagination S4 Blocks (parallel) &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " K E Q t t H w 0 h I 5 X j T M / s 4 k L R + 4 2 7 A 0 = " &gt; A A A C A n i c b V D L S s N A F L 2 p r 1 p f V Z d u B o v g q i T i a 1 l w 0 2 U F + 4 A m l M l 0 0 g 6 d T M L M R K g h O 7 / B r a 7 d i V t / x K V / 4 q T N w r Y e u H A 4 5 1 7 u 4 f g x Z 0 r b 9 r d V W l v f 2 N w q b 1 d 2 d v f 2 D 6 q H R x 0 V J Z L Q N o l 4 J H s + V p Q z Q d u a a U 5 7 s a Q 4 9 D n t + p O 7 3 O 8 + U q l Y J B 7 0 N K Z e i E e C B Y x g b S T X D b E e + 0 H 6 l A 3 s Q b V m 1 + 0 Z 0 C p x C l K D A q 1 B 9 c c d R i Q J q d C E Y 6 X 6 j h 1 r L 8 V S M 8 J p V n E T R W N M J n h E + 4 Y K H F L l p b P M G T o z y h A F k T Q j N J q p f y 9 S H C o 1 D X 2 z m W d U y 1 4 u / u f 1 E x 3 c e i k T c a K p I P N H Q c K R j l B e A B o y S Y n m U 0 M w k c x k R W S M J S b a 1 L T w x Q 8 z 0 4 m z 3 M A q 6 V z U n e v 6 1 f 1 l r d E s 2 i n D C Z z C O T h w A w 1 o Q g v a Q C C G F 3 i F N + v Z e r c + r M / 5 a s k q b o 5 h A d b X L x f G m G c = &lt; / l a t e x i t &gt; z 0 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 6 S p V b 0 R q H / o Z 9 T y G + l M 1 F A S Z V k Y = " &gt; A A A B / n i c b V A 9 S w N B E J 2 L X z F + R S 1 t F o N g F e 7 E q G X A J m U E 8 w H J E f Y 2 e 8 m S 3 b 1 j d 0 8 I x 4 G / w V Z r O 7 H 1 r 1 j 6 T 9 w k V 5 j E B w O P 9 2 a Y m R f E n G n j u t 9 O Y W N z a 3 u n u F v a 2 z 8 4 P C o f n 7 R 1 l C h C W y T i k e o G W F P O J G 0 Z Z j j t x o p i E X D a C S b 3 M 7 / z R J V m k X w 0 0 5 j 6 A o 8 k C x n B x k r d f i B S n A 2 8 Q b n i V t 0 5 0 D r x c l K B H M 1 B + a c / j E g i q D S E Y 6 1 7 n h s b P 8 X K M M J p V u o n m s a Y T P C I 9 i y V W F D t p / N 7 M 3 R h l S E K I 2 V L G j R X / 0 6 k W G g 9 F Y H t F N i M 9 a o 3 E / / z e o k J 7 / y U y T g x V J L F o j D h y E R o 9 j w a M k W J 4 V N L M F H M 3 o r I G C t M j I 1 o a U s g M p u J t 5 r A O m l f V b 2 b a u 3 h u l J v 5 O k U 4 Q z O 4 R I 8 u I U 6 N K A J L S D A 4 Q V e 4 c 1 5 d t 6 d D + d z 0 V p w 8 p l T W I L z 9 Q u 6 X p a E &lt; / l a t e x i t &gt; a1 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " w + Y g W R E R C X e z q 9 d b 0 k H / V 6 1 f M / Q = " &gt; A A A C A n i c b V D L S s N A F L 2 p r 1 p f V Z d u B o v g q i T i a 1 l w 0 2 U F + 4 A m l M l 0 0 g 6 d T M L M R K g h O 7 / B r a 7 d i V t / x K V / 4 q T N w r Y e u H A 4 5 1 7 u 4 f g x Z 0 r b 9 r d V W l v f 2 N w q b 1 d 2 d v f 2 D 6 q H R x 0 V J Z L Q N o l 4 J H s + V p Q z Q d u a a U 5 7 s a Q 4 9 D n t + p O 7 3 O 8 + U q l Y J B 7 0 N K Z e i E e C B Y x g b S T X D b E e + 0 H 6 l A 2 c Q b V m 1 + 0 Z 0 C p x C l K D A q 1 B 9 c c d R i Q J q d C E Y 6 X 6 j h 1 r L 8 V S M 8 J p V n E T R W N M J n h E + 4 Y K H F L l p b P M G T o z y h A F k T Q j N J q p f y 9 S H C o 1 D X 2 z m W d U y 1 4 u / u f 1 E x 3 c e i k T c a K p I P N H Q c K R j l B e A B o y S Y n m U 0 M w k c x k R W S M J S b a 1 L T w x Q 8 z 0 4 m z 3 M A q 6 V z U n e v 6 1 f 1 l r d E s 2 i n D C Z z C O T h w A w 1 o Q g v a Q C C G F 3 i F N + v Z e r c + r M / 5 a s k q b o 5 h A d b X L x l Z m G g = &lt; / l a t e x i t &gt; z 1 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " b 0 a g k e q G o o S b Y A g 7 K h / C + z u Q 5 / k = " &gt; A A A B / n i c b V D L S g N B E O y N r x h f U Y 9 e B o P g K e w G X 8 e A l x w j m A c k S 5 i d z C Z D Z m a X m V k h L A t + g 1 c 9 e x O v / o p H / 8 R J s g e T W N B Q V H X T 3 R X E n G n j u t 9 O Y W N z a 3 u n u F v a 2 z 8 4 P C o f n 7 R 1 l C h C W y T i k e o G W F P O J G 0 Z Z j j t x o p i E X D a C S b 3 M 7 / z R J V m k X w 0 0 5 j 6 A o 8 k C x n B x k r d f i B S n A 1 q g 3 L F r b p z o H X i 5 a Q C O Z q D 8 k 9 / G J F E U G k I x 1 r 3 P D c 2 f o q V Y Y T T r N R P N I 0 x m e A R 7 V k q s a D a T + f 3 Z u j C K k M U R s q W N G i u / p 1 I s d B 6 K g L b K b A Z 6 1 V v J v 7 n 9 R I T 3 v k p k 3 F i q C S L R W H C k Y n Q 7 H k 0 Z I o S w 6 e W Y K K Y v R W R M V a Y G B v R 0 p Z A Z D Y T b z W B d d K u V b 2 b 6 v X D V a X e y N M p w h m c w y V 4 c A t 1 a E A T W k C A w w u 8 w p v z 7 L w 7 H 8 7 n o r X g 5 D O n s A T n 6 x e 7 8 Z a F &lt; / l a t e x i t &gt; a2 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " K a p M a I 9 6 k R G F G T + S f b x H h G K J 1 a w = " &gt; A A A C C n i c b V D L S s N A F J 3 4 r P U V 6 9 L N Y B F c l a T 4 W h b c d F n B P q A J Z T K d t E N n J m F m I i 0 h f + A 3 u N W 1 O 3 H r T 7 j 0 T 5 y 0 W d j W A x c O 5 9 z L P Z w g Z l R p x / m 2 N j a 3 t n d 2 S 3 v l / Y P D o 2 P 7 p N J R U S I x a e O I R b I X I E U Y F a S t q W a k F 0 u C e M B I N 5 j c 5 3 7 3 i U h F I / G o Z z H x O R o J G l K M t J E G d s U b I 5 1 6 H O l x E K b T L B v U B 3 b V q T l z w H X i F q Q K C r Q G 9 o 8 3 j H D C i d C Y I a X 6 r h N r P 0 V S U 8 x I V v Y S R W K E J 2 h E + o Y K x I n y 0 3 n 2 D F 4 Y Z Q j D S J o R G s 7 V v x c p 4 k r N e G A 2 8 5 B q 1 c v F / 7 x + o s M 7 P 6 U i T j Q R e P E o T B j U E c y L g E M q C d Z s Z g j C k p q s E I + R R F i b u p a + B D w z n b i r D a y T T r 3 m 3 t S u H 6 6 q j W b R T g m c g X N w C V x w C x q g C V q g D T C Y g h f w C t 6 s Z + v d + r A + F 6 s b V n F z C p Z g f f 0 C n p + b Z Q = = &lt; / l a t e x i t &gt; x2 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " T b G 7 2 g f 4 V x u S j h Z c A R w w / D U d v 5 g = " &gt; A A A B / n i c b V D L S g N B E O y N r x h f U Y 9 e B o P g K e w G X 8 e A l x w j m A c k S 5 i d z C Z D Z m a X m V k h L A t + g 1 c 9 e x O v / o p H / 8 R J s g e T W N B Q V H X T 3 R X E n G n j u t 9 O Y W N z a 3 u n u F v a 2 z 8 4 P C o f n 7 R 1 l C h C W y T i k e o G W F P O J G 0 Z Z j j t x o p i E X D a C S b 3 M 7 / z R J V m k X w 0 0 5 j 6 A o 8 k C x n B x k r d f i D S c T a o D c o V t + r O g d a J l 5 M K 5 G g O y j / 9 Y U Q S Q a U h H G v d 8 9 z Y + C l W h h F O s 1 I / 0 T T G Z I J H t G e p x I J q P 5 3 f m 6 E L q w x R G C l b 0 q C 5 + n c i x U L r q Q h s p 8 B m r F e 9 m f i f 1 0 t M e O e n T M a J o Z I s F o U J R y Z C s + f R k C l K D J 9 a g o l i 9 l Z E x l h h Y m x E S 1 s C k d l M v N U E 1 k m 7 V v V u q t c P V 5 V 6 I 0 + n C G d w D p f g w S 3 U o Q F N a A E B D i / w C m / O s / P u f D i f i 9 a C k 8 + c w h K c r 1 / H C 5 a M &lt; / l a t e x i t &gt; h2 S4 Blocks (single step) &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " A 8 C t g r l M R A P / y r C / s y h V + l W z o B Y = " &gt; A A A B / n i c b V D L S g N B E O y N r x h f U Y 9 e B o P g K e z 6 P g a 8 5 B j B P C B Z w u x k N h k y M 7 v M z A p h W f A b v O r Z m 3 j 1 V z z 6 J 0 6 S P Z j E g o a i q p v u r i D m T B v X / X Y K a + s b m 1 v F 7 d L O 7 t 7 + Q f n w q K W j R B H a J B G P V C f A m n I m a d M w w 2 k n V h S L g N N 2 M L 6 f + u 0 n q j S L 5 K O Z x N Q X e C h Z y A g 2 V u r 0 A p H i r H / Z L 1 f c q j s D W i V e T i q Q o 9 E v / / Q G E U k E l Y Z w r H X X c 2 P j p 1 g Z R j j N S r 1 E 0 x i T M R 7 S r q U S C 6 r 9 d H Z v h s 6 s M k B h p G x J g 2 b q 3 4 k U C 6 0 n I r C d A p u R X v a m 4 n 9 e N z H h n Z 8 y G S e G S j J f F C Y c m Q h N n 0 c D p i g x f G I J J o r Z W x E Z Y Y W J s R E t b A l E Z j P x l h N Y J a 2 L q n d T v X 6 4 q t T q e T p F O I F T O A c P b q E G d W h A E w h w e I F X e H O e n X f n w / m c t x a c f O Y Y F u B 8 / Q K 9 h J a G &lt; / l a t e x i t &gt; a3 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " C g / w l M Y / l G v f O E 7 I w y S / O g 6 A G g w = " &gt; A A A C C n i c b V D L S s N A F J 3 4 r P U V 6 9 L N Y B F c l c T 3 s u C m y w r 2 A U 0 o k + m k H T o z C T M T a Q n 5 A 7 / B r a 7 d i V t / w q V / 4 q T N w r Y e u H A 4 5 1 7 u 4 Q Q x o 0 o 7 z r e 1 t r 6 x u b V d 2 i n v 7 u 0 f H N p H l b a K E o l J C 0 c s k t 0 A K c K o I C 1 N N S P d W B L E A 0 Y 6 w f g + 9 z t P R C o a i U c 9 j Y n P 0 V D Q k G K k j d S 3 K 9 4 I 6 d T j S I + C M J 1 k W f + y b 1 e d m j M D X C V u Q a q g Q L N v / 3 i D C C e c C I 0 Z U q r n O r H 2 U y Q 1 x Y x k Z S 9 R J E Z 4 j I a k Z 6 h A n C g / n W X P 4 J l R B j C M p B m h 4 U z 9 e 5 E i r t S U B 2 Y z D 6 m W v V z 8 z + s l O r z z U y r i R B O B 5 4 / C h E E d w b w I O K C S Y M 2 m h i A s q c k K 8 Q h J h L W p a + F L w D P T i b v c w C p p X 9 T c m 9 r 1 w 1 W 1 3 i j a K Y E T c A r O g Q t u Q R 0 0 Q B O 0 A A Y T 8 A J e w Z v 1 b L 1 b H 9 b n f H X N K m 6 O w Q K s r 1 + g M p t m &lt; / l a t e x i t &gt; x3
&lt; l a t e x i t s h a 1 _ b a s e 6 4 = " P f o X X i z u w 2 2 X O w 4 N t 2 K g + j 4 l t j E = " &gt; A A A B / n i c b V D L S g N B E O y N r x h f U Y 9 e B o P g K e z 6 P g a 8 5 B j B P C B Z w u
x k N h k y M 7 v M z A p h W f A b v O r Z m 3 j 1 V z z 6 J 0 6 S P Z j E g o a i q p v u r i D m T B v X / X Y K a + s b m 1 v F 7 d L O 7 t 7 + Q f n w q K W j R B H a J B G P V C f A m n I m a d M w w 2 k n V h S L g N N 2 M L 6 f + u 0 n q j S L 5 K O Z x N Q X e C h Z y A g 2 V u r 0 A p G O s v 5 l v 1 x x q + 4 M a J V 4 O a l A j k a / / N M b R C Q R V B r C s d Z d z 4 2 N n 2 J l G O E 0 K / U S T W N M xG I R 6 o b Y E 0 5 k 7 R l m O G 0 G y u K R c B p J 5 j c z / z O E 1 W a R f L R T G P q C z y S L G Q E G y t 1 + 4 F I c T a o D c o V t + r O g d a J l 5 M K 5 G g O y j / 9 Y U Q S Q a U h H G v d 8 9 z Y + C l W h h F O s 1 I / 0 T T G Z I J H t G e p x I J q P 5 3 f m 6 E L q w x R G C l b 0 q C 5 + n c i x U L r q Q h s p 8 B m r F e 9 m f i f 1 0 t M e O e n T M a J o Z I s F o U J R y Z C s + f R k C l K D J 9 a g o l i 9 l Z E x l h h Y m x E S 1 s C k d l M v N U E 1 k n 7 q u r d V K 8 f a p V 6 I 0 + n C G d w D p f g w S 3 U o Q F N a A E B D i / w C m / O s / P u f D i f i 9 a C k 8 + c w h K c r 1 + / F 5 a H &lt; / l a t e x i t &gt; a4 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " b / D u Q 4 t h T 4 r u D r H 9 I v n F w E F v W 1 E = " &gt; A A A C C n i c b V D L S s N A F J 3 U V 6 2 v W J d u B o v g q i T i a 1 l w 0 2 U F + 4 A m l M l 0 0 g 6 d m Y S Z i b S E / I H f 4 F b X 7 s S t P + H S P 3 H S Z m F b D 1 w 4 n H M v 9 3 C C m F G l H e f b K m 1 s b m 3 v l H c r e / s H h 0 f 2 c b W j o k R i 0 s Y R i 2 Q v Q I o w K k h b U 8 1 I L 5 Y E 8 Y C R b j C 5 z / 3 u E 5 G K R u J R z 2 L i c z Q S N K Q Y a S M N 7 K o 3 R j r 1 O N L j I E y n W T a 4 G t g 1 p + 7 M A d e J W 5 A a K N A a 2 D / e M M I J J 0 J j h p T q u 0 6 s / R R J T T E j W c V L F I k R n q A R 6 R s q E C f K T + f Z M 3 h u l C E M I 2 l G a D h X / 1 6 k i C s 1 4 4 H Z z E O q V S 8 X / / P 6 i Q 7 v / J S K O N F E 4 M W j M G F Q R z A v A g 6 p J F i z m S E I S 2 q y Q j x G E m F t 6 l r 6 E v D M d O K u N r B O O p d 1 9 6 Z + / X B V a z S L d s r g F J y B C + C C W 9 A A T d A C b Y D B F L y A V / B m P V v v 1 o f 1 u V g t W c X N C V i C 9 f U L o c W b Z w = = &lt; / l a t e x i t &gt;G I R 6 o b Y E 0 5 k 7 R l m O G 0 G y u K R c B p J 5 j c z / z O E 1 W a R f L R T G P q C z y S L G Q E G y t 1 + 4 F I x 9 m g N i h X 3 K o 7 B 1 o n X k 4 q k K M 5 K P / 0 h x F J B J W G c K x 1 z 3 N j 4 6 d Y G U Y 4 z U r 9 R N M Y k w k e 0 Z 6 l E g u q / X R + b 4 Y u r D J E Y a R s S Y P m 6 t + J F A u t p y K w n Q K b s V 7 1 Z u J / X i 8 x 4 Z 2 f M h k n h k q y W B Q m H J k I z Z 5 H Q 6 Y o M X x q C S a K 2 V s R G W O F i b E R L W 0 J R G Y z 8 V Y T W C f t q 6 p 3 U 7 1 + q F X q j T y d I p z B O V y C B 7 d Q h w Y 0 o Q U E O L z A Kz i Z j Z m a X m V k h L P E b v O r Z m 3 j 1 X z z 6 J 0 6 S P Z j E g o a i q p v u r i D h T B v X / X Y K a + s b m 1 v F 7 d L O 7 t 7 + Q f n w q K X j V B H a J D G P V S f A m n I m a d M w w 2 k n U R S L g N N 2 M L q b + u 0 n q j S L 5 Y M Z J 9 Q X e C B Z x A g 2 V m r 1 S B g b 3 S 9 X 3 K o 7 A 1 o l X k 4 q k K P R L / / 0 w p i k g k p D O N a 6 6 7 m J 8 T O s D C O c T k q 9 V N M E k x E e 0 K 6 l E g u q / W x 2 7 Q S d W S V E U a x s S Y N m 6 t + J D A u t x y K w n Q K b o V 7 2 p u J / X j c 1 0 a 2 f M Z m k h k o y X x S l H J k Y T V 9 H I V O U G D 6 2 B B P F 7 K 2 I D L H C x N i A F r Y E Y m I z 8 Z Y T W C W t i 6 p 3 X b 2 6 v 6 z U 6 n k 6 R T i B U z g H D 2 6 g B n V o Q B M I P M I L v M K b 8 + y 8 O x / O 5 7 y 1 4 O Q z x 7 A A 5 + s X d s + V 1 Q = = &lt; / l a t e x i t &gt; • • • Dec Dec Dec
&lt; l a t e x i t s h a 1 _ b a s e 6 4 = " H 1 J i G i + A p 3 N a N q q y p e P 8 u Q
C o U x w = " &gt; A A A C A n i c b V D L S s N A F L 3 x W e u r 6 t J N s A i u S l J 8 L Q t u u q x g H 9 C E M p l O 2 q E z k z A z E W r I z m 9 w q 2 t 3 4 t Y f c e m f O G m z s K 0 H L h z O u Z d 7 O E H M q N K O 8 2 2 t r W 9 s b m 2 X d s q 7 e / s H h 5 W j 4 4 6 K E o l J G 0 c s k r 0 A K c K o I G 1 N N S O 9 W B L E A 0 a 6 w e Q u 9 7 u P R C o a i Q c 9 j Y n P 0 U j Q k G K k j e R 5 H O l x E K Z P 2 a A + q F S d m j O D v U r c g l S h Q G t Q + f G G E U 4 4 E R o z p F T f d W L t p 0 h q i h n Jl W h h F O p 2 U / 1 V R i M s Z D 2 r N U 4 J j q I J t l n q J T q w x Q l C j 7 h E E z 9 f d G h m O t J 3 F o J / O M e t H L x f + 8 X m q i 2 y B j Q q a G C j I / F K U c m Q T l B a A B U 5 Q Y P r E E E 8 V s V k R G W G F i b E 1 l W 4 K 3 + O V l 0 j 6 v e d e 1 q / v L a r 1 R 1 F G C Y z i B M / D g B u r Q g C a 0 g I C E Z 3 i F Nl W h h F O p 2 U / 1 V R i M s Z D 2 r N U 4 J j q I J t l n q J T q w x Q l C j 7 h E E z 9 f d G h m O t J 3 F o J / O M e t H L x f + 8 X m q i 2 y B j Q q a G C j I / F K U c m Q T l B a A B U 5 Q Y P r E E E 8 V s V k R G W G F i b E 1 l W 4 K 3 + O V l 0 j 6 v e d e 1 q / v L a r 1 R 1 F G C Y z i B M / D g B u r Q g C a 0 g I C E Z 3 i F NV Z W 0 a i 1 j 1 A q K Z 4 J K 1 D T e C 9 R L F S B Q I 1 g 0 m d 7 n f f W R K 8 1 g + m G n C / I i M J A 8 5 J c Z K n h c R M w 7 C 7 G k 2 u B x U a 0 7 d m Q O v E r c g N S j Q G l S / v G F M 0 4 h J Q w X R u u 8 6 i f E z o g y n g s 0 q X q p Z Q u i E j F j f U k k i p v 1 s n n m G z 6 w y x G G s 7 J M G z 9 X f G x m J t J 5 G g Z 3 M M + p l L x f / 8 / q p C W / 9 j M s k N U z S x a E w F d j E O C 8 A D 7 l i 1 I i p J Y Q q b r N i O i a K U G N r q t g S 3 O U v r 5 L O R d 2 9 r l / d X 9 Y a z a K O M p z A K Z y D C z f Q g C a 0 o A 0 U E n i G V 3 h D K X p B 7 + h j M V p C x c 4 x / A H 6 / A E 3 C J H V &lt; / l a t e x i t &gt; z 4
Context &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " 6 S p
V b 0 R q H / o Z 9 T y G + l M 1 F A S Z V k Y = " &gt; A A A B / n i c b V A 9 S w N B E J 2 L X z F + R S 1 t F o N g F e 7 E q G X A J m U E 8 w H J E f YP L 3 U + y c 4 a h 9 T t I X E x C w = " &gt; A A A C A n i c b V D L S s N A F L 2 p r 1 p f V Z d u B o v g q i T i a 1 l w 0 2 U F + 4 A m l M l 0 0 g 6 d T M L M R C w h O 7 / B r a 7 d i V t / x K V / 4 q T N w r Y e u H A 4 5 1 7 u 4 f g x Z 0 r b 9 r d V W l v f 2 N w q b 1 d 2 d v f 2 D 6 q H R x 0 V J Z L Q N o l 4 J H s + V p Q z Q d u a a U 5 7 s a Q 4 9 D n t + p O 7 3 O 8 + U q l Y J B 7 0 N K Z e i E e C B Y x g b S T X D b E e + 0 H 6 l A 3 s Q b V m 1 + 0 Z 0 C p x C l K D A q 1 B 9 c c d R i Q J q d C E Y 6 X 6 j h 1 r L 8 V S M 8 J p V n E T R W N M J n h E + 4 Y K H F L l p b P M G T o z y h A F k T Q j N J q p f y 9 S H C o 1 D X 2 z m W d U y 1 4 u / u f 1 E x 3 c e i k T c a K p I P N H Q c K R j l B e A B o y S Y n m U 0 M w k c x k R W S M J S b a 1 L T w x Q 8 z 0 4 m z 3 M A q 6 V z U n e v 6 1 f 1 l r d E s 2 i n D C Z z C O T h w A w 1 o Q g v a Q C C G F 3 i F N + v Z e r c + r M / 5 a s k q b o 5 h A d b X L x S a m G U = &lt; / l a t e x i t &gt; x 0 Enc &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " f 3 g k h J W 1 r v K 2 g W g m 7 c v 3 D j 6 k c G A = " &gt; A A A C A n i c b V D L S s N A F L 2 p r 1 p f V Z d u B o v g q i T i a 1 l w 0 2 U F + 4 A m l M l 0 0 g 6 d T M L M R C w h O 7 / B r a 7 d i V t / x K V / 4 q T N w r Y e u H A 4 5 1 7 u 4 f g x Z 0 r b 9 r d V W l v f 2 N w q b 1 d 2 d v f 2 D 6 q H R x 0 V J Z L Q N o l 4 J H s + V p Q z Q d u a a U 5 7 s a Q 4 9 D n t + p O 7 3 O 8 + U q l Y J B 7 0 N K Z e i E e C B Y x g b S T X D b E e + 0 H 6 l A 2 c Q b V m 1 + 0 Z 0 C p x C l K D A q 1 B 9 c c d R i Q J q d C E Y 6 X 6 j h 1 r L 8 V S M 8 J p V n E T R W N M J n h E + 4 Y K H F L l p b P M G T o z y h A F k T Q j N J q p f y 9 S H C o 1 D X 2 z m W d U y 1 4 u / u f 1 E x 3 c e i k T c a K p I P N H Q c K R j l B e A B o y S Y n m U 0 M w k c x k R W S M J S b a 1 L T w x Q 8 z 0 4 m z 3 M A q 6 V z U n e v 6 1 f 1 l r d E s 2 i n D C Z z C O T h w A w 1 o Q g v a Q C C G F 3 i F N + v Z e r c + r M / 5 a s k q b o 5 h A d b X L x Y t m G Y = &lt; / l a t e x i t &gt; x 1 Enc S4 Blocks (parallel) &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " w S o X J O k v E t C u 2 O A W 5 j k C U t I Q t K s = " &gt; A A A C C H i c b V D L S s N A F J 3 U V 6 2 v q E s 3 g 0 V w V R L x t S y 4 0 G U F + 4 A m l M l 0 0 g 6 d R 5 i Z F E r o D / g N b n X t T t z 6 F y 7 9 E y d t F r b 1 w I X D O f d y L i d K G N X G 8 7 6 d 0 t r 6 x u Z W e b u y s 7 u 3 f + A e H r W 0 T B U m T S y Z V J 0 I a c K o I E 1 D D S O d R B H E I 0 b a 0 e g u 9 9 t j o j S V 4 s l M E h J y N B A 0 p h g Z K / V c N 4 h 4 F o y R E t I M q R h M e 2 7 V q 3 k z w F X i F 6 Q K C j R 6 7 k / Q l z j l R B j M k N Z d 3 0 t M m C F l K G Z k W g l S T R K E R 2 h A u p Y K x I k O s 9 n n U 3 h m l T 6 M p b I j D J y p f y 8 y x L W e 8 M h u c m S G e t n L x f + 8 b m r i 2 z C j I k k N E X g e F K c M G g n z G m C f K o I N m 1 i C s K L 2 V 4 i H S C F s b F k L K R H P O / G X G 1 g l r Y u a fz + u h 1 C K J 8 L y u E = " &gt; A A A B / n i c b V A 9 S w N B E J 2 L X z F + R S 1 t D o N g F e 7 E r z J g o W U E E w P J E f Y 2 c 8 m S 3 b 1 j d 0 8 I R 8 D f Y K u 1 n d j 6 V y z 9 J 2 6 S K 0 z i g 4 H H e z P M z A s T z r T x v G + n s L K 6 t r 5 R 3 C x t b e / s 7 p X 3 D 5 o 6 T h X F B o 1 5 r F o h 0 c i Z x I Z h h m M r U U h E y P E x H N 5 M / M c n V J r F 8 s G M E g w E 6 U s W M U q M l V q d U G Q 4 7 n r d c s W r e l O 4 y 8 T P S Q V y 1 L v l n 0 4 v p q l A a S g n W r d 9 L z F B R p R h l O O 4 1 E k 1 J o Q O S R / b l k o i U A f Z 9 N 6 x e 2 K V n h v F y p Y 0 7 l T 9 O 5 E R o f V I h L Z T E D P Q i 9 5 E / M 9 r p y a 6 D j I m k 9 S g p L N F U c p d E 7 u T 5 9 0 e U 0 g N H 1 l C q G L 2 V p c O i C L U 2 I j m t o R i b D P x F x N Y J s 2 z q n 9 Z v b g / r 9 R u 8 3 S K c A T H c A o + X E E N 7 q A O D a D A 4 Q V e 4 cP K p 1 + M + 5 f p I e V n u + t R V T g = " &gt; A A A B / n i c b V A 9 S w N B E J 2 L X z F + R S 1 t D o N g F e 7 E r z J g o W U E E w P J E f Y 2 c 8 m S 3 b 1 j d 0 8 I R 8 D f Y K u 1 n d j 6 V y z 9 J 2 6 S K 0 z i g 4 H H e z P M z A s T z r T x v G + n s L K 6 t r 5 R 3 C x t b e / s 7 p X 3 D 5 o 6 T h X F B o 1 5 r F o h 0 c i Z x I Z h h m M r U U h E y P E x H N 5 M / M c n V J r F 8 s G M E g w E 6 U s W M U q M l V q d U G Q 4 7 v r d c s W r e l O 4 y 8 T P S Q V y 1 L v l n 0 4 v p q l A a S g n W r d 9 L z F B R p R h l O O 4 1 E k 1 J o Q O S R / b l k o i U A f Z 9 N 6 x e 2 K V n h v F y p Y 0 7 l T 9 O 5 E R o f V I h L Z T E D P Q i 9 5 E / M 9 r p y a 6 D j I m k 9 S g p L N F U c p d E 7 u T 5 9 0 e U 0 g N H 1 l C q G L 2 V p c O i C L U 2 I j m t o R i b D P x F x N Y J s 2 z q n 9 Z v b g / r 9 R u 8 3 S K c A T H c A o + X E E N 7 q A O D a D A 4 Q V e 4 c</p>
<p>B.2 Cache Length of TSSM-XL</p>
<p>In our main experiments, we have used the cache length m = 128 for TSSM-XL, because it is close to S4WM in terms of computational cost.Here we provide a more thorough investigation with larger cache lengths.</p>
<p>We report results on the non-teleport Four Rooms and Ten Rooms environments in  16 and 17.We find that increasing the cache length generally improves generation quality, at the cost of slower training and imagination speed.Notably, TSSM-XL with m = 512 shows better context-dependent recall than S4WM on the Ten Rooms teleport environment, consistent with the findings in previous work [24,15] that Transformers are better than S4 at performing context-dependent operations.</p>
<p>C Additional Experiment Figures</p>
<p>D Offline Probing on Memory Maze</p>
<p>Pašukonis et al. [50] recently proposed the Memory Maze offline probing benchmark for evaluating the representation learning ability of world models.For completeness, we report the benchmark results in Table 6.Our implementation is based on the newer DreamerV3 [31], and the results of RSSM-TBTT are slightly better than reported in the original Memory Maze paper.</p>
<p>For RSSM-TBTT, TSSM-XL, and S4WM, we use concat[h t , z t ] as the input to the probing network, where h t is the output of the final Transformer/S4 block for TSSM-XL and S4WM.The probing network is an MLP with 4 hidden layers, each consisting of 1024 hidden units and followed by layer normalization [1] and SiLU [53] nonlinearity.Both TSSM-XL and S4WM underperform RSSM-TBTT.We conjecture that this is because in RSSM-TBTT, h t captures more global information, while in TSSM-XL and S4WM, h t captures more local information for each t.</p>
<p>Comparing RSSM-TBTT and S4WM, we find that the S4 hidden state s t plays a similar role as the h t in RSSM-TBTT by carrying over information from previous time steps.Therefore, we conjecture that s t will capture more global information and concat[s t , z t ] can be a more suitable embedding for probing.However, the S4 hidden state s t has a much higher (typically 64×) dimension than h t , making the above solution impractical.</p>
<p>Fortunately, S4WM is a general framework that works with many S4 variants.In particular, S5 [57] uses a hidden state s t that is of similar dimension as h t .Hence, we replace the S4 layers in S4WM with S5 layers, and call this model S5WM.We extract the S5 hidden state of the last S5 layer in each S5 block, and concatenate them with z t to form the input to the probing network.Our results show that this model outperforms RSSM-TBTT by a large margin on the 9×9 maze.Nevertheless, the larger 15×15 maze remains challenging for all models.</p>
<p>E Skill-Level Model-Predictive Control</p>
<p>To show the potential of S4WM for planning, we consider a skill-level Model-Predictive Control (MPC) agent, with predefined skills and an offline-trained world model.Specifically, we consider the Multi Doors Keys environments.The predefined skills are (1) picking up a key at a specific position, and (2) going to a door at a specific position and attempting to unlock it.The agent will return to its starting position at the end of each skill.The task is to unlock a door specified by a goal image, which shows the door in unlocked state (see Figure 20 for an illustration).The agent is allowed to execute two skills: pick up one key and then attempt to unlock one door.Hence, planning has two stages.First, the agent enumerates all allowed skill sequences (of length 2), and uses the world model to predict which skill sequence is most likely to unlock the correct door.Then the agent executes the first skill in the environment and replans.We show the success rate of RSSM-TBTT, TSSM-XL, and S4WM in Table 7.The MPC agent equipped with S4WM is able to unlock every door in all three environments, while RSSM-TBTT and TSSM-XL succeed roughly half of the time.</p>
<p>F Comparison with TECO</p>
<p>We provide a quantitative comparison with TECO [67] and relevant baselines in Table 8.This comparison is done on DMLab following the TECO evaluation protocol.TECO and other baselines use a pretrained VQGAN [13] encoder/decoder, while S4WM uses a jointly trained simple CNN encoder/decoder (see Appendix J and Table 10 for architecture details and hyperparameters).S4WM significantly outperforms Clockwork VAE [55] and Latent FDM [32] (a diffusion-based model), and is close to TECO despite having much fewer parameters.</p>
<p>G Additional Results of Instantiating S4WM with S5</p>
<p>We show a comparison of long-term imagination quality between S4WM and S5WM in Table 9, where S5WM is our instantiation of S4WM with the S5 model.S5WM demonstrates even better imagination quality than S4WM, showing the potential of our general framework for incorporating more advanced parallelizable SSMs.</p>
<p>H Extended Background</p>
<p>In this section, we briefly introduce RSSM and TSSM for completeness.We denote the sequence of observations and actions as (x 0 , a 1 , x 1 , a 2 , x 2 , . . ., a T , x T ).Namely, the agent takes action a t+1 after observing x t , and receives the next observation x t+1 .We omit the reward for simplicity.</p>
<p>where z 0:T are the stochastic latent states.The approximate posterior is defined as:</p>
<p>q(z 0:T | x 0:T , a 1:T ) = T t=0 q(z t | z &lt;t , a ≤t , x t ) .</p>
<p>The conditioning on previous states z &lt;t and actions a ≤t appears multiple times.RSSM uses a shared GRU [7] to compress z &lt;t and a ≤t into a deterministic encoding h t :
h t = GRU(h t−1 , MLP(concat[z t−1 , a t ])) .(15)
This is then used to compute the sufficient statistics of the prior, likelihood, and posterior: p(z t | z &lt;t , a ≤t ) = MLP(h t ) , (16) p(x t | z ≤t , a ≤t ) = N (x t , 1) , xt = Decoder(concat[h t , z t ]) , (17) q(z t | z &lt;t , a ≤t , x t ) = MLP(concat[h t , e t ]) , e t = Encoder(x t ) .</p>
<p>(
)18
The training objective is to maximize the evidence lower bound (ELBO):</p>
<p>log p(x 0:T | a 1:T ) ≥ E q T t=0 log p(x t | z ≤t , a ≤t ) − L KL q(z t | z &lt;t , a ≤t , x t ), p(z t | z &lt;t , a ≤t ) .</p>
<p>H.2 TSSM</p>
<p>Our implementation of TSSM [5] uses the same generative process, approximate posterior, and training objective as S4WM.For convenience, we repeat them below.The generative process is:</p>
<p>where z 0:T are the stochastic latent states.The approximate posterior is defined as:</p>
<p>q(z 0:T | x 0:T , a 1:T ) = T t=0 q(z t | x t ) , where q(z 0 | x 0 ) = p(z 0 | x 0 ) .</p>
<p>The training objective is to maximize the evidence lower bound (ELBO):</p>
<p>log p(x 1:T | x 0 , a 1:T ) ≥ E q T t=1 log p(x t | z ≤t , a ≤t ) − L KL q(z t | x t ), p(z t | z &lt;t , a ≤t ) .</p>
<p>The main difference from S4WM is that in TSSM the prior p(z t | z &lt;t , a ≤t ) is computed by a stack of Transformer [61] blocks.Specifically, the Transformer blocks output an embedding vector h t through self-attention over the history:
h t =</p>
<p>I Speed and Memory Usage Evaluation Details</p>
<p>All results in Figure 3 are obtained on a single NVIDIA RTX A6000 GPU.We make sure that the models have comparable number of parameters.For training, we use a batch size of 8, sequence length of 1000, and image size of 64×64.We report the number of episodes per second processed by each model, averaged over 100 batches, and also the peak memory usage.For imagination, we use a batch size of 64, context length of 500, generation length of 500, and image size of 64×64.We report the number of frames per second, averaged over 8 batches.</p>
<p>J Implementation Details and Hyperparameters</p>
<p>We base our implementation on the publicly available code of S4 [21] and DreamerV3 [31].We provide the hyperparameters used for 3D and 2D environments in Tables 10 and 11 respectively.For 3D environments, we largely follow the hyperparameters used in Memory Maze [50].For 2D environments, we follow the architecture of DreamerV3-S.We use a linear warmup (1000 gradient steps) and cosine anneal learning rate schedule for S4WM. Figure 21 shows the detailed architecture of an S4 block.For TSSM-XL and RSSM-TBTT, we use constant learning rates following the original papers.To ensure a fair comparison, all models use the same CNN encoder and decoder, with convolutional and transposed convolutional layers of kernel size 4 and stride 2, layer normalization [1], and SiLU [53] nonlinearity.The latent states z 0:T are vectors of categorical variables [30] optimized by straight-through gradients [3].To facilitate stable training, we parameterize the categorical distributions as mixtures of 1% uniform and 99% neural network output [31].We use KL balancing [30] to scale the gradient of the KL loss L KL (q, p) with respect to the posterior q and prior p: L KL (q, p) = α•KL[stop_grad(q) ∥ p] + (1 − α)•KL[q ∥ stop_grad(p)] .</p>
<p>(25) Here, stop_grad denotes the stop-gradient operator, and we set α = 0.8 to put more emphasis on learning the prior toward the posterior than the other way around.</p>
<p>K Broader Impact</p>
<p>The proposed S4WM and other world models investigated in this paper are fundamentally deep generative models.Therefore, they inherit the potential negative social impacts that deep generative models may have, such as generating fake images and videos that can contribute to digital misinformation and deception.Caution must be exercised in the application of these models, adhering to ethical guidelines and regulations to mitigate the risks.</p>
<p>t e x i t s h a 1 _ b a s e 6 4 = " 7 b O ME Q s I 3 l 5 h U 0 E U u t Z N F O / g r L s = " &gt; A A A B + 3 i c b V D L S s N A F J 3 U V 6 2 v W J d u g k V w V R L x t S y 4 6 b K C f U A T w m Q 6 a Y d O J m H m R l p C f s W N C 0 X c + i P u / Bs n b R b a e m D g c M 6 9 3 D M n S D h T Y N v f R m V j c 2 t 7 p 7 p b 2 9 s / O D w y j + s 9 F a e S 0 C 6 J e S w H A V a U M 0 G 7 w I D T Q S I p j g J O + 8 H 0 v v D 7 T 1 Q q F o t H m C f U i / B Y s J A R D F r y z b o 7 w Z C 5 E Y Z J E G a z P P c d 3 2 z Y T X s B a 5 0 4 J W m g E h 3</p>
<p>a X e y N M p w h m c w y V 4 c A t 1 a E A T W k C A w w u 8 w p v z 7 L w 7 H 8 7 n o r X g 5 D O n s A T n 6 x e 7 8 Z a F &lt; / l a t e x i t &gt; a2 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " z d k S R 6 7 g 7 7</p>
<p>a X e y N M p w h m c w y V 4 c A t 1 a E A T W k C A w w u 8 w p v z 7 L w 7 H 8 7 n o r X g 5 D O n s A T n 6 x e 7 8 Z a F &lt; / l a t e x i t &gt; a2 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " K a p M a I 96 k R G F G T + S f b x H h G K J 1 a w = " &gt; A A A C C n i c b V D L S s N A F J 3 4 r P U V 6 9 L N Y B F c l a T 4 W h b c d F n B P q A J Z T K d t E N n J m F m I i 0 h f + A 3 u N W 1 O 3 Hr T 7 j 0 T 5 y 0 W d j W A x c O 5 9 z L P Z w g Z l R p x / m 2 N j a 3 t n d 2 S 3 v l / Y P D o 2 P 7 p N J R U S I x a e O I R b I X I E U Y F a S t q W a k F 0 u C e M B I N 5 j c 5 3 7 3</p>
<p>4 c 1 5 d t 6 d D + d z 3 l p w 8 p l j W I D z 9 Q v I n p a N &lt; / l a t e x i t &gt; h3 S4 Blocks (single step)</p>
<p>Figure 2 :Figure 3 :
23
Figure 2: Partially observable 3D (Top) and 2D (Bottom) environments for evaluating memory capabilities of world models, including long-term imagination, context-dependent recall, reward prediction, and memory-based reasoning.</p>
<p>Figure 4 :
4
Figure 4: Long-term imagination in the Four Rooms environment.While RSSM-TBTT and TSSM-XL make many mistakes in wall colors, object colors, and object positions, S4WM is able to generate much more accurately, with only minor errors in object positions.</p>
<p>Figure 5 :Figure 6 :
56
Figure 5: Generation MSE per imagination step.Each environment is labeled with (context steps | query steps).S4WM maintains a relatively good generation quality for up to 500 steps, while RSSM-TBTT and TSSM-XL make large generation errors even within 50 steps.</p>
<p>Figure 7 :
7
Figure 7: Imagination in the Distracting Memory environment of width 100.RSSM-TBTT and TSSM-XL fail to keep track of the agent's position, leading to inaccurate reward prediction within imagination.</p>
<p>1 5 d t 6 d D + d z 1 l p w 8 p l D m I P z 9 Q u + 1 p a G &lt; / l a t e x i t &gt; e 0</p>
<p>1 &lt;
1
1 5 d t 6 d D + d z 1 l p w 8 p l D m I P z 9 Q v A a Z a H &lt; / l a t e x i t &gt; e l a t e x i t s h a 1 _ b a s e 6 4 = " L Q 1 L J j 8 5 S e d D M n / 1 S Y c / M v r T D W g = " &gt; A A A B / n i c b V D L S g N B E O y N r x h f U Y 9 e B o P g K e w G X 8 e A B z 1 G M A 9 I l j A 7 m U 2 G z M w u M 7 N C W B b 8 B q 9 6 9 i Z e / R W P / o m T Z A 8 m s a C h q O q m u y u I O d P G d b + d w t r 6 x u Z W c b u 0 s 7 u 3 f 1 A</p>
<p>n h I u 5 Z K L K j 2 0 9 m 9 G T q z y g C F k b I l D Z q p f y d S L L S e i M B 2 C m x G e t m b i v 9 5 3 c S E d3 7 K Z J w Y K s l 8 U Z h w Z C I 0 f R 4 N m K L E 8 I k l m C h m b 0 V k h B U m x k a 0 s C U Q m c 3 E W 0 5 g l b Q u q t 5 N 9 f r h q l K r 5 + k U 4 Q R O 4 R w 8 u I U a 1 K E B T S D A 4 Q V e4 c 1 5 d t 6 d D + d z 3 l p w 8 p l j W I D z 9 Q v I n p a N &lt; / l a t e x i t &gt; h3 S4 Blocks (single step) &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " r qU K g m M V y / v g n T c 2 + k 3 Z e J Q y 2 r 4 = " &gt; A A A B / n i c b V D L S g N B E O y N r x h f U Y 9 e B o P g K e x K f B w D X n K M Y B 6 Q L G F 2 M p s M m Z l d Z m a F s C z 4 D V 7 1 7 E 2 8 + i s e / R M n y R 5 M Y k F D U d V N d 1 c Q c 6a N 6 3 4 7 h Y 3 N r e 2 d 4 m 5 p b / / g 8 K h 8 f N L W U a I I b Z</p>
<p>x4&lt;</p>
<p>l a t e x i t s h a 1 _ b a s e 6 4 = " I h 6 m e H 1 U m f yj R K W C / 1 T m M + m N H N U = " &gt; A A A B / n i c b V D L S g N B E O y N r x h f U Y 9 e B o P g K e x K f B w D X n K M Y B 6 Q L G F 2 M p s M m Z l d Z m a F s C z 4 D V 7 1 7 E 2 8 + i s e / R M n y R 5 M Y k F D U d V N d 1 c Q c 6a N 6 3 4 7 h Y 3 N r e 2 d 4 m 5 p b / / g 8 K h 8 f N L W U a I I b Z</p>
<p>7 w 5 z 8 6 7 8 + F 8 L l o L T j 5 z C k t w v n 4 B y j G W j g = = &lt; / l a t e x i t &gt; h4 Generation &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " k b B z a Z s h d t 4 f I G h M t t y c K e f r X Q k = " &gt; A A A B / H i c b V D L S g N B E O y N r x h f U Y 9 e B o P g K e y K r 2 P A S 4 4 R z A O S J c z O</p>
<p>2 &lt; 2 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " z 8 7 F
22147
y l 6 i S I z w B I 1 I 3 1 C B O F F + O s u c 2 e d G G d p h J M 0 I b c / U v x c p 4 k p N e W A 2 8 4 x q 2 c v F / 7 x + o s N b P 6 U i T j Q R e P 4 o T J i t I z s v w B 5 S S b Bm U 0 M Q l t R k t f E Y S Y S 1 q W n h S 8 A z 0 4 m 7 3 M A q 6 d R r 7 n X t 6 v 6 y 2 m g W 7 Z T g F M 7 g A l y 4 g Q Y 0 o Q V t w B D D C 7 z C m / V s v V s f 1 u d 8 d c 0 q b k 5 g A d b X L x r s m G k = &lt; / l a t e x i t &gt;z l a t e x i t s h a 1 _ b a s e 6 4 = " H 1 J i G i + A p 3 N a N q q y p e P 8 u QC o U x w = " &gt; A A A C A n i c b V D L S s N A F L 3 x W e u r 6 t J N s A i u S l J 8 L Q t u u q x g H 9 C E M p l O 2 q E z k z A z E W r I z m 9 w q 2 t 3 4 t Y f c e m f O G m z s K 0 H L h z O u Z d 7 O E H M q N K O 8 2 2 t r W 9 s b m 2 X d s q 7 e / s H h 5 W j 4 4 6 K E o l J G 0 c s k r 0 A K c K o I G 1 N N S O 9 W B L E A 0 a 6 w e Q u 9 7 u P R C o a i Q c 9 j Y n P 0 U j Q k G K k j e R 5 H O l x E K Z P 2 a A + q F S d m j O D v U r c g l S h Q G t Q + f G G E U 4 4 E R o z p F T f d W L t p 0 h q i h n J y l 6 i S I z w B I 1 I 3 1 C B O F F + O s u c 2 e d G G d p h J M 0 I b c / U v x c p 4 k p N e W A 2 8 4 x q 2 c v F / 7 x + o s N b P 6 U i T j Q R e P 4 o T J i t I z s v w B 5 S S b B m U 0 M Q l t R k t f E Y S Y S 1 q W n h S 8 A z 0 4 m 7 3 M A q 6 d R r 7 n X t 6 v 6 y 2 m g W 7 Z T g F M 7 g A l y 4 g Q Y 0 o Q V t w B D D C 7 z C m / V s v V s f 1 u d 8 d c 0 q b k 5 g A d b X L x r s m G k = &lt; / l a t e x i t &gt; z V 2 d U c t g x t B R 0 q 0 i e Y z X B 6 o g = " &gt; A A A B 8 3 i c b V D L S g M x F L 3 j s 9 Z X 1 a W b Y B F c l R n f y 4 K b L i v Y B 3 S G k k k z b W g m E 5 K M U I f + h h s X ir j 1 Z 9 z 5 N 2 b a W W j r g c D h n H u 5 J y e U n G n j u t / O y u r a + s Z m a a u 8 v b O 7 t 1 8 5 O G z r J F W E t k j C E 9 U N s a a c C d o y z H D a l Y r i O O S 0 E 4 7 v c r / z S J V m i X g w E 0 m D G A 8 F i x j B x k q + H 2 M z C q P s a d q / 6 F e q b s 2 d A S 0 T r y B V K N D s V 7 7 8 Q U L S m A p D O N a 6 5 7 n S B B</p>
<p>y d 1 X p x 3 5 2 M 3 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " z 8 7 F
123147
+ u u I U O 0 f w B 8 7 n D z W E k d Q = &lt; / l a t e x i t &gt; z V 2 d U c t g x t B R 0 q 0 i e Y z X B 6 o g = " &gt; A A A B 8 3 i c b V D L S g M x F L 3 j s 9 Z X 1 a W b Y B F c l R n f y 4 K b L i v Y B 3 S G k k k z b W g m E 5 K M U I f + h h s X i r j 1 Z 9 z 5 N 2 b a W W j r g c D h n H u 5 J y e U n G n j u t / O y u r a + s Z m a a u 8 v b O 7 t 1 8 5 O G z r J F W E t k j C E 9 U N s a a c C d o y z H D a l Y r i O O S 0 E 4 7 v c r / z S J V m i X g w E 0 m D G A 8 F i x j B x k q + H 2 M z C q P s a d q / 6 Fe q b s 2 d A S 0 T r y B V K N D s V 7 7 8 Q U L S m A p D O N a 6 5 7 n S B B</p>
<p>y d 1 X p x 3 5 2 M 3 &lt;
123
+ u u I U O 0 f w B 8 7 n D z W E k d Q = &lt; / l a t e x i t &gt; z l a t e x i t s h a 1 _ b a s e 6 4 = " n t Y / 2 1 + 5 l I p R + a P t Q m Q 8 K y S f e 3 s = " &gt; A A A B 8 3 i c b V D L S g M x F L 2 p r 1 p f V Z d u g k V w V W b E 1 7 L g p s s K 9 g G d o W T S T B u a y Q x J R q h D f 8 O N C 0 X c+ j P u / B s z 7 S y 0 9 U D g c M 6 9 3 J M T J I J r 4 z j f q L S 2 v r G 5 V d 6 u 7 O z u 7 R 9 U D 4 8 6 O k 4</p>
<p>2 e 8 m S 3 b 1 j d 0 8 I x 4 G / w V Z r O 7 H 1 r 1 j 6 T 9 w k V 5 j E B w O P 9 2 aY m R f E n G n j u t 9 O Y W N z a 3 u n u F v a 2 z 8 4 P C o f n 7 R 1 l C h C W y T i k e o G W F P O J G 0 Z Z j j t x o p i E X D a C S b 3 M 7 / z R J V m k X w 0 0 5 j 6 A o 8 k C x n B x k r d f i B S n A 2 8 Q b n i V t 0 5 0 D r x c l K B H M 1 B + a c / j E g i q D S E Y 6 1 7 n h s b P 8 X K M M J p V u o n m s a Y T P C I 9 i y V W F D t p / N 7 M 3 R h l S E K I 2 V L G j R X / 0 6 k W G g 9 F Y H t F N i M 9 a o 3 E / / z e o k J 7 / y U y T g x V J L F o j D h y E R o 9 j w a M k W J 4 V N L M F H M 3 o r I G C t M j I 1 o a U s g M p u J t 5 r A O m l f V b 2 b a u 3 h u l J v 5 O k U 4 Q z O 4 R I 8 u I U 6 N K A J L S D A 4 Q V e4 c 1 5 d t 6 d D + d z 0 V p w 8 p l T W I L z 9 Q u 6 X p a E &lt; / l a t e x i t &gt; a1 &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " Q x d / u 7 Q W</p>
<p>1 2 7 e r y s 1 u + L d s r g B J y C c + C D G 1 A H D 6 A B m g C D M X g B r + D N e X b e n Q / n c 7 5 a c o q b Y 7 A A 5 + s X S N q a r w = = &lt; / l a t e x i t &gt; ???&lt; l a t e x i t s h a 1 _ b a s e 6 4 = " I 4 I 3 Y l p g b w b 9 j q</p>
<p>1 Figure 8 :
18
Figure 8: Architecture of S4WM-Full-Posterior.It maintains the parallel training ability while computing the posterior from the full history.∅ ∅ ∅ denotes dummy actions.</p>
<p>Figure 9 :
9
Figure 9: Generation MSE per imagination step of alternative S4WM architectures.Each environment is labeled with (context steps | query steps).S4WM-Full-Posterior performs the best as imagination horizon increases.</p>
<p>Figure 10 :
10
Figure 10: Long-term imagination from alternative S4WM architectures in the Four Rooms environment.S4WM and S4WM-Full-Posterior have similar imagination quality in this environment, while S4WM-No-MLP makes more mistakes in wall colors and object positions.</p>
<p>Figure 11 :
11
Figure 11: Comparison of alternative S4WM architectures on context-dependent recall in teleport environments.Each environment is labeled with (context steps | query steps).We provide up to 20 observations after the teleport as additional contexts.S4WM-Full-Posterior performs similarly as S4WM when the context phase is short, and becomes better when the context phase is longer.S4WM-No-MLP performs the worst, suggesting the importance of the MLP in the S4 blocks to context-dependent recall.</p>
<p>Figure 12 :Figure 13 :Figure 16 :
121316
Figure 12: Context-dependent recall from alternative S4WM architectures in the Four Rooms teleport environment.20 observations after the teleport are provided as additional contexts.S4WM and S4WM-Full-Posterior perform similarly in this environment, while S4WM-No-MLP makes more mistakes in wall colors and object positions.</p>
<p>Figure 17 :
17
Figure 17: Context-dependent recall from TSSM-XL with different cache lengths m in the Four Rooms teleport environment.20 observations after the teleport are provided as additional contexts.TSSM-XL (m = 256) and TSSM-XL (m = 512) perform similarly in this environment, and are both better than TSSM-XL (m = 128).</p>
<p>Figure 18 :
18
Figure 18: Context-dependent recall in the teleport environments.20 observations after the teleport are provided as additional contexts.TSSM-XL and S4WM perform similarly in the Two Rooms environment, while only S4WM is able to maintain good recall quality in the Four Rooms environment.</p>
<p>Figure 19 :
19
Figure 19: Imagination in the Multi Doors Keys environment with seven keys.</p>
<p>Figure 20 :
20
Figure 20: Illustration of the task solved by the skill-level MPC agent.The task is to unlock the door specified by the goal image on the left.The agent is allowed to execute two skills: pick up one key and then attempt to unlock one door.We use MPC to plan the optimal skill sequence with the offline-trained world model.</p>
<p>H. 1 RSSM
1
RSSM[28] models the observations and state transitions through the following generative process:p(x 0:T | a 1:T ) = T t=0 p(x t | z ≤t , a ≤t ) p(z t | z &lt;t , a ≤t ) dz 0:T ,</p>
<p>p(x 1 :
1
T | x 0 , a 1:T ) = p(z 0 | x 0 ) T t=1 p(x t | z ≤t , a ≤t ) p(z t | z &lt;t , a ≤t ) dz 0:T ,</p>
<p>Figure 21 :
21
Figure 21: Detailed architecture of an S4 block.</p>
<p>Table 1 :
1
Evaluation of long-term imagination.Each environment is labeled with (context steps | query steps).All models obtain good reconstruction, while S4WM is much better at long-term generation up to 500 steps.All models struggle in the Ten Rooms environment.
Recon.Gen.Recon.Gen.Recon.Gen.MSE (↓)MSE (↓)MSE (↓)MSE (↓)MSE (↓)MSE (↓)RSSM-TBTT1.762.21.5219.41.5323.1TSSM-XL2.562.92.4224.42.6360.4S4WM1.827.31.744.01.8224.4
Two Rooms (301 | 200) Four Rooms (501 | 500) Ten Rooms (1101 | 900)</p>
<p>Table 2 :
2
Reward prediction accuracy in the Distracting Memory environments.Each environment is labeled with (context steps | query steps).S4WM succeeds in all environments.TSSM-XL has limited success when observing the full sequence, but fails to predict rewards within imagination.RSSM-TBTT completely fails.
InferenceImaginationInferenceImaginationInferenceImaginationAccuracy (↑)Accuracy (↑)Accuracy (↑)Accuracy (↑)Accuracy (↑)Accuracy (↑)RSSM-TBTT47.9%49.6%48.7%48.4%50.4%52.2%TSSM-XL100.0%51.2%99.9%51.3%50.4%51.0%S4WM100.0%100.0%100.0%100.0%100.0%100.0%
Width = 100 (199 | 51) Width = 200 (399 | 101) Width = 400 (799 | 201)</p>
<p>Table 3 :
3
Memory-based reasoning in the Multi Doors Keys environments.Each environment is labeled with (context steps | query steps).S4WM performs well on all environments, while others struggle.Three Keys (76 | 174) Five Keys (170 | 380) Seven Keys (296 | 654)
Recon.Gen.Recon.Gen.Recon.Gen.MSE (↓)MSE (↓)MSE (↓)MSE (↓)MSE (↓)MSE (↓)RSSM-TBTT0.055.160.046.360.036.28TSSM-XL0.051.270.036.050.029.24S4WM0.010.040.020.270.020.10</p>
<p>Table 4 :
4
Comparison of alternative S4WM architectures on long-term imagination.Each environment is labeled with (context steps | query steps).S4WM-Full-Posterior is comparable to S4WM on the Four Rooms environment, but is better on the more challenging Ten Rooms environment.In contrast, S4WM-No-MLP performs much worse, suggesting the importance of the MLP in the S4 blocks to long-term imagination.
Four Rooms (501 | 500) Ten Rooms (1101 | 900) Recon. Gen. Recon. Gen.MSE (↓)MSE (↓)MSE (↓)MSE (↓)S4WM1.744.01.8224.4S4WM-Full-Posterior1.738.02.0171.1S4WM-No-MLP2.368.62.5277.0</p>
<p>Table 5 and
5
Figures 14 and 15.Results on teleport environments are reported in Figures</p>
<p>Table 6 :
6
Memory Maze offline probing benchmark results.
Memory 9×9Memory 15×15Memory 9×9Memory 15×15Constant BaselineWalls (Acc. ↑) 80.8%Walls (Acc. ↑) 78.3%Objects (MSE ↓) 23.9Objects (MSE ↓) 64.8RSSM-TBTT95.0%81.7%5.432.6TSSM-XL86.4%79.8%10.235.1S4WM88.4%80.2%8.934.8S5WM98.3%81.8%1.825.3</p>
<p>Table 7 :
7
Success rate of skill-level MPC agents in the Multi Doors Keys environments.
Three Keys Five Keys Seven KeysRSSM-TBTT0%60%42.86%TSSM-XL100%40%57.14%S4WM100%100%100%</p>
<p>Table 8 :
8
Comparison of generation quality on DMLab following TECO evaluation protocol.
DMLabPSNR (↑) SSIM (↑) LPIPS (↓) #ParamsCW-VAE [55]12.60.3720.465111MLatent FDM [32]17.80.5880.22231MS4WM20.60.6670.19641MTECO [67]21.90.7030.157169M</p>
<p>Table 9 :
9
Evaluation of long-term imagination.Each environment is labeled with (context steps | query steps).Two Rooms (301 | 200) Four Rooms (501 | 500) Ten Rooms (1101 | 900)
Recon.Gen.Recon.Gen.Recon.Gen.MSE (↓)MSE (↓)MSE (↓)MSE (↓)MSE (↓)MSE (↓)S4WM1.827.31.744.01.8224.4S5WM1.510.61.319.21.3159.2</p>
<p>TransformerBlocks(g 1:t ) , g t = MLP(concat[z t−1 , a t ]) .(23)Theht is then used for predicting the next latent state z t and decoding the latent state into image xt :p(z t | z &lt;t , a ≤t ) = MLP(h t ) , xt = Decoder(concat[h t , z t ]) .</p>
<p>Acknowledgments and Disclosure of FundingThis work is supported by Brain Pool Plus Program (No. 2021H1D3A2A03103645) through the National Research Foundation of Korea (NRF) funded by the Ministry of Science and ICT.We thank Jurgis Pašukonis, Danijar Hafner, Chang Chen, Jaesik Yoon, and Caglar Gulcehre for insightful discussions.
. Jimmy Ba, Jamie Ryan Kiros, Geoffrey Hinton, arXiv:1607.064502016Layer normalization. arXiv preprint</p>
<p>. Charles Beattie, Joel Z Leibo, Denis Teplyashin, Tom Ward, Marcus Wainwright, Heinrich Küttler, Andrew Lefrancq, Simon Green, Víctor Valdés, Amir Sadik, arXiv:1612.038012016arXiv preprint</p>
<p>Estimating or propagating gradients through stochastic neurons for conditional computation. Yoshua Bengio, Nicholas Léonard, Aaron Courville, arXiv:1308.34322013arXiv preprint</p>
<p>Prefix sums and their applications. Guy Blelloch, 1990School of Computer Science, Carnegie Mellon UniversityTechnical report</p>
<p>TransDreamer: Reinforcement learning with Transformer world models. Chang Chen, Yi-Fu Wu, Jaesik Yoon, Sungjin Ahn, Deep RL Workshop NeurIPS 2021. 2021</p>
<p>Minimalistic gridworld environment for Gymnasium. Maxime Chevalier-Boisvert, Lucas Willems, Suman Pal, 2018</p>
<p>Empirical evaluation of gated recurrent neural networks on sequence modeling. Junyoung Chung, Caglar Gulcehre, Kyunghyun Cho, Yoshua Bengio, arXiv:1412.35552014arXiv preprint</p>
<p>Leveraging procedural generation to benchmark reinforcement learning. Karl Cobbe, Chris Hesse, Jacob Hilton, John Schulman, International Conference on Machine Learning. 2020</p>
<p>Transformer-XL: Attentive language models beyond a fixed-length context. Zihang Dai, Zhilin Yang, Yiming Yang, Jaime Carbonell, Quoc Le, Ruslan Salakhutdinov, Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics. the 57th Annual Meeting of the Association for Computational Linguistics2019</p>
<p>Decision S4: Efficient sequence-based RL via state spaces layers. Bar Shmuel, Itamar David, Eliya Zimerman, Lior Nachmani, Wolf, International Conference on Learning Representations. 2023</p>
<p>DreamerPro: Reconstruction-free model-based reinforcement learning with prototypical representations. Fei Deng, Ingook Jang, Sungjin Ahn, International Conference on Machine Learning. 2022</p>
<p>An image is worth 16x16 words: Transformers for image recognition at scale. Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, Jakob Uszkoreit, Neil Houlsby, International Conference on Learning Representations. 2021</p>
<p>Taming Transformers for high-resolution image synthesis. Patrick Esser, Robin Rombach, Bjorn Ommer, CVPR. 2021</p>
<p>Generalization of reinforcement learners with working and episodic memory. Meire Fortunato, Melissa Tan, Ryan Faulkner, Steven Hansen, Adrià Puigdomènech Badia, Gavin Buttimore, Charles Deck, Joel Z Leibo, Charles Blundell, Advances in Neural Information Processing Systems. 2019</p>
<p>Hungry Hungry Hippos: Towards language modeling with state space models. Tri Daniel Y Fu, Khaled Dao, Armin W Kamal Saab, Atri Thomas, Christopher Rudra, Ré, International Conference on Learning Representations. 2023</p>
<p>Learning task informed abstractions. Xiang Fu, Ge Yang, Pulkit Agrawal, Tommi Jaakkola, International Conference on Machine Learning. 2021</p>
<p>It's raw! Audio generation with state-space models. Karan Goel, Albert Gu, Chris Donahue, Christopher Ré, International Conference on Machine Learning. 2022</p>
<p>HiPPO: Recurrent memory with optimal polynomial projections. Albert Gu, Tri Dao, Stefano Ermon, Atri Rudra, Christopher Ré, Advances in Neural Information Processing Systems. 2020</p>
<p>Combining recurrent, convolutional, and continuous-time models with linear state space layers. Albert Gu, Isys Johnson, Karan Goel, Khaled Kamal Saab, Tri Dao, Atri Rudra, Christopher Ré, Advances in Neural Information Processing Systems. 2021</p>
<p>On the parameterization and initialization of diagonal state space models. Albert Gu, Karan Goel, Ankit Gupta, Christopher Ré, Advances in Neural Information Processing Systems. 2022</p>
<p>Efficiently modeling long sequences with structured state spaces. Albert Gu, Karan Goel, Christopher Ré, International Conference on Learning Representations. 2022</p>
<p>How to train your HiPPO: State space models with generalized orthogonal basis projections. Albert Gu, Isys Johnson, Aman Timalsina, Atri Rudra, Christopher Ré, International Conference on Learning Representations. 2023</p>
<p>Diagonal state spaces are as effective as structured state spaces. Ankit Gupta, Albert Gu, Jonathan Berant, Advances in Neural Information Processing Systems. 2022</p>
<p>Simplifying and understanding state space models with diagonal linear RNNs. Ankit Gupta, Harsh Mehta, Jonathan Berant, arXiv:2212.007682022arXiv preprint</p>
<p>Recurrent world models facilitate policy evolution. David Ha, Jürgen Schmidhuber, Advances in Neural Information Processing Systems. 2018</p>
<p>Dream to generalize: Zero-shot model-based reinforcement learning for unseen visual distractions. Jeongsoo Ha, Kyungsoo Kim, Yusung Kim, AAAI. 2023</p>
<p>Benchmarking the spectrum of agent capabilities. Danijar Hafner, International Conference on Learning Representations. 2022</p>
<p>Learning latent dynamics for planning from pixels. Danijar Hafner, Timothy Lillicrap, Ian Fischer, Ruben Villegas, David Ha, Honglak Lee, James Davidson, International Conference on Machine Learning. 2019</p>
<p>Dream to control: Learning behaviors by latent imagination. Danijar Hafner, Timothy Lillicrap, Jimmy Ba, Mohammad Norouzi, International Conference on Learning Representations. 2020</p>
<p>Mastering Atari with discrete world models. Danijar Hafner, Timothy Lillicrap, Mohammad Norouzi, Jimmy Ba, International Conference on Learning Representations. 2021</p>
<p>Mastering diverse domains through world models. Danijar Hafner, Jurgis Pasukonis, Jimmy Ba, Timothy Lillicrap, arXiv:2301.041042023arXiv preprint</p>
<p>Flexible diffusion modeling of long videos. William Harvey, Saeid Naderiparizi, Vaden Masrani, Christian Weilbach, Frank Wood, Advances in Neural Information Processing Systems. 2022</p>
<p>Long short-term memory. Sepp Hochreiter, Jürgen Schmidhuber, Neural computation. 981997</p>
<p>Long movie clip classification with state-space video models. Mohaiminul Md, Gedas Islam, Bertasius, ECCV. 2022</p>
<p>Learning robust dynamics through variational sparse gating. Arnav Kumar Jain, Shivakanth Sujit, Shruti Joshi, Vincent Michalski, Danijar Hafner, Samira Ebrahimi Kahou, Advances in Neural Information Processing Systems. 2022</p>
<p>David W David M Knigge, Albert Romero, Efstratios Gu, Erik J Gavves, Jakub Bekkers, Mark Mikolaj Tomczak, Jan-Jakob Hoogendoorn, Sonke, Modelling long range dependencies in N D: From task-specific to a general purpose CNN. 2023International Conference on Learning Representations</p>
<p>Towards mental time travel: a hierarchical memory for reinforcement learning agents. Andrew Kyle Lampinen, Stephanie C Y Chan, Andrea Banino, Felix Hill, Advances in Neural Information Processing Systems. 2021</p>
<p>Structured state space models for in-context reinforcement learning. Chris Lu, Yannick Schroecker, Albert Gu, Emilio Parisotto, Jakob Foerster, Satinder Singh, Feryal Behbahani, arXiv:2303.039822023arXiv preprint</p>
<p>Planning in the brain. G Marcelo, Máté Mattar, Lengyel, Neuron. 11062022</p>
<p>Long range language modeling via gated state spaces. Harsh Mehta, Ankit Gupta, Ashok Cutkosky, Behnam Neyshabur, International Conference on Learning Representations. 2023</p>
<p>Transformers are sample-efficient world models. Vincent Micheli, Eloi Alonso, François Fleuret, International Conference on Learning Representations. 2023</p>
<p>Model-based reinforcement learning: A survey. Joost Thomas M Moerland, Aske Broekens, Catholijn M Plaat, Jonker, Foundations and Trends® in Machine Learning. 202316</p>
<p>S4ND: Modeling images and videos as multidimensional signals with state spaces. Eric Nguyen, Karan Goel, Albert Gu, Gordon Downs, Preey Shah, Tri Dao, Stephen Baccus, Christopher Ré, Advances in Neural Information Processing Systems. 2022</p>
<p>Temporal predictive coding for model-based planning in latent space. Rui Tung D Nguyen, Tuan Shu, Hung Pham, Stefano Bui, Ermon, International Conference on Machine Learning. 2021</p>
<p>Dreaming: Model-based reinforcement learning by latent imagination without reconstruction. Masashi Okada, Tadahiro Taniguchi, ICRA. 2021</p>
<p>DreamingV2: Reinforcement learning with discrete world models without reconstruction. Masashi Okada, Tadahiro Taniguchi, IROS. 2022</p>
<p>Resurrecting recurrent neural networks for long sequences. Antonio Orvieto, L Samuel, Albert Smith, Anushan Gu, Caglar Fernando, Razvan Gulcehre, Soham Pascanu, De, International Conference on Machine Learning. 2023</p>
<p>Stabilizing Transformers for reinforcement learning. Emilio Parisotto, Francis Song, Jack Rae, Razvan Pascanu, Caglar Gulcehre, Siddhant Jayakumar, Max Jaderberg, Raphaël Lopez Kaufman, Aidan Clark, Seb Noury, Matthew Botvinick, Nicolas Heess, Raia Hadsell, International Conference on Machine Learning. 2020</p>
<p>On the difficulty of training recurrent neural networks. Razvan Pascanu, Tomas Mikolov, Yoshua Bengio, International Conference on Machine Learning. 2013</p>
<p>Evaluating long-term memory in 3D mazes. Jurgis Pašukonis, Timothy Lillicrap, Danijar Hafner, International Conference on Learning Representations. 2023</p>
<p>The human imagination: the cognitive neuroscience of visual mental imagery. Joel Pearson, Nature Reviews Neuroscience. 20102019</p>
<p>Memory Gym: Partially observable challenges to memory-based agents. Marco Pleines, Matthias Pallasch, Frank Zimmer, Mike Preuss, International Conference on Learning Representations. 2023</p>
<p>Prajit Ramachandran, Barret Zoph, Quoc V Le, arXiv:1710.05941Searching for activation functions. 2017arXiv preprint</p>
<p>Transformer-based world models are happy with 100k interactions. Jan Robine, Marc Höftmann, Tobias Uelwer, Stefan Harmeling, International Conference on Learning Representations. 2023</p>
<p>Clockwork variational autoencoders. Vaibhav Saxena, Jimmy Ba, Danijar Hafner, Advances in Neural Information Processing Systems. 2021</p>
<p>Masked world models for visual control. Younggyo Seo, Danijar Hafner, Hao Liu, Fangchen Liu, Stephen James, Kimin Lee, Pieter Abbeel, CoRL2023</p>
<p>Simplified state space layers for sequence modeling. T H Jimmy, Andrew Smith, Scott Warrington, Linderman, International Conference on Learning Representations. 2023</p>
<p>Mental time travel and the shaping of the human mind. Thomas Suddendorf, Donna Rose Addis, Michael C Corballis, Philosophical Transactions of the Royal Society B: Biological Sciences. 3641521. 2009</p>
<p>Long Range Arena: A benchmark for efficient Transformers. Yi Tay, Mostafa Dehghani, Samira Abnar, Yikang Shen, Dara Bahri, Philip Pham, Jinfeng Rao, Liu Yang, Sebastian Ruder, Donald Metzler, International Conference on Learning Representations. 2021</p>
<p>Memory and consciousness. Endel Tulving, Canadian Psychology/Psychologie canadienne. 26111985</p>
<p>Attention is all you need. Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Ł Kaiser, Illia Polosukhin, Advances in Neural Information Processing Systems. 2017</p>
<p>Selective structured state-spaces for long-form video understanding. Jue Wang, Wentao Zhu, Pichao Wang, Xiang Yu, Linda Liu, Mohamed Omar, Raffay Hamid, CVPR. 2023</p>
<p>Prototypical context-aware dynamics generalization for highdimensional model-based reinforcement learning. Junjie Wang, Yao Mu, Dong Li, Qichao Zhang, Dongbin Zhao, Yuzheng Zhuang, Ping Luo, Bin Wang, Jianye Hao, arXiv:2211.127742022arXiv preprint</p>
<p>Pre-training contextualized world models with in-the-wild videos for reinforcement learning. Jialong Wu, Haoyu Ma, Chaoyi Deng, Mingsheng Long, arXiv:2305.184992023arXiv preprint</p>
<p>Day-Dreamer: World models for physical robot learning. Philipp Wu, Alejandro Escontrela, Danijar Hafner, Pieter Abbeel, Ken Goldberg, CoRL2023</p>
<p>ViZDoom competitions: Playing Doom from pixels. Marek Wydmuch, Michał Kempka, Wojciech Jaśkowski, IEEE Transactions on Games. 1132018</p>
<p>Temporally consistent Transformers for video generation. Wilson Yan, Danijar Hafner, Stephen James, Pieter Abbeel, International Conference on Machine Learning. 2023</p>
<p>Reward informed dreamer for task generalization in reinforcement learning. Chengyang Ying, Zhongkai Hao, Xinning Zhou, Hang Su, Songming Liu, Jialian Li, Dong Yan, Jun Zhu, arXiv:2303.050922023arXiv preprint</p>
<p>Deep latent state space models for time-series generation. Linqi Zhou, Michael Poli, Winnie Xu, Stefano Massaroli, Stefano Ermon, International Conference on Machine Learning. 2023</p>
<p>Efficient long sequence modeling via state space augmented Transformer. Simiao Zuo, Xiaodong Liu, Jian Jiao, Denis Charles, Eren Manavoglu, Tuo Zhao, Jianfeng Gao, arXiv:2212.081362022arXiv preprint</p>            </div>
        </div>

    </div>
</body>
</html>