<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-3224 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-3224</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-3224</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-74.html">extraction-schema-74</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve tasks, including details of the agent, the memory mechanism, the tasks, and performance comparisons.</div>
                <p><strong>Paper ID:</strong> paper-d56c1e49fcc6a8effe90786af5c7d1f0a295a7a6</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/d56c1e49fcc6a8effe90786af5c7d1f0a295a7a6" target="_blank">Recursively Summarizing Enables Long-Term Dialogue Memory in Large Language Models</a></p>
                <p><strong>Paper Venue:</strong> Neurocomputing</p>
                <p><strong>Paper TL;DR:</strong> This work proposes to recursively generate summaries/ memory using large language models (LLMs) to enhance long-term memory ability and is a potential solution to enable the LLM to model the extremely long context.</p>
                <p><strong>Paper Abstract:</strong> Recently, large language models (LLMs), such as GPT-4, stand out remarkable conversational abilities, enabling them to engage in dynamic and contextually relevant dialogues across a wide range of topics. However, given a long conversation, these chatbots fail to recall past information and tend to generate inconsistent responses. To address this, we propose to recursively generate summaries/ memory using large language models (LLMs) to enhance long-term memory ability. Specifically, our method first stimulates LLMs to memorize small dialogue contexts and then recursively produce new memory using previous memory and following contexts. Finally, the chatbot can easily generate a highly consistent response with the help of the latest memory. We evaluate our method on both open and closed LLMs, and the experiments on the widely-used public dataset show that our method can generate more consistent responses in a long-context conversation. Also, we show that our strategy could nicely complement both long-context (e.g., 8K and 16K) and retrieval-enhanced LLMs, bringing further long-term dialogue performance. Notably, our method is a potential solution to enable the LLM to model the extremely long context. The code and scripts are released.</p>
                <p><strong>Cost:</strong> 0.017</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e3224.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e3224.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve tasks, including details of the agent, the memory mechanism, the tasks, and performance comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LLM-Rsum</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Recursive Summarization (LLM-Rsum)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A plugin method that prompts an LLM to iteratively generate and update a short natural-language memory (summaries) per session by combining prior memory and new session context, then conditions responses on the latest memory to improve long-term dialogue consistency.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>LLM-Rsum</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>A prompting-based agent that performs two LLM tasks: (1) memory iteration: generate/update session summaries M_i = LLM(S_i, M_{i-1}, P_m) recursively; (2) memory-based response generation: produce responses r_t = LLM(C_t, M_N, P_r). Memory and response generation are done via designed step-by-step prompts; the same or different generative LLMs can be used for the two stages.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_used</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>memory-based (recursive natural-language summaries / episodic summaries)</td>
                        </tr>
                        <tr>
                            <td><strong>memory_mechanism_description</strong></td>
                            <td>Memory is stored as a short set of natural-language sentences (up to ~20 sentences per prompt). After each session the LLM is prompted with the previous memory and the session context to produce an updated memory (recursive summarization / Markov-style update). The latest memory M_N is prepended (via a response-generation prompt P_r) to the current context when generating responses.</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Multi-Session Chat (MSC) and Carecall (session 5 evaluation)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Long-term multi-session open-domain dialogue where the agent must remember/maintain persona and prior interactions across multiple sessions and produce context-relevant, consistent responses.</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>dialogue (long-term / multi-session)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td>MSC (session 5, ChatGPT backbone): F1=20.48; BLEU-1/2=21.83/12.59; BertScore=86.89; Human Engagingness=1.85, Coherence=1.60, Consistency=1.45. Carecall (session 5, ChatGPT backbone): F1=14.02; BLEU-1/2=21.64/12.48; BertScore=86.05; Human Engagingness=1.62, Coherence=1.60, Consistency=1.70. GPT-4 single-model scores (MSC session 5): Engagingness=78.92, Coherence=83.56, Consistency=84.76, Average=82.41.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td>Context-only ChatGPT (MSC session 5): F1=19.41; BLEU-1/2=21.23/12.24; BertScore=86.13; Human Engagingness=1.83, Coherence=1.37, Consistency=1.32. GPT-4 (MSC session 5): Engagingness=75.48, Coherence=75.00, Consistency=75.48, Average=75.32.</td>
                        </tr>
                        <tr>
                            <td><strong>has_performance_comparison</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Recursive summarization memory (LLM-Rsum) yields improved long-term dialogue quality and consistency vs. context-only and several memory/retrieval baselines: small but consistent automatic-metric gains (e.g., +0.2% F1 over ChatGPT-MemoryBank on MSC) and larger gains in human and GPT-4 judgments (GPT-4 average 82.41 vs MemoryBank 80.05). Pairwise evaluation vs MemoryBank: Rsum wins 48.2% vs loses 11.9% (net +36.3%). The method complements long-context windows and retrieval-enhanced LLMs.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Reported gains on automatic metrics are modest (e.g., ~+0.2% F1); effectiveness depends on prompt design and in-context examples (can be improved by 2â€“3 dialog illustrations); memory is constrained to concise natural-language summaries (prompt enforces <=20 sentences), which may omit fine-grained details; evaluation notes some misalignment between human and LLM judges.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Recursively Summarizing Enables Long-Term Dialogue Memory in Large Language Models', 'publication_date_yy_mm': '2023-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3224.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e3224.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve tasks, including details of the agent, the memory mechanism, the tasks, and performance comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ChatGPT-MemoryBank</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>MemoryBank (as used with ChatGPT)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A memory-based long-term dialogue mechanism that creates ordered per-session summaries (with timestamps), reorganizes and compresses them into a global memory, and applies a forgetting mechanism inspired by Ebbinghaus's curve.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>ChatGPT-MemoryBank</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>ChatGPT (gpt-3.5-turbo-0301) augmented with MemoryBank: session-level summaries are produced and stored with timestamps, reorganized/compacted to form a global memory which is then used when generating responses.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_used</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>memory-based (session summaries / global compressed memory)</td>
                        </tr>
                        <tr>
                            <td><strong>memory_mechanism_description</strong></td>
                            <td>MemoryBank generates ordered session summaries and compresses them into a global memory; it additionally models forgetting (Ebbinghaus curve) to decay older memory, and retrieved/organized memory is supplied to the response generator.</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Multi-Session Chat (MSC) and Carecall (session 5 evaluation)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Long-term multi-session open-domain dialogue evaluation focusing on maintaining consistency across sessions.</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>dialogue (long-term / multi-session)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td>MSC (session 5, ChatGPT-MemoryBank): F1=20.28; BLEU-1/2=21.82/12.58; BertScore=86.12; Human Engagingness=1.78, Coherence=1.57, Consistency=1.40. Carecall: F1=13.15; BLEU-1/2=21.29/12.39; BertScore=85.34; Human Engagingness=1.57, Coherence=1.52, Consistency=1.68. GPT-4 (MSC session 5): Engagingness=74.68, Coherence=80.92, Consistency=84.56, Average=80.05.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td>Context-only ChatGPT (see ChatGPT entry): MSC session 5 F1=19.41; BLEU-1/2=21.23/12.24; GPT-4 average=75.32.</td>
                        </tr>
                        <tr>
                            <td><strong>has_performance_comparison</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>MemoryBank provides stronger coherence and consistency than context-only ChatGPT in human evaluations and GPT-4 judgments; however, because MemoryBank's memory is fixed once stored it can become outdated relative to ongoing dialog updates.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Memory is fixed once stored and may become outdated; management relies on a forgetting/decay mechanism that may drop relevant information; lacks iterative update integrating prior memory and new session content at generation time (compared unfavorably to recursive update).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Recursively Summarizing Enables Long-Term Dialogue Memory in Large Language Models', 'publication_date_yy_mm': '2023-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3224.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e3224.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve tasks, including details of the agent, the memory mechanism, the tasks, and performance comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ChatGPT-MemoChat</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>MemoChat (as used with ChatGPT)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A memory-based approach that organizes structured conversational memory by topic and prompts the LLM to retrieve from this structured memory during response generation.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>ChatGPT-MemoChat</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>ChatGPT augmented with MemoChat: per-topic structured memory entries are generated and used as retrievalable memory to assist response generation.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_used</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>memory-based (structured, topic-level memory)</td>
                        </tr>
                        <tr>
                            <td><strong>memory_mechanism_description</strong></td>
                            <td>MemoChat produces topic-organized memory entries summarizing past dialogues for distinct conversation topics; these structured memories are then used as context to guide the LLM's response generation.</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Multi-Session Chat (MSC) and Carecall (session 5 evaluation)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Long-term dialogue requiring tracking topical persona and history across sessions.</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>dialogue (long-term / multi-session)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td>MSC (session 5, ChatGPT-MemoChat): F1=18.93; BLEU-1/2=21.82/12.59; BertScore=85.99; Human Engagingness=1.70, Coherence=1.55, Consistency=1.35. Carecall: F1=11.19; BLEU-1/2=21.07/12.18; BertScore=85.22; Human Engagingness=1.45, Coherence=1.20, Consistency=1.30. GPT-4 (MSC session 5): Engagingness=72.32, Coherence=77.36, Consistency=78.96, Average=76.21.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td>Context-only ChatGPT (MSC session 5): F1=19.41; BLEU-1/2=21.23/12.24; GPT-4 average=75.32.</td>
                        </tr>
                        <tr>
                            <td><strong>has_performance_comparison</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>MemoChat's structured per-topic memory can provide benefits, but in these experiments it underperformed MemoryBank and LLM-Rsum on several metrics; structured memory alone may be less effective than iterative updating of memory.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Structured topic memory may be less flexible and less helpful when topics or persona info change rapidly; in experiments it produced lower F1 and human-engagement scores than other memory approaches.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Recursively Summarizing Enables Long-Term Dialogue Memory in Large Language Models', 'publication_date_yy_mm': '2023-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3224.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e3224.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve tasks, including details of the agent, the memory mechanism, the tasks, and performance comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ChatGPT-BM25</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>ChatGPT with BM25 retrieval (ChatGPT-BM25)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A retrieval-augmented variant that uses BM25 to retrieve top-k past utterances and prepends them to ChatGPT's input to support long-term dialogue generation.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>ChatGPT-BM25</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>ChatGPT (gpt-3.5-turbo-0301) combined with BM25 retriever: previous utterances are indexed and the top-k (k=3 or 5) most relevant are retrieved and included in the prompt as context for response generation.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_used</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>retrieval-augmented (retrieved past utterances using BM25)</td>
                        </tr>
                        <tr>
                            <td><strong>memory_mechanism_description</strong></td>
                            <td>Past conversational utterances stored in a document store are queried using BM25; top-k retrieved passages are concatenated with current context and fed to the LLM to generate responses.</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Multi-Session Chat (MSC) and Carecall (session 5 evaluation)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Long-term dialogue where relevant historical utterances must be retrieved to inform current responses.</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>dialogue (long-term / multi-session)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td>ChatGPT-BM25 (k=3) MSC session 5: F1=19.56; BLEU-1/2=21.60/12.46; BertScore=85.82; Human Engagingness=1.72, Coherence=1.48, Consistency=1.32. Carecall: F1=12.64; BLEU-1/2=21.57/12.44; BertScore=85.24; Human Engagingness=1.40, Coherence=1.31, Consistency=1.31.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td>Context-only ChatGPT: MSC F1=19.41; Carecall F1=13.69 (see ChatGPT entry).</td>
                        </tr>
                        <tr>
                            <td><strong>has_performance_comparison</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Retrieval via BM25 can be helpful in some settings but may hurt performance when retrieved context is irrelevant; in Carecall retrieval-based variants underperformed vanilla ChatGPT because retrieval returned unrelated information for that dataset's conversational style.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Effectiveness depends on retriever quality and dataset characteristics; BM25 may retrieve irrelevant utterances for certain dialog types leading to degraded generation quality.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Recursively Summarizing Enables Long-Term Dialogue Memory in Large Language Models', 'publication_date_yy_mm': '2023-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3224.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e3224.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve tasks, including details of the agent, the memory mechanism, the tasks, and performance comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ChatGPT-DPR</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>ChatGPT with DPR retrieval (ChatGPT-DPR)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A retrieval-augmented variant that uses a dense passage retriever (DPR) to fetch top-k relevant past utterances and supply them to ChatGPT for response generation.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>ChatGPT-DPR</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>ChatGPT combined with a pre-trained Dense Passage Retriever (DPR): past utterances are embedded and DPR retrieves top-k semantically relevant passages to prepend to the LLM input.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_used</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>retrieval-augmented (dense retrieval / DPR)</td>
                        </tr>
                        <tr>
                            <td><strong>memory_mechanism_description</strong></td>
                            <td>A DPR model is used to encode conversation segments; given the current context DPR returns top-k semantically-most-similar past utterances which are included in the prompt for the LLM to condition on.</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Multi-Session Chat (MSC) and Carecall (session 5 evaluation)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Long-term dialogue requiring retrieval of semantically relevant historical utterances.</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>dialogue (long-term / multi-session)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td>ChatGPT-DPR (k=3) MSC session 5: F1=20.23; BLEU-1/2=21.75/12.55; BertScore=86.04; Human Engagingness=1.76, Coherence=1.51, Consistency=1.34. Carecall: F1=12.21; BLEU-1/2=21.39/12.35; BertScore=85.25; Human Engagingness=1.55, Coherence=1.35, Consistency=1.45.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td>Context-only ChatGPT: MSC F1=19.41; Carecall F1=13.69.</td>
                        </tr>
                        <tr>
                            <td><strong>has_performance_comparison</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Dense retrieval (DPR) can slightly improve some automatic metrics versus BM25 or context-only in MSC, but in Carecall retrieval variants still underperformed vanilla ChatGPT due to difficulty retrieving relevant guidance for that task.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Quality of retrieval is critical; DPR requires good embeddings/retriever training and may still return irrelevant passages for some dialog types, hurting generation.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Recursively Summarizing Enables Long-Term Dialogue Memory in Large Language Models', 'publication_date_yy_mm': '2023-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3224.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e3224.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve tasks, including details of the agent, the memory mechanism, the tasks, and performance comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ChatGPT (context-only)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>ChatGPT (gpt-3.5-turbo-0301) context-only baseline</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Vanilla ChatGPT used as a context-only dialogue agent that concatenates past sessions and current context without an explicit external memory mechanism beyond the input context window.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>ChatGPT (context-only)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>ChatGPT (gpt-3.5-turbo-0301) provided with concatenated dialog history (past sessions and current context) as input and asked to generate a response; no external memory module or retriever is used.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_used</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>context window only</td>
                        </tr>
                        <tr>
                            <td><strong>memory_mechanism_description</strong></td>
                            <td>No external memory beyond concatenation of the conversation history within the LLM's input window.</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Multi-Session Chat (MSC) and Carecall (session 5 evaluation)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Baseline long-term dialogue generation by feeding full dialogue history to the model without memory augmentation.</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>dialogue (long-term / multi-session)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td>MSC (session 5): F1=19.41; BLEU-1/2=21.23/12.24; BertScore=86.13; Human Engagingness=1.83, Coherence=1.37, Consistency=1.32. Carecall: F1=13.69; BLEU-1/2=21.15/12.20; BertScore=85.53; Human Engagingness=1.50, Coherence=1.52, Consistency=1.43. GPT-4 (MSC session 5) average=75.32.</td>
                        </tr>
                        <tr>
                            <td><strong>has_performance_comparison</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Using the entire concatenated history without an explicit compact memory is a reasonable baseline but tends to be less consistent/coherent than memory-augmented methods in long-term dialogues; memory-augmented approaches (MemoryBank, LLM-Rsum) generally improve consistency and coherence.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Concatenating long histories can be inefficient, and LLMs may still fail to 'recall' or integrate important past information even when it is in the input (limitations in using long context effectively).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Recursively Summarizing Enables Long-Term Dialogue Memory in Large Language Models', 'publication_date_yy_mm': '2023-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3224.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e3224.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve tasks, including details of the agent, the memory mechanism, the tasks, and performance comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>MemoryBank (orig.)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>MemoryBank (original method)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A human-like long-term memory mechanism that creates ordered session summaries with timestamps and compresses them into a global memory, employing a forgetting mechanism.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>MemoryBank (original)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>A memory module that generates ordered per-session summaries, compacts them into a global memory representation, and applies forgetting/decay to manage memory over time.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_used</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>memory-based (ordered/session summaries + compression + forgetting)</td>
                        </tr>
                        <tr>
                            <td><strong>memory_mechanism_description</strong></td>
                            <td>Generate session summaries, store with timestamps, reorganize/compress them into a global memory; memory items may decay/forget according to a forgetting schedule.</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Long-term dialogue / multi-session conversation (as benchmarked in MSC/Carecall when plugged into ChatGPT)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Maintain and update long-term conversational memory across sessions to produce consistent responses.</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>dialogue (long-term / multi-session)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td>When used with ChatGPT (see ChatGPT-MemoryBank entry) performance reported in Table 3 and GPT-4 evaluation: MSC session 5 F1=20.28 and GPT-4 average=80.05.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_performance_comparison</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>MemoryBank improves coherence and consistency over context-only baselines and is a strong memory-based baseline; however fixed stored memories can become stale relative to ongoing dialog updates.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>Memory items are relatively fixed once stored; this rigidity can cause outdated or inaccurate memory to harm response quality; relies on heuristics for reorganization and forgetting.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Recursively Summarizing Enables Long-Term Dialogue Memory in Large Language Models', 'publication_date_yy_mm': '2023-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3224.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e3224.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language model agents using memory to solve tasks, including details of the agent, the memory mechanism, the tasks, and performance comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>MemoChat (orig.)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>MemoChat (original method)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A memory mechanism that reorganizes past dialogues by topic and maintains structured conversational memory per topic for retrieval during generation.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>MemoChat (original)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Generates summaries organized by conversational topic to form a structured memory store; retrieval from this store aids response generation.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_used</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>memory-based (topic-structured memory)</td>
                        </tr>
                        <tr>
                            <td><strong>memory_mechanism_description</strong></td>
                            <td>Partition conversation history into topics, generate per-topic summaries, and retrieve from this topic-structured memory during response generation.</td>
                        </tr>
                        <tr>
                            <td><strong>task_name</strong></td>
                            <td>Long-term dialogue / multi-session conversation (benchmarked via ChatGPT-MemoChat)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Track topic-specific persona and history across sessions to improve dialogue consistency.</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>dialogue (long-term / multi-session)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td>When used with ChatGPT (see ChatGPT-MemoChat entry) MSC session 5 F1=18.93; GPT-4 average=76.21.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_performance_comparison</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Topic-structured memory can help capture dialogue structure but in the evaluated benchmarks it underperformed MemoryBank and LLM-Rsum; structured memories may be less adaptable to persona or state changes.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_challenges</strong></td>
                            <td>May fail to capture timely updates when persona or facts change quickly; structure may restrict flexibility and omit cross-topic dependencies.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Recursively Summarizing Enables Long-Term Dialogue Memory in Large Language Models', 'publication_date_yy_mm': '2023-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Multi-Session Chat <em>(Rating: 2)</em></li>
                <li>Carecall <em>(Rating: 2)</em></li>
                <li>MemoryBank <em>(Rating: 2)</em></li>
                <li>MemoChat <em>(Rating: 2)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-3224",
    "paper_id": "paper-d56c1e49fcc6a8effe90786af5c7d1f0a295a7a6",
    "extraction_schema_id": "extraction-schema-74",
    "extracted_data": [
        {
            "name_short": "LLM-Rsum",
            "name_full": "Recursive Summarization (LLM-Rsum)",
            "brief_description": "A plugin method that prompts an LLM to iteratively generate and update a short natural-language memory (summaries) per session by combining prior memory and new session context, then conditions responses on the latest memory to improve long-term dialogue consistency.",
            "citation_title": "here",
            "mention_or_use": "use",
            "agent_name": "LLM-Rsum",
            "agent_description": "A prompting-based agent that performs two LLM tasks: (1) memory iteration: generate/update session summaries M_i = LLM(S_i, M_{i-1}, P_m) recursively; (2) memory-based response generation: produce responses r_t = LLM(C_t, M_N, P_r). Memory and response generation are done via designed step-by-step prompts; the same or different generative LLMs can be used for the two stages.",
            "memory_used": true,
            "memory_type": "memory-based (recursive natural-language summaries / episodic summaries)",
            "memory_mechanism_description": "Memory is stored as a short set of natural-language sentences (up to ~20 sentences per prompt). After each session the LLM is prompted with the previous memory and the session context to produce an updated memory (recursive summarization / Markov-style update). The latest memory M_N is prepended (via a response-generation prompt P_r) to the current context when generating responses.",
            "task_name": "Multi-Session Chat (MSC) and Carecall (session 5 evaluation)",
            "task_description": "Long-term multi-session open-domain dialogue where the agent must remember/maintain persona and prior interactions across multiple sessions and produce context-relevant, consistent responses.",
            "task_type": "dialogue (long-term / multi-session)",
            "performance_with_memory": "MSC (session 5, ChatGPT backbone): F1=20.48; BLEU-1/2=21.83/12.59; BertScore=86.89; Human Engagingness=1.85, Coherence=1.60, Consistency=1.45. Carecall (session 5, ChatGPT backbone): F1=14.02; BLEU-1/2=21.64/12.48; BertScore=86.05; Human Engagingness=1.62, Coherence=1.60, Consistency=1.70. GPT-4 single-model scores (MSC session 5): Engagingness=78.92, Coherence=83.56, Consistency=84.76, Average=82.41.",
            "performance_without_memory": "Context-only ChatGPT (MSC session 5): F1=19.41; BLEU-1/2=21.23/12.24; BertScore=86.13; Human Engagingness=1.83, Coherence=1.37, Consistency=1.32. GPT-4 (MSC session 5): Engagingness=75.48, Coherence=75.00, Consistency=75.48, Average=75.32.",
            "has_performance_comparison": true,
            "key_findings": "Recursive summarization memory (LLM-Rsum) yields improved long-term dialogue quality and consistency vs. context-only and several memory/retrieval baselines: small but consistent automatic-metric gains (e.g., +0.2% F1 over ChatGPT-MemoryBank on MSC) and larger gains in human and GPT-4 judgments (GPT-4 average 82.41 vs MemoryBank 80.05). Pairwise evaluation vs MemoryBank: Rsum wins 48.2% vs loses 11.9% (net +36.3%). The method complements long-context windows and retrieval-enhanced LLMs.",
            "limitations_or_challenges": "Reported gains on automatic metrics are modest (e.g., ~+0.2% F1); effectiveness depends on prompt design and in-context examples (can be improved by 2â€“3 dialog illustrations); memory is constrained to concise natural-language summaries (prompt enforces &lt;=20 sentences), which may omit fine-grained details; evaluation notes some misalignment between human and LLM judges.",
            "uuid": "e3224.0",
            "source_info": {
                "paper_title": "Recursively Summarizing Enables Long-Term Dialogue Memory in Large Language Models",
                "publication_date_yy_mm": "2023-08"
            }
        },
        {
            "name_short": "ChatGPT-MemoryBank",
            "name_full": "MemoryBank (as used with ChatGPT)",
            "brief_description": "A memory-based long-term dialogue mechanism that creates ordered per-session summaries (with timestamps), reorganizes and compresses them into a global memory, and applies a forgetting mechanism inspired by Ebbinghaus's curve.",
            "citation_title": "",
            "mention_or_use": "use",
            "agent_name": "ChatGPT-MemoryBank",
            "agent_description": "ChatGPT (gpt-3.5-turbo-0301) augmented with MemoryBank: session-level summaries are produced and stored with timestamps, reorganized/compacted to form a global memory which is then used when generating responses.",
            "memory_used": true,
            "memory_type": "memory-based (session summaries / global compressed memory)",
            "memory_mechanism_description": "MemoryBank generates ordered session summaries and compresses them into a global memory; it additionally models forgetting (Ebbinghaus curve) to decay older memory, and retrieved/organized memory is supplied to the response generator.",
            "task_name": "Multi-Session Chat (MSC) and Carecall (session 5 evaluation)",
            "task_description": "Long-term multi-session open-domain dialogue evaluation focusing on maintaining consistency across sessions.",
            "task_type": "dialogue (long-term / multi-session)",
            "performance_with_memory": "MSC (session 5, ChatGPT-MemoryBank): F1=20.28; BLEU-1/2=21.82/12.58; BertScore=86.12; Human Engagingness=1.78, Coherence=1.57, Consistency=1.40. Carecall: F1=13.15; BLEU-1/2=21.29/12.39; BertScore=85.34; Human Engagingness=1.57, Coherence=1.52, Consistency=1.68. GPT-4 (MSC session 5): Engagingness=74.68, Coherence=80.92, Consistency=84.56, Average=80.05.",
            "performance_without_memory": "Context-only ChatGPT (see ChatGPT entry): MSC session 5 F1=19.41; BLEU-1/2=21.23/12.24; GPT-4 average=75.32.",
            "has_performance_comparison": true,
            "key_findings": "MemoryBank provides stronger coherence and consistency than context-only ChatGPT in human evaluations and GPT-4 judgments; however, because MemoryBank's memory is fixed once stored it can become outdated relative to ongoing dialog updates.",
            "limitations_or_challenges": "Memory is fixed once stored and may become outdated; management relies on a forgetting/decay mechanism that may drop relevant information; lacks iterative update integrating prior memory and new session content at generation time (compared unfavorably to recursive update).",
            "uuid": "e3224.1",
            "source_info": {
                "paper_title": "Recursively Summarizing Enables Long-Term Dialogue Memory in Large Language Models",
                "publication_date_yy_mm": "2023-08"
            }
        },
        {
            "name_short": "ChatGPT-MemoChat",
            "name_full": "MemoChat (as used with ChatGPT)",
            "brief_description": "A memory-based approach that organizes structured conversational memory by topic and prompts the LLM to retrieve from this structured memory during response generation.",
            "citation_title": "",
            "mention_or_use": "use",
            "agent_name": "ChatGPT-MemoChat",
            "agent_description": "ChatGPT augmented with MemoChat: per-topic structured memory entries are generated and used as retrievalable memory to assist response generation.",
            "memory_used": true,
            "memory_type": "memory-based (structured, topic-level memory)",
            "memory_mechanism_description": "MemoChat produces topic-organized memory entries summarizing past dialogues for distinct conversation topics; these structured memories are then used as context to guide the LLM's response generation.",
            "task_name": "Multi-Session Chat (MSC) and Carecall (session 5 evaluation)",
            "task_description": "Long-term dialogue requiring tracking topical persona and history across sessions.",
            "task_type": "dialogue (long-term / multi-session)",
            "performance_with_memory": "MSC (session 5, ChatGPT-MemoChat): F1=18.93; BLEU-1/2=21.82/12.59; BertScore=85.99; Human Engagingness=1.70, Coherence=1.55, Consistency=1.35. Carecall: F1=11.19; BLEU-1/2=21.07/12.18; BertScore=85.22; Human Engagingness=1.45, Coherence=1.20, Consistency=1.30. GPT-4 (MSC session 5): Engagingness=72.32, Coherence=77.36, Consistency=78.96, Average=76.21.",
            "performance_without_memory": "Context-only ChatGPT (MSC session 5): F1=19.41; BLEU-1/2=21.23/12.24; GPT-4 average=75.32.",
            "has_performance_comparison": true,
            "key_findings": "MemoChat's structured per-topic memory can provide benefits, but in these experiments it underperformed MemoryBank and LLM-Rsum on several metrics; structured memory alone may be less effective than iterative updating of memory.",
            "limitations_or_challenges": "Structured topic memory may be less flexible and less helpful when topics or persona info change rapidly; in experiments it produced lower F1 and human-engagement scores than other memory approaches.",
            "uuid": "e3224.2",
            "source_info": {
                "paper_title": "Recursively Summarizing Enables Long-Term Dialogue Memory in Large Language Models",
                "publication_date_yy_mm": "2023-08"
            }
        },
        {
            "name_short": "ChatGPT-BM25",
            "name_full": "ChatGPT with BM25 retrieval (ChatGPT-BM25)",
            "brief_description": "A retrieval-augmented variant that uses BM25 to retrieve top-k past utterances and prepends them to ChatGPT's input to support long-term dialogue generation.",
            "citation_title": "",
            "mention_or_use": "use",
            "agent_name": "ChatGPT-BM25",
            "agent_description": "ChatGPT (gpt-3.5-turbo-0301) combined with BM25 retriever: previous utterances are indexed and the top-k (k=3 or 5) most relevant are retrieved and included in the prompt as context for response generation.",
            "memory_used": true,
            "memory_type": "retrieval-augmented (retrieved past utterances using BM25)",
            "memory_mechanism_description": "Past conversational utterances stored in a document store are queried using BM25; top-k retrieved passages are concatenated with current context and fed to the LLM to generate responses.",
            "task_name": "Multi-Session Chat (MSC) and Carecall (session 5 evaluation)",
            "task_description": "Long-term dialogue where relevant historical utterances must be retrieved to inform current responses.",
            "task_type": "dialogue (long-term / multi-session)",
            "performance_with_memory": "ChatGPT-BM25 (k=3) MSC session 5: F1=19.56; BLEU-1/2=21.60/12.46; BertScore=85.82; Human Engagingness=1.72, Coherence=1.48, Consistency=1.32. Carecall: F1=12.64; BLEU-1/2=21.57/12.44; BertScore=85.24; Human Engagingness=1.40, Coherence=1.31, Consistency=1.31.",
            "performance_without_memory": "Context-only ChatGPT: MSC F1=19.41; Carecall F1=13.69 (see ChatGPT entry).",
            "has_performance_comparison": true,
            "key_findings": "Retrieval via BM25 can be helpful in some settings but may hurt performance when retrieved context is irrelevant; in Carecall retrieval-based variants underperformed vanilla ChatGPT because retrieval returned unrelated information for that dataset's conversational style.",
            "limitations_or_challenges": "Effectiveness depends on retriever quality and dataset characteristics; BM25 may retrieve irrelevant utterances for certain dialog types leading to degraded generation quality.",
            "uuid": "e3224.3",
            "source_info": {
                "paper_title": "Recursively Summarizing Enables Long-Term Dialogue Memory in Large Language Models",
                "publication_date_yy_mm": "2023-08"
            }
        },
        {
            "name_short": "ChatGPT-DPR",
            "name_full": "ChatGPT with DPR retrieval (ChatGPT-DPR)",
            "brief_description": "A retrieval-augmented variant that uses a dense passage retriever (DPR) to fetch top-k relevant past utterances and supply them to ChatGPT for response generation.",
            "citation_title": "",
            "mention_or_use": "use",
            "agent_name": "ChatGPT-DPR",
            "agent_description": "ChatGPT combined with a pre-trained Dense Passage Retriever (DPR): past utterances are embedded and DPR retrieves top-k semantically relevant passages to prepend to the LLM input.",
            "memory_used": true,
            "memory_type": "retrieval-augmented (dense retrieval / DPR)",
            "memory_mechanism_description": "A DPR model is used to encode conversation segments; given the current context DPR returns top-k semantically-most-similar past utterances which are included in the prompt for the LLM to condition on.",
            "task_name": "Multi-Session Chat (MSC) and Carecall (session 5 evaluation)",
            "task_description": "Long-term dialogue requiring retrieval of semantically relevant historical utterances.",
            "task_type": "dialogue (long-term / multi-session)",
            "performance_with_memory": "ChatGPT-DPR (k=3) MSC session 5: F1=20.23; BLEU-1/2=21.75/12.55; BertScore=86.04; Human Engagingness=1.76, Coherence=1.51, Consistency=1.34. Carecall: F1=12.21; BLEU-1/2=21.39/12.35; BertScore=85.25; Human Engagingness=1.55, Coherence=1.35, Consistency=1.45.",
            "performance_without_memory": "Context-only ChatGPT: MSC F1=19.41; Carecall F1=13.69.",
            "has_performance_comparison": true,
            "key_findings": "Dense retrieval (DPR) can slightly improve some automatic metrics versus BM25 or context-only in MSC, but in Carecall retrieval variants still underperformed vanilla ChatGPT due to difficulty retrieving relevant guidance for that task.",
            "limitations_or_challenges": "Quality of retrieval is critical; DPR requires good embeddings/retriever training and may still return irrelevant passages for some dialog types, hurting generation.",
            "uuid": "e3224.4",
            "source_info": {
                "paper_title": "Recursively Summarizing Enables Long-Term Dialogue Memory in Large Language Models",
                "publication_date_yy_mm": "2023-08"
            }
        },
        {
            "name_short": "ChatGPT (context-only)",
            "name_full": "ChatGPT (gpt-3.5-turbo-0301) context-only baseline",
            "brief_description": "Vanilla ChatGPT used as a context-only dialogue agent that concatenates past sessions and current context without an explicit external memory mechanism beyond the input context window.",
            "citation_title": "",
            "mention_or_use": "use",
            "agent_name": "ChatGPT (context-only)",
            "agent_description": "ChatGPT (gpt-3.5-turbo-0301) provided with concatenated dialog history (past sessions and current context) as input and asked to generate a response; no external memory module or retriever is used.",
            "memory_used": false,
            "memory_type": "context window only",
            "memory_mechanism_description": "No external memory beyond concatenation of the conversation history within the LLM's input window.",
            "task_name": "Multi-Session Chat (MSC) and Carecall (session 5 evaluation)",
            "task_description": "Baseline long-term dialogue generation by feeding full dialogue history to the model without memory augmentation.",
            "task_type": "dialogue (long-term / multi-session)",
            "performance_with_memory": null,
            "performance_without_memory": "MSC (session 5): F1=19.41; BLEU-1/2=21.23/12.24; BertScore=86.13; Human Engagingness=1.83, Coherence=1.37, Consistency=1.32. Carecall: F1=13.69; BLEU-1/2=21.15/12.20; BertScore=85.53; Human Engagingness=1.50, Coherence=1.52, Consistency=1.43. GPT-4 (MSC session 5) average=75.32.",
            "has_performance_comparison": true,
            "key_findings": "Using the entire concatenated history without an explicit compact memory is a reasonable baseline but tends to be less consistent/coherent than memory-augmented methods in long-term dialogues; memory-augmented approaches (MemoryBank, LLM-Rsum) generally improve consistency and coherence.",
            "limitations_or_challenges": "Concatenating long histories can be inefficient, and LLMs may still fail to 'recall' or integrate important past information even when it is in the input (limitations in using long context effectively).",
            "uuid": "e3224.5",
            "source_info": {
                "paper_title": "Recursively Summarizing Enables Long-Term Dialogue Memory in Large Language Models",
                "publication_date_yy_mm": "2023-08"
            }
        },
        {
            "name_short": "MemoryBank (orig.)",
            "name_full": "MemoryBank (original method)",
            "brief_description": "A human-like long-term memory mechanism that creates ordered session summaries with timestamps and compresses them into a global memory, employing a forgetting mechanism.",
            "citation_title": "",
            "mention_or_use": "use",
            "agent_name": "MemoryBank (original)",
            "agent_description": "A memory module that generates ordered per-session summaries, compacts them into a global memory representation, and applies forgetting/decay to manage memory over time.",
            "memory_used": true,
            "memory_type": "memory-based (ordered/session summaries + compression + forgetting)",
            "memory_mechanism_description": "Generate session summaries, store with timestamps, reorganize/compress them into a global memory; memory items may decay/forget according to a forgetting schedule.",
            "task_name": "Long-term dialogue / multi-session conversation (as benchmarked in MSC/Carecall when plugged into ChatGPT)",
            "task_description": "Maintain and update long-term conversational memory across sessions to produce consistent responses.",
            "task_type": "dialogue (long-term / multi-session)",
            "performance_with_memory": "When used with ChatGPT (see ChatGPT-MemoryBank entry) performance reported in Table 3 and GPT-4 evaluation: MSC session 5 F1=20.28 and GPT-4 average=80.05.",
            "performance_without_memory": null,
            "has_performance_comparison": true,
            "key_findings": "MemoryBank improves coherence and consistency over context-only baselines and is a strong memory-based baseline; however fixed stored memories can become stale relative to ongoing dialog updates.",
            "limitations_or_challenges": "Memory items are relatively fixed once stored; this rigidity can cause outdated or inaccurate memory to harm response quality; relies on heuristics for reorganization and forgetting.",
            "uuid": "e3224.6",
            "source_info": {
                "paper_title": "Recursively Summarizing Enables Long-Term Dialogue Memory in Large Language Models",
                "publication_date_yy_mm": "2023-08"
            }
        },
        {
            "name_short": "MemoChat (orig.)",
            "name_full": "MemoChat (original method)",
            "brief_description": "A memory mechanism that reorganizes past dialogues by topic and maintains structured conversational memory per topic for retrieval during generation.",
            "citation_title": "",
            "mention_or_use": "use",
            "agent_name": "MemoChat (original)",
            "agent_description": "Generates summaries organized by conversational topic to form a structured memory store; retrieval from this store aids response generation.",
            "memory_used": true,
            "memory_type": "memory-based (topic-structured memory)",
            "memory_mechanism_description": "Partition conversation history into topics, generate per-topic summaries, and retrieve from this topic-structured memory during response generation.",
            "task_name": "Long-term dialogue / multi-session conversation (benchmarked via ChatGPT-MemoChat)",
            "task_description": "Track topic-specific persona and history across sessions to improve dialogue consistency.",
            "task_type": "dialogue (long-term / multi-session)",
            "performance_with_memory": "When used with ChatGPT (see ChatGPT-MemoChat entry) MSC session 5 F1=18.93; GPT-4 average=76.21.",
            "performance_without_memory": null,
            "has_performance_comparison": true,
            "key_findings": "Topic-structured memory can help capture dialogue structure but in the evaluated benchmarks it underperformed MemoryBank and LLM-Rsum; structured memories may be less adaptable to persona or state changes.",
            "limitations_or_challenges": "May fail to capture timely updates when persona or facts change quickly; structure may restrict flexibility and omit cross-topic dependencies.",
            "uuid": "e3224.7",
            "source_info": {
                "paper_title": "Recursively Summarizing Enables Long-Term Dialogue Memory in Large Language Models",
                "publication_date_yy_mm": "2023-08"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Multi-Session Chat",
            "rating": 2
        },
        {
            "paper_title": "Carecall",
            "rating": 2
        },
        {
            "paper_title": "MemoryBank",
            "rating": 2
        },
        {
            "paper_title": "MemoChat",
            "rating": 2
        }
    ],
    "cost": 0.017308,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>Recursively Summarizing Enables Long-Term Dialogue Memory in Large Language Models</h1>
<p>Qingyue Wang ${ }^{\mathrm{a}}$, Yanhe $\mathrm{Fu}^{\mathrm{b}}$, Yanan Cao ${ }^{\mathrm{b}, *}$, Shuai Wang ${ }^{\mathrm{a}}$, Zhiliang Tian ${ }^{\mathrm{c}}$, Liang Ding $^{\mathrm{d}}$<br>${ }^{a}$ the Department of Computer Science and Engineering, Hong Kong University of Science and Technology, Hong Kong, China<br>${ }^{b}$ the institute of information engineering, Chinese Academy of Sciences, Beijing, China<br>${ }^{c}$ the College of Computer, National University of Defense Technology, Changsha, China<br>${ }^{d}$ the University of Sydney, Sydney, Australia</p>
<h4>Abstract</h4>
<p>Recently, large language models (LLMs), such as GPT-4, stand out remarkable conversational abilities, enabling them to engage in dynamic and contextually relevant dialogues across a wide range of topics. However, in a long-term conversation, these chatbots fail to recall appropriate information from the past, resulting in inconsistent responses. To address this, we propose to recursively generate summaries/ memory using large language models to enhance their long-term dialog ability. Specifically, our method first stimulates the LLM to memorize small dialogue contexts. After that, the LLM recursively produces new memory using previous old memory and subsequent contexts. Finally, the chatbot is prompted to generate a response based on the latest memory. The experiments on widely used LLMs show that our method generates more consistent responses in long-term</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>conversations, and it can be significantly enhanced with just two/ three dialog illustrations. Also, we find that our strategy could nicely complement both large context windows (e.g., 8 K and 16 K ) and retrieval-enhanced LLMs, bringing further long-term dialogue performance. Notably, our method is a potential solution to enable the LLM to model the extremely long dialog context. The code and scripts will be released later.</p>
<p>Keywords: recursive summary, long-term memory, large language models, dialog generation.</p>
<h1>1. Introduction</h1>
<p>Recently, large language models (LLMs), such as ChatGPT ${ }^{1}$ and GPT-4 (Achiam et al., 2023), demonstrate promising performances in various natural language applications (Brown et al., 2020; Zeng et al., 2022; Zhong et al., 2023; Lu et al., 2023b; Peng et al., 2023; Wu et al., 2023). One notable capability lies in their remarkable conversational prowess, comprehending input, and generating humanlike responses.</p>
<p>Large context windows allow many LLMs ${ }^{2}$ to process entire dialog histories, yet they often struggle to effectively comprehend past interactions and integrate key information into responses (Zhou et al., 2023). Applications such as personal AI companions, which need to recall past conversations for rapport building, and health assistants, which must consider a complete record of patient inquiries to provide diagnostic results, demonstrate the importance of maintaining consistency</p>
<p><sup id="fnref2:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Figure 1: A long-term conversation example from the Multi-Session Chat Dataset (Xu et al., 2022a). When the user refers back to previous subjects (i.e., composing music), even the ChatGPT (gpt-turbo-3.5-0301 version) generates an inconsistent response.
and coherence in long-term dialogues. Figure 1 illustrates a dialog spanning over 20 turns, centered around a discussion of the speakers' personas (e.g., the bot composes music, and the user enjoys country music). However, even the powerful ChatGPT forgets past information and produces a poor response, showing the necessity to explicitly model long-term memory during conversations.</p>
<p>To address this, there are two mainstream methods to enhance the long-term dialog ability of LLMs. The first one is the retrieval-based method, which directly stores past conversational utterances in the storage and adapts an advanced retriever to identify the most relevant history (Guu et al., 2020; Lewis et al., 2020). However, it is difficult to obtain a well-performing (ideal) retriever, ensuring that the retrieved utterances capture the complete semantics about current conversations. The second way is to employ a memory module to summarize important conversation information to assist the LLM, which is also called memory-based</p>
<p>approaches (MazarÃ© et al., 2018; Xu et al., 2022b; Chen et al., 2024a). They usually apply a separately trained model or a powerful large language model to generate memory for past dialogues. Nevertheless, these methods lack the necessary iteration mechanism on generated memory, resulting in the reserved outdated information directly hurting the quality of responses.</p>
<p>In this paper, we propose a simple and effective plug-in method that enables LLM itself to generate summaries, which store the real-time information of speakers through continuous updating and reviewing past context to aid long-term interactions. In practice, a generative LLM is first prompted to produce a summary given a short dialog context. After that, we ask the LLM to continue updating and generate a new summary/ memory by combining the previous memory and subsequent dialogues. Finally, we encourage the LLM to respond using the latest memory as the primary reference to engage the ongoing dialogue. Given that the generated summaries are much shorter than the full dialogues, our proposed schema not only models long-term conversation memory but also serves as a potential solution to enable current LLMs to handle extremely long contexts (across multiple dialogue sessions) without expensively expanding the maximum length setting.</p>
<p>Experimentally, we implement our method using a variety of state-of-theart open (Llama (Touvron et al., 2023) and ChatGLM (GLM et al., 2024)) and closed (OpenAI's GPT-3.5-Turbo) LLMs, and the performance on long-term dialog surpasses that of popular approaches both in automatic and human evaluations. Moreover, we verify the effectiveness of using explicit memory for longterm dialogs and using our generated memory is easier for LLMs to digest. These findings underscore the importance of developing advanced memory generation</p>
<p>strategies. Our method can further enhance response quality by incorporating the in-context learning (ICL) technique, where multiple samples in the format of (dialogue, memory, and golden response) are presented to LLMs. This allows them to utilize the generated memory more flexibly. Additionally, we demonstrate the generalizability of our approach across different LLMs, with our method achieving approximately a $+3 \%$ improvement in BLEU score on text-davinci-003. Finally, we observe that our schema complements existing window-extended LLMs (e.g., GPT-3.5-Turbo-16k and LongLoRA-8k) and retrieval-enhanced LLMs (e.g., LLM-BM25 and LLM-DPR), producing more coherent and consistent responses in long-term conversations.</p>
<p>In summary, our contributions are as follows:</p>
<ul>
<li>We propose a novel method by recursively summarizing past dialogues to enhance the LLM's memory, enabling the generation of highly consistent responses in long-term conversations.</li>
<li>The solid experiments on the public datasets show the superiority of the proposed method, with multiple open-source and closed-source LLMs verifying its universality and robustness.</li>
<li>The simplicity of our method makes it nicely complements existing works, including retrieval-based and long-context techniques, having the great potential to be an orthogonal plug-in for the LLM community.</li>
</ul>
<h1>2. Related Work</h1>
<h3>2.1. Large Language Models</h3>
<p>Language language models (LLMs) have shown outstanding performance in a variety of user-facing language technologies, including conversation, summarization, and creative writing (Achiam et al., 2023; Shuster et al., 2022; Rubin and Berant, 2024). While these LLMs achieve notable success in many popular tasks, their ability to model long text remains a challenge (An et al., 2023). To address the problem, some works are to adapt transformers to accommodate longer inputs, such as position interpolation (Chen et al., 2023) and efficient self-attention (Beltagy et al., 2020; Chen et al., 2024b). However, these context window-extended LLMs not only require continual training on high-quality long texts but still struggle to use and retrieve the core information from the entire input (Liu et al., 2023). Recently, in question-answer task, some researchers found that the performances of LLMs degrade significantly when people change the position of relevant information, indicating that current language models do not robustly make use of information in long input contexts (Liu et al., 2023; Li et al., 2023). Many works suggest that the lack of explicit memory mechanisms in current LLMs hinders their performance on tasks requiring sustained context awareness and understanding (Chen et al., 2024a). Nowadays, the performance of LLMs has not yet been explored deeply in long-range dialogue scenarios. This work focuses on developing the long-term modeling ability of the LLM, where we prompt it to self-memory, self-update, and self-use in conversations, aiding consistent response generation.</p>
<h1>2.2. Long-term Open-Domain Dialogue</h1>
<p>Open-domain dialogue systems (Liu et al., 2016; Zhang et al., 2018; Kann et al., 2022), also known as chatbots or conversational agents, have gained immense popularity and a lot of studies in recent years. Among them, the long-term conversation setting is pretty a hard problem, because it needs the capability of understanding and memorizing key dialogue history information (Wu et al., 2022; Zhang et al., 2022) about current query. The most popular and potential solution is to directly store the partial information for tracking the history of conversation (Lee et al., 2023), usually in the form of dialogue utterances or summaries. The current conversation and relevant information are then inputted into the response generator. One intuitive idea is to apply a retriever to find the most relevant utterances according to the current dialog, which is called as the retrievalbased method. Another popular method is a memory-based method, which tries to generate and manage the summary to obtain key information from history. For example, MemoChat (Lu et al., 2023a) allows chatbots to reorganize the past dialogue histories according to different topics of speakers and prompt the LLM to retrieve from the structured memory during generation. Going further, MemoryBank (Zhong et al., 2024) proposes a new memory mechanism by generating summaries for each dialog session first and then compressing them into a global one. However, their memory is completely fixed once stored, failing to guarantee its consistency with ongoing dialog. The important comparison between these existing methods and ours is shown in Figure 2. As seen, our approach and these methods mainly diverge in the way of memory generation, where we continuously integrate historical information and old memory to obtain real-time memory, enabling the gain of accurate memory and modeling of long-distance dependencies.</p>
<p><img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Figure 2: Comparison among baselines and ours. The "U", "S", "T", and "M" are abbreviations for the Utterance, Session, dialog Topic, and Memory. The red dashed box refers to the memory used to generate the response.</p>
<h1>3. Approach Overview</h1>
<p>Following previous works (Xu et al., 2022a; Bae et al., 2022), we denote that a long-context dialogue consists of multiple sessions with a specific user, which is also called Multi-Session Dialogue. The goal of the task is to generate contextrelevant and highly consistent responses to the user based on past sessions and current context. Formally, each dialogue can be written as $D=\left{S, C_{t}, r_{t}\right}$. Here, $S=\left{S_{1}, S_{2}, \ldots, S_{N}\right}$ represents $N$ past sessions and each of the sessions consists of multiple utterances between two speakers. $r_{t}$ is the ground truth response to $C_{t}$ with background sessions $S . C_{t}=\left{u_{1}, r_{1}, \ldots, u_{t}\right}$ denotes the dialogue context of the current session at $t$ step, where $u$ and $r$ represent the utterances from the user and the chatbot, respectively.</p>
<p>In this paper, we propose a new memory mechanism to aid a large language model for multi-session dialog tasks. The memory contains multiple natural language sentences, storing the key information of speakers extracted from previous sessions. Our goal is to obtain a reliable memory given past sessions and predict a consistent and meaningful response using the current dialogue context and the</p>
<p><img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>Figure 3: The schematic overview of our method. The model uses the first session to generate initial memory (green arrows), then updates the memory when the second session ends (yellow arrows), and generates a response using the latest memory at the third session (blue arrows).
memory. Specifically, we decompose the goal into two stages with the following probability distribution:</p>
<p>$$
P\left(r_{t} \mid C_{t}, S\right)=P\left(r_{t} \mid C_{t}, M_{N}\right) P\left(M_{N} \mid S\right)
$$</p>
<p>where $M_{i}$ represents the available memory when the $i$-th session is finished. And $P\left(M_{N} \mid S\right)=\prod_{i=1}^{N} P\left(M_{i} \mid S_{i}, M_{i-1}\right)$ is a sequential or Markov process where each memory $M_{i}$ of session $i$ depends only on the current session and the previous memory $M_{i-1}$.</p>
<h1>4. Approach</h1>
<p>To achieve long-term dialog, we prompt an arbitrary large language model to finish two tasks, i.e., memory iteration and memory-based response generation. The former is responsible for recursively summarizing the key information along with long-term dialogue, and the latter is to incorporate the latest mem-</p>
<p>ory and current dialog to generate an appropriate and consistent response. The workflow of our proposed method is shown in Figure 3.</p>
<h1>4.1. Memory Iteration</h1>
<p>The goal of memory iteration is to obtain a coherent and up-to-date summary for the chatbot. Early works (Bae et al., 2022; Choi et al., 2023) update memory by carrying multiple "hard operations" on summaries, such as replace, append, and delete, which rely on high-quality dialogue with operation labels. However, this laborious design disrupts the semantic coherence of the summary and is not suitable for management over a long period. Differently, we guide the LLMs to recursively self-generate memory (summaries) using dialogue context and previous memory. By utilizing old summaries, the model can fully digest the current dialog context and thus gain a high-quality memory. Formally, the updated memory is computed by:</p>
<p>$$
M_{i}=\boldsymbol{L} \boldsymbol{L} \boldsymbol{M}\left(S_{i}, M_{i-1}, \mathrm{P}_{m}\right)
$$</p>
<p>where $M_{i}=\left{m_{1}, m_{2}, \ldots, m_{J}\right}$ denotes multiple sentences, containing summarized key information from the session $S_{i}$, and $\mathrm{P}<em N="N">{\mathrm{m}}$ is the prompt of LLM for generating new memory. The memory iteration will be repeated $N$ times until all previous sessions end, where we can obtain the latest memory $M</em>$. Take the dialog in Figure 3 as an example, two memory iterations happen at the end of the first and second sessions. In the second iteration, the LLM incorporates the new personality (i.e., the bot recently joined a new gym) from Session 2 into the old memory (i.e., the bot enjoys walking and running).</p>
<p>Prompt Construction. To enable LLM to efficiently carry the memory iteration task, we design a specific prompt for it, which is shown in Table 1. It mainly</p>
<p>Table 1: The prompt design of memory iteration, including task definition, task description and task inputs</p>
<table>
<thead>
<tr>
<th style="text-align: left;"></th>
<th style="text-align: left;">You are an advanced AI language model with the ability to store and update a memory to keep track of</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">key personality information for both the user and the bot. You will receive a previous memory and</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">dialogue context. Your goal is to update the memory by incorporating the new personality information.</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">To successfully update the memory, follow these steps:</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">1.Carefully analyze the existing memory and extract the key personality of the user and bot from it.</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">2. Consider the dialogue context provided to identify any new or changed personality that needs to</td>
</tr>
<tr>
<td style="text-align: left;">Prompt</td>
<td style="text-align: left;">be incorporated into the memory.</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">3. Combine the old and new personality information to create an updated representation of the user and</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">bot's traits.</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">4. Structure the updated memory in a clear and concise manner, ensuring it does not exceed 20 sentences.</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">Remember, the memory should serve as a reference point to</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">maintain continuity in the dialogue and help you respond accurately to the user based on their personality.</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">[Previous Memory] [Session Context]</td>
</tr>
<tr>
<td style="text-align: left;">Output</td>
<td style="text-align: left;">[Updated Memory]</td>
</tr>
</tbody>
</table>
<p>consists of three parts: (1) Task definition is responsible for defining the role of the current LLM, as well as the memory iterator's (LLM) input and output. (2) Task description gives detailed steps to finish the above task. To make sure the memory update is timely, we remind the LLM to create a new representation of speakers by considering old summaries and current sessions.(3) Task input contains two placeholders, where we take previous memory and a whole session as the inputs. Through experimental verification, we found that using step-by-step instructions helps the LLM better understand and execute the memory iteration ${ }^{3}$.</p>
<p><sup id="fnref3:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>Table 2: The prompt of memory-based response generation, including task definition, task description and task inputs</p>
<table>
<thead>
<tr>
<th>Prompt</th>
<th>You will be provided with a memory containing personality information for both yourself and the user.</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td>Your goal is to respond accurately to the user based on the personality traits and dialogue context.</td>
</tr>
<tr>
<td></td>
<td>Follow these steps to successfully complete the task:</td>
</tr>
<tr>
<td></td>
<td>1. Analyze the provided memory to extract the key personality traits for both yourself and the user.</td>
</tr>
<tr>
<td></td>
<td>2. Review the dialogue history to understand the context and flow of the conversation.</td>
</tr>
<tr>
<td></td>
<td>3. Utilize the extracted personality traits and dialogue context to formulate an appropriate response.</td>
</tr>
<tr>
<td></td>
<td>4. If no specific personality trait is applicable, respond naturally as a human would.</td>
</tr>
<tr>
<td></td>
<td>5. Pay attention to the relevance and importance of the personality information, focusing on capturing</td>
</tr>
<tr>
<td></td>
<td>the most significant aspects while maintaining the overall coherence of the memory.</td>
</tr>
<tr>
<td></td>
<td>[Previous Memory] [Current Context]</td>
</tr>
<tr>
<td>Output</td>
<td>[Response]</td>
</tr>
</tbody>
</table>
<h1>4.2. Memory-based Response Generation</h1>
<p>The final goal is to produce consistent and natural responses given dialogue memory and the context of the current session. Formally, the response of the current session can be obtained by stimulating the LLM as a response generator:</p>
<p>$$
r_{t}=\boldsymbol{L} \boldsymbol{L} \boldsymbol{M}\left(C_{t}, M_{N}, \mathrm{P}_{\mathrm{r}}\right)
$$</p>
<p>where $P_{r}$ is a prompt of the generator. Especially, taking the generated memory $M_{N}$ and current session $C_{t}$, we ask the LLM again to generate a response. In Figure 3, the LLM considers the newest memory from Session 2 and provides a high consistent response to the user, i.e., " more flexibility with a 24 -hour gym membership".</p>
<p>Prompt Construction. The the prompt for memory-based response generation is shown in Table 2. The prompt is similar to that of memory iteration, including task definition, description, and inputs, where we remind the LLM to utilize the</p>
<div class="codehilite"><pre><span></span><code><span class="nt">Algorithm</span><span class="w"> </span><span class="nt">1</span><span class="o">:</span><span class="w"> </span><span class="nt">Response</span><span class="w"> </span><span class="nt">generation</span><span class="w"> </span><span class="nt">using</span><span class="w"> </span><span class="nt">recursive</span><span class="w"> </span><span class="nt">memory</span><span class="o">.</span>
<span class="w">    </span><span class="nt">Input</span><span class="o">:</span><span class="w"> </span><span class="nt">A</span><span class="w"> </span><span class="nt">long-term</span><span class="w"> </span><span class="nt">dialog</span><span class="w"> </span><span class="err">\</span><span class="o">(</span><span class="nt">D</span><span class="o">=</span><span class="err">\</span><span class="nt">left</span><span class="err">\</span><span class="p">{</span><span class="err">S,</span><span class="w"> </span><span class="err">C_{t</span><span class="p">}</span><span class="err">\</span><span class="nt">right</span><span class="err">\}\</span><span class="o">)</span><span class="w"> </span><span class="nt">consisting</span><span class="w"> </span><span class="nt">multiple</span><span class="w"> </span><span class="nt">sessions</span><span class="w"> </span><span class="nt">with</span>
<span class="w">        </span><span class="nt">a</span><span class="w"> </span><span class="nt">user</span><span class="o">;</span><span class="w"> </span><span class="nt">A</span><span class="w"> </span><span class="nt">generative</span><span class="w"> </span><span class="nt">pre-trained</span><span class="w"> </span><span class="nt">model</span><span class="w"> </span><span class="nt">LLM</span><span class="o">;</span><span class="w"> </span><span class="nt">Pre-defined</span><span class="w"> </span><span class="nt">prompt</span>
<span class="w">        </span><span class="err">\</span><span class="o">(</span><span class="nt">P_</span><span class="p">{</span><span class="err">m</span><span class="p">}</span><span class="err">\</span><span class="o">)</span><span class="w"> </span><span class="nt">and</span><span class="w"> </span><span class="err">\</span><span class="o">(</span><span class="nt">P_</span><span class="p">{</span><span class="err">r</span><span class="p">}</span><span class="err">\</span><span class="o">)</span>
<span class="w">    </span><span class="nt">Output</span><span class="o">:</span><span class="w"> </span><span class="nt">A</span><span class="w"> </span><span class="nt">response</span><span class="w"> </span><span class="nt">to</span><span class="w"> </span><span class="nt">user</span><span class="o">.</span>
<span class="w">    </span><span class="err">\</span><span class="o">(</span><span class="nt">1</span><span class="w"> </span><span class="nt">M_</span><span class="p">{</span><span class="err">0</span><span class="p">}</span><span class="w"> </span><span class="err">\</span><span class="nt">leftarrow</span><span class="err">\</span><span class="o">)</span><span class="w"> </span><span class="nt">none</span><span class="o">;</span>
<span class="w">    </span><span class="o">//</span><span class="w"> </span><span class="nt">Set</span><span class="w"> </span><span class="nt">initial</span><span class="w"> </span><span class="nt">memory</span><span class="w"> </span><span class="nt">as</span><span class="w"> </span><span class="nt">empty</span>
<span class="w">    </span><span class="nt">2</span><span class="w"> </span><span class="nt">for</span><span class="w"> </span><span class="err">\</span><span class="o">(</span><span class="nt">i</span><span class="w"> </span><span class="err">\</span><span class="nt">leftarrow</span><span class="w"> </span><span class="nt">1</span><span class="err">\</span><span class="o">)</span><span class="w"> </span><span class="nt">to</span><span class="w"> </span><span class="err">\</span><span class="o">(</span><span class="nt">N</span><span class="err">\</span><span class="o">)</span><span class="w"> </span><span class="nt">do</span>
<span class="w">    </span><span class="nt">3</span><span class="w"> </span><span class="err">\</span><span class="o">(</span><span class="err">\</span><span class="nt">quad</span><span class="w"> </span><span class="nt">M_</span><span class="p">{</span><span class="err">i</span><span class="p">}</span><span class="o">=</span><span class="nt">L</span><span class="w"> </span><span class="nt">L</span><span class="w"> </span><span class="nt">M</span><span class="err">\</span><span class="nt">left</span><span class="o">(</span><span class="nt">S_</span><span class="p">{</span><span class="err">i</span><span class="p">}</span><span class="o">,</span><span class="w"> </span><span class="nt">M_</span><span class="p">{</span><span class="err">i-1</span><span class="p">}</span><span class="o">,</span><span class="w"> </span><span class="nt">P_</span><span class="p">{</span><span class="err">m</span><span class="p">}</span><span class="err">\</span><span class="nt">right</span><span class="o">)</span><span class="w"> </span><span class="o">;</span><span class="err">\</span><span class="o">)</span>
<span class="w">    </span><span class="o">//</span><span class="w"> </span><span class="nt">Update</span><span class="w"> </span><span class="nt">memory</span><span class="w"> </span><span class="nt">when</span><span class="w"> </span><span class="nt">a</span><span class="w"> </span><span class="nt">session</span><span class="w"> </span><span class="nt">ends</span>
<span class="w">    </span><span class="err">\</span><span class="o">(</span><span class="nt">4</span><span class="w"> </span><span class="nt">r_</span><span class="p">{</span><span class="err">t</span><span class="p">}</span><span class="o">=</span><span class="nt">L</span><span class="w"> </span><span class="nt">L</span><span class="w"> </span><span class="nt">M</span><span class="err">\</span><span class="nt">left</span><span class="o">(</span><span class="nt">C_</span><span class="p">{</span><span class="err">t</span><span class="p">}</span><span class="o">,</span><span class="w"> </span><span class="nt">M_</span><span class="p">{</span><span class="err">N</span><span class="p">}</span><span class="o">,</span><span class="w"> </span><span class="nt">P_</span><span class="p">{</span><span class="err">r</span><span class="p">}</span><span class="err">\</span><span class="nt">right</span><span class="o">)</span><span class="w"> </span><span class="o">;</span><span class="err">\</span><span class="o">)</span>
<span class="w">    </span><span class="o">//</span><span class="w"> </span><span class="nt">Response</span><span class="w"> </span><span class="nt">using</span><span class="w"> </span><span class="nt">latest</span><span class="w"> </span><span class="nt">memory</span>
<span class="w">    </span><span class="nt">5</span><span class="w"> </span><span class="nt">return</span><span class="w"> </span><span class="err">\</span><span class="o">(</span><span class="nt">r_</span><span class="p">{</span><span class="err">t</span><span class="p">}</span><span class="err">\</span><span class="o">)</span>
</code></pre></div>

<p>extracted information and maintain the consistency of memory when responding. Also, the step-by-step instructions method is also effective for memory-based response generation.</p>
<h1>4.3. Algorithm</h1>
<p>The process of response generation using recursive memory is illustrated in Algorithm 1. In the beginning, the initial memory is set as an empty, i.e., "none" string. After that, we recursively update the memory using each session context (line 3). Finally, the LLM generates a response with the help of the latest memory (line 5). The generative pre-trained models used for memory iteration and response generation can be different. For instance, the developers can train a private memory iterator through customized models or data, to enhance the target open/</p>
<p>closed LLMs for long-term or long-context tasks.</p>
<h1>5. Experimental Settings</h1>
<h3>5.1. Datasets</h3>
<p>We validate the effectiveness of the proposed method on two widely-used long-term dialogue datasets: Multi-Session Chat (MSC) dataset (Xu et al., 2022a) and Carecall dataset (Bae et al., 2022).</p>
<p>MSC dataset. is the largest human-human long conversations dataset so far. The early sessions are a short conversation where two speakers get to know each other for the first time and then they either continue to talk about the previous subject or spark up conversation on a new topic.</p>
<p>Carecall. is a Korean open-domain multi-session dataset, which is used for monitoring patient health. For a fair comparison, we use the public machine-translated English version ${ }^{4}$ in the experiments.</p>
<p>The CareCall's setting is similar procedure presented in the MSC dataset. The main difference is that the Carecall additionally contains more persona updates that are likely to change in a short period, such as the user's health and diet, while the persona information in the MSC dataset remains fixed once it is stored. Both of the two datasets have five sessions and each one consists of multiple utterances between two speakers (the user and chatbot), where the conversationalists reengage after several hours or days and continue chatting. As early sessions only have a very short history of conversations, we mainly evaluate the proposed method in</p>
<p><sup id="fnref4:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>session 4 and 5 for the ability of long-term modeling. The statistics of two datasets are given in Appendix A.</p>
<h1>5.2. Evaluation Metrics</h1>
<p>we conduct diverse evaluations during experiments, including automatic metrics, human evaluation, and LLM judgments, focusing on the quality of generated memory and response.</p>
<p>Automatic Metrics. We employ BLEU-1/2 (Papineni et al., 2002), F1 with reference to the human annotations. Besides, we compute BertScore (Li et al., 2016) to measure the semantics similarity between the references and the generated responses.</p>
<p>Human Evaluation. Many works point out that automatic evaluation metrics are insufficient for capturing the nuances of conversations (Deriu et al., 2019). Following the previous works (Bae et al., 2022), we ask three crowd-sourcing workers to assign a score from 0 to 2 (0:bad, 1:OK, 2:good) to the generated responses based on the aspects of engagingness, coherence, and consistency. These criteria are discussed as follows: (1) Engagingness: It evaluates whether the chatbot captures the user's interest and makes them want to continue the conversation. A high score on engagingness means the responses are interesting and contextually appropriate, encouraging users to keep chatting. (2) Coherence: It measures whether the response maintains a logical and clear flow based on the conversation's context. A coherent response ensures the conversation makes sense and stays relevant, enhancing user engagement. (3) Consistency: It assesses whether the response aligns with the information provided in previous interactions. Con-</p>
<p>sistent responses build trust and reliability by demonstrating that the chatbot remembers and integrates past exchanges accurately.</p>
<p>LLM Evaluation. Recently, LLM-as-a-Judge strategy (Pan et al., 2023) has been widely used in evaluating generation tasks. Some works reveal minimal deviation of GPT-4's evaluation from humans ( $&gt;0.85$ agreements) in dialog quality (Zhang et al., 2023a). Inspired by this, we employ the GPT-4 as an advanced evaluator, using two common methods to assess the quality of generated responses. (1) Single model evaluation (Lu et al., 2023a): we prompt GPT-4 to rate the responses individually from the three aspects, i.e., engagingness, coherence and consistency with an integer scale from 1 (very bad) to 100 (very good). (2) Pairwise model evaluation (Dubois et al., 2024): we ask the GPT-4 to directly compare two anonymous generations and determine which response is better. While single model evaluation provides detailed insights into specific aspects of each response, pairwise comparison is essential for understanding relative performance, particularly when distinguishing subtle differences between outputs.</p>
<h1>5.3. Baselines</h1>
<p>We mainly employ the following methods for long-text dialogues in LLMs: context-only approaches (without using any memory), retrieval-based approaches (with different retrievers), and memory-based approaches (with different memory mechanisms)</p>
<p>Context-only Approach. It is the most naive approach to directly employ the LLM as a chatbot, where it concatenates past sessions and current dialogue context as</p>
<p>the input. We use "Llama2-7B" (Touvron et al., 2023), "ChatGLM2-6B"5, and OpenAI ChatGPT "gpt-3.5-turbo-0301" as the backbone LLMs for the contextonly approach ${ }^{6}$.</p>
<p>Retrieval-based Approach. Many previous works (Xu et al., 2022a) employ retrievers to filter key information and then include top- $k$ documents into inputs to assist long-context dialogs. For the long-term dialog, the top- $k$ documents refer to the relevant utterances from history. Here, we choose two widely used retrieval algorithms, i.e., BM25 (Robertson et al., 2009) and pre-trained dense passage retrieval (DPR) (Karpukhin et al., 2020), to look up the relevant utterances from past sessions. For convenience, we name the above retrieval-based baselines as ChatGPT-BM25 and ChatGPT-DPR, respectively.</p>
<p>Memory-based Approach. Recent works employ a summarizer to abstract important information from the past to aid long-term conversation. Simply, we just choose two representative methods from various memory-based techniques, MemoryBank (Zhong et al., 2024) and MemoChat (Lu et al., 2023a). MemoryBank proposes a human-like long-term memory mechanism, which creates ordered summaries of past dialogs with timestamps, and then reorganizes them to obtain the global memory. The memory will be forgotten and updated by Ebbinghaus's forgetting curve. Here, we plug MemoryBank with ChatGPT as a strong baseline, named ChatGPT-MemoryBank. Differently, MemoChat maintains the structured conversational memory to aid long-term dialogue, i.e., generating the summaries for each dialogue topic. We plug the MemoChat into ChatGPT, named</p>
<p><sup id="fnref5:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>ChatGPT-MemoChat, for a fair comparison with others.
Note that our approach focuses on the zero-shot setting for LLMs to engage in a long-term dialog, making the comparisons with other fine-tuned models unfair.</p>
<h1>5.4. Implementation</h1>
<p>We implement our method by letting the LLM response using recursively generated memory in a long-term dialogue, thus it is called as "LLM-Rsum".</p>
<p>Backbone LLMs. We employ OpenAI ChatGPT "gpt-3.5-turbo-0301", "Llama2$7 B$ " and "ChatGLM2-6B" in the main experiments, "text-davinci-003" and "Llama2$7 B$ " (Touvron et al., 2023) in the analysis to show the universality, "longlora$8 k$ " (Chen et al., 2024b) and ChatGPT-16k "gpt-3.5-turbo-16k" as the backbones of complementary discussion. Unless otherwise specified, we employ the same LLM to finish the memory iteration and memory-based response generation. During generation, we set the temperatures of all LLMs as 0 for fair comparisons. The max length of input tokens for Carecall and MSC datasets is no more than 4 k , thus all backbone LLMs in experiments can process the entire dialog context.</p>
<p>Retrievers. Considering the scale of past utterances is not large enough to use the FAISS (Research, 2019), we choose the top-k most relevant utterances that will be combined with ongoing dialogues, prompting the LLM to respond. Following previous works (Xu et al., 2022a) for long-term dialogs, the k is set into 3 and 5.</p>
<p>Memory-based Approaches. The implementation and prompt design of the MemoryBank and Memochat methods are based on the code publicly released in their original papers. For details, please refer to the original papers.</p>
<p>Table 3: Comparison of automatic and human evaluations among different methods on MSC and Carecall datasets, reporting the quality of generated response. The "BScore", "Enga.", "Cohe" and "Cons" are the abbreviations of BertScore, Engagingness, Coherence, and Consistency. The best value is bolded.</p>
<table>
<thead>
<tr>
<th>Method</th>
<th>MSC Dataset</th>
<th></th>
<th></th>
<th></th>
<th></th>
<th></th>
<th>Carecall Datset</th>
<th></th>
<th></th>
<th></th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td>F1</td>
<td>BLEU-1/2</td>
<td>BScore</td>
<td>Enga.</td>
<td>Cohe.</td>
<td>Cons.</td>
<td>F1</td>
<td>BLEU-1/2</td>
<td>BScore</td>
<td>Enga.</td>
<td>Cohe.</td>
<td>Cons.</td>
</tr>
<tr>
<td>Context-only LLM</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Llama2-7B</td>
<td>16.43</td>
<td>20.96/12.09</td>
<td>84.04</td>
<td>1.32</td>
<td>1.20</td>
<td>1.13</td>
<td>13.71</td>
<td>20.89/12.28</td>
<td>84.49</td>
<td>0.75</td>
<td>0.75</td>
<td>1.00</td>
</tr>
<tr>
<td>ChatGLM2-6B</td>
<td>15.38</td>
<td>21.69/12.51</td>
<td>84.48</td>
<td>1.10</td>
<td>1.15</td>
<td>1.07</td>
<td>13.09</td>
<td>20.59/12.03</td>
<td>84.91</td>
<td>0.66</td>
<td>0.63</td>
<td>0.86</td>
</tr>
<tr>
<td>ChatGPT</td>
<td>19.41</td>
<td>21.23/12.24</td>
<td>86.13</td>
<td>1.83</td>
<td>1.37</td>
<td>1.32</td>
<td>13.69</td>
<td>21.15/12.20</td>
<td>85.53</td>
<td>1.50</td>
<td>1.52</td>
<td>1.43</td>
</tr>
<tr>
<td>Retrieval-based Approach</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>ChatGPT-BM25 (k=3)</td>
<td>19.56</td>
<td>21.60/12.46</td>
<td>85.82</td>
<td>1.72</td>
<td>1.48</td>
<td>1.32</td>
<td>12.64</td>
<td>21.57/12.44</td>
<td>85.24</td>
<td>1.40</td>
<td>1.31</td>
<td>1.31</td>
</tr>
<tr>
<td>ChatGPT-DPR (k=3)</td>
<td>20.23</td>
<td>21.75/12.55</td>
<td>86.04</td>
<td>1.76</td>
<td>1.51</td>
<td>1.34</td>
<td>12.21</td>
<td>21.39/12.35</td>
<td>85.25</td>
<td>1.55</td>
<td>1.35</td>
<td>1.45</td>
</tr>
<tr>
<td>Memory-based Approach</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>ChatGPT-MemoChat</td>
<td>18.93</td>
<td>21.82/12.59</td>
<td>85.99</td>
<td>1.70</td>
<td>1.55</td>
<td>1.35</td>
<td>11.19</td>
<td>21.07/12.18</td>
<td>85.22</td>
<td>1.45</td>
<td>1.20</td>
<td>1.30</td>
</tr>
<tr>
<td>ChatGPT-MemoryBank</td>
<td>20.28</td>
<td>21.82/12.58</td>
<td>86.12</td>
<td>1.78</td>
<td>1.57</td>
<td>1.40</td>
<td>13.15</td>
<td>21.29/12.39</td>
<td>85.34</td>
<td>1.57</td>
<td>1.52</td>
<td>1.68</td>
</tr>
<tr>
<td>ChatGPT-Rsum (Ours)</td>
<td>20.48</td>
<td>21.83/12.59</td>
<td>86.89</td>
<td>1.85</td>
<td>1.60</td>
<td>1.45</td>
<td>14.02</td>
<td>21.64/12.48</td>
<td>86.05</td>
<td>1.62</td>
<td>1.60</td>
<td>1.70</td>
</tr>
</tbody>
</table>
<p>LLM evaluations. We use the GPT-4 model (version "gpt-4-0314") as the evaluator, setting the temperature to 0 when making judgments. The prompts for evaluating the single model and pairwise models are referred to (Lu et al., 2023a) and (Dubois et al., 2024), respectively. All prompts used in the experiments can be seen in Appendix B.</p>
<h1>6. Experimental Results</h1>
<h3>6.1. Main Results</h3>
<p>Automatic Metrics Results. In Table 3, we compare different methods over session 5 in the MSC and Carecall datasets using popular LLMs. Firstly, among the vanilla models ("Llama2-7B", "ChatGLM2-6B", and "ChatGPT"), ChatGPT consistently performs well across two datasets, with competitive scores in BScore, F1 and BLEU-1/2. These results illustrate that ChatGPT is robust enough to handle a</p>
<p>long-term dialog, thus, we leave ChatGPT as the backbone model for our method. Secondly, as expected, the proposed method ("ChatGPT-Rsum") achieves the best performance on both datasets, showing the benefits of using automatically recursive memory. Specifically, our method achieves about $+0.2 \%$ on the F1 score, which is acceptable compared to that in previous works (Xu et al., 2022a). The MSC datasets are harder than other open-domain datasets due to the 3x context, so the slight improvements are normal. Thirdly, retrieval-based methods may not be always helpful in enhancing the quality of generation. From the results, the performances of ChatGPT-BM25 and ChatGPT-DPR are much worse than vanilla ChatGPT in the Carecall dataset, which is completely contrary to that in MSC. The reason is that the chatbot needs to actively guide the dialog topics in the Carecall, thus it is hard to retrieve appropriate and relevant context from the user's query. Therefore, the performance of generated responses will be damaged due to unrelated information.</p>
<p>Human Evaluation Results. We also present the results of human evaluations on different methods in Table 3. From the results, we find that: 1) Most memoryaugmented methods gain higher scores on consistency and coherence than vanilla ChatGPT, proving that maintaining a memory is more effective than using the whole history directly when engaging in a long-term conversation for LLMs; 2) Our method can generate more engaging response than other memory-based baselines (ChatGPT-MemoryBank and ChatGPT-MemoChat). The reason is that continually updating memory actively establishes global dependencies inside past histories, which helps LLMs to better understand the dialog and generate highquality responses.</p>
<p>Table 4: Comparison of evaluation metrics results by GPT-4 across different methods on session 5 in MSC dataset.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Method</th>
<th style="text-align: left;">Engagingness</th>
<th style="text-align: left;">Coherence</th>
<th style="text-align: left;">Consistency</th>
<th style="text-align: left;">Average</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">ChatGPT</td>
<td style="text-align: left;">75.48</td>
<td style="text-align: left;">75.00</td>
<td style="text-align: left;">75.48</td>
<td style="text-align: left;">$\underline{75.32}$</td>
</tr>
<tr>
<td style="text-align: left;">ChatGPT-MemoryBank</td>
<td style="text-align: left;">74.68</td>
<td style="text-align: left;">80.92</td>
<td style="text-align: left;">84.56</td>
<td style="text-align: left;">$\underline{80.05}$</td>
</tr>
<tr>
<td style="text-align: left;">ChatGPT-MemoChat</td>
<td style="text-align: left;">72.32</td>
<td style="text-align: left;">77.36</td>
<td style="text-align: left;">78.96</td>
<td style="text-align: left;">$\underline{76.21}$</td>
</tr>
<tr>
<td style="text-align: left;">ChatGPT-Rsum (Ours)</td>
<td style="text-align: left;">$\mathbf{7 8 . 9 2}$</td>
<td style="text-align: left;">$\mathbf{8 3 . 5 6}$</td>
<td style="text-align: left;">$\mathbf{8 4 . 7 6}$</td>
<td style="text-align: left;">$\underline{\mathbf{8 2 . 4 1}}$</td>
</tr>
</tbody>
</table>
<h1>6.2. LLM Evaluation</h1>
<p>Single Model Evaluation. Table 4 reports the GPT-4's evaluation metrics results on session 5 among various methods in the MSC dataset. Also, the results prove the high agreements between humans (in Table 3) and GPT-4 judgment on the overall quality of generated responses, i.e., ChatGPT-Rsum $&gt;$ ChatGPT-MemoryBank $&gt;$ ChatGPT-MemoChat $&gt;$ ChatGPT. Given this, we mainly present the LLM evaluations in the following experiments to reduce labor costs. Lastly, it is worth noting that compared to human evaluation results, the GPT-4 tends to give higher scores on both sentence coherence and consistency. We suppose that the values of humans and LLMs might not be fully aligned at a fine-grained level, which could be a new direction for developing LLM evaluation.</p>
<p>Pairwise Models Evaluation. Furthermore, we randomly sample 1000 generated responses from pairwise models, i.e., ours vs. baselines, and then ask the GPT-4 to decide which response is better based on engagingness, consistency, and coherency. The results are shown in Figure 4. Compared to the most competitive baseline (MemoryBank), our proposed method obtains a $36.3 \%$ improvement (winning $48.2 \%$ and only losing $11.9 \%$ ), which illustrates the advancement of the proposed iteration mechanism.</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>${ }^{5}$ https://github.com/THUDM/ChatGLM2-6B
${ }^{6}$ For convenience's sake, the following "ChatGPT" refer to the gpt-3.5-turbo-0301 version.&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref3:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref4:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref5:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>