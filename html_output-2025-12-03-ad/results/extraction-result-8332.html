<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-8332 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-8332</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-8332</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-153.html">extraction-schema-153</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models (LLMs) being evaluated on puzzle games that require spatial knowledge (such as Sudoku, Rubik's Cube, Minesweeper, etc.), including details of the models, the puzzles, the evaluation setup, the mechanisms or strategies used by the models, performance metrics, evidence of spatial reasoning, comparisons to other models or humans, and any reported limitations or failure cases.</div>
                <p><strong>Paper ID:</strong> paper-547c2cc8d45c22eaba7c7eb34d4e11a7d95a9cff</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/547c2cc8d45c22eaba7c7eb34d4e11a7d95a9cff" target="_blank">Advancing Spatial Reasoning in Large Language Models: An In-Depth Evaluation and Enhancement Using the StepGame Benchmark</a></p>
                <p><strong>Paper Venue:</strong> AAAI Conference on Artificial Intelligence</p>
                <p><strong>Paper TL;DR:</strong> This research analyzes GPT’s spatial reasoning performance on the rectified benchmark, identifying proficiency in mapping natural language text to spatial relations but limitations in multi-hop reasoning, and proposes enhancements to improve spatial reasoning capabilities.</p>
                <p><strong>Paper Abstract:</strong> Artificial intelligence (AI) has made remarkable progress across various domains, with large language models like ChatGPT gaining substantial attention for their human-like text-generation capabilities. Despite these achievements, improving spatial reasoning remains a significant challenge for these models. Benchmarks like StepGame evaluate AI spatial reasoning, where ChatGPT has shown unsatisfactory performance. However, the presence of template errors in the benchmark has an impact on the evaluation results. Thus there is potential for ChatGPT to perform better if these template errors are addressed, leading to more accurate assessments of its spatial reasoning capabilities. In this study, we refine the StepGame benchmark, providing a more accurate dataset for model evaluation. We analyze GPT’s spatial reasoning performance on the rectified benchmark, identifying proficiency in mapping natural language text to spatial relations but limitations in multi-hop reasoning. We provide a flawless solution to the benchmark by combining template-to-relation mapping with logic-based reasoning. This combination demonstrates proficiency in performing qualitative reasoning on StepGame without encountering any errors. We then address the limitations of GPT models in spatial reasoning. To improve spatial reasoning, we deploy Chain-of-Thought and Tree-of-thoughts prompting strategies, offering insights into GPT’s cognitive process. Our investigation not only sheds light on model deficiencies but also proposes enhancements, contributing to the advancement of AI with more robust spatial reasoning capabilities.</p>
                <p><strong>Cost:</strong> 0.017</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e8332.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e8332.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models (LLMs) being evaluated on puzzle games that require spatial knowledge (such as Sudoku, Rubik's Cube, Minesweeper, etc.), including details of the models, the puzzles, the evaluation setup, the mechanisms or strategies used by the models, performance metrics, evidence of spatial reasoning, comparisons to other models or humans, and any reported limitations or failure cases.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GPT-4</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Generative Pre-trained Transformer 4</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>State-of-the-art large language model from OpenAI used in this paper to evaluate multi-hop directional spatial reasoning on the StepGame benchmark using baseline, Chain-of-Thought (CoT), and Tree-of-Thoughts (ToT) prompting.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-4</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Large pretrained transformer-based language model from OpenAI; used via API in experiments. Treated as the largest-capacity LLM in this study and evaluated on StepGame with base prompting, CoT, and ToT+CoT strategies.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>puzzle_name</strong></td>
                            <td>StepGame</td>
                        </tr>
                        <tr>
                            <td><strong>puzzle_type</strong></td>
                            <td>Synthetic multi-hop directional spatial reasoning benchmark (2D grid-like directional relations: above/below/left/right and four diagonals); requires chaining relations (k-hop inference) and coordinate-like inference.</td>
                        </tr>
                        <tr>
                            <td><strong>task_setup</strong></td>
                            <td>Inputs are natural-language 'stories' containing k relational sentences and a question about relation between two objects. Experiments used few-shot prompting (several variants: clean 5shot(1,3,5,7,10), clean 10shot, clean 5shot separate), temperature 0 for CoT, temperature 0.7 for ToT thought generation. Evaluations run on cleaned/corrected StepGame subsets (clean set) with test sizes of 30, 100, and 1000 examples for different experiments; for some ToT results GPT-4 was evaluated on a 20-instance test set due to token costs.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanisms_or_strategies</strong></td>
                            <td>Baseline direct prompting; customized Chain-of-Thought (CoT) with decomposed thoughts (link establishment, relation mapping, coordinate calculation) and offset-based coordinate arithmetic; Tree-of-Thoughts (ToT) adapted to build linking chains (generate multiple candidate chain expansions, evaluate states, select top b states) then perform CoT coordinate reasoning; use of offsets for 9 relations to compute coordinates.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Reported per-hop accuracies (k=1..10) from Table 4. Base: [100,70,55,45,40,25,40,35,35,25] (k=1..10). CoT: [/,80,75,95,85,85,90,80,60,65] ('/' indicates not reported for k=1). ToT_CoT: [/,/,85,85,90,90,85,90,100,95]. (Some ToT results reported on a small test set of 20 instances).</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_of_spatial_reasoning</strong></td>
                            <td>Qualitative and quantitative evidence: GPT-4 exhibits ability to map natural-language relation sentences to directional relations and to perform coordinate arithmetic when guided by CoT (explicit coordinate-calculation thoughts). ToT improves ability to find correct multi-hop linking chains. Improvements in accuracy under CoT/ToT (compared to base) indicate the model uses intermediate representation/stepwise reasoning induced by prompting, consistent with performing spatial chaining and coordinate computation.</td>
                        </tr>
                        <tr>
                            <td><strong>comparisons</strong></td>
                            <td>Compared against Davinci, Turbo (gpt-3.5-turbo), Curie+ASP, Davinci+ASP, a Map+ASP logic solution and the SOTA (GPT-3 parser + ASP) in Table 4. GPT-4 outperforms Davinci and Turbo across most configurations; ToT+CoT GPT-4 achieves near-SOTA/perfect performance on higher hops (e.g., 100% at k=9, 95% at k=10 reported). Map+ASP achieves 100% across hops (logic solution). SOTA (Yang et al.) reported ~88.3% at k=10; GPT-4 ToT+CoT exceeds that on the corrected dataset in these experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Performance drops markedly with increasing hops under baseline prompting (sharp fall from k=1 to higher k). CoT can sometimes reduce accuracy for complex k-hop tasks if chains are long and error-prone, but the customized CoT here improved performance for GPT-4. ToT results for GPT-4 are based on a small test set (20 instances) so reported high numbers may have high variance. Dataset issues: original StepGame template errors required dataset correction; some remaining semantic-parsing errors exist, and two-of-1000 errors in Davinci+ASP were due to parsing. Computational and token cost limits constrained larger-scale ToT evaluation (GPT-4 ToT on 20 examples).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Advancing Spatial Reasoning in Large Language Models: An In-Depth Evaluation and Enhancement Using the StepGame Benchmark', 'publication_date_yy_mm': '2024-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8332.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e8332.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models (LLMs) being evaluated on puzzle games that require spatial knowledge (such as Sudoku, Rubik's Cube, Minesweeper, etc.), including details of the models, the puzzles, the evaluation setup, the mechanisms or strategies used by the models, performance metrics, evidence of spatial reasoning, comparisons to other models or humans, and any reported limitations or failure cases.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Davinci</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>text-davinci-003 (GPT-3 family)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>High-capacity GPT-3 family model (text-davinci-003) used for relation extraction and as an LLM reasoner with base prompting, CoT, and ToT+CoT on StepGame.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>text-davinci-003 (Davinci)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>APT-family autoregressive transformer (OpenAI Davinci variant of GPT-3 family) accessed via API; used with different prompting strategies (base, CoT, ToT+CoT) and also combined with ASP for a hybrid pipeline (Davinci+ASP).</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>puzzle_name</strong></td>
                            <td>StepGame</td>
                        </tr>
                        <tr>
                            <td><strong>puzzle_type</strong></td>
                            <td>Synthetic multi-hop directional spatial reasoning benchmark (2D directional relations requiring chain inference).</td>
                        </tr>
                        <tr>
                            <td><strong>task_setup</strong></td>
                            <td>Few-shot prompting (5shot separate for per-k CoT baselines; 10shot used elsewhere); CoT with decomposed thought types; ToT used to build linking chain via GPT-4 and then Davinci used for CoT reasoning in ToT_CoT experiments. Temperature set to 0 for CoT; ToT generation used nonzero temperature for diversity when appropriate.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanisms_or_strategies</strong></td>
                            <td>Baseline prompting; custom CoT (link/map/calcu thought decomposition); ToT_CoT where GPT-4 constructs link chain and Davinci performs CoT reasoning along chain; also Davinci used as semantic parser in a pipeline with ASP reasoning (Davinci+ASP).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>From Table 4 per-hop accuracies (k=1..10). Base: [77,42,21,26,25,30,23,23,22,22]. CoT: [/,48,53,46,46,48,40,45,41,32]. ToT_CoT: [/,/,65,50,45,60,50,50,55,50]. Davinci+ASP (hybrid) on corrected dataset: [100,100,99,100,100,99,100,100,100,100] (k=1..10) with only 2 errors among 1000 examples reportedly due to semantic parsing.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_of_spatial_reasoning</strong></td>
                            <td>Davinci demonstrates good relation-extraction performance when combined with an ASP reasoner (Davinci+ASP yields near-perfect scores on corrected data), indicating it can map NL sentences to relation symbols though occasional parsing errors occur; with CoT and ToT prompting, Davinci's multi-hop performance improves substantially, showing capability to follow chain-based spatial reasoning when guided.</td>
                        </tr>
                        <tr>
                            <td><strong>comparisons</strong></td>
                            <td>Davinci outperforms Turbo in base and CoT settings; Davinci+ASP (hybrid) approaches Map+ASP logic performance on corrected dataset (near 100%). Compared to SOTA (GPT-3+ASP reported ~88-93%), Davinci+ASP on corrected data yields near-perfect accuracy.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Baseline performance degrades quickly with hop count. CoT and ToT help but are sensitive to prompt length and model capacity; some semantic parsing errors (examples given) cause remaining errors in hybrid pipelines. ToT_CoT improvements are variable across hops. Token and cost limits constrained large-scale ToT evaluation.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Advancing Spatial Reasoning in Large Language Models: An In-Depth Evaluation and Enhancement Using the StepGame Benchmark', 'publication_date_yy_mm': '2024-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8332.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e8332.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models (LLMs) being evaluated on puzzle games that require spatial knowledge (such as Sudoku, Rubik's Cube, Minesweeper, etc.), including details of the models, the puzzles, the evaluation setup, the mechanisms or strategies used by the models, performance metrics, evidence of spatial reasoning, comparisons to other models or humans, and any reported limitations or failure cases.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>gpt-3.5-turbo</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>gpt-3.5-turbo (ChatGPT / Turbo)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>OpenAI 3.5-series model (turbo) evaluated on StepGame with base prompting, CoT, and ToT+CoT; used both as a reasoner and as part of ToT_CoT pipelines.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>gpt-3.5-turbo</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Chat-style, cost-efficient OpenAI model (Turbo / GPT-3.5 family) used via Azure OpenAI; evaluated with similar prompting regimes (base, CoT, ToT) to compare capacity versus Davinci and GPT-4.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>puzzle_name</strong></td>
                            <td>StepGame</td>
                        </tr>
                        <tr>
                            <td><strong>puzzle_type</strong></td>
                            <td>Synthetic multi-hop directional spatial reasoning benchmark.</td>
                        </tr>
                        <tr>
                            <td><strong>task_setup</strong></td>
                            <td>Few-shot prompting (10shot, 5shot variants), CoT with temperature 0, ToT with temperature 0.7 for thought generation; ToT_CoT pipeline uses GPT-4 to build chains and Turbo to perform CoT reasoning in some experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanisms_or_strategies</strong></td>
                            <td>Baseline prompting; customized CoT (link/map/calcu); ToT_CoT where GPT-4 constructs link chains and Turbo runs CoT reasoning along the chain; hybrid experiments with ASP in some comparisons (e.g., SOTA or other pipelines).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>From Table 4 per-hop accuracies (k=1..10). Base: [62,43,30,35,29,25,29,31,16,20]. CoT: [/,34,40,36,28,28,26,31,25,24]. ToT_CoT: [/,/,35,35,25,45,15,40,40,35].</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_of_spatial_reasoning</strong></td>
                            <td>Turbo can map text to spatial relations at lower hops and shows limited ability to perform multi-hop coordinate reasoning when prompted with CoT/ToT, but its gains are smaller than larger models (Davinci, GPT-4). The model improves under CoT/ToT but remains substantially weaker on high-hop tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>comparisons</strong></td>
                            <td>Turbo generally underperforms Davinci and GPT-4 on StepGame; gap larger at lower hops, somewhat converging at higher hops. ToT+CoT and CoT provide modest improvements but not to the level of Davinci or GPT-4.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Lower capacity leads to worse relation extraction and chain-following; struggles with long prompts requiring precise coordinate arithmetic. ToT gains are inconsistent and sometimes small; baseline accuracy declines sharply with hops.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Advancing Spatial Reasoning in Large Language Models: An In-Depth Evaluation and Enhancement Using the StepGame Benchmark', 'publication_date_yy_mm': '2024-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8332.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e8332.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models (LLMs) being evaluated on puzzle games that require spatial knowledge (such as Sudoku, Rubik's Cube, Minesweeper, etc.), including details of the models, the puzzles, the evaluation setup, the mechanisms or strategies used by the models, performance metrics, evidence of spatial reasoning, comparisons to other models or humans, and any reported limitations or failure cases.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Curie</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>text-curie-001</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A smaller GPT-3 family model analyzed for relation-extraction performance and used in comparisons; exhibits the highest number of incorrect relation-extraction predictions among models evaluated.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>text-curie-001 (Curie)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Mid-capacity OpenAI GPT-3 family model. Evaluated mainly for relation-extraction subtask and in Curie+ASP hybrid pipeline.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>puzzle_name</strong></td>
                            <td>StepGame</td>
                        </tr>
                        <tr>
                            <td><strong>puzzle_type</strong></td>
                            <td>Synthetic 2D directional multi-hop spatial reasoning benchmark.</td>
                        </tr>
                        <tr>
                            <td><strong>task_setup</strong></td>
                            <td>Relation-extraction experiments and hybrid Curie+ASP evaluation on corrected StepGame; few-shot prompting used for relation-extraction. Curie+ASP results reported in Table 4 (accuracies per hop).</td>
                        </tr>
                        <tr>
                            <td><strong>mechanisms_or_strategies</strong></td>
                            <td>Used as a semantic parser to map NL sentences to symbolic relations, then ASP for logical multi-hop reasoning (Curie+ASP).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Curie+ASP hybrid accuracy (k=1..10): [46,43,42,59,67,67,57,56,58,61] (Table 4). Relation-extraction error counts by relation shown in Table 3: Curie had the most incorrect predictions across relation types (counts per relation groups shown in paper).</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_of_spatial_reasoning</strong></td>
                            <td>Curie can map text to relations in some cases but exhibits high error rates in relation extraction compared to Davinci and Turbo; when paired with ASP, performance remains substantially below Davinci+ASP and Map+ASP, indicating limited reliable spatial parsing.</td>
                        </tr>
                        <tr>
                            <td><strong>comparisons</strong></td>
                            <td>Underperforms Davinci and Turbo in relation extraction subtask; Curie+ASP much lower accuracy than Davinci+ASP and Map+ASP. Table 3 shows Curie had more incorrect relation-extraction predictions than Davinci and gpt-3.5-turbo.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>High relation-extraction error rate; Curie+ASP accuracy remains low, indicating difficulty in robust semantic parsing of the templated sentences in StepGame. Not competitive for multi-hop reasoning without substantial improvements in parsing.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Advancing Spatial Reasoning in Large Language Models: An In-Depth Evaluation and Enhancement Using the StepGame Benchmark', 'publication_date_yy_mm': '2024-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8332.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e8332.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models (LLMs) being evaluated on puzzle games that require spatial knowledge (such as Sudoku, Rubik's Cube, Minesweeper, etc.), including details of the models, the puzzles, the evaluation setup, the mechanisms or strategies used by the models, performance metrics, evidence of spatial reasoning, comparisons to other models or humans, and any reported limitations or failure cases.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GPT-3 + ASP (SOTA)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>GPT-3 semantic parsing + ASP reasoning (Yang, Ishay, and Lee 2023)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Prior state-of-the-art hybrid pipeline that uses GPT-3 (semantic parsing) to convert natural-language spatial descriptions into symbolic relations, then applies an Answer Set Programming (ASP) reasoner for multi-hop spatial inference on StepGame.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Coupling Large Language Models with Logic Programming for Robust and General Reasoning from Text</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-3 (semantic parser) + ASP reasoner</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Hybrid system: GPT-3 used to parse natural language spatial statements into symbolic relation representations; these facts are fed to an ASP solver (Clingo) implementing 2D grid offsets and inference rules to compute multi-hop relations.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>puzzle_name</strong></td>
                            <td>StepGame</td>
                        </tr>
                        <tr>
                            <td><strong>puzzle_type</strong></td>
                            <td>Synthetic multi-hop directional spatial reasoning benchmark.</td>
                        </tr>
                        <tr>
                            <td><strong>task_setup</strong></td>
                            <td>Semantic parsing by GPT-3 into symbolic relations followed by ASP-based reasoning rules modeling 9 spatial relations with offsets; evaluated on StepGame. The present paper re-evaluates this approach on the corrected dataset.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanisms_or_strategies</strong></td>
                            <td>LLM-based semantic parsing to symbolic facts + declarative logical reasoning via ASP (offset arithmetic rules) to perform provably correct multi-hop inference (no LLM in the reasoning stage).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Reported SOTA numbers from Yang et al. in Table 4: approx. [92.6, 89.9, 89.1, 93.8, 92.9, 91.6, 91.2, 90.4, 89.0, 88.3] (k=1..10). They reported ~10.7% faults attributed to data issues. On the corrected dataset this paper reports Curie+ASP and Davinci+ASP evaluations; Davinci+ASP had only 2 errors in 1000 examples.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_of_spatial_reasoning</strong></td>
                            <td>Strong evidence: the ASP reasoner implements exact offset-based composition rules resulting in high accuracy; failures mainly due to semantic parsing mistakes or dataset template issues rather than inference logic.</td>
                        </tr>
                        <tr>
                            <td><strong>comparisons</strong></td>
                            <td>SOTA hybrid pipeline outperformed vanilla LLM-only baseline approaches previously reported; the present paper's Map+ASP (template-based mapping + ASP) achieves 100% and the present ToT+CoT GPT-4 approach approaches or exceeds SOTA on corrected data in some settings.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Dependence on quality of semantic parsing (GPT-3 errors produce incorrect symbolic facts). The original SOTA authors attributed ~10.7% errors to data/template issues in StepGame; some templates were irreparable. The approach requires coupling to ASP rules and prior knowledge of relation offsets; not a pure LLM-only spatial reasoner.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Advancing Spatial Reasoning in Large Language Models: An In-Depth Evaluation and Enhancement Using the StepGame Benchmark', 'publication_date_yy_mm': '2024-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8332.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e8332.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models (LLMs) being evaluated on puzzle games that require spatial knowledge (such as Sudoku, Rubik's Cube, Minesweeper, etc.), including details of the models, the puzzles, the evaluation setup, the mechanisms or strategies used by the models, performance metrics, evidence of spatial reasoning, comparisons to other models or humans, and any reported limitations or failure cases.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Map+ASP</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Template-to-Relation Mapping + ASP logical reasoner</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A deterministic, logic-based pipeline introduced in this paper that maps template sentences to symbolic relations via exact template matching and then uses an ASP reasoner (Clingo) with offset rules to compute multi-hop spatial relations; reported to be essentially error-free on the corrected StepGame.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Map+ASP (template mapping + ASP)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Non-LLM logic solution: (1) template-based sentence-to-relation mapping (semantic parsing by matching to template base), (2) ASP rules encoding 2D offsets for 9 relations and composition rules to compute multi-hop relations; implemented in Clingo.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>puzzle_name</strong></td>
                            <td>StepGame</td>
                        </tr>
                        <tr>
                            <td><strong>puzzle_type</strong></td>
                            <td>Synthetic multi-hop directional spatial reasoning benchmark on a 2D grid; suited to symbolic offset reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>task_setup</strong></td>
                            <td>Corrected StepGame dataset (templates fixed/filtered); sentences are matched to template keys and converted to symbolic facts; ASP program computes positions via offsets and infers final relation. No LLM used for reasoning or parsing (parsing done by exact template matching).</td>
                        </tr>
                        <tr>
                            <td><strong>mechanisms_or_strategies</strong></td>
                            <td>Exact template-to-relation mapping (semantic-parsing by template lookup) + ASP with offset arithmetic representing 9 relations; deterministic logical inference yields composed coordinates and target relation.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Reported as 100% accuracy across k=1..10 on corrected StepGame (Table 4: Map+ASP row lists 100 for all hops). The authors state '100% accuracy for almost all hops' and for their template-to-relation mapping + ASP they report achieving perfect score on corrected benchmark.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_of_spatial_reasoning</strong></td>
                            <td>Because the system explicitly uses offsets for relations and composes them via ASP rules, it performs exact multi-hop spatial reasoning (qualitative/coordinate composition) and provides a flawless solution on corrected templates. This is direct evidence that the task is solvable by symbolic spatial reasoning when ground truth relation extraction is provided.</td>
                        </tr>
                        <tr>
                            <td><strong>comparisons</strong></td>
                            <td>Outperforms LLM-only baselines (GPT variants) and beats the previously reported SOTA (GPT-3+ASP) on the corrected dataset; serves as an upper-bound reference demonstrating correctness when parsing errors and template issues are removed.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Requires prior knowledge of templates and cannot generalize to unseen natural-language phrasings without updating the template base; four template types in original StepGame were irreparable and had to be removed in dataset cleaning. Not robust to free-form natural language or varying ontologies without manual template/ASP updates.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Advancing Spatial Reasoning in Large Language Models: An In-Depth Evaluation and Enhancement Using the StepGame Benchmark', 'publication_date_yy_mm': '2024-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Stepgame: A new benchmark for robust multi-hop spatial reasoning in texts <em>(Rating: 2)</em></li>
                <li>Coupling Large Language Models with Logic Programming for Robust and General Reasoning from Text <em>(Rating: 2)</em></li>
                <li>Tree of thoughts: Deliberate problem solving with large language models <em>(Rating: 2)</em></li>
                <li>SpartQA: A Textual Question Answering Benchmark for Spatial Reasoning <em>(Rating: 1)</em></li>
                <li>A multitask, multilingual, multimodal evaluation of ChatGPT on reasoning, hallucination, and interactivity <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-8332",
    "paper_id": "paper-547c2cc8d45c22eaba7c7eb34d4e11a7d95a9cff",
    "extraction_schema_id": "extraction-schema-153",
    "extracted_data": [
        {
            "name_short": "GPT-4",
            "name_full": "Generative Pre-trained Transformer 4",
            "brief_description": "State-of-the-art large language model from OpenAI used in this paper to evaluate multi-hop directional spatial reasoning on the StepGame benchmark using baseline, Chain-of-Thought (CoT), and Tree-of-Thoughts (ToT) prompting.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "GPT-4",
            "model_description": "Large pretrained transformer-based language model from OpenAI; used via API in experiments. Treated as the largest-capacity LLM in this study and evaluated on StepGame with base prompting, CoT, and ToT+CoT strategies.",
            "model_size": null,
            "puzzle_name": "StepGame",
            "puzzle_type": "Synthetic multi-hop directional spatial reasoning benchmark (2D grid-like directional relations: above/below/left/right and four diagonals); requires chaining relations (k-hop inference) and coordinate-like inference.",
            "task_setup": "Inputs are natural-language 'stories' containing k relational sentences and a question about relation between two objects. Experiments used few-shot prompting (several variants: clean 5shot(1,3,5,7,10), clean 10shot, clean 5shot separate), temperature 0 for CoT, temperature 0.7 for ToT thought generation. Evaluations run on cleaned/corrected StepGame subsets (clean set) with test sizes of 30, 100, and 1000 examples for different experiments; for some ToT results GPT-4 was evaluated on a 20-instance test set due to token costs.",
            "mechanisms_or_strategies": "Baseline direct prompting; customized Chain-of-Thought (CoT) with decomposed thoughts (link establishment, relation mapping, coordinate calculation) and offset-based coordinate arithmetic; Tree-of-Thoughts (ToT) adapted to build linking chains (generate multiple candidate chain expansions, evaluate states, select top b states) then perform CoT coordinate reasoning; use of offsets for 9 relations to compute coordinates.",
            "performance_metrics": "Reported per-hop accuracies (k=1..10) from Table 4. Base: [100,70,55,45,40,25,40,35,35,25] (k=1..10). CoT: [/,80,75,95,85,85,90,80,60,65] ('/' indicates not reported for k=1). ToT_CoT: [/,/,85,85,90,90,85,90,100,95]. (Some ToT results reported on a small test set of 20 instances).",
            "evidence_of_spatial_reasoning": "Qualitative and quantitative evidence: GPT-4 exhibits ability to map natural-language relation sentences to directional relations and to perform coordinate arithmetic when guided by CoT (explicit coordinate-calculation thoughts). ToT improves ability to find correct multi-hop linking chains. Improvements in accuracy under CoT/ToT (compared to base) indicate the model uses intermediate representation/stepwise reasoning induced by prompting, consistent with performing spatial chaining and coordinate computation.",
            "comparisons": "Compared against Davinci, Turbo (gpt-3.5-turbo), Curie+ASP, Davinci+ASP, a Map+ASP logic solution and the SOTA (GPT-3 parser + ASP) in Table 4. GPT-4 outperforms Davinci and Turbo across most configurations; ToT+CoT GPT-4 achieves near-SOTA/perfect performance on higher hops (e.g., 100% at k=9, 95% at k=10 reported). Map+ASP achieves 100% across hops (logic solution). SOTA (Yang et al.) reported ~88.3% at k=10; GPT-4 ToT+CoT exceeds that on the corrected dataset in these experiments.",
            "limitations_or_failure_cases": "Performance drops markedly with increasing hops under baseline prompting (sharp fall from k=1 to higher k). CoT can sometimes reduce accuracy for complex k-hop tasks if chains are long and error-prone, but the customized CoT here improved performance for GPT-4. ToT results for GPT-4 are based on a small test set (20 instances) so reported high numbers may have high variance. Dataset issues: original StepGame template errors required dataset correction; some remaining semantic-parsing errors exist, and two-of-1000 errors in Davinci+ASP were due to parsing. Computational and token cost limits constrained larger-scale ToT evaluation (GPT-4 ToT on 20 examples).",
            "uuid": "e8332.0",
            "source_info": {
                "paper_title": "Advancing Spatial Reasoning in Large Language Models: An In-Depth Evaluation and Enhancement Using the StepGame Benchmark",
                "publication_date_yy_mm": "2024-01"
            }
        },
        {
            "name_short": "Davinci",
            "name_full": "text-davinci-003 (GPT-3 family)",
            "brief_description": "High-capacity GPT-3 family model (text-davinci-003) used for relation extraction and as an LLM reasoner with base prompting, CoT, and ToT+CoT on StepGame.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "text-davinci-003 (Davinci)",
            "model_description": "APT-family autoregressive transformer (OpenAI Davinci variant of GPT-3 family) accessed via API; used with different prompting strategies (base, CoT, ToT+CoT) and also combined with ASP for a hybrid pipeline (Davinci+ASP).",
            "model_size": null,
            "puzzle_name": "StepGame",
            "puzzle_type": "Synthetic multi-hop directional spatial reasoning benchmark (2D directional relations requiring chain inference).",
            "task_setup": "Few-shot prompting (5shot separate for per-k CoT baselines; 10shot used elsewhere); CoT with decomposed thought types; ToT used to build linking chain via GPT-4 and then Davinci used for CoT reasoning in ToT_CoT experiments. Temperature set to 0 for CoT; ToT generation used nonzero temperature for diversity when appropriate.",
            "mechanisms_or_strategies": "Baseline prompting; custom CoT (link/map/calcu thought decomposition); ToT_CoT where GPT-4 constructs link chain and Davinci performs CoT reasoning along chain; also Davinci used as semantic parser in a pipeline with ASP reasoning (Davinci+ASP).",
            "performance_metrics": "From Table 4 per-hop accuracies (k=1..10). Base: [77,42,21,26,25,30,23,23,22,22]. CoT: [/,48,53,46,46,48,40,45,41,32]. ToT_CoT: [/,/,65,50,45,60,50,50,55,50]. Davinci+ASP (hybrid) on corrected dataset: [100,100,99,100,100,99,100,100,100,100] (k=1..10) with only 2 errors among 1000 examples reportedly due to semantic parsing.",
            "evidence_of_spatial_reasoning": "Davinci demonstrates good relation-extraction performance when combined with an ASP reasoner (Davinci+ASP yields near-perfect scores on corrected data), indicating it can map NL sentences to relation symbols though occasional parsing errors occur; with CoT and ToT prompting, Davinci's multi-hop performance improves substantially, showing capability to follow chain-based spatial reasoning when guided.",
            "comparisons": "Davinci outperforms Turbo in base and CoT settings; Davinci+ASP (hybrid) approaches Map+ASP logic performance on corrected dataset (near 100%). Compared to SOTA (GPT-3+ASP reported ~88-93%), Davinci+ASP on corrected data yields near-perfect accuracy.",
            "limitations_or_failure_cases": "Baseline performance degrades quickly with hop count. CoT and ToT help but are sensitive to prompt length and model capacity; some semantic parsing errors (examples given) cause remaining errors in hybrid pipelines. ToT_CoT improvements are variable across hops. Token and cost limits constrained large-scale ToT evaluation.",
            "uuid": "e8332.1",
            "source_info": {
                "paper_title": "Advancing Spatial Reasoning in Large Language Models: An In-Depth Evaluation and Enhancement Using the StepGame Benchmark",
                "publication_date_yy_mm": "2024-01"
            }
        },
        {
            "name_short": "gpt-3.5-turbo",
            "name_full": "gpt-3.5-turbo (ChatGPT / Turbo)",
            "brief_description": "OpenAI 3.5-series model (turbo) evaluated on StepGame with base prompting, CoT, and ToT+CoT; used both as a reasoner and as part of ToT_CoT pipelines.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "gpt-3.5-turbo",
            "model_description": "Chat-style, cost-efficient OpenAI model (Turbo / GPT-3.5 family) used via Azure OpenAI; evaluated with similar prompting regimes (base, CoT, ToT) to compare capacity versus Davinci and GPT-4.",
            "model_size": null,
            "puzzle_name": "StepGame",
            "puzzle_type": "Synthetic multi-hop directional spatial reasoning benchmark.",
            "task_setup": "Few-shot prompting (10shot, 5shot variants), CoT with temperature 0, ToT with temperature 0.7 for thought generation; ToT_CoT pipeline uses GPT-4 to build chains and Turbo to perform CoT reasoning in some experiments.",
            "mechanisms_or_strategies": "Baseline prompting; customized CoT (link/map/calcu); ToT_CoT where GPT-4 constructs link chains and Turbo runs CoT reasoning along the chain; hybrid experiments with ASP in some comparisons (e.g., SOTA or other pipelines).",
            "performance_metrics": "From Table 4 per-hop accuracies (k=1..10). Base: [62,43,30,35,29,25,29,31,16,20]. CoT: [/,34,40,36,28,28,26,31,25,24]. ToT_CoT: [/,/,35,35,25,45,15,40,40,35].",
            "evidence_of_spatial_reasoning": "Turbo can map text to spatial relations at lower hops and shows limited ability to perform multi-hop coordinate reasoning when prompted with CoT/ToT, but its gains are smaller than larger models (Davinci, GPT-4). The model improves under CoT/ToT but remains substantially weaker on high-hop tasks.",
            "comparisons": "Turbo generally underperforms Davinci and GPT-4 on StepGame; gap larger at lower hops, somewhat converging at higher hops. ToT+CoT and CoT provide modest improvements but not to the level of Davinci or GPT-4.",
            "limitations_or_failure_cases": "Lower capacity leads to worse relation extraction and chain-following; struggles with long prompts requiring precise coordinate arithmetic. ToT gains are inconsistent and sometimes small; baseline accuracy declines sharply with hops.",
            "uuid": "e8332.2",
            "source_info": {
                "paper_title": "Advancing Spatial Reasoning in Large Language Models: An In-Depth Evaluation and Enhancement Using the StepGame Benchmark",
                "publication_date_yy_mm": "2024-01"
            }
        },
        {
            "name_short": "Curie",
            "name_full": "text-curie-001",
            "brief_description": "A smaller GPT-3 family model analyzed for relation-extraction performance and used in comparisons; exhibits the highest number of incorrect relation-extraction predictions among models evaluated.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "text-curie-001 (Curie)",
            "model_description": "Mid-capacity OpenAI GPT-3 family model. Evaluated mainly for relation-extraction subtask and in Curie+ASP hybrid pipeline.",
            "model_size": null,
            "puzzle_name": "StepGame",
            "puzzle_type": "Synthetic 2D directional multi-hop spatial reasoning benchmark.",
            "task_setup": "Relation-extraction experiments and hybrid Curie+ASP evaluation on corrected StepGame; few-shot prompting used for relation-extraction. Curie+ASP results reported in Table 4 (accuracies per hop).",
            "mechanisms_or_strategies": "Used as a semantic parser to map NL sentences to symbolic relations, then ASP for logical multi-hop reasoning (Curie+ASP).",
            "performance_metrics": "Curie+ASP hybrid accuracy (k=1..10): [46,43,42,59,67,67,57,56,58,61] (Table 4). Relation-extraction error counts by relation shown in Table 3: Curie had the most incorrect predictions across relation types (counts per relation groups shown in paper).",
            "evidence_of_spatial_reasoning": "Curie can map text to relations in some cases but exhibits high error rates in relation extraction compared to Davinci and Turbo; when paired with ASP, performance remains substantially below Davinci+ASP and Map+ASP, indicating limited reliable spatial parsing.",
            "comparisons": "Underperforms Davinci and Turbo in relation extraction subtask; Curie+ASP much lower accuracy than Davinci+ASP and Map+ASP. Table 3 shows Curie had more incorrect relation-extraction predictions than Davinci and gpt-3.5-turbo.",
            "limitations_or_failure_cases": "High relation-extraction error rate; Curie+ASP accuracy remains low, indicating difficulty in robust semantic parsing of the templated sentences in StepGame. Not competitive for multi-hop reasoning without substantial improvements in parsing.",
            "uuid": "e8332.3",
            "source_info": {
                "paper_title": "Advancing Spatial Reasoning in Large Language Models: An In-Depth Evaluation and Enhancement Using the StepGame Benchmark",
                "publication_date_yy_mm": "2024-01"
            }
        },
        {
            "name_short": "GPT-3 + ASP (SOTA)",
            "name_full": "GPT-3 semantic parsing + ASP reasoning (Yang, Ishay, and Lee 2023)",
            "brief_description": "Prior state-of-the-art hybrid pipeline that uses GPT-3 (semantic parsing) to convert natural-language spatial descriptions into symbolic relations, then applies an Answer Set Programming (ASP) reasoner for multi-hop spatial inference on StepGame.",
            "citation_title": "Coupling Large Language Models with Logic Programming for Robust and General Reasoning from Text",
            "mention_or_use": "mention",
            "model_name": "GPT-3 (semantic parser) + ASP reasoner",
            "model_description": "Hybrid system: GPT-3 used to parse natural language spatial statements into symbolic relation representations; these facts are fed to an ASP solver (Clingo) implementing 2D grid offsets and inference rules to compute multi-hop relations.",
            "model_size": null,
            "puzzle_name": "StepGame",
            "puzzle_type": "Synthetic multi-hop directional spatial reasoning benchmark.",
            "task_setup": "Semantic parsing by GPT-3 into symbolic relations followed by ASP-based reasoning rules modeling 9 spatial relations with offsets; evaluated on StepGame. The present paper re-evaluates this approach on the corrected dataset.",
            "mechanisms_or_strategies": "LLM-based semantic parsing to symbolic facts + declarative logical reasoning via ASP (offset arithmetic rules) to perform provably correct multi-hop inference (no LLM in the reasoning stage).",
            "performance_metrics": "Reported SOTA numbers from Yang et al. in Table 4: approx. [92.6, 89.9, 89.1, 93.8, 92.9, 91.6, 91.2, 90.4, 89.0, 88.3] (k=1..10). They reported ~10.7% faults attributed to data issues. On the corrected dataset this paper reports Curie+ASP and Davinci+ASP evaluations; Davinci+ASP had only 2 errors in 1000 examples.",
            "evidence_of_spatial_reasoning": "Strong evidence: the ASP reasoner implements exact offset-based composition rules resulting in high accuracy; failures mainly due to semantic parsing mistakes or dataset template issues rather than inference logic.",
            "comparisons": "SOTA hybrid pipeline outperformed vanilla LLM-only baseline approaches previously reported; the present paper's Map+ASP (template-based mapping + ASP) achieves 100% and the present ToT+CoT GPT-4 approach approaches or exceeds SOTA on corrected data in some settings.",
            "limitations_or_failure_cases": "Dependence on quality of semantic parsing (GPT-3 errors produce incorrect symbolic facts). The original SOTA authors attributed ~10.7% errors to data/template issues in StepGame; some templates were irreparable. The approach requires coupling to ASP rules and prior knowledge of relation offsets; not a pure LLM-only spatial reasoner.",
            "uuid": "e8332.4",
            "source_info": {
                "paper_title": "Advancing Spatial Reasoning in Large Language Models: An In-Depth Evaluation and Enhancement Using the StepGame Benchmark",
                "publication_date_yy_mm": "2024-01"
            }
        },
        {
            "name_short": "Map+ASP",
            "name_full": "Template-to-Relation Mapping + ASP logical reasoner",
            "brief_description": "A deterministic, logic-based pipeline introduced in this paper that maps template sentences to symbolic relations via exact template matching and then uses an ASP reasoner (Clingo) with offset rules to compute multi-hop spatial relations; reported to be essentially error-free on the corrected StepGame.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "Map+ASP (template mapping + ASP)",
            "model_description": "Non-LLM logic solution: (1) template-based sentence-to-relation mapping (semantic parsing by matching to template base), (2) ASP rules encoding 2D offsets for 9 relations and composition rules to compute multi-hop relations; implemented in Clingo.",
            "model_size": null,
            "puzzle_name": "StepGame",
            "puzzle_type": "Synthetic multi-hop directional spatial reasoning benchmark on a 2D grid; suited to symbolic offset reasoning.",
            "task_setup": "Corrected StepGame dataset (templates fixed/filtered); sentences are matched to template keys and converted to symbolic facts; ASP program computes positions via offsets and infers final relation. No LLM used for reasoning or parsing (parsing done by exact template matching).",
            "mechanisms_or_strategies": "Exact template-to-relation mapping (semantic-parsing by template lookup) + ASP with offset arithmetic representing 9 relations; deterministic logical inference yields composed coordinates and target relation.",
            "performance_metrics": "Reported as 100% accuracy across k=1..10 on corrected StepGame (Table 4: Map+ASP row lists 100 for all hops). The authors state '100% accuracy for almost all hops' and for their template-to-relation mapping + ASP they report achieving perfect score on corrected benchmark.",
            "evidence_of_spatial_reasoning": "Because the system explicitly uses offsets for relations and composes them via ASP rules, it performs exact multi-hop spatial reasoning (qualitative/coordinate composition) and provides a flawless solution on corrected templates. This is direct evidence that the task is solvable by symbolic spatial reasoning when ground truth relation extraction is provided.",
            "comparisons": "Outperforms LLM-only baselines (GPT variants) and beats the previously reported SOTA (GPT-3+ASP) on the corrected dataset; serves as an upper-bound reference demonstrating correctness when parsing errors and template issues are removed.",
            "limitations_or_failure_cases": "Requires prior knowledge of templates and cannot generalize to unseen natural-language phrasings without updating the template base; four template types in original StepGame were irreparable and had to be removed in dataset cleaning. Not robust to free-form natural language or varying ontologies without manual template/ASP updates.",
            "uuid": "e8332.5",
            "source_info": {
                "paper_title": "Advancing Spatial Reasoning in Large Language Models: An In-Depth Evaluation and Enhancement Using the StepGame Benchmark",
                "publication_date_yy_mm": "2024-01"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Stepgame: A new benchmark for robust multi-hop spatial reasoning in texts",
            "rating": 2,
            "sanitized_title": "stepgame_a_new_benchmark_for_robust_multihop_spatial_reasoning_in_texts"
        },
        {
            "paper_title": "Coupling Large Language Models with Logic Programming for Robust and General Reasoning from Text",
            "rating": 2,
            "sanitized_title": "coupling_large_language_models_with_logic_programming_for_robust_and_general_reasoning_from_text"
        },
        {
            "paper_title": "Tree of thoughts: Deliberate problem solving with large language models",
            "rating": 2,
            "sanitized_title": "tree_of_thoughts_deliberate_problem_solving_with_large_language_models"
        },
        {
            "paper_title": "SpartQA: A Textual Question Answering Benchmark for Spatial Reasoning",
            "rating": 1,
            "sanitized_title": "spartqa_a_textual_question_answering_benchmark_for_spatial_reasoning"
        },
        {
            "paper_title": "A multitask, multilingual, multimodal evaluation of ChatGPT on reasoning, hallucination, and interactivity",
            "rating": 1,
            "sanitized_title": "a_multitask_multilingual_multimodal_evaluation_of_chatgpt_on_reasoning_hallucination_and_interactivity"
        }
    ],
    "cost": 0.0168185,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>Advancing Spatial Reasoning in Large Language Models: An In-Depth Evaluation and Enhancement Using the StepGame Benchmark</h1>
<p>Fangjun Li ${ }^{1}$, David C. Hogg ${ }^{1}$, Anthony G. Cohn ${ }^{1,2}$<br>${ }^{1}$ School of Computing, University of Leeds, Leeds, UK<br>${ }^{2}$ Alan Turing Institute, UK<br>scfli@leeds.ac.uk, d.c.hogg@leeds.ac.uk, a.g.cohn@leeds.ac.uk</p>
<h4>Abstract</h4>
<p>Artificial intelligence (AI) has made remarkable progress across various domains, with large language models like ChatGPT gaining substantial attention for their human-like text-generation capabilities. Despite these achievements, spatial reasoning remains a significant challenge for these models. Benchmarks like StepGame evaluate AI spatial reasoning, where ChatGPT has shown unsatisfactory performance. However, the presence of template errors in the benchmark has an impact on the evaluation results. Thus there is potential for ChatGPT to perform better if these template errors are addressed, leading to more accurate assessments of its spatial reasoning capabilities. In this study, we refine the StepGame benchmark, providing a more accurate dataset for model evaluation. We analyze GPT's spatial reasoning performance on the rectified benchmark, identifying proficiency in mapping natural language text to spatial relations but limitations in multi-hop reasoning. We provide a flawless solution to the benchmark by combining template-to-relation mapping with logic-based reasoning. This combination demonstrates proficiency in performing qualitative reasoning on StepGame without encountering any errors. We then address the limitations of GPT models in spatial reasoning. We deploy Chain-of-thought and Tree-of-thoughts prompting strategies, offering insights into GPT's "cognitive process", and achieving remarkable improvements in accuracy. Our investigation not only sheds light on model deficiencies but also proposes enhancements, contributing to the advancement of AI with more robust spatial reasoning capabilities.</p>
<h2>Introduction</h2>
<p>Spatial reasoning, the ability to understand and navigate relationships in physical space, is a fundamental aspect of human cognition that significantly influences interactions with the environment. Enhancing spatial reasoning in AI models has the potential to enrich their comprehension of their surroundings and response to user interactions, leading to more advanced and immersive user experiences (Alomari et al. 2022). In recent years, AI has revolutionized numerous domains, from healthcare to finance to entertainment. Notably, OpenAI's large language models (LLMs), such as ChatGPT and GPT-4 (OpenAI 2023), have gained significant attention for their human-like text generation capabilities. However, despite their impressive abilities, LLMs encounter challenges in many logical reasoning aspects crucial for human communication, particularly spatial reasoning (Bang et al. 2023; Cohn and Hernandez-Orallo 2023).</p>
<p>One approach to evaluating spatial reasoning in an AI system is to use synthetic benchmarks such as StepGame (Shi, Zhang, and Lipani 2022) and SpartQA (Mirzaee and Rajaby 2021). Unfortunately, models like ChatGPT have shown unsatisfactory performance on these benchmarks. Improving the spatial reasoning capabilities of LLMs remains a primary focus to enhance their overall performance and understanding of complex environments.</p>
<p>Whilst examining the StepGame benchmark we discovered that it contains template errors that distort model performance evaluations. These errors were previously overlooked, leading to studies conducted on a flawed benchmark, inaccurately assessing the capabilities of the LLMs (Bang et al. 2023; Yang, Ishay, and Lee 2023). To rectify this issue, we present a more accurate version of the StepGame dataset for model evaluation, ensuring precise assessments of the models' true capabilities and limitations ${ }^{1}$.</p>
<p>We then conducted evaluation tests on the rectified benchmark across various test subsets, few-shot sets, and models. We observed that larger GPT models demonstrate proficiency in mapping natural language text to spatial relations. However, they struggle with multi-hop spatial reasoning.</p>
<p>Our goal is not merely to critique, but also to propose potential improvements. To this end, we provide a flawless solution to the benchmark, and explore different approaches to enhance the spatial reasoning ability of LLMs.</p>
<p>The solution we propose for the benchmark entails combining template-based sentence-to-relation mapping with logic-based spatial reasoning. The logical reasoner used in this approach comes from (Yang, Ishay, and Lee 2023), where they integrated GPT-3 for the task. GPT-3 was employed to parse spatial descriptions into symbolic spatial relation representations, which were then passed to the logical program for spatial reasoning. This fusion resulted in significant improvement in StepGame, achieving state-of-the-art (SOTA) but not perfect results: around $90 \%$ accu-</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>racy for lower hops and $88.3 \%$ accuracy for 10-hop reasoning. They attributed $10.7 \%$ faults to data-related issues. With our aforementioned work on rectifying the benchmark, We take a step further to delve into the two components, analyzing the performance of each on our filtered version of the dataset. Remarkably, we achieved $100 \%$ accuracy for almost all hops, with only 2 errors among 1000 test examples, which were due to GPT-3's incorrect semantic parsing. Building on this, we replaced the GPT-3 parser with our sentence-to-relation mapping method and combined it with the ASP reasoner, showcasing proficiency in performing qualitative reasoning without encountering any errors, thus demonstrating a method to achieve a perfect score on the corrected benchmark.</p>
<p>Neither our solution or the SOTA utilize LLMs for the actual spatial reasoning functionality. Thus, we proceed to enhance GPT's capabilities as a native spatial reasoner. To achieve this, we employ Chain-of-Thoughts (CoT) and Tree-of-Thoughts (ToT) prompting strategies.</p>
<p>CoT (Wei et al. 2022) incorporates a sequence of intermediate reasoning steps to facilitate problem-solving. However, when applied to StepGame, previous studies (Yang, Ishay, and Lee 2023) have shown that CoT does not consistently improve performance and may even reduce accuracy in complex $k$-hop reasoning tasks. This observation is attributed to the higher probability of errors occurring in lengthy CoT processes. On the other hand, research on other tasks (Zhou et al. 2022; Creswell, Shanahan, and Higgins 2022) has demonstrated that breaking down complex problems into simpler subproblems and solving them sequentially can be beneficial. Given the ambiguity in the decomposition of "thoughts" ${ }^{2}$ within CoT, we propose refining the CoT prompt to empower language models to perform better in spatial reasoning tasks.</p>
<p>On the other hand, (Yao et al. 2023) introduced ToT, a framework enabling LLMs to explore multiple reasoning paths, and they demonstrated its effectiveness in improving problem-solving capabilities across tasks like the game of 24 , creative writing, and mini crosswords. In our work, we customize the ToT approach for object-linking chain building, a crucial subproblem in addressing spatial reasoning benchmarks.</p>
<p>Our customized CoT method showcases its advantages more prominently in larger models such as GPT-4 and Davinci, maintaining accuracy even as the tasks become more complex. Our ToT approach demonstrates its strengths on the three GPT models: on the largest model, GPT-4, we are able to maintain an accuracy of around $90 \%$ even as the tasks become more complex. On Davinci, the accuracy is maintained at around $50 \%$, while Turbo achieves a lower level of accuracy at around $30 \%$.</p>
<p>By identifying current deficiencies and proposing enhancements, we aim to contribute to the ongoing discourse</p>
<p><sup id="fnref2:0"><a class="footnote-ref" href="#fn:0">1</a></sup>in AI development, pushing the boundaries of what LLMs can achieve. Ultimately, our investigation can pave the way for the development of advanced, intuitive, and user-friendly AI systems with robust spatial reasoning capabilities.</p>
<h2>Related Work</h2>
<p>The field of spatial reasoning in language with artificial intelligence has evolved through sustained efforts over time, with significant advancements achieved through both traditional methods and modern LLMs.</p>
<p>Early strides in spatial reasoning in language were marked by the development of formal structures to represent spatial relationships. (Kordjamshidi, Moens, and van Otterlo 2010) proposed a spatial ontology to formalize the representation of spatial relations. This work laid the groundwork for the subsequent introduction of text-based spatial role labeling (Kordjamshidi, Van Otterlo, and Moens 2011), which aims to convert text into formal spatial representations.</p>
<p>Then comes synthetic tasks designed to evaluate the text understanding and spatial reasoning capabilities of learning algorithms. The positional reasoning task (Task 17) in the bAbI dataset (Weston et al. 2015) is for spatial reasoning and requires models to reason using one or two sentences, which makes this task comparatively simple. (Shi, Zhang, and Lipani 2022) advanced this field by creating the StepGame benchmark to evaluate multi-hop spatial reasoning in text, with richer variety in spatial relation descriptions. Both of these datasets emphasize directional spatial relations (Cohn and Hazarika 2001; Skiadopoulos and Koubarakis 2001; Cohn and Renz 2008; Chen et al. 2015). Three spatial QA datasets: SpartQA(Mirzaee and Rajaby 2021), SPARTUN, and RESQ (Mirzaee and Kordjamshidi 2022) expanded the resource landscape by encompassing wider-ranging spatial language expressions, posing challenges for traditional logical programming, and are important benchmarks for evaluating LLMs' spatial reasoning capabilities.</p>
<p>Concurrently, the advent of LLMs such as OpenAI's ChatGPT has opened up fresh pathways for spatial reasoning. These models, leveraging transformer architectures, can generate human-like text and handle complex linguistic structures. However, while these models are indeed impressive, their capabilities in spatial reasoning are yet to be fully explored and exploited. One recent approach to assess these capabilities was taken by (Bang et al. 2023), who put ChatGPT to the test using SpartQA and StepGame. Despite the generally advanced capabilities of ChatGPT, the model showed shortcomings in these tasks, signaling a need for further enhancements in the realm of spatial reasoning.</p>
<p>A promising technique known as 'prompt engineering' (Bommasani et al. 2021) has been making its mark recently. This approach involves crafting specific prompts to guide the responses of the models, leading to outputs that are more contextually apt and insightful. This method demonstrates significant potential in enhancing the capabilities of LLMs like ChatGPT in various domains (Li, Hogg, and Cohn 2022), including the challenging area of logical reasoning (Wang et al. 2023). For instance, when faced with multi-step reasoning tasks, a method called 'few-shot chain-of-thought' (CoT) prompting (Zhang et al. 2022) comes into</p>
<table>
<thead>
<tr>
<th>図</th>
<th>Story: I is diagonally above 11 to the right at a 45 degree.</th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td>Clock-position: $1 \square$ is the center of a clock face, $\square$ is located between 2 and 3.</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Compare-position: $\square$ is north east of 11</td>
<td></td>
</tr>
<tr>
<td></td>
<td>Relation extraction</td>
<td>1-hop reasoning</td>
</tr>
<tr>
<td></td>
<td>I is on the upper right of 11,</td>
<td>Question: What is the relation</td>
</tr>
<tr>
<td></td>
<td>11 is is on the lower left of 11</td>
<td>of the agent $\square$ to the agent 11?</td>
</tr>
<tr>
<td>Semantic</td>
<td>top_right("I","1")</td>
<td>Question: What is the relation</td>
</tr>
<tr>
<td>Parsing</td>
<td>down_left("11","I")</td>
<td>of the agent 11 to the agent 11?</td>
</tr>
<tr>
<td></td>
<td></td>
<td>Answer: lower-left</td>
</tr>
</tbody>
</table>
<p>Figure 1: An illustrative example for demonstrating relation extraction and 1-hop spatial reasoning. play. These demonstrations enable LLMs to explicitly generate reasoning steps, thereby improving their accuracy in reasoning tasks. This technique involves a handful of manually curated step-by-step reasoning demonstrations.</p>
<p>As we review these developments, it is clear that while significant progress has been made, challenges remain in both traditional and LLM approaches to spatial reasoning. The limitations of models like ChatGPT indicate the need for continued research and enhancement strategies. This paper aims to contribute to this by examining these limitations more closely and proposing potential avenues for improvement. We aim to explore the limit of GPT as a general problem solver that explores its own thoughts and guides its own exploration with deliberate reasoning as heuristics.</p>
<h2>The StepGame Benchmark for Evaluating Spatial Reasoning</h2>
<p>In this paper, we focus on StepGame, in line with other studies that evaluate ChatGPT's spatial reasoning proficiency using StepGame and SpartQA. StepGame comprises storyquestion pairs in natural language, The objective is to answer questions regarding the spatial relations between two specified entities. The StepGame benchmark contains two sets of data: a clean set where there are precisely $k$ facts given for any given $k$-hop instance, and a noise set where there are more than $k$ facts given, and the extra facts are distracting.</p>
<h2>Spatial Reasoning Types</h2>
<ul>
<li>1-Hop Spatial Reasoning. In 1-hop reasoning, we are given a relation description between two entities and are asked about the spatial relation from one entity to the other. 1-hop relation reasoning and relation extraction can be considered similar processes. As exemplified in Figure 1, consider the story where $J$ is diagonally above $B$ to the right at a 45-degree angle. The question is What is the spatial relation of agent $J$ to agent $B$ ?. This is similar to relation extraction. However, if we change the question to What is the spatial relation of agent $B$ to agent $J$ ?, it needs a reverse reasoning process top_right("J", "B") $\rightarrow$ down_left("B","J"). Both expressions are correct representations for relation extraction.</li>
<li>Multi-Hop Spatial Reasoning. Figure 2 provides one example of 10-hop reasoning, which is from the 'clean' set. The questions ask about the relation between two objects,</li>
</ul>
<table>
<thead>
<tr>
<th style="text-align: center;">10- hop story:</th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">1. is slightly off center to the top left and $\square$ is</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">slightly off center to the bottom right.</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">2. is at the bottom of 11</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">3. presents right to 11</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">4. is lower right of 11</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">5. is positioned above $\square$ and to the right.</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">6. is above $\square$ at 10 o'clock.</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">7. is at the upper left of 11</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">8. is at the bottom of 11</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">9. is sitting in the right direction of 11</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">10. is placed at the lower right of 11</td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">What is the relation of the agent 11 to the agent 11?</td>
<td style="text-align: center;"></td>
</tr>
</tbody>
</table>
<p>Figure 2: Example of 10-hop reasoning, featuring a question regarding two entities that are not directly connected in the stories. The diagrams on the right do not form part of the input to the AI system but are for illustrative purposes only. either directly or indirectly connected. Multi-hop reasoning adds more complexity to the problem, as it involves a greater number of provided relations. To solve the problem, one needs to identify useful relations and then proceed with relation inference step by step.</p>
<h2>Problems with the Dataset</h2>
<p>Eight spatial relations (top, down, left, right, top-left, topright, down-left, and down-right) are utilized for the story generation of StepGame. These relations are expressed through sentences in natural language. All sentences/statements are based on a crowd-sourced template base ${ }^{3}$. Each "story" is accompanied by a question that seeks to identify the relations between two objects, and it is labeled according to the intended relations at the time of story creation, rather than the actual sentences used. A template is considered to contain an error if the meaning conveyed by the sentence does not align with the relationship that was intended to be expressed during the creation of stories and labels.</p>
<p>Table 1 presents a detailed enumeration of errors in the relation-to-sentence mappings identified in StepGame. Out of the 214 templates examined, 14 were found to contain errors. Of the eight different relationship mappings available, only $o_{1}$.above_ $o_{2}$ and $o_{1}$.left_ $o_{2}$ are devoid of mistakes. The question arises as to why there are so many errors in the crowd-sourced expressions; presumably this is down to insufficient quality control over the crowdworker reponses.</p>
<p>For each $k$ value, the StepGame dataset includes 10,000 test samples. Table 2 displays the percentage of examples containing sentences derived from incorrect templates, which hints at a rising trend in inaccuracies as $k$ increases, suggesting a potential cumulative impact.</p>
<p>Among these 14 incorrect templates, four cannot be remedied in existing StepGame benchmark examples.</p>
<ul>
<li>$o_{1}$.upperright_ $o_{2}$ : Object A is above object $o_{1}$.</li>
<li>$o_{1}$.upperleft_ $o_{2}: o_{1}$ is diagonally left and above $o_{1}$.</li>
<li>$o_{1}$.lowerright_ $o_{2} \mid o_{1}$.upperleft_ $o_{2} \mid o_{1}$.upperright_ $o_{2}$ : $o_{1}$ is to the right and above $o_{2}$ at an angle of about 45 degrees.</li>
</ul>
<p><sup id="fnref3:0"><a class="footnote-ref" href="#fn:0">1</a></sup> <sup id="fnref4:0"><a class="footnote-ref" href="#fn:0">1</a></sup>: ${ }^{3}$ https://github.com/ZhengxiangShi/StepGame/blob/main/ Code/template.py</p>
<table>
<thead>
<tr>
<th>Relation</th>
<th>Original Incorrect Template</th>
</tr>
</thead>
<tbody>
<tr>
<td>right</td>
<td>$o_{2}$ and $o_{1}$ are parallel, and $o_{2}$ on the right of $o_{1}$. $o_{2}$ and $o_{1}$ are parallel, and $o_{2}$ is to the right of $o_{1}$. $o_{2}$ and $o_{1}$ are horizontal and $o_{2}$ is to the right of $o_{1}$. $o_{2}$ and $o_{1}$ are both there with the object $o_{2}$ is to the right of object $o_{1}$.</td>
</tr>
<tr>
<td>below</td>
<td>$o_{2}$ is placed at the bottom of $o_{1}$. $o_{2}$ is at the bottom of $o_{1}$ and is on the same vertical plane. $o_{2}$ presents below $o_{1}$.</td>
</tr>
<tr>
<td>lowerleft</td>
<td>$o_{2}$ is there and $o_{1}$ is at the 10 position of a clock face. $o_{2}$ is positioned below $o_{1}$ and to the left.</td>
</tr>
<tr>
<td>upperright</td>
<td>Object A is above object $o_{1}$ and to the right of it, too. $o_{2}$ is diagonally to the upper right of $o_{1}$.</td>
</tr>
<tr>
<td>lowerright</td>
<td>$o_{1}$ is to the right and above $o_{2}$ at an angle of about 45 degrees.</td>
</tr>
<tr>
<td>upperleft</td>
<td>$o_{1}$ is to the right and above $o_{2}$ at an angle of about 45 degrees. $o_{1}$ is diagonally left and above $o_{1}$.</td>
</tr>
</tbody>
</table>
<p>Table 1: Incorrect sentence templates in StepGame. The Relation column signifies relation for $o_{1}.\mathrm{relation} .o_{2}$.</p>
<table>
<thead>
<tr>
<th></th>
<th>k=1</th>
<th>k=2</th>
<th>k=3</th>
<th>k=4</th>
<th>k=5</th>
<th>k=6</th>
<th>k=7</th>
<th>k=8</th>
<th>k=9</th>
<th>k=10</th>
</tr>
</thead>
<tbody>
<tr>
<td>Clean</td>
<td>7.64</td>
<td>15.03</td>
<td>20.87</td>
<td>26.39</td>
<td>32.54</td>
<td>37.66</td>
<td>41.71</td>
<td>47.20</td>
<td>51.50</td>
<td>54.29</td>
</tr>
<tr>
<td>Noise</td>
<td>20.43</td>
<td>30.19</td>
<td>34.59</td>
<td>48.18</td>
<td>57.13</td>
<td>61.14</td>
<td>63.60</td>
<td>69.45</td>
<td>72.84</td>
<td>74.21</td>
</tr>
</tbody>
</table>
<p>Table 2: Percentage of incorrect instances out of all instances over k=1-10 test sets.</p>
<ul>
<li>$o_{1}.\mathrm{lowerleft} .o_{2}$ | $o_{1}.\mathrm{upperleft} .o_{2}$: $o_{2}$ is there and $o_{1}$ is at the 10 position of a clock face.</li>
</ul>
<p>The first and second templates are irreparable because it is impossible to identify what $o_{2}$ is when sentences are formed using them. The third and fourth templates cannot be corrected since they were applied to multiple spatial relations, although each accurately represents just one. For example, for the sentence ‘Q is to the right and above P at an angle of about 45 degrees’, three mapping relations exist: $Q . u p p e r r i g h t . . P$, $Q . l o w e r r i g h t . . P$, and $Q . u p p e r l e f t . . P$. Although this sentence expresses the meaning $Q . u p p e r r i g h t . . P$, it is uncertain which candidate was used for the label. For such templates, a unique correction could not be chosen, necessitating the removal of the sentences that use these template from the dataset.</p>
<h2>Methods</h2>
<h2>Solution for the Corrected Benchmark</h2>
<p>Our error-free approach is entirely logic-based, without the use of LLMs. We begin by performing template-based sentence-to-relation mapping, akin to semantic parsing. Then, we employ ASP for logical reasoning, utilizing the ASP reasoner introduced by (Yang, Ishay, and Lee 2023). These two components operate independently:</p>
<ul>
<li>Sentence-to-Relation Mapping. When presented with a natural language relation description $r$, we first identify the template used in $r$ through a comparison with the template base. This template is symbolized as $o_{0} . \nu . o_{1}$. Then,
<img alt="img-0.jpeg" src="img-0.jpeg" /></li>
</ul>
<p>Figure 3: Sentence-to-Relation Mapping Examples.
we convert this template form into a structured representation $\nu\left(o_{0}, o_{1}\right)$, where $o_{0}$ and $o_{1}$ correspond to the two objects mentioned in $r$, and $\nu$ signifies the spatial relation between $o_{0}$ and $o_{1}$. Specifically, for questions inquiring about relations from the start object $o_{0}$ to the target object $o_{t}$, the template is query.$o_{0} . o_{t}$, and the corresponding ASP fact is represented as query $\left(o_{0}, o_{t}\right)$. Illustrative examples of this process can be found in Figure 3.</p>
<ul>
<li>Logical Reasoning with ASP. The logical facts $\nu\left(o_{0}, o_{1}\right)$, generated through semantic parsing for all relations in the story $R$, are used as input to the ASP module for spatial reasoning. The ASP module was implemented using Clingo and includes rules specifically tailored for StepGame. These rules transform StepGame into a qualitative spatial reasoning problem in a 2D grid space. These rules incorporate offsets for 9 spatial relations, such as offset $(r i g h t)=(0,1)$ and offset(lower-left) $=$ $(-1,-1)$. The main rule in the ASP module calculates the location of $o_{0}$ to $o_{1}$ by adding the offsets $\nu\left(o_{0}, o_{1}\right)$.</li>
</ul>
<p>While this approach offers a solution to the StepGame benchmark challenge, it does require prior familiarity with the templates and mandates updates to the template base when confronted with new stories employing novel templates. In contrast, an LLM approach holds the potential to flexibly adjust to unfamiliar templates. Additionally, the method's dependence on customized rules within the logical program constitutes another aspect to be mindful of.</p>
<h2>Chain-of-Thought (CoT) Prompting</h2>
<p>We devised a customized CoT for the spatial reasoning task. The core idea of CoT is to introduce a chain of thoughts $c_{1}, \ldots, c_{i}, \ldots, c_{n}$ to bridge input $x$ and output $y$, where $i$ represents $i$-th step. In our customized CoT for StepGame, $x$ consists of the task description, few-shot examples, relation story, and question, while $y$ represents the answer regarding the relations between the queried objects (from the start object $o_{i}$ to the target object $o_{t}$ ). Each thought $c_{i}$ is to identify direct spatial connections between objects ( $o_{i}$ and $o_{i+1}$ ). We take CoT a step further by decomposing each step of thought $c_{i}$ to explore the potential advantages of incorporating a coherent and detailed reasoning process.</p>
<p>Thought Categorisation. We categorise the thought into three types: link establishment thoughts $c^{\text {link }}$, relation mapping thoughts $c^{\text {map }}$, and coordinate calculation thoughts $c^{\text {calcu }}$. At each reasoning step, these three types of thought are sequentially sampled as a continuous language sequence $c_{i}=\left[c_{i}^{\text {link }}, c_{i}^{\text {map }}, c_{i}^{\text {calcu }}\right]$ using the LLM.</p>
<ol>
<li>$c_{i}^{\text {link }}$ : Guide the LLM to examine all relations in the story $\left(R=\left[r^{1}, \ldots, r^{j}, \ldots, r^{k}\right]\right)$ and select $r^{j}$ for the $i$-th step</li>
</ol>
<p>for $k$-hop reasoning, ensuring it directly describes the relation with $o_{i}$ and has not been used in any previous step. For the start object $(i=0)$, we use the prompt "Start with $o_{0}$. According to" and for the middle objects $(i \geq 1)$, we use the prompt "Then search for $o_{i}$. According to". Full details of the prompts can be found in the Appendix ${ }^{4}$.
2. $c_{i}^{\text {map }}$ : Map $r^{j}$ to a simple relation description such as " $o_{i}$ is to the $\nu$ of $o_{i+1}$," where $\nu$ represents the key spatial relation from $o_{i}$ to $o_{i+1}$. The prompt "This means" helps the LLM perform this mapping.
3. $c_{i}^{\text {calcu }}$ : Use $r^{j}$ to calculate the coordinates of $o_{i+1}$. We set $o_{o}$ at $(0,0)$, and each spatial relation is assigned an offset to determine the positions of the objects. The prompt " $o_{i+1}=o_{i}+\operatorname{offset}\left(r^{j}\right)=\left(x_{o_{i}}, y_{o_{i}}\right)+\left(x_{\nu}, y_{\nu}\right)=$ $\left(x_{o_{i+1}}, y_{o_{i+1}}\right)$ " instructs the LLM on the calculation process. It computes the coordinates of $o_{i+1}$ and generates the output like "Therefore, B is at $\left(x_{o_{i+1}}, y_{o_{i+1}}\right)$."</p>
<h2>Tree-of-Thoughts (ToT) Prompting</h2>
<p>Algorithm 1 is designed to enhance the reasoning chainbuilding process, allowing LLMs to consider different pathways. This is useful because during the search for relations with an object, distracting connections may arise, as shown in Figure 2. However, it is essential to follow a correct sequence to successfully reach the target object. If an LLM mistakenly tracks an incorrect sequence, it could get stuck in a dead end leading to incorrect reasoning conclusions such as "The story does not provide direct spatial information."</p>
<p>The algorithm initiates by prompting the LLM to set up the initial tree state, denoted as $S_{0}$, using the input $x$, which comprises a story and a question. $S_{0}$ is in the form "chain: $o_{0} \rightarrow$, target: $o_{t}$, unused: $R$ ". $R$ represents all connections between objects in the story, in the form of object1-object2. Then it proceeds to construct a linking chain from $o_{0}$ to $o_{t}$ in iterative steps, wherein for the $i$-th step $(1 \leq i \leq 10)$, the LLM considers the tree state $S_{i-1}$ built up to that step. If no state $s$ in $S_{i-1}$ reaches $o_{t}$, the LLM is prompted to generate $j$ candidate thoughts for each $s$ in the current set of states, $S_{i}(j=2$ in this paper). $G$ prompts the LLM to search for a potential object $o_{i}$ connected to the current object $o_{i-1}$ from the unused relations $R_{i-1}^{\text {unused }}$. A check is made $(\operatorname{CheckExtn}(c)))$ to see if the proposal made is a real candidate extension. For all candidate thoughts, $V$ prompts the LLM to evaluate the state to determine if the chain can proceed with $o_{i}$ and the updated $R_{i-1}^{\text {unused }}$ to reach $o_{t}$. The top-rated $b$ tree states in $S_{i}^{\prime}$ are selected as $S_{i}$. When there is a state $s_{f}$ which reaches $o_{t}$, the L will be prompted with the linking chain construction prompt (Appendix D.4) to form the final links $l$.</p>
<ul>
<li>Thought Generation $G(s, j)$. Given a tree state $s$, we let the LLM propose $j$ thoughts using the thought generation prompt "Use relations listed in unused relations to enumerate all potential expansions of the chain by considering unused relations that exhibit a direct link to the last object</li>
</ul>
<p><sup id="fnref5:0"><a class="footnote-ref" href="#fn:0">1</a></sup>Algorithm 1: Our ToT Approach
Require: LLM, input $x$
$: S_{0} \leftarrow \operatorname{Init}(x)$
$: i \leftarrow 1$
while no $s_{f} \in S_{i-1}$ has arrived at $o_{t}$ do
$S_{i}^{\prime} \leftarrow\left{s \cdot c \mid c \in G(s, j) \wedge \operatorname{ChainExtn}(c) \wedge s \in S_{i-1}\right}$
if $S_{i}^{\prime}=\emptyset$ then return failure
$S_{i} \leftarrow \operatorname{select}\left(b,\left{\langle s, y\rangle \mid s \in S_{i}^{\prime} \wedge y=\Sigma_{1}^{n} \sigma(V(s))\right}\right)$
$i=i+1$
end while
return $\operatorname{Link}\left(s_{f}\right)$
within the chain." In our experiment, we set $j=2$, meaning that we instruct the LLM to generate content twice for each state $s \in S_{i-1}$.</p>
<ul>
<li>State Evaluation $V(s)$. Our approach involves a classification methodology, using the designed value prompt "Evaluate whether the chain can reach the target (sure/ likely/impossible). If the chain has already reached the target, it's 'sure'. If the unused relations include the current object, it's 'likely'. If there are no unused relations that include the current object, it's 'impossible'." This prompt guides the LLM to sequentially examine all newly generated states $s \in S_{i}^{\prime} n$ times - using the stochasticity of the LLM with a non zero temperature to increase the reliability of the scoring. The three types of outputs - 'sure', 'likely', and 'impossible' - are converted into numerical scores using a function $\sigma()$ to facilitate the selection process among all newly generated states.</li>
<li>Search Algorithm The choice between utilizing breadthfirst search (BFS) or depth-first search (DFS) depends on the tree structure. In the StepGame benchmark, the tree depth is limited (depth $\leq 10$ ), and the number of thought candidates $k$ for each step is also limited (width $\leq 3$ in most cases). However, a deeper search does not necessarily guarantee better results. In certain scenarios, $o_{0}$ and $o_{t}$ may be directly connected in one relation statement, allowing for shorter linking chains between them, which is preferable. Therefore, we opt for BFS to maintain all promising states. We set the breadth width $b=3$, maintaining the three most promising linking-chain states per step. The criterion for stopping searching is set when the linking chain arrives at the target object.</li>
</ul>
<p>Our ToT approach is used to construct the reasoning chain from $o_{0}$ to $o_{t}$. Subsequently, the spatial relation between these objects is computed following the previous CoT prompting method, with the use of $c^{\text {map }}$ and $c^{\text {calcu }}$.</p>
<h2>Experimental Design</h2>
<h2>Model Settings</h2>
<p>We use the Azure OpenAI Service for ChatGPT (3.5-Turbo) and GPT-3 (Davinci), and GPT-4 API access. To yield more concentrated and deterministic results, we set the temperature to 0 in CoT experiments. In ToT experiments, we follow</p>
<p>(Yao et al. 2023), setting the temperature to 0.7 for generating varied thought proposals. The remaining parameters were left at the standard configurations for these models.</p>
<p>Different Test Subsets It is common practice in the studies cited (Bang et al. 2023), (Yang, Ishay, and Lee 2023) to use a subset of 30 or 100 test examples from the full set of 10,000 for each $k$ value. While this method helps in conserving token usage, it could potentially introduce biases or inaccurate estimations of the model performance.</p>
<p>We examine the effect of the number of test examples. Specifically, we wanted to determine whether evaluating on a limited number of test examples could introduce inaccuracies. To achieve this, we conducted tests on a clean, filtered test set for $k$-hop reasoning $(k \in[1,10])$, thereby covering a range of task complexities. Tests were carried out on 30, 100, and 1000 test examples to assess the impact of the number of test examples on the evaluation.</p>
<p>Different Few-Shot Sets We created three different fewshot prompting sets to evaluate the influence of input examples in prompts.</p>
<ul>
<li>clean 5shot(1,3,5,7,10): Create a prompt consisting of five examples, with one example each from tasks requiring 1hop, 3-hop, 5-hop, 7-hop, and 10-hop reasoning.</li>
<li>clean 10shot: Formulate a prompt using ten examples, each one derived from a distinct $k$-hop task in clean set.</li>
<li>clean 5shot separate: Construct a prompt for each $k$-hop reasoning task, utilizing five examples from the corresponding $k$-hop training set as few-shot examples.</li>
</ul>
<h2>Experimental Results</h2>
<h2>Evaluation Results</h2>
<p>Influence of Scale of Test Examples We employ the clean 10shot prompting setting. The results are presented in the left subplot of Figure 4. Upon evaluation of the expanded test set comprising 1000 examples, the model shows a uniform decrement in performance as $k$ increases from 1 to 10 . This trend indicates the increased complexity as the number of hops increases. With smaller test sets of 100 or 30 examples, the trend is less consistent, and there are occasional increases in performance at certain hop levels. The variance in performance, particularly for the 30 -example test set, may indeed be larger. This could be due to the smaller sample size providing less comprehensive coverage of the potential range of tasks, leading to more fluctuations in performance. This indicates larger test sets can provide a more stable and reliable indicator of a model's performance across different complexity levels (i.e., number of hops).</p>
<p>Influence of Prompting Examples The middle subplot in figure 4 indicates that the choice of prompting strategy can impact the model's ability to handle tasks of varying complexity. Similar to the previous data, all prompting strategies show a trend of decreasing accuracy as the number of hops increases. This trend is consistent and suggests that the complexity of the tasks grows with the number of hops.</p>
<p>The performances of the three methods are close. While differences exist at specific hop levels, no single method</p>
<table>
<thead>
<tr>
<th style="text-align: left;"></th>
<th style="text-align: left;">left/ <br> right</th>
<th style="text-align: left;">above <br> /below</th>
<th style="text-align: left;">lower_left/ <br> upper_right</th>
<th style="text-align: left;">lower_right/ <br> upper_left</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">total</td>
<td style="text-align: left;">44</td>
<td style="text-align: left;">53</td>
<td style="text-align: left;">50</td>
<td style="text-align: left;">53</td>
</tr>
<tr>
<td style="text-align: left;">text-curie-001</td>
<td style="text-align: left;">11</td>
<td style="text-align: left;">41</td>
<td style="text-align: left;">30</td>
<td style="text-align: left;">37</td>
</tr>
<tr>
<td style="text-align: left;">text-davinci-003</td>
<td style="text-align: left;">$\mathbf{0}$</td>
<td style="text-align: left;">$\mathbf{0}$</td>
<td style="text-align: left;">$\mathbf{0}$</td>
<td style="text-align: left;">2</td>
</tr>
<tr>
<td style="text-align: left;">gpt-3.5-turbo</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;">3</td>
<td style="text-align: left;">$\mathbf{1}$</td>
</tr>
</tbody>
</table>
<p>Table 3: The relation extraction performance of GPT. The numbers in rows 2-4 are incorrect predictions numbers.
consistently outperforms the others across all hop levels. Interestingly, clean 5shot (1,3,5,7,10) performs better than clean 10shot ( $1 \sim 10$ ) at almost every hop level. This suggests that selecting examples from a wider range of hop levels $(1,3,5,7,10)$ can be more beneficial than having an example from each hop level from 1 to 10 .</p>
<p>Influence of Models As indicated in a recent study (Ye et al. 2023), Turbo demonstrates comparable performance to Davinci across many tasks. However, it falls short in the machine reading comprehension, part-of-speech, and relation extraction tasks, potentially owing to its smaller model size. The StepGame spatial reasoning task requires the comprehension of sequential spatial connections and the ability to draw deductions from them. According to the right subplot of Figure 4, the Davinci model generally outperforms the Turbo model across varying levels of task complexity (number of hops). The differences in performance between the two models are more significant at lower complexity levels, but they appear to converge as the complexity increases.</p>
<h2>Results of the Improved Methods</h2>
<p>Resolution for the Benchmark The results of our resolution (sentence-to-relation mapping + ASP-based reasoning) are displayed in the 'Map+ASP' row of Table 4. The numbers in the table indicate accuracy scores, with higher values indicating better performance. This demonstrates the proficiency achieved in spatial relation mapping and multi-hop spatial reasoning, all without encountering any errors.</p>
<p>GPT for Relation Extraction + ASP for Reasoning We analyze the performance of GPT in the relation extraction subtask, as outlined in Table 3. Curie has the highest number of wrong predictions across different relations, Davinci and Turbo show better performance.</p>
<p>The state-of-the-art results achieved by (Yang, Ishay, and Lee 2023) (using GPT-3 for semantic parsing and ASP for reasoning) are presented in the "SOTA" row of Table 4. They achieve approximately $90 \%$ accuracy for lower hops and $88.3 \%$ accuracy for 10-hop reasoning. They attribute $10.7 \%$ of the inaccuracies to data-related concerns.</p>
<p>We provide an evaluation of their approach onthe corrected dataset, with the results displayed in the "Curie+ASP" and "Davinci+ASP" rows. Among the 1000 test examples ( 100 for each k), only 2 errors were encountered with Davinci. caused by semantic parsing: the sentence "If E is the center of a clock face, H is located between 2 and 3." was parsed incorrectly as right("H", "E"), but</p>
<p><img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Figure 4: Accuracy comparison for varying numbers of hops (1-10) on the clean test set. On the left, we show the performance variation of the Turbo model with <em>10shot</em> prompting over different test set sizes (30, 100, and 1000 examples). The middle section illustrates the performance of the Turbo model under three distinct prompting settings: <em>5shot(1,3,5,7,10)</em>, <em>10shot</em>, and <em>5shot separate</em>. The right portion showcases the performance of two models - Davinci and Turbo - using <em>10shot</em> prompting.</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
<th>k=1</th>
<th>k=2</th>
<th>k=3</th>
<th>k=4</th>
<th>k=5</th>
<th>k=6</th>
<th>k=7</th>
<th>k=8</th>
<th>k=9</th>
<th>k=10</th>
</tr>
</thead>
<tbody>
<tr>
<td>Map+ASP</td>
<td></td>
<td>100</td>
<td>100</td>
<td>100</td>
<td>100</td>
<td>100</td>
<td>100</td>
<td>100</td>
<td>100</td>
<td>100</td>
<td>100</td>
</tr>
<tr>
<td>Curie+ASP</td>
<td></td>
<td>46</td>
<td>43</td>
<td>42</td>
<td>59</td>
<td>67</td>
<td>67</td>
<td>57</td>
<td>56</td>
<td>58</td>
<td>61</td>
</tr>
<tr>
<td>Davinci+ASP</td>
<td></td>
<td>100</td>
<td>100</td>
<td>99</td>
<td>100</td>
<td>100</td>
<td>99</td>
<td>100</td>
<td>100</td>
<td>100</td>
<td>100</td>
</tr>
<tr>
<td>SOTA</td>
<td></td>
<td>92.6</td>
<td>89.9</td>
<td>89.1</td>
<td>93.8</td>
<td>92.9</td>
<td>91.6</td>
<td>91.2</td>
<td>90.4</td>
<td>89.0</td>
<td>88.3</td>
</tr>
<tr>
<td>Turbo</td>
<td>base</td>
<td>62</td>
<td>43</td>
<td>30</td>
<td>35</td>
<td>29</td>
<td>25</td>
<td>29</td>
<td>31</td>
<td>16</td>
<td>20</td>
</tr>
<tr>
<td></td>
<td>CoT</td>
<td>/</td>
<td>34</td>
<td>40</td>
<td>36</td>
<td>28</td>
<td>28</td>
<td>26</td>
<td>31</td>
<td>25</td>
<td>24</td>
</tr>
<tr>
<td></td>
<td>ToT_CoT</td>
<td>/</td>
<td>/</td>
<td>35</td>
<td>35</td>
<td>25</td>
<td>45</td>
<td>15</td>
<td>40</td>
<td>40</td>
<td>35</td>
</tr>
<tr>
<td>Davinci</td>
<td>base</td>
<td>77</td>
<td>42</td>
<td>21</td>
<td>26</td>
<td>25</td>
<td>30</td>
<td>23</td>
<td>23</td>
<td>22</td>
<td>22</td>
</tr>
<tr>
<td></td>
<td>CoT</td>
<td>/</td>
<td>48</td>
<td>53</td>
<td>46</td>
<td>46</td>
<td>48</td>
<td>40</td>
<td>45</td>
<td>41</td>
<td>32</td>
</tr>
<tr>
<td></td>
<td>ToT_CoT</td>
<td>/</td>
<td>/</td>
<td>65</td>
<td>50</td>
<td>45</td>
<td>60</td>
<td>50</td>
<td>50</td>
<td>55</td>
<td>50</td>
</tr>
<tr>
<td>GPT-4</td>
<td>base</td>
<td>100</td>
<td>70</td>
<td>55</td>
<td>45</td>
<td>40</td>
<td>25</td>
<td>40</td>
<td>35</td>
<td>35</td>
<td>25</td>
</tr>
<tr>
<td></td>
<td>CoT</td>
<td>/</td>
<td>80</td>
<td>75</td>
<td>95</td>
<td>85</td>
<td>85</td>
<td>90</td>
<td>80</td>
<td>60</td>
<td>65</td>
</tr>
<tr>
<td></td>
<td>ToT_CoT</td>
<td>/</td>
<td>/</td>
<td>85</td>
<td>85</td>
<td>90</td>
<td>90</td>
<td>85</td>
<td>90</td>
<td>100</td>
<td>95</td>
</tr>
</tbody>
</table>
<p>Table 4: Accuracy comparison of GPT models on revised StepGame using different methods.</p>
<p>supposed to be <em>up_right</em> ("H", "E").</p>
<p><strong>CoT and ToT</strong> The experimental results in Table 4 involving GPT-4 and ToT are based on a test set comprising 20 instances considering token usage, while for Davinci and Turbo, we used a larger test set of 100 samples. The results for the base and CoT methods were obtained using the <em>5shot separate</em> prompting on the <em>clean</em> set. All the ToT_CoT results presented in the table involve the use of GPT-4 for building the linking chain, followed by the application of Turbo, Davinci, and GPT-4 for CoT reasoning with the constructed linking chain. The GPT-4 model exhibits superior performance across nearly all settings. With the basic input-output prompt, despite starting at 100% accuracy for <em>k</em> = 1, its accuracy dips to 25% for <em>k</em> = 10, indicating that even the most powerful GPT model struggles to maintain accuracy as task complexity rises. Humans would probably find this challenging too.</p>
<p>With the implementation of our CoT and ToT approach, the GPT-4 model demonstrates significant performance enhancements for more complex tasks (ranging from <em>k</em> = 2 to <em>k</em> = 10). Our ToT and CoT method considerably enhances the performance of the Davinci and GPT-4, particularly in larger hops. For the Turbo model, although our CoT method brings improvements as <em>k</em> increases, the gains are not as profound as those observed with the Davinci and GPT-4. This could be attributed to the long length of our prompts, requiring a nuanced understanding of coordinates and relations.</p>
<h3>Conclusion</h3>
<p>This paper has introduced a revised version of the StepGame benchmark, correcting template errors that distort model performance evaluations, leading to a more accurate evaluation of the spatial reasoning capabilities of AI systems attempting the challenge. We highlight Davinci and Turbo's abilities in mapping texts to spatial relations and their limitations in multi-hop spatial reasoning. Our solution combines template-to-relation mapping with logic-based reasoning, effectively addressing challenges in this task. We also enhance LLMs' spatial reasoning ability through prompt engineering, using CoT and ToT strategies.</p>
<p>This paper focuses on StepGame; future studies could extend our findings to other benchmarks. Our methods are suitable for adaptation to various 2D grid-based directional spatial tasks, such as the bAbI (task 17). This adaptation would involve customizing the template for the ASP-based solution and modifying task descriptions and few-shot examples for CoT and ToT approaches. For tasks that require a combination of directional, topological, and distance reasoning, like SpartQA, it would be necessary to integrate additional rules and ontology into both the ASP program and the prompts to LLMs for effective solution development.</p>
<p>The effective resolution of the StepGame benchmark prompts a need for more challenging versions. While having a well-defined set of spatial relations converted into natural language using a set of templates is appealing, it leads to controlled natural language which is more amenable to special purpose reasoning. Finding a way to generate more naturalistic problem statements automatically would therefore be highly desirable. Additionally, the current independent use of LLMs and logic programs suggests a potential research direction towards integrating these tools for more comprehensive and cohesive problem-solving strategies.</p>
<h2>Acknowledgments</h2>
<p>This work has been partially supported by Microsoft Research - Accelerating Foundation Models Research program, with the provision of Azure resources to access GPT. This work was also partially supported by the Turing's Defence and Security programme through a partnership with the UK government in accordance with the framework agreement between GCHQ and The Alan Turing Institute.</p>
<h2>Author Contributions</h2>
<p>AGC and DCH proposed the initial line of work. FL designed the actual implementation, performed all the evaluations, and wrote the initial paper draft. DCH and AGC supervised FL. All authors contributed to subsequent paper revisions.</p>
<h2>References</h2>
<p>Alomari, M.; Li, F.; Hogg, D. C.; and Cohn, A. G. 2022. Online perceptual learning and natural language acquisition for autonomous robots. Artificial Intelligence, 303: 103637.
Bang, Y.; Cahyawijaya, S.; Lee, N.; Dai, W.; Su, D.; Wilie, B.; Lovenia, H.; Ji, Z.; Yu, T.; Chung, W.; et al. 2023. A multitask, multilingual, multimodal evaluation of ChatGPT on reasoning, hallucination, and interactivity. arXiv preprint arXiv:2302.04023.
Bommasani, R.; Hudson, D. A.; Adeli, E.; Altman, R.; Arora, S.; von Arx, S.; Bernstein, M. S.; Bohg, J.; Bosselut, A.; Brunskill, E.; et al. 2021. On the opportunities and risks of foundation models. arXiv preprint arXiv:2108.07258.
Chen, J.; Cohn, A. G.; Liu, D.; Wang, S.; Ouyang, J.; and Yu, Q. 2015. A survey of qualitative spatial representations. The Knowledge Engineering Review, 30(1): 106-136.
Cohn, A. G.; and Hazarika, S. M. 2001. Qualitative spatial representation and reasoning: An overview. Fundamenta informaticae, 46(1-2): 1-29.
Cohn, A. G.; and Hernandez-Orallo, J. 2023. Dialectical language model evaluation: An initial appraisal of the commonsense spatial reasoning abilities of LLMs. arXiv preprint arXiv:2304.11164.
Cohn, A. G.; and Renz, J. 2008. Qualitative spatial representation and reasoning. Foundations of Artificial Intelligence, 3: 551-596.
Creswell, A.; Shanahan, M.; and Higgins, I. 2022. Selection-inference: Exploiting large language models for interpretable logical reasoning. arXiv preprint arXiv:2205.09712.
Kordjamshidi, P.; Moens, M.-F.; and van Otterlo, M. 2010. Spatial role labeling: Task definition and annotation scheme. In Proceedings of the Seventh conference on International Language Resources and Evaluation (LREC'10), 413-420. European Language Resources Association (ELRA).
Kordjamshidi, P.; Van Otterlo, M.; and Moens, M.-F. 2011. Spatial role labeling: Towards extraction of spatial relations from natural language. ACM Transactions on Speech and Language Processing (TSLP), 8(3): 1-36.</p>
<p>Li, F.; Hogg, D. C.; and Cohn, A. G. 2022. Ontology Knowledge-enhanced In-Context Learning for ActionEffect Prediction. In Advances in Cognitive Systems. ACS2022.</p>
<p>Mirzaee, R.; and Kordjamshidi, P. 2022. Transfer Learning with Synthetic Corpora for Spatial Role Labeling and Reasoning. arXiv preprint arXiv:2210.16952.
Mirzaee, R.; and Rajaby, H. 2021. SpartQA: A Textual Question Answering Benchmark for Spatial Reasoning. In The 2021 Annual Conference of the North American Chapter of the Association for Computational Linguistics (NAACL-2021).
OpenAI. 2023. GPT-4 Technical Report. ArXiv, abs/2303.08774.
Shi, Z.; Zhang, Q.; and Lipani, A. 2022. Stepgame: A new benchmark for robust multi-hop spatial reasoning in texts. In Proceedings of the AAAI Conference on Artificial Intelligence, 11321-11329.
Skiadopoulos, S.; and Koubarakis, M. 2001. Composing cardinal direction relations. In International Symposium on Spatial and Temporal Databases, 299-317. Springer.
Wang, L.; Xu, W.; Lan, Y.; Hu, Z.; Lan, Y.; Lee, R. K.-W.; and Lim, E.-P. 2023. Plan-and-Solve Prompting: Improving Zero-Shot Chain-of-Thought Reasoning by Large Language Models. arXiv preprint arXiv:2305.04091.
Wei, J.; Wang, X.; Schuurmans, D.; Bosma, M.; Chi, E.; Le, Q.; and Zhou, D. 2022. Chain of thought prompting elicits reasoning in large language models. arXiv preprint arXiv:2201.11903.
Weston, J.; Bordes, A.; Chopra, S.; Rush, A. M.; Van Merriënboer, B.; Joulin, A.; and Mikolov, T. 2015. Towards ai-complete question answering: A set of prerequisite toy tasks. arXiv preprint arXiv:1502.05698.
Yang, Z.; Ishay, A.; and Lee, J. 2023. Coupling Large Language Models with Logic Programming for Robust and General Reasoning from Text. arXiv preprint arXiv:2307.07696.
Yao, S.; Yu, D.; Zhao, J.; Shafran, I.; Griffiths, T. L.; Cao, Y.; and Narasimhan, K. 2023. Tree of thoughts: Deliberate problem solving with large language models. arXiv preprint arXiv:2305.10601.
Ye, J.; Chen, X.; Xu, N.; Zu, C.; Shao, Z.; Liu, S.; Cui, Y.; Zhou, Z.; Gong, C.; Shen, Y.; et al. 2023. A comprehensive capability analysis of gpt-3 and gpt-3.5 series models. arXiv preprint arXiv:2303.10420.
Zhang, Z.; Zhang, A.; Li, M.; and Smola, A. 2022. Automatic chain of thought prompting in large language models. arXiv preprint arXiv:2210.03493.
Zhou, D.; Schärli, N.; Hou, L.; Wei, J.; Scales, N.; Wang, X.; Schuurmans, D.; Cui, C.; Bousquet, O.; Le, Q.; et al. 2022. Least-to-most prompting enables complex reasoning in large language models. arXiv preprint arXiv:2205.10625.</p>
<h2>A. Example Prompts for Base</h2>
<p>Given a story about spatial relations among objects, answer the relation between two queried objects. Possible relations are: overlap, above, below, left, right, upper-left, upper-right, lower-left, and lower-right. If a sentence in the story is describing clock-wise information, then 12 denotes above, 1 and 2 denote upper-right, 3 denotes right, 4 and 5 denote lower-right, 6 denotes below, 7 and 8 denote lower-left, 9 denote left, 10 and 11 denote upper-left. If the sentence is describing cardinal directions, then north denotes above, east denotes right, south denotes below, and west denotes left.</p>
<p>Story:
$Q$ is to the right of $O$ and is on the same horizontal plane.
$Q$ is slightly off center to the top left and $M$ is slightly off center to the bottom right.
$X$ and $E$ are next to each other with $X$ on the top and $E$ at the bottom.
$O$ is sitting at the upper right position to E.
W is on the right side and below M.
What is the relation of the agent $W$ to the agent E?
Answer: lower-right</p>
<h2>$\cdots$</h2>
<p>Story:</p>
<ol>
<li>The object E is positioned directly above the object W.</li>
<li>E is sitting at the upper right position to I.</li>
<li>W is placed at the upper left of C.</li>
<li>$L$ is over there and $Y$ is on the left.</li>
<li>C and Y are both there with the object Y below the object C.</li>
<li>What is the relation of the agent $E$ to the agent Y ?</li>
</ol>
<h2>B. Example Prompts for CoT in (Yang, Ishay, and Lee 2023)</h2>
<p>Given a story about spatial relations among objects, answer the relation between two queried objects. Possible relations are: overlap, above, below, left, right, upper-left, upper-right, lower-left, and lower-right. If a sentence in the story is describing clock-wise information, then 12 denotes above, 1 and 2 denote upper-right, 3 denotes right, 4 and 5 denote lower-right, 6 denotes below, 7 and 8 denote lower-left, 9 denote left, 10 and 11 denote upper-left.</p>
<p>If the sentence is describing cardinal directions, then north denotes above, east denotes right, south denotes below, and west denotes left.</p>
<p>Story:
$Q$ is to the right of $O$ and is on the same horizontal plane.
$Q$ is slightly off center to the top left and $M$ is slightly off center to the bottom right.
$X$ and $E$ are next to each other with $X$ on the top and $E$ at the bottom.
$O$ is sitting at the upper right position to E.</p>
<p>W is on the right side and below M.
What is the relation of the agent $W$ to the agent E?
Answer: We first link W and E using the relations in the story. W is to the lower-right of M. M is to the lower-right of Q. Q is to the right of O. O is to the upper-right of E. So the answer is lower-right.</p>
<h2>$\cdots$</h2>
<p>Story:</p>
<ol>
<li>The object E is positioned directly above the object W.</li>
<li>E is sitting at the upper right position to I.</li>
<li>W is placed at the upper left of C.</li>
<li>L is over there and Y is on the left.</li>
<li>C and Y are both there with the object Y below the object C.</li>
<li>What is the relation of the agent $E$ to the agent Y ?</li>
</ol>
<h2>C. Example Prompts for Our CoT</h2>
<p>Given a story about spatial relations among objects, answer the relation between two queried objects. Possible relations are: overlap, above, below, left, right, upper-left, upper-right, lower-left, and lower-right. If a sentence in the story is describing clock-wise information, then 12 denotes above, 1 and 2 denote upper-right, 3 denotes right, 4 and 5 denote lower-right, 6 denotes below, 7 and 8 denote lower-left, 9 denote left, 10 and 11 denote upper-left. If the sentence is describing cardinal directions, then north denotes above, east denotes right, south denotes below, and west denotes left. In all the spatial relations, assume that all agents occupy a position on a grid point of equally spaced points in the vertical and horizontal directions and that agents occupy the nearest grid point consistent</p>
<p>with the spatial relation. The offsets of 9 spacial relations: offset (overlap) = $(0,0)$; offset (above) $=(0,1)$; offset (below) $=(0,-1) ;$ offset (left) $=(-1,0)$; offset (right) $=(1,0) ;$ offset (upper-left) $=(-1,1) ;$ offset (upper-right) $=$ $(1,1) ;$ offset (lower-left) $=(-1,-1)$; offset (lower-right) $=(1,-1)$.</p>
<p>Story:</p>
<ol>
<li>$Q$ is to the right of $O$ and is on the same horizontal plane.</li>
<li>$Q$ is slightly off center to the top left and $M$ is slightly off center to the bottom right.</li>
<li>$X$ and $E$ are next to each other with $X$ on the top and $E$ at the bottom.</li>
<li>$O$ is sitting at the upper right position to E.</li>
<li>W is on the right side and below M. What is the relation of the agent $W$ to the agent E?
Reasoning:
Let's suppose W is at $(0,0)$. We can connect W and E using the relations given in the story.
Start with W. According to 5, "W is on the right side and below M." This means $M$ is to the upper-left of $W . M=W+$ offset (upper-left) $=(0,0)+(-1,1)=(-1,1)$. Therefore, $M$ is at $(-1,1)$.
Then search for M. According to 2, "Q is slightly off center to the top left and $M$ is slightly off center to the bottom right." This means $Q$ is to the upper-left of M. Q= M+ offset (upper-left) $=(-1,1)+(-1,1)=(-2,2)$. Therefore, $Q$ is at $(-2,2)$.
Then search for $Q$. According to 1, "Q is to the right of $O$ and is on the same horizontal plane." This means $O$ is to the left of $Q$. $0=Q+$ offset (left) $=(-2,2)+(-1,0)=(-3,2)$. Therefore, $O$ is at $(-3,2)$.
Then search for $O$. According to 4, "O is sitting at the upper right position to E." This means E is to the lower-left of $O . \mathrm{E}=\mathrm{O}+$ offset (lower-left) $=$ $(-3,2)+(-1,-1)=(-4,1)$. Therefore, E is at $(-4,1)$.
We've reached E. So, considering W $(0,0)$ and $\mathrm{E}(-4,1), \mathrm{W}$ is to the lower-right of E . Answer: lower-right</li>
</ol>
<p>Story:</p>
<ol>
<li>The object $E$ is positioned directly above the object W.</li>
<li>E is sitting at the upper right position
to I.</li>
<li>W is placed at the upper left of C.</li>
<li>L is over there and $Y$ is on the left.</li>
<li>C and Y are both there with the object Y below the object C.</li>
<li>What is the relation of the agent E to the agent Y ?</li>
</ol>
<h2>D. Example Prompts for Our ToT</h2>
<h2>D.1. Tree state initialization prompt</h2>
<p>Provided with a sequence of statements that define the spatial relationships among various objects, your task is to detail the subsequent actions. This includes initiating the chain of connections, identifying the target object, and enumerating all links between objects from the statements.</p>
<p>Input: 1. $Q$ is to the right of $O$ and is on the same horizontal plane. 2. $Q$ is slightly off center to the top left and $M$ is slightly off center to the bottom right. 3. X and E are next to each other with X on the top and $E$ at the bottom. 4. O is sitting at the upper right position to E. 5. W is on the right side and below M. What is the relation of the agent $W$ to the agent $E$ ?
Possible next steps:
chain: W -&gt;, target: E, unused: 1. Q-O, 2. Q-M, 3. X-E, 4. O-E, 5. W-M.</p>
<p>Input: {input}
Possible next steps:</p>
<h2>D.2. Thought generation prompt</h2>
<p>Use relations listed in unused relations to enumerate all potential expansions of the chain by considering unused relations that exhibit a direct link to the last object within the chain.</p>
<p>Input: chain: G -&gt;, target: Q, unused: 1. C-R, 2. L-Q, 3. C-J, 4. J-E, 5. T-A, 6. G-N, 7. G-A, 8. L-Y, 9. R-Q, 10. Y-T.</p>
<p>Possible next steps:
The last object within the chain is G, and the unused relations 6. G-N and 7. G-A include G. relation chain: G -&gt; N (use 6) -&gt;, target: Q, unused: 1. C-R, 2. L-Q, 3. C-J, 4. J-E, 5. T-A, 7. G-A, 8. L-Y, 9. R-Q, 10. Y-T.
chain: G -&gt; A (use 7) -&gt;, target: Q, unused: 1. C-R, 2. L-Q, 3. C-J, 4. J-E, 5. T-A, 6. G-N, 8. L-Y, 9. R-Q, 10. Y-T.</p>
<p>Input: {input}
Possible next steps:</p>
<h2>D.3. State evaluation prompt</h2>
<p>Evaluate whether the chain can reach the target (sure/ likely/impossible). If the chain has already reached the target, it's 'sure'. If the unused relations include the current object, it's 'likely'. If there are no unused relations that include the current object, it's 'impossible'.
chain: F -&gt;, target: X, unused: 1. Y-F, 2. X-Y, 3. I-Q, 4. A-Q, 5. N-W, 6. N-A, 7. F-O, 8. O-W. The current object is F, there are unused relations that include F (1. Y-F, 7. F-O).
likely
chain: L -&gt; Q (use 2) -&gt;, target: Q, unused: 1. C-R, 3. C-J, 4. J-E, 7. G-A, 8. L-Y, 9. R-Q.
The chain already reaches the target object Q.
sure
chain: G -&gt; N (use 6) -&gt;, target: Q, unused: 1. C-R, 2. L-Q, 3. C-J, 4. J-E, 5. T-A, 8. L-Y, 9. R-Q, 10. Y-T.
The current object is N, and there are no unused relations that include N. impossible
{input}</p>
<h2>D.4. Linking chain construction prompt</h2>
<p>Given an input about spatial relations among objects, build the linking chain between the two queried objets.</p>
<p>Input:</p>
<ol>
<li>H is above S with a small gap between them. 2. S is positioned below I. 3. P is on the top side to I. What is the relation of the agent $S$ to the agent $P$ ?
Steps:
chain: S -&gt;, target: P, unused: 1. H-S, 2. S-I, 3. P-I.
chain: S -&gt; I (use 2) -&gt;, target: P, unused: 1. H-S, 3. P-I.
chain: I -&gt; P (use 3) -&gt;, target: P, unused: 1. H-S.
Answer: S -&gt; I (use 2) -&gt; P (use 3)</li>
</ol>
<p>Input:
{input}</p>
<h2>D.5. Spatial relation reasoning prompt</h2>
<p>Given a story about spatial relations among objects, answer the relation between two queried objects. Possible relations are: overlap, above, below, left, right, upper-left, upper-right, lower-left, and lower-right. If a sentence in the story is describing clock-wise information, then 12 denotes above, 1 and 2 denote upper-right, 3 denotes right, 4 and 5 denote lower-right, 6 denotes below, 7 and 8 denote lower-left, 9 denote left, 10 and 11 denote upper-left. If the sentence is describing cardinal directions, then north denotes above, east denotes right, south denotes below, and west denotes left. In all the spatial relations, assume that all agents occupy a position on a grid point of equally spaced points in the vertical and horizontal directions and that agents occupy the nearest grid point consistent with the spatial relation. The offsets of 9 spacial relations: offset (overlap) = $(0,0)$; offset (above) $=(0,1)$; offset (below) $=(0,-1)$; offset (left) $=(-1,0)$; offset (right) $=(1,0)$; offset (upper-left) $=(-1,1)$; offset (upper-right) $=$ $(1,1)$; offset(lower-left) $=(-1,-1)$; offset(lower-right) $=(1,-1)$.
Story:</p>
<ol>
<li>$Q$ is to the right of $O$ and is on the same horizontal plane.</li>
<li>$Q$ is slightly off center to the top left and $M$ is slightly off center to the bottom right.</li>
<li>$X$ and $E$ are next to each other with $X$ on the top and $E$ at the bottom.</li>
<li>O is sitting at the upper right position to E.</li>
<li>W is on the right side and below M. What is the relation of the agent $W$ to the agent E?
Linking chain: W -&gt; M (use 5) -&gt; Q (use 2) $-&gt;0$ (use 1) -&gt; E (use 4)
Reasoning:
Let's suppose W is at $(0,0)$. We can analyze the relation of $W$ to $E$ by following the linking chain and considering the relations provided in the story step by step. Start with W. According to 5, "W is on the right side and below M." This means $M$ is to the upper-left of $W . M=W+$ offset (upper-left) $=(0,0)+(-1,1)=(-1,1)$. Therefore, $M$ is at $(-1,1)$.
Then come to M. According to 2, "Q is slightly off center to the top left and $M$ is slightly off center to the bottom right." This means $Q$ is to the upper-left of M. Q= M+ offset (upper-left)</li>
</ol>
<p>$=(-1,1)+(-1,1)=(-2,2)$. Therefore, $Q$ is at $(-2,2)$.
Then come to Q. According to 1, "Q is to the right of 0 and is on the same horizontal plane." This means 0 is to the left of Q. $0=\mathrm{Q}+$ offset(left) $=(-2,2)+(-1,0)=(-3,2)$. Therefore, 0 is at $(-3,2)$.
Then come to 0 . According to 4 , " 0 is sitting at the upper right position to E." This means E is to the lower-left of $0 . \mathrm{E}=0+$ offset(lower-left) $=$ $(-3,2)+(-1,-1)=(-4,1)$. Therefore, $E$ is at $(-4,1)$.
We've reached E. So, considering W(0,0) and $\mathrm{E}(-4,1), \mathrm{W}$ is to the lower-right of E .
Answer: lower-right</p>
<p>Story:
{input}
Linking chain: {chain}</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>${ }^{4}$ The ArXiv version of this paper includes the Appendix containing prompting examples.&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref3:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref4:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref5:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>