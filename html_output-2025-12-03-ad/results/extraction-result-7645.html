<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-7645 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-7645</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-7645</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-143.html">extraction-schema-143</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how large language models are used to distill quantitative laws, equations, or functional relationships from collections of scholarly papers, including details of the models, prompting or fine‑tuning approaches, input corpora, extraction methods, types of laws, representation formats, evaluation datasets, metrics, baseline comparisons, validation procedures, and reported performance or limitations.</div>
                <p><strong>Paper ID:</strong> paper-258417843</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2304.14454v3.pdf" target="_blank">PMC-LLaMA: Towards Building Open-source Language Models for Medicine</a></p>
                <p><strong>Paper Abstract:</strong> Recently, Large Language Models (LLMs) have showcased remarkable capabilities in natural language understanding. While demonstrating proficiency in everyday conversations and question-answering situations, these models frequently struggle in domains that require precision, such as medical applications, due to their lack of domain-specific knowledge. In this paper, we describe the procedure for building a powerful, open-source language model specifically designed for medicine applications, termed as PMC-LLaMA. Our contributions are threefold: (i) we systematically investigate the process of adapting a general-purpose foundation language model towards medical domain, this involves data-centric knowledge injection through the integration of 4.8M biomedical academic papers and 30K medical textbooks, as well as comprehensive fine-tuning for alignment with domain-specific instructions; (ii) we contribute a large-scale, comprehensive dataset for instruction tuning. This dataset encompasses medical question-answering (QA), rationale for reasoning, and conversational dialogues, comprising a total of 202M tokens; (iii) we conduct thorough ablation studies to demonstrate the effectiveness of each proposed component. While evaluating on various public medical question-answering benchmarks, our lightweight PMCLLaMA, which consists of only 13 billion parameters, exhibits superior performance, even surpassing ChatGPT. All models, codes, datasets can be found in https://github.com/chaoyi-wu/PMC-LLaMA.</p>
                <p><strong>Cost:</strong> 0.004</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <p class="empty-note">No extracted data.</p>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <p class="empty-note">No potentially relevant new papers extracted.</p>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-7645",
    "paper_id": "paper-258417843",
    "extraction_schema_id": "extraction-schema-143",
    "extracted_data": [],
    "potentially_relevant_new_papers": [],
    "cost": 0.0043532499999999995,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>PMC-LLaMA: Towards Building Open-source Language Models for Medicine</p>
<p>Chaoyi Wu 
Cooperative Medianet Innovation Center
Shanghai Jiao Tong University
ShanghaiChina</p>
<p>Shanghai AI Laboratory
ShanghaiChina</p>
<p>Weixiong Lin wx_lin@sjtu.edu.cn 
Cooperative Medianet Innovation Center
Shanghai Jiao Tong University
ShanghaiChina</p>
<p>Shanghai AI Laboratory
ShanghaiChina</p>
<p>Xiaoman Zhang 
Cooperative Medianet Innovation Center
Shanghai Jiao Tong University
ShanghaiChina</p>
<p>Shanghai AI Laboratory
ShanghaiChina</p>
<p>Ya Zhang ya_zhang@sjtu.edu.cn 
Cooperative Medianet Innovation Center
Shanghai Jiao Tong University
ShanghaiChina</p>
<p>Shanghai AI Laboratory
ShanghaiChina</p>
<p>Yanfeng Wang wangyanfeng@sjtu.edu.cn 
Cooperative Medianet Innovation Center
Shanghai Jiao Tong University
ShanghaiChina</p>
<p>Shanghai AI Laboratory
ShanghaiChina</p>
<p>Weidi Xie 
Cooperative Medianet Innovation Center
Shanghai Jiao Tong University
ShanghaiChina</p>
<p>Shanghai AI Laboratory
ShanghaiChina</p>
<p>PMC-LLaMA: Towards Building Open-source Language Models for Medicine</p>
<p>Recently, Large Language Models (LLMs) have showcased remarkable capabilities in natural language understanding. While demonstrating proficiency in everyday conversations and question-answering situations, these models frequently struggle in domains that require precision, such as medical applications, due to their lack of domain-specific knowledge. In this paper, we describe the procedure for building a powerful, open-source language model specifically designed for medicine applications, termed as PMC-LLaMA. Our contributions are threefold: (i) we systematically investigate the process of adapting a general-purpose foundation language model towards medical domain, this involves data-centric knowledge injection through the integration of 4.8M biomedical academic papers and 30K medical textbooks, as well as comprehensive fine-tuning for alignment with domain-specific instructions; (ii) we contribute a large-scale, comprehensive dataset for instruction tuning. This dataset encompasses medical question-answering (QA), rationale for reasoning, and conversational dialogues, comprising a total of 202M tokens; (iii) we conduct thorough ablation studies to demonstrate the effectiveness of each proposed component. While evaluating on various public medical question-answering benchmarks, our lightweight PMC-LLaMA, which consists of only 13 billion parameters, exhibits superior performance, even surpassing ChatGPT. All models, codes, datasets can be found in https://github.com/ chaoyi-wu/PMC-LLaMA.</p>
<p>Introduction</p>
<p>The rapid advancement of large language models (LLMs), for example, OpenAI's ChatGPT (OpenAI 2023b) and GPT-4 (OpenAI 2023a) has truly revolutionized the natural language processing research (Nori, King et al. 2023;Singhal et al. 2022), sparking AI applications for numerous daily scenarios. Unfortunately, the training details and model architectures for the GPT-series remain unclear. The opensource LLMs, e.g., LLaMA-series (Touvron et al. 2023a,b), also show comparable performance with ChatGPT in the general domain. However, though the LLMs demonstrate proficiency in everyday conversations, in medical domain where requires high precision, they often produce seemingly accurate output but lead to incorrect conclusions, which * : Equal contributions. could be highly fatal. We conjecture this is due to their lack of comprehensive medical knowledge. Existing works have also explored several ways for adapting general-purpose LLMs towards medicine domain, like Med-Alpaca (Han, Adams et al. 2023), Chat-Doctor (Yunxiang et al. 2023) and MedPALM-2 (Anil, Dai et al. 2023). Among these, MedPALM-2 is the only work successfully outperforming ChatGPT while their training details, for example, training data, model architecture, remain unclear. Thus, systematic investigation on the medical domain adaptation for LLMs still needs to be discussed further especially in open-source community.</p>
<p>Our goal is to systematically adapt an open-source general LLM, i.e., LLaMA, towards the medicine domain from the following aspects. First, we adopt data-centric medicalspecific knowledge injection for the language model with a large-scale free text medical corpora. We claim that language models can accumulate enough medical knowledge in this step and build up a better embedding space for domainspecific complex terminologies. Second, augmenting the reasoning capabilities of the proposed model. This empowers the model to link its medical knowledge with provied case information and provide well-justified recommendations. Lastly, enhancing the alignment ability of LLMs. Robust alignment with various instructions facilitates effective zero-shot adaptation to a diverse spectrum of tasks.</p>
<p>In conclusion, in this paper we systematically build up an LLM for medicine through data-centric knowledge injection and medical-specific instruction tuning, and release an open-source lightweight medical-specific language model, PMC-LLaMA. Specifically, we first collect a large medical-specific corpus, named MedC-K, consisting of 4.8M biomedical academic papers and 30K textbooks for knowledge injection. We then adopt medical-specific instruction tuning on a new medical knowledge-aware instruction dataset, termed MedC-I, consisting of medical QA, rationale, and conversation with 202M tokens in total. We evaluate PMC-LLaMA on various medical QA benchmarks, surpassing ChatGPT and LLaMA-2 as shown in Fig. 1.</p>
<p>Related Work</p>
<p>Large Language Model. Recently, the great success of large language models (LLM) (OpenAI 2023b,a; Anil, Dai et al. 2023;Du et al. 2021), has garnered significant attention within the field of natural language processing. For example, OpenAI's strides with ChatGPT and GPT-4 have showcased remarkable capabilities in various tasks, including text generation, language translation, question answering, and more. However, intricate details concerning their training methodologies and weight parameters remain undisclosed. LLaMA (Touvron et al. 2023a) serves as an open-source alternative for the foundational language model, ranging from 7 billion to 65 billion parameters. In light of these advancements, there has been a surge of interest in tailoring language models for specific biomedical domains. Most of these models are prompt-tuned using LLaMA on a small medical corpus, resulting in a deficiency of comprehensive medical knowledge integration.</p>
<p>Instruction Tuning. For LLMs to follow natural language instructions and complete real-world tasks, instructiontuning has been widely used for alignment (Ouyang et al. 2022;Peng et al. 2023). This involves fine-tuning the model on a collection of tasks described via instructions, to effectively improve the zero-shot and few-shot generalization abilities of LLMs (Chung et al. 2022;Iyer et al. 2022). Building on the publicly accessible language models, Alpace (Taori et al. 2023) and Vicuna (Chiang, Li, and others. 2023) are proposed, by finetuning on the machine-generated instruction-following samples, showing promising performance. In the medical domain, Chat-Doctor (Yunxiang et al. 2023), and Med-Alpaca (Han, Adams et al. 2023), are instruction-tuned for medical question-answering and dialogue applications. Notably, Med-PaLM (Singhal et al. 2022) represents the pinnacle of LLMs in the medical field, trained with intensive instruction tuning on the strong PaLM model (with 540 billion parameters). However, its code and data remain inaccessible to the public.</p>
<p>Medical Foundational Language Model. In addition to instruction tuning, there has been extensive efforts on training foundation model for medicine, for example, BioBert, BioMedGPT, etc. (Lee et al. 2020;Zhang et al. 2023;Luo et al. 2022). However, these models exhibit certain limitations, first, most domain-specific models have been exclusively trained on medical corpora. The lack of exposure to diverse knowledge domains beyond medicine can impede the model's capability to perform reasoning or context understanding; second, these models are limited in model scale and are predominantly designed to base on BERT, thus imposing restrictions on their utility for a wide array of downstream tasks under zero-shot learning. In this work, we aim to resolve these two limitations by adapting a general LLM toward medicine with knowledge injection, followed by medical-specific instruction tuning.</p>
<p>Problem Formulation</p>
<p>In this paper, our goal is to systematically investigate the procedure for steering a pre-trained foundational language model to the knowledge-intense domain, i.e., medicine. The training process can be divided into two stages: first, a datacentric knowledge injection stage, that aims to enrich the language model with fundamental medical knowledge; second, a medical-specific instruction tuning stage, that tailors the model to align with clinical use cases. At training stage, assuming the text input as a sequence of tokens, e.g., U = {u 1 , u 2 , . . . , u N }, where each u i is a text token and N is the total sequence length, the training objective is to minimize auto-regressive loss, with the major difference on whether to compute loss on the entire sequence or only sub-sequence, as detailed in the following.</p>
<p>Data-centric Knowledge Injection. For the knowledge injection step, we simply minimize the default autoregressive loss, all free-form texts on medical knowledge can be used, for the model to accumulate sufficient medicalspecific knowledge contexts, formulated as
L(Φ) = − log Φ(u i |u &lt;i ).(1)
where u &lt;i indicates the tokens appear before index i and Φ denotes our model.</p>
<p>Medical-specific Instruction Tuning. At this stage, the token sequence is further split into instruction I, and response R, the former is to mimic user's query, thus the loss is ignored at training time, denoted as:
L(Φ) = − ui∈R log Φ(u i |u &lt;i , I).(2)
At inference time, the common use case is a conversation, where the user normally provides the question as instruction I, and the output of the model serves as the answer.</p>
<p>Dataset Construction</p>
<p>To support our two-stage training, namely data-centric knowledge injection, and medical-specific instruction tuning for alignment, we herein detail the procedure for constructing the high-quality language datasets.</p>
<p>Dataset-I: Fundamental Medical Knowledge</p>
<p>To steer a general-purpose foundational language model for medical scenario, we propose to first conduct data-centric knowledge injection, that aims to expose the model with medical-related terminologies and definitions. We primarily focus on two key data sources, namely, biomedical papers and textbooks.</p>
<p>Step-Ⅰ Data-   Our training flow can be separated into two parts, i.e., data-centric knowledge injection and medical-specific instruction tuning. In knowledge injection, we collect 4.8M biomedical academic papers and 30K medical books for further injecting knowledge into LLaMA. In the instruction tuning stage, we mainly consider three aspects, medical conversation, medical rationale question-answering, and knowledge graph, containing 202M tokens in total.</p>
<p>Knowledge Graph</p>
<p>Prompt-Description</p>
<p>Papers. As a valuable knowledge resource, academic papers naturally contains high-quality, cutting-edge medical knowledge. We start with the S2ORC (Lo et al. 2020) Datasets with 81.1M English-language academic papers, and pick out those biomedical related papers depending on whether having corresponding PubMed Central (PMC) IDs. As a result, there are around 4.8M biomedical papers left, totaling over 75B tokens.</p>
<p>Books. We collect 30K textbooks sourced from various outlets, for example, the open-library, university library, and reputable publishers, covering a wide range of medical specialties as shown in Fig. 3. For preprocessing, we first extract the text content from the book PDF, then carry out data cleaning via de-duplication and content filtering. Specifically, we eliminate extraneous elements such as URLs, author lists, superfluous information, document contents, references, and citations. Additionally, we have also removed any references to images and tables within the paragraphs, for example, ' Fig. 1'. After this thorough cleaning process, there are approximately 4B tokens left.</p>
<p>Combination. The two corpora encompass distinct types of medical knowledge, while papers predominantly cap-ture cutting-edge insights, books capture more fundamental medical knowledge, which is more crucial for pre-trained general-purpose language models. Hence, when blending these two datasets for knowledge injection training, we use a ratio of 15:4:1 at each training batch, by that we mean to emphasize "book" tokens more. Specifically, we sample more tokens from books, ensuring they occupy 15 parts per batch and sample tokens from "papers" less so that they occupy 4 parts per batch. For the remaining 1 occupation, we sample from a general language corpus, RedPajama-Data (Computer 2023) to form a complete batch. This mainly aims to avert catastrophic forgetting of previously acquired general text knowledge after extensive knowledge injection on largescale medical-specific data.</p>
<p>Knowledge Injection Training. Till here, we have constructed a large-scale language dataset of fundamental medical knowledge, termed as MedC-K. With such corpus, we conduct data-centric knowledge injection with autoregressive training, resulting a language model for medicine, named as PMC-LLaMA K , as the largest number of tokens are from PubMed Central academic papers. </p>
<p>Dataset-II: Medical Instructions</p>
<p>Here, we proceed to carry out instruction tuning with the goal of guiding the model to respond to various instructions, by exploiting the medical knowledge embedded in PMC-LLaMA K model. Generally speaking, our instruction tuning datasets are composed of three main parts, namely, medical consulting conversation, medical rationale QA, and medical knowledge graph prompting.</p>
<p>Medical Conversation. Considering there exists diverse doctor-patient dialogues in daily life, the questions raised by patients are naturally suitable as instructions and doctor responses as ground truth. We start with the data collected by Med-Alpaca (Han, Adams et al. 2023) and Chat-Doctor (Yunxiang et al. 2023), and further expand the provided instructions into various synonymous sentences to improve model's robustness to diverse instructions. Specifically, we use the GPT-4 with the following query prompt:</p>
<p>"Rewrite 10 sentences that convey similar meanings to what I've stated: {instruction seeds}.", where {instruction seeds} denotes the provided instruction from ChatDoctor or MedAlpaca, and the query can be repeated until the desired prompt number. At training time, we randomly select one instruction from the instruction base, to simulate the inputs from real users and avoid over-fitting on specific instruction templates.</p>
<p>Medical Rationale QA. Beyond daily conversations, we also consider equipping our model with reasoning ability with professional medical knowledge. We start with the training sets of the open-source medical multi-choice question-answering datasets, such as USMLE (Jin, Pan et al. 2021), PubMedQA (Jin et al. 2019) and MedMCQA (Pal, Umapathi et al. 2022). Despite the questions in them naturally demanding medical-specific knowledge, most of these datasets only include plain choices, lacking detailed reasoning guidance. To complement such information, we prompt ChatGPT (OpenAI 2023b) for causality analysis. Specifically, given a QA pair, we query ChatGPT to get rationale output (check supplementary for details), and treat the output as an explanation with structured format shown at the bottom of Fig. 2.</p>
<p>Medical Knowledge Graph Prompting. In addition to the aforementioned data, we also consider exploiting med-ical knowledge graphs UMLS (Lindberg, Humphreys, and McCray 1993), to align with clinicians' experience. Specifically, to link the medical terminologies with their respective knowledge description or corresponding relationships, we construct QA pairs to translate the common knowledge graph. There are two main types contained in medical knowledge graph, i.e., entity descriptions and entity relationships. We add two different prompts for them as shown at the bottom of Fig. 2, that demands the model to output descriptions for a certain entity or predict the relationship between two entities.</p>
<p>Medical-spcific Instruction Tuning. By combining the above three parts together, we form a large-scale, highquality, medical-specific instruction tuning dataset, MedC-I, consisting 202M tokens. We further tune PMC-LLaMA K on it, resulting in our final model -PMC-LLaMA.</p>
<p>Experiment Training Details</p>
<p>We start by carrying out knowledge injection on open-source LLaMA model, optimizing an auto-regressive loss. Specifically, at training time, the max context length is set as 2048, with a batch size to be 3200, and the model is trained with AdamW optimizer (Loshchilov and Hutter 2017) with a learning rate 2e-5. We adopt the Fully Sharded Data Parallel (FSDP) acceleration strategy, bf16 (Brain Floating Point) data format, and gradient checkpointing (Chen et al. 2016).</p>
<p>Since we sample more tokens from books in each batch, the model will finish seeing all book tokens earlier. Thus, we here define 1 epoch for seeing all book tokens instead of seeing all mixed tokens. The model is trained with knowledge injection for 5 epochs with 32 A100 GPUs. Then we carry out medical-specific instruction tuning on MedC-I, for 3 epochs with 256 batch sizewith 8 A100 GPUs. Note that, at instruction tuning stage, each epoch refers to looping through all sequences.</p>
<p>Benchmarks</p>
<p>In the literature, the primary method for measuring the ability of medical language models is based on multiple-choice question answering, which uses accuracy as the main metric.</p>
<p>Following the convention, we adopt three prominent medical question-answering (QA) benchmarks for evaluation.</p>
<p>• PubMedQA (Jin et al. 2019) is a biomedical QA dataset collected from PubMed abstracts. The task of Pub-MedQA is to answer research questions with yes/no/maybe, which can be considered as the multiple-choice question. It is split into three subsets: 1k manually labeled pairs (PQA-L), 61.2k unlabeled pairs (PQA-U), and 211.3k artificially generated pairs (PQA-A). Following former works (Diao, Pan et al. 2023), we view PQA-A as the train set, PQA-L as the test set, and discard the PQA-U parts.</p>
<p>• MedMCQA (Pal, Umapathi et al. 2022) is a dataset of multiple choice questions, that are sourced from mock exams and past exams of two Indian medical school entrance exams called AIIMS and NEET-PG (Pal, Umapathi et al. 2022 </p>
<p>Baseline Models</p>
<p>LLaMA (Touvron et al. 2023a). LLaMA is the most widely-used open-source language model, it has been trained on a large text corpus with only auto-regressive learning, i.e., no instruction tuning is involved.</p>
<p>LLaMA-2 (Touvron et al. 2023b). LLaMA-2 is the improved version of LLaMA that has been further tuned with instructions. Its largest version (70B) is reported to be the best on natural scenery among the open-source LLMs.</p>
<p>ChatGPT (OpenAI 2023b). ChatGPT is a commercial model released by OpenAI in November, 2022, that has shown remarkable performance on a wide range of NLP tasks in various domains, including medicine. Note that, since the exact details of ChatGPT are confidential, we follow the general presumption that ChatGPT is roughly the same as GPT-3 in model sizes (175B) (Kung et al. 2022).</p>
<p>Med-Alpaca (Han, Adams et al. 2023). Med-Alpaca is a model further fine-tuned on Alpaca (Taori et al. 2023) using medical instruction data. They focus on the task of assisting medical dialogues and question-answering.</p>
<p>Chat-Doctor (Yunxiang et al. 2023). Chat-Doctor is a language model aiming for health assistants, that is designed to provide users with medical information, advice, and guidance. For training, it has leveraged the dialogue-based instruction tuning data.</p>
<p>Evaluation Settings</p>
<p>In this section, we describe the evaluating detail to compare the above language models on the QA benchmarks.</p>
<p>Note that, we do not claim the presented comparison to be completely fair, as a number of training details, for example, data, architecture remain undisclosed for the commercial model. Therefore, we only treat these baseline models for reference, and more focused on presenting our procedure for building on a powerful language model for medicine. Our evaluation settings can be divided into two types: task-specific fine-tuning evaluation and zero-shot instruction evaluation.</p>
<p>Task-specific Fine-tuning Evaluation. In this evaluation setting, we use the combination of three QA training sets to further fine-tune a language model and then evaluate it. For models without instruction tuning, for example, LLaMA and PMC-LLaMA K , we adopt this evaluation setting by default.</p>
<p>Zero-shot Instruction Evaluation. In this evaluation setting, we directly test the model by giving a medical QA instruction, e.g., "Make a choice based on the question and options.", without doing any task-specific fine-tuning. Most models are evaluated in this setting, i.e., LLaMA-2, Med-Alpaca, Chat-Doctor, ChatGPT, and our own PMC-LLaMA.</p>
<p>Results</p>
<p>In this section, we will introduce the experimental results. First, we conduct thorough ablation study on medical QA benchmarks, to demonstrate the effectiveness of the different components in our training procedure. Then we show the comparison with different SOTA methods. Lastly, we present qualitative cases studies.</p>
<p>Ablation Study</p>
<p>As shown in Tab. 1, we systematically study the different design choices on various medical QA benchmarks, for example, effect of the model scale, data-centric knowledge injection, and medical-specific instruction tuning. Model scale. The scaling law (Kaplan et al. 2020) can also be observed in the medical corpus, for example, as shown in the table, when switching the model size from 7B to 13B, performance on all benchmarks have been improved. This phenomenon holds for both baseline LLaMA model and PMC-LLaMA K , which has further trained with fundamental medical knowledge. Data-centric knowledge injection. Compared with baseline 7B LLaMA model, integrating biomedical papers brings a performance gain from 44.54% to 44.70% and 48.51% to 50.54% on MedQA and MedMCQA respectively. While after adding books for training, the performance is improved significantly, i.e., obtaining 1.02%, 2.94%, and 1.2% on MedQA, MedMCQA and PubMedQA respectively. Both observations have shown the importance of injecting fundamental medical knowledge.</p>
<p>Medical-specific instruction tuning. We start instruction tuning with only rationale QA data. In this cases, since only QA task is considered, the difference from task-specific finetuning only lies on whether to give rationale sentence as supervision signal. We observe that simply incorporating rationale cases can lead to enhance QA results compared to  task-specific fine-tuning on plain choice data, showcasing an improvement of 1.17% on the MedQA dataset. Furthermore, integrating conversations with rationale QA for instruction tuning can produce substantial enhancements, with performance boosts from 49.32% to 54.43% on MedQA. This demonstrates the pivotal role played by the diversity of question types during the instruction tuning stage, as all involved questions will be limited on medical choice tests without conversation. In addition, the incorporation of a knowledge graph introduces a further improvement of 1.93% on the MedQA dataset, demonstrating the importance of using explicit instructions to emphasize the key medical concepts.</p>
<p>Comparison with Baselines</p>
<p>In Tab. 2, we conduct a comparative analysis of our model against SOTA baseline models on three QA benchmark datasets for evaluation. We also show a qualitative case study to demonstrate the conversation and rationale ability.</p>
<p>Medical QA Ability. While comparing with other large language models on medical QA benchmarks, PMC-LLaMA achieves superior results on most of them, improving the average accuracy from 54.97% to 64.43%, even surpassing the powerful ChatGPT, despite containing significantly fewer parameters.</p>
<p>Zero-shot Case Study. In Fig. 4, we show qualitative examples with the zero-shot prediction from PMC-LLaMA and ChatGPT to verify the quality of prediction, covering patient-physician conversation and rationale QA. The query in Fig. 6a is raised online after our data collection, thus, none of the models have seen this the question at training time. Based on the patient's description, both PMC-LLaMA and ChatGPT recognize the symptom of recurrent UTIs (urinary tract infections), while PMC-LLaMA proposes a sensitivity test as the specific advice, rather than the general suggestion (investigate the underlying causes) given by Chat-GPT. Fig. 6b shows a QA case of microbiology. As can be seen, PMC-LLaMA not only produces the accurate answer, but also briefly analyzes the wrong options, forming a more comprehensive rationale. Another case that focuses on pharmacology knowledge is illustrated in Fig. 6c. Both PMC-LLaMA and ChatGPT have shown to properly understand Rifampin's efficacy and mechanism of side effects.</p>
<p>Conclusion</p>
<p>In this paper, we have systematically investigated the procedure for building up a medical-specific large language model based on an open-source large language model, including data-centric knowledge injection and medical-specific instruction tuning. As a result, our proposed PMC-LLaMA is the first, open-source medical-specific language model, that demonstrates superior performance on various medical benchmarks, surpassing ChatGPT and LLaMA-2 with much fewer parameters.</p>
<p>Hello, I am a young and healthy teenage girl, but I suffer from many severe UTIs (urinary tract infections). I get an average of about eight infections annually over the past four years. I follow all of the conventional methods of hygiene, including vitamin C intake, using cotton underwear, etc. I drink about a gallon of water daily and exercise. This problem has spread to my kidneys the initial time and has never escalated to that state. I developed allergies to all antibiotics, so I am unsure how to treat them at this point. Also, I constantly have cloudy urine and lower back pain.</p>
<p>Please help.</p>
<p>Prompt</p>
<p>I have read your query and understand your concern. You seem to be having chronic UTI.</p>
<p>You need to get your urine culture and sensitivity test done to know the exact bacteria causing the infection and the antibiotics to which they are sensitive to. Based on the report, you need to take appropriate antibiotics for appropriate duration. Cloudy urine and lower back pain are due to the infection.</p>
<p>Please see a urologist for further management. Thanks.</p>
<p>PMC LLaMA</p>
<p>I'm not a doctor, but here are some points you might consider discussing with a healthcare professional:</p>
<ol>
<li>Specialist Consultation: Given your recurrent UTIs, seeking advice from a urologist could offer insights and tailored recommendations. 2. Alternative Treatments: Inform the urologist about your antibiotic allergies. They might suggest non-antibiotic approaches to manage and prevent UTIs. 3. Investigate Underlying Causes: Your doctor can explore possible underlying factors contributing to your frequent UTIs. 4. Address Symptoms: It's important to discuss your persistent cloudy urine and lower back pain for proper evaluation and management. 5. Medical Guidance: Trusting a medical professional's expertise will guide you toward the best solutions for your situation.</li>
</ol>
<p>Remember, consulting a healthcare provider is essential for personalized advice and treatment tailored to your individual needs.</p>
<p>ChatGPT</p>
<p>(a) Patient-Physician Conversation</p>
<p>A microbiologist is studying the emergence of a virulent strain of the virus. After a detailed study of the virus and its life cycle, he proposes a theory: Initially, a host cell is co-infected with 2 viruses from the same virus family. Within the host cell, concomitant production of various genome segments from both viruses occurs. Ultimately, the different genome segments from the viruses are packaged into a unique and novel virus particle. The newly formed virus particle is both stable and viable and is a new strain from the virus family that caused the outbreak of infection. Which of the following viruses is capable of undergoing the abovementioned process? A. Epstein-Barr virus B. Human immunodeficiency virus C. Rotavirus</p>
<p>D. Vaccinia virus</p>
<p>Prompt</p>
<p>Rotavirus is a double-stranded RNA virus. It is the most common cause of diarrhea in infants and children. The virus has a characteristic wheel-like appearance (from which it derives its name) and undergoes a unique process of viral replication. Initially, a host cell is co-infected with 2 viruses from the same virus family. Within the host cell, concomitant production of various genome segments from both viruses occurs. Ultimately, the different genome segments from the viruses are packaged into a unique and novel virus particle. The newly formed virus particle is both stable and viable and is a new strain from the virus family that caused the outbreak of infection. Epstein-Barr virus is a herpesvirus that causes infectious mononucleosis. Human immunodeficiency virus is a retrovirus that causes AIDS. Vaccinia virus is a large, complex double-stranded DNA virus that is related to smallpox. The correct answer is: C. Rotavirus</p>
<p>PMC LLaMA</p>
<p>The correct answer is: C. Rotavirus The description provided corresponds to the process of reassortment or genetic reassortment, which is commonly seen in segmented viruses like rotavirus. Rotavirus has a segmented genome, and when a host cell is co-infected with different strains of rotavirus, segments from different strains can mix and be packaged into new virus particles. This can result in the emergence of novel strains with a combination of genetic material from different parent strains, leading to changes in virulence or other properties.</p>
<p>ChatGPT</p>
<p>(b) Microbiology Question</p>
<p>A 26-year-old woman presents to a gynecologist after a missed period. After performing a complete physical examination and a screening test for pregnancy, her gynecologist informs her that she is pregnant. She is very surprised as she has been taking oral contraceptives regularly. When the gynecologist asks her about the consumption of any other medications, she mentions that she was placed on treatment for pulmonary tuberculosis (TB) 2 months ago. Her current anti-TB regimen includes rifampin, isoniazid, pyrazinamide, and ethambutol.</p>
<p>Which of the following mechanisms best explains the failure of oral contraceptives in this patient? Rifampin, one of the medications used in the patient's anti-TB regimen, is known to induce cytochrome P450 enzymes, particularly CYP3A4. This enzyme induction can accelerate the metabolism of many drugs, including oral contraceptives containing ethinylestradiol and progesterone. This results in decreased serum levels of these hormones, which compromises the effectiveness of the oral contraceptive and may lead to contraceptive failure. Therefore, it's important for healthcare providers to counsel patients on using additional or alternative contraceptive methods while taking rifampin or other medications that induce CYP3A4.</p>
<p>ChatGPT</p>
<p>Rifampin is a microsomal enzyme inducer and can increase the rate of metabolism of various drugs. It can increase the rate of metabolism of the oral contraceptive by inducing CYP3A4, leading to decreased serum levels of ethinylestradiol and progesterone. Rifampin does not affect the intestinal absorption of drugs. Pyrazinamide interferes with the intestinal absorption of the oral contraceptive. Ethambutol does not affect the renal elimination of drugs.</p>
<p>Option A is correct. </p>
<p>Prompt ChatGPT for Rationale QA</p>
<p>To form a rationale QA dataset, we have constructed several query prompts to distillate the response of ChatGPT. In this section we show details about the main two types of query prompts we use. Based on their response format, they can be divided into general-wise rationale prompts and optionalwise rationale prompts. In both cases, ChatGPT will be presented with QA pairs and solicited to generate rationales for gap mitigation from the question to answer. General-wise Rationale Prompts. The answer is Option C Atrophy, so the analysis is Chronic urethral obstruction because of urinary calculi, prostatic hyperophy, tumors, normal pregnancy, tumors, uterine prolapse or functional disorders cause hydronephrosis which by definition is used to describe dilatation of renal pelvis and calculus associated with progressive atrophy of the kidney due to obstruction to the outflow of urine.</p>
<h1>Few-shot Example 2 Quesion: Which vitamin is supplied from only animal source? A. Vitamin C B. Vitamin B7 C. Vitamin B12 D. Vitamin D The answer is Option C Vitamin B12, so the analysis is Vitamin B12 (Cobalamin) is synthesized solely by microorganisms. In humans, the only source for humans is food of animal origin, e.g., meat, fish, and dairy products. Vegetables, fruits, and other foods of nonanimal origin doesn't contain Vitamin B12 . Daily requirements of vitamin Bp is about 1-3 pg. Body stores are of the order of 2-3 mg, sufficient for 3-4 years if supplies are completely cut off.</h1>
<p>Now help me with another question {new question}</p>
<p>The answer is {answer idx}, so the analysis is In the example prompt upper, we provide two few-shot examples, guiding ChatGPT to generate comprehensive ratio-nales for the question. Through this prompt query, the response will be organized in a whole sentence. In the example prompt upper, we provide an examples to guide ChatGPT to generate option-wise rationale. We hope the answer can be analysed per option so that mode dense analysis can be added for model knowledge guidance.</p>
<p>Zero-shot Samples</p>
<p>Due to the space limitaion in the main body, we only show three cases. Here we present a broader array of zero-shot cases about conversation and rationale question-answering, providing a more encompassing perspective of PMC-LLaMA's capabilities.</p>
<p>QA Rationales As shown in Fig. 5, PMC-LLaMA and ChatGPT demonstrate commensurate abilities through diverse medical branches, which is within expectation. Due to our tons of efforts in knowledge injection, PMC-LLaMA possesses profound knowledge and tends to give thorough explanation of each option in question. This could be a favorable feature to those who trying to have a comprehensive knowledge about patients' symptoms.</p>
<p>Conversations Though PMC-LLaMA shows high competence on knowledge intensive cases, it's not as good in free-form conversations, especially when the topic branches off from medical domain.</p>
<p>In Fig6 (a), the patient describes a minor problem under his tongue. ChatGPT suggests the patient to monitor the symptom development, and to consult a professional if necessary. While PMC-LLaMA suggests the cause as rather severe disease, which could be an overestimation. Also,Fig6 (b) shows the user is trying to get pregnant who lacks libido. In this case, the proper advice should start from daily practice instead of prescribed medicine given by PMC-LLaMA. Fig 6 (c) presents a subtle case where the patient has low confidence about his physician's diagnosis and ask for second opinion. Any negative implication might give misguidance to the patient. Herein PMC-LLaMA gives straight suggestion to help the patient validate his health condition. But ChatGPT's response is wiser. It first attempts to persuade the patient to trust his own physician, and recommends further communication with the doctor.</p>
<p>Given the broader array of zero-shot samples, we can safely conclude that PMC-LLaMA have powerful abilities on knowledge intensive questions, and further exploration is needed on conversation ability.</p>
<p>A 56-year-old man with a history of hypertension presents to his physician with progressive fatigue and new onset muscle cramps. He has had no recent changes to his medication regimen, which includes hydrochlorothiazide, lisinopril, and amlodipine. His temperature is 98.0°F (36.7°C), blood pressure is 174/111 mmHg, pulse is 70/min, respirations are 12/min, and oxygen saturation is 98% on room air. The patient's cardiopulmonary and abdominal exams are unremarkable. Laboratory values are ordered as seen below. Serum: Na+: 138 mEq/L Cl-: 100 mEq/L K+: 3.3 mEq/L HCO3-: 33 mEq/L BUN: 20 mg/dL Glucose: 129 mg/dL What is the most likely underlying etiology of this patient's hypertension? A. Aldosterone excess B. Catecholamine-secreting mass C. Cortisol excess D. Impaired kidney perfusion Prompt This patient's laboratory values reveal a low bicarbonate (HCO3-) level, which can be caused by either an increase in bicarbonate loss or an increase in bicarbonate renal absorption. The patient's clinical picture is consistent with a diagnosis of primary aldosteronism, which is characterized by aldosterone excess. This can be caused by either an aldosterone-secreting adrenal adenoma or hyperplasia. The excess aldosterone causes increased renal absorption of sodium and increased excretion of potassium and hydrogen ions, leading to hypokalemic metabolic alkalosis. The excess aldosterone can be suppressed by the administration of exogenous corticosteroids, which explains the worsening of the patient's hypertension after the administration of dexamethasone.</p>
<p>The correct answer is A.</p>
<p>PMC LLaMA</p>
<p>A. Aldosterone excess</p>
<p>The clinical presentation, along with the laboratory values, suggests the possibility of primary hyperaldosteronism, also known as Conn's syndrome. The patient's hypertension, low potassium (hypokalemia), and metabolic alkalosis (elevated HCO3-) are indicative of excessive aldosterone production by the adrenal glands. This excess aldosterone leads to sodium retention and potassium excretion, which contributes to hypertension and electrolyte imbalances. The patient's fatigue and muscle cramps are likely due to the hypokalemia. The absence of significant changes to the patient's medication regimen and the specific electrolyte abnormalities make aldosterone excess the most likely underlying etiology in this case.</p>
<p>ChatGPT</p>
<p>(a) Neurology</p>
<p>A 61-year-old man with schizophrenia in a locked inpatient psychiatry unit was observed making an unusual smacking motion with his lips, pursing his mouth, and blinking excessively. These symptoms started slowly about 2 weeks ago and have become more pronounced, but they do not seem to bother the patient. He resides in an inpatient psychiatric facility where he has been successfully treated with haloperidol for the past several months. His physical exam and vitals are within normal limits. Which of the following accurately describes his symptoms?</p>
<p>A. Tardive dyskinesia B. Acute dystonia C. Pseudoparkinsonism D. Palsy</p>
<p>Prompt</p>
<p>The patient is experiencing a form of tardive dyskinesia called "oral-buccal dyskinesia" characterized by lip smacking, chewing, puckering, and pursing of the lips. Tardive dyskinesia is a late-appearing extrapyramidal symptom that is often permanent. It is more likely to occur in the elderly and with typical antipsychotic medications such as haloperidol. Acute dystonia is a movement disorder that occurs during the first few hours to days after the initiation of antipsychotic medication. Pseudoparkinsonism is a common extrapyramidal symptom that mimics Parkinson's disease. It is often reversible with central anticholinergic medication such as trihexyphenidyl. Akathisia is a subjectively unpleasant state of inner restlessness where one feels a need to move Significantly, this symptom does not exist in the list of options.</p>
<p>The correct answer is A.</p>
<p>PMC LLaMA</p>
<p>A. Tardive dyskinesia</p>
<p>The patient's presentation of unusual smacking motions with his lips, pursing his mouth, and excessive blinking is consistent with tardive dyskinesia. Tardive dyskinesia is a movement disorder that can occur as a side effect of long-term use of antipsychotic medications, including haloperidol. It often involves involuntary, repetitive, and abnormal movements of the face, lips, tongue, and sometimes other body parts. In this case, the symptoms started slowly after several months of haloperidol treatment, which aligns with the time frame typically associated with tardive dyskinesia development. It's important to monitor and manage such side effects to ensure the patient's overall wellbeing and mental health treatment.</p>
<p>ChatGPT</p>
<p>(b) Psychiatry</p>
<p>A 17-year-old football player with no significant past medical history, social history, or family history presents to his pediatrician with itching in his groin. He says this started during summer workouts leading up to this season. He denies having any rash anywhere else on his body. The blood pressure is 123/78 mm Hg, pulse is 67/min, respiratory rate is 15/min, and temperature is 38.1°C (98.7°F). Physical examination reveals an erythematous, well-demarcated patch with peripheral scale on the left thigh, pubic region, and perineum. There is no apparent scrotal involvement with the rash. How can you confirm the suspected diagnosis?</p>
<p>A. KOH examination of lesion scrapings B. Nikolsky's sign on physical exam C. Gram stain of skin scrapings D. AFB stain of skin scrapings</p>
<p>Prompt</p>
<p>A. KOH examination of lesion scrapings</p>
<p>The presentation of an erythematous, welldemarcated patch with peripheral scale in the groin area is suggestive of a fungal infection, likely tinea cruris (also known as jock itch). KOH (potassium hydroxide) examination of lesion scrapings is a commonly used diagnostic method to confirm fungal infections. It involves microscopic examination of skin scrapings after treating them with KOH, which helps to visualize the fungal elements (such as hyphae and spores) under the microscope. This test can help differentiate fungal infections from other conditions with similar symptoms and guide appropriate treatment. Nikolsky's sign is not relevant in this case, and Gram stain and AFB (acid-fast bacilli) stain are used for different types of infections.</p>
<p>ChatGPT</p>
<p>Tinea cruris is a dermatophyte infection of the groin, which can be confirmed by KOH examination of the scale, which will demonstrate short hyphae and round spores. The rash is usually erythematous and scaly, and the borders are well demarcated. It is more common in hot, humid weather, and is more common in those who sweat heavily. It is usually contracted from baths, showers, or swimming pools. Tinea cruris can be distinguished from other rashes by the fact that it does not spare the scrotum. Nikolsky's sign is positive in pemphigus vulgaris, where you can induce a blister with gentle rubbing. Gram stain of skin scrapings would be useful in diagnosing a staphylococcal infection, which could present with a similar rash. AFB stain of skin scrapings would be useful in diagnosing tuberculosis, which could also present with a rash. The correct answer is A. </p>
<p>Figure 1 :
1In the left, we show the general comparison between our PMC-LLaMA with LLaMA-2 and ChatGPT. On the right, we visually show the advantages of our model in model sizes. PMC-LLaMA is much smaller than the others.</p>
<p>Instruction:... Explain the definition of ... Input: Question: What is the meaning ... Response: Answer: the entity denotes ...</p>
<p>Figure 2 :
2The training pipeline of PMC-LLaMA.</p>
<p>Figure 3 :
3Distribution of medical textbooks categories. The box sizes denote the book numbers for different categories.</p>
<p>A. Induction of CYP3A4 by rifampin leading to decreased serum levels of ethinylestradiol and progesterone B. Induction of CYP2A6 by rifampin leading to increased inactivation of ethinylestradiol C. Interference with the intestinal absorption of the oral contraceptive by pyrazinamide D. Increased renal elimination of the progesterone component of the oral contraceptive by ethambutol Prompt The correct answer is: A.</p>
<p>Figure 4 :
4Examples of three zero-shot cases from PMC-LLaMA and ChatGPT. (a) compares their responses to the patient's query, where PMC-LLaMA proposes more concrete suggestions. (b) shows the probing of microbiology knowledge. And PMC-LLaMA analyze both correct and incorrect options, enhancing the comprehensiveness of the analysis. Example (c) examines the models' grasp of Pharmacology, and they respond with roughly equivalent answers. The correct options are marked bold.</p>
<p>about the question, take the following two questions as examples # Few-shot Example 1 Quesion: Chronic urethral obstruction due to benign prismatic hyperplasia can lead to the following change in kidney parenchyma A. Hyperplasia B. Hyperophy C. Atrophy D. Dyplasia</p>
<p>Figure 5 :
5Examples of zero-shot QA rationales covering more medical branches. The correct options are marked bold.</p>
<p>Question: Which of the following ... Options: A. ... B. ... C. ... D. ... Response: Option A is wrong because ... Answer: Option D is correct. It's possible that you have a vocal cord polyp. To confirm ... Instruction: ... Determine the relation between... Input: Question: What is the relation ... Response: Answer: Mercaptopurine ... has ...centric Knowledge Injection </p>
<p>LLaMA </p>
<p>Open-sorce LLMs 
for natural scenery </p>
<p>4.8M Academic Papers 
30K Medical Books 
Coronaviruses are a family of 
viruses </p>
<p>Knowledge Injection </p>
<p>PMC-LLaMA K </p>
<p>Step-Ⅱ Medical-specific Instruction Tuning </p>
<p>PMC-LLaMA K </p>
<p>LLMs with 
Medical Knowledge </p>
<p>Conversation 
Knowledge Graph 
Rationale QA </p>
<p>Instruction Tuning </p>
<p>Instruction: Assume you are … 
R: </p>
<p>PMC-LLaMA </p>
<p>MedC-K </p>
<p>MedC-I </p>
<p>MedC-I Samples </p>
<p>Rationale QA 
Instruction: 
In your capacity as ... Answer the medical 
questions. 
Input: 
Conversation 
Instruction: 
If you are a doctor, please answer the 
medical questions based on ... 
Input: 
Doctor, I have been experiencing ... 
What could be the problem? 
Response: 
Prompt-Relation </p>
<p>). The train split contains 182,822 questions, and the test split contains 4183 questions. Each question has 4 choices. • USMLE (Jin, Pan et al. 2021) is a dataset of multiple choice questions (4 choices per question), based on the United States Medical License Exams. The dataset is collected from the professional medical board exams, covering three languages: English, simplified Chinese, and traditional Chinese, containing 12,724, 34,251, and 14,123 questions respectively. Here, we use the English parts and split it into 10,178 questions for training, 1273 for validation, and 1273 for testing, following the official splits.</p>
<p>Table 1 :
1Ablation study on QA benchmarks. ACC scores are reported in the table. Note that for the models without ability to follow instruction, we task-specific fine-tune them on the combination of the three downstream training sets to get the number.Method 
Model Size 
Knowledge Injection 
Instruction Tuning 
MedQA MedMCQA PubMedQA 
Papers 
Books 
Rationale Conversation Knowledge Graph </p>
<p>Baseline (LLaMA) 
7B 
44.54 
48.51 
73.40 
Baseline (LLaMA) 
13B 
45.48 
51.42 
76.40 </p>
<p>PMC-LLaMAK </p>
<p>7B 
44.70 
50.54 
69.50 
7B 
45.56 
51.45 
74.60 
13B 
48.15 
54.15 
77.10 </p>
<p>PMC-LLaMA </p>
<p>13B 
49.32 
54.56 
77.20 
13B 
54.43 
55.77 
77.00 
13B 
56.36 
56.04 
77.90 </p>
<p>Table 2 :
2Evaluation on QA Benchmarks. ACC scores are reported. Average refers to the average of the three datasets.Methods 
Model Size 
MedQA 
MedMCQA 
PubMedQA 
Average </p>
<h2>Human (pass)</h2>
<h2>50.0</h2>
<h2>60.0</h2>
<h2>Human (expert)</h2>
<p>87.0 
90.0 
78.0 
85.0 </p>
<p>ChatGPT (OpenAI 2023b) 
175B 
57.0 
44.0 
63.9 
54.97 
LLaMA-2 (Touvron et al. 2023b) 
13B 
42.73 
37.41 
68.0 
49.40 
LLaMA-2 (Touvron et al. 2023b) 
70B 
43.68 
35.02 
74.3 
51.00 
Med-Alpaca (Han, Adams et al. 2023) 
13B 
30.85 
31.13 
53.2 
38.38 
Chat-Doctor (Yunxiang et al. 2023) 
7B 
33.93 
31.10 
54.3 
39.78 </p>
<p>PMC-LLaMA 
13B 
56.36 
56.04 
77.9 
64.43 </p>
<p>Optional-wise Rationale Prompts {the quesion} Answer: {answer idx} Analyze each option in detail in the format of Option A is TRUE. [option analysis for A] Option B is FALSE. [option analysis for B] Option C is FALSE. [option analysis for C] Option D is FALSE. [option analysis for D]
SupplementaryIn addition to previously introduced methods, we provide detailed implementation of prompt templates used to query ChatGPT to form our instruction tuning data. Besides, we also demonstrate more few-shot samples comparing PMC-LLaMA and ChatGPT.PromptHi, Thanks for asking the query.White patch under the tongue can be due to a number of reasons like trauma, ulceration, infection, leukoplakia, lichen plans, oral submucous fibrosis.I would suggest you to visit to an Oral and Maxillofacial Surgeon and get a thorough clinical examination done. Take a biopsy of the lesion to confirm the diagnosis.If it is a traumatic ulcer it will heal within 7-10 days. If it is an infective etiology it will heal with antibiotic course. If it is a leukoplakia it will regress with the use of antioxidants and antioxidants.Hope this helps out. Regards.PMC LLaMAOf course, I'd be happy to provide more detailed suggestions:Monitor: Since the white area is not causing pain or discomfort, you might choose to observe it for a few more days to see if there are any changes in size, color, or any development of symptoms.Maintain Oral Hygiene: Continue practicing good oral hygiene by brushing your teeth and tongue gently twice a day and using mouthwash to keep the area clean.Avoid Irritation: Be mindful of any irritants that might come into contact with the area, such as spicy or acidic foods. Avoid excessive alcohol or tobacco use, as they can sometimes contribute to oral issues.Hydration: Make sure you're staying adequately hydrated, as dry mouth can sometimes lead to minor irritations.Consult a Professional: If the white area persists beyond a couple of weeks or if you become concerned, it's a good idea to consult a dentist or a doctor for a proper examination. They can determine the cause and provide appropriate advice or treatment if necessary.Remember, while the area might not be causing immediate discomfort, it's always best to err on the side of caution and seek professional advice.ChatGPT(a) General Health AdviceHello doctor, Trying to get pregnant from last one year. All the tests for both of us are fine. The only problem is we are not very high on libido.PromptHello.I suggest you to get your thyroid profile done. Hypothyroidism can cause low libido. I also suggest you to get your hemoglobin and serum ferritin levels done. Low hemoglobin can also cause low libido. If everything is fine then you can take some medicines for increasing libido. You can discuss with your doctor about this.Hope I have been helpful.PMC LLaMAHello, It's great that you've been proactive about getting tests done and ensuring your overall health for pregnancy. Regarding low libido, it's important to remember that sexual desire can be influenced by various factors, including stress, lifestyle, hormonal changes, and emotional well-being. Here are a few suggestions you might consider:Open Communication: Talk to your partner openly about your feelings and concerns. Communication can help both of you understand each other's needs and work together to address them.Stress Management: High levels of stress can affect libido. Finding ways to manage stress, such as through relaxation techniques, exercise, or hobbies, can positively impact your desire.Healthy Lifestyle: Regular exercise, a balanced diet, and adequate sleep can all contribute to overall well-being, which in turn can affect libido.Intimacy: Focus on building emotional intimacy with your partner. Sometimes, enhancing emotional connection can lead to increased sexual desire.Professional Help: If you find that low libido is persistently affecting your relationship and wellbeing, consider seeking advice from a healthcare professional or a therapist who specializes in sexual health.Remember, everyone's experience with libido is unique. Don't hesitate to reach out to a healthcare professional who can offer personalized guidance based on your specific situation and needs.ChatGPT(b) Insufficient Symptomatic DescriptionHi doctor, I am a 32-year-old male. My body is athletic, with 22 % body fat. Four years back, I was found accidentally on a routine ultrasound with a splenomegaly of 17.5 centimeters. I did complete blood work, and the results were normal. In my last blood work two days ago, the only abnormality was my total bilirubin which was 1.21, which is borderline high, The ultrasound checked my liver as well, and the doctor said it was working fine. Please note I have had no unusual symptoms over the last four years except 2 to 3 colds lasting 2 to 3 days without any fever or anything like that.My doctor says to let it go, but it says lymphoma, liver, and leukaemia whenever I read. My doctor says it should have shown over the last four years if it was something like this, either symptomatic or shown in my blood work. He says he will not prescribe more invasive testing when I have no clinical symptoms or abnormal blood tests.Should I pursue this more? What else could it be? Thank you.PromptGiven your doctor's assessment and the information you've provided, here are some concise suggestions:Trust Your Doctor: Your doctor's assessment that your condition is likely not serious and doesn't require further invasive testing is based on your normal blood work, consistent spleen size, and lack of concerning symptoms. Trust their expertise.Open Communication: If you still have concerns, consider having an open conversation with your doctor about your worries. They can explain their reasoning for not pursuing further invasive testing.If you're still unsure, seeking a second opinion from another doctor could provide additional clarity and peace of mind.ChatGPTHi, Thanks for asking. Based on your query, my opinion is as follows. 1. Splenomegaly is seen in infections, storage disorders, lymphomas and leukemia. 2. As the ultrasound is normal, and your blood work is normal, possibility of leukemia or lymphoma is very less. 3. You can get a bone marrow biopsy done to rule out leukemia. However, if the biopsy is normal, then you need not worry. 4. You can get a CT scan abdomen to identify any other cause of splenomegaly. If it is also normal, then you can relax. Hope it helps. Any further queries, happy to help again.PMC LLaMA(c) Doctor-Patient RelationshipFigure 6: Examples of zero-shot conversation samples in more complex scenarios. Patient's query could be incomplete or unrelated to disease diagnosis.
. R Anil, A M Dai, abs/2305.10403ArXiv. PaLM 2 Technical ReportAnil, R.; Dai, A. M.; et al. 2023. PaLM 2 Technical Report. ArXiv, abs/2305.10403.</p>
<p>T Chen, arXiv:1604.06174Training deep nets with sublinear memory cost. arXiv preprintChen, T.; et al. 2016. Training deep nets with sublinear memory cost. arXiv preprint arXiv:1604.06174.</p>
<p>W.-L Chiang, Z Li, Vicuna: An Open-Source Chatbot Impressing GPT-4 with 90%<em> ChatGPT Quality. Chiang, W.-L.; Li, Z.; and others. 2023. Vicuna: An Open- Source Chatbot Impressing GPT-4 with 90%</em> ChatGPT Quality.</p>
<p>Scaling instruction-finetuned language models. H W Chung, arXiv:2210.11416Computer, T. 2023. RedPajama: An Open Source Recipe to Reproduce LLaMA training dataset. arXiv preprintChung, H. W.; et al. 2022. Scaling instruction-finetuned lan- guage models. arXiv preprint arXiv:2210.11416. Computer, T. 2023. RedPajama: An Open Source Recipe to Reproduce LLaMA training dataset.</p>
<p>LMFlow: An Extensible Toolkit for Finetuning and Inference of Large Foundation Models. S Diao, R Pan, Diao, S.; Pan, R.; et al. 2023. LMFlow: An Extensible Toolkit for Finetuning and Inference of Large Foundation Models. https://optimalscale.github.io/LMFlow/.</p>
<p>Glm: General language model pretraining with autoregressive blank infilling. Z Du, arXiv:2103.10360arXiv preprintDu, Z.; et al. 2021. Glm: General language model pre- training with autoregressive blank infilling. arXiv preprint arXiv:2103.10360.</p>
<p>MedAlpaca-An Open-Source Collection of Medical Conversational AI Models and Training Data. T Han, L C Adams, arXiv:2304.08247arXiv preprintHan, T.; Adams, L. C.; et al. 2023. MedAlpaca-An Open- Source Collection of Medical Conversational AI Models and Training Data. arXiv preprint arXiv:2304.08247.</p>
<p>Opt-iml: Scaling language model instruction meta learning through the lens of generalization. S Iyer, arXiv:2212.12017arXiv preprintIyer, S.; et al. 2022. Opt-iml: Scaling language model in- struction meta learning through the lens of generalization. arXiv preprint arXiv:2212.12017.</p>
<p>What disease does this patient have? a large-scale open domain question answering dataset from medical exams. D Jin, E Pan, arXiv:1909.06146Pubmedqa: A dataset for biomedical research question answering. 116421arXiv preprintJin, D.; Pan, E.; et al. 2021. What disease does this patient have? a large-scale open domain question answering dataset from medical exams. Applied Sciences, 11(14): 6421. Jin, Q.; et al. 2019. Pubmedqa: A dataset for biomedical research question answering. arXiv preprint arXiv:1909.06146.</p>
<p>. J Kaplan, S Mccandlish, T J Henighan, T B Brown, B Chess, R Child, S Gray, A Radford, J Wu, D Amodei, Scaling Laws for Neural Language Models. ArXiv, abs/2001.08361Kaplan, J.; McCandlish, S.; Henighan, T. J.; Brown, T. B.; Chess, B.; Child, R.; Gray, S.; Radford, A.; Wu, J.; and Amodei, D. 2020. Scaling Laws for Neural Language Mod- els. ArXiv, abs/2001.08361.</p>
<p>Performance of ChatGPT on USMLE: Potential for AI-assisted medical education using large language models. T H Kung, M Cheatham, A Medenilla, C Sillos, L D Leon, C Elepaño, M Madriaga, R Aggabao, G Diaz-Candido, J Maningo, V Tseng, PLOS Digital Health. 2Kung, T. H.; Cheatham, M.; Medenilla, A.; Sillos, C.; Leon, L. D.; Elepaño, C.; Madriaga, M.; Aggabao, R.; Diaz- Candido, G.; Maningo, J.; and Tseng, V. 2022. Performance of ChatGPT on USMLE: Potential for AI-assisted medi- cal education using large language models. PLOS Digital Health, 2.</p>
<p>BioBERT: a pre-trained biomedical language representation model for biomedical text mining. J Lee, Bioinformatics. 364Lee, J.; et al. 2020. BioBERT: a pre-trained biomedical language representation model for biomedical text mining. Bioinformatics, 36(4): 1234-1240.</p>
<p>The unified medical language system. D A Lindberg, B L Humphreys, A T Mccray, Yearbook of medical informatics. 201Lindberg, D. A.; Humphreys, B. L.; and McCray, A. T. 1993. The unified medical language system. Yearbook of medical informatics, 2(01): 41-51.</p>
<p>S2ORC: The Semantic Scholar Open Research Corpus. K Lo, 58th Annual Meeting of the ACL. Online: ACLLo, K.; et al. 2020. S2ORC: The Semantic Scholar Open Research Corpus. In 58th Annual Meeting of the ACL, 4969- 4983. Online: ACL.</p>
<p>. I Loshchilov, F Hutter, arXiv:1711.05101Decoupled weight decay regularization. arXiv preprintLoshchilov, I.; and Hutter, F. 2017. Decoupled weight decay regularization. arXiv preprint arXiv:1711.05101.</p>
<p>BioGPT: generative pre-trained transformer for biomedical text generation and mining. R Luo, L Sun, Y Xia, T Qin, S Zhang, H Poon, T.-Y Liu, Briefings in Bioinformatics. 236409Luo, R.; Sun, L.; Xia, Y.; Qin, T.; Zhang, S.; Poon, H.; and Liu, T.-Y. 2022. BioGPT: generative pre-trained trans- former for biomedical text generation and mining. Briefings in Bioinformatics, 23(6): bbac409.</p>
<p>Capabilities of gpt-4 on medical challenge problems. H Nori, N King, arXiv:2303.13375arXiv:2303.08774OpenAI. 2023a. GPT-4 Technical ReportNori, H.; King, N.; et al. 2023. Capabilities of gpt-4 on med- ical challenge problems. arXiv preprint arXiv:2303.13375. OpenAI. 2023a. GPT-4 Technical Report. arXiv:2303.08774.</p>
<p>. OpenAI. 2023b. OpenAI. Introducing chatgpt. OpenAI. 2023b. OpenAI. Introducing chatgpt. https:// openai.com/blog/chatgpt/.</p>
<p>Training language models to follow instructions with human feedback. L Ouyang, NIPS. 35Ouyang, L.; et al. 2022. Training language models to follow instructions with human feedback. NIPS, 35: 27730-27744.</p>
<p>MedMCQA: A largescale multi-subject multi-choice dataset for medical domain question answering. A Pal, L K Umapathi, PMLRConference on Health, Inference, and Learning. Pal, A.; Umapathi, L. K.; et al. 2022. MedMCQA: A large- scale multi-subject multi-choice dataset for medical domain question answering. In Conference on Health, Inference, and Learning, 248-260. PMLR.</p>
<p>B Peng, arXiv:2304.03277Instruction tuning with gpt-4. arXiv preprintPeng, B.; et al. 2023. Instruction tuning with gpt-4. arXiv preprint arXiv:2304.03277.</p>
<p>. K Singhal, S Azizi, T Tu, S S Mahdavi, J Wei, Singhal, K.; Azizi, S.; Tu, T.; Mahdavi, S. S.; Wei, J.; et al.</p>
<p>Large Language Models Encode Clinical Knowledge. arXiv:2212.13138arXiv preprintLarge Language Models Encode Clinical Knowledge. arXiv preprint arXiv:2212.13138.</p>
<p>Stanford Alpaca: An Instructionfollowing LLaMA model. R Taori, Taori, R.; et al. 2023. Stanford Alpaca: An Instruction- following LLaMA model. https://github.com/tatsu-lab/ stanford_alpaca.</p>
<p>H Touvron, T Lavril, G Izacard, ; Martinet, arXiv:2302.13971Llama: Open and efficient foundation language models. arXiv preprintTouvron, H.; Lavril, T.; Izacard, G.; Martinet; et al. 2023a. Llama: Open and efficient foundation language models. arXiv preprint arXiv:2302.13971.</p>
<p>Llama 2: Open Foundation and Fine-Tuned Chat Models. H Touvron, L Martin, K R Stone, abs/2307.09288ArXiv. Touvron, H.; Martin, L.; Stone, K. R.; et al. 2023b. Llama 2: Open Foundation and Fine-Tuned Chat Models. ArXiv, abs/2307.09288.</p>
<p>Chatdoctor: A medical chat model fine-tuned on llama model using medical domain knowledge. L Yunxiang, arXiv:2303.14070arXiv preprintYunxiang, L.; et al. 2023. Chatdoctor: A medical chat model fine-tuned on llama model using medical domain knowl- edge. arXiv preprint arXiv:2303.14070.</p>
<p>BiomedGPT: A Unified and Generalist Biomedical Generative Pre-trained Transformer for Vision, Language, and Multimodal Tasks. K Zhang, arXiv:2305.17100arXiv preprintZhang, K.; et al. 2023. BiomedGPT: A Unified and Gen- eralist Biomedical Generative Pre-trained Transformer for Vision, Language, and Multimodal Tasks. arXiv preprint arXiv:2305.17100.</p>
<p>Hi doctor. I have a small white area under my tongue for ten days. It is not raised and not painful. Thank youHi doctor. I have a small white area under my tongue for ten days. It is not raised and not painful. Thank you.</p>            </div>
        </div>

    </div>
</body>
</html>