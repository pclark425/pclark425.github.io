<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-3243 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-3243</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-3243</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-75.html">extraction-schema-75</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLM agents playing text games, with a focus on how memory is used, what types of memory are implemented, and how memory affects performance on text game tasks.</div>
                <p><strong>Paper ID:</strong> paper-204800714</p>
                <p><strong>Paper Title:</strong> <a href="https://arxiv.org/pdf/1910.09532v3.pdf" target="_blank">Building Dynamic Knowledge Graphs from Text-based Games</a></p>
                <p><strong>Paper Abstract:</strong> We are interested in learning how to update Knowledge Graphs (KG) from text. In this preliminary work, we propose a novel Sequence-to-Sequence (Seq2Seq) architecture to generate elementary KG operations. Furthermore, we introduce a new dataset for KG extraction built upon text-based game transitions (over 300k data points). We conduct experiments and discuss the results</p>
                <p><strong>Cost:</strong> 0.009</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e3243.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e3243.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLM agents playing text games, with a focus on how memory is used, what types of memory are implemented, and how memory affects performance on text game tasks.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Belief Graph (KG)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Belief Knowledge Graph (G_belief_t)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An explicit, structured memory representing the agent's partial observations of the game state as RDF triples; updated incrementally by add/delete operations to track discovered entities, relations, and states.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>N/A (memory module used by models)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Not an agent itself — a structured external memory used by Seq2Seq transformer models in the paper; nodes represent entities/states and edges represent relations (e.g., in, at, east_of).</td>
                        </tr>
                        <tr>
                            <td><strong>game_or_benchmark_name</strong></td>
                            <td>TextWorld KG (derived from TextWorld)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Store and maintain the partial world state discovered by an agent while it issues actions and receives textual observations; used to generate update operations that merge new observations into the graph.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_memory</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>external structured memory (knowledge graph / belief graph)</td>
                        </tr>
                        <tr>
                            <td><strong>memory_implementation_details</strong></td>
                            <td>Stored as RDF triples (nodes and directed relation edges). Memory is updated via generated atomic operations add(node1,node2,relation) and delete(node1,node2,relation). The graph is encoded by a graph encoder (GCN / R-GCN / R-GCN with relation embeddings) producing node embeddings which are attended to by the text encoder via an attention-based aggregator. During free-run evaluation the model inputs its own generated belief graph at each timestep.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_performance_comparison</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_benefits</strong></td>
                            <td>Provides a persistent record of observed facts enabling retrieval of past information (e.g., previous location after a 'go' action); helps models avoid re-discovering known facts and retrieve relational knowledge not present in current observation text.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_limitations_or_failures</strong></td>
                            <td>When the model must rely on its own generated graph over many steps, errors accumulate (lower FR-F1). Observations sometimes omit consumed ingredients (e.g., 'prepare' actions), so the KG must be queried to infer consumed items; if retrieval fails, performance suffers. Single-relation encoders (GCN) lack relational detail and underperform relative to relational encoders.</td>
                        </tr>
                        <tr>
                            <td><strong>best_practices_or_recommendations</strong></td>
                            <td>Maintain an explicit dynamic KG for partially-observable text games; represent facts as atomic add/delete operations; use relational graph encoders that account for relation labels; attend jointly over text and graph representations; during training enforce a deterministic ordering of update operations and use teacher forcing.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Building Dynamic Knowledge Graphs from Text-based Games', 'publication_date_yy_mm': '2019-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3243.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e3243.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLM agents playing text games, with a focus on how memory is used, what types of memory are implemented, and how memory affects performance on text game tasks.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Transformer Baseline</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Seq2Seq Transformer without Graph Encoder</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A transformer-based sequence-to-sequence model that generates KG update operations from concatenated (previous action; current observation) text without conditioning on an explicit belief graph.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>Seq2Seq Transformer (no graph encoder)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Transformer encoder-decoder (Vaswani et al. style) where text encoder reads [A_{t-1}; O_t] and decoder generates a token sequence of graph update commands using pointer-softmax; graph encoder is disabled so model has no explicit structured memory input.</td>
                        </tr>
                        <tr>
                            <td><strong>game_or_benchmark_name</strong></td>
                            <td>TextWorld KG (derived from TextWorld)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Predict sequence of KG update operations given previous action and current observation text, without access to a prior belief graph.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_memory</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_implementation_details</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_performance_comparison</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_benefits</strong></td>
                            <td>N/A for this model; used as baseline to show the value of explicit KG memory — baseline performs relatively poorly on actions requiring recall (e.g., 'go' actions where current observation lacks previous-location info).</td>
                        </tr>
                        <tr>
                            <td><strong>memory_limitations_or_failures</strong></td>
                            <td>Performs poorly on transitions where the observation does not contain facts that must be remembered (e.g., identifying the agent's previous location after a 'go'). Cannot retrieve multi-step or previously observed facts that are not present in O_t.</td>
                        </tr>
                        <tr>
                            <td><strong>best_practices_or_recommendations</strong></td>
                            <td>Use as baseline; compare models that incorporate structured memory to quantify benefits of an explicit belief graph.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Building Dynamic Knowledge Graphs from Text-based Games', 'publication_date_yy_mm': '2019-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3243.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e3243.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLM agents playing text games, with a focus on how memory is used, what types of memory are implemented, and how memory affects performance on text game tasks.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Transformer+GCN</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Seq2Seq Transformer with Graph Convolutional Network Encoder</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A transformer Seq2Seq model augmented with a GCN graph encoder that encodes the prior belief graph into node embeddings which are aggregated with text representations to condition update generation.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>Seq2Seq Transformer + GCN</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Same transformer-based text encoder and command generator; graph encoder is a standard Graph Convolutional Network that produces graph node embeddings (does not model multiple relation types explicitly). Aggregation between text and graph uses attention-weighted sums.</td>
                        </tr>
                        <tr>
                            <td><strong>game_or_benchmark_name</strong></td>
                            <td>TextWorld KG (derived from TextWorld)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Generate graph update operations using both current text input and the encoded prior belief graph (single-relation GCN encoding).</td>
                        </tr>
                        <tr>
                            <td><strong>uses_memory</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>external structured memory (knowledge graph) encoded via GCN</td>
                        </tr>
                        <tr>
                            <td><strong>memory_implementation_details</strong></td>
                            <td>Belief KG represented as nodes/edges; GCN layers propagate information to produce node embeddings h_G which are attended to by text representations (resulting in h_GO and h_OG) that condition the decoder.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_performance_comparison</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_benefits</strong></td>
                            <td>Improves performance relative to the no-graph baseline on teacher-forced metrics, demonstrating that conditioning on previous graph information helps generation when ground-truth graph is available.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_limitations_or_failures</strong></td>
                            <td>Does not handle multiple relation types or relation label semantics; underperforms relational encoders on free-run (FR-F1) where accumulated relational reasoning and label-sensitive distinctions matter.</td>
                        </tr>
                        <tr>
                            <td><strong>best_practices_or_recommendations</strong></td>
                            <td>Use relational-aware encoders (e.g., R-GCN) when relations are important; GCNs are a useful baseline but limited for multi-relation KGs.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Building Dynamic Knowledge Graphs from Text-based Games', 'publication_date_yy_mm': '2019-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3243.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e3243.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLM agents playing text games, with a focus on how memory is used, what types of memory are implemented, and how memory affects performance on text game tasks.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Transformer+R-GCN</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Seq2Seq Transformer with Relational Graph Convolutional Network</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A Seq2Seq transformer model conditioned on a Relational GCN that models multiple relation types in the belief graph, improving KG update generation by using relation-aware graph embeddings.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>Seq2Seq Transformer + R-GCN</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Transformer-based encoder-decoder conditioned on an R-GCN graph encoder which accounts for multiple relation types in message passing to produce relation-aware node embeddings fed into the attention-based aggregator.</td>
                        </tr>
                        <tr>
                            <td><strong>game_or_benchmark_name</strong></td>
                            <td>TextWorld KG (derived from TextWorld)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Generate KG update operations conditioned on textual observation/action and a multi-relation belief graph encoded by R-GCN.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_memory</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>external structured memory (knowledge graph) encoded via R-GCN</td>
                        </tr>
                        <tr>
                            <td><strong>memory_implementation_details</strong></td>
                            <td>Belief KG encoded by R-GCN layers which incorporate relation-type-specific transformations (but originally without textual relation-label embeddings). Aggregator attends between text and graph representations to condition the decoder.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_performance_comparison</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_benefits</strong></td>
                            <td>Outperforms GCN and no-graph baseline, showing that modeling multiple relation types is important; helps recover relational facts and improves generation fidelity when graph conditioning is available.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_limitations_or_failures</strong></td>
                            <td>R-GCN without relation-label embeddings still underperforms in free-run settings compared to relation-label-aware variants, indicating sensitivity to relation semantics and accumulated errors over long runs.</td>
                        </tr>
                        <tr>
                            <td><strong>best_practices_or_recommendations</strong></td>
                            <td>Use relational graph encoders to capture multi-relational KG structure; further improve by incorporating relation label information.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Building Dynamic Knowledge Graphs from Text-based Games', 'publication_date_yy_mm': '2019-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3243.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e3243.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLM agents playing text games, with a focus on how memory is used, what types of memory are implemented, and how memory affects performance on text game tasks.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Transformer+R-GCN+RelEmb</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Seq2Seq Transformer with R-GCN and Relation-Label Embeddings</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A Seq2Seq transformer with an R-GCN graph encoder augmented by learned vector representations of relation labels (from text embeddings), which are fed into the R-GCN to capture label semantics and symmetric relations.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>Seq2Seq Transformer + R-GCN (with relation embeddings)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>Transformer Seq2Seq model using a relational graph encoder whose relation-specific transformations are conditioned on learned embeddings derived from the textual labels of relations; aggregated with text encoder outputs to generate update commands.</td>
                        </tr>
                        <tr>
                            <td><strong>game_or_benchmark_name</strong></td>
                            <td>TextWorld KG (derived from TextWorld)</td>
                        </tr>
                        <tr>
                            <td><strong>task_description</strong></td>
                            <td>Generate KG update operations while leveraging relation-label-aware graph encodings so that relational semantics (e.g., east_of vs west_of) are captured and used in update generation.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_memory</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>external structured memory (knowledge graph) encoded via R-GCN with relation-label embeddings</td>
                        </tr>
                        <tr>
                            <td><strong>memory_implementation_details</strong></td>
                            <td>Relation labels are embedded (text embeddings) and used as additional input to R-GCN layers to produce relation-conditioned node embeddings; attention-based aggregator fuses text and graph representations for the decoder; pointer-softmax allows copying from source text.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_performance_comparison</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_benefits</strong></td>
                            <td>Significantly better free-run (FR-F1) performance than other variants, indicating that encoding relation label semantics reduces error accumulation and improves long-run consistency of the belief graph.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_limitations_or_failures</strong></td>
                            <td>Although superior, FR-F1 still degrades relative to teacher-forced metrics due to accumulated generation errors; complex multi-entity retrieval tasks (e.g., prepare actions consuming multiple ingredients) remain challenging.</td>
                        </tr>
                        <tr>
                            <td><strong>best_practices_or_recommendations</strong></td>
                            <td>Incorporate textual relation-label information into relational graph encoders to improve robustness in iterative/online graph construction; prefer relation-aware encoders when building dynamic KGs in text games.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Building Dynamic Knowledge Graphs from Text-based Games', 'publication_date_yy_mm': '2019-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Playing text-adventure games with graph-based deep reinforcement learning <em>(Rating: 2)</em></li>
                <li>Building dynamic knowledge graphs from text using machine reading comprehension <em>(Rating: 2)</em></li>
                <li>TextWorld: A learning environment for text-based games <em>(Rating: 2)</em></li>
                <li>Modeling relational data with graph convolutional networks <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-3243",
    "paper_id": "paper-204800714",
    "extraction_schema_id": "extraction-schema-75",
    "extracted_data": [
        {
            "name_short": "Belief Graph (KG)",
            "name_full": "Belief Knowledge Graph (G_belief_t)",
            "brief_description": "An explicit, structured memory representing the agent's partial observations of the game state as RDF triples; updated incrementally by add/delete operations to track discovered entities, relations, and states.",
            "citation_title": "here",
            "mention_or_use": "use",
            "agent_name": "N/A (memory module used by models)",
            "agent_description": "Not an agent itself — a structured external memory used by Seq2Seq transformer models in the paper; nodes represent entities/states and edges represent relations (e.g., in, at, east_of).",
            "game_or_benchmark_name": "TextWorld KG (derived from TextWorld)",
            "task_description": "Store and maintain the partial world state discovered by an agent while it issues actions and receives textual observations; used to generate update operations that merge new observations into the graph.",
            "uses_memory": true,
            "memory_type": "external structured memory (knowledge graph / belief graph)",
            "memory_implementation_details": "Stored as RDF triples (nodes and directed relation edges). Memory is updated via generated atomic operations add(node1,node2,relation) and delete(node1,node2,relation). The graph is encoded by a graph encoder (GCN / R-GCN / R-GCN with relation embeddings) producing node embeddings which are attended to by the text encoder via an attention-based aggregator. During free-run evaluation the model inputs its own generated belief graph at each timestep.",
            "performance_with_memory": null,
            "performance_without_memory": null,
            "has_performance_comparison": true,
            "memory_benefits": "Provides a persistent record of observed facts enabling retrieval of past information (e.g., previous location after a 'go' action); helps models avoid re-discovering known facts and retrieve relational knowledge not present in current observation text.",
            "memory_limitations_or_failures": "When the model must rely on its own generated graph over many steps, errors accumulate (lower FR-F1). Observations sometimes omit consumed ingredients (e.g., 'prepare' actions), so the KG must be queried to infer consumed items; if retrieval fails, performance suffers. Single-relation encoders (GCN) lack relational detail and underperform relative to relational encoders.",
            "best_practices_or_recommendations": "Maintain an explicit dynamic KG for partially-observable text games; represent facts as atomic add/delete operations; use relational graph encoders that account for relation labels; attend jointly over text and graph representations; during training enforce a deterministic ordering of update operations and use teacher forcing.",
            "uuid": "e3243.0",
            "source_info": {
                "paper_title": "Building Dynamic Knowledge Graphs from Text-based Games",
                "publication_date_yy_mm": "2019-10"
            }
        },
        {
            "name_short": "Transformer Baseline",
            "name_full": "Seq2Seq Transformer without Graph Encoder",
            "brief_description": "A transformer-based sequence-to-sequence model that generates KG update operations from concatenated (previous action; current observation) text without conditioning on an explicit belief graph.",
            "citation_title": "here",
            "mention_or_use": "use",
            "agent_name": "Seq2Seq Transformer (no graph encoder)",
            "agent_description": "Transformer encoder-decoder (Vaswani et al. style) where text encoder reads [A_{t-1}; O_t] and decoder generates a token sequence of graph update commands using pointer-softmax; graph encoder is disabled so model has no explicit structured memory input.",
            "game_or_benchmark_name": "TextWorld KG (derived from TextWorld)",
            "task_description": "Predict sequence of KG update operations given previous action and current observation text, without access to a prior belief graph.",
            "uses_memory": false,
            "memory_type": null,
            "memory_implementation_details": null,
            "performance_with_memory": null,
            "performance_without_memory": null,
            "has_performance_comparison": true,
            "memory_benefits": "N/A for this model; used as baseline to show the value of explicit KG memory — baseline performs relatively poorly on actions requiring recall (e.g., 'go' actions where current observation lacks previous-location info).",
            "memory_limitations_or_failures": "Performs poorly on transitions where the observation does not contain facts that must be remembered (e.g., identifying the agent's previous location after a 'go'). Cannot retrieve multi-step or previously observed facts that are not present in O_t.",
            "best_practices_or_recommendations": "Use as baseline; compare models that incorporate structured memory to quantify benefits of an explicit belief graph.",
            "uuid": "e3243.1",
            "source_info": {
                "paper_title": "Building Dynamic Knowledge Graphs from Text-based Games",
                "publication_date_yy_mm": "2019-10"
            }
        },
        {
            "name_short": "Transformer+GCN",
            "name_full": "Seq2Seq Transformer with Graph Convolutional Network Encoder",
            "brief_description": "A transformer Seq2Seq model augmented with a GCN graph encoder that encodes the prior belief graph into node embeddings which are aggregated with text representations to condition update generation.",
            "citation_title": "here",
            "mention_or_use": "use",
            "agent_name": "Seq2Seq Transformer + GCN",
            "agent_description": "Same transformer-based text encoder and command generator; graph encoder is a standard Graph Convolutional Network that produces graph node embeddings (does not model multiple relation types explicitly). Aggregation between text and graph uses attention-weighted sums.",
            "game_or_benchmark_name": "TextWorld KG (derived from TextWorld)",
            "task_description": "Generate graph update operations using both current text input and the encoded prior belief graph (single-relation GCN encoding).",
            "uses_memory": true,
            "memory_type": "external structured memory (knowledge graph) encoded via GCN",
            "memory_implementation_details": "Belief KG represented as nodes/edges; GCN layers propagate information to produce node embeddings h_G which are attended to by text representations (resulting in h_GO and h_OG) that condition the decoder.",
            "performance_with_memory": null,
            "performance_without_memory": null,
            "has_performance_comparison": true,
            "memory_benefits": "Improves performance relative to the no-graph baseline on teacher-forced metrics, demonstrating that conditioning on previous graph information helps generation when ground-truth graph is available.",
            "memory_limitations_or_failures": "Does not handle multiple relation types or relation label semantics; underperforms relational encoders on free-run (FR-F1) where accumulated relational reasoning and label-sensitive distinctions matter.",
            "best_practices_or_recommendations": "Use relational-aware encoders (e.g., R-GCN) when relations are important; GCNs are a useful baseline but limited for multi-relation KGs.",
            "uuid": "e3243.2",
            "source_info": {
                "paper_title": "Building Dynamic Knowledge Graphs from Text-based Games",
                "publication_date_yy_mm": "2019-10"
            }
        },
        {
            "name_short": "Transformer+R-GCN",
            "name_full": "Seq2Seq Transformer with Relational Graph Convolutional Network",
            "brief_description": "A Seq2Seq transformer model conditioned on a Relational GCN that models multiple relation types in the belief graph, improving KG update generation by using relation-aware graph embeddings.",
            "citation_title": "here",
            "mention_or_use": "use",
            "agent_name": "Seq2Seq Transformer + R-GCN",
            "agent_description": "Transformer-based encoder-decoder conditioned on an R-GCN graph encoder which accounts for multiple relation types in message passing to produce relation-aware node embeddings fed into the attention-based aggregator.",
            "game_or_benchmark_name": "TextWorld KG (derived from TextWorld)",
            "task_description": "Generate KG update operations conditioned on textual observation/action and a multi-relation belief graph encoded by R-GCN.",
            "uses_memory": true,
            "memory_type": "external structured memory (knowledge graph) encoded via R-GCN",
            "memory_implementation_details": "Belief KG encoded by R-GCN layers which incorporate relation-type-specific transformations (but originally without textual relation-label embeddings). Aggregator attends between text and graph representations to condition the decoder.",
            "performance_with_memory": null,
            "performance_without_memory": null,
            "has_performance_comparison": true,
            "memory_benefits": "Outperforms GCN and no-graph baseline, showing that modeling multiple relation types is important; helps recover relational facts and improves generation fidelity when graph conditioning is available.",
            "memory_limitations_or_failures": "R-GCN without relation-label embeddings still underperforms in free-run settings compared to relation-label-aware variants, indicating sensitivity to relation semantics and accumulated errors over long runs.",
            "best_practices_or_recommendations": "Use relational graph encoders to capture multi-relational KG structure; further improve by incorporating relation label information.",
            "uuid": "e3243.3",
            "source_info": {
                "paper_title": "Building Dynamic Knowledge Graphs from Text-based Games",
                "publication_date_yy_mm": "2019-10"
            }
        },
        {
            "name_short": "Transformer+R-GCN+RelEmb",
            "name_full": "Seq2Seq Transformer with R-GCN and Relation-Label Embeddings",
            "brief_description": "A Seq2Seq transformer with an R-GCN graph encoder augmented by learned vector representations of relation labels (from text embeddings), which are fed into the R-GCN to capture label semantics and symmetric relations.",
            "citation_title": "here",
            "mention_or_use": "use",
            "agent_name": "Seq2Seq Transformer + R-GCN (with relation embeddings)",
            "agent_description": "Transformer Seq2Seq model using a relational graph encoder whose relation-specific transformations are conditioned on learned embeddings derived from the textual labels of relations; aggregated with text encoder outputs to generate update commands.",
            "game_or_benchmark_name": "TextWorld KG (derived from TextWorld)",
            "task_description": "Generate KG update operations while leveraging relation-label-aware graph encodings so that relational semantics (e.g., east_of vs west_of) are captured and used in update generation.",
            "uses_memory": true,
            "memory_type": "external structured memory (knowledge graph) encoded via R-GCN with relation-label embeddings",
            "memory_implementation_details": "Relation labels are embedded (text embeddings) and used as additional input to R-GCN layers to produce relation-conditioned node embeddings; attention-based aggregator fuses text and graph representations for the decoder; pointer-softmax allows copying from source text.",
            "performance_with_memory": null,
            "performance_without_memory": null,
            "has_performance_comparison": true,
            "memory_benefits": "Significantly better free-run (FR-F1) performance than other variants, indicating that encoding relation label semantics reduces error accumulation and improves long-run consistency of the belief graph.",
            "memory_limitations_or_failures": "Although superior, FR-F1 still degrades relative to teacher-forced metrics due to accumulated generation errors; complex multi-entity retrieval tasks (e.g., prepare actions consuming multiple ingredients) remain challenging.",
            "best_practices_or_recommendations": "Incorporate textual relation-label information into relational graph encoders to improve robustness in iterative/online graph construction; prefer relation-aware encoders when building dynamic KGs in text games.",
            "uuid": "e3243.4",
            "source_info": {
                "paper_title": "Building Dynamic Knowledge Graphs from Text-based Games",
                "publication_date_yy_mm": "2019-10"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Playing text-adventure games with graph-based deep reinforcement learning",
            "rating": 2
        },
        {
            "paper_title": "Building dynamic knowledge graphs from text using machine reading comprehension",
            "rating": 2
        },
        {
            "paper_title": "TextWorld: A learning environment for text-based games",
            "rating": 2
        },
        {
            "paper_title": "Modeling relational data with graph convolutional networks",
            "rating": 1
        }
    ],
    "cost": 0.009178249999999999,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Building Dynamic Knowledge Graphs from Text-based Games
22 Oct 2019</p>
<p>Mikuláš Zelinka 
Faculty of Mathematics and Physics
Charles University
Czech Republic ‡ Microsoft Research
Montréal</p>
<p>Xingdi Yuan 
Marc-Alexandre Côté 
Romain Laroche 
Adam Trischler </p>
<p>Graph Representation Learning (GRL) Workshop
Microsoft Research, Montréal. 33rd Conference on Neural Information Processing Systems
2019)VancouverNeurIPSCanada</p>
<p>Building Dynamic Knowledge Graphs from Text-based Games
22 Oct 2019AC2E5444D80E2C7E430F39BAC6A29486arXiv:1910.09532v2[cs.CL]
We are interested in learning how to update Knowledge Graphs (KG) from text.In this preliminary work, we propose a novel Sequence-to-Sequence (Seq2Seq) architecture to generate elementary KG operations.Furthermore, we introduce a new dataset for KG extraction built upon text-based game transitions (over 300k data points).We conduct experiments and discuss the results.</p>
<p>Introduction</p>
<p>Text-based games are complex, interactive simulations in which text describes the game state and players make progress by entering text actions.They can be seen as sequential decision making tasks where accomplishing certain goals earns rewards (points).Solving these games requires both Reinforcement Learning (RL) and Natural Language Processing (NLP) techniques.</p>
<p>Given the complex, partially observable nature of text-based games, an explicit structured memorye.g., in the form of a graph -is a useful component for game-playing agents.In this work, we side step the game-playing aspect of the problem to focus solely on learning how to build and dynamically maintain a KG from text observations.Specifically, our proposed model learns to generate graph update operations to update an existing KG given new text information.We see this KG module as an independent block that can be leveraged by game-playing agents to improve their performance.</p>
<p>Related Work: Numerous recent works focus on learning or using KGs in textual environments.Das et al. (2018) leverage a machine reading comprehension (MRC) mechanism to query for entities and states in short text passages and use attention to address aliased entity occurrences and to track the entity states dynamically.Xiong et al. (2018) focus on one-shot learning of new relations from only one training instance.</p>
<p>For text games specifically, Ammanabrolu and Riedl (2018) leverage KGs to improve performance, relying on OpenIE for entity extraction and several game-specific rules for building and maintaining the KG.Sinha et al. (2019) introduce a dataset aimed at natural language understanding and generalization in reasoning about entity relations that was built using a KG-like structure.</p>
<p>To the best of our knowledge, all of the approaches for learning KGs are either concerned with building static KGs (rather than focusing on small, dynamic updates), or employ some domainspecific knowledge or rules to facilitate learning.In contrast, our proposed model learns to generate general update operations for modifying a KG. 2 The TextWorld KG Dataset</p>
<p>In this section, we introduce a new dynamic KG extraction dataset, TextWorld KG2 .TextWorld KG is based on a set of text-based games generated using TextWorld (Côté et al., 2018). 3That framework enables us to extract the underlying partial KG for every state, i.e., the subgraph that represents the agent's partial knowledge of the world -what it has observed so far.All games share the same overarching theme: the agent finds itself hungry in a simple modern house with the goal of gathering ingredients and cooking a meal.</p>
<p>To build the TextWorld KG dataset, we collect game transitions obtained by following each game's walkthrough (provided by TextWorld).Additionally, after each step in a walkthrough, we perform 5 additional actions sampled at random from the list of admissible commands4 (also provided by TextWorld).This presumably promotes robustness and generalizability of a training agent since it will encounter off-the-path transitions during game playing in the RL setting due to the absent of walkthroughs.Therefore an agent pre-trained on such data is more likely to work well in the RL setting.Formally, each data point in TextWorld KG is a tuple,
{G seen t−1 , A t−1 , O t , G seen t }, where G seen t−1
is a partial KG (in the format of Resource Description Framework (RDF) triples) representing the information an agent has seen during all previous game steps up to t − 1.After the agent issues an action A t−1 (a string of words), the game engine returns a new text observation O t describing its effects on the world.The task is to predict the updated partial KG G seen t given the above information.Note that the new observation might not contain new information, since some actions do not change the game state (e.g.look in the same room twice).Table 1 shows some statistics about TextWorld KG and Figure 1 illustrates an example data point.An important challenge posed by TextWorld is generalization.In each individual game instance, the interactable objects and their locations change along with the layout of the environment.Similarly, object names can be composed of multiple adjectives and a noun (e.g., red hot chili pepper), and at test time, players may encounter object names never seen during training.TextWorld KG inherits both of these challenging features.3 Learning to Update a KG</p>
<p>KG Definition</p>
<p>In a text-based game, at any given game step t, the game state s t can be represented as a graph
G full t = (V t , E t ).
In our setting, vertices V t represent entities (including objects, the player, and locations) and their states (e.g., closed, fried, sliced).Vertices are connected by edges E, which represent a set of relations between entities (e.g.north_of, in, is).</p>
<p>Since games are partially observable, at every step an agent only observes part of the full game state (e.g., the agent cannot know facts in a room it has not visited).Thus, an agent must build its belief about the world, G belief t , from its observations.Ideally, the belief graph should match the ground truth graph, G seen t , which is a subgraph of G full t representing what has been seen so far in the game.TextWorld games are deterministic, so by progressively exploring and observing, an agent should discover more knowledge to push into its belief graph.Eventually, this ought to converge to a graph that accurately represents the entire game state.</p>
<p>Updating a KG</p>
<p>Instead of generating the entire belief graph at every game step, we generate a set of update operations ∆g t such that G belief t = Update(G belief t−1 , ∆g t ), where Update is an oracle function that applies ∆g t .In our case, each update operation in ∆g t is represented as a text command.We define the following two types of update operation:</p>
<p>• add(node1, node2, relation): add a directed edge, named relation, between node1 and node2; if any of these nodes does not exist, add that node first.• delete(node1, node2, relation): delete a directed edge, named relation, between node1 and node2; if any of the nodes or the edge does not exist, ignore this operation.</p>
<p>Given a new observation string O t and an agent's current belief G belief t−1 , the agent is required to generate k ≥ 0 operations as defined above to merge newly observed information into its belief graph.For the example shown in Figure 1, the generated operations are listed in Table 2.</p>
<p>add (player, shed, at) add (shed, backyard, west_of) add (wooden door, shed, east_of) add (toolbox, shed, in) add (toolbox, closed, is) add (workbench, shed, in) delete (player, backyard, at) Table 2: Update operations corresponding to the transition shown in Figure 1.</p>
<p>We formulate the update generation task as a Seq2Seq problem.Specifically, we adopt the decoding strategy from Yuan et al. (2018), where given an observation sequence O t and a belief graph G belief t−1 , the agent generates a sequence of tokens consisting of multiple graph update operations separated by a delimiter token.</p>
<p>As pointed out by Meng et al. (2019), the order of ground-truth tokens and sequences (in our case, graph update operations) matters in Seq2Seq language generation.We therefore define a set of rules (e.g., always add before delete) to order ground-truth operations for teacher forcing during training.We use a transformer-based Seq2Seq model (Vaswani et al., 2017) to generate update operations.As shown in Figure 2 in Appendix A, the model consists of the following components:</p>
<p>1.A text encoder, which reads text inputs (the concatenation of observation O t and the action at the previous game step, A t−1 ), and generates hidden representations.</p>
<ol>
<li>
<p>A graph encoder, which encodes the previous belief G belief t−1 into hidden representations.3.An attention-based representation aggregator, which combines the two above representations.</p>
</li>
<li>
<p>A command generator, which takes aggregated representations and generates update operations token by token.</p>
</li>
</ol>
<p>For space considerations, we elaborate our model components in Appendix A. Following common practice in natural language generation (NLG), we train our operation generation model via teacher forcing.Specifically, during training, a right-shifted ground truth target sequence is provided as input to the decoder and the model is trained with the negative log-likelihood (NLL) loss.During test, the model starts generating from a start-of-sentence token and uses the previously generated token as input to the next step.The model terminates after generating an end-of-sequence token.</p>
<p>Experiments and Discussion</p>
<p>Model TF-F1 FR-F1  In this preliminary study we test 4 graph encoder variants of the proposed model.First, as a baseline, we disable the graph encoder, which renders the model a standard Seq2Seq transformer.Second, we utilize a Graph Convolutional Network (GCN) (Kipf and Welling, 2016) as the graph encoder.The GCN does not consider multiple relations.5Third, we enable conditioning on multiple relations by using a Relational Graph Convolutional Network (R-GCN) (Schlichtkrull et al., 2018).Although R-GCN takes into account multiple relations, it does not consider information in relation labels.In our task, this information is important (e.g., east_of and west_of are symmetric relations).Therefore, we finally learn a vector representation for each relation that is conditioned on the label's text embeddings.</p>
<p>The resulting relation representation is used as an extra input to the R-GCN layer.Table 3 shows the test results for all models.</p>
<p>During training, a model takes {G seen t−1 , A t−1 , O t } as input, where G seen t−1 is the input graph, and A t−1 and O t are the text action issued at the previous game step and the resulting text observation, respectively.The model outputs a sequence describing an update operation to the graph and the resulting G belief t .During evaluation:</p>
<p>• Teacher-force (TF) F 1 : we use the ground-truth G seen t−1 as input graph and compute the F 1 score between the model's generated graph update commands and the ground-truth commands.Note the F 1 score is computed on command level (i.e., if any token in a command is incorrect, this command is treated as incorrect).</p>
<p>• Free-run (FR) F 1 : we initialize the belief graph at the beginning of each game with an empty graph.For each game step, we use G belief t−1 (the graph generated by the model) as input.At the end of each game, we compute F 1 score between the final belief graph G belief T and ground truth G seen T , graphs are represented as RDF triples.In general, although all model variants show good performance on TF-F 1 , they perform worse on FR-F 1 .This is not surprising since errors accumulate in the latter setting.Models using R-GCN outperform those using GCN by a noticeable margin, which suggests relational information is essential in the proposed tasks.Interestingly, while the two R-GCN models perform similarly on TF-F 1 , the variant with relational embedding (considering information in relation labels) significantly outperforms the other on FR-F 1 .</p>
<p>To better understand the behavior of our proposed models on TextWorld KG, we conduct an error analysis, which we show in Appendix B.</p>
<p>The next step for this project is to leverage the KG update module while playing text-based games.We believe that maintaining such a graph could help an RL agent (1) to avoid re-discovering known facts about the world and (2) to discover new world knowledge efficiently.We are also interested in finding ways of transferring learned graphs from one game to another to improve agents' ability to generalize.</p>
<p>A Model Architecture</p>
<p>Text Encoder: An observation string O t is provided in response to the text action A t−1 an agent issued at previous game step.We concatenate the two text information together [A t−1 ; O t ] as the input to the text encoder, in which [•; •] indicates vector/string concatenation.The text encoder consists an embedding layer and a stack of transformer blocks.The text encoder results a sequence of hidden vectors h O ∈ R L O ×H , where L o is length of the concatenated string, H is hidden size.</p>
<p>Graph Encoder: At the same time, the graph encoder takes the agent's belief KG G belief t−1 (in which stores the agent's observations a all previous game steps) as input.We adopt different off-the-shelf graph neural networks (GNN) as the graph encoder (we will describe more details in experiment section).After several layers of propagation, graph representations h G ∈ R N ×H are generated, where N is number of nodes in the KG.</p>
<p>Representation Aggregator: We use an attention based layer to aggregate text and graph representations (Bahdanau et al., 2014;Seo et al., 2016).Specifically, we use weighted sum of text representations to represent graph information, which results h GO ∈ R N ×H ; similarly, we use weighted sum of graph representations to represent text information, resulting h OG ∈ R L O ×H .</p>
<p>Command Generator Finally, both h OG and h GO are used to condition text generation.Input tokens are first converted into embeddings, then they are fed into a stack of decoder transformer blocks which result a probability distribution over the vocabulary.To prevent model from utilizing future information, we follow Vaswani et al. (2017) to use a masked multi-head self attention layer in the beginning of each block.For being able to both generate a word from vocabulary, and point a word from the source text O t , we adopt the pointer-softmax mechanism (Gülçehre et al., 2016).In Figure 3, we report average TF-F 1 scores grouped by verbs found in input actions A t−1 .We can observe that vanilla transformer model performs poorly on go actions, which aligns with the fact that after issuing a go action, the resulting observation text O t does not contain any information of the agent's previous location.On the other hand, the other models benefit from their belief graph to retrieve that single information.</p>
<p>B Error Analysis</p>
<p>Also, we notice that all models perform relatively poorly on prepare actions.This also makes sense since in TextWorld games, the action of preparing a meal consumes multiple food ingredients at once in order to produce a meal object.The resulting observation text O t following a prepare action only contains information about the newly produced meal and does not mention what food ingredients have been consumed.Even though the information about the recipe (i.e.ingredients needed) is part of the KG graph, a model has to learn to retrieve multiple information at once from its belief graph G belief t−1 to figure out what ingredients will be consumed.</p>
<p>Figure 2 :
2
Figure 2: Graph update operation generation model.</p>
<p>Figure 3 :
3
Figure 3: Average TF-F 1 scores grouped by verbs.</p>
<p>You find yourself in a backyard.You make out a patio table.But it is empty.You see a patio chair.The patio chair is stylish.But there isn't a thing on it.You see a gleam over in a corner, where you can see a BBQ.There is a closed screen door leading south.There is an open wooden door leading west.to the shed.You can barely contain your excitement.You can make out a closed toolbox here.You can see a workbench.The workbench is wooden.Looks like someone's already been here and taken everything off it, though.You swear loudly.There is an open wooden door leading east.Illustration of an example in TextWorld KG.By issuing an action A t−1 at game step t − 1, the environment returns a new observation, O t .Given the KG at step t − 1, a model is required to predict the new KG given the text observation.
Welcome go west…𝑂 𝑡−1𝐴 𝑡−1𝑂 𝑡…kitchen patio chair BBQ in west of patio table in inbackyard living room player north of atnorth of south of west ofscreen door closed is open is wooden doorwest of in in kitchen BBQ patio in chair patio tablebackyard living room north of west of shed player atscreen door wooden north of south of door west of east of toolbox in workbench inupdate closed open closed is is isFigure 1:</p>
<p>Table 1 :
1
Statistics of TextWorld KG.Avg.Obs. is the average number of tokens an observation has.Avg.#Operations is the average number of update operations to generate per time step.#Vertices and #Edges correspond to the number of unique entities and relation types.Avg.#Connections is the average number of connections a graph has.</p>
<h1>Train#Valid#TestAvg. Obs.Avg. #Operations#Vertices#EdgesAvg. #Connections267,03113,44241,86529.3 tokens3.1991043.1</h1>
<p>Table 3 :
3
Test performance.</p>
<p>TextWorld KG is publicly available at https://github.com/MikulasZelinka/textworld_kg_ dataset
We use the games provided for the First TextWorld Problems competition, available at http://aka.ms/ftwp-dataset.
This is the set of game actions understood by the game in a given state.
For models that do not consider relational information, we use single relation KGs as ground-truth during evaluation.</p>
<p>Playing text-adventure games with graph-based deep reinforcement learning. P Ammanabrolu, M O Riedl, CoRR, abs/1812.016282018</p>
<p>Neural machine translation by jointly learning to align and translate. D Bahdanau, K Cho, Y Bengio, arXiv:1409.04732014arXiv preprint</p>
<p>M.-A Côté, A Kádár, X Yuan, B Kybartas, T Barnes, E Fine, J Moore, M Hausknecht, L E Asri, M Adada, W Tay, A Trischler, Textworld: A learning environment for text-based games. 2018</p>
<p>Building dynamic knowledge graphs from text using machine reading comprehension. R Das, T Munkhdalai, X Yuan, A Trischler, A Mccallum, CoRR, abs/1810.056822018</p>
<p>Pointing the unknown words. Ç Gülçehre, S Ahn, R Nallapati, B Zhou, Y Bengio, CoRR, abs/1603.081482016</p>
<p>Semi-supervised classification with graph convolutional networks. T N Kipf, M Welling, CoRR, abs/1609.029072016</p>
<p>Does order matter? an empirical study on generating multiple keyphrases as a sequence. R Meng, X Yuan, T Wang, P Brusilovsky, A Trischler, D He, 2019CoRR</p>
<p>Modeling relational data with graph convolutional networks. M Schlichtkrull, T N Kipf, P Bloem, Van Den, R Berg, I Titov, M Welling, European Semantic Web Conference. Springer2018</p>
<p>Bidirectional attention flow for machine comprehension. M Seo, A Kembhavi, A Farhadi, H Hajishirzi, arXiv:1611.016032016arXiv preprint</p>
<p>K Sinha, S Sodhani, J Dong, J Pineau, W L Hamilton, arXiv:1908.06177Clutrr: A diagnostic benchmark for inductive reasoning from text. 2019arXiv preprint</p>
<p>Attention is all you need. A Vaswani, N Shazeer, N Parmar, J Uszkoreit, L Jones, A N Gomez, L Kaiser, I Polosukhin, CoRR, abs/1706.037622017</p>
<p>One-shot relational learning for knowledge graphs. W Xiong, M Yu, S Chang, X Guo, W Y Wang, arXiv:1808.090402018arXiv preprint</p>
<p>Generating diverse numbers of diverse keyphrases. X Yuan, T Wang, R Meng, K Thaker, P Brusilovsky, D He, A Trischler, CoRR, abs/1810.052412018</p>            </div>
        </div>

    </div>
</body>
</html>