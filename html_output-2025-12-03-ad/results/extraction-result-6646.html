<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-6646 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-6646</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-6646</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-126.html">extraction-schema-126</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models perform arithmetic, including model details, task details, prompting methods, performance results, and any analysis of internal mechanisms or failure modes.</div>
                <p><strong>Paper ID:</strong> paper-a77d28e13ff34f34b8d1114e603bff074ee2b056</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/a77d28e13ff34f34b8d1114e603bff074ee2b056" target="_blank">Concise Thoughts: Impact of Output Length on LLM Reasoning and Cost</a></p>
                <p><strong>Paper Venue:</strong> arXiv.org</p>
                <p><strong>Paper TL;DR:</strong> The impact of output lengths on LLM inference pipelines is analyzed by introducing and proposing novel metrics to evaluate the correct conciseness of a model and related prompting techniques, and a refined prompt engineering strategy, Constrained-CoT (CCoT), is examined.</p>
                <p><strong>Paper Abstract:</strong> Today's large language models (LLMs) can solve challenging question-answering tasks, and prompt engineering techniques, such as chain-of-thought (CoT), have gained attention for enhancing the explanation and correctness of outputs. However, many models and techniques tend to produce excessively verbose and lengthy answers, leading to issues with both conciseness and generation time. To address this, this paper analyzes the impact of output lengths on LLM inference pipelines by introducing and proposing novel metrics to evaluate the \textit{correct conciseness} of a model and related prompting techniques. Then, we examine the impact of controlling output length through a refined prompt engineering strategy, Constrained-CoT (CCoT), which encourages the model to produce more concise outputs. To better understand the effects of such a prompt, we also introduce two additional scores for analyzing the conciseness, measured in terms of redundancy and information flow in generated answers. Experiments on pretrained LLMs and multiple datasets demonstrate the benefits of the proposed metrics and the effectiveness of CCoT across different models.</p>
                <p><strong>Cost:</strong> 0.015</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e6646.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e6646.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models perform arithmetic, including model details, task details, prompting methods, performance results, and any analysis of internal mechanisms or failure modes.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LLaMA2-70b</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>LLaMA2-70b-chat HF (instruction-tuned)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A large instruction‑tuned autoregressive transformer used in the paper's experiments; evaluated on multi-step arithmetic word problems (GSM8K, SVAMP, ASDIV) under base, CoT, and Constrained‑CoT prompts.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Concise Thoughts: Impact of Output Length on LLM Reasoning and Cost</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Llama2-70b-chathf</td>
                        </tr>
                        <tr>
                            <td><strong>model_family</strong></td>
                            <td>autoregressive transformer (decoder-only)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>70B</td>
                        </tr>
                        <tr>
                            <td><strong>training_data_description</strong></td>
                            <td>Instruction‑tuned on a mixture of generic and open-source datasets and further fine-tuned with human feedback (as reported in Llama2 release notes); training set described as diverse open-source corpora in the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>GSM8K, SVAMP, ASDIV</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>multi-step arithmetic word problems (multi-step addition/subtraction/multiplication/division in natural-language word problems)</td>
                        </tr>
                        <tr>
                            <td><strong>problem_format</strong></td>
                            <td>natural-language math word problems (textual description requiring multi-step arithmetic)</td>
                        </tr>
                        <tr>
                            <td><strong>difficulty_level</strong></td>
                            <td>grade-school to middle-school multi-step word problems (GSM8K = relatively complex word problems; SVAMP and ASDIV generally simpler)</td>
                        </tr>
                        <tr>
                            <td><strong>prompting_method</strong></td>
                            <td>compared plain (base), Chain‑of‑Thought (CoT) zero-shot prompting, and Constrained Chain‑of‑Thought (CCoT) (CoT + explicit limit on answer length in words, e.g., 15/30/45/60/100)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>accuracy (exact final answer match after post-processing), plus HCA/SCA/CCA (concise-aware metrics), and mean generation time (seconds)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>Reported examples: on GSM8K CoT accuracy = 36%; CCoT-30 = 37%; CCoT-100 = 41.77%. Average generation time on GSM8K decreased from 30.09s (CoT) to 23.86s (CCoT with k=100) and further reduced with stricter k; abstract reports constraining to 30 words gave a +4.41% average accuracy and -5.12s computational cost (aggregate reported). CCoT also improved HCA/SCA/CCA (paper reports unified metric improvements ~10%, ~9%, ~9% for HCA, SCA, CCA respectively in aggregate).</td>
                        </tr>
                        <tr>
                            <td><strong>internal_analysis</strong></td>
                            <td>Paper probes outputs at the step/sentence level using redundancy (RMS: syntactic overlap via matching subsequences) and Information Flow (semantic similarity between consecutive steps via BERTScore). Findings: CCoT answers from LLaMA2-70b show consistently lower redundancy (ORR for SVAMP ~19.8–22.6%; GSM8K ORR ~12.6–24.7% depending on constraint) and reduced information flow between steps (examples: for 8-step GSM8K answers CoT 1->2 = 0.5287 vs CCoT-15 = 0.3417; middle steps show largest reductions), indicating CCoT compresses reasoning content while preserving correctness.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_modes</strong></td>
                            <td>Models do not always respect strict short length constraints (k=15,30 can be challenging); for very strict constraints some correct answers exceed k and require tolerance. No internal neuron/attention probing of numeric computation is performed; observed behavioral failure modes include longer output / higher latency under CoT, and smaller margin to respect strict length causing either truncated reasoning or inability to produce correct answers if model cannot compress reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>scaling_trend</strong></td>
                            <td>Large-scale LLaMA2-70b benefits from CCoT: improved trade-off between accuracy and inference time and better conciseness metrics. Paper reports that larger models can follow length constraints more reliably and gain accuracy/time benefits.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Concise Thoughts: Impact of Output Length on LLM Reasoning and Cost', 'publication_date_yy_mm': '2024-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6646.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e6646.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models perform arithmetic, including model details, task details, prompting methods, performance results, and any analysis of internal mechanisms or failure modes.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Falcon-40b</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Falcon-40b-instruct</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An instruction‑tuned large decoder‑only transformer evaluated on the three arithmetic datasets to compare base, CoT, and CCoT prompting; used to show impact of CCoT on generation time and conciseness.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Concise Thoughts: Impact of Output Length on LLM Reasoning and Cost</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Falcon-40b-instruct</td>
                        </tr>
                        <tr>
                            <td><strong>model_family</strong></td>
                            <td>autoregressive transformer (decoder-only)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>40B</td>
                        </tr>
                        <tr>
                            <td><strong>training_data_description</strong></td>
                            <td>Trained on RefinedWeb and other web-scale corpora (paper cites Falcon series / RefinedWeb as training data source); instruction-tuned variant used for experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>GSM8K, SVAMP, ASDIV</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>multi-step arithmetic word problems (natural-language math reasoning)</td>
                        </tr>
                        <tr>
                            <td><strong>problem_format</strong></td>
                            <td>natural-language question (word problem)</td>
                        </tr>
                        <tr>
                            <td><strong>difficulty_level</strong></td>
                            <td>GSM8K (complex), SVAMP and ASDIV (simpler/varied)</td>
                        </tr>
                        <tr>
                            <td><strong>prompting_method</strong></td>
                            <td>base, CoT, and CCoT with explicit word-length constraints (15,30,45,60,100 words)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>accuracy (exact answer match), generation time (seconds), HCA/SCA/CCA, redundancy and information flow scores</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>Paper reports Falcon-40b shows improved trade-off with CCoT on SVAMP and ASDIV (higher accuracy and reduced generation time); for GSM8K, CCoT reduces generation time but does not always increase accuracy relative to CoT (CoT still sometimes better on GSM8K). Example qualitative: CoT outputs were longer and slower; CCoT reduced average length and latency in experiments (specific per-constraint numbers in figures/tables).</td>
                        </tr>
                        <tr>
                            <td><strong>internal_analysis</strong></td>
                            <td>Redundancy and Information Flow measured similarly to LLaMA2-70b. However, Falcon-40b often shows higher information-flow values (more semantic repetition across steps) under many CCoT settings, interpreted as partial inability of a medium-scale model to compress semantic content without repeating. In Falcon-40b's reported 8- and 9-step comparisons, many CCoT variants sometimes yield equal or larger semantic similarity between steps than CoT, indicating less effective compression.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_modes</strong></td>
                            <td>Medium-scale Falcon-40b struggles more than LLaMA2-70b to satisfy strict length constraints while maintaining accuracy; under some CCoT settings it produces outputs with higher semantic repetition or fails to reduce steps effectively. CoT increases output length and latency markedly. Overall, inability to follow tight constraints and occasional loss of accuracy on the more complex GSM8K are observed.</td>
                        </tr>
                        <tr>
                            <td><strong>scaling_trend</strong></td>
                            <td>Compared to LLaMA2-70b, Falcon-40b shows weaker ability to compress reasoning under tight constraints; suggests model-size and training-data differences affect capacity to follow CCoT prompts and benefit from them.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Concise Thoughts: Impact of Output Length on LLM Reasoning and Cost', 'publication_date_yy_mm': '2024-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6646.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e6646.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models perform arithmetic, including model details, task details, prompting methods, performance results, and any analysis of internal mechanisms or failure modes.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>CCoT</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Constrained Chain‑of‑Thought prompting (CCoT)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A prompt engineering method introduced in this paper that augments Chain‑of‑Thought prompts with an explicit natural‑language constraint on maximum answer length (e.g., 'limit the length of the answer to 30 words') to encourage concise reasoning and reduce inference time.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_family</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>training_data_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>GSM8K, SVAMP, ASDIV (used to evaluate CCoT)</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>multi-step arithmetic word problems (compression of CoT reasoning)</td>
                        </tr>
                        <tr>
                            <td><strong>problem_format</strong></td>
                            <td>natural-language word problems with appended CCoT instruction in prompt</td>
                        </tr>
                        <tr>
                            <td><strong>difficulty_level</strong></td>
                            <td>applied across datasets of varied complexity (GSM8K more complex, SVAMP/ASDIV simpler)</td>
                        </tr>
                        <tr>
                            <td><strong>prompting_method</strong></td>
                            <td>zero-shot CoT augmented with an added sentence constraining output length (x = concat(x_user, x_p_CoT, x_l_length_constraint)); evaluated with multiple k values (15,30,45,60,100 words)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>accuracy, HCA/SCA/CCA (conciseness-aware accuracy metrics), mean generation time, redundancy (RMS), information flow (BERTScore-based)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>Aggregate findings: CCoT reduces average generation time compared to CoT (example: LLaMA2-70b GSM8K CoT avg 30.09s -> CCoT up to 23.86s for k=100; stricter k reduced time further). Accuracy often improves or minimally impacted for large models (e.g., LLaMA2-70b GSM8K: CoT 36% -> CCoT-30 37% -> CCoT-100 41.77%). CCoT reduces redundancy (ORR ~12–25% depending on dataset/constraint) and information flow between steps (reported percent reductions up to ~41% in some steps).</td>
                        </tr>
                        <tr>
                            <td><strong>internal_analysis</strong></td>
                            <td>CCoT's effect measured behaviorally: reduces token/word output length, lowers redundancy (syntactic overlap) and decreases semantic overlap between consecutive reasoning steps. No internal weights/activation-level mechanistic probes were performed; the analysis is at output/embedding similarity level.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_modes</strong></td>
                            <td>LLMs do not always strictly obey the specified word limit; very small k values (e.g., 15) are hard to respect for many samples, and smaller models sometimes fail to provide correct answers under tight constraints. CCoT can trade off completeness of intermediate reasoning if the model cannot compress essential steps.</td>
                        </tr>
                        <tr>
                            <td><strong>scaling_trend</strong></td>
                            <td>Effectiveness increases with model size and instruction-following capability: large models (LLaMA2-70b, Falcon-40b) can leverage CCoT to improve conciseness and time, whereas small/medium models struggle.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Concise Thoughts: Impact of Output Length on LLM Reasoning and Cost', 'publication_date_yy_mm': '2024-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6646.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e6646.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models perform arithmetic, including model details, task details, prompting methods, performance results, and any analysis of internal mechanisms or failure modes.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>HCA/SCA/CCA</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Hard-k Concise Accuracy / Soft-k Concise Accuracy / Consistent Concise Accuracy</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Three novel conciseness-aware accuracy metrics introduced in this paper that penalize correct answers for excessive output length and variability: HCA(k) counts correct answers with length <= k; SCA(k,α) applies a soft exponential penalty when length > k; CCA(k,α,β) further penalizes high variance in output lengths across samples.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_family</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>training_data_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>designed to evaluate models on GSM8K, SVAMP, ASDIV</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>evaluative metric for multi-step arithmetic reasoning and any text-to-text tasks where output length matters</td>
                        </tr>
                        <tr>
                            <td><strong>problem_format</strong></td>
                            <td>applied to model outputs after post-processing/extraction of final answer</td>
                        </tr>
                        <tr>
                            <td><strong>difficulty_level</strong></td>
                            <td>not applicable (metric)</td>
                        </tr>
                        <tr>
                            <td><strong>prompting_method</strong></td>
                            <td>applied to outputs from base, CoT, and CCoT prompting to quantify conciseness-aware correctness</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>these are the metrics themselves (HCA/SCA/CCA); reported improvements quantify trade-offs</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>Paper reports that using CCoT with LLaMA2 on GSM8K/SVAMP/ASDIV increased average accuracy with conciseness weighting: e.g., unified improvements reported: HCA +10%, SCA +9%, CCA +9% (aggregate improvement claimed); many table entries show HCA/SCA/CCA per dataset and k values (detailed numeric tables in paper).</td>
                        </tr>
                        <tr>
                            <td><strong>internal_analysis</strong></td>
                            <td>Metrics formalize penalties: HCA uses a hard cutoff p_hard; SCA uses exponential decay p_soft = min(1, exp((k - N(y))/α)); CCA multiplies SCA by p_var = min(1, exp((β - σ)/β)) where σ is std dev of output lengths. Used to show that CCoT improves concise-correct outputs and reduces variability in lengths.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_modes</strong></td>
                            <td>Choice of k, α, β is user-defined and affects conclusions; small α/β can make metrics brittle, and strict HCA can penalize correct but slightly longer helpful answers. Metrics assume reliable post-processing Γ to extract final numeric answer.</td>
                        </tr>
                        <tr>
                            <td><strong>scaling_trend</strong></td>
                            <td>Metrics show CCoT's benefits more clearly for larger models that can follow length constraints; smaller models produce fewer gains under these metrics.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Concise Thoughts: Impact of Output Length on LLM Reasoning and Cost', 'publication_date_yy_mm': '2024-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e6646.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e6646.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models perform arithmetic, including model details, task details, prompting methods, performance results, and any analysis of internal mechanisms or failure modes.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Smaller-models (summary)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Falcon-7b, Llama2-7b, Vicuna-13b (evaluated smaller/medium LLMs)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A set of smaller and medium-sized LLMs evaluated in appendix experiments; used to test whether CCoT is effective at smaller scales and to compare generation time / accuracy trade-offs.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Concise Thoughts: Impact of Output Length on LLM Reasoning and Cost</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Falcon-7b, Llama2-7b, Vicuna-13b (examples in appendix experiments)</td>
                        </tr>
                        <tr>
                            <td><strong>model_family</strong></td>
                            <td>autoregressive transformer (decoder-only)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>7B (Falcon-7b, Llama2-7b), 13B (Vicuna-13b)</td>
                        </tr>
                        <tr>
                            <td><strong>training_data_description</strong></td>
                            <td>Falcon-7b trained on RefinedWeb; Llama2-7b and Vicuna-13b are smaller variants/fine-tuned versions of larger Llama family with differing instruction/data mixes (per paper appendix summary).</td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_name</strong></td>
                            <td>GSM8K (used in appendix evaluation), possibly SVAMP/ASDIV in additional tests</td>
                        </tr>
                        <tr>
                            <td><strong>task_type</strong></td>
                            <td>multi-step arithmetic word problems</td>
                        </tr>
                        <tr>
                            <td><strong>problem_format</strong></td>
                            <td>natural-language word problems</td>
                        </tr>
                        <tr>
                            <td><strong>difficulty_level</strong></td>
                            <td>GSM8K complexity (challenging for small models)</td>
                        </tr>
                        <tr>
                            <td><strong>prompting_method</strong></td>
                            <td>base, CoT, CCoT (k varied)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metric</strong></td>
                            <td>accuracy and generation time (as in main experiments)</td>
                        </tr>
                        <tr>
                            <td><strong>performance_value</strong></td>
                            <td>Paper reports that small-scale models struggle with CCoT: Falcon-7b and Llama2-7b are often unable to follow tight constraints without loss of accuracy; Vicuna-13b produces competitive results (being fine-tuned), while Falcon-7b sometimes has higher generation times or incorrect answers under strict CCoT. Figure 10 in appendix shows generation time and accuracy comparisons across these models on GSM8K.</td>
                        </tr>
                        <tr>
                            <td><strong>internal_analysis</strong></td>
                            <td>No fine-grained internal mechanism probing reported for small models; behavioral patterns: inability to compress reasoning content, failure to meet length constraints reliably, and sometimes increased latency under some CCoT settings.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_modes</strong></td>
                            <td>Small models may produce incorrect answers when forced to compress CoT reasoning (under short k), or may ignore the constraint producing long outputs; in some cases CCoT increased generation time for smaller models (depending on k) rather than reducing it.</td>
                        </tr>
                        <tr>
                            <td><strong>scaling_trend</strong></td>
                            <td>Paper concludes CCoT effectiveness increases with model size and instruction-following capabilities; smaller models perform worse or show inconsistent gains.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Concise Thoughts: Impact of Output Length on LLM Reasoning and Cost', 'publication_date_yy_mm': '2024-07'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Chain-of-thought prompting elicits reasoning in large language models <em>(Rating: 2)</em></li>
                <li>Training verifiers to solve math word problems <em>(Rating: 2)</em></li>
                <li>Are nlp models really able to solve simple math word problems? <em>(Rating: 2)</em></li>
                <li>A diverse corpus for evaluating and developing english math word problem solvers <em>(Rating: 2)</em></li>
                <li>Over-reasoning and redundant calculation of large language models <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-6646",
    "paper_id": "paper-a77d28e13ff34f34b8d1114e603bff074ee2b056",
    "extraction_schema_id": "extraction-schema-126",
    "extracted_data": [
        {
            "name_short": "LLaMA2-70b",
            "name_full": "LLaMA2-70b-chat HF (instruction-tuned)",
            "brief_description": "A large instruction‑tuned autoregressive transformer used in the paper's experiments; evaluated on multi-step arithmetic word problems (GSM8K, SVAMP, ASDIV) under base, CoT, and Constrained‑CoT prompts.",
            "citation_title": "Concise Thoughts: Impact of Output Length on LLM Reasoning and Cost",
            "mention_or_use": "use",
            "model_name": "Llama2-70b-chathf",
            "model_family": "autoregressive transformer (decoder-only)",
            "model_size": "70B",
            "training_data_description": "Instruction‑tuned on a mixture of generic and open-source datasets and further fine-tuned with human feedback (as reported in Llama2 release notes); training set described as diverse open-source corpora in the paper.",
            "benchmark_name": "GSM8K, SVAMP, ASDIV",
            "task_type": "multi-step arithmetic word problems (multi-step addition/subtraction/multiplication/division in natural-language word problems)",
            "problem_format": "natural-language math word problems (textual description requiring multi-step arithmetic)",
            "difficulty_level": "grade-school to middle-school multi-step word problems (GSM8K = relatively complex word problems; SVAMP and ASDIV generally simpler)",
            "prompting_method": "compared plain (base), Chain‑of‑Thought (CoT) zero-shot prompting, and Constrained Chain‑of‑Thought (CCoT) (CoT + explicit limit on answer length in words, e.g., 15/30/45/60/100)",
            "performance_metric": "accuracy (exact final answer match after post-processing), plus HCA/SCA/CCA (concise-aware metrics), and mean generation time (seconds)",
            "performance_value": "Reported examples: on GSM8K CoT accuracy = 36%; CCoT-30 = 37%; CCoT-100 = 41.77%. Average generation time on GSM8K decreased from 30.09s (CoT) to 23.86s (CCoT with k=100) and further reduced with stricter k; abstract reports constraining to 30 words gave a +4.41% average accuracy and -5.12s computational cost (aggregate reported). CCoT also improved HCA/SCA/CCA (paper reports unified metric improvements ~10%, ~9%, ~9% for HCA, SCA, CCA respectively in aggregate).",
            "internal_analysis": "Paper probes outputs at the step/sentence level using redundancy (RMS: syntactic overlap via matching subsequences) and Information Flow (semantic similarity between consecutive steps via BERTScore). Findings: CCoT answers from LLaMA2-70b show consistently lower redundancy (ORR for SVAMP ~19.8–22.6%; GSM8K ORR ~12.6–24.7% depending on constraint) and reduced information flow between steps (examples: for 8-step GSM8K answers CoT 1-&gt;2 = 0.5287 vs CCoT-15 = 0.3417; middle steps show largest reductions), indicating CCoT compresses reasoning content while preserving correctness.",
            "failure_modes": "Models do not always respect strict short length constraints (k=15,30 can be challenging); for very strict constraints some correct answers exceed k and require tolerance. No internal neuron/attention probing of numeric computation is performed; observed behavioral failure modes include longer output / higher latency under CoT, and smaller margin to respect strict length causing either truncated reasoning or inability to produce correct answers if model cannot compress reasoning.",
            "scaling_trend": "Large-scale LLaMA2-70b benefits from CCoT: improved trade-off between accuracy and inference time and better conciseness metrics. Paper reports that larger models can follow length constraints more reliably and gain accuracy/time benefits.",
            "uuid": "e6646.0",
            "source_info": {
                "paper_title": "Concise Thoughts: Impact of Output Length on LLM Reasoning and Cost",
                "publication_date_yy_mm": "2024-07"
            }
        },
        {
            "name_short": "Falcon-40b",
            "name_full": "Falcon-40b-instruct",
            "brief_description": "An instruction‑tuned large decoder‑only transformer evaluated on the three arithmetic datasets to compare base, CoT, and CCoT prompting; used to show impact of CCoT on generation time and conciseness.",
            "citation_title": "Concise Thoughts: Impact of Output Length on LLM Reasoning and Cost",
            "mention_or_use": "use",
            "model_name": "Falcon-40b-instruct",
            "model_family": "autoregressive transformer (decoder-only)",
            "model_size": "40B",
            "training_data_description": "Trained on RefinedWeb and other web-scale corpora (paper cites Falcon series / RefinedWeb as training data source); instruction-tuned variant used for experiments.",
            "benchmark_name": "GSM8K, SVAMP, ASDIV",
            "task_type": "multi-step arithmetic word problems (natural-language math reasoning)",
            "problem_format": "natural-language question (word problem)",
            "difficulty_level": "GSM8K (complex), SVAMP and ASDIV (simpler/varied)",
            "prompting_method": "base, CoT, and CCoT with explicit word-length constraints (15,30,45,60,100 words)",
            "performance_metric": "accuracy (exact answer match), generation time (seconds), HCA/SCA/CCA, redundancy and information flow scores",
            "performance_value": "Paper reports Falcon-40b shows improved trade-off with CCoT on SVAMP and ASDIV (higher accuracy and reduced generation time); for GSM8K, CCoT reduces generation time but does not always increase accuracy relative to CoT (CoT still sometimes better on GSM8K). Example qualitative: CoT outputs were longer and slower; CCoT reduced average length and latency in experiments (specific per-constraint numbers in figures/tables).",
            "internal_analysis": "Redundancy and Information Flow measured similarly to LLaMA2-70b. However, Falcon-40b often shows higher information-flow values (more semantic repetition across steps) under many CCoT settings, interpreted as partial inability of a medium-scale model to compress semantic content without repeating. In Falcon-40b's reported 8- and 9-step comparisons, many CCoT variants sometimes yield equal or larger semantic similarity between steps than CoT, indicating less effective compression.",
            "failure_modes": "Medium-scale Falcon-40b struggles more than LLaMA2-70b to satisfy strict length constraints while maintaining accuracy; under some CCoT settings it produces outputs with higher semantic repetition or fails to reduce steps effectively. CoT increases output length and latency markedly. Overall, inability to follow tight constraints and occasional loss of accuracy on the more complex GSM8K are observed.",
            "scaling_trend": "Compared to LLaMA2-70b, Falcon-40b shows weaker ability to compress reasoning under tight constraints; suggests model-size and training-data differences affect capacity to follow CCoT prompts and benefit from them.",
            "uuid": "e6646.1",
            "source_info": {
                "paper_title": "Concise Thoughts: Impact of Output Length on LLM Reasoning and Cost",
                "publication_date_yy_mm": "2024-07"
            }
        },
        {
            "name_short": "CCoT",
            "name_full": "Constrained Chain‑of‑Thought prompting (CCoT)",
            "brief_description": "A prompt engineering method introduced in this paper that augments Chain‑of‑Thought prompts with an explicit natural‑language constraint on maximum answer length (e.g., 'limit the length of the answer to 30 words') to encourage concise reasoning and reduce inference time.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": null,
            "model_family": null,
            "model_size": null,
            "training_data_description": null,
            "benchmark_name": "GSM8K, SVAMP, ASDIV (used to evaluate CCoT)",
            "task_type": "multi-step arithmetic word problems (compression of CoT reasoning)",
            "problem_format": "natural-language word problems with appended CCoT instruction in prompt",
            "difficulty_level": "applied across datasets of varied complexity (GSM8K more complex, SVAMP/ASDIV simpler)",
            "prompting_method": "zero-shot CoT augmented with an added sentence constraining output length (x = concat(x_user, x_p_CoT, x_l_length_constraint)); evaluated with multiple k values (15,30,45,60,100 words)",
            "performance_metric": "accuracy, HCA/SCA/CCA (conciseness-aware accuracy metrics), mean generation time, redundancy (RMS), information flow (BERTScore-based)",
            "performance_value": "Aggregate findings: CCoT reduces average generation time compared to CoT (example: LLaMA2-70b GSM8K CoT avg 30.09s -&gt; CCoT up to 23.86s for k=100; stricter k reduced time further). Accuracy often improves or minimally impacted for large models (e.g., LLaMA2-70b GSM8K: CoT 36% -&gt; CCoT-30 37% -&gt; CCoT-100 41.77%). CCoT reduces redundancy (ORR ~12–25% depending on dataset/constraint) and information flow between steps (reported percent reductions up to ~41% in some steps).",
            "internal_analysis": "CCoT's effect measured behaviorally: reduces token/word output length, lowers redundancy (syntactic overlap) and decreases semantic overlap between consecutive reasoning steps. No internal weights/activation-level mechanistic probes were performed; the analysis is at output/embedding similarity level.",
            "failure_modes": "LLMs do not always strictly obey the specified word limit; very small k values (e.g., 15) are hard to respect for many samples, and smaller models sometimes fail to provide correct answers under tight constraints. CCoT can trade off completeness of intermediate reasoning if the model cannot compress essential steps.",
            "scaling_trend": "Effectiveness increases with model size and instruction-following capability: large models (LLaMA2-70b, Falcon-40b) can leverage CCoT to improve conciseness and time, whereas small/medium models struggle.",
            "uuid": "e6646.2",
            "source_info": {
                "paper_title": "Concise Thoughts: Impact of Output Length on LLM Reasoning and Cost",
                "publication_date_yy_mm": "2024-07"
            }
        },
        {
            "name_short": "HCA/SCA/CCA",
            "name_full": "Hard-k Concise Accuracy / Soft-k Concise Accuracy / Consistent Concise Accuracy",
            "brief_description": "Three novel conciseness-aware accuracy metrics introduced in this paper that penalize correct answers for excessive output length and variability: HCA(k) counts correct answers with length &lt;= k; SCA(k,α) applies a soft exponential penalty when length &gt; k; CCA(k,α,β) further penalizes high variance in output lengths across samples.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": null,
            "model_family": null,
            "model_size": null,
            "training_data_description": null,
            "benchmark_name": "designed to evaluate models on GSM8K, SVAMP, ASDIV",
            "task_type": "evaluative metric for multi-step arithmetic reasoning and any text-to-text tasks where output length matters",
            "problem_format": "applied to model outputs after post-processing/extraction of final answer",
            "difficulty_level": "not applicable (metric)",
            "prompting_method": "applied to outputs from base, CoT, and CCoT prompting to quantify conciseness-aware correctness",
            "performance_metric": "these are the metrics themselves (HCA/SCA/CCA); reported improvements quantify trade-offs",
            "performance_value": "Paper reports that using CCoT with LLaMA2 on GSM8K/SVAMP/ASDIV increased average accuracy with conciseness weighting: e.g., unified improvements reported: HCA +10%, SCA +9%, CCA +9% (aggregate improvement claimed); many table entries show HCA/SCA/CCA per dataset and k values (detailed numeric tables in paper).",
            "internal_analysis": "Metrics formalize penalties: HCA uses a hard cutoff p_hard; SCA uses exponential decay p_soft = min(1, exp((k - N(y))/α)); CCA multiplies SCA by p_var = min(1, exp((β - σ)/β)) where σ is std dev of output lengths. Used to show that CCoT improves concise-correct outputs and reduces variability in lengths.",
            "failure_modes": "Choice of k, α, β is user-defined and affects conclusions; small α/β can make metrics brittle, and strict HCA can penalize correct but slightly longer helpful answers. Metrics assume reliable post-processing Γ to extract final numeric answer.",
            "scaling_trend": "Metrics show CCoT's benefits more clearly for larger models that can follow length constraints; smaller models produce fewer gains under these metrics.",
            "uuid": "e6646.3",
            "source_info": {
                "paper_title": "Concise Thoughts: Impact of Output Length on LLM Reasoning and Cost",
                "publication_date_yy_mm": "2024-07"
            }
        },
        {
            "name_short": "Smaller-models (summary)",
            "name_full": "Falcon-7b, Llama2-7b, Vicuna-13b (evaluated smaller/medium LLMs)",
            "brief_description": "A set of smaller and medium-sized LLMs evaluated in appendix experiments; used to test whether CCoT is effective at smaller scales and to compare generation time / accuracy trade-offs.",
            "citation_title": "Concise Thoughts: Impact of Output Length on LLM Reasoning and Cost",
            "mention_or_use": "use",
            "model_name": "Falcon-7b, Llama2-7b, Vicuna-13b (examples in appendix experiments)",
            "model_family": "autoregressive transformer (decoder-only)",
            "model_size": "7B (Falcon-7b, Llama2-7b), 13B (Vicuna-13b)",
            "training_data_description": "Falcon-7b trained on RefinedWeb; Llama2-7b and Vicuna-13b are smaller variants/fine-tuned versions of larger Llama family with differing instruction/data mixes (per paper appendix summary).",
            "benchmark_name": "GSM8K (used in appendix evaluation), possibly SVAMP/ASDIV in additional tests",
            "task_type": "multi-step arithmetic word problems",
            "problem_format": "natural-language word problems",
            "difficulty_level": "GSM8K complexity (challenging for small models)",
            "prompting_method": "base, CoT, CCoT (k varied)",
            "performance_metric": "accuracy and generation time (as in main experiments)",
            "performance_value": "Paper reports that small-scale models struggle with CCoT: Falcon-7b and Llama2-7b are often unable to follow tight constraints without loss of accuracy; Vicuna-13b produces competitive results (being fine-tuned), while Falcon-7b sometimes has higher generation times or incorrect answers under strict CCoT. Figure 10 in appendix shows generation time and accuracy comparisons across these models on GSM8K.",
            "internal_analysis": "No fine-grained internal mechanism probing reported for small models; behavioral patterns: inability to compress reasoning content, failure to meet length constraints reliably, and sometimes increased latency under some CCoT settings.",
            "failure_modes": "Small models may produce incorrect answers when forced to compress CoT reasoning (under short k), or may ignore the constraint producing long outputs; in some cases CCoT increased generation time for smaller models (depending on k) rather than reducing it.",
            "scaling_trend": "Paper concludes CCoT effectiveness increases with model size and instruction-following capabilities; smaller models perform worse or show inconsistent gains.",
            "uuid": "e6646.4",
            "source_info": {
                "paper_title": "Concise Thoughts: Impact of Output Length on LLM Reasoning and Cost",
                "publication_date_yy_mm": "2024-07"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Chain-of-thought prompting elicits reasoning in large language models",
            "rating": 2
        },
        {
            "paper_title": "Training verifiers to solve math word problems",
            "rating": 2
        },
        {
            "paper_title": "Are nlp models really able to solve simple math word problems?",
            "rating": 2
        },
        {
            "paper_title": "A diverse corpus for evaluating and developing english math word problem solvers",
            "rating": 2
        },
        {
            "paper_title": "Over-reasoning and redundant calculation of large language models",
            "rating": 1
        }
    ],
    "cost": 0.015212999999999999,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>Concise Thoughts: Impact of Output Length on LLM Reasoning and Cost</h1>
<p>Sania Nayab<em> Giulio Rossolini</em> Marco Simoni<em> ${ }^{</em> \ddagger}$ Andrea Saracino<em><em> Giorgio Buttazzo</em> Nicolamaria Manes ${ }^{\dagger}$ Fabrizio Giacomelli ${ }^{\dagger}$<br></em>Department of Excellence in Robotics and AI, Scuola Superiore Sant'Anna, Pisa, Italy<br>*Institute of Informatics and Telematics, National Research Council of Italy<br>${ }^{\ddagger}$ Sapienza Università di Roma, ${ }^{\dagger}$ Mediavoice Srl - Roma e Napoli, Italy</p>
<h4>Abstract</h4>
<p>Today's large language models (LLMs) can solve challenging question-answering tasks, and prompt engineering techniques, such as chain-of-thought (CoT), have gained attention for enhancing the explanation and correctness of outputs. However, many models and techniques tend to produce excessively verbose and lengthy answers, leading to issues with both conciseness and generation time. To address this, this paper analyzes the impact of output lengths on LLM inference pipelines by introducing and proposing novel metrics to evaluate the correct conciseness of a model and related prompting techniques. Then, we examine the impact of controlling output length through a refined prompt engineering strategy, Constrained-CoT (CCoT), which encourages the model to produce more concise outputs. To better understand the effects of such a prompt, we also introduce two additional scores for analyzing the conciseness, measured in terms of redundancy and information flow in generated answers. Experiments on pretrained LLMs and multiple datasets demonstrate the benefits of the proposed metrics and the effectiveness of CCoT across different models.</p>
<h2>1 Introduction</h2>
<p>In recent years, large language models (LLMs) have demonstrated remarkable capabilities in tackling complex question-answering tasks, making significant strides in natural language understanding and generative AI (Taori et al., 2023; Chiang et al., 2023; Dolly, 2023; Geng et al., 2023). The continuous advancements made in architectures and training methods played a crucial role in enhancing the performance of these models. Alongside these developments, prompt techniques have also seen substantial evolution. One such technique that has attracted considerable attention is chain-of-thought (CoT) prompting (Wei et al., 2022; Fu et al., 2023),
which enhances the explanation and correctness of the output by encouraging the LLM to articulate its answer through intermediate reasoning steps.</p>
<p>Despite its advantages, the CoT prompting can lead to long outputs, increasing the time required for the model to generate a response. This is due to the nature of autoregressive transformers, which decode text word by word (Vaswani et al., 2017; Shekhar et al., 2024), which implies that the time required to generate a response is unbounded and heavily influenced by the length of the reasoning provided, as demonstrated in Section 3. Such lengthy and variable delays in responses can be undesirable when an LLM interacts with a user in an interactive conversation. Furthermore, especially for complex models, long answers imply a loss of conciseness and even of precision in the answer, with a performance degradation which is not only bound to computation time. This issue highlights the need to consider (i) metrics for evaluating the conciseness of the outputs and (ii) solutions to avoid excessively long chains of reasoning.</p>
<p>To address this, the first part of this work emphasizes the importance of accounting for the length of an answer in its correctness evaluation, as an indicator of computational cost. This is achieved by introducing three novel metrics (HCA, SCA, and CCA) that assess both the brevity and correctness of a generated answer. The proposed metrics aim to reweight the accuracy of a model by considering aspects related to output length that impact inference time and time predictability.</p>
<p>Then, to address the significant increase in output length caused by CoT techniques, the second part of this work explores how to leverage the benefits of CoT advances while getting control over the length of CoT reasoning through specific prompt designs. To this end, we introduce a refined prompt strategy called Constrained-CoT (CCoT), which encourages LLMs to generate concise outputs by explicitly limiting the reasoning length. The ap-</p>
<p>proach allows users to set a flexible length constraint that serves as a tunable parameter, balancing the strictness of brevity in the answers. The objective is to enable controlled reasoning, ensuring that outputs are concise and computationally efficient without sacrificing accuracy.</p>
<p>To better assess the ability of LLMs to follow such instructions and gain deeper insights into conciseness, we also introduce additional scores that analyze the level of redundancy and the information flow in the generated answers. These scores help demonstrate, through experimental analysis, that large models (such as Llama2-70b and Falcon40b) can effectively leverage the proposed prompt to produce more concise yet accurate responses, while still retaining useful information. This allows achieving an enhanced trade-off between accuracy and brevity, measured comprehensively using the proposed metrics. For instance, using LLaMA2 on three datasets (GSM8K, SVAMP, ASDIV), constraining the reasoning length to 30 words (CCoT30) increases the average accuracy by $4.41 \%$ and reduces computational costs by 5.12s. These accuracy and cost improvements are better remarked and unified in the proposed metrics, showing an improvement of $10 \%, 9 \%$ and $9 \%$ for HCA, SCA, and CCA, respectively.</p>
<p>To summarize, this work provides the following main contributions:</p>
<ul>
<li>Introduction of the concept of Constrained-CoT (CCoT), a prompt engineering strategy designed to limit the length of answers generated by LLMs, thereby enhancing the trade-off between generation time and correct conciseness.</li>
<li>Three novel metrics to evaluate the correctness of LLM outputs while accounting for the conciseness (HCA, SCA and CCA).</li>
<li>Introduction of an analysis of the conciseness in terms of redundancy and information flow for a given answer, thus offering an understanding of the effects of constraining output length.</li>
<li>We conducted multiple experiments to analyze the impact of CCoT across different datasets and LLMs, demonstrating its benefits in terms of inference time, accuracy and conciseness with respect to the original CoT. Furthermore, we show the benefits of adopting the proposed metrics and scores in terms of conciseness.</li>
</ul>
<p>The rest of the paper is organized as follows: Section 2 discusses the literature related to this work; Section 3 motivates the addressed study; Section 4 presents a set of metrics that account for conciseness; Section 5 introduces the proposed CCoT approach; Section 6 introduces analysis for evaluating the conciseness of a given answer; Section 7 reports the results of a set of experiments carried out on pre-trained models with three arithmetic reasoning datasets; and Section 8 states the conclusions and discusses some future directions.</p>
<h2>2 Related work</h2>
<p>To the best of our knowledge, most recent works on LLMs focused on increasing their accuracy (Jiang et al., 2020; Kaplan et al., 2020; Zhu et al., 2023). However, as models scale up, they tend to generate more extensive and articulated responses (Bhargava et al., 2023), which can introduce other problems, such as hallucinations (where the model produces information that appears plausible but not grounded (Kadavath et al., 2022), or unnecessarily long explanations (Qiu et al., 2024; Azaria and Mitchell, 2023)), which can obscure key information, making it difficult for users to extract relevant content efficiently (Khashabi et al., 2021; Wang et al., 2024b). To filter out useless reasoning, Li et al. (2021) proposed a multi-hop processing technique, where an extraction task on the encoder to obtain the rationale for an answer, which is the most relevant piece of text in an input prompt to a given question.</p>
<p>To further improve the accuracy of LLMs, several prompt engineering approaches have been presented in recent years (Qin and Eisner, 2021). Prompt engineering involves the strategic design of input patterns to guide the model toward generating more accurate and relevant responses (Reynolds and McDonell, 2021; Marvin et al., 2023). However, most of these approaches have been conceived to enhance model accuracy, increasing the output length. For instance, Lo (2023) and Strobelt et al. (2022) introduced prompt-based approaches by adding task-specific patterns to frame the input data. While these methods allow boosting accuracy, they can also produce longer outputs due to the additional context and detail introduced by the prompt, making it challenging to provide factual and concise answers (Shi et al., 2023).</p>
<p>Another form of prompt engineering was proposed to improve reasoning within the conclusive</p>
<p>answer. In this context, Chain-of-Thought (CoT) prompting <em>Wei et al. (2022)</em> is one of the most notable methods, showing significant benefits in QA tasks by requiring the model to provide a step-by-step explanation along with the final response. However, as also highlighted in Section 3, answers generated with CoT tend to be lengthy, hence increasing the generation time <em>Liu et al. (2018); Takase and Okazaki (2019)</em>.</p>
<p>Given the substantial amount of work focused on improving the accuracy of LLMs, it is not surprising that most of the adopted metrics <em>Lin (2004); Stallings and Gillmore (1971)</em> and benchmarks <em>Clark et al. (2018); Lin et al. (2021)</em> only address the correctness of the responses, without paying attention to conciseness and response times <em>Bhargava et al. (2023); Chiang and Lee (2024)</em>. In other tasks too, such as reasoning in control engineering, the focus has been primarily on correctness rather than consistency or conciseness <em>Kevian et al. (2024)</em>. Additionally, several studies have addressed computational cost challenges but not the conciseness. For example, <em>Wang et al. (2024a)</em> evaluated the budget-aware reasoning capabilities of LLMs, while <em>Zheng et al. (2024b)</em> proposed an inference pipeline to improve processing speed. Other works have explored similar optimization approaches, including <em>Hao et al. (2024)</em> and <em>Bi et al. (2020)</em>. In addition, <em>Chiang and Lee (2024)</em> proposed a benchmark to study LLMs accuracy while incorporating a manual redundancy assessment.</p>
<p>Despite recent advancements, several key aspects remain not sufficiently explored: (i) the impact of concise answers on inference cost and time predictability; (ii) the integration of such aspects into unified metrics that evaluate LLMs not only in terms of correctness but also conciseness; and (iii) an understanding of the analysis of conciseness through the conciseness based on the embeddings content extracted by the generated answers.</p>
<p>This work. To address these challenges, this work introduces novel metrics that jointly account for the conciseness and correctness of generated responses. Additionally, two new scores are proposed to assess conciseness from the embeddings produced by the model. These scores focus on the importance of reasoning steps by analyzing redundancy and information flow. Then, to evaluate the ability of LLMs to control the length of reasoning in their outputs, this work introduces a refined version of the CoT prompting <em>Wei et al. (2022)</em>, termed Constrained Chain-of-Thought (CCoT). This approach explicitly guides the model to limit the length of its reasoning while preserving the quality of its answers and improving the inference time. This is achieved by improving the conciseness of the responses, which is analyzed and assessed using the proposed scores.</p>
<h2>3 Motivations</h2>
<p>The output generation time of an LLM depends on various factors, including the model architecture, the pre-and post-processing steps, the answer decoding process, and the question posed, also considering the use of prompt engineering approaches. While the computational cost due to the architecture is well understood, the influence of the other aspects on the overall generation time is less clear and requires further investigation. More formally, an LLM can be represented as a function $f$ that takes as input a prompt $x$ with $\mathcal{N}(x)$ tokens and generates an output $\hat{y}=f(x)$, having $\mathcal{N}(\hat{y})$ tokens, where $\mathcal{N}$ is a length operator that simply counts the number of tokens. The input $x$ can be considered as composed of the original user input $x_{\text {us }}$ and a prompt engineering text $x_{p}$, depending on the technique used. For instance, in a zero-shot CoT setting, the prompt can be computed as $x=\operatorname{concat}(x_{\text {us }}, x_{p})$, where $x_{p}$ is an explicit request for providing reasoning steps in the answer and $\operatorname{concat}(a,b)$ is the concatenation operator that merges two vectors $a$ and $b$ into a single one.</p>
<p>In an encoder-decoder architecture, as the one used by Transformers <em>Vaswani et al. (2017)</em>, let $f_{e}(x)$ and $f_{d}(x)$ denote the functions associated with the encoder and the decoder, respectively. Then, the output $\hat{y}$ is a list of tokens $[a^{(1)}, \ldots, a^{(\mathcal{N}(\hat{y}))}]$, where each $a^{(i)}$ is computed based on the previously generated tokens and the encoder's embedding representation $f_{e}(x)$. That is,</p>
<p>$$
a^{(i)}=f_{d}\left(f_{e}(x),\left[a^{(0)}, \ldots, a^{(i-1)}\right]\right), \quad i&gt;0
$$</p>
<p>From Equation (1), it is clear that the larger the set of output tokens in the answer, the higher the time the model takes to generate the answer due to the increased number of times the decoder is invoked. The same consideration could also be</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Figure 1: Analysis of the impact of CoT on Falcon-40b efficiency: (top) Relation between response time and output length, without CoT (blue dots) and with CoT (red dots), across 100 questions from the GSM8K test set. (bottom) Output words variation between output length with CoT and without CoT using 50 random samples from the GSM8K test set.</p>
<p>applied to decoder only, where the model runs a new inference for each produced word.</p>
<p>To highlight such a dependency, we conducted preliminary tests on Falcon-40B to evaluate the impact of the CoT method in answering arithmetic questions, using a subset of 100 random questions from the GSM8K dataset (Cobbe et al., 2021). The results of this test are illustrated in Figure 1a, where red and blue dots refer to answers given with and without CoT, respectively. The scatter plot shows that CoT significantly increases the output length and generation time. This suggests that while CoT improves the correctness of responses (see Section 7), more attention should be given to the time cost it introduces. To better appreciate the impact of CoT on the output length, Figure 1b reports the output length (in terms of number of generated words) produced by Falcon-40b on a set of 50 questions from GSM8K without CoT (blue bars) and with CoT (pink bars). Note that purple areas denote the areas where the two bars overlap.</p>
<h2>4 Metrics for Correct Conciseness</h2>
<p>Motivated by the previous considerations, this section presents three novel metrics to evaluate the capability of an LLM to provide <em>correct</em> as well as <em>concise</em> responses. The idea is to redefine the classic accuracy metric to integrate conciseness aspects, which as highlighted in Section 7.3 impacts significantly the generation time and the computational cost, into the LLM output's correctness. Formally, an answer <em>ŷ</em> is considered correct if the conclusion extracted through a post-processing function Γ matches the given ground truth <em>y</em>. Thus, the accuracy of an LLM can be computed as</p>
<p>$$
\mathcal{A} = \frac{1}{N} \sum_{i=1}^{N} \mathbb{1}(\Gamma(\hat{y}), y), \tag{2}
$$</p>
<p>where <em>N</em> is the number of tested samples and $\mathbb{1}(u, v)$ is the indicator function that returns 1 if <em>u = v</em>, 0 otherwise. Please note that Γ represents a user-defined function that can be implemented based on a regular expression (e.g., by extracting specific patterns from the sentence (Fu et al., 2023)) or using pseudo-judge approaches (e.g., by using a secondary large model as a judge (Zheng et al., 2024a)).</p>
<p>Starting from Equation (2), the conciseness of an output <em>ŷi</em> can be integrated with its correctness by multiplying the indicator function by a penalty term $p(\hat{y}_i) \in [0, 1]$ that decreases its value for long outputs:</p>
<p>$$
\frac{1}{N} \sum_{i=1}^{N} \left[ \mathbb{1}(\Gamma(\hat{y}_i), y_i) \cdot p(\hat{y}_i) \right]. \tag{3}
$$</p>
<p>The following defines three specific metrics by setting a proper penalty function.</p>
<p><strong>Hard-$$k$$</strong> <strong>Concise Accuracy:</strong> HCA(<em>k</em>). It measures the fraction of correct outputs that do not exceed a user-specified length <em>k</em>:</p>
<p>$$
\text{HCA}(k) = \frac{1}{N} \sum_{i=1}^{N} \left[ \mathbb{1}(\Gamma(\hat{y}<em hard="hard">i), y_i) \cdot p</em>_i, k) \right],
$$}(\hat{y</p>
<p>where</p>
<p>$$
p_{hard}(\hat{y}_i, k) = \begin{cases}
1 &amp; \text{if } \mathcal{N}(\hat{y}_i) \leq k \
0 &amp; \text{otherwise}
\end{cases} \tag{4}
$$</p>
<p>This metric does not account for responses that exceed the specified maximum length, thereby promoting conciseness. We believe it could be particularly useful in scenarios where strict adherence to length constraints is essential, such as in real-time systems or environments with limited computational resources.</p>
<p>Soft-k Concise Accuracy: $\operatorname{SCA}(k, \alpha)$. It generalizes the previous metric by penalizing the correct answers that exceed the maximum length $k$ with a term that decreases exponentially with a decay factor $\alpha$ :
$\operatorname{SCA}(k, \alpha)=\frac{1}{N} \sum_{i=1}^{N}\left[\mathbb{1}\left(\Gamma\left(\hat{y}<em i="i">{i}\right), y</em>, k, \alpha\right)\right]$,
where}\right) \cdot p_{\text {soft }}\left(\hat{y}_{i</p>
<p>$$
p_{\text {soft }}\left(\hat{y}<em i="i">{i}, k, \alpha\right)=\min \left(1, e^{\frac{k-\mathcal{N}\left(\hat{y}</em>\right)
$$}\right)}{\alpha}</p>
<p>In the formula, the user-defined decay $\alpha \geq 0$ can be considered a sort of tolerance that controls how much the length impacts the overall accuracy; the higher the value of $\alpha$, the higher the tolerance for answers exceeding the specified length $k$. Note that for $\alpha=0, \operatorname{SCA}(k, 0)$ reduces to $\operatorname{HCA}(k)$.</p>
<p>Consistent Concise Accuracy: $\operatorname{CCA}(k, \alpha, \beta)$. It further generalizes the previous metrics by also accounting for the variation in the lengths among all the outputs obtained:</p>
<p>$$
\operatorname{CCA}(k, \alpha, \beta)=\operatorname{SCA}(k, \alpha) \cdot p_{\text {var }}(\sigma, \beta)
$$</p>
<p>where</p>
<p>$$
p_{\text {var }}(\sigma, \beta)=\min \left(1, e^{\frac{\beta-\sigma}{\beta}}\right)
$$</p>
<p>In Equation (6), $\sigma$ denotes the standard deviation of the output length distribution, whereas $\beta$ is a parameter that controls the tolerance for having large length variations: the higher the value of $\beta$, the higher the tolerance. Note that, given a tolerance $\beta, p_{\text {var }}(\sigma, \beta)=1$ for $\sigma \leq \beta$, while it decreases exponentially for $\sigma&gt;\beta$.</p>
<p>The CCA metric aims to promote consistency in the lengths of responses, representing an important measure when the predictability of inference time is a crucial property for a specific application. A low standard deviation $\sigma$ indicates that the model produces responses of uniform length. In contrast, a high value of $\sigma$ denotes a model with a large response variability, making predicting its timing response time difficult.</p>
<h2>5 CCoT Prompting</h2>
<p>From the results presented in Section 3, it is clear that the relationship between output length and inference time necessitates deeper awareness. To this end, this section focuses on improving the use of</p>
<p>CoT, aiming to preserve the benefits of this technique while paying more attention to the length of the answers. This help achieve a better trade-off between efficiency and accuracy.</p>
<p>For this purpose, we introduce a constrained chain of thought (CCoT) prompt, which includes an explicit sentence to constrain the generated output to a maximum number of words, encouraging the model to compress its reasoning and produce a more concise answer in a reduced amount of time. As explained in Section 3, CoT-prompt can be computed as $x=\operatorname{concat}\left(x_{\text {us }}, x_{p}\right)$, where $x_{p}$ is an explicit request for providing reasoning steps in the generated answer (e.g., "let's think step by step"). Technically, to push LLMs to return more concise reasoning, the CCoT-prompt is formalized as $x=\operatorname{concat}\left(x_{\text {us }}, x_{p}, x_{l}\right)$, where $x_{l}$ represents the sentence that specifies the constraint on the output length (e.g., "and limit the length of the answer to 30 words"). Figure 2 shows an example that illustrates the difference between a CoT and a CCoT prompt. Note that the answer generated for that specific question using a CoT prompt consists of 67 words in 17.64 s , while the answer generated on the same question provided with a CCoT prompt (specifying a constraint of 45 words) consists of 34 words in 11.65 s , and it is still correct.</p>
<p>The analysis presented in the following section and experimental part in Section 7 provide a detailed evaluation of the CCoT prompting technique using various metrics and demonstrate its benefits on the conciseness along with redundancy and information flow scores of the generated answers.</p>
<h2>6 Analysis of the conciseness</h2>
<p>To provide a deeper understanding and more comprehensive comparisons of answers in terms of conciseness, we define some conciseness properties for a given answer in the following. Intuitively, we assume that the conciseness of an answer in the CoT paradigm could be derived from the following two concepts: how many steps are required to produce a response and how much information is repeated in successive steps. While the first property is easy to derive by immediately looking at the number of steps, assuming to have a similar number of steps from two answers, extracting a numerical interpretation of the conciseness could be more complicated. For this purpose, we define two additional scores: Redundancy, which measures</p>
<h1>CoT $\rightarrow$ output length 67 words; inference time 11.65 s</h1>
<p>Q: Tracy used a piece of wire 4 feet long to support tomato plants in the garden. The wire was cut into pieces 6 inches long. How many pieces did she obtain? Let's think a bit step by step</p>
<p>A: First, we need to convert 4 feet to inches. There are 12 inches in a foot, so 4 feet equals $4 \times 12=48$ inches. Next, we can divide the total number of inches by the length of each piece ( 6 inches) to find the total number of pieces: 48 inches $\div 6$ inches $=8$ pieces. Therefore, Tracy obtained 8 pieces of wire.</p>
<h2>CCoT-45 $\rightarrow$ output length 34 words; inference time 11.65 s</h2>
<p>Q: Tracy used a piece of wire 4 feet long to support tomato plants in the garden. The wire was cut into pieces 6 inches long. How many pieces did she obtain? Let's think a bit step by step and limit the answer length to 45 words.</p>
<p>A: 1. Convert 4 feet to inches: $4 \times 12=48$ inches 2 . Divide 48 inches by 6 inches per piece: $48 \div 6=8$ pieces. So, Tracy obtained 8 pieces of wire.</p>
<p>Figure 2: Example of CCoT in a zero-shot setting for a question extracted from the GSM8K dataset. In each box, we show the prompt and answer provided by the LLM. The box above shows the classic CoT zero-shot approach, where long reasoning is returned as output. The box below shows the use of CCoT, which reduces the number of output words while maintaining a correct answer. In the box title, we also show the word count along with inference time to clarify the improvements of the approach.
the extent to which individual steps in a generated answer repeat or overlap in synthetical content, and Information Flow, which measures how much the semantic information of the previous step is repeated in the current step. To compute these two scores, both CCoT and CoT answers are divided into discrete steps, based on sentence tokenization ${ }^{2}$.</p>
<h3>6.1 Redundancy Score</h3>
<p>The redundancy score for each step represents how much its content overlaps with other steps. Let a generated answer $\hat{y}$ be divided into $n$ steps $S=\left{s_{1}, s_{2}, \ldots, s_{n}\right}$, where each $s_{i}$ represents a single step (sentence). The redundancy mean score $\operatorname{RMS}(\hat{y})$ is computed as:</p>
<p>$$
\operatorname{RMS}(\hat{y})=\frac{1}{n \cdot(n-1)} \sum_{i}^{n} \sum_{j \neq i}^{n} \operatorname{SyS}\left(s_{i}, s_{j}\right)
$$</p>
<p>where $\operatorname{SyS}\left(s_{i}, s_{j}\right)$ measures the syntactical similarity between steps $s_{i}$ and $s_{j}$ as the ratio of matching subsequences. This is computed as $\operatorname{SyS}\left(s_{i}, s_{j}\right)=$ $\frac{\operatorname{LMS}\left(s_{i}, s_{j}\right)}{\operatorname{TLCS}\left(s_{i}, s_{j}\right)}$, where LMS states for Length of Matching Subsequences and TLCS states for Total Length of Compared Sequences (Ratcliff et al., 1988).</p>
<p>These scores help to evaluate whether the reasoning process is concise or contains redundant</p>
<p><sup id="fnref2:0"><a class="footnote-ref" href="#fn:0">1</a></sup>synthetical repetition. We assume that for not concise answers we have a high redundancy, which indicates that steps are overly reliant on repeating information rather than advancing the reasoning.</p>
<h3>6.2 Information Flow</h3>
<p>The Information Flow $\mathcal{I}\left(s_{i}, s_{i+1}\right)$ between two consecutive steps $s_{i}$ and $s_{i+1}$ measures the extent to which the content of $s_{i}$, in a semantic sense, persists in $s_{i+1}$. This can be expressed as:</p>
<p>$$
\mathcal{I}\left(s_{i}, s_{i+1}\right)=\operatorname{SeS}\left(s_{i+1}, s_{i}\right)
$$</p>
<p>where $\operatorname{SeS}\left(s_{i+1}, s_{i}\right)$ represents the semantic similarity between $s_{i}$ and $s_{i+1}$. In our implementation, we used BERTScore (Zhang et al., 2019; Devlin et al., 2018) to compute the semantic similarity between steps, which leverages contextual embeddings generated by BERT. For the last step, since there is no subsequent step, we assume $\mathcal{I}\left(s_{n}\right)=0$.</p>
<p>The rationale behind this score is that, when the number of steps is similar, the information flow across the steps tends to be higher in less concise answers because each step relies on a more similar set of details and context from the previous one, increasing the risk of repetitiveness.</p>
<h2>7 Experiments</h2>
<p>This section presents a set of experiments carried out to evaluate the effectiveness of the proposed CCoT approach under classic metrics, as well as</p>
<p>illustrate the benefits of the proposed metrics and scores in highlighting the trade-off between accuracy and computational cost. Specifically, the following research questions are investigated in the next experiments: RQ1 Is the CCoT approach beneficial in terms of efficiency and accuracy compared to classic CoT? RQ2 Are the proposed metrics representative of showing this trade-off?; and RQ3 Are the CCoT answers actually more concise, and to what extent are LLMs capable of controlling the output length based on an explicit prompt request?</p>
<h3>7.1 Experimental setup</h3>
<p>All the experiments have been carried out with the Text Generation Inference (TGI) platform ${ }^{3}$ on 8 NVIDIA A100 GPUs. Specifically, we evaluated large and open source pre-trained LLMs from Hugging Face ${ }^{4}$, such as instruction-tuned models Falcon-40b-instruct and model trained, reinforced by utilizing private data, namely Llama2-70b-chathf (Touvron et al., 2023). Additionally, further experiments on smaller models were conducted to evaluate their capability in handling CCoT, with detailed results provided in Appendix Section B.</p>
<p>The experiments utilized three arithmetic reasoning datasets: GSM8k (Cobbe et al., 2021), SVAMP (Patel et al., 2021), and ASDIV (Miao et al., 2021), commonly used to assess models' mathematical inference and computational reasoning abilities. The GSM8k test set includes over 1.3 k problems out of 8,000. The SVAMP test set contains 300 examples, and the ASDIV test set comprises 1.22 k examples.</p>
<p>For all experiments, the effectiveness of CCoT was compared by assessing the selected LLMs both with and without CoT (base mode).</p>
<h3>7.2 Impact of CCoT on Accuracy and Efficiency</h3>
<p>This experiment was carried out to evaluate the impact of CCoT on computation time and accuracy (RQ1). In particular, the selected LLMs were evaluated on three datasets using plain prompt (base), $C O T$, and $C C O T$ with different length constraints:15, 30, 45, 60, 100. The results are presented in Figure 3 for Llama2-70b (top) and for Falcon-40b (bottom), showing accuracy and generation time in the first and second rows, respectively.</p>
<p><sup id="fnref3:0"><a class="footnote-ref" href="#fn:0">1</a></sup>Considering the results with Llama2-70b, CCoT prompting demonstrates the ability to reduce generation time compared to CoT and, in most cases, achieves a time reduction similar to or better than plain prompting (base). Additionally, it generally improves or minimally impacts accuracy, thereby enhancing the trade-off in both directions. For instance, the average generation time decreases from 30.09 seconds with CoT to a maximum of 23.86 seconds with CCoT on GSM8K with Llama2-70b, achieved with a length constraint of 100, and further reduces with stricter constraints. At the same time, also the accuracy consistently improves, for example, with the GSM8k dataset, the accuracy of Llama2-70b increases from $36 \%$ with CoT to $37 \%$ (with CCoT-30) and 41.77\% (with CCoT-100).</p>
<p>Similar observations can be made for the results with Falcon-40b (bottom part), where the CCoT approach improves the trade-off between efficiency and accuracy across all three datasets. In particular, CCoT achieves better accuracy overall for SVAMP and ASDIV, while significantly reducing generation time. This improvement in terms of accuracy, however, does not occur for the GSM8K dataset, where the sentences are more complex than those in the other two datasets. We believe that such a complexity makes it more challenging for a mediumsized model like Falcon-40b to effectively handle the CCoT constraint. Nonetheless, the accuracy remains higher than the base mode, indicating that the CoT-based approach still provides benefits.</p>
<p>We also acknowledge that different behaviors may arise when dealing with datasets of varying complexity, as the nature of the questions can differ. For instance, CCoT-15 outperforms other CCoT variations because its 15 -word responses potentially align better with the simpler nature of this dataset. We argue that this effect is closely related to the complexity of the questions, which makes the constraint impactful even on accuracy.</p>
<h3>7.3 Analysis of the correct conciseness</h3>
<p>Based on the previous results, CCoT demonstrates clear benefits in balancing accuracy and computational efficiency. To unify these aspects, we introduced new metrics in Section 4 that integrate answer length with correctness. The analysis presented in Tables 1 and 2 for Llama2-70b and Falcon-40b, respectively, highlights how these metrics effectively combine cost and accuracy (RQ2), while also remarking the advantages of CCoT.</p>
<p><img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Figure 3: Accuracy (white plots, the higher the better) and mean generation time (background colored plots, the lower the better) for Llama2-70b (top row) and Falcon-40b (bottom row) on the GSM8K, SVAMP, and ASDIV datasets. The models are evaluated using plain prompts (base), CoT, and CCoT under different len-constraints.</p>
<h3>HCA evaluation</h3>
<p>The <em>Hard-k concise accuracy</em> evaluates the accuracy considering only the correct answers whose length is less than a specified value <em>k</em>. The top parts of Tables 1 and 2 report the value of this performance index across the three datasets, when using the different prompt approaches and for different values of <em>k</em>.</p>
<p>Specifically, for both Llama2-70b and Falcon-40b, the use of CCoT gets better results compared to base and CoT prompts across all values of <em>k</em>. Notably, for lower values of <em>k</em>, CoT prompts exhibit a significant reduction in performance, while this accuracy drop can be mitigated by using CCoT with strict length constraints, such as 15 or 30.</p>
<h3>SCA evaluation</h3>
<p>We also evaluated both models using the <em>Soft Conciseness Accuracy (SCA)</em>, across different <em>k</em> values and <em>α</em>, where <em>α</em> represents a tolerance for accepting answers longer than the desired limit <em>k</em>. This metric is a generalization of the <em>HCA</em>, giving more flexibility in considering correct answers that are larger but still close to the desired length <em>k</em>.</p>
<p>The SCA values computed for Llama2-70b and Falcon-40b on the datasets are reported in center parts of the tables for different values of <em>k</em> and a fixed tolerance value <em>α</em> = 10. For both models, the SCA values in CCoT settings are often comparable to HCA values for high values of <em>k</em>, such as 80 or 100. This is because, as discussed in Sec.7.5, for such lengths, the CCoT prompts are effective at returning outputs below the desired limit, making the tolerance less necessary. Conversely, for smaller <em>k</em> values, such as <em>k</em> = 40, SCA starts exceeding HCA, indicating that some correct answers have a length larger than <em>k</em>. However, for such <em>k</em> values of, using a tolerance <em>α</em> results in more pronounced improvements for CCoT prompts compared to Base and CoT. This means that, although many correct outputs are longer than <em>k</em>, under CCoT the model is still encouraged to constrain them close to <em>k</em>, thus achieving a higher score. This effect is particularly noticeable on Llama2-70b, which is more capable of controlling the length and produce correct outputs than Falcon-40b.</p>
<h3>CCA evaluation</h3>
<p>The <em>Consistent Concise Accuracy</em> measures the capability of a model to generate correct answers whose lengths do not vary significantly, and therefore are consistent with the specified constraint. The <em>CCA</em> requires a third parameter <em>β</em> (in addition to <em>k</em> and <em>α</em>), denoting a tolerance on the output length variability. The bottom parts of the tables report the <em>CCA</em> scores obtained on Llama2-70b and Falcon-40b for <em>α</em> = 10, <em>β</em> = 40, and different values of <em>k</em>, for the various prompting methods. According to these settings, the CCoTs results in a clear improvement.</p>
<table>
<thead>
<tr>
<th></th>
<th>Base:</th>
<th>CoT:</th>
<th>CCoT15</th>
<th>CCoT30</th>
<th>CCoT45</th>
<th>CCoT60</th>
<th>CCoT100</th>
<th>Base:</th>
<th>CoT:</th>
<th>CCoT15</th>
<th>CCoT30</th>
<th>CCoT45</th>
<th>CCoT60</th>
<th>CCoT100</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td>G5M0K - SCA</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>G5M0K - SCA</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>H-:nc</td>
<td>35.0</td>
<td>36.0</td>
<td>31.6</td>
<td>37.1</td>
<td>38.6</td>
<td>39.8</td>
<td>41.8</td>
<td>H-:nc</td>
<td>23.0</td>
<td>31.5</td>
<td>27.1</td>
<td>27.6</td>
<td>28.2</td>
<td>27.4</td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>H-100</td>
<td>29.9</td>
<td>22.9</td>
<td>31.2</td>
<td>35.3</td>
<td>37.5</td>
<td>38.7</td>
<td>38.9</td>
<td>H-100</td>
<td>23.7</td>
<td>29.3</td>
<td>26.7</td>
<td>27.3</td>
<td>27.2</td>
<td>26.8</td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>H-80</td>
<td>22.0</td>
<td>15.4</td>
<td>29.2</td>
<td>31.8</td>
<td>33.1</td>
<td>35.0</td>
<td>33.6</td>
<td>H-80</td>
<td>22.0</td>
<td>26.8</td>
<td>25.8</td>
<td>26.1</td>
<td>25.9</td>
<td>25.2</td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>H-40</td>
<td>4.8</td>
<td>0.8</td>
<td>12.7</td>
<td>10.8</td>
<td>8.0</td>
<td>8.5</td>
<td>8.5</td>
<td>H-40</td>
<td>13.0</td>
<td>10.4</td>
<td>13.4</td>
<td>13.4</td>
<td>12.2</td>
<td>11.8</td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>H-:nc</td>
<td>46.3</td>
<td>58.7</td>
<td>62.0</td>
<td>63.7</td>
<td>62.3</td>
<td>62.3</td>
<td>65.0</td>
<td>H-:nc</td>
<td>46.7</td>
<td>45.3</td>
<td>51.3</td>
<td>49.7</td>
<td>43.7</td>
<td>50.7</td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>H-100</td>
<td>46.3</td>
<td>50.0</td>
<td>59.7</td>
<td>61.0</td>
<td>61.0</td>
<td>59.7</td>
<td>61.7</td>
<td>H-100</td>
<td>46.7</td>
<td>45.3</td>
<td>51.3</td>
<td>49.3</td>
<td>43.0</td>
<td>48.3</td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>H-80</td>
<td>46.3</td>
<td>41.0</td>
<td>56.7</td>
<td>57.7</td>
<td>57.0</td>
<td>54.3</td>
<td>53.7</td>
<td>H-80</td>
<td>46.3</td>
<td>49.7</td>
<td>49.7</td>
<td>47.3</td>
<td>40.7</td>
<td>46.7</td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>H-40</td>
<td>23.3</td>
<td>12.0</td>
<td>44.7</td>
<td>34.0</td>
<td>30.0</td>
<td>30.0</td>
<td>20.0</td>
<td>H-40</td>
<td>38.7</td>
<td>20.3</td>
<td>36.7</td>
<td>36.0</td>
<td>31.7</td>
<td>33.0</td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>G5M0K - SCA ( $\alpha=10$ )</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td>G5M0K - SCA</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>SCA-100</td>
<td>31.4</td>
<td>26.9</td>
<td>31.5</td>
<td>36.3</td>
<td>38.1</td>
<td>39.2</td>
<td>40.1</td>
<td>H-:nc</td>
<td>21.0</td>
<td>31.5</td>
<td>27.1</td>
<td>27.6</td>
<td>28.2</td>
<td>27.4</td>
</tr>
<tr>
<td>SCA-80</td>
<td>25.6</td>
<td>19.0</td>
<td>30.1</td>
<td>33.8</td>
<td>35.3</td>
<td>36.6</td>
<td>35.0</td>
<td>H-100</td>
<td>23.7</td>
<td>29.3</td>
<td>26.7</td>
<td>27.3</td>
<td>27.2</td>
<td>26.8</td>
</tr>
<tr>
<td>SCA-40</td>
<td>8.7</td>
<td>3.3</td>
<td>18.0</td>
<td>18.9</td>
<td>15.4</td>
<td>16.3</td>
<td>11.0</td>
<td>H-40</td>
<td>23.7</td>
<td>29.3</td>
<td>26.7</td>
<td>27.3</td>
<td>27.2</td>
<td>26.8</td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p><img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>Figure 4: Percentage of number of generated answers as per 'no. of reasoning steps' of Llama2-70b (top row) and with Falcon-40b (bottom row) on the GSM8K (a), SVAMP (b), and ASDIV (c) test datasets.</p>
<p>Datasets (Figures 4a and 4b) reveal that the quartile ranges of the answer distributions for CCoT and CoT answers are very similar. Specifically, in both datasets, the interquartile range spans approximately 4 to 12 steps (Q1 to Q3) for SVAMP and around 5 to 14 steps for GSM8K. This suggests comparable step counts across CCoT and CoT answers, within such ranges of reasoning steps.</p>
<p>To evaluate the conciseness of these reasoning steps more effectively, we present redundancy scores in Figure 5. This figure highlights the differences in redundancy between CCoT and CoT answers, categorized by their number of steps. Notably, when focusing on step intervals within the interquartile range (Q1 to Q3, where most answers fall), which are highlighted in grey in the plots, redundancy scores are consistently higher for CoT than for CCoT. This demonstrates that CCoT achieves improved syntactic conciseness compared to CoT, even when the number of steps is similar.</p>
<p>To better quantify the reduction in redundancy achieved by CCoT, we define the <em>Mean Redundancy Reduction (MRR)</em> across single-step redundancies RMS<sub>i</sub> for all reasoning steps <em>i</em>, and the <em>Overall Redundancy Reduction (ORR)</em> as:</p>
<p>MRR = $$\frac{1}{n} \sum_{i=1}^{n} \left( \frac{\text{CoT RMS}_i - \text{CCoT RMS}_i}{\text{CoT RMS}_i} \times 100 \right)$$</p>
<p>ORR = $$\frac{\text{CoT RMS} - \text{CCoT RMS}}{\text{CoT RMS}} \times 100$$</p>
<p>Table 3 presents the average ORR and MRR calculated for the SVAMP and GSM8K datasets, focusing on steps within the interquartile range (Q1 to Q3). The results indicate that CCoT consistently reduces redundancy. For SVAMP, the redundancy reduction ranges from 19.77% to 22.72% (ORR), while for GSM8K, it ranges from 12.64% to 24.74% (ORR).</p>
<p><img alt="img-3.jpeg" src="img-3.jpeg" /></p>
<p>Figure 5: RMS score (lower values indicate better conciseness) of Llama2-70b on the GSM8K (top) and SVAMP (bottom) datasets. The grey area highlights the portion of the answer distribution between the Q1 and Q3 quartiles.</p>
<table>
<thead>
<tr>
<th>Method</th>
<th>Dataset</th>
<th>CCoT15</th>
<th>CCoT30</th>
<th>CCoT45</th>
<th>CCoT60</th>
<th>CCoT100</th>
</tr>
</thead>
<tbody>
<tr>
<td>MRR</td>
<td>SVAMP</td>
<td>20.02</td>
<td>22.50</td>
<td>21.48</td>
<td>22.92</td>
<td>20.14</td>
</tr>
<tr>
<td></td>
<td>GSM8K</td>
<td>13.58</td>
<td>11.65</td>
<td>22.81</td>
<td>23.23</td>
<td>16.33</td>
</tr>
<tr>
<td>ORR</td>
<td>SVAMP</td>
<td>20.22</td>
<td>22.57</td>
<td>21.29</td>
<td>22.72</td>
<td>19.77</td>
</tr>
<tr>
<td></td>
<td>GSM8K</td>
<td>15.34</td>
<td>12.64</td>
<td>24.62</td>
<td>24.74</td>
<td>16.81</td>
</tr>
</tbody>
</table>
<p>Table 3: Mean and Overall Redundancy Reduction for SVAMP and GSM8K Datasets</p>
<p>Information Flow Evaluation. To demonstrate an improved level of conciseness also from a semantic perspective, we analyze the information flow. Specifically, the median number of steps in the answer distributions for CoT and CCoT (Figures 4a and 4b) is approximately 8 for both the SVAMP and GSM8K datasets. Thus, focusing on answers with a total of 8 steps, we present in Tables 4 the Information Flow between consecutive steps $i \rightarrow j$ for Llama2-70b on the GSM8K (top) and SVAMP (bottom) datasets.</p>
<p>In Table 4, CCoT-15 exhibits the largest reductions across all steps, for instance, ranging from $26 \%$ to $41 \%$ compared to CoT scores for GSM8K, while CCoT-100 shows the smallest reductions ( $4 \%$ to $20 \%$ ), preserving more redundant semantic information. Generally, the middle steps show the largest differences, especially for aggressive variations like CCoT-15 and CCoT-45, whereas early and late steps retain more information flow. In summary, a lower information flow indicates that the model effectively retains, step by step, only the logically necessary information required to arrive at a correct answer.</p>
<table>
<thead>
<tr>
<th style="text-align: center;"></th>
<th style="text-align: center;">GSM8K - Llama2-70b</th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">Steps</td>
<td style="text-align: center;">CoT</td>
<td style="text-align: center;">CCoT-15</td>
<td style="text-align: center;">CCoT-30</td>
<td style="text-align: center;">CCoT-45</td>
<td style="text-align: center;">CCoT-60</td>
<td style="text-align: center;">CCoT-100</td>
</tr>
<tr>
<td style="text-align: center;">$1 \rightarrow 2$</td>
<td style="text-align: center;">0.5287</td>
<td style="text-align: center;">0.3417</td>
<td style="text-align: center;">0.35</td>
<td style="text-align: center;">0.49</td>
<td style="text-align: center;">0.49</td>
<td style="text-align: center;">0.43</td>
</tr>
<tr>
<td style="text-align: center;">$2 \rightarrow 3$</td>
<td style="text-align: center;">0.59</td>
<td style="text-align: center;">0.39</td>
<td style="text-align: center;">0.45</td>
<td style="text-align: center;">0.51</td>
<td style="text-align: center;">0.32</td>
<td style="text-align: center;">0.53</td>
</tr>
<tr>
<td style="text-align: center;">$3 \rightarrow 4$</td>
<td style="text-align: center;">0.56</td>
<td style="text-align: center;">0.37</td>
<td style="text-align: center;">0.43</td>
<td style="text-align: center;">0.36</td>
<td style="text-align: center;">0.37</td>
<td style="text-align: center;">0.47</td>
</tr>
<tr>
<td style="text-align: center;">$4 \rightarrow 5$</td>
<td style="text-align: center;">0.55</td>
<td style="text-align: center;">0.38</td>
<td style="text-align: center;">0.41</td>
<td style="text-align: center;">0.56</td>
<td style="text-align: center;">0.36</td>
<td style="text-align: center;">0.46</td>
</tr>
<tr>
<td style="text-align: center;">$5 \rightarrow 6$</td>
<td style="text-align: center;">0.56</td>
<td style="text-align: center;">0.39</td>
<td style="text-align: center;">0.42</td>
<td style="text-align: center;">0.36</td>
<td style="text-align: center;">0.37</td>
<td style="text-align: center;">0.51</td>
</tr>
<tr>
<td style="text-align: center;">$6 \rightarrow 7$</td>
<td style="text-align: center;">0.56</td>
<td style="text-align: center;">0.42</td>
<td style="text-align: center;">0.45</td>
<td style="text-align: center;">0.57</td>
<td style="text-align: center;">0.37</td>
<td style="text-align: center;">0.54</td>
</tr>
<tr>
<td style="text-align: center;">$7 \rightarrow 8$</td>
<td style="text-align: center;">0.52</td>
<td style="text-align: center;">0.42</td>
<td style="text-align: center;">0.47</td>
<td style="text-align: center;">0.57</td>
<td style="text-align: center;">0.36</td>
<td style="text-align: center;">0.50</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">SVAMP - Llama2-70b</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">Steps</td>
<td style="text-align: center;">CoT</td>
<td style="text-align: center;">CCoT-15</td>
<td style="text-align: center;">CCoT-30</td>
<td style="text-align: center;">CCoT-45</td>
<td style="text-align: center;">CCoT-60</td>
<td style="text-align: center;">CCoT-100</td>
</tr>
<tr>
<td style="text-align: center;">$1 \rightarrow 2$</td>
<td style="text-align: center;">0.54</td>
<td style="text-align: center;">0.33</td>
<td style="text-align: center;">0.41</td>
<td style="text-align: center;">0.41</td>
<td style="text-align: center;">0.30</td>
<td style="text-align: center;">0.52</td>
</tr>
<tr>
<td style="text-align: center;">$2 \rightarrow 3$</td>
<td style="text-align: center;">0.52</td>
<td style="text-align: center;">0.35</td>
<td style="text-align: center;">0.47</td>
<td style="text-align: center;">0.43</td>
<td style="text-align: center;">0.35</td>
<td style="text-align: center;">0.35</td>
</tr>
<tr>
<td style="text-align: center;">$3 \rightarrow 4$</td>
<td style="text-align: center;">0.51</td>
<td style="text-align: center;">0.34</td>
<td style="text-align: center;">0.46</td>
<td style="text-align: center;">0.40</td>
<td style="text-align: center;">0.30</td>
<td style="text-align: center;">0.57</td>
</tr>
<tr>
<td style="text-align: center;">$4 \rightarrow 5$</td>
<td style="text-align: center;">0.51</td>
<td style="text-align: center;">0.37</td>
<td style="text-align: center;">0.43</td>
<td style="text-align: center;">0.39</td>
<td style="text-align: center;">0.30</td>
<td style="text-align: center;">0.30</td>
</tr>
<tr>
<td style="text-align: center;">$5 \rightarrow 6$</td>
<td style="text-align: center;">0.51</td>
<td style="text-align: center;">0.38</td>
<td style="text-align: center;">0.41</td>
<td style="text-align: center;">0.44</td>
<td style="text-align: center;">0.36</td>
<td style="text-align: center;">0.57</td>
</tr>
<tr>
<td style="text-align: center;">$6 \rightarrow 7$</td>
<td style="text-align: center;">0.50</td>
<td style="text-align: center;">0.41</td>
<td style="text-align: center;">0.48</td>
<td style="text-align: center;">0.40</td>
<td style="text-align: center;">0.36</td>
<td style="text-align: center;">0.40</td>
</tr>
<tr>
<td style="text-align: center;">$7 \rightarrow 8$</td>
<td style="text-align: center;">0.47</td>
<td style="text-align: center;">0.35</td>
<td style="text-align: center;">0.43</td>
<td style="text-align: center;">0.37</td>
<td style="text-align: center;">0.34</td>
<td style="text-align: center;">0.50</td>
</tr>
</tbody>
</table>
<p>Table 4: Information Flow Mean Values comparison for GSM8K (top) and SVAMP (bottom) across answers with 8 steps. Better information flow indicates lower semantic conciseness between steps (highlighted with blue-like colors in the tables).</p>
<h3>7.5 Ability to control the output length</h3>
<p>The previous experiments looked at how CCoT strategies can affect the accuracy and generation time in the average. However, despite the discussed benefits, it is also crucial to understand how CCoT prompting can effectively limit the output length for each addressed sample (RQ3). This can be useful for better tuning the length parameter in the CCoT prompt or identifying the conditions in which the proposed prompting strategy fails to compress the output. To evaluate the ability of an LLM to produce concise answers in response to a given prompting, we analyzed in Figure 6 the output length under different CCoT length constraints.</p>
<p>Figure 6 shows the statistics on the length of the answers provided by addressed models with the GSM8K test set. Each box plot represents the output lengths between the 5th and the 95th percentiles of all tested samples, the blue line represents the provided CCoT length constraint, the red line denotes the median, while the greed dot the mean. Ideally, a model respecting the given length constraint for each tested sample should have the entire distribution below the blue line.</p>
<p>As depicted in Figure 6, CoT based LLMs tend to produce long answers if not explicitly constrained, significantly impacting the generation time. The imposed length constraint in the CCoT prompt significantly affects the output length, although in practice LLMs are not always able to respect the given limit, especially for smaller values, such as 15,30 , or 40 , which are more challenging.</p>
<p>To summarize, given the nature of the CCoT prompting, it is reasonable to consider a tolerance margin in respecting the requested length. To this end, in the following paragraphs we evaluate the considered models by the metrics proposed in Section 4, which extend the accuracy by also accounting for conciseness.</p>
<h2>8 Final Remark and Conclusion</h2>
<p>Limitations and Future Directions. From the findings revealed by the conducted experiments, a key insight is that for sufficient-scale models, such as Falcon-40b and Llama2-70b, CCoT effectively achieves a better trade-off between accuracy and efficiency. However, we acknowledge that smaller models may struggle to improve this trade-off, often producing incorrect answers when attempting to limit reasoning length. A detailed analysis of these findings is provided in the appendix B. We believe this aligns with the inherent capability of LLMs to exhibit a sense of understanding of output length in their generated responses(Bhargava</p>
<p><img alt="img-4.jpeg" src="img-4.jpeg" /></p>
<p>Figure 6: Distribution of output lengths (y-axis) between the 5th and 95th percentiles for different models and prompting strategies using the GSM8K test set. The top plot shows the results for Falcon-40b, while the bottom plot presents those for Llama2-70b.</p>
<p>et al., 2023). Future investigations should explore addressing this constraint and proposed metrics not only through inference prompts but also as part of a fine-tuning strategy, which could prove beneficial even for smaller-sized models.</p>
<p>Another point involves a deeper analysis of other potential benefits of conciseness in LLMs, beyond a study of the efficiency, which is the main scope of this work. For instance, while most analyses justify conciseness through a reduction in the number of steps (see Section 7.4), a detailed examination of redundancy and information reveals that this behavior also emerges in scenarios where CCoT and CoT have a similar number of steps. We believe that these metrics can be further leveraged to explore additional benefits of concise generation, such as mitigating hallucinations or reducing error propagation. For instance, a lower Information Flow score suggests that the model retains only the logically necessary information required to reach a correct answer, step by step, while excluding superfluous details. This approach could help reduce the risk of error propagation by filtering out unnecessary or irrelevant information at each step (Li et al., 2024).</p>
<p><strong>Conclusion.</strong> This work explored the importance of conciseness in answers generated by LLMs for text-to-text tasks, introducing three new metrics to evaluate both conciseness and correctness based on user-defined parameters. Additionally, it proposed a prompt engineering approach, Constrained Chain-of-Thought, to get a better control of output length of generated answer, thus impacting the inference time. Furthermore, it deepened the analysis of conciseness by evaluating its significance within the generated reasoning steps, particularly in terms of redundancy and information flow.</p>
<p>Experimental results demonstrated how the proposed Constrained CoT (CCoT) effectively highlights the trade-off (RO1) and presents a unified perspective through new metrics (RO2), particularly when applied to large LLMs such as Falcon-40b and Llama2-70b. Furthermore, we provide an in-depth analysis of the concept of conciseness, the capability to control output length, and the importance of information within the generated reasoning steps (RO3).</p>
<p>In conclusion, this work emphasizes the need to focus on the conciseness of LLMs by proposing novel performance metrics that evaluate both the correctness of the output and its length. Additionally, the proposed CCoT prompting offers a simple yet effective strategy to enhance conciseness, potentially paving the way for new research directions to make LLMs more predictable and efficient.</p>
<h2>References</h2>
<p>Ebtesam Almazrouei, Hamza Alobeidli, Abdulaziz Alshamsi, Alessandro Cappelli, Ruxandra Cojocaru, Mérouane Debbah, Étienne Goffinet, Daniel Hesslow, Julien Launay, Quentin Malartic, et al. 2023. The falcon series of open language models. arXiv preprint arXiv:2311.16867.</p>
<p>Amos Azaria and Tom Mitchell. 2023. The internal state of an llm knows when its lying. arXiv preprint arXiv:2304.13734.</p>
<p>Aman Bhargava, Cameron Witkowski, Manav Shah, and Matt Thomson. 2023. What's the magic word? a control theory of llm prompting. arXiv preprint arXiv:2310.04444.</p>
<p>Bin Bi, Chenliang Li, Chen Wu, Ming Yan, Wei Wang, Songfang Huang, Fei Huang, and Luo Si. 2020. Palm: Pre-training an autoencoding\&amp;autoregressive language model for context-conditioned generation. arXiv preprint arXiv:2004.07159.</p>
<p>Cheng-Han Chiang and Hung-yi Lee. 2024. Over-reasoning and redundant calculation of large language models. arXiv preprint arXiv:2401.11467.</p>
<p>Wei-Lin Chiang, Zhuohan Li, Zi Lin, Ying Sheng, Zhanghao Wu, Hao Zhang, Lianmin Zheng, Siyuan Zhuang, Yonghao Zhuang, Joseph E Gonzalez, et al. 2023. Vicuna: An open-source chatbot impressing gpt-4 with $90 \%$ * chatgpt quality. See https://vicuna. lmsys. org (accessed 14 April 2023).</p>
<p>Peter Clark, Isaac Cowhey, Oren Etzioni, Tushar Khot, Ashish Sabharwal, Carissa Schoenick, and Oyvind Tafjord. 2018. Think you have solved question answering? try arc, the ai2 reasoning challenge. arXiv preprint arXiv:1803.05457.</p>
<p>Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, et al. 2021. Training verifiers to solve math word problems. arXiv preprint arXiv:2110.14168.</p>
<p>Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2018. Bert: Pre-training of deep bidirectional transformers for language understanding. arXiv preprint arXiv:1810.04805.</p>
<p>Free Dolly. 2023. Introducing the world's first truly open instruction-tuned llm. databricks. com.</p>
<p>Yao Fu, Litu Ou, Mingyu Chen, Yuhao Wan, Hao Peng, and Tushar Khot. 2023. Chain-of-thought hub: A continuous effort to measure large language models' reasoning performance. arXiv preprint arXiv:2305.17306.</p>
<p>Yao Fu, Hao Peng, Ashish Sabharwal, Peter Clark, and Tushar Khot. 2022. Complexity-based prompting for multi-step reasoning. In The Eleventh International Conference on Learning Representations.</p>
<p>Xinyang Geng, Arnav Gudibande, Hao Liu, Eric Wallace, Pieter Abbeel, Sergey Levine, and Dawn Song. 2023. Koala: A dialogue model for academic research. Blog post, April, 1.</p>
<p>Shibo Hao, Sainbayar Sukhbaatar, DiJia Su, Xian Li, Zhiting Hu, Jason Weston, and Yuandong Tian. 2024. Training large language models to reason in a continuous latent space. arXiv preprint arXiv:2412.06769.</p>
<p>Zhengbao Jiang, Frank F Xu, Jun Araki, and Graham Neubig. 2020. How can we know what language models know? Transactions of the Association for Computational Linguistics, 8:423438.</p>
<p>Saurav Kadavath, Tom Conerly, Amanda Askell, Tom Henighan, Dawn Drain, Ethan Perez, Nicholas Schiefer, Zac Hatfield-Dodds, Nova DasSarma, Eli Tran-Johnson, et al. 2022. Language models (mostly) know what they know. arXiv preprint arXiv:2207.05221.</p>
<p>Jared Kaplan, Sam McCandlish, Tom Henighan, Tom B Brown, Benjamin Chess, Rewon Child, Scott Gray, Alec Radford, Jeffrey Wu, and Dario Amodei. 2020. Scaling laws for neural language models. arXiv preprint arXiv:2001.08361.</p>
<p>Darioush Kevian, Usman Syed, Xingang Guo, Aaron Havens, Geir Dullerud, Peter Seiler, Lianhui Qin, and Bin Hu. 2024. Capabilities of large language models in control engineering: A benchmark study on gpt-4, claude 3 opus, and gemini 1.0 ultra. arXiv preprint arXiv:2404.03647.</p>
<p>Daniel Khashabi, Amos Ng, Tushar Khot, Ashish Sabharwal, Hannaneh Hajishirzi, and Chris</p>
<p>Callison-Burch. 2021. Gooaq: Open question answering with diverse answer types. arXiv preprint arXiv:2104.08727.</p>
<p>Chenliang Li, Bin Bi, Ming Yan, Wei Wang, and Songfang Huang. 2021. Addressing semantic drift in generative question answering with auxiliary extraction. In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 2: Short Papers), pages 942-947.</p>
<p>Ruosen Li, Ziming Luo, and Xinya Du. 2024. Finegrained hallucination detection and mitigation in language model mathematical reasoning. arXiv preprint arXiv:2410.06304.</p>
<p>Chin-Yew Lin. 2004. Rouge: A package for automatic evaluation of summaries. In Text summarization branches out, pages 74-81.</p>
<p>Stephanie Lin, Jacob Hilton, and Owain Evans. 2021. Truthfulqa: Measuring how models mimic human falsehoods. arXiv preprint arXiv:2109.07958.</p>
<p>Yizhu Liu, Zhiyi Luo, and Kenny Zhu. 2018. Controlling length in abstractive summarization using a convolutional neural network. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages $4110-4119$.</p>
<p>Leo S Lo. 2023. The clear path: A framework for enhancing information literacy through prompt engineering. The Journal of Academic Librarianship, 49(4):102720.</p>
<p>Ggaliwango Marvin, Nakayiza Hellen, Daudi Jjingo, and Joyce Nakatumba-Nabende. 2023. Prompt engineering in large language models. In International Conference on Data Intelligence and Cognitive Informatics, pages 387-402. Springer.</p>
<p>Shen-Yun Miao, Chao-Chun Liang, and Keh-Yih Su. 2021. A diverse corpus for evaluating and developing english math word problem solvers. arXiv preprint arXiv:2106.15772.</p>
<p>Arkil Patel, Satwik Bhattamishra, and Navin Goyal. 2021. Are nlp models really able to solve simple math word problems? arXiv preprint arXiv:2103.07191.</p>
<p>Guilherme Penedo, Quentin Malartic, Daniel Hesslow, Ruxandra Cojocaru, Alessandro Cappelli, Hamza Alobeidli, Baptiste Pannier, Ebtesam Almazrouei, and Julien Launay. 2023. The refinedweb dataset for falcon llm: outperforming curated corpora with web data, and web data only. arXiv preprint arXiv:2306.01116.</p>
<p>Guanghui Qin and Jason Eisner. 2021. Learning how to ask: Querying lms with mixtures of soft prompts. arXiv preprint arXiv:2104.06599.</p>
<p>Haoran Qiu, Weichao Mao, Archit Patke, Shengkun Cui, Saurabh Jha, Chen Wang, Hubertus Franke, Zbigniew T Kalbarczyk, Tamer Başar, and Ravishankar K Iyer. 2024. Efficient interactive llm serving with proxy modelbased sequence length prediction. arXiv preprint arXiv:2404.08509.</p>
<p>John W Ratcliff, David E Metzener, et al. 1988. Pattern matching: The gestalt approach. Dr. Dobb's Journal, 13(7):46.</p>
<p>Laria Reynolds and Kyle McDonell. 2021. Prompt programming for large language models: Beyond the few-shot paradigm. In Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems, pages 1-7.</p>
<p>Shivanshu Shekhar, Tanishq Dubey, Koyel Mukherjee, Apoorv Saxena, Atharv Tyagi, and Nishanth Kotla. 2024. Towards optimizing the costs of llm usage. arXiv preprint arXiv:2402.01742.</p>
<p>Freda Shi, Xinyun Chen, Kanishka Misra, Nathan Scales, David Dohan, Ed H Chi, Nathanael Schärli, and Denny Zhou. 2023. Large language models can be easily distracted by irrelevant context. In International Conference on Machine Learning, pages 31210-31227. PMLR.</p>
<p>William M Stallings and Gerald M Gillmore. 1971. A note on "accuracy" and "precision". Journal of Educational Measurement, 8(2):127-129.</p>
<p>Hendrik Strobelt, Albert Webson, Victor Sanh, Benjamin Hoover, Johanna Beyer, Hanspeter Pfister, and Alexander M Rush. 2022. Interactive and visual prompt engineering for ad-hoc task adaptation with large language models. IEEE transactions on visualization and computer graphics, 29(1):1146-1156.</p>
<p>Sho Takase and Naoaki Okazaki. 2019. Positional encoding to control output sequence length. arXiv preprint arXiv:1904.07418.</p>
<p>Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann Dubois, Xuechen Li, Carlos Guestrin, Percy Liang, and Tatsunori B Hashimoto. 2023. Stanford alpaca: An instruction-following llama model.</p>
<p>Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, et al. 2023. Llama: Open and efficient foundation language models. arXiv preprint arXiv:2302.13971.</p>
<p>Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. Advances in neural information processing systems, 30.</p>
<p>Junlin Wang, Siddhartha Jain, Dejiao Zhang, Baishakhi Ray, Varun Kumar, and Ben Athiwaratkun. 2024a. Reasoning in token economies: Budget-aware evaluation of llm reasoning strategies. arXiv preprint arXiv:2406.06461.</p>
<p>Xindi Wang, Mahsa Salmani, Parsa Omidi, Xiangyu Ren, Mehdi Rezagholizadeh, and Armaghan Eshaghi. 2024b. Beyond the limits: A survey of techniques to extend the context length in large language models. arXiv preprint arXiv:2402.02244.</p>
<p>Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc V Le, Denny Zhou, et al. 2022. Chain-of-thought prompting elicits reasoning in large language models. Advances in Neural Information Processing Systems, 35:24824-24837.</p>
<p>Tianyi Zhang, Varsha Kishore, Felix Wu, Kilian Q. Weinberger, and Yoav Artzi. 2019. Bertscore: Evaluating text generation with BERT. CoRR, abs/1904.09675.</p>
<p>Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao Zhuang, Zi Lin, Zhuohan Li, Dacheng Li, Eric Xing, et al. 2024a. Judging llm-as-a-judge with mt-bench and chatbot arena. Advances in Neural Information Processing Systems, 36.</p>
<p>Zangwei Zheng, Xiaozhe Ren, Fuzhao Xue, Yang Luo, Xin Jiang, and Yang You. 2024b. Response length perception and sequence scheduling: An llm-empowered llm inference pipeline. Advances in Neural Information Processing Systems, 36.</p>
<p>Kaijie Zhu, Jindong Wang, Jiaheng Zhou, Zichen Wang, Hao Chen, Yidong Wang, Linyi Yang, Wei Ye, Neil Zhenqiang Gong, Yue Zhang, et al. 2023. Promptbench: Towards evaluating the robustness of large language models on adversarial prompts. arXiv preprint arXiv:2306.04528.</p>
<p>Appendix of the paper "Concise Thoughts: Impact of Output Length on
LLM Reasoning and Cost"</p>
<p>Appendices</p>
<p>A Additional analysis of the conciseness</p>
<p>A.1 Analysis of the RMS</p>
<p>Figures 7,8, and 9 present the RMS values for
Llama2-70b and Falcon-40b across the three
datasets analyzed in the paper. These results specif-
ically highlight scenarios where the model success-
fully answers questions with the CCoT prompt but
not with the CoT prompt. The purpose of these
plots is to check whether the behavior of CCoT
in terms of redundancy is coherent with that ob-
served in Section 7.4. In addition, these plots help
to investigate the potential correlation between the
accuracy of the model's responses and the reduc-
tion in redundancy. The plots in the left column
correspond to Llama2-70b, while those in the right
column correspond to Falcon-40b. In each plot, we
also highlight the interval between Q1 and Q3 for
CoT and CCoT answers, along with the overlap
range of these intervals.</p>
<p>As we can see from these plots, the redundancy
behavior for CCoT and CoT closely resembles the
trend observed in Section 7.4 calculated across all
questions. This suggests that the reduction in re-
dundancy (for Llama2-70b) and number of steps
(for Falcon-40b) achieved by CCoT is consistent
and provides more accurate and concise answers
compared to CoT. In fact, the reduction in terms of
redundancy or number of steps in the cases where
CoT fails indicates that the CCoT prompt provides
better guidance to the model, even in complex or
ambiguous scenarios where CoT tends to struggle.</p>
<p>A.2 Information Flow</p>
<p>Since the main paper examined the information
flow in answers with 8 steps based on the CCoT
answer distribution, we further demonstrate the
effectiveness of CCoT by analyzing step-by-step
information flow for another median step count,
specifically 9 steps. Tables 5 and 6 present the
scores for Llama2-70b on GSM8K and SVAMP,
respectively.</p>
<p>In Table 5, for GSM8K, all steps show a reduced
repetition of semantic information for CCoT, ex-
<img alt="img-5.jpeg" src="img-5.jpeg" /></p>
<p>Figure 7: RMS mean score comparison between CCoT-
true and CoT-false on the GSM8K dataset, with Llama2-
70b (left side) and Falcon-40b (right side). The over-
lapped highlighted area illustrates the answer distribu-
tion between Q1 and Q3.</p>
<p>cept for CCoT-45 at the initial step and CCoT-100
at the final step. A different behavior is observed
at the final step for all CCoTs in the other dataset
(SVAMP), as shown in Table 6, although semantic
information is retained throughout the steps.</p>
<p>We also calculated the semantic information flow
for answers with 8 and 9 steps, based on the median
step distribution of CCoT answers generated by
Falcon-40b. The results are presented in Tables 7
and 8 for the GSM8K and SVAMP datasets, respec-
tively. Interestingly, Falcon-40b exhibits contrast-
ing behavior in terms of information scores, often
displaying higher values, which suggest greater rep-
etition of semantic information across steps. This
behavior is likely influenced by its medium-scale
architecture and the nature of its training dataset,
which may not be well-suited for handling con-
strained reasoning tasks.</p>
<p>However, as also highlighted in the main text of
the paper, it is important to note that Falcon-40b</p>
<p><img alt="img-6.jpeg" src="img-6.jpeg" /></p>
<p>Figure 8: RMS mean score comparison between CCoT-true and CoT-false on the SVAMP dataset, with Llama2-70b (left side) and Falcon-40b (right side). The overlapped highlighted area illustrates the answer distribution between Q1 and Q3.</p>
<table>
<thead>
<tr>
<th>Steps</th>
<th>CoT</th>
<th>CCoT-15</th>
<th>CCoT-30</th>
<th>CCoT-45</th>
<th>CCoT-60</th>
<th>CCoT-100</th>
</tr>
</thead>
<tbody>
<tr>
<td>1 -&gt; 2</td>
<td>0.48</td>
<td>0.28</td>
<td>0.32</td>
<td>0.45</td>
<td>0.49</td>
<td>0.33</td>
</tr>
<tr>
<td>2 -&gt; 3</td>
<td>0.54</td>
<td>0.38</td>
<td>0.40</td>
<td>0.35</td>
<td>0.53</td>
<td>0.36</td>
</tr>
<tr>
<td>3 -&gt; 4</td>
<td>0.49</td>
<td>0.36</td>
<td>0.37</td>
<td>0.40</td>
<td>0.38</td>
<td>0.35</td>
</tr>
<tr>
<td>4 -&gt; 5</td>
<td>0.49</td>
<td>0.35</td>
<td>0.36</td>
<td>0.38</td>
<td>0.57</td>
<td>0.34</td>
</tr>
<tr>
<td>5 -&gt; 6</td>
<td>0.51</td>
<td>0.38</td>
<td>0.40</td>
<td>0.39</td>
<td>0.38</td>
<td>0.36</td>
</tr>
<tr>
<td>6 -&gt; 7</td>
<td>0.49</td>
<td>0.37</td>
<td>0.37</td>
<td>0.39</td>
<td>0.36</td>
<td>0.36</td>
</tr>
<tr>
<td>7 -&gt; 8</td>
<td>0.50</td>
<td>0.36</td>
<td>0.37</td>
<td>0.43</td>
<td>0.40</td>
<td>0.35</td>
</tr>
<tr>
<td>8 -&gt; 9</td>
<td>0.55</td>
<td>0.50</td>
<td>0.54</td>
<td>0.45</td>
<td>0.51</td>
<td>0.61</td>
</tr>
</tbody>
</table>
<p>Table 5: GSM8K Llama2-70b Information Flow Mean Values comparison across answers with 9 steps</p>
<p>achieves improved conciseness due to the significantly lower average number of steps it produces. This allows for quicker reasoning decisions in many samples. This observation clarifies that the analysis reported in Tables 7 and 8 is inherently unbalanced, as the number of Falcon-40b answers with 8 and 9 steps under CCoT is smaller than those under CoT. Please note that in Table 8, there are no information scores for CCoT-15 because Falcon-40b does not generate answers with 8 or 9 steps when constrained to a reasoning length of up to 15 tokens.</p>
<h3>B Testing CCoT with smaller LLMs.</h3>
<p>In this experiment, we investigate the capability of larger set of LLMs to handle the CCoT prompting. Specifically, in Figure 10, we present an evaluation conducted on five LLMs, including small</p>
<p><img alt="img-7.jpeg" src="img-7.jpeg" /></p>
<p>Figure 9: RMS mean score comparison between CCoT-true and CoT-false on the ASDIV dataset, with Llama2-70b shown (left side) and Falcon-40b (right side). The overlapped highlighted area illustrates the answer distribution between Q1 and Q3.</p>
<table>
<thead>
<tr>
<th>Steps</th>
<th>CoT</th>
<th>CCoT-15</th>
<th>CCoT-30</th>
<th>CCoT-45</th>
<th>CCoT-60</th>
<th>CCoT-100</th>
</tr>
</thead>
<tbody>
<tr>
<td>1 -&gt; 2</td>
<td>0.46</td>
<td>0.29</td>
<td>0.32</td>
<td>0.36</td>
<td>0.29</td>
<td>0.32</td>
</tr>
<tr>
<td>2 -&gt; 3</td>
<td>0.49</td>
<td>0.31</td>
<td>0.36</td>
<td>0.33</td>
<td>0.34</td>
<td>0.34</td>
</tr>
<tr>
<td>3 -&gt; 4</td>
<td>0.46</td>
<td>0.33</td>
<td>0.34</td>
<td>0.32</td>
<td>0.30</td>
<td>0.32</td>
</tr>
<tr>
<td>4 -&gt; 5</td>
<td>0.45</td>
<td>0.32</td>
<td>0.34</td>
<td>0.32</td>
<td>0.29</td>
<td>0.31</td>
</tr>
<tr>
<td>5 -&gt; 6</td>
<td>0.49</td>
<td>0.32</td>
<td>0.39</td>
<td>0.37</td>
<td>0.36</td>
<td>0.34</td>
</tr>
<tr>
<td>6 -&gt; 7</td>
<td>0.51</td>
<td>0.31</td>
<td>0.37</td>
<td>0.41</td>
<td>0.34</td>
<td>0.33</td>
</tr>
<tr>
<td>7 -&gt; 8</td>
<td>0.47</td>
<td>0.32</td>
<td>0.38</td>
<td>0.38</td>
<td>0.37</td>
<td>0.39</td>
</tr>
<tr>
<td>8 -&gt; 9</td>
<td>0.49</td>
<td>0.54</td>
<td>0.63</td>
<td>0.68</td>
<td>0.62</td>
<td>0.70</td>
</tr>
</tbody>
</table>
<p>Table 6: SVAMP Llama70b Information Flow Mean Values comparison across answers with 9 steps</p>
<p>and medium-sized models such as Falcon-7b (Almazrouei et al., 2023) and LLama2-7b (Touvron et al., 2023). The results acknowledge some difficulties in addressing the CCoT prompt when considering smaller models.</p>
<p>We believe that such different outcomes of CCoT prompting can be attributed to various factors, such as the training data, the approach used to train the model, the model size, and the technique adopted during training. For instance, Llama2-70b is an autoregressive large-scale language model fine-tuned with human feedback, trained on a diverse combination of generic and open-source datasets. Such technical measures contribute to making CCoT effective in controlling the output length while improving the model accuracy. The Falcon-40b model, in contrast, is smaller than Llama2-70b and trained</p>
<p>Table 7: GSM8K Falcon-40b Information Flow Mean Values Comparison</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Steps</th>
<th style="text-align: center;">CoT</th>
<th style="text-align: center;">CCoT-15</th>
<th style="text-align: center;">CCoT-30</th>
<th style="text-align: center;">CCoT-45</th>
<th style="text-align: center;">CCoT-60</th>
<th style="text-align: center;">CCoT-100</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">$1 \Rightarrow 2$</td>
<td style="text-align: center;">0.58</td>
<td style="text-align: center;">0.65</td>
<td style="text-align: center;">0.64</td>
<td style="text-align: center;">0.65</td>
<td style="text-align: center;">0.61</td>
<td style="text-align: center;">0.59</td>
</tr>
<tr>
<td style="text-align: center;">$2 \Rightarrow 3$</td>
<td style="text-align: center;">0.62</td>
<td style="text-align: center;">0.69</td>
<td style="text-align: center;">0.68</td>
<td style="text-align: center;">0.70</td>
<td style="text-align: center;">0.68</td>
<td style="text-align: center;">0.64</td>
</tr>
<tr>
<td style="text-align: center;">$3 \Rightarrow 4$</td>
<td style="text-align: center;">0.60</td>
<td style="text-align: center;">0.74</td>
<td style="text-align: center;">0.76</td>
<td style="text-align: center;">0.74</td>
<td style="text-align: center;">0.68</td>
<td style="text-align: center;">0.63</td>
</tr>
<tr>
<td style="text-align: center;">$4 \Rightarrow 5$</td>
<td style="text-align: center;">0.59</td>
<td style="text-align: center;">0.66</td>
<td style="text-align: center;">0.63</td>
<td style="text-align: center;">0.64</td>
<td style="text-align: center;">0.64</td>
<td style="text-align: center;">0.66</td>
</tr>
<tr>
<td style="text-align: center;">$5 \Rightarrow 6$</td>
<td style="text-align: center;">0.61</td>
<td style="text-align: center;">0.62</td>
<td style="text-align: center;">0.72</td>
<td style="text-align: center;">0.67</td>
<td style="text-align: center;">0.66</td>
<td style="text-align: center;">0.64</td>
</tr>
<tr>
<td style="text-align: center;">$6 \Rightarrow 7$</td>
<td style="text-align: center;">0.60</td>
<td style="text-align: center;">0.61</td>
<td style="text-align: center;">0.66</td>
<td style="text-align: center;">0.68</td>
<td style="text-align: center;">0.68</td>
<td style="text-align: center;">0.62</td>
</tr>
<tr>
<td style="text-align: center;">$7 \Rightarrow 8$</td>
<td style="text-align: center;">0.59</td>
<td style="text-align: center;">0.50</td>
<td style="text-align: center;">0.55</td>
<td style="text-align: center;">0.54</td>
<td style="text-align: center;">0.56</td>
<td style="text-align: center;">0.59</td>
</tr>
</tbody>
</table>
<p>(a) Answers with 8 steps</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Steps</th>
<th style="text-align: center;">CoT</th>
<th style="text-align: center;">CCoT-15</th>
<th style="text-align: center;">CCoT-30</th>
<th style="text-align: center;">CCoT-45</th>
<th style="text-align: center;">CCoT-60</th>
<th style="text-align: center;">CCoT-100</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">$1 \Rightarrow 2$</td>
<td style="text-align: center;">0.55</td>
<td style="text-align: center;">0.62</td>
<td style="text-align: center;">0.69</td>
<td style="text-align: center;">0.61</td>
<td style="text-align: center;">0.58</td>
<td style="text-align: center;">0.67</td>
</tr>
<tr>
<td style="text-align: center;">$2 \Rightarrow 3$</td>
<td style="text-align: center;">0.58</td>
<td style="text-align: center;">0.62</td>
<td style="text-align: center;">0.65</td>
<td style="text-align: center;">0.65</td>
<td style="text-align: center;">0.57</td>
<td style="text-align: center;">0.73</td>
</tr>
<tr>
<td style="text-align: center;">$3 \Rightarrow 4$</td>
<td style="text-align: center;">0.54</td>
<td style="text-align: center;">0.62</td>
<td style="text-align: center;">0.67</td>
<td style="text-align: center;">0.63</td>
<td style="text-align: center;">0.61</td>
<td style="text-align: center;">0.73</td>
</tr>
<tr>
<td style="text-align: center;">$4 \Rightarrow 5$</td>
<td style="text-align: center;">0.54</td>
<td style="text-align: center;">0.62</td>
<td style="text-align: center;">0.64</td>
<td style="text-align: center;">0.46</td>
<td style="text-align: center;">0.55</td>
<td style="text-align: center;">0.63</td>
</tr>
<tr>
<td style="text-align: center;">$5 \Rightarrow 6$</td>
<td style="text-align: center;">0.54</td>
<td style="text-align: center;">0.69</td>
<td style="text-align: center;">0.74</td>
<td style="text-align: center;">0.67</td>
<td style="text-align: center;">0.64</td>
<td style="text-align: center;">0.76</td>
</tr>
<tr>
<td style="text-align: center;">$6 \Rightarrow 7$</td>
<td style="text-align: center;">0.55</td>
<td style="text-align: center;">0.70</td>
<td style="text-align: center;">0.59</td>
<td style="text-align: center;">0.48</td>
<td style="text-align: center;">0.56</td>
<td style="text-align: center;">0.66</td>
</tr>
<tr>
<td style="text-align: center;">$7 \Rightarrow 8$</td>
<td style="text-align: center;">0.55</td>
<td style="text-align: center;">0.65</td>
<td style="text-align: center;">0.77</td>
<td style="text-align: center;">0.68</td>
<td style="text-align: center;">0.65</td>
<td style="text-align: center;">0.75</td>
</tr>
<tr>
<td style="text-align: center;">$8 \Rightarrow 9$</td>
<td style="text-align: center;">0.59</td>
<td style="text-align: center;">0.52</td>
<td style="text-align: center;">0.60</td>
<td style="text-align: center;">0.46</td>
<td style="text-align: center;">0.48</td>
<td style="text-align: center;">0.68</td>
</tr>
</tbody>
</table>
<p>(b) Answers with 9 steps</p>
<p>Table 8: SVAMP Falcon-40b Information Flow Mean Values Comparison</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Steps</th>
<th style="text-align: center;">CoT</th>
<th style="text-align: center;">CCoT-15</th>
<th style="text-align: center;">CCoT-30</th>
<th style="text-align: center;">CCoT-45</th>
<th style="text-align: center;">CCoT-60</th>
<th style="text-align: center;">CCoT-100</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">$1 \Rightarrow 2$</td>
<td style="text-align: center;">0.26</td>
<td style="text-align: center;">0.60</td>
<td style="text-align: center;">0.58</td>
<td style="text-align: center;">0.55</td>
<td style="text-align: center;">0.58</td>
<td style="text-align: center;">0.63</td>
</tr>
<tr>
<td style="text-align: center;">$2 \Rightarrow 3$</td>
<td style="text-align: center;">0.68</td>
<td style="text-align: center;">0.58</td>
<td style="text-align: center;">0.53</td>
<td style="text-align: center;">0.53</td>
<td style="text-align: center;">0.60</td>
<td style="text-align: center;">0.52</td>
</tr>
<tr>
<td style="text-align: center;">$3 \Rightarrow 4$</td>
<td style="text-align: center;">0.60</td>
<td style="text-align: center;">0.68</td>
<td style="text-align: center;">0.52</td>
<td style="text-align: center;">0.60</td>
<td style="text-align: center;">0.49</td>
<td style="text-align: center;">0.54</td>
</tr>
<tr>
<td style="text-align: center;">$4 \Rightarrow 5$</td>
<td style="text-align: center;">0.61</td>
<td style="text-align: center;">0.56</td>
<td style="text-align: center;">0.51</td>
<td style="text-align: center;">0.56</td>
<td style="text-align: center;">0.63</td>
<td style="text-align: center;">0.60</td>
</tr>
<tr>
<td style="text-align: center;">$5 \Rightarrow 6$</td>
<td style="text-align: center;">0.63</td>
<td style="text-align: center;">0.51</td>
<td style="text-align: center;">0.65</td>
<td style="text-align: center;">0.55</td>
<td style="text-align: center;">0.68</td>
<td style="text-align: center;">0.64</td>
</tr>
<tr>
<td style="text-align: center;">$6 \Rightarrow 7$</td>
<td style="text-align: center;">0.63</td>
<td style="text-align: center;">0.95</td>
<td style="text-align: center;">0.76</td>
<td style="text-align: center;">0.52</td>
<td style="text-align: center;">0.64</td>
<td style="text-align: center;">0.62</td>
</tr>
<tr>
<td style="text-align: center;">$7 \Rightarrow 8$</td>
<td style="text-align: center;">0.55</td>
<td style="text-align: center;">0.73</td>
<td style="text-align: center;">0.57</td>
<td style="text-align: center;">0.60</td>
<td style="text-align: center;">0.56</td>
<td style="text-align: center;">0.65</td>
</tr>
</tbody>
</table>
<p>(a) Answers with 8 Steps</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Steps</th>
<th style="text-align: center;">CoT</th>
<th style="text-align: center;">CCoT-15</th>
<th style="text-align: center;">CCoT-30</th>
<th style="text-align: center;">CCoT-45</th>
<th style="text-align: center;">CCoT-60</th>
<th style="text-align: center;">CCoT-100</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">$1 \Rightarrow 2$</td>
<td style="text-align: center;">0.26</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">0.64</td>
<td style="text-align: center;">0.62</td>
<td style="text-align: center;">0.56</td>
<td style="text-align: center;">0.61</td>
</tr>
<tr>
<td style="text-align: center;">$2 \Rightarrow 3$</td>
<td style="text-align: center;">0.65</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">0.59</td>
<td style="text-align: center;">0.55</td>
<td style="text-align: center;">0.53</td>
<td style="text-align: center;">0.66</td>
</tr>
<tr>
<td style="text-align: center;">$3 \Rightarrow 4$</td>
<td style="text-align: center;">0.57</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">0.66</td>
<td style="text-align: center;">0.52</td>
<td style="text-align: center;">0.62</td>
<td style="text-align: center;">0.63</td>
</tr>
<tr>
<td style="text-align: center;">$4 \Rightarrow 5$</td>
<td style="text-align: center;">0.58</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">0.74</td>
<td style="text-align: center;">0.67</td>
<td style="text-align: center;">0.55</td>
<td style="text-align: center;">0.54</td>
</tr>
<tr>
<td style="text-align: center;">$5 \Rightarrow 6$</td>
<td style="text-align: center;">0.60</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">0.67</td>
<td style="text-align: center;">0.47</td>
<td style="text-align: center;">0.67</td>
<td style="text-align: center;">0.61</td>
</tr>
<tr>
<td style="text-align: center;">$6 \Rightarrow 7$</td>
<td style="text-align: center;">0.57</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">0.86</td>
<td style="text-align: center;">0.47</td>
<td style="text-align: center;">0.75</td>
<td style="text-align: center;">0.64</td>
</tr>
<tr>
<td style="text-align: center;">$7 \Rightarrow 8$</td>
<td style="text-align: center;">0.63</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">0.77</td>
<td style="text-align: center;">0.69</td>
<td style="text-align: center;">0.63</td>
<td style="text-align: center;">0.62</td>
</tr>
<tr>
<td style="text-align: center;">$8 \Rightarrow 9$</td>
<td style="text-align: center;">0.54</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">0.61</td>
<td style="text-align: center;">0.56</td>
<td style="text-align: center;">0.57</td>
<td style="text-align: center;">0.43</td>
</tr>
</tbody>
</table>
<p>(b) Answers with 9 Steps
on a different dataset (the dedicated RefinedWeb data (Penedo et al., 2023)). While CCoT does not improve the accuracy of the model with respect to CoT, it still performs better than the base plain prompting, offering a trade-off by reducing generation times compared to CoT. Vicuna-13b also provides competitive results across different prompts, as it is a fine-tuned version of Llama2 and smaller than the previous Llama2-70b.</p>
<p>Conversely, small-scale LLMs, such as Falcon7 b and Llama2-7b, are not capable of properly handling the constrained prompting conditions in CCoT, resulting in higher generation times (as shown for Falcon-7b with large length values in CCoT ) or incorrect answers with short CCoT values in Llama2-7b. This suggests that model size and training strategies severely impact the effectiveness of CCoT.</p>
<p>Considering the observations presented here, we believe that future directions could face potential training and fine-tuning strategy to integrate a better awareness and capability fo thandlign lengths
<img alt="img-8.jpeg" src="img-8.jpeg" /></p>
<p>Figure 10: Generation time (a) and accuracy (b) of five LLMs (Llama2-7b, Llama2-70b, Falcon-7b, Falcon40b, and Vicuna-13b) on the GSM8K test dataset. Each model is evaluated using plain promt (base), CoT, and CCoT with different length constraints.</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>${ }^{3}$ https://huggingface.co/docs/ text-generation-inference
${ }^{4}$ https://huggingface.co/blog/os-llms&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref3:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>