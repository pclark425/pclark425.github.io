<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-8679 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-8679</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-8679</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-156.html">extraction-schema-156</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of representational formats of conceptual knowledge at a functional (not neural) level, including descriptions of the format, supporting or challenging evidence, cognitive tasks or phenomena used as evidence, comparisons between formats, and theoretical claims or implications.</div>
                <p><strong>Paper ID:</strong> paper-3726967</p>
                <p><strong>Paper Title:</strong> Semantic Processing in the Anterior Temporal Lobes: A Meta-analysis of the Functional Neuroimaging Literature</p>
                <p><strong>Paper Abstract:</strong> The role of the anterior temporal lobes (ATLs) in semantic cognition is not clear from the current literature. Semantic dementia patients show a progressive and a specific semantic impairment, following bilateral atrophy of the ATLs. Neuroimaging studies of healthy participants, however, do not consistently show ATL activation during semantic tasks. Consequently, several influential theories of semantic memory do not ascribe a central role to the ATLs. We conducted a meta-analysis of 164 functional neuroimaging studies of semantic processing to investigate factors that might contribute to the inconsistency in previous results. Four factors influenced the likelihood of finding ATL activation: (1) the use of PET versus fMRI, reflecting the fact that fMRI but not PET is sensitive to distortion artifacts caused by large variations in magnetic susceptibility in the area of the ATL; (2) a field of view (FOV) of more than 15 cm, thereby ensuring whole-brain coverage; (3) the use of a high baseline task to prevent subtraction of otherwise uncontrolled semantic activation; (4) the inclusion of the ATL as an ROI. The type of stimuli or task did not influence the likelihood of ATL activation, consistent with the view that this region underpins an amodal semantic system. Spoken words, written words, and picture stimuli produced overlapping ATL peaks. On average, these were more inferior for picture-based tasks. We suggest that the specific pattern of ATL activation may be influenced by stimulus type due to variations across this region in the degree of connectivity with modality-specific areas in posterior temporal cortex.</p>
                <p><strong>Cost:</strong> 0.014</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e8679.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e8679.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of representational formats of conceptual knowledge at a functional (not neural) level, including descriptions of the format, supporting or challenging evidence, cognitive tasks or phenomena used as evidence, comparisons between formats, and theoretical claims or implications.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Amodal semantic hub</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Amodal semantic hub (hub-and-spoke model)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A functional representational format in which the anterior temporal lobes (ATLs) act as a central, amodal 'hub' that integrates modality-specific 'spokes' (sensory/motor/linguistic representations) to form coherent, modality-independent conceptual representations and support mapping/generalization across input/output modalities.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Where do you know what you know? The representation of semantic knowledge in the human brain.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>representational_format_name</strong></td>
                            <td>Amodal semantic hub (hub-and-spoke)</td>
                        </tr>
                        <tr>
                            <td><strong>representational_format_description</strong></td>
                            <td>Conceptual knowledge is represented by modality-specific feature stores (spokes) plus a central amodal integrative hub located in bilateral ATLs; the hub binds and abstracts across modality-specific inputs to form multimodal, generalizable concept representations used for comprehension and production across modalities.</td>
                        </tr>
                        <tr>
                            <td><strong>format_type</strong></td>
                            <td>hybrid (amodal hub + distributed modality-specific spokes)</td>
                        </tr>
                        <tr>
                            <td><strong>cognitive_task_or_phenomenon</strong></td>
                            <td>Semantic dementia (SD) patient deficits across words, pictures, objects, sounds, smells; rTMS disruption of ATL affecting both verbal and nonverbal semantic tasks; conjunction analyses showing ATL activation for words and pictures; semantic judgment, naming, comprehension tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Convergent evidence supports an ATL amodal hub: (1) SD and HSVE patients with bilateral ATL damage show progressive, modality-general semantic degradation correlated with ATL atrophy; (2) rTMS to ATL in healthy participants disrupts semantic judgments for words and pictures; (3) ALE and conjunction analyses of imaging studies (when ATL signal is recoverable) show overlapping ATL peaks for picture and verbal tasks and bilateral distribution. The meta-analysis found that stimulus type did not change the overall likelihood of ATL activation (consistent with amodal hub), and peaks were present bilaterally (no strong hemispheric specialization).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_other_formats</strong></td>
                            <td>Favored over pure modality-specific-only accounts (which posit that semantic knowledge is represented solely by direct links among modality-specific cortical areas). The hub-and-spoke model reconciles evidence from neuropsychology (SD) and imaging better than a strictly distributed-only model; however, it is compatible with graded specialization models that incorporate both hub and modality-biased gradients.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_counter_evidence</strong></td>
                            <td>Many fMRI studies do not find ATL activation (likely due to susceptibility artifacts and restricted FOV), which historically led some researchers to favor non-ATL substrates; stroke aphasia literature implicates left temporo-parietal and inferior frontal regions (semantic control) and could be taken to challenge a central ATL role if ATL signal loss is not accounted for. The meta-analysis emphasizes technical/analytic reasons for some null ATL findings rather than purely theoretical refutation.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_claims_or_implications</strong></td>
                            <td>The ATL hub provides amodal conceptual representations that enable abstraction and generalization across surface modalities, and supports mapping among modality-specific representations; bilateral instantiation increases robustness to unilateral damage. The hub is functionally distinct from left-hemisphere semantic control systems (frontal/temporoparietal) that regulate or select semantic information.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8679.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e8679.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of representational formats of conceptual knowledge at a functional (not neural) level, including descriptions of the format, supporting or challenging evidence, cognitive tasks or phenomena used as evidence, comparisons between formats, and theoretical claims or implications.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Modality-specific (feature-based) representations</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Modality-specific (sensory-motor / attribute-based) representations</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Functional format where conceptual knowledge is encoded in distributed modality-specific cortical systems (visual, auditory, motor, etc.), such that attributes of concepts are represented in the same regions supporting perception and action for those attributes.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>The representation of object concepts in the brain.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>representational_format_name</strong></td>
                            <td>Modality-specific (feature-based / embodied) representations</td>
                        </tr>
                        <tr>
                            <td><strong>representational_format_description</strong></td>
                            <td>Concepts are represented as patterns of activity across modality-specific cortical systems (e.g., posterior inferior temporal cortex for visual form, superior temporal cortex for auditory/phonological, premotor/parietal for praxis), such that conceptual knowledge arises from distributed sensorimotor/attribute encodings rather than from a single amodal code.</td>
                        </tr>
                        <tr>
                            <td><strong>format_type</strong></td>
                            <td>distributed / feature-based / embodied</td>
                        </tr>
                        <tr>
                            <td><strong>cognitive_task_or_phenomenon</strong></td>
                            <td>Category-specific processing, object recognition, attribute/perceptual judgments (color, form, motion), naming from different modalities, semantic priming and connectivity measures in modality-specific networks.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Imaging reliably shows posterior inferior temporal activation for visual attributes and superior temporal activation for auditory/phonological processing; these regions are commonly activated in semantic tasks and are implicated in category- and attribute-specific effects. Stroke and lesion data (left temporo-parietal and frontal) implicate distributed regions in semantic deficits (semantic aphasia).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_other_formats</strong></td>
                            <td>Contrasted with the amodal hub model: modality-specific accounts can explain attribute- and category-specific activations but struggle to account for modality-general severe semantic deficits following bilateral ATL damage (as seen in SD/HSVE) and for rTMS effects on both words and pictures when ATL is disrupted. The paper frames modality-specific representations as necessary but not sufficient, suggesting they form the 'spokes' in a hub-and-spoke architecture.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_counter_evidence</strong></td>
                            <td>Cannot alone explain amodal, cross-modal semantic degradation following bilateral ATL pathology (SD/HSVE) or the bilateral rTMS disruption of both verbal and nonverbal semantics; pure modality-specific models risk failing to capture deep semantic relationships that require integration across modalities.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_claims_or_implications</strong></td>
                            <td>Modality-specific systems encode sensory-motor/conceptual attributes and contribute necessary content to concepts, but an integrative mechanism (hub) may be required to form abstract, modality-independent conceptual representations and to support cross-modal generalization and conceptual coherence.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8679.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e8679.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of representational formats of conceptual knowledge at a functional (not neural) level, including descriptions of the format, supporting or challenging evidence, cognitive tasks or phenomena used as evidence, comparisons between formats, and theoretical claims or implications.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Graded specialization model</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Graded modality-specific specialization (Plaut computational account / graded hub-and-spoke)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A hybrid functional format where ATL and temporal lobe regions form a graded, continuous representational space: units contribute to multiple modalities but show graded specialization according to their connectivity distance to modality-specific posterior regions, producing overlapping but biased modality-preferences rather than absolute segregation.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Graded modality-specific specialisation in semantics: A computational account of optic aphasia.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>representational_format_name</strong></td>
                            <td>Graded modality-specific specialization (graded hub-and-spoke)</td>
                        </tr>
                        <tr>
                            <td><strong>representational_format_description</strong></td>
                            <td>A distributed-hybrid representation in which units across the temporal lobes are multimodal but exhibit graded biases (e.g., superior ATL relatively more tied to auditory/verbal inputs, inferior ATL relatively more tied to visual/pictorial inputs) determined by graded connectivity to posterior modality-specific regions; the ATL itself remains multimodal but with continuous, not categorical, specialization.</td>
                        </tr>
                        <tr>
                            <td><strong>format_type</strong></td>
                            <td>hybrid (distributed + graded connectivity biases)</td>
                        </tr>
                        <tr>
                            <td><strong>cognitive_task_or_phenomenon</strong></td>
                            <td>Differences in peak ATL activation location for picture vs verbal tasks (ALE analysis shows superior-inferior skew), optic aphasia and other modality-related deficits, cross-modal conjunctions showing overlapping activations with graded spatial shifts.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>ALE in this meta-analysis revealed overlapping ATL peaks for pictorial and verbal stimuli but with a graded difference: verbal tasks skewed superiorly and pictorial tasks skewed inferiorly (graded inferiorsuperior distribution). This pattern is consistent with Plaut's computational model that predicts graded specialization arising from connection strengths to modality-specific posterior cortices. The graded result remained after checking for FOV differences, suggesting it is not solely a technical artifact.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_other_formats</strong></td>
                            <td>Reconciles the amodal hub and modality-specific accounts by preserving a central multimodal representation (hub-like) while allowing modality-biased gradient structure; thus it is intermediate between pure hub and pure distributed models and is favored by evidence of both modality-general ATL involvement and systematic modality-related spatial variation.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_counter_evidence</strong></td>
                            <td>Technical imaging issues (susceptibility artifacts, restricted FOV) can bias apparent location of peaks; some of the superior/inferior skew could reflect these methodological confounds, although the paper reports analyses suggesting these are unlikely to be the sole cause. More direct, distortion-corrected imaging and lesion-modeling are required to fully validate the graded topology.</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_claims_or_implications</strong></td>
                            <td>Functional representations are multimodal but topographically graded according to connectivity to modality-specific inputs, allowing both amodal conceptual abstraction and modality-preferential processing; this supports flexible access from different input types and explains why ATL damage produces multimodal deficits while still permitting modal biases in activation patterns.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e8679.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e8679.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of representational formats of conceptual knowledge at a functional (not neural) level, including descriptions of the format, supporting or challenging evidence, cognitive tasks or phenomena used as evidence, comparisons between formats, and theoretical claims or implications.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Combinatorial semantic composition</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Combinatorial semantic composition specialization (sentence-level meaning computation)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A proposed functional representation/process whereby ATL regions (particularly superior aspects) compute combinatorial or compositional meaning across sequences (e.g., sentences), integrating word-level semantics into higher-order propositional or sentence-level representations.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>The cortical organization of speech processing.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>representational_format_name</strong></td>
                            <td>Combinatorial / compositional semantic representation</td>
                        </tr>
                        <tr>
                            <td><strong>representational_format_description</strong></td>
                            <td>Representation implemented as computations that combine lexical semantic elements into structured, higher-order meanings (compositional semantics) across temporal sequences (e.g., spoken sentences); functionally, this is a process-level representational format for deriving overarching sentence meaning rather than isolated concept tokens.</td>
                        </tr>
                        <tr>
                            <td><strong>format_type</strong></td>
                            <td>structured / compositional (process-level representation)</td>
                        </tr>
                        <tr>
                            <td><strong>cognitive_task_or_phenomenon</strong></td>
                            <td>Auditory sentence comprehension (spoken sentences), deriving overarching sentence meaning, rapid sequential input processing, tasks requiring combinatorial interpretation beyond single-word semantics.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>The meta-analysis found that auditory sentence tasks were more likely than many other stimuli to elicit ATL activation; one interpretation (cited) is that ATL is engaged in computing combinatorial meaning. However, written sentences did not show the same advantage, and the authors note methodological confounds (FOV, susceptibility) that may favor superior ATL involvement for auditory tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_other_formats</strong></td>
                            <td>This account is not mutually exclusive with the amodal hub model; combinatorial composition could be a functional specialization or role implemented within ATL hub representations (particularly superior ATL), rather than an alternative global representational format. The evidence is suggestive but not definitive in favor of an ATL-specific combinatorial role.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_counter_evidence</strong></td>
                            <td>The sentence-specific ATL activation effect might reflect methodological biases (superior ATL less affected by susceptibility artifact, better included in restricted FOVs) and does not generalize to written sentences; thus the claim of ATL specialization for combinatorial meaning is tentative and requires more controlled/directed investigation (e.g., distortion-corrected fMRI).</td>
                        </tr>
                        <tr>
                            <td><strong>theoretical_claims_or_implications</strong></td>
                            <td>If present, a combinatorial/structural semantic computation in ATL would indicate that ATLs not only store amodal concept representations but also support higher-order composition of concepts into complex meanings (e.g., sentence-level); this would extend the hub role to include dynamic combinatorial processing on top of representational integration.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Where do you know what you know? The representation of semantic knowledge in the human brain. <em>(Rating: 2)</em></li>
                <li>Structure and deterioration of semantic memory: A neuropsychological and computational investigation. <em>(Rating: 2)</em></li>
                <li>Graded modality-specific specialisation in semantics: A computational account of optic aphasia. <em>(Rating: 2)</em></li>
                <li>Anterior temporal lobes mediate semantic representation: Mimicking semantic dementia by using rTMS in normal participants. <em>(Rating: 2)</em></li>
                <li>Conceptual knowledge is underpinned by the temporal pole bilaterally: Convergent evidence from rTMS. <em>(Rating: 2)</em></li>
                <li>Susceptibility-induced loss of signal: Comparing PET and fMRI on a semantic task. <em>(Rating: 1)</em></li>
                <li>The cortical organization of speech processing. <em>(Rating: 1)</em></li>
                <li>The representation of object concepts in the brain. <em>(Rating: 1)</em></li>
                <li>An anterior temporal cortex and semantic memory: Reconciling findings from neuropsychology and functional imaging. <em>(Rating: 1)</em></li>
                <li>Coherent concepts are computed in the anterior temporal lobes. <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-8679",
    "paper_id": "paper-3726967",
    "extraction_schema_id": "extraction-schema-156",
    "extracted_data": [
        {
            "name_short": "Amodal semantic hub",
            "name_full": "Amodal semantic hub (hub-and-spoke model)",
            "brief_description": "A functional representational format in which the anterior temporal lobes (ATLs) act as a central, amodal 'hub' that integrates modality-specific 'spokes' (sensory/motor/linguistic representations) to form coherent, modality-independent conceptual representations and support mapping/generalization across input/output modalities.",
            "citation_title": "Where do you know what you know? The representation of semantic knowledge in the human brain.",
            "mention_or_use": "use",
            "representational_format_name": "Amodal semantic hub (hub-and-spoke)",
            "representational_format_description": "Conceptual knowledge is represented by modality-specific feature stores (spokes) plus a central amodal integrative hub located in bilateral ATLs; the hub binds and abstracts across modality-specific inputs to form multimodal, generalizable concept representations used for comprehension and production across modalities.",
            "format_type": "hybrid (amodal hub + distributed modality-specific spokes)",
            "cognitive_task_or_phenomenon": "Semantic dementia (SD) patient deficits across words, pictures, objects, sounds, smells; rTMS disruption of ATL affecting both verbal and nonverbal semantic tasks; conjunction analyses showing ATL activation for words and pictures; semantic judgment, naming, comprehension tasks.",
            "key_findings": "Convergent evidence supports an ATL amodal hub: (1) SD and HSVE patients with bilateral ATL damage show progressive, modality-general semantic degradation correlated with ATL atrophy; (2) rTMS to ATL in healthy participants disrupts semantic judgments for words and pictures; (3) ALE and conjunction analyses of imaging studies (when ATL signal is recoverable) show overlapping ATL peaks for picture and verbal tasks and bilateral distribution. The meta-analysis found that stimulus type did not change the overall likelihood of ATL activation (consistent with amodal hub), and peaks were present bilaterally (no strong hemispheric specialization).",
            "comparison_with_other_formats": "Favored over pure modality-specific-only accounts (which posit that semantic knowledge is represented solely by direct links among modality-specific cortical areas). The hub-and-spoke model reconciles evidence from neuropsychology (SD) and imaging better than a strictly distributed-only model; however, it is compatible with graded specialization models that incorporate both hub and modality-biased gradients.",
            "limitations_or_counter_evidence": "Many fMRI studies do not find ATL activation (likely due to susceptibility artifacts and restricted FOV), which historically led some researchers to favor non-ATL substrates; stroke aphasia literature implicates left temporo-parietal and inferior frontal regions (semantic control) and could be taken to challenge a central ATL role if ATL signal loss is not accounted for. The meta-analysis emphasizes technical/analytic reasons for some null ATL findings rather than purely theoretical refutation.",
            "theoretical_claims_or_implications": "The ATL hub provides amodal conceptual representations that enable abstraction and generalization across surface modalities, and supports mapping among modality-specific representations; bilateral instantiation increases robustness to unilateral damage. The hub is functionally distinct from left-hemisphere semantic control systems (frontal/temporoparietal) that regulate or select semantic information.",
            "uuid": "e8679.0"
        },
        {
            "name_short": "Modality-specific (feature-based) representations",
            "name_full": "Modality-specific (sensory-motor / attribute-based) representations",
            "brief_description": "Functional format where conceptual knowledge is encoded in distributed modality-specific cortical systems (visual, auditory, motor, etc.), such that attributes of concepts are represented in the same regions supporting perception and action for those attributes.",
            "citation_title": "The representation of object concepts in the brain.",
            "mention_or_use": "use",
            "representational_format_name": "Modality-specific (feature-based / embodied) representations",
            "representational_format_description": "Concepts are represented as patterns of activity across modality-specific cortical systems (e.g., posterior inferior temporal cortex for visual form, superior temporal cortex for auditory/phonological, premotor/parietal for praxis), such that conceptual knowledge arises from distributed sensorimotor/attribute encodings rather than from a single amodal code.",
            "format_type": "distributed / feature-based / embodied",
            "cognitive_task_or_phenomenon": "Category-specific processing, object recognition, attribute/perceptual judgments (color, form, motion), naming from different modalities, semantic priming and connectivity measures in modality-specific networks.",
            "key_findings": "Imaging reliably shows posterior inferior temporal activation for visual attributes and superior temporal activation for auditory/phonological processing; these regions are commonly activated in semantic tasks and are implicated in category- and attribute-specific effects. Stroke and lesion data (left temporo-parietal and frontal) implicate distributed regions in semantic deficits (semantic aphasia).",
            "comparison_with_other_formats": "Contrasted with the amodal hub model: modality-specific accounts can explain attribute- and category-specific activations but struggle to account for modality-general severe semantic deficits following bilateral ATL damage (as seen in SD/HSVE) and for rTMS effects on both words and pictures when ATL is disrupted. The paper frames modality-specific representations as necessary but not sufficient, suggesting they form the 'spokes' in a hub-and-spoke architecture.",
            "limitations_or_counter_evidence": "Cannot alone explain amodal, cross-modal semantic degradation following bilateral ATL pathology (SD/HSVE) or the bilateral rTMS disruption of both verbal and nonverbal semantics; pure modality-specific models risk failing to capture deep semantic relationships that require integration across modalities.",
            "theoretical_claims_or_implications": "Modality-specific systems encode sensory-motor/conceptual attributes and contribute necessary content to concepts, but an integrative mechanism (hub) may be required to form abstract, modality-independent conceptual representations and to support cross-modal generalization and conceptual coherence.",
            "uuid": "e8679.1"
        },
        {
            "name_short": "Graded specialization model",
            "name_full": "Graded modality-specific specialization (Plaut computational account / graded hub-and-spoke)",
            "brief_description": "A hybrid functional format where ATL and temporal lobe regions form a graded, continuous representational space: units contribute to multiple modalities but show graded specialization according to their connectivity distance to modality-specific posterior regions, producing overlapping but biased modality-preferences rather than absolute segregation.",
            "citation_title": "Graded modality-specific specialisation in semantics: A computational account of optic aphasia.",
            "mention_or_use": "use",
            "representational_format_name": "Graded modality-specific specialization (graded hub-and-spoke)",
            "representational_format_description": "A distributed-hybrid representation in which units across the temporal lobes are multimodal but exhibit graded biases (e.g., superior ATL relatively more tied to auditory/verbal inputs, inferior ATL relatively more tied to visual/pictorial inputs) determined by graded connectivity to posterior modality-specific regions; the ATL itself remains multimodal but with continuous, not categorical, specialization.",
            "format_type": "hybrid (distributed + graded connectivity biases)",
            "cognitive_task_or_phenomenon": "Differences in peak ATL activation location for picture vs verbal tasks (ALE analysis shows superior-inferior skew), optic aphasia and other modality-related deficits, cross-modal conjunctions showing overlapping activations with graded spatial shifts.",
            "key_findings": "ALE in this meta-analysis revealed overlapping ATL peaks for pictorial and verbal stimuli but with a graded difference: verbal tasks skewed superiorly and pictorial tasks skewed inferiorly (graded inferiorsuperior distribution). This pattern is consistent with Plaut's computational model that predicts graded specialization arising from connection strengths to modality-specific posterior cortices. The graded result remained after checking for FOV differences, suggesting it is not solely a technical artifact.",
            "comparison_with_other_formats": "Reconciles the amodal hub and modality-specific accounts by preserving a central multimodal representation (hub-like) while allowing modality-biased gradient structure; thus it is intermediate between pure hub and pure distributed models and is favored by evidence of both modality-general ATL involvement and systematic modality-related spatial variation.",
            "limitations_or_counter_evidence": "Technical imaging issues (susceptibility artifacts, restricted FOV) can bias apparent location of peaks; some of the superior/inferior skew could reflect these methodological confounds, although the paper reports analyses suggesting these are unlikely to be the sole cause. More direct, distortion-corrected imaging and lesion-modeling are required to fully validate the graded topology.",
            "theoretical_claims_or_implications": "Functional representations are multimodal but topographically graded according to connectivity to modality-specific inputs, allowing both amodal conceptual abstraction and modality-preferential processing; this supports flexible access from different input types and explains why ATL damage produces multimodal deficits while still permitting modal biases in activation patterns.",
            "uuid": "e8679.2"
        },
        {
            "name_short": "Combinatorial semantic composition",
            "name_full": "Combinatorial semantic composition specialization (sentence-level meaning computation)",
            "brief_description": "A proposed functional representation/process whereby ATL regions (particularly superior aspects) compute combinatorial or compositional meaning across sequences (e.g., sentences), integrating word-level semantics into higher-order propositional or sentence-level representations.",
            "citation_title": "The cortical organization of speech processing.",
            "mention_or_use": "use",
            "representational_format_name": "Combinatorial / compositional semantic representation",
            "representational_format_description": "Representation implemented as computations that combine lexical semantic elements into structured, higher-order meanings (compositional semantics) across temporal sequences (e.g., spoken sentences); functionally, this is a process-level representational format for deriving overarching sentence meaning rather than isolated concept tokens.",
            "format_type": "structured / compositional (process-level representation)",
            "cognitive_task_or_phenomenon": "Auditory sentence comprehension (spoken sentences), deriving overarching sentence meaning, rapid sequential input processing, tasks requiring combinatorial interpretation beyond single-word semantics.",
            "key_findings": "The meta-analysis found that auditory sentence tasks were more likely than many other stimuli to elicit ATL activation; one interpretation (cited) is that ATL is engaged in computing combinatorial meaning. However, written sentences did not show the same advantage, and the authors note methodological confounds (FOV, susceptibility) that may favor superior ATL involvement for auditory tasks.",
            "comparison_with_other_formats": "This account is not mutually exclusive with the amodal hub model; combinatorial composition could be a functional specialization or role implemented within ATL hub representations (particularly superior ATL), rather than an alternative global representational format. The evidence is suggestive but not definitive in favor of an ATL-specific combinatorial role.",
            "limitations_or_counter_evidence": "The sentence-specific ATL activation effect might reflect methodological biases (superior ATL less affected by susceptibility artifact, better included in restricted FOVs) and does not generalize to written sentences; thus the claim of ATL specialization for combinatorial meaning is tentative and requires more controlled/directed investigation (e.g., distortion-corrected fMRI).",
            "theoretical_claims_or_implications": "If present, a combinatorial/structural semantic computation in ATL would indicate that ATLs not only store amodal concept representations but also support higher-order composition of concepts into complex meanings (e.g., sentence-level); this would extend the hub role to include dynamic combinatorial processing on top of representational integration.",
            "uuid": "e8679.3"
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Where do you know what you know? The representation of semantic knowledge in the human brain.",
            "rating": 2,
            "sanitized_title": "where_do_you_know_what_you_know_the_representation_of_semantic_knowledge_in_the_human_brain"
        },
        {
            "paper_title": "Structure and deterioration of semantic memory: A neuropsychological and computational investigation.",
            "rating": 2,
            "sanitized_title": "structure_and_deterioration_of_semantic_memory_a_neuropsychological_and_computational_investigation"
        },
        {
            "paper_title": "Graded modality-specific specialisation in semantics: A computational account of optic aphasia.",
            "rating": 2,
            "sanitized_title": "graded_modalityspecific_specialisation_in_semantics_a_computational_account_of_optic_aphasia"
        },
        {
            "paper_title": "Anterior temporal lobes mediate semantic representation: Mimicking semantic dementia by using rTMS in normal participants.",
            "rating": 2,
            "sanitized_title": "anterior_temporal_lobes_mediate_semantic_representation_mimicking_semantic_dementia_by_using_rtms_in_normal_participants"
        },
        {
            "paper_title": "Conceptual knowledge is underpinned by the temporal pole bilaterally: Convergent evidence from rTMS.",
            "rating": 2,
            "sanitized_title": "conceptual_knowledge_is_underpinned_by_the_temporal_pole_bilaterally_convergent_evidence_from_rtms"
        },
        {
            "paper_title": "Susceptibility-induced loss of signal: Comparing PET and fMRI on a semantic task.",
            "rating": 1,
            "sanitized_title": "susceptibilityinduced_loss_of_signal_comparing_pet_and_fmri_on_a_semantic_task"
        },
        {
            "paper_title": "The cortical organization of speech processing.",
            "rating": 1,
            "sanitized_title": "the_cortical_organization_of_speech_processing"
        },
        {
            "paper_title": "The representation of object concepts in the brain.",
            "rating": 1,
            "sanitized_title": "the_representation_of_object_concepts_in_the_brain"
        },
        {
            "paper_title": "An anterior temporal cortex and semantic memory: Reconciling findings from neuropsychology and functional imaging.",
            "rating": 1,
            "sanitized_title": "an_anterior_temporal_cortex_and_semantic_memory_reconciling_findings_from_neuropsychology_and_functional_imaging"
        },
        {
            "paper_title": "Coherent concepts are computed in the anterior temporal lobes.",
            "rating": 1,
            "sanitized_title": "coherent_concepts_are_computed_in_the_anterior_temporal_lobes"
        }
    ],
    "cost": 0.014010749999999999,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Semantic Processing in the Anterior Temporal Lobes: A Meta-analysis of the Functional Neuroimaging Literature</p>
<p>M Visser 
E Jefferies 
M A Lambon Ralph 
Semantic Processing in the Anterior Temporal Lobes: A Meta-analysis of the Functional Neuroimaging Literature
10.1162/jocn.2009.21309
■ The role of the anterior temporal lobes (ATLs) in semantic cognition is not clear from the current literature. Semantic dementia patients show a progressive and a specific semantic impairment, following bilateral atrophy of the ATLs. Neuroimaging studies of healthy participants, however, do not consistently show ATL activation during semantic tasks. Consequently, several influential theories of semantic memory do not ascribe a central role to the ATLs. We conducted a meta-analysis of 164 functional neuroimaging studies of semantic processing to investigate factors that might contribute to the inconsistency in previous results. Four factors influenced the likelihood of finding ATL activation: (1) the use of PET versus fMRI, reflecting the fact that fMRI but not PET is sensitive to distortion artifacts caused by large variations in magnetic susceptibility in the area of the ATL; (2) a field of view (FOV) of more than 15 cm, thereby ensuring whole-brain coverage; (3) the use of a high baseline task to prevent subtraction of otherwise uncontrolled semantic activation; (4) the inclusion of the ATL as an ROI. The type of stimuli or task did not influence the likelihood of ATL activation, consistent with the view that this region underpins an amodal semantic system. Spoken words, written words, and picture stimuli produced overlapping ATL peaks. On average, these were more inferior for picture-based tasks. We suggest that the specific pattern of ATL activation may be influenced by stimulus type due to variations across this region in the degree of connectivity with modality-specific areas in posterior temporal cortex. ■</p>
<p>INTRODUCTION</p>
<p>Semantic memory refers to our mental representations of the meaning of words, objects, people, and factual information about the world. It is essential for human communication and cognition, yet there is still considerable controversy about its neural basis. Inferior frontal, inferior parietal, and temporal cortex have all been associated with semantic processing, but agreement about the contribution of each of these areas has not been achieved. In particular, the involvement of the anterior temporal lobes (ATLs) is not clear from the existing literature: Functional neuroimaging investigations using PET and fMRI and patients with dementia and stroke aphasia have given rise to conflicting conclusions about this region. This study seeks to clarify these inconsistencies by considering factors that might account for variation in the results of functional neuroimaging studies.</p>
<p>Patient studies provide some of the best evidence to date about the brain regions that are essential for semantic cognition. Arguably, the purest semantic deficits are seen in semantic dementia (SD): These patients show a progressive deterioration of semantic knowledge despite largely preserved sensory and language skills and memory for recent events (Hodges, Patterson, Oxbury, &amp; Funnell, 1992;Snowden, Griffiths, Neary, &amp; Mann, 1989;Warrington, 1975). Patients with SD have circumscribed atrophy and hypometabolism of the ATLs bilaterally, and the degree of this damage correlates with the severity of the semantic impairment (Noppeney et al., 2007;Nestor, Fryer, &amp; Hodges, 2006;Davies, Graham, Xuereb, Williams, &amp; Hodges, 2004;Gorno-Tempini et al., 2004;Galton et al., 2001;Mummery et al., 2000). They have impaired comprehension and production in a wide range of semantic tasks, affecting spoken and written words, pictures, objects, environmental sounds, and smells (Coccia, Bartolini, Luzzi, Provinciali, &amp; Lambon Ralph, 2004;Bozeat, Lambon Ralph, Patterson, Garrard, &amp; Hodges, 2000). The consistency of the impairment across these different input and output modalities suggests that the ATL acts as a semantic hub, combining information from different sensory and motor areas to form amodal semantic representations (Patterson, Nestor, &amp; Rogers, 2007;Rogers et al., 2004). This allows the ATLs to map between different modalityspecific representations and to make appropriate generalizations based on central semantic relationships rather than superficial similarities found in one particular domain . Further evidence for the ATLs as a semantic "hub" comes from patients with herpes simplex virus encephalitis (HSVE). HSVE produces bilateral frontotemporal damage overlapping with the regions damaged in SD and also gives rise to amodal semantic deficits (Lambon Ralph, Lowe, &amp; Rogers, 2007;Noppeney et al., 2007;Kapur et al., 1994). Moreover, repetitive transcranial magnetic stimulation (rTMS) of the ATLs in healthy volunteers disrupts performance on both verbal and nonverbal semantic tasks, but not nonsemantic control tasks matched for difficulty, confirming the conclusions of these patient studies (Lambon Ralph, Pobric, &amp; Jefferies, 2009;Pobric, Jefferies, &amp; Lambon Ralph, 2007).</p>
<p>Comprehension impairment is also frequently observed in the context of stroke aphasia (e.g., Wernickeʼs aphasia, transcortical aphasia, and global aphasia). However, in contrast to SD and HSVE, these semantic problems are associated with left temporo-parietal and inferior frontal infarcts and not damage to ATLs ( Jefferies &amp; Lambon Ralph, 2006;Berthier, 2001;Chertkow, Bub, Deaudon, &amp; Whitehead, 1997). Stroke rarely produces ATL lesions (and almost never produces bilateral infarcts) for two reasons: (i) in most individuals, the ATL has a double blood supply (via the anterior temporal cortical artery of the middle cerebral artery and the anterior temporal branch of the distal posterior cerebral artery) (Conn, 2003); and (ii) the anterior temporal cortical artery branches below the main trifurcation of the middle cerebral artery, making it potentially less vulnerable to emboli (Borden, 2006). As a consequence, models of the neural basis of semantic memory based on stroke data alone consider left temporo-parietal and inferior frontal regions to be the critical substrate for semantic memory and overlook the contributions of ATLs ( Wise, 2003).</p>
<p>When considered in totality (i.e., stroke, dementia, etc.), the neuropsychological evidence suggests that all three regions ( bilateral ATL, left temporo-parietal cortex, and left inferior frontal cortex) make a necessary contribution to semantic cognition; however, their respective roles may be different. Some aphasic individuals with left frontal or temporo-parietal damage can fail the same range of verbal and nonverbal semantic tasks as SD patients but have difficulty applying their semantic knowledge in a task-appropriate fashion rather than showing the deterioration of amodal semantic knowledge seen in SD-a pattern we have dubbed "semantic aphasia" ( Jefferies, Patterson, &amp; Lambon Ralph, 2008;Jefferies, Baker, Doran, &amp; Lambon Ralph, 2007;Jefferies &amp; Lambon Ralph, 2006;Metzler, 2001;Thompson-Schill, DʼEsposito, Aguirre, &amp; Farah, 1997). Thus, left frontal/temporo-parietal areas may contribute to executive control over semantic processing, whereas bilateral ATL provides the substrate for the semantic store itself (Noonan, Jefferies, Corbett, &amp; Lambon Ralph, in press;Jefferies &amp; Lambon Ralph, 2006).</p>
<p>The neural network underlying normal semantic processing has also been studied widely in functional neuroimaging studies of healthy participants; however, these techniques have produced inconsistent findings and are not in complete agreement with neuropsychological studies. For example, many fMRI studies report activation within prefrontal and temporo-parietal areas during semantic tasks but do not observe activation within the ATLs (Denkova, Botzung, &amp; Manning, 2006;Gold et al., 2006;Mechelli, Sartori, Orlandi, &amp; Price, 2006;Wible et al., 2006;Chee, Westphal, Goh, Graham, &amp; Song, 2003;Demb et al., 1995). These activated regions overlap with the areas implicated by patients with semantic aphasia, and the convergence of these literatures has led some researchers to conclude that the critical neural substrate for semantic memory is outside the ATLs (Martin, 2007;Catani &amp; Ffytche, 2005). In line with the poor regulatory control of semantic activation seen in patients with semantic aphasia, activation in left prefrontal and temporo-parietal regions has been linked to controlled semantic retrieval and executive demands of semantic tasks rather than to the activation of semantic representations per se (Scott, Leff, &amp; Wise, 2003;Thompson-Schill, 2003;Gabrieli, Poldrack, &amp; Desmond, 1998;Price et al., 1996;Demonet et al., 1992). In addition, activation within posterior temporal regions is likely to contribute to knowledge of specific visual attributes, such as color, form, and motion, whereas premotor and inferior parietal areas are thought to play a role in praxis knowledge (for reviews, see Martin, 2007;Thompson-Schill, 2003). There is considerable debate about whether direct links between these modalityspecific areas are sufficient for semantic processing, or whether an additional amodal semantic hub within the ATLs is required to uncover "deep" semantic relationships (Lambon Ralph, Sage, Jones, &amp; Mayberry, 2010;Patterson et al., 2007). In this context, the absence of ATL activation in many functional neuroimaging studies of semantic cognition presents a major challenge to the view that this brain region has a central role in the semantic network.</p>
<p>In considering the functional neuroimaging of the ATL, however, it is critically important to bear in mind that using fMRI to probe the function of this region is known to be problematic. The fMRI signal is distorted near air-filled cavities, such as the sinuses, due to discrepancies in the magnetic susceptibility across different tissue types (e.g., air, bone, water). This "susceptibility artifact" leads to a loss of signal from the ATLs ( both spatial distortion and signal break up if using gradient EPI), potentially explaining the absence of ATL activation in many fMRI studies of semantic memory ( Jezzard, Matthews, &amp; Smith, 2001;Schmithorst, Dardzinski, &amp; Holland, 2001;Devlin et al., 2000). PET is not subject to these distortions, and therefore having controlled for other relevant factors (see below), we would expect most PET studies to reveal ATL activation during semantic processing. Direct support for this suggestion was obtained by Devlin et al. (2000) who found ATL activation using PET but not f MRI for the same semantic task.</p>
<p>It is also possible that other factors relating to experimental design and data analysis might contribute to the sensitivity of functional neuroimaging studies to signal in ATLs. Given the substantial degree of inconsistency amongst previous functional neuroimaging studies, the preeminence of this methodology in cognitive neuroscience, and the considerable theoretical impact of previous null results, it is essential to establish which factors have a major influence on the likelihood of observing ATL activation in neuroimaging studies of semantic memory. To address this issue, we undertook a meta-analysis of 164 fMRI and PET studies published between 1994 and 2008 that examined semantic processing. We investigated the impact of a wide range of factors relating to imaging methodology and experimental design that could conceivably influence the likelihood of observing significant activation within ATLs. First, we contrasted studies using PET and fMRI to establish whether there are genuine differences between these imaging modalities, as anticipated by Devlin et al. (2000). Second, we examined the FOV of the included studies. Given that the ATL is one of the most inferior parts of the brain, it is likely to be excluded from the image acquisition in some studies with a restricted FOV. We examined, therefore, if studies with an FOV of more than 15 cm (covering the whole brain) were more likely to report ATL activation than those with a smaller FOV. Third, we examined several variables-namely year of publication, number of participants, use of ROI analysis, threshold level, and degree of spatial smoothing-that might be expected to influence the sensitivity of imaging studies to ATL activation. Experiments that include more participants and ROI analyses should have greater statistical power, allowing weaker ATL activation to reach the threshold for significance. Advances in imaging technology might also allow weaker activations to be detected, although the higher field strengths used in many modern MRI facilities are likely to exacerbate distortion artifacts in the ATLs. In addition, the threshold level used during the analyses should influence the results: Studies that use less stringent statistical thresholds are presumably more likely to report weaker activations in ATLs. Finally, there is variation between neuroimaging studies in the degree of spatial smoothing. This technique is used to increase the signalto-noise-ratio; however, the optimal size of the smoothing kernel depends on the size of the activated area. If a large kernel is used, small areas of activation can be missed and visa versa.</p>
<p>Fourth, we investigated the effect of the different behavioral tasks used. The choice of baseline task might be important because low-level baselines (e.g., rest or passive viewing of scrambled letters) are likely to allow semantic processing to continue during daydreaming or "idle" thought. Thus, when low-level baselines are subtracted from semantic tasks, large portions of the brain activity attributable to conceptual processing may be removed (Binder et al., 1999). Moreover, the choice of semantic task is likely to be critical. The use of paced or difficult semantic tasks might increase the signal from the ATLs (Binder et al., 1994). In addition, individual studies have shown greater ATL activation for specific-level concepts (e.g., identifying an animal as a "poodle") than for basiclevel concepts (e.g., identifying an animal as a "dog") (Rogers et al., 2006;Tyler et al., 2004).</p>
<p>Next, we considered the effect of the type of semantic stimulus. We specified six different types of stimuli, namely, pictures, auditory words, visual words, auditory sentences, visual sentences, and environmental sounds. If the ATL acts as a semantic hub, combining modalityspecific information from these different stimulus types into amodal semantic representations, this area should respond to all stimuli (Rogers et al., 2004). Nevertheless, even within an amodal semantic hub, the specific pattern of activation across the ATLs might vary according to the task (although activation for different tasks should overlap). For example, different processing streams-underlying the recognition of pictures (in inferior temporal cortex) versus auditory words (in superior temporal cortex)might converge on the temporal poles. In line with this view, numerous studies have shown that posterior inferior temporal regions are associated with visual form processing, whereas activation in superior temporal areas is linked to understanding spoken words (Okada &amp; Hickok, 2006;Okada, Smith, Humphries, &amp; Hickok, 2003;Scott &amp; Johnsrude, 2003;Chao, Weisberg, &amp; Martin, 2002;Scott, Blank, Rosen, &amp; Wise, 2000;Chao, Haxby, &amp; Martin, 1999;Moore &amp; Price, 1999;Martin, Wiggs, Ungerleider, &amp; Haxby, 1996;Demonet et al., 1992). These two processing streams may be differentially connected with inferior and superior portions of ATLs, respectively. This does not necessitate an absolute segregation of areas within the ATL; instead, it is conceivable that all of the units in the ATLs contribute to semantic processing for the full range of stimulus types, but that the degree of their involvement depends on the strength of connections into modality-specific posterior temporal areas (for an implementation of this idea, see Plaut, 2002). This would result in somewhat different patterns of ATL activation for verbal versus nonverbal semantic tasks. Thus, in addition to examining the effect of various methodological factors on the likelihood of observing ATL activation, we also explored the possibility that the location of these peak activations might vary according to stimulus type.</p>
<p>Finally, we examined the degree of hemispheric specificity for different types of semantic tasks. Semantic impairment follows bilateral ATL damage in patients with SD and HSVE, suggesting that semantic knowledge may be distributed across the two hemispheres. However, the left and the right ATLs might have somewhat different specializations. For example, Lambon Ralph, McClelland, Patterson, Galton, and Hodges (2001) found that SD patients with more left-than right-sided atrophy (L &gt; R) had greater word-finding problems (anomia) than patients with R &gt; L atrophy with the same level of comprehension deficit. In addition, Snowden, Thompson, and Neary (2004) demonstrated that SD patients with L &gt; R atrophy identified famous faces better than famous names, whereas R &gt; L patients showed the opposite pattern. Therefore, one possibility is that there is a division of labor across the left and the right ATL brought about either by left-hemisphere dominance for language or because the perceptual information that interacts with semantic representations comes more strongly from right than left posterior regions (Gainotti, 2007). Alternatively, both hemispheres may contribute broadly equally to semantic processing for words and pictures-which would fit with the results of recent rTMS explorations of left versus right ATL regions in normal participants (Lambon Ralph et al., 2009). We examined these possibilities by looking at the distribution of peaks across the hemispheres for pictorial and verbal stimuli.</p>
<p>METHODS</p>
<p>Web of Knowledge (www.isiknowledge.com) was used to identify fMRI and PET studies of semantic memory using the following search terms: "fMRI" or "PET" combined with "semantic," "comprehension," "conceptual knowledge," "naming," "verbal fluency," "lexical," "sentence," or "face." The inclusion and the exclusion criteria were as follows:</p>
<p>(1) PET and fMRI studies on the topic of semantic memory were included; (2) the studies were published in peerreviewed journals (in English) between January 1994 and March 2008; (3) studies were excluded when they did not include ATL areas explicitly in their data acquisition or analyses; and (4) studies were excluded if their focus was on patients, sex differences, task switching, priming, adaptation, metaphoric and idiom comprehension, bilingualism, language development, syntax, working memory, or episodic memory. We avoided more complex designs (e.g., conjunctions of semantic and episodic memory) because our objective was to examine the general role of ATLs in semantic processing. We also excluded studies unlikely to include contrasts specifically focussed on semantic memory (e.g., studies on metaphoric comprehension that might subtract nonmetaphoric semantic processing). This search identified 164 PET and fMRI studies ( listed in the Supplementary Materials).</p>
<p>We conducted two sets of analyses. First, we investigated the influence of each of the following factors on the probability of ATL activation:</p>
<ol>
<li>
<p>Imaging modality: PET (n = 71) or fMRI (n = 103). 2. FOV categorized as follows: less than 15 cm (n = 102) and more than 15 cm (n = 22). 3. Stimulus type categorized as follows: pictures (n = 51), auditory words (n = 19), visual words (n = 59), auditory sentences (n = 30), visual sentences (n= 17), and "other" (n = 19, of which 5 are environmental sounds). 4. Nature of semantic task categorized as follows: passive listening to words, sentences or sounds (n = 38), reading (n = 34), semantic judgment (n = 40), naming (n = 33), property verification (n = 14), lexical decision (n = 10), verbal fluency (n = 12), and "other" (n = 23). 5. Number of participants in the analysis.</p>
</li>
<li>
<p>Inclusion of ATLs as ROI in the analysis (n = 12). 7. Degree of spatial smoothing, examined separately for a. fMRI using four categories; 1-3 mm (n = 6), 4-6 mm (n = 34), 7-9 mm (n = 30), and 10-12 mm (n = 16) smoothing. b. PET using two categories: smoothing kernel less than 15 mm (n = 21) or 15 mm and above (n = 45).</p>
</li>
</ol>
<p>Studies that did not report the degree of spatial smoothing were excluded from this analysis (n = 22.) 8. Year of publication, divided into three time periods : 1994-1998 (n = 22), 1999-2003 (n = 72), and 2004-2008 (n = 80). 9. Level of baseline task: cognitively demanding (n = 125) versus low level (e.g., presentation of fixation cross or rest; n = 52). 10. Threshold level, divided in four categories: studies using multiple correction and a p value of .05 or lower (n = 69); studies using uncorrected data with a p value of .001 or lower (n = 66); studies using a uncorrected p value of .005 or lower with an extent of at least 5 voxels (n = 18); and the remaining studies were placed in the category "other" (n = 21).</p>
<p>Some studies included more than one semantic task or the same task with different stimuli. We examined each task/stimulus type separately when examining the influence of these variables on ATL activation (Factors 3 and 4). This resulted in 204 data points. For the other factors, when a study included more then one experiment, we counted each one separately only if two different participant groups were used. This resulted in 174 data points. In each case, the dependent variable was whether ATL activation (unilateral or bilateral) was found or not. For inclusion, evidence of ATL activation had to be presented in a table or clearly in a figure.</p>
<p>In the first analysis, ATL activation was counted as "present" when significant peaks or clusters were reported within the temporal or fusiform gyri, anterior to a y-coordinate of 0 in MNI standard space (Talairach coordinates were transferred to MNI space using a converter based on a nonlinear transformation provided by Brett-wwwneuro03.unimuenster.de/ger/t2tconv/ ). We examined the most anterior parts of the ATLs for two reasons: (i) the atrophy in SD is focussed on the temporal poles, suggesting this region has an essential role in semantic memory; and (ii) we wanted to investigate the effect of the susceptibility artifact, which is more severe in these anterior regions. However, SD atrophy usually encompasses additional areas that are more posterior than y = 0 (Nestor et al., 2006;Davies et al., 2004;Gorno-Tempini et al., 2004;Galton et al., 2001;Mummery et al., 2000). Therefore, in a second analysis focused on a more extensive ATL region, we also included peak activations with y-coordinates between 0 and −15.</p>
<p>In addition, we selected the "positive" studies (those that observed ATL activation) and examined the coordinates of peak activations in more detail. If studies included several peaks within the ATL, each peak was included as a separate datum. We investigated whether stimulus type influenced the position of peak activations in the ATL, using activation likelihood estimation (ALE; Laird et al., 2005). We followed the procedure as described in Laird et al. (2005). Smoothing was implemented with a 12-mm FWHM kernel; the permutation test included 5,000 permutations; the FDR was set at α = .05. This technique enables estimates of the likelihood of activation in specific voxels when inserting peak coordinates found in "positive studies." Therefore, we can examine if the location of peak activations varies depending on the stimulus type used in the task. Finally, we investigated the distribution of peaks across the two hemispheres for verbal and nonverbal tasks. MRIcro was used to display the activations  on an MNI template brain (www.sph.sc.edu/comd/rorden/ mricro.html).</p>
<p>RESULTS</p>
<p>Tables 1 and 2 provide an overview of the results.</p>
<p>(1) Studies using PET were substantially more likely to reveal ATL activation than those using fMRI. This effect, depicted in Figure 1, presumably reflects signal loss and distortion in ATL regions due to the magnetic susceptibility artifact.</p>
<p>(2) Studies with whole-brain coverage (e.g., FOV of 15 cm or greater) were more likely to show ATL activation than studies using an FOV of less then 15 cm. A restriction of the FOV might explain why quite a few PET studies do not find ATL activation, despite the absence of signal loss/ distortion (although the current data did not show a significant effect of FOV in PET studies separately).</p>
<p>(3) Studies including high baseline tasks were more likely to show ATL activation than studies using a low baseline tasks such as rest or fixation cross. (4) The inclusion of ATLs as an ROI significantly increased the likelihood of finding ATL activation. (5) Recent (2004Recent ( -2008 fMRI studies were more likely to show ATL activation than older studies (1999)(2000)(2001)(2002)(2003). (There were insufficient fMRI studies from 1994 to 1998, so this date range was removed from the analysis.) This improvement over time might reflect improvements in MR equipment and methods; however, recent studies were also more likely to use auditory sentences as stimuli. Auditory sentences were somewhat more likely to show ATL activation than other types of stimuli (see below), which could account for this effect.</p>
<p>In agreement with this, the effect of study date disappeared when sentence listening tasks were excluded from the analysis. The current meta-analyses did not find a significant influence of the following factors: number of participants, size of the smoothing kernel, and statistical threshold level. Although these factors are highly likely to influence the outcome of imaging studies, the examined studies were different in multiple ways, making it difficult to pick up all sources of variation. In addition, there were insufficient studies using semantic stimuli at the specific level to examine the hypothesis that specific-level concepts are more likely to show ATL activation than basic-level concepts. Table 2 shows the effects of stimulus type and semantic task. There was an influence of stimulus type: Auditory sentences were more likely to show ATL activation than Figure 1. Counts of fMRI and PET that did and did not yield significant ATL activation. other stimuli combined (see Figure 2). This effect was eliminated when auditory sentences were excluded from the analysis, suggesting that all other verbal and nonverbal stimulus types were equally likely to induce ATL activation. Studies using spoken sentences were more likely to show ATL activation compared with pictures, written sentences, and written words. However, the effect of stimulus type was not significant when comparing spoken sentences and spoken words. In addition, there were effects of task and sensory modality: (i) listening tasks were more likely to yield ATL activation compared with other tasks, and (ii) auditory tasks were more likely to show ATL activation then visual tasks. Both of these effects resulted from the inclusion of auditory sentences (and were not obtained when these stimuli were excluded from the analysis).</p>
<p>Why is auditory sentence comprehension more likely than any other task to elicit ATL activation? There are three possibilities. First, some researchers have suggested that the ATL is specialized for the computation of combinatorial meaning (Hickok &amp; Poeppel, 2007). Thus, deriving the overarching meaning from a spoken sentence might engage the ATL region. Second, a less exciting but equally plausible suggestion is that ATL activation will be stronger when this region is working more vigorously, for example, by processing a string of rapidly presented stimuli (the words within a sentence) or fine-grained semantic distinctions. This would fit with studies that have found ATL activation in nonsentence but rapidly presented visual stimuli (e.g., Devlin et al., 2000) and those that have contrasted different levels of semantic specificity (e.g., Rogers et al., 2006). Both the first and the second possibilities do not seem to fit so well with the finding from this metaanalysis that written sentence tasks are not more likely than other tasks to elicit ATL activation. This apparent contradiction should be treated with caution, however, because the other identified factors that influence the likelihood of ATL activation work to the advantage of auditory-based tasks. Thus, the third explanation follows from the proposal that auditory-verbal information is processed in the more superior aspects of the ATL, which is favored in the current analysis for several reasons: (i) this region is less affected by the magnetic susceptibility artifact than the inferior part of ATL; (ii) this area will be included in the imaging acquisition even with a restricted FOV; and (iii) the analyses above only examined ATL activation when y was anterior to 0. This might have favored superior peaks within the ATLs because the temporal lobe is tilted along the y-axis. In a second analysis, we examined peak activations with a y-value between 0 and −15 (16 additional studies) but the results were unchanged.</p>
<p>In the next analysis, we examined whether the distributions of the peak activations were influenced by stimulus type using ALE (Laird et al., 2005). Figure 3A shows the ALE results for each input modality. A key result from the ALE analysis was that pictorial and verbal tasks produced overlapping peaks especially in the ATLs. It should be noted that it is only possible to include the positive imaging results in the ALE analysis, and so if there are systematic bases in the literature (e.g., FOV, imaging method, etc., see previous section above), then these will be reflected in the ALE maps. For example, it could be that the lack of peaks within the inferior, anterior aspects of the temporal lobe sections in Figure 3A reflects limited FOV and susceptibility artifacts in fMRI. The second result from the ALE analysis was that where there were significant differences in the most anterior temporal areas (see Figure 3B), these were graded differences in the sense that the region was activated by both pictorial and verbal tasks with a superior-inferior gradation such that the distribution of peaks tended to be more superior for verbal tasks and the distribution for picture tasks was skewed inferiorly. Moving posteriorly, the distributions for verbal and pictorial tasks became gradually more distinct, with a clearer separation of superior-verbal peaks and inferiorpictorial peaks. These results are consistent with Plautʼs (2002) computational model in which function within a general semantic system is graded by the connection distance. This differential connectivity produces graded specialization such that areas closest to input modalities (verbal, visual, etc.) are relatively more important for semantic tasks in that domain, whereas regions furthest from any input (e.g., the ATL) are most multimodal.</p>
<p>To ensure that this second result (graded specialization) did not reflect technical issues alone, we examined whether peaks associated with verbal stimuli were more likely have a restricted FOV than those elicited by picture tasks. We were able to calculate the FOV for 17 picture peaks; only 2 of these had an FOV of more than 15 cm. Similar results were obtained for studies using visual and auditory words; whole-brain coverage was used in 4/13 and 0/4 studies, respectively. In contrast, studies using auditory and visual sentences (which were, on the whole, more recent) were more likely to have unrestricted FOVs: There was whole-brain coverage for 13/33 auditory sentence peaks and 8/12 visual sentence peaks. There was a significant difference in FOV between picture and auditory sentence peaks, χ 2 (1) = 4.2, p = .04, but not between pictures and other verbal tasks. Thus, although FOV issues might contribute to the apparent tendency for auditory sentence tasks to successfully elicit ATL activation (discussed above), this technical issue is unlikely to be the sole cause of the inferior/superior gradation observed for pictures versus verbal stimuli.</p>
<p>The final analysis confirmed that there was no significant difference in the distribution of peaks across the two hemispheres for semantic tasks involving pictures, single words, and sentences (combining visual and auditory presentation)-the ALE maps clearly demonstrate a bilateral distribution of peaks (see Figure 3). Instead, all stimuli types resulted in slightly more left than right-sided peaks. This is summarized in Figure 4. These findings are consistent with the notion of an amodal semantic system in bilateral ATLs.</p>
<p>DISCUSSION</p>
<p>Although studies of patients with SD and HSVE suggest that the bilateral ATLs are a critical substrate for semantic memory, functional neuroimaging studies have not consistently observed activation in this region. In contrast, other areas within the semantic network ( left inferior frontal and temporo-parietal cortex) are reliably activated, and these areas also converge with the findings from aphasiological research. As a consequence, some researchers consider the ATLs to form a "semantic hub" (Lambon Ralph et al., 2009;Patterson et al., 2007;Rogers et al., 2004), whereas other influential models of the neural basis of semantic memory do not ascribe a key role to this brain region (Martin, 2007;Catani &amp; Ffytche, 2005;Booth et al., 2002). We conducted a meta-analysis to investigate potential causes of this inconsistency in the neuroimaging literature. Specifically, we identified several methodological factors that influence the likelihood of observing ATL activation in PET and fMRI studies, helping to clarify the role of this region in semantic cognition.</p>
<p>One key finding was that PET studies were considerably more likely to observe ATL activation than fMRI. The fMRI Figure 3. ALE results for ATL voxels. (A) ALE overall results for picture (yellow) and verbal tasks ( blue). (B) ALE subtractions-relative differences between picture (yellow) versus verbal tasks ( blue). These slice series show the results from various ALE analyses. Coronal slices are included from y = 2 to y = 22, thus covering the anterior parts of the temporal lobe. It should be noted that these analyses can only be based on positive studiesthat is, those that demonstrated significant ATL activations. As such, they are subject to the same biases as found in the literature as a wholeincluding imaging modality, magnetic susceptibility artefacts, and FOV restrictions (see text for details). These factors are likely to be the cause of the lack of inferior ATL peaks in the ALE results (the area of maximal MR distortion and the area most commonly omitted if a restricted FOV is used). Panel A shows the ALE overlays for the distribution of peaks in each verbal task (yellow) against those involving pictures (blue). Areas of overlap can be seen in green. Panel B shows the relative differences between the pair of tasksthat is, the difference is graded rather than absolute. Note that because ALE analyses use a smoothing kernel, peaks within the superior temporal region will be smoothed and occasionally bleed over into inferior frontal and anterior insular areas. signal from ATL and orbito-frontal regions is known to be influenced by a "susceptibility artifact," caused by the differing magnetic susceptibilities of brain, bone, and air. This produces signal loss and distortions, with the consequence that activation in the ATL is less likely to reach the threshold for significance (Weiskopf, Hutton, Josephs, &amp; Deichmann, 2006;Schmithorst et al., 2001). PET is not sensitive to this susceptibility artifact, and this is likely to explain why PET studies were more likely than fMRI investigations to report ATL activations for semantic tasks. This key result from the meta-analysis aligns closely with Devlin et al. (2000) who demonstrated significant ATL activation in a semantic task using PET but not fMRI in a direct comparison of these two imaging methodologies. Future fMRI studies might use a distortion correction and/or optimal acquisition parameters to overcome the susceptibility artifact (Embleton, Lambon Ralph, &amp; Parker, 2006;Weiskopf et al., 2006;Bowtell, McIntyre, Commandre, Glover, &amp; Mansfield, 1994). Indeed, we have recently developed a distortion-corrected fMRI method that yielded significant ATL activation for the semantic task of Devlin et al. (see also Visser, Embleton, Jefferies, Parker, &amp; Lambon Ralph, submitted). Future studies using distortion-corrected fMRI will allow more detailed explorations of the role of the ATLs in semantic cognition.</p>
<p>Another important finding was that restrictions of the FOV were associated with an absence of ATL activation: Studies that used an FOV of more than 15 cm were more likely to report ATL activation during semantic tasks. When the FOV is less than 15 cm, inferior parts of the ATLs may be missed during image acquisition. As a consequence, these imaging studies were actually unable to retrieve signals from the ATLs.</p>
<p>Two other aspects of the experimental design and analyses also turned out to be important. First, the use of a high baseline task compared with a low baseline task positively influenced the likelihood of ATL activation. Low baseline tasks, such as rest or passive viewing of a fixation cross, have been found to activate the same areas as semantic tasks, possibly because of ongoing semantic processes related to "idle thought" or internal speech (Binder et al., 1999). Therefore, low baseline tasks are likely to remove semantic areas in subtraction analyses. Second, studies that included the ATL as an ROI were more likely to show ATL activation. This suggests that neuroimaging studies are not always sensitive enough to detect activations in the ATL; however, ROI analyses increase statistical power and make it more likely that ATL activation will reach the threshold for significance.</p>
<p>In our meta-analysis, the likelihood of ATL activation was also influenced by the type of semantic stimuli used. Studies using auditory sentences were more likely to find ATL activation than studies using other types of stimuli, such as visual words and pictures. There are three possible reasons for this result. First, some researchers have suggested that the ATL is specialized for the computation of combinatorial meaning (Hickok &amp; Poeppel, 2007). Thus, deriving the overarching meaning from a spoken sentence might engage the ATL region. Second, a less exciting but equally plausible suggestion is that ATL activation will be stronger when this region is worked more vigorously, for example, by processing a string of rapidly presented stimuli (the words within a sentence) or finegrained semantic distinctions. This would fit with studies that have found ATL activation in nonsentence but rapidly presented visual stimuli (e.g., Devlin et al., 2000) and those that have contrasted different levels of semantic specificity (e.g., Rogers et al., 2006). Third, auditory sentences might benefit from the fact that auditory-verbal information is processed in the more superior aspects of the ATL, which is favored in the current literature for the reasons noted above, in particular, the greater magnetic susceptibility artifact in the inferior aspects of the ATL and the restricted FOV used in many tasks.</p>
<p>Other task differences, such as the use of verbal and nonverbal stimuli, did not influence the likelihood of ATL activation. This fits well with the view that the ATL acts as a semantic hub bringing together modality-specific information to form amodal semantic representations and to compute semantic generalizations (Lambon Ralph  Patterson et al., 2007;Rogers et al., 2004). Several lines of evidence now converge on this conclusion: (1) Patients with SD and HSVE, who have damage to the ATL, have an amodal semantic impairment affecting the comprehension of words, pictures, faces, objects, sounds, and smells (Coccia et al., 2004;Bozeat et al., 2000).</p>
<p>(2) Within the functional neuroimaging literature, conjunction analyses for individual studies have revealed common areas of activation within the ATL for (i) words and pictures (Bright, Moss, &amp; Tyler, 2004;Vandenberghe, Price, Wise, Josephs, &amp; Frackowiak, 1996) and (ii) pictures and environmental sounds (Tranel, Grabowski, Lyon, &amp; Damasio, 2005). (3) Recent studies have also shown that rTMS of the ATL selectively disrupts semantic judgments for both words and pictures (Lambon Ralph et al., 2009;Pobric et al., 2007). A key question that arises from this conclusion is why there is a need for an amodal ATL contribution to semantic cognition. Although modalityspecific cortical areas play an important role in semantic processing, information needs to be combined across modalities to allow the correct conceptual relationships to be discerned independent of surface similarities. This is because semantically related objects, such as a banana and a kiwi, may be dissimilar in several key modalities (e.g., shape, color, texture), and so the statistical structure of modality-specific regions is only a partial guide to semantic similarities and relationships (Lambon .</p>
<p>The current meta-analysis revealed that both words and pictures activated both left and right ATL, with no clear hemispheric specialization for either type of input. This finding is again consistent with studies of SD and HSVE, in which severe semantic impairment follows bilateral damage to ATLs. Moreover, studies that have directly compared rTMS stimulation of left versus right ATLs have observed equivalent effects on semantic decision times for words and pictures (Pobric et al., 2007). Given that semantic memory is core to many of our everyday verbal and nonverbal activities, then it may be that this bilateral ATL representation of amodal semantics has beneficial effects in terms of increasing the robustness of the system to damage.</p>
<p>Even in an amodal system, the specific pattern of activation within the ATL might be influenced in a graded fashion by the modality of the task due to variations in connectivity with modality-specific areas in posterior temporal cortex (Plaut, 2002). The meta-analysis revealed that the distribution of ATL peak activations for semantic tasks using picture and verbal stimuli had a graded inferiorsuperior difference in terms of the skew of each overlapping distribution. As noted in the Introduction, inferior regions in posterior temporal cortex are thought to be critical for visual object recognition (Chao et al., 2002(Chao et al., , 1999Moore &amp; Price, 1999;Martin et al., 1996), whereas superior temporal areas are involved in the comprehension of spoken words and sentences (Scott &amp; Johnsrude, 2003;Scott et al., 2000;Demonet et al., 1992). Consequently, inferior and superior regions within the ATL might receive stronger inputs from processing pathways in (i) posterior inferior temporal cortex (for pictures) and (ii) superior temporal areas (for words). A similar divergence between pictures and auditory stimuli (including speech) in the ATL was noted in a meta-analysis by Olson, Plotzker, and Ezzyat (2007), focussed on social and emotional processing.</p>
<p>Our meta-analysis examined the location of peaks within more extensive areas of ATL activation. Although there were significant differences in the location of these peaks for pictures and words, they were highly overlapping, in line with the findings of conjunction analyses for individual studies (Tranel et al., 2005;Bright et al., 2004;Vandenberghe et al., 1996). This indicates that there is not an absolute distinction between semantic processing for different stimuli types in the ATLs. Instead, the verbal processing stream within superior temporal cortex may converge in the ATL on a parallel inferior temporal stream that allows semantic access from pictures. This would allow the ATL to form amodal semantic representations and make appropriate generalizations based on central semantic relationships rather than superficial similarities found in one particular domain (Lambon Ralph et al., 2009).</p>
<p>Figure 2 .
2Counts of imaging studies showing ATL for different stimulus types.</p>
<p>Figure 4 .
4Counts of peak activations within the left and right ATL for different stimuli types.</p>
<p>Table 1 .
1Effects of Experimental Design and Analysis Variables on the Likelihood of ATL ActivationThese analyses included 174 data points. ns = not significant; NE = not enough studies; n/a = not applicable.This analysis did not include the oldest articles, see text.Factors </p>
<p>Imaging Method Included in the Meta-analysis </p>
<p>PET and fMRI 
PET Only 
fMRI Only </p>
<p>PET versus fMRI 
χ 2 (1) = 13.3, p &lt; .001 
n/a 
n/a </p>
<p>FOV less than or more than 15 cm 
χ 2 (1) = 6.2, p = .013 
ns 
NE </p>
<p>Baseline task: high versus low 
χ 2 (1) = 4.6, p = .032 
NE 
ns </p>
<p>ROI analysis 
χ 2 (1) = 4.7, p = .031 
NE 
NE </p>
<p>Year of publication 
ns 
ns 
χ 2 (1) = 7.6, p = .006 a </p>
<p>No. participants: high versus low 
ns 
ns 
ns </p>
<p>Size of smoothing kernel 
n/a 
ns 
ns </p>
<p>Threshold level 
ns 
ns 
ns </p>
<p>a </p>
<p>Table 2 .
2Effects of Task and Stimulus Type on the Likelihood of ATL ActivationThese analyses included 204 data points. ns = not significant; NE = not enough studies.Factors 
Details </p>
<p>ATL Activation </p>
<p>PET and fMRI 
PET 
fMRI </p>
<p>Task 
Listening, reading, naming, 
semantic judgments </p>
<p>χ 2 (3) = 13.0, p = .005 
NE 
NE </p>
<p>Same analysis with auditory 
sentences excluded </p>
<p>ns 
NE 
NE </p>
<p>Modality 
Auditory versus visual 
χ 2 (1) = 18.0, p &lt; .0001 
χ 2 (1) = 7.1, p = .008 
χ 2 (1) = 13.1, p = .0001 </p>
<p>Same analysis with auditory 
sentences excluded </p>
<p>χ 2 (1) = 6.3, p = .12 
ns 
ns </p>
<p>Stimuli 
All types 
χ 2 (4) = 17.8, p = .001 
NE 
NE </p>
<p>Same analysis with auditory 
sentences excluded </p>
<p>ns 
NE 
NE </p>
<p>Auditory sentences versus 
pictures </p>
<p>χ 2 (1) = 9.3, p = .002 
NE 
χ 2 (1) = 6.8, p = .009 </p>
<p>Auditory sentences versus 
written sentences </p>
<p>χ 2 (1) = 9.0, p = .003 
NE 
χ 2 (1) = 9.3, p = .002 </p>
<p>Auditory sentences versus 
auditory words </p>
<p>ns 
NE 
NE </p>
<p>Auditory sentences versus 
written words </p>
<p>χ 2 (1) = 12.8, p = .001 
NE 
χ 2 (1) = 12.0, p = .001 </p>
<p>Downloaded from http://www.mitpressjournals.org/doi/pdf/10.1162/jocn.2009.21309 by guest on 25 April 2021
AcknowledgmentsThis study was supported by an MRC program grant (G0501632) and an MRC Pathfinder grant (G0300952).Reprint requests should be sent to M. A. Lambon Ralph, Neuroscience and Aphasia Research Unit (NARU), School of Psychological Sciences, University of Manchester, Zochonis Building, Oxford Road, Manchester, M13 9PL, UK, or via e-mail: matt. lambon-ralph@manchester.ac.uk.
Unexpected brain-language relationships in aphasia: Evidence from transcortical sensory aphasia associated with frontal lobe lesions. M L Berthier, Aphasiology. 15Berthier, M. L. (2001). Unexpected brain-language relationships in aphasia: Evidence from transcortical sensory aphasia associated with frontal lobe lesions. Aphasiology, 15, 99-130.</p>
<p>Conceptual processing during the conscious resting state: A functional MRI study. J R Binder, J A Frost, T A Hammeke, P S F Bellgowan, S M Rao, R W Cox, Journal of Cognitive Neuroscience. 11Binder, J. R., Frost, J. A., Hammeke, T. A., Bellgowan, P. S. F., Rao, S. M., &amp; Cox, R. W. (1999). Conceptual processing during the conscious resting state: A functional MRI study. Journal of Cognitive Neuroscience, 11, 80-93.</p>
<p>Effects of stimulus rate on signal response during functional magnetic resonance imaging of auditory cortex. J R Binder, S M Rao, T A Hammeke, J A Frost, P A Bandettini, J S Hyde, Cognitive Brain Research. 2Binder, J. R., Rao, S. M., Hammeke, T. A., Frost, J. A., Bandettini, P. A., &amp; Hyde, J. S. (1994). Effects of stimulus rate on signal response during functional magnetic resonance imaging of auditory cortex. Cognitive Brain Research, 2, 31-38.</p>
<p>Modality independence of word comprehension. J R Booth, D D Burman, J R Meyer, D R Gitelman, T B Parrish, M M Mesulam, Human Brain Mapping. 16Booth, J. R., Burman, D. D., Meyer, J. R., Gitelman, D. R., Parrish, T. B., &amp; Mesulam, M. M. (2002). Modality independence of word comprehension. Human Brain Mapping, 16, 251-261.</p>
<p>N M Borden, 3D angiographic atlas of neurovascular anatomy and pathology. CambridgeCambridge University PressBorden, N. M. (2006). 3D angiographic atlas of neurovascular anatomy and pathology. Cambridge: Cambridge University Press.</p>
<p>Correction of geometric distortion in echo planar images. R W Bowtell, D J O Mcintyre, M J Commandre, P M Glover, P Mansfield, Proceedings of the Society of Magnetic Resonance. the Society of Magnetic ResonanceSan FranciscoBowtell, R. W., McIntyre, D. J. O., Commandre, M. J., Glover, P. M., &amp; Mansfield, P. (1994). Correction of geometric distortion in echo planar images. Proceedings of the Society of Magnetic Resonance, San Francisco.</p>
<p>Non-verbal semantic impairment in semantic dementia. S Bozeat, M A Lambon Ralph, K Patterson, P Garrard, J R Hodges, Neuropsychologia. 38Bozeat, S., Lambon Ralph, M. A., Patterson, K., Garrard, P., &amp; Hodges, J. R. (2000). Non-verbal semantic impairment in semantic dementia. Neuropsychologia, 38, 1207-1215.</p>
<p>Unitary vs. Multiple semantics: PET studies of word and picture processing. P Bright, H Moss, L K Tyler, Brain and Language. 89Bright, P., Moss, H., &amp; Tyler, L. K. (2004). Unitary vs. Multiple semantics: PET studies of word and picture processing. Brain and Language, 89, 417-432.</p>
<p>The rises and falls of disconnection syndromes. M Catani, D H Ffytche, Brain. 128Catani, M., &amp; Ffytche, D. H. (2005). The rises and falls of disconnection syndromes. Brain, 128, 2224-2239.</p>
<p>Attribute-based neural substrates in temporal cortex for perceiving and knowing about objects. L L Chao, J V Haxby, A Martin, Nature Neuroscience. 2Chao, L. L., Haxby, J. V., &amp; Martin, A. (1999). Attribute-based neural substrates in temporal cortex for perceiving and knowing about objects. Nature Neuroscience, 2, 913-919.</p>
<p>Experiencedependent modulation of category-related cortical activity. L L Chao, J Weisberg, A Martin, Cerebral Cortex. 12Chao, L. L., Weisberg, J., &amp; Martin, A. (2002). Experience- dependent modulation of category-related cortical activity. Cerebral Cortex, 12, 545-551.</p>
<p>Word frequency and subsequent memory effects studied using event-related fMRI. M W L Chee, C Westphal, J Goh, S Graham, A W Song, Neuroimage. 20Chee, M. W. L., Westphal, C., Goh, J., Graham, S., &amp; Song, A. W. (2003). Word frequency and subsequent memory effects studied using event-related fMRI. Neuroimage, 20, 1042-1051.</p>
<p>On the status of object concepts in aphasia. H Chertkow, D Bub, C Deaudon, V Whitehead, Brain and Language. 58Chertkow, H., Bub, D., Deaudon, C., &amp; Whitehead, V. (1997). On the status of object concepts in aphasia. Brain and Language, 58, 203-232.</p>
<p>Semantic memory is an amodal, dynamic system: Evidence from the interaction of naming and object use in semantic dementia. M Coccia, M Bartolini, S Luzzi, L Provinciali, M A Ralph, Cognitive Neuropsychology. 21Coccia, M., Bartolini, M., Luzzi, S., Provinciali, L., &amp; Lambon Ralph, M. A. (2004). Semantic memory is an amodal, dynamic system: Evidence from the interaction of naming and object use in semantic dementia. Cognitive Neuropsychology, 21, 513-527.</p>
<p>P M Conn, Neuroscience in medicine. Totowa, NJHumana Press2nd ed.Conn, P. M. (2003). Neuroscience in medicine (2nd ed.). Totowa, NJ: Humana Press.</p>
<p>The human perirhinal cortex and semantic memory. R R Davies, K S Graham, J H Xuereb, G B Williams, J R Hodges, European Journal of Neuroscience. 20Davies, R. R., Graham, K. S., Xuereb, J. H., Williams, G. B., &amp; Hodges, J. R. (2004). The human perirhinal cortex and semantic memory. European Journal of Neuroscience, 20, 2441-2446.</p>
<p>Semantic encoding and retrieval in the left inferior prefrontal cortex: A functional MRI study of task-difficulty and process specificity. J B Demb, J E Desmond, A D Wagner, C J Vaidya, G H Glover, J D E Gabrieli, Journal of Neuroscience. 15Demb, J. B., Desmond, J. E., Wagner, A. D., Vaidya, C. J., Glover, G. H., &amp; Gabrieli, J. D. E. (1995). Semantic encoding and retrieval in the left inferior prefrontal cortex: A functional MRI study of task-difficulty and process specificity. Journal of Neuroscience, 15, 5870-5878.</p>
<p>The anatomy of phonological and semantic processing in normal subjects. J F Demonet, F Chollet, S Ramsay, D Cardebat, J L Nespoulous, R Wise, Brain. 115Demonet, J. F., Chollet, F., Ramsay, S., Cardebat, D., Nespoulous, J. L., Wise, R., et al. (1992). The anatomy of phonological and semantic processing in normal subjects. Brain, 115, 1753-1768.</p>
<p>Neural correlates of remembering/knowing famous people: An event-related fMRI study. E Denkova, A Botzung, L Manning, Neuropsychologia. 44Denkova, E., Botzung, A., &amp; Manning, L. (2006). Neural correlates of remembering/knowing famous people: An event-related fMRI study. Neuropsychologia, 44, 2783-2791.</p>
<p>Susceptibility-induced loss of signal: Comparing PET and fMRI on a semantic task. J T Devlin, R P Russell, M H Davis, C J Price, J Wilson, H E Moss, Neuroimage. 11Devlin, J. T., Russell, R. P., Davis, M. H., Price, C. J., Wilson, J., Moss, H. E., et al. (2000). Susceptibility-induced loss of signal: Comparing PET and fMRI on a semantic task. Neuroimage, 11, 589-600.</p>
<p>A combined distortion corrected protocol for diffusion weighted tractography and fMRI. K Embleton, M A Lambon Ralph, G J Parker, Proceedings of the International Society for Magnetic Resonance in Medicine. the International Society for Magnetic Resonance in MedicineEmbleton, K., Lambon Ralph, M. A., &amp; Parker, G. J. M. (2006). A combined distortion corrected protocol for diffusion weighted tractography and fMRI. Proceedings of the International Society for Magnetic Resonance in Medicine.</p>
<p>The role of left prefrontal cortex in language and memory. J D E Gabrieli, R A Poldrack, J E Desmond, Proceedings of the National Academy of Sciences. the National Academy of SciencesU.S.A.95Gabrieli, J. D. E., Poldrack, R. A., &amp; Desmond, J. E. (1998). The role of left prefrontal cortex in language and memory. Proceedings of the National Academy of Sciences, U.S.A., 95, 906-913.</p>
<p>Different patterns of famous people recognition disorders in patients with right and left anterior temporal lesions: A systematic review. G Gainotti, Neuropsychologia. 45Gainotti, G. (2007). Different patterns of famous people recognition disorders in patients with right and left anterior temporal lesions: A systematic review. Neuropsychologia, 45, 1591-1607.</p>
<p>Differing patterns of temporal atrophy in Alzheimerʼs disease and semantic dementia. C J Galton, K Patterson, K Graham, M A Lambon Ralph, G Williams, N Antoun, Neurology. 57Galton, C. J., Patterson, K., Graham, K., Lambon Ralph, M. A., Williams, G., Antoun, N., et al. (2001). Differing patterns of temporal atrophy in Alzheimerʼs disease and semantic dementia. Neurology, 57, 216-225.</p>
<p>Dissociation of automatic and strategic lexical-semantics: Functional magnetic resonance imaging evidence for differing roles of multiple frontotemporal regions. B T Gold, D A Balota, S J Jones, D K Powell, C D Smith, A H Andersen, Journal of Neuroscience. 26Gold, B. T., Balota, D. A., Jones, S. J., Powell, D. K., Smith, C. D., &amp; Andersen, A. H. (2006). Dissociation of automatic and strategic lexical-semantics: Functional magnetic resonance imaging evidence for differing roles of multiple frontotemporal regions. Journal of Neuroscience, 26, 6523-6532.</p>
<p>Cognition and anatomy in three variants of primary progressive aphasia. M L Gorno-Tempini, N F Dronkers, K P Rankin, J M Ogar, L Phengrasamy, H J Rosen, Annals of Neurology. 55Gorno-Tempini, M. L., Dronkers, N. F., Rankin, K. P., Ogar, J. M., Phengrasamy, L., Rosen, H. J., et al. (2004). Cognition and anatomy in three variants of primary progressive aphasia. Annals of Neurology, 55, 335-346.</p>
<p>The cortical organization of speech processing. G Hickok, D Poeppel, Nature Reviews Neuroscience. 8Hickok, G., &amp; Poeppel, D. (2007). The cortical organization of speech processing. Nature Reviews Neuroscience, 8, 393-402.</p>
<p>Semantic dementia: Progressive fluent aphasia with temporal-lobe atrophy. J R Hodges, K Patterson, S Oxbury, E Funnell, Brain. 115Hodges, J. R., Patterson, K., Oxbury, S., &amp; Funnell, E. (1992). Semantic dementia: Progressive fluent aphasia with temporal-lobe atrophy. Brain, 115, 1783-1806.</p>
<p>Refractory effects in stroke aphasia: A consequence of poor semantic control. E Jefferies, S S Baker, M Doran, M A Ralph, Neuropsychologia. 45Jefferies, E., Baker, S. S., Doran, M., &amp; Lambon Ralph, M. A. (2007). Refractory effects in stroke aphasia: A consequence of poor semantic control. Neuropsychologia, 45, 1065-1079.</p>
<p>Semantic impairment in stroke aphasia versus semantic dementia: A case-series comparison. E Jefferies, M A Ralph, Brain. 129Jefferies, E., &amp; Lambon Ralph, M. A. (2006). Semantic impairment in stroke aphasia versus semantic dementia: A case-series comparison. Brain, 129, 2132-2147.</p>
<p>Deficits of knowledge versus executive control in semantic cognition: Insights from cued naming. E Jefferies, K Patterson, M A Ralph, Neuropsychologia. 46Jefferies, E., Patterson, K., &amp; Lambon Ralph, M. A. (2008). Deficits of knowledge versus executive control in semantic cognition: Insights from cued naming. Neuropsychologia, 46, 649-658.</p>
<p>Functional MRI: An introduction to methods. P Jezzard, P M Matthews, S M Smith, Oxford University PressOxfordJezzard, P., Matthews, P. M., &amp; Smith, S. M. (2001). Functional MRI: An introduction to methods. Oxford: Oxford University Press.</p>
<p>Herpes-simplex encephalitis: Long-term magnetic-resonance-imaging and neuropsychological profile. N Kapur, S Barker, E H Burrows, D Ellison, J Brice, L S Illis, Journal of Neurology Neurosurgery and Psychiatry. 57Kapur, N., Barker, S., Burrows, E. H., Ellison, D., Brice, J., Illis, L. S., et al. (1994). Herpes-simplex encephalitis: Long-term magnetic-resonance-imaging and neuropsychological profile. Journal of Neurology Neurosurgery and Psychiatry, 57, 1334-1342.</p>
<p>Ale meta-analysis: Controlling the false discovery rate and performing statistical contrasts. A R Laird, P M Fox, C J Price, D C Glahn, A M Uecker, J L Lancaster, Human Brain Mapping. 25Laird, A. R., Fox, P. M., Price, C. J., Glahn, D. C., Uecker, A. M., Lancaster, J. L., et al. (2005). Ale meta-analysis: Controlling the false discovery rate and performing statistical contrasts. Human Brain Mapping, 25, 155-164.</p>
<p>Neural basis of category-specific semantic deficits for living things: Evidence from semantic dementia, HSVE and a neural network model. Lambon Ralph, M A Lowe, C Rogers, T T , Brain. 130Lambon Ralph, M. A., Lowe, C., &amp; Rogers, T. T. (2007). Neural basis of category-specific semantic deficits for living things: Evidence from semantic dementia, HSVE and a neural network model. Brain, 130, 1127-1137.</p>
<p>No right to speak? The relationship between object naming and semantic impairment: Neuropsychological abstract evidence and a computational model. Lambon Ralph, M A Mcclelland, J L Patterson, K Galton, C J Hodges, J R , Journal of Cognitive Neuroscience. 13Lambon Ralph, M. A., McClelland, J. L., Patterson, K., Galton, C. J., &amp; Hodges, J. R. (2001). No right to speak? The relationship between object naming and semantic impairment: Neuropsychological abstract evidence and a computational model. Journal of Cognitive Neuroscience, 13, 341-356.</p>
<p>Generalization and differentiation in semantic memory: Insights from semantic dementia. Lambon Ralph, M A Patterson, K , Cognitive Neuroscience. 1124Lambon Ralph, M. A., &amp; Patterson, K. (2008). Generalization and differentiation in semantic memory: Insights from semantic dementia. Cognitive Neuroscience, 1124, 61-76.</p>
<p>Conceptual knowledge is underpinned by the temporal pole bilaterally: Convergent evidence from rTMS. Lambon Ralph, M A Pobric, G Jefferies, E , Cerebral Cortex. 19Lambon Ralph, M. A., Pobric, G., &amp; Jefferies, E. (2009). Conceptual knowledge is underpinned by the temporal pole bilaterally: Convergent evidence from rTMS. Cerebral Cortex, 19, 832-838.</p>
<p>Coherent concepts are computed in the anterior temporal lobes. Lambon Ralph, M A Sage, K Jones, R W Mayberry, E J , Proceedings of the National Academy of Sciences. the National Academy of SciencesU.S.A.107Lambon Ralph, M. A., Sage, K., Jones, R. W., &amp; Mayberry, E. J. (2010). Coherent concepts are computed in the anterior temporal lobes. Proceedings of the National Academy of Sciences, U.S.A., 107, 2712-2722.</p>
<p>The representation of object concepts in the brain. A Martin, Annual Review of Psychology. 58Martin, A. (2007). The representation of object concepts in the brain. Annual Review of Psychology, 58, 25-45.</p>
<p>Neural correlates of category-specific knowledge. A Martin, C L Wiggs, L G Ungerleider, J V Haxby, Nature. 379Martin, A., Wiggs, C. L., Ungerleider, L. G., &amp; Haxby, J. V. (1996). Neural correlates of category-specific knowledge. Nature, 379, 649-652.</p>
<p>Semantic relevance explains category effects in medial fusiform gyri. A Mechelli, G Sartori, P Orlandi, C J Price, Neuroimage. 30Mechelli, A., Sartori, G., Orlandi, P., &amp; Price, C. J. (2006). Semantic relevance explains category effects in medial fusiform gyri. Neuroimage, 30, 992-1002.</p>
<p>Effects of left frontal lesions on the selection of context-appropriate meanings. C Metzler, Neuropsychology. 15Metzler, C. (2001). Effects of left frontal lesions on the selection of context-appropriate meanings. Neuropsychology, 15, 315-328.</p>
<p>A functional neuroimaging study of the variables that generate category-specific object processing differences. C J Moore, C J Price, Brain. 122Moore, C. J., &amp; Price, C. J. (1999). A functional neuroimaging study of the variables that generate category-specific object processing differences. Brain, 122, 943-962.</p>
<p>A voxel-based morphometry study of semantic dementia: Relationship between temporal lobe atrophy and semantic memory. C J Mummery, K Patterson, C J Price, J Ashburner, R S J Frackowiak, J R Hodges, Annals of Neurology. 47Mummery, C. J., Patterson, K., Price, C. J., Ashburner, J., Frackowiak, R. S. J., &amp; Hodges, J. R. (2000). A voxel-based morphometry study of semantic dementia: Relationship between temporal lobe atrophy and semantic memory. Annals of Neurology, 47, 36-45.</p>
<p>Declarative memory impairments in Alzheimerʼs disease and semantic dementia. P J Nestor, T D Fryer, J R Hodges, Neuroimage. 30Nestor, P. J., Fryer, T. D., &amp; Hodges, J. R. (2006). Declarative memory impairments in Alzheimerʼs disease and semantic dementia. Neuroimage, 30, 1010-1020.</p>
<p>Elucidating the nature of deregulated semantic cognition in semantic aphasia: Evidence for the roles of prefrontal and temporo-parietal cortices. K A Noonan, E Jefferies, F Corbett, M A Ralph, Journal of Cognitive Neuroscience. in pressNoonan, K. A., Jefferies, E., Corbett, F., &amp; Lambon Ralph, M. A. (in press). Elucidating the nature of deregulated semantic cognition in semantic aphasia: Evidence for the roles of prefrontal and temporo-parietal cortices. Journal of Cognitive Neuroscience.</p>
<p>Temporal lobe lesions and semantic impairment: A comparison of herpes simplex virus encephalitis and semantic dementia. U Noppeney, K Patterson, L K Tyler, H Moss, E A Stamatakis, P Bright, Brain. 130Noppeney, U., Patterson, K., Tyler, L. K., Moss, H., Stamatakis, E. A., Bright, P., et al. (2007). Temporal lobe lesions and semantic impairment: A comparison of herpes simplex virus encephalitis and semantic dementia. Brain, 130, 1138-1147.</p>
<p>Identification of lexicalphonological networks in the superior temporal sulcus using functional magnetic resonance imaging. K Okada, G Hickok, NeuroReport. 17Okada, K., &amp; Hickok, G. (2006). Identification of lexical- phonological networks in the superior temporal sulcus using functional magnetic resonance imaging. NeuroReport, 17, 1293-1296.</p>
<p>Word length modulates neural activity in auditory cortex during covert object naming. K Okada, K R Smith, C Humphries, G Hickok, NeuroReport. 14Okada, K., Smith, K. R., Humphries, C., &amp; Hickok, G. (2003). Word length modulates neural activity in auditory cortex during covert object naming. NeuroReport, 14, 2323-2326.</p>
<p>The enigmatic temporal pole: A review of findings on social and emotional processing. I R Olson, A Plotzker, Y Ezzyat, Brain. 130Olson, I. R., Plotzker, A., &amp; Ezzyat, Y. (2007). The enigmatic temporal pole: A review of findings on social and emotional processing. Brain, 130, 1718-1731.</p>
<p>Where do you know what you know? The representation of semantic knowledge in the human brain. K Patterson, P J Nestor, T T Rogers, Nature Reviews Neuroscience. 8Patterson, K., Nestor, P. J., &amp; Rogers, T. T. (2007). Where do you know what you know? The representation of semantic knowledge in the human brain. Nature Reviews Neuroscience, 8, 976-987.</p>
<p>Graded modality-specific specialisation in semantics: A computational account of optic aphasia. D C Plaut, Cognitive Neuropsychology. 19Plaut, D. C. (2002). Graded modality-specific specialisation in semantics: A computational account of optic aphasia. Cognitive Neuropsychology, 19, 603-639.</p>
<p>Anterior temporal lobes mediate semantic representation: Mimicking semantic dementia by using rTMS in normal participants. G Pobric, E Jefferies, M A Ralph, Proceedings of the National Academy of Sciences, U.S.A. 104Pobric, G., Jefferies, E., &amp; Lambon Ralph, M. A. (2007). Anterior temporal lobes mediate semantic representation: Mimicking semantic dementia by using rTMS in normal participants. Proceedings of the National Academy of Sciences, U.S.A., 104, 20137-20141.</p>
<p>Hearing and saying: The functional neuro-anatomy of auditory word processing. C J Price, R J S Wise, E A Warburton, C J Moore, D Howard, K Patterson, Brain. 119Price, C. J., Wise, R. J. S., Warburton, E. A., Moore, C. J., Howard, D., Patterson, K., et al. (1996). Hearing and saying: The functional neuro-anatomy of auditory word processing. Brain, 119, 919-931.</p>
<p>Anterior temporal cortex and semantic memory: Reconciling findings from neuropsychology and functional imaging. T T Rogers, J Hocking, U Noppeney, A Mechelli, M L Gorno-Tempini, K Patterson, Cognitive, Affective, and Behavioral Neuroscience. 6Rogers, T. T., Hocking, J., Noppeney, U., Mechelli, A., Gorno- Tempini, M. L., Patterson, K., et al. (2006). Anterior temporal cortex and semantic memory: Reconciling findings from neuropsychology and functional imaging. Cognitive, Affective, and Behavioral Neuroscience, 6, 201-213.</p>
<p>Structure and deterioration of semantic memory: A neuropsychological and computational investigation. T T Rogers, M A Ralph, P Garrard, S Bozeat, J L Mcclelland, J R Hodges, Psychological Review. 111Rogers, T. T., Lambon Ralph, M. A., Garrard, P., Bozeat, S., McClelland, J. L., Hodges, J. R., et al. (2004). Structure and deterioration of semantic memory: A neuropsychological and computational investigation. Psychological Review, 111, 205-235.</p>
<p>Simultaneous correction of ghost and geometric distortion artifacts in EPI using a multi-echo reference scan. V J Schmithorst, D J Dardzinski, S K Holland, IEEE Transactions on Medical Imaging. 20Schmithorst, V. J., Dardzinski, D. J., &amp; Holland, S. K. (2001). Simultaneous correction of ghost and geometric distortion artifacts in EPI using a multi-echo reference scan. IEEE Transactions on Medical Imaging, 20, 535-539.</p>
<p>Identification of a pathway for intelligible speech in the left temporal lobe. S K Scott, C C Blank, S Rosen, R J S Wise, Brain. 123Scott, S. K., Blank, C. C., Rosen, S., &amp; Wise, R. J. S. (2000). Identification of a pathway for intelligible speech in the left temporal lobe. Brain, 123, 2400-2406.</p>
<p>The neuroanatomical and functional organization of speech perception. S K Scott, I S Johnsrude, Trends in Neurosciences. 26Scott, S. K., &amp; Johnsrude, I. S. (2003). The neuroanatomical and functional organization of speech perception. Trends in Neurosciences, 26, 100-107.</p>
<p>Going beyond the information given: A neural system supporting semantic interpretation. S K Scott, A P Leff, R J S Wise, Neuroimage. 19Scott, S. K., Leff, A. P., &amp; Wise, R. J. S. (2003). Going beyond the information given: A neural system supporting semantic interpretation. Neuroimage, 19, 870-876.</p>
<p>Semantic dementia: A form of circumscribed cerebral atrophy. J S Snowden, H L Griffiths, D Neary, D Mann, Behavioural Neurology. 2Snowden, J. S., Griffiths, H. L., Neary, D., &amp; Mann, D. (1989). Semantic dementia: A form of circumscribed cerebral atrophy. Behavioural Neurology, 2, 167-182.</p>
<p>Knowledge of famous faces and names in semantic dementia. J S Snowden, J C Thompson, D Neary, Brain. 127Snowden, J. S., Thompson, J. C., &amp; Neary, D. (2004). Knowledge of famous faces and names in semantic dementia. Brain, 127, 860-872.</p>
<p>Neuroimaging studies of semantic memory: Inferring "How" From "Where. S L Thompson-Schill, Neuropsychologia. 41Thompson-Schill, S. L. (2003). Neuroimaging studies of semantic memory: Inferring "How" From "Where." Neuropsychologia, 41, 280-292.</p>
<p>Role of left inferior prefrontal cortex in retrieval of semantic knowledge: A reevaluation. S L Thompson-Schill, M Dʼesposito, G K Aguirre, M J Farah, Proceedings of the National Academy of Sciences. the National Academy of SciencesU.S.A.94Thompson-Schill, S. L., DʼEsposito, M., Aguirre, G. K., &amp; Farah, M. J. (1997). Role of left inferior prefrontal cortex in retrieval of semantic knowledge: A reevaluation. Proceedings of the National Academy of Sciences, U.S.A., 94, 14792-14797.</p>
<p>Naming the same entities from visual or from auditory stimulation engages similar regions of left inferotemporal cortices. D Tranel, T J Grabowski, J Lyon, H Damasio, Journal of Cognitive Neuroscience. 17Tranel, D., Grabowski, T. J., Lyon, J., &amp; Damasio, H. (2005). Naming the same entities from visual or from auditory stimulation engages similar regions of left inferotemporal cortices. Journal of Cognitive Neuroscience, 17, 1293-1305.</p>
<p>Processing objects at different levels of specificity. L K Tyler, E A Stamatakis, P Bright, K Acres, S Abdallah, J M Rodd, Journal of Cognitive Neuroscience. 16Tyler, L. K., Stamatakis, E. A., Bright, P., Acres, K., Abdallah, S., Rodd, J. M., et al. (2004). Processing objects at different levels of specificity. Journal of Cognitive Neuroscience, 16, 351-362.</p>
<p>Functional anatomy of a common semantic system for words and pictures. R Vandenberghe, C Price, R Wise, O Josephs, R S J Frackowiak, Nature. 383Vandenberghe, R., Price, C., Wise, R., Josephs, O., &amp; Frackowiak, R. S. J. (1996). Functional anatomy of a common semantic system for words and pictures. Nature, 383, 254-256.</p>
<p>The anterior temporal lobes and semantic memory clarified: Novel evidence from distortion. M Visser, K V Embleton, E Jefferies, J G Parker, M A Ralph, submitted. corrected fMRIVisser, M., Embleton, K. V., Jefferies, E., Parker, J. G., &amp; Lambon Ralph, M. A. (submitted). The anterior temporal lobes and semantic memory clarified: Novel evidence from distortion-corrected fMRI.</p>
<p>The selective impairment of semantic memory. E K Warrington, Quarterly Journal of Experimental Psychology. 27Warrington, E. K. (1975). The selective impairment of semantic memory. Quarterly Journal of Experimental Psychology, 27, 635-657.</p>
<p>Optimal EPI parameters for reduction of susceptibilityinduced BOLD sensitivity losses: A whole-brain analysis at 3 T and 1.5 T. N Weiskopf, C Hutton, O Josephs, R Deichmann, Neuroimage. 33Weiskopf, N., Hutton, C., Josephs, O., &amp; Deichmann, R. (2006). Optimal EPI parameters for reduction of susceptibility- induced BOLD sensitivity losses: A whole-brain analysis at 3 T and 1.5 T. Neuroimage, 33, 493-504.</p>
<p>Connectivity among semantic associates: An fMRI study of semantic priming. C G Wible, S D Han, M H Spencer, M Kubicki, M H Niznikiewicz, F A Jolesz, Brain and Language. 97Wible, C. G., Han, S. D., Spencer, M. H., Kubicki, M., Niznikiewicz, M. H., Jolesz, F. A., et al. (2006). Connectivity among semantic associates: An fMRI study of semantic priming. Brain and Language, 97, 294-305.</p>
<p>Language systems in normal and aphasic human subjects: Functional imaging studies and inferences from animal studies. R J S Wise, British Medical Bulletin. 65Wise, R. J. S. (2003). Language systems in normal and aphasic human subjects: Functional imaging studies and inferences from animal studies. British Medical Bulletin, 65, 95-119.</p>            </div>
        </div>

    </div>
</body>
</html>