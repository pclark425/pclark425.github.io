<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-1677 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-1677</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-1677</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-32.html">extraction-schema-32</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of sim-to-real transfer for robotic agents, scientific discovery agents, or laboratory automation systems, including details about simulation fidelity, transfer success, and the conditions that enable or hinder skill transfer from virtual to real environments.</div>
                <p><strong>Paper ID:</strong> paper-227334352</p>
                <p><strong>Paper Title:</strong> <a href="https://arxiv.org/pdf/2012.03806v1.pdf" target="_blank">Perspectives on Sim2Real Transfer for Robotics: A Summary of the R:SS 2020 Workshop</a></p>
                <p><strong>Paper Abstract:</strong> This report presents the debates, posters, and discussions of the Sim2Real workshop held in conjunction with the 2020 edition of the"Robotics: Science and System"conference. Twelve leaders of the field took competing debate positions on the definition, viability, and importance of transferring skills from simulation to the real world in the context of robotics problems. The debaters also joined a large panel discussion, answering audience questions and outlining the future of Sim2Real in robotics. Furthermore, we invited extended abstracts to this workshop which are summarized in this report. Based on the workshop, this report concludes with directions for practitioners exploiting this technology and for researchers further exploring open problems in this area.</p>
                <p><strong>Cost:</strong> 0.019</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e1677.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e1677.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of sim-to-real transfer for robotic agents, scientific discovery agents, or laboratory automation systems, including details about simulation fidelity, transfer success, and the conditions that enable or hinder skill transfer from virtual to real environments.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>OpenAI Rubik's Cube</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Solving Rubik's Cube with a Robot Hand (OpenAI)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A high-profile Sim2Real effort where policies were trained extensively in simulation to control a dexterous robotic hand to solve a Rubik's cube and then deployed on real hardware; noted in the workshop for its high simulation cost and long engineering effort required for transfer.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Solving rubik's cube with a robot hand</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>agent_system_name</strong></td>
                            <td>OpenAI dexterous robot hand system</td>
                        </tr>
                        <tr>
                            <td><strong>agent_system_description</strong></td>
                            <td>A multi-fingered dexterous robotic hand used to manipulate and solve a Rubik's cube by executing complex in-hand manipulation policies.</td>
                        </tr>
                        <tr>
                            <td><strong>domain</strong></td>
                            <td>general robotics manipulation</td>
                        </tr>
                        <tr>
                            <td><strong>virtual_environment_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>virtual_environment_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>simulation_fidelity_level</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_aspects_modeled</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_aspects_simplified</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>real_environment_description</strong></td>
                            <td>Physical dexterous robotic hand and a real Rubik's cube; real-world lab/hardware setup used for deployment and evaluation.</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_skill_transferred</strong></td>
                            <td>In-hand manipulation / solving a Rubik's cube</td>
                        </tr>
                        <tr>
                            <td><strong>training_method</strong></td>
                            <td>Reinforcement learning / simulation-trained policies (extensive simulation training)</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_success_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>transfer_performance_sim</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>transfer_performance_real</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>transfer_success</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>domain_randomization_used</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_randomization_details</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>sim_to_real_gap_factors</strong></td>
                            <td>Complex contact interactions, high-dimensional dexterous control, simulator inaccuracies necessitating extensive engineering</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_enabling_conditions</strong></td>
                            <td>Large engineering effort, extensive simulation training and manual tuning over long development time; iterative refinement to bridge gaps</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_requirements_identified</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>fine_tuning_in_real_world</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>fine_tuning_details</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_across_fidelity_levels</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_comparison_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Demonstrates that very challenging manipulation skills can be transferred from simulation to reality but at high simulation cost and long manual development time; cited as evidence both for Sim2Real potential and for its engineering expense.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Perspectives on Sim2Real Transfer for Robotics: A Summary of the R:SS 2020 Workshop', 'publication_date_yy_mm': '2020-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1677.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e1677.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of sim-to-real transfer for robotic agents, scientific discovery agents, or laboratory automation systems, including details about simulation fidelity, transfer success, and the conditions that enable or hinder skill transfer from virtual to real environments.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Deep Drone Acrobatics</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Deep Drone Acrobatics</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A Sim2Real example applying simulation-trained policies to agile drone flight and acrobatics; presented as one of several high-profile 2019-2020 works demonstrating sim-to-real in dynamic aerial tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Deep drone acrobatics</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>agent_system_name</strong></td>
                            <td>Autonomous agile quadrotor (drone) system</td>
                        </tr>
                        <tr>
                            <td><strong>agent_system_description</strong></td>
                            <td>High-performance quadrotor platform executing agile maneuvers and acrobatics controlled by policies trained in simulation.</td>
                        </tr>
                        <tr>
                            <td><strong>domain</strong></td>
                            <td>robotics - aerial navigation and control</td>
                        </tr>
                        <tr>
                            <td><strong>virtual_environment_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>virtual_environment_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>simulation_fidelity_level</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_aspects_modeled</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_aspects_simplified</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>real_environment_description</strong></td>
                            <td>Physical quadrotor flight arena for testing agile maneuvers in real world.</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_skill_transferred</strong></td>
                            <td>Agile flight maneuvers / drone acrobatics (control policies)</td>
                        </tr>
                        <tr>
                            <td><strong>training_method</strong></td>
                            <td>Reinforcement learning / policy learning in simulation</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_success_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>transfer_performance_sim</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>transfer_performance_real</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>transfer_success</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>domain_randomization_used</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_randomization_details</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>sim_to_real_gap_factors</strong></td>
                            <td>Dynamics mismatch, actuator and timing differences, possibly sensor noise and aerodynamic effects not fully captured</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_enabling_conditions</strong></td>
                            <td>Use of powerful simulation + careful policy design and likely engineering effort to bridge simulator-real differences</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_requirements_identified</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>fine_tuning_in_real_world</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>fine_tuning_details</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_across_fidelity_levels</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_comparison_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Listed as an example where simulation-trained policies have been applied successfully to complex dynamic robotic tasks, illustrating the potential of Sim2Real for high-speed control problems.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Perspectives on Sim2Real Transfer for Robotics: A Summary of the R:SS 2020 Workshop', 'publication_date_yy_mm': '2020-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1677.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e1677.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of sim-to-real transfer for robotic agents, scientific discovery agents, or laboratory automation systems, including details about simulation fidelity, transfer success, and the conditions that enable or hinder skill transfer from virtual to real environments.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Mahler Ambidextrous Grasping</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Learning Ambidextrous Robot Grasping Policies (Mahler et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Work using synthetic data and simulation to train grasping policies that transfer to real robots, cited as a successful Sim2Real application in grasping.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Learning ambidextrous robot grasping policies</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>agent_system_name</strong></td>
                            <td>Ambidextrous robotic grasping system</td>
                        </tr>
                        <tr>
                            <td><strong>agent_system_description</strong></td>
                            <td>Robotic manipulators trained to perform robust grasping using policies/algorithms trained on synthetic/simulated data.</td>
                        </tr>
                        <tr>
                            <td><strong>domain</strong></td>
                            <td>robotics - manipulation / grasping</td>
                        </tr>
                        <tr>
                            <td><strong>virtual_environment_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>virtual_environment_description</strong></td>
                            <td>Simulation used to generate synthetic labeled data for grasping tasks (visual + physics aspects implied).</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_fidelity_level</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_aspects_modeled</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_aspects_simplified</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>real_environment_description</strong></td>
                            <td>Real robot arms/hands executing grasp policies on physical objects</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_skill_transferred</strong></td>
                            <td>Grasp planning and execution (ambidextrous grasping)</td>
                        </tr>
                        <tr>
                            <td><strong>training_method</strong></td>
                            <td>Supervised learning / synthetic-data-driven policy learning (simulation-generated labels)</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_success_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>transfer_performance_sim</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>transfer_performance_real</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>transfer_success</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>domain_randomization_used</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_randomization_details</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>sim_to_real_gap_factors</strong></td>
                            <td>Visual realism gap, contact modelling imperfections, distribution mismatch between synthetic and real data</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_enabling_conditions</strong></td>
                            <td>Use of large amounts of synthetic labeled data and domain-aware design of representation/features to generalize to real images</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_requirements_identified</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>fine_tuning_in_real_world</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>fine_tuning_details</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_across_fidelity_levels</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_comparison_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Grasping has been a domain with notable Sim2Real successes, often enabled by synthetic labeled data and explicit representation choices that mitigate the visual and contact reality gaps.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Perspectives on Sim2Real Transfer for Robotics: A Summary of the R:SS 2020 Workshop', 'publication_date_yy_mm': '2020-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1677.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e1677.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of sim-to-real transfer for robotic agents, scientific discovery agents, or laboratory automation systems, including details about simulation fidelity, transfer success, and the conditions that enable or hinder skill transfer from virtual to real environments.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Dao Biped Transfer</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Learning to Walk without Dynamics Randomization (Dao et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Reported example where controllers trained in a state-of-the-art simulator transferred successfully to a real bipedal walking robot without using domain randomization, noted despite simulator contact limitations.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Learning to walk without dynamics randomization</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>agent_system_name</strong></td>
                            <td>Bipedal walking robot</td>
                        </tr>
                        <tr>
                            <td><strong>agent_system_description</strong></td>
                            <td>A walking robot platform whose locomotion controllers were trained in simulation and then deployed on real hardware.</td>
                        </tr>
                        <tr>
                            <td><strong>domain</strong></td>
                            <td>robotics - locomotion / legged robots</td>
                        </tr>
                        <tr>
                            <td><strong>virtual_environment_name</strong></td>
                            <td>state-of-the-art simulator (unspecified)</td>
                        </tr>
                        <tr>
                            <td><strong>virtual_environment_description</strong></td>
                            <td>Physics simulator modelling locomotion dynamics; noted to have limitations in contact simulation but adequate for controller training in this study.</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_fidelity_level</strong></td>
                            <td>state-of-the-art physics simulation (contact modelling limited)</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_aspects_modeled</strong></td>
                            <td>Rigid-body dynamics and walking dynamics; some contact modelling</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_aspects_simplified</strong></td>
                            <td>Contacts simulated with limitations (contact-rich phenomena imperfectly modelled); limited friction/complex contact dynamics fidelity</td>
                        </tr>
                        <tr>
                            <td><strong>real_environment_description</strong></td>
                            <td>Physical bipedal robot tested in lab for walking behaviors</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_skill_transferred</strong></td>
                            <td>Locomotion / bipedal walking controllers</td>
                        </tr>
                        <tr>
                            <td><strong>training_method</strong></td>
                            <td>Reinforcement learning / controller learning in simulation (without dynamics randomization)</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_success_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>transfer_performance_sim</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>transfer_performance_real</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>transfer_success</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>domain_randomization_used</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>domain_randomization_details</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>sim_to_real_gap_factors</strong></td>
                            <td>Simulator contact inaccuracies; unmodelled real-world disturbances; differences in actuator and sensor characteristics</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_enabling_conditions</strong></td>
                            <td>Use of a high-quality state-of-the-art simulator and controller design robust enough to tolerate simulator limitations; task/robot conducive to transfer even without dynamics randomization</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_requirements_identified</strong></td>
                            <td>Not precisely quantified, but suggests that some locomotion tasks can transfer even when contact simulation is imperfect</td>
                        </tr>
                        <tr>
                            <td><strong>fine_tuning_in_real_world</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>fine_tuning_details</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_across_fidelity_levels</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_comparison_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Demonstrates that successful Sim2Real transfer for legged locomotion is possible without dynamics randomization if the simulator and controller are sufficiently capable; highlights that perfect contact modelling is not always required.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Perspectives on Sim2Real Transfer for Robotics: A Summary of the R:SS 2020 Workshop', 'publication_date_yy_mm': '2020-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1677.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e1677.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of sim-to-real transfer for robotic agents, scientific discovery agents, or laboratory automation systems, including details about simulation fidelity, transfer success, and the conditions that enable or hinder skill transfer from virtual to real environments.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Malmir Inverse Dynamics</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Robust Sim2Real Transfer by Learning Inverse Dynamics of Simulated Systems (Malmir et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Proposes learning the inverse dynamics discrepancy between simulation and real world to compute corrective controllers, aiming to improve robustness of simulation-trained policies when deployed on real robots.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Robust sim2real transfer by learning inverse dynamics of simulated systems</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>agent_system_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>agent_system_description</strong></td>
                            <td>Method applied to robotic systems where inverse dynamics differ between sim and real; specific platforms not detailed in the workshop summary.</td>
                        </tr>
                        <tr>
                            <td><strong>domain</strong></td>
                            <td>robotics - general control / manipulation</td>
                        </tr>
                        <tr>
                            <td><strong>virtual_environment_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>virtual_environment_description</strong></td>
                            <td>Simulation used to derive nominal dynamics and inverse dynamics estimates; discrepancy modelled and corrected.</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_fidelity_level</strong></td>
                            <td>approximate dynamics with learnable residuals</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_aspects_modeled</strong></td>
                            <td>Nominal forward/inverse dynamics of simulated system</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_aspects_simplified</strong></td>
                            <td>Residual dynamics and nuanced contact/actuator effects left to learned correction rather than modelled explicitly</td>
                        </tr>
                        <tr>
                            <td><strong>real_environment_description</strong></td>
                            <td>Real robotic platforms where inverse dynamics differ from simulation; specifics not given</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_skill_transferred</strong></td>
                            <td>Controller policies corrected via learned inverse-dynamics discrepancy (general motor skills / control)</td>
                        </tr>
                        <tr>
                            <td><strong>training_method</strong></td>
                            <td>Learning-based correction on top of simulation (likely supervised/regression or RL for residuals)</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_success_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>transfer_performance_sim</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>transfer_performance_real</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>transfer_success</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_randomization_used</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_randomization_details</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>sim_to_real_gap_factors</strong></td>
                            <td>Mismatch in inverse dynamics between sim and real due to unmodelled actuator/sensor/contacts</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_enabling_conditions</strong></td>
                            <td>Learning explicit corrections for inverse dynamics discrepancies to adapt simulated controllers to real-world behavior</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_requirements_identified</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>fine_tuning_in_real_world</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>fine_tuning_details</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_across_fidelity_levels</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_comparison_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Suggests that modelling and learning the inverse-dynamics discrepancy is a viable strategy to reduce Sim2Real gaps, enabling more robust transfer without solely relying on improving simulator fidelity.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Perspectives on Sim2Real Transfer for Robotics: A Summary of the R:SS 2020 Workshop', 'publication_date_yy_mm': '2020-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1677.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e1677.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of sim-to-real transfer for robotic agents, scientific discovery agents, or laboratory automation systems, including details about simulation fidelity, transfer success, and the conditions that enable or hinder skill transfer from virtual to real environments.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Heiden Differentiable Sim</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Augmenting Differentiable Simulators with Neural Networks to Close the Sim2Real Gap (Heiden et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Proposes a differentiable rigid-body dynamics formulation that enables training residual physics models and internal simulator parameters end-to-end, aiming to reduce sim-to-real discrepancy by backpropagating through physics models.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Augmenting differentiable simulators with neural networks to close the sim2real gap</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>agent_system_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>agent_system_description</strong></td>
                            <td>Methodology for simulators rather than a single agent; intended to improve simulation models used to train controllers for robots.</td>
                        </tr>
                        <tr>
                            <td><strong>domain</strong></td>
                            <td>robotics - simulation / modelling</td>
                        </tr>
                        <tr>
                            <td><strong>virtual_environment_name</strong></td>
                            <td>differentiable rigid-body simulator (unspecified)</td>
                        </tr>
                        <tr>
                            <td><strong>virtual_environment_description</strong></td>
                            <td>Differentiable physics simulator modelling rigid-body dynamics, allowing gradient-based optimization of parameters and neural residuals.</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_fidelity_level</strong></td>
                            <td>differentiable physics simulation with learnable residuals</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_aspects_modeled</strong></td>
                            <td>Rigid-body dynamics; backpropagation through forward physics to tune parameters and residuals</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_aspects_simplified</strong></td>
                            <td>Potentially complex non-differentiable phenomena may still be simplified or approximated to allow differentiability</td>
                        </tr>
                        <tr>
                            <td><strong>real_environment_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>task_or_skill_transferred</strong></td>
                            <td>Improved simulator fidelity to support downstream Sim2Real transfer (general tasks implied)</td>
                        </tr>
                        <tr>
                            <td><strong>training_method</strong></td>
                            <td>Gradient-based optimization of simulator parameters and neural residuals using real data (system identification + ML)</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_success_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>transfer_performance_sim</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>transfer_performance_real</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>transfer_success</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_randomization_used</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_randomization_details</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>sim_to_real_gap_factors</strong></td>
                            <td>Simulator parameter mismatch and residual unmodelled physics; non-differentiable real phenomena</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_enabling_conditions</strong></td>
                            <td>Differentiability enabling end-to-end fitting of simulator parameters and neural residual models from real data</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_requirements_identified</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>fine_tuning_in_real_world</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>fine_tuning_details</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_across_fidelity_levels</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_comparison_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Differentiable simulation combined with neural residuals is a promising avenue to close reality gaps by directly optimizing simulator parameters against real data, though full differentiability may not always be necessary or feasible.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Perspectives on Sim2Real Transfer for Robotics: A Summary of the R:SS 2020 Workshop', 'publication_date_yy_mm': '2020-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1677.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e1677.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of sim-to-real transfer for robotic agents, scientific discovery agents, or laboratory automation systems, including details about simulation fidelity, transfer success, and the conditions that enable or hinder skill transfer from virtual to real environments.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Possas BayesSim</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Online BayesSim for Combined Simulator Parameter Inference and Policy Improvement (Possas et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Proposes treating the simulator as a black box while using online inference of simulator parameters (BayesSim) during learning to align simulation with the real world and improve policies.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Online bayessim for combined simulator parameter inference and policy improvement</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>agent_system_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>agent_system_description</strong></td>
                            <td>Framework for online simulator parameter inference used alongside policy learning for robotic systems.</td>
                        </tr>
                        <tr>
                            <td><strong>domain</strong></td>
                            <td>robotics - system identification / adaptive simulation</td>
                        </tr>
                        <tr>
                            <td><strong>virtual_environment_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>virtual_environment_description</strong></td>
                            <td>Black-box simulator whose parameters are inferred online from real-world observations to reduce mismatch.</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_fidelity_level</strong></td>
                            <td>black-box simulator with inferred parameters (fidelity depends on inference)</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_aspects_modeled</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_aspects_simplified</strong></td>
                            <td>Treats simulator as black box, so internal modelling details are not required; unmodelled phenomena remain unless parameterized</td>
                        </tr>
                        <tr>
                            <td><strong>real_environment_description</strong></td>
                            <td>Real robot or environment providing observations used to infer simulator parameters online</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_skill_transferred</strong></td>
                            <td>General policy improvement via online simulator calibration (task-agnostic)</td>
                        </tr>
                        <tr>
                            <td><strong>training_method</strong></td>
                            <td>Online Bayesian inference of simulator parameters combined with policy learning</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_success_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>transfer_performance_sim</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>transfer_performance_real</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>transfer_success</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_randomization_used</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_randomization_details</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>sim_to_real_gap_factors</strong></td>
                            <td>Mis-specified simulator parameters, non-stationary dynamics, observation noise</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_enabling_conditions</strong></td>
                            <td>Online parameter inference (Real2Sim) that closes loop between real observations and simulator calibration during learning</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_requirements_identified</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>fine_tuning_in_real_world</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>fine_tuning_details</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_across_fidelity_levels</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_comparison_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>A practical approach to reduce Sim2Real gaps by continuously inferring simulator parameters from real data during policy learning, enabling adaptive alignment between simulation and reality.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Perspectives on Sim2Real Transfer for Robotics: A Summary of the R:SS 2020 Workshop', 'publication_date_yy_mm': '2020-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1677.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e1677.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of sim-to-real transfer for robotic agents, scientific discovery agents, or laboratory automation systems, including details about simulation fidelity, transfer success, and the conditions that enable or hinder skill transfer from virtual to real environments.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Kadian HaPy / SRCC</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Habitat-PyRobot Bridge (HaPy) and Sim-vs-Real Correlation Coefficient (SRCC) (Kadian et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Proposes a tool (HaPy) for executing code seamlessly on simulated agents and real robots and introduces SRCC as a metric to quantify whether simulation performance improvements correlate with real-world improvements.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Sim2real predictivity: Does evaluation in simulation predict real-world performance?</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>agent_system_name</strong></td>
                            <td>HaPy-enabled agents / robots (framework)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_system_description</strong></td>
                            <td>Software bridge enabling shared codebases for simulated agents (Habitat) and real robots to facilitate comparable evaluation and transfer studies.</td>
                        </tr>
                        <tr>
                            <td><strong>domain</strong></td>
                            <td>robotics - benchmarking and evaluation</td>
                        </tr>
                        <tr>
                            <td><strong>virtual_environment_name</strong></td>
                            <td>Habitat (with PyRobot bridge)</td>
                        </tr>
                        <tr>
                            <td><strong>virtual_environment_description</strong></td>
                            <td>Simulated embodied environments for navigation and perception experiments; supports execution of same code on real robots via bridge</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_fidelity_level</strong></td>
                            <td>simulated embodied environments (visual + navigation); fidelity varies with rendering and physics</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_aspects_modeled</strong></td>
                            <td>Visual rendering, geometry, navigation dynamics as supported by Habitat; sensor simulation for embodied agents</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_aspects_simplified</strong></td>
                            <td>Detailed physics/contact dynamics may be simplified depending on Habitat capabilities</td>
                        </tr>
                        <tr>
                            <td><strong>real_environment_description</strong></td>
                            <td>Real mobile robots and physical environments where the same agent code can be executed for comparison</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_skill_transferred</strong></td>
                            <td>General navigation and embodied agent behaviors; focus on predictivity of simulation evaluations for real-world performance</td>
                        </tr>
                        <tr>
                            <td><strong>training_method</strong></td>
                            <td>Not a training method; provides evaluation/benchmarking infrastructure and a correlation metric (SRCC)</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_success_metric</strong></td>
                            <td>Sim-vs-Real Correlation Coefficient (SRCC) measuring correlation between simulation and real performance improvements</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_performance_sim</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>transfer_performance_real</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>transfer_success</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_randomization_used</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_randomization_details</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>sim_to_real_gap_factors</strong></td>
                            <td>Mismatch between simulated and real sensor/actuator/perceptual conditions leading to low predictivity</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_enabling_conditions</strong></td>
                            <td>Unified evaluation codepath and a metric (SRCC) to assess whether simulation improvements generalize to real-world gains</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_requirements_identified</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>fine_tuning_in_real_world</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>fine_tuning_details</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_across_fidelity_levels</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_comparison_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Proposes practical tooling and a correlation metric to assess whether simulation evaluations are predictive of real-world improvements, addressing the need for better Sim2Real benchmarking.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Perspectives on Sim2Real Transfer for Robotics: A Summary of the R:SS 2020 Workshop', 'publication_date_yy_mm': '2020-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1677.8">
                <h3 class="extraction-instance">Extracted Data Instance 8 (e1677.8)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of sim-to-real transfer for robotic agents, scientific discovery agents, or laboratory automation systems, including details about simulation fidelity, transfer success, and the conditions that enable or hinder skill transfer from virtual to real environments.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>BlenderProc</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>BlenderProc: Reducing the Reality Gap with Photorealistic Rendering (Denninger et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A pipeline for procedural generation of labeled photorealistic images using Blender to produce synthetic training data for vision tasks, intended to reduce the visual reality gap for Sim2Real.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Blenderproc: Reducing the reality gap with photorealistic rendering</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>agent_system_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>agent_system_description</strong></td>
                            <td>Data-generation pipeline rather than a single robot; used to generate labeled vision datasets for downstream robotic perception tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>domain</strong></td>
                            <td>computer vision for robotics / perception</td>
                        </tr>
                        <tr>
                            <td><strong>virtual_environment_name</strong></td>
                            <td>Blender (via BlenderProc pipeline)</td>
                        </tr>
                        <tr>
                            <td><strong>virtual_environment_description</strong></td>
                            <td>Photorealistic rendering environment that simulates lighting, textures, geometry to produce labeled synthetic images</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_fidelity_level</strong></td>
                            <td>photorealistic rendering (high visual fidelity)</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_aspects_modeled</strong></td>
                            <td>Lighting, textures, geometry, camera rendering and labels for vision tasks</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_aspects_simplified</strong></td>
                            <td>Physical dynamics, contact physics, and sensor temporal characteristics not central to rendering pipeline</td>
                        </tr>
                        <tr>
                            <td><strong>real_environment_description</strong></td>
                            <td>Real images and robotic vision setups used to validate segmentation and detection models</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_skill_transferred</strong></td>
                            <td>Vision tasks such as image segmentation and object detection trained on synthetic data and applied to real images</td>
                        </tr>
                        <tr>
                            <td><strong>training_method</strong></td>
                            <td>Supervised learning on synthetic photorealistic datasets</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_success_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>transfer_performance_sim</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>transfer_performance_real</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>transfer_success</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_randomization_used</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_randomization_details</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>sim_to_real_gap_factors</strong></td>
                            <td>Visual domain gap due to differences in rendering vs. real sensor capture; label distortion risk with domain adaptation</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_enabling_conditions</strong></td>
                            <td>High-quality photorealistic rendering and procedural generation to create diverse labeled datasets that better match real-world visuals</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_requirements_identified</strong></td>
                            <td>High visual fidelity helps vision tasks, but requires good CAD models and careful label consistency</td>
                        </tr>
                        <tr>
                            <td><strong>fine_tuning_in_real_world</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>fine_tuning_details</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_across_fidelity_levels</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_comparison_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Photorealistic synthetic data pipelines can reduce the visual reality gap for vision tasks, enabling Sim2Real for perception components when CAD models and rendering are adequate.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Perspectives on Sim2Real Transfer for Robotics: A Summary of the R:SS 2020 Workshop', 'publication_date_yy_mm': '2020-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1677.9">
                <h3 class="extraction-instance">Extracted Data Instance 9 (e1677.9)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of sim-to-real transfer for robotic agents, scientific discovery agents, or laboratory automation systems, including details about simulation fidelity, transfer success, and the conditions that enable or hinder skill transfer from virtual to real environments.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Zhang Contact Rich Critique</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Necessity for More Realistic Contact Simulation (Zhang)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A position arguing that the reality gap for contact-rich manipulation tasks is too large for current simulators to support positive transfer even with domain randomization, highlighting the limitations of existing contact models.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Necessity for more realistic contact simulation</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>agent_system_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>agent_system_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain</strong></td>
                            <td>robotics - contact-rich manipulation</td>
                        </tr>
                        <tr>
                            <td><strong>virtual_environment_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>virtual_environment_description</strong></td>
                            <td>Critique of current simulators' limited ability to model realistic contact phenomena</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_fidelity_level</strong></td>
                            <td>insufficient/low-fidelity for contact-rich tasks</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_aspects_modeled</strong></td>
                            <td>Basic contact and friction models (often Coulomb/idealized) in many simulators</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_aspects_simplified</strong></td>
                            <td>Complex frictional, anisotropic, and contact phenomena; realistic contact geometry and material interactions</td>
                        </tr>
                        <tr>
                            <td><strong>real_environment_description</strong></td>
                            <td>Contact-rich manipulation environments (e.g., precision agriculture, deformable object handling)</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_skill_transferred</strong></td>
                            <td>Contact-rich manipulation tasks (argued to be poorly supported by current Sim2Real)</td>
                        </tr>
                        <tr>
                            <td><strong>training_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>transfer_success_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>transfer_performance_sim</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>transfer_performance_real</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>transfer_success</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>domain_randomization_used</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_randomization_details</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>sim_to_real_gap_factors</strong></td>
                            <td>Inaccurate contact models, simplified friction models (isotropic Coulomb), and NP-hard nature of realistic contact simulation</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_enabling_conditions</strong></td>
                            <td>Higher-fidelity contact simulation or alternative strategies (e.g., learning residuals, system identification) required; domain randomization alone often insufficient</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_requirements_identified</strong></td>
                            <td>Argues contact-rich tasks require more realistic contact modelling than many current simulators provide, though no numeric fidelity thresholds given</td>
                        </tr>
                        <tr>
                            <td><strong>fine_tuning_in_real_world</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>fine_tuning_details</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_across_fidelity_levels</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_comparison_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>For contact-rich manipulation, current simulators are often too inaccurate for reliable Sim2Real; improved contact modelling or alternative bridging techniques are necessary.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Perspectives on Sim2Real Transfer for Robotics: A Summary of the R:SS 2020 Workshop', 'publication_date_yy_mm': '2020-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1677.10">
                <h3 class="extraction-instance">Extracted Data Instance 10 (e1677.10)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of sim-to-real transfer for robotic agents, scientific discovery agents, or laboratory automation systems, including details about simulation fidelity, transfer success, and the conditions that enable or hinder skill transfer from virtual to real environments.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Raparthy CUNAS</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>CUNAS  Curiosity-driven Neural-Augmented Simulator (Raparthy et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Proposes a curiosity-driven approach to collect real-world data to train a physics-based simulator augmented with a neural residual, aiming to close sim-to-real gaps by targeted data collection and learned corrections.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Cunascuriosity-driven neural-augmented simulator</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>agent_system_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>agent_system_description</strong></td>
                            <td>Method for simulator improvement via curiosity-guided data collection and neural residual modelling rather than a single robot system</td>
                        </tr>
                        <tr>
                            <td><strong>domain</strong></td>
                            <td>robotics - simulator learning / system identification</td>
                        </tr>
                        <tr>
                            <td><strong>virtual_environment_name</strong></td>
                            <td>physics-based simulator with neural residual (unspecified)</td>
                        </tr>
                        <tr>
                            <td><strong>virtual_environment_description</strong></td>
                            <td>Physics simulator augmented by a learned neural residual to better match real-world dynamics</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_fidelity_level</strong></td>
                            <td>physics-based with neural augmentation</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_aspects_modeled</strong></td>
                            <td>Nominal physical dynamics (gravity, rigid-body dynamics) plus learned residuals for unmodelled effects</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_aspects_simplified</strong></td>
                            <td>Certain detailed phenomena left to neural residual rather than explicitly modelled</td>
                        </tr>
                        <tr>
                            <td><strong>real_environment_description</strong></td>
                            <td>Real robot/environment data collected via curiosity-driven exploration to train the simulator residual</td>
                        </tr>
                        <tr>
                            <td><strong>task_or_skill_transferred</strong></td>
                            <td>Simulator improvement to support better policy transfer (general tasks implied)</td>
                        </tr>
                        <tr>
                            <td><strong>training_method</strong></td>
                            <td>Curiosity-driven data collection + learning neural residuals (ML/system identification hybrid)</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_success_metric</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>transfer_performance_sim</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>transfer_performance_real</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>transfer_success</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_randomization_used</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_randomization_details</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>sim_to_real_gap_factors</strong></td>
                            <td>Unmodelled dynamics and simulator parameter mismatch; insufficient data in regions critical for task performance</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_enabling_conditions</strong></td>
                            <td>Targeted real-data collection guided by curiosity and training neural residuals to correct simulator predictions</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_requirements_identified</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>fine_tuning_in_real_world</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>fine_tuning_details</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_across_fidelity_levels</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_comparison_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Active data collection combined with neural residual models offers a strategy to improve simulators in task-relevant regions and reduce Sim2Real gaps without requiring full high-fidelity modelling.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Perspectives on Sim2Real Transfer for Robotics: A Summary of the R:SS 2020 Workshop', 'publication_date_yy_mm': '2020-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Solving rubik's cube with a robot hand <em>(Rating: 2)</em></li>
                <li>Learning agile and dynamic motor skills for legged robots <em>(Rating: 2)</em></li>
                <li>Learning ambidextrous robot grasping policies <em>(Rating: 2)</em></li>
                <li>Deep drone acrobatics <em>(Rating: 2)</em></li>
                <li>Learning to walk without dynamics randomization <em>(Rating: 2)</em></li>
                <li>Robust sim2real transfer by learning inverse dynamics of simulated systems <em>(Rating: 2)</em></li>
                <li>Blenderproc: Reducing the reality gap with photorealistic rendering <em>(Rating: 2)</em></li>
                <li>Online bayessim for combined simulator parameter inference and policy improvement <em>(Rating: 2)</em></li>
                <li>Cunascuriosity-driven neural-augmented simulator <em>(Rating: 2)</em></li>
                <li>Sim2real predictivity: Does evaluation in simulation predict real-world performance? <em>(Rating: 2)</em></li>
                <li>Necessity for more realistic contact simulation <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-1677",
    "paper_id": "paper-227334352",
    "extraction_schema_id": "extraction-schema-32",
    "extracted_data": [
        {
            "name_short": "OpenAI Rubik's Cube",
            "name_full": "Solving Rubik's Cube with a Robot Hand (OpenAI)",
            "brief_description": "A high-profile Sim2Real effort where policies were trained extensively in simulation to control a dexterous robotic hand to solve a Rubik's cube and then deployed on real hardware; noted in the workshop for its high simulation cost and long engineering effort required for transfer.",
            "citation_title": "Solving rubik's cube with a robot hand",
            "mention_or_use": "mention",
            "agent_system_name": "OpenAI dexterous robot hand system",
            "agent_system_description": "A multi-fingered dexterous robotic hand used to manipulate and solve a Rubik's cube by executing complex in-hand manipulation policies.",
            "domain": "general robotics manipulation",
            "virtual_environment_name": null,
            "virtual_environment_description": null,
            "simulation_fidelity_level": null,
            "fidelity_aspects_modeled": null,
            "fidelity_aspects_simplified": null,
            "real_environment_description": "Physical dexterous robotic hand and a real Rubik's cube; real-world lab/hardware setup used for deployment and evaluation.",
            "task_or_skill_transferred": "In-hand manipulation / solving a Rubik's cube",
            "training_method": "Reinforcement learning / simulation-trained policies (extensive simulation training)",
            "transfer_success_metric": null,
            "transfer_performance_sim": null,
            "transfer_performance_real": null,
            "transfer_success": true,
            "domain_randomization_used": null,
            "domain_randomization_details": null,
            "sim_to_real_gap_factors": "Complex contact interactions, high-dimensional dexterous control, simulator inaccuracies necessitating extensive engineering",
            "transfer_enabling_conditions": "Large engineering effort, extensive simulation training and manual tuning over long development time; iterative refinement to bridge gaps",
            "fidelity_requirements_identified": null,
            "fine_tuning_in_real_world": null,
            "fine_tuning_details": null,
            "comparison_across_fidelity_levels": null,
            "fidelity_comparison_results": null,
            "key_findings": "Demonstrates that very challenging manipulation skills can be transferred from simulation to reality but at high simulation cost and long manual development time; cited as evidence both for Sim2Real potential and for its engineering expense.",
            "uuid": "e1677.0",
            "source_info": {
                "paper_title": "Perspectives on Sim2Real Transfer for Robotics: A Summary of the R:SS 2020 Workshop",
                "publication_date_yy_mm": "2020-12"
            }
        },
        {
            "name_short": "Deep Drone Acrobatics",
            "name_full": "Deep Drone Acrobatics",
            "brief_description": "A Sim2Real example applying simulation-trained policies to agile drone flight and acrobatics; presented as one of several high-profile 2019-2020 works demonstrating sim-to-real in dynamic aerial tasks.",
            "citation_title": "Deep drone acrobatics",
            "mention_or_use": "mention",
            "agent_system_name": "Autonomous agile quadrotor (drone) system",
            "agent_system_description": "High-performance quadrotor platform executing agile maneuvers and acrobatics controlled by policies trained in simulation.",
            "domain": "robotics - aerial navigation and control",
            "virtual_environment_name": null,
            "virtual_environment_description": null,
            "simulation_fidelity_level": null,
            "fidelity_aspects_modeled": null,
            "fidelity_aspects_simplified": null,
            "real_environment_description": "Physical quadrotor flight arena for testing agile maneuvers in real world.",
            "task_or_skill_transferred": "Agile flight maneuvers / drone acrobatics (control policies)",
            "training_method": "Reinforcement learning / policy learning in simulation",
            "transfer_success_metric": null,
            "transfer_performance_sim": null,
            "transfer_performance_real": null,
            "transfer_success": true,
            "domain_randomization_used": null,
            "domain_randomization_details": null,
            "sim_to_real_gap_factors": "Dynamics mismatch, actuator and timing differences, possibly sensor noise and aerodynamic effects not fully captured",
            "transfer_enabling_conditions": "Use of powerful simulation + careful policy design and likely engineering effort to bridge simulator-real differences",
            "fidelity_requirements_identified": null,
            "fine_tuning_in_real_world": null,
            "fine_tuning_details": null,
            "comparison_across_fidelity_levels": null,
            "fidelity_comparison_results": null,
            "key_findings": "Listed as an example where simulation-trained policies have been applied successfully to complex dynamic robotic tasks, illustrating the potential of Sim2Real for high-speed control problems.",
            "uuid": "e1677.1",
            "source_info": {
                "paper_title": "Perspectives on Sim2Real Transfer for Robotics: A Summary of the R:SS 2020 Workshop",
                "publication_date_yy_mm": "2020-12"
            }
        },
        {
            "name_short": "Mahler Ambidextrous Grasping",
            "name_full": "Learning Ambidextrous Robot Grasping Policies (Mahler et al.)",
            "brief_description": "Work using synthetic data and simulation to train grasping policies that transfer to real robots, cited as a successful Sim2Real application in grasping.",
            "citation_title": "Learning ambidextrous robot grasping policies",
            "mention_or_use": "mention",
            "agent_system_name": "Ambidextrous robotic grasping system",
            "agent_system_description": "Robotic manipulators trained to perform robust grasping using policies/algorithms trained on synthetic/simulated data.",
            "domain": "robotics - manipulation / grasping",
            "virtual_environment_name": null,
            "virtual_environment_description": "Simulation used to generate synthetic labeled data for grasping tasks (visual + physics aspects implied).",
            "simulation_fidelity_level": null,
            "fidelity_aspects_modeled": null,
            "fidelity_aspects_simplified": null,
            "real_environment_description": "Real robot arms/hands executing grasp policies on physical objects",
            "task_or_skill_transferred": "Grasp planning and execution (ambidextrous grasping)",
            "training_method": "Supervised learning / synthetic-data-driven policy learning (simulation-generated labels)",
            "transfer_success_metric": null,
            "transfer_performance_sim": null,
            "transfer_performance_real": null,
            "transfer_success": true,
            "domain_randomization_used": null,
            "domain_randomization_details": null,
            "sim_to_real_gap_factors": "Visual realism gap, contact modelling imperfections, distribution mismatch between synthetic and real data",
            "transfer_enabling_conditions": "Use of large amounts of synthetic labeled data and domain-aware design of representation/features to generalize to real images",
            "fidelity_requirements_identified": null,
            "fine_tuning_in_real_world": null,
            "fine_tuning_details": null,
            "comparison_across_fidelity_levels": null,
            "fidelity_comparison_results": null,
            "key_findings": "Grasping has been a domain with notable Sim2Real successes, often enabled by synthetic labeled data and explicit representation choices that mitigate the visual and contact reality gaps.",
            "uuid": "e1677.2",
            "source_info": {
                "paper_title": "Perspectives on Sim2Real Transfer for Robotics: A Summary of the R:SS 2020 Workshop",
                "publication_date_yy_mm": "2020-12"
            }
        },
        {
            "name_short": "Dao Biped Transfer",
            "name_full": "Learning to Walk without Dynamics Randomization (Dao et al.)",
            "brief_description": "Reported example where controllers trained in a state-of-the-art simulator transferred successfully to a real bipedal walking robot without using domain randomization, noted despite simulator contact limitations.",
            "citation_title": "Learning to walk without dynamics randomization",
            "mention_or_use": "mention",
            "agent_system_name": "Bipedal walking robot",
            "agent_system_description": "A walking robot platform whose locomotion controllers were trained in simulation and then deployed on real hardware.",
            "domain": "robotics - locomotion / legged robots",
            "virtual_environment_name": "state-of-the-art simulator (unspecified)",
            "virtual_environment_description": "Physics simulator modelling locomotion dynamics; noted to have limitations in contact simulation but adequate for controller training in this study.",
            "simulation_fidelity_level": "state-of-the-art physics simulation (contact modelling limited)",
            "fidelity_aspects_modeled": "Rigid-body dynamics and walking dynamics; some contact modelling",
            "fidelity_aspects_simplified": "Contacts simulated with limitations (contact-rich phenomena imperfectly modelled); limited friction/complex contact dynamics fidelity",
            "real_environment_description": "Physical bipedal robot tested in lab for walking behaviors",
            "task_or_skill_transferred": "Locomotion / bipedal walking controllers",
            "training_method": "Reinforcement learning / controller learning in simulation (without dynamics randomization)",
            "transfer_success_metric": null,
            "transfer_performance_sim": null,
            "transfer_performance_real": null,
            "transfer_success": true,
            "domain_randomization_used": false,
            "domain_randomization_details": null,
            "sim_to_real_gap_factors": "Simulator contact inaccuracies; unmodelled real-world disturbances; differences in actuator and sensor characteristics",
            "transfer_enabling_conditions": "Use of a high-quality state-of-the-art simulator and controller design robust enough to tolerate simulator limitations; task/robot conducive to transfer even without dynamics randomization",
            "fidelity_requirements_identified": "Not precisely quantified, but suggests that some locomotion tasks can transfer even when contact simulation is imperfect",
            "fine_tuning_in_real_world": null,
            "fine_tuning_details": null,
            "comparison_across_fidelity_levels": null,
            "fidelity_comparison_results": null,
            "key_findings": "Demonstrates that successful Sim2Real transfer for legged locomotion is possible without dynamics randomization if the simulator and controller are sufficiently capable; highlights that perfect contact modelling is not always required.",
            "uuid": "e1677.3",
            "source_info": {
                "paper_title": "Perspectives on Sim2Real Transfer for Robotics: A Summary of the R:SS 2020 Workshop",
                "publication_date_yy_mm": "2020-12"
            }
        },
        {
            "name_short": "Malmir Inverse Dynamics",
            "name_full": "Robust Sim2Real Transfer by Learning Inverse Dynamics of Simulated Systems (Malmir et al.)",
            "brief_description": "Proposes learning the inverse dynamics discrepancy between simulation and real world to compute corrective controllers, aiming to improve robustness of simulation-trained policies when deployed on real robots.",
            "citation_title": "Robust sim2real transfer by learning inverse dynamics of simulated systems",
            "mention_or_use": "mention",
            "agent_system_name": null,
            "agent_system_description": "Method applied to robotic systems where inverse dynamics differ between sim and real; specific platforms not detailed in the workshop summary.",
            "domain": "robotics - general control / manipulation",
            "virtual_environment_name": null,
            "virtual_environment_description": "Simulation used to derive nominal dynamics and inverse dynamics estimates; discrepancy modelled and corrected.",
            "simulation_fidelity_level": "approximate dynamics with learnable residuals",
            "fidelity_aspects_modeled": "Nominal forward/inverse dynamics of simulated system",
            "fidelity_aspects_simplified": "Residual dynamics and nuanced contact/actuator effects left to learned correction rather than modelled explicitly",
            "real_environment_description": "Real robotic platforms where inverse dynamics differ from simulation; specifics not given",
            "task_or_skill_transferred": "Controller policies corrected via learned inverse-dynamics discrepancy (general motor skills / control)",
            "training_method": "Learning-based correction on top of simulation (likely supervised/regression or RL for residuals)",
            "transfer_success_metric": null,
            "transfer_performance_sim": null,
            "transfer_performance_real": null,
            "transfer_success": null,
            "domain_randomization_used": null,
            "domain_randomization_details": null,
            "sim_to_real_gap_factors": "Mismatch in inverse dynamics between sim and real due to unmodelled actuator/sensor/contacts",
            "transfer_enabling_conditions": "Learning explicit corrections for inverse dynamics discrepancies to adapt simulated controllers to real-world behavior",
            "fidelity_requirements_identified": null,
            "fine_tuning_in_real_world": null,
            "fine_tuning_details": null,
            "comparison_across_fidelity_levels": null,
            "fidelity_comparison_results": null,
            "key_findings": "Suggests that modelling and learning the inverse-dynamics discrepancy is a viable strategy to reduce Sim2Real gaps, enabling more robust transfer without solely relying on improving simulator fidelity.",
            "uuid": "e1677.4",
            "source_info": {
                "paper_title": "Perspectives on Sim2Real Transfer for Robotics: A Summary of the R:SS 2020 Workshop",
                "publication_date_yy_mm": "2020-12"
            }
        },
        {
            "name_short": "Heiden Differentiable Sim",
            "name_full": "Augmenting Differentiable Simulators with Neural Networks to Close the Sim2Real Gap (Heiden et al.)",
            "brief_description": "Proposes a differentiable rigid-body dynamics formulation that enables training residual physics models and internal simulator parameters end-to-end, aiming to reduce sim-to-real discrepancy by backpropagating through physics models.",
            "citation_title": "Augmenting differentiable simulators with neural networks to close the sim2real gap",
            "mention_or_use": "mention",
            "agent_system_name": null,
            "agent_system_description": "Methodology for simulators rather than a single agent; intended to improve simulation models used to train controllers for robots.",
            "domain": "robotics - simulation / modelling",
            "virtual_environment_name": "differentiable rigid-body simulator (unspecified)",
            "virtual_environment_description": "Differentiable physics simulator modelling rigid-body dynamics, allowing gradient-based optimization of parameters and neural residuals.",
            "simulation_fidelity_level": "differentiable physics simulation with learnable residuals",
            "fidelity_aspects_modeled": "Rigid-body dynamics; backpropagation through forward physics to tune parameters and residuals",
            "fidelity_aspects_simplified": "Potentially complex non-differentiable phenomena may still be simplified or approximated to allow differentiability",
            "real_environment_description": null,
            "task_or_skill_transferred": "Improved simulator fidelity to support downstream Sim2Real transfer (general tasks implied)",
            "training_method": "Gradient-based optimization of simulator parameters and neural residuals using real data (system identification + ML)",
            "transfer_success_metric": null,
            "transfer_performance_sim": null,
            "transfer_performance_real": null,
            "transfer_success": null,
            "domain_randomization_used": null,
            "domain_randomization_details": null,
            "sim_to_real_gap_factors": "Simulator parameter mismatch and residual unmodelled physics; non-differentiable real phenomena",
            "transfer_enabling_conditions": "Differentiability enabling end-to-end fitting of simulator parameters and neural residual models from real data",
            "fidelity_requirements_identified": null,
            "fine_tuning_in_real_world": null,
            "fine_tuning_details": null,
            "comparison_across_fidelity_levels": null,
            "fidelity_comparison_results": null,
            "key_findings": "Differentiable simulation combined with neural residuals is a promising avenue to close reality gaps by directly optimizing simulator parameters against real data, though full differentiability may not always be necessary or feasible.",
            "uuid": "e1677.5",
            "source_info": {
                "paper_title": "Perspectives on Sim2Real Transfer for Robotics: A Summary of the R:SS 2020 Workshop",
                "publication_date_yy_mm": "2020-12"
            }
        },
        {
            "name_short": "Possas BayesSim",
            "name_full": "Online BayesSim for Combined Simulator Parameter Inference and Policy Improvement (Possas et al.)",
            "brief_description": "Proposes treating the simulator as a black box while using online inference of simulator parameters (BayesSim) during learning to align simulation with the real world and improve policies.",
            "citation_title": "Online bayessim for combined simulator parameter inference and policy improvement",
            "mention_or_use": "mention",
            "agent_system_name": null,
            "agent_system_description": "Framework for online simulator parameter inference used alongside policy learning for robotic systems.",
            "domain": "robotics - system identification / adaptive simulation",
            "virtual_environment_name": null,
            "virtual_environment_description": "Black-box simulator whose parameters are inferred online from real-world observations to reduce mismatch.",
            "simulation_fidelity_level": "black-box simulator with inferred parameters (fidelity depends on inference)",
            "fidelity_aspects_modeled": null,
            "fidelity_aspects_simplified": "Treats simulator as black box, so internal modelling details are not required; unmodelled phenomena remain unless parameterized",
            "real_environment_description": "Real robot or environment providing observations used to infer simulator parameters online",
            "task_or_skill_transferred": "General policy improvement via online simulator calibration (task-agnostic)",
            "training_method": "Online Bayesian inference of simulator parameters combined with policy learning",
            "transfer_success_metric": null,
            "transfer_performance_sim": null,
            "transfer_performance_real": null,
            "transfer_success": null,
            "domain_randomization_used": null,
            "domain_randomization_details": null,
            "sim_to_real_gap_factors": "Mis-specified simulator parameters, non-stationary dynamics, observation noise",
            "transfer_enabling_conditions": "Online parameter inference (Real2Sim) that closes loop between real observations and simulator calibration during learning",
            "fidelity_requirements_identified": null,
            "fine_tuning_in_real_world": null,
            "fine_tuning_details": null,
            "comparison_across_fidelity_levels": null,
            "fidelity_comparison_results": null,
            "key_findings": "A practical approach to reduce Sim2Real gaps by continuously inferring simulator parameters from real data during policy learning, enabling adaptive alignment between simulation and reality.",
            "uuid": "e1677.6",
            "source_info": {
                "paper_title": "Perspectives on Sim2Real Transfer for Robotics: A Summary of the R:SS 2020 Workshop",
                "publication_date_yy_mm": "2020-12"
            }
        },
        {
            "name_short": "Kadian HaPy / SRCC",
            "name_full": "Habitat-PyRobot Bridge (HaPy) and Sim-vs-Real Correlation Coefficient (SRCC) (Kadian et al.)",
            "brief_description": "Proposes a tool (HaPy) for executing code seamlessly on simulated agents and real robots and introduces SRCC as a metric to quantify whether simulation performance improvements correlate with real-world improvements.",
            "citation_title": "Sim2real predictivity: Does evaluation in simulation predict real-world performance?",
            "mention_or_use": "mention",
            "agent_system_name": "HaPy-enabled agents / robots (framework)",
            "agent_system_description": "Software bridge enabling shared codebases for simulated agents (Habitat) and real robots to facilitate comparable evaluation and transfer studies.",
            "domain": "robotics - benchmarking and evaluation",
            "virtual_environment_name": "Habitat (with PyRobot bridge)",
            "virtual_environment_description": "Simulated embodied environments for navigation and perception experiments; supports execution of same code on real robots via bridge",
            "simulation_fidelity_level": "simulated embodied environments (visual + navigation); fidelity varies with rendering and physics",
            "fidelity_aspects_modeled": "Visual rendering, geometry, navigation dynamics as supported by Habitat; sensor simulation for embodied agents",
            "fidelity_aspects_simplified": "Detailed physics/contact dynamics may be simplified depending on Habitat capabilities",
            "real_environment_description": "Real mobile robots and physical environments where the same agent code can be executed for comparison",
            "task_or_skill_transferred": "General navigation and embodied agent behaviors; focus on predictivity of simulation evaluations for real-world performance",
            "training_method": "Not a training method; provides evaluation/benchmarking infrastructure and a correlation metric (SRCC)",
            "transfer_success_metric": "Sim-vs-Real Correlation Coefficient (SRCC) measuring correlation between simulation and real performance improvements",
            "transfer_performance_sim": null,
            "transfer_performance_real": null,
            "transfer_success": null,
            "domain_randomization_used": null,
            "domain_randomization_details": null,
            "sim_to_real_gap_factors": "Mismatch between simulated and real sensor/actuator/perceptual conditions leading to low predictivity",
            "transfer_enabling_conditions": "Unified evaluation codepath and a metric (SRCC) to assess whether simulation improvements generalize to real-world gains",
            "fidelity_requirements_identified": null,
            "fine_tuning_in_real_world": null,
            "fine_tuning_details": null,
            "comparison_across_fidelity_levels": null,
            "fidelity_comparison_results": null,
            "key_findings": "Proposes practical tooling and a correlation metric to assess whether simulation evaluations are predictive of real-world improvements, addressing the need for better Sim2Real benchmarking.",
            "uuid": "e1677.7",
            "source_info": {
                "paper_title": "Perspectives on Sim2Real Transfer for Robotics: A Summary of the R:SS 2020 Workshop",
                "publication_date_yy_mm": "2020-12"
            }
        },
        {
            "name_short": "BlenderProc",
            "name_full": "BlenderProc: Reducing the Reality Gap with Photorealistic Rendering (Denninger et al.)",
            "brief_description": "A pipeline for procedural generation of labeled photorealistic images using Blender to produce synthetic training data for vision tasks, intended to reduce the visual reality gap for Sim2Real.",
            "citation_title": "Blenderproc: Reducing the reality gap with photorealistic rendering",
            "mention_or_use": "mention",
            "agent_system_name": null,
            "agent_system_description": "Data-generation pipeline rather than a single robot; used to generate labeled vision datasets for downstream robotic perception tasks.",
            "domain": "computer vision for robotics / perception",
            "virtual_environment_name": "Blender (via BlenderProc pipeline)",
            "virtual_environment_description": "Photorealistic rendering environment that simulates lighting, textures, geometry to produce labeled synthetic images",
            "simulation_fidelity_level": "photorealistic rendering (high visual fidelity)",
            "fidelity_aspects_modeled": "Lighting, textures, geometry, camera rendering and labels for vision tasks",
            "fidelity_aspects_simplified": "Physical dynamics, contact physics, and sensor temporal characteristics not central to rendering pipeline",
            "real_environment_description": "Real images and robotic vision setups used to validate segmentation and detection models",
            "task_or_skill_transferred": "Vision tasks such as image segmentation and object detection trained on synthetic data and applied to real images",
            "training_method": "Supervised learning on synthetic photorealistic datasets",
            "transfer_success_metric": null,
            "transfer_performance_sim": null,
            "transfer_performance_real": null,
            "transfer_success": null,
            "domain_randomization_used": null,
            "domain_randomization_details": null,
            "sim_to_real_gap_factors": "Visual domain gap due to differences in rendering vs. real sensor capture; label distortion risk with domain adaptation",
            "transfer_enabling_conditions": "High-quality photorealistic rendering and procedural generation to create diverse labeled datasets that better match real-world visuals",
            "fidelity_requirements_identified": "High visual fidelity helps vision tasks, but requires good CAD models and careful label consistency",
            "fine_tuning_in_real_world": null,
            "fine_tuning_details": null,
            "comparison_across_fidelity_levels": null,
            "fidelity_comparison_results": null,
            "key_findings": "Photorealistic synthetic data pipelines can reduce the visual reality gap for vision tasks, enabling Sim2Real for perception components when CAD models and rendering are adequate.",
            "uuid": "e1677.8",
            "source_info": {
                "paper_title": "Perspectives on Sim2Real Transfer for Robotics: A Summary of the R:SS 2020 Workshop",
                "publication_date_yy_mm": "2020-12"
            }
        },
        {
            "name_short": "Zhang Contact Rich Critique",
            "name_full": "Necessity for More Realistic Contact Simulation (Zhang)",
            "brief_description": "A position arguing that the reality gap for contact-rich manipulation tasks is too large for current simulators to support positive transfer even with domain randomization, highlighting the limitations of existing contact models.",
            "citation_title": "Necessity for more realistic contact simulation",
            "mention_or_use": "mention",
            "agent_system_name": null,
            "agent_system_description": null,
            "domain": "robotics - contact-rich manipulation",
            "virtual_environment_name": null,
            "virtual_environment_description": "Critique of current simulators' limited ability to model realistic contact phenomena",
            "simulation_fidelity_level": "insufficient/low-fidelity for contact-rich tasks",
            "fidelity_aspects_modeled": "Basic contact and friction models (often Coulomb/idealized) in many simulators",
            "fidelity_aspects_simplified": "Complex frictional, anisotropic, and contact phenomena; realistic contact geometry and material interactions",
            "real_environment_description": "Contact-rich manipulation environments (e.g., precision agriculture, deformable object handling)",
            "task_or_skill_transferred": "Contact-rich manipulation tasks (argued to be poorly supported by current Sim2Real)",
            "training_method": null,
            "transfer_success_metric": null,
            "transfer_performance_sim": null,
            "transfer_performance_real": null,
            "transfer_success": false,
            "domain_randomization_used": null,
            "domain_randomization_details": null,
            "sim_to_real_gap_factors": "Inaccurate contact models, simplified friction models (isotropic Coulomb), and NP-hard nature of realistic contact simulation",
            "transfer_enabling_conditions": "Higher-fidelity contact simulation or alternative strategies (e.g., learning residuals, system identification) required; domain randomization alone often insufficient",
            "fidelity_requirements_identified": "Argues contact-rich tasks require more realistic contact modelling than many current simulators provide, though no numeric fidelity thresholds given",
            "fine_tuning_in_real_world": null,
            "fine_tuning_details": null,
            "comparison_across_fidelity_levels": false,
            "fidelity_comparison_results": null,
            "key_findings": "For contact-rich manipulation, current simulators are often too inaccurate for reliable Sim2Real; improved contact modelling or alternative bridging techniques are necessary.",
            "uuid": "e1677.9",
            "source_info": {
                "paper_title": "Perspectives on Sim2Real Transfer for Robotics: A Summary of the R:SS 2020 Workshop",
                "publication_date_yy_mm": "2020-12"
            }
        },
        {
            "name_short": "Raparthy CUNAS",
            "name_full": "CUNAS  Curiosity-driven Neural-Augmented Simulator (Raparthy et al.)",
            "brief_description": "Proposes a curiosity-driven approach to collect real-world data to train a physics-based simulator augmented with a neural residual, aiming to close sim-to-real gaps by targeted data collection and learned corrections.",
            "citation_title": "Cunascuriosity-driven neural-augmented simulator",
            "mention_or_use": "mention",
            "agent_system_name": null,
            "agent_system_description": "Method for simulator improvement via curiosity-guided data collection and neural residual modelling rather than a single robot system",
            "domain": "robotics - simulator learning / system identification",
            "virtual_environment_name": "physics-based simulator with neural residual (unspecified)",
            "virtual_environment_description": "Physics simulator augmented by a learned neural residual to better match real-world dynamics",
            "simulation_fidelity_level": "physics-based with neural augmentation",
            "fidelity_aspects_modeled": "Nominal physical dynamics (gravity, rigid-body dynamics) plus learned residuals for unmodelled effects",
            "fidelity_aspects_simplified": "Certain detailed phenomena left to neural residual rather than explicitly modelled",
            "real_environment_description": "Real robot/environment data collected via curiosity-driven exploration to train the simulator residual",
            "task_or_skill_transferred": "Simulator improvement to support better policy transfer (general tasks implied)",
            "training_method": "Curiosity-driven data collection + learning neural residuals (ML/system identification hybrid)",
            "transfer_success_metric": null,
            "transfer_performance_sim": null,
            "transfer_performance_real": null,
            "transfer_success": null,
            "domain_randomization_used": null,
            "domain_randomization_details": null,
            "sim_to_real_gap_factors": "Unmodelled dynamics and simulator parameter mismatch; insufficient data in regions critical for task performance",
            "transfer_enabling_conditions": "Targeted real-data collection guided by curiosity and training neural residuals to correct simulator predictions",
            "fidelity_requirements_identified": null,
            "fine_tuning_in_real_world": null,
            "fine_tuning_details": null,
            "comparison_across_fidelity_levels": null,
            "fidelity_comparison_results": null,
            "key_findings": "Active data collection combined with neural residual models offers a strategy to improve simulators in task-relevant regions and reduce Sim2Real gaps without requiring full high-fidelity modelling.",
            "uuid": "e1677.10",
            "source_info": {
                "paper_title": "Perspectives on Sim2Real Transfer for Robotics: A Summary of the R:SS 2020 Workshop",
                "publication_date_yy_mm": "2020-12"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Solving rubik's cube with a robot hand",
            "rating": 2,
            "sanitized_title": "solving_rubiks_cube_with_a_robot_hand"
        },
        {
            "paper_title": "Learning agile and dynamic motor skills for legged robots",
            "rating": 2,
            "sanitized_title": "learning_agile_and_dynamic_motor_skills_for_legged_robots"
        },
        {
            "paper_title": "Learning ambidextrous robot grasping policies",
            "rating": 2,
            "sanitized_title": "learning_ambidextrous_robot_grasping_policies"
        },
        {
            "paper_title": "Deep drone acrobatics",
            "rating": 2,
            "sanitized_title": "deep_drone_acrobatics"
        },
        {
            "paper_title": "Learning to walk without dynamics randomization",
            "rating": 2,
            "sanitized_title": "learning_to_walk_without_dynamics_randomization"
        },
        {
            "paper_title": "Robust sim2real transfer by learning inverse dynamics of simulated systems",
            "rating": 2,
            "sanitized_title": "robust_sim2real_transfer_by_learning_inverse_dynamics_of_simulated_systems"
        },
        {
            "paper_title": "Blenderproc: Reducing the reality gap with photorealistic rendering",
            "rating": 2,
            "sanitized_title": "blenderproc_reducing_the_reality_gap_with_photorealistic_rendering"
        },
        {
            "paper_title": "Online bayessim for combined simulator parameter inference and policy improvement",
            "rating": 2,
            "sanitized_title": "online_bayessim_for_combined_simulator_parameter_inference_and_policy_improvement"
        },
        {
            "paper_title": "Cunascuriosity-driven neural-augmented simulator",
            "rating": 2,
            "sanitized_title": "cunascuriositydriven_neuralaugmented_simulator"
        },
        {
            "paper_title": "Sim2real predictivity: Does evaluation in simulation predict real-world performance?",
            "rating": 2,
            "sanitized_title": "sim2real_predictivity_does_evaluation_in_simulation_predict_realworld_performance"
        },
        {
            "paper_title": "Necessity for more realistic contact simulation",
            "rating": 1,
            "sanitized_title": "necessity_for_more_realistic_contact_simulation"
        }
    ],
    "cost": 0.01862425,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Perspectives on Sim2Real Transfer for Robotics: A Summary of the R:SS 2020 Workshop</p>
<p>Sebastian Hfer 
Kostas Bekris 
Ankur Handa 
Juan Camilo Gamboa 
Florian Golemo 
Melissa Mozifian 
Chris Atkeson 
Dieter Fox 
Ken Goldberg 
John Leonard 
C Karen Liu 
Jan Peters 
Shuran Song 
Peter Welinder 
Martha White 
Perspectives on Sim2Real Transfer for Robotics: A Summary of the R:SS 2020 Workshop</p>
<p>This report presents the debates, posters, and discussions of the Sim2Real workshop held in conjunction with the 2020 edition of the "Robotics: Science and System" conference. Twelve leaders of the field took competing debate positions on the definition, viability, and importance of transferring skills from simulation to the real world in the context of robotics problems. The debaters also joined a large panel discussion, answering audience questions and outlining the future of Sim2Real in robotics. Furthermore, we invited extended abstracts to this workshop which are summarized in this report. Based on the workshop, this report concludes with directions for practitioners exploiting this technology and for researchers further exploring open problems in this area.</p>
<p>I. INTRODUCTION</p>
<p>Simulation is an important tool for developing robotic agents. While simulation has been well-established for robotics education and integrated robot software testing for years, there is an ongoing debate in the research community about the ability to transfer robotics skills learned in simulation to reality, a concept termed Sim2Real transfer.</p>
<p>The appeal of learning in simulation stems from the fact that it can be faster than real-time, cheaper, safer, and more informative (e.g. providing perfect ground truth labels) than real-world experimentation. Recent work in Sim2Real has studied difficult real-world robotic problems related to autonomous driving, grasping, or in-hand manipulation with policies trained in simulation only. Fig. 1 highlights some of the work carried out this year. However, Sim2Real still faces significant challenges, and it remains an open question to which extent and in which problem domains Sim2Real can compete with or outperform techniques based on real-world experimentation.</p>
<p>To shed light on these questions, we organized a scientific workshop on the topic of Sim2Real transfer, which was held at the Robotics: Science and Systems (R:SS) 2020 17 conference. We invited subject matter experts to debate the state of the art and future of the field. The highlight of the workshop were three debates with the following topics and corresponding controversial key statements:</p>
<p> Why should we invest in Sim2Real? -"Sim2Real is a waste of time and money."  What is Sim2Real? -"Sim2Real is old news. It is just [model-based reinforcement learning | domain randomization | system identification | . . .]."  How should we apply Sim2Real? -"For successful sim2real transfer, there is no alternative to accurate simulation." In order to ensure that a wide range of arguments were considered during the debates, we divided the debate participants equally into proponents and opponents (two debaters for each side in each debate) and asked them to adhere to their assigned role throughout the debate.</p>
<p>The workshop also featured contributed work in the form of 18 peer-reviewed two-page abstracts and was concluded with a panel discussion including all debate participants.</p>
<p>The goal of this article is to summarize the workshop and draw conclusions about Sim2Real for robotics from both from a practitioner's as well as a researcher's perspective. In the first part, we summarize the three debates and the concluding panel discussion, highlighting the main arguments brought forward during the debates 18 and the panel. The second part gives an overview of the contributed work, highlighting the main themes and summarizing individual contributions. In the last section, we draw lessons from the workshop to give concrete recommendations to practitioners on how to apply Sim2Real to their robotic applications, and to gather fundamental open questions in Sim2Real that require the attention of future research.</p>
<p>II. THE SIM2REAL DEBATES</p>
<p>A. Debate 1: Why should we invest in Sim2Real?</p>
<p>The debates started off by questioning the motivation for using Sim2Real transfer. Chris Atkeson and Abhinav Gupta argued in favor of and Ken Goldberg and Peter Welinder against the controversial statement "Sim2Real is waste of time and money". We present the key topics covered in the debate which can be broadly clustered into the actual monetary cost and the effectiveness/time saved by Sim2Real.</p>
<p>Sim2Real is cheap. The opponent side argued that Sim2Real is significantly cheaper than real world experimentation due to the reduced cost in building and maintaining (a) Learning locomotion skills by imitating animals [18] (b) RL-CycleGAN [20] (c) Deep Drone Acrobatics [10] (d) Sim to real on granular media [14] (e) Manipulating Rubik's cube with dexterous hand [15]  real robots. The proponents countered that Sim2Real being cheap is a myth as training a policy for OpenAI's Rubik's cube costed several thousands of dollars for simulation alone and over a year of development was necessary to successfully transfer policies to the real world [16]. The opponents argued that the high cost reflects the fact that Sim2Real was applied to a problem of such complexity for the first time, and that its cost will reduce significantly, similar to how the cost of robotic hardware decreased over the last decades.</p>
<p>Sim2Real democratizes research vs. "Sim2Null". Given the low cost of simulation compared to real-robot experiments, simulation clearly lowers the entry barrier for students and researchers. However, there was consensus that easy-touse simulation environments like OpenAI gym also lead to a rise of simulation-only research that does not generalize to the real world -a concept Ken Goldberg termed Sim2Null.</p>
<p>Sim2Real is diverse. Another variant of the cost argument relates to the diversity of data that can be acquired through simulation. While it is possible to sample millions of variants of the same task using techniques like domain randomization, the proponent side suggested that data collection in the real world can generate much more diverse data sets cheaply, for example by renting apartments and exploring them with robots. All agreed that realistic non-deterministic simulation is understudied.</p>
<p>Sim2Real already works. The opponents highlighted that there are various successful applications of Sim2Real, such as in civil engineering and aircraft design, but also in robotic grasping [12]. The proponents objected that "Sim2Real works" is not a well-defined statement, and that many approaches, in particular policies trained in OpenAI gym, generalize poorly if at all to the real world.</p>
<p>Simulation as a necessary but not sufficient condition for success in real. Another argument revolved around the question whether successful performance in simulation is a necessary condition for success in the real world. The opponent side argued for this view, highlighting the opportunity to accelerate research using simulation. The proponents questioned the idea of simulation as a necessary condition, since overly simplified modeling of the world and its modalities may render the simulated problem much harder than the real one.</p>
<p>Sim2Real is safe. There was agreement that experimentation in Sim2Real is inherently safe and thus useful for dangerous tasks and exploration. However, the proponent side argued that robots are becoming safer themselves, for example soft robots.</p>
<p>Sim2Gradstudent2Real. All panelists agreed that the state of the art in Sim2Real involves a large amount of manual tuning. The proponent side criticized this fact and suggested that useful Sim2Real research should be concerned with rigorous modeling and problem understanding [7]. In contrast, the opponent side argued that this situation motivates investigating in data-efficient general-purpose Sim2Real methods.</p>
<p>In the closing remarks, all speakers unanimously agreed that simulations alone are not sufficient. There was agreement that simulation tasks and benchmarks need to become more challenging and that researchers need to run convincing real-world experiments rather than drawing general conclusions from simulation-only experiments.</p>
<p>B. Debate 2: What Is Sim2Real?</p>
<p>The second debate topic addressed the question of whether Sim2Real qualifies as a methodology or field of its own. Jan Peters and Martha White argued in favor of and Greg Dudek and John Leonard against the controversial statement "Sim2Real is old news. It is just [model-based Reinforcement Learning | domain randomization | system identification | . . .]". The debate centered around the issues of building upon existing work, providing grounds for a community to form, and the specifics of the field that make it unique.</p>
<p>Sim2Real is prior art. The proponent side's main argument was that current Sim2Real methods date back to the 1960s to 1980s, with the main difference being the scale of computational resources available. For example, Real2Sim can be regarded as system identification and Sim2Real as adaptive control: Both combine analytical models with parametric ones (such as shallow neural networks) in order to model complex systems and learn controllers. Similarly, model-based reinforcement learning can be regarded as a method that iteratively refines a poor model or simulation of the world to learn a controller for the real world.</p>
<p>Sim2Real brings together distant research communities. While acknowledging that the techniques used in Sim2Real are not necessarily new, the opposing side argued that Sim2Real approaches have had significant impact on a wide variety of research domains beyond control (like perception and physical modelling). Therefore, treating Sim2Real as a field of its own provides value by connecting researchers from different disciplines, including robotics, computer vision, control theory, physics-based modelling, reinforcement learning and simulation-based inference.</p>
<p>Impact of the reality gap on Sim2Real. Both sides agreed that highly accurate simulations of reality remain a distant "pipe dream" for robotics: there will always exist a reality gap, for any level of sophistication of computer simulations. The debaters disagreed on the impact of this statement on the debate topic. The opponent side argued that the inability to close the reality gap justifies the existence of Sim2Real as a field of its own: Rather than reducing Sim2Real to making simulators more accurate, Sim2Real would then be the field that studies how useful information can be extracted from models that are not entirely accurate. The proponents countered that if Sim2Real is not about closing the reality gap with better modelling, it would simply re-brand existing techniques in robust control.</p>
<p>C. Debate 3: How should we apply Sim2Real?</p>
<p>The goal of the third debate was to shed light on the relationship between Sim2Real methods and accurate simulations. Dieter Fox and Karen Liu argued in favor and Anca Dragan and Shuran Song against the controversial statement "For successful Sim2Real transfer, there is no alternative to accurate simulation". The debate touched upon a variety of topics, from levels of abstraction to the trade-off between accuracy and generalization.</p>
<p>Right level of abstraction. The debaters agreed that finding the right level of abstraction is key, yet difficult as it presupposes knowing what is relevant to the task. Both sides agreed that current simulators do not model physical phenomena sufficiently well. While the proponent side concluded that this situation calls for investing into better modeling at lower levels of abstraction, the opponent side argued that high-level abstraction suffices, comparing simulation of physical interaction with human behavior: Robots need to learn to collaborate with humans without simulating the entire human brain, so why would physical interaction require low-level simulation of physics? Furthermore, humans themselves learn from "abstract simulation", such as books and movies. Imprecision. Assuming a given level of abstraction, the debaters discussed the implications of imprecise simulation. The opponents argued that accurate modelling is expensive and often infeasible. Additionally, any abstraction -and thus, any simulator -inevitably results in a loss of accuracy due to the fact that it does not capture the underlying process. The proponent side argued that imprecise simulators at any level of abstraction are useless because, once deployed to the real world, the agent has to unlearn a lot of what it had learned in the imprecise simulator. The only way to get around this issue is heavy domain randomization over a large set of simulation parameters, which however does not scale for more complex tasks and environments. The opposing side argued that exactly this imperfection and deliberate bias causes model resilience and policy generalization.</p>
<p>Generalization and Extrapolation. Another argument of the proponents against imprecise simulation concerned its limited generalization capability: A precise simulator is a useful building block to solve many different problems, while an imprecise simulator will work for some but not other tasks. The proponent side explicitly distinguished generalpurpose simulators from task-specific internal models, which do not need to be precise but only serve a single purpose.</p>
<p>Uncertainty and Noise. The speakers agreed upon the importance of explicit uncertainty estimates, i.e. modeling where the simulator is uncertain about its future state predictions. Such estimates, while difficult to obtain, would be useful to identify failure cases early on or leverage them to collect data for improving the simulator.</p>
<p>III. PANEL DISCUSSION</p>
<p>The workshop was concluded with a panel discussion. During the panel, the debaters were allowed to express their personal opinions and a few debaters noticed that their opinions had reshaped after defending extreme positions during the debates. The lively panel was a free-form discussion with some recurring topics which we summarize in this section.</p>
<p>Task-agnostic vs. task-specific simulation. An important question to the panel was whether simulators should be taskagnostic or task-specific. The panelists agreed that there are diminishing returns in improving task-agnostic simulation as we ultimately care about task performance, not simulation accuracy. Moreover, certain domains such as underwater robotics or scenarios involving human interaction are still beyond the scope of state-of-the-art simulators. At the same time, task-agnostic simulators are regarded as the only means to provide tools that generalize across a sufficiently large range of problems. The panelists mentioned domain randomization as a success story that shows how task-agnostic stateof-the-art simulation tools allow to learn real-world policies. At the same time, there was agreement that it remains an open question how to apply this technique at scale.</p>
<p>Several alternatives to task-agnostic simulation were considered. One proposition was to invest in task-agnostic but customizable simulators. Such a simulator could be obtained by closing the loop and iteratively tuning the simulation to the world using Real2Sim and system identification.</p>
<p>The panelists identified differentiable simulators as another promising research direction. The main benefit of this direction is that it moves simulation closer to models which can be used in model-based optimization, allowing for computing derivatives and thus improving the controller directly. There were doubts whether full differentiability is needed since many real world phenomena are not differentiable and this would inevitably make simulator design more complex.</p>
<p>Meta learning was identified as an promising orthogonal direction. The key idea is to learn to adapt to a changing world (in simulation) rather than attempting to learn all the characteristics of the world.</p>
<p>Sim2Real as a research discipline on its own (with its own symposia and academic curriculum). The panelists acknowledged the importance of Sim2Real in its own right, hypothesizing that Sim2Real could be a way of building bridges between disciplines across non-traditional paths, potentially through a Sim2Real grand challenge. The panel agreed that we should refrain from introducing new symposia and conferences to avoid further fragmentation of the robotics community, and to continue exploring Sim2Real in scientific workshops.</p>
<p>The value of robotics research performed exclusively in simulation (Sim2Sim). There was wide agreement that the ultimate goal is to design robotic systems that live in the real-world. Nevertheless, simulation-only results can provide valuable insights, for examples by providing repeatable benchmarks on standardized tasks. Therefore, there should not be a rejection by default of papers that do not contain real-world experiments. At the same time, authors need to do due diligence and provide convincing evidence about the real-world applicability of new approaches that are only validated in simulation. Moreover, the community should invest into creating simulators that simplify the job of researchers as well as practitioners and allow for better Sim2Real transfer.</p>
<p>IV. PRESENTED ABSTRACTS</p>
<p>18 short research abstracts were selected to be presented in the workshop during three 20-minutes interactive sessions. Authors were invited to submit work on topics related to Sim2Real, including methods for improving simulator accuracy, training robust controllers, formalizing the Sim2Real problem, assessing the difficulty of and benchmarking strategies for Sim2Real. Below, we provide a short summary of each work.</p>
<p>A. On the formalization and difficulty of Sim2Real</p>
<p>One of the standing issues in Sim2Real is the lack of a framework for comparing Sim2Real solutions. Paull et al. [17] propose to distinguish between the use of the simulator as a predictor vs. as a teacher, and argue that regardless of its role, the value of any simulator is its impact on final task performance.</p>
<p>On the topic of the difficulty of Sim2Real, multiple submissions explored the question whether current simulators are adequate for solving complex manipulation and locomotion tasks. Zhang [26] argues that the gap between current simulators for contact-rich tasks is too wide to expect any positive transfer, even when considering domain randomization. Rizzardo et al. [22] describe one such contact-rich task, precision agriculture, where simulation of fruit picking is a bottleneck for Sim2Real. Dao et al. [3] show show how a state-of-the-art simulator, with its limitations in simulating contacts, can be used to train controllers that successfully transfer to real a walking bipedal robot without using any domain randomization.</p>
<p>Finally, on the topic of benchmarking, Kadian et al. [9] introduce Habitat-PyRobot Bridge (HaPy), a library for seamless execution of code on simulated agents and robots, and propose using the Sim-vs-Real Correlation Coefficient (SRCC) as a transfer metric: to evaluate whether improvements in performance in simulation are correlated with improvements in the real world.</p>
<p>B. On bridging the reality gap with existing simulators</p>
<p>A successful technique for Sim2Real is to explicitly design or learn intermediate representations that generalize between simulation data and real data. Zhang et al. [25] propose to using an off-the-shelf 3D object detector to train obstacle avoidance policies for manipulation that directly transfer to the real world without the need of a visually accurate simulator. Related to this approach, Liang et al. [11] train obstacle avoidance policies for mobile robot navigation in simulated environments to navigate crowds. Here, the intermediate representation is provided by laser scan readings, which are easier to simulate than cameras. Yan et al. [24] propose to learn intermediate representations for deformable object manipulation by jointly optimizing both the visual representation model and the dynamics model using contrastive estimation. Antonova et al. [1] propose a metarepresentation learning approach that infers analytic relations from simulation and leverages these relations when learning intermediate representations in the real domain.</p>
<p>A related approach for vision tasks is to use off-the-shelf photorealistic rendering engines to produce self-labeled data. Denninger et al. [4] introduce BlenderProc, a pipeline for procedural generation of labelled data for vision tasks, which the authors demonstrate on the task of image segmentation. Wu et al. [23] leverage domain randomization to generalize deformable object manipulation policies to the real domain.</p>
<p>Finally, the Sim2Real gap can be addressed at the policy level. Malmir et al. [13] introduce a method that leverages the discrepancies between inverse dynamics in simulation and the real world to compute corrections to controllers learned in simulation. Josifovski et al. [8] propose reducing the Sim2Real gap using curriculum learning, by training the robot on increasingly more difficult versions of the task.</p>
<p>C. On bridging the reality gap with improved models and real-world data</p>
<p>Based on the intuition that more accurate models are more likely to transfer to real, several submissions propose leveraging real-world data for improving simulators.</p>
<p>Raparthy et al. [21] propose a curiosity-based data collection scheme for training a physics-based simulator with a residual model for the discrepancies between real-world and simulated data. Heiden et al. [6] propose a differentiable formulation of rigid-body dynamics that allows training both a residual physics model along with the internal parameters of the simulator, allowing to backpropagate through the physics-based model.</p>
<p>Possas et al. [19] take an alternative approach, where the simulator is treated as a black-box, and real-world data is used to infer the parameters of the simulator online as a robot is learning to execute a task. Antonova et al. [2] propose a related method, where inference is done with Gaussian Processes with kernels learned from simulation data. Similarly, Desai et al. [5] propose to reduce the distribution mismatch between simulator and real world by learning behaviors that mimic the observations of behavior demonstrations.</p>
<p>V. KEY DIRECTIONS FORWARD</p>
<p>The workshop debates and contributed papers provide a view on the state-of-the-art in Sim2Real techniques and open problems in this area. This section summarizes the findings and conclusions from the workshop, which we classify as belonging to either a practitioner's or a researcher's perspective. For the practitioner's perspective, we aim to give concrete advice on applying existing Sim2Real techniques, their capabilities and their limitations 19 . For the researcher's perspective, we state fundamental research problems identified during the workshop, hoping to inspire future research endeavors.</p>
<p>A. Practitioner's View: What Can Sim2Real Already Achieve?</p>
<p>The first question that practitioners should ask themselves is whether their problem setting would benefit from Sim2Real techniques. The following list of requirements constitute criteria that can provide guidance in answering this question:</p>
<p> Bootstrapping: Is it possible to obtain a proof of concepts relevant to the real-world problem in simulation? Simulators can be extremely helpful for scoping the problem and initial hypothesis testing. For learning and adaptive systems, learning in a carefully tuned simulator is an effective way to bootstrap learning in the real world.  Long-term data starvation: Is the effort in collecting real world data, especially labeled data, considerably higher, more dangerous or even infeasible relative to the effort of developing a simulator? Simulators can be a valuable and endless source of labeled synthetic data, in particular if data is and remains hard to collect due to cost or safety constraints. However, real data should be preferred if available in sufficient quantities.  Hardware-in-the-loop optimization: Is the goal to co-design hardware and software? In such scenarios there may be no alternative to simulation. Sim2Real techniques can be useful for learning and exploring the hardware design space, which may be impractical without a simulator.  Common computer vision problems: Is the problem mainly a computer vision task? Object detection, image segmentation and geometry estimation have received significant attention in the last decade, with the role of synthetic data becoming more prominent as part of their solutions. To address the requirements from the previous list, we summarize some of the techniques that have been shown to work well in practice.</p>
<p>Domain randomization (DR) is a simple yet powerful technique to augment the training set, and particularly well suited for training deep neural networks. The main challenges, however, correspond to finding the right set of parameters to randomize. The cost of applying DR grows exponentially with the number of parameters.</p>
<p>Explicit transferable abstractions A powerful alternative to DR is identifying explicit features or state abstractions, which transfer easily between simulated and real data. For example, pre-processing images into segmented images, edges, depth maps or using off-the-shelf image-to-image translation methods circumvents the problem of generating realistic images in simulation, but it still requires careful tuning.</p>
<p>Combining analytical modeling with system identification (SysID) In some settings we can identify challenging problem aspects, which can be modeled analytically and apply SysID/ML for them. This approach has been successfully used for grasping and locomotion, and is commonplace in model-based control. Nevertheless, finding appropriate models is a challenging task.</p>
<p>Meta-Learning and Curriculum Learning: A common limitation of Sim2Real is its application to situations where the robot dynamics are hard to simulate, e.g. simulating the transformation from control signals to motor torques. While learning SysID modules is a possible way of exploiting simulated data, meta-learning provides an alternative for directly learning systems that adapt to changing environments or erroneous models. DR techniques can be used to provide a task distribution for meta-learning. Furthermore, controlling DR simulators can be an effective way of controlling the difficulty of learning.</p>
<p>Depth &amp; RGB rendering Depth sensors including their noise models can be effectively simulated and transfer smoothly to the real world RGB rendering is also catching up, and recent work has shown increasingly better Sim2Real generalization [12]. These approaches, however, generally require high-quality CAD models to be available.</p>
<p>Domain adaption via GANs A complementary technique is to enhance the quality of synthetically generated images using domain adaption techniques [28]. One challenge here is to make sure the labels are not distorted.</p>
<p>As a final remark, it is important to be aware of the fact that Sim2Real techniques are not yet Plug-&amp;-Play nor completely automated. Their application still requires careful human attention for understanding the problem and for tuning the parameters of the chosen approach. Systematic and Efficient Domain Randomization (DR) Existing DR methods are computationally wasteful, even after careful selection of the randomization distributions. Furthermore, selecting the appropriate randomization distribution may be as hard as the problems we would like to address with DR. What methods can help us automate the selection of a DR distribution? What are the data requirements of these methods? Can we establish how hard finding a DR distribution is? Can we accelerate learning using a DR schedule or curriculum?</p>
<p>Contact-Rich Tasks Many simulators struggle to simulate physically realistic contacts. Contacts with friction is in general an NP-hard problem and many simulators implement contacts with isotropic Coulomb friction, which is an inaccurate approximation of real contacts. What level of accuracy is necessary for applying Sim2Real techniques to these important aspects for manipulation and locomotion?</p>
<p>Differentiable Simulators There is growing interest in creating simulation pipelines, which allows differentiating the stack of operations involved in simulating dynamics and rendering. This is a promising direction as that could allow rapid testing and learning of the simulation parameters. Is differentiability a requirement for successful Sim2Real? Do the benefits of differentiable simulation outweigh the cost of replacing existing black-box simulators? Are there fundamental limits to closing the reality gap with differentiable simulation?</p>
<p>Highly Accurate Simulations As time goes on, the capabilities for high-fidelity simulation and rendering keep improving in accuracy and speed. Will this trend continue to a point where high fidelity simulation becomes an easily accessible commodity for most robotics tasks? How can we improve the simulation accuracy and speed for fabrics, deformable materials as well as contact-rich tasks? Are there any fundamental limits to simulation?</p>
<p>Production-level Sim2Real How can we push task performance using Sim2Real to production level (99.99% success rates)?</p>
<p>VI. CONCLUSION</p>
<p>The workshop highlighted the fact that Sim2Real is a "hot topic", with many academic and industrial institutions putting significant resources into investigating the applying and developing Sim2Real approaches. While there was no agreement in the debates as to how far Sim2Real will take us in the future and whether it is the right approach in general, there was consensus on what Sim2Real can do for robotics applications today. A community is forming around the problem with a steadily increasing number of submissions. This may require the introduction of this keyword as a separate category during submission to the main robotics venues, if not potentially devoted meetings in this area. While the future will tell how Sim2Real will evolve and what impact it may have on the next breakthroughs in robotics, it is an exciting area to explore from many different perspectives.</p>
<p>Fig. 1 :
1Various state-of-the-art applications of Sim2Real in robotics published in 2019-2020.</p>
<p>B. Researcher's View: What Are the Open Questions? While the current Sim2Real methods have shown promising results for real world problems, there remain important open questions and unsolved problems.
In general, we avoid highlighting the debaters' names since they were assigned fixed positions which might not reflect their actual beliefs.
We mainly focus on established techniques that have relevance for the workshop. For a recent, more complete survey see e.g.[27].
ACKNOWLEDGEMENTSThe authors would like to thank Anca Dragan, Gregory Dudek and Abhinav Gupta for their contributions to the debates and panel discussion as well as the R:SS 2020 organizers for hosting our workshop.
Modular latent space transfer with analytic manifold learning. R Antonova, M Maydanskiy, D Kragic, S Devlin, K Hofmann, 2nd Workshop on Closing the Reality Gap in Sim2Real Transfer for Robotics. RSS. R. Antonova, M. Maydanskiy, D. Kragic, S. Devlin, and K. Hofmann. Modular latent space transfer with analytic manifold learning. In 2nd Workshop on Closing the Reality Gap in Sim2Real Transfer for Robotics. RSS, 2020.</p>
<p>How to sim2real with gaussian processes: Prior mean versus kernels as priors. R Antonova, A Rai, D Kragic, 2nd Workshop on Closing the Reality Gap in Sim2Real Transfer for Robotics. RSS. R. Antonova, A. Rai, and D. Kragic. How to sim2real with gaussian processes: Prior mean versus kernels as priors. In 2nd Workshop on Closing the Reality Gap in Sim2Real Transfer for Robotics. RSS, 2020.</p>
<p>Learning to walk without dynamics randomization. J Dao, H Duan, K Green, J Hurst, A Fern, 2nd Workshop on Closing the Reality Gap in Sim2Real Transfer for Robotics. RSS. J. Dao, H. Duan, K. Green, J. Hurst, and A. Fern. Learning to walk without dynamics randomization. In 2nd Workshop on Closing the Reality Gap in Sim2Real Transfer for Robotics. RSS, 2020.</p>
<p>Blenderproc: Reducing the reality gap with photorealistic rendering. M Denninger, M Sundermeyer, D Winkelbauer, D Olefir, T Hodan, Y Zidan, M Elbadrawy, M Knauer, H Katam, A Lodhi, 2nd Workshop on Closing the Reality Gap in Sim2Real Transfer for Robotics. RSS. M. Denninger, M. Sundermeyer, D. Winkelbauer, D. Olefir, T. Hodan, Y. Zidan, M. Elbadrawy, M. Knauer, H. Katam, and A. Lodhi. Blenderproc: Reducing the reality gap with photorealistic rendering. In 2nd Workshop on Closing the Reality Gap in Sim2Real Transfer for Robotics. RSS, 2020.</p>
<p>An imitation from observation approach to sim-to-real transfer. S Desai, I Durugkar, H Karnan, G Warnell, J Hanna, P Stone, 2nd Workshop on Closing the Reality Gap in Sim2Real Transfer for Robotics. RSS. S. Desai, I. Durugkar, H. Karnan, G. Warnell, J. Hanna, and P. Stone. An imitation from observation approach to sim-to-real transfer. In 2nd Workshop on Closing the Reality Gap in Sim2Real Transfer for Robotics. RSS, 2020.</p>
<p>Augmenting differentiable simulators with neural networks to close the sim2real gap. E Heiden, D Millard, E Coumans, G Sukhatme, 2nd Workshop on Closing the Reality Gap in Sim2Real Transfer for Robotics. RSS. E. Heiden, D. Millard, E. Coumans, and G. Sukhatme. Augmenting differentiable simulators with neural networks to close the sim2real gap. In 2nd Workshop on Closing the Reality Gap in Sim2Real Transfer for Robotics. RSS, 2020.</p>
<p>Learning agile and dynamic motor skills for legged robots. Jemin Hwangbo, Joonho Lee, Alexey Dosovitskiy, Dario Bellicoso, Vassilios Tsounis, Vladlen Koltun, Marco Hutter, Science Robotics. 4265872Jemin Hwangbo, Joonho Lee, Alexey Dosovitskiy, Dario Bellicoso, Vassilios Tsounis, Vladlen Koltun, and Marco Hutter. Learning agile and dynamic motor skills for legged robots. Science Robotics, 4(26):eaau5872, January 2019.</p>
<p>Continual learning on incremental simulations for real-world robotic manipulation tasks. J Josifovski, M Malmir, N Klarmann, A Knoll, 2nd Workshop on Closing the Reality Gap in Sim2Real Transfer for Robotics. RSS. J. Josifovski, M. Malmir, N. Klarmann, and A. Knoll. Continual learn- ing on incremental simulations for real-world robotic manipulation tasks. In 2nd Workshop on Closing the Reality Gap in Sim2Real Transfer for Robotics. RSS, 2020.</p>
<p>Sim2real predictivity: Does evaluation in simulation predict real-world performance?. A Kadian, J Truong, A Gokaslan, A Clegg, E Wijmans, S Lee, M Savva, S Chernova, D Batra, 2nd Workshop on Closing the Reality Gap in Sim2Real Transfer for Robotics. RSS. A. Kadian, J. Truong, A. Gokaslan, A. Clegg, E. Wijmans, S. Lee, M. Savva, S. Chernova, and D. Batra. Sim2real predictivity: Does evaluation in simulation predict real-world performance? In 2nd Workshop on Closing the Reality Gap in Sim2Real Transfer for Robotics. RSS, 2020.</p>
<p>. Elia Kaufmann, Antonio Loquercio, Ren Ranftl, Matthias Mller, Vladlen Koltun, Davide Scaramuzza, Deep drone acrobatics. R:SS. Elia Kaufmann, Antonio Loquercio, Ren Ranftl, Matthias Mller, Vladlen Koltun, and Davide Scaramuzza. Deep drone acrobatics. R:SS, 2020.</p>
<p>Accurate high fidelity simulations for training robot navigation policies for dense crowds using deep reinforcement learning. J Liang, U Patel, A J Sathyamoorthy, D Manocha, 2nd Workshop on Closing the Reality Gap in Sim2Real Transfer for Robotics. RSS 2020. J. Liang, U. Patel, A. J. Sathyamoorthy, and D. Manocha. Accurate high fidelity simulations for training robot navigation policies for dense crowds using deep reinforcement learning. In 2nd Workshop on Closing the Reality Gap in Sim2Real Transfer for Robotics. RSS 2020, 2020.</p>
<p>Learning ambidextrous robot grasping policies. Jeffrey Mahler, Matthew Matl, Vishal Satish, Michael Danielczuk, Bill Derose, Stephen Mckinley, Ken Goldberg, Science Robotics. 426Jeffrey Mahler, Matthew Matl, Vishal Satish, Michael Danielczuk, Bill DeRose, Stephen McKinley, and Ken Goldberg. Learning ambidex- trous robot grasping policies. Science Robotics, 4(26), January 2019.</p>
<p>Robust sim2real transfer by learning inverse dynamics of simulated systems. M Malmir, J Josifovski, N Klarmann, A Knoll, 2nd Workshop on Closing the Reality Gap in Sim2Real Transfer for Robotics. RSS. M. Malmir, J. Josifovski, N. Klarmann, and A. Knoll. Robust sim2real transfer by learning inverse dynamics of simulated systems. In 2nd Workshop on Closing the Reality Gap in Sim2Real Transfer for Robotics. RSS, 2020.</p>
<p>Inferring the material properties of granular media for robotic tasks. Carolyn Matl, Yashraj Narang, Ruzena Bajcsy, Fabio Ramos, Dieter Fox, Carolyn Matl, Yashraj Narang, Ruzena Bajcsy, Fabio Ramos, and Dieter Fox. Inferring the material properties of granular media for robotic tasks, 2020.</p>
<p>Solving rubik's cube with a robot hand. Ilge Openai, Marcin Akkaya, Maciek Andrychowicz, Mateusz Chociej, Bob Litwin, Arthur Mcgrew, Alex Petron, Matthias Paino, Glenn Plappert, Raphael Powell, Jonas Ribas, Nikolas Schneider, Jerry Tezak, Peter Tworek, Lilian Welinder, Qiming Weng, Wojciech Yuan, Lei Zaremba, Zhang, OpenAI, Ilge Akkaya, Marcin Andrychowicz, Maciek Chociej, Ma- teusz Litwin, Bob McGrew, Arthur Petron, Alex Paino, Matthias Plappert, Glenn Powell, Raphael Ribas, Jonas Schneider, Nikolas Tezak, Jerry Tworek, Peter Welinder, Lilian Weng, Qiming Yuan, Wojciech Zaremba, and Lei Zhang. Solving rubik's cube with a robot hand, 2019.</p>
<p>Solving rubik's cube with a robot hand. Ilge Openai, Marcin Akkaya, Maciek Andrychowicz, Mateusz Chociej, Bob Litwin, Arthur Mcgrew, Alex Petron, Matthias Paino, Glenn Plappert, Raphael Powell, Jonas Ribas, Nikolas Schneider, Jerry Tezak, Peter Tworek, Lilian Welinder, Qiming Weng, Wojciech Yuan, Lei Zaremba, Zhang, OpenAI, Ilge Akkaya, Marcin Andrychowicz, Maciek Chociej, Ma- teusz Litwin, Bob McGrew, Arthur Petron, Alex Paino, Matthias Plappert, Glenn Powell, Raphael Ribas, Jonas Schneider, Nikolas Tezak, Jerry Tworek, Peter Welinder, Lilian Weng, Qiming Yuan, Wojciech Zaremba, and Lei Zhang. Solving rubik's cube with a robot hand, 2019.</p>
<p>On assessing the value of simulation for robotics. L Paull, A Courchesne, 2nd Workshop on Closing the Reality Gap in Sim2Real Transfer for Robotics. RSS. L. Paull and A. Courchesne. On assessing the value of simulation for robotics. In 2nd Workshop on Closing the Reality Gap in Sim2Real Transfer for Robotics. RSS, 2020.</p>
<p>Learning agile robotic locomotion skills by imitating animals. Xue Bin, Erwin Peng, Tingnan Coumans, Tsang-Wei Zhang, Jie Lee, Sergey Tan, Levine, Xue Bin Peng, Erwin Coumans, Tingnan Zhang, Tsang-Wei Lee, Jie Tan, and Sergey Levine. Learning agile robotic locomotion skills by imitating animals, 2020.</p>
<p>Online bayessim for combined simulator parameter inference and policy improvement. R Possas, F Ramos, D Fox, L Barcelos, R Oliveira, 2nd Workshop on Closing the Reality Gap in Sim2Real Transfer for Robotics. RSS. R. Possas, F. Ramos, D. Fox, L. Barcelos, and R. Oliveira. Online bayessim for combined simulator parameter inference and policy improvement. In 2nd Workshop on Closing the Reality Gap in Sim2Real Transfer for Robotics. RSS, 2020.</p>
<p>Rl-cyclegan: Reinforcement learning aware simulation-to-real. Kanishka Rao, Chris Harris, Alex Irpan, Sergey Levine, Julian Ibarz, Mohi Khansari, Kanishka Rao, Chris Harris, Alex Irpan, Sergey Levine, Julian Ibarz, and Mohi Khansari. Rl-cyclegan: Reinforcement learning aware simulation-to-real, 2020.</p>
<p>Cunascuriosity-driven neural-augmented simulator. S C Raparthy, M Mozifian, L Paull, F Golemo, 2nd Workshop on Closing the Reality Gap in Sim2Real Transfer for Robotics. RSS. S. C. Raparthy, M. Mozifian, L. Paull, and F. Golemo. Cunas - curiosity-driven neural-augmented simulator. In 2nd Workshop on Closing the Reality Gap in Sim2Real Transfer for Robotics. RSS, 2020.</p>
<p>The importance and the limitations of sim2real for robotic manipulation in precision agriculture. C Rizzardo, S Katyara, M Fernandes, F Chen, 2nd Workshop on Closing the Reality Gap in Sim2Real Transfer for Robotics. RSS. C. Rizzardo, S. Katyara, M. Fernandes, and F. Chen. The importance and the limitations of sim2real for robotic manipulation in precision agriculture. In 2nd Workshop on Closing the Reality Gap in Sim2Real Transfer for Robotics. RSS, 2020.</p>
<p>Learning to manipulate deformable objects without demonstrations. Y Wu, T Yan, L Kurutach, P Pinto, Abbeel, 2nd Workshop on Closing the Reality Gap in Sim2Real Transfer for Robotics. RSS. Y. Wu, W Yan, T. Kurutach, L. Pinto, and P. Abbeel. Learning to manipulate deformable objects without demonstrations. In 2nd Workshop on Closing the Reality Gap in Sim2Real Transfer for Robotics. RSS, 2020.</p>
<p>Learning predictive representations for deformable objects with contrastive estimation. W Yan, A Vangipuram, P Abbeel, L Pinto, 2nd Workshop on Closing the Reality Gap in Sim2Real Transfer for Robotics. RSS. W. Yan, A. Vangipuram, P. Abbeel, and L. Pinto. Learning predictive representations for deformable objects with contrastive estimation. In 2nd Workshop on Closing the Reality Gap in Sim2Real Transfer for Robotics. RSS, 2020.</p>
<p>Sim2real learning of visionbased obstacle avoidance for robotic manipulators. K Zhang, T Zhang, J Lin, L Bi, 2nd Workshop on Closing the Reality Gap in Sim2Real Transfer for Robotics. RSS. K. Zhang, T. Zhang, J. Lin, and L. Bi. Sim2real learning of vision- based obstacle avoidance for robotic manipulators. In 2nd Workshop on Closing the Reality Gap in Sim2Real Transfer for Robotics. RSS, 2020.</p>
<p>Necessity for more realistic contact simulation. M Zhang, 2nd Workshop on Closing the Reality Gap in Sim2Real Transfer for Robotics. RSS. M. Zhang. Necessity for more realistic contact simulation. In 2nd Workshop on Closing the Reality Gap in Sim2Real Transfer for Robotics. RSS, 2020.</p>
<p>Simto-real transfer in deep reinforcement learning for robotics: a survey. Wenshuai Zhao, Jorge Pea Queralta, Tomi Westerlund, Wenshuai Zhao, Jorge Pea Queralta, and Tomi Westerlund. Sim- to-real transfer in deep reinforcement learning for robotics: a survey, 2020.</p>
<p>Unpaired image-to-image translation using cycle-consistent adversarial networks. Jun-Yan Zhu, Taesung Park, Phillip Isola, Alexei A Efros, 2017 International Conference on Computer Vision (ICCV. Jun-Yan Zhu, Taesung Park, Phillip Isola, and Alexei A. Efros. Unpaired image-to-image translation using cycle-consistent adversarial networks. In 2017 International Conference on Computer Vision (ICCV), 2017.</p>            </div>
        </div>

    </div>
</body>
</html>