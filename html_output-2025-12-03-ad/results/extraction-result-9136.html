<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-9136 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-9136</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-9136</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-161.html">extraction-schema-161</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLMs being used as text-based simulators in specific scientific subdomains, including details on the simulation task, the accuracy or evaluation results, and any factors or variables identified as affecting simulation accuracy.</div>
                <p><strong>Paper ID:</strong> paper-273098039</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2410.02110v2.pdf" target="_blank">Can LLMs Reliably Simulate Human Learner Actions? A Simulation Authoring Framework for Open-Ended Learning Environments</a></p>
                <p><strong>Paper Abstract:</strong> Simulating learner actions helps stress-test open-ended interactive learning environments and prototype new adaptations before deployment. While recent studies show the promise of using large language models (LLMs) for simulating human behavior, such approaches have not gone beyond rudimentary proof-of-concept stages due to key limitations. First, LLMs are highly sensitive to minor prompt variations, raising doubts about their ability to generalize to new scenarios without extensive prompt engineering. Moreover, apparently successful outcomes can often be unreliable, either because domain experts unintentionally guide LLMs to produce expected results, leading to self-fulfilling prophecies; or because the LLM has encountered highly similar scenarios in its training data, meaning that models may not be simulating behavior so much as regurgitating memorized content. To address these challenges, we propose Hyp-Mix, a simulation authoring framework that allows experts to develop and evaluate simulations by combining testable hypotheses about learner behavior. Testing this framework in a physics learning environment, we found that GPT-4 Turbo maintains calibrated behavior even as the underlying learner model changes, providing the first evidence that LLMs can be used to simulate realistic behaviors in open-ended interactive learning environments, a necessary prerequisite for useful LLM behavioral simulation.</p>
                <p><strong>Cost:</strong> 0.009</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e9136.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e9136.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLMs being used as text-based simulators in specific scientific subdomains, including details on the simulation task, the accuracy or evaluation results, and any factors or variables identified as affecting simulation accuracy.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GPT-4 Turbo (HYP-MIX)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>GPT-4 Turbo used within the HYP-MIX simulation-authoring framework</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>GPT-4 Turbo was used as a text-based simulator to generate next-step learner actions in an open-ended educational physics environment (HoloOrbits), guided by modular Marginalized Distributional Hypotheses (MDHyps) and prompt templates; its outputs were evaluated for statistical calibration under modifications to the learner model.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Can LLMs Reliably Simulate Human Learner Actions? A Simulation Authoring Framework for Open-Ended Learning Environments</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-4 Turbo</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Identified in the paper as a state-of-the-art large language model (cited via Achiam et al. 2023); used in-text with chain-of-thought prompting and calibrated prompt templates (no parameter counts or training-data specifics provided in this paper).</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_subdomain</strong></td>
                            <td>Educational technology / Physics education (simulation of learner behavior in an environment teaching Kepler's Laws)</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_task</strong></td>
                            <td>Text-based simulation of a 13-year-old learner interacting with the HoloOrbits environment: choose measurement actions (e.g., MEASURE-F1-X) or SUBMIT/EXIT actions, with the objective of verifying whether a planetary orbit satisfies Kepler's First Law by submitting three equal arithmetic expressions constructed from measured distances.</td>
                        </tr>
                        <tr>
                            <td><strong>evaluation_metric</strong></td>
                            <td>Distributional calibration tests tied to MDHyps: Spearman rank correlation coefficient (ρ) with p-value for monotonic relationship hypotheses (T_mono); Chi-squared test p-value (P_{χ²}) for uniform-distribution hypotheses (T_uniform); evaluation is performed pre- and post- learner-model edit operations and across three different action-space labelings.</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_accuracy</strong></td>
                            <td>Calibration held in 16 of 18 tested cases (≈88.9% success rate) across five learner-model edit operations and three action-space labelings; the COMBINE operation failed to maintain calibration in 2 out of 3 action-space labelings. Specific statistical success criteria: for monotonic hypotheses, TRUE if ρ>0 and p≤0.05 (for monotonically increasing) or ρ<0 and p≤0.05 (for decreasing); for uniform hypotheses, TRUE if P_{χ²}>0.05.</td>
                        </tr>
                        <tr>
                            <td><strong>factors_affecting_accuracy</strong></td>
                            <td>['Prompt sensitivity / need for prompt calibration: small wording or template changes can affect outputs', 'Compositionality challenge when combining separately calibrated hypotheses (COMBINE operation failures)', 'Action-space labeling (three labelings used to detect sensitivity to label phrasing)', 'Template calibration process (calibrated templates improved stability across edits)', 'Potential memorization / data contamination (models may regurgitate seen scenarios rather than reason)', 'Clever-Hans effect (prompt engineers inadvertently biasing prompts toward expected outputs)', 'Approximate marginalization (state-space subsampling introduces statistical estimation uncertainty)', 'Limited scope of learner characteristics and single environment (domain complexity limits generalization)']</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Internal pre-operation vs post-operation calibration comparisons (no external human or traditional simulator baseline reported); robustness assessed across three labelings of the action space to detect prompt/label sensitivity.</td>
                        </tr>
                        <tr>
                            <td><strong>limitations_or_failure_cases</strong></td>
                            <td>Study limited to two learner characteristics (geometry proficiency and persistence) in one environment (HoloOrbits); COMBINE operation showed calibration loss in 2/3 labelings indicating difficulty combining separately calibrated MDHyps; potential hyper-accuracy distortion and memorization (LLM may be unable to feign ignorance), prompt-sensitivity issues, and reliance on subsampled state-space rather than exhaustive marginalization.</td>
                        </tr>
                        <tr>
                            <td><strong>author_recommendations_or_insights</strong></td>
                            <td>Use MDHyps as modular, testable units for authoring and evaluating LLM-based simulations; perform template calibration once and test generalization across model edits (calibrate-once, use-forever aim); test across multiple action-space labelings to reduce label-sensitivity artifacts; favor explicit authoring for sensitive domains and balance expert constraints with LLM commonsense; expand experiments across more learner characteristics, environments, and LLMs (including open-source models) and examine continuous action spaces in future work.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Can LLMs Reliably Simulate Human Learner Actions? A Simulation Authoring Framework for Open-Ended Learning Environments', 'publication_date_yy_mm': '2024-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Using Large Language Models to Simulate Multiple Humans and Replicate Human Subject Studies <em>(Rating: 2)</em></li>
                <li>Generative Agents: Interactive Simulacra of Human Behavior <em>(Rating: 2)</em></li>
                <li>The challenge of using llms to simulate human behavior: a causal inference perspective <em>(Rating: 2)</em></li>
                <li>Using GPT for market research <em>(Rating: 1)</em></li>
                <li>PersonaLLM: Investigating the Ability of Large Language Models to Express Personality Traits <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-9136",
    "paper_id": "paper-273098039",
    "extraction_schema_id": "extraction-schema-161",
    "extracted_data": [
        {
            "name_short": "GPT-4 Turbo (HYP-MIX)",
            "name_full": "GPT-4 Turbo used within the HYP-MIX simulation-authoring framework",
            "brief_description": "GPT-4 Turbo was used as a text-based simulator to generate next-step learner actions in an open-ended educational physics environment (HoloOrbits), guided by modular Marginalized Distributional Hypotheses (MDHyps) and prompt templates; its outputs were evaluated for statistical calibration under modifications to the learner model.",
            "citation_title": "Can LLMs Reliably Simulate Human Learner Actions? A Simulation Authoring Framework for Open-Ended Learning Environments",
            "mention_or_use": "use",
            "model_name": "GPT-4 Turbo",
            "model_description": "Identified in the paper as a state-of-the-art large language model (cited via Achiam et al. 2023); used in-text with chain-of-thought prompting and calibrated prompt templates (no parameter counts or training-data specifics provided in this paper).",
            "scientific_subdomain": "Educational technology / Physics education (simulation of learner behavior in an environment teaching Kepler's Laws)",
            "simulation_task": "Text-based simulation of a 13-year-old learner interacting with the HoloOrbits environment: choose measurement actions (e.g., MEASURE-F1-X) or SUBMIT/EXIT actions, with the objective of verifying whether a planetary orbit satisfies Kepler's First Law by submitting three equal arithmetic expressions constructed from measured distances.",
            "evaluation_metric": "Distributional calibration tests tied to MDHyps: Spearman rank correlation coefficient (ρ) with p-value for monotonic relationship hypotheses (T_mono); Chi-squared test p-value (P_{χ²}) for uniform-distribution hypotheses (T_uniform); evaluation is performed pre- and post- learner-model edit operations and across three different action-space labelings.",
            "simulation_accuracy": "Calibration held in 16 of 18 tested cases (≈88.9% success rate) across five learner-model edit operations and three action-space labelings; the COMBINE operation failed to maintain calibration in 2 out of 3 action-space labelings. Specific statistical success criteria: for monotonic hypotheses, TRUE if ρ&gt;0 and p≤0.05 (for monotonically increasing) or ρ&lt;0 and p≤0.05 (for decreasing); for uniform hypotheses, TRUE if P_{χ²}&gt;0.05.",
            "factors_affecting_accuracy": [
                "Prompt sensitivity / need for prompt calibration: small wording or template changes can affect outputs",
                "Compositionality challenge when combining separately calibrated hypotheses (COMBINE operation failures)",
                "Action-space labeling (three labelings used to detect sensitivity to label phrasing)",
                "Template calibration process (calibrated templates improved stability across edits)",
                "Potential memorization / data contamination (models may regurgitate seen scenarios rather than reason)",
                "Clever-Hans effect (prompt engineers inadvertently biasing prompts toward expected outputs)",
                "Approximate marginalization (state-space subsampling introduces statistical estimation uncertainty)",
                "Limited scope of learner characteristics and single environment (domain complexity limits generalization)"
            ],
            "comparison_baseline": "Internal pre-operation vs post-operation calibration comparisons (no external human or traditional simulator baseline reported); robustness assessed across three labelings of the action space to detect prompt/label sensitivity.",
            "limitations_or_failure_cases": "Study limited to two learner characteristics (geometry proficiency and persistence) in one environment (HoloOrbits); COMBINE operation showed calibration loss in 2/3 labelings indicating difficulty combining separately calibrated MDHyps; potential hyper-accuracy distortion and memorization (LLM may be unable to feign ignorance), prompt-sensitivity issues, and reliance on subsampled state-space rather than exhaustive marginalization.",
            "author_recommendations_or_insights": "Use MDHyps as modular, testable units for authoring and evaluating LLM-based simulations; perform template calibration once and test generalization across model edits (calibrate-once, use-forever aim); test across multiple action-space labelings to reduce label-sensitivity artifacts; favor explicit authoring for sensitive domains and balance expert constraints with LLM commonsense; expand experiments across more learner characteristics, environments, and LLMs (including open-source models) and examine continuous action spaces in future work.",
            "uuid": "e9136.0",
            "source_info": {
                "paper_title": "Can LLMs Reliably Simulate Human Learner Actions? A Simulation Authoring Framework for Open-Ended Learning Environments",
                "publication_date_yy_mm": "2024-10"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Using Large Language Models to Simulate Multiple Humans and Replicate Human Subject Studies",
            "rating": 2,
            "sanitized_title": "using_large_language_models_to_simulate_multiple_humans_and_replicate_human_subject_studies"
        },
        {
            "paper_title": "Generative Agents: Interactive Simulacra of Human Behavior",
            "rating": 2,
            "sanitized_title": "generative_agents_interactive_simulacra_of_human_behavior"
        },
        {
            "paper_title": "The challenge of using llms to simulate human behavior: a causal inference perspective",
            "rating": 2,
            "sanitized_title": "the_challenge_of_using_llms_to_simulate_human_behavior_a_causal_inference_perspective"
        },
        {
            "paper_title": "Using GPT for market research",
            "rating": 1,
            "sanitized_title": "using_gpt_for_market_research"
        },
        {
            "paper_title": "PersonaLLM: Investigating the Ability of Large Language Models to Express Personality Traits",
            "rating": 1,
            "sanitized_title": "personallm_investigating_the_ability_of_large_language_models_to_express_personality_traits"
        }
    ],
    "cost": 0.008596,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Can LLMs Reliably Simulate Human Learner Actions? A Simulation Authoring Framework for Open-Ended Learning Environments
12 Oct 2024</p>
<p>Amogh Mannekote amogh.mannekote@ufl.edu 
University of Florida</p>
<p>Adam Davies adavies4@illinois.edu 
University of Illinois Urbana-Champaign</p>
<p>Jina Kang jinakang@illinois.edu 
University of Illinois Urbana-Champaign</p>
<p>Kristy Elizabeth Boyer keboyer@ufl.edu 
University of Florida</p>
<p>Can LLMs Reliably Simulate Human Learner Actions? A Simulation Authoring Framework for Open-Ended Learning Environments
12 Oct 2024A78517847E324D720E04FFCB0C6C8B8EarXiv:2410.02110v2[cs.AI]
Simulating learner actions helps stress-test open-ended interactive learning environments and prototype new adaptations before deployment.While recent studies show the promise of using large language models (LLMs) for simulating human behavior, such approaches have not gone beyond rudimentary proof-of-concept stages due to key limitations.First, LLMs are highly sensitive to minor prompt variations, raising doubts about their ability to generalize to new scenarios without extensive prompt engineering.Moreover, apparently successful outcomes can often be unreliable, either because domain experts unintentionally guide LLMs to produce expected results, leading to self-fulfilling prophecies; or because the LLM has encountered highly similar scenarios in its training data, meaning that models may not be simulating behavior so much as regurgitating memorized content.To address these challenges, we propose HYP-MIX, a simulation authoring framework that allows experts to develop and evaluate simulations by combining testable hypotheses about learner behavior.Testing this framework in a physics learning environment, we found that GPT-4 Turbo maintains calibrated behavior even as the underlying learner model changes, providing the first evidence that LLMs can be used to simulate realistic behaviors in open-ended interactive learning environments, a necessary prerequisite for useful LLM behavioral simulation.</p>
<p>Introduction</p>
<p>Open-ended interactive learning environments offer unique educational value by providing tailored and dynamic spaces where learners can explore, experiment, and construct knowledge-capabilities (Renkl and Atkinson 2007;Hannafin, Land, and Oliver 2013;Land and Jonassen 2012).However, developing these environments is challenging.It requires not only the creation of pedagogical content but also mechanisms to adapt learning experiences for learners with varying knowledge levels and psychological characteristics for very large state spaces due to the relatively open-ended nature of the environments (Kim 2012;Hannafin et al. 2014;Akpanoko et al. 2024).This complexity necessitates an iterative process in which theoretical best practices are continuously balanced with practical demands (Sandoval 2014).</p>
<p>Simulations of learner behavior have been instrumental in streamlining the process of developing intelligent sys-Preprint.Under review.Figure 1: We characterize the effort involved in authoring LLMbased simulations of learner behavior as a function of two key attributes of the simulation authoring process: 1) prompt sensitivity and 2) the extent of environment-specific handcrafting required during development.High prompt sensitivity necessitates excessive editing for minor phrasing changes, thus consuming valuable expert time.On the other hand, the need for environment-specific handcrafting arises when an LLM struggles to generalize across learning environments, impeding rapid iteration.The proposed approach of mixing-and-matching expert-hypotheses to define simulation behavior offers a promising balance, enabling authors to impose necessary constraints while leveraging the advantages of state-of-the-art knowledge and reasoning capabilities of LLMs for "filling in the gaps."tems for education (Koedinger et al. 2015;Matsuda, Cohen, and Koedinger 2015).By allowing developers to rigorously test features before full deployment, these simulations reduce reliance on resource-intensive pilot testing in real-world classrooms (Käser and Alexandron 2023).They enable developers to identify software issues and evaluate design choices early, later fine-tuning the environment to meet learner needs.However, developing simulations during the cold-start phase is challenging due to the lack of reallearner data in new environments.This scarcity prevents purely data-driven approaches, requiring reliance on log data from similar studies, predictions from learning science theories, instructor experience, and expert intuition (Holstein, McLaren, and Aleven 2019).Without action logs from the target demographic, these sources provide the best alternative for accurate simulations.</p>
<p>Combining these alternative information sources to craft realistic simulations of learner actions requires a balanced integration of expert knowledge and automated reasoning.Fully handcrafted, rule-based simulations offer fine-grained control but become impractical as complexity increases, while purely automatic systems may miss critical nuances (Wang et al. 2024).LLM prompting may potentially strike an ideal balance, using rich natural language to specify behavior while leveraging the LLM's reasoning capabilities.This approach holds the potential for flexible, fine-tuned simulations that effectively bridge the gap between manual control and automation.</p>
<p>Promisingly, there has been a recent surge in studies that suggest that LLMs, with their extensive world knowledge and reasoning capabilities, can accurately predict human responses to both natural language descriptions of hypothetical situations and actual experimental setups taken from academic disciplines like psychology and behavioral economics (Aher, Arriaga, and Kalai 2023).However, such claims must be approached with caution.We identify three reasons to be skeptical of simulations based on large language model (LLM) prompting reliably generalizing to new situations.</p>
<ol>
<li>LLMs are known to be highly sensitive to small, inconsequential changes to the prompt wording (prompt sensitivity) (Sclar et al. 2023;Loya, Sinha, and Futrell 2023b).</li>
</ol>
<p>As a result, a simulation that works in one context might fail with changes to either the description of the learning environment (corresponding to, say, a new feature that the developers are planning to add to the environment) or the learner model (corresponding to refinements in the expert's understanding of how learners behave).2. LLMs, trained on vast web data, may rely on memorization rather than genuine reasoning, limiting their ability to generalize (Sainz et al. 2023).3.There is no disciplined method to prevent prompt engineers from unconsciously shaping prompts to elicit expected answers, raising concerns of a Clever Hans1 -like setup, where human cues influence the outcome (Kambhampati 2024).</p>
<p>For the reasons stated above, the usefulness of LLMs for simulating learner actions beyond single proof-of-concept experiments has not yet been established.To address this gap, we introduce a simulation authoring framework that serves the dual purposes of: 1) systematically evaluating whether an LLM-based simulator can usefully generalize to new contexts (e.g., modifications of the original learning environment or the original learner model) without reengineering the LLM prompt; and 2) establishing a clear prompting workflow to avoid Clever-Hans-style biases, preventing overestimation of the LLM's capabilities.</p>
<p>A robust simulator must dynamically adapt to changes in the simulation context (learning environment or learner model) without extensive prompt recalibration.Once a prompt template is calibrated to specific learner behaviors, this calibration should generalize to new simulation contexts, maintaining consistent simulation behavior.This generalization is important for two reasons: (1) the exponential increase in experiment runs needed as state variables grow, and (2) the limited utility of LLM simulations that only predict behaviors when specifically calibrated, which fails to generate new insights and merely reproduces existing findings (Clever Hans effect).</p>
<p>Our main contribution with HYP-MIX is a systematic simulation authoring framework2 for incorporating expert knowledge into LLM-based simulations of learner actions.Our hypothesis-based framework presents a well-defined, statistical notion of what it means for the simulation to be robust and generalizable to new simulation scenarios.Using our framework, we find that GPT-4 Turbo is capable of maintaining prompt calibration under changes to the learner model, indicating that it may already be feasible to simulate realistic learner behaviors in learning environments using frontier LLMs.</p>
<p>Related Work</p>
<p>Simulated Learner Behavior for Authoring Educational Technologies.Simulated learners streamline the authoring of intelligent tutoring systems (ITSs), which often require over 100 hours of work per instructional hour (Blessing and Gilbert 2008).Tools like SimStudent (Matsuda, Cohen, and Koedinger 2015) simulate learner behavior to aid in ITS development via interactive tutoring.However, compared to ITSs, open-ended interactive learning environments typically involve more states due to their open-ended and exploratory nature and a greater emphasis on scaffolding the affective aspects of learning (Rieber 1996).While Christensen et al. (2011) simulate psychological aspects of learners, their method is handcrafted, highly context-specific, and therefore, would not scale well to complex interactive environments.To our knowledge, our work is the first to apply learner behavior simulations to these environments.Additionally, Käser and Alexandron (2023) identify a widespread lack of validation in simulated learner research, which we address in the HYP-MIX framework by centering on falsifiable hypotheses for both authoring and evaluation.Our approach is also in line with Ainsworth and Grimshaw (2004), who focus on group-level behavior specification, similar to our use of distributional hypotheses.</p>
<p>Simulating Human Behavior with LLMs Several recent works explore the ability of LLMs to simulate human behaviors across various contexts, including social platform design (Park et al. 2022), market research (Brand, Israeli, and Ngwe 2023), and experimental economics (Gui and Toubia 2023).LLMs have also been shown to reflect human-like cognitive biases in reasoning tasks (Dasgupta et al. 2022;Ozeki et al. 2024).Most related to our work are studies that analyze LLMs agents' consistency with provided personality traits (Frisch and Giulianelli 2024;Jiang et al. 2024) or character profiles (Xiao et al. 2023).However, in contrast to these works, we evaluate agent consistency using simple hypotheses specifying the statistical relationship between values of agent (learner) characteristics and behaviors, alleviating the need for fine-grained annotation of individual responses; and further consider how these simulated behaviors change in response to changes in the simulation context.</p>
<p>Prompt Sensitivity and Prompt Calibration.Experiments using LLMs rely heavily on natural language prompts to define personas, situations, and tasks, but LLMs are highly sensitive to slight variations in prompt text, making this a critical issue for research (Mohammadi 2024).Loya, Sinha, and Futrell (2023a) find that ChatGPT exhibits sensitivity to prompt phrasing for decision-making tasks such as ours.In response, various prompt calibration approaches have emerged, particularly focusing on reducing the LLMs' sensitivity to the order of in-context examples (Lu et al. 2022;Zhao et al. 2021).In contrast to this family of work that focuses on reducing variance between different templates, in this work we our goal is to test the consistency of LLM behaviors across different simulation contexts.</p>
<p>The HYP-MIX Framework</p>
<p>The HYP-MIX framework is designed to create and evaluate realistic and scalable simulations of learner behavior by translating theoretical constructs into concrete, testable predictions.The unit of authoring and evaluation in this framework is a Marginalized Distributional Hypotheses (MD-Hyp).These are called "marginal" because they focus on one learner characteristic at a time, while "marginalizing" over all other variables.This is essential because, while it is straightforward to reason about a single characteristic, jointly considering multiple characteristics can quickly become difficult.For instance, an MDHyp might predict that low persistence leads to a higher probability of taskabandonment, focusing specifically on persistence while accounting for other variables in the background.The rest of this section details the motivation and implementation of MDHyps, along with its integration with LLM prompting.</p>
<p>MDHyps for Simulation Evaluation</p>
<p>A common method for validating simulated agents involves presenting the generated behaviors to human crowdworkers, who then rate the realism of these behaviors either over a quantitative scale or according to a qualitative rubric (Park et al. 2023;Jiang et al. 2024).While this approach has been widely adopted in recent studies, particularly with the proliferation of crowdsourcing platforms, it is fundamentally limited and ill-suited for evaluating simulated learner actions in complex, iterative experiments, for several reasons:</p>
<p>Cost Constraints:</p>
<p>Crowdsourcing becomes prohibitively expensive in iterative studies, particularly those requiring extensive experimentation.2. State Space Explosion: As the complexity of the environment and the number of learner characteristics in-crease, the task of collecting annotations for every possible combination becomes infeasible.3. Demographic Mismatch: The typical crowdworker populace does not include individuals deeply involved in education, such as researchers or educators (Huff and Tingley 2015).As a result, they are generally not equipped to accurately assess the realism of behaviors exhibited by young learners with specific characteristics.4. Inherent Noise in Learners' Actions: The stochastic nature of interactions within learning environments introduces significant noise into the evaluation process.Even with a sophisticated model of a learner, it is nearly impossible to predict with certainty how they will behave in a given situation, making deterministic point estimates unreliable.</p>
<p>We propose using MDHyps to evaluate learner behavior simulations at a distributional level, drawing from prior studies or instructor experience.An MDHyp is a natural language statement that describes a relationship between a learner's characteristic and their probability of taking certain actions (e.g., "a more persistent learner is less likely to abandon the task as more time passes").This relationship can be tested by analyzing the distribution of outcomes from multiple simulation runs across different environment states.</p>
<p>MDHyps for Simulation Authoring</p>
<p>The central thesis of the HYP-MIX framework is that MD-Hyps serve not only as useful tools for evaluating an existing simulation, but also as powerful building blocks for expertauthoring LLM-based simulations of learner behavior.</p>
<p>Achieving Mix-and-Match Simulation Authoring with MDHyps For MDHyps to be effective in prompt-based simulation authoring, the LLM must demonstrate compositional generalization (Mannekote 2024).We need MD-Hyps to function as modular elements that can be easily added, edited, removed, swapped, and combined to shape the LLM's outputs.Similar to SKILL-MIX (Yu et al. 2023), which tests LLMs' ability to combine literary and logical devices to generate free-form text, HYP-MIX tests LLMs' ability to combine calibrated expert-hypotheses to simulate learner actions in a "calibrate once, use forever" fashion.Achieving this, of course, is challenging due to LLMs' sensitivity to prompt phrasing and requires empirical validation.</p>
<p>Existing Notions of "Calibration" The term "calibration" carries different definitions across disciplines.In statistics and machine learning, calibration refers to the alignment between a model's predicted probabilities and the actual observed frequencies of outcomes, ensuring that predictions accurately reflect real-world occurrences over time (Bella et al. 2010).In the context of physical measurement devices, calibration ensures that a measurement device's accuracy is consistent.This process involves aligning the device with a known standard to maintain reliable accuracy across future measurements (Castrup et al. 1994).The HYP-MIX notion of calibration combines the two: we want the predicted action probabilities from the LLM to align with the MDHyp (analogous to the statistical notion) and also to hold this calibration across different hypotheses and changes in the underlying learner model (analogous to the metrological notion).</p>
<p>Holding Calibration Building on this integrated definition, the ability of an LLM to hold calibration of a prompt template across simulation contexts is critical for minimizing the labor-intensive re-engineering of prompt templates after each modification to the simulation model.By grouping hypotheses into hypothesis classes based on similar functional relationships and linking them to specific statistical tests, we ensure robust calibration, even as the simulation model undergoes modifications.</p>
<p>Hypothesis Classes A hypothesis class defines a specific functional relationship that its member-hypotheses posit between independent variables (e.g., learner persona values, environment state variables) and a dependent variable (e.g., probability mass of specific learner actions).Formally, a hypothesis H i belongs to the hypothesis class H class (denoted as c(H i ) = H class ).Each hypothesis class is associated with a prompt template, Îclass , that its member-hypotheses instantiate by specifying slot values, and is linked to a specific success criterion T class , typically expected to be the result of a statistical test (e.g., Chi-squared) designed to assess how well the LLM maintains consistency and accuracy when different instances of that class's characteristic relationship are tested (e.g., any relationship that can be expressed in natural language, such as linear, logarithmic, or piecewise continuous relationships).</p>
<p>Template Calibration Finally, template calibration is the human-in-the-loop "prompt engineering" process that involves iteratively refining the prompt template associated with a hypothesis class until the LLM's output probabilities for specific actions align with one or more memberhypotheses that are used as validation.Successful calibration is achieved when statistical tests confirm this alignment.The calibrated prompt template should remain robust under changes in the learner model and across new memberhypotheses.Table 1 shows the set of instantiated prompts corresponding to the hypothesis classes and hypotheses that we use in our illustrative experiments that are described later in the paper.</p>
<p>Experiments</p>
<p>We test the robustness and generalization capabilities of GPT-4 Turbo, a state-of-the-art LLM, in the HoloOrbits environment by assessing how well it maintains calibration when the learner model is modified.</p>
<p>Learning Environment</p>
<p>We situate our experiments within HoloOrbits (Rajarathinam, Palaguachi, and Kang 2024), an open-ended interactive learning environment designed for teaching Kepler's Laws that we use for our experiments (see Figure 2).We selected HoloOrbits due to its small, well-defined state and action spaces, which make it ideal for preliminary experiments.Since our experiments involve a text-based LLM, we only need a textual description of the learning environment to feed into the model as a natural language prompt.An unintended advantage of this approach is that it allows us to describe learning environments not yet implemented in software.</p>
<p>Learning Task We particularly focus on the learner's task to verify if a given planetary system adheres to Kepler's First Law by submitting three equal arithmetic expressions.These expressions can use any combination of distance measurements between the following points: aphelion (A), perihelion (P), focus 1 (F1), focus 2 (F2), and a fixed point on the orbit (X).The correct solution involves submitting the following measurements: (F1-A + F2-A), (F1-P + F2-P), and (F1-X + F2-X).</p>
<p>State Representation For our experiments, we define a minimal state representation with ten boolean variables indicating whether the learner has measured the distances between each pair of points.Additionally, we include two integer variables to track the number of submission attempts and the time elapsed since the session began, respectively.</p>
<p>Action Space</p>
<p>The learner can perform measurements between any pairs of key points in the planetary system, with specific actions such as MEASURE-F1-X to measure the distance between Focus 1 (F1) and a fixed point on the orbit (X), MEASURE-A-F1 to measure the distance between Aphelion (A) and Focus 1 (F1), or MEASURE-A-P to measure the distance between Aphelion (A) and Perihelion (P).In addition to these measurement actions, the learner can submit solutions using SUBMIT(X, Y, Z), where X, Y, and Z represent arithmetic expressions involving the measured distances.The goal is for all three expressions to be equal.The learner also has the option to EXIT at any time.</p>
<p>Learner Model</p>
<p>We represent each learner through a learner model L = (C, V, M).C is the set of learner characteristics (e.g., geometry proficiency, persistence) being modeled.V is the
Hypothesis (H i ∈ H c(Hi) ) Initial, Uncalibrated Prompt Template Îc(Hi) (H i ) H G1 ∈ H mono
A learner with a higher geometry proficiency is more likely to make productive measurements (i.e., those that measure distances between pairs of points in the planetary system that are potentially useful to verify if the orbit is elliptical).To make productive measurements is to make one of the following actions: MEASURE-F1-X, MEASURE-F2-X, MEASURE-F1-P, MEASURE-F2-P, MEASURE-A-F1, MEASURE-A-F2.</p>
<p>H P 1 ∈ H mono A learner with a higher persistence is less likely to abandon the task as the number of measurements increases (i.e., to prematurely exit the session before submitting the right solution).To abandon the task as the number of measurements increases is to make one of the following actions: EXIT.</p>
<p>H P 2 ∈ H mono A learner with a higher persistence is less likely to abandon the task as the time elapsed increases (i.e., to prematurely exit the session before submitting the right solution).To abandon the task as the time elapsed increases is to make one of the following actions: EXIT.</p>
<p>H G2 ∈ H uniform As learners get closer and closer to the lower end of the geometry proficiency spectrum (value of 1), they are equally likely to perform the following actions.In other words, such a learner exhibits a uniform distribution over these actions: <ALL MEASUREMENT ACTIONS>.mapping between each learner characteristic, C i ∈ C, to its corresponding persona level, V i , of the current learner.Each V i ∈ V is quantified on a numerical scale (V i ∈ [1, 10]).Finally, each learner characteristic C i is associated with a learner characteristic model M i ∈ M, which, in turn, comprises one or more MDHyps.</p>
<p>Learner Characteristics For the HoloOrbits learning environment, we model learners using persistence (a psychological factor) and geometry proficiency (which reflects the learner's knowledge of the subject matter) with the following operating theoretical definitions:</p>
<p>• Persistence: "maintaining a sustained effort toward completion of a goal-directed task despite challenges or difficulties" (Anderson 2002; Hilton and Pellegrino 2012) • Geometry Proficiency: "the ability to apply the knowledge of the properties of common shapes to solve problems" (Jablonski and Ludwig 2023)</p>
<p>Design of the LLM Prompt for the Simulation The simulation prompt fed to the LLM, Îsim , consists of introductory instructions, a description of the learning environment, current state, and the learner model (a graphic of the prompt template is shown in the Appendix).Furthermore, the prompt template for each learner characteristic model is a concatenation of prompt templates of the MDHyps that make up the learner characteristic model.We also instruct the LLM to perform Chain-of-Thought reasoning (Wei et al. 2022) before outputting the simulated action to strengthen the reasoning and provide the practitioners with a semblance of the intermediary steps used to arrive at the output, which can then be used to refine the simulation.</p>
<p>Approximate Marginalization Testing an MDHyp by running the simulation over all value-assignments of state variables S requires an intractable number of LLM calls that grows exponentially with |S|.To address this, we statistically approximate the state space by subsampling it.This approach allows for manageable marginalization while controlling computational costs.</p>
<p>Learner Model Edit Graph: A Case Study</p>
<p>This section details a case study of how we developed a simulation of learner actions for the HoloOrbits environment leveraging the HYP-MIX framework.The goal of this case study is to demonstrate how HYP-MIX can be used to evaluate the compositional generalization capabilities of an LLM (we used GPT-4 Turbo (Achiam et al. 2023) in our experiments).We focus on five representative types of modifications (edit operations) to the learner model, reflecting the iterative process a developer might follow when constructing a learner model.Throughout the development process, we use the four MDHyps listed in Table 1.These modifications are represented via a Learner Model Edit Graph (shown in Figure 3).</p>
<p>Initial Hypotheses and Operationalization:</p>
<p>We initialize the learner model with two hypotheses: H G1 and H P 1 , both obtained by operationalizing the theoretical definitions of geometry proficiency and persistence respectively into MDHyps (see Table 1 for all hypotheses used).Both H G1 and H P 1 posit monotonic relationships between variables.We grouped them under the hypothesis class H mono .We calibrated Îmono using H G1 as the calibration reference hypothesis and tested for generalization on H P 1 .We define the success criteria function for monotonic hypotheses, T mono using the Spearman correlation coefficient ρ and its corresponding p-value P ρ as follows:
T mono (ρ, P ρ ) =                     </p>
<p>Results and Discussion</p>
<p>The criterion for evaluating whether an LLM can support flexible simulation authoring within the HYP-MIX framework is that the calibration state of all hypothesis classes must remain intact after a learner model edit operation.Specifically, for each hypothesis H i in the learner model, the LLM outputs must continue to satisfy the success criterion function T c(Hi) without requiring any changes to the associated prompt template, Îc(Hi) .We evaluate this by comparing the success criterion function outputs for all hypotheses in the learner model before (Pre-Op) and after (Post-Op) the edit operation.We use three different labelings of the action space to enhance the reliability of calibration and results.This approach helps rule out LLM sensitivity to minor label variations, such as EXIT vs. QUIT.Consequently, each operation in Table 2 is represented by three rows (the action spaces are shown in the Appendix).</p>
<p>To better illustrate this process, consider the following example.According to the definition of H G1 , we expect the learner's empirical probability of making productive measurements between key points in the planetary system to increase monotonically with the learner's geometry proficiency level.Since H G1 ∈ H monotonic , we calibrate the template Îmonotonic using H G1 as the calibration reference hypothesis until the monotonicity test T monotonic is satisfied for H G1 .Once H G1 is successfully calibrated, we modify the learner model by introducing a new hypothesis, H P 1 .We then reapply T monotonic to H G1 (with H P 1 included in the learner model via the LLM prompt).We report whether the calibration state of Îmonotonic is maintained or lost in our results (see Table 2).This procedure is repeated for all directed edges in the graph.</p>
<p>We find that except for the COMBINE operation where calibration was not maintained for two out of three action spaces, GPT-4 Turbo succeeds in holding calibration through all the remaining four learner model edit operations (Table 2).This result indicates that GPT-4 Turbo was usually (in 16 of 18 cases) able to generalize to new learner models and characteristics without requiring re-calibration, which is important both for practical reasons (e.g., the cost associated with manual re-calibration) and more fundamental ones (e.g., generating novel insights rather than simply calibrating to reproduce existing findings).The two instances where calibration was not maintained suggest that combining separately calibrated hypotheses might be more challenging yet the model demonstrates strong stability across other operations where multiple hypotheses are Table 2: Results of statistical tests evaluating the impact of different operations on the calibration state of hypotheses within the learner model.The table compares pre-operation (Pre-Op) and post-operation (Post-Op) results using Chi-squared and Spearman correlation tests, conducted across three different labelings of the action space for improved reliability.The operations include Ex-Situ Transfer, Combine Hypotheses, Variable Swap, LC Swap, and Calibration Regression.For each operation, the table provides the specific hypotheses tested, the applied statistical test, and the resulting p-values.Bolded hypotheses indicate those tested in both the pre-and post-op phases.Green shading denotes stable test results (holding calibration), red shading shows a total loss of calibration, and yellow shading indicates that the MDHyp is satisfied post-operation, though with some degradation in statistical significance.</p>
<p>present.</p>
<p>While further experimental evidence is needed before we can generalize these claims across learning environments, learner characteristics, and even different LLMs, the results from this illustrative experiment bode well for the use of MDHyps as the unit of simulation-authoring with existing LLM technology.More broadly, balancing explicit and implicit authoring of agent simulations involves deciding which specific agent behaviors must be defined manually and which can be left for the LLM to handle automatically.In sensitive domains like education, a bias toward explicit authoring is prudent (Tian et al. 2024), as LLMs struggle with certain reasoning tasks (Huang and Chang 2022;Kambhampati 2024;Kambhampati et al. 2024).Our proposed MDHyps and Learner Model Edit Graph abstractions offer a foundation for building benchmark datasets that evaluate LLM performance across different learner characteristics and multiple learning environments.</p>
<p>Limitations and Future Work</p>
<p>Our study focuses on two learner characteristics-geometry proficiency and persistence-within a single learning environment.While this scope is limited, it allows us to generate targeted insights and refine our methods, laying the groundwork for future expansion.Complex, non-linear interactions likely exist that are challenging to calibrate without real learner data (Klein-Latucha and Hershkovitz 2024).Future work should build on this foundation by exploring a broader range of environments and more intricate relationships among learner characteristics while assessing the robustness of LLMs to changes in both the learner model and the environment.Although MDHyps offer scalable assessments, the real value of learner action simulations lies in their use for downstream tasks and expert evaluation.These simulations can predict learner actions, serving as effective copilots in designing learning environments.Future research should analyze these predictions to identify biases and failure modes, informing improvements in learning environment designs.Other avenues for future empirical work with the HYP-MIX framework include experimenting with alternative LLMs (including open-source ones) and learning environments with continuous action spaces (including natural language input).</p>
<p>Conclusion</p>
<p>This study introduced the HYP-MIX framework using Marginal Distributional Hypotheses (MDHyps) to simulate learner actions in open-ended interactive learning environments, addressing the challenges of costly and timeconsuming testing and evaluating whether current LLMs are capable of maintaining calibration under changes to the simulation environment.We demonstrated that GPT-4 Turbo can maintain calibration across various learner model modifications, reducing the need for frequent recalibration and highlighting the potential of LLMs for behavioral simulation.Our key contribution is a scalable method for leveraging LLMs to enhance the adaptability of open-ended interactive learning environments and test their generalization across different contexts.</p>
<p>Action Spaces</p>
<p>To maximize the reliability of the experimental results while traversing with the Learner Model Edit Graph, we run the LLM with not one, but three labellings of the learner's action space.We present all three labelings that we used in Table 3.</p>
<p>Best Practices for Hypothesis Class Induction</p>
<p>The process of calibrating a template for a hypothesis class may necessitate the addition of new fields to the instruction template by the prompt engineer.A key design principle is to ensure that each field is sufficiently flexible to accommodate a wide range of hypotheses.This flexibility not only supports the adaptability of the framework but also maximizes its utility across different research contexts.</p>
<p>Another important design principle is to maintain parsimony in the number of hypothesis classes.While the in-  troduction of new hypothesis classes can enhance the specificity of the framework, each new class introduces an initial calibration overhead.Therefore, it is essential to balance the benefits of adding new classes with the associated costs in terms of time and resources.
A B C MEASURE-F1-X MEASURE-X-F1 CALC(f1, o) MEASURE-A-F1 MEASURE-F1-A CALC(a, f1) MEASURE-A-P MEASURE-P-A CALC(a, p) MEASURE-A-F2 MEASURE-F2-A CALC(a, f2) MEASURE-A-X MEASURE-X-A CALC(a, o) MEASURE-F1-P MEASURE-P-F1 CALC(f1, p) MEASURE-F1-F2 MEASURE-F2-F1 CALC(f1, f2) MEASURE-F2-P MEASURE-P-F2 CALC(f2, p) MEASURE-F2-X MEASURE-X-F2 CALC(f2,
We also posit that a balance should be struck between allowing the LLM's commonsense reasoning to guide responses and adhering to expert-defined hypotheses.Striking this balance is crucial for ensuring that the LLM's outputs are both grounded in expert knowledge and adaptable to new and unexpected scenarios.By carefully managing this interplay, researchers can optimize the performance of LLMs within our framework, leading to more reliable and insightful results.</p>
<p>MDHyps as Learner Model Update Rules in Disguise</p>
<p>The process of developing a learner model is directly analogous to defining an MDHyp.Learner modeling is the process of creating (and iteratively refining) a representation of a learner's knowledge, skills, abilities, and preferences to tailor educational experiences and improve learning outcomes (Hooshyar et al. 2020) We make the key observation that such an update rule may be transformed into an equivalent MDHyp that takes the fol- This one-to-one correspondence between a learner model's update rule and an MDHyp illustrates that hypothesis-development is already an inherent and integral part of the initial development effort of a learning environment today, albeit formulated differently.This means that educational experts, who will be responsible for formulating MDHyps of learner behavior are already well-acquainted with the underlying principles.Consequently, transforming these update rules into MDHyps for simulation purposes should be a natural extension of their existing expertise.</p>
<p>Global Prompt Templates</p>
<p>Figure 2 :
2
Figure 2: A screenshot of the original HoloOrbits environment (Rajarathinam, Palaguachi, and Kang 2024) with the keypoints annotated.</p>
<p>Figure 4 :
4
Figure 4: This figure depicts the hierarchical composition of the learner simulation prompt template, Îsim, which integrates global fragments ( Îglobal), environment descriptions ( Îenvironment),and learner persona values ( Îlearner) to provide contextual grounding.The template also includes Learner Characteristic (LC) Models, ÎLC(M), which are parameterized to simulate responses under different hypotheses, Hi,j, evaluated within individual LC models (M1, M2).These components collectively facilitate the generation of contextually appropriate actions in the simulation, reflecting the interplay between the environment and the learner's characteristics.</p>
<p>lowing form: "Learners with a [HIGH | LOW] <CHARACTERISTIC> are more likely to perform <ACTION> when <CONDI-TION(S)> than learners with a [LOW | HIGH] <CHAR-ACTERISTIC>."</p>
<p>Table 1 :
1
Illustrative hypotheses used in our learner modeling experiments.The regular text represents the template for each hypothesis class, with blue text indicating specific slot values filled by each hypothesis.The Appendix provides the updated, calibrated prompt templates.</p>
<p>The Learner Model Edit Graph used in our experiments to evaluate LLM robustness across five distinct edit operations to the learner model.Each node represents a "snapshot" of the learner model after specific edits by the developer.Inside each node, the MDHyps comprising the learner model snapshot are listed.Green nodes indicate calibrated snapshots, while yellow nodes represent states untested for calibration.Each MDHyp in the learner model is annotated with a superscript: '?' for untested calibration status and '*' for confirmed calibration.(1)Ex-Situ Transfer: Tests if an MDHyp that is calibrated alongside other MDHyps remains calibrated when tested alone.(2)Combine Hypotheses: Assesses if two separately calibrated hypotheses remain stable when combined.(3) Variable Swap: Involves swapping a single variable within a hypothesis.(4) LC Swap: Evaluates if a prompt template calibrated for one learner characteristic works for another in the same class.(5) Calibration Regression: Tests if a calibrated hypothesis remains stable when a new hypothesis is added to the model.
LCCOMBI NESW APHYPSVARI ABLESW APCALI BRATI ONEX-SI TUREGRESSI ONTRANSFERFigure 3: of the original MDHyp for persistence, resulting in a newhypothesis, H P 2 .3. Append: During testing, we observed that learners withminimal Geometry Proficiency (1/10) were unexpectedlyproducing a high percentage (∼80%) of productive mea-surements, contrary to our expectation of a uniform dis-tributionTRUE,if ρ &gt; 0 and P ρ ≤ 0.05for a monotonicallyincreasing hypothesisTRUE,if ρ &lt; 0 and P ρ ≤ 0.05for a monotonicallydecreasing hypothesisFALSE, otherwise(1)For H G1 , Spearman correlation is computed between thepersona value for geometry proficiency and empiricalprobability of making a productive measurement.
2. Variable Swap: After consulting with learning science experts, we determined that the "Number of Submissions" was a more suitable measure of "challenge" than "Number of Minutes Elapsed."Thisled to a modification 3 .To address this, we introduced H G2 and a new hypothesis class, H uniform , to explicitly model this behavior and refine the Geometry Proficiency model, better align it with our theoretical expectations.The success criteria function T uniform for the uniform distribution hypothesis is defined using the p-value of a Chi-squared test P χ 2 as follows:T uniform (P χ 2 ) = TRUE if P χ 2 &gt; 0.05 else FALSE (2) 4. Combine Hypotheses: After calibrating the prompt templates for H G2 and H P 2 , we combined these MD-Hyps into a unified learner model, completing the development process.</p>
<p>Table 3 :
3
Three different labelings of the learner's action space used in the LLM experiments to ensure reliability when traversing the Learner Model Edit Graph.</p>
<p>Îglobal 1 You are a simulated learner agent → working in a learning → environment designed to test → your understanding of → Kepler's First Law.Given a → scenario in the learning → environment, you will → generate the next action that → a 13 year old human learner → who possesses the given → learner characteristics would → most likely perform in the → given situation.The → stipulated class period for → this activity is 40 minutes.→ The teacher has instructed → you to work on the activity → for the entire class period.Kepler's First Law.Given a → scenario in the learning → environment, you will → generate the next action that → a 13 year old human learner → who possesses the given → learner characteristics would → most likely perform in the → given situation.The → stipulated class period for → this activity is 40 minutes.→ The teacher has instructed → you to work on the activity → for the entire class period.You are a simulated learner agent → working in a learning → environment designed to test → your understanding of → Kepler's First Law.Given a → scenario in the learning → environment, you will → generate the next action that → a 13 year old human learner → who possesses the given → learner characteristics would → most likely perform in the → given situation.The → stipulated class period for → this activity is 40 minutes.→ The teacher has instructed → you to work on the activity → for the entire class period.ÎH monotonic (at H B , H E , and H I )
1 Hypothesis Class Prompt TemplatesÎH monotonic (Uncalibrated)Îenvironment1 You are a simulated learner agent → working in a learning → environment designed to test → your understanding of → Îlearner1 A learner with a higher <learner → characteristic> level is more → likely to <short description → of target behavior> (i.e., → <long-description of target → behavior>). To '<short → description of target → behavior>' is to make one of → the following actions: <list → of actions>. In the event → that your commonsense → reasoning DIRECTLY conflicts → with this hypothesis, use → this hypothesis. ÎH uniform (Uncalibrated)
1 A learner with a higher <learner → characteristic> level is more → likely to <short description → of target behavior> (i.e., → <long-description of target → behavior>).To '<short → description of target → behavior>' is to make one of → the following actions: <list → of actions>.1As learners get closer and closer → to the <low_or_high>er end of → the <learner_characteristic> → spectrum (value of &lt;1 if → low_or_high = 'low' else 10&gt;)</p>
<p>The term originates from Hans, a horse in early
20th century Germany, who seemed to perform arithmetic by tapping his hoof. It was later found he was responding to subtle cues from his trainer or the audience.
https://github.com/msamogh/hypmix
We hypothesize this result to be a result of a more general phenomenon that Aher, Arriaga, and Kalai (2023) refer to as "hyper-accuracy distortion," where LLMs struggle to feign ignorance about a topic to simulate human behavior.
AcknowledgementsWe thank ChengXiang Zhai for his valuable feedback in developing the ideas behind this work.This material is based upon work supported by the National Science Foundation and the Institute of Education Sciences under Grant #2229612 (National AI Institute for Inclusive Intelligent Technologies for Education).Any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of National Science Foundation or the U.S. Department of Education.
J Achiam, S Adler, S Agarwal, L Ahmad, I Akkaya, F L Aleman, D Almeida, J Altenschmidt, S Altman, S Anadkat, arXiv:2303.08774Gpt-4 technical report. 2023arXiv preprint</p>
<p>Using Large Language Models to Simulate Multiple Humans and Replicate Human Subject Studies. G Aher, R I Arriaga, A T Kalai, ArXiv:2208.102642023</p>
<p>Evaluating the RE-DEEM authoring tool: can teachers create effective learning environments?. S Ainsworth, S Grimshaw, International Journal of Artificial Intelligence in Education. 143-42004</p>
<p>Investigating the Relations between StudentsâC™ Affective States and the Coherence in their Activities in Open-Ended Learning Environments. C E Akpanoko, S , A T Cordell, G Biswas, G , Proceedings of the 17th International Conference on Educational Data Mining. B Paaãÿen, C D Epp, the 17th International Conference on Educational Data MiningAtlanta, Georgia, USAInternational Educational Data Mining Society2024</p>
<p>Assessment and development of executive function (EF) during childhood. P Anderson, Child neuropsychology. 822002</p>
<p>Calibration of machine learning models. A Bella, C Ferri, J Hernández-Orallo, M J Ramírez-Quintana, Handbook of Research on Machine Learning Applications and Trends: Algorithms, Methods, and Techniques. IGI Global2010</p>
<p>Evaluating an authoring tool for model-tracing intelligent tutoring systems. S B Blessing, S Gilbert, International Conference on Intelligent Tutoring Systems. Springer2008</p>
<p>Using GPT for market research. J Brand, A Israeli, D Ngwe, 2023Harvard Business School Marketing Unit Working Paper</p>
<p>Metrology: Calibration and measurement processes guidelines. H T Castrup, W G Eicke, J L Hayes, A Mark, R E Martin, J L Taylor, 95: 18745NASA STI/Recon Technical Report. 1994</p>
<p>SimSchool: An online dynamic simulator for enhancing teacher preparation. R Christensen, G Knezek, T Tyler-Wood, D Gibson, International Journal of Learning Technology. 622011</p>
<p>Language models show human-like content effects on reasoning. I Dasgupta, A K Lampinen, S C Chan, A Creswell, D Kumaran, J L Mcclelland, F Hill, arXiv:2207.07051ArXiv:2402.02896 [cs] version: 1Frisch, I.; and Giulianelli, M. 2024. LLM Agents in Interaction: Measuring Personality Consistency and Linguistic Alignment in Interacting Populations of Large Language Models. 2022arXiv preprint</p>
<p>The challenge of using llms to simulate human behavior: a causal inference perspective. G Gui, O Toubia, S Land, K Oliver, ArXiv, abs/2312.15524Instructional-design theories and models. 2023. 2013Open learning environments: Foundations, methods, and models. Routledge</p>
<p>Student-centered, open learning environments: Research, theory, and practice. Handbook of research on educational communications and technology. M J Hannafin, J R Hill, S M Land, E Lee, 2014</p>
<p>Codesigning a real-time classroom orchestration tool to support teacher-AI complementarity. Grantee Submission. M L Hilton, J W Pellegrino, B M Mclaren, V Aleven, D Hooshyar, M Pedaste, K Saks, Ä Leijen, E Bardone, M Wang, Computers &amp; education. 1541038782012. 2019. 2020National Academies PressOpen learner models in supporting self-regulated learning in higher education: A systematic literature review</p>
<p>J Huang, K C Chang, -C , arXiv:2212.10403Towards reasoning in large language models: A survey. 2022arXiv preprint</p>
<p>Evaluating the demographic characteristics and political preferences of MTurk survey respondents. C Huff, D Tingley, Research &amp; Politics. 2320531680156046482015Who are these people?</p>
<p>Teaching and Learning of Geometry-A Literature Review on Current Developments in Theory and Practice. S Jablonski, M Ludwig, Education Sciences. 7132023</p>
<p>PersonaLLM: Investigating the Ability of Large Language Models to Express Personality Traits. H Jiang, X Zhang, X Cao, C Breazeal, D Roy, J Kabbara, Findings of the Association for Computational Linguistics: NAACL 2024. K Duh, H Gomez, S Bethard, Mexico City; MexicoAssociation for Computational Linguistics2024</p>
<p>Can Large Language Models Reason and Plan?. S Kambhampati, ArXiv:2403.04121Annals of the New York Academy of Sciences. 153412024</p>
<p>LLMs Can't Plan, But Can Help Planning in LLM-Modulo Frameworks. S Kambhampati, K Valmeekam, L Guan, K Stechly, M Verma, S Bhambri, L Saldyt, A Murthy, ArXiv:2402.018172024</p>
<p>The role of affective and motivational factors in designing personalized learning environments. C Kim, Educational Technology Research and Development. 602012</p>
<p>When Leaving is Persisting: Studying Patterns of Persistence in an Online Game-Based Learning Environment for Mathematics. O Klein-Latucha, A Hershkovitz, Journal of Learning Analytics. 2024</p>
<p>Simulated Learners in Educational Technology: A Systematic Literature Review and a Turing-like Test. K R Koedinger, N Matsuda, C J Maclellan, E A Mclaughlin, AIED Workshops. Käser, T.; and Alexandron, G. 2023. 2015Methods for Evaluating Simulated Learners: Examples from SimStudent</p>
<p>Theoretical foundations of learning environments. S Land, D Jonassen, 2012Routledge</p>
<p>Exploring the sensitivity of LLMs' decision-making capabilities: Insights from prompt variations and hyperparameters. M Loya, D Sinha, R Futrell, Findings of the association for computational linguistics: EMNLP 2023. H Bouamor, J Pino, K Bali, SingaporeAssociation for Computational Linguistics2023a</p>
<p>Exploring the Sensitivity of LLMs' Decision-Making Capabilities: In. M Loya, D A Sinha, R Futrell, arXiv:2312.17476sights from Prompt Variation and Hyperparameters. 2023barXiv preprint</p>
<p>Fantastically ordered prompts and where to find them: Overcoming few-shot prompt order sensitivity. Y Lu, M Bartolo, A Moore, S Riedel, P Stenetorp, Proceedings of the 60th annual meeting of the association for computational linguistics. S Muresan, P Nakov, A Villavicencio, the 60th annual meeting of the association for computational linguisticsDublin, IrelandAssociation for Computational Linguistics20221</p>
<p>A Mannekote, arXiv:2404.13074Towards Compositionally Generalizable Semantic Parsing in Large Language Models: A Survey. 2024arXiv preprint</p>
<p>Teaching the teacher: tutoring SimStudent leads to more effective cognitive tutor authoring. N Matsuda, W W Cohen, K R Koedinger, International Journal of Artificial Intelligence in Education. 252015Springer</p>
<p>Wait, It's All Token Noise? Always Has Been: Interpreting LLM Behavior Using Shapley Value. B Mohammadi, ArXiv:2404.013322024</p>
<p>Exploring Reasoning Biases in Large Language Models Through Syllogism: Insights from the NeuBAROCO Dataset. K Ozeki, R Ando, T Morishita, H Abe, K Mineshima, M Okada, Findings of the Association for Computational Linguistics ACL 2024. L.-W Ku, A Martins, V Srikumar, BangkokAssociation for Computational Linguistics2024</p>
<p>J S Park, J C O'brien, C J Cai, M R Morris, P Liang, M S Bernstein, ArXiv:2304.03442Generative Agents: Interactive Simulacra of Human Behavior. 2023</p>
<p>Enhancing Multimodal Learning Analytics: A Comparative Study of Facial Features Captured Using Traditional vs 360-Degree Cameras in Collaborative Learning. J S Park, L Popowski, C Cai, M R Morris, P Liang, M S Bernstein, R J Rajarathinam, C Palaguachi, J Kang, Proceedings of the 35th Annual ACM Symposium on User Interface Software and Technology. B Paaãÿen, C D Epp, the 35th Annual ACM Symposium on User Interface Software and TechnologyAtlanta, Georgia, USA2022. 2024Proceedings of the 17th International Conference on Educational Data Mining. International Educational Data Mining Society</p>
<p>Interactive learning environments: Contemporary issues and trends. An introduction to the special issue. A Renkl, R K Atkinson, Educational Psychology Review. 192007</p>
<p>Seriously considering play: Designing interactive learning environments based on the blending of microworlds, simulations, and games. L P Rieber, Educational technology research and development. 199644</p>
<p>NLP Evaluation in trouble: On the Need to Measure LLM Data Contamination for each Benchmark. O Sainz, J Campos, I García-Ferrero, J Etxaniz, O L De Lacalle, E Agirre, Findings of the Association for Computational Linguistics: EMNLP 2023. H Bouamor, J Pino, K Bali, SingaporeAssociation for Computational Linguistics2023</p>
<p>Conjecture mapping: An approach to systematic educational design research. W Sandoval, Journal of the learning sciences. 2312014</p>
<p>Quantifying Language Models' Sensitivity to Spurious Features in Prompt Design or: How I learned to start worrying about prompt formatting. M Sclar, Y Choi, Y Tsvetkov, A Suhr, arXiv:2310.113242023arXiv preprint</p>
<p>Examining LLM Prompting Strategies for Automatic Evaluation of Learner-Created Computational Artifacts. X Tian, A Mannekote, C E Solomon, Y Song, C F Wise, T Mcklin, J Barrett, K E Boyer, M Israel, Proceedings of the 17th International Conference on Educational Data Mining. B Paaãÿen, C D Epp, the 17th International Conference on Educational Data MiningAtlanta, Georgia, USAInternational Educational Data Mining Society2024</p>
<p>A survey on large language model based autonomous agents. L Wang, C Ma, X Feng, Z Zhang, H Yang, J Zhang, Z Chen, J Tang, X Chen, Y Lin, Frontiers of Computer Science. 1861863452024</p>
<p>Chain-ofthought prompting elicits reasoning in large language models. J Wei, X Wang, D Schuurmans, M Bosma, F Xia, E Chi, Q V Le, D Zhou, Advances in neural information processing systems. 202235</p>
<p>Y Xiao, Y Cheng, J Fu, J Wang, W Li, P Liu, arXiv:2312.17115How far are we from believable AI agents? A framework for evaluating the believability of human behavior simulation. 2023arXiv preprint</p>
<p>D Yu, S Kaur, A Gupta, J Brown-Cohen, A Goyal, S Arora, arXiv:2310.17567Skill-Mix: A flexible and expandable family of evaluations for AI models. 2023arXiv preprint</p>
<p>T Z Zhao, E Wallace, S Feng, D Klein, S Singh, ArXiv:2102.09690Calibrate Before Use: Improving Few-Shot Performance of Language Models. 2021</p>            </div>
        </div>

    </div>
</body>
</html>