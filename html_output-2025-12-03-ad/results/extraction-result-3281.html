<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-3281 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-3281</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-3281</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-76.html">extraction-schema-76</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models using diverse reasoning methods versus similar reasoning styles to solve reasoning problems, including details of the reasoning methods, tasks, model types, and performance comparisons.</div>
                <p><strong>Paper ID:</strong> paper-dcbf62f17dad0f4554f91c822d141fb92f78429a</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/dcbf62f17dad0f4554f91c822d141fb92f78429a" target="_blank">Self-Generated In-Context Learning: Leveraging Auto-regressive Language Models as a Demonstration Generator</a></p>
                <p><strong>Paper Venue:</strong> arXiv.org</p>
                <p><strong>Paper TL;DR:</strong> Self-generated in-context learning (SG-ICL) is proposed, which generates demonstrations for in- context learning from PLM itself to minimize the reliance on the external demonstration.</p>
                <p><strong>Paper Abstract:</strong> Large-scale pre-trained language models (PLMs) are well-known for being capable of solving a task simply by conditioning a few input-label pairs dubbed demonstrations on a prompt without being explicitly tuned for the desired downstream task. Such a process (i.e., in-context learning), however, naturally leads to high reliance on the demonstrations which are usually selected from external datasets. In this paper, we propose self-generated in-context learning (SG-ICL), which generates demonstrations for in-context learning from PLM itself to minimize the reliance on the external demonstration. We conduct experiments on four different text classification tasks and show SG-ICL significantly outperforms zero-shot learning and is generally worth approximately 0.6 gold training samples. Moreover, our generated demonstrations show more consistent performance with low variance compared to randomly selected demonstrations from the training dataset.</p>
                <p><strong>Cost:</strong> 0.012</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e3281.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e3281.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models using diverse reasoning methods versus similar reasoning styles to solve reasoning problems, including details of the reasoning methods, tasks, model types, and performance comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>SG-ICL</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Self-Generated In-Context Learning</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A method that generates demonstration examples from an auto-regressive pre-trained language model conditioned on the current test input and a target class, then reuses those generated examples as in-context demonstrations for inference.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-J</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>An auto-regressive transformer pre-trained language model; implementation and weights from Huggingface Transformers were used in experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>6B</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_methods</strong></td>
                            <td>['in-context learning (ICL)', 'self-generated demonstrations (generation conditioned on test input + class)', 'zero-shot inference (as baseline comparison)', 'few-shot inference with gold demonstrations (baseline comparison)']</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_methods_description</strong></td>
                            <td>SG-ICL is a two-step procedure: (1) Self-generation: for each test input and a chosen class token, the PLM generates example(s) (demonstrations) using a generation template G(input, class). Temperature sampling (T=0.5) was used and 8 generated in-context samples per test input were produced. (2) Inference: the generated examples are formatted with an inference template T(·) and concatenated with the test input to perform standard in-context prediction by selecting the class token with highest probability.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_of_methods</strong></td>
                            <td>Single core reasoning style (in-context learning) with internal diversity created via different generation strategies for demonstrations; the paper contrasts two generation styles (class-conditioned vs input+class-conditioned) to produce more or less input-correlated demonstrations.</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task_name</strong></td>
                            <td>SST-2, SST-5, RTE, CB</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task_description</strong></td>
                            <td>Text classification tasks: SST-2 (binary sentiment), SST-5 (5-way sentiment), RTE (binary textual entailment), CB (3-way commitment bank NLI). Accuracy is the reported metric.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_by_method</strong></td>
                            <td>Qualitative and relative results reported: SG-ICL (8 generated demonstrations per test input) significantly outperforms zero-shot across all four datasets; SG-ICL yields much lower variance than few-shot with randomly selected gold demonstrations. Quantitative summary provided by authors: 'SG-ICL outperforms few-shot learning with up to 5 in-context (gold) samples' and 'one self-generated in-context sample is worth about 0.6 gold training sample.' Exact per-dataset accuracy numbers are not given in the main text.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_of_methods</strong></td>
                            <td>SG-ICL compared to zero-shot and few-shot baselines (same number of demonstrations): SG-ICL > zero-shot consistently; SG-ICL matches or exceeds few-shot when few-shot uses up to 5 gold examples while SG-ICL uses 8 generated examples. SG-ICL exhibits lower variance than few-shot ICL with randomly selected demonstrations.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Generating demonstrations conditioned on the test input and class produces more input-correlated examples which improve ICL performance and stability; SG-ICL removes dependence on external training demonstrations and is roughly equivalent to a modest number of gold training examples (~0.6 sample per generated example).</td>
                        </tr>
                        <tr>
                            <td><strong>counter_examples_or_negative_results</strong></td>
                            <td>No specific failure cases with numeric degradation are reported; authors note dependency on the PLM's generative ability and suggest larger PLMs may further improve results (limitation rather than a reported negative result).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Self-Generated In-Context Learning: Leveraging Auto-regressive Language Models as a Demonstration Generator', 'publication_date_yy_mm': '2022-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3281.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e3281.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models using diverse reasoning methods versus similar reasoning styles to solve reasoning problems, including details of the reasoning methods, tasks, model types, and performance comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Class-conditioned generation</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Generation conditioned only on class label</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A generation strategy where the PLM is prompted to produce demonstrations conditioned only on a target class token (no conditioning on the current test input).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-J</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Auto-regressive transformer PLM used to generate demonstrations given a template containing only class information.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>6B</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_methods</strong></td>
                            <td>['generation conditioned on class label', 'in-context learning using generated demonstrations']</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_methods_description</strong></td>
                            <td>The generation template provides the model with the class token and asks it to generate an example for that class (e.g., 'Generate a "negative" review :'). Generated examples are then used as demonstrations for ICL.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_of_methods</strong></td>
                            <td>This is a single, homogeneous generation style that produces class-typical examples (less input-specific).</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task_name</strong></td>
                            <td>SST-2, SST-5 (reported similarity analysis); used as a generation method for ICL across tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task_description</strong></td>
                            <td>Same sentiment classification tasks used for downstream evaluation.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_by_method</strong></td>
                            <td>Cosine similarity (sentence embeddings) between input instance and generated demonstration: SST-2 = 0.0689; SST-5 = 0.0735. Downstream performance: class-conditioned generation provides performance gain over zero-shot but less gain than input+class-conditioned generation (exact accuracy numbers not reported in paper main text).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_of_methods</strong></td>
                            <td>Compared directly to input+class-conditioned generation: class-conditioned yields much lower input-demo cosine similarity and lower downstream task performance (see Figure 3 and Table 1 in the paper).</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Conditioning only on class produces demonstrations that are not well aligned semantically with the test input (low cosine similarity) and delivers smaller performance improvements when used as ICL demonstrations.</td>
                        </tr>
                        <tr>
                            <td><strong>counter_examples_or_negative_results</strong></td>
                            <td>No numeric cases where class-conditioned outperforms input+class-conditioned are reported.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Self-Generated In-Context Learning: Leveraging Auto-regressive Language Models as a Demonstration Generator', 'publication_date_yy_mm': '2022-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3281.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e3281.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models using diverse reasoning methods versus similar reasoning styles to solve reasoning problems, including details of the reasoning methods, tasks, model types, and performance comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Input+Class-conditioned generation</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Generation conditioned on both the test input and the class label</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A generation strategy where the PLM is prompted with both the current test input and a target class token to produce demonstrations that are semantically closer to the test input.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-J</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Auto-regressive transformer PLM used to generate demonstrations given a template containing both the test input and the class token; 8 generated demonstrations per test input using temperature sampling (T=0.5).</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>6B</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_methods</strong></td>
                            <td>['generation conditioned on test input + class', 'in-context learning using generated demonstrations']</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_methods_description</strong></td>
                            <td>Generation template G(x_test, V(y)) supplies the PLM with the specific test instance and the class token, instructing it to generate an example (demonstration) representative of that class in the context of the test input. The generated demonstration is then formatted and used as an in-context example for inference.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_of_methods</strong></td>
                            <td>Method produces demonstrations that are more tailored (diverse with respect to the test input) but is still a single reasoning style (ICL) with refined demonstration generation.</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task_name</strong></td>
                            <td>SST-2, SST-5 (similarity analysis) and downstream classification tasks (SST-2, SST-5, RTE, CB).</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task_description</strong></td>
                            <td>Same text classification tasks; aim is to improve ICL by using input-correlated generated examples.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_by_method</strong></td>
                            <td>Cosine similarity between input and generated demonstration: SST-2 = 0.3051; SST-5 = 0.3098 (substantially higher than class-conditioned). Downstream performance: input+class-conditioned generation provides greater performance gains over class-conditioned generation and zero-shot in the authors' experiments (exact accuracies are not tabulated in the main text, but Figure 3 shows higher accuracy for input+class-conditioned across tasks).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_of_methods</strong></td>
                            <td>Direct ablation vs class-conditioned generation: input+class-conditioned yields higher input-demo similarity and higher downstream accuracy; authors attribute improved ICL performance to higher input-demonstration correlation.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Conditioning generation on both the test input and the class yields demonstrations that are semantically closer to the input and produce larger performance gains when used for ICL.</td>
                        </tr>
                        <tr>
                            <td><strong>counter_examples_or_negative_results</strong></td>
                            <td>No reported cases where input+class-conditioned generation underperforms class-conditioned in their experiments; authors note overall gains depend on the underlying PLM's generation quality.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Self-Generated In-Context Learning: Leveraging Auto-regressive Language Models as a Demonstration Generator', 'publication_date_yy_mm': '2022-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3281.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e3281.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models using diverse reasoning methods versus similar reasoning styles to solve reasoning problems, including details of the reasoning methods, tasks, model types, and performance comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Few-shot ICL (gold demonstrations)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Few-shot In-Context Learning using gold training demonstrations</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Standard in-context learning where k labeled examples (here up to 8) are sampled from a gold training set and concatenated with the test input for inference without parameter updates.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-J</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Auto-regressive PLM used to perform few-shot ICL with k gold training examples; two inference templates were used (minimal and manual).</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>6B</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_methods</strong></td>
                            <td>['few-shot in-context learning with randomly selected gold demonstrations', 'sampling/order sensitivity analyses (background)']</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_methods_description</strong></td>
                            <td>k labeled training examples are concatenated (using an inference template) with the test input; prediction is made by scoring verbalizer tokens. In experiments, up to 8 gold examples were used; results averaged over 5 random seeds to capture variability.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_of_methods</strong></td>
                            <td>Method relies on the diversity/selection of the gold demonstrations; the paper treats randomly selected demonstrations as the typical few-shot approach and shows it has higher variance compared to SG-ICL-generated demonstrations.</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task_name</strong></td>
                            <td>SST-2, SST-5, RTE, CB</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task_description</strong></td>
                            <td>Same text classification tasks used for evaluation.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_by_method</strong></td>
                            <td>Authors report that few-shot learning with up to 8 gold examples achieves competitive accuracies but higher variance; SG-ICL with 8 generated samples outperforms few-shot with up to 5 gold examples. Exact accuracy numbers are not provided in the main text.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_of_methods</strong></td>
                            <td>Few-shot ICL (with random gold example selection) shows larger performance variance and in the reported comparisons is outperformed by SG-ICL when SG-ICL uses 8 generated demos and few-shot uses <=5 gold demos.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Randomly sampled gold demonstrations can produce unstable performance; well-conditioned generated demonstrations can provide more stable and sometimes superior performance relative to a small number of gold examples.</td>
                        </tr>
                        <tr>
                            <td><strong>counter_examples_or_negative_results</strong></td>
                            <td>No precise numerical counterexamples where few-shot gold demonstrations outperform SG-ICL when using the same number of examples, but authors show few-shot with more than 5 gold examples may outperform SG-ICL with 8 generated samples (implied by the statement SG-ICL outperforms few-shot learning with up to 5 gold training samples).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Self-Generated In-Context Learning: Leveraging Auto-regressive Language Models as a Demonstration Generator', 'publication_date_yy_mm': '2022-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3281.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e3281.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models using diverse reasoning methods versus similar reasoning styles to solve reasoning problems, including details of the reasoning methods, tasks, model types, and performance comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Zero-shot ICL</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Zero-shot In-Context Learning (no demonstrations)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Inference by prompting the PLM without any in-context demonstrations (k = 0).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-J</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Auto-regressive PLM performing zero-shot inference using the inference template and verbalizer tokens.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>6B</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_methods</strong></td>
                            <td>['zero-shot prompting']</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_methods_description</strong></td>
                            <td>Provide a task prompt and ask the model to produce an answer without any labeled examples; used as baseline for comparisons.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_of_methods</strong></td>
                            <td>Single style (no in-context demonstration); used as a baseline rather than a diversity strategy.</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task_name</strong></td>
                            <td>SST-2, SST-5, RTE, CB</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task_description</strong></td>
                            <td>Text classification tasks used as baselines for comparison with SG-ICL and few-shot ICL.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_by_method</strong></td>
                            <td>Authors report SG-ICL significantly outperforms zero-shot across all four tasks. Exact accuracy values for zero-shot are not provided in main text.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_of_methods</strong></td>
                            <td>SG-ICL vs zero-shot: SG-ICL yields consistent and significant gains despite both having no access to training data, because SG-ICL creates generated demonstrations conditioned on input+class.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Generating demonstrations from the model (SG-ICL) yields substantial gains over direct zero-shot prompting.</td>
                        </tr>
                        <tr>
                            <td><strong>counter_examples_or_negative_results</strong></td>
                            <td>No negative cases reported where zero-shot beats SG-ICL.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Self-Generated In-Context Learning: Leveraging Auto-regressive Language Models as a Demonstration Generator', 'publication_date_yy_mm': '2022-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3281.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e3281.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of language models using diverse reasoning methods versus similar reasoning styles to solve reasoning problems, including details of the reasoning methods, tasks, model types, and performance comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GPT-3 (background mention)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Generative Pre-trained Transformer 3</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A prominent large auto-regressive language model introduced by Brown et al. (2020) and referenced in the paper as foundational work on few-shot in-context learning.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Language models are few-shot learners</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-3</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Large auto-regressive transformer introduced in Brown et al. (2020); established the paradigm of few-shot in-context learning. Mentioned in background/related work but not used in experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>various (e.g., up to 175B in original paper)</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_methods</strong></td>
                            <td>['few-shot in-context learning (original motivating work)']</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_methods_description</strong></td>
                            <td>Described historically as the demonstration-based prompting approach where a few examples are provided to the model in-context to adapt behavior at inference time.</td>
                        </tr>
                        <tr>
                            <td><strong>diversity_of_methods</strong></td>
                            <td>Not experimentally analyzed in this paper; cited as prior work demonstrating ICL.</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_by_method</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_of_methods</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Cited as establishing the few-shot ICL paradigm which this paper builds upon; no new experimental results in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>counter_examples_or_negative_results</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Self-Generated In-Context Learning: Leveraging Auto-regressive Language Models as a Demonstration Generator', 'publication_date_yy_mm': '2022-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Language models are few-shot learners <em>(Rating: 2)</em></li>
                <li>What makes good in-context examples for GPT-3? <em>(Rating: 2)</em></li>
                <li>Learning to retrieve prompts for in-context learning <em>(Rating: 2)</em></li>
                <li>Calibrate before use: Improving few-shot performance of language models <em>(Rating: 1)</em></li>
                <li>Zerogen: Efficient zero-shot learning via dataset generation <em>(Rating: 2)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-3281",
    "paper_id": "paper-dcbf62f17dad0f4554f91c822d141fb92f78429a",
    "extraction_schema_id": "extraction-schema-76",
    "extracted_data": [
        {
            "name_short": "SG-ICL",
            "name_full": "Self-Generated In-Context Learning",
            "brief_description": "A method that generates demonstration examples from an auto-regressive pre-trained language model conditioned on the current test input and a target class, then reuses those generated examples as in-context demonstrations for inference.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "GPT-J",
            "model_description": "An auto-regressive transformer pre-trained language model; implementation and weights from Huggingface Transformers were used in experiments.",
            "model_size": "6B",
            "reasoning_methods": [
                "in-context learning (ICL)",
                "self-generated demonstrations (generation conditioned on test input + class)",
                "zero-shot inference (as baseline comparison)",
                "few-shot inference with gold demonstrations (baseline comparison)"
            ],
            "reasoning_methods_description": "SG-ICL is a two-step procedure: (1) Self-generation: for each test input and a chosen class token, the PLM generates example(s) (demonstrations) using a generation template G(input, class). Temperature sampling (T=0.5) was used and 8 generated in-context samples per test input were produced. (2) Inference: the generated examples are formatted with an inference template T(·) and concatenated with the test input to perform standard in-context prediction by selecting the class token with highest probability.",
            "diversity_of_methods": "Single core reasoning style (in-context learning) with internal diversity created via different generation strategies for demonstrations; the paper contrasts two generation styles (class-conditioned vs input+class-conditioned) to produce more or less input-correlated demonstrations.",
            "reasoning_task_name": "SST-2, SST-5, RTE, CB",
            "reasoning_task_description": "Text classification tasks: SST-2 (binary sentiment), SST-5 (5-way sentiment), RTE (binary textual entailment), CB (3-way commitment bank NLI). Accuracy is the reported metric.",
            "performance_by_method": "Qualitative and relative results reported: SG-ICL (8 generated demonstrations per test input) significantly outperforms zero-shot across all four datasets; SG-ICL yields much lower variance than few-shot with randomly selected gold demonstrations. Quantitative summary provided by authors: 'SG-ICL outperforms few-shot learning with up to 5 in-context (gold) samples' and 'one self-generated in-context sample is worth about 0.6 gold training sample.' Exact per-dataset accuracy numbers are not given in the main text.",
            "comparison_of_methods": "SG-ICL compared to zero-shot and few-shot baselines (same number of demonstrations): SG-ICL &gt; zero-shot consistently; SG-ICL matches or exceeds few-shot when few-shot uses up to 5 gold examples while SG-ICL uses 8 generated examples. SG-ICL exhibits lower variance than few-shot ICL with randomly selected demonstrations.",
            "key_findings": "Generating demonstrations conditioned on the test input and class produces more input-correlated examples which improve ICL performance and stability; SG-ICL removes dependence on external training demonstrations and is roughly equivalent to a modest number of gold training examples (~0.6 sample per generated example).",
            "counter_examples_or_negative_results": "No specific failure cases with numeric degradation are reported; authors note dependency on the PLM's generative ability and suggest larger PLMs may further improve results (limitation rather than a reported negative result).",
            "uuid": "e3281.0",
            "source_info": {
                "paper_title": "Self-Generated In-Context Learning: Leveraging Auto-regressive Language Models as a Demonstration Generator",
                "publication_date_yy_mm": "2022-06"
            }
        },
        {
            "name_short": "Class-conditioned generation",
            "name_full": "Generation conditioned only on class label",
            "brief_description": "A generation strategy where the PLM is prompted to produce demonstrations conditioned only on a target class token (no conditioning on the current test input).",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "GPT-J",
            "model_description": "Auto-regressive transformer PLM used to generate demonstrations given a template containing only class information.",
            "model_size": "6B",
            "reasoning_methods": [
                "generation conditioned on class label",
                "in-context learning using generated demonstrations"
            ],
            "reasoning_methods_description": "The generation template provides the model with the class token and asks it to generate an example for that class (e.g., 'Generate a \"negative\" review :'). Generated examples are then used as demonstrations for ICL.",
            "diversity_of_methods": "This is a single, homogeneous generation style that produces class-typical examples (less input-specific).",
            "reasoning_task_name": "SST-2, SST-5 (reported similarity analysis); used as a generation method for ICL across tasks.",
            "reasoning_task_description": "Same sentiment classification tasks used for downstream evaluation.",
            "performance_by_method": "Cosine similarity (sentence embeddings) between input instance and generated demonstration: SST-2 = 0.0689; SST-5 = 0.0735. Downstream performance: class-conditioned generation provides performance gain over zero-shot but less gain than input+class-conditioned generation (exact accuracy numbers not reported in paper main text).",
            "comparison_of_methods": "Compared directly to input+class-conditioned generation: class-conditioned yields much lower input-demo cosine similarity and lower downstream task performance (see Figure 3 and Table 1 in the paper).",
            "key_findings": "Conditioning only on class produces demonstrations that are not well aligned semantically with the test input (low cosine similarity) and delivers smaller performance improvements when used as ICL demonstrations.",
            "counter_examples_or_negative_results": "No numeric cases where class-conditioned outperforms input+class-conditioned are reported.",
            "uuid": "e3281.1",
            "source_info": {
                "paper_title": "Self-Generated In-Context Learning: Leveraging Auto-regressive Language Models as a Demonstration Generator",
                "publication_date_yy_mm": "2022-06"
            }
        },
        {
            "name_short": "Input+Class-conditioned generation",
            "name_full": "Generation conditioned on both the test input and the class label",
            "brief_description": "A generation strategy where the PLM is prompted with both the current test input and a target class token to produce demonstrations that are semantically closer to the test input.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "GPT-J",
            "model_description": "Auto-regressive transformer PLM used to generate demonstrations given a template containing both the test input and the class token; 8 generated demonstrations per test input using temperature sampling (T=0.5).",
            "model_size": "6B",
            "reasoning_methods": [
                "generation conditioned on test input + class",
                "in-context learning using generated demonstrations"
            ],
            "reasoning_methods_description": "Generation template G(x_test, V(y)) supplies the PLM with the specific test instance and the class token, instructing it to generate an example (demonstration) representative of that class in the context of the test input. The generated demonstration is then formatted and used as an in-context example for inference.",
            "diversity_of_methods": "Method produces demonstrations that are more tailored (diverse with respect to the test input) but is still a single reasoning style (ICL) with refined demonstration generation.",
            "reasoning_task_name": "SST-2, SST-5 (similarity analysis) and downstream classification tasks (SST-2, SST-5, RTE, CB).",
            "reasoning_task_description": "Same text classification tasks; aim is to improve ICL by using input-correlated generated examples.",
            "performance_by_method": "Cosine similarity between input and generated demonstration: SST-2 = 0.3051; SST-5 = 0.3098 (substantially higher than class-conditioned). Downstream performance: input+class-conditioned generation provides greater performance gains over class-conditioned generation and zero-shot in the authors' experiments (exact accuracies are not tabulated in the main text, but Figure 3 shows higher accuracy for input+class-conditioned across tasks).",
            "comparison_of_methods": "Direct ablation vs class-conditioned generation: input+class-conditioned yields higher input-demo similarity and higher downstream accuracy; authors attribute improved ICL performance to higher input-demonstration correlation.",
            "key_findings": "Conditioning generation on both the test input and the class yields demonstrations that are semantically closer to the input and produce larger performance gains when used for ICL.",
            "counter_examples_or_negative_results": "No reported cases where input+class-conditioned generation underperforms class-conditioned in their experiments; authors note overall gains depend on the underlying PLM's generation quality.",
            "uuid": "e3281.2",
            "source_info": {
                "paper_title": "Self-Generated In-Context Learning: Leveraging Auto-regressive Language Models as a Demonstration Generator",
                "publication_date_yy_mm": "2022-06"
            }
        },
        {
            "name_short": "Few-shot ICL (gold demonstrations)",
            "name_full": "Few-shot In-Context Learning using gold training demonstrations",
            "brief_description": "Standard in-context learning where k labeled examples (here up to 8) are sampled from a gold training set and concatenated with the test input for inference without parameter updates.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "GPT-J",
            "model_description": "Auto-regressive PLM used to perform few-shot ICL with k gold training examples; two inference templates were used (minimal and manual).",
            "model_size": "6B",
            "reasoning_methods": [
                "few-shot in-context learning with randomly selected gold demonstrations",
                "sampling/order sensitivity analyses (background)"
            ],
            "reasoning_methods_description": "k labeled training examples are concatenated (using an inference template) with the test input; prediction is made by scoring verbalizer tokens. In experiments, up to 8 gold examples were used; results averaged over 5 random seeds to capture variability.",
            "diversity_of_methods": "Method relies on the diversity/selection of the gold demonstrations; the paper treats randomly selected demonstrations as the typical few-shot approach and shows it has higher variance compared to SG-ICL-generated demonstrations.",
            "reasoning_task_name": "SST-2, SST-5, RTE, CB",
            "reasoning_task_description": "Same text classification tasks used for evaluation.",
            "performance_by_method": "Authors report that few-shot learning with up to 8 gold examples achieves competitive accuracies but higher variance; SG-ICL with 8 generated samples outperforms few-shot with up to 5 gold examples. Exact accuracy numbers are not provided in the main text.",
            "comparison_of_methods": "Few-shot ICL (with random gold example selection) shows larger performance variance and in the reported comparisons is outperformed by SG-ICL when SG-ICL uses 8 generated demos and few-shot uses &lt;=5 gold demos.",
            "key_findings": "Randomly sampled gold demonstrations can produce unstable performance; well-conditioned generated demonstrations can provide more stable and sometimes superior performance relative to a small number of gold examples.",
            "counter_examples_or_negative_results": "No precise numerical counterexamples where few-shot gold demonstrations outperform SG-ICL when using the same number of examples, but authors show few-shot with more than 5 gold examples may outperform SG-ICL with 8 generated samples (implied by the statement SG-ICL outperforms few-shot learning with up to 5 gold training samples).",
            "uuid": "e3281.3",
            "source_info": {
                "paper_title": "Self-Generated In-Context Learning: Leveraging Auto-regressive Language Models as a Demonstration Generator",
                "publication_date_yy_mm": "2022-06"
            }
        },
        {
            "name_short": "Zero-shot ICL",
            "name_full": "Zero-shot In-Context Learning (no demonstrations)",
            "brief_description": "Inference by prompting the PLM without any in-context demonstrations (k = 0).",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "GPT-J",
            "model_description": "Auto-regressive PLM performing zero-shot inference using the inference template and verbalizer tokens.",
            "model_size": "6B",
            "reasoning_methods": [
                "zero-shot prompting"
            ],
            "reasoning_methods_description": "Provide a task prompt and ask the model to produce an answer without any labeled examples; used as baseline for comparisons.",
            "diversity_of_methods": "Single style (no in-context demonstration); used as a baseline rather than a diversity strategy.",
            "reasoning_task_name": "SST-2, SST-5, RTE, CB",
            "reasoning_task_description": "Text classification tasks used as baselines for comparison with SG-ICL and few-shot ICL.",
            "performance_by_method": "Authors report SG-ICL significantly outperforms zero-shot across all four tasks. Exact accuracy values for zero-shot are not provided in main text.",
            "comparison_of_methods": "SG-ICL vs zero-shot: SG-ICL yields consistent and significant gains despite both having no access to training data, because SG-ICL creates generated demonstrations conditioned on input+class.",
            "key_findings": "Generating demonstrations from the model (SG-ICL) yields substantial gains over direct zero-shot prompting.",
            "counter_examples_or_negative_results": "No negative cases reported where zero-shot beats SG-ICL.",
            "uuid": "e3281.4",
            "source_info": {
                "paper_title": "Self-Generated In-Context Learning: Leveraging Auto-regressive Language Models as a Demonstration Generator",
                "publication_date_yy_mm": "2022-06"
            }
        },
        {
            "name_short": "GPT-3 (background mention)",
            "name_full": "Generative Pre-trained Transformer 3",
            "brief_description": "A prominent large auto-regressive language model introduced by Brown et al. (2020) and referenced in the paper as foundational work on few-shot in-context learning.",
            "citation_title": "Language models are few-shot learners",
            "mention_or_use": "mention",
            "model_name": "GPT-3",
            "model_description": "Large auto-regressive transformer introduced in Brown et al. (2020); established the paradigm of few-shot in-context learning. Mentioned in background/related work but not used in experiments.",
            "model_size": "various (e.g., up to 175B in original paper)",
            "reasoning_methods": [
                "few-shot in-context learning (original motivating work)"
            ],
            "reasoning_methods_description": "Described historically as the demonstration-based prompting approach where a few examples are provided to the model in-context to adapt behavior at inference time.",
            "diversity_of_methods": "Not experimentally analyzed in this paper; cited as prior work demonstrating ICL.",
            "reasoning_task_name": null,
            "reasoning_task_description": null,
            "performance_by_method": "",
            "comparison_of_methods": "",
            "key_findings": "Cited as establishing the few-shot ICL paradigm which this paper builds upon; no new experimental results in this paper.",
            "counter_examples_or_negative_results": "",
            "uuid": "e3281.5",
            "source_info": {
                "paper_title": "Self-Generated In-Context Learning: Leveraging Auto-regressive Language Models as a Demonstration Generator",
                "publication_date_yy_mm": "2022-06"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Language models are few-shot learners",
            "rating": 2
        },
        {
            "paper_title": "What makes good in-context examples for GPT-3?",
            "rating": 2
        },
        {
            "paper_title": "Learning to retrieve prompts for in-context learning",
            "rating": 2
        },
        {
            "paper_title": "Calibrate before use: Improving few-shot performance of language models",
            "rating": 1
        },
        {
            "paper_title": "Zerogen: Efficient zero-shot learning via dataset generation",
            "rating": 2
        }
    ],
    "cost": 0.012178499999999998,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>Self-Generated In-Context Learning: Leveraging Auto-regressive Language Models as a Demonstration Generator</h1>
<p>Hyuhng Joon Kim ${ }^{\dagger}$, Hyunsoo Cho ${ }^{\dagger}$, Junyeob Kim ${ }^{\dagger}$, Taeuk Kim ${ }^{\ddagger}$, Kang Min Yoo ${ }^{\dagger \S}$, Sang-goo Lee ${ }^{\dagger}$<br>${ }^{\dagger}$ Seoul National University, ${ }^{\ddagger}$ Hanyang University, ${ }^{\S}$ NAVER AI Lab, ${ }^{\text {N }}$ NAVER CLOVA<br>{heyjoonkim, johyunsoo, juny116, sglee}@europa.snu.ac.kr<br>kimtaeuk@hanyang.ac.kr<br>kangmin.yoo@navercorp.com</p>
<h4>Abstract</h4>
<p>Large-scale pre-trained language models (PLMs) are well-known for being capable of solving a task simply by conditioning a few input-label pairs dubbed demonstrations on a prompt without being explicitly tuned for the desired downstream task. Such a process (i.e., in-context learning), however, naturally leads to high reliance on the demonstrations which are usually selected from external datasets. In this paper, we propose self-generated incontext learning (SG-ICL), which generates demonstrations for in-context learning from PLM itself to minimize the reliance on the external demonstration. We conduct experiments on four different text classification tasks and show SG-ICL significantly outperforms zero-shot learning and is generally worth approximately 0.6 gold training samples. Moreover, our generated demonstrations show more consistent performance with low variance compared to randomly selected demonstrations from the training dataset.</p>
<h2>1 Introduction</h2>
<p>The scale of pre-trained language models (PLMs) is ever-growing as they tend to deliver more meaningful results with larger models and have reached the scale of hundreds of billions. However, transferring such large-scale PLMs with the traditional method i.e., fine-tuning, is problematic as it entails an immense cost to train and store parameters for an individual task. Numerous branches of work have been proposed to circumvent such issues, such as Adapters (Houlsby et al., 2019), LoRA (Hu et al., 2021), and in-context learning (ICL) (Brown et al., 2020).</p>
<p>Among others, ICL is in the limelight as it derives answers only from the internal knowledge of PLMs without any parameter updates. Specifically, ICL learns to solve a task simply by conditioning a few input-label pairs dubbed demonstrations on a prompt, which serves to give contexts regarding the
downstream task during the inference phase, allowing PLMs to solve the tasks better. The working principle of ICL intuitively leads to high reliance on the demonstrations, and performance deeply varies depending on the assortment of the demonstrations.</p>
<p>Many lines of work tackled the issue of ICL's high reliance on the demonstration. For instance, Lu et al. (2021) shown in-context learning suffers from the order sensitivity of the demonstrations. Zhao et al. (2021) introduces a contextual calibration procedure to reduce the variance across different choices of demonstrations. Rubin et al. (2021) suggests demonstration selection by retrieving incontext samples. Notably, Liu et al. (2022) showed that selecting a demonstration that has a high correlation with the test input can improve performance.</p>
<p>Motivated by previous research considering the limits of ICL's working process, we tried to solve the following research question:</p>
<ol>
<li>Can we eliminate the dependency on the training dataset by generating demonstrations?</li>
<li>If so, how can we create demonstrations with high input-demonstration correlation?</li>
</ol>
<p>To this end, we propose a novel method termed self-generated in-context learning (SGICL) which generates demonstrations by leveraging the superiority of PLMs generative abilities (Adiwardana et al., 2020; Brown et al., 2020; Shwartz et al., 2020; Ye et al., 2022). To the best of our knowledge, this is the first study to utilize PLMs to create demonstrations for ICL. SG-ICL consists of two operation steps: the self-generation step and the inference step. In the self-generation step, we generate demonstrations for each class in the downstream task by conditioning on the current test input and class information with a simple manually designed template. By giving conditions about the current input, PLM can generate demonstrations with a high input-demonstration correlation which is more befitted for ICL. Then, the inference step performs ICL with generated demonstrations</p>
<p><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Figure 1: Overall process of SG-ICL. Texts in yellow are manually designed prompts for generation and the texts in red are expected class for generated demonstration. Demonstrations (colored in blue) are generated in the self-generation step and are reused for in-context learning in the inference step. Texts in green are manually designed inference prompts.</p>
<p>From the previous step, which eliminates the requirement for training data or manual selection from training data.</p>
<p>We evaluate our method in four different natural language understanding (NLU) tasks, including sentiment classification and natural language inference. Through extensive experiments, we show that SG-ICL significantly outperforms zero-shot learning methods and is generally worth approximately 0.6 gold training samples. Moreover, our generated demonstrations show more stable performance with low variance compared to randomly selected demonstrations from training dataset.</p>
<h1>2 Method</h1>
<h2>2.1 Few-shot Learning</h2>
<p>Given a PLM <em>P</em>, our objective is to solve a classification task <em>D<sup>test</sup></em> = (<em>X<sup>test</sup></em>, <em>Y<sup>test</sup></em>). A natural language template <em>T</em>(·) is provided, containing additional information about the downstream task. A limited number of training data <em>D<sup>train</sup></em> = (<em>X<sup>train</sup></em>, <em>Y<sup>train</sup></em>) is available as demonstration. Inference input is generated by concatenating <em>k</em> training samples and the test input with the template. Additionally, we define a verbalzier <em>V</em>(·) <em>Schick and Schütze (2020)</em> which maps each class <em>y<sub>i</sub></em> ∈ <em>Y</em> to a pre-defined token. The final prediction is made by selecting the class with the highest probability for the mapped token:</p>
<p>$$
p(y_i \mid x_i^{test}) = P(V(y_i)) \mid T(x_{1}^{train}, y_{1}^{train}), \tag{1}
$$</p>
<p>Zero-shot learning is a special case of few-shot learning where the number of training data <em>k</em> = 0.</p>
<h2>2.2 Self-generated In-context Learning</h2>
<p>SG-ICL can be divided into two steps: the self-generation step and the inference step. In the first step, we generate demonstrations conditioned on the test input and a specific class. This way we can generate demonstrations highly correlated with the test input. Details about the generation methods will be further discussed in Section 3.3. In the second step, we use the self-generated samples as a demonstration for in-context learning. The overall process of SG-ICL is visualized in Figure 1.</p>
<h3>Self-generation Step</h3>
<p>In the self-generation step, we generate in-context sample <em>s<sub>i</sub></em>. Specifically, generation template <em>G</em>(·) is defined, which takes the test instance <em>x<sub>i</sub><sup>test</sup></em> ∈ <em>X<sup>test</sup></em> and a class token <em>V</em>(<em>y<sub>i</sub></em>) as an input. The PLM <em>P</em> takes the generation input <em>G</em>(<em>x<sub>i</sub><sup>test</sup></em>, <em>V</em>(<em>y<sub>i</sub></em>)) and generates in-context sample <em>s<sub>i</sub></em>.</p>
<p>For single-sentence tasks (e.g., SST-2 and SST-5), the generation input can be defined as <em>G</em>(<em>x<sub>i</sub><sup>test</sup></em>, <em>V</em>(<em>y<sub>i</sub></em>)). The generated in-context sample <em>x<sub>i</sub><sup>gen</sup></em> would be pairs of (<em>s<sub>i</sub></em>, <em>y<sub>i</sub></em>). In sentence-pair tasks (e.g., RTE and CB) consisting of sentence-pair inputs <em>x<sub>i,1</sub></em>, <em>x<sub>i,2</sub></em>, the generation input can be</p>
<p><img alt="img-1.jpeg" src="img-1.jpeg" />Figure 2: Main results of our experiments. Figure 2a and Figure 2b compares SG-ICL with zero/few-shot learning. Two settings are exactly the same except the inference template. SG-ICL outperforms zero-shot learning consistently. Notice that SG-ICL has significantly low variance compared to few-shot learning.</p>
<p>defined as $G(x_{i,1},x_{i,2},V(y_{i}))$. In this case, generated in-context sample $x_{i}^{gen}$ would be a set of $(x_{i,1},s_{i},y_{i})$.</p>
<p>Inference Step In the inference step, we use the generated samples as the demonstration for in-context learning. In detail, we take each generated samples $x_{i}^{gen}$ and convert them using the inference template $T(\cdot)$. The inference input is generated by concatenating all $k$ generated samples and the test instance. The prediction is made in the same way as few-shot learning :</p>
<p>$p(y_{i} \mid x_{i}^{\text {test }})=P\left(V\left(y_{i}\right)\right) \mid T\left(x_{1}^{g e n}, y_{1}^{g e n}\right),$
$\ldots, T\left(x_{k}^{g e n}, y_{k}^{g e n}\right), T\left(x_{i}^{\text {test }}\right))$</p>
<h2>3 Experiments</h2>
<h3>3.1 Experimental Setup</h3>
<p>Datasets and Metrics We report results on four text classification datasets : sentiment classification with SST-2 <em>Socher et al. (2013)</em> and SST-5 <em>Socher et al. (2013)</em>, natural language inference with CB <em>De Marneffe et al. (2019)</em> and RTE <em>Dagan et al. (2005)</em>. We report accuracy for all tasks. All reported results are averaged over 5 different random seeds. See Table 2 in Appendix A for details about the datasets.</p>
<p>Baselines We compare SG-ICL with zero-shot learning and few-shot learning with 8 in-context samples. 2 different inference templates were used: minimal and manual. For inference templates and verbalizers, see Table 3 in Appendix B.</p>
<p>Models The main experiments were done with GPT-J (6B) <em>Wang (2021)</em>, one of the largest publicly available auto-regressive models. We used the implementation and the pre-trained weights from Huggingface Transformers library <em>Wolf et al. (2019)</em>.</p>
<p>Generation Settings For each test input $x_{i}^{\text {test }}$, we self-generate 8 in-context samples. We use temperature sampling for generation <em>Hinton et al. (2015)</em> with temperature $T=0.5$. Details of generation templates are available in Table 4 in Appendix B.</p>
<h3>3.2 Main results</h3>
<p>Figure 2 is our main experimental results with the settings stipulated above. We compare SG-ICL with zero/few-shot learning with the same number of in-context samples. We observed that SG-ICL performs significantly better than zero-shot learning, consistent across all four text classification tasks. This result is significant since both zero-shot learning and SG-ICL does not have any access to training data, but SG-ICL was able to gain improvements by using self-generated in-context samples.</p>
<p>Additionally, we can observe that the performance with SG-ICL is stable with very low variance. As in-context learning is highly dependent on the choice of the demonstration, its performance fluctuations are not negligible. SG-ICL alleviates this downside by generating an input conditioned sample highly correlated with the input instance and provides stable performance.</p>
<h3>3.3 Why condition on the input?</h3>
<p>In this section, we show the effect of conditioning on the input instance during the generation process. To do so, we conduct a simple experiment comparing two types of generation methods: (1) conditioning only on the class and (2) conditioning on both the class and the input instances. Previous work <em>Liu et al. (2022)</em> has shown that in-context samples semantically-similar to the input instance are more likely to serve as a better in-context sample, improving performance. Based on previous research, we conduct an experiment to see whether</p>
<table>
<thead>
<tr>
<th>Method</th>
<th>SST-2</th>
<th>SST-5</th>
</tr>
</thead>
<tbody>
<tr>
<td>class conditioned</td>
<td>0.0689</td>
<td>0.0735</td>
</tr>
<tr>
<td>input-class conditioned</td>
<td>0.3051</td>
<td>0.3098</td>
</tr>
</tbody>
</table>
<p>Table 1: Cosine similarity of the input instance and the generated demonstration. Inputs with similar sentence embedding have higher cosine similarity. Generating samples conditioned on both the input and the class shows higher cosine similarity.
<img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>Figure 3: Results comparing two different generation methods alongside zero/few-shot in-context learning. Generating samples conditioned additionally on the input instance provides more performance gain.
conditioning on the input instance has a significant impact on the performance gain. We first calculate the correlation between the generated sample and the input instance. We use the sentence embedding from Reimers and Gurevych (2019) and calculate the cosine similarity between the two instance. Table 1 shows the results on SST-2 and SST-5. We can observe that samples generated conditioned on the input instance shows a higher correlation with the input instance.</p>
<p>To verify the correlation between the similarity and the downstream task performance, we report the downstream task performance of the two generation methods. The results are shown in Figure 3. Regardless of the generation method, making use of the generated demonstrations provides performance gain. Additionally, we can observe incontext samples conditioned additionally on input instance performs better, aligning with the results in Table 1.</p>
<h3>3.4 How many in-context samples does self-generation worth?</h3>
<p>We first analyze the significance of self-generated in-context samples in SG-ICL. To do so, we show few-shot learning performances with a varying number of in-context samples from 1 to 8 and compare it with SG-ICL. Figure 4 shows the results
<img alt="img-3.jpeg" src="img-3.jpeg" /></p>
<p>Figure 4: Results comparing few-shot learning with various sample sizes with SG-ICL. SG-ICL outperforms few-shot learning with up to 5 in-context samples.
on two tasks: SST-2, SST-5. The results show that using 8 self-generated in-context samples can outperform few-shot learning with at most 5 gold training samples consistently. Experiments show one self-generated in-context sample worth about 0.6 gold training sample.</p>
<h2>4 Conclusion \&amp; Future Work</h2>
<p>In this paper, we propose self-generated in-context learning (SG-ICL), generating in-context samples and reusing them as demonstrations. We were able to generate quality demonstrations, eliminating the need for training data during in-context learning. Our experiments on four text classification datasets show that SG-ICL can provide significant improvements in performance without the use of any training data. Moreover, SG-ICL show more stable performance with low variance compared to randomly selected demonstrations from training dataset.</p>
<p>As the quality of the generated samples is highly dependent on the generation abilities of the PLM, applying SG-ICL to larger PLMs would likely show significant improvements and is left as future work. Despite the positive results in natural language understanding tasks, applying SG-ICL to other tasks is not fully explored. Future work could</p>
<p>include applying SG-ICL in various task domains.</p>
<h2>Acknowledgements</h2>
<p>This work was supported by SNU-Naver Hyperscale AI Center.</p>
<h2>References</h2>
<p>Daniel Adiwardana, Minh-Thang Luong, David R So, Jamie Hall, Noah Fiedel, Romal Thoppilan, Zi Yang, Apoorv Kulshreshtha, Gaurav Nemade, Yifeng Lu, et al. 2020. Towards a human-like open-domain chatbot. arXiv preprint arXiv:2001.09977.</p>
<p>Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. 2020. Language models are few-shot learners. Advances in neural information processing systems, 33:1877-1901.</p>
<p>Ido Dagan, Oren Glickman, and Bernardo Magnini. 2005. The pascal recognising textual entailment challenge. In Machine Learning Challenges Workshop, pages 177-190. Springer.</p>
<p>Marie-Catherine De Marneffe, Mandy Simons, and Judith Tonhauser. 2019. The commitmentbank: Investigating projection in naturally occurring discourse. In proceedings of Sinn und Bedeutung, volume 23, pages 107-124.</p>
<p>Geoffrey Hinton, Oriol Vinyals, Jeff Dean, et al. 2015. Distilling the knowledge in a neural network. arXiv preprint arXiv:1503.02531, 2(7).</p>
<p>Neil Houlsby, Andrei Giurgiu, Stanislaw Jastrzebski, Bruna Morrone, Quentin de Laroussilhe, Andrea Gesmundo, Mona Attariyan, and Sylvain Gelly. 2019. Parameter-efficient transfer learning for nlp. In ICML.</p>
<p>Edward Hu, Yelong Shen, Phil Wallis, Zeyuan AllenZhu, Yuanzhi Li, Lu Wang, and Weizhu Chen. 2021. Lora: Low-rank adaptation of large language models.</p>
<p>Jiachang Liu, Dinghan Shen, Yizhe Zhang, Bill Dolan, Lawrence Carin, and Weizhu Chen. 2022. What makes good in-context examples for GPT-3? In Proceedings of Deep Learning Inside Out (DeeLIO 2022): The 3rd Workshop on Knowledge Extraction and Integration for Deep Learning Architectures, pages 100-114, Dublin, Ireland and Online. Association for Computational Linguistics.</p>
<p>Yao Lu, Max Bartolo, Alastair Moore, Sebastian Riedel, and Pontus Stenetorp. 2021. Fantastically ordered prompts and where to find them: Overcoming few-shot prompt order sensitivity. arXiv preprint arXiv:2104.08786.</p>
<p>Nils Reimers and Iryna Gurevych. 2019. Sentencebert: Sentence embeddings using siamese bertnetworks. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics.</p>
<p>Ohad Rubin, Jonathan Herzig, and Jonathan Berant. 2021. Learning to retrieve prompts for in-context learning. arXiv preprint arXiv:2112.08633.</p>
<p>Timo Schick and Hinrich Schütze. 2020. Exploiting cloze questions for few shot text classification and natural language inference. arXiv preprint arXiv:2001.07676.</p>
<p>Vered Shwartz, Peter West, Ronan Le Bras, Chandra Bhagavatula, and Yejin Choi. 2020. Unsupervised commonsense question answering with self-talk. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 4615-4629, Online. Association for Computational Linguistics.</p>
<p>Richard Socher, Alex Perelygin, Jean Wu, Jason Chuang, Christopher D Manning, Andrew Y Ng, and Christopher Potts. 2013. Recursive deep models for semantic compositionality over a sentiment treebank. In Proceedings of the 2013 conference on empirical methods in natural language processing, pages $1631-1642$.</p>
<p>Ben Wang. 2021. Mesh-Transformer-JAX: ModelParallel Implementation of Transformer Language Model with JAX. https://github.com/ kingoflolz/mesh-transformer-jax.</p>
<p>Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, Rémi Louf, Morgan Funtowicz, et al. 2019. Huggingface's transformers: State-of-the-art natural language processing. arXiv preprint arXiv:1910.03771.</p>
<p>Jiacheng Ye, Jiahui Gao, Qintong Li, Hang Xu, Jiangtao Feng, Zhiyong Wu, Tao Yu, and Lingpeng Kong. 2022. Zerogen: Efficient zero-shot learning via dataset generation. arXiv preprint arXiv:2202.07922.</p>
<p>Zihao Zhao, Eric Wallace, Shi Feng, Dan Klein, and Sameer Singh. 2021. Calibrate before use: Improving few-shot performance of language models. In International Conference on Machine Learning, pages 12697-12706. PMLR.</p>
<h2>A Dataset Details</h2>
<p>Table 2 shows detailed statistics of the datasets used in the main experiment.</p>
<h2>B Templates for Generation and Inference</h2>
<p>Table 4 and Table 3 shows details of the prompts and verbalizers used for inference and generation, respectively.</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Dataset</th>
<th style="text-align: center;"># of Train Set</th>
<th style="text-align: center;"># of Validation Set</th>
<th style="text-align: center;"># of Classes</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">SST-2</td>
<td style="text-align: center;">67,349</td>
<td style="text-align: center;">872</td>
<td style="text-align: center;">2</td>
</tr>
<tr>
<td style="text-align: center;">SST-5</td>
<td style="text-align: center;">8,544</td>
<td style="text-align: center;">2,210</td>
<td style="text-align: center;">5</td>
</tr>
<tr>
<td style="text-align: center;">RTE</td>
<td style="text-align: center;">2,490</td>
<td style="text-align: center;">277</td>
<td style="text-align: center;">2</td>
</tr>
<tr>
<td style="text-align: center;">CB</td>
<td style="text-align: center;">250</td>
<td style="text-align: center;">57</td>
<td style="text-align: center;">3</td>
</tr>
</tbody>
</table>
<p>Table 2: Datasets used for experiments.</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Task</th>
<th style="text-align: center;">Inference Template</th>
<th style="text-align: center;">Verbalizer</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">Minimal</td>
<td style="text-align: center;">a fast, funny, highly enjoyable movie . <br> positive</td>
<td style="text-align: center;">-</td>
</tr>
<tr>
<td style="text-align: center;">SST-2</td>
<td style="text-align: center;">Review : a fast, funny, highly enjoyable movie . <br> Sentiment : positive</td>
<td style="text-align: center;">positive / negative</td>
</tr>
<tr>
<td style="text-align: center;">SST-5</td>
<td style="text-align: center;">Review : it 's worth taking the kids to . <br> Sentiment : great</td>
<td style="text-align: center;">terrible / bad/ okay/ good / great</td>
</tr>
<tr>
<td style="text-align: center;">RTE</td>
<td style="text-align: center;">Premise : Dana Reeve, the widow of the actor Christopher Reeve, has died of lung cancer at age 44, according to the Christopher Reeve Foundation. <br> Hypothesis : Christopher Reeve had an accident. <br> True or False? false</td>
<td style="text-align: center;">true / false</td>
</tr>
<tr>
<td style="text-align: center;">CB</td>
<td style="text-align: center;">Premise : It was a complex language. Not written down but handed down. One might say it was peeled down. <br> Hypothesis : the language was peeled down <br> Yes, No, or Neither? yes</td>
<td style="text-align: center;">yes / no / neither</td>
</tr>
</tbody>
</table>
<p>Table 3: Templates and verbalizers for inference. Texts in red are manually designed prompts and texts in blue are expected output for prediction. The rightmost column shows tokens mapped with each class.</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Task</th>
<th style="text-align: center;">Generation Template</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">SST-2</td>
<td style="text-align: center;">Generate a review : a fast, funny, highly enjoyable movie . <br> Generate a "negative" review :</td>
</tr>
<tr>
<td style="text-align: center;">SST-5</td>
<td style="text-align: center;">Generate a review : it 's worth taking the kids to . <br> Generate a "negative" review :</td>
</tr>
<tr>
<td style="text-align: center;">RTE</td>
<td style="text-align: center;">Premise : Dana Reeve, the widow of the actor Christopher Reeve, has died of lung cancer at age 44, according to the Christopher Reeve Foundation. <br> Generate a Hypothesis : Christopher Reeve had an accident. <br> Generate a "true" Hypothesis :</td>
</tr>
<tr>
<td style="text-align: center;">CB</td>
<td style="text-align: center;">Premise : It was a complex language. Not written down but handed down. One might say it was peeled down. <br> Generate a Hypothesis : the language was peeled down <br> Generate a "neither" Hypothesis :</td>
</tr>
</tbody>
</table>
<p>Table 4: Templates for self-generating in-context samples. Texts in red are manually designed prompts for generation and texts in blue are tokens representing the expected class.</p>            </div>
        </div>

    </div>
</body>
</html>