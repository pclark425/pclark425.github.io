<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-415 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-415</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-415</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-16.html">extraction-schema-16</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of experimental methods, techniques, or procedures being transferred, adapted, or applied from one scientific domain or context to another scientific domain or context, including details about the transfer process and outcomes.</div>
                <p><strong>Paper ID:</strong> paper-254854366</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2212.08744v3.pdf" target="_blank">Toward cross-subject and cross-session generalization in EEG-based emotion recognition: Systematic review, taxonomy, and methods</a></p>
                <p><strong>Paper Abstract:</strong> A systematic review on machine-learning strategies for improving generalizability (cross-subjects and cross-sessions) electroencephalography (EEG) based in emotion classification was realized. In this context, the non-stationarity of EEG signals is a critical issue and can lead to the Dataset Shift problem. Several architectures and methods have been proposed to address this issue, mainly based on transfer learning methods. 418 papers were retrieved from the Scopus, IEEE Xplore and PubMed databases through a search query focusing on modern machine learning techniques for generalization in EEG-based emotion assessment. Among these papers, 75 were found eligible based on their relevance to the problem. Studies lacking a specific cross-subject and cross-session validation strategy and making use of other biosignals as support were excluded. On the basis of the selected papers' analysis, a taxonomy of the studies employing Machine Learning (ML) methods was proposed, together with a brief discussion on the different ML approaches involved. The studies with the best results in terms of average classification accuracy were identified, supporting that transfer learning methods seem to perform better than other approaches. A discussion is proposed on the impact of (i) the emotion theoretical models and (ii) psychological screening of the experimental sample on the classifier performances.</p>
                <p><strong>Cost:</strong> 0.024</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e415.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e415.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of experimental methods, techniques, or procedures being transferred, adapted, or applied from one scientific domain or context to another scientific domain or context, including details about the transfer process and outcomes.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Image-DA -> EEG adaptation</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Adaptation of domain-adaptation strategies originally developed for image classification to EEG-based emotion recognition</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>General practice of taking DA methods (MMD-based, adversarial, subspace alignment, etc.) developed for image tasks and adapting them to EEG emotion classification by changing input representations and loss terms to account for EEG nonstationarity and electrode topology.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Graph neural networks: A review of methods and applications.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_name</strong></td>
                            <td>Domain adaptation strategies from image classification</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_description</strong></td>
                            <td>A family of methods that reduce distributional discrepancy between a labelled source dataset and an (unlabelled or partially labelled) target dataset by learning mappings or feature representations that align marginal/conditional distributions (e.g., MMD minimization, adversarial domain discriminators, subspace alignment, transfer component analysis). In images these operate on pixel/feature tensors; when moved to EEG they are applied to EEG-derived features (PSD, spectrograms, time-frequency maps) or graph/electrode-structured inputs.</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_type</strong></td>
                            <td>computational method / transfer learning technique</td>
                        </tr>
                        <tr>
                            <td><strong>source_domain</strong></td>
                            <td>computer vision / image classification</td>
                        </tr>
                        <tr>
                            <td><strong>target_domain</strong></td>
                            <td>EEG-based affective neuroscience / emotion recognition</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_type</strong></td>
                            <td>adapted/modified for new context</td>
                        </tr>
                        <tr>
                            <td><strong>modifications_made</strong></td>
                            <td>Input representations were changed from images to EEG-specific formats (spectrograms, EFDMs, electrode graphs, covariance matrices); discrepancy measures were applied on EEG feature spaces (PSD, time-frequency embeddings); architectures were modified to respect electrode topology (GNNs) or hemispheric separation; often small amounts of labelled target data or target-unlabelled data were used (semi/unsupervised DA).</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_success</strong></td>
                            <td>partially successful - widely adopted in reviewed literature and often improves cross-subject/session accuracy versus classical ML baselines, but success varies by dataset and method (examples: several deep-DA (CSS) studies report top performances; see Du et al. (2020) with SEED 3-class accuracy 90.92% ± 1.05, Ning et al. (2021) reported 97.66% ± 14.46 on SEED in a deep DA setting).</td>
                        </tr>
                        <tr>
                            <td><strong>barriers_encountered</strong></td>
                            <td>EEG non-stationarity, different data dimensionality and temporal dynamics than images, need to preserve spatial electrode relationships, small number of labelled target samples, variability in acquisition devices and stimuli.</td>
                        </tr>
                        <tr>
                            <td><strong>facilitating_factors</strong></td>
                            <td>Shared ML formalism (feature learning, adversarial losses, MMD) allows reuse of core algorithms; ability to convert EEG to image-like or structured representations; availability of public EEG datasets for benchmarking.</td>
                        </tr>
                        <tr>
                            <td><strong>contextual_requirements</strong></td>
                            <td>EEG-specific preprocessing (line noise removal, referencing, artifact removal), conversion to suitable input formats (spectrograms, EFDMs, graphs), often GPU compute for deep models, careful cross-subject validation (LOSO).</td>
                        </tr>
                        <tr>
                            <td><strong>generalizability</strong></td>
                            <td>Moderately generalizable across EEG emotion tasks when representation adjustments are made; methods can be applied to other biosignal domains (ECG, EDA) with analogous representation changes, but direct transfer without adaptation is usually ineffective.</td>
                        </tr>
                        <tr>
                            <td><strong>knowledge_type</strong></td>
                            <td>explicit procedural steps, theoretical principles</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Toward cross-subject and cross-session generalization in EEG-based emotion recognition: Systematic review, taxonomy, and methods', 'publication_date_yy_mm': '2022-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e415.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e415.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of experimental methods, techniques, or procedures being transferred, adapted, or applied from one scientific domain or context to another scientific domain or context, including details about the transfer process and outcomes.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>DANN</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Domain Adversarial Neural Network (DANN)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A deep adversarial domain-adaptation architecture that jointly optimizes a feature extractor for label prediction while making domain discrimination (source vs target) difficult, promoting domain-invariant features.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>EEG-based emotion recognition using domain adaptation network.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_name</strong></td>
                            <td>Domain Adversarial Neural Network (DANN)</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_description</strong></td>
                            <td>Neural network composed of a feature extractor, a label predictor, and a domain classifier; a gradient reversal layer or adversarial loss trains the feature extractor to maximize label accuracy while maximizing domain-classifier loss, reducing distributional differences between source and target in feature space.</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_type</strong></td>
                            <td>computational method / deep transfer learning</td>
                        </tr>
                        <tr>
                            <td><strong>source_domain</strong></td>
                            <td>machine learning / general domain adaptation (initially applied in vision and NLP)</td>
                        </tr>
                        <tr>
                            <td><strong>target_domain</strong></td>
                            <td>EEG-based emotion recognition</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_type</strong></td>
                            <td>adapted/modified for new context</td>
                        </tr>
                        <tr>
                            <td><strong>modifications_made</strong></td>
                            <td>Applied to EEG inputs by changing input layers to accept EEG-derived representations (time-series, spectrograms, electrode graphs), adding hemisphere-specific branches (BiDANN) or multiple feature streams (e.g., separate encoders for left/right hemispheres), and integrating attention or graph modules to respect electrode spatial layout.</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_success</strong></td>
                            <td>successful in multiple EEG emotion studies — e.g., Jin et al. (2017) evaluated DANN on SEED, and many later EEG studies report improved cross-subject performance when using DANN variants; deep adversarial approaches form a dominant class among high-performing cross-subject methods in the review.</td>
                        </tr>
                        <tr>
                            <td><strong>barriers_encountered</strong></td>
                            <td>Potential 'over-alignment' where class-discriminative structure is lost if domain alignment ignores labels; needs careful balancing of adversarial and classification losses, and EEG-specific pretraining/representation choices.</td>
                        </tr>
                        <tr>
                            <td><strong>facilitating_factors</strong></td>
                            <td>Adversarial framework directly addresses dataset-shift, availability of unlabelled target data, modular network design allows EEG-specific encoder modules.</td>
                        </tr>
                        <tr>
                            <td><strong>contextual_requirements</strong></td>
                            <td>EEG preprocessing and feature extraction, careful hyperparameter tuning (adversarial weight), sometimes small labelled target set for validation, compute resources for deep training.</td>
                        </tr>
                        <tr>
                            <td><strong>generalizability</strong></td>
                            <td>High within EEG emotion tasks when modified to include electrode/temporal priors; conceptually applicable to other biosignals with analogous encoder changes.</td>
                        </tr>
                        <tr>
                            <td><strong>knowledge_type</strong></td>
                            <td>explicit procedural steps, theoretical principles</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Toward cross-subject and cross-session generalization in EEG-based emotion recognition: Systematic review, taxonomy, and methods', 'publication_date_yy_mm': '2022-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e415.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e415.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of experimental methods, techniques, or procedures being transferred, adapted, or applied from one scientific domain or context to another scientific domain or context, including details about the transfer process and outcomes.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ADDA / WGANDA</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Adversarial Discriminative Domain Adaptation (ADDA) / Wasserstein GAN Domain Adaptation (WGANDA) adapted for EEG</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Two-stage adversarial approaches that learn separate encoders for source and target and adversarially align their feature distributions; WGANDA uses Wasserstein loss for stable distribution matching and was adapted to EEG.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Wgan domain adaptation for eeg-based emotion recognition.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_name</strong></td>
                            <td>ADDA / WGANDA</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_description</strong></td>
                            <td>ADDA: train a source encoder+classifier on labelled source data, then adversarially train a target encoder to map target data into the source encoder feature space so the source classifier can be used. WGANDA: uses Wasserstein distance and GAN-based adversarial training between source and target feature generators to minimize distributional differences more stably.</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_type</strong></td>
                            <td>computational method / adversarial domain adaptation</td>
                        </tr>
                        <tr>
                            <td><strong>source_domain</strong></td>
                            <td>computer vision / domain adaptation (ADDA originally for images)</td>
                        </tr>
                        <tr>
                            <td><strong>target_domain</strong></td>
                            <td>EEG-based emotion recognition</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_type</strong></td>
                            <td>adapted/modified for new context</td>
                        </tr>
                        <tr>
                            <td><strong>modifications_made</strong></td>
                            <td>EEG-specific generators/encoders were designed to take EEG feature vectors or spectrograms; pretraining steps included EEG feature preprocessing; Wasserstein/GAN losses tuned for EEG feature statistics; outputs fed to emotion classifiers.</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_success</strong></td>
                            <td>reported as successful in EEG studies: Luo et al. (2018) adapted ADDA into WGANDA for EEG and reported improved alignment enabling cross-subject classification; compared favorably to some baselines in the review (no single universal metric reported).</td>
                        </tr>
                        <tr>
                            <td><strong>barriers_encountered</strong></td>
                            <td>GAN training instability on EEG features, limited labelled target samples for validation, need to preserve task-discriminative structure during adversarial alignment.</td>
                        </tr>
                        <tr>
                            <td><strong>facilitating_factors</strong></td>
                            <td>Wasserstein metric provides more stable adversarial objective; pretraining on source stabilizes later adversarial tuning; modular two-stage approach separates source learning from target adaptation.</td>
                        </tr>
                        <tr>
                            <td><strong>contextual_requirements</strong></td>
                            <td>Robust EEG preprocessing, selection of stable EEG feature embeddings (e.g., EFDMs, spectrograms), careful GAN hyperparameter tuning and regularization.</td>
                        </tr>
                        <tr>
                            <td><strong>generalizability</strong></td>
                            <td>Applicable to many EEG cross-subject problems but training stability and representation choice are critical; the two-stage adversarial concept generalizes to other biosignal domains.</td>
                        </tr>
                        <tr>
                            <td><strong>knowledge_type</strong></td>
                            <td>explicit procedural steps, instrumental/technical skills</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Toward cross-subject and cross-session generalization in EEG-based emotion recognition: Systematic review, taxonomy, and methods', 'publication_date_yy_mm': '2022-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e415.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e415.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of experimental methods, techniques, or procedures being transferred, adapted, or applied from one scientific domain or context to another scientific domain or context, including details about the transfer process and outcomes.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>TCA</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Transfer Component Analysis (TCA)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An MMD-based approach that learns a subspace where marginal distributions of source and target are close while preserving data variance, used in unsupervised and supervised variants.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Transfer components between subjects for eeg-based emotion recognition.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_name</strong></td>
                            <td>Transfer Component Analysis (TCA)</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_description</strong></td>
                            <td>TCA finds a linear (kernelized) projection to a lower-dimensional subspace that simultaneously maximizes variance and minimizes Maximum Mean Discrepancy (MMD) between source and target distributions, enabling simpler classifiers to work on aligned features.</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_type</strong></td>
                            <td>computational method / shallow domain adaptation</td>
                        </tr>
                        <tr>
                            <td><strong>source_domain</strong></td>
                            <td>machine learning / general domain adaptation (original image/text tasks)</td>
                        </tr>
                        <tr>
                            <td><strong>target_domain</strong></td>
                            <td>EEG emotion recognition</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_type</strong></td>
                            <td>adapted/modified for new context</td>
                        </tr>
                        <tr>
                            <td><strong>modifications_made</strong></td>
                            <td>Applied to EEG by selecting EEG-specific features (PSD, DE, time-frequency embeddings) as inputs to TCA; kernel and projected dimensionality tuned for EEG datasets; sometimes combined with instance selection (sub-sampling sources).</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_success</strong></td>
                            <td>used successfully in EEG studies (Zheng et al. (2015) evaluated unsupervised TCA on SEED with LOSO validation), often improving over raw-feature baselines though results depend on feature choice and subspace dimensionality.</td>
                        </tr>
                        <tr>
                            <td><strong>barriers_encountered</strong></td>
                            <td>Choice of kernel and target dimensionality critical; TCA assumes a shared feature space and may be limited when conditional distributions differ substantially across subjects/sessions.</td>
                        </tr>
                        <tr>
                            <td><strong>facilitating_factors</strong></td>
                            <td>MMD provides a principled discrepancy measure; EEG features with stable statistics across subjects (e.g., log-PSD) facilitate alignment.</td>
                        </tr>
                        <tr>
                            <td><strong>contextual_requirements</strong></td>
                            <td>Careful EEG feature extraction and normalization, cross-validation to choose subspace dimension, compute for kernel PCA/TCA steps.</td>
                        </tr>
                        <tr>
                            <td><strong>generalizability</strong></td>
                            <td>Well-suited to EEG and other biosignals where feature vectors can be defined; limited when feature distributions have complex conditional shifts.</td>
                        </tr>
                        <tr>
                            <td><strong>knowledge_type</strong></td>
                            <td>explicit procedural steps, theoretical principles</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Toward cross-subject and cross-session generalization in EEG-based emotion recognition: Systematic review, taxonomy, and methods', 'publication_date_yy_mm': '2022-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e415.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e415.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of experimental methods, techniques, or procedures being transferred, adapted, or applied from one scientific domain or context to another scientific domain or context, including details about the transfer process and outcomes.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Pretrained-vision CNNs on EEG</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Use of pretrained convolutional neural networks (InceptionResNetV2, DenseNet121) trained on images, applied to EEG via image-like representations</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Applying off-the-shelf image CNNs pre-trained on large image corpora to EEG emotion tasks by converting EEG signals into 2D image representations (spectrograms, EFDMs) and fine-tuning classifiers.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Investigating the use of pretrained convolutional neural network on cross-subject and cross-dataset eeg emotion recognition.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_name</strong></td>
                            <td>Pretrained convolutional neural networks (transfer from computer vision)</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_description</strong></td>
                            <td>Transform EEG epochs into 2D representations (time-frequency spectrograms, electrode-frequency maps) which are then input to standard CNN architectures pre-trained on ImageNet; the CNN feature extractor is fine-tuned on EEG emotion labels or used as frozen feature extractor with a new classifier head.</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_type</strong></td>
                            <td>computational method / supervised transfer learning</td>
                        </tr>
                        <tr>
                            <td><strong>source_domain</strong></td>
                            <td>computer vision / image recognition</td>
                        </tr>
                        <tr>
                            <td><strong>target_domain</strong></td>
                            <td>EEG-based emotion recognition</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_type</strong></td>
                            <td>adapted/modified for new context</td>
                        </tr>
                        <tr>
                            <td><strong>modifications_made</strong></td>
                            <td>EEG signals converted to images (spectrograms, EFDMs); input channels and normalization adjusted to match CNN expected input; final layers replaced or fine-tuned; sometimes augmented with EEG-specific preprocessing like stratified normalization.</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_success</strong></td>
                            <td>reported as effective in cross-subject and cross-dataset evaluations (e.g., Cimtay & Ekmekcioglu (2020) and Pusarla et al. (2022) used InceptionResNetV2/DenseNet121 variants with improved subject-transfer performance compared with some baselines), though performance depends on the quality of the EEG-to-image mapping.</td>
                        </tr>
                        <tr>
                            <td><strong>barriers_encountered</strong></td>
                            <td>Mismatch between statistical properties of natural images and EEG-derived images; need for careful normalization and channel encoding; risk of overfitting due to limited labelled EEG data.</td>
                        </tr>
                        <tr>
                            <td><strong>facilitating_factors</strong></td>
                            <td>Large pre-trained weights provide robust low-level feature extractors; converting EEG into image-like inputs makes methods plug-and-play.</td>
                        </tr>
                        <tr>
                            <td><strong>contextual_requirements</strong></td>
                            <td>High-quality EEG-to-image transforms, GPU compute for fine-tuning, cross-subject validation protocols.</td>
                        </tr>
                        <tr>
                            <td><strong>generalizability</strong></td>
                            <td>Applicable to other time-series biosignals when informative image-like transforms exist (e.g., spectrograms of ECG/EOG), but effectiveness depends on representational fidelity.</td>
                        </tr>
                        <tr>
                            <td><strong>knowledge_type</strong></td>
                            <td>instrumental/technical skills, explicit procedural steps</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Toward cross-subject and cross-session generalization in EEG-based emotion recognition: Systematic review, taxonomy, and methods', 'publication_date_yy_mm': '2022-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e415.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e415.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of experimental methods, techniques, or procedures being transferred, adapted, or applied from one scientific domain or context to another scientific domain or context, including details about the transfer process and outcomes.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GNN + DA</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Graph Neural Networks combined with domain adaptation for EEG</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Use of graph neural network architectures to model electrode spatial relations, combined with adversarial or discrepancy-based domain adaptation to improve subject-independent EEG emotion recognition.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Cross-subject eeg-based emotion recognition using adversarial domain adaption with attention mechanism.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_name</strong></td>
                            <td>Graph neural networks with domain adaptation</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_description</strong></td>
                            <td>Construct a graph whose nodes correspond to EEG electrodes (or learned nodes), process signals with GNN layers (graph convolutions or attention) to capture spatial dependencies, and apply domain-adversarial training (node-wise discriminators or global domain classifiers) or MMD penalties to align source and target graph feature distributions.</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_type</strong></td>
                            <td>computational method / deep learning + domain adaptation</td>
                        </tr>
                        <tr>
                            <td><strong>source_domain</strong></td>
                            <td>graph machine learning / network science (often used in social networks, chemistry, vision)</td>
                        </tr>
                        <tr>
                            <td><strong>target_domain</strong></td>
                            <td>EEG emotion recognition</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_type</strong></td>
                            <td>adapted/modified for new context</td>
                        </tr>
                        <tr>
                            <td><strong>modifications_made</strong></td>
                            <td>Define electrode adjacency either by physical scalp layout or learn it from data (self-organized graphs); employ node-wise domain discriminators (NodeDAT) or attention to focus alignment on challenging nodes; combine with EEG-specific encoders (temporal convolutions or RNNs).</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_success</strong></td>
                            <td>successful in several studies: Ye et al. (2021) and Zhong et al. (2020) reported improved subject-independent results via GNN+DA; node-wise adversarial training and attention improved alignment.</td>
                        </tr>
                        <tr>
                            <td><strong>barriers_encountered</strong></td>
                            <td>Determining appropriate graph topology, computational cost of GNNs, and ensuring alignment preserves class structure across nodes.</td>
                        </tr>
                        <tr>
                            <td><strong>facilitating_factors</strong></td>
                            <td>Electrode spatial structure maps naturally to graph representations; attention and node-wise discriminators allow focused alignment.</td>
                        </tr>
                        <tr>
                            <td><strong>contextual_requirements</strong></td>
                            <td>Accurate electrode location info or learning procedure for adjacency, graph-aware preprocessing, computational resources for GNN training.</td>
                        </tr>
                        <tr>
                            <td><strong>generalizability</strong></td>
                            <td>Highly generalizable to other sensor-array modalities (e.g., MEG, multi-channel ECG) where spatial topology matters.</td>
                        </tr>
                        <tr>
                            <td><strong>knowledge_type</strong></td>
                            <td>explicit procedural steps, instrumental/technical skills</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Toward cross-subject and cross-session generalization in EEG-based emotion recognition: Systematic review, taxonomy, and methods', 'publication_date_yy_mm': '2022-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e415.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e415.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of experimental methods, techniques, or procedures being transferred, adapted, or applied from one scientific domain or context to another scientific domain or context, including details about the transfer process and outcomes.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>SPD / Riemannian DA (daSPDnet)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Domain adaptation using symmetric positive-definite (SPD) matrix networks and Riemannian geometry</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Methods that represent EEG epochs by covariance (SPD) matrices and perform domain adaptation respecting Riemannian manifold geometry, often via specialized networks (daSPDnet) or Wasserstein-based alignment.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>A prototype-based spd matrix network for domain adaptation eeg emotion recognition.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_name</strong></td>
                            <td>SPD / Riemannian domain adaptation (daSPDnet)</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_description</strong></td>
                            <td>Compute covariance matrices of multichannel EEG as SPD manifold points, use Riemannian metrics/distances to measure discrepancies (or embed SPD matrices with manifold-aware layers), and train networks (with adversarial or prototype-based objectives) that align source and target distributions on the manifold rather than Euclidean feature space.</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_type</strong></td>
                            <td>computational method / geometry-aware data analysis + domain adaptation</td>
                        </tr>
                        <tr>
                            <td><strong>source_domain</strong></td>
                            <td>information geometry / signal processing (applications in radar, SPD matrix processing)</td>
                        </tr>
                        <tr>
                            <td><strong>target_domain</strong></td>
                            <td>EEG-based emotion recognition</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_type</strong></td>
                            <td>adapted/modified for new context</td>
                        </tr>
                        <tr>
                            <td><strong>modifications_made</strong></td>
                            <td>Manifold-aware neural network layers (e.g., SPDNet variants) were used to maintain positive-definiteness; adversarial or prototype-based domain-alignment losses implemented on manifold distances; small labelled target sets were sometimes required (semi-supervised DA).</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_success</strong></td>
                            <td>reported as promising: Wang et al. (2021c) (daSPDnet) retained intrinsic geometry and improved domain adaptation performance on EEG emotion tasks; published results in review indicate competitive performance though specific numbers vary by dataset.</td>
                        </tr>
                        <tr>
                            <td><strong>barriers_encountered</strong></td>
                            <td>Higher mathematical and implementation complexity (manifold operations), computational cost, and requirement for stable covariance estimation (sensitive to epoch length/noise).</td>
                        </tr>
                        <tr>
                            <td><strong>facilitating_factors</strong></td>
                            <td>Covariance is a natural representation for multichannel EEG, and manifold distances better reflect structure than Euclidean metrics; prior work in radar/SPD provided methodological foundations.</td>
                        </tr>
                        <tr>
                            <td><strong>contextual_requirements</strong></td>
                            <td>Sufficient epoch length for reliable covariance estimation, numerically stable manifold operations, and expertise in Riemannian methods.</td>
                        </tr>
                        <tr>
                            <td><strong>generalizability</strong></td>
                            <td>Applicable to any multichannel time-series data where covariance carries key info (MEG, multi-lead ECG), but requires domain-specific tuning.</td>
                        </tr>
                        <tr>
                            <td><strong>knowledge_type</strong></td>
                            <td>theoretical principles, instrumental/technical skills</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Toward cross-subject and cross-session generalization in EEG-based emotion recognition: Systematic review, taxonomy, and methods', 'publication_date_yy_mm': '2022-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e415.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e415.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of experimental methods, techniques, or procedures being transferred, adapted, or applied from one scientific domain or context to another scientific domain or context, including details about the transfer process and outcomes.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Dictionary learning / Transferable sparse coding</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Transferable dictionary learning and sparse coding methods adapted for multi-source EEG domain adaptation</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Dictionary-learning approaches that learn common and domain-specific atoms across sources and targets to produce representations robust to domain shifts, sometimes combined with multi-source weighting.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Multi-source domain transfer discriminative dictionary learning modeling for electroencephalogram-based emotion recognition.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_name</strong></td>
                            <td>Transferable sparse coding / discriminative dictionary learning</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_description</strong></td>
                            <td>Learn an overcomplete dictionary and sparse codes such that reconstruction is accurate and codes are domain-discriminative; add domain-alignment regularizers (MMD, Fisher criteria) and instance weighting/selection to mitigate negative transfer from irrelevant sources.</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_type</strong></td>
                            <td>computational method / representation learning + domain adaptation</td>
                        </tr>
                        <tr>
                            <td><strong>source_domain</strong></td>
                            <td>signal processing / computer vision (sparse coding, dictionary learning)</td>
                        </tr>
                        <tr>
                            <td><strong>target_domain</strong></td>
                            <td>EEG emotion recognition</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_type</strong></td>
                            <td>adapted/modified for new context</td>
                        </tr>
                        <tr>
                            <td><strong>modifications_made</strong></td>
                            <td>Regularizers for preserving local sample relations and class discrimination added; multi-source decomposition into sub-dictionaries per subject/session; small labelled target data sometimes used for semi-supervised adaptation; evaluation on DEAP/SEED.</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_success</strong></td>
                            <td>reported as effective in multi-source EEG settings (Gu et al. (2022) MDTDDL and Ni et al. (2021) report promising cross-subject/session results), improving robustness to negative transfer by selecting relevant sub-sources.</td>
                        </tr>
                        <tr>
                            <td><strong>barriers_encountered</strong></td>
                            <td>Computational complexity for multi-source dictionary training, need to choose size and number of sub-dictionaries, potential sensitivity to noisy EEG samples.</td>
                        </tr>
                        <tr>
                            <td><strong>facilitating_factors</strong></td>
                            <td>Sparsity provides robust representations; instance/source selection strategies (TrAdaBoost, MMD ranking) reduce negative transfer.</td>
                        </tr>
                        <tr>
                            <td><strong>contextual_requirements</strong></td>
                            <td>Careful hyperparameter tuning (dictionary size, sparsity), preprocessing, and sometimes labelled target samples for weighting.</td>
                        </tr>
                        <tr>
                            <td><strong>generalizability</strong></td>
                            <td>Generalizable to other biosignal multi-source fusion tasks where shared sparse structure exists, but computational costs grow with number of sources.</td>
                        </tr>
                        <tr>
                            <td><strong>knowledge_type</strong></td>
                            <td>explicit procedural steps, instrumental/technical skills</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Toward cross-subject and cross-session generalization in EEG-based emotion recognition: Systematic review, taxonomy, and methods', 'publication_date_yy_mm': '2022-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e415.8">
                <h3 class="extraction-instance">Extracted Data Instance 8 (e415.8)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of experimental methods, techniques, or procedures being transferred, adapted, or applied from one scientific domain or context to another scientific domain or context, including details about the transfer process and outcomes.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Adaptive BatchNorm (adaBN) in EEG DA</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Adaptive Batch Normalization (adaBN) integrated into domain adaptation networks for EEG</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Using adaptive batch-normalization layers to correct domain shifts by updating normalization statistics per domain (source vs target) as part of a DA pipeline.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Two-level domain adaptation neural network for EEG-based emotion recognition.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_name</strong></td>
                            <td>Adaptive Batch Normalization (adaBN) within DA networks</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_description</strong></td>
                            <td>Replace or augment standard batch-normalization layers with domain-aware variants that maintain separate mean/variance (and sometimes affine parameters) for source and target domains, reducing covariate shift across domains and improving transfer.</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_type</strong></td>
                            <td>computational method / normalization technique within deep networks</td>
                        </tr>
                        <tr>
                            <td><strong>source_domain</strong></td>
                            <td>deep learning best practices (computer vision / general ML)</td>
                        </tr>
                        <tr>
                            <td><strong>target_domain</strong></td>
                            <td>EEG emotion recognition</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_type</strong></td>
                            <td>adapted/modified for new context</td>
                        </tr>
                        <tr>
                            <td><strong>modifications_made</strong></td>
                            <td>adaBN was applied to EEG-specific CNN pipelines; EEG inputs converted to 2D maps for CNNs or directly used in temporal CNNs; combined with other DA losses (MMD, adversarial) in multi-stage pipelines (e.g., TDANN uses MMD+adaBN).</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_success</strong></td>
                            <td>useful and practical: Bao et al. (2020) TDANN used adaBN plus MMD and reported improved leave-one-subject-out cross-subject performance on SEED; adaBN is often used as a stabilizing DA component.</td>
                        </tr>
                        <tr>
                            <td><strong>barriers_encountered</strong></td>
                            <td>Requires careful bookkeeping of domain statistics and sufficient batch composition from each domain; may be insufficient alone if conditional shifts exist.</td>
                        </tr>
                        <tr>
                            <td><strong>facilitating_factors</strong></td>
                            <td>Simple to implement, low computational overhead, synergizes with other DA objectives (MMD/adversarial).</td>
                        </tr>
                        <tr>
                            <td><strong>contextual_requirements</strong></td>
                            <td>Network architectures supporting BN, ability to collect domain-specific mini-batches during training, EEG preprocessing consistent across domains.</td>
                        </tr>
                        <tr>
                            <td><strong>generalizability</strong></td>
                            <td>Widely generalizable within deep DA pipelines across biosignal tasks; a low-cost adaptation mechanism.</td>
                        </tr>
                        <tr>
                            <td><strong>knowledge_type</strong></td>
                            <td>instrumental/technical skills, explicit procedural steps</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Toward cross-subject and cross-session generalization in EEG-based emotion recognition: Systematic review, taxonomy, and methods', 'publication_date_yy_mm': '2022-12'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>A survey on transfer learning <em>(Rating: 2)</em></li>
                <li>Unsupervised domain adaptation by backpropagation <em>(Rating: 2)</em></li>
                <li>Adversarial discriminative domain adaptation <em>(Rating: 2)</em></li>
                <li>Transfer component analysis <em>(Rating: 2)</em></li>
                <li>Deep domain confusion: Maximizing for domain invariance <em>(Rating: 1)</em></li>
                <li>Transfer sparse coding for robust image representation <em>(Rating: 1)</em></li>
                <li>Wgan domain adaptation for eeg-based emotion recognition <em>(Rating: 2)</em></li>
                <li>EEG-based emotion recognition using domain adaptation network <em>(Rating: 2)</em></li>
                <li>Two-level domain adaptation neural network for EEG-based emotion recognition <em>(Rating: 2)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-415",
    "paper_id": "paper-254854366",
    "extraction_schema_id": "extraction-schema-16",
    "extracted_data": [
        {
            "name_short": "Image-DA -&gt; EEG adaptation",
            "name_full": "Adaptation of domain-adaptation strategies originally developed for image classification to EEG-based emotion recognition",
            "brief_description": "General practice of taking DA methods (MMD-based, adversarial, subspace alignment, etc.) developed for image tasks and adapting them to EEG emotion classification by changing input representations and loss terms to account for EEG nonstationarity and electrode topology.",
            "citation_title": "Graph neural networks: A review of methods and applications.",
            "mention_or_use": "mention",
            "procedure_name": "Domain adaptation strategies from image classification",
            "procedure_description": "A family of methods that reduce distributional discrepancy between a labelled source dataset and an (unlabelled or partially labelled) target dataset by learning mappings or feature representations that align marginal/conditional distributions (e.g., MMD minimization, adversarial domain discriminators, subspace alignment, transfer component analysis). In images these operate on pixel/feature tensors; when moved to EEG they are applied to EEG-derived features (PSD, spectrograms, time-frequency maps) or graph/electrode-structured inputs.",
            "procedure_type": "computational method / transfer learning technique",
            "source_domain": "computer vision / image classification",
            "target_domain": "EEG-based affective neuroscience / emotion recognition",
            "transfer_type": "adapted/modified for new context",
            "modifications_made": "Input representations were changed from images to EEG-specific formats (spectrograms, EFDMs, electrode graphs, covariance matrices); discrepancy measures were applied on EEG feature spaces (PSD, time-frequency embeddings); architectures were modified to respect electrode topology (GNNs) or hemispheric separation; often small amounts of labelled target data or target-unlabelled data were used (semi/unsupervised DA).",
            "transfer_success": "partially successful - widely adopted in reviewed literature and often improves cross-subject/session accuracy versus classical ML baselines, but success varies by dataset and method (examples: several deep-DA (CSS) studies report top performances; see Du et al. (2020) with SEED 3-class accuracy 90.92% ± 1.05, Ning et al. (2021) reported 97.66% ± 14.46 on SEED in a deep DA setting).",
            "barriers_encountered": "EEG non-stationarity, different data dimensionality and temporal dynamics than images, need to preserve spatial electrode relationships, small number of labelled target samples, variability in acquisition devices and stimuli.",
            "facilitating_factors": "Shared ML formalism (feature learning, adversarial losses, MMD) allows reuse of core algorithms; ability to convert EEG to image-like or structured representations; availability of public EEG datasets for benchmarking.",
            "contextual_requirements": "EEG-specific preprocessing (line noise removal, referencing, artifact removal), conversion to suitable input formats (spectrograms, EFDMs, graphs), often GPU compute for deep models, careful cross-subject validation (LOSO).",
            "generalizability": "Moderately generalizable across EEG emotion tasks when representation adjustments are made; methods can be applied to other biosignal domains (ECG, EDA) with analogous representation changes, but direct transfer without adaptation is usually ineffective.",
            "knowledge_type": "explicit procedural steps, theoretical principles",
            "uuid": "e415.0",
            "source_info": {
                "paper_title": "Toward cross-subject and cross-session generalization in EEG-based emotion recognition: Systematic review, taxonomy, and methods",
                "publication_date_yy_mm": "2022-12"
            }
        },
        {
            "name_short": "DANN",
            "name_full": "Domain Adversarial Neural Network (DANN)",
            "brief_description": "A deep adversarial domain-adaptation architecture that jointly optimizes a feature extractor for label prediction while making domain discrimination (source vs target) difficult, promoting domain-invariant features.",
            "citation_title": "EEG-based emotion recognition using domain adaptation network.",
            "mention_or_use": "use",
            "procedure_name": "Domain Adversarial Neural Network (DANN)",
            "procedure_description": "Neural network composed of a feature extractor, a label predictor, and a domain classifier; a gradient reversal layer or adversarial loss trains the feature extractor to maximize label accuracy while maximizing domain-classifier loss, reducing distributional differences between source and target in feature space.",
            "procedure_type": "computational method / deep transfer learning",
            "source_domain": "machine learning / general domain adaptation (initially applied in vision and NLP)",
            "target_domain": "EEG-based emotion recognition",
            "transfer_type": "adapted/modified for new context",
            "modifications_made": "Applied to EEG inputs by changing input layers to accept EEG-derived representations (time-series, spectrograms, electrode graphs), adding hemisphere-specific branches (BiDANN) or multiple feature streams (e.g., separate encoders for left/right hemispheres), and integrating attention or graph modules to respect electrode spatial layout.",
            "transfer_success": "successful in multiple EEG emotion studies — e.g., Jin et al. (2017) evaluated DANN on SEED, and many later EEG studies report improved cross-subject performance when using DANN variants; deep adversarial approaches form a dominant class among high-performing cross-subject methods in the review.",
            "barriers_encountered": "Potential 'over-alignment' where class-discriminative structure is lost if domain alignment ignores labels; needs careful balancing of adversarial and classification losses, and EEG-specific pretraining/representation choices.",
            "facilitating_factors": "Adversarial framework directly addresses dataset-shift, availability of unlabelled target data, modular network design allows EEG-specific encoder modules.",
            "contextual_requirements": "EEG preprocessing and feature extraction, careful hyperparameter tuning (adversarial weight), sometimes small labelled target set for validation, compute resources for deep training.",
            "generalizability": "High within EEG emotion tasks when modified to include electrode/temporal priors; conceptually applicable to other biosignals with analogous encoder changes.",
            "knowledge_type": "explicit procedural steps, theoretical principles",
            "uuid": "e415.1",
            "source_info": {
                "paper_title": "Toward cross-subject and cross-session generalization in EEG-based emotion recognition: Systematic review, taxonomy, and methods",
                "publication_date_yy_mm": "2022-12"
            }
        },
        {
            "name_short": "ADDA / WGANDA",
            "name_full": "Adversarial Discriminative Domain Adaptation (ADDA) / Wasserstein GAN Domain Adaptation (WGANDA) adapted for EEG",
            "brief_description": "Two-stage adversarial approaches that learn separate encoders for source and target and adversarially align their feature distributions; WGANDA uses Wasserstein loss for stable distribution matching and was adapted to EEG.",
            "citation_title": "Wgan domain adaptation for eeg-based emotion recognition.",
            "mention_or_use": "use",
            "procedure_name": "ADDA / WGANDA",
            "procedure_description": "ADDA: train a source encoder+classifier on labelled source data, then adversarially train a target encoder to map target data into the source encoder feature space so the source classifier can be used. WGANDA: uses Wasserstein distance and GAN-based adversarial training between source and target feature generators to minimize distributional differences more stably.",
            "procedure_type": "computational method / adversarial domain adaptation",
            "source_domain": "computer vision / domain adaptation (ADDA originally for images)",
            "target_domain": "EEG-based emotion recognition",
            "transfer_type": "adapted/modified for new context",
            "modifications_made": "EEG-specific generators/encoders were designed to take EEG feature vectors or spectrograms; pretraining steps included EEG feature preprocessing; Wasserstein/GAN losses tuned for EEG feature statistics; outputs fed to emotion classifiers.",
            "transfer_success": "reported as successful in EEG studies: Luo et al. (2018) adapted ADDA into WGANDA for EEG and reported improved alignment enabling cross-subject classification; compared favorably to some baselines in the review (no single universal metric reported).",
            "barriers_encountered": "GAN training instability on EEG features, limited labelled target samples for validation, need to preserve task-discriminative structure during adversarial alignment.",
            "facilitating_factors": "Wasserstein metric provides more stable adversarial objective; pretraining on source stabilizes later adversarial tuning; modular two-stage approach separates source learning from target adaptation.",
            "contextual_requirements": "Robust EEG preprocessing, selection of stable EEG feature embeddings (e.g., EFDMs, spectrograms), careful GAN hyperparameter tuning and regularization.",
            "generalizability": "Applicable to many EEG cross-subject problems but training stability and representation choice are critical; the two-stage adversarial concept generalizes to other biosignal domains.",
            "knowledge_type": "explicit procedural steps, instrumental/technical skills",
            "uuid": "e415.2",
            "source_info": {
                "paper_title": "Toward cross-subject and cross-session generalization in EEG-based emotion recognition: Systematic review, taxonomy, and methods",
                "publication_date_yy_mm": "2022-12"
            }
        },
        {
            "name_short": "TCA",
            "name_full": "Transfer Component Analysis (TCA)",
            "brief_description": "An MMD-based approach that learns a subspace where marginal distributions of source and target are close while preserving data variance, used in unsupervised and supervised variants.",
            "citation_title": "Transfer components between subjects for eeg-based emotion recognition.",
            "mention_or_use": "use",
            "procedure_name": "Transfer Component Analysis (TCA)",
            "procedure_description": "TCA finds a linear (kernelized) projection to a lower-dimensional subspace that simultaneously maximizes variance and minimizes Maximum Mean Discrepancy (MMD) between source and target distributions, enabling simpler classifiers to work on aligned features.",
            "procedure_type": "computational method / shallow domain adaptation",
            "source_domain": "machine learning / general domain adaptation (original image/text tasks)",
            "target_domain": "EEG emotion recognition",
            "transfer_type": "adapted/modified for new context",
            "modifications_made": "Applied to EEG by selecting EEG-specific features (PSD, DE, time-frequency embeddings) as inputs to TCA; kernel and projected dimensionality tuned for EEG datasets; sometimes combined with instance selection (sub-sampling sources).",
            "transfer_success": "used successfully in EEG studies (Zheng et al. (2015) evaluated unsupervised TCA on SEED with LOSO validation), often improving over raw-feature baselines though results depend on feature choice and subspace dimensionality.",
            "barriers_encountered": "Choice of kernel and target dimensionality critical; TCA assumes a shared feature space and may be limited when conditional distributions differ substantially across subjects/sessions.",
            "facilitating_factors": "MMD provides a principled discrepancy measure; EEG features with stable statistics across subjects (e.g., log-PSD) facilitate alignment.",
            "contextual_requirements": "Careful EEG feature extraction and normalization, cross-validation to choose subspace dimension, compute for kernel PCA/TCA steps.",
            "generalizability": "Well-suited to EEG and other biosignals where feature vectors can be defined; limited when feature distributions have complex conditional shifts.",
            "knowledge_type": "explicit procedural steps, theoretical principles",
            "uuid": "e415.3",
            "source_info": {
                "paper_title": "Toward cross-subject and cross-session generalization in EEG-based emotion recognition: Systematic review, taxonomy, and methods",
                "publication_date_yy_mm": "2022-12"
            }
        },
        {
            "name_short": "Pretrained-vision CNNs on EEG",
            "name_full": "Use of pretrained convolutional neural networks (InceptionResNetV2, DenseNet121) trained on images, applied to EEG via image-like representations",
            "brief_description": "Applying off-the-shelf image CNNs pre-trained on large image corpora to EEG emotion tasks by converting EEG signals into 2D image representations (spectrograms, EFDMs) and fine-tuning classifiers.",
            "citation_title": "Investigating the use of pretrained convolutional neural network on cross-subject and cross-dataset eeg emotion recognition.",
            "mention_or_use": "use",
            "procedure_name": "Pretrained convolutional neural networks (transfer from computer vision)",
            "procedure_description": "Transform EEG epochs into 2D representations (time-frequency spectrograms, electrode-frequency maps) which are then input to standard CNN architectures pre-trained on ImageNet; the CNN feature extractor is fine-tuned on EEG emotion labels or used as frozen feature extractor with a new classifier head.",
            "procedure_type": "computational method / supervised transfer learning",
            "source_domain": "computer vision / image recognition",
            "target_domain": "EEG-based emotion recognition",
            "transfer_type": "adapted/modified for new context",
            "modifications_made": "EEG signals converted to images (spectrograms, EFDMs); input channels and normalization adjusted to match CNN expected input; final layers replaced or fine-tuned; sometimes augmented with EEG-specific preprocessing like stratified normalization.",
            "transfer_success": "reported as effective in cross-subject and cross-dataset evaluations (e.g., Cimtay & Ekmekcioglu (2020) and Pusarla et al. (2022) used InceptionResNetV2/DenseNet121 variants with improved subject-transfer performance compared with some baselines), though performance depends on the quality of the EEG-to-image mapping.",
            "barriers_encountered": "Mismatch between statistical properties of natural images and EEG-derived images; need for careful normalization and channel encoding; risk of overfitting due to limited labelled EEG data.",
            "facilitating_factors": "Large pre-trained weights provide robust low-level feature extractors; converting EEG into image-like inputs makes methods plug-and-play.",
            "contextual_requirements": "High-quality EEG-to-image transforms, GPU compute for fine-tuning, cross-subject validation protocols.",
            "generalizability": "Applicable to other time-series biosignals when informative image-like transforms exist (e.g., spectrograms of ECG/EOG), but effectiveness depends on representational fidelity.",
            "knowledge_type": "instrumental/technical skills, explicit procedural steps",
            "uuid": "e415.4",
            "source_info": {
                "paper_title": "Toward cross-subject and cross-session generalization in EEG-based emotion recognition: Systematic review, taxonomy, and methods",
                "publication_date_yy_mm": "2022-12"
            }
        },
        {
            "name_short": "GNN + DA",
            "name_full": "Graph Neural Networks combined with domain adaptation for EEG",
            "brief_description": "Use of graph neural network architectures to model electrode spatial relations, combined with adversarial or discrepancy-based domain adaptation to improve subject-independent EEG emotion recognition.",
            "citation_title": "Cross-subject eeg-based emotion recognition using adversarial domain adaption with attention mechanism.",
            "mention_or_use": "use",
            "procedure_name": "Graph neural networks with domain adaptation",
            "procedure_description": "Construct a graph whose nodes correspond to EEG electrodes (or learned nodes), process signals with GNN layers (graph convolutions or attention) to capture spatial dependencies, and apply domain-adversarial training (node-wise discriminators or global domain classifiers) or MMD penalties to align source and target graph feature distributions.",
            "procedure_type": "computational method / deep learning + domain adaptation",
            "source_domain": "graph machine learning / network science (often used in social networks, chemistry, vision)",
            "target_domain": "EEG emotion recognition",
            "transfer_type": "adapted/modified for new context",
            "modifications_made": "Define electrode adjacency either by physical scalp layout or learn it from data (self-organized graphs); employ node-wise domain discriminators (NodeDAT) or attention to focus alignment on challenging nodes; combine with EEG-specific encoders (temporal convolutions or RNNs).",
            "transfer_success": "successful in several studies: Ye et al. (2021) and Zhong et al. (2020) reported improved subject-independent results via GNN+DA; node-wise adversarial training and attention improved alignment.",
            "barriers_encountered": "Determining appropriate graph topology, computational cost of GNNs, and ensuring alignment preserves class structure across nodes.",
            "facilitating_factors": "Electrode spatial structure maps naturally to graph representations; attention and node-wise discriminators allow focused alignment.",
            "contextual_requirements": "Accurate electrode location info or learning procedure for adjacency, graph-aware preprocessing, computational resources for GNN training.",
            "generalizability": "Highly generalizable to other sensor-array modalities (e.g., MEG, multi-channel ECG) where spatial topology matters.",
            "knowledge_type": "explicit procedural steps, instrumental/technical skills",
            "uuid": "e415.5",
            "source_info": {
                "paper_title": "Toward cross-subject and cross-session generalization in EEG-based emotion recognition: Systematic review, taxonomy, and methods",
                "publication_date_yy_mm": "2022-12"
            }
        },
        {
            "name_short": "SPD / Riemannian DA (daSPDnet)",
            "name_full": "Domain adaptation using symmetric positive-definite (SPD) matrix networks and Riemannian geometry",
            "brief_description": "Methods that represent EEG epochs by covariance (SPD) matrices and perform domain adaptation respecting Riemannian manifold geometry, often via specialized networks (daSPDnet) or Wasserstein-based alignment.",
            "citation_title": "A prototype-based spd matrix network for domain adaptation eeg emotion recognition.",
            "mention_or_use": "use",
            "procedure_name": "SPD / Riemannian domain adaptation (daSPDnet)",
            "procedure_description": "Compute covariance matrices of multichannel EEG as SPD manifold points, use Riemannian metrics/distances to measure discrepancies (or embed SPD matrices with manifold-aware layers), and train networks (with adversarial or prototype-based objectives) that align source and target distributions on the manifold rather than Euclidean feature space.",
            "procedure_type": "computational method / geometry-aware data analysis + domain adaptation",
            "source_domain": "information geometry / signal processing (applications in radar, SPD matrix processing)",
            "target_domain": "EEG-based emotion recognition",
            "transfer_type": "adapted/modified for new context",
            "modifications_made": "Manifold-aware neural network layers (e.g., SPDNet variants) were used to maintain positive-definiteness; adversarial or prototype-based domain-alignment losses implemented on manifold distances; small labelled target sets were sometimes required (semi-supervised DA).",
            "transfer_success": "reported as promising: Wang et al. (2021c) (daSPDnet) retained intrinsic geometry and improved domain adaptation performance on EEG emotion tasks; published results in review indicate competitive performance though specific numbers vary by dataset.",
            "barriers_encountered": "Higher mathematical and implementation complexity (manifold operations), computational cost, and requirement for stable covariance estimation (sensitive to epoch length/noise).",
            "facilitating_factors": "Covariance is a natural representation for multichannel EEG, and manifold distances better reflect structure than Euclidean metrics; prior work in radar/SPD provided methodological foundations.",
            "contextual_requirements": "Sufficient epoch length for reliable covariance estimation, numerically stable manifold operations, and expertise in Riemannian methods.",
            "generalizability": "Applicable to any multichannel time-series data where covariance carries key info (MEG, multi-lead ECG), but requires domain-specific tuning.",
            "knowledge_type": "theoretical principles, instrumental/technical skills",
            "uuid": "e415.6",
            "source_info": {
                "paper_title": "Toward cross-subject and cross-session generalization in EEG-based emotion recognition: Systematic review, taxonomy, and methods",
                "publication_date_yy_mm": "2022-12"
            }
        },
        {
            "name_short": "Dictionary learning / Transferable sparse coding",
            "name_full": "Transferable dictionary learning and sparse coding methods adapted for multi-source EEG domain adaptation",
            "brief_description": "Dictionary-learning approaches that learn common and domain-specific atoms across sources and targets to produce representations robust to domain shifts, sometimes combined with multi-source weighting.",
            "citation_title": "Multi-source domain transfer discriminative dictionary learning modeling for electroencephalogram-based emotion recognition.",
            "mention_or_use": "use",
            "procedure_name": "Transferable sparse coding / discriminative dictionary learning",
            "procedure_description": "Learn an overcomplete dictionary and sparse codes such that reconstruction is accurate and codes are domain-discriminative; add domain-alignment regularizers (MMD, Fisher criteria) and instance weighting/selection to mitigate negative transfer from irrelevant sources.",
            "procedure_type": "computational method / representation learning + domain adaptation",
            "source_domain": "signal processing / computer vision (sparse coding, dictionary learning)",
            "target_domain": "EEG emotion recognition",
            "transfer_type": "adapted/modified for new context",
            "modifications_made": "Regularizers for preserving local sample relations and class discrimination added; multi-source decomposition into sub-dictionaries per subject/session; small labelled target data sometimes used for semi-supervised adaptation; evaluation on DEAP/SEED.",
            "transfer_success": "reported as effective in multi-source EEG settings (Gu et al. (2022) MDTDDL and Ni et al. (2021) report promising cross-subject/session results), improving robustness to negative transfer by selecting relevant sub-sources.",
            "barriers_encountered": "Computational complexity for multi-source dictionary training, need to choose size and number of sub-dictionaries, potential sensitivity to noisy EEG samples.",
            "facilitating_factors": "Sparsity provides robust representations; instance/source selection strategies (TrAdaBoost, MMD ranking) reduce negative transfer.",
            "contextual_requirements": "Careful hyperparameter tuning (dictionary size, sparsity), preprocessing, and sometimes labelled target samples for weighting.",
            "generalizability": "Generalizable to other biosignal multi-source fusion tasks where shared sparse structure exists, but computational costs grow with number of sources.",
            "knowledge_type": "explicit procedural steps, instrumental/technical skills",
            "uuid": "e415.7",
            "source_info": {
                "paper_title": "Toward cross-subject and cross-session generalization in EEG-based emotion recognition: Systematic review, taxonomy, and methods",
                "publication_date_yy_mm": "2022-12"
            }
        },
        {
            "name_short": "Adaptive BatchNorm (adaBN) in EEG DA",
            "name_full": "Adaptive Batch Normalization (adaBN) integrated into domain adaptation networks for EEG",
            "brief_description": "Using adaptive batch-normalization layers to correct domain shifts by updating normalization statistics per domain (source vs target) as part of a DA pipeline.",
            "citation_title": "Two-level domain adaptation neural network for EEG-based emotion recognition.",
            "mention_or_use": "use",
            "procedure_name": "Adaptive Batch Normalization (adaBN) within DA networks",
            "procedure_description": "Replace or augment standard batch-normalization layers with domain-aware variants that maintain separate mean/variance (and sometimes affine parameters) for source and target domains, reducing covariate shift across domains and improving transfer.",
            "procedure_type": "computational method / normalization technique within deep networks",
            "source_domain": "deep learning best practices (computer vision / general ML)",
            "target_domain": "EEG emotion recognition",
            "transfer_type": "adapted/modified for new context",
            "modifications_made": "adaBN was applied to EEG-specific CNN pipelines; EEG inputs converted to 2D maps for CNNs or directly used in temporal CNNs; combined with other DA losses (MMD, adversarial) in multi-stage pipelines (e.g., TDANN uses MMD+adaBN).",
            "transfer_success": "useful and practical: Bao et al. (2020) TDANN used adaBN plus MMD and reported improved leave-one-subject-out cross-subject performance on SEED; adaBN is often used as a stabilizing DA component.",
            "barriers_encountered": "Requires careful bookkeeping of domain statistics and sufficient batch composition from each domain; may be insufficient alone if conditional shifts exist.",
            "facilitating_factors": "Simple to implement, low computational overhead, synergizes with other DA objectives (MMD/adversarial).",
            "contextual_requirements": "Network architectures supporting BN, ability to collect domain-specific mini-batches during training, EEG preprocessing consistent across domains.",
            "generalizability": "Widely generalizable within deep DA pipelines across biosignal tasks; a low-cost adaptation mechanism.",
            "knowledge_type": "instrumental/technical skills, explicit procedural steps",
            "uuid": "e415.8",
            "source_info": {
                "paper_title": "Toward cross-subject and cross-session generalization in EEG-based emotion recognition: Systematic review, taxonomy, and methods",
                "publication_date_yy_mm": "2022-12"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "A survey on transfer learning",
            "rating": 2,
            "sanitized_title": "a_survey_on_transfer_learning"
        },
        {
            "paper_title": "Unsupervised domain adaptation by backpropagation",
            "rating": 2,
            "sanitized_title": "unsupervised_domain_adaptation_by_backpropagation"
        },
        {
            "paper_title": "Adversarial discriminative domain adaptation",
            "rating": 2,
            "sanitized_title": "adversarial_discriminative_domain_adaptation"
        },
        {
            "paper_title": "Transfer component analysis",
            "rating": 2,
            "sanitized_title": "transfer_component_analysis"
        },
        {
            "paper_title": "Deep domain confusion: Maximizing for domain invariance",
            "rating": 1,
            "sanitized_title": "deep_domain_confusion_maximizing_for_domain_invariance"
        },
        {
            "paper_title": "Transfer sparse coding for robust image representation",
            "rating": 1,
            "sanitized_title": "transfer_sparse_coding_for_robust_image_representation"
        },
        {
            "paper_title": "Wgan domain adaptation for eeg-based emotion recognition",
            "rating": 2,
            "sanitized_title": "wgan_domain_adaptation_for_eegbased_emotion_recognition"
        },
        {
            "paper_title": "EEG-based emotion recognition using domain adaptation network",
            "rating": 2,
            "sanitized_title": "eegbased_emotion_recognition_using_domain_adaptation_network"
        },
        {
            "paper_title": "Two-level domain adaptation neural network for EEG-based emotion recognition",
            "rating": 2,
            "sanitized_title": "twolevel_domain_adaptation_neural_network_for_eegbased_emotion_recognition"
        }
    ],
    "cost": 0.0244315,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Toward cross-subject and cross-session generalization in EEG-based emotion recognition: Systematic review, taxonomy, and methods
19 Aug 2024</p>
<p>Andrea Apicella 
Laboratory of Augmented Reality for Health Monitoring (ARHeMLab)</p>
<p>Department of Electrical Engineering and Information Technology
University of Naples Federico II</p>
<p>Pasquale Arpaia 
Laboratory of Augmented Reality for Health Monitoring (ARHeMLab)</p>
<p>Department of Electrical Engineering and Information Technology
University of Naples Federico II</p>
<p>Giovanni D'errico 
Department of Applied Science and Technology
Polytechnic University of Turin</p>
<p>Davide Marocco 
Natural and Artificial Cognition Laboratory</p>
<p>Giovanna Mastrati 
Laboratory of Augmented Reality for Health Monitoring (ARHeMLab)</p>
<p>Department of Electrical Engineering and Information Technology
University of Naples Federico II</p>
<p>Nicola Moccaldi 
Laboratory of Augmented Reality for Health Monitoring (ARHeMLab)</p>
<p>Department of Electrical Engineering and Information Technology
University of Naples Federico II</p>
<p>Roberto Prevete 
Laboratory of Augmented Reality for Health Monitoring (ARHeMLab)</p>
<p>Department of Electrical Engineering and Information Technology
University of Naples Federico II</p>
<p>Toward cross-subject and cross-session generalization in EEG-based emotion recognition: Systematic review, taxonomy, and methods
19 Aug 20245057FFA09191FC60B0AA15799D5116CA10.1016/j.neucom.2024.128354arXiv:2212.08744v3[cs.LG]
A systematic review on machine-learning strategies for improving generalizability (cross-subjects and cross-sessions) electroencephalography (EEG) based in emotion classification was realized.In this context, the nonstationarity of EEG signals is a critical issue and can lead to the Dataset Shift problem.Several architectures and methods have been proposed to address this issue, mainly based on transfer learning methods.418 papers were retrieved from the Scopus, IEEE Xplore and PubMed databases through a search query focusing on modern machine learning techniques for generalization in EEG-based emotion assessment.Among these papers, 75 were found eligible based on their relevance to the problem.Studies lacking a specific cross-subject and cross-session validation strategy and making use of other biosignals as support were excluded.On the basis of the selected papers' analysis, a taxonomy of the studies employing Machine Learning (ML) methods was proposed, together with a brief discussion on the different ML approaches involved.The studies with the best results in terms of average classification accuracy were identified, supporting that transfer learning methods seem to perform better than other approaches.A discussion is proposed on the impact of (i) the emotion theoretical models and (ii) psychological screening of the experimental sample on the classifier performances.</p>
<p>Introduction</p>
<p>Emotions are our internal compass and play a primary role in learning, reasoning, decision-making processes, and communication between individuals.The Information and Communication Technology (ICT) sector's interest in emotions has grown tremendously in recent years, shaping the concept of affective computing, an emerging field aimed at monitoring and predicting emotions in order to improve human-computer interaction Cambria et al. (2017); for instance, the introduction of affective loops makes it possible to implement increasingly adaptive human-machine interfaces and virtual assistants tailored to users Saganowski et al. (2020), or the outputs of emotion monitoring systems, in the healthcare context, can be useful in the treatment of psychological disorders based on emotional deficits, in autism Feng et al. (2018), in the improvement of wellbeing Healy et al. (2018), and in stress containment Saganowski (2022).</p>
<p>In particular, in this context, there is a growing interest in the literature for Brain-Computer Interface (BCI) systems based on EEG signals Torres et al. (2020).In fact, the number of annual scientific publications indexed on Scopus database on the topic of EEG-based emotion recognition shows an exponential growth trend (see Fig. 1).</p>
<p>A critical issue underlying the processing and classification of EEG signals is their inherent variability among different subjects or different acquisition times (i.e.sessions) of the same subject, since the EEG signal is usually stochastic and stationary only for short intervals (generally ranging from a few seconds to minutes) Inouye et al. (1995); Im (2018); Sörnmo and Laguna (2005).More in detail, the EEG signal is not a Wide Sense Stationary signal Cao and Slobounov (2011).This characteristic of non-stationarity implies a variation in the temporal and spectral characteristics of the EEG signal over time.This is an open issue in the literature leading to a loss of generalizability for classification systems across subjects (inter-subject task) and, for the same subject, across different sessions (intra-subject task) Nasiri and Clifford (2020).</p>
<p>Data-driven approaches using Machine Learning (ML) are often employed at multiple levels in the EEG signal processing pipeline to pursue the classification of emotional states and their generalization across subjects and sessions.</p>
<p>Currently, the literature shows increasing use of modern machine learning strategies, adopting deep neural networks and transfer learning-based approaches, such as domain adaptation, domain generalization and/or hybrid methods Zhao et al. (2021).This paper proposes a systematic review on the use of machine learning to improve generalizability capabilities in EEG-based emotion recognition systems across different subjects and sessions.</p>
<p>As will be discussed in detail in the next section, several surveys have been proposed in recent years, gathering and discussing the main directions of the literature on this research topic.However, to the best of our knowledge, a focus on the application of ML methods to improve the inter/intra-subjective generalization performance of EEG-based emotion recognition is missing in the literature.</p>
<p>The rest of the paper is organized as follows: Section 2 reviews related works, with reference to recent surveys carried out on this specific topic.Section 3 presents a theoretical background on EEG, with a first part focused on BCIs for emotion recognition and a second part on ML for emotion recognition.Section 4 presents the used search queries and the paper selection process according to the PRISMA method Liberati et al. (2009).Section 5 presents the results of the review, proposing a taxonomy of the ML methods currently proposed in the selected papers, discussing the ML methods with respect the proposed taxonomy.A statistical analyses of the results was reported.Section 6 aims to discuss the results obtained, reporting the most promising lines of research and approaches that have emerged and highlighting possible future directions in this area.Finally, Section 7 draws conclusions.</p>
<p>Related Works</p>
<p>Several reviews have been conducted in recent years on this line of research.Alarcao and Fonseca Alarcao and Fonseca (2017) focus on the generic topic of EEG-Emotion Recognition, presenting a review of papers published in the period from 2009 to 2016.The survey appears interesting in focusing on the different stages of the emotion recognition process from EEG signals and proposing a criterion for assessing the quality of the papers by applying a set of well-known guidelines (Brouwer's recommendations Brouwer et al. (2015)).However, there is no in-depth analysis on the issue of inter/intra-subject generalisation, nor the EEG-nonstationarity problem is addressed.Other reviews Lotte et al. (2018); Wu et al. (2020) analyse works about the EEG-based classification methods, but without focusing on the emotion domain.Wu et al. Wu et al. (2020), offer a non-systematic review focusing on the affective BCIs (aBCIs), but without an in-depth analysis on the emotion recognition problem.The study proposed in Suhaimi et al. (2020) deals with the EEG-inter/intra-subject variability problem as a specific topic on which to focus future research efforts, without exploring the problem in-depth.Recently, Li and colleagues Li et al. (2021b) published a review focusing on the topic of EEG-based emotion recognition and discussing the importance of transfer learning.While offering some interesting results, it does not present itself as a systematic review (only 18 studies were reported without PRISMA methodology to collect them).Thus, differently from the cited works, a systematic literature review focused on the inter/intra-subject generalization on EEG-based emotion recognition systems and the use of modern ML-based methods as a possible solution is proposed in this paper.</p>
<p>3 Theoretical Background</p>
<p>BCI for Emotion Recognition</p>
<p>The emotional states can be recognized through several biosignals.In particular, brain signals have received increasing attention from the scientific community.In fact, the EEG signal resulted particularly effective for emotion recognition due to the high temporal resolution and its non-invasiveness.The EEG signal has a frequency range between [0.01, 100.00]Hz, an amplitude varying typically within the range [-100, 100] µV , and a power spectral density higher at lower frequencies Daly et al. (2012).Five background rhythms are present in the EEG and can be classified into different frequency bands: delta [0.5, 4.0] Hz, theta [4,7] Hz, alpha [8,13] Hz, beta [14,30] Hz, and gamma [30,100] Hz.</p>
<p>The 10-20 International Positioning System is an internationally recognized method to place the electrodes on the scalp Acharya et al. (2016) for the EEG signal recording.The method allows to maintain a standardized EEG electrodes placement proportional to the scalp size and shape in order to preserve the relationship between each location and the underlying brain area.In order to obtain a high-quality EEG, a substantial requirement is the use of high performance electrodes.The electrodes need to ensure a good and constant electrical contact with the skin and therefore need low impedance properties Casson (2019).The electrode-skin contact can either be ensured by adding a conductive gel between the electrode and the skin or by increasing the contact surface that ensures electrical contact.Recently, besides wet electrodes, dry electrodes are employed for the EEG signal recording.A good signal quality and comparable performances with respect to wet electrodes are achieved using dry electrodes Lopez-Gordo et al. (2014).</p>
<p>Besides the quality of the EEG signal, the emotion induction methods and the eliciting stimuli employed represent a crucial point for the effectiveness of the emotional elicitation.Facial and body movements, recall of past events, odors, images, film clips, and music are techniques currently used in laboratories for inducing emotions.Current literature reports that film clips, images, and music are particularly effective to elicit emotions Westermann et al. (1996); Lang (2005).The use of images over other kind of stimuli represents a great advantage insofar as the images are standardized stimuli.Datasets of images were exper-imentally validated (e.g., International Affective Picture System -IAPS Lang (2005), Open Affective Standardized Image Set -OASIS Kurdi et al. (2017), and Geneva Affective Picture Database -GAPED Dan-Glauser and Scherer (2011)).There are several publicly-available databases for EEG-based emotion recognition (e.g., DEAP Koelstra et al. (2011), SEED Zheng and Lu (2015), and DREAMER Katsigiannis and Ramzan (2017)).Each dataset is characterized by different physiological signals and a well-established experimental setup (in terms of stimulus sources, emotional theory adopted, number of subjects, and psychometric metrological references).For a comprehensive description of the various available datasets see Li et al. (2021b).</p>
<p>In case of self-produced EEG data, the preprocessing stage is fundamental to filter out the noise from the brain activity signal.Some steps are often helpful to achieve a successful EEG signal preprocessing: (i) line noise removal, (ii) referencing, (iii) bad channels removal, and (iv) artifacts removal.They can be summarized as:</p>
<p>• Line noise removal: line noise is an artifact which contaminates the gamma band of the EEG signal, specifically at 50 Hz (60 Hz in the USA) Im (2018).Conventional filters such as lowpass filters with cutoff frequencies between 50 Hz and 70 Hz can be used to remove this artifact and reduce the noise at higher frequencies, notch filters must be employed to reject the 50 Hz power supply.</p>
<p>• Referencing: when acquiring the EEG signals, the voltage in a specific scalp area is measured with respect to a reference electrode.If the reference electrode is subjected to artifacts, all electrodes are also affected.</p>
<p>The re-referencing allows to minimize the impact of the reference electrode by subtracting a reference channel from the original EEG channels.Most used reference electrodes are the mastoid channel, the EEG signal at a specific channel, the average of the mastoid channels, or the average of all EEG channels Lepage et al. (2014).To avoid lateralization effects Lepage et al. (2014), also Cz and FCz electrodes are often used as references.</p>
<p>• Bad channels removal: EEG signal of one or more channels can be also contaminated by the noise due to a poor contact between the electrode and the scalp.Therefore, it is necessary to detect the noisy or bad channels and remove them.Methods to find out bad channels are the visual inspection of each single channel, the dispersion and the correlation criteria da Cruz et al. ( 2018).(2014).Good results in the recognition of emotional states can be achieved by using entropy-based features, i.e., approximate, sample, differential, and wavelet entropy Phadikar et al. (2019).Higher-order crossing (HOC), the fractal dimension, and the Non-Stationary Index (NSI) Patil et al. (2016); Nan and Jinghua (1988); Kroupi et al. (2011) are further time domain feature often used for the EEG analysis.</p>
<p>• Frequency domain: the most used feature is the power spectral density (PSD).PSD is the signal power in the unit frequency band Wang et al. (2011).Other representative features of different emotional states involving the PSD are: (i) logarithm, (ii) maximum, (iii) minimum and, (iv) standard deviation of the power spectrum.</p>
<p>• Time-frequency domain: the time-frequency analysis (TFA) allows to observe spectrum changes with timeZhang (2019).The short-time Fourier transform (STFT),the continuous wavelet transform (CWT), the discrete wavelet transform (DWT) Hernández et al. (2018), matching pursuit and empirical mode decomposition are the most used methods to extract timefrequency features.</p>
<p>Often, the number of EEG features is very high, therefore a feature selection strategy is required Jenke et al. (2014).Another critical point is represented by the large number of EEG channels often used for the signal acquisitions.A high number of channels can lead to high computational complexity.Therefore, the selection of the most informative EEG channels can be crucial Apicella et al. (2022).</p>
<p>Machine Learning for Emotion Recognition</p>
<p>After that the EEG have been properly preprocessed and a proper set of features has been extracted, the data are ready to be fed to a supervised ML system.The typical pipeline of a ML framework applied to an EEG emotion recognition task is reported in Fig. 2.</p>
<p>In the current literature, a large part of research works proposed methods framed into Transfer Learning approach to tackle emotion recognition tasks.The motivation of this trend can be summarized as follows: in classical supervised ML a set of already labeled data has to be available.This implies that in the EEG emotion recognition tasks a set of EEG signals recorded from one or more subjects has to be mapped with the emotion felt during the acquisition.Labelled data can be then used to train the ML system, generating a ML model able to classify the input data.Once the ML model has been obtained, new unlabelled data can be fed to the ML model to obtain the predicted emotion/class.To evaluate the trained model, it is a good practice to reserve a part of the labelled data outside from the training stage.These data can then be used to evaluate the final model predictions using suitable performance metrics (e.g.accuracy).However, a standard hypothesis of the traditional ML methods states that all the available data, no matter if involved in the training process or not, come from the same probability distribution.Due to the characteristics of the EEG data, this assumption results not always verified in the EEG signal.Indeed, the EEG signals acquired from a subject can be strongly different from the one acquired from another subject, even under the same conditions Im (2018).This can also happen for EEG signals acquired from the same subject in different times/sessions, leading to loss generalisation performances in cross-subject/session problems.In the current literature, this problem was initially addressed considering the availability of further unlabelled data belonging to the target subject/session which can help the training of the ML model (transductive learning approaches).However, these methods do not make any consideration about the data distributions.In fact, the training EEG data can be sensibly different in terms of probability distribution(s) from the data used outside the training stage.In ML literature, this can be viewed an instance of the Dataset Shift problem Quinonero-Candela et al. (2008).In a nutshell, Dataset Shift arises when the standard ML assumption is not verified, so the distribution of the training data differs from the data distribution used outside of the training stage.The idea that the training data come from different probability distribution(s) respect to the data used outside of the training stage is the main hypothesis of the transfer learning approaches.</p>
<p>In the last years, several architectures and methods have been proposed to address the dataset shift problem following the base assumptions of transfer learning, and different categorizations of the proposed methods have been reported Pan and Yang (2009); Ganin and Lempitsky (2015).One of the first and most important review on Transfer Learning methods was proposed in Pan and Yang (2009), however several new strategies (e.g., Domain Generalization-based works) have been proposed in the following years.</p>
<p>Papers selection method</p>
<p>The present literature review took into account the guidelines for systematic literature reviews presented by Kitchenham (Kitchenham (2004)), covering also the use of PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-Analyses) recommendations in order to transparently report the document extraction process (Liberati et al. (2009)).The survey was conducted covering the period between January 2010 to March 2022, using the following databases: Scopus, IEEE (Institute of Electrical and Electronics Engineers), Xplore, and PubMed.</p>
<p>In accordance with PRISMA's recommendations, the pipeline consists in four successive steps: 'Identification', 'Screening', 'Eligibility' and, finally, 'Inclusion', which considerably narrowed down the amount of surveyed work.For the initial identification of the articles, the following query was used in all pre-dicted data sources, taking into account titles and abstracts: EEG AND (Emotion OR Preference) AND ("Domain Adaptation" OR "Domain Generalisation" OR "Transfer Learning" OR "Adversarial" OR "Transfer" OR "Cross Session" OR "Cross Subject" OR "Cross Gender" OR " Non-stationary EEG").</p>
<p>From the first phase, 418 articles were collected.Then, as a first prescreening process, the following criteria are used to exclude papers from the review: duplicated articles, not peer-reviewed articles, and not written in English articles.For all articles that survived the screening stage, a careful examination of the full text was carried out.In a conclusive screening, the following papers were excluded: (a) all articles in which the problem of generalisability was not explicitly stated as a peculiar topic, (b) studies in which a cross-subject/session validation strategy was not clearly envisaged, (c) studies oriented towards a 'multimodal fusion', i.e. aimed at corroborating the EEG signal-based classification with other biosignals, (d) studies not specifically focusing on emotion recognition.Thus, 75 papers survived and were included in the review analysis.The complete flow diagram of the systematic review process using the PRISMA approach is presented in Fig. 3.</p>
<p>Results</p>
<p>In this paper, a categorisation of the reviewed articles with respect ML methods which do not satisfy the standard ML hypothesis is proposed (see Figure 4).Among all the reviewed papers, a subset of them leveraging on the classical transductive learning approaches, i.e. considering a set of unlabelled data coming from the target subject/session in the training stage, is isolated.On the other side, the papers dealing with the cross-subject/session problem as an instance of the dataset shift problem were considered.These methods are known in literature as transfer learning methods, which can be further divided in:</p>
<p>• Unsupervised and Semisupervised Domain Adaptation methods: they consider both the data coming from different subjects/sessions and unlabelled data coming from a target subject/session during the training stage.Therefore, they can be considered as an intersection between the transductive and transfer Learning methods;</p>
<p>• Supervised Domain Adaptation methods: these methods rely on the hypothesis that both labelled and unlabelled data from the target subject/session are available during the training stage;</p>
<p>• Domain Generalization methods: in these methods data from several probability distributions are available and can be used during the training, but no data from the target subject/session is used during the training stage.</p>
<p>On the basis of the above categorization shown in Fig. 4, in Tab. 1 all papers included in the review were reported, indicating if belonging to the proposed taxonomy or to classical ML methods.Moreover, for each research study several information is presented, such as the type of generalisation (cross-subject, cross-session, or cross-device), the EEG dataset, the adopted classifier (whether proposed as a personal contribution or adopted from the literature), and the validation strategy.Studies in which the description of the experimental setup was not sufficiently clear, especially in terms of validation strategies, were voluntarily omitted from the table for reproducibility issues.</p>
<p>In the following of this section, the reviewed papers are discussed in according with the Tab. 1.</p>
<p>Classical machine learning approaches</p>
<p>A model trained on a set of EEG data acquired from a given subject at a specific time (or during a specific session) could not work as expected in classifying EEG signal acquired from a different subject or from the same subject at different times.In other words, the model has poor generalization performance.To deal with this problem, several solution based on Machine Learning approach have been proposed over the years.The most common approaches proposed proper strategy of feature transformations or feature selection.The former wants to be transformations of the data able to hold only the most useful information with the hope that these are shared between all the subjects, while the latter are methods to select only useful information from the input signals without changing it.The feature extraction/selection is usually one of the first step of a machine learning pipeline, where the training data are transformed before being fed to the training stage of a machine learning model.These methods adopted the classical machine learning framework, that is that only the training data are available during the training stage, without any knowledge of the effective data on which the model will be effectively used.This can be viewed as a consequence of the the starting hypothesis of the traditional ML methods stating that all the available data, no matter if used in the training process or not, come from the same probability distribution.Under this hypothesis, the training data are enough to generalise over all the possible data.</p>
<p>The underlying hypothesis is that a proper EEG data transformation is enough to allow a ML model to generalise well, independently from the fact the data belongs to the same subject/session used during the training or not.Going deeper, in a ML problem on EEG data the feature extraction and selection process can be made considering two different aspects: i) the EEG signal or ii) the electrodes.In the first case, a proper transformation or selection strategy for the EEG signal is made.The reviewed literature proposed different works that analyse if several known feature extraction methods are suitable to generalise across several datasets Rayatdoost and Soleymani (2018); Li et al. (2018b).In particular, in Rayatdoost and Soleymani (2018) the authors investigated the robustness of emotion recognition methods across different experimental conditions, subjects and datasets.</p>
<p>In Yang et al. (2019); Jiang et al. (2019a) Sequential Backward Selection (SBS) was applied to find a good set of features that generalise across different subjects.To find the best subset of features, SBS decreases the number of features in an iterative way measuring, at each step, the obtained accuracy on a given classifier (SVM in Yang et al. (2019), Decision Trees in Jiang et al. (2019a)).SBS method is adopted to exploit the significant differences between the classes.A leave-one-subject-out verification strategy was employed on DEAP and SEED datasets in Yang et al. (2019), while Jiang et al. (2019a) validates its results on DEAP and self-produced data.</p>
<p>In Cai et al. (2019); Yin et al. (2017) a family of Transferable Recursive Feature Elimination (TRFE) methods are used to make a set of EEG features steadily distributed among all the training subjects, therefore removing the EEG features resulting not generic for all users.The proposed feature selector is validated using SVMs as classifiers on DEAP dataset both in within-subject and cross-subject ways.In Zhang and Yin (2020) Cross-subject Recursive Feature Elimination (C-RFE) is exploited to rank the features in order of importance with the aim of removing the features giving a low contribution to the classification.The method is validated on EEG data fed to SVMs.</p>
<p>In Liu et al. (2020) an evolution of the well-known Differential Entropy features is proposed.The Dynamic Differential Entropy (DDE) features take into account also the time-domain instead of only the frequency domain extracted by the classical DE.The goal is to maximise the difference between classes minimising at the same time the difference within classes, learning a set of common characteristics across different subjects.</p>
<p>In Li et al. (2019c) a latent representation of the EEG data from SEED and DEAP is learned through a Variational Auto Encoder (VAE) and then classified using a LSTM.VAEs start from the hypothesis that all the data are generated by a random process involving latent variables.A VAE is usually trained to encode the input data into a latent representation and then mapping it to a reconstructed version of the data.Li et al. (2019c) hypothesises that there exists learnable intrinsic features shared across several subjects EEG signals taking part in emotional processes.These intrinsic features can be encoded by the VAE latent representations.The power of VAE to represent latent EEG factors is also investigated in Li et al. (2020c), together with classical Auto-Encoders (AEs) and Restricted Boltzmann Machines (RBMs).Final classification is made with an LSTM and the generalisation performances are evaluated in LOSO mode on DEAP and SEED dataset.</p>
<p>In Pandey and Seeja (2019) the cross-subject problem is tackled using Variational Mode Decomposition (VMD) as feature extraction technique.The system is validated in an hold-out way without any intersections between subjects' data in the training and the test set using a DNN as emotions classifier.Despite the encouraging results reported, no reason about why the proposed system works well in a cross-subject approach seems to be provided.In Chen et al. (2021c); Fernandez et al. (2021); Arevalillo-Herráez et al. (2019) is shown that the normalisation scheme used to preprocess the EEG data can affect the cross-subject performances.</p>
<p>In Chen et al. (2021c) several normalisation methods were applied following two different schemes: i) All-subjects, where the whole dataset was normalised, ii) Single-subject, where the normalisation is made individually for each subject.The All-subject schema is the most common method used to mitigate the impact of each data values on the entire dataset.Single-subject, instead, consider each subject individually, applying normalisation on each subject.The authors empirically shown on SEED dataset that Single-subject Z-score performs better in a EEG emotion recognition problem respect to other normalisation schemes as min-max normalisation.On the same data, in Fernandez et al. (2021) the authors apply single-subject Z − score normalisation after each neural network layer (Stratified Normalisation).</p>
<p>In Arevalillo-Herráez et al. (2019) a simple transformation of the original data is proposed.It consists in using binary features having 0 and 1 as components values based on the fact that the feature is lower or higher than the median feature value.This leads to a more effective reduction of the subjectdependent part of the EEG signal.</p>
<p>Instead, considering the electrodes in place of the EEG signals, different channels selection strategies searching for a robust set of channels across the subjects was proposed in Gupta et al. (2018); Zhang et al. (2016).To achieve EEG-based cross-session emotion recognition, in Peng et al. (2021) the author propose a way to learn the importance of the EEG channels and features to separate discriminative features from the noisy and redundant ones.The proposed strategy is evaluated on pairs of a-priori chosen sessions.</p>
<p>In Tian et al. (2021) a neural network to classify emotion by EEG signals is proposed.The proposed model introduces a channel-attention layer to select the most important channels for a set of emotions.Notably, the different personalities across the subjects are taken into account, grouping together the subjects having similar personalities.Indeed, a different model for each group was trained.Validation is made on the ASCERTAIN dataset.This dataset results particularly suited for this task, since it links personality and emotional state with physiological reactions.</p>
<p>In other works, the structure of the electrodes is taken into account and modelled as a graph.Graph representation methodology resulted effective to model structured data achieving significant performance in many applications, included EEG emotion signal processing Song et al. (2018).GNNs are useful to retain the spatial structure of the electrodes disposition.Usually, the graph structure is fixed and given a priori following the spatial disposition of the electrodes on the scalp.Instead, Dynamical Graph Convolutional Neural Networks (DGCNN, Song et al. ( 2018)) and Self-Organized Graph Neural Network (SOGNN, Li et al. (2021a)) organises the graph structure leveraging on the input brain signals rather than on a predefined graph structure.The resulting graph can be processed by the graph convolutional layers to extract the more suitable features for emotion recognition.The features obtained are also tested in cross-subject scenarios.</p>
<p>Transductive methods</p>
<p>Transductive methods Vapnik (2006) start from the hypothesis that the unlabeled test data are available in the training stage (no assumption about the distribution of the data, differently from the DA methods).The idea is that in several problems there is only a specific set of data (usually corresponding to the test set) to classify, and it is available at training time.Note that in standard ML approach the goal is to generalize on new unseen data, by contrast in transductive learning the goal is to correctly classify the test set only.The Transductive SVM (TSVM) is an example of a transductive method.Described in Joachims et al. (1999), differently from classical SVMs that leverages only on labelled data, TSVMs exploit also unlabelled test data to find the best decision boundary between the classes.In other words, the target data is viewed as an additional set of information about the data.One of the main drawback of TSVM is that an estimation of the number of elements for each class in the test set is needed.Progressive TSVM (PTSVM, Chen et al. (2003)) tries to resolve this problem progressively labeling the unlabeled data during the training instead of classifying it as a whole at the same time.</p>
<p>The only study collected in this review using explicitly transdutive methods is Yang et al. (2020), where the PTSVM generalisation power across several sessions of EEG data acquired from different subjects is validated.</p>
<p>Transfer Learning methods</p>
<p>Transfer Learning methods are based on the concepts of Domain and Task.Following the survey of Pan et al.Pan and Yang (2009), a Domain can be defined as a set D = {F, P (X)} where F is a feature space and P (X) is the marginal probability distribution of a specific dataset X = {x 1 , x 2 , . . ., x n } ∈ F .Instead, a Task is a set T = {L, f } where L is a label space and f is a predictive function f usually learned by the data.For instance, f (x i ) can be used to assign the predicted label to x i ∈ X.Therefore, f can be equivalently viewed as the probability of a label y given a data x, i.e. p(y ∈ L|x ∈ X).</p>
<p>A Dataset of n points can be defined as a set S = {(x i ∈ X, y i ∈ L)} n i=1 .Transfer learning wants to exploit the knowledge of a domain D A on a task T A to resolve the same or another task T B on another domain D B .By the definition of domain, it is straightforward that two domains D A = {F A , P (X A )} and D B = {F B , P (X B )} can be considered different if they differ in the feature spaces or in the marginal probability distributions.Obviously, the same holds for two Tasks T A = {L A , f A } and T B = {L B , f B }.More in details, the following cases can happen:</p>
<ol>
<li>D A = D B and T A = T B : since the Tasks and the Domains are the same, this can be considered a classical Machine Learning Problem.</li>
</ol>
<p>D
A ̸ = D B : F A ̸ = F B or F A = F B and P (X A ) ̸ = P (X B ) 3. T A ̸ = T B : L A ̸ = L B or f A ̸ = f B .
The non-stationarity of the EEG signals between different subjects in an emotion classification problem can be viewed as a multi-domain problem where the data belonging to each subject are sampled from different Domains.Usually, given a pair of two different subjects A and B, a common features space is assumed to be shared by the two domains (the EEG data representation), the conditional data distributions P (L A |X A ) = P (L B |X B ) are assumed to be the same while the marginal probability distributions are different on the available data, i.e.P (X A ) = P (X B ). Therefore, minimising the non-stationarity of EEG signal should be viewed as reducing a discrepancy measure between several Domains.</p>
<p>In the current literature, transfer learning strategies can be divided in three families:</p>
<p>• Unsupervised/semisupervised Domain Adaptation (DA) methods,</p>
<p>• Supervised DA Methods, also known as PreTraining, (PT) methods,</p>
<p>• Domain Generalization (DG) methods.</p>
<p>These families differ mainly in which data are processed during the learning stage.DA methods start from the hypothesis that data sampled from two different domains are available, called Source Domain and Target Domain respectively.The main difference between them is that, while a complete dataset S Source = {(x i , y i )} n i=1 can be sampled from the Source domain, only feature data points X T arget = {x j } m j=1 ∈ F T arget can be sampled from the Target one, without knowledge (unsupervised DA) or minimal knowledge (semi-supervised DA) of their real labels.Unsupervised DA methods can be viewed as transductive machine learning methods with the further hypothesis that the data come from two different distributions.Instead, PT methods work adapting a model already trained on a known (Source) Domain to go toward a new (Target) domain.Since both features X and labels y of the new domain are known during the adapting stage, PT strategies are also known as supervised DA methods.In contrast, DG methods rely on the hypothesis that d ≥ 2 source domains together with their labeled samples are available, while any data from the Target domain is unknown.</p>
<p>DA and DG methods are getting a great deal of attention in the scientific literature in different contexts (e.g.image classification and voice recognition), and several proposals have been made until now.One trend of the literature is to adapt DA/DG methods originally proposed for a context to another one.For example, in Zhou et al. (2020b) methods to adapt DA strategies for image classification to EEG emotion classification are proposed.However, each context has its characteristics and peculiarities, making the transfer of a DA method from a task to another task not immediate.Several attempts were made by the scientific community to adapt well-established DA/DG methods in tasks involving the processing of EEG signals in the emotion recognition field.</p>
<p>Domain Adaptation (DA) methods</p>
<p>Several DA methods relied on minimising the discrepance measures between the Source and the Target domain.In Ganin and Lempitsky (2015) these methods are categorised into shallow and deep DA.As will be explained in the section (Proposed Taxonomy), an extension of this taxonomy is proposed in this paper, by adding the Source selection methods:</p>
<p>• Source selection: a subset of DA methods take into account that not all the training data can effectively be useful for the target space.Therefore, a selection of the training data is made, in order to avoid negative transfer.Several of these methods are also known as Instance weighting Jiang (2008), since they assign weights to the data; they can be made as a kind of preprocessing for the other methods;</p>
<p>• Shallow DA: the data representation is given a-priori.Only a mapping between the Source and Target representations is learned, without affecting the starting data representation;</p>
<p>• Deep DA: the data representation is learned as part of the DA strategy.</p>
<p>In the following part of this section, the studies according the above discussed ML approaches are reported.</p>
<p>Source selection</p>
<p>Source selection methods take into account that not all the training data can effectively be useful for the target space.In Zhang et al. (2019b) TrAdaBoost Dai et al. (2007) is used to score the source EEG data so that they does not negatively influence the training process.In other words, a small amount of labeled target data helps to vote on the usefulness of each of the available source data instance.As initial step, only the source subjects closest to the target one are selected according to the MMD similarity and fed as auxiliary data to TrAdaBoost.This family of methods can be also used as initial step of another DA method, for example in Lin et al. (2017); Zhou et al. (2020a) the similarity between source and target EEG data is measured using the Pearson Correlation Coefficient and the Average Frechet Distance respectively.In particular, in Zhou et al. (2020a) only the closer EEG source data to the target data are fed to TCA together with the target one.Finally, the classification step is made by an Echo State Network (ESN, Ozturk et al. (2007)).In Hua et al. (2021), Neighborhood Component Analysis (NCA, Kenneth et al. (2020)) is employed to learn the Mahalanobis distance between data and linearly project them into a subspace such that the classification accuracy is maximized and to reduce the dimensionality of the EEG features.The obtained features are then used with Geodesic flow kernel for Unsupervised Domain Adaptation Gong et al. (2012).In Wang et al. (2021a) (DMATN) data belonging to the existing subjects are divided into several sub-source domains.Then, a set of sub-source are chosen as the most relevant with the target data.The proposed architecture combines together DAN and DANN to learn representation domain invariant representation.</p>
<p>Shallow DA methods</p>
<p>Different strategies were proposed in literature, usually relied on one of following alternatives:</p>
<p>• Target Space-Based (TSB): searching for a good transformation which directly maps Source data S to the Target data T space (S → T );</p>
<p>• Shared Space-Based (SSB): searching for a good transformation which maps Source S and Target T data in a new shared space where the discrepancy between S and T is minimal (S, T → C).</p>
<p>Once all the data are projected in a common space having the marginal distributions of the Domains close enough each others, common classification methods can be used to emotion recognition.In Target space-based papers, Fernando et al. (2013) tried to align the source space toward the target one.Rather than using the data in their original feature spaces, the authors used PCA for a more robust and compact data representation.More specifically, two PCA projection matrices Z S and Z T are computed for the Source and the Target domain respectively.Therefore, a transformation matrix M able to align the source space to the target one is searched by an optimisation problem, i.e.</p>
<p>arg min
M ||Z S M − Z T || 2 F
This problem has a closed form solution in the form M = Z T S Z T .Indeed, a similarity between the projected data can be computed.</p>
<p>In Chai et al. (2017) ASFM is adopted for EEG-based Emotion Recognition.However, as a large part of the domain adaptation strategies, Chai et al. (2017) uses all the source subject as a whole as they belong to the same domain.In other words, the data belonging to different training subjects are viewed as an unique subject.Differently, in Chai et al. (2018) (Multi-Subject Subspace Alignment, MSSA) the ASFM strategy is applied to each source subject individually, then the projected data are fed to different for-subject classifiers.</p>
<p>Other data transformations have been investigated in the DA scenario for EEG emotion recognition, such as Robust Principal Component Analysis Wright et al. (2009) in Lin (2019).RCA decomposes a set X of data as X = L + S, where L and S are two superimposed matrices: the former is a low-rank matrix, the latter a sparse matrix.These matrices are computed resolving the following optimisation problem: min  2012)) is adapted for EEG emotion recognition task to generalise across different subjects.In a nutshell, STM maps source data to target data by an affine transformation.The solution of the proposed problem is in closed form, so it can be easily computed.Few labeled target data are used to make a source data selection, so starting from the hypothesis that a small amount of labeled data are available.On the other side, ins Shared space-based the Maximum Mean Discrepancy (MMD, Gretton et al. (2006)) is one of the currectly most used discrepancy measure in DA/DG strategies.In the original study, MMD is proposed to test if two probability distributions p and q are different or not.Formally, the authors show that in a Reduced Kernel Hilbert Space (RKHS) a discrepancy measure between the two distributions can be defined as
M M D(p, q) = ||E X S ∼p (ϕ(X S )) − E X T ∼q (ϕ(X T ))|| 2 H
where ϕ(•) is an appropriate feature mapping.In Gretton et al. (2006) is proven that, in a RKHS, M M D(p, q) is 0 if and only if the two distributions p and q are the same.MMD can be empirical estimated as the difference between the averages of two data sampled from the two distributions projected in a RKHS.Therefore, considering X S and X T as two sets sampled from the Source and the Target domain respectively, empirical M M D(X S , X T ) can be expressed as:
M M D(X S , X T ) = || 1 |X S | |X S | i=1 ϕ(x (i) S ) − 1 |X T | |X T | i=1 ϕ(x (i) T )|| 2 H where x (i) S and x (i)
T are elements of X S and X T respectively.In other words, having two samples from two different distributions, the distance between the two distributions can be estimate through the distance between two means of the samples projected in a RKHS.</p>
<p>Transfer Component Analysis (TCA, Pan et al. (2010)) is one of the most used MMD-based DA method.In the original work, two different TCA versions were proposed: i) an unsupervised version, where a transformation of the data is found such that the data variance is maximally preserved reducing, at the same time, the MMD distance of the domains distributions, and ii) a supervised one, where the data dependence with the training labels is taken into account.</p>
<p>An evaluation of the unsupervised TCA on EEG data for emotion recognition was made in Zheng et al. (2015).Instead of using all the available EEG data, a random selection of a subset of samples from Source domain data was made during the evaluation strategy, letting out a subject as Target domain.In Xue et al. (2020) TCA is tested on SEED dataset trying several desired dimensions for the feature space.Instead, in He et al. (2022b) TCA is tested on self-made EEG data.</p>
<p>In Long et al. (2013) Transfer Sparse Coding (TSC) the MMD was exploited to find a sparse representation of image data sampled from different distribution.Sparse code representations are well-known data approximation obtained as linear combinations of elements in a set of basis functions.In a nutshell, a sparse coding method searches for a representative over-complete set of basis functions (a dictionary) together with an encoding that best represent the data.In its simplest form, the sparse coding problem can be expressed as min
B,S ||X − BS|| 2 F + λ n i=1 |s i |
where X ∈ R m×n is a matrix containing n data points to approximate and B ∈ R m×k and S ∈ R k×n are the dictionary matrix and the encoding matrix respectively, where k &gt; m to ensure the over-completeness.The sparsity is induced by the second equation term on the coefficient matrix columns s i and regulated through the hyperparameter λ ∈ R.However, if X is composed of data sampled from two different Domains (e.g., X = [X S |X T ]) the above formalisation does not take into account the differences between the marginal distributions.To deal with this problem, Long et al. (2013) proposed to add a further regularisation term to the objective function that takes into account the MMD distance between the different Domains of the input data.</p>
<p>In Ni et al. (2021), similarly, a common dictionary between source and target domain is computed, but preserving the local information between samples and the discriminative knowledge between the domains exploiting the PCA and Fisher criteria Fisher (1992).This work required a little set of labelled data from the target domain, falling in the semi-supervised DA approaches.</p>
<p>While it is not specifically designed for Domain Adaptation, Kernel-PCA (KPCA, Schölkopf et al. (1997)) is often used in comparisons with several DA methods.In a nutshell, KPCA uses the kernel trick to project the data into a kernel space and then applying the PCA on the projected data.A comparison between Kernel-PCA and TCA for EEG emotion recognition is reported in Zheng et al. (2015).In Chai et al. (2016) (SAAE), a features transformation ϕ(•) is computed through Kernel-PCA maximising the embedded data variance.Before the transformation, an autoencoder trained on data from both the Source and the Target Domains was employed to preprocess the data.In Zheng and Lu (2016) TCA, KPCA, TSVM, and TPT are evaluated on the EEG-based emotional SEED dataset in a Leave-On-Subject-Out approach, while in Lan et al. ( 2018) similar methods are tested on SEED and DEAP also for Cross-Dataset generalisation.</p>
<p>Deep DA methods</p>
<p>In deep DA approaches, a feature data representation learning is embedded in the DA method.Instead of searching for a transformation of features given a priori, this is done by changing the feature space representation.</p>
<p>Deep DA methods can be further divided in:</p>
<p>• Common Shared Space (CSS) methods: Source and Target are projected in a new shared space</p>
<p>• Shared+Specific Spaces (SSS) methods: Source and Target are first projected in a unique shared space, then auxiliary more specific spaces are used.</p>
<p>As can be seen in Table 2, CSS represents the category of studies exhibiting the best performance in terms of accuracy, at least in four of the cases considered.In Tzeng et al. (2014) (Deep Domain Confusion, DDC) two identical networks are trained together, the former classifying data from the Source Domain, the latter adapting the distance between Source and Target domains using Target feature data.The combination of both the classification performance and the MMD is used as final loss.Zhang et al. (2019a) uses DDC for cross-subject EEG emotion recognition.The networks' architectures used are of type residual CNNs He et al. (2016).To be fed to the CNNs, the EEG inputs are firstly transformed into Electrodefrequency Distribution Maps (EFDMs, Wang et al. (2020)).Results are validated with a Leave-One-Subject out CV approach.The authors of Long et al. (2015) proposed a DA framework considering the general structure of a Convolutional Neural Network (CNN), that is usually composed by a sequence of convolutional layers followed by a fully-connected ones.The authors hypothesise that in a deep neural network the transition from general to the specific task features grows with the increasing of the network depth.Indeed, in a CNN, while the initial convolutional layers learn general features, the final fully-connected ones learn domain specific features that are not transferable.Their proposed model (Deep Adaptation Network, DAN) deeply adapt the final fully connected layers minimising the Multi-Kernel Maximum Mean Discrepancies (MK-MMD, Zhu et al. (2017)), a multiple kernel variant of MMD used as distribution discrepancy measurement.DAN was evaluated in EEG emotion recognition on SEED and SEED-IV in Li et al. (2018a).In Kuang et al. (2021) the proposed Multi-Spatial Domain Adaptation Network (MSDAN) aligns source and target domain considering the spatial relationships between the electrodes.This is done by using Graph Convolutional Layers and exploiting MMD distance in the resulting graph space.Differently from other works, Kuang et al. (2021) uses data acquired in a Virtual Reality (VR) environment to generate stimuli, and the cross device problem is taken into account.One of the most used deep DA strategies is the Domain Adversarial Learning, proposed in Ganin and Lempitsky (2015); Ajakan et al. (2014); Ganin et al. (2016).The authors proposed an embedded problem formulation considering both the desired task and the discrepancy between the Source and the Target domain.The basic idea is to make the data distributions indistinguishable for an ad-hoc domain classifier.This can be made by a deep neural network model (Domain Adversarial Neural Network, DANN) that, for each input, predicts both the corresponding class and the belonging domain.In a nutshell, DANN is composed of three main components: a feature extractor, a label predictor, and a domain classifier.Therefore, a learning process searches for a feature mapping maximising the class prediction performances and, at the same time, maximising the domain classification loss to make the feature distributions as similar as possible.DANN is evaluated in EEG emotion recognition task in Jin et al. (2017) on SEED.In Li et al. (2018d) BiDANN, a DANN variation is adopted for EEG emotion recognition, but considering the differences between the brain hemispheres, is proposed.In a nutshell, EEG data from the two hemispheres are processed separately: two different features mapping together with a domain discriminator are learned for the brain hemispheres, instead of only one feature mapping as in the original DANN formulation.Difference between the hemispheres in a DA approach is not dealt only by BiDANN; for instance, BiHDM Li et al. (2018e, 2020d uses two different RNN to code the data belonging to the two hemispheres, and also in this case a domain discriminator is used to mix up the features of the Source and the Target domain.In He et al. (2022a) the authors propose a new DA method which is framed in the context of deep adversarial learning approaches.In particular a temporal convolutional network is used as encoder.Interestingly, the method is successfully evaluated in both cross-subject and cross-dataset.In Ye et al. (2021); Zhong et al. (2020) domain adversarial approaches are used together with Graph Neural Networks (GNN, Zhou et al. (2020b)) as feature extractor.In particular, Ye et al. (2021) leverages on an attention mechanism Niu et al. (2021) focusing the learning stage on the alignment of the more changeling areas of the feature space.Performances are evaluated on SEED dataset.Instead, Zhong et al. (2020) proposes a node-wise domain adversarial training (NodeDAT) method to regularise the GNN output for better subject-independent performances.In EEG literature, Domain adversarial learning is widely used in several other studies for EEG data recognition, for example in Tzeng et al. (2017); Bao et al. (2020); Li et al. (2019d,a); Furukawa et al. (2021); Hwang et al. (2020b).In particular, in Li et al. (2019d) possible differences between several brain regions are also taken into account with a proposed attention module.In Du et al. (2020) (ATtention-based LSTM with Domain Discriminator, ATDD-LSTM) a domain discriminator in terms of LSTMs is presented to reduce the discrepance between the distributions.An attention-based encoder-decoder focuses on emotion-related helping the final classification probability estimation.An interesting adversarial approach was also investigated in Wang et al. (2021c).The proposed work exploits the Covariance Matrices between EEG data and Riemannian distances Barbaresco (2008).The work proposed a new kind of Neural Network (daSPDnet) able to retain the intrinsic geometry information of the data.However, differently from the typical DA approach, a little set of labelled data belonging to the Target domain are required during the training process, resulting as semi-supervised DA method.A similar approach, also requiring a few of labelled target data, was proposed in Li et al. (2021c).Multi-source Domain Transfer Discriminative Dictionary Learning modeling (MDTDDL) is developed in Gu et al. (2022); the aim is to learn a joint subspace between source and target domains exploiting dictionary learning Mairal et al. (2008) methods.DEEP and SEED are evaluated both in Cross-Subject and Cross-Session mode.In Tzeng et al. (2017) Adversarial Discriminative Domain Adaptation (ADDA), a strategy to tackle the DA on an image classification task, was proposed.Differently from DANN, the ADDA basic idea consisted in building two different functions for the Source and the Target domains represented with two different encoders E S and E T , respectively.E S is trained together with a classifier C using labelled data from the Source domain.Then, through an adversarial learning procedure, E T is trained to map the Target domain data in the space of E S outputs.In this space, target data can be classified by C. A similar idea was adapted in EEG emotion classification domain in Luo et al. (2018) (Wasserstein GAN Domain Adaptation, WGANDA), mixing together a pre-training stage and an adversarial training stage.More in detail, two generators for the source and target domain respectively are pre-trained to output two feature vectors of the same size.These vectors are considered as belonging to a shared feature space.An adversarial training step based on minimising the Wasserstein distance tunes the parameters of the generators such that the outputs match more closely as possible each other.The combined outputs are then used as input for an output classifier network.Inspired by the MMD optimization made in Chai et al. (2016), in Bao et al. (2020)(TDANN) a two stage DA method is proposed.In the first stage, MMD is minimized training a CNN equipped with adaBN Li et al. (2018c).To be fed to the CNN and to preserve spatial information, the EEG input signals are transformed into images Bashivan et al. (2015); Hwang et al. (2020a).In the second stage, a domain discriminator is used to further reduce the distance between the source and the target distributions.The method was evaluated in a leave-one-subject out cross validation framework.One of the main issue of the DANN networks is that no label is considered during the adversarial learning process, therefore the relationship between target data and the task-specific decision boundary during the distributions alignment is not taken into account.A DA method can confuse the distributions of the two domains by reducing the distance between them, resulting in a simple mixing of the samples of the two domains, leading the categories within each domain to not be distinguishable.Indeed, in DANN the decision boundary inside each domain is ignored.In Saito et al. (2018) (Maximum Classifier Discrepancy, MCD), instead, the labels of the Source domain data are considered, helping to search a good task-specific decision boundaries between the classes.This is achieved by using different classifiers fed with the same inputs and evaluating the discrepancy.More in detail, two classifier C 1 and C 2 with the same characteristics are fed with input of feature generator G. G can be fed with data x coming from the source or the target domain.The output of C 1 and C 2 are the labels of the input x returned by G. Before the training step, C 1 and C 2 start from different initial state, rising two different classifiers after the training.How much the two classifiers disagree on their predictions on the same input is defined discrepancy by the authors.Indeed, the generator G is trained to minimise the discrepancy (that is, project source and target data in the same space), while C 1 and C 2 are trained to maximise the discrepancy (so that the two classification boundaries are far from each other).The learned generator G will be able to relocate the target domain data in the source space, but taking into account its most probable belonging class.Task-Specific Domain Adversarial Neural Network (T-DANN, Ding et al. (2021)) is an MCD similar model proposed for EEG emotion recognition.T-DANN adapts the conditional distribution between domains and, at the same time, adapts classification boundaries between classes exploiting MCD in conjunction with a domain discriminator.Instead, Ning et al. (2021) deal with the excessive allignment problem exploiting a few-shot learning and attention mechanism approach.From a different point of view, Wang et al. (2021b) used Siamese Networks Koch et al. (2015) for evaluating the similarity between samples belonging to different domains.Siamese networks were originally proposed to to determine whether two inputs belong to the same category or not.In Wang et al. (2021b) the Siamese framework is converted to handle different domains.However, this method require a few of labelled data belonging to the Target domain.In Tao and Dan (2021) the authors propose a DA approach for EEGbased emotion recognition based on a multi-source co-adaptation framework (MACI).The proposed framework mainly takes advantage of correlation knowledge among several sources and features to build a proper objective function.The proposed method is compared with both standard (shallow) DA approaches and deep (CNN-based) approaches.Cross-subjects and cross-datasets evaluations are performed.Computational costs is a critical point of the proposed framework.The authors of Luo et al. (2021) propose a novel approach which attempts to unify in an unique optimisation problem two standard DA approaches, instance reweighting (that we refer as source selection) and feature matching.This novel approach is named Progressive Low-Rank Subspace Alignment (PLRSA).In particular, instance reweighting is implemented by minimizing the Maximum Mean Discrepancy (MMD) distance and the TrAdaBoost algorithm, and feature matching by the Transfer Component Analysis (TCA).Importantly, a tiny amount of labeled target data is used to better exploit the source auxiliary data.The proposed method is evaluated in a both cross-subjects and cross-sessions scenario.The method is compared with five state-of-the-art DA methods.The results seem promising, however the time complexity is a little more expensive than related state-of-the-art methods.</p>
<p>Although several studies start from the hypothesis that a shared feature space is enough for DA, Shared+Specific Space (SSS) methods go in different direction, believing that a single shared classifier built in a shared space still has poor performance for the never seen sessions/subjects.Notably, in these studies each subject/session available is considered as a single domain, and not as a whole.Hypothetically, EEG data representations can be splitted into shared emotional components, universal to all the subjects, and private components, specific to each subject.Leveraging on this hypothesis, Zhao et al. (2021) builds a shared encoder and private encoders for each source subject data to capture the subject-invariant emotional representations and private components, respectively.The obtained encoders are then used to build several emotion classifiers.Finally, a new subject classifier using few data is built.All these classifier are built exploiting the shared encoder.A classifier fusion strategy is then applied to obtain the final classification result.However, the proposed framework requires few labelled target data, falling in the unsupervised DA category.MEERNet Chen et al. (2021b) considers different classifiers for each different domain (subject or session), preceded by a feature extractor shared by all the domains.Final classification is made averaging between domain-specific classifiers.Similarly, Luo and Lu (2021) proposed a framework composed of a common feature extractor to map all the domains in a common subspace, a main task classifier or regressor, and private discriminators for each domain.The training is made reducing the Wasserstein distance between the marginal distribution of each source domain and target one in an adversarial way.In Chen et al. (2021a) the authors propose a Multi Source-Marginal Distribution Adaptation (MS-MDA) algorithm for EEG emotion recognition.Also in this case, the key idea is that the final response is obtained by the average of the responses of target-source specific classifiers, preceded by a common feature extractor.Notably, the authors explore the impact of different types of data normalisation on the performance of the proposed model.MS-MDA is compared with several standard DA methods and it has very promising results.Similarly, the authors of Cao et al. (2021) propose Multi-Dource and Multi-Representation Adaptation (MSMRA), an approach with many similarities with respect MS-MDA algorithm Chen et al. (2021a).Both cross-subjects and cross-sessions evaluations are performed.</p>
<p>Supervised DA (PreTraining) methods</p>
<p>In the supervised Domain Adaptation category, four studies were included in the reviews.In Cimtay and Ekmekcioglu (2020) a pretrained version of Incep-tionResnetV2 Szegedy et al. (2017) is used as feature extractor for EEG data.The classification is made by a final network layer added to the InceptionRes-netV2 module.Instead, Pusarla et al. (2022) exploited DenseNet121 Huang et al. (2017) as pre-trained model to build a new architecture fed with EEG data transformed in spectrogram images.In Wang et al. (2020) a CNN model trained on different subjects and sessions taken from the SEED dataset is then re-trained on a small amount of data of a target subject taken from DEAP dataset to evaluate the cross-dataset emotion recognition performances.In Li et al. (2020a) several classifiers trained on different data belonging to different subjects and sessions are ensembled together obtaining a final classifier suitable both for cross-sessions and cross-subjects EEG emotion recognition.</p>
<p>Domain Generalization (DG) methods</p>
<p>Finally, differently from classical domain adaptation methods, in Domain Generalization data from several domains are available, but no data from the test domain is observed during the training stage.Differently from classical domain adaptation methods, data from several domains are available, but no data from the test domain is observed during the training stage Muandet et al. (2013).Methods can be divided as:</p>
<p>• shallow DG: a data transformation is given a priori;</p>
<p>• deep DG: the data rapresentation is learned as part of the DG strategy.</p>
<p>Shallow DG methods share the same principles of shollow DA ones, building a shared space between domains letting the input data representation unchanged.Domain Invariant Component Analysis (DICA) Muandet et al. (2013) searches for common features across several domains.Features data are transformed by a learned orthogonal transformation which minimizes the dissimilarity between a set of known domains preserving, at the same time, the relations between data features and their real labels.The authors also provided an unsupervised DICA version which did not take care of the class labels.</p>
<p>In Ghifary et al. (2016) Scatter Component Analysis (SCA) is proposed.The aim of the authors is to propose a method adapt both DG and DA requirements.SCA search for a data transformation where at the same time, i) the source and the target Domains are similar, ii) elements of the same class are similar, iii) elements of different classes are well separated and, iv) the variance of the whole data is maximised.This is made introducing Scatter, a measure closely related to MMD.In Ma et al. (2019), SCA and DICA are applied and evaluated on SEED dataset.</p>
<p>On the other side, in deep DG methods include the data representation as part of the generalization strategy.In Gonzalez et al. (2019) data from similar subjects are used to train the same classifier.The similarity between data is computed through a clustering algorithm.This subset of similar subjects is used to train a final CNN classifier.In Liu et al. (2021) a similar strategy is adopted, but for Domain Adaptation context.Hagad et al. (2021) join together BiDANN and Variational Autoencoder (VAE) obtaining a subject-invariant Bi-lateral Variational Domain Adversarial Neural Network (BiVDANN).VAEs are generative neural networks able to learn embedding of data constrained to a Gaussian distribution.As any classical autoencoder, a VAE is composed of an encoder network able to transforms data to an embedding space while a decoder network is able to reconstruct the original input from the embedding.In the proposed work, the learned features are further refined by domain adversarial training across different subjects to learn subject-independent features.Furthermore, to maximize dataset intercompatibility spectral topography data of the EEG signal are used as input.</p>
<p>The pie charts in Figure 5 show some statistics about the papers included in the survey.First of all, it is evident that almost three quarters of the studies surveyed (73.4 %) focus on a cross-subject mode of generalisation, while crosssession studies account for only 17 % and only 9 % operate a cross-dataset mode of generalisation.Graph b) shows the percentage distribution according to the proposed taxonomy.Looking at this graph, it is evident that the majority of generalisation studies are moving towards the use of Deep Domain Adaptation (CSS) (33.33 %), at the expense of more traditional approaches, which still retain 26.67 %.This is followed by Shallow DA (SSB) approaches (9.33 %), Deap DA (SSS) (8 %), Source Selection DA (6.67 %), Shallow DA (TSB) and Supervised DA (5.33 %), Deep DG (4 %) and finally Transductive (1.33 %).The pie chart in Figure 5.c) shows the number of times each EEG dataset is exploited in the reviewed literature.The mainly used datasets are SEED (45.8 %) and DEAP (27.5 %).This is followed by 8.3 % of studies that propose their own self-produced dataset, while of the other datasets available in the literature only SEED IV stands out (at 7.5 %), which is interesting in that it adopts a discrete space of four emotions for classification (happy, sad, fear and neutral).Each of the other datasets do not exceed 5 % (MAHNOB Soleymani et al. (2011) and DREAMER Katsigiannis and Ramzan (2017) (3.33 %), CMEED Zhao et al. (2018) (1.7 %), ASCERTAIN Subramanian et al. (2016), MDME Shenoy et al. (2006) and SDMN Lin et al. (2010) (0.8 %)).</p>
<p>Finally, Figure 5.d) offers an interesting statistic about the interest of the authors of the studies examined in the various perspectives of emotion representation.As already mentioned in section 1.3, the two dominant perspectives, and the only ones considered in the literature examined, are those based on categorical and dimensional models.More than 80 per cent of the works are based on a representation of emotions, and then their subsequent classification in terms of valence and arousal (and only in one case also dominance Wang et al. (2021c)).</p>
<p>Studies identified as best performers in terms of mean classification accuracy are proposed in Table 2.Only cross-subject studies were considered in this selection, being the statistically most significant percentage among all the generalisation studies surveyed.The ten best results were identified considering as many classification issues.Each issue is defined by considering the number and type of classes identified (binary and ternary on valence and arousal, quaternary on the two-dimensional valence-arousal plane, binary and quaternary on discrete dimensions) and the dataset adopted (considering three possibilities: DEAP, SEED, other).Only studies reporting both mean accuracy and standard deviation were included in the performance assessment.</p>
<p>Discussion</p>
<p>To date, no robust electroencephalographic patterns are recognized in scientific literature for correlating with emotional states.Some studies base their results on the asymmetry of scalp activations, but several theories based on statistical samples that are not yet particularly large still coexist Demaree et al. (2005); Coan and Allen (2003); Davidson (1984).</p>
<p>When aiming for a generalization goal in EEG-based Emotion Recognition, Transfer Learning methods are becoming more and more established in the literature.Domain Adaptation methods (Deep DA (CSB), Shallow DA (SSB), Source Selection DA, Deep DA (SSS), Shallow DA (TSB) and Supervised DA) exceed 60 % of the total surveyed studies and exhibit very high accuracy performances in the table of best performers (see Table 2).In particular, Deep DA (Common Shared Space) is used by five best performers studies.This could be also due to the current massive use of Deep DA (Common Shared Space) in the literature.Indeed, one third of the surveyed studies (Figure 5.d) belongs to this category.</p>
<p>However, a still substantial percentage of works (27.4 %) belongs to the Classical ML category.An emblematic case in this context is Li et al. (2021a), namely the best performer in the classification issue on SEED IV with four discrete classes.This is an interesting study based on a self-organized graph construction module.This solution can be considered as a peculiar implementation of the well established adaptive filters strategy, when the generalization goal is pursued by customising the network to the current input.Conversely, the DA strategies make the data from different domains more homogeneous by means of appropriate transformations.The different impact between DA and adaptive filters approaches can be better appreciated by making a comparison between the previous study and Zhong et al. (2020).Both studies address the problem of four-class classification on the same dataset by using a pipeline based on graphs and deep networks.In the first case, an adaptive graph is used without any DA methods, while the second study makes use of a (nonadaptive) graph approach  in combination with Domain Adaptation techniques.Even though they use different approaches, the reported accuracy performances are comparable.This suggests how the dynamic search for feature extraction procedures represents an interesting frontier for future studies in this area, not excluding the potential of using this approach in combination with DA/DG techniques.</p>
<p>Another point to take into account is that the proliferation of EEG acquisition devices on the market is not always coupled with consistency in terms of quality between the various devices (considering electrode type and positioning, interference shielding and signal-to-noise ratio, amplification strategies, etc).A comparison among different studies must take into account the quality of EEG instrumentation used.The IEC 60601-2-26 standard applies to basic safety and essential performance of electroencephalographs used in a clinical environment.</p>
<p>Among the requirements, the minimum overall signal quality for an electroencephalographic device to be considered acceptable is defined Goldsack et al. (2020).Even if IEC 60601-2-26 is a standard specifically developed for clinical purposes, it is nowadays the only available standard for EEG instrumentation quality certification.In the future, it is desirable for research to be increasingly based on certified instruments.However, an encouraging trend emerges from the most recent public datasets.They are all based on standardized equipment: (i) Neuroelectrics Enobio 8 in the case of LUMED Cimtay and Ekmekcioglu (2020), (ii) NuAmp Neuroscan in the case of CMEED Du et al. (2020), and (iii) gtec.HIamp in the case of the dataset produced by Bao et al. (2020)).</p>
<p>A further concern in the use of public datasets is its underlying theoretical background, often acritically accepted by the scientists.Many studies validate the same machine learning algorithm on different datasets although the targeted psychic phenomena are radically different.Indeed, each dataset leverages on a specific theory of emotions and related experimental setup of emotion elicitation.For instance, DEAP is based on a dimensional approach and SEED IV on discrete one.The discrete theory is based on the assumption that there are basic emotions that have evolved through natural selection TenHouten (2017).In this vein, close to the Darwinian tradition, Ekman's theory identifies six basic emotions that would be universal and innate: anger, disgust, fear, happiness, sadness and surprise Ekman (1999).After him, Plutchik, identifies eight basic emotions (anger, anticipation, joy, trust, fear, surprise, sadness and disgust) and arranges them on a wheel model Suhaimi et al. (2020).In contrast, the dimensional theory expresses emotions in a continuous two-dimensional (valence-arousal) or three-dimensional (valence-arousal-dominance) space.While valence measures levels of pleasantness (happy vs. sad) of an emotion, arousal identifies degrees of excitement or motivational activation.In the three-dimensional model, the dominance dimension is added to valence and arousal, where the dominance evaluates emotions on a scale between submission and empowerment Torres et al. (2020).The underlying assumption of discrete approach is that few fundamental emotions are mediated by associated dedicated neural circuits, with a large innate (hardwired) component.Only two main brain networks are recognized by the dimensional approach Posner et al. (2009).The two theoretical approaches identify two different phenomena also at a neurophysiological level, with peculiar spatial signal features.</p>
<p>Finally, at present, the available public datasets do not adopt an established practice of psychological screening of the subjects involved.In general, studies on EEG-based emotion assessment could benefit from administering psychometric questionnaires to participants.Indeed, psychological data could help to understand individual differences in emotional response, leading to clustering of subjects Liu et al. (2021).Recently, unsupervised clustering based on large datasets is emerging as a promising strategy for empirical identification of personality types Gerlach et al. (2018).Meanwhile, correlations have been found between personality types and EEG patterns Li et al. (2020b).Moreover, prior psychological assessments allow to manage bias due to individual traits or states.The introduction of psycho-metric tests and assessments during the production of upcoming datasets could lead to a much more fruitful use of data in support of generalization.</p>
<p>Conclusion</p>
<p>A systematic literature review collecting papers on machine learning strategies to pursue (cross-subjects and cross-sessions) generalizability in EEG-based emotion recognition was carried out.Among the 418 articles retrieved from Scopus, IEEE (Institute of Electrical and Electronics Engineers) Xplore, and PubMed databases, 75 papers resulted eligible.A taxonomy of the studies employing ML method was proposed.</p>
<p>The studies with the best results in terms of average classification accuracy were identified, and the ten best results considering as many classification problems were highlighted.An interesting perspective based on self-organized graph construction modules emerged as peculiar strategy.This suggests how the adaptive feature extraction procedures represent an interesting frontier for future studies in this area, not excluding the potential of using this approach in combination with DA/DG techniques.</p>
<p>Future research on EEG-based emotion assessment could also benefit from administering psychometric questionnaires to participants in order to conduct a psychological screening of the experimental sample.This could help to understand individual differences in emotional responses, leading to clustering of subjects also taking into account the different subjects' personality.</p>
<p>Figure 1 :
1
Figure 1: Scopus trend for EEG-based Emotion Recognition studies.</p>
<p>Figure 2 :
2
Figure 2: A pipeline of a classical ML process involving EEG signals.</p>
<p>Figure 3 :
3
Figure 3: PRISMA flow diagram of the systematic review process.</p>
<p>Figure 4 :
4
Figure 4: Proposed Taxonomy.</p>
<p>Figure 5 :
5
Figure 5: Pie charts for distribution of papers occurrences according to: a) generalization types, b) categories of the taxonomy, c) used datasets, d) emotional theories.</p>
<p>DResNet -Domain Residual Network ESN -Echo State Network GNB -Gaussian Naïve Bayes HO -Hold Out LOO -Leave One Out LSTM -Long short-term memory MACI -Multi-Source Co-adaptation Correlation Information MDTDDL -Multi-source Domain Transfer Discriminative Dictionary Learning modelling MEERNet -Multi-Source EEG-based Emotion Recognition Network MIDA -Maximum Independence Domain Adaptation MSDAN -Multi-Spatial Domain Adaptation Network MS-MDA -Multi Source-Marginal Distribution Adaptation MSSA -Multi-Subject Subspace Alignment Na -not available NCA = Neighborhood Component Analysis O2OSE -ONE-TO-ONE-SESSION PLRSA -Progressive Low-Rank Subspace Alignment PPDA -Plug-and-Play Domain Adaptation R2G-STNN -Regional To Global Spatial-Temporal Neural Network RCNN -Residual CNN RF -Random Forest RFE -Recursive Feature Elimination RGNN -Regularized Graph Neural Network RPCA -Robust Principal Component Analysis SAAE -Subspace Alignment Auto Encoder SBS -Sequential Backward Selection SDA-FSL -Single-Source Domain Adaptive Few-Shot Learning Network SE2SE -session-to-session SOGNN -Self-Organized Graph Neural Network sp -self-produced SSB -Shared Space-Based SSS -Shared+Specific Spaces STM -Style Transfer Mapping SU2SU -subject-to-subject SVM -Support Vector Machine TCA -Transfer Component Analysis TDANN -Two-Level Domain Adaptation Neural Network TPT -Transductive Parameter Transfer TRFE -Transferable Recursive Feature Elimination TSB -Target Space-Based VAE -Variational Auto Encoder WGANDA -Wasserstein Generative Adversarial Network Domain Adaptation wMADA -Wasserstein-Distance-based Multi-Source Adversarial Domain Adaptation</p>
<p>•</p>
<p>Jiang et al. (2019b)rtifacts are all the unwanted signals that may affect the measurement and corrupt the EEG signal.They can be due to all the physiological systems different from the brain, such as heart, eyes, muscle, etc., or all the environmental noise, such as wireless signals, electrode adhesion, cable movements, etc.In the EEG signals, artifacts are present in specific frequency bands: ocular artifacts and cardiac activity are dominant below 4 Hz, muscle movements above 30 Hz.Other physiological artifacts are due to skin perspiration, sweating, movements of the tongue, chest movements, etc. Removing artifacts from the EEG signal means to correct (or eliminate) the fluctuations introduced by the artifacts without causing distortions in the brain signal.Part of the artifacts can be removed with the filtering process (e.g., line noise) but, for a more effective removal of artifacts, further processing is requiredJiang et al. (2019b).Main artifacts removal methods are: linear regression, filtering, wavelet transform, empirical mode decomposition (EMD), Independent Component Analysis (ICA), Principal Component Analysis (PCA), Canonical Correlation Analysis (CCA), and Artefact Subspace Reconstruction (ASR).Once the EEG signal has been preprocessed, it is usually divided into epochs, and a feature extraction process is then applied.EEG features can be categorized into three domains, namely time, frequency and time-frequency.</p>
<p>• Time domain: the main features are the statistics of the signal, such as mean, variance, skewness, kurtosis, etc Geethanjali et al. (2012); Vidaurre et al. (2009); Yuen et al. (2009).Other time-domain features are the Hjorth parameters, namely Activity, Mobility, and Complexity Oh et al.</p>
<p>Li et al. (2019b)lear norm, || • || 1 the l 1 norm and λ a weighting parameter.In Lin (2019) a proposal to use RPCA to build a Cross-Day emotion recognition model is made.InLi et al. (2019b)a method for personalised handwriting recognition (Style Transfer Mapping, STMZhang and Liu (</p>
<p>L,S ||L|| * + λ||S|| 1 where || • || *</p>
<p>Table 1 :
1
Reviewed studies on generalization strategies for emotion recognition.Datasets used, classifiers, evaluation strategy and type of generalization (i.e.intersubjects, cross sessions and cross datasets) are presented for each entry in the table.(sp = self produced, nl = not labelled; for the other abbreviations see section 7).
Classifier CategoryStudyDatasetClassifierEvaluation StrategyCross Subject Cross Session Cross DatasetYin et al. (2017)DEAPTRFELOOXRayatdoost and Soleymani (2018)DEAP, MAHNOB, spRFLOOXXLi et al. (2018b)DEAP, SEEDSVMLOOXSong et al. (2018)SEED, DREAMERDGCNNLOOXYang et al. (2019)DEAP, SEEDSVMLOOXJiang et al. (2019a)DEAP, spSBSLOOXCai et al. (2019)DEAPTRFELOOXCLASSICAL MLLi et al. (2019c)DEAP, SEEDVAE-LSTMLOOXPandey and Seeja (2019)DEAPSVMLOOXArevalillo-Herráez et al. (2019)DEAP, MAHNOB, DREAMERSVMLOOXZhang and Yin (2020)DEAP, MAHNOBRFELOOXLiu et al. (2020)SEEDDECNNLOOXLi et al. (2020c)DEAP, SEEDVAE-LSTMLOOXChen et al. (2021c)SEEDSVMLOOXFernandez et al. (2021)SEEDSVMLOOXTian et al. (2021)ASCERTAINBiLSTMLOOXLi et al. (2021a)SEED, SEED IVSOGNNLOOXTRANSDUCTIVEYang et al. (2020)SEED, spPTSVMLOOXLin et al. (2017)spGNBASIXZhang et al. (2019b)DEAPSVMLOOXDOMAIN ADAPTATIONZhou et al. (2020a)DEAPESNLOOX(SOURCE SELECTION)Hua et al. (2021)DEAPNCALOOXWang et al. (2021a)SEEDDMATNLOOXChai et al. (2017)SEEDASFMLOOXXSHALLOW DA (TSB)Chai et al. (2018)SEEDMSSALOOXLin (2019)MDME, SDMNRPCAASIXLi et al. (2019b)SEEDSTMLSOXZheng et al. (2015)SEEDTCALOOXChai et al. (2016)SEEDSAAESU2SU, SE2SE, LOOXXZheng and Lu (2016)SEEDTPTLOOXSHALLOW DA (SSB)Lan et al. (2018)DEAP, SEEDMIDALOOXXXue et al. (2020)SEEDTCALOOXNi et al. (2021)DEAP, SEEDDASRCLOOXXHe et al. (2022b)spTCAHOXJin et al. (2017)SEEDDANNLOOXLi et al. (2018a)SEED, SEED IVDANLOOXLi et al. (2018d)SEEDBiDANNLOOXLuo et al. (2018)DEAPWGANDALOOXZhang et al. (2019a)SEEDDDCLOOXLi et al. (2019d)SEEDR2G-STNNLOOXLi et al. (2019a)DEAP, SEEDnlLOO, SU2SU, O2OSEXXLi et al. (2020d)SEED, SEED IV, MPEDBiHDMLOOXZhong et al. (2020)SEED, SEED IVRGNNLOOXBao et al. (2020)SEED, spTDANNLOOXXDEEP DA (CSS)Hwang et al. (2020b)SEED, CMEEDA-DNNLOOXDu et al. (2020)DEAP, SEED, CMEEDATDD-LSTMLOOXXKuang et al. (2021)spMSDANLOOXFurukawa et al. (2021)SEEDnlLOOXLi et al. (2021c)SEEDnlLOOXDing et al. (2021)SEEDTDANNSU2SUXNing et al. (2021)DEAP, SEEDSDA-FSLLOSOXXTao and Dan (2021)DEAP, SEEDMACILOOXXLuo et al. (2021)DEAP, SEEDPLRSALOO, SU2SUXXHe et al. (2022a)DEAP, DREAMERAD-TCNLOOXXLi et al. (2018e)SEEDBiHDMLOOXGu et al. (2022)DEAP, SEEDMDTDDLLOOXX</p>
<p>Table 2 :
2
The most representative studies according to their classification accuracy, categorised by EEG dataset (SEED, DEAP, others) and by number and type of classes considered.DIM = Dimensional; DIS = Discrete; sp =
ProposedStudyDatasetReference#ClassesAccuracycategoryTheorySUPERVISED DACimtay and Ekmekcioglu (2020) DEAPDIM (VAL)#2 (LV/HV)72.81 ± 5.07OtherDIM (VAL)#2 (LV/HV)81.80 ± 10.92DA -SOURCE SELECTIONZhou et al. (2020a)DEAPDIM (VAL)#3 (LV/MV/HV)68.06 ± 10.93DEEP DA (SSS)Liu et al. (2021)DEAP DIM (VAL-ARO)#2 (LV/HV)73.90 ± 13.50 (VAL)#2 (LA/HA)68.80 ± 11.20 (ARO)DEEP DA (CSS)Li et al. (2019a)DEAP DIM (VAL-ARO)#4 (LALV-HALV-62.66 ± 10.45LAHV-HAHV)DEEP DA (CSS)Ning et al. (2021)SEEDDIM (VAL)#2 (LV/HV)97.66 ± 14.46DEEP DA (CSS)Du et al. (2020)SEEDDIM (VAL)#3 (LV/MV/HV)90.92 ± 1.05Other DIM (VAL-ARO)#2 (LV/HV)94.21 ± 5.88 (VAL)#2 (LA/HA)88.03 ± 6.32 (ARO)DEEP DA (CSS)Bao et al. (2020)Other DIS (HAPPY, SAD #2 (JOY/SADNESS) 83.79 ± 1.55 (JOY/SAD)FEAR, ANGER) #2 (JOY/ANGER) 84.13 ± 1.37 (JOY/ANGER)#2 (JOY/FEAR)81.72 ± 1.30 (JOY/FEAR)CLASSICAL MLLi et al. (2021a)Other DIS (HAPPY, SAD #4 (HAPPY/SAD/75.27 ± 8.19FEAR, NEUTRAL) FEAR/NEUTRAL)
This work has been published on Neurocomputing journal.Please refer to the final version of the paper on https://doi.org/10.1016/j.neucom.2024.128354.Old title "Machine Learning Strategies to Improve Generalization in EEG-based Emotion Assessment: a Systematic Review" has been changed to the current one.
Hemispheric Discrepancy Model BiLSTM -Bidirectional LSTM BiVDANN -Bi-lateral Variational Domain Adversarial Neural Network CSS -Common Shared Space DAN -Deep Adaptation Network DANN -Domain Adversarial Neural Network DASC -Domain Adaptation Subject Clustering DASRC -Domain Adaptation Sparse Representation Classifier DDC -Deep Domain Confusion DECNN -Dynamic Empirical Convolutional Neural network DGCNN -Dynamical Graph Convolutional Neural Networks DG-DANN -Domain Generalization DANN References Acharya. A-Dnn - , Adversarial Deep Neural Network AD-TCN -Adversarial Discriminative Temporal Convolutional Network ASFM -Adaptive Subspace Feature Matching ASI -Add-Session-In ATDD-LSTM -Attention-based LSTM BiDANN -Bi-hemispheres DANN BiHDM -Bi. J N Hani, A J Cheek, J Thirumala, P Tsuchida, T N , 201656American clinical neurophysiology society guideline 2: guidelines for standard electrode position nomenclature</p>
<p>H Ajakan, P Germain, H Larochelle, F Laviolette, M Marchand, arXiv:1412.4446Domain-adversarial neural networks. 2014arXiv preprint</p>
<p>Emotions recognition using eeg signals: A survey. S M Alarcao, M J Fonseca, IEEE Transactions on Affective Computing. 1032017</p>
<p>A survey on eeg-based solutions for emotion recognition with a low number of channels. A Apicella, P Arpaia, F Isgrò, G Mastrati, N Moccaldi, IEEE Access. 2022</p>
<p>Combining inter-subject modeling with a subject-based data transformation to improve affect recognition from eeg signals. M Arevalillo-Herráez, M Cobos, S Roger, M García-Pineda, Sensors. 191329992019</p>
<p>Two-level domain adaptation neural network for eeg-based emotion recognition. G Bao, N Zhuang, L Tong, B Yan, J Shu, L Wang, Y Zeng, Z Shen, Frontiers in Human Neuroscience. 142020</p>
<p>Innovative tools for radar signal processing based on cartan's geometry of spd matrices &amp; information geometry. F Barbaresco, 2008 IEEE Radar Conference. IEEE2008</p>
<p>Learning representations from eeg with deep recurrent-convolutional neural networks. P Bashivan, I Rish, M Yeasin, N Codella, arXiv:1511.064482015arXiv preprint</p>
<p>Using neurophysiological signals that reflect cognitive or affective state: six recommendations to avoid common pitfalls. A.-M Brouwer, T O Zander, J B Van Erp, J E Korteling, A W Bronkhorst, Frontiers in neuroscience. 91362015</p>
<p>Multiple transferable recursive feature elimination technique for emotion recognition based on eeg signals. J Cai, W Chen, Z Yin, Symmetry. 1156832019</p>
<p>Affective computing and sentiment analysis. E Cambria, D Das, S Bandyopadhyay, A Feraco, A practical guide to sentiment analysis. Springer2017</p>
<p>Application of a novel measure of eeg nonstationarity as 'shannon-entropy of the peak frequency shifting'for detecting residual abnormalities in concussed individuals. C Cao, S Slobounov, Clinical Neurophysiology. 12272011</p>
<p>Multi-source and multi-representation adaptation for cross-domain electroencephalography emotion recognition. J Cao, X He, C Yang, S Chen, Z Li, Z Wang, Frontiers in Psychology. 122021</p>
<p>Wearable eeg and beyond. A J Casson, Biomedical engineering letters. 912019</p>
<p>A fast, efficient domain adaptation technique for cross-domain electroencephalography (eeg)-based emotion recognition. X Chai, Q Wang, Y Zhao, Y Li, D Liu, X Liu, O Bai, Sensors. 17510142017</p>
<p>Unsupervised domain adaptation techniques based on auto-encoder for non-stationary eegbased emotion recognition. X Chai, Q Wang, Y Zhao, X Liu, O Bai, Y Li, Computers in biology and medicine. 792016</p>
<p>Multisubject subspace alignment for non-stationary eeg-based emotion recognition. X Chai, Q Wang, Y Zhao, X Liu, D Liu, O Bai, Technology and Health Care. 26S12018</p>
<p>Ms-mda: Multisource marginal distribution adaptation for cross-subject and cross-session eeg emotion recognition. H Chen, M Jin, Z Li, C Fan, J Li, H He, Frontiers in Neuroscience. 152021a</p>
<p>Meernet: Multi-source eeg-based emotion recognition network for generalization across subjects and sessions. H Chen, Z Li, M Jin, J Li, 2021 43rd Annual International Conference of the IEEE Engineering in Medicine &amp; Biology Society (EMBC). IEEE2021b</p>
<p>Personalzscore: Eliminating individual difference for eeg-based cross-subject emotion recognition. H Chen, S Sun, J Li, R Yu, N Li, X Li, B Hu, IEEE Transactions on Affective Computing. 2021c</p>
<p>Learning with progressive transductive support vector machine. Y Chen, G Wang, S Dong, Pattern Recognition Letters. 24122003</p>
<p>Investigating the use of pretrained convolutional neural network on cross-subject and cross-dataset eeg emotion recognition. Y Cimtay, E Ekmekcioglu, Sensors. 20720342020</p>
<p>The state and trait nature of frontal eeg asymmetry in emotion. J A Coan, J J Allen, 2003</p>
<p>An automatic pre-processing pipeline for eeg analysis (app) based on robust statistics. J R Da Cruz, V Chicherov, M H Herzog, P Figueiredo, Clinical Neurophysiology. 12972018</p>
<p>Boosting for transfer learning. W Dai, Q Yang, G.-R Xue, Y Yu, Proceedings of the 24th International Conference on Machine Learning, ICML '07. the 24th International Conference on Machine Learning, ICML '07New York, NY, USAAssociation for Computing Machinery2007</p>
<p>What does clean eeg look like?. I Daly, F Pichiorri, J Faller, V Kaiser, A Kreilinger, R Scherer, G Müller-Putz, 2012 Annual International Conference of the IEEE Engineering in Medicine and Biology Society. IEEE2012</p>
<p>The geneva affective picture database (gaped): a new 730-picture database focusing on valence and normative significance. E S Dan-Glauser, K R Scherer, Behavior research methods. 4324682011</p>
<p>Hemispheric asymmetry and emotion. R J Davidson, Approaches to emotion. 21984</p>
<p>Brain lateralization of emotional processing: historical roots and a future incorporating "dominance. H A Demaree, D E Everhart, E A Youngstrom, D W Harrison, Behavioral and cognitive neuroscience reviews. 412005</p>
<p>Eeg emotion enhancement using task-specific domain adversarial neural network. K.-M Ding, T Kimura, K.-I Fukui, M Numao, 2021 International Joint Conference on Neural Networks (IJCNN). IEEE2021</p>
<p>An efficient lstm network for emotion recognition from multichannel eeg signals. X Du, C Ma, G Zhang, J Li, Y.-K Lai, G Zhao, X Deng, Y.-J Liu, H Wang, IEEE Transactions on Affective Computing. 2020</p>
<p>Basic emotions. Handbook of cognition and emotion. P Ekman, 19999816</p>
<p>A wavelet-based approach to emotion classification using eda signals. H Feng, H M Golshan, M H Mahoor, Expert Systems with Applications. 1122018</p>
<p>Crosssubject eeg-based emotion recognition through neural networks with stratified normalization. J Fernandez, N Guttenberg, O Witkowski, A Pasquali, Frontiers in neuroscience. 15112021</p>
<p>Unsupervised visual domain adaptation using subspace alignment. B Fernando, A Habrard, M Sebban, T Tuytelaars, Proceedings of the IEEE international conference on computer vision. the IEEE international conference on computer vision2013</p>
<p>Statistical methods for research workers. R A Fisher, Breakthroughs in statistics. Springer1992</p>
<p>Emotion recognition with domain adaptation based on few-shot eeg learning. S Furukawa, T Sakuma, S Kato, 2021 IEEE 10th Global Conference on Consumer Electronics (GCCE). IEEE2021</p>
<p>Unsupervised domain adaptation by backpropagation. Y Ganin, V Lempitsky, International conference on machine learning. PMLR2015</p>
<p>Domain-adversarial training of neural networks. Y Ganin, E Ustinova, H Ajakan, P Germain, H Larochelle, F Laviolette, M Marchand, V Lempitsky, The journal of machine learning research. 1712016</p>
<p>Time domain feature extraction and classification of eeg data for brain computer interface. P Geethanjali, Y K Mohan, J Sen, 2012 9th International Conference on Fuzzy Systems and Knowledge Discovery. IEEE2012</p>
<p>A robust data-driven approach identifies four personality types across four large data sets. M Gerlach, B Farb, W Revelle, L A Nunes Amaral, Nature human behaviour. 2102018</p>
<p>Scatter component analysis: A unified framework for domain adaptation and domain generalization. M Ghifary, D Balduzzi, W B Kleijn, M Zhang, IEEE transactions on pattern analysis and machine intelligence. 201639</p>
<p>. J C Goldsack, A Coravos, J P Bakker, B Bent, A V Dowling, C Fitzer-Attas, A Godfrey, J G Godino, N Gujar, E Izmailova, 2020</p>
<p>Verification, analytical validation, and clinical validation (v3): the foundation of determining fit-for-purpose for biometric monitoring technologies (biomets). npj digital. Medicine. 31</p>
<p>Geodesic flow kernel for unsupervised domain adaptation. B Gong, Y Shi, F Sha, K Grauman, 2012 IEEE conference on computer vision and pattern recognition. IEEE2012</p>
<p>Eeg-based emotion detection using unsupervised transfer learning. H A Gonzalez, J Yoo, I M Elfadel, 2019 41st Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC). IEEE2019</p>
<p>A kernel method for the two-sample-problem. A Gretton, K Borgwardt, M Rasch, B Schölkopf, A Smola, Advances in neural information processing systems. 2006. 19</p>
<p>Multi-source domain transfer discriminative dictionary learning modeling for electroencephalogram-based emotion recognition. X Gu, W Cai, M Gao, Y Jiang, X Ning, P Qian, IEEE Transactions on Computational Social Systems. 2022</p>
<p>Cross-subject emotion recognition using flexible analytic wavelet transform from eeg signals. V Gupta, M D Chopda, R B Pachori, IEEE Sensors Journal. 1962018</p>
<p>Learning subject-generalized topographical eeg embeddings using deep variational autoencoders and domain-adversarial regularization. J L Hagad, T Kimura, K.-I Fukui, M Numao, Sensors. 21517922021</p>
<p>Deep residual learning for image recognition. K He, X Zhang, S Ren, J Sun, Proceedings of the IEEE conference on computer vision and pattern recognition. the IEEE conference on computer vision and pattern recognition2016</p>
<p>An adversarial discriminative temporal convolutional network for eeg-based cross-domain emotion recognition. Z He, Y Zhong, J Pan, Computers in biology and medicine. 1411050482022a</p>
<p>Cross-day eegbased emotion recognition using transfer component analysis. Z He, N Zhuang, G Bao, Y Zeng, B Yan, Electronics. 1146512022b</p>
<p>A machine learning emotion detection platform to support affective well being. M Healy, R Donovan, P Walsh, H Zheng, 2018 IEEE International Conference on Bioinformatics and Biomedicine (BIBM). IEEE2018</p>
<p>Detecting epilepsy in eeg signals using time, frequency and time-frequency domain features. D Hernández, L Trujillo, O Villanueva, O Romo-Fewell, Computer science and engineering-theory and applications. Springer2018</p>
<p>Manifold feature fusion with dynamical feature selection for cross-subject emotion recognition. Y Hua, X Zhong, B Zhang, Z Yin, J Zhang, Brain Sciences. 111113922021</p>
<p>Densely connected convolutional networks. G Huang, Z Liu, L Van Der Maaten, K Q Weinberger, Proceedings of the IEEE conference on computer vision and pattern recognition. the IEEE conference on computer vision and pattern recognition2017</p>
<p>Learning cnn features from de features for eeg-based emotion recognition. S Hwang, K Hong, G Son, H Byun, Pattern Analysis and Applications. 2332020a</p>
<p>Subject-independent eeg-based emotion recognition using adversarial learning. S Hwang, M Ki, K Hong, H Byun, 2020 8th International Winter Conference on Brain-Computer Interface (BCI). IEEE2020b</p>
<p>Computational eeg analysis. C.-H Im, 2018Springer10Singapore; Singapore</p>
<p>A new segmentation method of electroencephalograms by use of akaike's information criterion. T Inouye, S Toi, Y Matsumoto, Cognitive brain research. 311995</p>
<p>Feature extraction and selection for emotion recognition from eeg. R Jenke, A Peer, M Buss, IEEE Transactions on Affective computing. 532014</p>
<p>A literature survey on domain adaptation of statistical classifiers. J Jiang, 200833</p>
<p>Cross-subject emotion recognition with a decision tree classifier based on sequential backward selection. W Jiang, G Liu, X Zhao, F Yang, 2019 11th International Conference on Intelligent Human-Machine Systems and Cybernetics (IHMSC). IEEE2019a1</p>
<p>Removal of artifacts from eeg signals: a review. X Jiang, G.-B Bian, Z Tian, Sensors. 1959872019b</p>
<p>Eeg-based emotion recognition using domain adaptation network. Y.-M Jin, Y.-D Luo, W.-L Zheng, B.-L Lu, 2017 international conference on orange technologies (ICOT). IEEE2017</p>
<p>Transductive inference for text classification using support vector machines. T Joachims, Icml. 199999</p>
<p>Dreamer: A database for emotion recognition through eeg and ecg signals from wireless low-cost off-the-shelf devices. S Katsigiannis, N Ramzan, IEEE journal of biomedical and health informatics. 2212017</p>
<p>Face morphing attack detection in the presence of post-processed image sources using neighborhood component analysis and decision tree classifier. O M Kenneth, S A Bashir, O A Abisoye, A D Mohammed, International Conference on Information and Communication Technology and Applications. Springer2020</p>
<p>Procedures for performing systematic reviews. B Kitchenham, 2004. 200433Keele, UK, Keele University</p>
<p>Siamese neural networks for one-shot image recognition. G Koch, R Zemel, R Salakhutdinov, ICML deep learning workshop. Lille201520</p>
<p>Deap: A database for emotion analysis; using physiological signals. S Koelstra, C Muhl, M Soleymani, J.-S Lee, A Yazdani, T Ebrahimi, T Pun, A Nijholt, I Patras, IEEE transactions on affective computing. 312011</p>
<p>Eeg correlates of different emotional states elicited during watching music videos. E Kroupi, A Yazdani, T Ebrahimi, International Conference on Affective Computing and Intelligent Interaction. Springer2011</p>
<p>Cross-subject and cross-device wearable eeg emotion recognition using frontal eeg under virtual reality scenes. F Kuang, L Shu, H Hua, S Wu, L Zhang, X Xu, Y Liu, M Jiang, 2021 IEEE International Conference on Bioinformatics and Biomedicine (BIBM). IEEE2021</p>
<p>Introducing the open affective standardized image set (oasis). B Kurdi, S Lozano, M R Banaji, Behavior research methods. 201749</p>
<p>Domain adaptation techniques for eeg-based emotion recognition: a comparative study on two public datasets. Z Lan, O Sourina, L Wang, R Scherer, G R Müller-Putz, IEEE Transactions on Cognitive and Developmental Systems. 1112018</p>
<p>International affective picture system (iaps): Affective ratings of pictures and instruction manual. P J Lang, 2005Technical report</p>
<p>A statistically robust eeg re-referencing procedure to mitigate reference effect. K Q Lepage, M A Kramer, C J Chu, Journal of neuroscience methods. 2352014</p>
<p>Cross-subject emotion recognition using deep adaptation networks. H Li, Y.-M Jin, W.-L Zheng, B.-L Lu, International conference on neural information processing. Springer2018a</p>
<p>Foit: Fast online instance transfer for improved eeg emotion recognition. J Li, H Chen, T Cai, 2020 IEEE International Conference on Bioinformatics and Biomedicine (BIBM). IEEE2020a</p>
<p>Cross-subject eeg emotion recognition with self-organized graph neural network. J Li, S Li, J Pan, F Wang, Frontiers in Neuroscience. 6892021a</p>
<p>Domain adaptation for eeg emotion recognition based on latent representation similarity. J Li, S Qiu, C Du, Y Wang, H He, IEEE Transactions on Cognitive and Developmental Systems. 1222019a</p>
<p>Multisource transfer learning for cross-subject eeg emotion recognition. J Li, S Qiu, Y.-Y Shen, C.-L Liu, H He, IEEE transactions on cybernetics. 5072019b</p>
<p>Eeg responses to emotional videos can quantitatively predict big-five personality traits. W Li, X Hu, X Long, L Tang, J Chen, F Wang, D Zhang, Neurocomputing. 4152020b</p>
<p>Can emotion be transferred?-a review on transfer learning for eeg-based emotion recognition. W Li, W Huan, B Hou, Y Tian, Z Zhang, A Song, IEEE Transactions on Cognitive and Developmental Systems. 2021b</p>
<p>Exploring eeg features in cross-subject emotion recognition. X Li, D Song, P Zhang, Y Zhang, Y Hou, B Hu, Frontiers in neuroscience. 121622018b</p>
<p>Variational autoencoder based latent factor decoding of multichannel eeg for emotion recognition. X Li, Z Zhao, D Song, Y Zhang, C Niu, J Zhang, J Huo, J Li, 2019 IEEE International Conference on Bioinformatics and Biomedicine (BIBM). IEEE2019c</p>
<p>Latent factor decoding of multi-channel eeg for emotion recognition through autoencoder-like neural networks. X Li, Z Zhao, D Song, Y Zhang, J Pan, L Wu, J Huo, C Niu, D Wang, 2020c1487Frontiers in neuroscience</p>
<p>A novel bi-hemispheric discrepancy model for eeg emotion recognition. Y Li, L Wang, W Zheng, Y Zong, L Qi, Z Cui, T Zhang, T Song, IEEE Transactions on Cognitive and Developmental Systems. 1322020d</p>
<p>Adaptive batch normalization for practical domain adaptation. Y Li, N Wang, J Shi, X Hou, J Liu, Pattern Recognition. 802018c</p>
<p>A novel neural network model based on cerebral hemispheric asymmetry for eeg emotion recognition. Y Li, W Zheng, Z Cui, T Zhang, Y Zong, IJCAI. 2018d</p>
<p>From regional to global brain: A novel hierarchical spatial-temporal neural network model for eeg emotion recognition. Y Li, W Zheng, L Wang, Y Zong, Z Cui, IEEE Transactions on Affective Computing. 2019d</p>
<p>A bihemisphere domain adversarial neural network model for eeg emotion recognition. Y Li, W Zheng, Y Zong, Z Cui, T Zhang, X Zhou, IEEE Transactions on Affective Computing. 2018e</p>
<p>Reducing the calibration effort of eeg emotion recognition using domain adaptation with soft labels. Z Li, H Chen, M Jin, J Li, 2021 43rd Annual International Conference of the IEEE Engineering in Medicine &amp; Biology Society (EMBC). IEEE2021c</p>
<p>The prisma statement for reporting systematic reviews and meta-analyses of studies that evaluate health care interventions: explanation and elaboration. A Liberati, D G Altman, J Tetzlaff, C Mulrow, P C Gøtzsche, J P Ioannidis, M Clarke, P J Devereaux, J Kleijnen, D Moher, Journal of clinical epidemiology. 62102009</p>
<p>Constructing a personalized cross-day eeg-based emotionclassification model using transfer learning. Y.-P Lin, IEEE journal of biomedical and health informatics. 2452019</p>
<p>Improving cross-day eeg-based emotion classification using robust principal component analysis. Y.-P Lin, P.-K Jao, Y.-H Yang, Frontiers in computational neuroscience. 11642017</p>
<p>Eeg-based emotion recognition in music listening. Y.-P Lin, C.-H Wang, T.-P Jung, T.-L Wu, S.-K Jeng, J.-R Duann, J.-H Chen, IEEE Transactions on Biomedical Engineering. 5772010</p>
<p>Domain adaptation for cross-subject emotion recognition by subject clustering. J Liu, X Shen, S Song, D Zhang, 2021 10th International IEEE/EMBS Conference on Neural Engineering (NER). IEEE2021</p>
<p>Subjectindependent emotion recognition of eeg signals based on dynamic empirical convolutional neural network. S Liu, X Wang, L Zhao, J Zhao, Q Xin, S Wang, IEEE/ACM Transactions on Computational Biology and Bioinformatics. 2020</p>
<p>Learning transferable features with deep adaptation networks. M Long, Y Cao, J Wang, M Jordan, International conference on machine learning. PMLR2015</p>
<p>Transfer sparse coding for robust image representation. M Long, G Ding, J Wang, J Sun, Y Guo, P S Yu, Proceedings of the IEEE conference on computer vision and pattern recognition. the IEEE conference on computer vision and pattern recognition2013</p>
<p>Dry eeg electrodes. M A Lopez-Gordo, D Sanchez-Morillo, F P Valle, Sensors. 1472014</p>
<p>A review of classification algorithms for eeg-based brain-computer interfaces: a 10 year update. F Lotte, L Bougrain, A Cichocki, M Clerc, M Congedo, A Rakotomamonjy, F Yger, Journal of neural engineering. 153310052018</p>
<p>Progressive lowrank subspace alignment based on semi-supervised joint domain adaption for personalized emotion recognition. J Luo, M Wu, Z Wang, Y Chen, Y Yang, Neurocomputing. 4562021</p>
<p>Wasserstein-distance-based multi-source adversarial domain adaptation for emotion recognition and vigilance estimation. Y Luo, B.-L Lu, 2021 IEEE International Conference on Bioinformatics and Biomedicine (BIBM). IEEE2021</p>
<p>Wgan domain adaptation for eeg-based emotion recognition. Y Luo, S.-Y Zhang, W.-L Zheng, B.-L Lu, International Conference on Neural Information Processing. Springer2018</p>
<p>Reducing the subject variability of eeg signals with adversarial domain generalization. B.-Q Ma, H Li, W.-L Zheng, B.-L Lu, International Conference on Neural Information Processing. Springer2019</p>
<p>Supervised dictionary learning. J Mairal, J Ponce, G Sapiro, A Zisserman, F Bach, Advances in neural information processing systems. 200821</p>
<p>Domain generalization via invariant feature representation. K Muandet, D Balduzzi, B Schölkopf, International Conference on Machine Learning. PMLR2013</p>
<p>The fractal dimension of eeg as a physical measure of conscious human brain activities. Nan , X Jinghua, X , Bulletin of Mathematical Biology. 5051988</p>
<p>Attentive adversarial network for largescale sleep staging. S Nasiri, G D Clifford, Machine Learning for Healthcare Conference. PMLR2020</p>
<p>A domain adaptation sparse representation classifier for cross-domain electroencephalogram-based emotion classification. T Ni, Y Ni, J Xue, S Wang, Frontiers in Psychology. 30152021</p>
<p>Cross-subject eeg emotion recognition using domain adaptive few-shot learning networks. R Ning, C P Chen, T Zhang, 2021 IEEE International Conference on Bioinformatics and Biomedicine (BIBM). IEEE2021</p>
<p>A review on the attention mechanism of deep learning. Z Niu, G Zhong, H Yu, Neurocomputing. 4522021</p>
<p>A novel eeg feature extraction method using hjorth parameter. S.-H Oh, Y.-R Lee, H.-N Kim, International Journal of Electronics and Electrical Engineering. 222014</p>
<p>Analysis and design of echo state networks. M C Ozturk, D Xu, J C Principe, Neural computation. 1912007</p>
<p>Domain adaptation via transfer component analysis. S J Pan, I W Tsang, J T Kwok, Q Yang, 201022</p>
<p>A survey on transfer learning. S J Pan, Q Yang, IEEE Transactions on knowledge and data engineering. 22102009</p>
<p>Subject independent emotion recognition from eeg using vmd and deep learning. P Pandey, K Seeja, Journal. 2019King Saud University-Computer and Information Sciences</p>
<p>Feature extraction of eeg for emotion recognition using hjorth features and higher order crossings. A Patil, C Deshmukh, A Panat, 2016 Conference on Advances in Signal Processing (CASP). IEEE2016</p>
<p>Self-weighted semi-supervised classification for joint eeg-based emotion recognition and affective activation patterns mining. Y Peng, W Kong, F Qin, F Nie, J Fang, B.-L Lu, A Cichocki, IEEE Transactions on Instrumentation and Measurement. 702021</p>
<p>A survey on feature extraction methods for eeg based emotion recognition. S Phadikar, N Sinha, R Ghosh, International Conference on Innovation in Modern Science and Technology. Springer2019</p>
<p>The neurophysiological bases of emotion: An fmri study of the affective circumplex using emotiondenoting words. J Posner, J A Russell, A Gerber, D Gorman, T Colibazzi, S Yu, Z Wang, A Kangarlu, H Zhu, B S Peterson, Human brain mapping. 3032009</p>
<p>Learning densenet features from eeg based spectrograms for subject independent emotion recognition. A N Pusarla, B A Singh, C S Tripathi, Biomedical Signal Processing and Control. 741034852022</p>
<p>Dataset shift in machine learning. J Quinonero-Candela, M Sugiyama, A Schwaighofer, N D Lawrence, 2008Mit Press</p>
<p>Cross-corpus eeg-based emotion recognition. S Rayatdoost, M Soleymani, 2018 IEEE 28th International Workshop on Machine Learning for Signal Processing. IEEE2018</p>
<p>Bringing emotion recognition out of the lab into real life: Recent advances in sensors and machine learning. S Saganowski, Electronics. 1134962022</p>
<p>Emotion recognition using wearables: A systematic literature review-work-in-progress. S Saganowski, A Dutkowiak, A Dziadek, M Dzieżyc, J Komoszyńska, W Michalska, A Polak, M Ujma, P Kazienko, 2020 IEEE International Conference on Pervasive Computing and Communications Workshops (PerCom Workshops). IEEE2020</p>
<p>Maximum classifier discrepancy for unsupervised domain adaptation. K Saito, K Watanabe, Y Ushiku, T Harada, Proceedings of the IEEE conference on computer vision and pattern recognition. the IEEE conference on computer vision and pattern recognition2018</p>
<p>Kernel principal component analysis. B Schölkopf, A Smola, K.-R Müller, International conference on artificial neural networks. Springer1997</p>
<p>Towards adaptive classification for bci. P Shenoy, M Krauledat, B Blankertz, R P Rao, K.-R Müller, Journal of neural engineering. 31R132006</p>
<p>Multimodal emotion recognition in response to videos. M Soleymani, M Pantic, T Pun, IEEE transactions on affective computing. 322011</p>
<p>Eeg emotion recognition using dynamical graph convolutional neural networks. T Song, W Zheng, P Song, Z Cui, IEEE Transactions on Affective Computing. 1132018</p>
<p>Bioelectrical signal processing in cardiac and neurological applications. L Sörnmo, P Laguna, 2005Academic press8</p>
<p>Ascertain: Emotion and personality recognition using commercial sensors. R Subramanian, J Wache, M K Abadi, R L Vieriu, S Winkler, N Sebe, IEEE Transactions on Affective Computing. 922016</p>
<p>Eeg-based emotion recognition: A state-of-the-art review of current trends and opportunities. Computational intelligence and neuroscience. N S Suhaimi, J Mountstephens, J Teo, 2020. 2020</p>
<p>Inception-v4, inception-resnet and the impact of residual connections on learning. C Szegedy, S Ioffe, V Vanhoucke, A A Alemi, Thirty-first AAAI conference on artificial intelligence. 2017</p>
<p>Multi-source co-adaptation for eeg-based emotion recognition by mining correlation information. J Tao, Y Dan, Frontiers in Neuroscience. 154012021</p>
<p>From primary emotions to the spectrum of affect: An evolutionary neurosociology of the emotions. W D Tenhouten, Neuroscience and social science. Springer2017</p>
<p>Personality first in emotion: a deep neural network based on electroencephalogram channel attention for cross-subject emotion recognition. Z Tian, D Huang, S Zhou, Z Zhao, D Jiang, Royal Society open science. 882019762021</p>
<p>Eeg-based bci emotion recognition: A survey. E P Torres, E A Torres, M Hernández-Álvarez, S G Yoo, Sensors. 201850832020</p>
<p>Adversarial discriminative domain adaptation. E Tzeng, J Hoffman, K Saenko, T Darrell, Proceedings of the IEEE conference on computer vision and pattern recognition. the IEEE conference on computer vision and pattern recognition2017</p>
<p>Deep domain confusion: Maximizing for domain invariance. E Tzeng, J Hoffman, N Zhang, K Saenko, T Darrell, arXiv:1412.34742014arXiv preprint</p>
<p>24 transductive inference and semi-supervised learning. V Vapnik, 2006</p>
<p>Time domain parameters as a feature for eeg-based brain-computer interfaces. C Vidaurre, N Krämer, B Blankertz, A Schlögl, Neural Networks. 2292009</p>
<p>Emotion recognition with convolutional neural network and eeg-based efdms. F Wang, S Wu, W Zhang, Z Xu, Y Zhang, C Wu, S Coleman, Neuropsychologia. 1461075062020</p>
<p>A deep multi-source adaptation transfer network for cross-subject electroencephalogram emotion recognition. F Wang, W Zhang, Z Xu, J Ping, H Chu, Neural Computing and Applications. 2021a</p>
<p>Eeg-based emotion recognition using frequency domain features and support vector machines. X.-W Wang, D Nie, B.-L Lu, International conference on neural information processing. Springer2011</p>
<p>Cross-subject eeg emotion classification based on few-label adversarial domain adaption. Y Wang, J Liu, Q Ruan, S Wang, C Wang, Expert Systems with Applications. 1851155812021b</p>
<p>A prototype-based spd matrix network for domain adaptation eeg emotion recognition. Y Wang, S Qiu, X Ma, H He, Pattern Recognition. 1101076262021c</p>
<p>Relative effectiveness and validity of mood induction procedures: A meta-analysis. R Westermann, K Spies, G Stahl, F W Hesse, European Journal of social psychology. 2641996</p>
<p>Robust principal component analysis: Exact recovery of corrupted low-rank matrices via convex optimization. J Wright, A Ganesh, S Rao, Y Peng, Y Ma, Advances in neural information processing systems. 200922</p>
<p>Transfer learning for eeg-based braincomputer interfaces: A review of progress made since. D Wu, Y Xu, B.-L Lu, IEEE Transactions on Cognitive and Developmental Systems. 1412020. 2016</p>
<p>Feature transfer learning in eeg-based emotion recognition. B Xue, Z Lv, J Xue, 2020 Chinese Automation Congress (CAC). IEEE2020</p>
<p>Multi-method fusion of cross-subject emotion recognition based on high-dimensional eeg features. F Yang, X Zhao, W Jiang, P Gao, G Liu, Frontiers in computational neuroscience. 13532019</p>
<p>Improving session-to-session transfer performance of emotion recognition using adaptive support vector machine. K Yang, G Bao, Y Zeng, L Tong, J Shu, B Yan, Journal of Physics: Conference Series. IOP Publishing2020160142028</p>
<p>Cross-subject eeg-based emotion recognition using adversarial domain adaption with attention mechanism. Y Ye, X Zhu, Y Li, T Pan, W He, 2021 43rd Annual International Conference of the IEEE Engineering in Medicine &amp; Biology Society (EMBC). IEEE2021</p>
<p>Cross-subject eeg feature selection for emotion recognition using transfer recursive feature elimination. Z Yin, Y Wang, L Liu, W Zhang, J Zhang, Frontiers in neurorobotics. 11192017</p>
<p>Classification of human emotions from eeg signals using statistical features and neural network. C T Yuen, W San San, T C Seong, M Rizon, International Journal of Integrated Engineering. 312009</p>
<p>Relieff-based eeg sensor selection methods for emotion recognition. J Zhang, M Chen, S Zhao, S Hu, Z Shi, Y Cao, Sensors. 161015582016</p>
<p>Crosssubject eeg-based emotion recognition with deep domain confusion. W Zhang, F Wang, Y Jiang, Z Xu, S Wu, Y Zhang, International conference on intelligent robotics and applications. Springer2019a</p>
<p>Eeg feature selection for emotion recognition based on cross-subject recursive feature elimination. W Zhang, Z Yin, 2020 39th Chinese Control Conference (CCC). IEEE2020</p>
<p>Individual similarity guided transfer modeling for eeg-based emotion recognition. X Zhang, W Liang, T Ding, J Pan, J Shen, X Huang, J Gao, 2019 IEEE International Conference on Bioinformatics and Biomedicine (BIBM). IEEE2019b</p>
<p>Writer adaptation with style transfer mapping. X.-Y Zhang, C.-L Liu, IEEE transactions on pattern analysis and machine intelligence. 201235</p>
<p>Spectral and time-frequency analysis. Z Zhang, EEG Signal Processing and feature extraction. Springer2019</p>
<p>Frontal eeg asymmetry and middle line power difference in discrete emotions. G Zhao, Y Zhang, Y Ge, Frontiers in behavioral neuroscience. 122252018</p>
<p>Plug-and-play domain adaptation for cross-subject eeg-based emotion recognition. L.-M Zhao, X Yan, B.-L Lu, Proceedings of the 35th AAAI Conference on Artificial Intelligence. sn. the 35th AAAI Conference on Artificial Intelligence. sn2021</p>
<p>Investigating critical frequency bands and channels for eeg-based emotion recognition with deep neural networks. W.-L Zheng, B.-L Lu, IEEE Transactions on autonomous mental development. 732015</p>
<p>Personalizing eeg-based affective models with transfer learning. W.-L Zheng, B.-L Lu, Proceedings of the twenty-fifth international joint conference on artificial intelligence. the twenty-fifth international joint conference on artificial intelligence2016</p>
<p>Transfer components between subjects for eeg-based emotion recognition. W.-L Zheng, Y.-Q Zhang, J.-Y Zhu, B.-L Lu, 2015 international conference on affective computing and intelligent interaction (ACII). IEEE2015</p>
<p>Eeg-based emotion recognition using regularized graph neural networks. P Zhong, D Wang, C Miao, IEEE Transactions on Affective Computing. 2020</p>
<p>An eeg emotion recognition method based on transfer learning and echo state network for hilcps. Microprocessors and Microsystems. J Zhou, S Chu, X Li, F Xiao, L Sun, 2020a103381</p>
<p>J Zhou, G Cui, S Hu, Z Zhang, C Yang, Z Liu, L Wang, C Li, M Sun, Graph neural networks: A review of methods and applications. AI Open. 2020b1</p>
<p>Maximum mean discrepancy based multiple kernel learning for incomplete multimodality neuroimaging data. X Zhu, K.-H Thung, E Adeli, Y Zhang, D Shen, International Conference on Medical Image Computing and Computer-Assisted Intervention. Springer2017</p>            </div>
        </div>

    </div>
</body>
</html>