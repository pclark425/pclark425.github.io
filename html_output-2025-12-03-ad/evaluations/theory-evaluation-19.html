<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Theory Evaluation theory-evaluation-19 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Theory Evaluation Details for theory-evaluation-19</h1>

        <div class="section">
            <h2>Theory Evaluation (General Information)</h2>
            <div class="info-section">
                <p><strong>Evaluation ID:</strong> theory-evaluation-19</p>
                <p><strong>This evaluation is for theory ID:</strong> <a href="../theories/theory-335.html">theory-335</a></p>
                <p><strong>This evaluation resulted in these revised theories:</strong> <a href="../theories/theory-379.html">theory-379</a></p>
                <p><strong>Overall Support or Contradict:</strong> support</p>
                <p><strong>Overall Support or Contradict Explanation:</strong> The evidence strongly supports the theory's core claims about compositional generalization gaps, curriculum benefits, and non-linear depth scaling, with multiple studies providing convergent evidence. However, the evidence also reveals critical missing components (representation geometry, architecture effects, multi-modal considerations) and important nuances (curricula can introduce spurious correlations, primitive mastery alone is insufficient) that should be incorporated to make the theory more complete, mechanistic, and predictive across diverse domains and architectures.</p>
            </div>
        </div>

        <div class="section">
            <h2>Theory Evaluation (Components)</h2>

            <h3>Fully Supporting Evidence</h3>
<ol>
    <li>Multiple studies demonstrate substantial compositional generalization gaps exist: COGITAO CompGen shows ID-OOD gaps of 12.7-72.5 percentage points across settings (C1-C3), MLC shows gaps of ~13-22 pp between trained and novel compositions (99.92% 3-shot vs 78-87% systematicity), and RL experiments show primitive mastery (>69% accuracy) failing to transfer to compositions (0-15% accuracy), with gaps exceeding 50-60 pp. <a href="../results/extraction-result-2019.html#e2019.0" class="evidence-link">[e2019.0]</a> <a href="../results/extraction-result-2017.html#e2017.0" class="evidence-link">[e2017.0]</a> <a href="../results/extraction-result-2008.html#e2008.0" class="evidence-link">[e2008.0]</a> </li>
    <li>Curriculum approaches consistently and substantially outperform non-curriculum baselines: MLC achieves 86.73% mean OOD accuracy vs 0% for static seq2seq training (gap of ~87 pp), Determiner curriculum (4D→8D) reduces training episodes by ~15% while maintaining ~79% zero-shot generalization, and Preposition curriculum enables convergence where baseline completely fails (>3.5M episodes without convergence vs ~2.2-2.9M with curriculum achieving 76% zero-shot). <a href="../results/extraction-result-2017.html#e2017.0" class="evidence-link">[e2017.0]</a> <a href="../results/extraction-result-2017.html#e2017.2" class="evidence-link">[e2017.2]</a> <a href="../results/extraction-result-2013.html#e2013.0" class="evidence-link">[e2013.0]</a> <a href="../results/extraction-result-2013.html#e2013.1" class="evidence-link">[e2013.1]</a> </li>
    <li>Non-linear (super-linear) scaling with composition depth is empirically confirmed: MLC ablations show catastrophic drops when removing intermediate (level-1) compositions (86.73% → 21.01%, a 65.7 pp drop), indicating that jumping directly to depth-3 compositions without intermediate practice causes disproportionate failure. COGITAO C3 experiments show dramatic OOD collapse when extrapolating from depth-2 training to depth-3 testing (OOD accuracies near 1-6% for most models). <a href="../results/extraction-result-2017.html#e2017.1" class="evidence-link">[e2017.1]</a> <a href="../results/extraction-result-2019.html#e2019.0" class="evidence-link">[e2019.0]</a> </li>
    <li>Compositional diversity is critical and quantity alone is insufficient: from-scratch (n,k) experiments show that increasing combinatorial diversity (higher n or k) substantially improves zero-shot OOD accuracy (from random-level to >90% in some cases), while dataset-size scaling tests show that increasing sample count by 4× at fixed combinatorial coverage does not reduce the 60-80% generalization gap. Three-phase feature learning shows representations progress from spurious to linearly factored as diversity increases. <a href="../results/extraction-result-2005.html#e2005.0" class="evidence-link">[e2005.0]</a> <a href="../results/extraction-result-2005.html#e2005.1" class="evidence-link">[e2005.1]</a> <a href="../results/extraction-result-2005.html#e2005.2" class="evidence-link">[e2005.2]</a> </li>
    <li>Specific curriculum components are causally important: MLC ablations show that removing the auxiliary copy task reduces OOD performance from 86.73% to 69.05% (17.7 pp drop), removing primitives reduces it to 75.27% (11.5 pp drop), and removing level-1 compositions causes catastrophic failure (21.01%, 65.7 pp drop). This demonstrates that each curriculum phase contributes materially to generalization. <a href="../results/extraction-result-2017.html#e2017.1" class="evidence-link">[e2017.1]</a> </li>
    <li>Primitive skill learnability with small datasets validates the primitives-first approach: Atomic Task Learnability study shows that atomic tasks are reliably learnable with ≤500 examples (often achieving near 100% accuracy), confirming that primitive mastery is feasible with limited data and can serve as a foundation for compositional learning. <a href="../results/extraction-result-2020.html#e2020.4" class="evidence-link">[e2020.4]</a> </li>
</ol>            <h3>Partially Supporting Evidence</h3>
<ol>
    <li>Primitive mastery aids composition but format, alignment, and combination method matter critically: ComposableCoT shows that training primitives in a composition-friendly format (with proxy prefixes/suffixes) enables substantially better zero-shot composition than standard formats, often matching or exceeding supervised compositional fine-tuning. Compositional Ablation Study shows gains depend strongly on semantic alignment of primitive pairs (original pairings: +7.5 to +15 pp; replacing one component: +2-5 pp; replacing both: -18 to -3 pp). <a href="../results/extraction-result-2020.html#e2020.0" class="evidence-link">[e2020.0]</a> <a href="../results/extraction-result-2020.html#e2020.2" class="evidence-link">[e2020.2]</a> <a href="../results/extraction-result-2020.html#e2020.3" class="evidence-link">[e2020.3]</a> <a href="../results/extraction-result-2008.html#e2008.1" class="evidence-link">[e2008.1]</a> </li>
    <li>Curriculum benefits are confirmed but design details matter substantially: curriculum-length manipulation shows that the specific ratio of primitive to compositional examples modulates strategy emergence (shorter compositional blocks foster stronger compositional strategies; longer blocks produce mixed strategies). Robustness across moduli shows curriculum benefits depend on task difficulty and adequate primitive exposure (P=41 required ≥11 subtask examples vs fewer for P=59). <a href="../results/extraction-result-2011.html#e2011.3" class="evidence-link">[e2011.3]</a> <a href="../results/extraction-result-2011.html#e2011.4" class="evidence-link">[e2011.4]</a> </li>
    <li>Retrieval-augmented approaches that align primitive representations across modalities improve compositional generalization: RAG-for-MSCG shows consistent improvements (+1.8-3.0 pp overall; CFR: 72.41%→74.21%, Qwen-VL: 68.49%→71.53%), with joint retrieval from both linguistic and visual databases outperforming single-modality retrieval. This suggests representation alignment is a practical mechanism for reducing gaps. <a href="../results/extraction-result-2006.html#e2006.0" class="evidence-link">[e2006.0]</a> <a href="../results/extraction-result-2006.html#e2006.2" class="evidence-link">[e2006.2]</a> </li>
    <li>Rejection sampling fine-tuning (RFT) on small compositional datasets can effectively bootstrap composition from atomic skills: RFT starting from ComposableCoT combined models yields the strongest improvement on compositional tasks within limited data budgets, outperforming standard continued fine-tuning and multitask baselines, indicating that primitive-trained models can be efficiently adapted to novel compositions with targeted supervision. <a href="../results/extraction-result-2020.html#e2020.1" class="evidence-link">[e2020.1]</a> </li>
    <li>Intrinsic analysis shows that composable formats produce more robust compositional reasoning: ComposableCoT models generate both atomic CoT patterns in compositional outputs far more frequently than StandardCoT (e.g., 100% vs 85.3% for Qwen2.5 on Last Letter + Multiplication), and ProxyPrefix ablations show that training with arbitrary/uninformative prefixes (random letters) produces better out-of-domain generalization than realistic prefixes, supporting the theory that reducing spurious correlations in primitive training aids composition. <a href="../results/extraction-result-2020.html#e2020.2" class="evidence-link">[e2020.2]</a> <a href="../results/extraction-result-2020.html#e2020.3" class="evidence-link">[e2020.3]</a> </li>
</ol>            <h3>Fully Contradicting Evidence</h3>
<p class="empty-note">No evidence provided.</p>            <h3>Partially Contradicting Evidence</h3>
<ol>
    <li>Curricula can introduce spurious correlations rather than only reducing them: mismatch experiments show curriculum-trained models fail catastrophically when in-context subtasks use different parameters than the compositional block, demonstrating strong reliance on contextual correlations that the curriculum created. This directly contradicts the theory's claim that curricula primarily reduce spurious correlations - they can also create context-dependent spurious patterns. <a href="../results/extraction-result-2011.html#e2011.2" class="evidence-link">[e2011.2]</a> </li>
    <li>General-purpose LLMs largely fail at systematic compositional generalization despite massive pretraining: GPT-4o achieves 22.28% on 3-shot but only 0.99% on systematicity (21.3 pp drop), o3-mini shows 64.04%→0.53% (63.5 pp drop), suggesting that extensive 'primitive' exposure through pretraining doesn't provide the right kind of automaticity or that scale alone is insufficient without structured curriculum. This challenges the theory's assumption that primitive mastery (however achieved) enables composition. <a href="../results/extraction-result-2017.html#e2017.3" class="evidence-link">[e2017.3]</a> </li>
    <li>Negative transfer can occur from continued training even after primitive mastery: RL Generalization Experiments show that optimization can entrench brittle heuristics and sometimes reverse prior OOD gains (matrix-rank OOD dropped ~30 pp after RL), contradicting the theory's implicit assumption that more training on primitives or compositions monotonically improves generalization. The theory needs to account for when training harms rather than helps. <a href="../results/extraction-result-2008.html#e2008.0" class="evidence-link">[e2008.0]</a> </li>
</ol>            <h3>Potentially Modifying Evidence</h3>
<ol>
    <li>Representation geometry (linear factorization) is a critical mechanism not explicitly addressed by the theory: three-phase feature learning shows representations progress from spurious/entangled to linearly factored as diversity increases (R²>0.8, cosine similarity<0.1 enables >90% zero-shot), minimal compositional learning proposition proves that k=2 combinations suffice under ideal linear factorization, and pretrained model probing shows partial linear structure enables better OOD performance. The theory should incorporate representational structure as a key mechanistic factor. <a href="../results/extraction-result-2005.html#e2005.2" class="evidence-link">[e2005.2]</a> <a href="../results/extraction-result-2005.html#e2005.3" class="evidence-link">[e2005.3]</a> <a href="../results/extraction-result-2005.html#e2005.4" class="evidence-link">[e2005.4]</a> </li>
    <li>Architecture and inductive biases dramatically modulate the generalization gap in ways the theory doesn't account for: COGITAO EnvGen shows different architectures produce vastly different ID-OOD gaps on identical tasks (G5: Vanilla 70pp, Grid 97.8pp, LLaDA 57pp), and environmental shifts interact with architectural biases to affect generalization. The CompGen study shows Grid-ViT achieves 71% ID but only 18.7% OOD on C1 (52.4pp gap) while LLaDA shows 54.2% ID and 26.2% OOD (28pp gap). The theory needs to specify how curriculum design should adapt to architecture. <a href="../results/extraction-result-2019.html#e2019.1" class="evidence-link">[e2019.1]</a> <a href="../results/extraction-result-2019.html#e2019.0" class="evidence-link">[e2019.0]</a> </li>
    <li>Cross-modal compositional generalization introduces additional complexity not addressed by the theory: GQA-MSCG shows that multi-sourced compositions (LL, VV, LV) have different difficulty profiles and that performance degrades as co-occurrence level increases (Level-1→Level-3), with modality-specific retrieval helping corresponding splits. The theory should extend to account for multi-modal primitive types, their interactions, and modality-specific curriculum considerations. <a href="../results/extraction-result-2006.html#e2006.1" class="evidence-link">[e2006.1]</a> <a href="../results/extraction-result-2006.html#e2006.0" class="evidence-link">[e2006.0]</a> <a href="../results/extraction-result-2006.html#e2006.2" class="evidence-link">[e2006.2]</a> </li>
    <li>The theory's empirical scope is severely limited to shallow compositions (depth ≤2): Composition Depth Limitation explicitly notes experiments only evaluate pairwise compositions and that deeper compositions remain untested. D+P few-shot shows that even with curriculum pretraining, scaling to very large combinatorial spaces (160k combinations) yields substantial gaps (53% success vs 80%+ primitive performance). The theory's claims about depth scaling beyond 2-3 primitives lack direct empirical support. <a href="../results/extraction-result-2020.html#e2020.5" class="evidence-link">[e2020.5]</a> <a href="../results/extraction-result-2013.html#e2013.2" class="evidence-link">[e2013.2]</a> </li>
    <li>In-context learning and meta-learning provide alternative paths to compositional generalization that don't require the strict three-phase structure: Curriculum vs Vanilla ICL study shows that providing primitives in-context (not as separate pretraining) enables zero-shot composition with better robustness than vanilla training. Linear-probe analysis reveals this works through explicit intermediate representations formed during inference. This suggests the theory's three-phase structure may be one approach among several, not a universal requirement. <a href="../results/extraction-result-2011.html#e2011.0" class="evidence-link">[e2011.0]</a> <a href="../results/extraction-result-2011.html#e2011.1" class="evidence-link">[e2011.1]</a> </li>
    <li>Semantic alignment and compatibility of primitives matter for composition success: Compositional Ablation Study shows that only semantically-coherent skill pairings yielded post-RL compositional gains (original: +7.5/+15pp; replacing one: +2-5pp; replacing both: -18/-3pp), indicating that successful composition requires compatible joint training distributions, not just individual primitive mastery. The theory should specify conditions for primitive compatibility. <a href="../results/extraction-result-2008.html#e2008.1" class="evidence-link">[e2008.1]</a> </li>
    <li>The theory doesn't account for curriculum learning being mentioned as a promising future direction in multiple studies without empirical validation: COGITAO and OMEGA papers explicitly recommend curriculum scaffolding and dynamically ordered tasks as future work to bridge compositional gaps, but provide no experimental data. This suggests the theory is ahead of empirical validation in some domains. <a href="../results/extraction-result-2019.html#e2019.2" class="evidence-link">[e2019.2]</a> <a href="../results/extraction-result-2008.html#e2008.2" class="evidence-link">[e2008.2]</a> </li>
</ol>            <h3>Suggested Revisions</h3>
            <ol>
                <li>Add representation geometry (specifically linear factorization of concept features) as a fourth key factor determining the generalization gap, alongside primitive automaticity, compositional diversity, and spurious correlations. Include quantitative statements about how linear factorization (R²>0.8, orthogonality) enables efficient generalization.</li>
                <li>Modify the three-phase curriculum structure to be more flexible and architecture-dependent: specify that primitives can be learned through pretraining, in-context, or via meta-learning depending on the domain and architecture. Add that the optimal structure depends on whether primitives can be meaningfully isolated and on architectural inductive biases.</li>
                <li>Add explicit consideration of architecture and inductive biases as a major factor: specify how curriculum design should adapt based on model architecture (convolutional vs transformer vs modular networks) and include statements about how architectural choices interact with the generalization gap (e.g., Grid-ViT vs Vanilla-ViT showing 52pp vs 12pp gaps on same tasks).</li>
                <li>Extend the theory to multi-modal settings: add statements about how cross-modal compositions create additional challenges, how modality-specific primitive types should be handled in curricula, and how representation alignment across modalities affects the gap. Include the finding that performance degrades with co-occurrence level (Level-1→Level-3).</li>
                <li>Refine the spurious correlation component to acknowledge bidirectionality: specify that curricula can both reduce AND introduce spurious correlations (e.g., contextual dependencies from in-context learning), and provide design principles to minimize curriculum-induced spurious patterns (e.g., using arbitrary proxy prefixes, varying contexts systematically).</li>
                <li>Add explicit boundary conditions on scope: state that current evidence primarily supports the theory for compositions of depth ≤2-3, that claims about deeper compositions or exponential scaling lack direct empirical support, and that very large combinatorial spaces (>100k combinations) may require additional mechanisms beyond the three-phase structure.</li>
                <li>Incorporate negative transfer considerations: add statements about how continued training or optimization can harm generalization by entrenching shortcuts or brittle heuristics, specify conditions under which training should pause or curriculum should adapt (e.g., when OOD performance decreases), and note that the relationship between training and generalization is non-monotonic.</li>
                <li>Add primitive compatibility requirements: specify that primitives must be semantically aligned or compatible for successful composition, not just individually mastered. Include guidance on assessing compatibility and designing joint training distributions that preserve compositional structure.</li>
                <li>Add quantitative operational definitions for compositional diversity: specify metrics for structural vs contextual diversity based on the linear factorization framework (e.g., k=2 combinations per value under ideal conditions, higher k needed for non-ideal representations), and provide guidance on measuring when sufficient diversity has been achieved.</li>
                <li>Clarify the relationship between primitive automaticity thresholds and composition depth: specify that primitives used in deeper compositions require higher automaticity (closer to 100%) than those in shallow compositions, and that the automaticity threshold should be adaptive to planned composition complexity.</li>
            </ol>
        </div>

        <div class="section">
            <h2>Theory Evaluation (Debug)</h2>
            <pre><code>{
    "id": "theory-evaluation-19",
    "theory_id": "theory-335",
    "fully_supporting_evidence": [
        {
            "text": "Multiple studies demonstrate substantial compositional generalization gaps exist: COGITAO CompGen shows ID-OOD gaps of 12.7-72.5 percentage points across settings (C1-C3), MLC shows gaps of ~13-22 pp between trained and novel compositions (99.92% 3-shot vs 78-87% systematicity), and RL experiments show primitive mastery (&gt;69% accuracy) failing to transfer to compositions (0-15% accuracy), with gaps exceeding 50-60 pp.",
            "uuids": [
                "e2019.0",
                "e2017.0",
                "e2008.0"
            ]
        },
        {
            "text": "Curriculum approaches consistently and substantially outperform non-curriculum baselines: MLC achieves 86.73% mean OOD accuracy vs 0% for static seq2seq training (gap of ~87 pp), Determiner curriculum (4D→8D) reduces training episodes by ~15% while maintaining ~79% zero-shot generalization, and Preposition curriculum enables convergence where baseline completely fails (&gt;3.5M episodes without convergence vs ~2.2-2.9M with curriculum achieving 76% zero-shot).",
            "uuids": [
                "e2017.0",
                "e2017.2",
                "e2013.0",
                "e2013.1"
            ]
        },
        {
            "text": "Non-linear (super-linear) scaling with composition depth is empirically confirmed: MLC ablations show catastrophic drops when removing intermediate (level-1) compositions (86.73% → 21.01%, a 65.7 pp drop), indicating that jumping directly to depth-3 compositions without intermediate practice causes disproportionate failure. COGITAO C3 experiments show dramatic OOD collapse when extrapolating from depth-2 training to depth-3 testing (OOD accuracies near 1-6% for most models).",
            "uuids": [
                "e2017.1",
                "e2019.0"
            ]
        },
        {
            "text": "Compositional diversity is critical and quantity alone is insufficient: from-scratch (n,k) experiments show that increasing combinatorial diversity (higher n or k) substantially improves zero-shot OOD accuracy (from random-level to &gt;90% in some cases), while dataset-size scaling tests show that increasing sample count by 4× at fixed combinatorial coverage does not reduce the 60-80% generalization gap. Three-phase feature learning shows representations progress from spurious to linearly factored as diversity increases.",
            "uuids": [
                "e2005.0",
                "e2005.1",
                "e2005.2"
            ]
        },
        {
            "text": "Specific curriculum components are causally important: MLC ablations show that removing the auxiliary copy task reduces OOD performance from 86.73% to 69.05% (17.7 pp drop), removing primitives reduces it to 75.27% (11.5 pp drop), and removing level-1 compositions causes catastrophic failure (21.01%, 65.7 pp drop). This demonstrates that each curriculum phase contributes materially to generalization.",
            "uuids": [
                "e2017.1"
            ]
        },
        {
            "text": "Primitive skill learnability with small datasets validates the primitives-first approach: Atomic Task Learnability study shows that atomic tasks are reliably learnable with ≤500 examples (often achieving near 100% accuracy), confirming that primitive mastery is feasible with limited data and can serve as a foundation for compositional learning.",
            "uuids": [
                "e2020.4"
            ]
        }
    ],
    "partially_supporting_evidence": [
        {
            "text": "Primitive mastery aids composition but format, alignment, and combination method matter critically: ComposableCoT shows that training primitives in a composition-friendly format (with proxy prefixes/suffixes) enables substantially better zero-shot composition than standard formats, often matching or exceeding supervised compositional fine-tuning. Compositional Ablation Study shows gains depend strongly on semantic alignment of primitive pairs (original pairings: +7.5 to +15 pp; replacing one component: +2-5 pp; replacing both: -18 to -3 pp).",
            "uuids": [
                "e2020.0",
                "e2020.2",
                "e2020.3",
                "e2008.1"
            ]
        },
        {
            "text": "Curriculum benefits are confirmed but design details matter substantially: curriculum-length manipulation shows that the specific ratio of primitive to compositional examples modulates strategy emergence (shorter compositional blocks foster stronger compositional strategies; longer blocks produce mixed strategies). Robustness across moduli shows curriculum benefits depend on task difficulty and adequate primitive exposure (P=41 required ≥11 subtask examples vs fewer for P=59).",
            "uuids": [
                "e2011.3",
                "e2011.4"
            ]
        },
        {
            "text": "Retrieval-augmented approaches that align primitive representations across modalities improve compositional generalization: RAG-for-MSCG shows consistent improvements (+1.8-3.0 pp overall; CFR: 72.41%→74.21%, Qwen-VL: 68.49%→71.53%), with joint retrieval from both linguistic and visual databases outperforming single-modality retrieval. This suggests representation alignment is a practical mechanism for reducing gaps.",
            "uuids": [
                "e2006.0",
                "e2006.2"
            ]
        },
        {
            "text": "Rejection sampling fine-tuning (RFT) on small compositional datasets can effectively bootstrap composition from atomic skills: RFT starting from ComposableCoT combined models yields the strongest improvement on compositional tasks within limited data budgets, outperforming standard continued fine-tuning and multitask baselines, indicating that primitive-trained models can be efficiently adapted to novel compositions with targeted supervision.",
            "uuids": [
                "e2020.1"
            ]
        },
        {
            "text": "Intrinsic analysis shows that composable formats produce more robust compositional reasoning: ComposableCoT models generate both atomic CoT patterns in compositional outputs far more frequently than StandardCoT (e.g., 100% vs 85.3% for Qwen2.5 on Last Letter + Multiplication), and ProxyPrefix ablations show that training with arbitrary/uninformative prefixes (random letters) produces better out-of-domain generalization than realistic prefixes, supporting the theory that reducing spurious correlations in primitive training aids composition.",
            "uuids": [
                "e2020.2",
                "e2020.3"
            ]
        }
    ],
    "fully_contradicting_evidence": [],
    "partially_contradicting_evidence": [
        {
            "text": "Curricula can introduce spurious correlations rather than only reducing them: mismatch experiments show curriculum-trained models fail catastrophically when in-context subtasks use different parameters than the compositional block, demonstrating strong reliance on contextual correlations that the curriculum created. This directly contradicts the theory's claim that curricula primarily reduce spurious correlations - they can also create context-dependent spurious patterns.",
            "uuids": [
                "e2011.2"
            ]
        },
        {
            "text": "General-purpose LLMs largely fail at systematic compositional generalization despite massive pretraining: GPT-4o achieves 22.28% on 3-shot but only 0.99% on systematicity (21.3 pp drop), o3-mini shows 64.04%→0.53% (63.5 pp drop), suggesting that extensive 'primitive' exposure through pretraining doesn't provide the right kind of automaticity or that scale alone is insufficient without structured curriculum. This challenges the theory's assumption that primitive mastery (however achieved) enables composition.",
            "uuids": [
                "e2017.3"
            ]
        },
        {
            "text": "Negative transfer can occur from continued training even after primitive mastery: RL Generalization Experiments show that optimization can entrench brittle heuristics and sometimes reverse prior OOD gains (matrix-rank OOD dropped ~30 pp after RL), contradicting the theory's implicit assumption that more training on primitives or compositions monotonically improves generalization. The theory needs to account for when training harms rather than helps.",
            "uuids": [
                "e2008.0"
            ]
        }
    ],
    "potentially_modifying_evidence": [
        {
            "text": "Representation geometry (linear factorization) is a critical mechanism not explicitly addressed by the theory: three-phase feature learning shows representations progress from spurious/entangled to linearly factored as diversity increases (R²&gt;0.8, cosine similarity&lt;0.1 enables &gt;90% zero-shot), minimal compositional learning proposition proves that k=2 combinations suffice under ideal linear factorization, and pretrained model probing shows partial linear structure enables better OOD performance. The theory should incorporate representational structure as a key mechanistic factor.",
            "uuids": [
                "e2005.2",
                "e2005.3",
                "e2005.4"
            ]
        },
        {
            "text": "Architecture and inductive biases dramatically modulate the generalization gap in ways the theory doesn't account for: COGITAO EnvGen shows different architectures produce vastly different ID-OOD gaps on identical tasks (G5: Vanilla 70pp, Grid 97.8pp, LLaDA 57pp), and environmental shifts interact with architectural biases to affect generalization. The CompGen study shows Grid-ViT achieves 71% ID but only 18.7% OOD on C1 (52.4pp gap) while LLaDA shows 54.2% ID and 26.2% OOD (28pp gap). The theory needs to specify how curriculum design should adapt to architecture.",
            "uuids": [
                "e2019.1",
                "e2019.0"
            ]
        },
        {
            "text": "Cross-modal compositional generalization introduces additional complexity not addressed by the theory: GQA-MSCG shows that multi-sourced compositions (LL, VV, LV) have different difficulty profiles and that performance degrades as co-occurrence level increases (Level-1→Level-3), with modality-specific retrieval helping corresponding splits. The theory should extend to account for multi-modal primitive types, their interactions, and modality-specific curriculum considerations.",
            "uuids": [
                "e2006.1",
                "e2006.0",
                "e2006.2"
            ]
        },
        {
            "text": "The theory's empirical scope is severely limited to shallow compositions (depth ≤2): Composition Depth Limitation explicitly notes experiments only evaluate pairwise compositions and that deeper compositions remain untested. D+P few-shot shows that even with curriculum pretraining, scaling to very large combinatorial spaces (160k combinations) yields substantial gaps (53% success vs 80%+ primitive performance). The theory's claims about depth scaling beyond 2-3 primitives lack direct empirical support.",
            "uuids": [
                "e2020.5",
                "e2013.2"
            ]
        },
        {
            "text": "In-context learning and meta-learning provide alternative paths to compositional generalization that don't require the strict three-phase structure: Curriculum vs Vanilla ICL study shows that providing primitives in-context (not as separate pretraining) enables zero-shot composition with better robustness than vanilla training. Linear-probe analysis reveals this works through explicit intermediate representations formed during inference. This suggests the theory's three-phase structure may be one approach among several, not a universal requirement.",
            "uuids": [
                "e2011.0",
                "e2011.1"
            ]
        },
        {
            "text": "Semantic alignment and compatibility of primitives matter for composition success: Compositional Ablation Study shows that only semantically-coherent skill pairings yielded post-RL compositional gains (original: +7.5/+15pp; replacing one: +2-5pp; replacing both: -18/-3pp), indicating that successful composition requires compatible joint training distributions, not just individual primitive mastery. The theory should specify conditions for primitive compatibility.",
            "uuids": [
                "e2008.1"
            ]
        },
        {
            "text": "The theory doesn't account for curriculum learning being mentioned as a promising future direction in multiple studies without empirical validation: COGITAO and OMEGA papers explicitly recommend curriculum scaffolding and dynamically ordered tasks as future work to bridge compositional gaps, but provide no experimental data. This suggests the theory is ahead of empirical validation in some domains.",
            "uuids": [
                "e2019.2",
                "e2008.2"
            ]
        }
    ],
    "suggested_revisions": [
        "Add representation geometry (specifically linear factorization of concept features) as a fourth key factor determining the generalization gap, alongside primitive automaticity, compositional diversity, and spurious correlations. Include quantitative statements about how linear factorization (R²&gt;0.8, orthogonality) enables efficient generalization.",
        "Modify the three-phase curriculum structure to be more flexible and architecture-dependent: specify that primitives can be learned through pretraining, in-context, or via meta-learning depending on the domain and architecture. Add that the optimal structure depends on whether primitives can be meaningfully isolated and on architectural inductive biases.",
        "Add explicit consideration of architecture and inductive biases as a major factor: specify how curriculum design should adapt based on model architecture (convolutional vs transformer vs modular networks) and include statements about how architectural choices interact with the generalization gap (e.g., Grid-ViT vs Vanilla-ViT showing 52pp vs 12pp gaps on same tasks).",
        "Extend the theory to multi-modal settings: add statements about how cross-modal compositions create additional challenges, how modality-specific primitive types should be handled in curricula, and how representation alignment across modalities affects the gap. Include the finding that performance degrades with co-occurrence level (Level-1→Level-3).",
        "Refine the spurious correlation component to acknowledge bidirectionality: specify that curricula can both reduce AND introduce spurious correlations (e.g., contextual dependencies from in-context learning), and provide design principles to minimize curriculum-induced spurious patterns (e.g., using arbitrary proxy prefixes, varying contexts systematically).",
        "Add explicit boundary conditions on scope: state that current evidence primarily supports the theory for compositions of depth ≤2-3, that claims about deeper compositions or exponential scaling lack direct empirical support, and that very large combinatorial spaces (&gt;100k combinations) may require additional mechanisms beyond the three-phase structure.",
        "Incorporate negative transfer considerations: add statements about how continued training or optimization can harm generalization by entrenching shortcuts or brittle heuristics, specify conditions under which training should pause or curriculum should adapt (e.g., when OOD performance decreases), and note that the relationship between training and generalization is non-monotonic.",
        "Add primitive compatibility requirements: specify that primitives must be semantically aligned or compatible for successful composition, not just individually mastered. Include guidance on assessing compatibility and designing joint training distributions that preserve compositional structure.",
        "Add quantitative operational definitions for compositional diversity: specify metrics for structural vs contextual diversity based on the linear factorization framework (e.g., k=2 combinations per value under ideal conditions, higher k needed for non-ideal representations), and provide guidance on measuring when sufficient diversity has been achieved.",
        "Clarify the relationship between primitive automaticity thresholds and composition depth: specify that primitives used in deeper compositions require higher automaticity (closer to 100%) than those in shallow compositions, and that the automaticity threshold should be adaptive to planned composition complexity."
    ],
    "overall_support_or_contradict": "support",
    "overall_support_or_contradict_explanation": "The evidence strongly supports the theory's core claims about compositional generalization gaps, curriculum benefits, and non-linear depth scaling, with multiple studies providing convergent evidence. However, the evidence also reveals critical missing components (representation geometry, architecture effects, multi-modal considerations) and important nuances (curricula can introduce spurious correlations, primitive mastery alone is insufficient) that should be incorporated to make the theory more complete, mechanistic, and predictive across diverse domains and architectures.",
    "revised_theory_ids": [
        "theory-379"
    ],
    "model_str": "claude-sonnet-4-5-20250929"
}</code></pre>
        </div>
    </div>
</body>
</html>