<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-99 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-99</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-99</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-5.html">extraction-schema-5</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of synaptic plasticity rules, brain connectivity patterns, and how they support learning at different temporal scales (e.g., milliseconds to days).</div>
                <p><strong>Paper ID:</strong> paper-1a1879f7e1abaa056db71ebf2123d01bf6d6a7cf</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/1a1879f7e1abaa056db71ebf2123d01bf6d6a7cf" target="_blank">Meta-SpikePropamine: learning to learn with synaptic plasticity in spiking neural networks</a></p>
                <p><strong>Paper Venue:</strong> Frontiers in Neuroscience</p>
                <p><strong>Paper TL;DR:</strong> It is demonstrated that models of three-factor learning with synaptic plasticity taken from the neuroscience literature can be trained in Spiking Neural Networks with gradient descent via a framework of learning-to-learn to address challenging online learning problems.</p>
                <p><strong>Paper Abstract:</strong> We propose that in order to harness our understanding of neuroscience toward machine learning, we must first have powerful tools for training brain-like models of learning. Although substantial progress has been made toward understanding the dynamics of learning in the brain, neuroscience-derived models of learning have yet to demonstrate the same performance capabilities as methods in deep learning such as gradient descent. Inspired by the successes of machine learning using gradient descent, we introduce a bi-level optimization framework that seeks to both solve online learning tasks and improve the ability to learn online using models of plasticity from neuroscience. We demonstrate that models of three-factor learning with synaptic plasticity taken from the neuroscience literature can be trained in Spiking Neural Networks (SNNs) with gradient descent via a framework of learning-to-learn to address challenging online learning problems. This framework opens a new path toward developing neuroscience inspired online learning algorithms.</p>
                <p><strong>Cost:</strong> 0.02</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e99.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e99.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of synaptic plasticity rules, brain connectivity patterns, and how they support learning at different temporal scales (e.g., milliseconds to days).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Pair-STDP</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Pair-based Spike-Timing-Dependent Plasticity (pair-based STDP)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A spike-timing dependent plasticity rule where synaptic potentiation (LTP) and depression (LTD) are produced as products of pre- and post-synaptic spike-timing traces; implemented additively in the cue-association experiments to maintain separate LTP and LTD eligibility traces.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>synaptic_rule_name</strong></td>
                            <td>Pair-based STDP (additive)</td>
                        </tr>
                        <tr>
                            <td><strong>synaptic_rule_description</strong></td>
                            <td>Weight updates are computed as the sum of an LTP term proportional to a pre-synaptic trace x_i times a post-synaptic spike s_j and an LTD term proportional to a post-synaptic trace x_j times a pre-synaptic spike s_i: ΔW_ij = η_+ x_i(t) s_j(t) - η_- x_j(t) s_i(t). In the experiments an additive form (η constants independent of W) was used and separate eligibility traces for LTP and LTD were maintained. Key parameters: trace decay α_x (related to time constant τ), update amplitudes η_+, η_-, and optional soft bounds W_min/W_max if multiplicative variants are used.</td>
                        </tr>
                        <tr>
                            <td><strong>temporal_scale</strong></td>
                            <td>Operates on fast spike-timing scales (sub-millisecond to milliseconds for spike coincidences and pairing effects) and on trace decay scales set by α_x which in simulation map to tens-to-hundreds of milliseconds; in broader theory these traces can bridge to seconds (behavioral timescales) when combined with neuromodulatory gating.</td>
                        </tr>
                        <tr>
                            <td><strong>brain_region_circuit</strong></td>
                            <td>Not specified — used as a generic plasticity rule inside a computational Differentiable Plasticity SNN (DP-SNN); intended to be biologically-plausible rather than region-specific.</td>
                        </tr>
                        <tr>
                            <td><strong>connectivity_pattern</strong></td>
                            <td>Applied to input→hidden synapses in a one-hidden-layer SNN; network initialized with 50% connection probability and 80% excitatory / 20% inhibitory assignment of synapses.</td>
                        </tr>
                        <tr>
                            <td><strong>learning_type</strong></td>
                            <td>Associative/one-shot continual learning (cue association) and rapid within-lifetime adaptation.</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_or_model</strong></td>
                            <td>Computational model / simulation (spiking neural network experiments in this paper).</td>
                        </tr>
                        <tr>
                            <td><strong>multi_timescale_interaction</strong></td>
                            <td>Pair-based STDP produces fast eligibility traces from ms spike interactions; these traces persist over a trace time-constant and are converted into lasting weight changes only when a slower neuromodulatory signal (third factor) is present, thereby linking millisecond spike timing to behavioral feedback arriving tens-to-hundreds of ms after stimuli in the simulations (and seconds/minutes in biological interpretation).</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>An additive pair-based STDP rule combined with a learned neuromodulatory signal enabled one-shot cue-association: the DP-SNN achieved 95.6% test accuracy (averaged over 30 trainings) on M=5 one-shot cue problems, generalized to varying M (e.g., 98.1% at M=1, 96.7% at M=3, 94.2% at M=7, 68.7% at M=15). Pair-STDP served as the inner-loop learning mechanism optimized (meta-learned) by outer-loop gradient descent over many task permutations.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_measure</strong></td>
                            <td>Cue-association test accuracy: 95.6% average (M=5) across 30 random initializations; cross-M results given (see key_findings).</td>
                        </tr>
                        <tr>
                            <td><strong>slow_vs_fast_learning</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>consolidation_mechanism</strong></td>
                            <td>Conversion of fast eligibility traces into synaptic change is gated by neuromodulatory signals (three-factor rule); no separate long-timescale consolidation to days is implemented or reported, but the outer-loop gradient descent shapes plasticity dynamics across meta-training (slow timescale).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Meta-SpikePropamine: learning to learn with synaptic plasticity in spiking neural networks', 'publication_date_yy_mm': '2023-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e99.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e99.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of synaptic plasticity rules, brain connectivity patterns, and how they support learning at different temporal scales (e.g., milliseconds to days).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Triplet-STDP</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Triplet-based Spike-Timing-Dependent Plasticity (triplet-STDP)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A higher-order STDP rule that uses interactions between one pre-synaptic spike and two post-synaptic spikes via a fast and a slow post-synaptic trace to capture frequency- and triplet-dependent plasticity effects not explained by pair-based rules.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>synaptic_rule_name</strong></td>
                            <td>Triplet-based STDP</td>
                        </tr>
                        <tr>
                            <td><strong>synaptic_rule_description</strong></td>
                            <td>LTP depends on the product of a pre-synaptic trace and a slow post-synaptic trace (capturing patterns like pre with two posts), while LTD uses conventional pairwise components; implemented with two post-synaptic traces with different decay constants (fast and slow). Parameters include decay rates (α_x for fast trace, α_τ for slow trace with α_τ > α_x), amplitudes A_+, A_- and possible weight-dependence exponents μ.</td>
                        </tr>
                        <tr>
                            <td><strong>temporal_scale</strong></td>
                            <td>Fast spike timing (milliseconds) for individual spike interactions; slow post-synaptic trace integrates over longer windows (tens to hundreds of milliseconds or longer depending on α_τ) enabling frequency dependence and integration over short behavioral epochs; in biological interpretation can link to seconds-scale phenomena when combined with modulators.</td>
                        </tr>
                        <tr>
                            <td><strong>brain_region_circuit</strong></td>
                            <td>Not specified — used in the DP-SNN for the one-shot character recognition task as a plasticity model intended to better match biological STDP experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>connectivity_pattern</strong></td>
                            <td>Applied to input→hidden synapses in the character-recognition DP-SNN; network connectivity initialized at 50% probability and E/I ratio 80/20.</td>
                        </tr>
                        <tr>
                            <td><strong>learning_type</strong></td>
                            <td>Rapid associative learning / one-shot class encoding (within-trial encoding of a phase-1 exemplar to find match in phase-2).</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_or_model</strong></td>
                            <td>Computational model / simulation (spiking neural network experiments in this paper).</td>
                        </tr>
                        <tr>
                            <td><strong>multi_timescale_interaction</strong></td>
                            <td>The slow post-synaptic trace in triplet-STDP extends the effective integration window beyond single-spike pairings, allowing the rule to be sensitive to spike patterns and rate over a longer short-term window; these synaptic traces can then interact with neuromodulatory signals that arrive only during specific intervals (e.g., phase-1 presentation) to produce rapid single-trial synaptic modifications.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Using triplet-based STDP plus a learned neuromodulatory signal allowed the DP-SNN to perform online one-shot character class recognition with 20.4% test error after 2000 outer-loop gradient updates (much better than a non-plastic SNN which had ~80% error and better than the L2L EProp baseline which had 29.2% error). The triplet rule enabled more biologically-accurate frequency-dependent plasticity for fast single-example learning.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_measure</strong></td>
                            <td>Character recognition test error: DP-SNN 20.4% (after 2000 outer-loop gradient updates); non-plastic SNN ~80% error; L2L EProp 29.2% error; informal human error ~15%. Also DP-SNN achieved 64.1% accuracy on MNIST without additional plasticity parameter training.</td>
                        </tr>
                        <tr>
                            <td><strong>slow_vs_fast_learning</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>consolidation_mechanism</strong></td>
                            <td>Fast synaptic changes during the short (20 ms) phase-1 presentation are instantiated by triplet-STDP eligibility traces gated by neuromodulation; no explicit multi-day consolidation mechanism reported, but outer-loop meta-training constitutes a slower-timescale shaping of the plasticity rule.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Meta-SpikePropamine: learning to learn with synaptic plasticity in spiking neural networks', 'publication_date_yy_mm': '2023-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e99.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e99.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of synaptic plasticity rules, brain connectivity patterns, and how they support learning at different temporal scales (e.g., milliseconds to days).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Eligibility/Three-factor</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Eligibility traces and neuromodulated (three-factor) plasticity</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A three-factor learning rule in which local eligibility traces (capturing pre/post interactions) are formed continuously and only converted into synaptic weight changes when a third, often global or neuron-specific, neuromodulatory signal (e.g., dopamine) is present.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>synaptic_rule_name</strong></td>
                            <td>Eligibility traces / three-factor neuromodulated plasticity</td>
                        </tr>
                        <tr>
                            <td><strong>synaptic_rule_description</strong></td>
                            <td>Local eligibility E_ij(t) accumulates based on functions of pre- and post-synaptic activity and decays with factor γ; synaptic change occurs as ΔW_ij(t) = M(t) E_ij(t) or neuron-specific ΔW_ij = M_j(t) E_ij(t), where M(t) (or M_j(t)) is a neuromodulatory signal. The model supports separate LTP and LTD eligibility traces and allows neuromodulators to scale or reverse potentiation/depression. Important parameters: eligibility decay γ, per-synapse insertion rate α_ij, modulatory magnitude and timing.</td>
                        </tr>
                        <tr>
                            <td><strong>temporal_scale</strong></td>
                            <td>Eligibility traces integrate fast spike interactions (ms) into longer-lasting flags that can persist over tens-to-hundreds of milliseconds (simulation) and in biological theory over seconds-to-minutes (behavioral time scales); neuromodulatory signals can act on similar slower timescales (decision/reward intervals in experiments are tens-to-hundreds of ms; biologically often seconds or longer).</td>
                        </tr>
                        <tr>
                            <td><strong>brain_region_circuit</strong></td>
                            <td>Generic; theory motivated by neuromodulatory systems (e.g., dopaminergic, cholinergic projections) broadly projecting to plastic synapses—no single brain region instantiated in the simulations.</td>
                        </tr>
                        <tr>
                            <td><strong>connectivity_pattern</strong></td>
                            <td>Neuromodulatory signals in the model are computed by a separate neuromodulatory SNN (NM-SNN) that receives sensory and DP hidden activity and produces input-neuron-specific modulatory signals that gate plastic synapses; NM-SNN is two fully-connected layers of 64 CUBA neurons (non-plastic).</td>
                        </tr>
                        <tr>
                            <td><strong>learning_type</strong></td>
                            <td>Credit assignment across behavioral delays, reinforcement-like and associative learning, one-shot learning and continual within-lifetime learning.</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_or_model</strong></td>
                            <td>Computational model / simulation; implements three-factor rules explicitly in SNN experiments and optimizes neuromodulatory dynamics via meta-learning (outer-loop gradient descent).</td>
                        </tr>
                        <tr>
                            <td><strong>multi_timescale_interaction</strong></td>
                            <td>Eligibility traces record fine-timescale spike interactions and persist until a temporally-delayed neuromodulatory feedback (the third factor) arrives, enabling correct credit assignment for outcomes that occur well after the causal spikes; outer-loop meta-learning (gradient descent across many tasks) is a still slower timescale which sculpts the dynamics of both eligibility formation and neuromodulatory responses.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>The interaction of eligibility traces with learned neuromodulatory signals allowed the networks to perform one-shot/within-lifetime learning where feedback arrived after the stimulus sequence (e.g., reward at decision interval) and to avoid catastrophic forgetting across interleaved trials. Meta-optimized neuromodulatory dynamics enabled solving tasks that non-plastic networks could not (e.g., cue-association and one-shot character recognition).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_measure</strong></td>
                            <td>See associated task metrics: cue-association 95.6% accuracy (M=5); character recognition DP-SNN 20.4% error. Eligibility traces plotted in Figure 2D demonstrate trace dynamics across sampled synapses.</td>
                        </tr>
                        <tr>
                            <td><strong>slow_vs_fast_learning</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>consolidation_mechanism</strong></td>
                            <td>Eligibility traces provide a mechanism for transient storage of pre/post interactions until slower neuromodulatory signals convert them into weight changes; no explicit multi-day consolidation mechanism is implemented, but outer-loop optimization shapes plasticity over many meta-training episodes (a slower consolidation of the learning rule itself).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Meta-SpikePropamine: learning to learn with synaptic plasticity in spiking neural networks', 'publication_date_yy_mm': '2023-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e99.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e99.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of synaptic plasticity rules, brain connectivity patterns, and how they support learning at different temporal scales (e.g., milliseconds to days).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Weight-dependence</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Weight-dependent (additive vs multiplicative) STDP</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Forms of STDP differ in how update magnitudes depend on current synaptic weight: additive rules apply constant update magnitudes, while multiplicative/weight-dependent rules scale LTP/LTD by distance to soft bounds to control saturation and competition.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>synaptic_rule_name</strong></td>
                            <td>Additive and multiplicative (weight-dependent) STDP</td>
                        </tr>
                        <tr>
                            <td><strong>synaptic_rule_description</strong></td>
                            <td>Additive: A_+(W)=η_+ (constant), A_-(W)=η_- (constant). Multiplicative: A_+(W)=η_+(W_max - W)^μ and A_-(W)=η_-(W - W_min)^μ with exponent μ controlling interpolation between additive (μ=0) and multiplicative (μ=1) behavior. Multiplicative rules impose soft bounds and reduce unbounded growth or bimodality; additive promotes strong synaptic competition.</td>
                        </tr>
                        <tr>
                            <td><strong>temporal_scale</strong></td>
                            <td>Weight dependence modulates the long-term accumulation of plasticity across many plasticity events (minutes to hours in aggregate), while individual update events are triggered on ms-to-hundreds-of-ms timescales.</td>
                        </tr>
                        <tr>
                            <td><strong>brain_region_circuit</strong></td>
                            <td>Not region-specific — discussed as theoretical forms and the paper indicates the cue-association experiments used an additive pair-based STDP implementation.</td>
                        </tr>
                        <tr>
                            <td><strong>connectivity_pattern</strong></td>
                            <td>Interacts with initialization connectivity (50% connection probability, 80/20 E/I) to produce specialization or stable distributions of synaptic weights across the network.</td>
                        </tr>
                        <tr>
                            <td><strong>learning_type</strong></td>
                            <td>Supports synaptic competition, selectivity and stability which are relevant to receptive-field formation, associative learning and stable lifelong learning.</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_or_model</strong></td>
                            <td>Conceptual / computational; forms are described in Methods and additive model was employed in the cue-association experiment.</td>
                        </tr>
                        <tr>
                            <td><strong>multi_timescale_interaction</strong></td>
                            <td>Weight-dependence governs how many fast updates accumulate into stable weight distributions over long sequences of events; multiplicative soft bounds bias LTD or LTP depending on current weight, affecting longer-term stability across many trials.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Paper notes additive STDP (used in cue experiments) induces strong synaptic specialization and was effective in the inner-loop learning; multiplicative rules discussed as alternatives that curb runaway dynamics but were not the primary choice for the demonstrated cue task.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_measure</strong></td>
                            <td>The additive pair-based STDP (used) supported the high performance metrics of the cue task (95.6% accuracy). No separate quantitative comparison between additive vs multiplicative variants is reported in the experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>slow_vs_fast_learning</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>consolidation_mechanism</strong></td>
                            <td>Weight-dependence affects the long-term accumulation/stability of fast weight updates (i.e., how transient eligibility-driven updates consolidate into stable weight distributions), but no explicit biological consolidation across days is implemented.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Meta-SpikePropamine: learning to learn with synaptic plasticity in spiking neural networks', 'publication_date_yy_mm': '2023-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e99.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e99.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of synaptic plasticity rules, brain connectivity patterns, and how they support learning at different temporal scales (e.g., milliseconds to days).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Sparse E/I architecture</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Sparse excitatory/inhibitory connectivity and neuromodulatory projection architecture</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Network wiring pattern used in experiments: random sparse connectivity (50% prob.), excitatory/inhibitory assignment (80/20), feedforward plastic input→hidden layer (DP-SNN), non-plastic hidden→output, and a separate neuromodulatory SNN that provides top-down modulatory signals to plastic synapses.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>synaptic_rule_name</strong></td>
                            <td>Network connectivity pattern (sparse E/I, input→hidden plastic, NM top-down)</td>
                        </tr>
                        <tr>
                            <td><strong>synaptic_rule_description</strong></td>
                            <td>At initialization each potential synapse is present with probability 0.5; present synapses are marked excitatory with probability 0.8 or inhibitory with probability 0.2. Plasticity is applied to input→hidden synapses; output connections are non-plastic and trained via BPTT. A separate NM-SNN (two fully-connected layers of 64 CUBA neurons) receives sensory and hidden activity and emits neuron-specific modulatory signals that gate plasticity at those synapses.</td>
                        </tr>
                        <tr>
                            <td><strong>temporal_scale</strong></td>
                            <td>Connectivity itself is structural (stable across the experiment), but interacts with temporal dynamics: sparse wiring shapes spike statistics and eligibility formation on ms-to-hundreds-of-ms time windows; NM-SNN modulatory outputs operate on decision intervals (tens-to-hundreds of ms in simulation).</td>
                        </tr>
                        <tr>
                            <td><strong>brain_region_circuit</strong></td>
                            <td>Computational architecture (not a mapped biological brain region) but inspired by broad top-down neuromodulatory projections (e.g., dopamine, acetylcholine) to plastic synapses in the brain.</td>
                        </tr>
                        <tr>
                            <td><strong>connectivity_pattern</strong></td>
                            <td>Explicitly: 50% connection probability at initialization; 80% excitatory / 20% inhibitory synapse assignment; DP-SNN: one hidden layer of 48 CUBA neurons; NM-SNN: two layers of 64 CUBA neurons fully connected; neuromodulation is implemented as input-neuron specific modulatory signals to LTP/LTD traces.</td>
                        </tr>
                        <tr>
                            <td><strong>learning_type</strong></td>
                            <td>Supports online within-lifetime learning (one-shot cue association, one-shot character recognition) by enabling sparse specialization and modulatory gating for credit assignment.</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_or_model</strong></td>
                            <td>Computational model / simulation (architecture used directly in experiments).</td>
                        </tr>
                        <tr>
                            <td><strong>multi_timescale_interaction</strong></td>
                            <td>Sparse E/I wiring produces network dynamics (spiking, hidden representations) at fast timescales; these representations feed the NM-SNN which computes modulatory signals that act on slower decision epochs to gate plasticity, enabling cross-timescale credit assignment and stable information storage in selected synapses.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>This connectivity motif combined with neuromodulated plasticity enabled strong one-shot learning performance in both tasks; sparse initial connectivity and E/I composition helped specialization without catastrophic instability reported in plastic ANNs.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_measure</strong></td>
                            <td>Architecture supported the reported task metrics: cue-association 95.6% accuracy; character recognition DP-SNN 20.4% test error. Connection probabilities and E/I fractions reported as 50% and 80/20 respectively.</td>
                        </tr>
                        <tr>
                            <td><strong>slow_vs_fast_learning</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>consolidation_mechanism</strong></td>
                            <td>Structural connectivity is fixed during episodes; consolidation of learned information occurs via synaptic weight updates gated by neuromodulation, not via structural rewiring; no multi-day consolidation mechanism reported.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Meta-SpikePropamine: learning to learn with synaptic plasticity in spiking neural networks', 'publication_date_yy_mm': '2023-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e99.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e99.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of synaptic plasticity rules, brain connectivity patterns, and how they support learning at different temporal scales (e.g., milliseconds to days).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Meta-plasticity (L2L)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Meta-learning of plasticity rules (learning-to-learn with neuromodulated plasticity)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A bilevel/meta-learning framework in which plasticity rule parameters and neuromodulatory dynamics (meta-parameters ω) are optimized by slow outer-loop gradient descent so that the inner-loop synaptic dynamics (eligibility + neuromodulation) can perform rapid online learning.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>synaptic_rule_name</strong></td>
                            <td>Meta-learned neuromodulated plasticity (meta-plasticity)</td>
                        </tr>
                        <tr>
                            <td><strong>synaptic_rule_description</strong></td>
                            <td>Meta-parameters ω parameterize the plasticity rules (e.g., amplitudes, trace time-constants, modulatory response functions) and neuromodulatory network parameters; outer-loop BPTT updates ω to minimize a meta-objective across tasks, while inner-loop online learning updates synaptic weights θ via the neuromodulated eligibility-rule dynamics on a per-episode basis.</td>
                        </tr>
                        <tr>
                            <td><strong>temporal_scale</strong></td>
                            <td>Two explicit timescales: fast inner-loop synaptic changes happening within trials (ms→hundreds of ms) via eligibility + modulatory gating, and slow outer-loop optimization (many episodes / gradient steps) which sculpts ω — wallclock or biological analogue could be hours/days of training though simulations performed over thousands of gradient steps.</td>
                        </tr>
                        <tr>
                            <td><strong>brain_region_circuit</strong></td>
                            <td>Computational framework applied to DP-SNN and NM-SNN; not mapped to a specific brain region but motivated by neuromodulatory systems in biology.</td>
                        </tr>
                        <tr>
                            <td><strong>connectivity_pattern</strong></td>
                            <td>Meta-learning operates over the described DP-SNN / NM-SNN architecture (sparse input→hidden plastic synapses, NM-SNN fully connected) and thus shapes plasticity across that wiring pattern.</td>
                        </tr>
                        <tr>
                            <td><strong>learning_type</strong></td>
                            <td>Learning-to-learn: shapes the inner-loop learning algorithm to improve rapid within-lifetime adaptation such as one-shot learning and continual online learning.</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_or_model</strong></td>
                            <td>Computational/theoretical (bilevel optimization implemented by BPTT over simulated SNN episodes).</td>
                        </tr>
                        <tr>
                            <td><strong>multi_timescale_interaction</strong></td>
                            <td>Explicit: inner-loop (fast) synaptic dynamics perform trial-by-trial learning via neuromodulated eligibility traces; outer-loop (slow) gradient descent updates meta-parameters ω across many trials to improve the inner-loop update dynamics, thereby integrating very fast (ms) plasticity with very slow (training across episodes) optimization.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Meta-optimization of neuromodulated plasticity produced inner-loop learning dynamics that solved tasks that non-plastic networks could not; outer-loop shaping of plasticity yielded one-shot continual learning (cue task) and one-shot character recognition, demonstrating that gradient-descent meta-learning can tune biologically-informed three-factor plasticity into effective online learning rules.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_measure</strong></td>
                            <td>Outer-loop training used many episodes; example results: cue-association 95.6% accuracy, character recognition DP-SNN 20.4% test error after 2000 outer-loop updates. Meta-training gradients computed over batches (e.g., 256 cue trials per gradient) as described in Methods.</td>
                        </tr>
                        <tr>
                            <td><strong>slow_vs_fast_learning</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>consolidation_mechanism</strong></td>
                            <td>Outer-loop optimization acts as a long-timescale consolidation of the learning algorithm (plasticity parameters ω) across many tasks; inner-loop synaptic changes consolidate task-specific information within an episode via neuromodulated eligibility conversion. No explicit biological multi-day consolidation protocol is implemented in the experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Meta-SpikePropamine: learning to learn with synaptic plasticity in spiking neural networks', 'publication_date_yy_mm': '2023-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Neuromodulated spike-timing-dependent plasticity, and theory of three-factor learning rules <em>(Rating: 2)</em></li>
                <li>Eligibility traces and plasticity on behavioral time scales: experimental support of neohebbian three-factor learning rules <em>(Rating: 2)</em></li>
                <li>A triplet spike-timing-dependent plasticity model generalizes the Bienenstock–Cooper–Munro rule to higher-order spatiotemporal correlations <em>(Rating: 2)</em></li>
                <li>Triplets of spikes in a model of spike timing-dependent plasticity <em>(Rating: 2)</em></li>
                <li>A solution to the learning dilemma for recurrent networks of spiking neurons <em>(Rating: 2)</em></li>
                <li>One-shot learning with spiking neural networks <em>(Rating: 2)</em></li>
                <li>Spikepropamine: differentiable plasticity in spiking neural networks <em>(Rating: 2)</em></li>
                <li>Responses of monkey dopamine neurons to reward and conditioned stimuli during successive steps of learning a delayed response task <em>(Rating: 1)</em></li>
            </ol>
        </div>

        </div>

    </div>
</body>
</html>