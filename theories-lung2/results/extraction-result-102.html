<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-102 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-102</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-102</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-5.html">extraction-schema-5</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of synaptic plasticity rules, brain connectivity patterns, and how they support learning at different temporal scales (e.g., milliseconds to days).</div>
                <p><strong>Paper ID:</strong> paper-3c520f3ebd82ac156ab735791d610ab958920e59</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/3c520f3ebd82ac156ab735791d610ab958920e59" target="_blank">Mechanisms underlying sharpening of visual response dynamics with familiarity</a></p>
                <p><strong>Paper Venue:</strong> eLife</p>
                <p><strong>Paper TL;DR:</strong> The mechanism underlying sharpening of both stimulus selectivity and response dynamics with familiarity observed in monkey inferotemporal cortex is investigated to highlight the importance of analyzing changes in dynamics as well as network patterns to further reveal the mechanisms of visual learning.</p>
                <p><strong>Paper Abstract:</strong> Experience-dependent modifications of synaptic connections are thought to change patterns of network activities and stimulus tuning with learning. However, only a few studies explored how synaptic plasticity shapes the response dynamics of cortical circuits. Here, we investigated the mechanism underlying sharpening of both stimulus selectivity and response dynamics with familiarity observed in monkey inferotemporal cortex. Broadening the distribution of activities and stronger oscillations in the response dynamics after learning provide evidence for synaptic plasticity in recurrent connections modifying the strength of positive feedback. Its interplay with slow negative feedback via firing rate adaptation is critical in sharpening response dynamics. Analysis of changes in temporal patterns also enables us to disentangle recurrent and feedforward synaptic plasticity and provides a measure for the strengths of recurrent synaptic plasticity. Overall, this work highlights the importance of analyzing changes in dynamics as well as network patterns to further reveal the mechanisms of visual learning.</p>
                <p><strong>Cost:</strong> 0.045</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e102.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e102.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of synaptic plasticity rules, brain connectivity patterns, and how they support learning at different temporal scales (e.g., milliseconds to days).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Recurrent Hebbian-type plasticity</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Hebbian-type synaptic plasticity in recurrent excitatory connections</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Activity-dependent modification of recurrent excitatory synapses inferred from time-averaged and time-course ITC data; potentiation in high firing-rate neurons (cell assemblies) increases positive feedback and broadens the distribution of time-averaged responses.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>synaptic_rule_name</strong></td>
                            <td>Hebbian-type recurrent plasticity (rate-based separable rule)</td>
                        </tr>
                        <tr>
                            <td><strong>synaptic_rule_description</strong></td>
                            <td>A separable, rate-based learning rule ΔW_Rij = (1/N) f_R(ξ_i) g_R(ξ_j) where ξ denotes pre/post normalized firing averaged during stimulus presentation; f_R is the postsynaptic dependence (potentiation at high rates, depression at low rates in examples), and g_R is the presynaptic dependence (weighting of contribution by high-rate neurons). Potentiation among high-rate neurons creates correlated recurrent structure (cell assemblies); in mean-field this contributes a term proportional to the average product f·g (denoted f g¯_R). The authors inferred f_R from data and implemented Hebbian-like updates in network simulations.</td>
                        </tr>
                        <tr>
                            <td><strong>temporal_scale</strong></td>
                            <td>Long-term (learning over repeated stimulus exposures; hours → days, across experimental sessions) for the change in synaptic weights; neural integration time constant τ_R ~ 5 ms (fast dynamics) determines how recurrent feedback affects millisecond-scale responses; the effect on population dynamics emerges over trials and is persistent (experimentally observed as familiarity across sessions).</td>
                        </tr>
                        <tr>
                            <td><strong>brain_region_circuit</strong></td>
                            <td>Inferotemporal cortex (ITC), modeled as a recurrent excitatory network (E→E recurrent connections central), excitatory population dominant in shaping observed dynamics; inhibitory population treated implicitly (inhibition assumed to follow excitatory activity).</td>
                        </tr>
                        <tr>
                            <td><strong>connectivity_pattern</strong></td>
                            <td>Recurrent excitatory synapses becoming correlated with learned activity patterns (strengthened within high-rate neuron subsets forming a cell assembly); initial homogeneous/unstructured recurrent connectivity before learning; connectivity after learning acquires structure aligned with learned stimulus patterns (pattern overlap variables m,n capture this).</td>
                        </tr>
                        <tr>
                            <td><strong>learning_type</strong></td>
                            <td>Familiarity detection / visual learning; also relates to associative memory (attractor-like features) via recurrent assembly formation.</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_or_model</strong></td>
                            <td>Computational modeling (mean-field analysis and large-scale firing-rate network simulations) constrained and fitted to in vivo electrophysiological data from monkey ITC (passive viewing and dimming-detection tasks).</td>
                        </tr>
                        <tr>
                            <td><strong>multi_timescale_interaction</strong></td>
                            <td>Recurrent potentiation (a slow, long-term change in weights across learning sessions) increases positive feedback and, when combined with a slower negative feedback (firing-rate adaptation with τ_A ~ 200 ms), leads to resonance-like damped oscillations (period ~150 ms, ~5 Hz) in response dynamics; recurrent plasticity sets strength of positive loop while adaptation sets negative feedback timescale that shapes oscillatory rebound.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Overall potentiation in recurrent inputs among high-rate neurons is required to produce in-phase increases in mean and maximal responses and to drive damped oscillatory rebound after learning; the magnitude of the rebound (230–320 ms slope) is proportional to the postsynaptic dependence f_R and can serve as a graded measure of recurrent plasticity strength. Recurrent plasticity alone (without slow negative feedback) fails to generate the observed oscillations.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_measure</strong></td>
                            <td>Changes in average and maximal firing rates (normalized per neuron), rebound strength quantified as slope of activity change between 230 ms and 320 ms after stimulus onset, oscillation period ≈150 ms (~5 Hz); fitted mean-field parameter values used include τ_R = 5 ms, τ_A = 200 ms, f g¯_R (example) = 0.9, average post-synaptic recurrent term f¯_R ≈ 0.3 in fits.</td>
                        </tr>
                        <tr>
                            <td><strong>slow_vs_fast_learning</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>consolidation_mechanism</strong></td>
                            <td>No explicit consolidation protocol described; the paper treats synaptic weight changes as slow, persistent modifications (learning across exposures) interacting with faster adaptation processes, but does not propose a separate mechanistic consolidation process (e.g., hippocampus→neocortex transfer).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Mechanisms underlying sharpening of visual response dynamics with familiarity', 'publication_date_yy_mm': '2019-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e102.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e102.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of synaptic plasticity rules, brain connectivity patterns, and how they support learning at different temporal scales (e.g., milliseconds to days).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Feedforward depression</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Depression in feedforward (external) inputs / feedforward synaptic plasticity</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Learning-related reduction of feedforward input strength (uniform scaling down or depression) is used to account for the experimentally observed decrease in average responses across stimuli while recurrent potentiation increases maximal responses.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>synaptic_rule_name</strong></td>
                            <td>Feedforward depression (rate-based separable rule)</td>
                        </tr>
                        <tr>
                            <td><strong>synaptic_rule_description</strong></td>
                            <td>Modeled as ΔW_Fij = (1/N) f_F(ξ_i) g_F(ξ_j) with an average post-synaptic tendency f¯_F < 0 (dominant depression) in fits; in network examples feedforward plasticity was implemented as a uniform scaling down of the time-varying external inputs (parameter γ < 1 after learning). This reduces the baseline / average excitatory drive to the population, lowering mean responses across stimuli.</td>
                        </tr>
                        <tr>
                            <td><strong>temporal_scale</strong></td>
                            <td>Long-term (learning across repeated exposures; hours → days) for persistent reduction in feedforward drive; the effect is manifest during stimulus presentations (hundreds of ms timescales) after learning.</td>
                        </tr>
                        <tr>
                            <td><strong>brain_region_circuit</strong></td>
                            <td>Inferotemporal cortex (ITC) receiving external feedforward input representing visual drive; feedforward synapses onto excitatory neurons are modified.</td>
                        </tr>
                        <tr>
                            <td><strong>connectivity_pattern</strong></td>
                            <td>Feedforward (input → cortical neuron) pathway plasticity; implemented in models as changes to W^F (external input weights), often assumed initially as identity (pre-learning) and then scaled or depressed after learning.</td>
                        </tr>
                        <tr>
                            <td><strong>learning_type</strong></td>
                            <td>Familiarity detection / visual learning that reduces average firing to familiar stimuli (sparsening, efficient coding).</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_or_model</strong></td>
                            <td>Computational/modeling using electrophysiological data to derive feedforward changes and fit dynamics; also motivated by experimental observations of reduced average responses after learning.</td>
                        </tr>
                        <tr>
                            <td><strong>multi_timescale_interaction</strong></td>
                            <td>Feedforward depression (slow, persistent change) reduces average input, whereas recurrent potentiation (slow) increases the strongest responses; their interaction shapes the distribution of time-averaged responses and temporal sharpening when combined with adaptation (hundreds ms).</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Feedforward depression with f¯_F < 0 is required (together with recurrent potentiation) to reproduce both decreased mean firing rates and increased maximal firing rates after learning; recurrent potentiation alone increases mean activity and cannot explain observed average reduction.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_measure</strong></td>
                            <td>In fits, example average parameters include f¯_F ≈ −0.7 (used in Fig.5 fitting); outcome metrics are average response decrease (late phase 200–250 ms) and retained increased maximal responses.</td>
                        </tr>
                        <tr>
                            <td><strong>slow_vs_fast_learning</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>consolidation_mechanism</strong></td>
                            <td>No explicit consolidation mechanism described; feedforward depression is treated as a slow learning outcome inferred from changes between novel and familiar stimulus responses.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Mechanisms underlying sharpening of visual response dynamics with familiarity', 'publication_date_yy_mm': '2019-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e102.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e102.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of synaptic plasticity rules, brain connectivity patterns, and how they support learning at different temporal scales (e.g., milliseconds to days).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Firing-rate adaptation</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Single-neuron firing-rate adaptation (slow negative feedback)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A slow negative feedback mechanism modeled as an adaptation current: a low-pass filtered version of firing rate (a_i) with strength k and time constant τ_A; crucial for producing damped oscillatory rebound and temporal sharpening after learning.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>synaptic_rule_name</strong></td>
                            <td>Not a synaptic rule but a neuronal adaptation mechanism (spike-frequency adaptation modeled as low-pass filter)</td>
                        </tr>
                        <tr>
                            <td><strong>synaptic_rule_description</strong></td>
                            <td>Adaptation implemented as a per-neuron variable a_i following τ_A da_i/dt = −a_i + r_i; this subtracts k·a_i from the input to the transfer function Φ, providing slow negative feedback. Parameters in examples: adaptation strength k (e.g., k = 1.8 in fits) and time constant τ_A (e.g., τ_A = 200 ms).</td>
                        </tr>
                        <tr>
                            <td><strong>temporal_scale</strong></td>
                            <td>Fast neural time constant τ_R ≈ 5 ms (integration) for excitatory dynamics; adaptation operates on ~hundreds of milliseconds (τ_A ≈ 200 ms in fits); paper also cites adaptation effects on longer timescales up to seconds for repetition suppression and references mechanisms with multiple adaptation timescales (ms → seconds → longer).</td>
                        </tr>
                        <tr>
                            <td><strong>brain_region_circuit</strong></td>
                            <td>Inferotemporal cortex (ITC) neurons (adaptation applied per excitatory neuron or sub-population in the model); adaptation is private to neurons or sub-populations (not purely global) in order to reproduce observed dynamics.</td>
                        </tr>
                        <tr>
                            <td><strong>connectivity_pattern</strong></td>
                            <td>Interaction with recurrent potentiation: adaptation provides a private (per-neuron or per-assembly) slow negative feedback loop that balances strengthened recurrent positive feedback; necessity of a negative-feedback element private to neurons/subpopulations is emphasized (global-only inhibition insufficient).</td>
                        </tr>
                        <tr>
                            <td><strong>learning_type</strong></td>
                            <td>Supports temporal sharpening and rapid processing of familiar stimuli by preparing neurons to respond to subsequent stimuli (affects short-term temporal processing and contributes to familiarity effects).</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_or_model</strong></td>
                            <td>Modeling (mean-field and network simulations) guided by analysis of in vivo ITC recordings; adaptation motivated by prior cellular physiology literature and fit to response time-courses.</td>
                        </tr>
                        <tr>
                            <td><strong>multi_timescale_interaction</strong></td>
                            <td>Adaptation (hundreds ms) interacts with recurrent plasticity (slow across learning) and millisecond-scale recurrent integration (τ_R ~5 ms) so that strong recurrent positive feedback from learned assemblies plus adaptation yield resonance/damped oscillations (period ~150 ms). Adaptation also enforces late-phase suppression (200–250 ms) producing temporal sharpening.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Adaptation-like slow negative feedback is critical: only when recurrent potentiation is combined with adaptation (private to neurons/subpopulations, τ_A ~200 ms, k ~1.8) do network models reproduce the experimentally observed rebound/damped oscillation and late-phase suppression for familiar stimuli; global delayed inhibition cannot substitute for private adaptation in producing these qualitative dynamics.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_measure</strong></td>
                            <td>Fitted adaptation parameters: τ_A = 200 ms, k ~1.8 (used in figures). Oscillation period ≈ 150 ms tied to τ_A and recurrent strength; rebound quantified by slope between 230–320 ms.</td>
                        </tr>
                        <tr>
                            <td><strong>slow_vs_fast_learning</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>consolidation_mechanism</strong></td>
                            <td>Adaptation encodes recent stimulus history (recency) on sub-second to second timescales; the paper discusses multiple adaptation timescales but does not present a consolidation mechanism transferring adaptation effects into long-term memory.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Mechanisms underlying sharpening of visual response dynamics with familiarity', 'publication_date_yy_mm': '2019-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e102.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e102.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of synaptic plasticity rules, brain connectivity patterns, and how they support learning at different temporal scales (e.g., milliseconds to days).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Short-term depression (STD)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Short-term synaptic depression (resource depletion model)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Phenomenological model of presynaptic resource depletion (variable x_j, recovery time constant τ_X and depletion rate γ) considered as an alternative negative feedback; tested in simulations but found insufficient to reproduce the strong rebound/damped oscillation after learning.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>synaptic_rule_name</strong></td>
                            <td>Short-term depression (Tsodyks–Markram-type phenomenological model)</td>
                        </tr>
                        <tr>
                            <td><strong>synaptic_rule_description</strong></td>
                            <td>Synaptic efficacy is scaled by x_j (fraction of available resources) with dynamics dx_j/dt = (1−x_j)/τ_X − γ x_j r_j so that high presynaptic firing depletes resources; recovery time τ_X and depression strength γ govern timescales and magnitude. Implemented in simulations to test whether STD could substitute for adaptation as the slow negative feedback.</td>
                        </tr>
                        <tr>
                            <td><strong>temporal_scale</strong></td>
                            <td>Intermediate timescale: recovery/refractory τ_X used in examples = 200 ms (hundreds of ms); depletion occurs on the timescale of presynaptic firing (ms to tens of ms) but the effective feedback is set by τ_X (~200 ms in fits).</td>
                        </tr>
                        <tr>
                            <td><strong>brain_region_circuit</strong></td>
                            <td>Modeled within recurrent excitatory pathways of an ITC-like network; STD applied to recurrent synapses of high-rate neurons in reduced two-variable approximations.</td>
                        </tr>
                        <tr>
                            <td><strong>connectivity_pattern</strong></td>
                            <td>Pre-synaptic dependence (g_R larger for high-rate neurons) couples STD to recurrent inputs; STD modifies effective recurrent gain dynamically rather than producing persistent weight changes.</td>
                        </tr>
                        <tr>
                            <td><strong>learning_type</strong></td>
                            <td>Tested in context of visual familiarity-induced temporal sharpening (short-term circuit dynamics), not as long-term memory mechanism in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_or_model</strong></td>
                            <td>Computational model / simulation testing (phenomenological implementation inspired by Tsodyks & Markram 1997) compared to experimental time-course data.</td>
                        </tr>
                        <tr>
                            <td><strong>multi_timescale_interaction</strong></td>
                            <td>STD introduces a dynamic reduction of recurrent input on the sub-second scale that could in principle interact with recurrent potentiation, but in the parameter search the best-fit STD parameters could not generate the strong oscillatory rebound observed experimentally, implying STD alone cannot replace adaptation in the multi-timescale interaction required.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Simple phenomenological STD models (with τ_X ≈ 200 ms and best-fit γ) could not reproduce the strong rebound/damped oscillation after learning seen in ITC data; thus STD is insufficient as the principal slow negative feedback mechanism for the observed familiarity-induced oscillations.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_measure</strong></td>
                            <td>Best-fit example: τ_X = 200 ms, fitted γ ≈ 0.125 and fitted recurrent f g term ≈ 2.56 for the reduced high-rate neuron model—these parameter sets failed to produce robust oscillatory rebound matching data.</td>
                        </tr>
                        <tr>
                            <td><strong>slow_vs_fast_learning</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>consolidation_mechanism</strong></td>
                            <td>No consolidation mechanism associated with STD in this study; STD considered as a transient, dynamic modulatory process rather than a long-term storage mechanism.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Mechanisms underlying sharpening of visual response dynamics with familiarity', 'publication_date_yy_mm': '2019-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e102.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e102.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of synaptic plasticity rules, brain connectivity patterns, and how they support learning at different temporal scales (e.g., milliseconds to days).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Delayed global inhibition</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Delayed global inhibitory feedback (slow global inhibition)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A model variant where all excitatory neurons receive the same slow inhibitory signal proportional to the population mean activity (a global low-pass filtered r¯), tested as an alternative slow negative feedback mechanism to adaptation.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>synaptic_rule_name</strong></td>
                            <td>Not a synaptic plasticity rule per se; modeled as slow global inhibitory feedback (population-level negative feedback)</td>
                        </tr>
                        <tr>
                            <td><strong>synaptic_rule_description</strong></td>
                            <td>Global inhibition implemented by replacing private adaptation a_i with a population-filtered inhibitory variable a^I that tracks the mean excitatory activity r¯ with time constant τ_A and strength k^I; mean-field dynamics derived and compared to adaptation-based model. This provides delayed inhibitory feedback proportional to average activity rather than private per-neuron adaptation.</td>
                        </tr>
                        <tr>
                            <td><strong>temporal_scale</strong></td>
                            <td>Slow population-level feedback tested with τ_A ≈ 200 ms (hundreds of ms); delay/latency could be larger in biological top-down sources (tens to hundreds of ms).</td>
                        </tr>
                        <tr>
                            <td><strong>brain_region_circuit</strong></td>
                            <td>ITC modeled with an added global inhibitory pathway (could be realized by local slow inhibitory currents or top-down inputs from prefrontal cortex in biological scenarios).</td>
                        </tr>
                        <tr>
                            <td><strong>connectivity_pattern</strong></td>
                            <td>Global (all-to-all) inhibitory feedback proportional to average excitatory firing, i.e., shared inhibitory pathway rather than private per-cell adaptation; contrasted with local/private adaptation.</td>
                        </tr>
                        <tr>
                            <td><strong>learning_type</strong></td>
                            <td>Considered in the context of visual familiarity effects and temporal dynamics (damped oscillation) testing whether global inhibition can generate the same signatures as private adaptation.</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_or_model</strong></td>
                            <td>Computational/analytical (mean-field derivation and simulation) as an alternative hypothesis; paper finds it inadequate to generate the same qualitative changes.</td>
                        </tr>
                        <tr>
                            <td><strong>multi_timescale_interaction</strong></td>
                            <td>Global inhibition lacks the private negative feedback term n that arises when adaptation is private to high-rate neurons, and therefore cannot produce the same oscillatory rebound in both the learned assembly and the rest of the population when combined with recurrent potentiation.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Mean-field analysis shows global delayed inhibition (shared slow feedback) cannot replace private adaptation for generating the damped oscillations observed experimentally; private/assembly-specific slow feedback is required to interact with strengthened recurrent positive feedback to produce the observed dynamics.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_measure</strong></td>
                            <td>Analytical mean-field comparison (presence/absence of n variable) and simulation outcomes showing absence of the qualitative damped oscillation with global inhibition in parameter regimes that produce oscillation with private adaptation.</td>
                        </tr>
                        <tr>
                            <td><strong>slow_vs_fast_learning</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>consolidation_mechanism</strong></td>
                            <td>No consolidation mechanism discussed for global inhibition; treated as an alternative dynamic feedback path rather than a locus of long-term memory change.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Mechanisms underlying sharpening of visual response dynamics with familiarity', 'publication_date_yy_mm': '2019-08'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Inferring learning rules from distributions of firing rates in cortical neurons <em>(Rating: 2)</em></li>
                <li>Image familiarization sharpens response dynamics of neurons in inferotemporal cortex <em>(Rating: 2)</em></li>
                <li>Spike frequency adaptation and neocortical rhythms <em>(Rating: 2)</em></li>
                <li>The neural code between neocortical pyramidal neurons depends on neurotransmitter release probability <em>(Rating: 2)</em></li>
                <li>Temporal whitening by power-law adaptation in neocortical neurons <em>(Rating: 1)</em></li>
                <li>Computation by ensemble synchronization in recurrent networks with synaptic depression <em>(Rating: 1)</em></li>
            </ol>
        </div>

        </div>

    </div>
</body>
</html>