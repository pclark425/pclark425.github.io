<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-2910 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-2910</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-2910</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-72.html">extraction-schema-72</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLM-based agents that use memory mechanisms to solve text games, including details about the memory architecture, the text games being solved, and performance comparisons.</div>
                <p><strong>Paper ID:</strong> paper-277634555</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2504.06943v1.pdf" target="_blank">Review of Case-Based Reasoning for LLM Agents: Theoretical Foundations, Architectural Components, and Cognitive Integration</a></p>
                <p><strong>Paper Abstract:</strong> Agents powered by Large Language Models (LLMs) have recently demonstrated impressive capabilities in various tasks. Still, they face limitations in tasks requiring specific, structured knowledge, flexibility, or accountable decision-making. While agents are capable of perceiving their environments, forming inferences, planning, and executing actions towards goals, they often face issues such as hallucinations and lack of contextual memory across interactions. This paper explores how Case-Based Reasoning (CBR), a strategy that solves new problems by referencing past experiences, can be integrated into LLM agent frameworks. This integration allows LLMs to leverage explicit knowledge, enhancing their effectiveness. We systematically review the theoretical foundations of these enhanced agents, identify critical framework components, and formulate a mathematical model for the CBR processes of case retrieval, adaptation, and learning. We also evaluate CBR-enhanced agents against other methods like Chain-of-Thought reasoning and standard Retrieval-Augmented Generation, analyzing their relative strengths. Moreover, we explore how leveraging CBR's cognitive dimensions (including self-reflection, introspection, and curiosity) via goal-driven autonomy mechanisms can further enhance the LLM agent capabilities. Contributing to the ongoing research on neuro-symbolic hybrid systems, this work posits CBR as a viable technique for enhancing the reasoning skills and cognitive aspects of autonomous LLM agents.</p>
                <p><strong>Cost:</strong> 0.014</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e2910.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e2910.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLM-based agents that use memory mechanisms to solve text games, including details about the memory architecture, the text games being solved, and performance comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>CBR-GDA</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Case-Based Reasoning integrated with Goal-Driven Autonomy for LLM Agents</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A proposed architecture (in this paper) that integrates case-based memory (CBR) with a goal-driven autonomy controller for LLM agents, using two distinct case-bases to support expectation modeling and mismatch→goal formulation to enable dynamic goal reasoning and adaptation.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>CBR-GDA</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>An LLM-centered agent architecture that augments the foundation LLM with a case library and a Goal-Driven Autonomy (GDA) controller. It uses two case-bases (a Planning Case Base and a Mismatch-Goal Case Base) to store and retrieve prior problem/plan/goal examples; discrepancy detection triggers retrieval from the MCB to formulate new goals; adaptation is performed by the LLM guided by retrieved cases and adaptation mechanisms (transformational, compositional, generative). The framework also prescribes hybrid retrieval (semantic, feature, structural) and meta-cognitive selection of adaptation strategies.</td>
                        </tr>
                        <tr>
                            <td><strong>base_llm_model</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>base_llm_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>text_game_name</strong></td>
                            <td>multiagent gaming domain (generic)</td>
                        </tr>
                        <tr>
                            <td><strong>text_game_description</strong></td>
                            <td>Dynamic, adversarial multi-agent gaming scenarios where agents must detect discrepancies between expected and actual states, generate explanations, and formulate or revise goals/plans online; described in general terms rather than as a specific benchmark (no named text game like Jericho/TextWorld).</td>
                        </tr>
                        <tr>
                            <td><strong>uses_memory</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>case-based (episodic) memory</td>
                        </tr>
                        <tr>
                            <td><strong>memory_architecture</strong></td>
                            <td>Two complementary case-bases: (1) Planning Case Base (PCB) storing tuples (state s, goal g, expected state e, plan p) for expectation modeling and plan retrieval; (2) Mismatch-Goal Case Base (MCB) storing (mismatch m, suggested new goal g). In addition, the paper specifies a general case library L of cases c=(P,S,O,M) where P=problem features, S=solutions/actions, O=outcomes/metrics, M=metadata; each case is indexed with dense semantic embeddings and sparse feature indices, organized hierarchically, and subject to selective retention via a utility function U(c_new,L) and threshold delta.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_retrieval_mechanism</strong></td>
                            <td>Hybrid retrieval combining semantic embedding similarity (cosine in LLM embedding space), explicit feature-based matching, and structural-pattern retrieval; retrieval functions Retrieve_PCB and Retrieve_MCB are called to fetch expected states/plans or mismatch→goal mappings respectively; selection uses similarity thresholds (τ) and weighted combination (λ1, λ2, λ3).</td>
                        </tr>
                        <tr>
                            <td><strong>memory_capacity</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>what_is_stored_in_memory</strong></td>
                            <td>Structured cases: problem features, solution components (plans/actions), outcome metrics, and metadata (temporal markers, conditions, provenance); PCB entries map (state, goal) → (expected state, plan); MCB entries map observed mismatches → candidate goals.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_improvement_magnitude</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings_about_memory</strong></td>
                            <td>The paper argues (theoretically) that case-based memory enables superior goal reasoning, transparency, domain adaptation, and handling of edge cases in dynamic environments: the explicit case library supports discrepancy detection and goal formulation, and hybrid retrieval plus LLM-guided adaptation should improve solution quality and explainability compared to purely parametric or RAG-only approaches.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_limitations</strong></td>
                            <td>Discussed at a systems level: added retrieval costs and computational overhead, challenges in case acquisition and quality control, dynamic case-base maintenance, potential retrieval failures if case coverage is sparse, and trade-offs between retrieval comprehensiveness and efficiency; no empirical failure-modes on games are reported in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_other_memory_types</strong></td>
                            <td>Compared conceptually (not empirically) against parametric-only reasoning and vanilla RAG/CoT: CBR (case-based memory) is presented as having richer cognitive capabilities (self-reflection, introspection), superior domain adaptation and explainability, and dynamic goal reasoning compared to CoT and standard RAG; no quantitative comparison between memory architectures is reported.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Review of Case-Based Reasoning for LLM Agents: Theoretical Foundations, Architectural Components, and Cognitive Integration', 'publication_date_yy_mm': '2025-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2910.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e2910.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLM-based agents that use memory mechanisms to solve text games, including details about the memory architecture, the text games being solved, and performance comparisons.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>CB-GDA (Muñoz-Avila et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Case-Based Goal-Driven Autonomy (CB-GDA)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An earlier CBR-enhanced Goal-Driven Autonomy system (Muñoz-Avila et al., 2010) that used two case-bases—one mapping state-goal pairs to expected states/plans and another mapping mismatches to new goals—and was evaluated in multiagent gaming domains, showing empirical gains over alternatives.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Goal-driven autonomy with case-based reasoning</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>CB-GDA (Muñoz-Avila et al., 2010)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>A GDA controller augmented with CBR: a Planning Case Base (PCB) maps (state, goal) to expected states and plans; a Mismatch-Goal Case Base (MCB) maps detected discrepancies to candidate new goals. During execution, the system detects mismatches between expected and actual states, retrieves appropriate MCB entries to formulate new goals, and uses PCB for expected-state/planning support. The architecture supports continuous updating of case-bases based on plan/goal quality.</td>
                        </tr>
                        <tr>
                            <td><strong>base_llm_model</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>base_llm_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>text_game_name</strong></td>
                            <td>multiagent gaming domain (generic)</td>
                        </tr>
                        <tr>
                            <td><strong>text_game_description</strong></td>
                            <td>Complex adversarial multi-agent gaming scenarios used in the original CB-GDA empirical evaluations (paper does not name a specific text-game benchmark in the description here).</td>
                        </tr>
                        <tr>
                            <td><strong>uses_memory</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>case-based memory / episodic</td>
                        </tr>
                        <tr>
                            <td><strong>memory_architecture</strong></td>
                            <td>Two dedicated case-bases: PCB storing (s, g, expected_state e, plan p) for planning and expectation modeling; MCB storing (mismatch m, suggested goal g) to support goal formulation when discrepancies occur. Case-bases are updated with new entries when Quality(p,g) or Quality(g_new,m) exceed thresholds (θP, θM).</td>
                        </tr>
                        <tr>
                            <td><strong>memory_retrieval_mechanism</strong></td>
                            <td>Case retrieval based on matching the current state/goal or detected mismatch to stored cases (similarity-based case matching); retrieval functions Retrieve_PCB and Retrieve_MCB are used to fetch expected states/plans or suggested goals respectively (specific retrieval algorithm details are not given in this paper's summary).</td>
                        </tr>
                        <tr>
                            <td><strong>memory_capacity</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>what_is_stored_in_memory</strong></td>
                            <td>PCB entries: current state, goal, expected state, plan; MCB entries: mismatch descriptions and suggested new goals; implicitly stores prior problem-solution episodes used for expectation and goal reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td>Reported qualitatively: CB-GDA systems (using the two case-bases) outperformed both rule-based GDA variants and non-GDA replanning agents in complex adversarial gaming scenarios; no numeric performance metrics are provided in this paper's description.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>memory_improvement_magnitude</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings_about_memory</strong></td>
                            <td>Empirical evaluations cited show that integrating case-based memory with GDA improves adaptability and performance in complex adversarial gaming scenarios compared to rule-based GDA and non-GDA replanning approaches, demonstrating the value of case-based episodic memory for dynamic goal reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_limitations</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_other_memory_types</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Review of Case-Based Reasoning for LLM Agents: Theoretical Foundations, Architectural Components, and Cognitive Integration', 'publication_date_yy_mm': '2025-04'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Goal-driven autonomy with case-based reasoning <em>(Rating: 2)</em></li>
                <li>Memory matters: The need to improve long-term memory in llm-agents <em>(Rating: 2)</em></li>
                <li>Position: Episodic memory is the missing piece for long-term llm agents <em>(Rating: 2)</em></li>
                <li>Generative agents: Interactive simulacra of human behavior <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-2910",
    "paper_id": "paper-277634555",
    "extraction_schema_id": "extraction-schema-72",
    "extracted_data": [
        {
            "name_short": "CBR-GDA",
            "name_full": "Case-Based Reasoning integrated with Goal-Driven Autonomy for LLM Agents",
            "brief_description": "A proposed architecture (in this paper) that integrates case-based memory (CBR) with a goal-driven autonomy controller for LLM agents, using two distinct case-bases to support expectation modeling and mismatch→goal formulation to enable dynamic goal reasoning and adaptation.",
            "citation_title": "here",
            "mention_or_use": "mention",
            "agent_name": "CBR-GDA",
            "agent_description": "An LLM-centered agent architecture that augments the foundation LLM with a case library and a Goal-Driven Autonomy (GDA) controller. It uses two case-bases (a Planning Case Base and a Mismatch-Goal Case Base) to store and retrieve prior problem/plan/goal examples; discrepancy detection triggers retrieval from the MCB to formulate new goals; adaptation is performed by the LLM guided by retrieved cases and adaptation mechanisms (transformational, compositional, generative). The framework also prescribes hybrid retrieval (semantic, feature, structural) and meta-cognitive selection of adaptation strategies.",
            "base_llm_model": null,
            "base_llm_size": null,
            "text_game_name": "multiagent gaming domain (generic)",
            "text_game_description": "Dynamic, adversarial multi-agent gaming scenarios where agents must detect discrepancies between expected and actual states, generate explanations, and formulate or revise goals/plans online; described in general terms rather than as a specific benchmark (no named text game like Jericho/TextWorld).",
            "uses_memory": true,
            "memory_type": "case-based (episodic) memory",
            "memory_architecture": "Two complementary case-bases: (1) Planning Case Base (PCB) storing tuples (state s, goal g, expected state e, plan p) for expectation modeling and plan retrieval; (2) Mismatch-Goal Case Base (MCB) storing (mismatch m, suggested new goal g). In addition, the paper specifies a general case library L of cases c=(P,S,O,M) where P=problem features, S=solutions/actions, O=outcomes/metrics, M=metadata; each case is indexed with dense semantic embeddings and sparse feature indices, organized hierarchically, and subject to selective retention via a utility function U(c_new,L) and threshold delta.",
            "memory_retrieval_mechanism": "Hybrid retrieval combining semantic embedding similarity (cosine in LLM embedding space), explicit feature-based matching, and structural-pattern retrieval; retrieval functions Retrieve_PCB and Retrieve_MCB are called to fetch expected states/plans or mismatch→goal mappings respectively; selection uses similarity thresholds (τ) and weighted combination (λ1, λ2, λ3).",
            "memory_capacity": null,
            "what_is_stored_in_memory": "Structured cases: problem features, solution components (plans/actions), outcome metrics, and metadata (temporal markers, conditions, provenance); PCB entries map (state, goal) → (expected state, plan); MCB entries map observed mismatches → candidate goals.",
            "performance_with_memory": null,
            "performance_without_memory": null,
            "has_ablation_study": null,
            "memory_improvement_magnitude": null,
            "key_findings_about_memory": "The paper argues (theoretically) that case-based memory enables superior goal reasoning, transparency, domain adaptation, and handling of edge cases in dynamic environments: the explicit case library supports discrepancy detection and goal formulation, and hybrid retrieval plus LLM-guided adaptation should improve solution quality and explainability compared to purely parametric or RAG-only approaches.",
            "memory_limitations": "Discussed at a systems level: added retrieval costs and computational overhead, challenges in case acquisition and quality control, dynamic case-base maintenance, potential retrieval failures if case coverage is sparse, and trade-offs between retrieval comprehensiveness and efficiency; no empirical failure-modes on games are reported in this paper.",
            "comparison_with_other_memory_types": "Compared conceptually (not empirically) against parametric-only reasoning and vanilla RAG/CoT: CBR (case-based memory) is presented as having richer cognitive capabilities (self-reflection, introspection), superior domain adaptation and explainability, and dynamic goal reasoning compared to CoT and standard RAG; no quantitative comparison between memory architectures is reported.",
            "uuid": "e2910.0",
            "source_info": {
                "paper_title": "Review of Case-Based Reasoning for LLM Agents: Theoretical Foundations, Architectural Components, and Cognitive Integration",
                "publication_date_yy_mm": "2025-04"
            }
        },
        {
            "name_short": "CB-GDA (Muñoz-Avila et al.)",
            "name_full": "Case-Based Goal-Driven Autonomy (CB-GDA)",
            "brief_description": "An earlier CBR-enhanced Goal-Driven Autonomy system (Muñoz-Avila et al., 2010) that used two case-bases—one mapping state-goal pairs to expected states/plans and another mapping mismatches to new goals—and was evaluated in multiagent gaming domains, showing empirical gains over alternatives.",
            "citation_title": "Goal-driven autonomy with case-based reasoning",
            "mention_or_use": "mention",
            "agent_name": "CB-GDA (Muñoz-Avila et al., 2010)",
            "agent_description": "A GDA controller augmented with CBR: a Planning Case Base (PCB) maps (state, goal) to expected states and plans; a Mismatch-Goal Case Base (MCB) maps detected discrepancies to candidate new goals. During execution, the system detects mismatches between expected and actual states, retrieves appropriate MCB entries to formulate new goals, and uses PCB for expected-state/planning support. The architecture supports continuous updating of case-bases based on plan/goal quality.",
            "base_llm_model": null,
            "base_llm_size": null,
            "text_game_name": "multiagent gaming domain (generic)",
            "text_game_description": "Complex adversarial multi-agent gaming scenarios used in the original CB-GDA empirical evaluations (paper does not name a specific text-game benchmark in the description here).",
            "uses_memory": true,
            "memory_type": "case-based memory / episodic",
            "memory_architecture": "Two dedicated case-bases: PCB storing (s, g, expected_state e, plan p) for planning and expectation modeling; MCB storing (mismatch m, suggested goal g) to support goal formulation when discrepancies occur. Case-bases are updated with new entries when Quality(p,g) or Quality(g_new,m) exceed thresholds (θP, θM).",
            "memory_retrieval_mechanism": "Case retrieval based on matching the current state/goal or detected mismatch to stored cases (similarity-based case matching); retrieval functions Retrieve_PCB and Retrieve_MCB are used to fetch expected states/plans or suggested goals respectively (specific retrieval algorithm details are not given in this paper's summary).",
            "memory_capacity": null,
            "what_is_stored_in_memory": "PCB entries: current state, goal, expected state, plan; MCB entries: mismatch descriptions and suggested new goals; implicitly stores prior problem-solution episodes used for expectation and goal reasoning.",
            "performance_with_memory": "Reported qualitatively: CB-GDA systems (using the two case-bases) outperformed both rule-based GDA variants and non-GDA replanning agents in complex adversarial gaming scenarios; no numeric performance metrics are provided in this paper's description.",
            "performance_without_memory": null,
            "has_ablation_study": null,
            "memory_improvement_magnitude": null,
            "key_findings_about_memory": "Empirical evaluations cited show that integrating case-based memory with GDA improves adaptability and performance in complex adversarial gaming scenarios compared to rule-based GDA and non-GDA replanning approaches, demonstrating the value of case-based episodic memory for dynamic goal reasoning.",
            "memory_limitations": null,
            "comparison_with_other_memory_types": null,
            "uuid": "e2910.1",
            "source_info": {
                "paper_title": "Review of Case-Based Reasoning for LLM Agents: Theoretical Foundations, Architectural Components, and Cognitive Integration",
                "publication_date_yy_mm": "2025-04"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Goal-driven autonomy with case-based reasoning",
            "rating": 2,
            "sanitized_title": "goaldriven_autonomy_with_casebased_reasoning"
        },
        {
            "paper_title": "Memory matters: The need to improve long-term memory in llm-agents",
            "rating": 2,
            "sanitized_title": "memory_matters_the_need_to_improve_longterm_memory_in_llmagents"
        },
        {
            "paper_title": "Position: Episodic memory is the missing piece for long-term llm agents",
            "rating": 2,
            "sanitized_title": "position_episodic_memory_is_the_missing_piece_for_longterm_llm_agents"
        },
        {
            "paper_title": "Generative agents: Interactive simulacra of human behavior",
            "rating": 1,
            "sanitized_title": "generative_agents_interactive_simulacra_of_human_behavior"
        }
    ],
    "cost": 0.013868499999999999,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>REVIEW OF CASE-BASED REASONING FOR LLM AGENTS: THEORETICAL FOUNDATIONS, ARCHITECTURAL COMPONENTS, AND COGNITIVE INTEGRATION A PREPRINT
April 14, 2025</p>
<p>Kostas Hatalis kostas@gocharlie.ai 0000-0001-8191-5728
Gocharlie Ai 
Despina Christou despina@gocharlie.ai 
Vyshnavi Kondapalli 
REVIEW OF CASE-BASED REASONING FOR LLM AGENTS: THEORETICAL FOUNDATIONS, ARCHITECTURAL COMPONENTS, AND COGNITIVE INTEGRATION A PREPRINT
April 14, 20250886A8DB729816F093012958CDAAEE1CarXiv:2504.06943v2[cs.AI]Case-Based ReasoningLarge Language ModelsRetrieval-Augmented GenerationChain-of-Thought ReasoningAutonomous AgentsGoal-Driven AutonomyCognitive ArchitecturesMeta-cognition
Agents powered by Large Language Models (LLMs) have recently demonstrated impressive capabilities in various tasks.Still, they face limitations in tasks requiring specific, structured knowledge, flexibility, or accountable decision-making.While agents are capable of perceiving their environments, forming inferences, planning, and executing actions towards goals, they often face issues such as hallucinations and lack of contextual memory across interactions.This paper explores how Case-Based Reasoning (CBR), a strategy that solves new problems by referencing past experiences, can be integrated into LLM agent frameworks.This integration allows LLMs to leverage explicit knowledge, enhancing their effectiveness.We systematically review the theoretical foundations of these enhanced agents, identify critical framework components, and formulate a mathematical model for the CBR processes of case retrieval, adaptation, and learning.We also evaluate CBR-enhanced agents against other methods like Chain-of-Thought reasoning and standard Retrieval-Augmented Generation, analyzing their relative strengths.Moreover, we explore how leveraging CBR's cognitive dimensions (including self-reflection, introspection, and curiosity) via goal-driven autonomy mechanisms can further enhance the LLM agent capabilities.Contributing to the ongoing research on neuro-symbolic hybrid systems, this work posits CBR as a viable technique for enhancing the reasoning skills and cognitive aspects of autonomous LLM agents.</p>
<p>Introduction</p>
<p>Groundbreaking advances in intelligence have been driven by LLMs showcasing remarkable capabilities in comprehending language and carrying out tasks effectively.The development of systems empowered by LLM technology marks a frontier in AI research with significant impacts on the collaboration between humans and AI.Despite their abilities and skills, these agents face difficulties in intricate reasoning situations that require specialized knowledge in the field, and they need to improve in how they apply that knowledge and explain the reasoning behind their decisions.[Huang and Chang, 2023].</p>
<p>CBR, a concept rooted in both computer science and AI, presents a method to tackle these challenges.CBR operates on the idea that similar problems tend to have similar solutions by using experiences and knowledge stored in previous cases to solve new problems [Aamodt and Plaza, 1994].This approach closely resembles how human experts often rely on reasoning and past decisions to solve problems [Kolodner, 1992].The standard CBR process includes four main steps: (1) Retrieve relevant cases; (2) Reuse the knowledge embedded in these cases; (3) Revise the proposed solution; and (4) Retain the new problem-solution pair for future reference [Aamodt and Plaza, 1994].</p>
<p>The inclusion of CBR in LLM agent structures shows promise as an area of research that could improve the ability to reason effectively across domains while also increasing transparency within these systems.This combination aims to combine the strong language comprehension skills of LLMs with CBR's memory-based reasoning abilities to overcome common limitations found in LLM models such as hallucinations and the difficulty in retaining information across interactions [Sourati et al., 2023].</p>
<p>By integrating organized case repositories and drawing inspiration from CBR for reasoning processes, LLMs could potentially address the shortcomings related to depth of reasoning, retrieval of knowledge, and adaptation of solutions as seen in existing methodologies [Weitl-Harms et al., 2024, Wiratunga et al., 2024].Recent work by Christou et al. [Christou et al., 2024] emphasizes notable weaknesses of LLMs in marketing situations-such as misunderstanding consumer preferences, producing misleading information, and lacking specific domain knowledge-highlighting the need for enhanced reasoning frameworks like CBR.</p>
<p>Furthermore, the cognitive dimensions of CBR, particularly self-reflection, introspection, and curiosity, offer opportunities to enhance traditional LLM-based agents with deeper understanding capabilities [Craw and Aamodt, 2018].Goal-driven autonomy (GDA), a complementary approach that enables agents to reason about and dynamically select their goals during execution [Muñoz-Avila et al., 2010], provides a framework for incorporating these cognitive elements into CBR-augmented LLM agents.GDA allows agents to continually monitor their expectations against actual outcomes, explain discrepancies, formulate new goals when needed, and manage these goals effectively.These capabilities align well with CBR's focus on learning from experience and adapting over time.</p>
<p>This paper thoroughly examines CBR-enhanced LLM agents by delving into their underlying principles and structural elements as well as highlighting their benefits compared to other reasoning models.We propose a model for applying CBR methods within LLM agents and evaluate its effectiveness compared to Chain of Thought (CoT) reasoning and standard Retrieval-Augmented Generation (RAG).</p>
<p>The main contributions of this work are:</p>
<p>• A clear explanation of the theoretical foundations behind CBR-augmented LLM agents, synthesizing insights from cognitive science, knowledge representation, and language model research.• A detailed architectural framework outlining the essential components of CBR-enhanced LLM agents, including case representation, indexing strategies, similarity assessment mechanisms, and adaptation procedures.• A mathematically rigorous formulation of CBR processes within LLM agents, encompassing case retrieval, similarity computation, solution adaptation, and continuous learning.• A comparative analysis evaluating CBR-augmented agents against CoT reasoning and vanilla RAG approaches across multiple dimensions, including reasoning transparency, domain adaptation, and solution quality.• An exploration of cognitive dimensions in CBR for LLM agents, including self-reflection, introspection, and curiosity, integrated within a goal-driven autonomy framework.• A proposed framework for meta-cognitive CBR that enables introspective reasoning about case selection, adaptation strategies, and goal formulation in dynamic environments.</p>
<p>The remainder of this paper is structured as follows: Section 2 provides comprehensive background on CBR, LLM agents, and related work.Section 3 presents the theoretical foundations and formal characterization of CBR-augmented LLM agents.Section 4 describes the architectural components and implementation considerations.Section 5 explores cognitive dimensions and meta-cognitive aspects of CBR for LLM agents.Section 6 introduces goal-driven autonomy as a framework for enhancing CBR-based LLM agent reasoning.Section 7 offers a comparative analysis against alternative approaches.Section 8 discusses implications, limitations, and future directions, followed by concluding remarks in Section 9.</p>
<p>encompasses four principal phases: (1) Retrieve relevant cases from a knowledge repository; (2) Reuse the knowledge embedded in these cases to address the current problem; (3) Revise the proposed solution based on the specific constraints of the target problem; and (4) Retain the new problem-solution pair as a learned case for future reference.</p>
<p>The theoretical underpinnings of CBR are rooted in multiple disciplines.From cognitive science, CBR draws upon models of episodic memory and analogical reasoning [Gentner et al., 1997].From a philosophical perspective, CBR reflects casuistic reasoning approaches that privilege experiential knowledge over abstract principles [Jonsen et al., 1988].In the computational realm, CBR presented an alternative to rule-based expert systems, emphasizing experiential knowledge representation rather than explicit rule codification [Kolodner, 1992].</p>
<p>The efficacy of CBR has been demonstrated across diverse domains, including legal reasoning [Ashley, 1988], medical diagnosis [Bichindaritz and Marling, 2006], engineering design [Maher and Pu, 2014], and more recently, in recommendation systems [Bridge et al., 2005] and educational technologies [Kolodner et al., 2005].The enduring appeal of CBR lies in its capacity to handle ill-defined problems, accommodate incomplete domain models, and provide transparent explanations through precedent-based reasoning.</p>
<p>LLM Agents: Evolution and Current Paradigms</p>
<p>LLM agents represent an evolutionary progression in the application of neural language models, transitioning from passive text generation to active decision-making systems capable of goal-directed behavior [Xi et al., 2025].These agents are characterized by their use of LLMs as the central component to perceive, reason, plan, and act within an environment to accomplish complex tasks [Wang et al., 2024].Contemporary LLM agents typically integrate several key components: (1) a foundation LLM providing core linguistic and reasoning capabilities;</p>
<p>(2) a memory system for maintaining contextual information and past experiences; (3) planning mechanisms for decomposing complex tasks; and (4) interfaces with external tools or environments [Wang et al., 2024].</p>
<p>The architecture of LLM agents emphasizes several core components:</p>
<p>Planning: This crucial aspect enables the agent to break down complex tasks into manageable sub-tasks and devise action sequences to achieve objectives [Yao et al., 2023].Techniques like Chain-of-Thought (CoT) prompting [Wei et al., 2022], which elicits step-by-step reasoning, and Tree-of-Thought (ToT) [Yao et al., 2023], which explores multiple reasoning branches concurrently, enhance planning capabilities.</p>
<p>Memory: Both short-term memory (for current task information) and long-term memory (for persistent knowledge across interactions) are vital components [Guo et al., 2023, Pink et al., 2025].Vector stores are frequently used to implement long-term memory, enabling efficient retrieval of relevant information based on semantic similarity.</p>
<p>Retrieval-Augmented Generation: RAG methodologies enhance LLM capabilities by incorporating external knowledge retrieval mechanisms, enabling models to access and utilize information beyond their parametric knowledge [Lewis et al., 2020, Gao et al., 2023].</p>
<p>Tool Use: Tool-augmented agents extend LLM capabilities through integration with external tools, APIs, and computational resources, enabling interaction with databases, web services, and specialized algorithms [Schick et al., 2023, Qin et al., 2024].</p>
<p>Multi-Agent Architectures: These approaches distribute complex tasks across multiple specialized LLM agents, enabling collaborative problem-solving through agent communication and coordination [Wu et al., Park et al., 2023].</p>
<p>Despite these advancements, LLM agents continue to face challenges in reasoning consistency, domain adaptation, and explanation transparency.They often struggle with hallucinations, lack of persistent memory across interactions, and limitations in handling novel situations with limited available data-areas where CBR integration may offer significant advantages [Sourati et al., 2023].</p>
<p>A critical limitation of current LLM agents relates to memory management.Hatalis et al. [Hatalis et al., 2023] review existing approaches to memory in LLM agents, distinguishing between short-term memory (implemented through context window retention) and long-term memory (typically implemented via vector databases).They highlight fundamental challenges in LLM agent memory systems, including the separation of different memory types (procedural, episodic, and semantic), the risk of agents becoming trapped in task loops, and the need for effective memory management over an agent's lifetime.The authors propose that future developments should focus on metadata enrichment in both procedural and semantic memory stores and better integration of external knowledge sources with vector databases to enhance memory retrieval and utilization.</p>
<p>Intersection of CBR and LLMs: Emerging Research</p>
<p>The integration of CBR principles with large language models represents an emerging research frontier with promising explorations aimed at creating more robust, adaptable, and explainable AI systems.This synthesis capitalizes on the complementary strengths of both paradigms: CBR offers LLMs a mechanism for persistent memory and structured reasoning, while LLMs contribute powerful language understanding capabilities to CBR processes [Sourati et al., 2023].</p>
<p>Several architectures and frameworks have been proposed for this integration: DS-Agent: This framework automates data science tasks by empowering LLM agents with CBR [Guo et al., 2024].It operates in two stages: a development stage following the complete CBR cycle to capitalize on expert knowledge, and a deployment stage using a simplified CBR paradigm to adapt past successful solutions for direct code generation.</p>
<p>CaseGPT: This approach synergizes LLMs and Retrieval-Augmented Generation technology to enhance case-based reasoning, particularly in healthcare and legal domains [Wiratunga et al., 2024].CaseGPT addresses limitations of traditional database queries by enabling semantic searches based on contextual understanding and leverages fine-tuned models for domain-specific case encoding.</p>
<p>CBR-RAG: This framework uses the initial retrieval stage of the CBR cycle to enhance LLM queries within a Retrieval-Augmented Generation framework [Wiratunga et al., 2024].The integration aims to augment original LLM queries with contextually relevant cases, leading to improved answer quality.</p>
<p>Other researchers have explored specific aspects of CBR-LLM integration.Wiratunga et al. [2024] demonstrated that retrieval of similar examples can enhance LLM reasoning performance on complex tasks.Peng et al. [2023] proposed a CBR-inspired approach for verification of LLM-generated solutions through comparison with retrieved exemplars.Sumers et al. [2023] explored the intersection of cognitive architectures and LLMs, suggesting potential synergies with memory-based reasoning systems.</p>
<p>Previous work has also investigated CBR in the context of earlier language technologies.Weber et al. [2001] applied CBR principles to text classification tasks, while Brüninghaus and Ashley [2001] explored case-based approaches for information extraction.More recently, Wiratunga et al. [2024] demonstrated the efficacy of contextual retrieval for enhancing language model performance on knowledge-intensive tasks.</p>
<p>Recent work by Dannenhauer et al. [Dannenhauer et al., 2024] demonstrates the effectiveness of CBR for improving code generation through dynamic few-shot prompting.Their approach maintains a case base of problem-solution pairs, where problems are natural language task descriptions and solutions are executable Python code.When presented with a new problem, the system retrieves the most similar cases and uses them to provide guidance to the LLM, which then adapts the retrieved solutions to the current context.This dynamic approach showed improved performance over both zero-shot and static few-shot prompting in generating task plans as Python code, particularly in reducing common errors such as incorrect function calls, missed function calls, and improper ordering of operations.The authors identify seven distinct failure modes in LLM code generation and demonstrate how CBR can help address these challenges.</p>
<p>Cognitive Systems and Goal-Driven Autonomy</p>
<p>The field of cognitive systems, which aims to build AI systems with human-like understanding capabilities, has seen resurgence in interest with the advancement of LLMs [Craw and Aamodt, 2018].Cognitive systems understand the world through learning and experience, employing mechanisms such as self-reflection, introspection, and curiosity [Langley, 2012].Case-based systems are inherently suited to cognitive computing paradigms due to their experiential knowledge representation and episodic memory structures that mirror aspects of human cognition.</p>
<p>Goal-Driven Autonomy (GDA) represents a complementary framework that enhances agents' ability to reason about and self-select goals during execution [Muñoz-Avila et al., 2010].The GDA model extends traditional planning approaches by incorporating mechanisms for discrepancy detection, explanation generation, goal formulation, and goal management.This enables agents to dynamically adjust their objectives in response to unexpected events or changing circumstances-capabilities that are particularly valuable in complex, dynamic environments.-Avila et al. [2010] demonstrated the efficacy of integrating CBR with GDA in a multiagent gaming domain.</p>
<p>Muñoz</p>
<p>Their CB-GDA system employed two distinct case bases: one mapping goals to expectations given particular states, and another mapping discrepancies between expected and actual states to appropriate new goals.Empirical evaluations showed that this CBR-enhanced GDA approach outperformed both rule-based GDA variants and non-GDA replanning agents when faced with complex adversarial scenarios.</p>
<p>The integration of cognitive dimensions and goal-driven autonomy with CBR-enhanced LLM agents represents a promising direction for addressing the limitations of current approaches.By incorporating self-reflection, introspection, and curiosity within a goal-reasoning framework, these hybrid systems can potentially achieve greater adaptability, explainability, and robustness in complex problem-solving scenarios.</p>
<p>Our work extends these research directions by providing a comprehensive theoretical framework specifically for CBRaugmented LLM agents, formal mathematical characterizations of the integrated processes, systematic comparative analysis against alternative approaches, and exploration of cognitive dimensions and goal-driven autonomy as enhancing mechanisms for CBR-LLM integration.</p>
<p>3 Theoretical Foundations of CBR-Augmented LLM Agents</p>
<p>This section formalizes the theoretical underpinnings of integrating Case-Based Reasoning within LLM agents.We define the structure of cases, formulate the core CBR processes (retrieval, adaptation, and learning) and present mathematical models that characterize their implementation in language-based agent architectures.</p>
<p>Formal Definition of Cases in the LLM Agent Context</p>
<p>In the context of LLM agents, we define a case c ∈ C as a structured representation encompassing problem characteristics, solution strategies, and outcome assessments.Formally, a case can be represented as a tuple:
c = (P, S, O, M )(1)
where:</p>
<p>• P denotes the problem space, characterized by features p 1 , p 2 , ..., p n • S represents the solution space, encompassing actions
s 1 , s 2 , ..., s m • O captures the outcome space, including success metrics o 1 , o 2 , ..., o k • M comprises metadata elements m 1 , m 2 , .
.., m j , such as temporal markers, environmental conditions, and provenance information</p>
<p>This structured representation enables systematic organization of experiential knowledge within the agent's case library L = {c 1 , c 2 , ..., c l }, facilitating efficient retrieval and adaptation processes.</p>
<p>Mathematical Formulation of Case Retrieval</p>
<p>The case retrieval process in CBR-augmented LLM agents can be formalized as an optimization problem seeking to identify cases with maximal relevance to the target problem.Given a query problem q, the retrieval function R aims to identify a subset of cases C q ⊆ L such that:
C q = R(q, L) = {c i ∈ L | sim(q, P i ) ≥ τ } (2)
where sim(q, P i ) represents a similarity function measuring the correspondence between the query problem and the problem component of case c i , and τ denotes a threshold parameter determining retrieval selectivity.</p>
<p>The similarity function sim(q, P i ) can be decomposed into multiple components:
sim(q, P i ) = d j=1 w j • sim j (q j , p ij )(3)
where d represents the dimensionality of the feature space, w j denotes the weight assigned to feature j, and sim j specifies the similarity metric for feature j.</p>
<p>In the context of LLM agents, we can further refine this formulation by incorporating semantic similarity measures derived from the embedding space of the foundation model:
sim semantic (q, P i ) = E(q) • E(P i ) ||E(q)|| • ||E(P i )|| (4)
where E(•) represents the embedding function mapping textual inputs to high-dimensional vectors in the LLM's latent space.</p>
<p>Solution Adaptation Process</p>
<p>The adaptation process transforms retrieved solutions to address the specific requirements of the target problem.We formalize this process as a function A that maps a set of retrieved cases C q and a query problem q to a candidate solution ŝ:
ŝ = A(q, C q ) = f LLM (q, C q , Θ)(5)
where f LLM represents the language model's generation function parameterized by Θ.</p>
<p>This adaptation function can be further decomposed into sequential operations:
A(q, C q ) = A compose • A transform • A select (q, C q ) (6)
where:</p>
<p>• A select identifies the most relevant components from retrieved solutions • A transform modifies these components to align with the target problem constraints • A compose integrates the transformed components into a coherent solution</p>
<p>The LLM serves as the primary mechanism for implementing these adaptation operations, leveraging its generative capabilities to transform retrieved solution patterns into context-appropriate responses.</p>
<p>Case Learning and Knowledge Evolution</p>
<p>A distinctive characteristic of CBR systems is their capacity for continuous learning through case acquisition and refinement.We formalize the case retention process as a function T that determines whether a new problem-solution episode warrants inclusion in the case library:
L t+1 = L t ∪ {c new } if U (c new , L t ) ≥ δ L t otherwise (7)
where U (c new , L t ) represents a utility function assessing the marginal value of incorporating the new case, and δ denotes a threshold parameter for case retention.</p>
<p>The utility function U can be formulated to consider multiple factors:
U (c new , L) = α • novelty(c new , L) + β • effectiveness(c new ) + γ • generalizability(c new )(8)
where α, β, and γ are weighting coefficients for the respective utility components.</p>
<p>This formulation provides a mathematical framework for selective case retention, ensuring that the agent's knowledge base evolves to incorporate valuable experiences while maintaining computational efficiency.</p>
<p>Architectural Components of CBR-Enhanced LLM Agents</p>
<p>This section outlines the core architectural elements necessary for implementing CBR-enhanced LLM agents.We describe strategies for case representation and indexing, detail hybrid retrieval mechanisms, and examine adaptation processes, culminating in a framework that integrates case-based reasoning with the inherent capabilities of large language models.</p>
<p>Case Representation and Indexing Strategies</p>
<p>Effective case representation constitutes a foundational element of CBR-augmented LLM agents.We propose a multi-faceted representation scheme that captures the semantic richness of cases while facilitating efficient retrieval operations:</p>
<p>This representation scheme incorporates both dense semantic embeddings E i derived from the foundation LLM and sparse feature-based indices I i capturing domain-specific attributes.The hierarchical organization facilitates efficient retrieval by enabling coarse-to-fine search strategies.Generate metadata M i ← GenerateMetadata(d i )</p>
<p>9:</p>
<p>Create structured case c i ← (P i , S i , O i , M i )</p>
<p>10:</p>
<p>Compute semantic embedding E i ← E(c i )</p>
<p>11:</p>
<p>Compute feature-based indices I i ← IndexFeatures(c i )</p>
<p>12:</p>
<p>Add indexed case to library L ← L ∪ {(c i , E i , I i )} 13: end for 14: Organize library using hierarchical structure L ← OrganizeHierarchy(L) 15: return L</p>
<p>Hybrid Retrieval Mechanisms</p>
<p>CBR-augmented LLM agents employ a hybrid retrieval approach that combines multiple search strategies to identify relevant cases:
R(q, L) = λ 1 • R semantic (q, L) ∪ λ 2 • R feature (q, L) ∪ λ 3 • R structural (q, L)(9)
where:</p>
<p>• R semantic performs retrieval based on embedding similarity in the LLM's latent space • R feature conducts search based on explicit feature matching • R structural identifies cases with similar problem structures or solution patterns • λ 1 , λ 2 , λ 3 represent weighting coefficients determining the relative contribution of each retrieval mechanism This hybrid approach leverages both the semantic understanding capabilities of the foundation LLM and structured domain knowledge encoded in the case representation.</p>
<p>Adaptation Mechanisms</p>
<p>The adaptation process in CBR-augmented LLM agents comprises several sophisticated mechanisms:</p>
<p>Transformational Adaptation: Modifies retrieved solutions through substitution, deletion, or insertion operations to align with target problem constraints:
S adapted = T sub (S retrieved , ∆ constraints ) • T del (S retrieved , ∆ constraints ) • T ins (S retrieved , ∆ constraints )(10)
Compositional Adaptation: Integrates components from multiple retrieved solutions to address complex problems:
S adapted = k i=1 w i • S i(11)
where represents a composition operator and w i denotes the weight assigned to solution S i .</p>
<p>Generative Adaptation: Leverages the LLM's generative capabilities to synthesize novel solutions guided by retrieved cases:
S adapted = f LLM (q, {S 1 , S 2 , ..., S k }, Θ)(12)
These adaptation mechanisms are orchestrated through a meta-cognitive process that selects the appropriate approach based on problem characteristics and retrieval results.</p>
<p>Integration with LLM Reasoning Processes</p>
<p>CBR-augmented LLM agents integrate case-based processes with the inherent reasoning capabilities of the foundation model.This integration can be formalized through a weighted combination of reasoning pathways:
f reasoning (q) = ω 1 • f CBR (q) + ω 2 • f CoT (q) + ω 3 • f parametric (q)(13)
where:</p>
<p>• f CBR represents the case-based reasoning pathway</p>
<p>• f CoT denotes the chain-of-thought reasoning process</p>
<p>• f parametric captures direct inference from the model's parametric knowledge</p>
<p>• ω 1 , ω 2 , ω 3 are dynamic weights determined by confidence metrics associated with each pathway</p>
<p>This integrated approach enables the agent to leverage the complementary strengths of experiential knowledge and neural reasoning processes.</p>
<p>Cognitive Dimensions of CBR for LLM Agents</p>
<p>Cognitive dimensions of CBR present opportunities to enhance LLM agents with deeper understanding capabilities through self-reflection, introspection, and curiosity.These cognitive elements enable the agent to develop a more nuanced understanding of its knowledge and reasoning processes, leading to more robust and adaptable problem-solving capabilities.</p>
<p>Cognition through Self-Reflection</p>
<p>Self-reflection enables the CBR-LLM agent to understand and make sense of its knowledge.This cognitive dimension can be characterized through several key aspects:</p>
<p>Context Understanding: The agent develops an understanding of the different facets and contexts in which each case is relevant.A case captures a collection of related information for an experience, and self-reflection enables the agent to understand the relationships among various facets and recognize the different contexts in which the case applies [Craw and Aamodt, 2018].</p>
<p>Domain Insight: Through reflection on collections of cases, the agent develops insights into the landscape of the domain.Areas with many similar cases indicate regions of high confidence, while sparse or inconsistent regions suggest complexity requiring more sophisticated reasoning [Smyth and McKenna, 2001].This insight allows the agent to understand where "fast thinking" intuitive reasoning is appropriate versus where "slow thinking" deliberative reasoning is needed [Kahneman, 2011, Craw andAamodt, 2018].</p>
<p>Intuitive Reasoning: Self-reflection on successful and unsuccessful applications of the similarity assumption ("similar problems have similar solutions") enables the agent to develop intuition about when this assumption holds.The agent can identify regions of the case space where retrieval-based solutions are likely to be effective without extensive adaptation [Craw and Aamodt, 2018].</p>
<p>Analogical Reasoning: Through reflection on adaptation patterns, the agent develops a deeper understanding of how differences in problem specifications should be reflected in solution adjustments.This enables more sophisticated analogical reasoning that recognizes when and how to transform retrieved solutions [Forbus and Hinrich, 2017].</p>
<p>Meta-cognition through Introspection</p>
<p>Meta-cognition involves "cognition about cognition" or understanding one's own understanding.For CBR-LLM agents, introspection provides mechanisms for understanding failure modes and developing strategies to improve reasoning processes.</p>
<p>Understanding Different Contexts: Introspection on case retrieval enables the agent to develop selection strategies based on identifying key features or feature combinations for different contexts.By examining clusters in problem and solution spaces, the agent can identify which dimensions are most relevant for different types of problems [Craw and Aamodt, 2018].</p>
<p>Understanding Reasoning Failures: When the agent's solutions are incorrect or suboptimal, introspection enables it to determine whether failures stem from retrieval limitations (finding the wrong cases) or adaptation limitations (incorrectly transforming retrieved solutions).This understanding guides refinement of similarity metrics or adaptation strategies [Cox, 2005, Craw andAamodt, 2018].</p>
<p>Learning Selection Strategies: Meta-cognition enables the agent to learn when to apply different retrieval and adaptation strategies based on problem characteristics and past performance.These strategies can be encoded across different knowledge containers, including representation adjustments, similarity metrics, or adaptation rules [Richter and Weber, 2016, Craw andAamodt, 2018].</p>
<p>Curiosity and Extrospection</p>
<p>Curiosity extends the agent's cognitive capabilities by driving active exploration and knowledge acquisition from external sources.</p>
<p>Gap Identification: Reflective and introspective processes enable the identification of knowledge gaps -areas where the agent's case library lacks sufficient coverage or where reasoning consistently fails [Gottlieb et al., 2013, Craw andAamodt, 2018].</p>
<p>Active Knowledge Seeking: Curiosity drives the agent to actively seek new information from external sources to address identified gaps.This involves distinguishing between "known unknowns" (areas where the agent recognizes its limitations) and "unknown unknowns" (limitations the agent has not yet recognized) [Craw and Aamodt, 2018].</p>
<p>Source Evaluation: The curious agent develops strategies for evaluating the reliability and relevance of external knowledge sources, balancing the exploration of novel information with verification requirements [Craw and Aamodt, 2018].</p>
<p>Knowledge Container Interactions in Cognitive CBR</p>
<p>The cognitive dimensions of CBR can be understood through Richter's knowledge container framework [Richter and Weber, 2016], where knowledge can be shifted between vocabulary, cases, similarity, and solution adaptation containers.</p>
<p>Cognitive processes enable dynamic knowledge redistribution across these containers:
K t+1 i = T (K t i , ∆K t j )(14)
where K i represents knowledge container i, t denotes the time step, and T is a transfer function that defines how knowledge from container j influences the evolution of container i.</p>
<p>This formulation captures how insights from self-reflection on cases can lead to refinements in similarity metrics, or how introspection on adaptation failures can lead to improved case representation.These knowledge container interactions provide the foundation for a cognitive CBR system that continuously improves its understanding and problem-solving capabilities.</p>
<p>6 Goal-Driven Autonomy for CBR-Enhanced LLM Agents</p>
<p>Goal-Driven Autonomy (GDA) provides a complementary framework for enhancing CBR-augmented LLM agents with dynamic goal reasoning capabilities.GDA enables agents to reason about their objectives and self-select goals throughout execution, making them more adaptable in complex, dynamic environments.</p>
<p>Conceptual Model of GDA</p>
<p>The GDA conceptual model extends traditional planning approaches by incorporating four key components within the controller [Muñoz-Avila et al., 2010]:</p>
<p>• Discrepancy Detection: Compares observations to expectations and identifies unexpected events • Explanation Generation: Hypothesizes explanations for detected discrepancies • Goal Formulation: Generates new goals based on discrepancies and their explanations • Goal Management: Maintains and prioritizes pending goals This model enables agents to dynamically adjust their objectives in response to changing circumstances or unexpected events, a capability that is particularly valuable in complex, open-ended domains.</p>
<p>Integration of CBR and GDA</p>
<p>The integration of CBR with GDA creates a powerful framework for dynamic reasoning in LLM agents.We propose a CBR-GDA architecture that utilizes two distinct case bases [Muñoz-Avila et al., 2010]:</p>
<p>• Planning Case Base (PCB): Contains mappings from state-goal pairs to expected states and plans: (s, g, e, p) where s is the current state, g is the goal, e is the expected state after achieving the goal, and p is the plan • Mismatch-Goal Case Base (MCB): Contains mappings from mismatches between expected and actual states to appropriate new goals: (m, g) where m is the mismatch and g is the suggested new goal</p>
<p>The algorithm for CBR-enhanced GDA can be formalized as follows:</p>
<p>Algorithm 2 CBR-GDA Algorithm for LLM Agents end while 16: end while This algorithm enables the agent to continuously monitor its expectations against actual outcomes, detect discrepancies, and formulate new goals when necessary.The CBR mechanism provides a principled approach to learning from past experiences, allowing the agent to improve its discrepancy detection and goal formulation capabilities over time.</p>
<p>Mathematical Model of CBR-GDA</p>
<p>The integration of CBR and GDA can be formalized through a mathematical model that captures the dynamic interaction between case-based knowledge and goal reasoning processes.</p>
<p>Let Σ = (S, A, E, γ) represent a state transition system, where S is the set of states, A is the set of actions, E is the set of exogenous events, and γ : S × (A ∪ E) → S is the state transition function.</p>
<p>The GDA controller receives as input a planning problem (M Σ , s c , g c ), where M Σ is a model of Σ, s c is the current state, and g c ∈ G is a goal that can be satisfied by some set of states S g ⊂ S.</p>
<p>For a CBR-enhanced GDA agent, we define the following functions:
Retrieve P CB : S × G → S × P (15) Retrieve M CB : M → G (16)
where M is the space of mismatches between expected and actual states, and P is the space of plans.</p>
<p>The goal formulation process can be represented as:
g new = f formulate (s c , m, Retrieve M CB (m))(17)
where m = Discrepancy(s c , e c , s actual ) represents the detected discrepancy.</p>
<p>This formulation provides a rigorous foundation for implementing and analyzing CBR-enhanced GDA systems for LLM agents.</p>
<p>Learning in CBR-GDA</p>
<p>A key advantage of the CBR-GDA approach is its capacity for continuous learning.The PCB and MCB can be updated based on execution experiences, enabling the agent to improve its expectations and goal formulation strategies over time.</p>
<p>The update process for the PCB can be formalized as:
PCB t+1 = PCB t ∪ {(s, g, e actual , p)|Quality(p, g) &gt; θ P }(18)
Similarly, the MCB can be updated as:
MCB t+1 = MCB t ∪ {(m, g new )|Quality(g new , m) &gt; θ M }(19)
where Quality functions evaluate the effectiveness of plans and goals, and θ P and θ M are quality thresholds.</p>
<p>This learning process enables the agent to continuously refine its understanding of the environment and improve its goal reasoning capabilities, leading to more adaptive and robust behavior over time.</p>
<p>7 Comparative Analysis: CBR vs. CoT vs. Vanilla RAG This section presents a comparative analysis of CBR-augmented LLM agents against Chain-of-Thought reasoning and standard Retrieval-Augmented Generation approaches.We evaluate each method across multiple dimensions (e.g.reasoning transparency, domain adaptation, cognitive capabilities) to highlight the unique strengths and trade-offs of CBR-based architectures.</p>
<p>Theoretical Comparative Framework</p>
<p>We establish a multidimensional framework for comparing CBR-augmented LLM agents against alternative approaches: This framework highlights the distinctive characteristics of each approach, with CBR emphasizing experiential knowledge organization, transparent precedent-based reasoning, and explicit domain modeling.</p>
<p>Reasoning Transparency and Explainability</p>
<p>CBR-augmented agents demonstrate superior explainability through the explicit presentation of precedent cases and adaptation rationales.This inherent transparency stems from CBR's reliance on past cases, allowing agents to provide justifications for their decisions based on previously encountered scenarios [Wilkerson, 2024].The retrieved cases serve as explicit examples illustrating why a particular action was taken or a specific solution was proposed.</p>
<p>This explainability advantage can be formalized through an explainability metric:
E(a) = 1 n n i=1 trace(r i ) complexity(r i )(20)
where E(a) represents the explainability score for agent a, r i denotes reasoning instance i, trace(r i ) measures the completeness of the explanation trace, and complexity(r i ) captures the cognitive complexity of the reasoning process.</p>
<p>Empirical evaluations indicate that CBR-augmented agents achieve higher explainability scores compared to CoT and vanilla RAG approaches, particularly for domain-specific reasoning tasks.Studies by Wilkerson [2024] in triage classification scenarios found that providing the nearest neighbor case, along with explicit statements of difference between the current problem and the retrieved case, elicited the highest user scores on trust metrics.Explanations built from cases have been shown to be more convincing than those built from domain-based rules, and the CBR process itself mimics human reasoning methods, further enhancing trust in the agent's outputs [Sourati et al., 2023].</p>
<p>Domain Adaptation and Knowledge Transfer</p>
<p>The capacity for domain adaptation represents a critical dimension for evaluating agent performance.CBR equips LLM agents with a mechanism to effectively address novel situations they have not encountered before [Guo et al., 2024].</p>
<p>The CBR cycle's retention phase, where new problems and their successful solutions are stored as new cases, allows the agent to continuously learn and adapt to previously unseen scenarios over time.</p>
<p>We formalize this adaptation capability as the rate of performance improvement as a function of domain-specific experience:
A(a, d) = ∂P (a, d, t) ∂t(21)
where A(a, d) denotes the adaptation rate of agent a in domain d, and P (a, d, t) represents the performance metric at time t.</p>
<p>CBR-augmented agents exhibit accelerated adaptation trajectories due to their explicit case acquisition mechanisms, particularly in specialized domains with limited training data availability.The lazy learning approach inherent in CBR, where generalization is delayed until a specific problem is encountered, makes it particularly well-suited for handling novelty [Aamodt and Plaza, 1994].</p>
<p>Studies with the DS-Agent framework demonstrate this advantage, showing that by using CBR to structure the experiment planning process for automated data science tasks, LLM agents can achieve significantly better results compared to baseline models when adapting to new domains [Guo et al., 2024].By identifying situations that are not present in its case base, a CBR-integrated LLM agent can store these novel scenarios for future reuse, thus continuously expanding its problem-solving capabilities and accelerating domain adaptation.</p>
<p>Computational Efficiency and Scalability</p>
<p>The computational characteristics of different approaches impact their practical applicability.We analyze these dimensions through the following metrics:</p>
<p>T (a, q) = T retrieval (a, q) + T processing (a, q) + T generation (a, q) (22)
M (a) = M model (a) + M knowledge (a) + M working (a)(23)
where T (a, q) represents the total computation time for agent a processing query q, and M (a) denotes the memory requirements.</p>
<p>Our analysis reveals trade-offs across approaches: CBR-augmented agents incur additional retrieval costs but benefit from reduced processing requirements for well-matched cases.The selective retention mechanisms of CBR also contribute to more efficient knowledge base management compared to comprehensive corpus-based approaches in vanilla RAG.</p>
<p>Cognitive Capabilities and Goal Reasoning</p>
<p>CBR-augmented LLM agents demonstrate enhanced cognitive capabilities through self-reflection, introspection, and curiosity-driven learning.When combined with goal-driven autonomy, these agents exhibit more flexible and adaptive behavior in complex environments.</p>
<p>Empirical evaluations in gaming environments have shown that CB-GDA systems outperform both rule-based GDA and non-GDA replanning agents in complex adversarial scenarios [Muñoz-Avila et al., 2010].The ability to dynamically adjust goals in response to unexpected events or changing circumstances provides these agents with a significant advantage in open-ended, dynamic domains.</p>
<p>The integration of cognitive capabilities with goal reasoning enables CBR-augmented LLM agents to exhibit more robust and adaptive behavior patterns compared to traditional approaches.This is particularly evident in scenarios requiring long-term autonomy, where the agent must navigate changing environments and objectives without direct human intervention.</p>
<p>Solution Quality and Performance Metrics</p>
<p>We evaluate solution quality across multiple dimensions:
Q(a) = α • accuracy(a) + β • relevance(a) + γ • coherence(a) + δ • novelty(a)(24)
Several studies have evaluated the performance of LLM agents that incorporate Case-Based Reasoning across a range of tasks.Sourati et al. [2023] demonstrated that integrating CBR with language models improves both the accuracy and generalizability in logical fallacy detection.In automated data science, the DS-Agent framework achieved a 100% success rate in the development stage and a 99% one-pass rate in the deployment stage with GPT-4, outperforming other state-of-the-art LLM agents while also demonstrating cost efficiency [Guo et al., 2024].Wilkerson [2024] found that providing case knowledge improved both user trust and LLM accuracy in triage classification tasks.Wiratunga et al. [2024] showed that using CBR's retrieval stage to enhance LLM queries with contextually relevant cases led to significant improvements in the quality of legal question answering.</p>
<p>Empirical evaluations across these diverse task domains indicate that CBR-augmented agents demonstrate:</p>
<p>• Superior performance on domain-specific tasks requiring specialized knowledge • Enhanced consistency in solution generation across related problems • Improved handling of edge cases through explicit storage of exceptional situations • More graceful degradation when confronted with problems outside the training distribution • Higher user trust scores, particularly when cases are presented alongside explanations of differences • Greater adaptability to changing goals and problem specifications</p>
<p>The comparative advantages of CBR-augmented agents are particularly pronounced in domains characterized by complex procedural knowledge, highly structured problem spaces, and availability of high-quality historical cases.The metrics used in these evaluations include accuracy, generalizability, user trust, task completion rate, mean rank, best rank, one-pass rate, cost efficiency, and various explainability metrics.</p>
<p>Discussion and Future Directions</p>
<p>Integrating Case-Based Reasoning with LLM agents presents both significant opportunities and practical challenges, reshaping how language models can reason, learn, and adapt.The discussion examines the broader impact of this integration and identifies critical areas for future work, including the design of richer case representations, the incorporation of cognitive mechanisms, and the development of scalable hybrid architectures that bridge symbolic and neural reasoning.</p>
<p>Theoretical Implications</p>
<p>The integration of CBR with LLM agents bridges symbolic and neural approaches to artificial intelligence, contributing to the ongoing discourse on neuro-symbolic architectures.This hybridization demonstrates how structured knowledge representation and experiential learning can complement the distributional semantics captured in neural language models.</p>
<p>Our formal characterization of CBR processes within LLM agents establishes a theoretical foundation for understanding knowledge utilization, adaptation mechanisms, and learning dynamics in these hybrid systems.This framework enables systematic analysis of the interplay between parametric and non-parametric knowledge representations in language-based agents.</p>
<p>The incorporation of cognitive dimensions and goal-driven autonomy further extends the theoretical landscape by providing mechanisms for meta-level reasoning about knowledge and goals.This addresses fundamental questions about how AI systems can develop more human-like understanding capabilities that go beyond pattern recognition to include self-reflection, introspection, and purposeful exploration.</p>
<p>Practical Considerations and Implementation Challenges</p>
<p>Several practical challenges warrant consideration in the implementation of CBR-augmented LLM agents:</p>
<p>Case Acquisition and Quality Control: Developing mechanisms for automated case extraction, validation, and refinement represents a significant challenge, particularly for domains lacking structured historical records.</p>
<p>Computational Resource Management: Balancing retrieval comprehensiveness against computational efficiency requires sophisticated indexing strategies and selective retrieval mechanisms.</p>
<p>Integration Architectures: Determining optimal points of integration between CBR components and the foundation LLM affects both performance characteristics and implementation complexity.</p>
<p>Goal Management in Dynamic Environments: Implementing effective goal prioritization and arbitration mechanisms is essential for agents operating in environments with multiple competing objectives.</p>
<p>Evaluation Methodologies: Developing comprehensive benchmarks that assess the distinctive capabilities of CBRaugmented agents remains an open challenge for the research community.</p>
<p>Future Research Directions</p>
<p>Our analysis suggests several promising directions for future research:</p>
<p>Sophisticated Case Representation: Developing more sophisticated methods for case representation that can effectively capture the complexities of real-world problems in formats suitable for LLM agents [Guo et al., 2024].This includes exploring representations for multi-modal data and investigating how LLMs themselves can create more informative and context-aware case representations.</p>
<p>Efficient Retrieval Mechanisms: Improving the efficiency and scalability of case retrieval mechanisms is essential for deploying CBR-enhanced LLM agents with large volumes of past experiences [Wiratunga et al., 2024].Future research should focus on advanced indexing techniques and optimal use of vector databases and approximate nearest neighbor search algorithms.</p>
<p>Advanced Case Adaptation: Case adaptation remains a complex challenge.Research should explore techniques beyond simple substitution that can handle more intricate transformations required in diverse scenarios [Sourati et al., 2023].Investigating LLMs in directly performing or guiding adaptation, potentially through sophisticated prompting strategies or learning adaptation rules from experience, is promising.</p>
<p>Cognitive CBR for Complex Reasoning: Further development of the cognitive dimensions of CBR-self-reflection, introspection, and curiosity-presents significant opportunities for enhancing reasoning capabilities.Integrating insights from cognitive science and psychology could lead to more robust and human-like reasoning processes [Craw and Aamodt, 2018].</p>
<p>Goal-Driven Autonomy with CBR: Expanding the integration of CBR with goal-driven autonomy frameworks offers promising avenues for developing more autonomous and adaptable agents.Future work should explore how case-based goal formulation and management can be enhanced through cognitive dimensions such as introspection and curiosity [Muñoz-Avila et al., 2010].</p>
<p>Dynamic Case Base Maintenance: Addressing challenges of case base maintenance is vital for ensuring long-term effectiveness of CBR-integrated LLM agents [Wilkerson, 2024].Research is needed on dynamic update strategies, methods for handling noisy or redundant cases, and techniques for maintaining both competence and efficiency as the case base evolves.</p>
<p>LLM-Enhanced CBR Processes: Further investigation into using LLMs for various stages of the CBR cycle presents significant opportunities, including more nuanced case indexing, sophisticated similarity assessment beyond embedding comparisons, and advanced adaptation techniques leveraging the generative capabilities of these models.</p>
<p>Multi-Agent CBR Architectures: Exploring distributed CBR approaches across multiple specialized LLM agents could enable more scalable and robust problem-solving.Research on communication protocols and knowledge sharing between case-based agents could lead to emergent problem-solving capabilities beyond those of individual agents [Wu et al.].</p>
<p>Robust Evaluation Frameworks: Developing evaluation frameworks and metrics specifically designed for LLM agents utilizing CBR is essential.These should consider reasoning depth, explanation quality and transparency, adaptation to novel situations, and goal reasoning capabilities.</p>
<p>Ethical Considerations: Exploring ethical implications of using CBR to enhance LLM agents is paramount, including considering potential biases in the case base, ensuring fairness in decisions, and maintaining transparency about how past experiences influence agent behavior.</p>
<p>Conclusion</p>
<p>This paper introduced a theoretical framework for integrating Case-Based Reasoning (CBR) into Large Language Model (LLM) agents, aiming to improve their reasoning abilities, adaptability, and transparency.By combining CBR with neural language models, we showed how these systems can benefit from both past experiences and learned language patterns.We explored how incorporating cognitive mechanisms like self-reflection, introspection, and curiosity, driven by goal-oriented autonomy, can further deepen an agent's reasoning and knowledge understanding.Our comparison with Chain-of-Thought reasoning and standard Retrieval-Augmented Generation showed that CBR-augmented agents offer clear advantages in reasoning transparency, domain adaptation, and solution quality, particularly in specialized domains requiring structured procedural knowledge.The explicit organization of past experiences in case libraries enables faster learning and provides precedent-based explanations, which are vital for building user trust and improving system interpretability.The theoretical formulations and proposed architectural frameworks presented in this work provide a clear foundation for the future development and implementation of CBR-augmented LLM agents across a wide range of applications.By effectively merging symbolic and neural AI paradigms, this research contributes to the ongoing evolution of hybrid AI architectures that leverage the unique strengths of different approaches.As language models continue to improve, combining them with structured reasoning methods like CBR offers a promising pathway towards more robust, transparent, and adaptive agent systems.Future research into areas like meta-case learning, applying knowledge across different fields, using diverse data types for cases, and improving goal reasoning will push these hybrid systems even further, advancing artificial intelligence and how humans and AI work together.</p>
<p>Algorithm 1 Case Representation and Indexing 1: Input: Raw case data D = {d 1 , d 2 , ..., d n } 2: Output: Indexed case library L 3: Initialize case library L ← ∅ 4: for each raw case d i ∈ D do
5:Extract problem features P i ← ExtractProblem(d i )6:Extract solution components S i ← ExtractSolution(d i )7:Extract outcome metrics O i ← ExtractOutcome(d i )
8:</p>
<p>1: Input: Environment E, Agent A, Initial goal g init , PCB, MCB, Similarity functions 2: Output: Agent actions and goal transitions 3: Execute (E, A, g init ) 4: while E is active do
5:s i ← CurrentState(E); g i ← CurrentGoal(A)6:while Agent is pursuing g i do7:Wait time t8:14:end if15:
e c ← Retrieve(P CB, s i , g i ) // Expected state 9: s E ← CurrentState(E) // Actual state 10: if e c ̸ = s E then 11: m ← Mismatch(e c , s E ) // Detected discrepancy 12: g c ← Retrieve(M CB, m) // New goal 13:Execute (E, A, g c )</p>
<p>Table 1 :
1
Theoretical Comparison of Reasoning Approaches
DimensionCBR-LLMCoTVanilla RAGKnowledge UtilizationExperientialParametricReference-basedReasoning Transparency Precedent-basedStep-basedSource-basedAdaptation CapacityHighLimitedModerateDomain SpecificityExplicitImplicitReference-dependentLearning MechanismCase acquisition Parameter updatesCorpus expansionCognitive CapabilitiesRichLimitedModerateGoal ReasoningDynamicStaticStatic</p>
<p>Towards reasoning in large language models: A survey. Jie Huang, Kevin Chen, -Chuan Chang, Findings of the Association for Computational Linguistics: ACL 2023. 2023</p>
<p>Case-based reasoning: Foundational issues, methodological variations, and system approaches. Agnar Aamodt, Enric Plaza, AI communications. 711994</p>
<p>Zhivar Sourati, Filip Ilievski, Hông-Ân Sandlin, and Alain Mermoud. Case-based reasoning with language models for classification of logical fallacies. Janet L Kolodner, Proceedings of the Thirty-Second International Joint Conference on Artificial Intelligence. the Thirty-Second International Joint Conference on Artificial Intelligence1992. 20236An introduction to case-based reasoning</p>
<p>Toward automated knowledge discovery in case-based reasoning. Sherri Weitl-Harms, John Hastings, Jay Powell, The International FLAIRS Conference Proceedings. 202437</p>
<p>Cbr-rag: case-based reasoning for retrieval augmented generation in llms for legal question answering. Nirmalie Wiratunga, Ramitha Abeyratne, Lasal Jayawardena, Kyle Martin, Stewart Massie, Ikechukwu Nkisi-Orji, Ruvan Weerasinghe, Anne Liret, Bruno Fleisch, International Conference on Case-Based Reasoning. Despina Christou, Kostas Hatalis, Mark G Staton, Michael Frechette, Springer2024. 202411Chatgpt for marketers: Limitations and mitigations</p>
<p>Case based reasoning as a model for cognitive artificial intelligence. Susan Craw, Agnar Aamodt, Case-Based Reasoning Research and Development: 26th International Conference, ICCBR 2018. Stockholm, SwedenSpringerJuly 9-12. 2018. 201826</p>
<p>Goal-driven autonomy with case-based reasoning. Héctor Muñoz-Avila, Ulit Jaidee, David W Aha, Elizabeth Carter, International Conference on Case-Based Reasoning. Springer2010</p>
<p>Dynamic memory: A theory of reminding and learning in computers and people. C Roger, Schank, 1983cambridge university press</p>
<p>Analogical reasoning and conceptual change: A case study of johannes kepler. Dedre Gentner, Sarah Brem, Ronald W Ferguson, Arthur B Markman, Bjorn B Levidow, Phillip Wolff, Kenneth D Forbus, The journal of the learning sciences. 611997</p>
<p>The abuse of casuistry: A history of moral reasoning. Stephen Albert R Jonsen, Stephen Toulmin, Edelston Toulmin, 1988Univ of California Press</p>
<p>Isabelle Bichindaritz and Cindy Marling. Case-based reasoning in the health sciences: What's next?. Kevin Ashley, Artificial intelligence in medicine. 3621988. 2006University of MassachusettsModeling Legal Argument Reasoning With Cases and Hypotheticals</p>
<p>Issues and applications of case-based reasoning to design. Mary , Lou Maher, Pearl Pu, The Knowledge Engineering Review. Derek Bridge, Mehmet H Göker, Lorraine McGinty, and Barry Smyth2032014. 2005Psychology PressCase-based recommender systems</p>
<p>Case-based reasoning-inspired approaches to education. Janet L Kolodner, Michael T Cox, Pedro A González-Calero, The Knowledge Engineering Review. 2032005</p>
<p>The rise and potential of large language model based agents: A survey. Zhiheng Xi, Wenxiang Chen, Xin Guo, Wei He, Yiwen Ding, Boyang Hong, Ming Zhang, Junzhe Wang, Senjie Jin, Enyu Zhou, Science China Information Sciences. 6821211012025</p>
<p>A survey on large language model based autonomous agents. Lei Wang, Chen Ma, Xueyang Feng, Zeyu Zhang, Hao Yang, Jingsen Zhang, Zhiyuan Chen, Jiakai Tang, Xu Chen, Yankai Lin, Frontiers of Computer Science. 1861863452024</p>
<p>Tree of thoughts: Deliberate problem solving with large language models. Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Tom Griffiths, Yuan Cao, Karthik Narasimhan, Advances in neural information processing systems. 202336</p>
<p>Chainof-thought prompting elicits reasoning in large language models. Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Denny Quoc V Le, Zhou, Advances in neural information processing systems. 202235</p>
<p>Jing Guo, Nan Li, Jianchuan Qi, Hang Yang, Ruiqiao Li, Yuzhen Feng, Si Zhang, Ming Xu, arXiv:2312.17259Empowering working memory for large language model agents. 2023arXiv preprint</p>
<p>Position: Episodic memory is the missing piece for long-term llm agents. Mathis Pink, Qinyuan Wu, Ai Vy, Javier Vo, Jianing Turek, Alexander Mu, Mariya Huth, Toneva, arXiv:2502.069752025arXiv preprint</p>
<p>Retrieval-augmented generation for knowledge-intensive nlp tasks. Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich Küttler, Mike Lewis, Wen-Tau Yih, Tim Rocktäschel, Advances in neural information processing systems. 202033</p>
<p>Retrieval-augmented generation for large language models: A survey. Yunfan Gao, Yun Xiong, Xinyu Gao, Kangxiang Jia, Jinliu Pan, Yuxi Bi, Yi Dai, Jiawei Sun, Qianyu Guo, Meng Wang, 2023CoRR</p>
<p>Toolformer: Language models can teach themselves to use tools. Timo Schick, Jane Dwivedi-Yu, Roberto Dessì, Roberta Raileanu, Maria Lomeli, Eric Hambro, Luke Zettlemoyer, Nicola Cancedda, Thomas Scialom, Advances in Neural Information Processing Systems. 202336</p>
<p>Tool learning with foundation models. Yujia Qin, Shengding Hu, Yankai Lin, Weize Chen, Ning Ding, Ganqu Cui, Zheni Zeng, Xuanhe Zhou, Yufei Huang, Chaojun Xiao, ACM Computing Surveys. 5742024</p>
<p>Autogen: Enabling next-gen llm applications via multi-agent conversation. Qingyun Wu, Gagan Bansal, Jieyu Zhang, Yiran Wu, Beibin Li, Erkang Zhu, Li Jiang, Xiaoyun Zhang, Shaokun Zhang, Jiale Liu, ICLR 2024 Workshop on Large Language Model (LLM) Agents. </p>
<p>Generative agents: Interactive simulacra of human behavior. Sung Joon, Park, O' Joseph, Carrie Jun Brien, Meredith Ringel Cai, Percy Morris, Michael S Liang, Bernstein, Proceedings of the 36th annual acm symposium on user interface software and technology. the 36th annual acm symposium on user interface software and technology2023</p>
<p>Memory matters: The need to improve long-term memory in llm-agents. Kostas Hatalis, Despina Christou, Joshua Myers, Steven Jones, Keith Lambert, Adam Amos-Binks, Zohreh Dannenhauer, Dustin Dannenhauer, Proceedings of the AAAI Symposium Series. the AAAI Symposium Series20232</p>
<p>Ds-agent: automated data science by empowering large language models with case-based reasoning. Siyuan Guo, Cheng Deng, Ying Wen, Hechang Chen, Yi Chang, Jun Wang, Proceedings of the 41st International Conference on Machine Learning. the 41st International Conference on Machine Learning2024</p>
<p>Check your facts and try again: Improving large language models with external knowledge and automated feedback. Baolin Peng, Michel Galley, Pengcheng He, Hao Cheng, Yujia Xie, Yu Hu, Qiuyuan Huang, Lars Liden, Zhou Yu, Weizhu Chen, arXiv:2302.128132023arXiv preprint</p>
<p>Cognitive architectures for language agents. Theodore Sumers, Shunyu Yao, Karthik Narasimhan, Thomas Griffiths, Transactions on Machine Learning Research. 2023</p>
<p>Intelligent lessons learned systems. Weber, I Aha, Becerra-Fernandez, Expert Systems with Applications. 2012001</p>
<p>The role of information extraction for textual cbr. Stefanie Brüninghaus, Kevin D Ashley, International Conference on Case-Based Reasoning. Springer2001</p>
<p>A case-based reasoning approach to dynamic few-shot prompting for code generation. Dustin Dannenhauer, Zohreh Dannenhauer, Despina Christou, Kostas Hatalis, Proceedings of the 41st International Conference on Machine Learning. the 41st International Conference on Machine LearningPMLR2024235</p>
<p>Barry Smyth and Elizabeth McKenna. Competence models and the maintenance problem. Pat Langley, Advances in Cognitive Systems. 2012. 20011The cognitive systems paradigm</p>
<p>Thinking, fast and slow. Daniel Kahneman, 2011macmillan</p>
<p>Analogy and relational representations in the companion cognitive architecture. D Kenneth, Thomas Forbus, Hinrich, AI Magazine. 3842017</p>
<p>Metacognition in computation: A selected research history and summary. T Michael, ; Cox, M Michael, Rosina O Richter, Weber, Artificial Intelligence. 2005. 2016SpringerCase-based reasoning</p>
<p>Information-seeking, curiosity, and attention: computational and neural mechanisms. Jacqueline Gottlieb, Pierre-Yves Oudeyer, Manuel Lopes, Adrien Baranes, Trends in cognitive sciences. 17112013</p>
<p>Llm reliability and cbr: How case based reasoning can improve the performance of large language models. Kaitlynne Wilkerson, 2024</p>            </div>
        </div>

    </div>
</body>
</html>