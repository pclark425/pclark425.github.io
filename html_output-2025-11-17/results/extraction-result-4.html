<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-4 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-4</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-4</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-1.html">extraction-schema-1</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLM-based agents playing text games or interactive fiction, focusing on how they use memory to improve task performance, including types of memory used, memory representations, and performance comparisons with and without memory.</div>
                <p><strong>Paper ID:</strong> paper-966423188dcdb22dcb29bfc08890f32b7791e83a</p>
                <p><strong>Cost:</strong> 0.002</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e4.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e4.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of LLM-based agents playing text games or interactive fiction, focusing on how they use memory to improve task performance, including types of memory used, memory representations, and performance comparisons with and without memory.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>AEC</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Agentic Episodic Control</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>AEC is a novel architecture that integrates reinforcement learning with large language models (LLMs) to enhance decision-making through episodic memory and structured working memory.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>agent_name</strong></td>
                            <td>AEC</td>
                        </tr>
                        <tr>
                            <td><strong>agent_description</strong></td>
                            <td>The AEC agent utilizes a large language model for semantic state encoding and combines it with dual-memory systems, including episodic memory and a World-Graph working memory, to improve task performance in text-based environments.</td>
                        </tr>
                        <tr>
                            <td><strong>text_game_name</strong></td>
                            <td>BabyAI-Text</td>
                        </tr>
                        <tr>
                            <td><strong>memory_used</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_type</strong></td>
                            <td>Episodic memory and World-Graph working memory</td>
                        </tr>
                        <tr>
                            <td><strong>memory_mechanism_description</strong></td>
                            <td>The episodic memory stores state-action pairs with their maximum observed returns, while the World-Graph working memory captures structured environmental dynamics. The agent dynamically switches between exploration and memory recall based on critical state recognition.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_memory</strong></td>
                            <td>Success rates of 0.84 in GoToLocal and 0.95 in UnlockLocal tasks, with significant improvements in sample efficiency.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_memory</strong></td>
                            <td>Success rates of 0.13 in GoToLocal and below 0.15 in UnlockLocal tasks for baseline agents.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_comparison_reported</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>memory_benefits_summary</strong></td>
                            <td>The use of memory allows for better long-term planning, improved state tracking, and enhanced exploration, leading to substantial performance gains in complex tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_limitations_or_challenges</strong></td>
                            <td>Increased computational overhead compared to traditional RL methods, which may affect time efficiency.</td>
                        </tr>
                        <tr>
                            <td><strong>agent_training_method</strong></td>
                            <td>Reinforcement learning with episodic memory integration.</td>
                        </tr>
                        <tr>
                            <td><strong>memory_training_method</strong></td>
                            <td>Episodic memory is updated based on experiences collected during interactions, with state embeddings generated by the LLM.</td>
                        </tr>
                        <tr>
                            <td><strong>task_complexity_description</strong></td>
                            <td>The BabyAI-Text tasks involve navigating and interacting with objects in a text-based environment, requiring long-term dependencies and reasoning over limited sensory input.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Agentic Episodic Control', 'publication_date_yy_mm': '2025-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Neural Episodic Control <em>(Rating: 2)</em></li>
                <li>Episodic Reinforcement Learning with Associative Memory <em>(Rating: 1)</em></li>
                <li>Grounding Large Language Models in Interactive Environments with Online Reinforcement Learning <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-4",
    "paper_id": "paper-966423188dcdb22dcb29bfc08890f32b7791e83a",
    "extraction_schema_id": "extraction-schema-1",
    "extracted_data": [
        {
            "name_short": "AEC",
            "name_full": "Agentic Episodic Control",
            "brief_description": "AEC is a novel architecture that integrates reinforcement learning with large language models (LLMs) to enhance decision-making through episodic memory and structured working memory.",
            "citation_title": "here",
            "mention_or_use": "use",
            "agent_name": "AEC",
            "agent_description": "The AEC agent utilizes a large language model for semantic state encoding and combines it with dual-memory systems, including episodic memory and a World-Graph working memory, to improve task performance in text-based environments.",
            "text_game_name": "BabyAI-Text",
            "memory_used": true,
            "memory_type": "Episodic memory and World-Graph working memory",
            "memory_mechanism_description": "The episodic memory stores state-action pairs with their maximum observed returns, while the World-Graph working memory captures structured environmental dynamics. The agent dynamically switches between exploration and memory recall based on critical state recognition.",
            "performance_with_memory": "Success rates of 0.84 in GoToLocal and 0.95 in UnlockLocal tasks, with significant improvements in sample efficiency.",
            "performance_without_memory": "Success rates of 0.13 in GoToLocal and below 0.15 in UnlockLocal tasks for baseline agents.",
            "performance_comparison_reported": true,
            "memory_benefits_summary": "The use of memory allows for better long-term planning, improved state tracking, and enhanced exploration, leading to substantial performance gains in complex tasks.",
            "memory_limitations_or_challenges": "Increased computational overhead compared to traditional RL methods, which may affect time efficiency.",
            "agent_training_method": "Reinforcement learning with episodic memory integration.",
            "memory_training_method": "Episodic memory is updated based on experiences collected during interactions, with state embeddings generated by the LLM.",
            "task_complexity_description": "The BabyAI-Text tasks involve navigating and interacting with objects in a text-based environment, requiring long-term dependencies and reasoning over limited sensory input.",
            "uuid": "e4.0",
            "source_info": {
                "paper_title": "Agentic Episodic Control",
                "publication_date_yy_mm": "2025-06"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Neural Episodic Control",
            "rating": 2
        },
        {
            "paper_title": "Episodic Reinforcement Learning with Associative Memory",
            "rating": 1
        },
        {
            "paper_title": "Grounding Large Language Models in Interactive Environments with Online Reinforcement Learning",
            "rating": 1
        }
    ],
    "cost": 0.0024837,
    "model_str": null
}</code></pre>
        </div>

    </div>
</body>
</html>