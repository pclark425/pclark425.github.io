<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-397 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-397</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-397</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-16.html">extraction-schema-16</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of experimental methods, techniques, or procedures being transferred, adapted, or applied from one scientific domain or context to another scientific domain or context, including details about the transfer process and outcomes.</div>
                <p><strong>Paper ID:</strong> paper-267109688</p>
                <p><strong>Paper Title:</strong> Agriculture Named Entity Recognition—Towards FAIR, Reusable Scholarly Contributions in Agriculture</p>
                <p><strong>Paper Abstract:</strong> : We introduce the Open Research Knowledge Graph Agriculture Named Entity Recognition (the ORKG Agri-NER) corpus and service for contribution-centric scientific entity extraction and classification. The ORKG Agri-NER corpus is a seminal benchmark for the evaluation of contribution-centric scientific entity extraction and classification in the agricultural domain. It comprises titles of scholarly papers that are available as Open Access articles on a major publishing platform. We describe the creation of this corpus and highlight the obtained findings in terms of the following features: (1) a generic conceptual formalism focused on capturing scientific entities in agriculture that reflect the direct contribution of a work; (2) a performance benchmark for named entity recognition of scientific entities in the agricultural domain by empirically evaluating various state-of-the-art sequence labeling neural architectures and transformer models; and (3) a delineated 3-step automatic entity resolution procedure for the resolution of the scientific entities to an authoritative ontology, specifically AGROVOC that is released in the Linked Open Vocabularies cloud. With this work we aim to provide a strong foundation for future work on the automatic discovery of scientific entities in the scholarly literature of the agricultural domain.</p>
                <p><strong>Cost:</strong> 0.018</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e397.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e397.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of experimental methods, techniques, or procedures being transferred, adapted, or applied from one scientific domain or context to another scientific domain or context, including details about the transfer process and outcomes.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>CS→Agri entity-type transfer</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Transfer and adaptation of contribution-centric named-entity type framework from Computer Science to Agriculture</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>The paper adapts a contribution-centric NER conceptual formalism (originally used in Computer Science) to the agricultural domain by selecting, pruning, and reconciling CS entity types with AGROVOC top-level concepts to produce a 7-type Agri-NER schema used for annotation and model training.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_name</strong></td>
                            <td>Contribution-centric named-entity type framework adaptation</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_description</strong></td>
                            <td>A 3-step methodological transfer: (1) take an existing list of contribution-centric entity types used in Computer Science (SOLUTION, RESEARCH PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET) as a reference; (2) consult AGROVOC top-level concepts (24 categories) to identify agriculture-relevant conceptual types; (3) run a pilot annotation on 50 paper titles to prune, subsume, and reconcile both lists into a final set of seven entity types (RESEARCH PROBLEM, RESOURCE, PROCESS, LOCATION, METHOD, SOLUTION, TECHNOLOGY). The process included lemmatization, subsumption of several AGROVOC concepts into RESOURCE or METHOD, removal of CS types not applicable (TOOL, LANGUAGE, DATASET), and iterative human judgment to determine functional role.</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_type</strong></td>
                            <td>conceptual formalism adaptation / annotation schema transfer</td>
                        </tr>
                        <tr>
                            <td><strong>source_domain</strong></td>
                            <td>Computer Science (scientific NER / scholarly contribution modeling)</td>
                        </tr>
                        <tr>
                            <td><strong>target_domain</strong></td>
                            <td>Agricultural scholarly publications / agricultural NER</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_type</strong></td>
                            <td>adapted/modified for new context</td>
                        </tr>
                        <tr>
                            <td><strong>modifications_made</strong></td>
                            <td>Removed CS-specific types (TOOL, LANGUAGE, DATASET) that did not map well to titles in agriculture; subsumed multiple AGROVOC top-level categories into broader contribution-centric categories (e.g., objects/organisms/subjects/substances → RESOURCE; strategies → METHOD); lemmatized phrases (e.g., 'processes' → PROCESS); validated via a 50-title pilot annotation to guide pruning and produced the final seven-type set.</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_success</strong></td>
                            <td>successful - produced a working 7-type Agri-NER schema and a human-annotated gold-standard corpus of 5,500 paper titles (15,261 entity annotations) which supported downstream model training and deployment as the ORKG Agri-NER service.</td>
                        </tr>
                        <tr>
                            <td><strong>barriers_encountered</strong></td>
                            <td>Domain differences in what constitutes a 'contribution' (CS vs. agriculture); many AGROVOC concepts are terminological/specific rather than functional, requiring subsumption or rejection; subjective phrase boundary determination for contribution-centric roles in titles.</td>
                        </tr>
                        <tr>
                            <td><strong>facilitating_factors</strong></td>
                            <td>Existence of prior CS contribution-centric schema and prior annotated datasets; availability of AGROVOC top-level concepts to provide domain grounding; pilot annotation by domain-expert annotator to guide decisions; iterative human-in-the-loop curation.</td>
                        </tr>
                        <tr>
                            <td><strong>contextual_requirements</strong></td>
                            <td>Human domain expertise for annotation; a pilot annotation phase; access to AGROVOC for mapping decisions; a corpus of domain paper titles (copyright-permitting CC-BY titles); clear annotation guidelines for functional roles.</td>
                        </tr>
                        <tr>
                            <td><strong>generalizability</strong></td>
                            <td>Likely generalizable: the methodological pattern (use prior domain schema + domain ontology + pilot annotation to adapt entity types) is applicable to other scientific domains, but specifics (which types to retain/subsume) must be re-evaluated per target domain.</td>
                        </tr>
                        <tr>
                            <td><strong>knowledge_type</strong></td>
                            <td>explicit procedural steps and interpretive/ontological framing (conceptual knowledge plus annotation know-how)</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Agriculture Named Entity Recognition—Towards FAIR, Reusable Scholarly Contributions in Agriculture', 'publication_date_yy_mm': '2024-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e397.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e397.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of experimental methods, techniques, or procedures being transferred, adapted, or applied from one scientific domain or context to another scientific domain or context, including details about the transfer process and outcomes.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>CharCNN+BiLSTM+CRF→Agri</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Application of the Char-CNN + Word BiLSTM + CRF neural sequence-labeling architecture to agricultural NER</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>The paper implements the established character-convolution + word-level BiLSTM + CRF neural sequence-labeler, adapts feature inputs (POS, generic NER tags), and evaluates GloVe initialization and tag encoding formats on the Agri-NER corpus.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_name</strong></td>
                            <td>Char CNN + Word BiLSTM + CRF sequence labeling</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_description</strong></td>
                            <td>A three-layer neural sequence-labeler: (1) Character-level encoder using CNNs over characters with max-pooling to capture morphological features; (2) Word-level encoder using bidirectional LSTMs to capture left and right context for each token; (3) Conditional Random Field inference layer to model output label dependencies. In this work the architecture was run with/without pretrained GloVe word embeddings and with additional token features (POS tags and generic domain NER tags from Stanford Stanza). Experiments used CONLL-style tokenized input (titles tokenized by spaces) and both IOB and IOBES tagging schemes, implemented using the NCRF++ toolkit.</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_type</strong></td>
                            <td>computational method / sequence-labeling model (machine learning)</td>
                        </tr>
                        <tr>
                            <td><strong>source_domain</strong></td>
                            <td>Natural Language Processing / Computer Science (sequence labeling / NER research)</td>
                        </tr>
                        <tr>
                            <td><strong>target_domain</strong></td>
                            <td>Agricultural scholarly NER (title-level contribution extraction)</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_type</strong></td>
                            <td>adapted/modified for new context</td>
                        </tr>
                        <tr>
                            <td><strong>modifications_made</strong></td>
                            <td>Applied model to short scholarly title sequences (tokenization by spaces); incorporated additional token-level features (POS and generic NER tags from Stanford Stanza); experimented with initializing word embeddings from GloVe vs. training from scratch; evaluated both IOB and IOBES tag encodings; tuned hyperparameters for short-title data.</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_success</strong></td>
                            <td>partially successful - yielded reasonable baseline performance (best 'Char CNN + BiLSTM + CRF' exact-match F1 ≈ 60.85% and inexact-match F1 ≈ 64.72% under best-config), but was outperformed by the finetuned BERT-based models on the Agri-NER task.</td>
                        </tr>
                        <tr>
                            <td><strong>barriers_encountered</strong></td>
                            <td>Short, title-only inputs reduce context compared with full-text/abstracts; domain-specific vocabulary and long-tail solution mentions increase difficulty; choice of tag encoding and feature set influenced performance nontrivially; limited training data size relative to deep models.</td>
                        </tr>
                        <tr>
                            <td><strong>facilitating_factors</strong></td>
                            <td>Well-established architecture and available NCRF++ implementation; benefit from pretrained GloVe embeddings which improved results; ability to add POS/NER auxiliary features from existing NLP toolkits.</td>
                        </tr>
                        <tr>
                            <td><strong>contextual_requirements</strong></td>
                            <td>Gold-standard annotated corpus (5,500 titles), token-level features (POS, NER) extracted via Stanza, appropriate hyperparameter tuning and compute resources for neural training.</td>
                        </tr>
                        <tr>
                            <td><strong>generalizability</strong></td>
                            <td>Technique is general-purpose for sequence-labeling tasks; applicable to other scholarly-domain NER problems, but absolute performance depends on available annotated data and domain vocabulary.</td>
                        </tr>
                        <tr>
                            <td><strong>knowledge_type</strong></td>
                            <td>instrumental/technical procedural know-how (computational method and model-configuration practices)</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Agriculture Named Entity Recognition—Towards FAIR, Reusable Scholarly Contributions in Agriculture', 'publication_date_yy_mm': '2024-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e397.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e397.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of experimental methods, techniques, or procedures being transferred, adapted, or applied from one scientific domain or context to another scientific domain or context, including details about the transfer process and outcomes.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>BERT finetune→Agri</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Finetuning pretrained transformer language models (BERT / SciBERT) for agricultural NER</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>The paper finetunes pretrained transformer models (BERT-base-cased and SciBERT) for the Agri-NER sequence-labeling task, augmenting token embeddings with CNN-based character embeddings and decoding with BiLSTM+CRF for label prediction.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_name</strong></td>
                            <td>Finetuning pretrained transformer encoders for NER (BERT, SciBERT)</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_description</strong></td>
                            <td>Pretrained transformer language models provide contextual token embeddings; the finetuning architecture used concatenated per-token BERT embeddings with CNN-based character embeddings, passed through two stacked bidirectional LSTMs, and decoded with a CRF layer to produce sequence labels. Models were finetuned on the Agri-NER annotated title corpus via a scikit-learn wrapper for BERT, experimenting with IOB and IOBES encoding. Two pretrained variants were compared: generic BERT (BookCorpus + Wikipedia) and SciBERT (pretrained on scientific articles dominated by biomedical/CS).</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_type</strong></td>
                            <td>computational method / transfer learning (language model finetuning)</td>
                        </tr>
                        <tr>
                            <td><strong>source_domain</strong></td>
                            <td>Large-scale language model pretraining (general NLP / scientific-text NLP)</td>
                        </tr>
                        <tr>
                            <td><strong>target_domain</strong></td>
                            <td>Agricultural NER (scholarly title entity extraction)</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_type</strong></td>
                            <td>adapted/modified via finetuning</td>
                        </tr>
                        <tr>
                            <td><strong>modifications_made</strong></td>
                            <td>Augmented transformer token embeddings with character-CNN embeddings; inserted BiLSTM encoder and CRF decoder on top of transformer outputs; formatted title data for token-level NER finetuning; compared pretrained variants (general BERT vs SciBERT) to assess domain-pretraining effects.</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_success</strong></td>
                            <td>successful and superior - the finetuned generic BERT-base-cased achieved the best reported performance on Agri-NER (exact-match F1 = 64.19%, inexact-match F1 = 67.91%), outperforming the CharCNN+BiLSTM+CRF baseline; SciBERT performed slightly worse than generic BERT on this agricultural title corpus.</td>
                        </tr>
                        <tr>
                            <td><strong>barriers_encountered</strong></td>
                            <td>Domain mismatch for SciBERT (pretraining dominated by biomedical texts) reduced its effectiveness; short-title inputs provide limited context for deep models; computational cost of finetuning.</td>
                        </tr>
                        <tr>
                            <td><strong>facilitating_factors</strong></td>
                            <td>Power of large-scale pretraining delivering contextualized embeddings; finetuning paradigm allows rapid adaptation to a small annotated corpus; concatenation of character-level embeddings improved token representation for noisy/rare terms.</td>
                        </tr>
                        <tr>
                            <td><strong>contextual_requirements</strong></td>
                            <td>Annotated Agri-NER corpus, appropriate tokenization compatible with BERT vocabulary, compute resources for finetuning, hyperparameter tuning, and an inference wrapper (bert-sklearn) for deployment.</td>
                        </tr>
                        <tr>
                            <td><strong>generalizability</strong></td>
                            <td>High generalizability: finetuning pretrained transformers is applicable across domains, but optimal pretrained base depends on similarity between pretraining corpus and target domain; domain-specific pretraining covering agriculture may further improve results.</td>
                        </tr>
                        <tr>
                            <td><strong>knowledge_type</strong></td>
                            <td>theoretical principles (transfer learning) and explicit procedural steps (finetuning configuration and model stacking)</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Agriculture Named Entity Recognition—Towards FAIR, Reusable Scholarly Contributions in Agriculture', 'publication_date_yy_mm': '2024-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e397.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e397.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of experimental methods, techniques, or procedures being transferred, adapted, or applied from one scientific domain or context to another scientific domain or context, including details about the transfer process and outcomes.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>AGROVOC linking</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Three-step automatic entity resolution procedure to link Agri-NER entities to AGROVOC ontology</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>The paper implements an iterative programmatic linking process that queries AGROVOC for exact phrase matches and, failing that, progressively matches longest subphrases to obtain ontology concept URIs for Agri-NER annotated phrases.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_name</strong></td>
                            <td>3-step automatic entity resolution to AGROVOC</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_description</strong></td>
                            <td>Given an annotated Agri-NER phrase, the procedure queries AGROVOC concept nodes for exact matches; if no match is found, the phrase is split into longest spanning subphrases (iteratively decreasing subphrase length from phrase_length-1 down to 1) and each subphrase is queried until one or more AGROVOC concept URIs resolve. Matching stops when at least one subphrase resolves. This mapping produces linked-data URIs that enrich the Agri-NER entities with AGROVOC definitions and cross-links (e.g., to DBpedia).</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_type</strong></td>
                            <td>data-integration / ontology linking / linked-data resolution</td>
                        </tr>
                        <tr>
                            <td><strong>source_domain</strong></td>
                            <td>Semantic Web / ontology linking (AGROVOC linked data infrastructure)</td>
                        </tr>
                        <tr>
                            <td><strong>target_domain</strong></td>
                            <td>Agri-NER annotated contributions (entity enrichment via ontology URIs)</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_type</strong></td>
                            <td>adapted/modified for new context</td>
                        </tr>
                        <tr>
                            <td><strong>modifications_made</strong></td>
                            <td>Implemented iterative longest-subphrase matching (splitting phrases) to cope with contribution-centric, variable-length title phrases that often do not directly match terminological AGROVOC entries; used programmatic queries against AGROVOC concept nodes and stopped upon first successful resolution.</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_success</strong></td>
                            <td>partially successful - 16% of annotated Agri-NER entities matched AGROVOC concepts as whole phrases; an additional 53.75% could be resolved by matching longest-spanning subphrases, demonstrating substantial but incomplete coverage and revealing how contribution-centric phrases often require subphrase linking.</td>
                        </tr>
                        <tr>
                            <td><strong>barriers_encountered</strong></td>
                            <td>AGROVOC is terminologically focused whereas Agri-NER entities are functional/contribution-centric, causing mismatch; many long-tail or novel solution phrases do not exist in AGROVOC; subjective boundaries in phrasal annotation make exact matches less frequent.</td>
                        </tr>
                        <tr>
                            <td><strong>facilitating_factors</strong></td>
                            <td>Availability of AGROVOC as an authoritative linked-data concept hub; programmatic access to AGROVOC concept nodes; simple iterative subphrase heuristic to recover partial matches.</td>
                        </tr>
                        <tr>
                            <td><strong>contextual_requirements</strong></td>
                            <td>Access to AGROVOC linked-data endpoints or dump; ability to programmatically tokenize and generate subphrases; normalization/lemmatization pipelines to enhance matching.</td>
                        </tr>
                        <tr>
                            <td><strong>generalizability</strong></td>
                            <td>Method is generalizable to linking contribution-centric entities to other terminological ontologies, but success depends strongly on target ontology coverage and whether the ontology prioritizes terminological vs. functional conceptualizations.</td>
                        </tr>
                        <tr>
                            <td><strong>knowledge_type</strong></td>
                            <td>explicit procedural steps (algorithmic heuristic) and instrumental/technical knowledge (ontology querying and linking)</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Agriculture Named Entity Recognition—Towards FAIR, Reusable Scholarly Contributions in Agriculture', 'publication_date_yy_mm': '2024-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e397.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e397.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of experimental methods, techniques, or procedures being transferred, adapted, or applied from one scientific domain or context to another scientific domain or context, including details about the transfer process and outcomes.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Stanza POS/NER feature transfer</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Use of Stanford Stanza POS and NER tagger outputs as auxiliary features for Agri-NER models</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>The authors incorporated off-the-shelf POS and generic-domain NER tags produced by the Stanford Stanza toolkit as additional token-level features in the neural sequence-labeler experiments, evaluating their contribution to performance.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_name</strong></td>
                            <td>POS and generic NER feature extraction using Stanford Stanza</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_description</strong></td>
                            <td>Titles were tokenized (space-split), then Stanford Stanza was used to annotate tokens with POS tags and a generic-domain NER label; these annotations were placed as additional feature columns in the CONLL input and fed to the CharCNN+BiLSTM+CRF models (and tested in combinations) to assess impact on sequence-labeling performance.</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_type</strong></td>
                            <td>preprocessing / feature-engineering using off-the-shelf NLP tools</td>
                        </tr>
                        <tr>
                            <td><strong>source_domain</strong></td>
                            <td>Natural Language Processing toolkit (Stanza POS/NER)</td>
                        </tr>
                        <tr>
                            <td><strong>target_domain</strong></td>
                            <td>Agricultural title-level NER model features</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_type</strong></td>
                            <td>direct application without modification</td>
                        </tr>
                        <tr>
                            <td><strong>modifications_made</strong></td>
                            <td>No internal modification to Stanza; outputs were added as extra columns (POS, generic NER) in the CONLL-format training data and experiments tested combinations of these features with/without pretrained embeddings and with different tagging schemes.</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_success</strong></td>
                            <td>successful as a facilitating feature - additional POS and generic NER features improved performance in many of the CharCNN+BiLSTM+CRF experiments (the paper reports that both IOB and IOBES settings benefited from enriched feature representations), though BERT-based finetuning still outperformed feature-augmented classical neural architectures.</td>
                        </tr>
                        <tr>
                            <td><strong>barriers_encountered</strong></td>
                            <td>Generic-domain NER labels may not align perfectly with contribution-centric types; possible noise from Stanza on short, domain-specific title tokens.</td>
                        </tr>
                        <tr>
                            <td><strong>facilitating_factors</strong></td>
                            <td>Robustness and availability of Stanza; low integration overhead (simple additional columns in CONLL format); complementary syntactic and coarse entity cues provided by POS/NER outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>contextual_requirements</strong></td>
                            <td>Preprocessing pipeline that runs Stanza on titles, mapping its tokenization to the model tokenization; handling mismatches between Stanza tokenization and model input tokenization.</td>
                        </tr>
                        <tr>
                            <td><strong>generalizability</strong></td>
                            <td>Widely generalizable: using off-the-shelf POS/NER outputs as auxiliary features is common practice for many low-data sequence-labeling tasks, though the payoff varies by domain and downstream model class.</td>
                        </tr>
                        <tr>
                            <td><strong>knowledge_type</strong></td>
                            <td>instrumental/technical (tool use and feature-integration practice)</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Agriculture Named Entity Recognition—Towards FAIR, Reusable Scholarly Contributions in Agriculture', 'publication_date_yy_mm': '2024-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e397.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e397.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of experimental methods, techniques, or procedures being transferred, adapted, or applied from one scientific domain or context to another scientific domain or context, including details about the transfer process and outcomes.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GloVe init→Agri</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Initialization of neural-word-embedding space with pretrained GloVe vectors for Agri-NER</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>The authors initialized the word-embedding layer of the CharCNN+BiLSTM+CRF architecture with pretrained GloVe vectors rather than learning embeddings solely from the small Agri-NER corpus, which improved sequence-labeler performance.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_name</strong></td>
                            <td>Pretrained GloVe embedding initialization</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_description</strong></td>
                            <td>Instead of learning word vectors from the limited training corpus, the model's word-embedding matrix was initialized with fixed/pretrained GloVe vectors (global vectors learned from large external corpora), providing a richer external semantic space; experiments compared training with and without GloVe initialization.</td>
                        </tr>
                        <tr>
                            <td><strong>procedure_type</strong></td>
                            <td>computational method / transfer learning for embeddings</td>
                        </tr>
                        <tr>
                            <td><strong>source_domain</strong></td>
                            <td>General NLP pretrained embeddings (GloVe trained on large corpora)</td>
                        </tr>
                        <tr>
                            <td><strong>target_domain</strong></td>
                            <td>Agricultural NER model training</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_type</strong></td>
                            <td>direct application without modification</td>
                        </tr>
                        <tr>
                            <td><strong>modifications_made</strong></td>
                            <td>No modification to GloVe itself; model pipeline used pretrained vectors and optionally fine-tuned or froze them depending on configuration; evaluated impact across tag encodings and auxiliary features.</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_success</strong></td>
                            <td>successful - initializing with GloVe improved sequence-labeler performance across experimented feature settings compared to training embeddings from the Agri-NER corpus alone (paper reports consistent benefit in RQ2).</td>
                        </tr>
                        <tr>
                            <td><strong>barriers_encountered</strong></td>
                            <td>GloVe covers general vocabulary better than rare agricultural jargon or newly coined solution phrases; OOV tokens still exist for domain-specific terms.</td>
                        </tr>
                        <tr>
                            <td><strong>facilitating_factors</strong></td>
                            <td>Availability of high-quality pretrained embeddings capturing broad semantic relations; easy integration into standard neural architectures.</td>
                        </tr>
                        <tr>
                            <td><strong>contextual_requirements</strong></td>
                            <td>Vocabulary mapping from corpus tokens to GloVe indices, handling of out-of-vocabulary tokens, and possibly dimensionality matching between embedding layer and model architecture.</td>
                        </tr>
                        <tr>
                            <td><strong>generalizability</strong></td>
                            <td>Highly generalizable: pretrained embeddings commonly help low-data domain tasks, but domain-specific embeddings or continued pretraining on domain text can yield further improvements.</td>
                        </tr>
                        <tr>
                            <td><strong>knowledge_type</strong></td>
                            <td>instrumental/technical (practical method for initializing model parameters)</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Agriculture Named Entity Recognition—Towards FAIR, Reusable Scholarly Contributions in Agriculture', 'publication_date_yy_mm': '2024-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Computer science named entity recognition in the open research knowledge graph <em>(Rating: 2)</em></li>
                <li>A Large-Scale Knowledge Graph of Research Entities and Claims in Computer Science (CS-KG) <em>(Rating: 1)</em></li>
                <li>Pretrained Language Model for Scientific Text (SciBERT) <em>(Rating: 2)</em></li>
                <li>GloVe: Global Vectors for Word Representation <em>(Rating: 2)</em></li>
                <li>End-to-end Sequence Labeling via Bi-directional LSTM-CNNs-CRF <em>(Rating: 2)</em></li>
                <li>NCRF++: An Open-source Neural Sequence Labeling Toolkit <em>(Rating: 2)</em></li>
                <li>AGROVOC: The linked data concept hub for food and agriculture <em>(Rating: 2)</em></li>
                <li>Stanza: A Python Natural Language Processing Toolkit for Many Human Languages <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-397",
    "paper_id": "paper-267109688",
    "extraction_schema_id": "extraction-schema-16",
    "extracted_data": [
        {
            "name_short": "CS→Agri entity-type transfer",
            "name_full": "Transfer and adaptation of contribution-centric named-entity type framework from Computer Science to Agriculture",
            "brief_description": "The paper adapts a contribution-centric NER conceptual formalism (originally used in Computer Science) to the agricultural domain by selecting, pruning, and reconciling CS entity types with AGROVOC top-level concepts to produce a 7-type Agri-NER schema used for annotation and model training.",
            "citation_title": "here",
            "mention_or_use": "use",
            "procedure_name": "Contribution-centric named-entity type framework adaptation",
            "procedure_description": "A 3-step methodological transfer: (1) take an existing list of contribution-centric entity types used in Computer Science (SOLUTION, RESEARCH PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, DATASET) as a reference; (2) consult AGROVOC top-level concepts (24 categories) to identify agriculture-relevant conceptual types; (3) run a pilot annotation on 50 paper titles to prune, subsume, and reconcile both lists into a final set of seven entity types (RESEARCH PROBLEM, RESOURCE, PROCESS, LOCATION, METHOD, SOLUTION, TECHNOLOGY). The process included lemmatization, subsumption of several AGROVOC concepts into RESOURCE or METHOD, removal of CS types not applicable (TOOL, LANGUAGE, DATASET), and iterative human judgment to determine functional role.",
            "procedure_type": "conceptual formalism adaptation / annotation schema transfer",
            "source_domain": "Computer Science (scientific NER / scholarly contribution modeling)",
            "target_domain": "Agricultural scholarly publications / agricultural NER",
            "transfer_type": "adapted/modified for new context",
            "modifications_made": "Removed CS-specific types (TOOL, LANGUAGE, DATASET) that did not map well to titles in agriculture; subsumed multiple AGROVOC top-level categories into broader contribution-centric categories (e.g., objects/organisms/subjects/substances → RESOURCE; strategies → METHOD); lemmatized phrases (e.g., 'processes' → PROCESS); validated via a 50-title pilot annotation to guide pruning and produced the final seven-type set.",
            "transfer_success": "successful - produced a working 7-type Agri-NER schema and a human-annotated gold-standard corpus of 5,500 paper titles (15,261 entity annotations) which supported downstream model training and deployment as the ORKG Agri-NER service.",
            "barriers_encountered": "Domain differences in what constitutes a 'contribution' (CS vs. agriculture); many AGROVOC concepts are terminological/specific rather than functional, requiring subsumption or rejection; subjective phrase boundary determination for contribution-centric roles in titles.",
            "facilitating_factors": "Existence of prior CS contribution-centric schema and prior annotated datasets; availability of AGROVOC top-level concepts to provide domain grounding; pilot annotation by domain-expert annotator to guide decisions; iterative human-in-the-loop curation.",
            "contextual_requirements": "Human domain expertise for annotation; a pilot annotation phase; access to AGROVOC for mapping decisions; a corpus of domain paper titles (copyright-permitting CC-BY titles); clear annotation guidelines for functional roles.",
            "generalizability": "Likely generalizable: the methodological pattern (use prior domain schema + domain ontology + pilot annotation to adapt entity types) is applicable to other scientific domains, but specifics (which types to retain/subsume) must be re-evaluated per target domain.",
            "knowledge_type": "explicit procedural steps and interpretive/ontological framing (conceptual knowledge plus annotation know-how)",
            "uuid": "e397.0",
            "source_info": {
                "paper_title": "Agriculture Named Entity Recognition—Towards FAIR, Reusable Scholarly Contributions in Agriculture",
                "publication_date_yy_mm": "2024-01"
            }
        },
        {
            "name_short": "CharCNN+BiLSTM+CRF→Agri",
            "name_full": "Application of the Char-CNN + Word BiLSTM + CRF neural sequence-labeling architecture to agricultural NER",
            "brief_description": "The paper implements the established character-convolution + word-level BiLSTM + CRF neural sequence-labeler, adapts feature inputs (POS, generic NER tags), and evaluates GloVe initialization and tag encoding formats on the Agri-NER corpus.",
            "citation_title": "here",
            "mention_or_use": "use",
            "procedure_name": "Char CNN + Word BiLSTM + CRF sequence labeling",
            "procedure_description": "A three-layer neural sequence-labeler: (1) Character-level encoder using CNNs over characters with max-pooling to capture morphological features; (2) Word-level encoder using bidirectional LSTMs to capture left and right context for each token; (3) Conditional Random Field inference layer to model output label dependencies. In this work the architecture was run with/without pretrained GloVe word embeddings and with additional token features (POS tags and generic domain NER tags from Stanford Stanza). Experiments used CONLL-style tokenized input (titles tokenized by spaces) and both IOB and IOBES tagging schemes, implemented using the NCRF++ toolkit.",
            "procedure_type": "computational method / sequence-labeling model (machine learning)",
            "source_domain": "Natural Language Processing / Computer Science (sequence labeling / NER research)",
            "target_domain": "Agricultural scholarly NER (title-level contribution extraction)",
            "transfer_type": "adapted/modified for new context",
            "modifications_made": "Applied model to short scholarly title sequences (tokenization by spaces); incorporated additional token-level features (POS and generic NER tags from Stanford Stanza); experimented with initializing word embeddings from GloVe vs. training from scratch; evaluated both IOB and IOBES tag encodings; tuned hyperparameters for short-title data.",
            "transfer_success": "partially successful - yielded reasonable baseline performance (best 'Char CNN + BiLSTM + CRF' exact-match F1 ≈ 60.85% and inexact-match F1 ≈ 64.72% under best-config), but was outperformed by the finetuned BERT-based models on the Agri-NER task.",
            "barriers_encountered": "Short, title-only inputs reduce context compared with full-text/abstracts; domain-specific vocabulary and long-tail solution mentions increase difficulty; choice of tag encoding and feature set influenced performance nontrivially; limited training data size relative to deep models.",
            "facilitating_factors": "Well-established architecture and available NCRF++ implementation; benefit from pretrained GloVe embeddings which improved results; ability to add POS/NER auxiliary features from existing NLP toolkits.",
            "contextual_requirements": "Gold-standard annotated corpus (5,500 titles), token-level features (POS, NER) extracted via Stanza, appropriate hyperparameter tuning and compute resources for neural training.",
            "generalizability": "Technique is general-purpose for sequence-labeling tasks; applicable to other scholarly-domain NER problems, but absolute performance depends on available annotated data and domain vocabulary.",
            "knowledge_type": "instrumental/technical procedural know-how (computational method and model-configuration practices)",
            "uuid": "e397.1",
            "source_info": {
                "paper_title": "Agriculture Named Entity Recognition—Towards FAIR, Reusable Scholarly Contributions in Agriculture",
                "publication_date_yy_mm": "2024-01"
            }
        },
        {
            "name_short": "BERT finetune→Agri",
            "name_full": "Finetuning pretrained transformer language models (BERT / SciBERT) for agricultural NER",
            "brief_description": "The paper finetunes pretrained transformer models (BERT-base-cased and SciBERT) for the Agri-NER sequence-labeling task, augmenting token embeddings with CNN-based character embeddings and decoding with BiLSTM+CRF for label prediction.",
            "citation_title": "here",
            "mention_or_use": "use",
            "procedure_name": "Finetuning pretrained transformer encoders for NER (BERT, SciBERT)",
            "procedure_description": "Pretrained transformer language models provide contextual token embeddings; the finetuning architecture used concatenated per-token BERT embeddings with CNN-based character embeddings, passed through two stacked bidirectional LSTMs, and decoded with a CRF layer to produce sequence labels. Models were finetuned on the Agri-NER annotated title corpus via a scikit-learn wrapper for BERT, experimenting with IOB and IOBES encoding. Two pretrained variants were compared: generic BERT (BookCorpus + Wikipedia) and SciBERT (pretrained on scientific articles dominated by biomedical/CS).",
            "procedure_type": "computational method / transfer learning (language model finetuning)",
            "source_domain": "Large-scale language model pretraining (general NLP / scientific-text NLP)",
            "target_domain": "Agricultural NER (scholarly title entity extraction)",
            "transfer_type": "adapted/modified via finetuning",
            "modifications_made": "Augmented transformer token embeddings with character-CNN embeddings; inserted BiLSTM encoder and CRF decoder on top of transformer outputs; formatted title data for token-level NER finetuning; compared pretrained variants (general BERT vs SciBERT) to assess domain-pretraining effects.",
            "transfer_success": "successful and superior - the finetuned generic BERT-base-cased achieved the best reported performance on Agri-NER (exact-match F1 = 64.19%, inexact-match F1 = 67.91%), outperforming the CharCNN+BiLSTM+CRF baseline; SciBERT performed slightly worse than generic BERT on this agricultural title corpus.",
            "barriers_encountered": "Domain mismatch for SciBERT (pretraining dominated by biomedical texts) reduced its effectiveness; short-title inputs provide limited context for deep models; computational cost of finetuning.",
            "facilitating_factors": "Power of large-scale pretraining delivering contextualized embeddings; finetuning paradigm allows rapid adaptation to a small annotated corpus; concatenation of character-level embeddings improved token representation for noisy/rare terms.",
            "contextual_requirements": "Annotated Agri-NER corpus, appropriate tokenization compatible with BERT vocabulary, compute resources for finetuning, hyperparameter tuning, and an inference wrapper (bert-sklearn) for deployment.",
            "generalizability": "High generalizability: finetuning pretrained transformers is applicable across domains, but optimal pretrained base depends on similarity between pretraining corpus and target domain; domain-specific pretraining covering agriculture may further improve results.",
            "knowledge_type": "theoretical principles (transfer learning) and explicit procedural steps (finetuning configuration and model stacking)",
            "uuid": "e397.2",
            "source_info": {
                "paper_title": "Agriculture Named Entity Recognition—Towards FAIR, Reusable Scholarly Contributions in Agriculture",
                "publication_date_yy_mm": "2024-01"
            }
        },
        {
            "name_short": "AGROVOC linking",
            "name_full": "Three-step automatic entity resolution procedure to link Agri-NER entities to AGROVOC ontology",
            "brief_description": "The paper implements an iterative programmatic linking process that queries AGROVOC for exact phrase matches and, failing that, progressively matches longest subphrases to obtain ontology concept URIs for Agri-NER annotated phrases.",
            "citation_title": "here",
            "mention_or_use": "use",
            "procedure_name": "3-step automatic entity resolution to AGROVOC",
            "procedure_description": "Given an annotated Agri-NER phrase, the procedure queries AGROVOC concept nodes for exact matches; if no match is found, the phrase is split into longest spanning subphrases (iteratively decreasing subphrase length from phrase_length-1 down to 1) and each subphrase is queried until one or more AGROVOC concept URIs resolve. Matching stops when at least one subphrase resolves. This mapping produces linked-data URIs that enrich the Agri-NER entities with AGROVOC definitions and cross-links (e.g., to DBpedia).",
            "procedure_type": "data-integration / ontology linking / linked-data resolution",
            "source_domain": "Semantic Web / ontology linking (AGROVOC linked data infrastructure)",
            "target_domain": "Agri-NER annotated contributions (entity enrichment via ontology URIs)",
            "transfer_type": "adapted/modified for new context",
            "modifications_made": "Implemented iterative longest-subphrase matching (splitting phrases) to cope with contribution-centric, variable-length title phrases that often do not directly match terminological AGROVOC entries; used programmatic queries against AGROVOC concept nodes and stopped upon first successful resolution.",
            "transfer_success": "partially successful - 16% of annotated Agri-NER entities matched AGROVOC concepts as whole phrases; an additional 53.75% could be resolved by matching longest-spanning subphrases, demonstrating substantial but incomplete coverage and revealing how contribution-centric phrases often require subphrase linking.",
            "barriers_encountered": "AGROVOC is terminologically focused whereas Agri-NER entities are functional/contribution-centric, causing mismatch; many long-tail or novel solution phrases do not exist in AGROVOC; subjective boundaries in phrasal annotation make exact matches less frequent.",
            "facilitating_factors": "Availability of AGROVOC as an authoritative linked-data concept hub; programmatic access to AGROVOC concept nodes; simple iterative subphrase heuristic to recover partial matches.",
            "contextual_requirements": "Access to AGROVOC linked-data endpoints or dump; ability to programmatically tokenize and generate subphrases; normalization/lemmatization pipelines to enhance matching.",
            "generalizability": "Method is generalizable to linking contribution-centric entities to other terminological ontologies, but success depends strongly on target ontology coverage and whether the ontology prioritizes terminological vs. functional conceptualizations.",
            "knowledge_type": "explicit procedural steps (algorithmic heuristic) and instrumental/technical knowledge (ontology querying and linking)",
            "uuid": "e397.3",
            "source_info": {
                "paper_title": "Agriculture Named Entity Recognition—Towards FAIR, Reusable Scholarly Contributions in Agriculture",
                "publication_date_yy_mm": "2024-01"
            }
        },
        {
            "name_short": "Stanza POS/NER feature transfer",
            "name_full": "Use of Stanford Stanza POS and NER tagger outputs as auxiliary features for Agri-NER models",
            "brief_description": "The authors incorporated off-the-shelf POS and generic-domain NER tags produced by the Stanford Stanza toolkit as additional token-level features in the neural sequence-labeler experiments, evaluating their contribution to performance.",
            "citation_title": "here",
            "mention_or_use": "use",
            "procedure_name": "POS and generic NER feature extraction using Stanford Stanza",
            "procedure_description": "Titles were tokenized (space-split), then Stanford Stanza was used to annotate tokens with POS tags and a generic-domain NER label; these annotations were placed as additional feature columns in the CONLL input and fed to the CharCNN+BiLSTM+CRF models (and tested in combinations) to assess impact on sequence-labeling performance.",
            "procedure_type": "preprocessing / feature-engineering using off-the-shelf NLP tools",
            "source_domain": "Natural Language Processing toolkit (Stanza POS/NER)",
            "target_domain": "Agricultural title-level NER model features",
            "transfer_type": "direct application without modification",
            "modifications_made": "No internal modification to Stanza; outputs were added as extra columns (POS, generic NER) in the CONLL-format training data and experiments tested combinations of these features with/without pretrained embeddings and with different tagging schemes.",
            "transfer_success": "successful as a facilitating feature - additional POS and generic NER features improved performance in many of the CharCNN+BiLSTM+CRF experiments (the paper reports that both IOB and IOBES settings benefited from enriched feature representations), though BERT-based finetuning still outperformed feature-augmented classical neural architectures.",
            "barriers_encountered": "Generic-domain NER labels may not align perfectly with contribution-centric types; possible noise from Stanza on short, domain-specific title tokens.",
            "facilitating_factors": "Robustness and availability of Stanza; low integration overhead (simple additional columns in CONLL format); complementary syntactic and coarse entity cues provided by POS/NER outputs.",
            "contextual_requirements": "Preprocessing pipeline that runs Stanza on titles, mapping its tokenization to the model tokenization; handling mismatches between Stanza tokenization and model input tokenization.",
            "generalizability": "Widely generalizable: using off-the-shelf POS/NER outputs as auxiliary features is common practice for many low-data sequence-labeling tasks, though the payoff varies by domain and downstream model class.",
            "knowledge_type": "instrumental/technical (tool use and feature-integration practice)",
            "uuid": "e397.4",
            "source_info": {
                "paper_title": "Agriculture Named Entity Recognition—Towards FAIR, Reusable Scholarly Contributions in Agriculture",
                "publication_date_yy_mm": "2024-01"
            }
        },
        {
            "name_short": "GloVe init→Agri",
            "name_full": "Initialization of neural-word-embedding space with pretrained GloVe vectors for Agri-NER",
            "brief_description": "The authors initialized the word-embedding layer of the CharCNN+BiLSTM+CRF architecture with pretrained GloVe vectors rather than learning embeddings solely from the small Agri-NER corpus, which improved sequence-labeler performance.",
            "citation_title": "here",
            "mention_or_use": "use",
            "procedure_name": "Pretrained GloVe embedding initialization",
            "procedure_description": "Instead of learning word vectors from the limited training corpus, the model's word-embedding matrix was initialized with fixed/pretrained GloVe vectors (global vectors learned from large external corpora), providing a richer external semantic space; experiments compared training with and without GloVe initialization.",
            "procedure_type": "computational method / transfer learning for embeddings",
            "source_domain": "General NLP pretrained embeddings (GloVe trained on large corpora)",
            "target_domain": "Agricultural NER model training",
            "transfer_type": "direct application without modification",
            "modifications_made": "No modification to GloVe itself; model pipeline used pretrained vectors and optionally fine-tuned or froze them depending on configuration; evaluated impact across tag encodings and auxiliary features.",
            "transfer_success": "successful - initializing with GloVe improved sequence-labeler performance across experimented feature settings compared to training embeddings from the Agri-NER corpus alone (paper reports consistent benefit in RQ2).",
            "barriers_encountered": "GloVe covers general vocabulary better than rare agricultural jargon or newly coined solution phrases; OOV tokens still exist for domain-specific terms.",
            "facilitating_factors": "Availability of high-quality pretrained embeddings capturing broad semantic relations; easy integration into standard neural architectures.",
            "contextual_requirements": "Vocabulary mapping from corpus tokens to GloVe indices, handling of out-of-vocabulary tokens, and possibly dimensionality matching between embedding layer and model architecture.",
            "generalizability": "Highly generalizable: pretrained embeddings commonly help low-data domain tasks, but domain-specific embeddings or continued pretraining on domain text can yield further improvements.",
            "knowledge_type": "instrumental/technical (practical method for initializing model parameters)",
            "uuid": "e397.5",
            "source_info": {
                "paper_title": "Agriculture Named Entity Recognition—Towards FAIR, Reusable Scholarly Contributions in Agriculture",
                "publication_date_yy_mm": "2024-01"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Computer science named entity recognition in the open research knowledge graph",
            "rating": 2,
            "sanitized_title": "computer_science_named_entity_recognition_in_the_open_research_knowledge_graph"
        },
        {
            "paper_title": "A Large-Scale Knowledge Graph of Research Entities and Claims in Computer Science (CS-KG)",
            "rating": 1,
            "sanitized_title": "a_largescale_knowledge_graph_of_research_entities_and_claims_in_computer_science_cskg"
        },
        {
            "paper_title": "Pretrained Language Model for Scientific Text (SciBERT)",
            "rating": 2,
            "sanitized_title": "pretrained_language_model_for_scientific_text_scibert"
        },
        {
            "paper_title": "GloVe: Global Vectors for Word Representation",
            "rating": 2,
            "sanitized_title": "glove_global_vectors_for_word_representation"
        },
        {
            "paper_title": "End-to-end Sequence Labeling via Bi-directional LSTM-CNNs-CRF",
            "rating": 2,
            "sanitized_title": "endtoend_sequence_labeling_via_bidirectional_lstmcnnscrf"
        },
        {
            "paper_title": "NCRF++: An Open-source Neural Sequence Labeling Toolkit",
            "rating": 2,
            "sanitized_title": "ncrf_an_opensource_neural_sequence_labeling_toolkit"
        },
        {
            "paper_title": "AGROVOC: The linked data concept hub for food and agriculture",
            "rating": 2,
            "sanitized_title": "agrovoc_the_linked_data_concept_hub_for_food_and_agriculture"
        },
        {
            "paper_title": "Stanza: A Python Natural Language Processing Toolkit for Many Human Languages",
            "rating": 1,
            "sanitized_title": "stanza_a_python_natural_language_processing_toolkit_for_many_human_languages"
        }
    ],
    "cost": 0.017973999999999997,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Agriculture Named Entity Recognition-Towards FAIR, Reusable Scholarly Contributions in Agriculture
19 January 2024</p>
<p>Jennifer D ' Souza jennifer.dsouza@tib.eu 
TIB Leibniz Information Centre for Science and Technology
30167HannoverGermany</p>
<p>Agriculture Named Entity Recognition-Towards FAIR, Reusable Scholarly Contributions in Agriculture
19 January 2024FCC29C00D9B2CB4271380CC4F45F6C6810.3390/knowledge4010001Received: 16 May 2023 Revised: 11 January 2024 Accepted: 15 January 2024D'Souza, J. Agriculture Named Entity Recognition-Towards FAIR, Reusable Scholarly information extractionnamed entity recognitionnatural language processingdatasetsequence labelingscholarly knowledge graphsopen research knowledge graph
We introduce the Open Research Knowledge Graph Agriculture Named Entity Recognition (the ORKG Agri-NER) corpus and service for contribution-centric scientific entity extraction and classification.The ORKG Agri-NER corpus is a seminal benchmark for the evaluation of contributioncentric scientific entity extraction and classification in the agricultural domain.It comprises titles of scholarly papers that are available as Open Access articles on a major publishing platform.We describe the creation of this corpus and highlight the obtained findings in terms of the following features: (1) a generic conceptual formalism focused on capturing scientific entities in agriculture that reflect the direct contribution of a work; (2) a performance benchmark for named entity recognition of scientific entities in the agricultural domain by empirically evaluating various state-of-the-art sequence labeling neural architectures and transformer models; and (3) a delineated 3-step automatic entity resolution procedure for the resolution of the scientific entities to an authoritative ontology, specifically AGROVOC that is released in the Linked Open Vocabularies cloud.With this work we aim to provide a strong foundation for future work on the automatic discovery of scientific entities in the scholarly literature of the agricultural domain.</p>
<p>Introduction</p>
<p>Scientific innovations drive progress in companies, industries and the economy.Currently, the scholarly publication cycles are at an alarming rate of 2.5 million articles per year [1].Thus, the traditional documents ranked lists offered by scholarly search engines no longer support efficient research and development (R&amp;D).While they pinpoint individual papers of interest from a mass of documents, they do not offer researchers a sense of an overview of the field.Researchers seem to drown in the deluge of publications as a consequence of the tediously long information assimilation cycle to manually scan salient aspects of research contributions within information buried in static text.Thus, enabling machine-actionability of scholarly knowledge is warranted now more than ever.In this vein, the method of scholarly knowledge strategic reading powered by Natural Language Processing (NLP) is being advocated for research, business, government, and non-governmental organization (NGO) stakeholders [2].Most current strategic reading relies on human recognition of scientific terms from text, perhaps assisted with string searching and mental calculation of ontological relationships, combined with burdensome tactics of bookmarking, note-taking, and window arrangement.To this end, recently, an increasing number of research efforts are geared toward putting in place next-generation Findable, Accessible, Interoperable, and Reusable (FAIR) [3] scholarly knowledge representation models as Knowledge Graphs (KGs) [4,5].They advocate advanced semantic machineinterpretability of publications via KGs to enable more intelligent automated processing (e.g., smart information access).This development started in advanced scholarly digital libraries (DL) such as the Open Research Knowledge Graph (ORKG, https://orkg.org/,accessed on 14 January 2024) [5], that crowdsources templated research contributions resulting in tabulated surveys of comparable contributions (cf. Figure 1), thus demonstrates strategic reading in practice.To represent scholarly publications as KGs, from an Information Extraction (IE) perspective, named entity recognition (NER) over scholarly publications becomes a vital task since entities are at the core of KGs.As an IE task, NER over scholarly documents is a long-standing task in the NLP community-the Computer Science domain itself has been addressed over a wide body of works with various knowledge capture objectives [6][7][8][9][10][11][12][13][14][15][16][17][18][19].However, this well-established research area [20][21][22][23], thus far, has not seen any practical applications in the Agricultural scholarly publications domain.</p>
<p>In the domain of agriculture, the gradual sophistication of food production and agricultural methods led to an increasing demand for data exchange, processing and information retrieval.Thus the recording of knowledge as information islands via manual notetaking had to evolve to the recording of relational knowledge in databases via protocols.These protocols facilitated standardized recording and exchange of knowledge between different databases via purposefully invented data dictionaries and coding systems that assigned simple alphanumeric codes to products, varieties, breeds or crops.E.g., the ISOBUS [24]/ISO11783 [25] data dictionary or the European and Mediterranean Plant Protection Organization (EPPO) codes of crops used for plant protection applications [26].Today, however, we are faced with not only sophisticated agricultural practices but also voluminous masses of agricultural research findings published worldwide.Hence the call for the adoption of next-generation semantic web publishing model [27] of machine-actionable, structured scholarly contributions content via the ORKG platform.Within this model, a large-scale agricultural KG would be predicated on standardized templated subgraph patterns for recording interoperable structured scholarly contributions in agriculture.The custom-templated subgraphs ensure the standardized recording of comparable research contributions in an overarching interoperable graph of highly varied underlying research domains.The research domains can include appraisals of agricultural products, e.g., A chemotaxonomic reappraisal of the Section Ciconium Pelargonium (Geraniaceae) [28], or the restoration and management of plant systems, e.g., mangrove systems.Table 1 lists 15 sub research domains of contemporary research in agriculture.An information modeling objective ensures capturing contributions under a uniform set of salient properties within a single domain, while allowing for the definition of varied sets of salient properties across domains.This enables machine-assisted strategic reading within the semantic web publishing model directly addressing the information ingestion problem over massive volumes of findings for the researchers by smart machine assistance.E.g., as structured contribution comparisons computed over the set of salient contribution properties in one domain as depicted in Figure 1.The road to discovering contribution templates for research domains should be based on a set of generic entity types being applicable across all domains that can be further specialized and instantiated as domain-specific, full-fledged templates.In other words, prior to obtaining research-domain-specific contribution template patterns, there needs to be put in place a standardized set of generic entity types that can foster the further development of the problem-specific contribution templates constituted by additional semantic properties.As such the Agriculture Named Entity Recognition service of the ORKG (the ORKG Agri-NER service), addressed seminally in this work, proposes a set of seven generic entity types that encapsulate the contribution of a work extracted from paper titles.The seven contribution-centric entity types are: RESEARCH PROBLEM, RESOURCE, PROCESS, LOCATION, METHOD, SOLUTION, and TECHNOLOGY.Building on this idea, this study makes two novel key contributions: (1) we propose for the first time an NER service specifically tailored for the agricultural domain; and (2) predicated on seven contributioncentric entities derived from paper titles and inspired from the top-level concepts of the AGROVOC ontology (https://agrovoc.fao.org,accessed on 14 January 2024) of the Food and Agriculture Organization of the United Nations (FAO, https://www.fao.org/home/en/, accessed on 14 January 2024), we lay the groundwork for the discovery of domainspecific contribution templates for the further specification of the generic entity types.</p>
<p>The ORKG Agri-NER service is an IE system of seven entity types such as research problems, resources, location of study, etc., which since extracted from paper titles implicitly encapsulate the contributions of scholarly articles.Conceptually, the shared understanding around paper titles is that they are succinct summarizations of the contribution of a work [18].Thus when looking to formulate a contribution-centric entity extraction objective, the first place to seek out this information is from paper titles.Specifically, ORKG Agri-NER provides a conceptual ecosphere of seven entity types to begin to generically structure and compare the contributions of scholarly articles in the domain of Agriculture as illustrated in Figure 2. A striking feature of the proposed work is that it supports retrieving, exploring and comparing research findings based on explicitly named entities of the knowledge contained in agricultural scientific publications.If applied widely, ORKG Agri-NER can have a significant impact on scholarly communication in the agricultural domain.It specifically addresses researchers who want to compare their research with related works, get an overview of works in a certain field, or search for research contributions addressing a particular problem or having certain characteristics.Figure 3 gives a high-level overview of the proposed semantic model by showing the seven core entity types in Agri-NER.The ORKG Agri-NER service then is the first step in a long-term research agenda to create a paradigm shift from document-based to structured knowledge-based scholarly communication for the agricultural domain.Other than the discovery of contribution-centric template patterns in the ORKG, the machine-readable description of research knowledge in the seven entity types could support other services for analyzing scientific literature in the agricultural domain such as forecasting agricultural research dynamics, identifying key insights, informing funding decisions, and confirming claims in news on contemporary agricultural research.</p>
<p>To facilitate further research, we contribute two resources to the community: (1) The ORKG Agri-NER human-annotated gold-standard corpus which can be downloaded at https://github.com/jd-coderepos/contributions-ner-agri(accessed on 14 January 2024) under the CC BY-SA 4.0 license; and (2) The ORKG Agri-NER tool whose source code can be accessed at https://gitlab.com/TIBHannover/orkg/nlp/experiments/orkg-agriculture-ner(accessed on 14 January 2024) under the MIT license, and which furthermore are available as services to the community in two ways-the python package version of the service can be accessed at https://orkg-nlp-pypi.readthedocs.io/en/latest/services/services.html(accessed on 14 January 2024); also, it is possible to directly interact with the REST API for the Agri-NER service directly via the interaction documentation page at https://orkg.org/nlp/api/docs#/annotation/annotates_agri_paper_annotation_agriner_post (accessed on 14 January 2024).The remainder of the paper explains both the creation of the dataset resource and tool in detail.</p>
<p>Background</p>
<p>"Semantic Web ... does not require complex artificial intelligence to interpret human ideas, but 'relies solely on the machine's ability to solve well-defined problems by performing well-defined operations on well-defined data' ". [27,29] The FAIRification guidelines [3] for scholarly knowledge publishing inadvertently advocates for adopting semantic models for machine-actionable knowledge capture of certain aspects of the article content such that they are findable, actionable, interoperable, and reusable.Ontological or entity-centric conceptual schemas are an elegant demonstration of what "going FAIR" (https://www.go-fair.org/fair-principles/,accessed on 14 January 2024) means in practice across the broad spectrum of the researchers landscape as long as they are involved in the publication of their work.These schemas, by going beyond 'data' in the conventional sense, and instead applying to algorithms, tools, and workflows that lead to the data which are traditionally captured in discourse text, bring the recording of these aspects of scholarly knowledge in the FAIR landscape.Thereby, transparency, reproducibility, and reusability of scholarly analytical pipelines are fostered.Broadly, the research paradigms around the generation of FAIR data can be classified into two broad types: (1) ontological models that can directly produce FAIR-compliant data when instantiated; and (2) informal conceptual annotation models which are not characteristically FAIR-compliant but which work on data instances that support the discovery of ontologies in a bottom-up manner.These models equip experts with a tool for semantifying their scholarly publications ranging from strictly-ontologized methodologies [30,31] to less-strict, flexible conceptual description schemes [7,17], wherein the latter aim toward the bottom-up, data-driven discovery of an ontology.</p>
<p>The remainder of this section is organized per these two broad paradigms.</p>
<p>Ontological Structuring of Scholarly Publications</p>
<p>Early works can be traced to the Dublin Core Metadata Terms (DCTerms) [32] ontology (http://purl.org/dc/terms/,accessed on 14 January 2024).The original "Dublin Core" was the result of a March 1995 workshop in Dublin, Ohio, which sought to define a generic metadata record that was generic enough to describe a wide range of electronic objects [33].Subsequent ontologies specifically modeled scholarly articles but inherited DCTerms in an upper-level ontology space.</p>
<p>Some ontologies focused on modeling the scholarly document structure and rhetorics.In this vein, the Document Components Ontology (DoCO) [34] is an ontology for describing both structural and rhetorical document components in RDF.For structural annotations, DoCO imports the Document Structural Patterns Ontology (https://sparontologies.github.io/po/current/po.html,accessed on 14 January 2024) with classes such as Sentence, Paragraph, Footnote, Table, Figure, CaptionedBox, FigureBox, List, BibliographicReferenceList etc.The pattern ontology defines formally patterns for segmenting a document into atomic components, in order to be manipulated independently and reflowed in different contexts.For the rhetorical annotations, DoCO imports the Discourse Elements Ontology (https://sparontologies.github.io/deo/current/deo.html, accessed on 14 January 2024) which was written describing the major rhetorical elements of a document such as a journal article.Its classes include deo:Introduction, deo:Materials, deo:Methods, deo:Results, deo:RelatedWork, deo:FutureWork, etc.These rhetorical components give a defined rhetorical structure to the paper, which assists readers to identify the important aspects of the paper.DEO reuses some of the rhetorical blocks from the SALT Rhetorical Ontology [35] and extends them by introducing 24 additional classes.In the context of structural and rhetorical organization of scholarly articles, it was noted that the rhetoric organization of a paper does not necessarily correspond neatly to its structural components (sections, paragraphs, etc.).The Ontology of Rhetorical Blocks (orb) [36] introduces rhetorical classes to semantify sections of scholarly publications.Eg., orb:Introduction, orb:Methods, orb:Results, orb:Discussion to structure the Body of an article inspired after the IMRAD structure [37].The hypothesis preceding this ontology is that the coarse rhetoric emerging from publications' content have commonly shared semantics.Thus ORB provided a minimal set of rhetorical blocks that could be leveraged from the Header, Body, and Tail of scholarly publications.The Ontology of Scientific Experiments [38], EXPO, advocated that the development of ontology of experiments-which are testbeds for cause-effect relations-is a fundamental step in the formalization of science.Reported scientific findings with their salient attributes buried in discourse is made explicit increasing the findability of problems with formal, semantic annotations supported by EXPO.It then constitutes the intermediate layer of a general ontology of scientific experiments with ontological concepts such as experimental goals, experimental methods and actions, types of experiments, rules for experimental design, etc., that are common between different scientific areas.</p>
<p>With the ontologies discussed, one observes that each ontology defines an information scope for formalization.The current level of formalization varies greatly in granularity and between the sciences.Ontology reuse [39] addresses in a sense the extent to which generalization or specification can occur depending on the level of the ontology model they are applied in, nonetheless is a key realizer in what would otherwise seem an impossible goal to design an ontology for Science.One of the first attempts to address the description of the whole publishing domain is the introduction of the Semantic Publishing and Referencing (SPAR) ontologies (http://www.sparontologies.net/,accessed on 14 January 2024).SPAR is a suite of orthogonal and complementary OWL2 ontologies that enable all aspects of the publishing process to be described in machine-readable metadata statements, encoded using RDF.It includes FaBiO, CiTO proposed by [40], BiRO, C4O proposed by [41], among others.Another noteworthy example that followed best practices in ontology development by reusing related ontologies [39] listed in the Linked Open Vocabularies (LOV) was Semsur, the Semantic Survey Ontology, proposed by [30,42].It introduced the semantification model for survey articles as a core ontology for for describing individual research problems, approaches, implementations and evaluations in a structured, comparable way.It modeled metadata based on DCTerms, Semantic Web for Research Communities (SWRC) [43] and Friend of a Friend (FOAF) (http://xmlns.com/foaf/0.1/,accessed on 14 January 2024) ontologies.The inner structure of scientific articles was partially modeled by Discourse Elements Ontology (DEO) (http://www.sparontologies.net/ontologies/deo,accessed on 14 January 2024) and Linked Science Core (LSC) [44] to model publication workflows.Survey articles have been the traditional method for documenting overview of research progresses.However with the document-based publishing model, much of the data points presenting research progress remained buried in discourse, as a result were forever statically encoded.Semsur aimed to offer machine-actionability to these key resources.</p>
<p>Entity-Centric Annotation Models of Scholarly Publications</p>
<p>The trend towards scientific terminology mining methods in NLP steered the release of phrase-based annotated datasets in various domains.An early dataset in this line of work was the ACL RD-TEC corpus [8] which identified seven conceptual classes for terms in the full-text of scholarly publications in Computational Linguistics, viz.Technology and Method; Tool and Library; Language Resource; Language Resource Product; Models; Measures and Measurements; and Other.Another dataset focused on the research dynamics discovery around scientific terminology in Computational Lingistics included the FTD corpus [7] annotated with Focus, Task and Domain of application entity types.Similar to terminology mining is the task of scientific keyphrase extraction.Extracting keyphrases is an important task in publishing platforms as they help recommend articles to readers, highlight missing citations to authors, identify potential reviewers for submissions, and analyse research trends over time.Scientific keyphrases, in particular, of type Processes, Tasks and Materials were the focus of the SemEval17 corpus annotations [10].The dataset comprised annotations of the full text articles in Computer Science, Material Sciences, and Physics.Following suit was the SciERC corpus [12] of annotated abstracts from the Artificial Intelligence domain.It included annotations for six concepts, viz.Task, Method, Metric, Material, Other-Scientific Term, and Generic.Subsequently, based on this conceptual formalism, largescale knowledge graphs such as AI-KG [14] and CS-KG [45] were generated.Recently, tackling the multidisciplinary discovery of entities, the STEM-ECR corpus [15] was introduced notably including the Science, Technology, Engineering, and Medicine domains.It was annotated with four generic concept types, viz.Process, Method, Material, and Data that mapped across all domains, and further with terms grounded in the real-world via Wikipedia/Wiktionary links.Furthermore, along the lines of the motivation of Agri-NER is the CS-NER service [18,19] that addresses the extraction of seven contribution-centric entities applicable in the Computer Science research field, viz.Research problem, Resource, Method, Tool, Dataset, Language, and Solution entity types from Computer Science paper titles and abstracts.These seven entity types were proposed to foster the discovery of research-domain-specific contribution templates in Computer Science.</p>
<p>Leaderboards construct of progress trackers taken up for the recording of results in the field of empirical Artificial Intelligence (AI) at large is a case in point of the development of templates arising from contribution-centric entities.This construct underlies the Pa-persWithCode https://paperswithcode.com/ (accessed on 14 January 2024) framework, as well as the ORKG Benchmarks https://orkg.org/benchmarks(accessed on 14 January 2024) feature.The construct defines the recording of results around four entity types viz.Task, Dataset, Metric, and Score from the full text of scholarly articles.The entities were then combined within the full-fledged semantic construct of a Leaderboard with between three or all four types for machine learning [13,17,[46][47][48].</p>
<p>The Agri-NER service is situated within this latter broad paradigm of obtaining structured comparable, FAIR descriptions of scholarly contributions for the agricultural domain with the aim of bottom-up discovery of template patterns.However, it also relies on the first paradigm of scholarly knowledge structuring by mapping the automatically extracted terms to the AGROVOC ontology [49] which offers a controlled vocabulary designed to cover unambiguous semantic descriptions for terminology under the FAO's areas of interest.The following desiderata guided the creation of Agri-NER.(1) Manual curation of Agriculture named entities from 5500 article titles that reflect the contribution of a work enabling machine learning model training and development.(2) Associating terms within the AGROVOC ontology allowing for conceptual enrichment for the terms.</p>
<p>(3) Allowing for ongoing, collaborative expert curation of named entities termwise and for their typing.(4) Juxtaposing a contribution-centric information extraction objective with term standardization in ontologies -why a simple term normalization against authoritative ontologies does not serve the objective of obtaining contribution-centric models?The rest of paper discusses how these requirements were accomplished.</p>
<p>In essence, our work's focus on FAIR principles, advanced NLP techniques, and the integration of machine-actionable knowledge capture aligns well with the core tenets of Industry 5.0, specifically in terms of its influence on agriculture [50,51].Industry 5.0 emphasizes personalized and sustainable solutions, blending human-centric approaches with advanced technological innovations [52].The focus of the ORKG Agri-NER service, proposed in this work, on creating interoperable, reusable, and machine-interpretable models of scholarly contributions in agriculture fits into this paradigm by enabling more nuanced, efficient, and collaborative research practices.This approach can lead to more tailored agricultural practices and innovations, reflecting the personalized and sustainable ethos of Industry 5.0.</p>
<p>Materials and Methods</p>
<p>This section details the research methodology followed to develop the ORKG Agri-NER service.Our approach aligns with the typical methods used in Computer Science (CS) research within the field of NLP.This paper specifically addresses the development of a machine learning system for the automatic extraction of agricultural research-relevant entity types from scholarly articles, contributing to the ORKG database.The methodology adopted here is empirical and consists of four primary steps.The initial step involved defining the Agri-NER objective by selecting appropriate entity types pertinent to agriculture, based on theoretical considerations of various entity source types.This process is thoroughly explained in Section 3.1.Subsequently, from the theoretically identified entities, a set of seven specific entity types were chosen to formalize the ORKG Agri-NER goal, which we then defined.The chosen entity types and their definitions are detailed in Section 3.2.1.The third step entailed creating a human-annotated, gold-standard corpus of paper titles tagged with these seven entity types.Our aim was to build a corpus of high quality and size to facilitate the development of effective and robust machine learning models, as elaborated in Section 3.2.2.The final step involved training a machine learning system using this annotated corpus, which is discussed comprehensively in the dedicated section, Section 4.</p>
<p>Theoretical Paradigm: The AGROVOC Ontology and the ORKG Agri-NER Model</p>
<p>The work discussed in this paper seeks to integrate two paradigms of information representation: ontologized knowledge indexing supported by the AGROVOC ontology [49], and contribution-centric entity-based knowledge extraction supported by the ORKG Agri-NER model.The latter is the focus of this work.In both projects, the source material is taken from scholarly publications.The domain in both contexts is Agriculture where it is known that AGROVOC domain coverage is an amalgamation of the following related domains, viz.Agriculture, Fisheries, Forestry, and Environment.Detailed information about the respective projects i.e., AGROVOC [53][54][55][56] and ORKG [5,57] can be obtained elsewhere.</p>
<p>In a system like the ORKG (https://orkg.org/,accessed on 14 January 2024), it is impossible to exhaustively predict in advance which entity types will be needed to semantically model scholarly contributions in the vast domain of Agriculture.The list of entity types, for instance, is in principle open-ended for the main reason that scholarly innovations are continuously made.However, this implication also holds true for the AGROVOC ontology since, as research progresses, the existing agricultural terminology is constantly evolving, on the one hand, and new concepts are constantly discovered, on the other hand.In the context of the ORKG, our initial hypothesis is that starting out with an initial set of candidate entity types in Agri-NER as recommendations offer researchers a rough sketch to design templates aggregating one or more of the suggested entity types and define new types in addition to standardize the process of describing innovations across research papers addressing the same research problem or in the same domain, for instance.Given this, the workflow of Agri-NER will be constantly evolving as new entity types introduced by researchers describing their contributions will be periodically reviewed and fed back as input to retrain the models.In a sense, the evolution of AGROVOC is indeed based on the same principles.</p>
<p>Finally, we note that the notion of entity types from Agri-NER and concepts in AGROVOC are not equivalent.A concept in AGROVOC pertains to a real-world entity with alternate names.E.g., Maize https://agrovoc.fao.org/browse/agrovoc/en/page/c_12332(accessed on 14 January 2024) is a concept in AGROVOC with alternate names such as "corn".In contrast, entity types in ORKG Agri-NER refer to the functional role of various real-world entities in the context of the contribution of a work which depends on the publication sentence discourse describing the contribution.</p>
<p>The ORKG Agri-NER Specifications</p>
<p>In this subsection, we first offer definitions for each of the seven entity types considered in ORKG Agri-NER.Following which, we discuss the annotation process and conclude with corpus statistics.</p>
<p>The Seven ORKG Agri-NER Entity Type Definitions</p>
<p>The Agri-NER model is structured around the following seven core entity types.</p>
<p>•</p>
<p>RESEARCH PROBLEM.It is a natural language mention phrase of the theme of the investigation in a scholarly article [42].Alternatively, in the Computer Science domain it is referred to as task [17] or focus [7]. to the ORKG contribution model.E.g., radiation-induced genome alterations, artificially assembled seed dispersal system, commercial craftwork, integrated ecological modeling system, the MiLA tool, next generation crop models etc. • TECHNOLOGY.Practical systems realized as tools, machinery or equipment based on the systematized application of reproducible scientific knowledge to reach a specifiable, repeatable goal.In the context of the agriculture domain, the goals would pertain to agricultural and food systems.E.g., stream and riverine ecosystem services, hyperspectral imaging, biotechnology, continuous vibrating conveyor, low exchange water recirculating aquaculture systems, etc.</p>
<p>The ORKG Agri-NER Corpus Annotation Methodology</p>
<p>Having introduced the seven contribution-centric entity types used in ORKG Agri-NER, we now elicit the methodology for producing the instance annotations for the entity types from a corpus of paper titles.</p>
<p>Raw Dataset</p>
<p>The first step entailed downloading a raw corpus comprising paper titles of scholarly articles published in the agricultural domain.For this, a sample size needed to be defined.In this regard, the corpus size needed to satisfy two criteria: a large enough sample size to train a machine learning model and a small enough sample size such that the human annotation task was feasible.As such after discussions with the human annotator a sample size of 5500 titles was arrived at.A corpus with thousands of data points easily satisfies the objective of obtaining a robust machine learning system.This we concur based on our prior work with training NER machine learning systems in a multidisciplinary setting [15,58] and a single domain setting [19].Thus 5500 articles in text format and restricted only to the articles with the CC-BY redistributable license on Elsevier were first downloaded using the following list https://github.com/jd-coderepos/stem-ner-60k/blob/main/raw-data/Elsevier-ccby-articles-w-domain-mapping.tsv(accessed on 14 January 2024).Next, our aim was to obtain the seven entity type annotations for only the titles in this corpus of publications.For this, a raw dataset of the article titles was created https://github.com/jd-coderepos/contributions-ner-agri/tree/main/raw-data(accessed on 14 January 2024).</p>
<p>Corpus Annotation</p>
<p>With a corpus of titles in place, we were then first and foremost faced with a blank slate of entity types to annotate since there was no reported prior work for NER in the agricultural domain.A natural question here is how did we arrive at the seven entity types, viz.RESEARCH PROBLEM, RESOURCE, PROCESS, LOCATION, METHOD, SO-LUTION, and TECHNOLOGY, defined earlier?This was done based on the following 3-step methodology.</p>
<p>1.</p>
<p>A list of entity types used in our prior work [19] on contribution-centric NER for the Computer Science (CS) domain was created as a reference list.This list included the following CS-domain-specific contribution-centric types, viz.SOLUTION, RESEARCH PROBLEM, METHOD, RESOURCE, TOOL, LANGUAGE, and DATASET.We identified this as a suitable first step owing to the strong overlap of the annotation aim between our prior work on the CS domain and our present work on the agriculture domain, i.e., that of identifying contribution-centric entities from paper titles.We hypothesized that some entity types, e.g., RESEARCH PROBLEM, that satisfy the functional role of reflecting the contribution of scholarly articles by nature of their genericity could be applicable across domains.As such the listed CS-domain contribution-centric entity types were tested for this hypothesis.Furthermore, based on the successful annotation outcomes of paper titles offering a rich store of contribution-centric entities, this work focusing on a new domain, i.e., agriculture, similarly based its entity annotation task on paper titles.Thus, with an initial set of entities in place, our task was then to identify the entities that were generic enough to be transferred from the CS domain to the domain of agriculture.</p>
<p>2.</p>
<p>Considering that some new agriculture domain-specific entity types would also need to be introduced, a list of the 24 top-level concepts in the AGROVOC ontology [53] as the reference standard was drawn up.This list included concepts such as FEATURES (https://agrovoc.fao.org/browse/agrovoc/en/page/c_331061,accessed on 14 January 2024), LOCATION (https://agrovoc.fao.org/browse/agrovoc/en/page/c_330988, accessed on 14 January 2024), MEASURE (https://agrovoc.fao.org/browse/agrovoc/en/page/c_330493, accessed on 14 January 2024), PROPERTIES (https://agrovoc.fao.org/browse/agrovoc/en/page/c_49874,accessed on 14 January 2024), STRATEGIES (https://agrovoc.fao.org/browse/agrovoc/en/page/c_330991,accessed on 14 January 2024), etc.The focus was maintained only on the top-level concepts, since traversing lower levels in the ontology led to specific terminology defined as a concept space such as Maize https://agrovoc.fao.org/browse/agrovoc/en/page/c_12332 (accessed on 14 January 2024).Since specific terminology do not serve the purpose of reflecting a functional role, hence by their inherent nature were ruled out as conceptual candidates for contribution-centric entity types.</p>
<p>3.</p>
<p>Given the two reference lists of generic CS domain entity types and domain-specific AGROVOC concepts from steps 1 and 2, respectively, the third step involved selecting and pruning the lists to arrive at a final set of contribution-centric entity types to annotate agricultural domain paper titles with.There were two prerequisites defined for arriving at the final set of entity types: (a) it needed to include as many of the generic entities as were semantically applicable; and (b) introduce new domain-specific types complementing the semantic interpretation of the generic types such that the final set could be used as a unit for contribution-centric entity recognition.Concretely, these requisites were realized as a pilot annotation task over a set of 50 paper titles performed by a postdoctoral researcher.Starting with the CS domain inspired list of generic entities, the pilot annotation task showed that the CS domain TOOL, LANGUAGE, and DATASET types were not applicable to agricultural domain.This left a set of four types, viz.SOLUTION, RESEARCH PROBLEM, METHOD, and RESOURCE for the final annotation task.For the domain-specific entities, via the pilot annotation exercise, it was fairly straightforward to prune out most of the AGROVOC concepts on the basis of the following three criteria.(a) Six concepts did not fit in the criteria of offering a functional role that reflected the contribution of a work.These were entities, factors, groups, properties, stages, state.(b) Nine concepts indicated that they were more paper contentspecific than title-specific.These were activities, events, features, measure, phenomena, products, site, systems, and time.And, (c) since our objective was to capture the most generic entity satisfying the functional role of reflecting the paper contribution, some of the top-level AGROVOC concepts could be subsumed by others.Specifically, the four types viz.objects, organisms, subjects, substances were subsumed as AGROVOC resources.Also strategies was subsumed as AGROVOC methods.In the end, from an initial list of 25 types, pruning out 15 types and subsuming 5 types, we were left with a set of five types for the final annotation task, viz.location, methods, processes, resources, technology.</p>
<p>Then the generic and domain-specific lists were resolved as follows: SOLUTION and RESEARCH PROBLEM originating from the CS domain were retained as is for the agriculture domain; AGROVOC methods was resolved to the generic METHOD type and AGROVOC resources was resolved to RESOURCE; the remaining AGROVOC entities were first lemmatized for plurals (e.g., processes → PROCESS) and otherwise retained as is for LOCATION and TECHNOLOGY types.</p>
<p>With the final list of seven contribution-centric entity types arrived at for the agricultural domain, the raw dataset of 5500 paper titles could then be annotated.Note that among the seven entity candidates, three or four entity types applied at most for annotating a paper title for its entities with a possibility for repeated occurrences of one or more types.To offer the reader an insightful look into our corpus, Table 2 illustrates with the help of color codes for the entity types, five annotated paper title instances as examples.To facilitate further research on this topic, our corpus is publicly released with the CC BY-SA 4.0 license at https://github.com/jd-coderepos/contributions-ner-agri(accessed on 14 January 2024).The Agri-NER Corpus Statistics Our corpus characteristics are further examined in terms of the overall corpus statistics shown in Table 3. From a raw dataset of 5500 paper titles, a total of 15,261 entity annotations were obtained with 10,406 of them being unique.The annotation rate in terms of number of entities annotated per title is at 2.93 entities.Of the 5500 titles, eight could not be annotated with any of the seven contribution-centric entity types.Hence the minimum number of entities/title shows a 0 count statistic.These eight titles were outliers in our corpus.Consider the two-token title "Garden Masterclass" as one example among the eight unannotatable titles of which the others similarly reflected a peculiar characteristic such as, for instance, being too short.</p>
<p>Results</p>
<p>With an annotated corpus in place, various neural machine learning models were evaluated to create the ORKG Agri-NER service.This section is devoted to discussions about our machine learning experimental setup and results from the various trained models to obtain an optimal ORKG Agri-NER automated service.</p>
<p>Experimental Setup</p>
<p>Dataset</p>
<p>The ORKG Agri-NER corpus presents a sequence labeling scenario.For learning a sequence labeler, each sentence is tokenized as a set of words where each word is assigned a classification symbol.The series of classification decisions over the words are then aggregated in a final step to extract classifications for phrases.Thus, in a first step, our raw annotated data had to be converted into a suitable format for machine learning.The most common representation format adopted for sequence labeling is called the CONLL format introduced in the CONLL 2003 shared task series [59].Per the prescribed format, each line in the data file consists of tab-separated values with the tokenized word to be classified in the first column, features such as the part-of-speech (POS) tag in the columns in between, and the classification token in the last column.Sequences of tokenized words constitute consecutive lines in the data file.And an empty line separates sentence sequences.To create our data in this format, for tokenization the titles were simply split on spaces.In addition since we were interested in testing additional features as informative to the task or not, we obtained POS tags and NER tags for the tokens with the help of the Stanford Stanza library [60].These features constituted the second and the third columns of our data file.Finally, the fourth column constituted the classification tag.For this we experimented with two well-known formats, viz.IOB and IOBES.The IOB tagging sequence [61] is the one where the B-tag is used in the beginning of every phrasal entity type, I-prefix before a tag indicates that the tag is inside a phrasal entity type, and O tag indicates that a token belongs to no entity type.E.g., if the a phrase is of type METHOD, the tag for the first token of the phrase will be B-METHOD and all the remaining tokens of the phrase will be tagged I-METHOD.On the other hand, the IOBES tagging sequence [62] is the one with the tags B, E, I, S or O where S is used to represent a chunk containing a single token.Chunks of length greater than or equal to two always start with the B tag and end with the E tag.</p>
<p>Once our data was converted to the CONLL format, the annotated gold-standard collection of 5500 annotated titles was randomly split as 5000 titles in the training set, 200 titles in the development set for the tuning of hyperparameters of the machine learning models, and 300 titles in the test set.The resulting dataset is also part of the community release and can be accessed here https://github.com/jd-coderepos/contributions-neragri/tree/main/NCRFpp-input-format(accessed on 14 January 2024).</p>
<p>Models</p>
<p>In this age of the "deep learning tsunami" [63], neural sequence labeling models are the state-of-the-art technique.The neural models completely alleviated the traditional method of manual feature engineering.Instead in neural models, features are extracted automatically through network structures including long short-term memory (LSTM) [64] and convolution neural network (CNN) [65].As such various network architectures have evolved with each class of models outperforming the others.One class of models belongs to word-level neural networks [66] where words of a sentence are given as input to a Recurrent Neural Network (RNN), specifically, an LSTM and each word is represented by its word embedding.Another class of models belongs to character-level neural networks [67] where a sentence is taken to be a sequence of characters.This sequence is passed through a CNN, predicting labels for each character.Character labels are transformed into word labels via post processing.The third and most successful class of models belongs to a combination of word+character neural networks [68,69] where the first layer represents words as a combination of a word embedding and a convolution over the characters of the word, following this with a Bi-LSTM layer over the word representations of a sentence.</p>
<p>Thus inspired from state-of-the-art neural sequence labelers [68][69][70][71], we leveraged the outperforming architectural variant, i.e., the "Char CNN + Word BiLSTM + CRF" neural sequence labeling model architecture.The model has three layers.1. Character Sequence Layer which relies on CNN neural encoders for character sequence information.Specifically, the sliding window approach captures local features, which are then maxpooled to obtain an aggregated encoding of the character sequence.2. Word Sequence Layer which relies on bidirectional LSTMs as the word sequence extractor.Since word contexts are a crucial feature to build optimal sequence labelers, the bidirectional LSTMs are shown to be most effective since they encode both the left and right context information of each word.The hidden vectors for both directions on each word are concatenated to represent the corresponding word.Further, the word representations were computed one of two ways: either directly from the data, or as precomputed vectorized embedding representations.We used GloVe embeddings [72].And 3. Inference Layer as the last layer for token classification by taking the extracted word sequence representations as features and assigning labels to the word sequence.In this layer, we leverage Conditional Random Fields (CRFs).Since CRFs are able to capture label dependencies in the output layer which leads to better predictions, their usage has resulted in many state-of-the-art neural sequence labeling models [69,71,73].For implementation purposes, we leveraged the open-source toolkit called NCRF++ [74] (https://github.com/jiesutd/NCRFpp,accessed on 14 January 2024) based on PyTorch.Our experimental configuration files for model hyperparameter details including learning rate, dropout rate, number of layers, hidden size etc., are released as config files here https://gitlab.com/TIBHannover/orkg/nlp/experiments/orkg-agriculture-ner/ (accessed on 14 January 2024).</p>
<p>Aside from experimenting with different neural architectures, another class of models that have proven to be the state-of-the-art for sequence labeling are the transformerbased BERT language models [75].These models are pretrained for language comprehension with a masked language modeling objective on a large-scale corpus comprising millions of articles and billions of tokens.As such there are variants of the pretrained transformer language models released.We test two model variants: the original BERT model trained on the BookCorpus [76] plus English Wikipedia; and a pretrained variant released over scientific text called SciBERT [77] trained on 1.14 M papers from Semantic Scholar [4] which consists of 18% papers from the computer science domain and 82% from the biomedical domain.The large-scale transformer language models obtained pretrained deep bidirectional representations from the unlabeled text by jointly conditioning on both left and right context in all layers.To obtain state-of-the-art models for downstream tasks, the pretrained model parameters are then finetuned via a task-specific architecture taking as input a task-specific dataset.For NER sequence labeling, the finetuning model consists of three components: (a) a token embedding layer comprising a per-sentence sequence of tokens, where each token is represented as a concatenation of BERT word embeddings and CNN-based character embeddings [68], (b) a token-level encoder with two stacked bidirectional LSTMs [64], and (c) a Conditional Random Field (CRF) based tag decoder [68].Note the two features columns discussed earlier in the dataset section are not relevant for BERT models, thus can be removed from the data or replaced by dummy tokens.The dataset for BERT models is also released https: //github.com/jd-coderepos/contributions-ner-agri/tree/main/BERT-input-format(accessed on 14 January 2024).For implementation purposes, we use the scikit-learn wrapper to finetune the two BERT variants based on the https://github.com/charles9n/bert-sklearn(accessed on 14 January 2024) package.Furthermore, we experiment with BERT-base-cased and SciBERT-base-cased pretrained models, respectively.The best model hyperparameters are released in our Jupyter notebook created for experimental purposes also available in our code repo.</p>
<p>Summarily, to investigate a state-of-the-art neural sequence labeler, we experiment with the "Char CNN + Word BiLSTM + CRF" neural architecture which were an early class of models offering best performances on sequence labeling tasks, where the word embeddings are computed directly on the training corpus or obtained from fixed word embedding models, e.g., GloVe.As a second class of models we experiment with a BERTbased transformer sequence labeler that obtains contextualized embeddings from a largescale pretrained model and is finetuned on our downstream Agri-NER task based on our annotated corpus.A pictorial depiction of our end-to-end sequence labeling architecture is shown in Figure 4.</p>
<p>Evaluation Metrics</p>
<p>Evaluations are considered in two main settings: 1. strict, i.e., exact match; and 2. relaxed, i.e., inexact match where the gold answer is checked to be contained in the predicted answer.We elaborate on the relaxed match setting with an example.Given a title "Woody vegetation dynamics in a communally utilised semi-arid savanna in Bushbuckridge, South Africa" where "Woody vegetation dynamics" is annotated as research problem, if the machine predicts "vegetation dynamics", then this is marked as a true inexact match since two of the tokens in the gold-standard annotation are present in the prediction.In both settings, the standard Precision, Recall, and F1 score metrics are applied at the phrase level.Our phrase-based evaluation script can be accessed at https://github.com/jd-coderepos/contributions-ner-agri/blob/main/scripts/evaluate.py(accessed on 14 January 2024).</p>
<p>Experiments</p>
<p>In this section, we present the results and discuss observations from our two main sequence labeling strategies, respectively, and further contrast them w.r.t. each other.On the one hand, the "Char CNN + Word BiLSTM + CRF" sequence labeler resulted in 16 core experiments: one with no additional features, one with additional POS features, one with additional generic domain NER tag features, one with both POS and NER tags.Each of the four experiments were conducted in two scenarios: without and with GloVe embeddings.And each of the eight experiments were repeated in two tag encoding scenarios as IOBES and IOB tags.On the other hand, the BERT-based sequence labeler resulted in four total experiments: one with the BERT model variant and a second with the SciBERT model variant.And the two experiments repeated in the two tag encoding scenarios as IOBES and IOB tags.Thus overall 20 main experiments were conducted with additional sub-experiments within each category for model hyperparameter tuning.</p>
<p>The 16 core experiment results from the "Char CNN + Word BiLSTM + CRF" sequence labeler are reported in Table 5.And the four core experiment results from the transformer models are reported in Table 6.In the two tables, respectively, the best results for each of the precision, recall, and f-score metrics are highlighted in the bold, with the best F-scores overall in the exact versus inexact evaluation settings underlined.Next we discuss the experimental results with respect to five main research questions (RQ).To answer this question, we examine the results reported in Table 5.Both tagging settings i.e., IOBES and IOB obtained improved scores with the additional features.On the one hand, the IOB tag representation experiments reported highest performances from NER tags.On the other hand, the IOBES tag representations, which constituted a larger classification space, benefited from the enriched feature representation space including both POS and the generic NER tags.</p>
<p>RQ2:</p>
<p>Was initializing the word embeddings space with statically encoded embeddings from GloVe beneficial to the "Char CNN + Word BiLSTM + CRF" neural sequence labeler?</p>
<p>Contrasting the alternative rows in Table 5, we see that for each experimented feature setting, initialization of the word embeddings space with the precomputed GloVe embeddings obtained a better performing sequence labeler.Thus projecting the words in our dataset into an externally predefined semantic space formed from a larger external corpus was indeed more beneficial than computing words embeddings from the restricted space of the just the Agri-NER corpus.</p>
<p>RQ3: Which of the tag sequence representations, i.e., IOB versus IOBES, constituted the most effective task representation?</p>
<p>From the "Char CNN + Word BiLSTM + CRF" sequence labeler results reported in Table 5, the results were not conclusive.In the exact match settings, the IOBES tag sequence reported an insignificant 0.05% improvement with 60.85% F1 over the results from the IOB tag representation.In the inexact match settings, the IOB tag representation reported a 1% improvement with 64.72% F1 over the results from the IOBES tag representation.From the BERT-based sequence labeler results reported in Table 6, the results showed the IOB tag representation was the better format.In the exact match settings, the results with the IOB representation was at 64.19% F1-2 points above the results with the IOBES representation at 62.47% F1.In the inexact match settings, again the results with the IOB tag representation was better at 67.91% F1-1 point above the results with the IOBES representation at 66.63% F1.</p>
<p>RQ4:</p>
<p>Which method contrasting the results from the "Char CNN + Word BiLSTM + CRF" neural sequence labeler versus the BERT-based labeler produced the best results?</p>
<p>We examine the underlined results reported in Tables 5 and 6 from the "Char CNN + Word BiLSTM + CRF" sequence labeler and the BERT-based labeler, respectively.The BERT-based model significantly outperforms the "Char CNN + Word BiLSTM + CRF" in both settings including exact match with 64.19% F1 versus 60.85% inexact match with 67.91% F1 versus 64.72% F1.</p>
<p>In light of the better performing BERT-based sequence labeler, revisiting RQ3, we claim that the IOB tag sequence representation is ideal given the ORKG Agri-NER corpus.</p>
<p>RQ5: Was a sequence labeler finetuned on a scholarly domain pretrained BERT variant more effective than a pretrained BERT variant on the generic domain?</p>
<p>Finally, comparing results between the scholarly domain SciBERT versus the generic domain BERT, we see that the generic domain BERT variant outperformed SciBERT.We can attribute these unexpected results observation on the fact that SciBERT is pretrained on data largely from the biomedical domain which is different from the agricultural domain.It remains to be explored in future work whether we can achieve boosted performances of our Agri-NER task given a large-scale pretrained model also covering agriculture.</p>
<p>Our source code is publicly released here https://gitlab.com/TIBHannover/orkg/nlp/experiments/orkg-agriculture-ner (accessed on 14 January 2024) with the MIT license.Based on the experimental results, the best model is released as the ORKG Agri-NER service available in two formats: 1) as a Python package at https://orkg-nlp-pypi.readthedocs.io/en/latest/services/services.html(accessed on 14 January 2024), and as a REST API that can be invoked directly online via the interactive documentation at https://orkg.org/nlp/api/docs#/annotation/annotates_agri_paper_annotation_agriner_post (accessed on 14 January 2024).</p>
<p>Discussion</p>
<p>"The first step is putting data on the Web in a form that machines can naturally understand, or converting it to that form.This creates what I call a Semantic Web-a web of data that can be processed directly or indirectly by machines".[29] The Web flourished based on the hypertext linked information principle.Hypertext linking of information on the Web as a global information space revolutionized information access by enabling users to traverse, search, share, and browse information with the all-pervasive technology of web browsers.With the formalization of the Semantic Web [29], these same principles that applied to information represented as document descriptions are being applied to data.This has fostered the evolution of the Web as a global information space of only linked documents to one where both documents and data are linked.A prerequisite to realizing the Semantic Web is what is called as establishing a Linked Open Data Cloud (LOD Cloud).Linked Data constitutes the LOD.In other words, the LOD Cloud is a KG that manifests as a Semantic Web of Linked Data via a small set of standardized technologies: URIs and HTTP as identification and access mechanism for data resources on the web, and RDF as content representation format.Thus Linked Data realizes the vision of evolving the Web into a global data commons as what is defined as the Semantic Web, allowing applications to operate on top of an unbounded set of data sources, via standardised access mechanisms [78].The LOD Cloud https://lod-cloud.net/(accessed on 14 January 2024) constitutes the central hub that allow users to start browsing in one open-access submitted data source and then navigate along links into related data sources.This global data space connects data from diverse domains such as geography, government, life sciences, linguistics, media, scholarly publications, social networks etc.Without the Linked Data creation tools and technologies, earlier data creation processes always resulted in data silos worldwide with no access means of interaction or interoperability.Now, however, leveraging a small standardized set of technologies of the Linked Data creation paradigm, any data source can be submitted to the LOD Cloud fostering the building of the Semantic Web.In light of these technological inventions, the FAIR guiding principles [3] for scientific data creation can indeed be a practice.</p>
<p>The next natural question is, is the ORKG Agri-NER corpus released in the LOD Cloud?The response is not yet.However in this last concluding section of the paper, we set the stage for realizing the vision of releasing the ORKG Agri-NER corpus within the LOD Cloud to be taken up in future work.The research paradigms underlying the NLP production of data and the Semantic Web production of data over a new domain are particularly beset by several steps of methodological and technological considerations.This merits dedicated discussions of the respective paradigm research processes and outcomes.The NLP data production lifecycle focuses on instantiated data annotation and all the steps that precede it including selecting a task and defining a conceptual annotation space for the task.While the Semantic Web data production lifecycle focuses on data representation in a strict machine-readable semantic representation language such as RDF or OWL to facilitate axiomatic machine reasoning.In other words, it is a natural product of the following ingredients.(1) Open Standards-such as URI, URL, HTTP, HTML, RDF, RDF-Turtle (and other RDF Notations), the SPARQL Query Language, the SPARQL Protocol, and SPARQL Query Solution Document Types.And, (2) A modern DBMS platform-Virtuoso from OpenLink Software or Neo4J (https://neo4j.com/,accessed on 14 January 2024) as a graph database management system.This work has described the NLP NER research paradigm over the novel agricultural domain.As such it entailed presenting the selected contribution-centric NER task for the agricultural domain, defining the selected entity types for annotation, and annotating a corpus of 5500 paper titles as instantiated data for Agri-NER.In following work, the aim is to address the Semantic Web research paradigm such that scholarly contribution resources in the agricultural domain will be made into FAIR and reusable Linked Data.Linked Data refers to data published on the Web in such a way that it is machine-readable, its meaning explicitly defined, it is linked to other external data sets, and can in turn be linked to from external data sets [78].Machine-readability will utilize URIs and HTTP as identification and access mechanisms and RDF content representation.Meaning definition will be handled via a schema model.Links to external datasets will be handled as linking to the AGROVOC ontology [49] as it is the only other semantic representation model for the agricultural domain.As already alluded to, Agri-NER and AGROVOC prescribe different conceptual spaces for how the entities are expected to be processed by machines.Specifically, AGROVOC enables the processing of the entities within a terminologically defined semantic space.It provides concepts resolved to URIs and supplemented with RDF descriptions of thousands of terms in the FAO's area of interest.While ORKG Agri-NER permits the processing of the entities w.r.t.their functional role as reflecting the contribution of a scholarly work.By aiming to link the entities in our ORKG Agri-NER corpus to AGROVOC, we enable users to fetch an enriched representation of the terms such as: What is its terminological definition?, or What are the alternative term namings across languages?, or Which other data linkings can be facilitated via the Linked Data source in consideration?For instance, "Borneo" a LOCATION entity type from Agri-NER is first resolved to AGROVOC concept for Borneo as https://agrovoc.fao.org/browse/agrovoc/en/page/c_1017 (accessed on 14 January 2024).This Linked Data enriches the term with its definition, alternate names of Borneo in various languages, etc.Furthermore, the AGROVOC Linked Data connects to the DBpedia Linked Data source [79].Thus via AGROVOC the concept Borneo is enriched via a DBpedia knowledge source link https://dbpedia.org/page/Borneo(accessed on 14 January 2024) which offers additional information such as its total geographical area, geo-coordinates, the total population size etc.In this way, by adopting data linking the Linked Data principles will foster scaling the development approach of Agri-NER beyond a fixed, predefined data silo of capturing contribution-centric entities, to encompass a larger number of relevant structured knowledge sources on the LOD cloud comprising heterogeneous data models that each constitute unique semantic spaces for the machine-actionability of terms.</p>
<p>Toward FAIR, Reusable Scholarly Contributions in Agriculture, for machine readability and semantic representation, the schema and URI space will be implemented via global property and resource identifiers within the ORKG web ecosphere at https://orkg.org/(accessed on 14 January 2024).And for obtaining Linked Data, AGROVOC will be utilized.In this section, we offer concrete implementation details that contrast ORKG Agri-NER and AGROVOC models as potential related Linked Data sources.The preliminary findings discussed in this paragraph are obtained w.r.t. the following research question.RQ6: How many ORKG Agri-NER entities can be mapped to AGROVOC?To answer the question, a programmatic process flow depicted in Figure 5 was established.The process was fairly straightforward.Given the terms annotated in the Agri-NER model, query the concept nodes in AGROVOC with the terms.For those terms that were found as a whole, the corresponding AGROVOC concept URI is the desired retrieval unit.For the terms that were not found as a whole, they were iteratively split as the longest spanning subphrases with subphrase lengths as: original phrase length − 1 ≤ range ≤ 1.The link retrieval step was stopped when one or more of the subphrases for a specified subphrase length could be resolved to one or more AGROVOC concepts.Resultingly, some statistical insights shown in Table 7 were obtained.This will form the basis of Linked Data creation in future work toward realizing FAIR, Reusable Scholarly Contributions in Agriculture.Of all the entities annotated in Agri-NER, 16% of them are found as AGROVOC concepts.And 53.75% of the Agri-NER entities are found as subphrase AGROVOC concepts.Per Agri-NER entity type, the ones that were most linkable involved the least amount of subjectivity in phrasal boundary determination.One way of gauging the subjective boundary determination decisions for Agri-NER entity types from the least to most can be based on the proportion of the Agri-NER entity type terms that could be directly resolved to AGROVOC.From the least to the most, they were: LOCATION, TECHNOLOGY, PROCESS, METHOD, RESEARCH PROBLEM, RESOURCE, and SOLUTION.The corpus used in the analysis is publicly released https://github.com/jd-coderepos/contributions-ner-agri/tree/main/AGROVOC-linked-data-analysis (accessed on 19 January 2024).</p>
<p>Table 7. Statistics of the terms in the Open Research Knowledge Graph Agriculture Named Entity Recognition (ORKG Agri-NER) corpus that were linkable to the AGROVOC ontology overall (first three rows) and per the seven entity types annotated.The parenthesized numbers represent the proportion of entity phrases that could only be resolved to AGROVOC by one or more of their longest span subphrases.</p>
<p>Statistic Parameter Counts
%</p>
<p>Future Directions</p>
<p>As we advance in the field of Agriculture NER, the integration and utilization of large language models (LLMs) present a promising avenue for future research and development [80].These models, known for their deep learning capabilities and extensive training on diverse datasets, offer significant potential in enhancing the accuracy and scope of entity recognition in agricultural texts.The application of LLMs could revolutionize the way we extract, process, and interpret complex scientific entities, leading to more nuanced and contextually aware recognition systems.In context of furthering Agri-NER research, a key direction for future work is the customization of LLMs to better understand and interpret the unique terminologies and concepts specific to agriculture.This involves training models on domain-specific datasets such as ours, including scholarly articles and technical documents in the agricultural sector.Such specialized training would enable LLMs to accurately identify and classify a wide range of agricultural entities, thereby enhancing the overall quality and reliability of knowledge extraction in this field.</p>
<p>Conclusions</p>
<p>In this paper, we have introduced the Open Research Knowledge Graph Agriculture Named Entity Recognition (ORKG Agri-NER) corpus and service for contribution-centric scientific entity extraction and classification in the agricultural domain.The ORKG Agri-NER corpus is a benchmark for evaluating scientific entity extraction and classification in agriculture, using a generic conceptual formalism.This paper presents a baseline set of results on the benchmark leveraging state-of-the-art sequence labeling neural architectures and transformer models.The paper also presents a 3-step automatic entity resolution procedure for mapping scientific entities to the AGROVOC ontology.The goal of this work is to provide a foundation for future research on automatic discovery of scientific entities in agricultural literature.</p>
<p>In conclusion, the development of the ORKG Agri-NER corpus and service represents a significant advancement in the field of agricultural NER.The utilization of machineactionable representations and strategic reading techniques has demonstrated the potential to enhance the accessibility and interpretability of scholarly contributions in agriculture.The establishment of standardized entity types and the utilization of machine learning systems have shown promising results in the extraction and classification of scientific entities.Moving forward, the FAIR and reusable scholarly contributions in agriculture, facilitated by the ORKG Agri-NER service, hold the potential to significantly impact research, business, and organizational stakeholders within the agricultural domain.</p>
<p>Funding: Supported by TIB Leibniz Information Centre for Science and Technology, the EU H2020 ERC project ScienceGraph (GA ID: 819536) and the BMBF project SCINEXT (GA ID: 01lS22070).</p>
<p>Data Availability Statement:</p>
<p>The dataset developed for this study can be found on the Github platform at https://github.com/jd-coderepos/contributions-ner-agri,accessed on 14 January 2024.</p>
<p>Figure 1 .
1
Figure 1.Demonstration of strategic reading of machine-actionable representations of 3 scholarly contributions on the problem of Question Answering in the Open Research Knowledge Graph (ORKG), which generates aggregated comparative views from the graph-based semantic research contribution descriptions.</p>
<p>Figure 2 .
2
Figure 2. Transition from document-based to contribution-centric named entity recognition servicepowered knowledge-based scholarly communication.</p>
<p>Figure 3 .
3
Figure 3.The seven core concepts proposed to capture contributions from scholarly articles in the Agriculture domain.</p>
<p>Figure 4 .
4
Figure 4.The traditional "Char CNN + Word BiLSTM + CRF" neural sequence labeling architecture for the input "Woody vegetation dynamics".</p>
<p>Figure 5 .
5
Figure 5. Process flow for linking Agri-NER entities to the AGROVOC ontology concept terms as an authoritative Linked Data source in the domain of Agriculture.</p>
<p>Table 1 .
1
A listing of 15 different research domains in the table columns that were observed in a corpus of 5500 scholarly publication titles in Agriculture.
Agriculture Research Domainsfertilizersdifferent natures of agricultural produc-restoration and management of planttion communities such as the winter-systemsrainfall desert communitymicroalgae refineriesfirst reports on plant findingsinvestigation of biochemical activities inplant speciesclimatic factors such as fires affectingappraisals of agricultural productsin vitro cultivation of plant speciesfood productionland degradation and cultivation research competitive growth advantages ofcharacterizing seeds or plant speciespaired cultivationantibacterial and chemical byproductscreation of taxonomic lists of cropsimporting new plant species across regionsfrom plants</p>
<p>[19]rticle can address one or more research problems.E.g., seed germination, humoral immunity in cattle, sunbird pollination, seasonal and inter-annual soil CO 2 efflux, etc.Generally, RESEARCH PROBLEM mentions are often found in the article Title, Abstract, or Introduction in the context of discourse discussions on the theme of the study; otherwise in the Results section in the context of findings discussions on the theme of the study.Often LOCATION, in terms of relevance to the research theme, is the place where the study is conducted or a place studied for its RESOURCE or PROCESSes w.r.t. a RESEARCH PROBLEM.LOCATION mentions can be as fine-grained as having regional boundaries or as broad as having continental boundaries.E.g., Cape Floristic Region of South Africa, winter rainfall area of South Africa, sahel zone of Niger, southern continents, etc. • METHOD.This concept imported from the Computer Science domain pertains to existing protocols used to support the solution[19].The interpretation or definition of the concept similarly holds for the agricultural domain.It is a predetermined way of accomplishing an objective in terms of prespecified set of steps.E.g., On-farm comparison, semi-stochastic models, burrows pond rearing system, bradyrhizobium inoculation, electronic olfaction, systematic studies, etc. • SOLUTION.It is a phrasal succinct mention of the novel contribution or discovery of a work that solves the RESEARCH PROBLEM [19].The SOLUTION entity type is characterized by a long-tailed distribution of mentions determined by the new research discoveries made.The SOLUTION of one work can be used as a METHOD or TECHNOL-OGY or comparative baselines in subsequent research works.Of all the entity types introduced in this work, SOLUTION like RESEARCH PROBLEM is specifically tailored</p>
<p>[49]SOURCE.They are either man-made or naturally occurring tangible objects that are directly utilized in the process of a research investigation as material to facilitate a study's research findings."Resourcesarethingsthatareusedduringaproduction process or that are required to cover human needs in everyday life"[53].E.g., RE-SOURCE 'pesticides' used to study the RESEARCH PROBLEM 'survival of pines'; the PROCESS 'repeated migrations' studied over RESOURCE 'southern African members of the genus Zygophyllum'; RESOURCE 'Soil aggregate-associated heavy metals' studied in LOCATION 'subtropical China'.Resources are used to either address the RESEARCH PROBLEM or to obtain the SOLUTION.•PROCESS.It is defined as an event with a continuous time-frame that is pertinent with a specific function or role to the theme of a particular investigation or research study.As defined in the AGROVOC ontology[53], a PROCESS can be a set of interrelated or interacting activities which transforms inputs into outputs, or simply a naturally occurring phenomenon that is studied.E.g., irradiance, environmental gradient, seasonal variation, quality control, salt and alkali stresses, etc. • LOCATION.Includes all geographical locations in the world seen similar to the AGROVOC location concept[49]as a 'point in space'.</p>
<p>Table 2 .
2
Six example instances in the ORKG Agri-NER corpus of annotated paper titles with the seven contribution-centric entity types, viz.RESOURCE, RESEARCH PROBLEM, PROCESS, LOCATION, METHOD, SOLUTION, and TECHNOLOGY.Comparing pressures on national parks in Ghana and Tanzania: The case of Mole and Tarangire National Parks RESEARCH PROBLEM: Comparing pressures on national parks LOCATION: Ghana, Tanzania, Mole and Tarangire National Parks
Annotated Paper Titles</p>
<p>Table 3 .
3
Overall statistics of the gold-standard Open Research Knowledge Graph Agriculture Named Entity Recognition (ORKG Agri-NER) corpus.Corpus statistics in terms of instantiated entities per entity type are shown in Table4.We see that among the seven entity types, RESOURCE and RESEARCH PROBLEM are highly predominant as contribution-centric entity annotations.
Statistic ParameterCountsNum. Title Tokens overall71,632Max., Min., Avg. Num. Tokens/Title65, 2, 13.75Num. Entity Tokens overall47,608Max., Min., Avg. Num. Tokens/Entity15, 1, 3.12Num. Entities15,261Num. Unique Entities10,406Max., Min., Avg. Num. Entities/Title9, 0, 2.93</p>
<p>Table 4 .
4
Statistics of the gold-standard Open Research Knowledge Graph Agriculture Named Entity Recognition (ORKG Agri-NER) corpus per the seven entity types annotated.The parenthesized numbers represent the unique entity counts.
Entity TypeCountsNum. RESOURCE5490 (4073)Num. RESEARCH PROBLEM4707 (3403)Num. PROCESS1789 (1525)Num. LOCATION1525 (776)Num. METHOD1364 (940)Num. SOLUTION250 (221)Num. TECHNOLOGY136 (113)</p>
<p>Table 5 .
5
Results from the state-of-the-art "Char CNN + Word BiLSTM + CRF" Neural Sequence Labeler.Numbers in bold are the highest score for each metric; numbers underlined are the overall highest exact and inexact match scores, respectively.
IOBESIOBExact MatchInexact MatchExact MatchInexact MatchPRF1PRF1PRF1PRF1no features56.38 62.27 59.18 59.165.27 62.03 54.62 59.47 56.94 58.52 63.71 61.0+GloVe57.74 62.79 60.16 60.86 66.19 63.41 57.963.49 60.57 61.64 67.59 64.48POS57.11 61.88 59.40 60.24 65.27 62.66 56.060.53 58.18 60.42 65.362.76+GloVe57.563.58 60.38 60.09 66.45 63.11 56.63 63.11 59.760.45 67.38 63.73NER56.12 61.158.558.39 63.58 60.88 56.43 61.59 58.960.44 65.96 63.08+GloVe57.563.58 60.38 60.09 66.45 63.11 58.32 63.49 60.862.09 67.59 64.72POS + NER56.66 61.75 59.09 59.52 64.88 62.09 55.93 61.77 58.71 59.88 66.14 62.85+GloVe58.23 63.71 60.85 60.98 66.71 63.72 55.93 61.77 58.71 59.88 66.14 62.85</p>
<p>Table 6 .
6
Results from the state-of-the-art BERT-based Transformer Language Models.Numbers in bold are the highest score for each metric; numbers underlined are the overall highest exact and inexact match scores, respectively.
IOBESIOBExact MatchInexact MatchExact MatchInexact MatchPRF1PRF1PRF1PRF1BERT-Base-Cased58.74 66</p>
<p>.71 62.47 62.64 71.15 66.63 60.58 68.25 64.19 64.09 72.2 67.91
SciBERT-SciVocab-Cased58.78 66.06 62.2 62.49 70.23 66.13 59.15 66.09 62.43 63.63 71.11 67.17RQ1: How effective were the additional POS tag and generic domain NER tag features inthe "Char CNN + Word BiLSTM + CRF" neural sequence labeler?
Acknowledgments:The author would like to acknowledge the ORKG Team for support with implementing the ORKG frontend interfaces of the Agriculture NER Annotator service.Conflicts of Interest:The author declares no conflict of interest.The funders had no role in the design of the study; in the collection, analyses, or interpretation of data; in the writing of the manuscript; or in the decision to publish the results.AbbreviationsThe
R Johnson, A Watkinson, M Mabe, The STM Report: An Overview of Scientific and Scholarly Publishing; International Association of Scientific, Technical and Medical Publishers. Oxford, UK2018</p>
<p>Strategic reading, ontologies, and the future of scientific publishing. A H Renear, C L Palmer, 10.1126/science.1157784Science. 3252009</p>
<p>The FAIR Guiding Principles for scientific data management and stewardship. M D Wilkinson, M Dumontier, I J Aalbersberg, G Appleton, M Axton, A Baak, N Blomberg, J W Boiten, L B Da Silva Santos, P E Bourne, 10.1038/sdata.2016.182016. 1600183</p>
<p>Construction of the Literature Graph in Semantic Scholar. W Ammar, D Groeneveld, C Bhagavatula, I Beltagy, M Crawford, D Downey, J Dunkelberger, A Elgohary, S Feldman, V Ha, Proceedings of the NAACL-HLT. the NAACL-HLTNew Orleans, LA, USAJune 2018</p>
<p>Improving access to scientific literature with knowledge graphs. S Auer, A Oelen, M Haris, M Stocker, J D'souza, K E Farfar, L Vogt, M Prinz, V Wiens, M Y Jaradeh, 10.1515/bfp-2020-2042Bibl. Forsch. Prax. 442020</p>
<p>Semeval-2010 task 5: Automatic keyphrase extraction from scientific articles. S N Kim, O Medelyan, M Y Kan, T Baldwin, Proceedings of the 5th International Workshop on Semantic Evaluation. the 5th International Workshop on Semantic EvaluationUppsala, SwedenJuly 2010</p>
<p>Analyzing the Dynamics of Research by Extracting Key Aspects of Scientific Papers. S Gupta, C Manning, Proceedings of the 5th International Joint Conference on Natural Language Processing. the 5th International Joint Conference on Natural Language ProcessingChiang Mai, Thailand8-13 November 2011</p>
<p>The ACL RD-TEC 2.0: A Language Resource for Evaluating Term Extraction and Entity Recognition Methods. B Qasemizadeh, A K Schumann, Proceedings of the Tenth International Conference on Language Resources and Evaluation (LREC'16). the Tenth International Conference on Language Resources and Evaluation (LREC'16)Portorož, SloveniaMay 2016</p>
<p>Semeval-2015 task 13: Multilingual all-words sense disambiguation and entity linking. A Moro, R Navigli, Proceedings of the 9th International Workshop on Semantic Evaluation. the 9th International Workshop on Semantic EvaluationDenver, CO, USASemEval 2015. June 2015</p>
<p>ScienceIE-Extracting Keyphrases and Relations from Scientific Publications. I Augenstein, M Das, S Riedel, L Vikraman, A Mccallum, Semeval, 10.18653/v1/S17-2091Proceedings of the 11th International Workshop on Semantic Evaluation (SemEval-2017). the 11th International Workshop on Semantic Evaluation (SemEval-2017)Vancouver, BC, Canada2017. August 201710</p>
<p>Semantic relation extraction and classification in scientific papers. K Gábor, D Buscaldi, A K Schumann, B Qasemizadeh, H Zargayouna, T Charnois, Semeval, Proceedings of the 12th International Workshop on Semantic Evaluation. the 12th International Workshop on Semantic EvaluationNew Orleans, LA, USA2018. June 20187</p>
<p>Multi-Task Identification of Entities, Relations, and Coreferencefor Scientific Knowledge Graph Construction. Y Luan, L He, M Ostendorf, H Hajishirzi, Proceedings of the Conference Empirical Methods Natural Language Process (EMNLP). the Conference Empirical Methods Natural Language Process (EMNLP)Brussels, Belgium31 October-4 November 2018</p>
<p>Identification of Tasks, Datasets, Evaluation Metrics, and Numeric Scores for Scientific Leaderboards Construction. Y Hou, C Jochim, M Gleize, F Bonin, D Ganguly, 10.18653/v1/P19-1513Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics. the 57th Annual Meeting of the Association for Computational LinguisticsFlorence, Italy28 July-2 August 2019</p>
<p>Ai-kg: An automatically generated knowledge graph of artificial intelligence. D Dessì, F Osborne, D Reforgiato Recupero, D Buscaldi, E Motta, H Sack, Proceedings of the International Semantic Web Conference. the International Semantic Web ConferenceOnlineNovember 2020</p>
<p>. Springer, 2020Berlin/HeidelbergGermany</p>
<p>Grounding Scientific Entity References in STEM Scholarly Content to Authoritative Encyclopedic and Lexicographic Sources. D' Souza, J Hoppe, A Brack, A Jaradeh, M Y Auer, S Ewerth, R The, Stem-Ecr Dataset, Proceedings of the 12th Language Resources and Evaluation Conference. the 12th Language Resources and Evaluation ConferenceMarseille, FranceMay 2020</p>
<p>SemEval-2021 Task 11: NLPContributionGraph-Structuring Scholarly NLP Contributions for a Research Knowledge Graph. D' Souza, J Auer, S Pedersen, T , 10.18653/v1/2021.semeval-1.44Proceedings of the 15th International Workshop on Semantic Evaluation. the 15th International Workshop on Semantic EvaluationSemEval-2021), Online, 5-6 August 2021</p>
<p>Automated Mining of Leaderboards for Empirical AI Research. S Kabongo, J D'souza, S Auer, Proceedings of the International Conference on Asian Digital Libraries (ICADL 2021). the International Conference on Asian Digital Libraries (ICADL 2021)Berlin/Heidelberg, GermanySpringer1-3 December 2021. 2021</p>
<p>Pattern-based acquisition of scientific entities from scholarly article titles. D' Souza, J Auer, S , Proceedings of the International Conference on Asian Digital Libraries (ICADL 2021). the International Conference on Asian Digital Libraries (ICADL 2021)Berlin/Heidelberg, GermanySpringerOnline, 1-3 December 2021. 2021</p>
<p>Computer science named entity recognition in the open research knowledge graph. D' Souza, J Auer, S , Proceedings of the International Conference on Asian Digital Libraries (ICADL 2022). the International Conference on Asian Digital Libraries (ICADL 2022)Hanoi, Vietnam; Berlin/Heidelberg, GermanySpringer30 November-2 December 2022. 2022</p>
<p>Overview of results of the MUC-6 evaluation. B Sundheim, Proceedings of the Sixth Message Understanding Conference (MUC-6). the Sixth Message Understanding Conference (MUC-6)Columbia, MA, USANovember 1995</p>
<p>MUC-7 named entity task definition. N Chinchor, P Robinson, Proceedings of the Seventh Conference on Message Understanding. the Seventh Conference on Message UnderstandingFairfax, VA, USA29 April-1 May 199829</p>
<p>Introduction to the CoNLL-2003 Shared Task: Language-Independent Named Entity Recognition. E T K Sang, F De Meulder, Proceedings of the Seventh Conference on Natural Language Learning at HLT-NAACL. the Seventh Conference on Natural Language Learning at HLT-NAACLEdmonton, AB, Canada31 May-1 June 2003</p>
<p>OntoNotes: The 90% solution. E Hovy, M Marcus, M Palmer, L Ramshaw, R Weischedel, Proceedings of the Human Language Technology Conference of the NAACL, Companion Volume: Short Papers. the Human Language Technology Conference of the NAACL, Companion Volume: Short PapersNew York, NY, USAJune 2006</p>
<p>E E T Batbayar, S Tsogt-Ochir, M Oyumaa, W C Ham, K T Chong, Development of ISO 11783 Compliant Agricultural Systems: Experience Report. Berlin/Heidelberg, GermanySpringer2019Automotive Systems and Software Engineering</p>
<p>ISO 11783-Standard and its Implementation. T Oksanen, M Öhman, M Miettinen, A Visala, IFAC Proceedings Volumes. Amsterdam, The NetherlandsElsevier200538</p>
<p>The use of EPPO Codes in tropical weed science. Le Bourgeois, T Marnotte, P Schwartz, M , Proceedings of the EPPO Codes Users Meeting 5th Webinar. the EPPO Codes Users Meeting 5th WebinarJune 2021</p>
<p>Semantic publishing: The coming revolution in scientific journal publishing. D Shotton, 10.1087/2009202Learn. Publ. 222009</p>
<p>A chemotaxonomic reappraisal of the Section Ciconium Pelargonium (Geraniaceae). M T Lis-Balchin, 10.1016/S0254-6299(15)30657-8S. Afr. J. Bot. 621996</p>
<p>The semantic web. T Berners-Lee, J Hendler, O Lassila, 10.1038/scientificamerican0501-34Sci. Am. 2842001</p>
<p>A core ontology for the semantic representation of research findings. S Fathalla, S Vahdati, S Auer, C Lange, Semsur, 10.1016/j.procs.2018.09.015Procedia Comput. Sci. 1372018</p>
<p>Toward Representing Research Contributions in Scholarly Knowledge Graphs Using Knowledge Graph Cells. L Vogt, J D'souza, M Stocker, S Auer, Proceedings of the JCDL'20. the JCDL'20Wuhan, ChinaAugust 2020</p>
<p>Dublin Core Metadata Initiative Dublin Core Metadata Element Set, Version 1.1; DCMI Usage Board. Board Dcmi Usage, 2008Metro ManilaPhilippines</p>
<p>Libraries, languages of description, and linked data: A Dublin Core perspective. T Baker, Library Hi Tech. 302012</p>
<p>The document components ontology (DoCO). A Constantin, S Peroni, S Pettifer, D Shotton, F Vitali, 10.3233/SW-150177Semant. Web. 72016</p>
<p>T Groza, S Handschuh, K Möller, S Decker, L A T E X Salt-Semantically Annotated, Scientific For, Publications, Proceedings of the European Semantic Web Conference. the European Semantic Web ConferenceInnsbruck, Austria; Berlin/Heidelberg, GermanySpringerJune 2007. 2007</p>
<p>Ontology of Rhetorical Blocks (orb). P Ciccarese, T Groza, June 2011. May 2012Editor's Draft</p>
<p>The introduction, methods, results, and discussion (IMRAD) structure: A fifty-year survey. L B Sollaci, M G Pereira, J. Med. Libr. Assoc. 923642004</p>
<p>An ontology of scientific experiments. L N Soldatova, R D King, 10.1098/rsif.2006.0134J. R. Soc. Interface. 32006</p>
<p>Reusing ontologies on the Semantic Web: A feasibility study. E Simperl, 10.1016/j.datak.2009.02.002Data Knowl. Eng. 682009</p>
<p>Ontologies for describing bibliographic resources and citations. S Peroni, D Shotton, Fabio, Cito, 10.1016/j.websem.2012.08.001J. Web Semant. 172012</p>
<p>Describing bibliographic references in RDF. A Di Iorio, A G Nuzzolese, S Peroni, D M Shotton, F Vitali, Proceedings of the SePublica. the SePublicaGreece25 May 2014</p>
<p>Towards a knowledge graph representing research findings by semantifying survey articles. S Fathalla, S Vahdati, S Auer, C Lange, Proceedings of the International Conference on Theory and Practice of Digital Libraries. the International Conference on Theory and Practice of Digital LibrariesThessaloniki, Greece; GermanyBerlin/Heidelberg18-21 September 2017. 2017</p>
<p>The SWRC Ontology-Semantic Web for Research Communities. Y Sure, S Bloehdorn, P Haase, J Hartmann, D Oberle, Progress in Artificial Intelligence: 12th Portuguese Conference on Artificial Intelligence, EPIA 2005. Covilhã, Portugal; GermanyBerlin/Heidelberg5-8 December 2005. 200512</p>
<p>Linked Science Core Vocabulary Specification. A Baglatzi, T Kauppinen, C Keßler, 2011. 14 January 2024Tech. Rep</p>
<p>A Large-Scale Knowledge Graph of Research Entities and Claims in Computer Science. D Dessí, F Osborne, D Reforgiato Recupero, D Buscaldi, E Motta, Cs-Kg, Proceedings of the International Semantic Web Conference. the International Semantic Web ConferenceHangzhou, China; GermanyBerlin/HeidelbergOctober 2022. 2022</p>
<p>SciREX: A Challenge Dataset for Document-Level Information Extraction. S Jain, M Van Zuylen, H Hajishirzi, I Beltagy, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics. the 58th Annual Meeting of the Association for Computational LinguisticsOnline, 5-10 July 2020</p>
<p>End-to-End Construction of NLP Knowledge Graph. I Mondal, Y Hou, C Jochim, 10.18653/v1/2021.findings-acl.165Proceedings of the Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021. the Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021Bangkok, ThailandAugust 2021</p>
<p>Zero-Shot Entailment of Leaderboards for Empirical AI Research. S Kabongo, J D'souza, S Auer, 10.1109/JCDL57899.2023.00042Proceedings of the 2023 ACM/IEEE Joint Conference on Digital Libraries (JCDL). the 2023 ACM/IEEE Joint Conference on Digital Libraries (JCDL)Santa Fe, NM, USAJune 2023</p>
<p>AGROVOC: The linked data concept hub for food and agriculture. I Subirats-Coll, K Kolshus, A Turbati, A Stellato, E Mietzsch, D Martini, M Zeng, 10.1016/j.compag.2020.105965Comput. Electron. Agric. 2022, 196, 105965</p>
<p>Toward better food security using concepts from industry 5.0. Sensors. S Guruswamy, M Pojić, J Subramanian, J Mastilović, S Sarang, A Subbanagounder, G Stojanović, V Jeoti, 10.3390/s22218377202222</p>
<p>Ensuring global food security: Transforming approaches in the context of agriculture 5.0. N Baryshnikova, P Altukhov, N Naidenova, A Shkryabina, 10.1088/1755-1315/988/3/032024IOP Conf. Ser. Earth Environ. Sci. 9882022. 032024</p>
<p>Edinbarough, I. State of Industry 5.0-Analysis and identification of current research trends. A Akundi, D Euresti, S Luna, W Ankobiah, A Lopes, 10.3390/asi5010027Appl. Syst. Innov. 2022, 5, 27</p>
<p>. Agrovoc Webpage, 2022. 12 October 2022</p>
<p>Reengineering thesauri for new applications: The AGROVOC example. D Soergel, B Lauser, A Liang, F Fisseha, J Keizer, S Katz, J. Digit. Inf. 42004</p>
<p>From AGROVOC to the Agricultural Ontology Service/Concept Server. An OWL model for creating ontologies in the agricultural domain. B Lauser, M Sini, A Liang, J Keizer, S Katz, Proceedings of the Dublin Core Conference Proceedings, Dublin Core DCMI. the Dublin Core Conference Proceedings, Dublin Core DCMIManzanillo, MexicoOctober 2006</p>
<p>How Agricultural Digital Innovation Can Benefit from Semantics: The Case of the AGROVOC Multilingual Thesaurus. E Mietzsch, D Martini, K Kolshus, A Turbati, I Subirats, Eng. Proc. 202117</p>
<p>Towards an Open Research Knowledge Graph. S Auer, 2018. 14 January 2024</p>
<p>Domain-independent extraction of scientific concepts from research articles. A Brack, J D'souza, A Hoppe, S Auer, R Ewerth, Proceedings of the European Conference on Information Retrieval (ECIR 2020). the European Conference on Information Retrieval (ECIR 2020)GermanyBerlin/HeidelbergApril 2020. 2020</p>
<p>Introduction to the CoNLL-2003 Shared Task: Language-Independent Named Entity Recognition. E F T K Sang, F De Meulder, Development. 18371341</p>
<p>Stanza: A Python Natural Language Processing Toolkit for Many Human Languages. P Qi, Y Zhang, Y Zhang, J Bolton, C D Manning, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: System Demonstrations. the 58th Annual Meeting of the Association for Computational Linguistics: System DemonstrationsOnline, 5-10 July 2020</p>
<p>Text chunking using transformation-based learning. L A Ramshaw, M P Marcus, Natural Language Processing Using Very Large Corpora. Berlin/Heidelberg, GermanySpringer1999</p>
<p>Named Entity Recognition. Stanf. Lect. CS229. V Krishnan, V Ganapathy, 2005. 14 January 2024</p>
<p>Computational linguistics and deep learning. C D Manning, 10.1162/COLI_a_00239Comput. Linguist. 412015</p>
<p>Long short-term memory. S Hochreiter, J Schmidhuber, 10.1162/neco.1997.9.8.1735Neural Comput. 91997</p>
<p>Backpropagation applied to handwritten zip code recognition. Y Lecun, B Boser, J S Denker, D Henderson, R E Howard, W Hubbard, L D Jackel, 10.1162/neco.1989.1.4.541Neural Comput. 11989</p>
<p>Bidirectional LSTM-CRF models for sequence tagging. Z Huang, W Xu, K Yu, arXiv:1508.019912015</p>
<p>Character-aware neural language models. Y Kim, Y Jernite, D Sontag, A M Rush, Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence. the Thirtieth AAAI Conference on Artificial IntelligencePhoenix, AZ, USAFebruary 2016</p>
<p>End-to-end Sequence Labeling via Bi-directional LSTM-CNNs-CRF. X Ma, E Hovy, Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics. Long Papers. the 54th Annual Meeting of the Association for Computational LinguisticsBerlin, GermanyAugust 20161</p>
<p>Neural Architectures for Named Entity Recognition. G Lample, M Ballesteros, S Subramanian, K Kawakami, C Dyer, Proceedings of the 2016 Conference of the North American Chapter. the 2016 Conference of the North American ChapterSan Diego, CA, USAHuman Language TechnologiesJune 2016</p>
<p>Named entity recognition with bidirectional LSTM-CNNs. J P Chiu, E Nichols, Trans. Assoc. Comput. Linguist. 42016</p>
<p>Semi-supervised sequence tagging with bidirectional language models. M Peters, W Ammar, C Bhagavatula, R Power, Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics. Long Papers. the 55th Annual Meeting of the Association for Computational LinguisticsVancouver, BC, Canada30 July-4 August 20171</p>
<p>GloVe: Global Vectors for Word Representation. J Pennington, R Socher, C Manning, 10.3115/v1/D14-1162Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP). the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)Doha, QatarOctober 2014</p>
<p>Natural language processing (almost) from scratch. R Collobert, J Weston, L Bottou, M Karlen, K Kavukcuoglu, P Kuksa, J. Mach. Learn. Res. 122011</p>
<p>NCRF++: An Open-source Neural Sequence Labeling Toolkit. J Yang, Y Zhang, Proceedings of the Proceedings of ACL 2018, System Demonstrations. the ACL 2018, System DemonstrationsMelbourne, Australia15-20 July 2018</p>
<p>Pre-training of Deep Bidirectional Transformers for Language Understanding. J D M W C Kenton, L K Toutanova, Bert, Proceedings of the NAACL-HLT. the NAACL-HLTMinneapolis, MN, USA2-7 June 2019</p>
<p>Aligning books and movies: Towards story-like visual explanations by watching movies and reading books. Y Zhu, R Kiros, R Zemel, R Salakhutdinov, R Urtasun, A Torralba, S Fidler, Proceedings of the IEEE International Conference on Computer Vision. the IEEE International Conference on Computer VisionSantiago, ChileDecember 2015</p>
<p>I Beltagy, K Lo, A Cohan, Scibert, arXiv:1903.10676Pretrained Language Model for Scientific Text. 2019</p>
<p>Linked data: The story so far. C Bizer, T Heath, T Berners-Lee, Semantic Services, Interoperability and Web Applications: Emerging Concepts. Hershey, PA, USA2011IGI Global</p>
<p>A nucleus for a web of open data. S Auer, C Bizer, G Kobilarov, J Lehmann, R Cyganiak, Z Ives, Dbpedia, The Semantic Web. Berlin/Heidelberg, GermanySpringer2007</p>
<p>A Catalog of Transformer Models. D' Souza, J , 2023. 19 January 2024</p>
<p>Disclaimer/Publisher's Note: The statements, opinions and data contained in all publications are solely those of the individual author(s) and contributor(s) and not of MDPI and/or the editor(s). MDPI and/or the editor(s) disclaim responsibility for any injury to people or property resulting from any ideas, methods. instructions or products referred to in the content</p>            </div>
        </div>

    </div>
</body>
</html>