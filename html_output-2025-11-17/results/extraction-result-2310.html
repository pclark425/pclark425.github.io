<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-2310 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-2310</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-2310</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-63.html">extraction-schema-63</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <p><strong>Paper ID:</strong> paper-221376970</p>
                <p><strong>Paper Title:</strong> Machine learning for metal additive manufacturing: predicting temperature and melt pool fluid dynamics using physics-informed neural networks</p>
                <p><strong>Paper Abstract:</strong> The recent explosion of machine learning (ML) and artificial intelligence (AI) shows great potential in the breakthrough of metal additive manufacturing (AM) process modeling, which is an indispensable step to derive the process-structure-property relationship. However, the success of conventional machine learning tools in data science is primarily attributed to the unprecedented large amount of labeled data-sets (big data), which can be either obtained by experiments or first-principle simulations. Unfortunately, these labeled data-sets are expensive to obtain in AM due to the high expense of the AM experiments and prohibitive computational cost of high-fidelity simulations, hindering the direct applications of big-data based ML tools to metal AM problems. To fully exploit the power of machine learning for metal AM while alleviating the dependence on “big data”, we put forth a physics-informed neural network (PINN) framework that fuses both data and first physical principles, including conservation laws of momentum, mass, and energy, into the neural network to inform the learning processes. To the best knowledge of the authors, this is the first application of physics-informed deep learning to three dimensional AM processes modeling. Besides, we propose a hard-type approach for Dirichlet boundary conditions (BCs) based on a Heaviside function, which can not only exactly enforce the BCs but also accelerate the learning process. The PINN framework is applied to two representative metal manufacturing problems, including the 2018 NIST AM-Benchmark test series. We carefully assess the performance of the PINN model by comparing the predictions with available experimental data and high-fidelity simulation results, using finite element based variational multi-scale formulation method. The investigations show that the PINN, owed to the additional physical knowledge, can accurately predict the temperature and melt pool dynamics during metal AM processes with only a moderate amount of labeled data-sets. The foray of PINN to metal AM shows the great potential of physics-informed deep learning for broader applications to advanced manufacturing. All the data-sets and the PINN code will be made open-sourced in https://yan.cee.illinois.edu/ once the paper is published.</p>
                <p><strong>Cost:</strong> 0.02</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e2310.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e2310.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>PINN</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Physics-Informed Neural Network</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A deep neural network trained with a loss that penalizes both data mismatch and the residuals of governing PDEs (momentum, mass, energy), used here to predict temperature, pressure, velocity and melt-pool metrics in metal additive manufacturing with only modest labeled data.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>Metal additive manufacturing (thermal-fluid modeling; melt pool dynamics)</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Predict spatiotemporal temperature field, melt-pool fluid velocity and pressure, melt-pool dimensions and cooling rates for laser-based metal AM (LPBF/scan-track experiments) under scarce labeled data conditions.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>Limited/scarce labeled experimental data (NIST measurements) and high-fidelity simulations are expensive; the authors used a small subset of FEM-generated synthetic labels (e.g., a brief time window 1.2–1.5 ms) for training and in one example trained with no labeled data (1D solidification). Data quality: high-fidelity FEM used as reference; experimental measurements sparse/noisy for some quantities (cooling rates).</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>High-dimensional, continuous spatiotemporal fields (3D spatial + time), i.e., time-series of physical fields (temperature, velocity, pressure); structured by physical domain/geometric coordinates and continuous PDE solutions; multimodal in physics (momentum + energy + phase-fraction fields).</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>High: coupled, non-linear, multi-physics PDE system (incompressible Navier–Stokes + energy + phase change via liquid fraction), multi-scale and multi-physics interactions, high dimensionality (3D + time), stiff gradients in melt-pool, and complex boundary/BC conditions.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>Mature in terms of classical numerical modeling: well-established high-fidelity FEM/VoF/level-set/Lattice-Boltzmann models and benchmark data (NIST AM-Bench) exist, but computational cost is high and problem-specific numerical expertise required.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>High - mechanistic/causal understanding is required for scientific validity; the method explicitly enforces conservation laws (PDEs) to preserve mechanistic fidelity and enable interpretability of physical fields.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Physics-Informed Neural Network (PINN)</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>A fully-connected deep neural network maps input coordinates [t,x,y,z] to outputs [u,v,w,p,T]; the loss is a weighted sum of (1) data mean-squared-error on available labeled points and (2) PDE residual losses computed at collocation points for momentum, continuity and energy equations (including latent-heat/phase-fraction terms). Dirichlet BCs are enforced via a 'hard' construction using a Heaviside-based weighting of network outputs; Neumann BCs are penalized in the loss. Training uses automatic differentiation to compute spatial/temporal derivatives and the Adam optimizer (SGD/Adam). Implementation in TensorFlow; loss-weights (lambda) chosen by balancing magnitudes estimated from FEM residuals. Collocation-point sampling is used for PDE residuals.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>physics-informed ML / hybrid (data + PDE-constrained supervised learning)</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Appropriate and well-suited: PINNs exploit available mechanistic knowledge (PDEs) to compensate for sparse labeled data in AM; required adaptations included a hard Dirichlet BC enforcement and careful weighting of PDE vs data losses. Limitations: current PINN did not model ambient gas, free-surface deformation, or evaporation (modeling simplifications), and training efficiency depends on amount of training data.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td>Melt-pool geometry and cooling-rate metrics: Case A length PINN=594.8 μm (9.7% relative discrepancy vs NIST 659 ±21 μm), width=193.3 μm, depth=64.0 μm; Case B length=740.3 μm (5.1% vs 782 μm), width=160.0 μm, depth=52.8 μm; Case C length=732.5 μm (2.9% vs 754 μm), width=131.5 μm, depth=43.2 μm. Peak melt-pool velocities predicted up to 1.641 m/s (case A), 1.566 m/s (case B), 1.446 m/s (case C). Cooling-rate predictions: Case A 8.54×10^5 K/s (37.7% discrepancy vs NIST mean 6.20×10^5 K/s), Case B 8.59×10^5 K/s (8.1% discrepancy vs NIST 9.35×10^5 K/s), Case C 1.38×10^6 K/s (7.8% discrepancy vs NIST 1.28×10^6 K/s). In 1D solidification PINN convergence rates comparable to FEM; with no labeled data PINN solved energy-only problem; in a sequential environment PINN was ~2× slower than FEM for the 1D PDE-only case.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>Qualitatively effective: PINN produced temperature, velocity and melt-pool dimensions similar to high-fidelity FEM and to experimental profiles using only moderate labeled data; hard-BC enforcement improved accuracy and convergence versus soft BC enforcement; PINN sometimes underperforms for noisy experimental metrics (e.g., cooling rates in case A) but outperforms or matches FEM in other cases; shows robustness at low spatial resolution where FEM had noticeable discrepancies.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>High: can reduce dependence on large labeled datasets (expensive experiments/HPC simulations), speed up predictive modeling and potentially enable faster design/parameter studies, uncertainty quantification and real-time or near-real-time surrogate models for AM; generalizable to other multi-physics engineering PDE problems when mechanistic equations are known.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Direct comparison to FEM (high-fidelity VMS formulation) and to the award-winning simulation by Gan et al. PINN matched or closely tracked FEM predictions for melt-pool dimensions and velocity fields and obtained similar convergence behavior to FEM. For cooling rates PINN had mixed performance: worse than Gan et al. for case A but comparable or better for cases B and C. PINN required much less labeled data than standard supervised DL would need.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Embedding conservation laws (PDE residuals) into the loss, using automatic differentiation for accurate derivatives, enforcing Dirichlet BCs via a hard Heaviside-based construction, leveraging high-fidelity FEM synthetic data for training/validation, judicious weighting of PDE vs data loss terms, and using Adam optimizer for stable training.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>Fusing mechanistic PDE constraints into deep networks (PINNs) enables accurate prediction of complex, coupled thermal-fluid melt-pool dynamics in metal AM with limited labeled data by trading pure data requirements for physical knowledge embedded as loss constraints.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Machine learning for metal additive manufacturing: predicting temperature and melt pool fluid dynamics using physics-informed neural networks', 'publication_date_yy_mm': '2021-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2310.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e2310.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>FCNN</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Fully-Connected Neural Network (feedforward DNN)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A multilayer perceptron (fully connected) with swish activation used as the function approximator backbone of the PINN, mapping spatiotemporal coordinates to physical fields.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>Metal additive manufacturing (thermal-fluid modeling)</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Function approximation of continuous PDE solutions (velocity, pressure, temperature) over space and time to enable PDE-residual evaluation and data fitting within the PINN framework.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>Same limited labeled data context as PINN; FCNN used with collocation points for PDE residuals and with small labeled subsets from FEM/experiment.</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>Inputs are continuous coordinates (time and spatial coordinates); outputs are continuous scalar/vector fields (T, p, u components).</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>High nonlinearity in mappings due to Navier-Stokes/enthalpy physics and phase-change; network depth/width tuned (e.g., 5 hidden layers × 200 neurons used in 1D solidification example) to attain required expressivity.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>Standard deep learning architecture; well-established but requires physical constraints to perform well in scientific PDE tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>Medium-high: architecture is a black-box approximator but is coupled to mechanistic constraints (PDE residuals) to enforce physical behavior.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Fully-connected deep neural network (FCNN) with swish activation</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>A feed-forward network with N_layers hidden layers, weights and biases trained to minimize the combined data + PDE residual loss; swish activation used (x * sigmoid(x)); derivatives for PDE residuals computed by automatic differentiation.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>supervised / function-approximation component of physics-informed ML</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Appropriate as function approximator for PINN; alone would require large labeled datasets but with PDE constraints it becomes suitable for sparse-data scientific modeling.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td>Network configurations reported e.g., 5 hidden layers × 200 neurons for 1D solidification yielded accurate predictions; no separate quantitative ML metric for pure FCNN reported beyond integrated PINN results.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>Worked effectively as the differentiable approximator within the PINN, enabling use of AD for PDE residuals; deeper/wider architectures improved approximation capability in experiments reported.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>As a general-purpose approximator it enables PINN-style approaches for many PDE-constrained problems when combined with physics-informed losses.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Conventional supervised networks (without PDE constraints) would need much larger labeled datasets and were not directly compared; FCNN chosen over CNN/RNN because inputs are coordinates and outputs are continuous fields.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Sufficient depth/width for expressivity, choice of swish activation, and integration with AD and PDE-residual losses.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>A standard FCNN, when coupled with PDE residual losses and AD, can approximate complex spatiotemporal PDE solutions without requiring large labeled datasets.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Machine learning for metal additive manufacturing: predicting temperature and melt pool fluid dynamics using physics-informed neural networks', 'publication_date_yy_mm': '2021-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2310.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e2310.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Hard-BC Heaviside</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Hard enforcement of Dirichlet boundary conditions via a Heaviside-based network construction</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A method that modifies network outputs using a smooth Heaviside function of distance-to-boundary so that Dirichlet boundary values are exactly satisfied (u_NN = u_bc[1 - H(x)] + u_H(x)), improving accuracy and training speed.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>Physics-informed ML for PDE-constrained problems (metal AM thermal-fluid flows)</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Enforce Dirichlet boundary conditions exactly inside a PINN to avoid soft-constraint penalties and to accelerate convergence.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>Boundary values are prescribed (Dirichlet BCs) as part of problem specification; no additional labeled interior data required for BC enforcement.</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>Geometric distance field d(x) to Dirichlet boundaries used to construct a smooth Heaviside H(d(x)/epsilon).</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>Enforcing boundary conditions in PDE-constrained ML can be difficult and can slow or bias training if enforced softly; this approach reduces that complexity.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>Novel adaptation in this paper inspired by interface-capturing methods in multiphase fluid mechanics; BC treatment in PINNs is an active research topic.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>High: exact BC satisfaction is important for mechanistic fidelity of PDE solutions.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Heaviside-based hard Dirichlet BC enforcement</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>Define H(x) = 1 - cos[d(x)π/ε] if d(x) < ε else 0 (smooth transition over artificial thickness ε). Compose network outputs as prescribed_bc*(1 - H) + NN_component*H so that as d→0 the network output equals the prescribed BC, eliminating the need for an explicit BC term in the loss. Shown to accelerate learning and improve solution accuracy compared to soft-constraint BC loss terms.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>physics-informed ML adaptation / architectural constraint</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Highly applicable to PDE problems with Dirichlet BCs; particularly beneficial where exact BCs are required and where soft enforcement degrades training.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td>Hard-BC yielded faster convergence and more accurate temperature predictions in the 1D solidification test compared to soft enforcement (plots and convergence rates shown; no single scalar improvement number provided but qualitative and plotted evidence reported).</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>Improved both learning speed and boundary accuracy vs soft BC loss enforcement; recommended by authors for PDE-informed networks where exact BC satisfaction is desirable.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>Medium-high: Can be adopted generally in PINN-style models to improve training stability and physical fidelity for boundary-constrained PDE problems.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Compared directly to the conventional 'soft' BC enforcement (BC residuals added to loss) and found hard-BC to be both faster to train and more accurate in the solidification example.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Smooth construction of H with an artificial thickness parameter, clear separation of BC-satisfying component and PDE-satisfying component in network output, leveraging interface-capturing ideas from multiphase fluid mechanics.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>Enforcing Dirichlet BCs through architectural composition with a distance-based Heaviside function yields exact boundary satisfaction and accelerates PINN training relative to soft-constraint approaches.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Machine learning for metal additive manufacturing: predicting temperature and melt pool fluid dynamics using physics-informed neural networks', 'publication_date_yy_mm': '2021-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2310.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e2310.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>SciML (concept)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Scientific Machine Learning (SciML)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>The paradigm of combining machine learning models with physical principles (PDEs, conservation laws) to improve predictive performance in data-scarce scientific applications; motivates the PINN methodology.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>Cross-cutting: scientific computing and computational physics (here applied to metal AM)</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Address sparse-data scientific modeling by embedding mechanistic knowledge (e.g., PDEs) into data-driven ML models to improve generalization and physical consistency.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>SciML is motivated by situations with limited labeled data and abundant domain knowledge (PDEs); typical practice uses a mix of sparse labels and physics constraints.</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>Varies by application; in this paper SciML targets spatiotemporal continuous PDE field data.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>SciML often targets complex multiphysics systems where pure data-driven approaches are impractical due to data scarcity and physical constraints.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>Emerging and rapidly growing research area with many early successful applications (some single-physics examples cited); active methodology development.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>High - central to SciML is the requirement to incorporate mechanistic understanding directly into learning.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Physics-constrained / physics-informed machine learning (SciML paradigm)</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>General approach of augmenting ML models (GPR, DNNs, PINNs) with physics constraints (PDE residuals, conservation laws) either through loss penalties, model structure, or hybrid coupling with simulators.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>hybrid / physics-informed ML</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Highly applicable to scientific domains with known governing equations and limited labeled data (e.g., AM thermal-fluid flows).</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td>Not quantified generically in paper; effectiveness demonstrated in the PINN experiments of this paper (see PINN entry).</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>SciML is presented as a remedy to big-data requirements of vanilla DL; effective where prior physical knowledge is available and must be respected.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>High across scientific modeling: reduces labeled-data demands, improves physical fidelity, and can enable learning-accelerated surrogates and inverse modeling.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Contrasted with pure data-driven DL and pure numerical PDE solvers: SciML blends both to mitigate disadvantages of each (data hunger vs computational cost).</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Availability of reliable mechanistic equations, differentiable formulations (for AD), and means to balance data vs physics losses.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>Embedding mechanistic laws into ML models allows practical learning for complex scientific PDE problems when labeled data are scarce or expensive.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Machine learning for metal additive manufacturing: predicting temperature and melt pool fluid dynamics using physics-informed neural networks', 'publication_date_yy_mm': '2021-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2310.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e2310.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GPR/DNN (conventional ML mentions)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Gaussian Process Regression and Deep Neural Networks (as conventional ML/SciML building blocks)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Standard machine learning methods (GPR, DNN) cited as prior approaches in SciML that can be constrained by physics; referenced as common choices but limited by large labeled-data requirements for AM.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>General scientific regression and surrogate modeling (here in context of AM and other scientific domains)</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Used in literature to learn mappings from inputs to physical quantities (e.g., material properties, surrogate PDE solvers) but typically require abundant labeled data unless physics is embedded.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>These methods usually assume abundant labeled data (big-data) which is not available in AM; hence purely data-driven GPR/DNN are less feasible here.</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>Typically structured/continuous data, could be spatiotemporal fields or low-dimensional parameter-to-observable maps depending on application.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>Varies; deep networks can handle high dimensionality but need much data; GPR offers uncertainty quantification but scales poorly with dataset size.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>Mature ML methods with extensive tooling; application to SciML is active but constrained by data availability or computational cost.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>Low to medium when used as pure data-driven methods; higher when combined with physics constraints.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Gaussian Process Regression (GPR); Deep Neural Networks (DNN)</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>Mentioned as conventional supervised learning approaches that some SciML works augment with physics constraints; not directly used in experiments in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>supervised learning / probabilistic regression (GPR) / deep learning</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Limited directly for AM due to lack of big labeled datasets; more applicable when rich labeled data or transfer/other techniques available.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>Recognized as powerful but data-hungry; motivation for physics-informed approaches that reduce labeled-data dependence.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>Can be high if labeled data become available or if combined with physics constraints; otherwise limited in the AM setting described.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Contrasted qualitatively with PINNs / SciML: pure GPR/DNN require big-data and lack guaranteed physical consistency without physics constraints.</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Large labeled datasets, good feature representations, and computational resources (GPUs).</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>Conventional GPR/DNN are effective predictors but their direct application to metal AM is limited by expensive/rare labeled data, motivating physics-informed hybrids.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Machine learning for metal additive manufacturing: predicting temperature and melt pool fluid dynamics using physics-informed neural networks', 'publication_date_yy_mm': '2021-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2310.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e2310.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI or machine learning methodologies being applied to scientific problems, including details about the problem characteristics (data availability, data structure, complexity, domain maturity, mechanistic understanding requirements) and the outcomes (applicability, effectiveness, impact).</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>AD + Adam</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Automatic Differentiation and Adam optimizer</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Implementation/training tools: AD is used to compute exact derivatives of network outputs w.r.t. inputs for PDE residuals; Adam optimizer (with SGD discussion) used to train network parameters efficiently.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_problem_domain</strong></td>
                            <td>Training physics-informed ML models for PDE-constrained scientific problems</td>
                        </tr>
                        <tr>
                            <td><strong>problem_description</strong></td>
                            <td>Efficiently and accurately compute spatial and temporal derivatives required by PDE residuals and perform robust optimization of high-dimensional network parameters.</td>
                        </tr>
                        <tr>
                            <td><strong>data_availability</strong></td>
                            <td>Not applicable (training infrastructure detail); relies on collocation points and labeled data discussed under PINN.</td>
                        </tr>
                        <tr>
                            <td><strong>data_structure</strong></td>
                            <td>Provides derivatives of continuous coordinate->field mappings via AD; enables gradient-based minimization on mixed data+PDE losses.</td>
                        </tr>
                        <tr>
                            <td><strong>problem_complexity</strong></td>
                            <td>AD avoids finite-difference truncation errors and enables accurate PDE residual evaluation even for high-order derivatives; optimizer must handle non-convex high-dimensional loss with multiple components.</td>
                        </tr>
                        <tr>
                            <td><strong>domain_maturity</strong></td>
                            <td>AD and Adam are standard, mature tools in modern ML frameworks (TensorFlow used here).</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_understanding_requirements</strong></td>
                            <td>Medium: AD enables faithful mechanistic enforcement by providing exact derivatives for PDE residuals.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_name</strong></td>
                            <td>Automatic Differentiation (AD); Adam optimizer (with SGD motivation)</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_description</strong></td>
                            <td>AD computes PDE derivatives by backpropagating analytic layer derivatives; Adam optimizer (adaptive learning rates + momentum) used to update network weights for faster and more stable convergence than plain SGD; minibatch/stochastic collocation sampling used in training.</td>
                        </tr>
                        <tr>
                            <td><strong>ai_methodology_category</strong></td>
                            <td>training/optimization tools within supervised / physics-informed learning</td>
                        </tr>
                        <tr>
                            <td><strong>applicability</strong></td>
                            <td>Essential and highly applicable for PINNs and similar SciML methods that require accurate derivatives and stable training.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_quantitative</strong></td>
                            <td>No standalone metrics provided; authors attribute accelerated convergence and stability to Adam and to accurate derivatives from AD.</td>
                        </tr>
                        <tr>
                            <td><strong>effectiveness_qualitative</strong></td>
                            <td>AD provided high-accuracy derivatives without truncation error, enabling precise PDE residual evaluation; Adam improved convergence speed and helped avoid poor local minima compared with vanilla SGD.</td>
                        </tr>
                        <tr>
                            <td><strong>impact_potential</strong></td>
                            <td>Crucial enabling technologies for PINN-scaled applications; their availability in modern ML libraries reduces implementation burden.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_alternatives</strong></td>
                            <td>Compared qualitatively to numerical differentiation (finite difference) which suffers truncation/round-off errors and to plain SGD (slower/oscillatory).</td>
                        </tr>
                        <tr>
                            <td><strong>success_factors</strong></td>
                            <td>Availability of AD in TensorFlow and the use of Adam for stable, accelerated training.</td>
                        </tr>
                        <tr>
                            <td><strong>key_insight</strong></td>
                            <td>Automatic differentiation and modern adaptive optimizers are essential enablers for training PDE-constrained neural networks accurately and efficiently.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Machine learning for metal additive manufacturing: predicting temperature and melt pool fluid dynamics using physics-informed neural networks', 'publication_date_yy_mm': '2021-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Physics-informed deep learning (part i): data-driven solutions of nonlinear partial differential equations <em>(Rating: 2)</em></li>
                <li>Physics-informed neural networks: a deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations <em>(Rating: 2)</em></li>
                <li>Hidden fluid mechanics: learning velocity and pressure fields from flow visualizations <em>(Rating: 2)</em></li>
                <li>Machine learning of linear differential equations using Gaussian processes <em>(Rating: 1)</em></li>
                <li>Surrogate modeling for fluid flows based on physics-constrained deep learning without simulation data <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-2310",
    "paper_id": "paper-221376970",
    "extraction_schema_id": "extraction-schema-63",
    "extracted_data": [
        {
            "name_short": "PINN",
            "name_full": "Physics-Informed Neural Network",
            "brief_description": "A deep neural network trained with a loss that penalizes both data mismatch and the residuals of governing PDEs (momentum, mass, energy), used here to predict temperature, pressure, velocity and melt-pool metrics in metal additive manufacturing with only modest labeled data.",
            "citation_title": "here",
            "mention_or_use": "use",
            "scientific_problem_domain": "Metal additive manufacturing (thermal-fluid modeling; melt pool dynamics)",
            "problem_description": "Predict spatiotemporal temperature field, melt-pool fluid velocity and pressure, melt-pool dimensions and cooling rates for laser-based metal AM (LPBF/scan-track experiments) under scarce labeled data conditions.",
            "data_availability": "Limited/scarce labeled experimental data (NIST measurements) and high-fidelity simulations are expensive; the authors used a small subset of FEM-generated synthetic labels (e.g., a brief time window 1.2–1.5 ms) for training and in one example trained with no labeled data (1D solidification). Data quality: high-fidelity FEM used as reference; experimental measurements sparse/noisy for some quantities (cooling rates).",
            "data_structure": "High-dimensional, continuous spatiotemporal fields (3D spatial + time), i.e., time-series of physical fields (temperature, velocity, pressure); structured by physical domain/geometric coordinates and continuous PDE solutions; multimodal in physics (momentum + energy + phase-fraction fields).",
            "problem_complexity": "High: coupled, non-linear, multi-physics PDE system (incompressible Navier–Stokes + energy + phase change via liquid fraction), multi-scale and multi-physics interactions, high dimensionality (3D + time), stiff gradients in melt-pool, and complex boundary/BC conditions.",
            "domain_maturity": "Mature in terms of classical numerical modeling: well-established high-fidelity FEM/VoF/level-set/Lattice-Boltzmann models and benchmark data (NIST AM-Bench) exist, but computational cost is high and problem-specific numerical expertise required.",
            "mechanistic_understanding_requirements": "High - mechanistic/causal understanding is required for scientific validity; the method explicitly enforces conservation laws (PDEs) to preserve mechanistic fidelity and enable interpretability of physical fields.",
            "ai_methodology_name": "Physics-Informed Neural Network (PINN)",
            "ai_methodology_description": "A fully-connected deep neural network maps input coordinates [t,x,y,z] to outputs [u,v,w,p,T]; the loss is a weighted sum of (1) data mean-squared-error on available labeled points and (2) PDE residual losses computed at collocation points for momentum, continuity and energy equations (including latent-heat/phase-fraction terms). Dirichlet BCs are enforced via a 'hard' construction using a Heaviside-based weighting of network outputs; Neumann BCs are penalized in the loss. Training uses automatic differentiation to compute spatial/temporal derivatives and the Adam optimizer (SGD/Adam). Implementation in TensorFlow; loss-weights (lambda) chosen by balancing magnitudes estimated from FEM residuals. Collocation-point sampling is used for PDE residuals.",
            "ai_methodology_category": "physics-informed ML / hybrid (data + PDE-constrained supervised learning)",
            "applicability": "Appropriate and well-suited: PINNs exploit available mechanistic knowledge (PDEs) to compensate for sparse labeled data in AM; required adaptations included a hard Dirichlet BC enforcement and careful weighting of PDE vs data losses. Limitations: current PINN did not model ambient gas, free-surface deformation, or evaporation (modeling simplifications), and training efficiency depends on amount of training data.",
            "effectiveness_quantitative": "Melt-pool geometry and cooling-rate metrics: Case A length PINN=594.8 μm (9.7% relative discrepancy vs NIST 659 ±21 μm), width=193.3 μm, depth=64.0 μm; Case B length=740.3 μm (5.1% vs 782 μm), width=160.0 μm, depth=52.8 μm; Case C length=732.5 μm (2.9% vs 754 μm), width=131.5 μm, depth=43.2 μm. Peak melt-pool velocities predicted up to 1.641 m/s (case A), 1.566 m/s (case B), 1.446 m/s (case C). Cooling-rate predictions: Case A 8.54×10^5 K/s (37.7% discrepancy vs NIST mean 6.20×10^5 K/s), Case B 8.59×10^5 K/s (8.1% discrepancy vs NIST 9.35×10^5 K/s), Case C 1.38×10^6 K/s (7.8% discrepancy vs NIST 1.28×10^6 K/s). In 1D solidification PINN convergence rates comparable to FEM; with no labeled data PINN solved energy-only problem; in a sequential environment PINN was ~2× slower than FEM for the 1D PDE-only case.",
            "effectiveness_qualitative": "Qualitatively effective: PINN produced temperature, velocity and melt-pool dimensions similar to high-fidelity FEM and to experimental profiles using only moderate labeled data; hard-BC enforcement improved accuracy and convergence versus soft BC enforcement; PINN sometimes underperforms for noisy experimental metrics (e.g., cooling rates in case A) but outperforms or matches FEM in other cases; shows robustness at low spatial resolution where FEM had noticeable discrepancies.",
            "impact_potential": "High: can reduce dependence on large labeled datasets (expensive experiments/HPC simulations), speed up predictive modeling and potentially enable faster design/parameter studies, uncertainty quantification and real-time or near-real-time surrogate models for AM; generalizable to other multi-physics engineering PDE problems when mechanistic equations are known.",
            "comparison_to_alternatives": "Direct comparison to FEM (high-fidelity VMS formulation) and to the award-winning simulation by Gan et al. PINN matched or closely tracked FEM predictions for melt-pool dimensions and velocity fields and obtained similar convergence behavior to FEM. For cooling rates PINN had mixed performance: worse than Gan et al. for case A but comparable or better for cases B and C. PINN required much less labeled data than standard supervised DL would need.",
            "success_factors": "Embedding conservation laws (PDE residuals) into the loss, using automatic differentiation for accurate derivatives, enforcing Dirichlet BCs via a hard Heaviside-based construction, leveraging high-fidelity FEM synthetic data for training/validation, judicious weighting of PDE vs data loss terms, and using Adam optimizer for stable training.",
            "key_insight": "Fusing mechanistic PDE constraints into deep networks (PINNs) enables accurate prediction of complex, coupled thermal-fluid melt-pool dynamics in metal AM with limited labeled data by trading pure data requirements for physical knowledge embedded as loss constraints.",
            "uuid": "e2310.0",
            "source_info": {
                "paper_title": "Machine learning for metal additive manufacturing: predicting temperature and melt pool fluid dynamics using physics-informed neural networks",
                "publication_date_yy_mm": "2021-01"
            }
        },
        {
            "name_short": "FCNN",
            "name_full": "Fully-Connected Neural Network (feedforward DNN)",
            "brief_description": "A multilayer perceptron (fully connected) with swish activation used as the function approximator backbone of the PINN, mapping spatiotemporal coordinates to physical fields.",
            "citation_title": "here",
            "mention_or_use": "use",
            "scientific_problem_domain": "Metal additive manufacturing (thermal-fluid modeling)",
            "problem_description": "Function approximation of continuous PDE solutions (velocity, pressure, temperature) over space and time to enable PDE-residual evaluation and data fitting within the PINN framework.",
            "data_availability": "Same limited labeled data context as PINN; FCNN used with collocation points for PDE residuals and with small labeled subsets from FEM/experiment.",
            "data_structure": "Inputs are continuous coordinates (time and spatial coordinates); outputs are continuous scalar/vector fields (T, p, u components).",
            "problem_complexity": "High nonlinearity in mappings due to Navier-Stokes/enthalpy physics and phase-change; network depth/width tuned (e.g., 5 hidden layers × 200 neurons used in 1D solidification example) to attain required expressivity.",
            "domain_maturity": "Standard deep learning architecture; well-established but requires physical constraints to perform well in scientific PDE tasks.",
            "mechanistic_understanding_requirements": "Medium-high: architecture is a black-box approximator but is coupled to mechanistic constraints (PDE residuals) to enforce physical behavior.",
            "ai_methodology_name": "Fully-connected deep neural network (FCNN) with swish activation",
            "ai_methodology_description": "A feed-forward network with N_layers hidden layers, weights and biases trained to minimize the combined data + PDE residual loss; swish activation used (x * sigmoid(x)); derivatives for PDE residuals computed by automatic differentiation.",
            "ai_methodology_category": "supervised / function-approximation component of physics-informed ML",
            "applicability": "Appropriate as function approximator for PINN; alone would require large labeled datasets but with PDE constraints it becomes suitable for sparse-data scientific modeling.",
            "effectiveness_quantitative": "Network configurations reported e.g., 5 hidden layers × 200 neurons for 1D solidification yielded accurate predictions; no separate quantitative ML metric for pure FCNN reported beyond integrated PINN results.",
            "effectiveness_qualitative": "Worked effectively as the differentiable approximator within the PINN, enabling use of AD for PDE residuals; deeper/wider architectures improved approximation capability in experiments reported.",
            "impact_potential": "As a general-purpose approximator it enables PINN-style approaches for many PDE-constrained problems when combined with physics-informed losses.",
            "comparison_to_alternatives": "Conventional supervised networks (without PDE constraints) would need much larger labeled datasets and were not directly compared; FCNN chosen over CNN/RNN because inputs are coordinates and outputs are continuous fields.",
            "success_factors": "Sufficient depth/width for expressivity, choice of swish activation, and integration with AD and PDE-residual losses.",
            "key_insight": "A standard FCNN, when coupled with PDE residual losses and AD, can approximate complex spatiotemporal PDE solutions without requiring large labeled datasets.",
            "uuid": "e2310.1",
            "source_info": {
                "paper_title": "Machine learning for metal additive manufacturing: predicting temperature and melt pool fluid dynamics using physics-informed neural networks",
                "publication_date_yy_mm": "2021-01"
            }
        },
        {
            "name_short": "Hard-BC Heaviside",
            "name_full": "Hard enforcement of Dirichlet boundary conditions via a Heaviside-based network construction",
            "brief_description": "A method that modifies network outputs using a smooth Heaviside function of distance-to-boundary so that Dirichlet boundary values are exactly satisfied (u_NN = u_bc[1 - H(x)] + u_H(x)), improving accuracy and training speed.",
            "citation_title": "here",
            "mention_or_use": "use",
            "scientific_problem_domain": "Physics-informed ML for PDE-constrained problems (metal AM thermal-fluid flows)",
            "problem_description": "Enforce Dirichlet boundary conditions exactly inside a PINN to avoid soft-constraint penalties and to accelerate convergence.",
            "data_availability": "Boundary values are prescribed (Dirichlet BCs) as part of problem specification; no additional labeled interior data required for BC enforcement.",
            "data_structure": "Geometric distance field d(x) to Dirichlet boundaries used to construct a smooth Heaviside H(d(x)/epsilon).",
            "problem_complexity": "Enforcing boundary conditions in PDE-constrained ML can be difficult and can slow or bias training if enforced softly; this approach reduces that complexity.",
            "domain_maturity": "Novel adaptation in this paper inspired by interface-capturing methods in multiphase fluid mechanics; BC treatment in PINNs is an active research topic.",
            "mechanistic_understanding_requirements": "High: exact BC satisfaction is important for mechanistic fidelity of PDE solutions.",
            "ai_methodology_name": "Heaviside-based hard Dirichlet BC enforcement",
            "ai_methodology_description": "Define H(x) = 1 - cos[d(x)π/ε] if d(x) &lt; ε else 0 (smooth transition over artificial thickness ε). Compose network outputs as prescribed_bc*(1 - H) + NN_component*H so that as d→0 the network output equals the prescribed BC, eliminating the need for an explicit BC term in the loss. Shown to accelerate learning and improve solution accuracy compared to soft-constraint BC loss terms.",
            "ai_methodology_category": "physics-informed ML adaptation / architectural constraint",
            "applicability": "Highly applicable to PDE problems with Dirichlet BCs; particularly beneficial where exact BCs are required and where soft enforcement degrades training.",
            "effectiveness_quantitative": "Hard-BC yielded faster convergence and more accurate temperature predictions in the 1D solidification test compared to soft enforcement (plots and convergence rates shown; no single scalar improvement number provided but qualitative and plotted evidence reported).",
            "effectiveness_qualitative": "Improved both learning speed and boundary accuracy vs soft BC loss enforcement; recommended by authors for PDE-informed networks where exact BC satisfaction is desirable.",
            "impact_potential": "Medium-high: Can be adopted generally in PINN-style models to improve training stability and physical fidelity for boundary-constrained PDE problems.",
            "comparison_to_alternatives": "Compared directly to the conventional 'soft' BC enforcement (BC residuals added to loss) and found hard-BC to be both faster to train and more accurate in the solidification example.",
            "success_factors": "Smooth construction of H with an artificial thickness parameter, clear separation of BC-satisfying component and PDE-satisfying component in network output, leveraging interface-capturing ideas from multiphase fluid mechanics.",
            "key_insight": "Enforcing Dirichlet BCs through architectural composition with a distance-based Heaviside function yields exact boundary satisfaction and accelerates PINN training relative to soft-constraint approaches.",
            "uuid": "e2310.2",
            "source_info": {
                "paper_title": "Machine learning for metal additive manufacturing: predicting temperature and melt pool fluid dynamics using physics-informed neural networks",
                "publication_date_yy_mm": "2021-01"
            }
        },
        {
            "name_short": "SciML (concept)",
            "name_full": "Scientific Machine Learning (SciML)",
            "brief_description": "The paradigm of combining machine learning models with physical principles (PDEs, conservation laws) to improve predictive performance in data-scarce scientific applications; motivates the PINN methodology.",
            "citation_title": "",
            "mention_or_use": "mention",
            "scientific_problem_domain": "Cross-cutting: scientific computing and computational physics (here applied to metal AM)",
            "problem_description": "Address sparse-data scientific modeling by embedding mechanistic knowledge (e.g., PDEs) into data-driven ML models to improve generalization and physical consistency.",
            "data_availability": "SciML is motivated by situations with limited labeled data and abundant domain knowledge (PDEs); typical practice uses a mix of sparse labels and physics constraints.",
            "data_structure": "Varies by application; in this paper SciML targets spatiotemporal continuous PDE field data.",
            "problem_complexity": "SciML often targets complex multiphysics systems where pure data-driven approaches are impractical due to data scarcity and physical constraints.",
            "domain_maturity": "Emerging and rapidly growing research area with many early successful applications (some single-physics examples cited); active methodology development.",
            "mechanistic_understanding_requirements": "High - central to SciML is the requirement to incorporate mechanistic understanding directly into learning.",
            "ai_methodology_name": "Physics-constrained / physics-informed machine learning (SciML paradigm)",
            "ai_methodology_description": "General approach of augmenting ML models (GPR, DNNs, PINNs) with physics constraints (PDE residuals, conservation laws) either through loss penalties, model structure, or hybrid coupling with simulators.",
            "ai_methodology_category": "hybrid / physics-informed ML",
            "applicability": "Highly applicable to scientific domains with known governing equations and limited labeled data (e.g., AM thermal-fluid flows).",
            "effectiveness_quantitative": "Not quantified generically in paper; effectiveness demonstrated in the PINN experiments of this paper (see PINN entry).",
            "effectiveness_qualitative": "SciML is presented as a remedy to big-data requirements of vanilla DL; effective where prior physical knowledge is available and must be respected.",
            "impact_potential": "High across scientific modeling: reduces labeled-data demands, improves physical fidelity, and can enable learning-accelerated surrogates and inverse modeling.",
            "comparison_to_alternatives": "Contrasted with pure data-driven DL and pure numerical PDE solvers: SciML blends both to mitigate disadvantages of each (data hunger vs computational cost).",
            "success_factors": "Availability of reliable mechanistic equations, differentiable formulations (for AD), and means to balance data vs physics losses.",
            "key_insight": "Embedding mechanistic laws into ML models allows practical learning for complex scientific PDE problems when labeled data are scarce or expensive.",
            "uuid": "e2310.3",
            "source_info": {
                "paper_title": "Machine learning for metal additive manufacturing: predicting temperature and melt pool fluid dynamics using physics-informed neural networks",
                "publication_date_yy_mm": "2021-01"
            }
        },
        {
            "name_short": "GPR/DNN (conventional ML mentions)",
            "name_full": "Gaussian Process Regression and Deep Neural Networks (as conventional ML/SciML building blocks)",
            "brief_description": "Standard machine learning methods (GPR, DNN) cited as prior approaches in SciML that can be constrained by physics; referenced as common choices but limited by large labeled-data requirements for AM.",
            "citation_title": "",
            "mention_or_use": "mention",
            "scientific_problem_domain": "General scientific regression and surrogate modeling (here in context of AM and other scientific domains)",
            "problem_description": "Used in literature to learn mappings from inputs to physical quantities (e.g., material properties, surrogate PDE solvers) but typically require abundant labeled data unless physics is embedded.",
            "data_availability": "These methods usually assume abundant labeled data (big-data) which is not available in AM; hence purely data-driven GPR/DNN are less feasible here.",
            "data_structure": "Typically structured/continuous data, could be spatiotemporal fields or low-dimensional parameter-to-observable maps depending on application.",
            "problem_complexity": "Varies; deep networks can handle high dimensionality but need much data; GPR offers uncertainty quantification but scales poorly with dataset size.",
            "domain_maturity": "Mature ML methods with extensive tooling; application to SciML is active but constrained by data availability or computational cost.",
            "mechanistic_understanding_requirements": "Low to medium when used as pure data-driven methods; higher when combined with physics constraints.",
            "ai_methodology_name": "Gaussian Process Regression (GPR); Deep Neural Networks (DNN)",
            "ai_methodology_description": "Mentioned as conventional supervised learning approaches that some SciML works augment with physics constraints; not directly used in experiments in this paper.",
            "ai_methodology_category": "supervised learning / probabilistic regression (GPR) / deep learning",
            "applicability": "Limited directly for AM due to lack of big labeled datasets; more applicable when rich labeled data or transfer/other techniques available.",
            "effectiveness_quantitative": null,
            "effectiveness_qualitative": "Recognized as powerful but data-hungry; motivation for physics-informed approaches that reduce labeled-data dependence.",
            "impact_potential": "Can be high if labeled data become available or if combined with physics constraints; otherwise limited in the AM setting described.",
            "comparison_to_alternatives": "Contrasted qualitatively with PINNs / SciML: pure GPR/DNN require big-data and lack guaranteed physical consistency without physics constraints.",
            "success_factors": "Large labeled datasets, good feature representations, and computational resources (GPUs).",
            "key_insight": "Conventional GPR/DNN are effective predictors but their direct application to metal AM is limited by expensive/rare labeled data, motivating physics-informed hybrids.",
            "uuid": "e2310.4",
            "source_info": {
                "paper_title": "Machine learning for metal additive manufacturing: predicting temperature and melt pool fluid dynamics using physics-informed neural networks",
                "publication_date_yy_mm": "2021-01"
            }
        },
        {
            "name_short": "AD + Adam",
            "name_full": "Automatic Differentiation and Adam optimizer",
            "brief_description": "Implementation/training tools: AD is used to compute exact derivatives of network outputs w.r.t. inputs for PDE residuals; Adam optimizer (with SGD discussion) used to train network parameters efficiently.",
            "citation_title": "here",
            "mention_or_use": "use",
            "scientific_problem_domain": "Training physics-informed ML models for PDE-constrained scientific problems",
            "problem_description": "Efficiently and accurately compute spatial and temporal derivatives required by PDE residuals and perform robust optimization of high-dimensional network parameters.",
            "data_availability": "Not applicable (training infrastructure detail); relies on collocation points and labeled data discussed under PINN.",
            "data_structure": "Provides derivatives of continuous coordinate-&gt;field mappings via AD; enables gradient-based minimization on mixed data+PDE losses.",
            "problem_complexity": "AD avoids finite-difference truncation errors and enables accurate PDE residual evaluation even for high-order derivatives; optimizer must handle non-convex high-dimensional loss with multiple components.",
            "domain_maturity": "AD and Adam are standard, mature tools in modern ML frameworks (TensorFlow used here).",
            "mechanistic_understanding_requirements": "Medium: AD enables faithful mechanistic enforcement by providing exact derivatives for PDE residuals.",
            "ai_methodology_name": "Automatic Differentiation (AD); Adam optimizer (with SGD motivation)",
            "ai_methodology_description": "AD computes PDE derivatives by backpropagating analytic layer derivatives; Adam optimizer (adaptive learning rates + momentum) used to update network weights for faster and more stable convergence than plain SGD; minibatch/stochastic collocation sampling used in training.",
            "ai_methodology_category": "training/optimization tools within supervised / physics-informed learning",
            "applicability": "Essential and highly applicable for PINNs and similar SciML methods that require accurate derivatives and stable training.",
            "effectiveness_quantitative": "No standalone metrics provided; authors attribute accelerated convergence and stability to Adam and to accurate derivatives from AD.",
            "effectiveness_qualitative": "AD provided high-accuracy derivatives without truncation error, enabling precise PDE residual evaluation; Adam improved convergence speed and helped avoid poor local minima compared with vanilla SGD.",
            "impact_potential": "Crucial enabling technologies for PINN-scaled applications; their availability in modern ML libraries reduces implementation burden.",
            "comparison_to_alternatives": "Compared qualitatively to numerical differentiation (finite difference) which suffers truncation/round-off errors and to plain SGD (slower/oscillatory).",
            "success_factors": "Availability of AD in TensorFlow and the use of Adam for stable, accelerated training.",
            "key_insight": "Automatic differentiation and modern adaptive optimizers are essential enablers for training PDE-constrained neural networks accurately and efficiently.",
            "uuid": "e2310.5",
            "source_info": {
                "paper_title": "Machine learning for metal additive manufacturing: predicting temperature and melt pool fluid dynamics using physics-informed neural networks",
                "publication_date_yy_mm": "2021-01"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Physics-informed deep learning (part i): data-driven solutions of nonlinear partial differential equations",
            "rating": 2,
            "sanitized_title": "physicsinformed_deep_learning_part_i_datadriven_solutions_of_nonlinear_partial_differential_equations"
        },
        {
            "paper_title": "Physics-informed neural networks: a deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations",
            "rating": 2,
            "sanitized_title": "physicsinformed_neural_networks_a_deep_learning_framework_for_solving_forward_and_inverse_problems_involving_nonlinear_partial_differential_equations"
        },
        {
            "paper_title": "Hidden fluid mechanics: learning velocity and pressure fields from flow visualizations",
            "rating": 2,
            "sanitized_title": "hidden_fluid_mechanics_learning_velocity_and_pressure_fields_from_flow_visualizations"
        },
        {
            "paper_title": "Machine learning of linear differential equations using Gaussian processes",
            "rating": 1,
            "sanitized_title": "machine_learning_of_linear_differential_equations_using_gaussian_processes"
        },
        {
            "paper_title": "Surrogate modeling for fluid flows based on physics-constrained deep learning without simulation data",
            "rating": 1,
            "sanitized_title": "surrogate_modeling_for_fluid_flows_based_on_physicsconstrained_deep_learning_without_simulation_data"
        }
    ],
    "cost": 0.019733999999999998,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Machine learning for metal additive manufacturing: predicting temperature and melt pool fluid dynamics using physics-informed neural networks
6 January 2021</p>
<p>Qiming Zhu 
Department of Civil and Environmental Engineering
University of Illinois at Urbana-Champaign
ChampaignILUSA</p>
<p>Zeliang Liu zeliang.liu@ansys.com 
Livermore Software Technology, An ANSYS Company
LivermoreCAUSA</p>
<p>Jinhui Yan 
Department of Civil and Environmental Engineering
University of Illinois at Urbana-Champaign
ChampaignILUSA</p>
<p>Machine learning for metal additive manufacturing: predicting temperature and melt pool fluid dynamics using physics-informed neural networks
6 January 2021F3D75687E79CB2332DCBA22BBC1156EF10.1007/s00466-020-01952-9Received: 1 August 2020 / Accepted: 16 November 2020 /CFDThermal multiphase flowsAdditive manufacturing
The recent explosion of machine learning (ML) and artificial intelligence (AI) shows great potential in the breakthrough of metal additive manufacturing (AM) process modeling, which is an indispensable step to derive the process-structureproperty relationship.However, the success of conventional machine learning tools in data science is primarily attributed to the unprecedented large amount of labeled data-sets (big data), which can be either obtained by experiments or firstprinciple simulations.Unfortunately, these labeled data-sets are expensive to obtain in AM due to the high expense of the AM experiments and prohibitive computational cost of high-fidelity simulations, hindering the direct applications of big-data based ML tools to metal AM problems.To fully exploit the power of machine learning for metal AM while alleviating the dependence on "big data", we put forth a physics-informed neural network (PINN) framework that fuses both data and first physical principles, including conservation laws of momentum, mass, and energy, into the neural network to inform the learning processes.To the best knowledge of the authors, this is the first application of physics-informed deep learning to three dimensional AM processes modeling.Besides, we propose a hard-type approach for Dirichlet boundary conditions (BCs) based on a Heaviside function, which can not only exactly enforce the BCs but also accelerate the learning process.The PINN framework is applied to two representative metal manufacturing problems, including the 2018 NIST AM-Benchmark test series.We carefully assess the performance of the PINN model by comparing the predictions with available experimental data and high-fidelity simulation results, using finite element based variational multi-scale formulation method.The investigations show that the PINN, owed to the additional physical knowledge, can accurately predict the temperature and melt pool dynamics during metal AM processes with only a moderate amount of labeled data-sets.The foray of PINN to metal AM shows the great potential of physics-informed deep learning for broader applications to advanced manufacturing.All the data-sets and the PINN code will be made open-sourced in https://yan.cee.illinois.edu/once the paper is published.</p>
<p>Introduction</p>
<p>It has been widely believed that metal additive manufacturing (AM) can revolutionize mechanical, aerospace, and biomed-AFRL AM modeling challenge series [5], to facilitate the development of metal AM modeling tools.</p>
<p>Among various computational models at different scales and fidelity, thermal-fluid process simulation is not only an essential tool to understand the metal AM physics but also acts as a spearhead to derive the process-structureproperty relationship.The metal AM process is intrinsically a multi-scale and multi-physics problem, involving rapid, complex, and coupled mass/flow/heat exchanges between gas, liquid, and solid phases, with large density ratios and complicated interfacial phenomenon.Current numerical simulation tools often employ mathematical models that couple Navier-Stokes equations and a heat transfer equation to capture the evolution of temperature and melt pool dynamics during manufacturing processes.For decades, the manufacturing community has been adopting computational methods that directly solve these mathematical models or their weak forms, based on spatial discretization (e.g., finite difference, finite volume, finite element, and mesh-free methods) and time-stepping.</p>
<p>The predictive capacities of these approaches have been significantly enhanced, thanks to the researchers' persistent efforts in numerical method development from the manufacturing and computational mechanics/mathematics communities.For example, Lawrence Livermore National Lab developed a thermal-fluid solver using the Arbitrary-Lagrangian Eulerian technique, which can simulate laser powder bed fusion (LPBF) processes at powder-scale [6][7][8][9]; Knapp et al. [10] and Mukherjee et al. [11,12] developed a coupled thermal-fluid model to simulate directed energy deposition (DED) and laser powder bed fusion (LPBF) processes.Lin et al. [13,14] developed a control-volume finite element approach to simulate directed energy deposition process.Lattice Boltzmann method has been used to model the metal powder melting and re-solidification in [15][16][17]; Zohdi group employed a discrete particle method to describe the selective laser sintering process [18][19][20]; Yan et al. developed a volume-of-fluid (VoF) based thermal-fluid solver to model multi-layer and multi-track LPBF process [21][22][23][24][25]; Panwisawas et al. also employed a VoF method by using OpenFOAM to analyze the inter-layer and inter-track void formation [26]; Li et al. developed a thermal-fluid model by combining level set method and Lagrangian particle tracking to investigate powder-gas interaction in LPBF processes [27].CFD-ACE+, a code developed by ESI group, has been used to analyze the defects such as porosity, balling, and denudation in metal AM [28,29]; The last author of this paper [30] developed a gas-liquid-solid thermal flow model based on the level set method and residual-based variational multiscale method to simulate laser spot melt pool flows.Li. et al. used a mesh-free model based on material point method for selective laser beam melting processes [31].Gan et al. developed a finite element method (FEM) based thermal-fluid model and applied it to the NIST AM-Bench problems [32].</p>
<p>The core of these conventional approaches can be viewed as the process of using numerical approximations to solve PDEs without using labeled experimental/computational data.Despite the continued success and evolution, these methods require sophisticated mathematical treatments for spatiotemporal discretizations, coupling strategies, boundary conditions, and linear solvers to ensure stability, robustness, and efficiency.The application of these approaches to real additive manufacturing problems is prohibitively expensive and intricate.The high-fidelity simulations are typically executed in a parallel environment and consume massive high-performance computing (HPC) hours.Also, the performance of these approaches is often problem-dependent, necessitating numerical practitioners to have a deep understanding of not only the manufacturing problems but also the underlying mathematical techniques.</p>
<p>Machine learning (ML) and artificial intelligence (AI) have the potential to accelerate breakthroughs in thermalfluid modeling for metal AM processes by harnessing data from sensors, experiments, and high-fidelity simulations.In general, ML focuses on algorithmic modeling of data and making predictions of labels based on observations, with emphasis on making accurate predictions for classification and regression tasks.Modern deep learning approaches have demonstrated tremendous successes in domains ranging from sentiment analysis to chemical predictions to material design [33][34][35][36][37][38].The first reason for the major success of modern ML techniques, especially deep learning, is the availability of vast amounts of data (big-data).The second reason is that many technical burdens have been mitigated by advances in both hardware and software, including high-performance computers, graphics processing units (GPUs), fast largescale optimization schemes, new optimality guarantees, and many user-friendly open-sourced packages, such as Tensorflow [39], PyTorch [40], Theano [41], and Caffe [42].</p>
<p>However, using deep learning for AM process modeling is still challenging.The primary challenge arises from the lack of large labeled data-sets since either experimental measurements or high-fidelity simulated data of AM processes are expensive to attain, rendering the big data-based ML/AI algorithms infeasible.The good news in scientific problems, however, is that there is highly condensed knowledge and expertise available in fundamental conservation, evolution, or constitutive principles, which are often expressed as a set of partial differential equations (PDEs).One can incorporate this type of knowledge into ML/AI models to enhance their predictive capability in sparse data regions.Nowadays, these approaches are coined as scientific machine learning (SciML) in the computational mathematics/mechanics communities.In particular, a widely used approach in SciML is to train a conventional deep learning (DL) model such as Gaussian process regression (GPR) [43,44] or deep neural network (DNN) [45][46][47][48][49] with physical principle constraints.Existing research has demonstrated SciML's capability in sparse-data scenarios for various application areas, such as environmental study [50,51], material science [52,53], and cardiovascular modeling [46,54,55].</p>
<p>Although most of the SciML applications are restricted to single physics systems, we envision the general concept can be extended to tackle the multi-physics problems in metal AM.Thus, this paper put forth a SciML framework for metal additive manufacturing processes to predict the temperature field and melt pool fluid dynamics via a physics-informed neural network (PINN).We aim to fully take advantage of the prediction capabilities of deep neural networks while significantly reducing the amount of costly training labeled data.To this end, the physical conservation laws of momentum, mass, and energy are fused into a fully connected neural network by penalizing the loss function with the residuals of the Navier-Stokes equations and enthalpy conservation equation on a set of collocation points.Owed to this additional knowledge, the learning process only requires a small amount of labeled data-set.Besides, to impose the necessary Dirichlet boundary condition (BC), we borrow the idea from the interface-capturing approach widely used in multiphase fluid mechanics, in which a small portion of the neural network is solely used to enforce the Dirichlet BC by a Heaviside function.This "hard" approach can not only precisely satisfy the Dirichlet BC but also speed up the learning process, compared with the conventional "soft" approach that uses additional constraint in the loss function to enforce the BC.Once the model is trained, the quantities of interest, such as temperature, velocity, pressure, and melt pool dimensions, can be predicted accurately.</p>
<p>The paper is structured as follows.Section 2 represents the physics-informed neural network framework, in which the PDEs of physical principles, design of loss function, enforcement of Dirichlet BC, and training procedures are introduced in an articulated way.Section 3 presents the training data generation by using a FEM based residualbased variational multi-scale thermal fluid flow formulation.Section 4 demonstrates the applications of the PINN framework to two representative manufacturing problems.The first application is using the PINN framework to solve a classic solidification problem from the textbook by Dantzig and Rappaz [56].For this problem, the PINN is informed by the energy conservation law and trained without labeled data-set.We compare the performance of "hard" BC and "soft" BC on this problem in terms of both accuracy and learning efficiency.The predictive capability of the PINN is assessed by comparing it with the standard finite element method (FEM) with resolution refinement studies.The second application is utilizing the PINN framework to predict the temperature field and melt pool fluid dynamics for the 2018 NIST AM-Bench test series.We utilize a validated finite element based variational multi-scale formulation (VMS) [30] to generate the synthetic training data-sets.The investigations show that the PINN, informed by conservation laws of momentum, mass, and energy, can accurately and efficiently predict the melt pool dimension, fluid field, and cooling rate for the three selective laser beam melting tests done by NIST with a small amount of training data.We summarize the contributions and limitations of the paper and outline future work in Sect. 5.</p>
<p>Machine learning model</p>
<p>Governing partial differential equations</p>
<p>This section presents the governing partial differential equations (PDEs) of the thermal-fluid flows in metal AM processes.The theory of the equations builds upon the tacit assumptions that the solid phase is a highly viscous fluid with the same constant density as the liquid phase, and the loss of metal material due to vaporization [57,58] and the effects on heat loss, composition change and fluid motion are negligible.A flat top surface is adopted based on the fact that the melt pool deformation is small compared with the melt pool dimensions in the problems considered in the paper.With the above assumptions, the thermal-fluid model based on conservation laws of momentum, mass, and energy is defined as the following coupled PDEs
ρ(u ,t + u • ∇u − g) + ∇ p − 2μ u = 0 (1) ∇ • u = 0 ( 2 ) (ρc p T ) ,t + u • ∇(ρc p T ) + (ρ L f L ) ,t + u • ∇(ρ L f L ) − κ∇ 2 T − Q T = 0(3)
Here Eqs. 1 and 2 are the Navier-Stokes equations of incompressible flows, where u is the velocity field, p is the pressure field, g is the gravitational acceleration vector, ∇ is the gradient operator, is the Laplace operator, ρ and μ are the density and dynamic viscosity, respectively.Equation 3 is the conservation equation of energy, where T is the temperature, c p is the specific heat capacity, L is the latent heat of fusion, κ is the thermal conductivity, Q T is an energy source.</p>
<p>To have well-posed systems, Eqs.1-3 are subjected to the following Dirichlet and Neumann boundary conditions where u bc , p bc and T bc are the prescribed velocity, pressure, and temperature on Dirichlet boundaries, respectively.τ and q are the prescribed traction and heat flux on the Neumann boundaries, respectively.∇ S is a symmetric gradient operator and n is the unit normal vector on the boundary.
u = u bc (4) p = p bc (5) T = T bc (6) − pn + 2μ∇ S u • n = τ (7) κ∇T • n = q (8)
In the model, the solid and liquid phases are distinguished by a liquid fraction f L , which takes 1 in the liquid phase, 0 in the solid phase, and a linear profile in the mushy zone [59].f L is defined as
f L = ⎧ ⎨ ⎩ 0 i f T &lt; T s T −T s T l −T s i f T s ≤ T ≤ T l 1 i f T &gt; T l(9)
where T s and T l are the solidus and liquidus temperature, respectively.With the assistance of f L , the material properties in the thermal-fluid model are evaluated by the following interpolation
ψ = f L ψ L + (1 − f L )ψ S (10)
where ψ denotes the specific material property in the model (e.g., density, dynamic viscosity, specific heat capacity, heat conductivity), and ψ L and ψ S are the corresponding property in the liquid and solid phase, respectively.</p>
<p>Physical informed neural network (PINN) for thermal-fluid flows</p>
<p>Neural network is a computing architecture that is vaguely inspired by the biological neural networks that constitute animal brains [60].Some typical neural network architectures are fully connected neural network (FC-NN) [61], convolutional neural network (CNN) [62], and recurrent neural network (RNN) [63], which have been successfully used in a variety of machine learning applications, such as system identification and control, signal classification, pattern recognition, 3D reconstruction, sequence recognition, social network filtering, data mining, and medical diagnosis [48,[64][65][66][67].In this paper, the PINN of the thermal-fluid model makes use of a fully connected deep neural network (FCNN) [61],</p>
<p>where the neurons of adjacent layers are fully connected.</p>
<p>Figure 1 shows the schematic picture of the fully connected neural network used in this paper, which consists of an input layer, hidden layers, and an output layer.A neural network with more than one hidden layer is conventionally called a deep neural network, whose function approximation capability increases with the number of hidden layers and neurons [68].A deep neural network maps the input z 0 to the output z N layer −1 from the input layer to the output layer, where N layer is the number of layers.In the hidden layers, each layer receives outputs from the previous layer and feeds forward inputs to the next layer.The relation of between the input z l−1 and output z l of the l th layer (l = 1, ..., N layer − 1) is defined as
z l = σ l (w T l z l−1 + b l ) (11)
where w l and b l are the weight matrix and bias vector of this layer.The dimensions of w l and b l are N l−1 × N l and N l , respectively, where N l is the number of neurons in l th layer.</p>
<p>In this paper, we denote the entire hidden parameters of a neural network as W = l w l and b = l b l .The dimensions of W and b are
N layer −2 l=0 N l × N l+1 and N layer −1 l=1 N l , respectively.
σ l in Eq. 11 is the activation function that can introduce the non-linearity to the system [69].Widely used activation functions in deep learning are tanh function, rectified linear unit (Relu) function, and sigmoid function [70].In this paper, we employ a swish activation function [71], which is a smoothed version of Relu function, defined as
σ l (x) = swish(x) = x sigmoid(x) = x/(1 − e −x ) (12)
Neural network is a nonlinear parametric function approximator, so all the information of unknown function (velocity, pressure, and temperature) can be represented by hidden parameters W and b.The goal of the neural network is to learn the following mapping for a given set of manufacturing parameters (e.g,.alloy properties, laser power, and scanning speed):
[t, x] W,b − − → <a href="13">u N N , p N N , T N N </a>
where the input [t, x] are the collocation points (in both space and time) of interest.The output u N N , p N N , T N N are the velocity, pressure, and temperature fields we want to predict.To enable such a mapping, the hidden parameters of the neural network, W and b, need to be identified by optimizing a meticulously designed loss function, which will be given in the next section.Once W, and b are determined, the output prediction can be easily achieved by a feed-forward evaluation, which is very efficient since only a few matrix multiplications are needed in Eq. 11.</p>
<p>Loss function design</p>
<p>The Let û, p, and T denote the available labeled data for velocity, pressure, and temperature, respectively.These labeled data can be either obtained by experiments or validated highfidelity simulations.As a mean squared deviation (MSD) of the discrepancy between the prediction and labeled data, the component in the loss function from the data constraint, L data , is defined as
L data (W, b) = 1 N u N u i=1 u N N (x i , t i , W, b) − û(x i , t i ) 2 + 1 N p N p i=1 p N N (x i , t i , W, b) − p(x i , t i ) 2 + 1 N T N T i=1 T N N (x i , t i , W, b) − T (x i , t i ) 2 (14)
where N u , N p , and N T are the number of labeled velocity, pressure, and temperature data points, respectively.Conventional off-the-shelf machine learning tools purely minimize this loss function to identify the hidden parameters.The success of this approach requires a massive amount of data-sets.However, considering the cost of experimental measurements and high-fidelity simulations, these labeled velocity, pressure, and temperature data points are expensive (sometimes impossible) to obtain.This limitation hinders the direct application of big-data based machine learning tools to metal AM process prediction.</p>
<p>To alleviate the dependence on big-data, we substitute extra expertise in fundamental physical principles into the loss function.These physical principles, often expressed as a set of PDEs with appropriate initial and boundary conditions, are highly condensed knowledge of fundamental physical mechanisms that can inform the neural network.For that, we first define the following residuals of conservation equations of momentum, mass, and energy (corresponding to Eqs. (1-3)) as
⎧ ⎪ ⎪ ⎨ ⎪ ⎪ ⎩ r M := ρ(u ,t + u • ∇u − g) + ∇ p − 2μ u r C := ∇ • u r T := (ρc p T ) ,t + u • ∇(ρc p T ) + (ρ L f L ) ,t + u • (ρ L∇ f L ) − κ∇ 2 T − Q T (15)
To have well-posed systems, appropriate initial and boundary conditions are often necessary.In this paper, the initial boundary conditions are treated as part of the labeled data constraint.For boundary conditions (BCs), many existing PINN frameworks utilize a "soft" approach by designing additional loss components defined on the collocation points of boundaries to constrain the BCs.The downsides of this approach are two-fold: (1) The accuracy of satisfying the BCs is not guaranteed ; (2) The assigned weight of BC loss can affect learning efficiency, and no theory is existed to guide choosing the weight at this point.</p>
<p>In this paper, we treat the Dirichlet BC in a "hard" way by using a particular portion of the neural network to purely satisfy the prescribed Dirichlet BC.For that, we first define a Heaviside function as
H (x) = 1 − cos[d(x)π/ ] if d(x) &lt; 1 i fd(x) ≥(16)
where d(x) is the distance to the Dirichlet boundary.defines a artificial thickness of the boundary.With H (x), the predictions of the neural networks are defined as
u N N = u bc [1 − H (x)] + uH (x) (17)p N N = p bc [1 − H (x)] + pH (x) (18)T N N = T bc [1 − H (x)] + T H (x)(19)
where u bc , p bc , and T bc are the prescribed velocity, pressure, and temperature.u, p, and T are the solutions that satisfy the PDEs in the interior.Since H (x) smoothly changes from 1 to 0 as d(x) approaches to 0, the prediction will automatically satisfy the prescribed values by definition, without needing additional constraint.Then, the loss term from the PDEs with embedded Dirichlet BCs is defined as.
L 1 pde (W, b) = 1 N r 1 N r 1 i=1 r M [u N N (x i , t i , W, b), p N N (x i , t i , W, b), T N N (x i , t i , W, b))] 2 + 1 N r 1 N r 1 i=1 r C [u N N (x i , t i , W, b), p N N (x i , t i , W, b), T N N (x i , t i , W, b))] 2 + 1 N r 1 N r 1 i=1 r T [u N N (x i , t i , W, b), p N N (x i , t i , W, b), T N N (x i , t i , W, b))] 2(20)
where N r 1 denotes the number of collocation points to constrain the PDEs.In the thermal-fluid flow model for metal AM processes, Neumann BCs incorporate surface tension for flow field and laser for thermal field.In this paper, the Neumann BCs are handled by the conventional way, where the following term is added in the loss function
L 2 pde (W, b) = 1 N r 2 N r 2 i=1 2μ∇ S u N N (x i , t i , W, b) • n − p N N (x i , t i , W, b)n − τ (x i , t i )} 2 + 1 N r 3 N r 3 i=1 [κ∇T N N (x i , t i , W, b)• n − q(x i , t i )] 2(21)
where N r 2 and N r 3 denote the number of collocation points on the fluid and temperature Neumann boundaries, respectively.</p>
<p>With above definitions, The hidden parameters W and b are obtained by minimizing the following total loss function, which are a linear combination of data constraint of L data and PDE constraints of L 1 pde and L 2 pde .</p>
<p>min
W,b L(W, b) = (1 − λ 1 pde − λ 2 pde )L data (W, b) + λ 1 pde L 1 pde (W, b) + λ 2 pde L 2 pde (W, b)(22)
where λ 1 pde and λ 2 pde are two positive numbers between 0 and 1, which define the weight of the physical law constraints in the loss function.The choice of the weights influences both the learning process and the prediction accuracy.No universal guideline exists for choosing the optimal weights at this point.We select the weights based on the ratios between different components in the loss function in this paper.We firstly estimate the magnitude of the PDE residual loss, boundary condition loss, and data loss.The ratios of PDE residuals can be roughly evaluated by the high fidelity simulations that generate training and validation data-sets (the formulation will be presented next).Then we specify the λ 1 pde and λ 2 pde so that the ratios of the three components are at the balanced level.</p>
<p>Learning procedure</p>
<p>The PINN model is trained by minimizing the loss function defined in Eq. 22 with respect to W and b.The minimization is executed by the following procedures: (1) The coordinates of collocation points and training data are substituted into Eq.22.</p>
<p>(2) Take the derivatives of the loss function with respect to W and b.</p>
<p>(3) Update W and b by a gradient descent.Most of current machine learning frameworks solve the optimization problem by a stochastic gradient descent (SGD) algorithm, which is a stochastic approximation of the gradient descent optimization [72].SGD only uses a subset of collocation points, randomly sampled from the input space at each iteration, to calculate the directional gradient.Research shows that SGD works very well to skip bad local minima.One issue with SGD is the oscillation of gradient direction caused by the random selection of sampled collocation points.In this paper, the Adam method [73] that combines adaptive learning rate and momentum methods is used to improve convergence speed [73].</p>
<p>The PINN learning process needs the spatial and temporal derivatives of W and b, which can be accurately and efficiently calculated by using automatic differentiation (AD) [74].The basic idea of AD is to use the chain rule to backpropagate derivatives from the output layer to the input layer since the connection between layers of a neural network is analytically defined.Compared to numerical differentiation techniques (e.g., finite difference and finite element), AD does not suffer from truncation or round-off errors, resulting in much higher accuracy.AD has been gaining increasing attention in the machine learning community and has been implemented in many modern deep learning frameworks, such as TensorFlow [39], PyTorch [40], Theano [41], and Caffe [42].In this paper, the PINN formulation is implemented in TensorFlow.</p>
<p>Training data generation: high fidelity FEM simulations</p>
<p>Due to the limited available experimental labeled data-sets, the high-fidelity thermal-fluid finite element model based on our previous work in [30] is utilized to generate the labeled data for AM processes.Only a small portion of simulated data will be used to train the PINN model, and the simulated data is also used to access the model's accuracy.The thermal-fluid FEM model makes use of a residual-based variational multiscale formulation (VMS).The core formulation is briefly presented as follows.Let W denote the testing function space for the Navier-Stokes and energy conservation equations, V denote the unknown velocity u, pressure p, and temperature T fields.The RBVMS formulation of thermal-fluid flows is stated as: ∀{v, q, η} ∈ W, find {u, p, T } ∈ V, such that
v • ρ u ,t + u • ∇u − g d + p∇ • vd − v • hd + ∇ s v : μ∇ s ud + q∇ • ud + η (ρc p T ) ,t + u • ∇(ρc p T ) + (ρ L f L ) ,t + u • ∇(ρ L f L ) d + ∇η • κ∇T d − ηQ T d + n el e=1 e τ M u • ∇v + ∇q ρ • r M d + n el e=1 e ρτ C ∇ • vr C d − n el e=1 e τ M v • [r M • ∇u] d − n el e=1 e ∇v ρ : (τ M r M ⊗ τ M r M )d + n el e=1 e τ T (u • ∇η)r T d = 0 (23)
where = e e is the computational domain, which is decomposed into n el elements.h is the applied traction on the Neumann boundary .r M , r C , and r T are the residuals of momentum, continuity, and energy conservation equations (see Eq. 15).τ M , τ C , and τ T are the corresponding stabilization parameters [30], defined as.
τ M = 4 t 2 + 4 u 2 h 2 + 16ν 2 h 4 −1/2(24)τ C = h 2 12τ M (25) τ T = 4 t 2 + 4 u 2 h 2 + 16κ 2 ρ 2 c 2 p h 4 −1/2 (26)
where t is the time step, h is the charateristic element length, and ν is the kinematic viscosity.Other widely used stabilization parameters can be found in [75,76,76,77,77,78].The unknown velocity, pressure, and temperature are solved in a fully coupled fashion.Generalized-α method is used for time integration.The nonlinear equations are linearized by Newton's method.The resulting linear systems are solved by a generalized minimal residual method (GMRES) with block preconditioning [79].The formulation is implemented for parallel environments using the Message Passing Interface (MPI).The formulation has been validated with a series of metal manufacturing problems in [30].It worths noting that the VMS and its extensions on moving fluid domains using Arbitrary Lagrangian-Eulerian technique (ALE-VMS) [80][81][82][83][84][85] and Space-Time (ST-VMS) technique [86][87][88][89][90] have been used as high-fidelity models to simulate a set of challenging fluid dynamics and fluid-structure interaction problems [91].Several recent applications include environmental flows [92], wind energy [87,[93][94][95][96][97][98][99][100][101][102], tidal energy [103][104][105], biomechanics [106,107,107,108], gas turbine [109][110][111][112][113] and transportation engineering [114,115].</p>
<p>Applications</p>
<p>Solidification of aluminum in a graphite mold without labeled data</p>
<p>The solidification process of aluminum in a graphite mold from the textbook Solidification by Dantzig and Rappaz [56] is investigated to assess the PINN formulation's performance.Only thermodynamics with phase transition is considered in the simulations here.Figure 2 shows the problem setup, where the left half of the domain (− 0.4 m ≤ x ≤ 0.0 m) is occupied by a solid graphite mold with temperature T low = 298.15K, and the right half of the domain (0.0 m &lt; x ≤ 0.4 m) is occupied with liquid aluminum with temperature T high = 973.15K, which is higher than the melting temperature of aluminum T melt = 933.15K .The solidification process, depicted in Fig. 2 (lower), occurs by transferring heat from the aluminum into the mold, and the solid-liquid interface propagates towards the right end.The material properties of the graphite mold and aluminum are given in Table 1.The analytical solutions have been derived in [56] for this problem and are specified as follows.</p>
<p>x * = 7.095  where x * is the solid-liquid interface location over time, T m , T s , and T l are the temperature distribution in the mold, solid aluminum, and liquid aluminum, respectively.Despite the simplicity, solving this problem provides valuable insights into the solidification behavior and the machine learning model's performance.The PINN model employs 5 hidden layers and 200 neurons of each layer, which provides better results over others based on our non-exhaustive investigation.The neural network is only informed with the energy conservation principle defined in Eq. 3 and trained without labeled data-set.No data component is not used in the loss function.The PINN model predicts the temperature distribution from t = 5 s to t = 10 s.
× 10 −3 √ t m (27)
Figure 3 illustrates the PINN setup and the resulting temperature prediction in the space-time (x − t) slab for the solidification process.We compare the performance of the proposed "hard" approach with the conventional "soft" approach for the Dirichlet boundary condition in Fig. 4, which depicts the learning process and temperature predictions at 10 s.The plot shows that the "hard" approach can not only facilitate the learning process (see Fig. 4 (left)) but also produce more accurate temperature prediction (see Fig.</p>
<p>(right)).</p>
<p>One important question is how the PINN's predictive capability compares with traditional numerical methods, such as the finite element method (FEM).To answer this question, we simulate this solidification problem by using PINN with four different numbers of collocation points and linear FEM with four equivalent resolutions (N x = 50, 100, 150, and 200 along x direction).Figure 5 shows the predictions of PINN and FEM for the time history of the solid-liquid interface position with the four resolutions.The convergence rate of error of temperature prediction over the x − t slab is shown in Figure 6.The two plots indicate that PINN and FEM obtain similar convergence rates.However, when the resolution is low, the PINN still attains high accuracy while a noticeable discrepancy is observed for the standard FEM.</p>
<p>NIST AM-bench test series</p>
<p>In this section, we apply the PINN framework to the Additive Manufacturing Benchmark (AM-Bench) test series conducted by the National Institute of Standards and Technology (NIST) [116,117].In 2018, NIST performed a series of metal AM experiments with different manufacturing parameters, which attracted blind simulations to compare with the in-situ and ex-situ measurements, such as temperature, melt pool dimensions, and micro-structures [116].The archived experimental measurements provide valuable benchmark data for modelers to test the predictive capabilities of simulation models.In this paper, we use the proposed PINN framework to predict the temperature, melt pool fluid dynamics, melt pool dimensions, and cooling rates during the NIST AM processes, which corresponds to the first challenge in the NIST AM-Bench test series [117].To the authors' best knowledge, this is the first application of PINN to three-dimensional metal AM processes.2. The laser is applied by imposing the following moving heat flux on the substrate.
κ∇T • n = q laser = 2Qη πr 2 b ex p −2((x − V s t) 2 + y 2 ) r 2 b (31)
where Q is the laser power, η is the absorptivity, r b is the laser beam radius, V s is the laser scanning speed.η = 0.43 and r b = 50 μm are used in this paper.Table 3 lists the laser power and scanning speed of three cases used in the NIST experiments.Based on the fact that the top surface deformation is relatively small compared with the melt pool dimension, a flat top surface is assumed, and the following boundary condition is applied for the fluid field.3, but only a small portion of the simulated data between 1.2 and 1.5 ms is used as labeled training data in the PINN model, which then predicts the manufacturing processes for a wider time interval from 0 ms to 2.0 ms.We first compare the predicted results of FEM and PINN with available experimental data for case B (195 W, 0.8 m/s).The purpose is two-fold: (1) Ensure the credibility of FEM data as the training data; (2) Validate the PINN model.Figure 9 shows the temperature field, melt pool fluid dynamics, and melt pool shape at 2.0 ms.The fast-moving laser, along with the effect of a negative Marangoni coefficient that drives the liquid metal from the higher temperature region to the lower temperature region, leading to a long and shallow melt pool.The predicted temperature profile along the scan track and experimental measurement extracted from [119] are plotted in Fig. 10  We then apply the PINN model to all the three cases listed in Table 3.The predicted melt pool shape and the fluid velocity field within the melt pool are presented in Fig. 11.The laser results in high velocity in the melt pool, which reaches up to 1.641 m/s, 1.566 m/s, and 1.446 m/s for the case A, B, and C, respectively.The predicted melt pool dimensions compared with the present FEM results, the thermal-fluid simulation results by Gan et al. [32] that won an award in the NIST AM-bench competition, and available NIST experimental measurements are listed in A critical factor in metal AM is the cooling rate, which profoundly influences dendrite arm spacing, grain structure, micro-segregation, and hot cracking.In this paper, the cooling rate is calculated as
− pn + 2μ∇ s u • n = τ = dσ dT [∇T − (∇T • n)n] (32)R c = T s − 1273.15K t c (33)
where t c = (D s − D 1273.15 )/V s , the cooling time interval determined by dividing the distance between solidus temperature and 1273.15K by the scanning speed V s .Table 5 presents the PINN prediction of cooling rate R c for the case A, B, and C. The results of FEM, Gan's results, and experimental measurements are also listed for compar-ison.Both modeling and experiment show that cooling rate increases from case A to case C. For the cooling rate, the relative discrepancy (with respect to the mean NIST measurements) of PINN, FEM, and Gan's predictions are 37.7%, 29.0% and 17.6% for case A, 8.1%, 12.7% and 26.3% for case B, and 7.8%, 7.8% and 11.7% for case C.Although all the models' prediction accuracy becomes lower compared with melt pool dimension prediction, we notice that the NIST measurements in cooling rates also exhibit significantly higher fluctuations than melt pool dimension measurements.Nevertheless, if using this discrepancy as an accuracy metric, the proposed PINN model only underperforms in case A and outperforms in both case B and case C, which is advantageous compared with the other two high-fidelity FEM simulations that employ millions of elements.</p>
<p>Conclusion</p>
<p>This paper presents the first attempt of using the physicsinformed neural network (PINN) to predict the temperature and melt pool fluid dynamics in metal AM processes.We applied the PINN model to two representative metal manufacturing problems.The results show that the PINN can accurately predict the quantities of interest by only using a small amount of labeled training data.This paper is also the first few applications of scientific machine learning (SciML), currently confined to single-phase systems, to complex multiscale and multi-physics problems that involve multi-phase fluid dynamics, heat transfer and phase transition.The two major technical contributions relevant to metal AM of the paper are:</p>
<p>-A SciML framework for metal AM processes, which can accurately predict temperature, pressure, and velocity field without relying on big-data.-A "hard" approach for imposing Dirichlet boundary condition, which exactly imposes the prescribed value and speeds up the learning process.</p>
<p>Although deep learning models cannot replace conventional numerical tools that will continue to be the principal player, the initial success presented in this paper demonstrates PINN's potential on the modeling and prediction of complicated metal AM processes and paves the way for the broad adoption in advanced manufacturing.</p>
<p>We also have to admit that this paper does not comprehensively handle the complexity of metal AM processes.To be precise, the PINN model here does not resolve the ambient gas phase, free-surface deformation of the melt pool, and the evaporation phenomenon, although the effects are not crucial for the applications considered in the paper.In terms of computational efficiency in AM simulations, we didn't make a quantitative comparison between FEM and PINN in this paper because of the different computing machines: the FEM was performed in a CPU parallel environment with 192 processors at Stampede2, while the PINN was performed using GPU with only four cores at Frontera.The general observation is that the more training data is, the more efficient the PINN is.Under an extreme scenario with no training data, the PINN, as a PDE solver, is two times slower than FEM in a sequential computing environment, as tested in the 1D solidification problem.</p>
<p>In the future, the multi-phase Navier-Stokes will be enhanced with the evaporation model in the momentum equations, which was used in our control volume finite element model [14], to capture the heat loss, composition change, and fluid motion induced by evaporation.Additional PDEs, such as convection equation of level set or volume-of-fluid used in the previous works [23,30], will be incorporated into the PINN to enable modeling metal AM process at the powder scale.</p>
<p>Fig. 1 A
1
Fig. 1 A fully connected deep neural network for metal AM</p>
<p>loss function, L(W, b), in the PINN for thermalfluid flows consists of two components: L data (W, b) and L pde (W, b), which represents the constraint of matching existing labeled data and the constraints of satisfying fundamental physical principles.Their definitions are given as follows.</p>
<p>Fig. 2
2
Fig.21D solidificaton process from[56]</p>
<p>Fig. 3 Fig. 4 Fig. 5
345
Fig. 3 PINN model for the solidification problem.Left: PINN setup.Right: Temperature prediction</p>
<p>Fig. 6 L
6
Fig. 6 L 2 norm of prediction error of PINN and FEM with different resolutions</p>
<p>Fig. 7
7
Fig. 7 NIST AM-bench test series</p>
<p>Fig. 8
8
Fig.8The mesh employed in the high-fidelity FEM thermal-fluid simulations</p>
<p>) 3 .
3
0 × 10 −5 T 2 − 0.0366T + 18.588 Liquid solid conductivity κ l (W m −1 K −1 ) 3 0 .078Latent heat of fusion c L (KJ kg −1 K −1 ) 290 Dynamic viscosity μ (Pa s) 7 × 10 −3 Marangoni coefficient ∂γ ∂ T (N m −1 K −1 ) −2 × 10 −5Reference temperature T re f (K) 295</p>
<p>Fig. 9
9
Fig. 9 Comparison of the predictions of the temperature and melt pool fluid dynamics of FEM, PINN and experiment for case B (195 W, 0.8 m/s) at quasi-steady state (2 ms), when the melt pool shape is not chang-</p>
<p>for comparison.The predicted results by both FEM and PINN show good agreement with available experimental data.Figures 9 and 10 also show that the PINN model, with a moderate amount of training data, can generate very similar predictions of temperature, melt pool length, and melt pool fluid velocity to those of FEM.</p>
<p>Fig. 10
10
Fig.10 Temperature profile along the scan track for case B (195 W, 0.8 m/s) at quasi-steady state.Experimental data extracted from NIST AM-Bench test series[119] are also plotted for comparison.(Please note we cut off the temperature inside the melt pool since the experimental provides an almost constant temperature.)</p>
<p>Fig. 11
11
Fig. 11 Melt pool shape and the temperature and melt pool flow velocity predicted by PINN for case A, B and C at quasi-steady state (2 ms)</p>
<p>Table 1
1
Definition of material properties for the solidification problem
MaterialsGraphiteAluminumAluminum(solid)(liquid)Density (kg/m 3 )220025552555Specific heat (J/(kg K))170011901190Thermal conductivity10021191(W/(kg K))Latent heat (J/kg)-398000-T m = 769.95 + 471.8er f96.69x √ tK(28)T s = 769.95 + 360.2er f60.02x √ tK(29)T 91.39x √ tK(30)
l = 973.15− 111.4er f c</p>
<p>Table 3
3
Three laser parameters
ParametersCase ACase BCase CLaser power150 W195 W195 WScan speed0.4 m/s0.8 m/s1.2 m/s</p>
<p>Table 2
2Mechanical properties of IN625NameNotation (units)ValueDensityρ (kg −3 )8440Solidus temperatureT s (K)1563Liquid temperatureT l (K)1623Solid specific heat capacityc ps (J kg −1 K −1 )0 .2441T + 338.39Liquid specific heat capacityc pl (J kg −1 K −1 )709.25Solid solid conductivityκ s (W m −1 K −1</p>
<p>Table 4
4. For</p>
<p>Table 4
4
Melt pool dimensions of case A, B and C
CasesApproachesLength (μm)Width (μm)D e p t h( μm)Case APINN594.8 (9.7%)193.364.0FEM584.4 (11.3%)190.862.8Gan et al. [32]542 (17.8%)--Experiment [119]659 ± 21--Case BPINN740.3 (5.1%)160.052.8FEM743.6 (4.7%)157.552.5Gan et al. [32]843 (8.1%)--Experiment [119]782 ± 21--Case CPINN732.5 (2.9%)131.543.2FEM727.2 (3.6%)130.342.6Gan et al. [32]785 (4.1%)--Experiment [119]754 ± 46--</p>
<p>Table 5
5
Cooling rates of case A, B and C
CasesApproachesSolid cooling rate (K/s)Case APINN8.54 × 10 5 (37.7%)FEM8.00 × 10 5 (29.0%)Gan et al. [32]5 .11 × 10 5 (17.6%)Experiment [119]6 .20 × 10 5 ± 7.99 × 10 4Case BPINN8.59 × 10 5 (8.1%)FEM8.16 × 10 5 (12.7%)Gan et al. [32]6 .89 × 10 5 (26.3%)Experiment [119]9 .35 × 10 5 ± 1.43 × 10 5Case CPINN1.38 × 10 6 (7.8%)FEM1.38 × 10 6 (7.8%)Gan et al. [32]1 1 .30 × 10 5 (11.7%)Experiment [119]1 .28 × 10 6 ± 3.94 × 10 5
Acknowledgements J. Yan is partially supported by ASME Robert M. and Mary Haythornthwaite Research Initiation Award and Singapore National Research Foundation (NRF2018-ITS004-0011).The PINN models were trained at the Texas Advanced Computing Center (Tacc) through a startup allocation on Frontera (CTS20014).These supports are greatly acknowledged.
Real-time monitoring of laser powder bed fusion process using high-speed x-ray imaging and diffraction. C Zhao, K Fezzaa, R Cunningham, H Wen, De Carlo, F Chen, L Rollett, A Sun, T , Sci Rep. 712017</p>
<p>Keyhole threshold and morphology in laser melting revealed by ultrahigh-speed x-ray imaging. R Cunningham, C Zhao, N Parab, C Kantzos, J Pauza, K Fezzaa, T Sun, A Rollett, Science. 36364292019</p>
<p>In-situ full-field mapping of melt flow dynamics in laser metal additive manufacturing. Q Guo, C Zhao, M Qu, L Xiong, S Hojjatzadeh, L Escano, N Parab, K Fezzaa, T Sun, L Chen, Addit Manuf. 311009392020</p>
<p>NIST Additive Manufacturing Benchmark Test Series. AM-BENCH2020. 03 Aug 2020</p>
<p>AFRL Additive Manufacturing Modeling Challenge Series. 2020. 07 July 2020</p>
<p>Ale3d: an arbitrary Lagrangian-Eulerian multi-physics code. C Noble, Anderson A Barton, N Bramwell, J Capps, A Chang, M Chou, J Dawson, D , Diana E Dunn, T , 2017Livermore, CA (United StatesLawrence Livermore National Lab.(LLNL)Techical report</p>
<p>Laser powder-bed fusion additive manufacturing: physics of complex melt flow and formation mechanisms of pores, spatter, and denudation zones. S Khairallah, A Anderson, A Rubenchik, W King, Acta Mater. 1082016</p>
<p>Modulating laser intensity profile ellipticity for microstructural control during metal additive manufacturing. T T Roehling, S S Wu, S A Khairallah, J D Roehling, S S Soezeri, M F Crumb, M J Matthews, Acta Mater. 1282017</p>
<p>S Khairallah, A Martin, J Lee, G Guss, N Calta, J Hammons, M Nielsen, K Chaput, E Schwalbach, M Shah, G Chapman, T Willey, A Rubenchik, A Anderson, Y Wang, M Matthews, W King, Controlling interdependent meso-nanosecond dynamics and defect generation in metal 3d printing. 2020368</p>
<p>Building blocks for a digital twin of additive manufacturing. G Knapp, T Mukherjee, J Zuback, H Wei, T Palmer, A De, T Debroy, Acta Mater. 1352017</p>
<p>Heat and fluid flow in additive manufacturing-part i: modeling of powder bed fusion. T Mukherjee, H Wei, A De, T Debroy, Comput Mater Sci. 1502018</p>
<p>Heat and fluid flow in additive manufacturing-part ii: Powder bed fusion of stainless steel, and titanium, nickel and aluminum base alloys. T Mukherjee, H Wei, A De, T Debroy, Comput Mater Sci. 1502018</p>
<p>Numerical methods and high performance computing for modeling metallic additive manufacturing processes at multiple scales. S Lin, 2019Northwestern UniversityPh.D. thesis</p>
<p>A conservative level set method on unstructured meshes for modeling multiphase thermofluid flow in additive manufacturing processes. S Lin, Z Gan, J Yan, G Wagner, Comput Methods Appl Mech Eng. 3721133482020</p>
<p>Lattice Boltzmann model for thermal free surface flows with liquid-solid phase transition. E Attar, C Körner, Int J Heat Fluid Flow. 3212011</p>
<p>Mesoscopic simulation of selective beam melting processes. C Körner, E Attar, P Heinl, J Mater Process Technol. 21162011</p>
<p>Fundamental consolidation mechanisms during selective beam melting of powders. C Körner, A Bauereiß, E Attar, Model Simul Mater Sci Eng. 218850112013</p>
<p>Additive particle deposition and selective laser processing-a computational manufacturing framework. T I Zohdi, Comput Mech. 5412014</p>
<p>A direct particle-based computational framework for electrically enhanced thermo-mechanical sintering of powdered materials. T Zohdi, Math Mech Solids. 1912014</p>
<p>Multiphysics modeling and simulation of selective laser sintering manufacturing processes. R Ganeriwala, T I Zohdi, Procedia Cirp. 142014</p>
<p>Multi-physics modeling of single/multiple-track defect mechanisms in electron beam selective melting. W Yan, W Ge, Y Qian, S Lin, B Zhou, W K Liu, F Lin, G J Wagner, Acta Mater. 1342017</p>
<p>Meso-scale modeling of multiple-layer fabrication process in selective electron beam melting: inter-layer/track voids formation. W Yan, Y Qian, W Ge, S Lin, W K Liu, F Lin, G J Wagner, Mater Des. 1412018</p>
<p>Data-driven multi-scale multi-physics models to derive process-structure-property relationships for additive manufacturing. W Yan, S Lin, O Kafka, Y Lian, C Yu, Z Liu, J Yan, S Wolff, H Wu, E Ndip-Agbor, M Mozaffar, K Ehmann, J Cao, G Wagner, W Liu, Comput Mech. 6152018</p>
<p>Multi-scale modeling of electron beam melting of functionally graded materials. W Yan, W Ge, J Smith, S Lin, O Kafka, F Lin, W Liu, Acta Mater. 1152016</p>
<p>Spattering and denudation in laser powder bed fusion process: multiphase flow modelling. H Chen, Yan W , Acta Mater. 1962020</p>
<p>Mesoscale modelling of selective laser melting: thermal fluid dynamics and microstructural evolution. C Panwisawas, C Qiu, M J Anderson, Y Sovani, R P Turner, M M Attallah, J W Brooks, H C Basoalto, Comput Mater Sci. 1262017</p>
<p>Revealing transient powdergas interaction in laser powder bed fusion process through multi-physics modeling and high-speed synchrotron x-ray imaging. X Li, C Zhao, T Sun, W Tan, Addit Manuf. 351013622020</p>
<p>Powder bed models-numerical assessment of as-built quality. M Megahed, H-W Mindt, B Shula, A Peralta, J Neumann, 57th AIAA/ASCE/AHS/ASC structures, structural dynamics, and materials conference. 20161657</p>
<p>Modeling of powder bed manufacturing defects. H-W Mindt, O Desmaison, M Megahed, A Peralta, J Neumann, J Mater Eng Perform. 2712018</p>
<p>A fully coupled finite element formulation for liquid-solid-gas thermo-fluid flow with melting and solidification. J Yan, Yan W Lin, S Wagner, G , Comput Methods Appl Mech Eng. 3362018</p>
<p>Meshfree simulations for additive manufacturing process of metals. Z Fan, B Li, Integrat Mater Manuf Innov. 822019</p>
<p>Benchmark study of thermal behavior, surface topography, and dendritic microstructure in selective laser melting of inconel 625. Z Gan, Y Lian, S E Lin, K K Jones, W K Liu, G J Wagner, Integrat Mater Manuf Innov. 822019</p>
<p>Transfer learning of deep material network for seamless structure-property predictions. Z Liu, C Wu, M Koishi, Comput Mech. 6422019</p>
<p>A deep material network for multiscale topology learning and accelerated nonlinear modeling of heterogeneous materials. Z Liu, C Wu, M Koishi, Comput Methods Appl Mech Eng. 3452019</p>
<p>Exploring the 3d architectures of deep material network in data-driven multiscale mechanics. Z Liu, C Wu, J Mech Phys Solids. 1272019</p>
<p>Data-driven self-consistent clustering analysis of heterogeneous materials with crystal plasticity. Z Liu, O Kafka, C Yu, W Liu, Advances in computational plasticity. E Oñate, D Peric, E De Souza Neto, M Chiumenti, Springer2018</p>
<p>Microstructural material database for self-consistent clustering analysis of elastoplastic strain softening materials. Z Liu, M Fleming, W Liu, Comput Methods Appl Mech Eng. 3302018</p>
<p>Self-consistent clustering analysis: an efficient multi-scale scheme for inelastic heterogeneous materials. Z Liu, M Bessa, W Liu, Comput Methods Appl Mech Eng. 3062016</p>
<p>Tensorflow: a system for large-scale machine learning. M Abadi, P Barham, Chen J Chen, Z Davis, A Dean, J , Devin M Ghemawat, S Irving, G Isard, M , 12th {USENIX} symposium on operating systems design and implementation. 201616</p>
<p>Pytorch: an imperative style, high-performance deep learning library. A Paszke, S Gross, F Massa, A Lerer, J Bradbury, G Chanan, T Killeen, Z Lin, N Gimelshein, L Antiga, Advances in neural information processing systems. H Wallach, H Larochelle, A Beygelzimer, F Alché-Buc, E Fox, R Garnett, 2019</p>
<p>F Bastien, P Lamblin, R Pascanu, J Bergstra, I Goodfellow, A Bergeron, N Bouchard, Warde - Farley, D Bengio, Y Theano, arXiv:1211.5590new features and speed improvements. </p>
<p>Caffe: convolutional architecture for fast feature embedding. Y Jia, E Shelhamer, J Donahue, S Karayev, J Long, R Girshick, S Guadarrama, T Darrell, Proceedings of the 22nd ACM international conference on multimedia. the 22nd ACM international conference on multimedia2014</p>
<p>Physics-informed Cokriging: a Gaussian-process-regressionbased multifidelity method for data-model convergence. X Yang, D Barajas-Solano, G Tartakovsky, A Tartakovsky, J Comput Phys. 3952019</p>
<p>Machine learning of linear differential equations using Gaussian processes. M Raissi, P Perdikaris, G E Karniadakis, J Comput Phys. 3482017</p>
<p>Artificial neural networks for solving ordinary and partial differential equations. I Lagaris, A Likas, D Fotiadis, IEEE Trans Neural Netw. 951998</p>
<p>Hidden fluid mechanics: learning velocity and pressure fields from flow visualizations. M Raissi, A Yazdani, G Karniadakis, Science. 36764812020</p>
<p>Surrogate modeling for fluid flows based on physics-constrained deep learning without simulation data. L Sun, H Gao, S Pan, J-X Wang, Comput Methods Appl Mech Eng. 3611127322020</p>
<p>A cloud based architecture capable of perceiving and predicting multiple vessel behaviour. D Zissis, E K Xidias, D Lekkas, Appl Soft Comput. 352015</p>
<p>M Raissi, P Perdikaris, G E Karniadakis, arXiv:1711.10561Physics informed deep learning (part i): data-driven solutions of nonlinear partial differential equations. </p>
<p>Physics-informed deep neural networks for multiphysics data assimilation in subsurface transport problems. Q He, G Tartakovsky, D Barajas-Solano, A Tartakovsky, AGUFM. 20192019</p>
<p>Physics-informed deep neural networks for learning parameters and constitutive relationships in subsurface flow problems. A Tartakovsky, C Marrero, P Perdikaris, G Tartakovsky, D Barajas-Solano, Water Resour Res. 5652020</p>
<p>Extraction of mechanical properties of materials through deep learning from instrumented indentation. L Lu, M Dao, P Kumar, U Ramamurty, G E Karniadakis, S Suresh, Proc Nat Acad Sci. 117132020</p>
<p>A physics-constrained data-driven approach based on locally convex reconstruction for noisy database. Q He, J Chen, Comput Methods Appl Mech Eng. 3631127912020</p>
<p>Physics-informed neural networks: a deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations. M Raissi, P Perdikaris, G Karniadakis, J Comput Phys. 3782019</p>
<p>Machine learning in cardiovascular flows modeling: predicting arterial blood pressure from non-invasive 4d flow mri data using physics-informed neural networks. G Kissas, Y Yang, E Hwuang, W Witschey, J Detre, P Perdikaris, Comput Methods Appl Mech Eng. 3581126232020</p>
<p>Solidification: revised &amp; expanded. J A Dantzig, M Rappaz, 2016EPFL PressLausanne</p>
<p>Alloying element vaporization and weld pool temperature during laser welding of alsl 202 stainless steel. P Khan, T Debroy, Metall Trans B. 1541984</p>
<p>Mechanism of alloying element vaporization during laser welding. M Collur, A Paul, T Debroy, Metall Trans B. 1841987</p>
<p>Eral source-based method for solidification phase change. V Voller, C Swaminathan, Numer Heat Transf Part B Fundam. 1921991</p>
<p>A survey of deep neural network architectures and their applications. W Liu, Z Wang, X Liu, N Zeng, Y Liu, F Alsaadi, Neurocomputing. 2342017</p>
<p>A G Schwing, arXiv:1503.02351Urtasun R Fully connected deep structured networks. </p>
<p>Face recognition: a convolutional neural-network approach. S Lawrence, C L Giles, A C Tsoi, A D Back, IEEE Trans Neural Netw. 811997</p>
<p>Recurrent neural network based language model. T Mikolov, M Karafiát, L Burget, J Černockỳ, S Khudanpur, Eleventh annual conference of the international speech communication association. 2010</p>
<p>Lung sound classification using cepstral-based statistical features. N Sengupta, M Sahidullah, G Saha, Comput Biol Med. 752016</p>
<p>Pattern recognition and machine learning. C M Bishop, 2006SpringerBerlin</p>
<p>-r2n2: a unified approach for single and multi-view 3d object reconstruction. C B Choy, D Xu, J Gwak, K Chen, S Savarese, 2016Springer</p>
<p>J Han, J Pei, M Kamber, Data mining: concepts and techniques. AmsterdamElsevier2011</p>
<p>Why deep neural networks for function approximation?. S Liang, R Srikant, arXiv:1610.04161</p>
<p>Analysis of different activation functions using back propagation neural networks. P Sibi, S A Jones, P Siddarth, J Theor Appl Inf Technol. 4732013</p>
<p>Rectifier nonlinearities improve neural network acoustic models. A Maas, A Hannun, A Ng, Proceedings ICML. 3032013</p>
<p>Gurevych I Is it time to swish? comparing deep learning activation functions across nlp tasks. S Eger, P Youssef, arXiv:1901.02671</p>
<p>Ruder S An overview of gradient descent optimization algorithms. arXiv:1609.04747</p>
<p>. D P Kingma, J Ba, Adam, arXiv:1412.6980</p>
<p>Automatic differentiation in machine learning: a survey. A Baydin, B Pearlmutter, A Radul, J Siskind, J Mach Learn Res. 1812017</p>
<p>Stabilized finite element formulations for incompressible flow computations. T E Tezduyar, 10.1016/S0065-2156(08)70153-4S0065-2156(08)70153-4Adv Appl Mech. 281992</p>
<p>Multiscale space-time fluidstructure interaction techniques. K Takizawa, T E Tezduyar, 10.1007/s00466-011-0571-zComput Mech. 482011</p>
<p>Space-time fluidstructure interaction methods. K Takizawa, T E Tezduyar, 10.1142/S0218202512300013Math Models Methods Appl Sci. 22supp0212300012012</p>
<p>Multiscale ST methods for thermo-fluid analysis of a ground vehicle and its tires. K Takizawa, T E Tezduyar, T Kuraishi, 10.1142/S0218202515400072Math Models Methods Appl Sci. 252015</p>
<p>Gmres: a generalized minimal residual algorithm for solving nonsymmetric linear systems. Y Saad, M H Schultz, SIAM J Sci Stat Comput. 731986</p>
<p>Isogeometric fluid-structure interaction: theory, algorithms, and computations. Y Bazilevs, V M Calo, Tjr Hughes, Y Zhang, Comput Mech. 432008</p>
<p>Space-time and ALE-VMS techniques for patient-specific cardiovascular fluidstructure interaction modeling. K Takizawa, Y Bazilevs, T E Tezduyar, 10.1007/s11831-012-9071-3Arch Comput Methods Eng. 192012</p>
<p>A variational multiscale stabilized formulation for the incompressible Navier-Stokes equations. A Masud, R Calderer, Comput Mech. 4422009</p>
<p>Interface-capturing method for free-surface plunging and breaking waves. L Zhu, S Goraya, A Masud, J Eng Mech. 1451140190882019</p>
<p>Residual-based turbulence models and arbitrary Lagrangian-Eulerian framework for free surface flows. R Calderer, L Zhu, R Gibson, A Masud, Math Models Methods Appl Sci. 25122015</p>
<p>Residual-based turbulence models for moving boundary flows: hierarchical application of variational multiscale method and three-level scale separation. A Masud, R Calderer, Int J Numer Meth Fluids. 7332013</p>
<p>Computational methods for parachute fluid-structure interactions. K Takizawa, T E Tezduyar, 10.1007/s11831-012-9070-4Arch Comput Methods Eng. 192012</p>
<p>Y Bazilevs, K Takizawa, T E Tezduyar, 10.1002/9781118483565Computational fluid-structure interaction: methods and applications. LondonWiley2013</p>
<p>Fluid-structure interaction modeling of ringsail parachutes with disreefing and modified geometric porosity. K Takizawa, M Fritze, D Montes, T Spielman, T E Tezduyar, 10.1007/s00466-012-0761-3Comput Mech. 502012</p>
<p>Fluid-structure interaction modeling of clusters of spacecraft parachutes with modified geometric porosity. K Takizawa, T E Tezduyar, J Boben, N Kostov, C Boswell, A Buscher, 10.1007/s00466-013-0880-5Comput Mech. 522013</p>
<p>Special methods for aerodynamic-moment calculations from parachute FSI modeling. K Takizawa, T E Tezduyar, C Boswell, Y Tsutsui, K Montel, 10.1007/s00466-014-1074-5Comput Mech. 552015</p>
<p>Computational flow analysis in aerospace, energy and transportation technologies with the variational multiscale methods. K Takizawa, Y Bazilevs, T E Tezduyar, A Korobenko, J Adv Eng Comput. 422020</p>
<p>A variational multiscale framework for atmospheric turbulent flows over complex environmental terrains. M Ravensbergen, T Helgedagsrud, Y Y Bazilevs, A Korobenko, Comput Methods Appl Mech Eng. 3681131822020</p>
<p>3D simulation of wind turbine rotors at full scale. Part I: geometry modeling and aerodynamics. Y Bazilevs, M-C Hsu, I Akkerman, S Wright, K Takizawa, B Henicke, T Spielman, T E Tezduyar, 10.1002/fld.2400Int J Numer Methods Fluids. 652011</p>
<p>Stabilized space-time computation of wind-turbine rotor aerodynamics. K Takizawa, B Henicke, T E Tezduyar, M-C Hsu, Y Bazilevs, 10.1007/s00466-011-0589-2Comput Mech. 482011</p>
<p>Numerical-performance studies for the stabilized space-time computation of wind-turbine rotor aerodynamics. K Takizawa, B Henicke, D Montes, T E Tezduyar, M-C Hsu, Y Bazilevs, 10.1007/s00466-011-0614-5Comput Mech. 482011</p>
<p>Space-time VMS computation of windturbine rotor and tower aerodynamics. K Takizawa, T E Tezduyar, S Mcintyre, N Kostov, R Kolesar, C Habluetzel, 10.1007/s00466-013-0888-xComput Mech. 532014</p>
<p>Engineering analysis and design with ALE-VMS and space-time methods. K Takizawa, Y Bazilevs, T E Tezduyar, M-C Hsu, O Øiseth, K M Mathisen, N Kostov, S Mcintyre, 10.1007/s11831-014-9113-0Arch Comput Methods Eng. 212014</p>
<p>Computational engineering analysis with the new-generation space-time methods. K Takizawa, 10.1007/s00466-014-0999-zComput Mech. 542014</p>
<p>Aerodynamic and FSI analysis of wind turbines with the ALE-VMS and ST-VMS methods. Y Bazilevs, K Takizawa, T E Tezduyar, M-C Hsu, N Kostov, S Mcintyre, 10.1007/s11831-014-9119-7Arch Comput Methods Eng. 212014</p>
<p>Space-time VMS method for flow computations with slip interfaces (ST-SI). K Takizawa, T E Tezduyar, H Mochizuki, H Hattori, S Mei, L Pan, K Montel, 10.1142/S0218202515400126Math Models Methods Appl Sci. 252015</p>
<p>Recent advances in ALE-VMS and ST-VMS computational aerodynamic and FSI analysis of wind turbines. A Korobenko, Y Bazilevs, K Takizawa, T E Tezduyar, 10.1007/978-3-319-96469-0_7Frontiers in computational fluid-structure interaction and flow simulation: research from lead investigators under forty-2018, modeling and simulation in science, engineering and technology. T E Tezduyar, BerlinSpringer2018</p>
<p>Spacetime variational multiscale isogeometric analysis of a tsunamishelter vertical-axis wind turbine. Y Otoguro, H Mochizuki, K Takizawa, T Tezduyar, Comput Mech. 6662020</p>
<p>The actuator line method for wind turbine modelling applied in a variational multiscale framework. M Ravensbergen, Mohamed A Korobenko, A , Comput Fluids. 2011044652020</p>
<p>Performance analysis of two vertical-axis hydrokinetic turbines using variational multiscale method. A Mohamed, C Bear, M Bear, A Korobenko, Comput Fluids. 2001044322020</p>
<p>Variational multiscale framework for cavitating flows. A Bayram, A Korobenko, Comput Mech. 662020</p>
<p>Spacetime fluid mechanics computation of heart valve models. K Takizawa, T E Tezduyar, A Buscher, S Asada, Comput Mech. 5442014</p>
<p>Heart valve isogeometric sequentially-coupled fsi analysis with the space-time topology change method. T Terahara, K Takizawa, T Tezduyar, Y Bazilevs, M Hsu, Comput Mech. 652020</p>
<p>Ventricle-valve-aorta flow analysis with the space-time isogeometric discretization and topology change. T Terahara, K Takizawa, T Tezduyar, A Tsushima, K Shiozaki, Comput Mech. 652020</p>
<p>Gas turbine computational flow and structure analysis with isogeometric discretization and a complex-geometry mesh generation method. Y Bazilevs, K Takizawa, M Wu, T Kuraishi, R Avsar, Z Xu, T Tezduyar, 10.1007/s00466-020-01919-wComput Mech. 2020</p>
<p>Wind turbine and turbomachinery computational analysis with the ale and space-time variational multiscale methods and isogeometric discretization. Y Bazilevs, K Takizawa, T Tezduyar, M Hsu, Y Otoguro, H Mochizuki, M Wu, J Adv Eng Comput. 412020</p>
<p>Optimizing gas turbine performance using the surrogate management framework and high-fidelity flow modeling. N Kozak, M Rajanna, M Wu, M Murugan, L Bravo, A Ghoshal, M Hsu, Y Bazilevs, Energies. 131742832020</p>
<p>Space-time vms flow analysis of a turbocharger turbine with isogeometric discretization: computations with timedependent and steady-inflow representations of the intake/exhaust cycle. Y Otoguro, K Takizawa, T E Tezduyar, K Nagaoka, R Avsar, Y Zhang, Comput Mech. 6452019</p>
<p>Turbocharger turbine and exhaust manifold flow computation with the space-time variational multiscale method and isogeometric analysis. Y Otoguro, K Takizawa, T E Tezduyar, K Nagaoka, S Mei, 10.1016/j.compfluid.2018.05.019Comput Fluids. 1792019</p>
<p>Space-time computational analysis of tire aerodynamics with actual geometry, road contact, tire deformation, road roughness and fluid film. T Kuraishi, K Takizawa, T Tezduyar, Comput Mech. 6462019</p>
<p>Tire aerodynamics with actual tire geometry, road contact and tire deformation. T Kuraishi, K Takizawa, T E Tezduyar, 2019</p>
<p>. 10.1007/s00466-018-1642-1Comput Mech. 63</p>
<p>Outcomes and conclusions from the 2018 am-bench measurements, challenge problems, modeling submissions, and conference. L Levine, B Lane, J Heigel, K Migler, M Stoudt, T Phan, R Ricker, M Strantza, M Hill, F Zhang, J Seppala, E Garboczi, E Bain, D Cole, Allen A Fox, J Campbell, C , Integr Mater Manuf Innov. 912020</p>
<p>In situ measurements of meltpool length and cooling rate during 3d builds of the metal ambench artifacts. J Heigel, B Lane, L Levine, Integr Mater Manuf Innov. 912020</p>
<p>Measurements of melt pool geometry and cooling rates of individual laser traces on in625 bare plates. L Brandon, H Jarred, R Richard, Z Ivan, K Vladimir, W Jordan, P Thien, S Mark, M Sergey, L Lyle, Integr Mater Manuf Innov. 92020</p>
<p>Measurement of the melt pool length during single scan tracks in a commercial laser powder bed fusion process. J Heigel, B Lane, J Manuf Sci Eng. 14052018</p>
<p>Publisher's Note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations. </p>            </div>
        </div>

    </div>
</body>
</html>