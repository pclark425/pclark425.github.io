<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-3004 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-3004</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-3004</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-73.html">extraction-schema-73</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models perform arithmetic, including mechanisms, internal representations, interventions, and performance on arithmetic tasks.</div>
                <p><strong>Paper ID:</strong> paper-267500101</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2402.03822v2.pdf" target="_blank">RevOrder: A Novel Method for Enhanced Arithmetic in Language Models</a></p>
                <p><strong>Paper Abstract:</strong> This paper presents RevOrder, a novel technique aimed at improving arithmetic operations in large language models (LLMs) by reversing the output digits in addition, subtraction, and n-digit by 1-digit (nD by 1D) multiplication tasks. Our method significantly reduces the Count of Sequential Intermediate Digits (CSID) to $\mathcal{O}(1)$, a new metric we introduce to assess equation complexity. Through comprehensive testing, RevOrder not only achieves perfect accuracy in basic arithmetic operations but also substantially boosts LLM performance in division tasks, particularly with large numbers where traditional models struggle. Implementation of RevOrder is cost-effective for both training and inference phases. Moreover, applying RevOrder to fine-tune the LLaMA2-7B model on the GSM8K math task results in a considerable improvement, reducing equation calculation errors by 46% and increasing overall scores from 41.6 to 44.4.</p>
                <p><strong>Cost:</strong> 0.015</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e3004.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e3004.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models perform arithmetic, including mechanisms, internal representations, interventions, and performance on arithmetic tasks.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>CSID</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Count of Sequential Intermediate Digits</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A complexity metric that counts the number of sequential intermediate digits (SIDs) a model would need to infer/memorize to produce a correct arithmetic digit; larger CSID indicates higher arithmetic difficulty for LMs.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>arithmetic_task_type</strong></td>
                            <td>general multi-digit addition, subtraction, multiplication, division (analysis of task complexity)</td>
                        </tr>
                        <tr>
                            <td><strong>reported_mechanism</strong></td>
                            <td>Not a mechanistic hypothesis but a complexity measure: errors arise because autoregressive LMs must predict digits sequentially and higher-order digits often depend on unseen lower-order 'SIDs' (carry/borrow or omitted intermediate digits).</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_for_mechanism</strong></td>
                            <td>Empirical training/evaluation on 15D+15D addition tasks shows model accuracy monotonically declines as CSID increases; larger models improve but gains diminish at high CSID, supporting CSID as predictive of difficulty.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_against_mechanism</strong></td>
                            <td>No direct counter-evidence reported; limitation: CSID formalization excludes some division-specific unpredictabilities (quotient estimation) which are noted as not fully captured by CSID.</td>
                        </tr>
                        <tr>
                            <td><strong>intervention_type</strong></td>
                            <td>Analytic / metric (used to guide interventions like RevOrder and decomposition).</td>
                        </tr>
                        <tr>
                            <td><strong>effect_of_intervention</strong></td>
                            <td>Serving as a diagnostic, CSID motivated RevOrder which reduces CSID and yielded large empirical accuracy gains.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>CSID growth characterized: addition/subtraction CSID = O(n); multiplication CSID = O(n^2); division CSID = O(n^2 - m^2) (analytical claims in Appendix A). Empirical performance declines with increasing CSID (plots and experiments on 15D+15D dataset).</td>
                        </tr>
                        <tr>
                            <td><strong>notable_failure_modes</strong></td>
                            <td>CSID does not fully capture unpredictability of quotient estimation in long division; some operations (division quotient guesses) yield unmeasurable/unstable CSID.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_humans_or_symbolic</strong></td>
                            <td>CSID is an algorithmic-complexity style measure analogous to time/space complexity for symbolic algorithms; used to compare LM capability limits against algorithmic expectations (no direct human behavioral comparison).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'RevOrder: A Novel Method for Enhanced Arithmetic in Language Models', 'publication_date_yy_mm': '2024-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3004.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e3004.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models perform arithmetic, including mechanisms, internal representations, interventions, and performance on arithmetic tasks.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>RevOrder</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>RevOrder (Reverse-Order Output Method)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An intervention that trains/forces LMs to emit arithmetic results in reverse digit order (least-significant digit first), thereby reducing sequential dependencies (CSID) to O(1) for addition, subtraction and nD×1D multiplication.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>arithmetic_task_type</strong></td>
                            <td>multi-digit addition, subtraction, nD by 1D multiplication, decomposition-based multiplication and division (long division with rollback mechanism)</td>
                        </tr>
                        <tr>
                            <td><strong>reported_mechanism</strong></td>
                            <td>By reversing output digits, the LM generates digits in the natural computational order (units→tens→...), so each predicted digit depends only on corresponding input digits and the previous carry/borrow (at most one SID), reducing the sequential intermediate dependency.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_for_mechanism</strong></td>
                            <td>Analytic argument showing CSID drops from O(n) to O(1) for add/sub and nD×1D multiplication; experimental results show near-perfect or perfect accuracy on Big-bench arithmetic tasks and expanded large-digit tests when RevOrder is applied and models are fine-tuned on RevOrder-formatted data.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_against_mechanism</strong></td>
                            <td>Division remains problematic because quotient-digit estimation can introduce unpredictability not fully addressed by reversing order; rollback heuristics are needed and do not fully guarantee O(1) CSID for division.</td>
                        </tr>
                        <tr>
                            <td><strong>intervention_type</strong></td>
                            <td>Format intervention + fine-tuning: change output format (prepend r| token or @@ markers), compact encoding variants, include rollback token 'W' for division corrections; used in training data and at inference time rules for reversing are applied.</td>
                        </tr>
                        <tr>
                            <td><strong>effect_of_intervention</strong></td>
                            <td>Dramatic accuracy improvements on add/sub/multiplication (claimed 100% on many tasks) and large improvements on division (e.g., 99.4% on 12D÷6D), while reducing required training examples and token overhead compared to naive chain-of-thought; modest additional token (r|) for add/sub.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Paper reports RevOrder-1B achieves 100% on many Big-bench arithmetic subtasks (addition/subtraction/multiplication tasks up to high digits listed in Table 1) and 99.4% on 12D÷6D division; claimed training-data efficiency (0.5M equations to reach parity vs. baselines needing 1M-1.7M). On GSM8K fine-tuning, overall model score improved from 41.6 to 44.4 and equation accuracy improved from 88.9% to 94.1%.</td>
                        </tr>
                        <tr>
                            <td><strong>notable_failure_modes</strong></td>
                            <td>Division quotient estimation errors (wrong quotient digit without triggering rollback) produce cascading nonsensical outputs; for very large-digit multiplication/division token usage grows polynomially and may surpass external-tool cost; models sometimes fail to follow the reverse-format token if not trained enough.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_humans_or_symbolic</strong></td>
                            <td>Compared implicitly to algorithmic long multiplication/division and to tool-based calculation (e.g., Python) — RevOrder approximates algorithmic digit-by-digit computation within the LM rather than calling external calculators; shown to be more token-efficient than chain-of-thought scratchpads for basic ops.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'RevOrder: A Novel Method for Enhanced Arithmetic in Language Models', 'publication_date_yy_mm': '2024-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3004.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e3004.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models perform arithmetic, including mechanisms, internal representations, interventions, and performance on arithmetic tasks.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>RevOrder-1B</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>RevOrder-1B (TinyLLaMA fine-tuned with RevOrder)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A 1.1B-parameter model (TinyLLaMA backbone) fine-tuned on synthetically generated RevOrder-formatted arithmetic equations to evaluate RevOrder's effectiveness.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>RevOrder-1B</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>1.1 billion parameter model built on TinyLLaMA; trained with batch size 500, lr schedule 1e-4 (2 epochs) then 1e-5 (1 epoch); 1.7M training equations (synthetic) including addition/subtraction up to 16D, multiplication up to 8D×8D and 16D×1D, division dividends up to 16D; RevOrder formatting used throughout.</td>
                        </tr>
                        <tr>
                            <td><strong>arithmetic_task_type</strong></td>
                            <td>Addition, subtraction, multiplication (nD×1D and decomposed nD×nD), division (long division with rollback), Big-bench arithmetic, extra large-digit arithmetic, GSM8K-styled word-problem arithmetic (for transfer tests).</td>
                        </tr>
                        <tr>
                            <td><strong>reported_mechanism</strong></td>
                            <td>Learns to perform digitwise algorithmic computation by emitting least-significant digits first (reverse-order), thereby avoiding long-range dependence on unseen carry/borrow digits.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_for_mechanism</strong></td>
                            <td>Empirical evaluation: 100% accuracy on a wide range of addition/subtraction/multiplication tasks in Big-bench and extra tasks; 99.4% on 12D÷6D division; error analysis shows remaining errors concentrated in division quotient estimation (not in digit-wise arithmetic).</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_against_mechanism</strong></td>
                            <td>Division quotient estimation errors remain (cases where 'W' rollback wasn't triggered), indicating the method does not eliminate all failure modes; no internal probing of neuron-level representations reported.</td>
                        </tr>
                        <tr>
                            <td><strong>intervention_type</strong></td>
                            <td>Fine-tuning on RevOrder-formatted synthetic dataset; use of rollback 'W' signals in training and 50% of division examples include rollback variants.</td>
                        </tr>
                        <tr>
                            <td><strong>effect_of_intervention</strong></td>
                            <td>Achieved near-perfect arithmetic without external tools in evaluated tasks; required fewer training examples (paper claims ~0.5M sufficient to reach target accuracy) compared to baselines; reduced inference token overhead for add/sub (one extra token) and compact forms for more complex ops.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Reported exact-match accuracies: 100% on many Big-bench add/sub/mul tasks across digits listed in Table 1; 99.4% on 12D÷6D division; claimed dataset-size efficiency: 0.5M equations to reach parity; GSM8K transfer not directly for this 1.1B model but similar method applied to 7B LLaMA2 (see separate entry).</td>
                        </tr>
                        <tr>
                            <td><strong>notable_failure_modes</strong></td>
                            <td>Division quotient estimation failures (missing rollback triggers), and scalability/token-growth concerns for extremely large-digit multiplication/division where RevOrder token count may grow polynomially and exceed external-tool cost.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_humans_or_symbolic</strong></td>
                            <td>Claimed comparable reliability to symbolic calculation for add/sub/mul on tested sizes, positioned as an alternative to calling external calculators; specific human comparison not performed.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'RevOrder: A Novel Method for Enhanced Arithmetic in Language Models', 'publication_date_yy_mm': '2024-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3004.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e3004.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models perform arithmetic, including mechanisms, internal representations, interventions, and performance on arithmetic tasks.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LLaMA2-7B (finetuned RevOrder)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>LLaMA2-7B fine-tuned with RevOrder format on GSM8K</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A 7-billion-parameter open foundation model (LLaMA2-7B) fine-tuned on GSM8K where arithmetic expressions were rewritten in RevOrder format plus a small synthetic RevOrder dataset to improve numeric calculation in word problems.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>LLaMA2-7B (finetuned)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>LLaMA2-7B backbone; fine-tuned with batch size 32, learning rate 5e-5, warm-up ratio 0.08 over 3 epochs; GSM8K training data modified to RevOrder format and augmented with synthetic RevOrder arithmetic examples.</td>
                        </tr>
                        <tr>
                            <td><strong>arithmetic_task_type</strong></td>
                            <td>Math word problems (GSM8K), which include addition, subtraction, multiplication and occasional division within narrative contexts.</td>
                        </tr>
                        <tr>
                            <td><strong>reported_mechanism</strong></td>
                            <td>Fine-tuning to emit reverse-ordered numeric results and to perform iterative pairwise expansions of polynomial equations — effectively teaching the model to perform low-CSID arithmetic internally rather than rely on external tools.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_for_mechanism</strong></td>
                            <td>Fine-tuned model shows reductions in calculation errors (paper reports 94% reduction for addition errors, 87% for subtraction, and 46% overall equation calculation error reduction) and an increase in final GSM8K score from 41.6 to 44.4 and equation-accuracy from 88.9% to 94.1%.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_against_mechanism</strong></td>
                            <td>Model occasionally failed to learn the reverse-order marker (r|) with limited data and required alternative notation (@@...@@) in training; authors warn about catastrophic forgetting if too much arithmetic-specific fine-tuning is applied.</td>
                        </tr>
                        <tr>
                            <td><strong>intervention_type</strong></td>
                            <td>Supervised fine-tuning with RevOrder-formatted GSM8K + small synthetic augmentation; symbol conventions introduced for reverse-order numbers.</td>
                        </tr>
                        <tr>
                            <td><strong>effect_of_intervention</strong></td>
                            <td>Improved arithmetic correctness within word-problem solving (notable reductions in calculation error rates and modest increase in task score); required modest additional training data and careful notation choices.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>GSM8K reported: overall score increased from 41.6 → 44.4; equation-accuracy reportedly increased from 88.9% → 94.1%; reported reductions in calculation errors: addition 94% less, subtraction 87% less, overall equation errors 46% less (as stated by authors).</td>
                        </tr>
                        <tr>
                            <td><strong>notable_failure_modes</strong></td>
                            <td>Failure to consistently apply reverse-formatting without sufficient training; word-problem errors remain when the model solves in reverse order but fails to reformat final answer; risk of catastrophic forgetting if over-fine-tuned.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_humans_or_symbolic</strong></td>
                            <td>Compared implicitly to the alternative of calling external tools (e.g., Python) during inference; RevOrder fine-tuning reduces reliance on tools for many GSM8K cases but authors note trade-offs and thresholds where tool use remains preferable (very large-digit cases).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'RevOrder: A Novel Method for Enhanced Arithmetic in Language Models', 'publication_date_yy_mm': '2024-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3004.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e3004.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models perform arithmetic, including mechanisms, internal representations, interventions, and performance on arithmetic tasks.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GPT-4</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Generative Pre-trained Transformer 4</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A large, closed-source language model by OpenAI, referenced as a strong baseline that in practice often uses external tools for arithmetic on web service; tableed baseline performance is reported for direct-generation scenarios in the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-4</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>State-of-the-art large LM (model size not specified in paper); authors report GPT-4's Big-bench arithmetic numbers taken from Liu & Low (2023) and note service behavior which uses external Python tools for computation in production.</td>
                        </tr>
                        <tr>
                            <td><strong>arithmetic_task_type</strong></td>
                            <td>Big-bench arithmetic (addition, subtraction, multiplication, division) and large-digit arithmetic reported in Table 1.</td>
                        </tr>
                        <tr>
                            <td><strong>reported_mechanism</strong></td>
                            <td>Direct result generation (no decomposition/tooling in the reported experiments in table); in practice (service) uses external programmatic tools for arbitrary-precision calculation.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_for_mechanism</strong></td>
                            <td>Reported baseline accuracies: near-perfect at small digit tasks but steep decline at large-digit tasks (examples in Table 1: e.g., addition accuracy falls to ~9.4% for 16D+16D in their cited table entries; division shows 0% for some large-digit cases as reported).</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_against_mechanism</strong></td>
                            <td>High variance and poor reliability on large-CSID tasks when relying solely on direct generation; production use of external tools by service indicates limitations of direct internal arithmetic.</td>
                        </tr>
                        <tr>
                            <td><strong>intervention_type</strong></td>
                            <td>Mentioned external-tool use (production) and chain-of-thought methods in broader literature; not directly intervened on in this paper's experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>effect_of_intervention</strong></td>
                            <td>When external tools are used (production systems), arithmetic correctness is restored at the cost of tokens/efficiency; direct-generation mode exhibits large errors at high-digit tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Table 1 reports GPT-4 numbers (as cited): e.g., many small-digit accuracies ~100%, but large-digit cases decline (specific table entries given in paper). Exact values vary across tasks; authors reference GPT-4's poor large-digit direct performance as motivation for tool usage.</td>
                        </tr>
                        <tr>
                            <td><strong>notable_failure_modes</strong></td>
                            <td>Fails on high-CSID large-digit arithmetic when generating results directly; often resorts to external calculators in deployed settings.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_humans_or_symbolic</strong></td>
                            <td>Production systems use symbolic calculators (Python) to ensure correctness; authors frame RevOrder as a token-efficient alternative to always calling external symbolic tools for basic operations.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'RevOrder: A Novel Method for Enhanced Arithmetic in Language Models', 'publication_date_yy_mm': '2024-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3004.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e3004.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models perform arithmetic, including mechanisms, internal representations, interventions, and performance on arithmetic tasks.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GOAT-7B</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>GOAT-7B (Fine-tuned LLaMA arithmetic model)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A 7B-parameter LLaMA-derived model fine-tuned on arithmetic decomposition-style instruction data; used as a primary baseline in comparisons.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Goat: Fine-tuned llama outperforms gpt-4 on arithmetic tasks</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GOAT-7B</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Fine-tuned LLAMA-7B model trained with ~1.7M instruction examples per Liu & Low (2023) (as referenced); uses decomposition methods for composite arithmetic but reportedly relies on direct generation for subtraction and addition in some variants.</td>
                        </tr>
                        <tr>
                            <td><strong>arithmetic_task_type</strong></td>
                            <td>Addition, subtraction, multiplication, division (decomposition-based arithmetic).</td>
                        </tr>
                        <tr>
                            <td><strong>reported_mechanism</strong></td>
                            <td>Decomposition of complex arithmetic into basic operations and chain-of-thought style steps; relies on direct result generation for some basic ops in reported setup.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_for_mechanism</strong></td>
                            <td>Table 1 comparisons show GOAT-7B achieves high accuracy on many tasks but can be outperformed by RevOrder-1B on large-digit division and some multiplication tasks; authors attribute GOAT's errors to imperfect basic-operation accuracy that amplifies in composite operations.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_against_mechanism</strong></td>
                            <td>Although decomposition mitigates CSID growth, minor errors in basic steps propagate and cause accuracy decline in larger-digit composite tasks; GOAT-7B does not reach 100% across all Big-bench subtasks per table.</td>
                        </tr>
                        <tr>
                            <td><strong>intervention_type</strong></td>
                            <td>Fine-tuning on stepwise/decomposed arithmetic demonstrations/instruction data.</td>
                        </tr>
                        <tr>
                            <td><strong>effect_of_intervention</strong></td>
                            <td>Strong baseline performance on many arithmetic tasks, but higher training data requirements and residual errors that amplify in composed calculations compared to RevOrder approach.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Table 1 (as cited in paper) reports GOAT-7B achieves near-100% on many lower-digit tasks and high-but-not-perfect accuracy on larger composite tasks (specific per-task numbers in paper's Table 1).</td>
                        </tr>
                        <tr>
                            <td><strong>notable_failure_modes</strong></td>
                            <td>Error amplification when small mistakes occur in basic operations; requires larger datasets to reach parity with RevOrder on some tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_humans_or_symbolic</strong></td>
                            <td>Positioned as LM-based decomposition approach; compared experimentally against RevOrder and GPT-4 baselines in the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'RevOrder: A Novel Method for Enhanced Arithmetic in Language Models', 'publication_date_yy_mm': '2024-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e3004.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e3004.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models perform arithmetic, including mechanisms, internal representations, interventions, and performance on arithmetic tasks.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>MathGLM-2B</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>MathGLM-2B</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A 2B-parameter GLM-family model fine-tuned extensively on step-by-step arithmetic data; cited as a baseline claiming that very large step-by-step datasets enable calculator-free arithmetic.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Gpt can solve mathematical problems without a calculator</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>MathGLM-2B</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>GLM-2B model finetuned on large amounts of step-by-step arithmetic training (claimed 1M–50M instances in cited work); used as a baseline comparison in arithmetic evaluations.</td>
                        </tr>
                        <tr>
                            <td><strong>arithmetic_task_type</strong></td>
                            <td>Addition, subtraction, multiplication, division trained with step-by-step chain-of-thought style data.</td>
                        </tr>
                        <tr>
                            <td><strong>reported_mechanism</strong></td>
                            <td>Learning algorithmic arithmetic via massive supervised stepwise examples (chain-of-thought style), enabling the model to emulate manual multi-step arithmetic without external calculators.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_for_mechanism</strong></td>
                            <td>Reported high accuracies on many arithmetic subtasks in prior work; in this paper it is reported as a competitive baseline but not achieving the same training-data efficiency or all-task accuracy as RevOrder-1B.</td>
                        </tr>
                        <tr>
                            <td><strong>evidence_against_mechanism</strong></td>
                            <td>Authors argue that chain-of-thought/decomposition methods are token-intensive and require far more training data; residual base-operation errors propagate in composite arithmetic similar to GOAT-7B.</td>
                        </tr>
                        <tr>
                            <td><strong>intervention_type</strong></td>
                            <td>Large-scale fine-tuning with step-by-step arithmetic examples (chain-of-thought style).</td>
                        </tr>
                        <tr>
                            <td><strong>effect_of_intervention</strong></td>
                            <td>Enables strong arithmetic performance in many regimes but at high data/training/token cost and less favorable scaling for very large-digit cases compared to RevOrder.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Cited in Table 1 as achieving strong but not perfect performance on many tasks; specific numbers are provided in the paper's Table 1 for direct comparison (MathGLM-2B entries shown).</td>
                        </tr>
                        <tr>
                            <td><strong>notable_failure_modes</strong></td>
                            <td>Token-intensive training and inference; errors in basic operations still observed and amplified in composite tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_humans_or_symbolic</strong></td>
                            <td>Presented as a route to avoid symbolic tools by teaching LMs algorithmic arithmetic through massive supervised examples; trade-offs with data and tokens are emphasized by the authors of this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'RevOrder: A Novel Method for Enhanced Arithmetic in Language Models', 'publication_date_yy_mm': '2024-02'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Show your work: Scratchpads for intermediate computation with language models <em>(Rating: 2)</em></li>
                <li>Goat: Fine-tuned llama outperforms gpt-4 on arithmetic tasks <em>(Rating: 2)</em></li>
                <li>Gpt can solve mathematical problems without a calculator <em>(Rating: 2)</em></li>
                <li>Chain-of-thought prompting elicits reasoning in large language models <em>(Rating: 1)</em></li>
                <li>Program-aided language models <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-3004",
    "paper_id": "paper-267500101",
    "extraction_schema_id": "extraction-schema-73",
    "extracted_data": [
        {
            "name_short": "CSID",
            "name_full": "Count of Sequential Intermediate Digits",
            "brief_description": "A complexity metric that counts the number of sequential intermediate digits (SIDs) a model would need to infer/memorize to produce a correct arithmetic digit; larger CSID indicates higher arithmetic difficulty for LMs.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": null,
            "model_description": null,
            "arithmetic_task_type": "general multi-digit addition, subtraction, multiplication, division (analysis of task complexity)",
            "reported_mechanism": "Not a mechanistic hypothesis but a complexity measure: errors arise because autoregressive LMs must predict digits sequentially and higher-order digits often depend on unseen lower-order 'SIDs' (carry/borrow or omitted intermediate digits).",
            "evidence_for_mechanism": "Empirical training/evaluation on 15D+15D addition tasks shows model accuracy monotonically declines as CSID increases; larger models improve but gains diminish at high CSID, supporting CSID as predictive of difficulty.",
            "evidence_against_mechanism": "No direct counter-evidence reported; limitation: CSID formalization excludes some division-specific unpredictabilities (quotient estimation) which are noted as not fully captured by CSID.",
            "intervention_type": "Analytic / metric (used to guide interventions like RevOrder and decomposition).",
            "effect_of_intervention": "Serving as a diagnostic, CSID motivated RevOrder which reduces CSID and yielded large empirical accuracy gains.",
            "performance_metrics": "CSID growth characterized: addition/subtraction CSID = O(n); multiplication CSID = O(n^2); division CSID = O(n^2 - m^2) (analytical claims in Appendix A). Empirical performance declines with increasing CSID (plots and experiments on 15D+15D dataset).",
            "notable_failure_modes": "CSID does not fully capture unpredictability of quotient estimation in long division; some operations (division quotient guesses) yield unmeasurable/unstable CSID.",
            "comparison_to_humans_or_symbolic": "CSID is an algorithmic-complexity style measure analogous to time/space complexity for symbolic algorithms; used to compare LM capability limits against algorithmic expectations (no direct human behavioral comparison).",
            "uuid": "e3004.0",
            "source_info": {
                "paper_title": "RevOrder: A Novel Method for Enhanced Arithmetic in Language Models",
                "publication_date_yy_mm": "2024-02"
            }
        },
        {
            "name_short": "RevOrder",
            "name_full": "RevOrder (Reverse-Order Output Method)",
            "brief_description": "An intervention that trains/forces LMs to emit arithmetic results in reverse digit order (least-significant digit first), thereby reducing sequential dependencies (CSID) to O(1) for addition, subtraction and nD×1D multiplication.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": null,
            "model_description": null,
            "arithmetic_task_type": "multi-digit addition, subtraction, nD by 1D multiplication, decomposition-based multiplication and division (long division with rollback mechanism)",
            "reported_mechanism": "By reversing output digits, the LM generates digits in the natural computational order (units→tens→...), so each predicted digit depends only on corresponding input digits and the previous carry/borrow (at most one SID), reducing the sequential intermediate dependency.",
            "evidence_for_mechanism": "Analytic argument showing CSID drops from O(n) to O(1) for add/sub and nD×1D multiplication; experimental results show near-perfect or perfect accuracy on Big-bench arithmetic tasks and expanded large-digit tests when RevOrder is applied and models are fine-tuned on RevOrder-formatted data.",
            "evidence_against_mechanism": "Division remains problematic because quotient-digit estimation can introduce unpredictability not fully addressed by reversing order; rollback heuristics are needed and do not fully guarantee O(1) CSID for division.",
            "intervention_type": "Format intervention + fine-tuning: change output format (prepend r| token or @@ markers), compact encoding variants, include rollback token 'W' for division corrections; used in training data and at inference time rules for reversing are applied.",
            "effect_of_intervention": "Dramatic accuracy improvements on add/sub/multiplication (claimed 100% on many tasks) and large improvements on division (e.g., 99.4% on 12D÷6D), while reducing required training examples and token overhead compared to naive chain-of-thought; modest additional token (r|) for add/sub.",
            "performance_metrics": "Paper reports RevOrder-1B achieves 100% on many Big-bench arithmetic subtasks (addition/subtraction/multiplication tasks up to high digits listed in Table 1) and 99.4% on 12D÷6D division; claimed training-data efficiency (0.5M equations to reach parity vs. baselines needing 1M-1.7M). On GSM8K fine-tuning, overall model score improved from 41.6 to 44.4 and equation accuracy improved from 88.9% to 94.1%.",
            "notable_failure_modes": "Division quotient estimation errors (wrong quotient digit without triggering rollback) produce cascading nonsensical outputs; for very large-digit multiplication/division token usage grows polynomially and may surpass external-tool cost; models sometimes fail to follow the reverse-format token if not trained enough.",
            "comparison_to_humans_or_symbolic": "Compared implicitly to algorithmic long multiplication/division and to tool-based calculation (e.g., Python) — RevOrder approximates algorithmic digit-by-digit computation within the LM rather than calling external calculators; shown to be more token-efficient than chain-of-thought scratchpads for basic ops.",
            "uuid": "e3004.1",
            "source_info": {
                "paper_title": "RevOrder: A Novel Method for Enhanced Arithmetic in Language Models",
                "publication_date_yy_mm": "2024-02"
            }
        },
        {
            "name_short": "RevOrder-1B",
            "name_full": "RevOrder-1B (TinyLLaMA fine-tuned with RevOrder)",
            "brief_description": "A 1.1B-parameter model (TinyLLaMA backbone) fine-tuned on synthetically generated RevOrder-formatted arithmetic equations to evaluate RevOrder's effectiveness.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "RevOrder-1B",
            "model_description": "1.1 billion parameter model built on TinyLLaMA; trained with batch size 500, lr schedule 1e-4 (2 epochs) then 1e-5 (1 epoch); 1.7M training equations (synthetic) including addition/subtraction up to 16D, multiplication up to 8D×8D and 16D×1D, division dividends up to 16D; RevOrder formatting used throughout.",
            "arithmetic_task_type": "Addition, subtraction, multiplication (nD×1D and decomposed nD×nD), division (long division with rollback), Big-bench arithmetic, extra large-digit arithmetic, GSM8K-styled word-problem arithmetic (for transfer tests).",
            "reported_mechanism": "Learns to perform digitwise algorithmic computation by emitting least-significant digits first (reverse-order), thereby avoiding long-range dependence on unseen carry/borrow digits.",
            "evidence_for_mechanism": "Empirical evaluation: 100% accuracy on a wide range of addition/subtraction/multiplication tasks in Big-bench and extra tasks; 99.4% on 12D÷6D division; error analysis shows remaining errors concentrated in division quotient estimation (not in digit-wise arithmetic).",
            "evidence_against_mechanism": "Division quotient estimation errors remain (cases where 'W' rollback wasn't triggered), indicating the method does not eliminate all failure modes; no internal probing of neuron-level representations reported.",
            "intervention_type": "Fine-tuning on RevOrder-formatted synthetic dataset; use of rollback 'W' signals in training and 50% of division examples include rollback variants.",
            "effect_of_intervention": "Achieved near-perfect arithmetic without external tools in evaluated tasks; required fewer training examples (paper claims ~0.5M sufficient to reach target accuracy) compared to baselines; reduced inference token overhead for add/sub (one extra token) and compact forms for more complex ops.",
            "performance_metrics": "Reported exact-match accuracies: 100% on many Big-bench add/sub/mul tasks across digits listed in Table 1; 99.4% on 12D÷6D division; claimed dataset-size efficiency: 0.5M equations to reach parity; GSM8K transfer not directly for this 1.1B model but similar method applied to 7B LLaMA2 (see separate entry).",
            "notable_failure_modes": "Division quotient estimation failures (missing rollback triggers), and scalability/token-growth concerns for extremely large-digit multiplication/division where RevOrder token count may grow polynomially and exceed external-tool cost.",
            "comparison_to_humans_or_symbolic": "Claimed comparable reliability to symbolic calculation for add/sub/mul on tested sizes, positioned as an alternative to calling external calculators; specific human comparison not performed.",
            "uuid": "e3004.2",
            "source_info": {
                "paper_title": "RevOrder: A Novel Method for Enhanced Arithmetic in Language Models",
                "publication_date_yy_mm": "2024-02"
            }
        },
        {
            "name_short": "LLaMA2-7B (finetuned RevOrder)",
            "name_full": "LLaMA2-7B fine-tuned with RevOrder format on GSM8K",
            "brief_description": "A 7-billion-parameter open foundation model (LLaMA2-7B) fine-tuned on GSM8K where arithmetic expressions were rewritten in RevOrder format plus a small synthetic RevOrder dataset to improve numeric calculation in word problems.",
            "citation_title": "",
            "mention_or_use": "use",
            "model_name": "LLaMA2-7B (finetuned)",
            "model_description": "LLaMA2-7B backbone; fine-tuned with batch size 32, learning rate 5e-5, warm-up ratio 0.08 over 3 epochs; GSM8K training data modified to RevOrder format and augmented with synthetic RevOrder arithmetic examples.",
            "arithmetic_task_type": "Math word problems (GSM8K), which include addition, subtraction, multiplication and occasional division within narrative contexts.",
            "reported_mechanism": "Fine-tuning to emit reverse-ordered numeric results and to perform iterative pairwise expansions of polynomial equations — effectively teaching the model to perform low-CSID arithmetic internally rather than rely on external tools.",
            "evidence_for_mechanism": "Fine-tuned model shows reductions in calculation errors (paper reports 94% reduction for addition errors, 87% for subtraction, and 46% overall equation calculation error reduction) and an increase in final GSM8K score from 41.6 to 44.4 and equation-accuracy from 88.9% to 94.1%.",
            "evidence_against_mechanism": "Model occasionally failed to learn the reverse-order marker (r|) with limited data and required alternative notation (@@...@@) in training; authors warn about catastrophic forgetting if too much arithmetic-specific fine-tuning is applied.",
            "intervention_type": "Supervised fine-tuning with RevOrder-formatted GSM8K + small synthetic augmentation; symbol conventions introduced for reverse-order numbers.",
            "effect_of_intervention": "Improved arithmetic correctness within word-problem solving (notable reductions in calculation error rates and modest increase in task score); required modest additional training data and careful notation choices.",
            "performance_metrics": "GSM8K reported: overall score increased from 41.6 → 44.4; equation-accuracy reportedly increased from 88.9% → 94.1%; reported reductions in calculation errors: addition 94% less, subtraction 87% less, overall equation errors 46% less (as stated by authors).",
            "notable_failure_modes": "Failure to consistently apply reverse-formatting without sufficient training; word-problem errors remain when the model solves in reverse order but fails to reformat final answer; risk of catastrophic forgetting if over-fine-tuned.",
            "comparison_to_humans_or_symbolic": "Compared implicitly to the alternative of calling external tools (e.g., Python) during inference; RevOrder fine-tuning reduces reliance on tools for many GSM8K cases but authors note trade-offs and thresholds where tool use remains preferable (very large-digit cases).",
            "uuid": "e3004.3",
            "source_info": {
                "paper_title": "RevOrder: A Novel Method for Enhanced Arithmetic in Language Models",
                "publication_date_yy_mm": "2024-02"
            }
        },
        {
            "name_short": "GPT-4",
            "name_full": "Generative Pre-trained Transformer 4",
            "brief_description": "A large, closed-source language model by OpenAI, referenced as a strong baseline that in practice often uses external tools for arithmetic on web service; tableed baseline performance is reported for direct-generation scenarios in the paper.",
            "citation_title": "",
            "mention_or_use": "mention",
            "model_name": "GPT-4",
            "model_description": "State-of-the-art large LM (model size not specified in paper); authors report GPT-4's Big-bench arithmetic numbers taken from Liu & Low (2023) and note service behavior which uses external Python tools for computation in production.",
            "arithmetic_task_type": "Big-bench arithmetic (addition, subtraction, multiplication, division) and large-digit arithmetic reported in Table 1.",
            "reported_mechanism": "Direct result generation (no decomposition/tooling in the reported experiments in table); in practice (service) uses external programmatic tools for arbitrary-precision calculation.",
            "evidence_for_mechanism": "Reported baseline accuracies: near-perfect at small digit tasks but steep decline at large-digit tasks (examples in Table 1: e.g., addition accuracy falls to ~9.4% for 16D+16D in their cited table entries; division shows 0% for some large-digit cases as reported).",
            "evidence_against_mechanism": "High variance and poor reliability on large-CSID tasks when relying solely on direct generation; production use of external tools by service indicates limitations of direct internal arithmetic.",
            "intervention_type": "Mentioned external-tool use (production) and chain-of-thought methods in broader literature; not directly intervened on in this paper's experiments.",
            "effect_of_intervention": "When external tools are used (production systems), arithmetic correctness is restored at the cost of tokens/efficiency; direct-generation mode exhibits large errors at high-digit tasks.",
            "performance_metrics": "Table 1 reports GPT-4 numbers (as cited): e.g., many small-digit accuracies ~100%, but large-digit cases decline (specific table entries given in paper). Exact values vary across tasks; authors reference GPT-4's poor large-digit direct performance as motivation for tool usage.",
            "notable_failure_modes": "Fails on high-CSID large-digit arithmetic when generating results directly; often resorts to external calculators in deployed settings.",
            "comparison_to_humans_or_symbolic": "Production systems use symbolic calculators (Python) to ensure correctness; authors frame RevOrder as a token-efficient alternative to always calling external symbolic tools for basic operations.",
            "uuid": "e3004.4",
            "source_info": {
                "paper_title": "RevOrder: A Novel Method for Enhanced Arithmetic in Language Models",
                "publication_date_yy_mm": "2024-02"
            }
        },
        {
            "name_short": "GOAT-7B",
            "name_full": "GOAT-7B (Fine-tuned LLaMA arithmetic model)",
            "brief_description": "A 7B-parameter LLaMA-derived model fine-tuned on arithmetic decomposition-style instruction data; used as a primary baseline in comparisons.",
            "citation_title": "Goat: Fine-tuned llama outperforms gpt-4 on arithmetic tasks",
            "mention_or_use": "mention",
            "model_name": "GOAT-7B",
            "model_description": "Fine-tuned LLAMA-7B model trained with ~1.7M instruction examples per Liu & Low (2023) (as referenced); uses decomposition methods for composite arithmetic but reportedly relies on direct generation for subtraction and addition in some variants.",
            "arithmetic_task_type": "Addition, subtraction, multiplication, division (decomposition-based arithmetic).",
            "reported_mechanism": "Decomposition of complex arithmetic into basic operations and chain-of-thought style steps; relies on direct result generation for some basic ops in reported setup.",
            "evidence_for_mechanism": "Table 1 comparisons show GOAT-7B achieves high accuracy on many tasks but can be outperformed by RevOrder-1B on large-digit division and some multiplication tasks; authors attribute GOAT's errors to imperfect basic-operation accuracy that amplifies in composite operations.",
            "evidence_against_mechanism": "Although decomposition mitigates CSID growth, minor errors in basic steps propagate and cause accuracy decline in larger-digit composite tasks; GOAT-7B does not reach 100% across all Big-bench subtasks per table.",
            "intervention_type": "Fine-tuning on stepwise/decomposed arithmetic demonstrations/instruction data.",
            "effect_of_intervention": "Strong baseline performance on many arithmetic tasks, but higher training data requirements and residual errors that amplify in composed calculations compared to RevOrder approach.",
            "performance_metrics": "Table 1 (as cited in paper) reports GOAT-7B achieves near-100% on many lower-digit tasks and high-but-not-perfect accuracy on larger composite tasks (specific per-task numbers in paper's Table 1).",
            "notable_failure_modes": "Error amplification when small mistakes occur in basic operations; requires larger datasets to reach parity with RevOrder on some tasks.",
            "comparison_to_humans_or_symbolic": "Positioned as LM-based decomposition approach; compared experimentally against RevOrder and GPT-4 baselines in the paper.",
            "uuid": "e3004.5",
            "source_info": {
                "paper_title": "RevOrder: A Novel Method for Enhanced Arithmetic in Language Models",
                "publication_date_yy_mm": "2024-02"
            }
        },
        {
            "name_short": "MathGLM-2B",
            "name_full": "MathGLM-2B",
            "brief_description": "A 2B-parameter GLM-family model fine-tuned extensively on step-by-step arithmetic data; cited as a baseline claiming that very large step-by-step datasets enable calculator-free arithmetic.",
            "citation_title": "Gpt can solve mathematical problems without a calculator",
            "mention_or_use": "mention",
            "model_name": "MathGLM-2B",
            "model_description": "GLM-2B model finetuned on large amounts of step-by-step arithmetic training (claimed 1M–50M instances in cited work); used as a baseline comparison in arithmetic evaluations.",
            "arithmetic_task_type": "Addition, subtraction, multiplication, division trained with step-by-step chain-of-thought style data.",
            "reported_mechanism": "Learning algorithmic arithmetic via massive supervised stepwise examples (chain-of-thought style), enabling the model to emulate manual multi-step arithmetic without external calculators.",
            "evidence_for_mechanism": "Reported high accuracies on many arithmetic subtasks in prior work; in this paper it is reported as a competitive baseline but not achieving the same training-data efficiency or all-task accuracy as RevOrder-1B.",
            "evidence_against_mechanism": "Authors argue that chain-of-thought/decomposition methods are token-intensive and require far more training data; residual base-operation errors propagate in composite arithmetic similar to GOAT-7B.",
            "intervention_type": "Large-scale fine-tuning with step-by-step arithmetic examples (chain-of-thought style).",
            "effect_of_intervention": "Enables strong arithmetic performance in many regimes but at high data/training/token cost and less favorable scaling for very large-digit cases compared to RevOrder.",
            "performance_metrics": "Cited in Table 1 as achieving strong but not perfect performance on many tasks; specific numbers are provided in the paper's Table 1 for direct comparison (MathGLM-2B entries shown).",
            "notable_failure_modes": "Token-intensive training and inference; errors in basic operations still observed and amplified in composite tasks.",
            "comparison_to_humans_or_symbolic": "Presented as a route to avoid symbolic tools by teaching LMs algorithmic arithmetic through massive supervised examples; trade-offs with data and tokens are emphasized by the authors of this paper.",
            "uuid": "e3004.6",
            "source_info": {
                "paper_title": "RevOrder: A Novel Method for Enhanced Arithmetic in Language Models",
                "publication_date_yy_mm": "2024-02"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Show your work: Scratchpads for intermediate computation with language models",
            "rating": 2,
            "sanitized_title": "show_your_work_scratchpads_for_intermediate_computation_with_language_models"
        },
        {
            "paper_title": "Goat: Fine-tuned llama outperforms gpt-4 on arithmetic tasks",
            "rating": 2,
            "sanitized_title": "goat_finetuned_llama_outperforms_gpt4_on_arithmetic_tasks"
        },
        {
            "paper_title": "Gpt can solve mathematical problems without a calculator",
            "rating": 2,
            "sanitized_title": "gpt_can_solve_mathematical_problems_without_a_calculator"
        },
        {
            "paper_title": "Chain-of-thought prompting elicits reasoning in large language models",
            "rating": 1,
            "sanitized_title": "chainofthought_prompting_elicits_reasoning_in_large_language_models"
        },
        {
            "paper_title": "Program-aided language models",
            "rating": 1,
            "sanitized_title": "programaided_language_models"
        }
    ],
    "cost": 0.015331249999999998,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>RevOrder: A Novel Method for Enhanced Arithmetic in Language Models
24 Feb 2024</p>
<p>Si Shen 
Nanjing University of Science and Technology
NanjingChina</p>
<p>Peijun Shen shenpeijun@henu.edu.cn 
Henan University
KaifengChina</p>
<p>Danhao Zhu 
Jiangsu Police Institute
NanjingChina</p>
<p>RevOrder: A Novel Method for Enhanced Arithmetic in Language Models
24 Feb 20242700B5939647649AED136CF676999FF1arXiv:2402.03822v2[cs.AI]
This paper presents RevOrder, a novel technique aimed at improving arithmetic operations in large language models (LLMs) by reversing the output digits in addition, subtraction, and n-digit by 1-digit (nD by 1D) multiplication tasks.Our method significantly reduces the Count of Sequential Intermediate Digits (CSID) to O(1), a new metric we introduce to assess equation complexity.Through comprehensive testing, RevOrder not only achieves perfect accuracy in basic arithmetic operations but also substantially boosts LLM performance in division tasks, particularly with large numbers where traditional models struggle.Implementation of RevOrder is cost-effective for both training and inference phases.Moreover, applying RevOrder to fine-tune the LLaMA2-7B model on the GSM8K math task results in a considerable improvement, reducing equation calculation errors by 46% and increasing overall scores from 41.6 to 44.4. 1 2</p>
<p>Introduction</p>
<p>Large language models (LLMs) have gained significant attention in recent years, excelling in natural language understanding and generation tasks (Zhao et al., 2023).Despite their advancements, the leading models like ChatGPT (OpenAI, 2022) and GPT-4 (OpenAI, 2023) struggle with basic arithmetic, particularly with large digits.The GPT-4 website service 3 addresses this by switching to external Python tools, as depicted in Fig. 1(a).This shift not only adds a cumbersome step but also leads to excessive token usage, significantly disrupting the language processing flow and efficiency.</p>
<p>Arithmetic reasoning has long focused on solving arithmetic problems with LMs (Lu et al., 2022).Typically, LMs generate the solutions step-by-step 1 Corresponding authors: Danhao Zhu 2 The data and code for this paper are available on Github. 3https://chat.openai.com/,2024-1-26 Figure 1: An illustration of performing addition using various methods.In the RevOrder method, the 'r|' symbol indicates that the subsequent digits are presented in reverse order.in a chain-of-thought (COT) manner, common in reasoning tasks (Wei et al., 2022b;Kojima et al., 2022;Zhou et al., 2022).For instance, Nye et al. (2021) used a 'Scratchpad' to generate intermediate steps, achieving high accuracy in 8D addition tasks, as shown in Fig. 1(b).Similar methods are applied for subtraction, multiplication, division, and other arithmetic operations (Liu and Low, 2023;Yang et al., 2023).</p>
<p>However, practical application of arithmetic reasoning in LMs faces significant challenges.Firstly, LMs lack consistency in providing accurate results, and there is no established theory to measure equation complexity or to determine if an equation is within an LM's capabilities.For example, Liu and Low (2023) posited that addition is learnable by LLMs, but their experiments with large-digit addition contained minor errors.Secondly, current decomposition methods are token-intensive, making them more expensive than tool-based solutions during inference.Even for a simple 2D addition, the Scratchpad method (Nye et al., 2021), shown in Fig. 1(b), is not more token-efficient than Python tools (Fig. 1(a)).</p>
<p>To address these challenges, we introduce two novel concepts.First, we propose the Count of Sequential Digits (CSID) as an indicator to measure the difficulty of arithmetic equations.A larger CSID suggests more omitted reasoning steps, indicating a more complex equation.We demonstrate that the CSID complexity grows at O(n) for addition and subtraction, where n is the digit count.Empirical evidence suggests that advanced language models struggle considerably with high-CSID problems.This indicates a notable limitation: LLMs are unreliable in directly producing results for even basic arithmetic tasks, such as single additions or subtractions, when the digits involved are large.</p>
<p>Second, we propose RevOrder, a technique that reduces the CSID to a constant 1 for addition, subtraction, and nD by 1D multiplication operations.Illustrated in Fig. 1(c), RevOrder reverses the output order of addition.This approach aligns with the natural human reasoning sequence, where higherorder digits are resolved after the lower ones.Unlike previous methods such as Scratchpad (Nye et al., 2021), RevOrder requires virtually no additional tokens for these basic operations.Building upon these, we can construct more complex operations with significantly reduced token usage.</p>
<p>RevOrder, evaluated on the Big-bench arithmetic task (Srivastava et al., 2022) and an expanded set with larger digits, achieved 100% accuracy in addition, subtraction, multiplication, and low-digit division tasks, and nearly 100% in large-digit division, outperforming baseline methods.The experimental section highlights its training and inference efficiency.Finetuning LLAMA2 (Touvron et al., 2023) with RevOrder on the GSM8K dataset (Cobbe et al., 2021) significantly improved equation accuracy and overall scores (from 88.9% to 94.1%, and 41.6 to 44.4, respectively).These results affirm RevOrder's effectiveness and token economy in a range of arithmetic tasks, especially in addition and subtraction.</p>
<p>Section 2 reviews related work, Section 3 introduces the CSID metric, Section 4 details the RevOrder technique, Section 5 reports on experiments on arithmetic calculation, Section 6 discusses finetuning on GSM8K, and Section 7 concludes the paper.</p>
<p>Related Works</p>
<p>Arithmetic ability, a cornerstone of mathematics, has long served as a benchmark for assessing model capabilities, evolving from statistical methods (Hosseini et al., 2014) through machine learning techniques (Kushman et al., 2014), deep learning approaches (Wang et al., 2017) to LLM methods (Wei et al., 2022a).</p>
<p>While scaling laws for LLMs suggest that model capacity increases with model size, compute resources, and training data (Kaplan et al., 2020;Hoffmann et al., 2022), LLMs often struggle to directly generate arithmetic results.Consequently, step-by-step arithmetic reasoning methods have been developed.ScratchPad (Nye et al., 2021) introduces this concept for additions, achieving nearperfect accuracy on 8D addition tasks.This idea has since been expanded to more complex operations, such as multiplication and division (Liu and Low, 2023;Yang et al., 2023).These complex operations depend on the assumption that LLMs can efficiently perform basic operations such as addition and subtraction.Otherwise, token usage quickly becomes unsustainable.However, these socalled basic operations often fail to achieve 100% accuracy with large digits, making the more complex operations built upon them even more prone to error.Our CSID theory provides a framework to assess the complexity of equations, showing that LLMs' ability to perform basic operations diminishes as digit size grows.Conversely, RevOrder introduces an efficient method to keep equations' CSID low, ensuring their manageability within constrained token budgets.</p>
<p>Given the limitations and high token consumption of previous arithmetic reasoning methods, more pragmatic solutions have emerged, such as utilizing external tools or programming (Schick et al., 2023;Chen et al., 2022;Gao et al., 2023).RevOrder stands out by offering reliability and efficiency in addition and subtraction, positioning itself as a resource-saving alternative to these methods.</p>
<p>Sequential Intermediate Digits in Arithmetic Computation</p>
<p>Arithmetic reasoning in language models (LMs) is challenging, mainly due to the sequential prediction of digits.This complexity is exacerbated when contextual digits required for accurate predictions are not inferred from previous steps.For example, in addition, LMs may predict higher-order digits before lower-order ones, contradicting the logical computation order.This paper introduces a novel metric to quantify and understand this complexity.</p>
<p>Definition of Sequential Intermediate Digits (SIDs)</p>
<p>A Sequential Intermediate Digit (SID) is a numeral crucial for the accurate prediction of the next digit in a sequence, yet not present in the preceding sequence.Within the framework of chain-of-thought reasoning, SIDs represent indispensable steps that, despite being missing, are vital for the computational process.Consequently, the Count of SIDs (CSIDs) is employed as a metric to assess the complexity of a generation step, with a higher CSID denoting a more demanding and intricate task.The CSID of an equation is thus defined as the maximum CSID required for generating each step of the result.The primary types of SIDs include:</p>
<p>• Carry-over or borrow digits in addition and subtraction.For example, in 123 + 179 = 302, the digit 3 in the hundreds place requires the carry-over from the tens and units places, resulting in a maximum CSID of 2.</p>
<p>• Digits from omitted reasoning steps, such as the intermediate sum 3 in 1 + 2 + 4 = 7.</p>
<p>It is postulated that basic operations like 1D by 1D addition, subtraction, multiplication, division, counting, and copying do not require SIDs, as their straightforward nature falls within the capabilities of modern LMs.Directly generating results for complex operations, such as multi-digit multiplication and division, requires more SIDs due to the omitted steps for decomposing these into multiple basic operations.</p>
<p>Reducing an equation's CSIDs, thereby lowering its solving difficulty, can be achieved by expanding the equation step-by-step in a chain-of-thought manner.For instance, the CSID for the calculation 1+2+4 = 3+4 = 7 is lower than for 1+2+4 = 7 because the intermediate sum 3 is included in the reasoning process, effectively reducing the number of SIDs.</p>
<p>The CSIDs for Arithmetic Operations</p>
<p>In our CSID analysis of standard arithmetic operations, which is akin to analyzing space or time complexity in algorithms, we focus on the
b m−1 . . . b 2 b 1 , result- ing in c = c t c t−1 . . . c 2 c 1 , with m ≤ n.
When involving negative numbers, the minus sign '-' is also treated as a digit.</p>
<p>• In addition and subtraction, the computation sequence
a n a n−1 . . . a 2 a 1 ± b m b m−1 . . . b 2 b 1 = c t c t−1 . . . c 2 c 1 depends on each c i involving a i , b i ,
and possibly c i−1 for carry-overs or borrows.Hence, the CSID for c t includes all lower digits as SIDs, indicating a complexity of O(n).</p>
<p>• For multiplication and division, the CSIDs are O(n 2 ) and O(n 2 − m 2 ) respectively, as detailed in Appendix A.</p>
<p>LLM Performance on Large CSID Equations</p>
<p>We trained various models on arithmetic tasks involving 15D+15D calculations, maintaining identical hyper-parameters, training data, and training steps across all models to ensure a fair comparison.</p>
<p>The test equations, strictly in 15D+15D format, were classified into various CSID levels according to the maximum number of continuous carry-over digits.The findings, as depicted in Fig. 2, demonstrate that:</p>
<p>• CSID effectively measures the complexity of arithmetic equations, where the performance consistently declines with increasing CSIDs.</p>
<p>• Larger models exhibit improved performance on equations with higher CSIDs.</p>
<p>• The benefit of increasing model size diminishes on high CSID equations.For instance, a 7B model shows more significant improvement on equations with CSIDs of 4 and 5 than on those with 6-9.This trend suggests that even advanced LLMs, like GPT-4, encounter difficulties with large digit addition tasks.Given that CSIDs have a complexity of at least O(n), arithmetic problems quickly surpass the capacity of LLMs when dealing with large digits.Therefore, LLMs cannot serve as reliable calculators for immediate result generation in complex arithmetic tasks.</p>
<p>4 RevOrder: Reversing the Order of Output Digits</p>
<p>We introduce RevOrder, an innovative technique devised to maintain low CSID in equations, thereby ensuring their solvability by LMs.Additionally, RevOrder is designed to minimize token usage, enhancing overall efficiency.</p>
<p>Addition and Subtraction</p>
<p>For addition and subtraction, we reverse the output digits' order:
a ± b = r|c 1 c 2 . . . c t = c t . . . c 2 c 1
Here, r| is a special token indicating that the followed digits are in a reversed order.To generate each c i in r|c 1 c 2 . . .c t , only a i , b i , and at most a SID for the carry-over or borrow number from c i−1 are required.Thus, both addition and subtraction only consume at most 1 SID regardless of number length.Therefore, the complexity of CSID drop to O(1) from O(n), by applying RevOrder.The cost of RevOrder for addition and subtraction is quite cheap during both training and inference.In training, RevOrder simply reverses the result digit orders.During inference, almost no additional tokens are required since the recovery of the result sequence can be done with rules.</p>
<p>Multiplication and Division</p>
<p>More complex operations like multiplication and division, can be decomposed to basic operations.</p>
<p>Multiplication</p>
<p>Firstly, consider the simplest form of multiplication, nD by 1D, e.g, 12*7=r|48, which consistently requires only 1 SID.This efficiency originates from the definition that 1D by 1D multiplication does not incur any SIDs, with the only one SID being the carry-over number in the addition.</p>
<p>Next, let's examine a more general multiplication example.</p>
<p>12 × 4567 =12 × 4000 + 12 × 500 + 12 × 60 + 12 × 7</p>
<p>(1)
=r|00084 + r|0006 + r|027 + r|48 (2) =(r|00084 + r|0006) + (r|027 + r|48) (3) =r|00045 + r|408 (4) =r|40845 =54804
First, decompose the multiplication as shown in Eqn.(1), which does not require any SIDs (require only count and copy operations that does not use SID in our definition).Second, output the results of each sub-multiplication in reverse order, as demonstrated in Eqn.(2).The zeros in these results can be efficiently generated through a copy operation from previous sequences.The nD by 1D multiplication in reverse order has a CSID of 1. Finally, iteratively combine the adjacent addition results until the final outcome is achieved, as illustrated in Eqn.</p>
<p>(3) and (4).As each addition operation involves only two numbers, the CSID remains constant at 1 throughout the process.</p>
<p>In conclusion, the CSID in this multiplication process never exceeds 1, with a complexity of O(1).</p>
<p>Division</p>
<p>Consider the division 948 ÷ 12 = 79:
948 ÷ 12 =7 Rem (948 − 12 × 70) (5) =7 Rem (948 − r|048) =7 Rem r|801 =79 Rem (r|801 − 12 * 9) (6) =79 Rem (r|801 − r|801) =79 Rem (0) =79
Utilizing traditional long division alongside RevOrder, the CSID typically remains at 1, with the exception of quotient estimation, as noted in Eqn.</p>
<p>(5) and Eqn.(6).Since the CSID analysis here is similar to that of multiplication, we omit it for brevity, .However, it's important to note that quotient estimation often involves heuristic guesswork, making precise CSID measurement challenging.In practice, we observed instances where the language model incorrectly estimated the quotient.To address this challenge, we implemented a rollback mechanism.If an incorrect quotient is detected, as illustrated in Eqn. ( 7), we insert a symbol 'W' after the line.This serves as a signal to adjust the process and re-estimate the quotient, as demonstrated in Eqn. ( 8).This method ensures more accurate quotient estimations in the long division process.In practice, a proportion of rollback scenarios are included in training to enhance the model's capability to correct such errors.
948 ÷ 12 =8 Rem (948 − 12 × 80) =8 Rem (948 − r|069) =8 Rem (−r|21)W (7) =7 Rem (948 − 12 × 70) (8) ...
However, the quotient estimation in division is inherently unpredictable, rendering the CSID of this operation less controllable.Consequently, unlike other arithmetic operations, the CSID for division cannot be consistently maintained at O(1).This limitation makes division with RevOrder less robust compared to addition, subtraction, and multiplication, as will be evidenced in our experimental results.</p>
<p>Towards More Compact Forms</p>
<p>To reduce token usage, we propose compact forms while maintaining CSID unchangeable.</p>
<p>For the multiplication example, it can be succinctly rewritten as: '12×4567 = 12×4000 + 12×500 + 12×60+ 12×7=r|00084 + r|0006 + r|027 + r|48 = r|00045 + r|408 = r|40845 = 54804'.Similarly, the division example can be condensed to: '948÷12 = 7R -(12×70)(r|048)(r|801) # 9R -(12×9)(r|801)(0) = 79', where R denotes REM and # denotes a new quotient estimation.</p>
<p>Two principles guide these simplifications: 1. Maintaining CSID: No digits essential for generating subsequent tokens are removed, ensuring the CSID remains unchanged.2. Eliminating Redundancy: Duplicated digits are removed, but care is taken to avoid introducing ambiguities that might confuse the LM.</p>
<p>Experiments on Arithmetic Problems</p>
<p>In this section, we aim to address two key research questions (RQs):</p>
<p>• RQ1: Does RevOrder enable a language model to function as a reliable calculator?(Section 5.2)</p>
<p>• RQ2: Is RevOrder a cost-effective solution for practical using?(Section 5.4)</p>
<p>Setup</p>
<p>Dataset</p>
<p>Our training dataset is synthetically generated using a Python script, with each sample being an equation formatted with RevOrder, e.g., '123+46=r|961'.The dataset comprises positive integers, except in subtraction where negative numbers may result.Each division equation is assigned a probability of 0.5 to be selected for generating a rollback version.This involves intentionally misestimating a quotient step by a number ±1, followed by a correction through the rollback process to the accurate estimation.The detailed of the training data is shown in Appendix B.</p>
<p>Training and evaluation protocol</p>
<p>We train a model named RevOrder-1B, which has 1.1 billion parameters.This model is trained on the TinyLLaMA 1.1B framework (Zhang et al., 2024), utilizing their released finetuning script.Specifically, the learning rate is set to 1e-4 for first 2 epochs and 1e-5 for the last epoch.The batch size is 500.</p>
<p>For evaluation, we employ the BIG-bench Arithmetic sub-task (Srivastava et al., 2022) and additional challenging tasks proposed in the GOAT-7B paper (Liu and Low, 2023).Each task has 1000 equations.We meticulously ensure that there is no overlap between the evaluation datasets and our training dataset, except for unavoidable overlaps in small digits tasks.The evaluation metric is exact match precision.</p>
<p>Baselines</p>
<p>As baselines, we compare against three methods:</p>
<p>• GOAT-7B (Liu and Low, 2023): This model, finetuned with 1 million instruction data on LLAMA-7B (Touvron et al., 2023), decomposes multiplication and division similarly to our approach.However, it relies on direct result generation for subtraction and addition.</p>
<p>• MathGLM-2B (Yang et al., 2023): Finetuned on the GLM-2B model for various arithmetic tasks, MATHGLM-2B claims that extensive step-by-step training data (1m-50m instances) enables GPT models to solve math problems without external calculators.</p>
<p>• GPT-4 (OpenAI, 2023): Currently one of the most powerful LMs, GPT-4's results are based on direct mathematical problem-solving, without auxiliary tools or equation decomposition.</p>
<p>Main Results (RQ1)</p>
<p>The results, as presented in Table 1, demonstrate several key findings.Firstly, RevOrder-1B proves to be a reliable method for addition, subtraction, multiplication, and low-digit division tasks, achieving 100% accuracy across all corresponding tasks.In contrast, the accuracy of all baseline methods decreases with the increase in digit size.Secondly, while RevOrder-1B shows slight imperfections in large-digit division tasks, it still significantly outperforms baseline models.For instance, RevOrder-1B attains a 99.4% accuracy on the challenging 12D ÷ 6D tasks, with an increasing of 10.1% than that of the best-performing baseline, GOAT-7B.</p>
<p>The major success of RevOrder in multiplication and division can be attributed to its precise execution of basic operations, including addition, subtraction, and nD-1D multiplication.While GOAT-7B and MathGLM-2B also decompose these operations into basic ones, minor errors in these fundamental steps are amplified in subsequent composite operations, leading to a rapid decline in accuracy with larger digits.</p>
<p>In summary, RevOrder emerges as an effective technique, enabling language models to perform exact arithmetic calculations in addition, subtraction, multiplication, and low-digit division tasks.</p>
<p>In-Depth Analysis on Division</p>
<p>Large-digit division represents the sole operation where RevOrder encounters notable difficulties, warranting additional focus.</p>
<p>Upon examining division errors case by case, we discovered that all errors stemmed from incorrect quotient estimations.Fig. 3 illustrates such an error, where RevOrder-1B erroneously estimated the 3rd quotient as 8 (marked in red) instead of 9, without triggering the 'W' symbol for a rollback.Consequently, this led to a series of nonsensical outputs.It's notable that when a constant CSID  of 1 is maintained in all four arithmetic operations, no errors occur.Errors only arise during quotient estimation, where CSID is unmeasurable.These results validate our theory regarding CSID.</p>
<p>We also assessed the effectiveness of the rollback mechanism.Fig. 4(a) presents the test precision for 12D ÷ 6D division across varying rollback ratios.A stark precision decline to 0.84 is observed with no rollback (ratio = 0).Precision does not significantly improve when the ratio exceeds 0.4, though this is partly due to the high baseline precision of 0.99.Fig. 4(b) illustrates the frequency of rollbacks during testing, indicating a higher incidence of rollbacks with larger digits.This trend underscores the importance of the rollback technique, particularly as it compensates for the increased likelihood of errors in quotient estimation with larger numbers.</p>
<p>The Cost of RevOrder (RQ2)</p>
<p>Cost of Training</p>
<p>By maintaining a low CSID, RevOrder simplifies the learning process for arithmetic problems, thereby reducing the volume of training data required.precision with at most half the training equations compared to other methods.Recent studies indicate that larger models often require less training data for task mastery (Hoffmann et al., 2022;Xia et al., 2022).Consequently, the training cost advantage of RevOrder is likely to be even more pronounced with larger LLMs.</p>
<p>Cost of Inference</p>
<p>The inference cost is assessed based on the number of additional tokens required for performing arithmetic calculations with RevOrder.We make two assumptions: 1) Each character (digit, symbol, etc.) is counted as one token, and 2) if the final result is output in reverse, the recovery process is handled by the tokenizer's decode function.</p>
<p>For addition and subtraction equations, only one extra token ('r|') is required.For multiplication and division equations, the number of extra tokens used is illustrated in Fig. 5. RevOrder is more token-efficient in both types of equations.Firstly, the compact form introduced in Section 3.3 significantly reduces the token requirement for division, approximately halving the number of extra tokens.Secondly, the iterative combination approach in multiplication, as exemplified in Eqn.</p>
<p>(3), also notably reduces token usage in multiplication.However, it must be acknowledged that for largedigit multiplication and division tasks, the token consumption of RevOrder increases polynomially and may eventually exceed the cost of using external tools.LLM service providers can set a threshold of digit number to decide between RevOrder and tool-based solutions.</p>
<p>Additional Experiments on Math Word Problems</p>
<p>In this section, we delve into finetuning scenarios to address the research question:</p>
<p>• RQ3: How does applying RevOrder affect finetuning performance on mathematical tasks?</p>
<p>Setup</p>
<p>The experiment is conducted on GSM8K (Cobbe et al., 2021), a dataset of 8.5K high quality linguistically diverse grade school math word problems created by human problem writers.Our experiments utilize LLAMA2-7B (Touvron et al., 2023) as the foundational model.We modified the equations in the GSM8K training set to adopt the RevOrder format.This adaptation involved two major updates: Firstly, we presented the outcomes for addition, subtraction, and multiplication in reverse order.Secondly, polynomial equations were expanded and solved iteratively, in pairs.Noted that we did not decompose multi-digit multiplications and divisions, as these cases are infrequent in the GSM8K dataset.To further enhance the model's proficiency with RevOrder, we supplemented the training set with a small, synthetically generated dataset using a Python script.The comprehensive details of the dataset and the training parameters are provided in Appendix C.</p>
<p>Results</p>
<p>From the analysis, it is evident that RevOrder significantly reduces calculation errors, by 94% for addition, 87% for subtraction, and 46% for overall equation errors, thereby enhancing the final score.This improvement underscores the potential of seamlessly integrating RevOrder into fine-tuning processes to achieve substantial performance gains.</p>
<p>We also observe the errors, and find most of the errors are due to lack of enough training.Table 3: Fine-tuning results on GSM8K Dataset.This table compares the performance of models fine-tuned with the original GSM8K dataset (baseline) against those finetuned using the RevOrder-modified GSM8K dataset.The Score is measured by the correctness ratio of final results.</p>
<p>stage rather than the fine-tuning stage.The primary rationale is that excessive fine-tuning can lead to catastrophic forgetting, thereby impairing the general capabilities of LMs (Luo et al., 2023;Ramasesh et al., 2021).</p>
<p>Conclusion</p>
<p>In this paper, we introduce the CSID as a metric to evaluate the complexity of arithmetic equations and demonstrate that even large-scale LLMs struggle with high-CSID equations.We propose RevOrder, an innovative technique that ensures accurate arithmetic calculations by minimizing CSID, thereby enhancing precision while reducing both training and inference costs.Our experiments confirm that RevOrder significantly outperforms previous methods in terms of accuracy and efficiency.</p>
<p>For future work, we identify two possible paths: Firstly, developing token-efficient decomposition algorithms suitable for larger LLMs, which can handle higher CSIDs for complex arithmetic operations.Secondly, integrating RevOrder into LLMs' pretraining could enhance arithmetic capabilities more fundamentally than finetuning, reducing the risk of catastrophic forgetting and ensuring broader model proficiency.</p>
<p>Ultimately, RevOrder stands out as a particularly promising approach for arithmetic operations, especially addition and subtraction, due to its precision and efficiency.This positions it as a competitive alternative to existing methods in enhancing LLMs' arithmetic reasoning.</p>
<p>A The CSID Analysis of Multiplication and Division</p>
<p>This section extends the CSID analysis to nD by nD multiplication and nD by mD division, following the algorithmic approach outlined in Section 4.2 but excluding the RevOrder technique.</p>
<p>A.1 Multiplication</p>
<p>The decomposition of an nD by nD multiplication into n sub-multiplications, each an nD by 1D operation, serves as the initial step.This phase does not generate SIDs, as all required digits for a × b are immediately accessible.Addressing these sub-multiplications yields up to n 2 + n × (n + 1) = 2n 2 + n SIDs, with n 2 SIDs allocated for the sub-multiplications and n×(n+1) SIDs dedicated to storing the outcomes.</p>
<p>Aggregating the results of these submultiplications necessitates a maximum of 4n 2 SIDs, with each addition consuming 4n SIDs, 2n for carry-overs and another 2n for storing the results.</p>
<p>Consequently, directly generating an nD by nD multiplication outcome requires a maximum of 6n 2 + n SIDs, indicating a complexity of O(n 2 ).This substantial complexity explains the difficulty models face with even 2D by 2D multiplications.</p>
<p>Decomposition methods, as applied in models like GOAT-7B and MathGLM-2B, reduce the CSID to O(n), by omitting intermediate results from the SID count, though carry-overs are still considered.</p>
<p>A.2 Division</p>
<p>For an nD by mD division, typically n − m iterations are needed, each estimating a quotient digit.</p>
<p>Each iteration involves an nD by 1D multiplication and a subtraction, with the multiplication incurring 2m SIDs for result and carry-over digit storage, and the subtraction using up to 2n SIDs for result storage and borrow digits.</p>
<p>Thus, the total CSID for an nD by mD division reaches (2m+2n) * (n−m) = 2n 2 −2m 2 , amounting to a complexity of O(n 2 − m 2 ).</p>
<p>This estimation excludes the quotient estimation step's complexity, which could further complicate large number divisions, potentially surpassing the O(n 2 − m 2 ) complexity.</p>
<p>In models like GOAT-7B and MathGLM-2B, using decomposition methods keeps the CSID at O(n), with the subtraction's borrow digits being the primary complexity factor.</p>
<p>B Training Data for Arithmetic Experiments</p>
<p>The training dataset comprises 1.7 million equations.For addition and subtraction tasks, equations involve numbers as large as 16D on both sides.Multiplication tasks are capped at 8D by 8D, supplemented by 16D by 1D equations to enhance generalization in the test set.Division tasks feature dividends up to 16D.Fig. 6 illustrates the distribution of these equations.The major training samples are division, since the quotient estimation steps require more training samples to achieve a high precision.</p>
<p>C Settings for Math Word Experiments C.1 Training Data</p>
<p>Our approach involved two types of instructional data to train models on arithmetic tasks using RevOrder.</p>
<p>Firstly, we modified the original GSM8K dataset to reflect RevOrder formatting.An example of this adaptation is illustrated in Fig. 7.</p>
<p>Secondly, to further bolster the model's proficiency in RevOrder calculations, we compiled an additional enhancement dataset.A sample from this dataset is depicted in Fig. 8.</p>
<p>Given the limited size of the training data, the 7B model faced challenges in mastering the use of the reverse symbol r|.To address this, we introduced a notation where all numbers enclosed by @@, signify reverse order.</p>
<p>C.2 Training Details</p>
<p>The models were trained with a batch size of 32 and a learning rate of 5e-5, employing a warm-up ratio of 0.08 over 3 epochs.During each epoch, the model was exposed to both the additional datasets and the GSM8K datasets sequentially.</p>
<p>C.3 Equation Errors</p>
<p>Fig. 9 showcases representative errors encountered in the GSM8K test set, attributable to difficulties in adhering to RevOrder instructions.For instance, while the model successfully solved the second equation in reverse order, it faltered in performing the simple task of reversing the solution to arrive at the final result.</p>
<p>Figure 2 :
2
Figure 2: LLM performance on equations with varying CSIDs.</p>
<p>Figure 3 :
3
Figure 3: An error example of division by RevOrder.</p>
<p>Figure 4 :
4
Figure 4: Analysis of the rollback ratio in division.(a) Test precision vs. rollback ratio for 12D ÷ 6D division.(b) Probability of rollbacks during testing across different digit sizes.</p>
<p>Figure 5 :
5
Figure 5: The number of extra tokens required for multiplication and division.</p>
<p>Figure 6 :
6
Figure 6: The distribution of the equations in training set.</p>
<p>Figure 7 :
7
Figure 7: A data sample from the GSM8K dataset formatted in RevOrder.</p>
<p>Figure 8 :
8
Figure 8: A sample from the additional enhancement dataset for RevOrder calculations.</p>
<p>Figure 9 :
9
Figure 9: Illustrative errors from the GSM8K test set encountered by the model trained with RevOrder.</p>
<p>Table 1 :
1
Liu and Low (2023) number of training equations needed for various methods.Despite being a smaller model, RevOrder-1B achieves perfect Performance comparison on various arithmetic tasks.The results of the baseline methods are taken from their original paper, while the result of GPT-4 is taken fromLiu and Low (2023).
TaskBIG-benchExtra TasksADD1D2D3D4D5D8D+8D16D+8D 16D+16DGPT-4100 100 99.6 98.8 94.192.19.494.1GOAT-7B100 100 99.4 98.3 98.197.897.197.6MathGLM-2B 100 100100100 99.4---RevOrder-1B100 100100100100100100100SUB1D2D3D4D5D8D-8D16D-8D16D-16DGPT-4100 100 99.2 98.9 92.470.510.659.6GOAT-7B100 100 99.7 98.6 98.496.895.896.3MathGLM-2B 100 100 99.9 99.8 98.9---RevOrder-1B100 100100100100100100100MUL1D2D3D4D5D16D × 1D 8D × 4D6D×6DGPT-4100 99.4 30.35.30.061.50.00.0GOAT-7B100 100 97.8 96.9 96.799.788.196.8MathGLM-2B 100 99.9 98.3 94.9 89.9---RevOrder-1B100 100100100100100100100DIV1D2D3D4D5D16D÷1D6D÷3D12D÷6DGPT-4100 100 94.5 90.9 53.4546.40.0GOAT-7B100 100 99.59996.59994.189.3MathGLM-2B 100 100 99.4 100 94.9---RevOrder-1B100 10010010010099.210099.4Model# Equations 100% ACCRevOrder-1B0.5mYesMathGLM-2B1m-50mNoGOAT-7B1.7mNo</p>
<p>Table 2 :
2
Number of training equations for different methods.This table reports the dataset size required for RevOrder-1B to achieve 100% accuracy on all Bigbench arithmetic sub-tasks.# Equations denotes the number of training equations.</p>
<p>Program of thoughts prompting: Disentangling computation from reasoning for numerical reasoning tasks. Wenhu Chen, Xueguang Ma, Xinyi Wang, William W Cohen, arXiv:2211.125882022arXiv preprint</p>
<p>Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, arXiv:2110.14168Training verifiers to solve math word problems. 2021arXiv preprint</p>
<p>Pal: Program-aided language models. Luyu Gao, Aman Madaan, Shuyan Zhou, Uri Alon, Pengfei Liu, Yiming Yang, Jamie Callan, Graham Neubig, International Conference on Machine Learning. PMLR2023</p>
<p>Jordan Hoffmann, Sebastian Borgeaud, Arthur Mensch, Elena Buchatskaya, Trevor Cai, Eliza Rutherford, Diego De Las, Lisa Anne Casas, Johannes Hendricks, Aidan Welbl, Clark, arXiv:2203.15556Training compute-optimal large language models. 2022arXiv preprint</p>
<p>Learning to solve arithmetic word problems with verb categorization. Mohammad Javad Hosseini, Hannaneh Hajishirzi, Oren Etzioni, Nate Kushman, Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP). the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)2014</p>
<p>Jared Kaplan, Sam Mccandlish, Tom Henighan, Tom B Brown, Benjamin Chess, Rewon Child, Scott Gray, Alec Radford, Jeffrey Wu, Dario Amodei, arXiv:2001.08361Scaling laws for neural language models. 2020arXiv preprint</p>
<p>Large language models are zero-shot reasoners. Takeshi Kojima, Shane Shixiang, Machel Gu, Yutaka Reid, Yusuke Matsuo, Iwasawa, Advances in neural information processing systems. 202235</p>
<p>Learning to automatically solve algebra word problems. Nate Kushman, Yoav Artzi, Luke Zettlemoyer, Regina Barzilay, Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics. Long Papers. the 52nd Annual Meeting of the Association for Computational Linguistics20141</p>
<p>Tiedong Liu, Bryan Kian, Hsiang Low, arXiv:2305.14201Goat: Fine-tuned llama outperforms gpt-4 on arithmetic tasks. 2023arXiv preprint</p>
<p>Pan Lu, Liang Qiu, Wenhao Yu, Sean Welleck, Kai-Wei Chang, arXiv:2212.10535A survey of deep learning for mathematical reasoning. 2022arXiv preprint</p>
<p>An empirical study of catastrophic forgetting in large language models during continual fine-tuning. Yun Luo, Zhen Yang, Fandong Meng, Yafu Li, Jie Zhou, Yue Zhang, arXiv:2308.087472023arXiv preprint</p>
<p>Maxwell Nye, Anders Johan Andreassen, Guy Gur-Ari, Henryk Michalewski, Jacob Austin, David Bieber, David Dohan, Aitor Lewkowycz, Maarten Bosma, David Luan, arXiv:2112.00114Show your work: Scratchpads for intermediate computation with language models. 2021arXiv preprint</p>
<p>Introducing chatgpt. Gpt-4 technical report. 2022OpenAI</p>
<p>Effect of scale on catastrophic forgetting in neural networks. Vinay Venkatesh Ramasesh, Aitor Lewkowycz, Ethan Dyer, 2021In International Conference on Learning Representations</p>
<p>Toolformer: Language models can teach themselves to use tools. Timo Schick, Jane Dwivedi-Yu, Roberto Dessì, Roberta Raileanu, Maria Lomeli, Luke Zettlemoyer, Nicola Cancedda, Thomas Scialom, arXiv:2302.047612023arXiv preprint</p>
<p>Aarohi Srivastava, Abhinav Rastogi, Abhishek Rao, Abu Awal, Md Shoeb, Abubakar Abid, Adam Fisch, Adam Adam R Brown, Aditya Santoro, Adrià Gupta, Garriga-Alonso, arXiv:2206.04615Beyond the imitation game: Quantifying and extrapolating the capabilities of language models. 2022arXiv preprint</p>
<p>Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, arXiv:2307.09288Llama 2: Open foundation and fine-tuned chat models. 2023arXiv preprint</p>
<p>Deep neural solver for math word problems. Yan Wang, Xiaojiang Liu, Shuming Shi, Proceedings of the 2017 conference on empirical methods in natural language processing. the 2017 conference on empirical methods in natural language processing2017</p>
<p>Jason Wei, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian Borgeaud, Dani Yogatama, Maarten Bosma, Denny Zhou, Donald Metzler, arXiv:2206.07682Emergent abilities of large language models. 2022aarXiv preprint</p>
<p>Chain-of-thought prompting elicits reasoning in large language models. Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Denny Quoc V Le, Zhou, Advances in Neural Information Processing Systems. 2022b35</p>
<p>Training trajectories of language models across scales. Mengzhou Xia, Mikel Artetxe, Chunting Zhou, Xi Victoria Lin, Ramakanth Pasunuru, Danqi Chen, Luke Zettlemoyer, Ves Stoyanov, arXiv:2212.098032022arXiv preprint</p>
<p>Zhen Yang, Ming Ding, Qingsong Lv, Zhihuan Jiang, Zehai He, Yuyi Guo, Jinfeng Bai, Jie Tang, arXiv:2309.03241Gpt can solve mathematical problems without a calculator. 2023arXiv preprint</p>            </div>
        </div>

    </div>
</body>
</html>