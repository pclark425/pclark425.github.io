<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-259 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-259</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-259</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-14.html">extraction-schema-14</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models perform arithmetic operations, including the types of arithmetic tasks, model properties, performance results, methods used, and any mechanistic insights about how the models solve arithmetic problems.</div>
                <p><strong>Paper ID:</strong> paper-268384852</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2403.09479v1.pdf" target="_blank">Laying the Foundation First? Investigating the Generalization from Atomic Skills to Complex Reasoning Tasks</a></p>
                <p><strong>Paper Abstract:</strong> Current language models have demonstrated their capability to develop basic reasoning, but struggle in more complicated reasoning tasks that require a combination of atomic skills, such as math word problem requiring skills like arithmetic and unit conversion. Previous methods either do not improve the inherent atomic skills of models or not attempt to generalize the atomic skills to complex reasoning tasks. In this paper, we first propose a probing framework to investigate whether the atomic skill can spontaneously generalize to complex reasoning tasks. Then, we introduce a hierarchical curriculum learning training strategy to achieve better skill generalization. In our experiments, we find that atomic skills can not spontaneously generalize to compositional tasks. By leveraging hierarchical curriculum learning, we successfully induce generalization, significantly improve the performance of open-source LMs on complex reasoning tasks. Promisingly, the skill generalization exhibit effective in cross-dataset and cross-domain scenarios. Complex reasoning can also help enhance atomic skills. Our findings offer valuable guidance for designing better training strategies for complex reasoning tasks.</p>
                <p><strong>Cost:</strong> 0.012</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e259.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e259.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models perform arithmetic operations, including the types of arithmetic tasks, model properties, performance results, methods used, and any mechanistic insights about how the models solve arithmetic problems.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LLaMA-2 (7B) - arithmetic evaluation</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>LLaMA-2 (7B) evaluated in "Laying the Foundation First? Investigating the Generalization from Atomic Skills to Complex Reasoning Tasks"</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Evaluation of a 7B LLaMA-2 model on arithmetic subskills (Add/Sub, simple multiplication S-Mul, complex multiplication C-Mul, division) and multi-hop arithmetic within math word problems (MWP). Experiments test baseline, skill-specialized fine-tuning, applied compositional training, and a two-stage hierarchical curriculum (skill training + applied learning) to probe generalization of arithmetic skills to complex reasoning.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>LLaMA-2</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>7B</td>
                        </tr>
                        <tr>
                            <td><strong>model_architecture</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>arithmetic_operation_type</strong></td>
                            <td>addition, subtraction, multiplication (simple S-Mul; complex C-Mul with digit-splitting chain-of-thought), division, multi-hop arithmetic (2-5 hops), mixed operations (MixMul, MixAll)</td>
                        </tr>
                        <tr>
                            <td><strong>number_range_or_complexity</strong></td>
                            <td>Variable: integers and floats, mixed types; significant digits length ranged 1–8; multi-hop formulas of 2–5 hops; problems include multi-digit and decimal multiplication (including up to 8 significant digits after augmentation)</td>
                        </tr>
                        <tr>
                            <td><strong>method_or_intervention</strong></td>
                            <td>Zero-shot and few-shot prompting for evaluation; Chain-of-Thought (COT) responses used for complex arithmetic in prerequisite data; three training regimes tested—Skill Training (ST) on automatically-generated arithmetic prerequisite data with replay of MWP examples, Applied Learning (AL) using compositional (MWP + inserted COT arithmetic/unit-conversion) data, and Hierarchical Curriculum Learning (HCL) = ST then AL. Replay mixing ratios used (arithmetic mixing ratio chosen = 10). Greedy decoding for inference.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_result</strong></td>
                            <td>Baseline MWP performance low on augmented HARD set (examples: LLaMA-2 improved from 13.60% to 28.76% zero-shot on HARD after HCL). Skill training massively improves atomic-subtask (C-Mul) accuracy: applied learning increased C-Mul from 22.91% to 40.72%, while dedicated skill training raised C-Mul to 93.45% (Appendix D.2). Arithmetic/unit-conversion evaluation on GSM8K reported: RAW overall 27.16% (w/ unit conv. 21.31%); HARD overall 14.44% (w/ unit conv. 1.72%). Exact per-operation breakdowns reported in paper figures/tables (AddSub, MixMul, MixAll) showing substantial drops on HARD vs RAW and large gains after HCL.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_insight</strong></td>
                            <td>No low-level mechanistic (attention-head / neuron) analysis was provided; authors' mechanistic interpretation: models do not spontaneously apply separately learned arithmetic skills to compositional MWP responses because response format and application differ; COT-style training (digit-splitting and stepwise arithmetic) and explicit applied-learning examples induce the model to integrate atomic-skill formats into complex-answer generation. Improvement attributed to improved atomic skill competence (composability of skill segments), not to external tools. Also observed that compositional training can reinforce atomic skills but is less effective than dedicated skill training because compositional datasets are less heterogeneous.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_scaling</strong></td>
                            <td>Reported training-data / convergence scaling: Applied Learning typically converged with <200K tokens, while Skill Training required >600K tokens to reach high atomic-skill proficiency. HCL (ST then AL) reaches a higher performance upper bound than AL alone. No explicit scaling with model parameter count beyond experiments on 7B models.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_modes</strong></td>
                            <td>Primary failure mode in baseline: arithmetic and unit-conversion errors dominate MWP failures. Specific observed error pattern: S-Mul (simple multiplication where second value has single significant digit) exhibited magnitude/decimal-place errors (example: calculating 2.61 * 0.01 resulting in 0.00261 vs correct 0.0261 in some HCL variants), indicating mistakes in decimal-place handling. Other failures include catastrophic forgetting when distribution of atomic operations in compositional data diverges from prerequisite training distribution. Few-shot prompting did not substitute for training-induced generalization (few-shot metrics did not surpass zero-shot in inducing the same generalization).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Compared baseline (vanilla LLaMA-2) vs Skill Training (ST) vs Applied Learning (AL) vs Hierarchical Curriculum Learning (HCL). Also compared zero-shot and few-shot prompting; mixture training (mixing arithmetic prerequisite and MWP examples) evaluated for replay to avoid forgetting. Mixture training and HCL outperform applied learning alone; ST essential for best performance.</td>
                        </tr>
                        <tr>
                            <td><strong>key_finding</strong></td>
                            <td>Arithmetic competence does not spontaneously transfer from isolated skill fine-tuning to complex MWP answering; explicitly teaching atomic arithmetic processes (digit-splitting COT) and then training on compositional examples (HCL: ST→AL) induces integration of arithmetic procedures into MWP solutions and yields substantial gains (e.g., LLaMA-2 HARD zero-shot from ~13.6% → ~28.8%; C-Mul up to ~93% with ST).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Laying the Foundation First? Investigating the Generalization from Atomic Skills to Complex Reasoning Tasks', 'publication_date_yy_mm': '2024-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e259.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e259.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of how language models perform arithmetic operations, including the types of arithmetic tasks, model properties, performance results, methods used, and any mechanistic insights about how the models solve arithmetic problems.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Mistral-7B - unit-conversion & arithmetic evaluation</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Mistral-7B evaluated in "Laying the Foundation First? Investigating the Generalization from Atomic Skills to Complex Reasoning Tasks"</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Evaluation of a Mistral-7B model on GSM8K MWP with emphasis on unit-conversion and arithmetic subskills; used as a cross-family model to test skill generalization and sensitivity to HARD augmentation.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Mistral-7B</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>7B</td>
                        </tr>
                        <tr>
                            <td><strong>model_architecture</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>arithmetic_operation_type</strong></td>
                            <td>addition, subtraction, multiplication, division, and unit-conversion related arithmetic in MWPs (same taxonomy as LLaMA-2 evaluation: AddSub, MixMul, MixAll, C-Mul/S-Mul distinctions)</td>
                        </tr>
                        <tr>
                            <td><strong>number_range_or_complexity</strong></td>
                            <td>GSM8K RAW and HARD augmentations: mixed integer and floating point values; HARD increases significant-digit lengths and diversifies unit representations (no explicit absolute numeric range provided).</td>
                        </tr>
                        <tr>
                            <td><strong>method_or_intervention</strong></td>
                            <td>Evaluated on RAW and HARD GSM8K; unit-conversion augmentation applied; training interventions (ST/AL/HCL) described in paper applied mainly in LLaMA-2 experiments, Mistral used as additional baseline for RAW vs HARD evaluation.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_result</strong></td>
                            <td>Reported GSM8K unit-conversion related results (Table 8): RAW overall 45.10% (w/ unit conv. 47.54%); HARD overall 29.46% (w/ unit conv. 13.79%). These numbers indicate performance drops on HARD augmentation and lower unit-conversion accuracy on HARD.</td>
                        </tr>
                        <tr>
                            <td><strong>mechanistic_insight</strong></td>
                            <td>No internal mechanistic analysis for Mistral; same high-level interpretation as for LLaMA-2: unit-conversion competency and integration into MWP answers require targeted data/formats and show sensitivity to representation variability.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_scaling</strong></td>
                            <td>No explicit model-size scaling beyond reporting of Mistral-7B numbers relative to LLaMA-2-7B; observed that RAW->HARD augmentation reduces accuracy for both models.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_modes</strong></td>
                            <td>Marked drop in unit-conversion performance on HARD; paper notes GSM8K originally had narrow unit representation leading to overestimation of unit-conversion ability and that diverse unit representations uncover weaknesses.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_baseline</strong></td>
                            <td>Compared RAW vs HARD evaluation and contrasted with LLaMA-2 results; used as cross-family baseline in paper.</td>
                        </tr>
                        <tr>
                            <td><strong>key_finding</strong></td>
                            <td>Model performance on arithmetic and unit-conversion tasks degrades on harder (HARD) augmented testsets that increase significant-digit complexity and diversify unit representations; targeted skill training is required to robustly generalize atomic arithmetic/unit skills into compositional MWPs.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Laying the Foundation First? Investigating the Generalization from Atomic Skills to Complex Reasoning Tasks', 'publication_date_yy_mm': '2024-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Goat: Fine-tuned llama outperforms gpt-4 on arithmetic tasks <em>(Rating: 2)</em></li>
                <li>Investigating the limitations of transformers with simple arithmetic tasks <em>(Rating: 2)</em></li>
                <li>Evaluating transformer language models on arithmetic operations using number decomposition <em>(Rating: 2)</em></li>
                <li>Chain-of-thought prompting elicits reasoning in large language models <em>(Rating: 2)</em></li>
                <li>Are NLP models really able to solve simple math word problems? <em>(Rating: 2)</em></li>
                <li>Enhancing quantitative reasoning skills of large language models through dimension perception <em>(Rating: 2)</em></li>
                <li>Do language models understand measurements? <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-259",
    "paper_id": "paper-268384852",
    "extraction_schema_id": "extraction-schema-14",
    "extracted_data": [
        {
            "name_short": "LLaMA-2 (7B) - arithmetic evaluation",
            "name_full": "LLaMA-2 (7B) evaluated in \"Laying the Foundation First? Investigating the Generalization from Atomic Skills to Complex Reasoning Tasks\"",
            "brief_description": "Evaluation of a 7B LLaMA-2 model on arithmetic subskills (Add/Sub, simple multiplication S-Mul, complex multiplication C-Mul, division) and multi-hop arithmetic within math word problems (MWP). Experiments test baseline, skill-specialized fine-tuning, applied compositional training, and a two-stage hierarchical curriculum (skill training + applied learning) to probe generalization of arithmetic skills to complex reasoning.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "LLaMA-2",
            "model_size": "7B",
            "model_architecture": null,
            "arithmetic_operation_type": "addition, subtraction, multiplication (simple S-Mul; complex C-Mul with digit-splitting chain-of-thought), division, multi-hop arithmetic (2-5 hops), mixed operations (MixMul, MixAll)",
            "number_range_or_complexity": "Variable: integers and floats, mixed types; significant digits length ranged 1–8; multi-hop formulas of 2–5 hops; problems include multi-digit and decimal multiplication (including up to 8 significant digits after augmentation)",
            "method_or_intervention": "Zero-shot and few-shot prompting for evaluation; Chain-of-Thought (COT) responses used for complex arithmetic in prerequisite data; three training regimes tested—Skill Training (ST) on automatically-generated arithmetic prerequisite data with replay of MWP examples, Applied Learning (AL) using compositional (MWP + inserted COT arithmetic/unit-conversion) data, and Hierarchical Curriculum Learning (HCL) = ST then AL. Replay mixing ratios used (arithmetic mixing ratio chosen = 10). Greedy decoding for inference.",
            "performance_result": "Baseline MWP performance low on augmented HARD set (examples: LLaMA-2 improved from 13.60% to 28.76% zero-shot on HARD after HCL). Skill training massively improves atomic-subtask (C-Mul) accuracy: applied learning increased C-Mul from 22.91% to 40.72%, while dedicated skill training raised C-Mul to 93.45% (Appendix D.2). Arithmetic/unit-conversion evaluation on GSM8K reported: RAW overall 27.16% (w/ unit conv. 21.31%); HARD overall 14.44% (w/ unit conv. 1.72%). Exact per-operation breakdowns reported in paper figures/tables (AddSub, MixMul, MixAll) showing substantial drops on HARD vs RAW and large gains after HCL.",
            "mechanistic_insight": "No low-level mechanistic (attention-head / neuron) analysis was provided; authors' mechanistic interpretation: models do not spontaneously apply separately learned arithmetic skills to compositional MWP responses because response format and application differ; COT-style training (digit-splitting and stepwise arithmetic) and explicit applied-learning examples induce the model to integrate atomic-skill formats into complex-answer generation. Improvement attributed to improved atomic skill competence (composability of skill segments), not to external tools. Also observed that compositional training can reinforce atomic skills but is less effective than dedicated skill training because compositional datasets are less heterogeneous.",
            "performance_scaling": "Reported training-data / convergence scaling: Applied Learning typically converged with &lt;200K tokens, while Skill Training required &gt;600K tokens to reach high atomic-skill proficiency. HCL (ST then AL) reaches a higher performance upper bound than AL alone. No explicit scaling with model parameter count beyond experiments on 7B models.",
            "failure_modes": "Primary failure mode in baseline: arithmetic and unit-conversion errors dominate MWP failures. Specific observed error pattern: S-Mul (simple multiplication where second value has single significant digit) exhibited magnitude/decimal-place errors (example: calculating 2.61 * 0.01 resulting in 0.00261 vs correct 0.0261 in some HCL variants), indicating mistakes in decimal-place handling. Other failures include catastrophic forgetting when distribution of atomic operations in compositional data diverges from prerequisite training distribution. Few-shot prompting did not substitute for training-induced generalization (few-shot metrics did not surpass zero-shot in inducing the same generalization).",
            "comparison_baseline": "Compared baseline (vanilla LLaMA-2) vs Skill Training (ST) vs Applied Learning (AL) vs Hierarchical Curriculum Learning (HCL). Also compared zero-shot and few-shot prompting; mixture training (mixing arithmetic prerequisite and MWP examples) evaluated for replay to avoid forgetting. Mixture training and HCL outperform applied learning alone; ST essential for best performance.",
            "key_finding": "Arithmetic competence does not spontaneously transfer from isolated skill fine-tuning to complex MWP answering; explicitly teaching atomic arithmetic processes (digit-splitting COT) and then training on compositional examples (HCL: ST→AL) induces integration of arithmetic procedures into MWP solutions and yields substantial gains (e.g., LLaMA-2 HARD zero-shot from ~13.6% → ~28.8%; C-Mul up to ~93% with ST).",
            "uuid": "e259.0",
            "source_info": {
                "paper_title": "Laying the Foundation First? Investigating the Generalization from Atomic Skills to Complex Reasoning Tasks",
                "publication_date_yy_mm": "2024-03"
            }
        },
        {
            "name_short": "Mistral-7B - unit-conversion & arithmetic evaluation",
            "name_full": "Mistral-7B evaluated in \"Laying the Foundation First? Investigating the Generalization from Atomic Skills to Complex Reasoning Tasks\"",
            "brief_description": "Evaluation of a Mistral-7B model on GSM8K MWP with emphasis on unit-conversion and arithmetic subskills; used as a cross-family model to test skill generalization and sensitivity to HARD augmentation.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "Mistral-7B",
            "model_size": "7B",
            "model_architecture": null,
            "arithmetic_operation_type": "addition, subtraction, multiplication, division, and unit-conversion related arithmetic in MWPs (same taxonomy as LLaMA-2 evaluation: AddSub, MixMul, MixAll, C-Mul/S-Mul distinctions)",
            "number_range_or_complexity": "GSM8K RAW and HARD augmentations: mixed integer and floating point values; HARD increases significant-digit lengths and diversifies unit representations (no explicit absolute numeric range provided).",
            "method_or_intervention": "Evaluated on RAW and HARD GSM8K; unit-conversion augmentation applied; training interventions (ST/AL/HCL) described in paper applied mainly in LLaMA-2 experiments, Mistral used as additional baseline for RAW vs HARD evaluation.",
            "performance_result": "Reported GSM8K unit-conversion related results (Table 8): RAW overall 45.10% (w/ unit conv. 47.54%); HARD overall 29.46% (w/ unit conv. 13.79%). These numbers indicate performance drops on HARD augmentation and lower unit-conversion accuracy on HARD.",
            "mechanistic_insight": "No internal mechanistic analysis for Mistral; same high-level interpretation as for LLaMA-2: unit-conversion competency and integration into MWP answers require targeted data/formats and show sensitivity to representation variability.",
            "performance_scaling": "No explicit model-size scaling beyond reporting of Mistral-7B numbers relative to LLaMA-2-7B; observed that RAW-&gt;HARD augmentation reduces accuracy for both models.",
            "failure_modes": "Marked drop in unit-conversion performance on HARD; paper notes GSM8K originally had narrow unit representation leading to overestimation of unit-conversion ability and that diverse unit representations uncover weaknesses.",
            "comparison_baseline": "Compared RAW vs HARD evaluation and contrasted with LLaMA-2 results; used as cross-family baseline in paper.",
            "key_finding": "Model performance on arithmetic and unit-conversion tasks degrades on harder (HARD) augmented testsets that increase significant-digit complexity and diversify unit representations; targeted skill training is required to robustly generalize atomic arithmetic/unit skills into compositional MWPs.",
            "uuid": "e259.1",
            "source_info": {
                "paper_title": "Laying the Foundation First? Investigating the Generalization from Atomic Skills to Complex Reasoning Tasks",
                "publication_date_yy_mm": "2024-03"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Goat: Fine-tuned llama outperforms gpt-4 on arithmetic tasks",
            "rating": 2,
            "sanitized_title": "goat_finetuned_llama_outperforms_gpt4_on_arithmetic_tasks"
        },
        {
            "paper_title": "Investigating the limitations of transformers with simple arithmetic tasks",
            "rating": 2,
            "sanitized_title": "investigating_the_limitations_of_transformers_with_simple_arithmetic_tasks"
        },
        {
            "paper_title": "Evaluating transformer language models on arithmetic operations using number decomposition",
            "rating": 2,
            "sanitized_title": "evaluating_transformer_language_models_on_arithmetic_operations_using_number_decomposition"
        },
        {
            "paper_title": "Chain-of-thought prompting elicits reasoning in large language models",
            "rating": 2,
            "sanitized_title": "chainofthought_prompting_elicits_reasoning_in_large_language_models"
        },
        {
            "paper_title": "Are NLP models really able to solve simple math word problems?",
            "rating": 2,
            "sanitized_title": "are_nlp_models_really_able_to_solve_simple_math_word_problems"
        },
        {
            "paper_title": "Enhancing quantitative reasoning skills of large language models through dimension perception",
            "rating": 2,
            "sanitized_title": "enhancing_quantitative_reasoning_skills_of_large_language_models_through_dimension_perception"
        },
        {
            "paper_title": "Do language models understand measurements?",
            "rating": 1,
            "sanitized_title": "do_language_models_understand_measurements"
        }
    ],
    "cost": 0.012105,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Laying the Foundation First? Investigating the Generalization from Atomic Skills to Complex Reasoning Tasks
14 Mar 2024</p>
<p>Yuncheng Huang yunchenghuang22@m.fudan.edu.cn 
School of Computer Science
Shanghai Key Laboratory of Data Science
Fudan University</p>
<p>Qianyu He ♠Yipei Xu 
School of Computer Science
Shanghai Key Laboratory of Data Science
Fudan University</p>
<p>Jiaqing Liang liangjiaqing@fudan.edu.cn 
School of Computer Science
Shanghai Key Laboratory of Data Science
Fudan University</p>
<p>School of Data Science
Fudan University ♢ Fudan-Aishu Cognitive Intelligence Joint Research Center</p>
<p>Yanghua Xiao 
School of Computer Science
Shanghai Key Laboratory of Data Science
Fudan University</p>
<p>Laying the Foundation First? Investigating the Generalization from Atomic Skills to Complex Reasoning Tasks
14 Mar 2024C65FE541F3478207A50295F45B8F30DCarXiv:2403.09479v1[cs.LG]
Current language models have demonstrated their capability to develop basic reasoning, but struggle in more complicated reasoning tasks that require a combination of atomic skills, such as math word problem requiring skills like arithmetic and unit conversion.Previous methods either do not improve the inherent atomic skills of models or not attempt to generalize the atomic skills to complex reasoning tasks.In this paper, we first propose a probing framework to investigate whether the atomic skill can spontaneously generalize to complex reasoning tasks.Then, we introduce a hierarchical curriculum learning training strategy to achieve better skill generalization.In our experiments, we find that atomic skills can not spontaneously generalize to compositional tasks.By leveraging hierarchical curriculum learning, we successfully induce generalization, significantly improve the performance of open-source LMs on complex reasoning tasks.Promisingly, the skill generalization exhibit effective in crossdataset and cross-domain scenarios.Complex reasoning can also help enhance atomic skills.Our findings offer valuable guidance for designing better training strategies for complex reasoning tasks.</p>
<p>Introduction</p>
<p>Current language models (LMs) have demonstrated their capability in a variety of reasoning tasks (Huang and Chang, 2023;Wei et al., 2022b).However, they struggle in more complex tasks that require the combination of various atomic skills, such as solving math word problem (MWP, Cobbe et al., 2021;Patel et al., 2021) requiring arithmetic (Liu and Low, 2023;Nogueira et al., 2021;Muffo et al., 2022) and unit conversion (Park et al., 2022) skills.Previous study argue that the inferior performance of current LMs in solving complex Can I apply these skills to complex reasoning task?</p>
<p>448 cm is equal to 44.8 decimeter.</p>
<p>Prerequisite Tasks</p>
<p>Training Ideal Response: Since….the total length of the ribbon is: 12 * 37 = 12 * 30 + 12 * 7 = 360 + 84 = 444 cm .Convert cm to decimeter: 444 cm is equal to 44.4 decimeter.So the total length of the ribbon is 44.4 decimeters.❌ ❌ Figure 1: An example of LMs' deficiencies on atomic skills when solving complex reasoning tasks.While these atomic skills can be improved through skill training, it remains uncertain whether language models can apply enhanced skills to complex tasks.</p>
<p>reasoning tasks is primarily attributed to their deficiency in atomic skills.As shown in Fig. 1 (top), despite following a correct reasoning process, the models still yield incorrect solutions due to errors in arithmetic and unit conversion skills.</p>
<p>Recent studies attempt to address this issue through skill enhancement, but there are still limitations.Some approach involves introducing external tools (Imani et al., 2023;Schick et al., 2023), validators (Khalifa et al., 2023) or knowledge bases (Lewis et al., 2020) to assist atomic skills.These methods rely on external support but do not inherently improve the atomic skills of the model itself.Other studies promote the performance through multitask learning (Chen et al., 2023;Kim et al., 2023).They argue that skill improvement can be implicitly achieved through the transfer effect between tasks.However, they neither specify which skills are improved nor quantitatively assess the performance gains from skill improvements.The skill enhancement is implicit and unobservable, and the relationships between tasks are inexplainable.The most related studies individually improve particular skills by integrating specific knowledge (Park et al., 2022) or by fine-tuning with specialized crafted Chain-of-Thought (Liu and Low, 2023).However, these studies tend to train a specialized models that proficient in atomic skills rather than enhance atomic skills while maintaining the original capabilities of the model.Moreover, they do not investigate whether the enhancement of skills can be generalized to complex tasks.</p>
<p>We argue that skill enhancement can generalize to complex tasks, as the response format for complex tasks is a composition of atomic skills.For instance, in Fig. 1, the response to the MWP compose arithmetic and unit conversion skills, which are respectively corresponding to the text segments "12×37=448 cm" and "448 decimeters".The precision of complex reasoning tasks is significantly influenced by the mastery of skills.In this case, if both skills are improved, the response would turn out to be correct.Language models have been proved to individually improve their skills through specialized training (Fig. 1, middle).What we are particularly interested in is whether models can apply the enhanced skills to complex tasks (Fig. 1, bottom), referred to as skill generalization in this paper.It is crucial to highlight that our research objective is fundamentally different from multitasking as we explicitly define skills.Furthermore, due to the composability between skills and complex tasks, this generalization effect should be observable and explainable.</p>
<p>In this work, we investigate the mechanism of skill generalization through empirical experimentation on MWP.We aim to answer two key questions: Can atomic skills spontaneously generalize to complex reasoning tasks?How can we maximize the skill generalization effectiveness?First, we propose a probing framework to investigate the skill generalization mechanism on complex reasoning tasks.We select two essential atomic skills in MWP for probing: arithmetic and unit conversion.Then, we specifically design prerequisite tasks to enhance atomic skills and construct corresponding datasets through automated methods.Moreover, inspired by hierarchical curriculum design in pedagogy (White and Gagné, 1974;Scott, 2008), we propose a two-stage training strategy named hierarchical curriculum learning to maximize skill generalization.The first stage is skill training, which involves continuous learning on prerequisite tasks, enabling LMs to enhance atomic skills while main-taining their original problem-solving abilities.The second stage is applied learning, where language models learn to apply skills to complex reasoning tasks.Finally, we carry out experiments across different models and perform detailed analyses.</p>
<p>In our experiments, we observe that (1) atomic skill can not spontaneously generalize to complex reasoning tasks, but can be induced to generalize through hierarchical curriculum learning.(2) A strong foundation laid in skill learning is crucial for effectiveness of LMs on complex reasoning tasks.</p>
<p>(3) Skill enhancement exhibits a cross-dataset and cross-domain generalization effect.(4) Conversely, complex reasoning task can also help enhance the atomic skills.We attribute this to the composability between skills and complex tasks.</p>
<p>Our contributions can be summarized as follows:</p>
<p>• To our best knowledge, we are the first to investigate the generalization from atomic skills to complex reasoning tasks.</p>
<p>• We propose a probing framework to investigate the spontaneity and effectiveness of skill generalization.</p>
<p>• We propose a hierarchical curriculum learning training strategy to induce skill generalization.</p>
<p>Our experiments demonstrate the effectiveness of this strategy in achieving better skill generalization.</p>
<p>Related Work</p>
<p>Task Generalization Cross-task generalization refers to effectively apply previously learned knowledge and skills from source task to new target tasks (Talmor and Berant, 2019;Khashabi et al., 2020;Ye et al., 2021).Recent studies attain significant success in cross-task generalization by employing a multi-tasking approach (Sanh et al., 2022;Wei et al., 2022a;Kim et al., 2023).Chen et al.</p>
<p>(2023) argues that the effectiveness of generalization stems from the implicit skill transfer between tasks and seeks to find an optimal sequence to maximize the effect.Our research differs from the aforementioned studies in that we explicitly predefine source and target tasks that possess composability in format.Moreover, our research does not depend on massive tasks but emphasizes generalization from atomic skills to complex reasoning tasks.</p>
<p>Compositional Generalization</p>
<p>Compositional generalization research primarily focus in semantic parsing (Lake and Baroni, 2018;Keysers et al., 2020;Kim and Linzen, 2020).They explore generalizing simple data to complex data through composition within an inter-dataset distribution.In contrast, our study explores cross-dataset generalization, especially skill generalization in complex reasoning tasks.</p>
<p>Atomic Skill Learning Numerous studies focus on individually enhancing specific skills.Liu and Low (2023) enhance arithmetic skill of LMs by specialized designed COT prompting.Huang et al. (2023) improve unit conversion skills through dimensional perception pretraining tasks.However, these studies do not investigate generalizing the enhanced skills to complex reasoning tasks.</p>
<p>Curriculum Learning Curriculum learning suggests that a structured and progressively challenging learning path can improve the learning effectiveness (Bengio et al., 2009;Wu et al., 2021).Previous work focus on ordinal training on a single task based on the difficulty of the data (Jiang et al., 2015;Xu et al., 2020;Elgaar and Amiri, 2023).</p>
<p>Our research advances the field by applying hierarchical curriculum learning to multitasks guided by composability among these tasks and investigates their generalization effects.</p>
<p>Method</p>
<p>In this section, we first propose a probing framework to investigate generalization from atomic skills to complex reasoning tasks ( § 3.1).Then, we propose a hierarchical curriculum learning strategy to maximize the generalization effect ( § 3.2).The framework is shown in Fig. 2.</p>
<p>Skill Generalization Probing</p>
<p>Task Selection</p>
<p>We chose math word problem (MWP, Cobbe et al., 2021;Patel et al., 2021) as the investigated task, as it is a common-used benchmark for complex reasoning and the correctness can be objectively assessed.We select arithmetic and unit conversion as atomic skills because LMs display weaknesses in these skills when addressing MWP (Imani et al., 2023;Schick et al., 2023;Huang et al., 2023).To obtain a model proficient in skills, we need to design prerequisite tasks and conduct skill training first ( § 3.1.2).After that, we can investigate the skill generalization on the enhanced model ( § 3.1.4)3.1.2Probing Skills Arithmetic Skill.Arithmetic skill refer to perform operations among numbers such as addition, subtract, multiplication and division.Most current LMs suffer from inaccurate arithmetic due to lacking specialized skill-oriented training (Liu and Low, 2023).We design a prerequisite task for arithmetic and construct the corresponding dataset.By training on prerequisite tasks, we can enhance the arithmetic skills.The arithmetic data encompasses a variety of difficulties, including different operation hops, operation types, value types and significant digits.For simple operations, we require the model to directly provide the arithmetic result.For complex operations, we design Chain-of-Thought responses, following Liu and Low (2023), due to the challenges in directly deriving the answers for these tasks.As shown in the example in Tab. 1, when answering "12 * 43.5", we require the model to present the process of splitting, expansion, producting, and adding term by term before providing the final answer.</p>
<p>Unit Conversion Skill.Similar to arithmetic, unit conversion is necessary when dealing with values of different units in MWP.Current LMs lack sufficient knowledge of units, making it difficult to accurately perform unit conversions (Huang et al., 2023).Therefore, we also propose a prerequisite task and corresponding training data for unit conversion.We first extract all quantity types in MWP based on a comprehensive unit knowledge base DimUnitKB (Huang et al., 2023).As shown in Tab. 1, the units involved in MWP include seven quantity types such as length, time, speed, etc.Then we construct the unit conversion dataset for unit pair under the same quantity type.For example, "meters" and "centimeters" are both denote length, so it can be naturally stated as "1 meter is Table 1: Examples for prerequisite tasks and complex reasoning tasks.The response for compositional tasks presents arithmetic and unit conversion skill and they are highlighted in orange and green respectively.S-refers to simple operation where the significant digit of the second number is 1.C-refers to complex operation.</p>
<p>equal to 100 centimeters".We detail the constrution method in Appendix A.2.</p>
<p>Skill Training (ST)</p>
<p>Since the data for arithmetic and unit conversion are both automatically constructed, we can generate them in large quantities.It is straight-forward to enhance the atomic skills into language models through continuous training.However, continuous training may lead to catastrophic forgetting (Mc-Closkey and Cohen, 1989).To address this, we employ the replay strategy (Ke and Liu, 2022) that is widely used in continuous training.We retain some training examples from MWP and mix them 1 with prerequisite task data to ensure the model retains its original problem-solving abilities in skill training.We conduct individual training for each skills as well as training with a mixture of skills.</p>
<p>How to determine whether skill generalization has been achieved?</p>
<p>Skill generalization refers to being able to apply skills learned from prerequisite tasks to complex reasoning tasks.Therefore, we can assess this by testing the skill-enhanced model in § 3.1.2on MWP.We can consider the following aspects.</p>
<p>Metrics Improvement: Skills improvement can fix mistakes caused by the deficiency of atomic skills of language models when solving reasoning tasks.Therefore, ideally, skill generalization should be reflected in an improvement in metrics.</p>
<p>Response Integration: As seen in Tab. 1, the for- 1 We discuss the mixing ratio in Appendix C.1.</p>
<p>mat we use for atomic skills in prerequisite tasks differs from how the original model performs these skills.Therefore, we can assess by determining whether there has been an implementation of response integration.For example, successful skill generalization should involve performing C-Mul in a Chain of Thought (COT) format rather than providing the answer directly.</p>
<p>Hierarchical Curriculum Learning (HCL)</p>
<p>Probing experiments show that atomic skills can not spontaneously generalize to complex tasks (results are detailed in § 5.1).Therefore, we propose hierarchical curriculum learning (HCL) to induce skill generalization.</p>
<p>Our approach is primarily inspired by hierarchical curriculum design in pedagogy (White and Gagné, 1974;Scott, 2008).In most of education system, student complete prerequisite course before enrolling in a more advanced course (Huang et al., 2005).Prerequisites are to ensure that students possess necessary foundational knowledge and skills and advanced courses enable students to learn how to apply these skills in complex scenarios (Rovick et al., 1999).Likewise, we design a two-stage hierarchical curriculum learning framework in our setting, shown in Fig. 2 left.The first stage is skill training, which has already been implemented ( § 3.1.3).We introduce the second phase of applied learning to enable LMs to apply their acquired skills to complex tasks.</p>
<p>Applied Learning (AL)</p>
<p>In this stage, we first construct compositional data (shown in Tab. 1 bottom) for applied learning.Next, we further train the model in the first stage with compositional data.In Tab. 1, the response of the original MWP directly provides the result when performing arithmetic.Moreover, the responses usually do not show the process of converting units.We incorporates the response format from prerequisite tasks into the problem-solving process for MWPs, aiming to induce the model to apply atomic skills to complex tasks.We detail the data construction method in Appendix A.3.</p>
<p>Experimental Settings</p>
<p>4.1 Evaluation Datasets.</p>
<p>We choose GSM8K (Cobbe et al., 2021), a widely used benchmark for complex multi-step reasoning, requiring arithmetic and unit conversion skills.We compile statistics of arithmetic and unit conversion in the test set and observe that it lacks comprehensiveness in terms of difficulty and knowledge coverage.Therefore, we enhance the difficulty of GSM8K test set to demonstrate skill generalization more significantly.We denote the origin dataset as RAW and the augmented dataset as HARD.</p>
<p>Arithmetic Augmentation.The difficulty of arithmetic skills can be assessed from four dimensions: operation hops, operation type, value type, and significant digit.RAW has reasonable settings in the first three dimensions, but its inclusion of short significant digit resulting in lower demands on arithmetic skills.Therefore, we extend the significant digits in RAW without changing the logic of the original problems.In Tab. 2 we showcase the performance of LLaMA-2 ( difficulty gradient, demonstrating the effectiveness of the enhanced dataset.</p>
<p>Unit Conversion Augmentation.The main challenge in unit conversion lies in the diverse ways units are represented.Statistical analysis of the data in GSM8K shown in Appendix B shows that the representation of these units in GSM8K is quite uniform, leading to an incomplete evaluation of unit conversion skills.Without altering the original meaning of the questions, we have diversified the representations of units within the same quantity type.Tab. 8 demonstrates that the enhanced data better tests unit conversion skills.</p>
<p>Models and Baselines.</p>
<p>We investigate the skill generalization on two models from different families, namely LLaMa-2 (7B;   skill does not generalize from metrics perspective.Moreover, as shown in Tab. 4, ST model employs a format entirely distinct from that of the prerequisite task.This clearly indicates that atomic skills actually do not generalize from prerequisite tasks to complex tasks at all.</p>
<p>Atomic skills can be induced to generalize through applied learning.HCL introduce the second phase of applied learning to induce skill generalization in hierarchical curriculum learning.As seen in Tab. 3, LLaMA-2 significantly improve from 13.60% to 28.76% with zero-shot prompting in HARD, demonstrating the successful generalization of skills.Case studies from Tab. 4 further show that models after applied learning (AL and HCL) are capable of integrating data from prerequisites into their responses to MWP, thus performing accurate calculations.Therefore, although skills do not spontaneously generalize from prerequisite tasks to compositional tasks, they can be induced through applied learning.Furthermore, we emphasize that this induced generalization needs to be achieved through training and cannot be replaced by few-shot prompting, as the metrics for few-shot learning do not surpass those for zero-shot learning.</p>
<p>The enhancement of compositional tasks stem from the improvement of atomic skills.We extract the atomic skill part from the responses on MWP and calculate their accuracy, shown in Fig. 4. Hierarchical curriculum learning results in significant improvements in arithmetic accuracy for all types of operations.The improvements are particularly striking for MixMul and MixAll, suggesting that current LMs are struggling to perform these arithmetic operations.These improvement is consistent with the gain in answer accuracy for compositional tasks, as detailed in Appendix D.1.</p>
<p>Furthermore, we conduct an error analysis of the responses, as seen in Fig. 5.We first determine if a response involves an atomic skill error, and subsequently categorize other mistakes.The majority of errors made by vanilla model stem from deficiencies in atomic skills.After applying HCL, a few of errors shift to be question misunderstood and reasoning errors, while most errors are fully corrected to the right answers.This demonstrates that the lack of atomic skills in a model masks its superior reasoning capabilities, and HCL can effectively address this.</p>
<p>Mixture training is also effective for skill generalization.As seen in the third column of Tab. 3,  Skill learning is indispensable in HCL.In Tab. 3, the performance of applied learning alone significantly lower than the full HCL.Fig. 6 left shows the accuracy of the applied learning and HCL with training increase and demonstrates that HCL reaches a better upper bound.We argue that this is because applied learning only teaches the formal application of the skills without imparting the associated knowledge.Furthermore, we observe that applied learning requires much less data compared to skill training.In Fig. 6 right, applied learning converge before 200K tokens, whereas skill training necessitates over 600K tokens.This suggests that enhancing skills is more difficult than learning how to apply them.It underscores the educational principle that mastering prerequisite tasks is essential for solid- ifying atomic skills, while swift applied learning afterwards boosts the model's practical application capabilities.In practical applications, it is often more challenging to obtain a large scale of heterogeneous compositional data than to acquire prerequisite data.The demand for data aligns with the challenges of data collection, which further demonstrates the feasibility of our approach.</p>
<p>RQ2: Do atomic skills exhibits cross dataset or cross domain generalization?</p>
<p>Given that the data in applied learning is sourced from GSM8k, we aim to ascertain whether skill generalization is also effective in out-ofdistribution (OOD) data.We categorize the OOD data into two types: inter-domain and cross-domain.</p>
<p>For inter-domain data, we use SVAMP (Patel et al., 2021) and MathQA (Amini et al., 2019), both of which comprise math word problems as well.</p>
<p>As for cross-domain data, we use the MMLU-Physics (Hendrycks et al., 2021), as it is a physical task but also relies on arithmetic skill.</p>
<p>Skill generalization is effective in inter-domain data.As seen in Tab. 5, with applied learning, models generates responses using step-wise format, unlike the original model which answered directly.This demonstrates models can effectively utilize the skills even if the questions originating from a cross-dataset distribution.</p>
<p>Atomic skills can generalize across domains and show selective adaptability.In Tab. 5, the model perform arithmetic among physical quantities in the same format as in prerequisite tasks, indicating that skill generalization still exhibits effectiveness in cross-domain scenarios.LMs also exhibit selective adaptability when processing unseen data.</p>
<p>For instance, when dealing with the exponential value "10 −6 " that is unseen in prerequisite tasks, LMs opt to answer in its original format.Our findings reveal that while we need to introduce some   compositional data during applied learning to induce skill generalization, it is not necessary to provide for every tasks.However, it is crucial to have well-designed prerequisite data that can be applied across a broad spectrum of scenarios.</p>
<p>RQ3: Can complex tasks help enhance atomic skills conversely?</p>
<p>Considering that applied learning data itself combines multiple atomic skills, it suggests that compositional data may also have a positive effect on atomic skills.We construct test dataset to assess the arithmetic skill, and then evaluate on the models with different training strategies.</p>
<p>Training with compositional data benefits the atomic skills, but the effect is limited.As shown in Tab.6, applied learning achieve better performance in all operations compared to SFT, showing that compositional task have a positive effect on prerequisite data conversely.This lead to a promising conclusion that training on complex reasoning dataset not only improve the performance of the specific task but also benefits its prerequisite tasks, as long as they exhibit composability in response.We further discuss the improvement in  Continued training on compositional tasks does not lead to catastrophic forgetting on atomic skills.Models with skill learning already possess proficient atomic skills but there is a risk that training on heterogeneous data in applied learning may lead to catastrophic forgetting.However, as seen in Tab.6, it striking is that HCL remains at a comparable level to skill training for most arithmetic operation.This illustrates that continuous training on a compositional tasks, can spontaneously prevent catastrophic forgetting of atomic skills.We suggest this due to the limited operations on compositional data in S-Mul, which may lead the model to be confused by other data within C-Mul.However, an anomaly is observed in S-Mul operation, which we further discuss in Appendix D.3.</p>
<p>Conclusion</p>
<p>In this work, we are the first to investigate the generalization from atomic tasks to complex reasoning tasks.We propose a probing framework, in which we select math word problems as research example and arithmetic and unit conversion as related atomic skills.By empirical experiments, we reveal that atomic skills can not spontaneously generalize to complex reasoning tasks.Furthermore, we propose a hierarchical curriculum learning strategy to induce skill generalization and show effectiveness.Our experimental findings provide valuable guidance for designing better training strategies for complex reasoning tasks in future work.</p>
<p>Limitations</p>
<p>In this work, we choose math word problems as the research task , yet there are numerous more complicated reasoning tasks that rely on atomic skills, such as task planning, scenario modelling, decision making, and so on.Although we do not delve deeply into more complicated and pluralistic reasoning tasks, these areas emerge a particularly interesting direction for future research.Another limitation is that our proposed skill generalization depends on atomic skills that can be explicitly demonstrated in the response.It remains uncertain whether implicit atomic skills can also have a positive effect on complex reasoning tasks.Moreover, the definition of atomic skills and the method for prerequisite data generation are based on manual specification.It is worth exploring automated methodologies to design a complete framework for hierarchical curriculum learning in future work.</p>
<p>Ethical Considerations</p>
<p>All the data sources and language models used in this paper is available.In this paper, most of the data generation and evaluation are automated, except for the error analysis in § 5.1 where human evaluation is used.The details about human evaluation are provided in Appendix C.2.We protect the privacy rights of annotators.All annotators have been paid above the local minimum wage and consented to use the evaluation dataset for research purposes covered in our paper.Our work does not raise any ethical considerations regarding potential risks and does not involve the research of human subjects.</p>
<p>A Detail for Training Data</p>
<p>A.1 Arithmetic Prerequisite Task</p>
<p>We construct data for arithmetic prerequisite task by a rule-based approach, seen in Algorithm 1.The difficulty of the data considers four aspects: the number of hops, the length of a significant digit, the type of value and the type of operation.The number of hops ranges from two to five, the more hops means the harder it is.The significant digit length ranges from one to eight.Longer length means the more complex and difficult for calculations.Value types include: all integers, all floating, and mixed data types, with increasing difficulty.Operation types include AddSub, W-Mul, C-Mul and S-Div.Among them, AddSub consists of only addition and subtraction, S-Mul involves simple multiplication operations (the second value with a significant figure of 1), C-Mul encompasses complex multiplication operations where we break down the second number and perform step-wise calculations, and S-Div represents simple division.</p>
<p>Algorithm 1: Arithmetic Data Generation In Algorithm 1, reponse demonstrates a stepwise arithmetic process based on hop.For C-Mul operation, the second value is split and then perform bit-wise multiplication and results addition.SplitCOT, MulCOT and AddCOT represent the process of digits splitting, bit-wise multiplication and results addition respectively.
Data: Operation set O, Significant Digit set D, Value type set V , Hop set H Result: Arithmetic Expression E, Response R // Initialization 1 h ← Random(H); o ← Random(O); 2 d ← Random(D); v ← Random(V ); 3 num0 ← NumberGenerator(d, v); E ← num0; // Expression generation 4 for i ← 1 to h do 5 op ← OperationGenerator(o); 6 ni+1 ← NumberGenerator(d, v, op); 7 E ← E • op • ni+1; 8 end 9 R ← ResponseGeneration (E); 10 return E, R;</p>
<p>A.2 Unit Conversion Prerequisite Task</p>
<p>We construct data for unit conversion prerequisite task based on DimUnitKB (Huang et al., 2023).We first extract the quantity types of units contained in the MWP, including seven type in total: length, time, speed, mass, volume, area and power.We construct pair-wise conversion data for units representing the same quantity types, detailed in Algorithm 2.</p>
<p>Algorithm 2: UnitConv.Data Generation Data: Quantity Type Set Q, DimUnitKB K Result: Unit Conversion Text Data T // Select random quantity type and units
1 q ← Random(S); 2 Uq ← {u ∈ K | u.type = q}; 3 u0, u1 ← Random(Uq, 2); // Calculate conversion ratio 4 conv ← u0.conv/u1.conv;
// Generate conversion text 5 T ← TextGeneration(u0, u1, conv); 6 return T ;</p>
<p>A.3 Compositional Data</p>
<p>In applied learning, we need to construct data that integrates atomic skills into compositional tasks.The construction of compositional data consists of the following steps:</p>
<ol>
<li>
<p>Sample data items from the train set of complex reasoning tasks.</p>
</li>
<li>
<p>Extract all segments related to atomic skills from the response of the item.</p>
</li>
</ol>
<p>Use the ResponseGeneration function and</p>
<p>TextGeneration function in Algorithm 1 and Algorithm 2 to generate the new format of response for atomic skill.</p>
<ol>
<li>Replace all segments related to atomic skills with the new answer response to construct compositional data.</li>
</ol>
<p>For example, in arithmetic, we extract the arithmetic segments "12 * 37 = 448" from the response "the total length of the ribbon is: 12 * 37 = 448 cm" and then replace it with "12 * 37 = 12 * (30 + 7) B Detail for Evaluation Data B.1 Deficiency of GSM8K in Skill Assessment GSM8K (Cobbe et al., 2021) is the current widely used evaluation benchmark for math word problem.However, it does not comprehensively cover the application of atomic skills across various difficulty levels.We analyze the difficulty coverage of GSM8k on arithmetic, taking into account four aspects mentioned in Section A.1, as depicted in Fig. 3 (left).Darker colours indicate more difficult, and a greater area signifies a larger volume of data.It shows that the GSM8k test set comprehensively covers various operation hops, operation types, and value types.However, the significant digits involved are primarily focused on simple data.GSM8k dataset also lacks comprehensiveness on unit conversion skills.The statistic is shown in Tab. 7. It covers only a few unit expressions in various types.</p>
<p>B.2 Method for Data Augmenting</p>
<p>As for arithmetic, we augment the evaluation data through increasing the significant digit lengths without changing the logic of the original problems and denote as HARD set.The algorithm is outlined in Algorithm 3. Initially, we extract the numbers in the question, along with the intermediate numbers in the answer, and the computation relationships between them.Subsequently, we randomly get new numbers based on the maximum significant value length, and compute new intermediate numbers accordingly.These updated numbers are then integrated into the original question and answer, resulting in an enhanced question-answer pairs.As shown in Fig. 3 (right), the HARD set covers a broader range of significant digits.The new data distribution is reasonable with the proportion decreasing appropriately as the difficulty increases.</p>
<p>As for unit conversion, we augment the test data by including a wider variety of unit representations.The algorithm is outlined in Algorithm 3. We evaluate LLAMA-2 on both RAW and HARD.As shown in Table 8, the results suggest that the HARD set provides greater differentiation.</p>
<p>C Experimental Details</p>
<p>The implementations of all the LMs in our paper are based on the HuggingFace Transformers 2 and Deepspeed 3 .We set the learning rate in 1e-5, 1e-6 with a WarmupLR scheduler, batch size of 32, max sequence length of 1024 and train for 8 epochs.All of our experiments are conducted on the worksta-tions of NVIDIA A800 PCIe with 80GB memory and the environment of Ubuntu 20.04.6 LTS and torch 2.0.1.In the evaluation, we employ vllm4 for inference.All the result are generate with a greedy decoding strategy.</p>
<p>We do not utilize additional prompts for prerequisite data but employ the prompt from Alpaca (Taori et al., 2023) for training and testing on MWP.</p>
<p>C.1 The Ratio Selection for Replay Strategy</p>
<p>We retain some training examples from MWP and mix them with prerequisite task data to ensure the model retains its original problem-solving abilities in skill training.Fig. 7 shows the performance of the model at different mixing ratios on prerequisite tasks (atomic skills) and complex reasoning tasks.Overall, as the proportion of prerequisite data increases, the model become better in atomic skills and worse in solving MWP.The balanced mixing ratios vary for different skills.Arithmetic requires more prerequisite data than unit conversion.Ultimately, we chose to set the mixing ratio for arithmetic to 10 and for unit conversion to 1 in skill training, to achieve a relatively effective continual learning.</p>
<p>C.2 Human Evaluation for Error Analysis</p>
<p>We recruite human evaluators to do error analysis on math word problem.All evaluators possess sufficient knowledge of mathematics and are provided with the necessary background for the evaluation criteria.Each item is annotated by at least three evaluators and inconsistencies will lead to a reassessment.</p>
<p>The evaluation of the response is divided into four types: 1.Atomic skill error: an error occurs within the atomic skill segment, e.g., an error in performing complex multiplication; 2.Question Misunderstood: the wrong value is used due to a misunderstanding of the question; and 3.Reason error: incorrect representation due to an error in the reasoning process.4.Correct: indicating that both the reasoning process and the answer are completely correct; The priority of these four types of classifications decreases in order.</p>
<p>D Additional Results</p>
<p>D.1 The correlation of atomic skills Fig. 8 illustrates the correlation between the accuracy gains in prerequisite tasks and compositional tasks.A higher performance on prerequisite tasks indicates a stronger atomic skill of the model, revealing a positive correlation between the model's atomic skills and its capability to solve compositional tasks.This supports our conclusion that the gains brought by our method are attributable to the enhancement of atomic skills.</p>
<p>D.2 Compositional task is not enough to enhanced atomic skills</p>
<p>We mention in Section 5.3 that the compositional task improves atomic skills, but the effect is limited.It can be seen from Tab. 9 that although the AL method learn the COT form to answer, it has not acquired complete knowledge, hence it cannot result in a completely correct answer.</p>
<p>D.3 Abnormal Results in S-Mul</p>
<p>We mention in Section 5.3 that HCL exhibit abnormal decline in S-Mul compared to ST.We observe that most of the error comes from the incorrect of magnitude.For example, HCL model reponse in "0.00261" when calculating "2.61 * 0.01" while the correct answer is "0.0261".We argue that this is primarily because the special operation S-Mul rarely occurs in compositional data, as we sample all values uniformly.Whereas in the skill learning phase, we construct a large amount of training data for the S-Mul operation.It indicates that the property of avoiding catastrophic forgetting mentioned in Section 5.3 is conditional.The distribution of atomic skills in compositional data being the same as in the prerequisite task.The distribution of atomic skills within composite data needs to be consistent with the distribution in the prerequisite task, otherwise the phenomenon of catastrophic forgetting may still occur.</p>
<p>D.4 Additional Examples on MWP</p>
<p>We supplement § 5.</p>
<p>✓ ✓</p>
<p>Question</p>
<p>A raspberry bush has 911 clusters of 637 fruit each and 797 individual fruit scattered across the bush.How many raspberries are there total?ST There are 911 clusters of raspberries, each with 637 fruit, so there are 911 * 637 = 545702 raspberries in the clusters.There are also 797 individual raspberries, so there are a total of 545702 + 797 = 553699 raspberries on the bush.</p>
<p>Your reasoning process is correct, but fail in arithmetic and unit conversion.You should enhance your atomic skills first!Now I have got the hang of the atomic skills !</p>
<p>Figure 2 :
2
Figure 2: Framework of our method.The right part is our probing approach.The left part describes the model training stages in hierarchical curriculum learning.</p>
<p>Figure 3 :
3
Figure 3: The distribution of data difficulty across four dimensions.Darker colors mean greater difficulty and larger areas mean more data.</p>
<p>The salesman sold 31 shoes for 31 * $25 = 775 .Thus, the salesman made a profit of 775 -340 = 435 .So the answer... ✗ AL The salesman sold 31 sneakers for 31 * $25 = 31 * 25 = 31 * 20 + 31 * 5 = 620 + 155 = 775 throughout the rest of the... ✓ HCL The salesman sold 31 shoes for $25 each, so his profit was 31 * $25 = 31 * 25 = 31 * 20 + 31 * 5 = 620 + 155 = 775 .In total ... ✓ Table 4: Example of LM's response to MWP with different training strategies.The last column indicates whether the prerequisite task format has been integrated.</p>
<p>Figure 4 :
4
Figure 4: Accuracy(%) of atomic skill on MWP of LLaMa-2.Left figure shows the results on RAW and right figure shows the results on HARD.</p>
<p>Figure 6 :
6
Figure 6: Accuracy(%) of LLaMa-2 as training increases in different setting.</p>
<p>MathQASFT:</p>
<p>If selling an article for Rs.1620 gives a 25% profit, then the percentage profit earned is 25/100<em>1620 = 405 .HCL: When the article is sold for Rs.1620, the seller makes a profit of 25/100</em>1620 = 25 / 100 * 1620 = 0.25 * 1620 = 0.25 * 1000 + 0.25 <em>600 + 0.25 * 20 + 0.25 * 0 = 250 + 150 + 5 + 0 = 400 + 5 + 0 = 405 + 0 = 405.When the article is sold for Rs.1280, the ... SFT: The stone's speed in the air is 24 m/s * 9.8 m/s ^2 = 24 * 9.8 = 22.8 = 22.8 m/s.The ... HCL: The horizontal component of the stone's speed is 24 m/s * 9.81 m/s^2 = 24 * 9.81 = 24 * 9 + 24 * 0.8 + 24 * 0.01 = 216 + 19.2 + 0.24 = 235.2+ 0.24 = 235.44= 235.44m/s.The ... MMLU -Physics HCL: ... Thus, R = PV/nT = (1.105</em> 20 * 10-6) / (0.0451 * 273) = 8.314 J/mol*K.Since ...</p>
<p>/</p>
<p>/ Iterative response generation 11 Function ResponseGeneration(exp): 12 i ← idx if exists op idx in M ulDiv else 0; 13 Ep ← (n0, op0, . . ., opi−1, ni); 14 Es ← (opi+1, . . ., nn); 15 SR ← OneHopResponse(ni, opi, ni+1); 16 nnew ← eval(ni, opi, ni+1); 17 M R ← MergeResponse(Ep, SR, Es); 18 E ← Ep • nnew • Es; 19 return MR + ResponseGeneration (E); // One Hop COT response generation 20 Function OneHopResponse(n0, op, n1): 21 if op = "C-MUL" then 22 w0, w1, ..., wm ← SplitDigits(n1); 23 SR ← SplitCOT(n0, w0, w1, ..., wm); 24 SR += MulCOT(n0, w0, w1, ..., wm); 25 SR += AddCOT(n0 * w0, ..., n0 * wm); 26 else 27 SR ← Eval(n0, op, n1);</p>
<p>Figure 7 :
7
Figure 7: Accuracy of LMs on prerequisite tasks and complex reasoning tasks with different mixing ratio.</p>
<p>Figure 8 :
8
Figure 8: Accuracy gain (%) on prerequisite tasks and composisiton tasks.</p>
<p>clusters of raspberries on the bush, so there are 911 * 637 = 911 * 600 + 911 * 30 + 911 * 7 = 546600 + 27330 + 6377 = 573930 + 6377 = 580307 raspberries in the clusters.There are also 797 individual raspberries scattered across the bush, so there are a total of 580307 + 797 = 581104 raspberries.✓ ✓ HCL First find the total number of fruit in the clusters: 911 clusters * 637 fruit/cluster = 911 * 600 + 911 * 30 + 911 * 7 = 546600 + 27330 + 6377 = 573930 + 6377 = 580307 fruit.Then add the number of individual fruit to find the total number of fruit: 580307 fruit + 797 fruit = 581104 fruit.✓ ✓ Question A glass of milk is 668 ounces of milk.John drinks 671 glasses of milk.If milk has 949 calories per ounce how many calories did he consume?ST He drank 671<em>668= 405508 ounces of milk.That means he consumed 405508</em>949=36545720 calories.</p>
<p>Criteria 1: Metrics Improvement Stage 1: Skill Training Probing on Skill Generalization Hierarchical Curriculum Learning (HCL) Compositional Data Criteria 2: Response Integration Stage 2: Applied Learning Spontaneously Skill Generalization? Prerequisite Data Better Skill Generalization?</p>
<p>Table 2 :
2DatasetOperartion AddSub Mixmul MixAllGSM8KRAW2-Hop 3-Hop43.10 22.7244.24 35.0034.88 14.32GSM8KHARD2-Hop 3-Hop31.90 21.5015.20 8.045.30 2.63
Touvron et al., 2023)on the test set before and after enhancement.The difficulty of these three operations increases progressively, but testing on RAW can not distinguish the difficulty.The enhanced test set aligns with this Arithmetic accuracy(%) of LLaMA-2 on RAW and HARD.AddSub involves only addition and subtraction operations, MixMul includes multiplication, and MixAll involves all operations.</p>
<p>Table 3 :
3
Accuracy(%) of different LMs with different training strategies on MWP.ST, AL, HCL refer to skill training, applied learning and hierarchical curriculum learning respectively.RAW refers to testing on the origin GSM8k test set, HARD refers to testing on the augmented test set on specific atomic skill.In Mixture column, ARITH and UNIT refer to testing on the augmented test set on arithmetic and unit conversion skills respectively.</p>
<p>Table 5 :
5
Example of response in cross-dataset and crossdomain senarios.</p>
<p>Table 6 :
6
Accuracy(%) in prerequisite tasks of LMs with and without skill training.
Appendix D.2. Moreover, the gains brought bycompositional tasks are minimal. Applied learningonly results in an increase from 22.91% to 40.72%on C-Mul while skill training leads to a skyrock-eting increase to 93.45%. We attribute this to thelimited heterogeneous data for applied learning.The prerequisite tasks can automatically generate alarge amount of heterogeneous data, but the compo-sitional data is limited by the training set of the orig-inal training set for complex reasoning task. There-fore, applied learning alone can not sufficientlyenhance atomic skills, further highlighting the im-portance of a skill training stage in hierarchicalcurriculum learning.</p>
<p>Table 8 :
8
Performance of LLaMa-2 on RAW and HARD dataset in unit conversion skill.
ModelGSM8kRAWGSM8kHARDoverall w/ unit conv. overall w/ unit conv.LLaMa-2-7B 27.1621.3114.441.72Mistral-7B 45.1047.5429.4613.79Algorithm 4: Augmenting MWP on UnitConversion.Input: Original math problem (QRAW , ARAW ),DimUnitKB KOutput: Augmented problem (QHARD, AHARD)1 u0 ← ExtractTargetUnit(QRAW , K);2 q ← GetQuantityKind(u0, K);// Randomly select a new unit with the same quantity type3 U1 ← RandomSelect({u ∈ K | u.type = q});4 conv ← u0.conv/u1.conv;5 (QHARD, AHARD) ←Substitude(QRAW , ARAW , u0, u1, conv);6 return QHARD, AHARD;</p>
<p>Table 9 :
9
1 with more complete examples, as shown in Tab.10.Example of the response in prerequisite task of different training strategies.COT indicates whether the model answer with a COT format and CORRECT indicates whether the final answer is correct.We mark the areas that led to errors in red.$631 per hour to teach and $30 to be a cheerleading coach.If she works 38 weeks a year, 32 hours a week as a teacher and 15 hours a week as a coach, what's her annual salary?ST Jill works 38 weeks a year * 32 hours a week = 1304 hours a year as a teacher.She earns 1304 hours a year * $631 a hour = $800800 a year as a teacher.As a coach, Jill works 15 hours a week * 38 weeks a year = 570 hours a year.She earns 570 hours a year * $30 a hour = $17100 a year as a coach.Therefore, Jill's annual salary is $17100 + $800800 = $802900.Jill works 38<em>32 = 38 * 30 + 38 * 2 = 1140 + 76 = 1216 weeks.She earns 1216</em>$631 = 1216 * 600 + 1216 * 30 + 1216 * 1 = 731600 + 36480 + 1216 = 768080 + 1216 = 769296.As a coach, Jill works 38<em>15 = 38 * 10 + 38 * 5 = 380 + 190 = 570 weeks.She earns 570</em>$30 = 570 * 30 + 570 * 0 = 17100 + 0 = 17100.Annually, she earns $769296+$17100 = $786396 ✗ ✗ HCL Jill earns 38 weeks * 32 hours/week = 38 * 30 + 38 * 2 = 1140 + 76 = 1216 hours a year as a teacher.She earns 1216 hours/year * $631/hour = 1216 * 600 + 1216 * 30 + 1216 * 1 = 729600 + 36480 + 1216 = 766080 + 1216 = 767296 a year as a teacher.She earns 15 hours/week * $30/hour = 15 * 30 = 15 * 30 + 15 * 0 = 450 + 0 = 450 a week as a coach.In a year, she earns $450/week * 38 weeks/year = 450 * 38 = 450 * 30 + 450 * 8 = 13500 + 3600 = 17100 as a coach.Her total salary is $767296 + $17100 = 784396.</p>
<h1>MethodResponseCOT CORRECTAL495.3 + 996.8 = 1491.1-✗1HCL 495.3 + 996.8 = 1492.1-✓AL6.8 0.1 = 68.33-✗2HCL 68 0.1 = 68-✓AL18.4 * 9.945 = 18.4 * 9 + 18.4 * 0.9 + 18.4 * 0.04 + 18.4 * 0.005 = 166.6 + 16.66 + 0.736 + 0.092 = 183.26 + 0.736 + 0.092 = 183.996 + 0.092 = 184.088✓✗3HCL 18.4 * 9.945 = 18.4 * 9 + 18.4 * 0.9 + 18.4 * 0.04 + 18.4 * 0.005 = 165.6 + 16.56 + 0.736 + 0.092 = 182.16 + 0.736 + 0.092 = 182.896 + 0.092 = 182.988✓✓AL69.4 * 81.8 = 69.4 * 80 + 69.4 * 1 + 69.4 * 0.8 = 5552 + 6.94 + 55.52 = 5618.94 + 55.52 = 5674.462✓✗4HCL 69.4 * 81.8 = 69.4 * 80 + 69.4 * 1 + 69.4 * 0.8 = 5552 + 69.4 + 55.52 = 5621.4 + 55.52 = 5676.92✓✓AL2.94 * 8.21 = 2.94 * 8 + 2.94 * 0.2 + 2.94 * 0.01 = 23.48 + 0.588 + 0.0294 = 24.068 + 0.0294 = 24.0974✓✗5HCL 2.94 * 8.21 = 2.94 * 8 + 2.94 * 0.2 + 2.94 * 0.01 = 23.52 + 0.588 + 0.0294 = 24.108 + 0.0294 = 24.1374✓✓AL539.25 -418.4 = 120.8-✗6HCL 539.25 -418.4 = 120.85-✓</h1>
<p>Table 10 :
10
Example of the response in complex reasoning task of different training strategies.SKILL indicates whether the model fail in atomic skills (arithmetic).CORRECT indicates whether the final answer is correct.We mark the areas that led to errors in red.</p>
<p>https://github.com/huggingface/transformers/
https://github.com/microsoft/DeepSpeed
https://github.com/vllm-project/vllm</p>
<p>MathQA: Towards interpretable math word problem solving with operation-based formalisms. Aida Amini, Saadia Gabriel, Shanchuan Lin, Rik Koncel-Kedziorski, Yejin Choi, Hannaneh Hajishirzi, 10.18653/v1/N19-1245Proceedings of the 2019 Conference of the North American Chapter. the Association for Computational Linguistics: Human Language Technologies. the 2019 Conference of the North American ChapterMinneapolis, MinnesotaAssociation for Computational Linguistics20191Long and Short Papers</p>
<p>Curriculum learning. Yoshua Bengio, Jérôme Louradour, Ronan Collobert, Jason Weston, Proceedings of the 26th annual international conference on machine learning. the 26th annual international conference on machine learning2009</p>
<p>Skill-it! a data-driven skills framework for understanding and training language models. F Mayee, Nicholas Chen, Kush Roberts, Jue Bhatia, Ce Wang, Frederic Zhang, Christopher Sala, Ré, ArXiv, abs/2307.144302023</p>
<p>Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, Christopher Hesse, John Schulman, arXiv:2110.14168Training verifiers to solve math word problems. 2021arXiv preprint</p>
<p>HuCurl: Human-induced curriculum discovery. Mohamed Elgaar, Hadi Amiri, 10.18653/v1/2023.acl-long.104Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics. Long Papers. the 61st Annual Meeting of the Association for Computational LinguisticsToronto, CanadaAssociation for Computational Linguistics20231</p>
<p>Measuring massive multitask language understanding. Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, Jacob Steinhardt, 9th International Conference on Learning Representations, ICLR 2021, Virtual Event. Austria2021. May 3-7, 2021OpenReview.net</p>
<p>Towards reasoning in large language models: A survey. Jie Huang, Kevin Chen, -Chuan Chang, 10.18653/v1/2023.findings-acl.67Findings of the Association for Computational Linguistics: ACL 2023. Toronto, CanadaAssociation for Computational Linguistics2023</p>
<p>Prerequisite change and its effect on intermediate accounting performance. Jiunn Huang, O' John, Robin Shaughnessy, Wagner, Journal of Education for Business. 8052005</p>
<p>Enhancing quantitative reasoning skills of large language models through dimension perception. Yuncheng Huang, Qianyu He, Jiaqing Liang, Sihang Jiang, Yanghua Xiao, Yunwen Chen, arXiv:2312.175322023arXiv preprint</p>
<p>MathPrompter: Mathematical reasoning using large language models. Shima Imani, Liang Du, Harsh Shrivastava, 10.18653/v1/2023.acl-industry.4Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics. the 61st Annual Meeting of the Association for Computational LinguisticsToronto, CanadaAssociation for Computational Linguistics20235Industry Track)</p>
<p>Alexandre Albert Q Jiang, Arthur Sablayrolles, Chris Mensch, Devendra Bamford, Diego Singh Chaplot, Florian De Las Casas, Gianna Bressand, Guillaume Lengyel, Lucile Lample, Saulnier, arXiv:2310.06825Mistral 7b. 2023arXiv preprint</p>
<p>Self-paced curriculum learning. Lu Jiang, Deyu Meng, Qian Zhao, Shiguang Shan, Alexander Hauptmann, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence201529</p>
<p>Continual learning of natural language processing tasks: A survey. Zixuan Ke, Bing Liu, arXiv:2211.127012022arXiv preprint</p>
<p>Measuring compositional generalization: A comprehensive method on realistic data. Daniel Keysers, Nathanael Schärli, Nathan Scales, Hylke Buisman, Daniel Furrer, Sergii Kashubin, Nikola Momchev, Danila Sinopalnikov, Lukasz Stafiniak, Tibor Tihon, Dmitry Tsarkov, Xiao Wang, Marc Van Zee, Olivier Bousquet, 8th International Conference on Learning Representations. Addis Ababa, Ethiopia2020. April 26-30, 20202020OpenReview.net</p>
<p>Grace: Discriminator-guided chain-of-thought reasoning. Muhammad Khalifa, Lajanugen Logeswaran, Moontae Lee, Honglak Lee, Lu Wang, 2023</p>
<p>UNIFIEDQA: Crossing format boundaries with a single QA system. Daniel Khashabi, Sewon Min, Tushar Khot, Ashish Sabharwal, Oyvind Tafjord, Peter Clark, Hannaneh Hajishirzi, 10.18653/v1/2020.findings-emnlp.171Findings of the Association for Computational Linguistics: EMNLP 2020. Online. Association for Computational Linguistics2020</p>
<p>TaskWeb: Selecting better source tasks for multi-task NLP. Joongwon Kim, Akari Asai, Gabriel Ilharco, Hannaneh Hajishirzi, 10.18653/v1/2023.emnlp-main.680Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing. the 2023 Conference on Empirical Methods in Natural Language ProcessingSingapore2023Association for Computational Linguistics</p>
<p>COGS: A compositional generalization challenge based on semantic interpretation. Najoung Kim, Tal Linzen, 10.18653/v1/2020.emnlp-main.731Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP). the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)Online. Association for Computational Linguistics2020</p>
<p>Generalization without systematicity: On the compositional skills of sequence-to-sequence recurrent networks. Brenden Lake, Marco Baroni, International conference on machine learning. PMLR2018</p>
<p>Retrieval-augmented generation for knowledge-intensive nlp tasks. Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich Küttler, Mike Lewis, Wen-Tau Yih, Tim Rocktäschel, Advances in Neural Information Processing Systems. 202033</p>
<p>Tiedong Liu, Bryan Kian, Hsiang Low, arXiv:2305.14201Goat: Fine-tuned llama outperforms gpt-4 on arithmetic tasks. 2023arXiv preprint</p>
<p>Catastrophic interference in connectionist networks: The sequential learning problem. Michael Mccloskey, Neal J Cohen, Psychology of learning and motivation. Elsevier198924</p>
<p>Evaluating transformer language models on arithmetic operations using number decomposition. Matteo Muffo, Aldo Cocco, Enrico Bertino, Proceedings of the Thirteenth Language Resources and Evaluation Conference. the Thirteenth Language Resources and Evaluation ConferenceMarseille, FranceEuropean Language Resources Association2022</p>
<p>Investigating the limitations of transformers with simple arithmetic tasks. Rodrigo Nogueira, Zhiying Jiang, Jimmy Lin, arXiv:2102.130192021arXiv preprint</p>
<p>Do language models understand measurements?. Sungjin Park, Seungwoo Ryu, Edward Choi, 10.18653/v1/2022.findings-emnlp.128Findings of the Association for Computational Linguistics: EMNLP 2022. Abu Dhabi, United Arab EmiratesAssociation for Computational Linguistics2022</p>
<p>Are NLP models really able to solve simple math word problems?. Arkil Patel, Satwik Bhattamishra, Navin Goyal, 10.18653/v1/2021.naacl-main.168Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language TechnologiesOnline. Association for Computational Linguistics2021</p>
<p>How accurate are our assumptions about our students' background knowledge?. Joel A Allen A Rovick, Harold I Michael, David S Modell, Barbara Bruce, Thomas Horwitz, Adamson, Dee U Daniel R Richardson, Shirley A Silverthorn, Whitescarver, Advances in Physiology Education. 2766S931999</p>
<p>Multitask prompted training enables zero-shot task generalization. Victor Sanh, Albert Webson, Colin Raffel, Stephen H Bach, Lintang Sutawika, Zaid Alyafeai, Antoine Chaffin, Arnaud Stiegler, Arun Raja, Manan Dey, Canwen Saiful Bari, Urmish Xu, Shanya Thakker, Eliza Sharma Sharma, Taewoon Szczechla, Gunjan Kim, Chhablani, V Nihal, Debajyoti Nayak, Jonathan Datta, Mike Chang, Tian-Jian, Han Jiang, Matteo Wang, Sheng Manica, Zheng Xin Shen, Harshit Yong, Rachel Pandey, Thomas Bawden, Wang, The Tenth International Conference on Learning Representations, ICLR 2022, Virtual Event. Jos Rozen, Abheesht Sharma, Andrea Santilli, Thibault Févry, Jason , Alan Fries, Ryan Teehan, Teven Le Scao, Stella Biderman, Leo Gao, Thomas Wolf, Alexander M Rush, 2022. April 25-29, 2022OpenReview.net</p>
<p>Toolformer: Language models can teach themselves to use tools. Timo Schick, Jane Dwivedi-Yu, Roberto Dessì, Roberta Raileanu, Maria Lomeli, Luke Zettlemoyer, Nicola Cancedda, Thomas Scialom, arXiv:2302.047612023arXiv preprint</p>
<p>Student academic performance in skills-based technology courses delivered through different scheduling formats. Shaun Eric, Scott , 2008Dissertations &amp; Theses -Gradworks</p>
<p>MultiQA: An empirical investigation of generalization and transfer in reading comprehension. Alon Talmor, Jonathan Berant, 10.18653/v1/P19-1485Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics. the 57th Annual Meeting of the Association for Computational LinguisticsFlorence, ItalyAssociation for Computational Linguistics2019</p>
<p>Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann Dubois, Xuechen Li, Carlos Guestrin, Percy Liang, Tatsunori B Hashimoto, Stanford alpaca: An instruction-following llama model. 2023</p>
<p>Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, arXiv:2307.09288Llama 2: Open foundation and fine-tuned chat models. 2023arXiv preprint</p>
<p>Finetuned language models are zero-shot learners. Jason Wei, Maarten Bosma, Y Vincent, Kelvin Zhao, Adams Wei Guu, Brian Yu, Nan Lester, Andrew M Du, Dai, V Quoc, Le, The Tenth International Conference on Learning Representations, ICLR 2022, Virtual Event. 2022a. April 25-29, 2022OpenReview.net</p>
<p>Chain-of-thought prompting elicits reasoning in large language models. Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Denny Quoc V Le, Zhou, Advances in Neural Information Processing Systems. 2022b35</p>
<p>Past and future research on learning hierarchies. T Richard, Robert M White, Gagné, Educational psychologist. 1111974</p>
<p>When do curricula work?. Xiaoxia Wu, Ethan Dyer, Behnam Neyshabur, 9th International Conference on Learning Representations, ICLR 2021, Virtual Event. Austria2021. May 3-7, 2021OpenReview.net</p>
<p>Curriculum learning for natural language understanding. Benfeng Xu, Licheng Zhang, Zhendong Mao, Quan Wang, Hongtao Xie, Yongdong Zhang, 10.18653/v1/2020.acl-main.542Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics. the 58th Annual Meeting of the Association for Computational LinguisticsOnline. Association for Computational Linguistics2020</p>
<p>CrossFit: A few-shot learning challenge for crosstask generalization in NLP. Qinyuan Ye, Bill Yuchen Lin, Xiang Ren, 10.18653/v1/2021.emnlp-main.5722021</p>            </div>
        </div>

    </div>
</body>
</html>