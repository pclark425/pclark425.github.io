<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-665 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-665</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-665</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-19.html">extraction-schema-19</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of variability, reproducibility, or stochasticity in language model-driven scientific experiments, including sources of variability, reproducibility metrics, and methods to improve reproducibility.</div>
                <p><strong>Paper ID:</strong> paper-17a6116e5bbd8b87082cbb2e795885567300c483</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/17a6116e5bbd8b87082cbb2e795885567300c483" target="_blank">Quantifying Language Models' Sensitivity to Spurious Features in Prompt Design or: How I learned to start worrying about prompt formatting</a></p>
                <p><strong>Paper Venue:</strong> International Conference on Learning Representations</p>
                <p><strong>Paper TL;DR:</strong> This work focuses on LLM sensitivity to a quintessential class of meaning-preserving design choices: prompt formatting, and presents a suite of analyses that characterize the nature of this sensitivity, including exploring the influence of particular atomic perturbations and the internal representation of particular formats.</p>
                <p><strong>Paper Abstract:</strong> As large language models (LLMs) are adopted as a fundamental component of language technologies, it is crucial to accurately characterize their performance. Because choices in prompt design can strongly influence model behavior, this design process is critical in effectively using any modern pre-trained generative language model. In this work, we focus on LLM sensitivity to a quintessential class of meaning-preserving design choices: prompt formatting. We find that several widely used open-source LLMs are extremely sensitive to subtle changes in prompt formatting in few-shot settings, with performance differences of up to 76 accuracy points when evaluated using LLaMA-2-13B. Sensitivity remains even when increasing model size, the number of few-shot examples, or performing instruction tuning. Our analysis suggests that work evaluating LLMs with prompting-based methods would benefit from reporting a range of performance across plausible prompt formats, instead of the currently-standard practice of reporting performance on a single format. We also show that format performance only weakly correlates between models, which puts into question the methodological validity of comparing models with an arbitrarily chosen, fixed prompt format. To facilitate systematic analysis we propose FormatSpread, an algorithm that rapidly evaluates a sampled set of plausible prompt formats for a given task, and reports the interval of expected performance without accessing model weights. Furthermore, we present a suite of analyses that characterize the nature of this sensitivity, including exploring the influence of particular atomic perturbations and the internal representation of particular formats.</p>
                <p><strong>Cost:</strong> 0.025</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e665.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e665.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of variability, reproducibility, or stochasticity in language model-driven scientific experiments, including sources of variability, reproducibility metrics, and methods to improve reproducibility.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>FORMATSPREAD</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>FORMATSPREAD (Bayesian prompt-format exploration)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A grammar-driven tool and Bayesian (Thompson-sampling) procedure that efficiently samples semantically-equivalent prompt formats under a user budget to estimate the interval (min,max) of expected task performance without access to model weights.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Multiple LLMs (LLaMA-2, Falcon, GPT-3.5 used in experiments)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Natural Language Processing — LLM evaluation / prompt engineering</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_task</strong></td>
                            <td>Estimate performance spread across semantically-equivalent prompt formats for few-shot classification and short-generation tasks (Super-NaturalInstructions subset) and identify best/worst formats within a compute budget.</td>
                        </tr>
                        <tr>
                            <td><strong>variability_sources</strong></td>
                            <td>Primary: prompt formatting choices defined by a grammar (separators S1/S2, inter-field space C, casing functions F_casing, enumeration/item functions F_item); Secondary factors considered: number of few-shot examples (n-shots), model size, instruction tuning, architecture, dataset sample ordering, scoring metric choice (ranking vs exact prefix matching).</td>
                        </tr>
                        <tr>
                            <td><strong>variability_measured</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>variability_metrics</strong></td>
                            <td>Performance spread (= max_i m(p_i,D) - min_i m(p_i,D)), ranking accuracy, exact prefix matching accuracy, standard deviation of accuracy across formats, centered mass (measure of degeneration), correlation between embedding separability and spread.</td>
                        </tr>
                        <tr>
                            <td><strong>variability_results</strong></td>
                            <td>FORMATSPREAD reports large variability: median spread ≈ 7.5 accuracy points across models/settings (aggregate); extreme cases up to 76 accuracy points (LLaMA-2-13B, 1-shot). For LLaMA-2-70B (1-shot, 320 formats) median spread = 0.171 (17.1 percentage points), mean=0.221, std=0.200, max=0.876; GPT-3.5 (320 formats, 53 tasks, exact prefix matching) median spread = 0.064 (6.4 points), mean=0.110, std=0.115, max=0.562. FORMATSPREAD (Thompson sampling) with budget E=51,200 found spreads within ~1 accuracy point of true spread; naive sampling within ~4 points; UCB within ~11 points.</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_assessed</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_metrics</strong></td>
                            <td>Difference between algorithm-found spread and true spread (computed with full evaluations), probability of reversal of model ordering across formats, one-sided McNemar (paired χ²) tests for statistical significance, classifier accuracy for prompt-format identifiability from prompt embeddings, correlation between top-PC separability and observed spread.</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_results</strong></td>
                            <td>Thompson sampling reliably recovers the true spread under budget (within ≈1 point with E=51,200). Ordering preservation across models is weak (<62% in pairwise comparisons); formats that make a model look better can make another look worse. Prompt-format identifiability: XGBoost on top-100 PCs achieves ≥0.98 classification accuracy; correlation between separability (top-2 PCs) and spread: 0.424 (p=8.04e-6) for 1-shot and 0.555 for 5-shot (exact prefix matching).</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_challenges</strong></td>
                            <td>Large, non-monotonic search space of semantically-equivalent formats; format effects differ across models (weak cross-model correlation); degeneration (models failing to produce any valid option) increases measurement noise; reporting single-format point estimates confounds comparisons and reproductions.</td>
                        </tr>
                        <tr>
                            <td><strong>mitigation_methods</strong></td>
                            <td>Sample and marginalize/report performance across plausible formats; use FORMATSPREAD to efficiently identify expected performance interval under a compute budget; employ Thompson sampling with informative Beta priors (set from original-format accuracy) and two-phase search (find max then min); restrict grammar/contextual constraints to ensure naturalness; use ranking accuracy to reduce degeneration-related noise; suggest future work on regularization/training to make models robust to formatting.</td>
                        </tr>
                        <tr>
                            <td><strong>mitigation_effectiveness</strong></td>
                            <td>Empirically effective: Thompson sampling with informative priors finds spread within ~1 accuracy point of true spread with E=51,200 (320 formats, B=20 averaged over trials); naive sampling and UCB perform worse (within ~4 and ~11 points respectively). With 5% exploration of a 320-format space (for 2,500 examples) FORMATSPREAD can estimate spread within ≈2 accuracy points.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_without_controls</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_runs</strong></td>
                            <td>Varied by experiment: common settings include 53 tasks, typically 10 randomly sampled formats per task (lower-bound experiments); larger runs used 320 formats and 250 samples each, budgets up to E=51,200 or 40,000 evaluations; many analyses averaged over 5 trials; datasets assumed size 1,000 for fair evaluation.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>FORMATSPREAD enables low-cost, practical estimation of the performance interval induced by semantically-equivalent prompt formatting; prompt-format driven variability is large and can change conclusions about model performance, but Thompson-sampling-based FORMATSPREAD can recover true spread efficiently under budgeted evaluation.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': "Quantifying Language Models' Sensitivity to Spurious Features in Prompt Design or: How I learned to start worrying about prompt formatting", 'publication_date_yy_mm': '2023-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e665.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e665.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of variability, reproducibility, or stochasticity in language model-driven scientific experiments, including sources of variability, reproducibility metrics, and methods to improve reproducibility.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Prompt-format sensitivity</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Sensitivity of LLMs to semantically-equivalent prompt formatting</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Empirical phenomenon: widely-used autoregressive LLMs (LLaMA-2 variants, Falcon, GPT-3.5) exhibit large, often unpredictable changes in task performance when only prompt formatting (spacing, separators, casing, enumeration style) is varied while preserving meaning.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>LLaMA-2-7B, LLaMA-2-13B, LLaMA-2-70B, Falcon-7B, Falcon-7B-Instruct, GPT-3.5-Turbo</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>NLP — model evaluation and prompt engineering</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_task</strong></td>
                            <td>Few-shot classification tasks (53 tasks from Super-NaturalInstructions: 19 multiple-choice, 34 classification) and additional short-generation and open-ended generation tasks; evaluate accuracy/metrics across many semantically-equivalent prompt formats.</td>
                        </tr>
                        <tr>
                            <td><strong>variability_sources</strong></td>
                            <td>Atomic prompt-format choices (descriptor casing, separator characters S1/S2, inter-field spaces C, enumeration/item formats F_item1/F_item2), scoring metric choice (ranking vs exact prefix matching), number and choice of few-shot examples, model size, instruction tuning, architecture differences, and dataset sampling.</td>
                        </tr>
                        <tr>
                            <td><strong>variability_measured</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>variability_metrics</strong></td>
                            <td>Performance spread (max-min accuracy across formats), ranking accuracy, exact prefix matching accuracy, ROUGE-L and BERTScore for open generation, standard deviation of accuracy, centered mass (valid-answer rate), probability of ordering reversal between models.</td>
                        </tr>
                        <tr>
                            <td><strong>variability_results</strong></td>
                            <td>Median spread ≈ 7.5 accuracy points across models/settings (10-format samples); 20% of tasks have spread ≥15 points (LLaMA-2 settings); individual tasks show spreads >70 points (e.g., up to 76 points for LLaMA-2-13B). Exact prefix matching yields higher spreads (median 12–28 points depending on model). Atomic changes: ~24% of atomic changes produce ≥5-point accuracy change under prefix matching (11% under probability ranking). Local monotonicity low: only ≈32–34% of atomic-change triples are monotonic, implying non-monotonic search landscapes.</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_assessed</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_metrics</strong></td>
                            <td>Pairwise preservation of relative format ordering across models (percentage), probability of reversal given difference d, one-sided McNemar paired χ² tests for significance, correlation measures between embedding separability and spread.</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_results</strong></td>
                            <td>Relative ordering preservation across models often <62% (e.g., LLaMA-2-7B vs 13B: 57.46%); probability that a better format for M becomes worse for M' by d=0.02 ≈0.14 in some pairings; many reversals are statistically significant (e.g., 76% and 47% of paired comparisons in two example model-pairs were significant on 1000 samples). Prompt embeddings' separability correlates with spread (r≈0.424 for 1-shot).</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_challenges</strong></td>
                            <td>Formatting choices are underreported in literature, causing hidden confounds; format effects differ by model (weak cross-model correlation); non-monotonicity and atomic-sensitivity make local search and simple heuristics unreliable; degeneration (models not producing any valid option) complicates exact-match metrics.</td>
                        </tr>
                        <tr>
                            <td><strong>mitigation_methods</strong></td>
                            <td>Report performance interval across plausible formats (marginalize over formats); use FORMATSPREAD to estimate spread efficiently; choose ranking-accuracy metrics to reduce degeneration sensitivity; enforce contextual restrictions in formatting grammar; in future, consider training-time regularization or other model-level robustness to formatting (left as future work).</td>
                        </tr>
                        <tr>
                            <td><strong>mitigation_effectiveness</strong></td>
                            <td>Reporting a spread gives more informative evaluations; FORMATSPREAD with Thompson sampling recovers true spread efficiently (see FORMATSPREAD entry). Using ranking accuracy reduces degeneration-driven spread compared to exact prefix matching. No training-level regularizers were tested in this work.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_without_controls</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_runs</strong></td>
                            <td>Experiments across 53 tasks: initially 10 random formats per task (lower-bound); larger analyses used 500 formats (some experiments), 320 formats with 250 samples each in FormatSpread runs; many comparisons used 1000 evaluation examples per format in identifiability experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Prompt formatting is a major source of variability in LLM-driven experiments — large, task-dependent spreads occur even for semantically-equivalent formats and are not eliminated by larger models, instruction tuning, or more few-shot examples; therefore, single-format point evaluations risk misleading conclusions.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': "Quantifying Language Models' Sensitivity to Spurious Features in Prompt Design or: How I learned to start worrying about prompt formatting", 'publication_date_yy_mm': '2023-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e665.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e665.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of variability, reproducibility, or stochasticity in language model-driven scientific experiments, including sources of variability, reproducibility metrics, and methods to improve reproducibility.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Thompson sampling (for FORMATSPREAD)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Thompson sampling (Bayesian bandit heuristic)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A Bayesian multi-armed bandit heuristic that samples arms (prompt formats) proportional to their probability of being optimal, modeling per-format accuracy with Beta distributions (Bernoulli trials) and using informative priors to accelerate search.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>An empirical evaluation of thompson sampling</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Applied within FORMATSPREAD to evaluate various LLMs (e.g., LLaMA-2 variants, Falcon, GPT-3.5)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Optimization / Bayesian bandits applied to prompt-format search</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_task</strong></td>
                            <td>Budgeted search over sampled prompt formats to identify maximum and minimum-performing formats (accuracy) without access to model weights.</td>
                        </tr>
                        <tr>
                            <td><strong>variability_sources</strong></td>
                            <td>Stochasticity of per-example Bernoulli rewards (correct/incorrect), limited evaluation budget E, initial prior set from original-format accuracy that influences early draws.</td>
                        </tr>
                        <tr>
                            <td><strong>variability_measured</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>variability_metrics</strong></td>
                            <td>Modeled Beta distributions per arm; empirical difference between algorithm-found spread and true spread; success/failure counters (S_i, N_i) for arms.</td>
                        </tr>
                        <tr>
                            <td><strong>variability_results</strong></td>
                            <td>Thompson sampling outperformed naive and UCB for spread estimation: with E=51,200 evaluations it recovered spread within ≈1 accuracy point of true spread (on average) over 31 tasks and 320 formats; naive sampling within ≈4 points and UCB within ≈11 points.</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_assessed</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_metrics</strong></td>
                            <td>Absolute error (algorithm-found spread minus true spread) as function of budget E averaged across tasks/trials.</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_results</strong></td>
                            <td>Low average error and stable recovery across trials when using informative priors derived from original-format accuracy; performance degrades with smaller budgets but remains better than naive/UCB baselines in experiments reported.</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_challenges</strong></td>
                            <td>Noisy Bernoulli rewards (per-sample accuracy variability), limited budget relative to format space size, highly non-monotonic objective function over formatting space.</td>
                        </tr>
                        <tr>
                            <td><strong>mitigation_methods</strong></td>
                            <td>Set informative Beta priors (alpha = max((beta*x)/(1-x), 1.1), beta=5) using the original format accuracy x; two-phase search (first find high-performing formats then low-performing, reusing counters); use batch evaluations B to amortize cost.</td>
                        </tr>
                        <tr>
                            <td><strong>mitigation_effectiveness</strong></td>
                            <td>Informative priors and two-phase Thompson sampling materially improved convergence speed and accuracy of spread estimates (quantified via spread-recovery numbers above).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_without_controls</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_runs</strong></td>
                            <td>Reported averages over 5 trials across 31 tasks with 320 formats and batch size B=20; budgets up to E=51,200 used in comparisons.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Thompson sampling with informative priors is an effective, practical method to find extremal prompt formats and estimate expected performance spread under a compute budget, outperforming naive and UCB baselines in spread-recovery accuracy.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': "Quantifying Language Models' Sensitivity to Spurious Features in Prompt Design or: How I learned to start worrying about prompt formatting", 'publication_date_yy_mm': '2023-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e665.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e665.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of variability, reproducibility, or stochasticity in language model-driven scientific experiments, including sources of variability, reproducibility metrics, and methods to improve reproducibility.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>UCB (Upper Confidence Bound)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Upper Confidence Bound (frequentist bandit algorithm)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A frequentist bandit algorithm that picks arms by adding an upper confidence bound (based on Chernoff/Hoeffding-type bounds) to the empirical mean; used as a baseline bandit method in FORMATSPREAD comparisons.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Asymptotically efficient adaptive allocation rules</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Applied within FORMATSPREAD comparisons (across multiple LLMs)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Optimization / bandit algorithms for prompt search</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_task</strong></td>
                            <td>Baseline method for budgeted identification of high/low performing prompt formats.</td>
                        </tr>
                        <tr>
                            <td><strong>variability_sources</strong></td>
                            <td>Same as bandit context: per-evaluation stochasticity (Bernoulli rewards), sensitivity to confidence-parameter c (used c=2), limited sampling budget.</td>
                        </tr>
                        <tr>
                            <td><strong>variability_measured</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>variability_metrics</strong></td>
                            <td>Algorithm-found spread vs true spread (absolute error), empirical accuracy estimates S_i/N_i plus exploration bonus c * sqrt(log t / N_i).</td>
                        </tr>
                        <tr>
                            <td><strong>variability_results</strong></td>
                            <td>UCB performed worse than Thompson sampling in spread recovery in experiments: with E=51,200, UCB found spreads within ≈11 accuracy points of true spread on average (versus ≈1 for Thompson sampling).</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_assessed</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_metrics</strong></td>
                            <td>Absolute spread-recovery error across budgets.</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_results</strong></td>
                            <td>Less robust under the non-monotonic formatting search space and limited budgets compared to Thompson sampling.</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_challenges</strong></td>
                            <td>Sensitivity to hyperparameter c, poorer handling of multi-modal/non-monotonic reward landscapes under constrained sampling.</td>
                        </tr>
                        <tr>
                            <td><strong>mitigation_methods</strong></td>
                            <td>None beyond standard UCB tuning (used c=2 per prior work); FORMATSPREAD uses UCB only as a baseline.</td>
                        </tr>
                        <tr>
                            <td><strong>mitigation_effectiveness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_without_controls</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_runs</strong></td>
                            <td>Compared across budgets in the same experimental setups as Thompson sampling (e.g., averaged trials across 31 tasks, 320 formats, B=20).</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>UCB is a viable baseline but empirically underperforms Thompson sampling for spread estimation in the non-monotonic, noisy formatting search space under typical evaluation budgets.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': "Quantifying Language Models' Sensitivity to Spurious Features in Prompt Design or: How I learned to start worrying about prompt formatting", 'publication_date_yy_mm': '2023-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e665.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e665.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of variability, reproducibility, or stochasticity in language model-driven scientific experiments, including sources of variability, reproducibility metrics, and methods to improve reproducibility.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LLaMA-2-13B</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>LLaMA-2-13B</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An autoregressive open-source LLM evaluated in the paper; showed dramatic sensitivity to prompt formatting with extreme performance differences across semantically-equivalent formats.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Llama 2: Open foundation and fine-tuned chat models</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>LLaMA-2-13B</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>13B</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Natural Language Processing — model evaluation</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_task</strong></td>
                            <td>1- and 5-shot classification tasks drawn from 53 Super-NaturalInstructions tasks; measuring accuracy across multiple prompt formats sampled from a grammar.</td>
                        </tr>
                        <tr>
                            <td><strong>variability_sources</strong></td>
                            <td>Prompt formatting choices (separators, spaces, casing, enumerations), scoring metric choice (ranking vs prefix), few-shot examples (fixed in experiments), and dataset sampling.</td>
                        </tr>
                        <tr>
                            <td><strong>variability_measured</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>variability_metrics</strong></td>
                            <td>Performance spread (accuracy points), ranking accuracy, exact prefix matching.</td>
                        </tr>
                        <tr>
                            <td><strong>variability_results</strong></td>
                            <td>Observed up to 76 percentage-point differences in accuracy between semantically-equivalent formats (example: LLaMA-2-13B). Median spread across tasks/models reported ≈7.5 points for sampled settings; 20% of tasks show spreads ≥15 points under LLaMA settings.</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_assessed</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_metrics</strong></td>
                            <td>Pairwise ordering preservation rates, probability of trend reversal with another model, McNemar tests.</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_results</strong></td>
                            <td>Format influence is model-specific: formats that are high-performing for one model may be low-performing for another; ordering preservation between LLaMA-2-7B and -13B ≈57.46%.</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_challenges</strong></td>
                            <td>Large format sensitivity undermines single-format comparison reproducibility; non-monotonic performance landscape limits simple search or deterministic reproduction without format marginalization.</td>
                        </tr>
                        <tr>
                            <td><strong>mitigation_methods</strong></td>
                            <td>Use FORMATSPREAD to sample and report performance intervals; compare models using distributions or intervals rather than single-format point estimates.</td>
                        </tr>
                        <tr>
                            <td><strong>mitigation_effectiveness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_without_controls</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_runs</strong></td>
                            <td>Evaluated across 53 tasks with sampled formats (typical experiments: 10 formats per task; additional runs used up to 320 formats with FormatSpread).</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>LLaMA-2-13B demonstrates extreme sensitivity to prompt formatting (up to 76-point accuracy swings), highlighting that prompt-format choices can dominate apparent performance differences and must be accounted for in evaluations.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': "Quantifying Language Models' Sensitivity to Spurious Features in Prompt Design or: How I learned to start worrying about prompt formatting", 'publication_date_yy_mm': '2023-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e665.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e665.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of variability, reproducibility, or stochasticity in language model-driven scientific experiments, including sources of variability, reproducibility metrics, and methods to improve reproducibility.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GPT-3.5-Turbo (API)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>GPT-3.5-Turbo</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An API-gated autoregressive model evaluated in the study; used to show that format-driven sensitivity exists even when model internals are inaccessible and evaluation must rely on prefix-matching.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Chatgpt: Optimizing language models for dialogue</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-3.5-Turbo</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Natural Language Processing — model evaluation (API-based)</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_task</strong></td>
                            <td>1-shot classification across 320 prompt formats on 53 Super-NaturalInstructions tasks using FORMATSPREAD (inference via API, no logits access).</td>
                        </tr>
                        <tr>
                            <td><strong>variability_sources</strong></td>
                            <td>Prompt formatting choices (as defined by the grammar), scoring metric limitations due to lack of logit access (forced to use exact prefix matching), number of formats sampled.</td>
                        </tr>
                        <tr>
                            <td><strong>variability_measured</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>variability_metrics</strong></td>
                            <td>Spread in exact-prefix-matching accuracy (due to no logits for ranking accuracy), median/mean/std of spread across tasks, maximum observed spread.</td>
                        </tr>
                        <tr>
                            <td><strong>variability_results</strong></td>
                            <td>Across 320 formats and 53 tasks: median spread = 0.064 (6.4 percentage points), mean = 0.110, std = 0.115, 25% of tasks had spread ≥0.148 (14.8 points), maximum observed spread ≈0.562 (56.2 points). FORMATSPREAD runs across 320 formats cost under US$10 on average per task in their setup.</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_assessed</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_metrics</strong></td>
                            <td>Spread across formats (exact prefix matching), significance tests where applicable.</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_results</strong></td>
                            <td>Formatting sensitivity persists for API models; FORMATSPREAD can be applied without model internals to estimate expected performance intervals.</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_challenges</strong></td>
                            <td>Lack of logits prevents ranking-accuracy computations and can increase reliance on noisy prefix-matching metrics; API cost and rate limits constrain exhaustive exploration.</td>
                        </tr>
                        <tr>
                            <td><strong>mitigation_methods</strong></td>
                            <td>Use FORMATSPREAD to sample plausible formats and report spread; use larger sample of formats within budget; prefer ranking accuracy if logits available, otherwise be cautious interpreting prefix-match spreads.</td>
                        </tr>
                        <tr>
                            <td><strong>mitigation_effectiveness</strong></td>
                            <td>FORMATSPREAD provided reasonable spread estimates under API constraints (median spread quantified above) and did so at modest monetary cost (≤≈US$10 per task for 320-format runs in their setup).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_without_controls</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_runs</strong></td>
                            <td>320 formats × 53 tasks experimental setting reported; many evaluations used 250 samples per format in larger analyses; budgets and costs noted in the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Even black-box API models like GPT-3.5-Turbo show substantial sensitivity to prompt formatting; FORMATSPREAD can be used without weights to quantify expected performance variability at modest cost.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': "Quantifying Language Models' Sensitivity to Spurious Features in Prompt Design or: How I learned to start worrying about prompt formatting", 'publication_date_yy_mm': '2023-10'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>An empirical evaluation of thompson sampling <em>(Rating: 2)</em></li>
                <li>Automatic prompt optimization with" gradient descent" and beam search <em>(Rating: 2)</em></li>
                <li>Reproducibility of benchmarked deep reinforcement learning tasks for continuous control <em>(Rating: 2)</em></li>
                <li>Deep reinforcement learning that matters <em>(Rating: 2)</em></li>
                <li>Prompt waywardness: The curious case of discretized interpretation of continuous prompts <em>(Rating: 2)</em></li>
                <li>Jailbroken: How does llm safety training fail? <em>(Rating: 1)</em></li>
                <li>Making pre-trained language models better few-shot learners <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-665",
    "paper_id": "paper-17a6116e5bbd8b87082cbb2e795885567300c483",
    "extraction_schema_id": "extraction-schema-19",
    "extracted_data": [
        {
            "name_short": "FORMATSPREAD",
            "name_full": "FORMATSPREAD (Bayesian prompt-format exploration)",
            "brief_description": "A grammar-driven tool and Bayesian (Thompson-sampling) procedure that efficiently samples semantically-equivalent prompt formats under a user budget to estimate the interval (min,max) of expected task performance without access to model weights.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "Multiple LLMs (LLaMA-2, Falcon, GPT-3.5 used in experiments)",
            "model_size": null,
            "scientific_domain": "Natural Language Processing — LLM evaluation / prompt engineering",
            "experimental_task": "Estimate performance spread across semantically-equivalent prompt formats for few-shot classification and short-generation tasks (Super-NaturalInstructions subset) and identify best/worst formats within a compute budget.",
            "variability_sources": "Primary: prompt formatting choices defined by a grammar (separators S1/S2, inter-field space C, casing functions F_casing, enumeration/item functions F_item); Secondary factors considered: number of few-shot examples (n-shots), model size, instruction tuning, architecture, dataset sample ordering, scoring metric choice (ranking vs exact prefix matching).",
            "variability_measured": true,
            "variability_metrics": "Performance spread (= max_i m(p_i,D) - min_i m(p_i,D)), ranking accuracy, exact prefix matching accuracy, standard deviation of accuracy across formats, centered mass (measure of degeneration), correlation between embedding separability and spread.",
            "variability_results": "FORMATSPREAD reports large variability: median spread ≈ 7.5 accuracy points across models/settings (aggregate); extreme cases up to 76 accuracy points (LLaMA-2-13B, 1-shot). For LLaMA-2-70B (1-shot, 320 formats) median spread = 0.171 (17.1 percentage points), mean=0.221, std=0.200, max=0.876; GPT-3.5 (320 formats, 53 tasks, exact prefix matching) median spread = 0.064 (6.4 points), mean=0.110, std=0.115, max=0.562. FORMATSPREAD (Thompson sampling) with budget E=51,200 found spreads within ~1 accuracy point of true spread; naive sampling within ~4 points; UCB within ~11 points.",
            "reproducibility_assessed": true,
            "reproducibility_metrics": "Difference between algorithm-found spread and true spread (computed with full evaluations), probability of reversal of model ordering across formats, one-sided McNemar (paired χ²) tests for statistical significance, classifier accuracy for prompt-format identifiability from prompt embeddings, correlation between top-PC separability and observed spread.",
            "reproducibility_results": "Thompson sampling reliably recovers the true spread under budget (within ≈1 point with E=51,200). Ordering preservation across models is weak (&lt;62% in pairwise comparisons); formats that make a model look better can make another look worse. Prompt-format identifiability: XGBoost on top-100 PCs achieves ≥0.98 classification accuracy; correlation between separability (top-2 PCs) and spread: 0.424 (p=8.04e-6) for 1-shot and 0.555 for 5-shot (exact prefix matching).",
            "reproducibility_challenges": "Large, non-monotonic search space of semantically-equivalent formats; format effects differ across models (weak cross-model correlation); degeneration (models failing to produce any valid option) increases measurement noise; reporting single-format point estimates confounds comparisons and reproductions.",
            "mitigation_methods": "Sample and marginalize/report performance across plausible formats; use FORMATSPREAD to efficiently identify expected performance interval under a compute budget; employ Thompson sampling with informative Beta priors (set from original-format accuracy) and two-phase search (find max then min); restrict grammar/contextual constraints to ensure naturalness; use ranking accuracy to reduce degeneration-related noise; suggest future work on regularization/training to make models robust to formatting.",
            "mitigation_effectiveness": "Empirically effective: Thompson sampling with informative priors finds spread within ~1 accuracy point of true spread with E=51,200 (320 formats, B=20 averaged over trials); naive sampling and UCB perform worse (within ~4 and ~11 points respectively). With 5% exploration of a 320-format space (for 2,500 examples) FORMATSPREAD can estimate spread within ≈2 accuracy points.",
            "comparison_with_without_controls": true,
            "number_of_runs": "Varied by experiment: common settings include 53 tasks, typically 10 randomly sampled formats per task (lower-bound experiments); larger runs used 320 formats and 250 samples each, budgets up to E=51,200 or 40,000 evaluations; many analyses averaged over 5 trials; datasets assumed size 1,000 for fair evaluation.",
            "key_findings": "FORMATSPREAD enables low-cost, practical estimation of the performance interval induced by semantically-equivalent prompt formatting; prompt-format driven variability is large and can change conclusions about model performance, but Thompson-sampling-based FORMATSPREAD can recover true spread efficiently under budgeted evaluation.",
            "uuid": "e665.0",
            "source_info": {
                "paper_title": "Quantifying Language Models' Sensitivity to Spurious Features in Prompt Design or: How I learned to start worrying about prompt formatting",
                "publication_date_yy_mm": "2023-10"
            }
        },
        {
            "name_short": "Prompt-format sensitivity",
            "name_full": "Sensitivity of LLMs to semantically-equivalent prompt formatting",
            "brief_description": "Empirical phenomenon: widely-used autoregressive LLMs (LLaMA-2 variants, Falcon, GPT-3.5) exhibit large, often unpredictable changes in task performance when only prompt formatting (spacing, separators, casing, enumeration style) is varied while preserving meaning.",
            "citation_title": "here",
            "mention_or_use": "use",
            "model_name": "LLaMA-2-7B, LLaMA-2-13B, LLaMA-2-70B, Falcon-7B, Falcon-7B-Instruct, GPT-3.5-Turbo",
            "model_size": null,
            "scientific_domain": "NLP — model evaluation and prompt engineering",
            "experimental_task": "Few-shot classification tasks (53 tasks from Super-NaturalInstructions: 19 multiple-choice, 34 classification) and additional short-generation and open-ended generation tasks; evaluate accuracy/metrics across many semantically-equivalent prompt formats.",
            "variability_sources": "Atomic prompt-format choices (descriptor casing, separator characters S1/S2, inter-field spaces C, enumeration/item formats F_item1/F_item2), scoring metric choice (ranking vs exact prefix matching), number and choice of few-shot examples, model size, instruction tuning, architecture differences, and dataset sampling.",
            "variability_measured": true,
            "variability_metrics": "Performance spread (max-min accuracy across formats), ranking accuracy, exact prefix matching accuracy, ROUGE-L and BERTScore for open generation, standard deviation of accuracy, centered mass (valid-answer rate), probability of ordering reversal between models.",
            "variability_results": "Median spread ≈ 7.5 accuracy points across models/settings (10-format samples); 20% of tasks have spread ≥15 points (LLaMA-2 settings); individual tasks show spreads &gt;70 points (e.g., up to 76 points for LLaMA-2-13B). Exact prefix matching yields higher spreads (median 12–28 points depending on model). Atomic changes: ~24% of atomic changes produce ≥5-point accuracy change under prefix matching (11% under probability ranking). Local monotonicity low: only ≈32–34% of atomic-change triples are monotonic, implying non-monotonic search landscapes.",
            "reproducibility_assessed": true,
            "reproducibility_metrics": "Pairwise preservation of relative format ordering across models (percentage), probability of reversal given difference d, one-sided McNemar paired χ² tests for significance, correlation measures between embedding separability and spread.",
            "reproducibility_results": "Relative ordering preservation across models often &lt;62% (e.g., LLaMA-2-7B vs 13B: 57.46%); probability that a better format for M becomes worse for M' by d=0.02 ≈0.14 in some pairings; many reversals are statistically significant (e.g., 76% and 47% of paired comparisons in two example model-pairs were significant on 1000 samples). Prompt embeddings' separability correlates with spread (r≈0.424 for 1-shot).",
            "reproducibility_challenges": "Formatting choices are underreported in literature, causing hidden confounds; format effects differ by model (weak cross-model correlation); non-monotonicity and atomic-sensitivity make local search and simple heuristics unreliable; degeneration (models not producing any valid option) complicates exact-match metrics.",
            "mitigation_methods": "Report performance interval across plausible formats (marginalize over formats); use FORMATSPREAD to estimate spread efficiently; choose ranking-accuracy metrics to reduce degeneration sensitivity; enforce contextual restrictions in formatting grammar; in future, consider training-time regularization or other model-level robustness to formatting (left as future work).",
            "mitigation_effectiveness": "Reporting a spread gives more informative evaluations; FORMATSPREAD with Thompson sampling recovers true spread efficiently (see FORMATSPREAD entry). Using ranking accuracy reduces degeneration-driven spread compared to exact prefix matching. No training-level regularizers were tested in this work.",
            "comparison_with_without_controls": true,
            "number_of_runs": "Experiments across 53 tasks: initially 10 random formats per task (lower-bound); larger analyses used 500 formats (some experiments), 320 formats with 250 samples each in FormatSpread runs; many comparisons used 1000 evaluation examples per format in identifiability experiments.",
            "key_findings": "Prompt formatting is a major source of variability in LLM-driven experiments — large, task-dependent spreads occur even for semantically-equivalent formats and are not eliminated by larger models, instruction tuning, or more few-shot examples; therefore, single-format point evaluations risk misleading conclusions.",
            "uuid": "e665.1",
            "source_info": {
                "paper_title": "Quantifying Language Models' Sensitivity to Spurious Features in Prompt Design or: How I learned to start worrying about prompt formatting",
                "publication_date_yy_mm": "2023-10"
            }
        },
        {
            "name_short": "Thompson sampling (for FORMATSPREAD)",
            "name_full": "Thompson sampling (Bayesian bandit heuristic)",
            "brief_description": "A Bayesian multi-armed bandit heuristic that samples arms (prompt formats) proportional to their probability of being optimal, modeling per-format accuracy with Beta distributions (Bernoulli trials) and using informative priors to accelerate search.",
            "citation_title": "An empirical evaluation of thompson sampling",
            "mention_or_use": "use",
            "model_name": "Applied within FORMATSPREAD to evaluate various LLMs (e.g., LLaMA-2 variants, Falcon, GPT-3.5)",
            "model_size": null,
            "scientific_domain": "Optimization / Bayesian bandits applied to prompt-format search",
            "experimental_task": "Budgeted search over sampled prompt formats to identify maximum and minimum-performing formats (accuracy) without access to model weights.",
            "variability_sources": "Stochasticity of per-example Bernoulli rewards (correct/incorrect), limited evaluation budget E, initial prior set from original-format accuracy that influences early draws.",
            "variability_measured": true,
            "variability_metrics": "Modeled Beta distributions per arm; empirical difference between algorithm-found spread and true spread; success/failure counters (S_i, N_i) for arms.",
            "variability_results": "Thompson sampling outperformed naive and UCB for spread estimation: with E=51,200 evaluations it recovered spread within ≈1 accuracy point of true spread (on average) over 31 tasks and 320 formats; naive sampling within ≈4 points and UCB within ≈11 points.",
            "reproducibility_assessed": true,
            "reproducibility_metrics": "Absolute error (algorithm-found spread minus true spread) as function of budget E averaged across tasks/trials.",
            "reproducibility_results": "Low average error and stable recovery across trials when using informative priors derived from original-format accuracy; performance degrades with smaller budgets but remains better than naive/UCB baselines in experiments reported.",
            "reproducibility_challenges": "Noisy Bernoulli rewards (per-sample accuracy variability), limited budget relative to format space size, highly non-monotonic objective function over formatting space.",
            "mitigation_methods": "Set informative Beta priors (alpha = max((beta*x)/(1-x), 1.1), beta=5) using the original format accuracy x; two-phase search (first find high-performing formats then low-performing, reusing counters); use batch evaluations B to amortize cost.",
            "mitigation_effectiveness": "Informative priors and two-phase Thompson sampling materially improved convergence speed and accuracy of spread estimates (quantified via spread-recovery numbers above).",
            "comparison_with_without_controls": true,
            "number_of_runs": "Reported averages over 5 trials across 31 tasks with 320 formats and batch size B=20; budgets up to E=51,200 used in comparisons.",
            "key_findings": "Thompson sampling with informative priors is an effective, practical method to find extremal prompt formats and estimate expected performance spread under a compute budget, outperforming naive and UCB baselines in spread-recovery accuracy.",
            "uuid": "e665.2",
            "source_info": {
                "paper_title": "Quantifying Language Models' Sensitivity to Spurious Features in Prompt Design or: How I learned to start worrying about prompt formatting",
                "publication_date_yy_mm": "2023-10"
            }
        },
        {
            "name_short": "UCB (Upper Confidence Bound)",
            "name_full": "Upper Confidence Bound (frequentist bandit algorithm)",
            "brief_description": "A frequentist bandit algorithm that picks arms by adding an upper confidence bound (based on Chernoff/Hoeffding-type bounds) to the empirical mean; used as a baseline bandit method in FORMATSPREAD comparisons.",
            "citation_title": "Asymptotically efficient adaptive allocation rules",
            "mention_or_use": "use",
            "model_name": "Applied within FORMATSPREAD comparisons (across multiple LLMs)",
            "model_size": null,
            "scientific_domain": "Optimization / bandit algorithms for prompt search",
            "experimental_task": "Baseline method for budgeted identification of high/low performing prompt formats.",
            "variability_sources": "Same as bandit context: per-evaluation stochasticity (Bernoulli rewards), sensitivity to confidence-parameter c (used c=2), limited sampling budget.",
            "variability_measured": true,
            "variability_metrics": "Algorithm-found spread vs true spread (absolute error), empirical accuracy estimates S_i/N_i plus exploration bonus c * sqrt(log t / N_i).",
            "variability_results": "UCB performed worse than Thompson sampling in spread recovery in experiments: with E=51,200, UCB found spreads within ≈11 accuracy points of true spread on average (versus ≈1 for Thompson sampling).",
            "reproducibility_assessed": true,
            "reproducibility_metrics": "Absolute spread-recovery error across budgets.",
            "reproducibility_results": "Less robust under the non-monotonic formatting search space and limited budgets compared to Thompson sampling.",
            "reproducibility_challenges": "Sensitivity to hyperparameter c, poorer handling of multi-modal/non-monotonic reward landscapes under constrained sampling.",
            "mitigation_methods": "None beyond standard UCB tuning (used c=2 per prior work); FORMATSPREAD uses UCB only as a baseline.",
            "mitigation_effectiveness": null,
            "comparison_with_without_controls": true,
            "number_of_runs": "Compared across budgets in the same experimental setups as Thompson sampling (e.g., averaged trials across 31 tasks, 320 formats, B=20).",
            "key_findings": "UCB is a viable baseline but empirically underperforms Thompson sampling for spread estimation in the non-monotonic, noisy formatting search space under typical evaluation budgets.",
            "uuid": "e665.3",
            "source_info": {
                "paper_title": "Quantifying Language Models' Sensitivity to Spurious Features in Prompt Design or: How I learned to start worrying about prompt formatting",
                "publication_date_yy_mm": "2023-10"
            }
        },
        {
            "name_short": "LLaMA-2-13B",
            "name_full": "LLaMA-2-13B",
            "brief_description": "An autoregressive open-source LLM evaluated in the paper; showed dramatic sensitivity to prompt formatting with extreme performance differences across semantically-equivalent formats.",
            "citation_title": "Llama 2: Open foundation and fine-tuned chat models",
            "mention_or_use": "use",
            "model_name": "LLaMA-2-13B",
            "model_size": "13B",
            "scientific_domain": "Natural Language Processing — model evaluation",
            "experimental_task": "1- and 5-shot classification tasks drawn from 53 Super-NaturalInstructions tasks; measuring accuracy across multiple prompt formats sampled from a grammar.",
            "variability_sources": "Prompt formatting choices (separators, spaces, casing, enumerations), scoring metric choice (ranking vs prefix), few-shot examples (fixed in experiments), and dataset sampling.",
            "variability_measured": true,
            "variability_metrics": "Performance spread (accuracy points), ranking accuracy, exact prefix matching.",
            "variability_results": "Observed up to 76 percentage-point differences in accuracy between semantically-equivalent formats (example: LLaMA-2-13B). Median spread across tasks/models reported ≈7.5 points for sampled settings; 20% of tasks show spreads ≥15 points under LLaMA settings.",
            "reproducibility_assessed": true,
            "reproducibility_metrics": "Pairwise ordering preservation rates, probability of trend reversal with another model, McNemar tests.",
            "reproducibility_results": "Format influence is model-specific: formats that are high-performing for one model may be low-performing for another; ordering preservation between LLaMA-2-7B and -13B ≈57.46%.",
            "reproducibility_challenges": "Large format sensitivity undermines single-format comparison reproducibility; non-monotonic performance landscape limits simple search or deterministic reproduction without format marginalization.",
            "mitigation_methods": "Use FORMATSPREAD to sample and report performance intervals; compare models using distributions or intervals rather than single-format point estimates.",
            "mitigation_effectiveness": null,
            "comparison_with_without_controls": true,
            "number_of_runs": "Evaluated across 53 tasks with sampled formats (typical experiments: 10 formats per task; additional runs used up to 320 formats with FormatSpread).",
            "key_findings": "LLaMA-2-13B demonstrates extreme sensitivity to prompt formatting (up to 76-point accuracy swings), highlighting that prompt-format choices can dominate apparent performance differences and must be accounted for in evaluations.",
            "uuid": "e665.4",
            "source_info": {
                "paper_title": "Quantifying Language Models' Sensitivity to Spurious Features in Prompt Design or: How I learned to start worrying about prompt formatting",
                "publication_date_yy_mm": "2023-10"
            }
        },
        {
            "name_short": "GPT-3.5-Turbo (API)",
            "name_full": "GPT-3.5-Turbo",
            "brief_description": "An API-gated autoregressive model evaluated in the study; used to show that format-driven sensitivity exists even when model internals are inaccessible and evaluation must rely on prefix-matching.",
            "citation_title": "Chatgpt: Optimizing language models for dialogue",
            "mention_or_use": "use",
            "model_name": "GPT-3.5-Turbo",
            "model_size": null,
            "scientific_domain": "Natural Language Processing — model evaluation (API-based)",
            "experimental_task": "1-shot classification across 320 prompt formats on 53 Super-NaturalInstructions tasks using FORMATSPREAD (inference via API, no logits access).",
            "variability_sources": "Prompt formatting choices (as defined by the grammar), scoring metric limitations due to lack of logit access (forced to use exact prefix matching), number of formats sampled.",
            "variability_measured": true,
            "variability_metrics": "Spread in exact-prefix-matching accuracy (due to no logits for ranking accuracy), median/mean/std of spread across tasks, maximum observed spread.",
            "variability_results": "Across 320 formats and 53 tasks: median spread = 0.064 (6.4 percentage points), mean = 0.110, std = 0.115, 25% of tasks had spread ≥0.148 (14.8 points), maximum observed spread ≈0.562 (56.2 points). FORMATSPREAD runs across 320 formats cost under US$10 on average per task in their setup.",
            "reproducibility_assessed": true,
            "reproducibility_metrics": "Spread across formats (exact prefix matching), significance tests where applicable.",
            "reproducibility_results": "Formatting sensitivity persists for API models; FORMATSPREAD can be applied without model internals to estimate expected performance intervals.",
            "reproducibility_challenges": "Lack of logits prevents ranking-accuracy computations and can increase reliance on noisy prefix-matching metrics; API cost and rate limits constrain exhaustive exploration.",
            "mitigation_methods": "Use FORMATSPREAD to sample plausible formats and report spread; use larger sample of formats within budget; prefer ranking accuracy if logits available, otherwise be cautious interpreting prefix-match spreads.",
            "mitigation_effectiveness": "FORMATSPREAD provided reasonable spread estimates under API constraints (median spread quantified above) and did so at modest monetary cost (≤≈US$10 per task for 320-format runs in their setup).",
            "comparison_with_without_controls": true,
            "number_of_runs": "320 formats × 53 tasks experimental setting reported; many evaluations used 250 samples per format in larger analyses; budgets and costs noted in the paper.",
            "key_findings": "Even black-box API models like GPT-3.5-Turbo show substantial sensitivity to prompt formatting; FORMATSPREAD can be used without weights to quantify expected performance variability at modest cost.",
            "uuid": "e665.5",
            "source_info": {
                "paper_title": "Quantifying Language Models' Sensitivity to Spurious Features in Prompt Design or: How I learned to start worrying about prompt formatting",
                "publication_date_yy_mm": "2023-10"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "An empirical evaluation of thompson sampling",
            "rating": 2
        },
        {
            "paper_title": "Automatic prompt optimization with\" gradient descent\" and beam search",
            "rating": 2
        },
        {
            "paper_title": "Reproducibility of benchmarked deep reinforcement learning tasks for continuous control",
            "rating": 2
        },
        {
            "paper_title": "Deep reinforcement learning that matters",
            "rating": 2
        },
        {
            "paper_title": "Prompt waywardness: The curious case of discretized interpretation of continuous prompts",
            "rating": 2
        },
        {
            "paper_title": "Jailbroken: How does llm safety training fail?",
            "rating": 1
        },
        {
            "paper_title": "Making pre-trained language models better few-shot learners",
            "rating": 1
        }
    ],
    "cost": 0.02500575,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>QUANTIFYING LANGUAGE MODELS' SENSITIVITY TO Spurious Features in Prompt Design or: How I learned to start worrying about prompt formatting</h1>
<p>Melanie Sclar ${ }^{1} \quad$ Yejin Choi ${ }^{1,2} \quad$ Yulia Tsvetkov ${ }^{1} \quad$ Alane Suhr ${ }^{3}$<br>${ }^{1}$ Paul G. Allen School of Computer Science \&amp; Engineering, University of Washington<br>${ }^{2}$ Allen Institute for Artificial Intelligence ${ }^{3}$ University of California, Berkeley<br>msclar@cs.washington.edu</p>
<h4>Abstract</h4>
<p>As large language models (LLMs) are adopted as a fundamental component of language technologies, it is crucial to accurately characterize their performance. Because choices in prompt design can strongly influence model behavior, this design process is critical in effectively using any modern pre-trained generative language model. In this work, we focus on LLM sensitivity to a quintessential class of meaning-preserving design choices: prompt formatting. We find that several widely used open-source LLMs are extremely sensitive to subtle changes in prompt formatting in few-shot settings, with performance differences of up to 76 accuracy points when evaluated using LLaMA-2-13B. Sensitivity remains even when increasing model size, the number of few-shot examples, or performing instruction tuning. Our analysis suggests that work evaluating LLMs with prompting-based methods would benefit from reporting a range of performance across plausible prompt formats, instead of the currently-standard practice of reporting performance on a single format. We also show that format performance only weakly correlates between models, which puts into question the methodological validity of comparing models with an arbitrarily chosen, fixed prompt format. To facilitate systematic analysis we propose FORMATSPREAD, an algorithm that rapidly evaluates a sampled set of plausible prompt formats for a given task, and reports the interval of expected performance without accessing model weights ${ }^{1}$. Furthermore, we present a suite of analyses that characterize the nature of this sensitivity, including exploring the influence of particular atomic perturbations and the internal representation of particular formats.</p>
<h2>1 INTRODUCTION</h2>
<p>As the capabilities of LLMs have rapidly improved, their sensitivity to input prompt features has been used to optimize performance via prompt engineering (White et al., 2023). However, there has been little work in characterizing this sensitivity, especially to seemingly innocuous feature choices that preserve prompt meaning and intent. In this work, we analyze the sensitivity of widely used, open-source LLMs to a class of features that should not influence a prompt's interpretation: formatting choices. We find that pre-trained LLMs are sensitive to these choices in unpredictable ways, with accuracy varying in up to 76 points for LLaMA-2-13B between equivalent formats, and $\sim 10$ accuracy points on average across $50+$ tasks and several models. We also show that this variance is not eliminated by adding few-shot examples, increasing model size, or instruction tuning.</p>
<p>Designing prompt templates is a critical part of effectively using a pre-trained language model. This design process includes making choices about wording, choosing few-shot examples for in-context learning, and making decisions about seemingly trivial features like formatting. This process, and often even the resulting templates, is rarely reported or discussed in research papers, under the assumption that performance variance across these choices is insignificant compared to variance across data points or models. However, some anecdotal evidence points to formatting choices actually having a significant influence on model behavior (Aghajanyan, 2023). In some cases, researchers report a limited number of manually generated formats to show that scaling trends hold despite perfor-</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Figure 1: Slight modifications in prompt format templating may lead to significantly different model performance for a given task. Each <text> represents a different variable-length placeholder to be replaced with actual data samples. Example shown corresponds to 1-shot LLaMA-2-7B performances for task280 from SuperNaturalInstructions (Wang et al., 2022). This StereoSet-inspired task (Nadeem et al., 2021) requires the model to, given a short passage, classify it into one of four types of stereotype or anti-stereotype (gender, profession, race, and religion).
mance being significantly different (Schick et al., 2021). The assumption that formatting does not influence overall model performance may become problematic when improvements over existing approaches are attributed to the amount and source of training data, number of parameters, or model architecture, without also accounting for changes in prompt format. Ignoring variance across formats may also negatively affect user experience, e.g. if users inadvertently choose formats the LLM does not perform well on.</p>
<p>Our proposed tool, FORMATSPREAD, enables a systematic analysis of these variances across a wide set of semantically equivalent prompt formats within a user-specified computational budget. We find that choices in formatting few-shot examples during in-context learning introduce spurious biases that may lead to significantly different conclusions in model performance. The sensitivity to formatting choices that we discover across widely-used, open-source models suggests that future research would benefit from reporting a performance spread over a sufficient sample of plausible formats, instead of simply reporting the formatting used and its performance, as is currently standard. Moreover, we argue that this reporting is crucial when comparing the performance of different models, as we show the influence of formatting choices only weakly correlates between models, thus making and fixing a formatting choice could introduce a significant confounding factor.</p>
<p>Fully exploring the space of prompt formats is intractable, as computation costs scale linearly with the number of formats considered. FORMATSPREAD efficiently explores the space of prompt formats under a user-specified computational budget using Bayesian optimization. FORMATSPREAD does not require access to the model weights, allowing its use on API-gated models: we find a spread up to 56 accuracy points with a median spread of 6.4 accuracy points with GPT3.5 across 320 formats and 53 tasks at a cost of under 10USD on average per task. Beyond facilitating evaluation, we also propose a suite of analyses to further characterize model sensitivity to formatting. Among other results, we show that the separability of continuous prompt embeddings correlates with the spread observed in task performance.</p>
<h1>2 OVERVIEW</h1>
<p>We evaluate LLM performance over the space of prompt formats that may plausibly be chosen by a non-adversarial user when designing a prompt for a target task, where the space of formats is defined by a grammar (§3.1). Our grammar's definition naturally induces a definition of semantic equivalence among formats. We quantify model sensitivity in terms of performance range in a target task across the space of equivalent prompt formats to the original choice (§4.2). We cast the problem of searching across this space as a bandit problem, and propose FORMATSPREAD (§3), which consists of a grammar (§3.1) and a procedure to estimate the minimum and maximum performance across a set of semantically equivalent formats given a pre-defined metric (§3.2). FORMATSPREAD uses Bayesian optimization to identify the expected performance range with low additional computational cost (§4.5) all without requiring access to model weights, which enables use on API-gated</p>
<p>LLMs. Furthermore, we perform in-depth analysis of this observed sensitivity, including by quantifying the contribution of individual feature choices to the final performance (§4.3) and measuring the identifiability of a format based solely on a model's internal, continuous representation of any prompt via correlation with model performance (§4.4).</p>
<h1>3 Measuring Sensitivity with FormatSpread</h1>
<h3>3.1 Grammar of Plausible Prompt Formats</h3>
<p>We construct a grammar that defines both the space of plausible prompt formats and semantic equivalence between formats. The grammar is manually constructed, as opposed to automatically induced from data, to guarantee a higher level of precision when defining the set of equivalent formats. Our grammar is directly tested by verifying that it can generate the formatting associated with 100+ Super-NaturalInstructions tasks (Wang et al., 2022).</p>
<p>Our grammar consists of fields that are composed to create a prompt format. For example, the format 'Passage: <text> || Answer: <text>', has basic fields 'Passage: <text>', and 'Answer: <text>', denoted $a_{1}$, and $a_{2}$. Each basic field consists of a descriptor (e.g. 'Passage'), a separator (e.g. ' : ' ), and a text placeholder to replace with each data point. We define basic fields as $B_{1}(d, s, f):=f(d) s&lt;$ text&gt; using Backus-Naur notation, where $d$ is a descriptor string, $s \in \mathcal{S}<em _casing="{casing" _text="\text">{1}$ a separator, and $f \in \mathcal{F}</em>,\right.$ ' || ' $)$.}}$ a function that alters $d$ while preserving meaning. Thus, in our example, $a_{1}=B_{1}($ Passage, ': ', id $)$ and $a_{2}=B_{1}($ Answer, ': ', id $)$, with id the identity function. We define joining several fields as $B_{2}^{(n)}\left(X_{1}, \ldots, X_{n}, c\right):=X_{1} c X_{2} c \ldots c X_{n}$, with $c \in \mathcal{C}$ being a space. Our example's prompt format may be written as $B_{2}^{(2)}\left(a_{1}, a_{2</p>
<p>The grammar also supports enumeration, which is defined as joining several basic fields, each representing a different list item. For example, the enumeration 'Option (A) : <text>, Option (B) : <text>, Option (C) : <text>' may be written as $B_{2}^{(3)}\left(a_{1}, a_{2}, a_{3},\right.$ ' $\left.\left.\left.\right|^{1}\right)^{\prime}\right)$, where $a_{i}=$ $B_{1}\left(e_{i}, \prime: \prime\right.$ ', id $)$. In our example, $e_{1}$ represents 'Option (A)', and may in turn be written as the concatenation $e_{i}:=d s_{2} f_{\text {item }}(i)$ with $d=$ 'option', $s_{2}=$ ' (single space), and $f_{\text {item }}(1)=$ '(A)'. Each $f_{\text {item }}$ transforms an item $i$ using a number format (e.g. letters or Roman numerals, denoted as $\mathcal{F}<em _item1="{item1" _text="\text">{\text {item } 2}$ ) and an item wrapper (e.g. (A) or [A], denoted as $\mathcal{F}</em>$ ).}</p>
<p>In summary, we define valid prompt formats as those accepted by the following grammar:</p>
<p>$$
\begin{aligned}
B_{0}(): &amp; =&lt;\text { text }&gt; \
B_{0}^{\prime}(d, s) &amp; :=f(d) s \quad \text { with } s \in \mathcal{S}<em _casing="{casing" _text="\text">{1}, f \in \mathcal{F}</em> \
B_{1}(d, s, f) &amp; :=f(d) s&lt;\text { text }&gt;\quad \text { with } s \in \mathcal{S}}<em _casing="{casing" _text="\text">{1}, f \in \mathcal{F}</em> \
B_{2}^{(n)}\left(X_{1}, \ldots, X_{n}, c\right) &amp; :=X_{1} c \ldots c X_{n} \quad \text { with } c \in \mathcal{C}, X_{i} \in\left{B_{0}, B_{0}^{\prime}, B_{1}, B_{2}, B_{3}\right} \forall i \
B_{3}^{(n)}\left(d, j_{1}, \ldots, j_{n}, s_{1}, s_{2}, c, f_{1}, f_{2}\right):= &amp; B_{2}^{(n)}\left(B_{1}\left(e_{1}, s_{1}, f_{2}\right)\right), \ldots, B_{1}\left(e_{n}, s_{1}, f_{2}\right), c\right) \
&amp; \text { where } e_{i}:=f_{2}(d) s_{2} f_{1}\left(j_{i}\right), j_{i} \in \mathbb{N}}<em 1="1">{0} \forall i \
&amp; s</em>} \in \mathcal{S<em 2="2">{1}, s</em>} \in \mathcal{S<em 1="1">{2}, f</em>} \in \mathcal{F<em 2="2">{\text {item }}, f</em>
\end{aligned}
$$} \in \mathcal{F}_{\text {casing }</p>
<p>Our grammar defines valid formats as finite compositions of $B_{0}, B_{0}^{\prime}, B_{1}, B_{2}, B_{3}$. The sets $\mathcal{S}<em 2="2">{1}, \mathcal{S}</em>}, \mathcal{C}$, $\mathcal{F<em _item="{item" _text="\text">{\text {casing }}, \mathcal{F}</em>$ ) to guarantee semantic equivalence; one may also define a set of functions that paraphrases the descriptor, e.g., via synonym replacement. Appendix A. 2 contains the full list of values we use for the constant sets, as well as a visualization of a prompt template generated from the grammar.}}$ (two sets of separators, spaces, casing functions, and itemizing functions respectively) are pre-defined by the user. Throughout this work, we instantiate all sets with values typically observed in human-written prompt formats. We intentionally only modify the casing of descriptors (via $\mathcal{F}_{\text {casing }</p>
<p>Prompt Format Equivalence. Two prompt formats $p_{1}, p_{2}$ are equivalent if they represent the same rule application $B_{i}$, the descriptors (if any) are the same, and the sub-elements (if any) are equivalent. Appendix A. 1 contains the formal definition of equivalence. The grammar's strict definition allows us to assume that sets of equivalent formats share equivalent meanings. When measuring sensitivity (§3.2), we explore only the space of formats equivalent to a task's original format.</p>
<p>Contextual Restrictions. We define restrictions to the combinations of spaces and separators to further ensure naturalness. For example, if $B_{2}\left(X_{1}, \ldots, X_{n}, c\right)$ where $c$ does not contain a newline, then each $X_{i}$ 's separators and any subcomponents' separators should not contain a newline. This</p>
<p>avoids unnatural formats like Input: $\backslash$ n <text> Output: $\backslash$ n <text>. We also allow for adding conditions that force constants (separators, spaces, etc.) in different applications of $B_{i}$ to be equal. When measuring sensitivity to format perturbations, if two separators or spaces are equal in an original format, they are forced to jointly change to be considered equivalent. Appendix A. 3 contains all contextual restrictions.</p>
<p>Final Prompt Construction. Given a valid format $p$ accepted by the grammar, the final prompt is constructed by concatenating with space $c$ an instruction string inst, $n$ fewshot data points $D_{1}, \ldots, D_{n}$ exemplifying the task, and a data point $D_{n+1}$ to be solved. All few-shot examples $D_{i}$ are formatted using $p$. Thus, the final prompt template is: inst $c p\left(D_{1}\right) c p\left(D_{2}\right) c \ldots c p\left(D_{n}\right) c p\left(D_{n+1}\right)$. Since $D_{n+1}$ 's output will be generated by the model, an empty string is added in place of the answer in the last field in the template. Prompt construction will modify inst to match specific choices encoded in $p$ : concretely, if $p$ enumerates valid multiple-choice options as characters $x_{1} \ldots x_{n}$, we ensure inst refers to these choices as $x_{1} \ldots x_{n}$.</p>
<h1>3.2 Measuring Sensitivity</h1>
<p>We measure how plausible choices in prompt formatting influence quantifiable metrics of generated outputs. Given a set of plausible formats $\left{p_{1}, \ldots, p_{n}\right}$, a dataset $\mathcal{D}$, and a scalar metric $m$, let the performance interval be $\left[\min <em i="i">{i} m\left(p</em>\right), \max }, \mathcal{D<em i="i">{i} m\left(p</em>\right)\right]$. We define the performance spread or simply spread as $\max }, \mathcal{D<em i="i">{i} m\left(p</em>\right)-\min }, \mathcal{D<em i="i">{i} m\left(p</em>\right)$. Higher spread indicates more sensitivity to variance within the space of plausible, semantically-equivalent formats. While our method is agnostic to the scalar metric $m$ used, and one could consider a number of metrics including text length, formality, or toxicity, throughout this work we focus our analysis on estimated task accuracy $a c c$. Due to ease in automatic evaluation, here we evaluate on classification tasks.}, \mathcal{D</p>
<p>Our goal is to compute spread for a given model and task. A comprehensive approach would be to fully evaluate each plausible format $p_{i}$ on the entire evaluation dataset $\mathcal{D}$. This increases the cost of reporting a model's performance linearly with $n$, which becomes computationally infeasible for large values of $n$. Following prior gradient-free prompt engineering work (Zhou et al., 2023; Pryzant et al., 2023), we model our problem as a multi-arm bandit. Given a random sample of $n$ formats (arms) $p_{1}, \ldots, p_{n}$ for a task, an arm $p_{i}$ 's hidden value is the actual performance $m\left(p_{i}, \mathcal{D}\right)$ when evaluated on the full dataset $\mathcal{D}$, and the reward for pulling the arm is an estimate $m\left(p_{i}, \hat{\mathcal{D}}\right)$ where $\hat{\mathcal{D}} \subset \mathcal{D},|\hat{\mathcal{D}}|=B$ (mini-batch size) and no element of $\hat{\mathcal{D}}$ has yet been evaluated with $p_{i}$.</p>
<p>We assume a budget of $E$ total data point evaluations. We first search for the highest performing format with budget $E / 2$, and then for the lowest performing format with budget $E / 2$. Evaluations done for the first exploration are readily available for the second exploration, which yields a more informative prior for many formats. We consider two well-known regret minimization bandit algorithms: Thompson sampling (used in FORMATSPREAD) and Upper Confidence Bound (UCB).</p>
<p>Thompson Sampling. This simple, high-performing Bayesian inference heuristic randomly draws each arm according to its probability of being optimal (Chapelle \&amp; Li, 2011). Each $m\left(p_{i}, \mathcal{D}\right)$ is modeled as a random variable, and since with our target metric each data point evaluation is a Bernoulli trial, it is natural to model $m\left(p_{i}, \hat{\mathcal{D}}\right)$ as a Beta distribution. In each round, Thompson sampling draws from each $m\left(p_{i}, \hat{\mathcal{D}}\right)$ and chooses the best arm $\hat{i}$ (Algorithm 1). It then updates $\hat{i}$ according to the number of observed successes $r$, and the corresponding $B-r$ failures, within $\hat{\mathcal{D}}$.</p>
<div class="codehilite"><pre><span></span><code><span class="nx">Algorithm</span><span class="w"> </span><span class="mi">1</span><span class="w"> </span><span class="nx">Thompson</span><span class="w"> </span><span class="nx">Sampling</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="nx">Bernoulli</span><span class="w"> </span><span class="nx">Bandits</span>
<span class="w">    </span><span class="err">\</span><span class="p">(</span><span class="nx">S_</span><span class="p">{</span><span class="nx">i</span><span class="p">}</span><span class="o">^</span><span class="p">{(</span><span class="mi">1</span><span class="p">)}</span><span class="w"> </span><span class="err">\</span><span class="nx">leftarrow</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="nx">N_</span><span class="p">{</span><span class="nx">i</span><span class="p">}</span><span class="o">^</span><span class="p">{(</span><span class="mi">1</span><span class="p">)}</span><span class="w"> </span><span class="err">\</span><span class="nx">leftarrow</span><span class="w"> </span><span class="mi">0</span><span class="err">\</span><span class="p">)</span><span class="w"> </span><span class="p">(</span><span class="nx">success</span><span class="w"> </span><span class="nx">counters</span><span class="w"> </span><span class="k">and</span><span class="w"> </span><span class="nx">total</span><span class="w"> </span><span class="nx">times</span><span class="w"> </span><span class="nx">armed</span><span class="w"> </span><span class="nx">was</span><span class="w"> </span><span class="nx">drawn</span><span class="w"> </span><span class="nx">counter</span><span class="p">)</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="err">\</span><span class="p">(</span><span class="nx">t</span><span class="w"> </span><span class="err">\</span><span class="nx">leftarrow</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="err">\</span><span class="nx">ldots</span><span class="w"> </span><span class="nx">E</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="nx">B</span><span class="err">\</span><span class="p">)</span><span class="w"> </span><span class="nx">do</span>
<span class="w">        </span><span class="k">for</span><span class="w"> </span><span class="err">\</span><span class="p">(</span><span class="nx">i</span><span class="w"> </span><span class="err">\</span><span class="nx">leftarrow</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="err">\</span><span class="nx">ldots</span><span class="p">,</span><span class="w"> </span><span class="nx">K</span><span class="err">\</span><span class="p">)</span><span class="w"> </span><span class="nx">do</span>
<span class="w">            </span><span class="nx">Take</span><span class="w"> </span><span class="err">\</span><span class="p">(</span><span class="err">\</span><span class="nx">theta_</span><span class="p">{</span><span class="nx">i</span><span class="p">}</span><span class="o">^</span><span class="p">{(</span><span class="nx">t</span><span class="p">)}</span><span class="err">\</span><span class="p">)</span><span class="w"> </span><span class="nx">from</span><span class="w"> </span><span class="nx">Beta</span><span class="w"> </span><span class="err">\</span><span class="p">(</span><span class="err">\</span><span class="nx">left</span><span class="p">(</span><span class="err">\</span><span class="nx">alpha_</span><span class="p">{</span><span class="nx">i</span><span class="p">}</span><span class="o">+</span><span class="nx">S_</span><span class="p">{</span><span class="nx">i</span><span class="p">}</span><span class="o">^</span><span class="p">{(</span><span class="nx">t</span><span class="p">)},</span><span class="w"> </span><span class="err">\</span><span class="nx">beta_</span><span class="p">{</span><span class="nx">i</span><span class="p">}</span><span class="o">+</span><span class="err">\</span><span class="nx">left</span><span class="p">(</span><span class="nx">N_</span><span class="p">{</span><span class="nx">i</span><span class="p">}</span><span class="o">^</span><span class="p">{(</span><span class="nx">t</span><span class="p">)}</span><span class="o">-</span><span class="nx">S_</span><span class="p">{</span><span class="nx">i</span><span class="p">}</span><span class="o">^</span><span class="p">{(</span><span class="nx">t</span><span class="p">)}</span><span class="err">\</span><span class="nx">right</span><span class="p">)</span><span class="err">\</span><span class="nx">right</span><span class="p">)</span><span class="err">\</span><span class="p">)</span>
<span class="w">        </span><span class="nx">Draw</span><span class="w"> </span><span class="nx">arm</span><span class="w"> </span><span class="err">\</span><span class="p">(</span><span class="err">\</span><span class="nx">hat</span><span class="p">{</span><span class="nx">i</span><span class="p">}=</span><span class="err">\</span><span class="nx">arg</span><span class="w"> </span><span class="err">\</span><span class="nx">max</span><span class="w"> </span><span class="nx">_</span><span class="p">{</span><span class="nx">i</span><span class="p">}</span><span class="w"> </span><span class="err">\</span><span class="nx">theta_</span><span class="p">{</span><span class="nx">i</span><span class="p">}</span><span class="o">^</span><span class="p">{(</span><span class="nx">t</span><span class="p">)}</span><span class="err">\</span><span class="p">)</span><span class="w"> </span><span class="p">(</span><span class="k">or</span><span class="w"> </span><span class="err">\</span><span class="p">(</span><span class="err">\</span><span class="nx">arg</span><span class="w"> </span><span class="err">\</span><span class="nx">min</span><span class="err">\</span><span class="p">)</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="nx">minimization</span><span class="w"> </span><span class="nx">problems</span><span class="p">)</span><span class="w"> </span><span class="k">and</span><span class="w"> </span><span class="k">observe</span><span class="w"> </span><span class="nx">reward</span><span class="w"> </span><span class="err">\</span><span class="p">(</span><span class="nx">r</span><span class="err">\</span><span class="p">)</span>
<span class="w">        </span><span class="err">\</span><span class="p">(</span><span class="nx">S_</span><span class="p">{</span><span class="nx">i</span><span class="p">}</span><span class="o">^</span><span class="p">{(</span><span class="nx">t</span><span class="o">+</span><span class="mi">1</span><span class="p">)}</span><span class="w"> </span><span class="err">\</span><span class="nx">leftarrow</span><span class="w"> </span><span class="nx">S_</span><span class="p">{</span><span class="nx">i</span><span class="p">}</span><span class="o">^</span><span class="p">{(</span><span class="nx">t</span><span class="p">)}</span><span class="o">+</span><span class="nx">r</span><span class="p">,</span><span class="w"> </span><span class="err">\</span><span class="nx">quad</span><span class="w"> </span><span class="nx">N_</span><span class="p">{</span><span class="nx">i</span><span class="p">}</span><span class="o">^</span><span class="p">{(</span><span class="nx">t</span><span class="o">+</span><span class="mi">1</span><span class="p">)}</span><span class="w"> </span><span class="err">\</span><span class="nx">leftarrow</span><span class="w"> </span><span class="nx">N_</span><span class="p">{</span><span class="nx">i</span><span class="p">}</span><span class="o">^</span><span class="p">{(</span><span class="nx">t</span><span class="p">)}</span><span class="o">+</span><span class="nx">B</span><span class="err">\</span><span class="p">)</span>
</code></pre></div>

<p>Thompson sampling allows for setting informative priors $\left(\alpha_{i}, \beta_{i}\right)$ based on domain knowledge to accelerate runtime. Appendix A. 4 details the exact priors we use. To our knowledge, we are the first to consider a Bayesian sampling method for prompt optimization.</p>
<p>Upper Confidence Bound (UCB) Sampling. UCB (Lai et al., 1985) computes an upper confidence bound to each arm's performance, derived from Chernoff's bound. The key difference with Thompson sampling is in how $\theta_{i}^{(t)}$ is defined. In UCB's frequentist approach, $\theta_{i}^{(t)}$ is assigned the estimated accuracy plus the upper confidence bound: $\theta_{i}^{(t)} \leftarrow S_{i} / N_{i}+c \sqrt{\log (t) / N_{i}}$. We use $c=2$ following Pryzant et al. (2023), who find UCB with $c=2$ to be most effective for prompt optimization.</p>
<p>Naive Sampling. Each prompt format is evaluated on $E / n$ points (with appropriate rounding).</p>
<h1>4 Characterizing Prompt Format Variance with FormatSpread</h1>
<h3>4.1 EXPERIMENTAL SETUP</h3>
<p>Data. We use a subset of 53 tasks from Super-NaturalInstructions (Wang et al., 2022) with diverse human-written formats and instructions, comprising 19 multiple-choice tasks and 34 classification tasks with ${2,3,4}$ basic fields. Appendix B. 1 details the exact task selection procedure. To construct the final prompt template, we concatenate each task's instruction and $n$ formatted few-shot examples using $\backslash \mathrm{n} \backslash \mathrm{n}$ as spacing. While selection and ordering of few-shot examples is a component of prompt design influencing features of model output (Lu et al., 2022), our work focuses on prompt formatting. To remove this confounder, we fix the exact choice and ordering of examples for each task and for a given number of shots $n$. Few-shot examples for each task are chosen randomly within each dataset and are not used for evaluation. We evaluate task data samples on an arbitrary order fixed across settings. Datasets are assumed to be of size 1,000 for fair evaluation across tasks.</p>
<p>Models. We evaluate LLaMA-2-{7B,13B,70B} (Touvron et al., 2023), Falcon-7B and Falcon-7BInstruct (Almazrouei et al., 2023), GPT-3.5-Turbo (Schulman et al., 2022), all autoregressive LMs.</p>
<p>Task Evaluation Metrics. We use two popular measures for computing accuracy: exact prefix matching and probability ranking. In exact prefix matching, we check if the output's prefix matches the expected answer after normalization (casing, spacing, newlines). Ranking accuracy computes the rate that the expected answer is the highest-ranked valid option (in multiple choice and classification tasks) according to the model's output distribution. Results are reported using ranking accuracy unless specified otherwise. Appendix B. 2 shows additional analysis of exact prefix matching, with spreads even higher than those shown in Section 4.2, and including how formatting choice affects task degeneration (i.e., not answering any valid option).</p>
<h3>4.2 PROMPT FORMATS HAVE A LARGE PERFORMANCE SPREAD, NOT ELIMINATED BY INCREASING FEW-SHOT EXAMPLES OR MODEL SIZE, NOR WITH INSTRUCTION TUNING</h3>
<p>For each evaluation task we randomly sample 10 plausible prompt formats and use FORMATSPREAD to compute performance spread for each modeling and $n$-shot choice (Figure 3). We find significant performance spread across tasks, with a median spread of 7.5 accuracy points across choices in the model and the number of few-shot examples. $20 \%$ of tasks consistently result in a spread of at least 15 accuracy points for all LLaMA-2 settings, and at least 9 points for all Falcon settings. We observe several tasks with performance spread over 70 accuracy points. Because this analysis uses only 10 randomly sampled formats, it represents a lower bound of the true spreads for each task. Furthermore, there exists significant performance spread regardless of increased model size (Figure 2a and Figure 11 for Llama-2-70B), instruction tuning (Figure 2b), or number of few-shot examples (Figure 2c; Figure 2a and 2b plot 1- and 5-shot jointly). Appendix B. 2 demonstrates similar results on a selection of non-classification tasks, and expands the spread discussion to plotting the entire accuracy distribution, along with a dispersion metric.</p>
<p>Comparison trends between models are often reversed just by choosing different formats. Assuming model $M$ is better than $M^{\prime}$ by at least $d$ accuracy using prompt $p$, we compute how often $M^{\prime}$ achieves at least $d$ higher accuracy than $M$ under a different format $p^{\prime}$. Figure 4 shows these trends are often reversed: LLaMA-2-13B and -70B reverse trend by at least $d=0.02$ with probability 0.141; LLaMA-2-7B and Falcon-7B reverse trend by at least $d=0.02$ with probability 0.140. Strikingly, often both experiments (first using $p$, and then $p^{\prime}$ ) were statistically significant (p-value $&lt;0.05$ ) on 1000 samples $^{2}: 76 \%$ and $47 \%$ respectively for the two model comparisons</p>
<p><sup id="fnref2:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p><img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Figure 2: Spread comparison between evaluating the same task under different models or $n$-shots.</p>
<p><img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>Figure 3: Spread across models and $n$-shots.</p>
<p><img alt="img-3.jpeg" src="img-3.jpeg" /></p>
<p>Figure 4: Probability that model $M$ performs worse than $M^{\prime}$ by at least $d$ when using format $p^{\prime}$, given that $M$ performed better than $M^{\prime}$ by at least $d$ using format $p$. 53 tasks, 1- and 5-shot.</p>
<p>mentioned above. We find that formats yielding high performance for model $M$ may not yield high performance for $M^{\prime}$, implying that formats may not be inherently good or bad (Appendix B.2).</p>
<h3>4.3 How do individual features contribute to performance?</h3>
<p>We analyze how choices in particular constants (i.e. $\mathcal{S}<em 2="2">{1}, \mathcal{S}</em>}, \mathcal{C}, \mathcal{F<em _item="{item" _text="\text">{\text {casing }}, \mathcal{F}</em>}}$ ) independently influence task performance across different formats. Figure 5 shows the distribution of accuracy for 500 sampled prompts conditioned on the choice of $\mathcal{S<em 1="1">{1}$ (the separator between a descriptor and the text placeholder) for one task in Super-NaturalInstructions. When comparing the individual influence of two feature choices, we measure both weak and strong notions of dissimilarity between distributions of accuracy across prompts conditioned on a chosen feature. We say two constant choices yield weakly different accuracy distributions if the values between the first quartile ( $Q</em>$ ' and ' : ' (fourth and sixth) are only weakly different.}$ ) and third quartile ( $Q_{3}$ ) do not intersect. This is equivalent to the boxes in a boxplot not overlapping. We say two constant choices yield strongly different accuracy distributions if the ranges $\left[2.5 Q_{1}-1.5 Q_{3}, 2.5 Q_{3}+1.5 Q_{1}\right]$ do not overlap (adjusted to end in a data point). This is equivalent to two boxplots with their whiskers not overlapping. In Figure 5, ' $\backslash \mathrm{n} \backslash \mathrm{c</p>
<p>We compute accuracy for 500 random formats with 250 samples each on 31 tasks for 1-shot Llama-2-7B. Table 1 shows that choices in $\mathcal{S}<em _item1="{item1" _text="\text">{2}, \mathcal{F}</em>}}, \mathcal{F<em 1="1">{\text {casing }}$ do not independently predict performance differences (weakly or strongly): although these features can have a large performance variance and thus should be explored with FORMATSPREAD, they cannot be used to independently predict accuracy changes. Other constant sets have varying degrees of differences, with $\mathcal{S}</em>$ (number format changes in enumerations) having the most individual impact. All tasks with strong dissimilarities are shown in Appendix B.4.}$ (separators) and $\mathcal{F}_{\text {item2 }</p>
<p>Small prompt variations often yield large performance differences. Table 2 shows a selection of tasks where changing a single constant on a format (e.g., casing in task322) results in large accuracy differences. Figure 6 shows that regardless of the scoring criterion used, a significant ratio of these atomic changes are associated with large accuracy changes. For example, 24\% of atomic changes have an associated accuracy change of at least 5 points when using exact prefix matching as scoring criteria ( $11 \%$ when using probability ranking).</p>
<p>The space of prompt format accuracy is highly non-monotonic, which makes local search algorithms over the space less effective. Let $\left(p_{1}, p_{2}, p_{3}\right)$ be a prompt format triple such that $p_{i+1}$ is obtained by making an atomic change to $p_{i}$. We argue that if the prompt format space is smooth, we should often see a triples' accuracy to be strictly monotonic over $i$. We choose 24 tasks ( 13 multiple choice,</p>
<p><img alt="img-4.jpeg" src="img-4.jpeg" /></p>
<p>Figure 5: Example of accuracy variance for different choices of constants in $\mathcal{S}_{1}$ for task1283.</p>
<p>Table 1: Tasks where at least two constants yield different performance (weakly different if their boxes in a boxplot do not overlap, strongly if boxes including whiskers do not overlap).</p>
<table>
<thead>
<tr>
<th style="text-align: center;"></th>
<th style="text-align: center;">Median Spread <br> (range $[0,1]$ )</th>
<th style="text-align: center;">Weak <br> Diff.</th>
<th style="text-align: center;">Strong <br> Diff.</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">$\mathcal{C}$</td>
<td style="text-align: center;">0.144</td>
<td style="text-align: center;">$29 \%$</td>
<td style="text-align: center;">$1 \%$</td>
</tr>
<tr>
<td style="text-align: center;">$\mathcal{S}_{1}$</td>
<td style="text-align: center;">0.132</td>
<td style="text-align: center;">$43 \%$</td>
<td style="text-align: center;">$22 \%$</td>
</tr>
<tr>
<td style="text-align: center;">$\mathcal{S}_{2}$</td>
<td style="text-align: center;">0.238</td>
<td style="text-align: center;">$0 \%$</td>
<td style="text-align: center;">$0 \%$</td>
</tr>
<tr>
<td style="text-align: center;">$\mathcal{F}_{\text {item1 }}$</td>
<td style="text-align: center;">0.176</td>
<td style="text-align: center;">$0 \%$</td>
<td style="text-align: center;">$0 \%$</td>
</tr>
<tr>
<td style="text-align: center;">$\mathcal{F}_{\text {item2 }}$</td>
<td style="text-align: center;">0.173</td>
<td style="text-align: center;">$45 \%$</td>
<td style="text-align: center;">$10 \%$</td>
</tr>
<tr>
<td style="text-align: center;">$\mathcal{F}_{\text {casing }}$</td>
<td style="text-align: center;">0.188</td>
<td style="text-align: center;">$3 \%$</td>
<td style="text-align: center;">$0 \%$</td>
</tr>
</tbody>
</table>
<p>Table 2: Examples of atomic changes' impact on accuracy using probability ranking (prefix matching shown in Table 4). $}$ represents a text field; $p_{2}$ yields higher accuracy than $p_{1}$ for all tasks.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Task Id</th>
<th style="text-align: left;">Prompt Format 1 $\left(p_{1}\right)$</th>
<th style="text-align: left;">Prompt Format 2 $\left(p_{2}\right)$</th>
<th style="text-align: left;">Acc $p_{1}$</th>
<th style="text-align: left;">Acc $p_{2}$</th>
<th style="text-align: left;">Diff.</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">task280</td>
<td style="text-align: left;">passage: ${}\backslash$ answer: $}$</td>
<td style="text-align: left;">passage ${}\backslash$ answer $}$</td>
<td style="text-align: left;">0.043</td>
<td style="text-align: left;">0.826</td>
<td style="text-align: left;">0.783</td>
</tr>
<tr>
<td style="text-align: left;">task317</td>
<td style="text-align: left;">Passage: : $}$ Answer: : $}$</td>
<td style="text-align: left;">Passage: : $}$ Answer: : $}$</td>
<td style="text-align: left;">0.076</td>
<td style="text-align: left;">0.638</td>
<td style="text-align: left;">0.562</td>
</tr>
<tr>
<td style="text-align: left;">task190</td>
<td style="text-align: left;">Sentence[II] - {}</td>
<td style="text-align: left;">Sentence[A] - {}Sentence[B] - {}</td>
<td style="text-align: left;">0.360</td>
<td style="text-align: left;">0.614</td>
<td style="text-align: left;">0.254</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">$\cdots$ Answer $\backslash t {}$</td>
<td style="text-align: left;">$\cdots$ Answer $\backslash t {}$</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
<tr>
<td style="text-align: left;">task904</td>
<td style="text-align: left;">input: : $}$ \n output: : $}$</td>
<td style="text-align: left;">input: : $}$ \n output: : $}$</td>
<td style="text-align: left;">0.418</td>
<td style="text-align: left;">0.616</td>
<td style="text-align: left;">0.198</td>
</tr>
<tr>
<td style="text-align: left;">task320</td>
<td style="text-align: left;">target - {} \n{} \nanswer - {}</td>
<td style="text-align: left;">target - {}; \n{}; \nanswer - {}</td>
<td style="text-align: left;">0.361</td>
<td style="text-align: left;">0.476</td>
<td style="text-align: left;">0.115</td>
</tr>
<tr>
<td style="text-align: left;">task322</td>
<td style="text-align: left;">COMMENT: {} ANSWER: {}</td>
<td style="text-align: left;">comment: {} answer: {}</td>
<td style="text-align: left;">0.614</td>
<td style="text-align: left;">0.714</td>
<td style="text-align: left;">0.100</td>
</tr>
<tr>
<td style="text-align: left;">task279</td>
<td style="text-align: left;">Passage : {}. Answer : {}</td>
<td style="text-align: left;">PASSAGE : {}. ANSWER : {}</td>
<td style="text-align: left;">0.372</td>
<td style="text-align: left;">0.441</td>
<td style="text-align: left;">0.069</td>
</tr>
</tbody>
</table>
<p>11 non-multiple choice), sample 300 $\left(p_{1}, p_{2}, p_{3}\right)$ triples for each, and the compute accuracy (using exact prefix matching) of each $p_{i}$ on 250 samples. 32.4 and $33.6 \%$ of triples were monotonic for multiple-choice and non-multiple-choice tasks respectively. Given that random shuffling within a triple will result in monotonicity $33.3 \%$ of the time, this suggests that local search mechanisms like simulated annealing may not be effective as they require a locally smooth search space.</p>
<h1>4.4 PROMPT FORMATS ARE IDENTIFIABLE TRANSFORMATIONS OF PROMPT EMBEDDINGS</h1>
<p>Prompt format choices represent a deterministic transformation of the input, even if its impact on the resulting performance is hard to predict. We represent prompt embeddings as the last hidden layer obtained when processing the whole input prompt (immediately before generating the first token). We demonstrate that format choice yields a highly identifiable transformation over this embedding, which suggests that formats can be seen as transformations of the output probability distribution.</p>
<p>For each task, and for both ${1,5}$-shot settings, we collect prompt embeddings from LLaMA-2-7B corresponding to 10 randomly sampled valid formats for 1000 evaluation examples. We train an XGBoost (Chen \&amp; Guestrin, 2016) classifier that maps from the top $n$ principal components of a prompt embedding to the prompt format. ${ }^{3}$ We find that although the original prompt embeddings are of size $4,096^{4}$, using just the top 100 principal components can result in a classifier with $\geq 0.98$ accuracy in format identification for all 31 tasks analyzed. Figure 7 shows the accuracy of format classification given a fixed number of principal components. ${ }^{5}$ We find that classifier accuracy given just the top two components correlates moderately with the spread of performance in the prompts they represent $\left(0.424, p=8.04 \cdot 10^{-6} ; 0.555\right.$ for the 5 -shot setting; using exact prefix matching).</p>
<h3>4.5 FAST EXPLORATION OF THE PROMPT FORMATTING SPACE: FORMATSPREAD</h3>
<p>In Section 4.2, we demonstrate that even when sampling just 10 formats from the space of plausible formats, we still observe significant performance spread on many tasks. However, this is only a lower</p>
<p><sup id="fnref3:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p><img alt="img-5.jpeg" src="img-5.jpeg" /></p>
<p>Figure 6: Probability that an atomic change (e.g. changing a space, separator) has a given impact in accuracy for two scoring criteria. 53 tasks, 30 sampled atomic changes each.
<img alt="img-6.jpeg" src="img-6.jpeg" /></p>
<p>Figure 8: Probability of observing a spread increase of at least $d$ when increasing sample size from $k_{1}$ to $k_{2}$ formats. 31 tasks, 100 trials each.
<img alt="img-7.jpeg" src="img-7.jpeg" /></p>
<p>Figure 7: Cumulative ratio of tasks that can be classified with at most $a$ accuracy using the top principal components of the last decoding layer of the prompt.
<img alt="img-8.jpeg" src="img-8.jpeg" /></p>
<p>Figure 9: Difference between the true sample spread and each algorithm-found spread with respect to $E$ (evaluation budget). 320 formats, $B=20$, average of 5 trials over 31 tasks shown.
bound of the spread a task may exhibit when increasing the number of formats: for example, about $17 \%$ of tasks are expected to increase their spread by at least 5 accuracy points when increasing from 10 to 20 sampled formats. Figure 8 quantifies the expected increase in spread when increasing the number of formats by evaluating 500 formats on 250 samples each and computing expected gains.</p>
<p>Figure 9 compares the efficiency of Thompson sampling, UCB, and naive sampling for estimating spread with respect to a budget $E$ (Section 3.2). To ensure accurate reports, we compute and show the true spread of the highest- and lowest-performing formats chosen by each method using all data. With a budget of 51,200 evaluations, Thompson sampling results in a spread within 1 accuracy point of the true spread, while naive sampling finds a spread within 4 points, and UCB within 11.</p>
<p>Finally, we use FormatSpread to measure sensitivity of several models where inference is expensive. With a budget of 40,000 evaluations and 320 prompt formats, we find that 1-shot LLaMA-2-70B-ran using 4-bit quantization (Dettmers et al., 2022)-yields a median spread of 0.171 (mean $=0.221$, std $=0.200$, using probability ranking across 53 tasks; $25 \%$ of tasks had a spread of 0.292 or higher, with a maximum spread of 0.876 ), and GPT-3.5 yields a median spread of 0.064 (mean $=0.110$, std $=0.115$, across 53 tasks using exact prefix matching given that we do not have access to the full logits; $25 \%$ of tasks had a spread of 0.148 or higher, with a maximum spread of 0.562 ), showing sensitivity to formatting is still present even on larger models. 5-shot LLaMA-270B still shows high spreads, with $25 \%$ of tasks having a spread of 0.310 and a maximum of 0.841 . See spread visualization in Figure 25, and a list of best and worst formats found in Table 6.</p>
<h1>5 Related Work</h1>
<p>The task of automatically finding the best-performing prompt for a given task without changing model parameters has recently gained attention, given the constantly improving yet somewhat unpredictable performance of LLMs. Prior work has often focused on discovering optimal prompts with gradient-based methods, which are effective, but often lead to disfluent or unnatural prompts (Shin</p>
<p>et al., 2020), which can be mitigated with a Langevin dynamics-based method (Shi et al., 2022). Another approach is to learn, optimize, and insert continuous representations of prompts and tasks as input to models (Qin \&amp; Eisner, 2021; Lester et al., 2021; Ding et al., 2022; Itharco et al., 2023). These methods also require access to the LLM's parameters, thus cannot be applied to models behind an API. In contrast, FORMATSPREAD does not assume access to any model internals. Prior gradientfree work has focused on edit-based enumeration over human-written prompts (Prasad et al., 2023), reinforcement learning (Deng et al., 2022), and by using LLMs themselves (Zhou et al., 2023; Gao et al., 2021). These works aim to achieve competitive task performance, even if the meaning of the prompt or instruction is modified. To our knowledge, we are the first to focus specifically on prompt formatting variance, a quintessential example of semantic equivalence.</p>
<p>Jailbreaking refers to the behavior of intentionally manipulating prompts to elicit inappropriate or sensitive responses, or otherwise reveal parts of the prompt that were intentionally not revealed. While the objective differs from our work, jailbreaking works (Wei et al., 2023; Zou et al., 2023) share the underlying technical question of finding the lowest-performing prompt. Our methods differ, since Wei et al. (2023) evaluate human-generated attacks to guide adversarial prompt design, and Zou et al. (2023) uses gradient-based search methods simultaneously across multiple models.</p>
<p>Some existing work has explored the influence of certain prompt design choices on model performance, for example the prompt's language (Gonen et al., 2022), the ordering of few-shot examples (Lu et al., 2022), and their patterns (Madaan et al., 2023). Other work has focused on providing textual interpretations of continuous prompt representations (Khashabi et al., 2022). Beyond autoregressive LLMs, existing work has focused on performance variance in masked language models (Elazar et al., 2021; Jiang et al., 2020). Our work follows efforts in other domains that explore the influence of spurious features on research evaluations, e.g., in deep reinforcement learning (Islam et al., 2017; Henderson et al., 2018) and statistical machine translation (Clark et al., 2011).</p>
<h1>6 DISCUSSION</h1>
<p>We introduce FORMATSPREAD, an algorithm that estimates the performance spread across prompt formatting choices. ${ }^{6}$ We use FORMATSPREAD to evaluate the spread of several widely-used opensource LLMs for classification tasks in few-shot learning settings. We find that spread is large regardless of model choice, even when increasing model size, number of few-shots, or when using instruction tuning. FORMATSPREAD is designed to efficiently search the space of plausible prompt formats under a user-specified computational budget. For example, with a computational budget of exploring only $5 \%$ of the entire search space for task with 2,500 test examples and 320 plausible formats, we are able to estimate spread within 2 accuracy points of the true spread.</p>
<p>We also characterize the space of prompt formats, finding that it is largely non-monotonic and that few atomic features can be predictors of performance alone, although the separability of format embeddings is highly correlated with observed performance spread. These findings informed the design of our search procedure, where local search methods are not advantageous.</p>
<p>Our findings suggest that performance spread caused by arbitrary prompt formatting choices may influence conclusions made about model performance, especially when comparing models on benchmark tasks. Thus, we recommend that work evaluating LLMs with prompting-based methods would benefit from reporting a range of performance across plausible formats. However, we want to emphasize that single-format evaluation may still be sufficient for many use cases. For example, for researchers or practitioners who build systems on top of LLMs, choosing a single prompt format that works sufficiently well for use in this larger system is a valid methodological choice. However, we encourage future research to compute FORMATSPREAD when comparing their systems to out-of-the-box models, to ensure fair baseline representation. Furthermore, FORMATSPREAD can be used to identify lower-bound performance of a model or system. For example, when using a model for socially impactful tasks, such as stereotype classification in Figure 1, it is important to report the range of accuracy a non-adversarial user might encounter. Likewise, it is crucial to consider robustness to spurious features when claiming that models possess general abilities, such as theory of mind; and beneficial to report when e.g. exploring model biases. We leave it to future research to develop regularization procedures either during training or with an already-trained model to make models robust to diverse formatting choices.</p>
<p><sup id="fnref4:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<h1>7 ACKNOWLEDGEMENTS</h1>
<p>We thank Jillian Fisher, Sachin Kumar, Angela Zhou, and the Berkeley NLP group for valuable discussions. This work was conducted while A.S. was a Young Investigator at AI2. This material is based upon work partly funded by the DARPA CMO under Contract No. HR001120C0124, by DARPA MCS program through NIWC Pacific (N66001-19-2-4031), by NSF DMS-2134012, IIS2125201, IIS-2203097, by NSF CAREER Grant No. IIS2142739, and an Alfred P. Sloan Foundation Fellowship. Any opinions, findings and conclusions or recommendations expressed in this material are those of the authors and do not necessarily state or reflect those of the United States Government or any agency thereof.</p>
<h2>REFERENCES</h2>
<p>Armen Aghajanyan. Tweet: Susan \&amp; I found MMLU performance jump 6-10 points in the 40 s by formatting multiple choice as (A) not A in MMLU (for internal model). All evaluation of LLM's are broken. Evaluating a task requires marginalizing across all prompts that describe the task, not point estimate of one. June 2023. URL https://twitter.com/ArmenAgha/status/1669084129261162497.</p>
<p>Ebtesam Almazrouei, Hamza Alobeidli, Abdulaziz Alshamsi, Alessandro Cappelli, Ruxandra Cojocaru, Merouane Debbah, Etienne Goffinet, Daniel Heslow, Julien Launay, Quentin Malartic, Badreddine Noune, Baptiste Pannier, and Guilherme Penedo. Falcon-40B: an open large language model with state-of-the-art performance. 2023.</p>
<p>Olivier Chapelle and Lihong Li. An empirical evaluation of thompson sampling. Advances in neural information processing systems, 24, 2011.</p>
<p>Tianqi Chen and Carlos Guestrin. XGBoost: A scalable tree boosting system. In Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD '16, pp. 785-794, New York, NY, USA, 2016. ACM. ISBN 978-1-4503-4232-2. doi: 10.1145/ 2939672.2939785. URL http://doi.acm.org/10.1145/2939672.2939785.</p>
<p>Jonathan H Clark, Chris Dyer, Alon Lavie, and Noah A Smith. Better hypothesis testing for statistical machine translation: Controlling for optimizer instability. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, pp. $176-181,2011$.</p>
<p>Mingkai Deng, Jianyu Wang, Cheng-Ping Hsieh, Yihan Wang, Han Guo, Tianmin Shu, Meng Song, Eric Xing, and Zhiting Hu. RLPrompt: Optimizing discrete text prompts with reinforcement learning. In Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, pp. 3369-3391, Abu Dhabi, United Arab Emirates, December 2022. Association for Computational Linguistics. doi: 10.18653/v1/2022.emnlp-main.222. URL https://aclanthology.org/2022.emnlp-main. 222.</p>
<p>Tim Dettmers, Mike Lewis, Younes Belkada, and Luke Zettlemoyer. GPT3.int8(): 8-bit matrix multiplication for transformers at scale. In Alice H. Oh, Alekh Agarwal, Danielle Belgrave, and Kyunghyun Cho (eds.), Advances in Neural Information Processing Systems, 2022. URL https://openreview.net/forum?id=dXiGWqBoxaD.</p>
<p>Ning Ding, Shengding Hu, Weilin Zhao, Yulin Chen, Zhiyuan Liu, Haitao Zheng, and Maosong Sun. Openprompt: An open-source framework for prompt-learning. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics: System Demonstrations, pp. $105-113,2022$.</p>
<p>Yanai Elazar, Nora Kassner, Shauli Ravfogel, Abhilasha Ravichander, Eduard Hovy, Hinrich Schütze, and Yoav Goldberg. Measuring and improving consistency in pretrained language models. Transactions of the Association for Computational Linguistics, 9:1012-1031, 2021.</p>
<p>Tianyu Gao, Adam Fisch, and Danqi Chen. Making pre-trained language models better few-shot learners. pp. 3816-3830, August 2021. doi: 10.18653/v1/2021.acl-long.295. URL https: //aclanthology.org/2021.acl-long. 295.</p>
<p>Hila Gonen, Srini Iyer, Terra Blevins, Noah A Smith, and Luke Zettlemoyer. Demystifying prompts in language models via perplexity estimation. arXiv preprint arXiv:2212.04037, 2022.</p>
<p>Peter Henderson, Riashat Islam, Philip Bachman, Joelle Pineau, Doina Precup, and David Meger. Deep reinforcement learning that matters. In Proceedings of the AAAI conference on artificial intelligence, volume 32, 2018.</p>
<p>Or Honovich, Uri Shaham, Samuel R. Bowman, and Omer Levy. Instruction induction: From few examples to natural language task descriptions. pp. 1935-1952, July 2023. doi: 10.18653/v1/ 2023.acl-long.108. URL https://aclanthology.org/2023.acl-long. 108.</p>
<p>Gabriel Ilharco, Marco Tulio Ribeiro, Mitchell Wortsman, Suchin Gururangan, Ludwig Schmidt, Hannaneh Hajishirzi, and Ali Farhadi. Editing models with task arithmetic. In International Conference on Learning Representations, 2023.</p>
<p>Riashat Islam, Peter Henderson, Maziar Gomrokchi, and Doina Precup. Reproducibility of benchmarked deep reinforcement learning tasks for continuous control. arXiv preprint arXiv:1708.04133, 2017.</p>
<p>Zhengbao Jiang, Frank F Xu, Jun Araki, and Graham Neubig. How can we know what language models know? Transactions of the Association for Computational Linguistics, 8:423-438, 2020.</p>
<p>Daniel Khashabi, Xinxi Lyu, Sewon Min, Lianhui Qin, Kyle Richardson, Sean Welleck, Hannaneh Hajishirzi, Tushar Khot, Ashish Sabharwal, Sameer Singh, and Yejin Choi. Prompt waywardness: The curious case of discretized interpretation of continuous prompts. In Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pp. 3631-3643, Seattle, United States, July 2022. Association for Computational Linguistics. doi: 10.18653/v1/2022.naacl-main.266. URL https://aclanthology.org/2022.naacl-main. 266.</p>
<p>Tze Leung Lai, Herbert Robbins, et al. Asymptotically efficient adaptive allocation rules. Advances in applied mathematics, 6(1):4-22, 1985.</p>
<p>Brian Lester, Rami Al-Rfou, and Noah Constant. The power of scale for parameter-efficient prompt tuning. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pp. 3045-3059, 2021.</p>
<p>Chin-Yew Lin. Rouge: A package for automatic evaluation of summaries. In Text summarization branches out, pp. 74-81, 2004.</p>
<p>Yao Lu, Max Bartolo, Alastair Moore, Sebastian Riedel, and Pontus Stenetorp. Fantastically ordered prompts and where to find them: Overcoming few-shot prompt order sensitivity. pp. 80868098, May 2022. doi: 10.18653/v1/2022.acl-long.556. URL https://aclanthology. org/2022.acl-long.556.</p>
<p>Aman Madaan, Katherine Hermann, and Amir Yazdanbakhsh. What makes chain-of-thought prompting effective? a counterfactual study. In Findings of the Association for Computational Linguistics: EMNLP 2023, pp. 1448-1535, 2023.</p>
<p>Moin Nadeem, Anna Bethke, and Siva Reddy. Stereoset: Measuring stereotypical bias in pretrained language models. In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pp. 5356-5371, 2021.</p>
<p>Archiki Prasad, Peter Hase, Xiang Zhou, and Mohit Bansal. GrIPS: Gradient-free, edit-based instruction search for prompting large language models. pp. 3845-3864, May 2023. doi: 10.18653/ v1/2023.eacl-main.277. URL https://aclanthology.org/2023.eacl-main. 277.</p>
<p>Reid Pryzant, Dan Iter, Jerry Li, Yin Tat Lee, Chenguang Zhu, and Michael Zeng. Automatic prompt optimization with" gradient descent" and beam search. arXiv preprint arXiv:2305.03495, 2023.</p>
<p>Guanghui Qin and Jason Eisner. Learning how to ask: Querying lms with mixtures of soft prompts. In Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT), 2021.</p>
<p>Timo Schick, Sahana Udupa, and Hinrich Schütze. Self-diagnosis and self-debiasing: A proposal for reducing corpus-based bias in nlp. Transactions of the Association for Computational Linguistics, 9:1408-1424, 2021.</p>
<p>John Schulman, Barret Zoph, Christina Kim, Jacob Hilton, Jacob Menick, Jiayi Weng, Juan Felipe Ceron Uribe, Liam Fedus, Luke Metz, Michael Pokorny, et al. Chatgpt: Optimizing language models for dialogue. OpenAI blog, 2022.</p>
<p>Weijia Shi, Xiaochuang Han, Hila Gonen, Ari Holtzman, Yulia Tsvetkov, and Luke Zettlemoyer. Toward human readable prompt tuning: Kubrick's the shining is a good movie, and a good prompt too? arXiv preprint arXiv:2212.10539, 2022.</p>
<p>Taylor Shin, Yasaman Razeghi, Robert L. Logan IV, Eric Wallace, and Sameer Singh. AutoPrompt: Eliciting Knowledge from Language Models with Automatically Generated Prompts. pp. 4222-4235, November 2020. doi: 10.18653/v1/2020.emnlp-main.346. URL https: //aclanthology.org/2020.emnlp-main. 346.</p>
<p>Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, et al. Llama 2: Open foundation and fine-tuned chat models. arXiv preprint arXiv:2307.09288, 2023.</p>
<p>Yizhong Wang, Swaroop Mishra, Pegah Alipoormolabashi, Yeganeh Kordi, Amirreza Mirzaei, Atharva Naik, Arjun Ashok, Arut Selvan Dhanasekaran, Anjana Arunkumar, David Stap, Eshaan Pathak, Giannis Karamanolakis, Haizhi Lai, Ishan Purohit, Ishani Mondal, Jacob Anderson, Kirby Kuznia, Krima Doshi, Kuntal Kumar Pal, Maitreya Patel, Mehrad Moradshahi, Mihir Parmar, Mirali Purohit, Neeraj Varshney, Phani Rohitha Kaza, Pulkit Verma, Ravsehaj Singh Puri, Rushang Karia, Savan Doshi, Shailaja Keyur Sampat, Siddhartha Mishra, Sujan Reddy A, Sumanta Patro, Tanay Dixit, and Xudong Shen. Super-NaturalInstructions: Generalization via declarative instructions on 1600+ NLP tasks. pp. 5085-5109, December 2022. doi: 10.18653/v1/2022.emnlp-main. 340. URL https://aclanthology.org/2022.emnlp-main. 340.</p>
<p>Alexander Wei, Nika Haghtalab, and Jacob Steinhardt. Jailbroken: How does llm safety training fail? arXiv preprint arXiv:2307.02483, 2023.</p>
<p>Jules White, Quchen Fu, Sam Hays, Michael Sandborn, Carlos Olea, Henry Gilbert, Ashraf Elnashar, Jesse Spencer-Smith, and Douglas C Schmidt. A prompt pattern catalog to enhance prompt engineering with chatgpt. arXiv preprint arXiv:2302.11382, 2023.</p>
<p>Tianyi Zhang, Varsha Kishore, Felix Wu, Kilian Q Weinberger, and Yoav Artzi. Bertscore: Evaluating text generation with bert. In International Conference on Learning Representations, 2019.</p>
<p>Yongchao Zhou, Andrei Ioan Muresanu, Ziwen Han, Keiran Paster, Silviu Pitis, Harris Chan, and Jimmy Ba. Large language models are human-level prompt engineers. In The Eleventh International Conference on Learning Representations, 2023. URL https://openreview.net/ forum?id=92gvk82DE-.</p>
<p>Andy Zou, Zifan Wang, J Zico Kolter, and Matt Fredrikson. Universal and transferable adversarial attacks on aligned language models. arXiv preprint arXiv:2307.15043, 2023.</p>
<h1>A Grammar Definition and InStantIation Details</h1>
<h2>A. 1 Equivalence Relation Definition</h2>
<p>Precisely, $p_{1} \sim p_{2}$ if and only if at least one of the following hold: $p_{1}=p_{2}=B_{0}$; or $p_{i}=$ $B_{0}^{\prime}\left(d_{i}, s_{i}\right)$ with $d_{1}=d_{2}$; or $p_{i}=B_{1}\left(d_{i}, s_{i}, f_{i}\right)$ with $d_{1}=d_{2}$; or $p_{i}=B_{2}^{(n)}\left(X_{1, i}, \ldots, X_{n, i}, c_{i}\right)$ with $X_{j, 1} \sim X_{j, 2} \forall 1 \leq j \leq n$; or $p_{i}=B_{3}^{(n)}\left(d_{i}, j_{1, i}, \ldots, j_{n, i}, s_{1}, s_{2}, c, f\right)$ where $d_{1}=d_{2}$ and $j_{k, 1}=j_{k, 2} \forall 1 \leq k \leq n$. It is possible that generated formats equivalent in their string representation are not equivalent according to this equivalence relation.</p>
<h2>A.1.1 Visualization of Prompt Format's Parsing and Full Format Generation</h2>
<p><img alt="img-9.jpeg" src="img-9.jpeg" /></p>
<p>Figure 10: Visualization of a complex prompt format showing its parsing and which constants or functions affect each part of the format.</p>
<p>Figure 10 shows a visualization of how a complex format is parsed using our defined grammar. A full prompt consists of an instruction, n few-shots and a data point to solve. For example, if the instruction was Given a sentence and two words that appear in it, answer which one of the two (A or B) appeared first in the sentence., a full prompt may look as follow. Note that we always use $\backslash \mathrm{n} \backslash \mathrm{n}$ as space character between instruction and few-shots. The example below shows a 1-shot prompt. It is simply illustrative and does not correspond to any of the tasks considered.</p>
<div class="codehilite"><pre><span></span><code><span class="nt">Given</span><span class="w"> </span><span class="nt">a</span><span class="w"> </span><span class="nt">sentence</span><span class="w"> </span><span class="nt">and</span><span class="w"> </span><span class="nt">two</span><span class="w"> </span><span class="nt">words</span><span class="w"> </span><span class="nt">that</span><span class="w"> </span><span class="nt">appear</span><span class="w"> </span><span class="nt">in</span><span class="w"> </span><span class="nt">it</span><span class="o">,</span><span class="w"> </span><span class="nt">answer</span><span class="w"> </span><span class="nt">which</span><span class="w"> </span><span class="nt">one</span><span class="w"> </span><span class="nt">of</span>
<span class="nt">the</span><span class="w"> </span><span class="nt">two</span><span class="w"> </span><span class="o">(</span><span class="nt">A</span><span class="w"> </span><span class="nt">or</span><span class="w"> </span><span class="nt">B</span><span class="o">)</span><span class="w"> </span><span class="nt">appeared</span><span class="w"> </span><span class="nt">first</span><span class="w"> </span><span class="nt">in</span><span class="w"> </span><span class="nt">the</span><span class="w"> </span><span class="nt">sentence</span><span class="o">.</span>
<span class="nt">The</span><span class="w"> </span><span class="nt">quick</span><span class="w"> </span><span class="nt">brown</span><span class="w"> </span><span class="nt">fox</span><span class="w"> </span><span class="nt">jumps</span>
<span class="nt">OPTIONS</span><span class="o">:</span>
<span class="nt">CHOICE</span><span class="w"> </span><span class="o">(</span><span class="nt">A</span><span class="o">):</span><span class="w"> </span><span class="nt">fox</span><span class="w"> </span><span class="o">;</span><span class="w"> </span><span class="nt">CHOICE</span><span class="w"> </span><span class="o">(</span><span class="nt">B</span><span class="o">):</span><span class="w"> </span><span class="nt">brown</span>
<span class="nt">ANSWER</span><span class="o">:</span><span class="w"> </span><span class="nt">B</span>
<span class="nt">Over</span><span class="w"> </span><span class="nt">the</span><span class="w"> </span><span class="nt">lazy</span><span class="w"> </span><span class="nt">dog</span>
<span class="nt">OPTIONS</span><span class="o">:</span>
<span class="nt">CHOICE</span><span class="w"> </span><span class="o">(</span><span class="nt">A</span><span class="o">):</span><span class="w"> </span><span class="nt">lazy</span><span class="w"> </span><span class="o">;</span><span class="w"> </span><span class="nt">CHOICE</span><span class="w"> </span><span class="o">(</span><span class="nt">B</span><span class="o">):</span><span class="w"> </span><span class="nt">dog</span>
<span class="nt">ANSWER</span><span class="o">:</span>
</code></pre></div>

<p>FormatSpreAd forces all instantiations of a multiple choice variable to change jointly to maintain coherence, and this includes text in the instruction. Therefore, when changing the option items from A and B to I and II, the prompt will be generated as follows.</p>
<div class="codehilite"><pre><span></span><code><span class="nt">Given</span><span class="w"> </span><span class="nt">a</span><span class="w"> </span><span class="nt">sentence</span><span class="w"> </span><span class="nt">and</span><span class="w"> </span><span class="nt">two</span><span class="w"> </span><span class="nt">words</span><span class="w"> </span><span class="nt">that</span><span class="w"> </span><span class="nt">appear</span><span class="w"> </span><span class="nt">in</span><span class="w"> </span><span class="nt">it</span><span class="o">,</span><span class="w"> </span><span class="nt">answer</span><span class="w"> </span><span class="nt">which</span><span class="w"> </span><span class="nt">one</span><span class="w"> </span><span class="nt">of</span>
<span class="nt">the</span><span class="w"> </span><span class="nt">two</span><span class="w"> </span><span class="o">(</span><span class="nt">I</span><span class="w"> </span><span class="nt">or</span><span class="w"> </span><span class="nt">II</span><span class="o">)</span><span class="w"> </span><span class="nt">appeared</span><span class="w"> </span><span class="nt">first</span><span class="w"> </span><span class="nt">in</span><span class="w"> </span><span class="nt">the</span><span class="w"> </span><span class="nt">sentence</span><span class="o">.</span>
<span class="nt">The</span><span class="w"> </span><span class="nt">quick</span><span class="w"> </span><span class="nt">brown</span><span class="w"> </span><span class="nt">fox</span><span class="w"> </span><span class="nt">jumps</span>
<span class="nt">OPTIONS</span><span class="o">:</span>
<span class="nt">CHOICE</span><span class="w"> </span><span class="o">(</span><span class="nt">I</span><span class="o">):</span><span class="w"> </span><span class="nt">fox</span><span class="w"> </span><span class="o">;</span><span class="w"> </span><span class="nt">CHOICE</span><span class="w"> </span><span class="o">(</span><span class="nt">II</span><span class="o">):</span><span class="w"> </span><span class="nt">brown</span>
<span class="nt">ANSWER</span><span class="o">:</span><span class="w"> </span><span class="nt">II</span>
<span class="nt">Over</span><span class="w"> </span><span class="nt">the</span><span class="w"> </span><span class="nt">lazy</span><span class="w"> </span><span class="nt">dog</span>
<span class="nt">OPTIONS</span><span class="o">:</span>
<span class="nt">CHOICE</span><span class="w"> </span><span class="o">(</span><span class="nt">I</span><span class="o">):</span><span class="w"> </span><span class="nt">lazy</span><span class="w"> </span><span class="o">;</span><span class="w"> </span><span class="nt">CHOICE</span><span class="w"> </span><span class="o">(</span><span class="nt">II</span><span class="o">):</span><span class="w"> </span><span class="nt">dog</span>
<span class="nt">ANSWER</span><span class="o">:</span>
</code></pre></div>

<h1>A. 2 ALLOWED VALUES FOR EACH SET $\mathcal{S}<em 2="2">{1}, \mathcal{S}</em>}, \mathcal{C}, \mathcal{F<em _ITEM="{ITEM" _text="\text">{\text {CASING }}, \mathcal{F}</em>$}</h1>
<p>$$
\begin{aligned}
&amp; \mathcal{S}<em 2="2">{1}=\left{{ }^{\prime \prime}, \prime^{\prime}, \prime^{\prime}, \backslash \mathrm{n}^{\prime}, \backslash \mathrm{n}^{\prime}, \mathrm{n}^{\prime},--^{\prime}, \prime^{\prime}, \prime^{\prime} ; \backslash \mathrm{n}^{\prime}, \prime\left|^{\prime}, \prime&lt;\operatorname{sep}&gt;\right.^{\prime}, \prime--^{\prime}, \prime, \prime^{\prime}, \backslash \mathrm{n}^{\prime}, \prime, \prime^{\prime}, \backslash \mathrm{n}^{\prime}, \prime, \prime^{\prime}, \prime,^{\prime}\right} \
&amp; \mathcal{S}</em> \
&amp; \mathcal{C}=\left{{ }^{\prime \prime}, \prime::^{\prime}, \prime^{\prime}::^{\prime}, \prime^{\prime}, \prime^{\prime}, \backslash \mathrm{n} \backslash \mathrm{t}^{\prime}, \backslash \mathrm{n}^{\prime}, \prime^{\prime}:^{\prime}, \prime,-^{\prime}, \prime^{\prime}, \prime^{\prime} \backslash \mathrm{n}^{\prime}, \backslash \mathrm{n} \backslash \mathrm{t}^{\prime}, \prime^{\prime}, \prime^{\prime}::^{\prime}, \prime-^{\prime}, \backslash \mathrm{t}^{\prime}\right} \
&amp; \mathcal{F}}=\left{{ }^{\prime \prime}, \prime^{\prime}, \prime^{\prime}, \prime^{\prime}, \backslash \mathrm{t}^{\prime}\right} \text { (no space, single space, double space, tab) <em _item="{item" _text="\text">{\text {casing }}=\left{\mathbf{f}(\mathrm{x})=\mathrm{x}, \mathbf{f}(\mathrm{x})=\mathrm{x} . \text { title }(), \mathbf{f}(\mathrm{x})=\mathrm{x} . \text { upper }(), \mathbf{f}(\mathrm{x})=\mathrm{x} . \text { lower }()\right} \
&amp; \mathcal{F}</em>}}=\left{x \mapsto f(g(x)) \mid \text { such that } f \in \mathcal{F<em _item2="{item2" _text="\text">{\text {item1 }} \wedge g \in \mathcal{F}</em>\right} \
&amp; \mathcal{F}}<em _item2="{item2" _text="\text">{\text {item1 }}=\left{\mathrm{x} \mapsto(\mathrm{x}), \mathrm{x} \mapsto \mathrm{x} ., \mathrm{x} \mapsto \mathrm{x}), \mathrm{x} \mapsto \mathrm{x} ., \mathrm{x} \mapsto[\mathrm{x}], \mathrm{x} \mapsto&lt;\mathrm{x}&gt;\right} \
&amp; \mathcal{F}</em>\right. \
&amp; \left.\mathrm{x} \rightarrow 0 \mathrm{x} 215 \mathrm{~F}+\mathrm{x}+1, \mathrm{x} \rightarrow \operatorname{ROMAN}[\mathrm{x}] . \text { lower }(), \mathrm{x} \rightarrow \operatorname{ROMAN}[\mathrm{x}] . \text { upper }()\right}
\end{aligned}
$$}}=\left{\mathrm{x} \rightarrow \mathrm{x}+1, \mathrm{x} \rightarrow{ }^{\prime} \mathrm{A}^{\prime}+\mathrm{x}, \mathrm{x} \rightarrow{ }^{\prime} \mathrm{a}^{\prime}+\mathrm{x</p>
<p>Enumerations are indexed from (i.e., "1, 2, 3" rather than "0, 1, 2"). ROMAN[x] represents the Roman numerals written in regular ASCII characters. ' $0 \times 215 \mathrm{~F}^{\prime}+\mathrm{x}$ represent the series of Unicode characters for Roman numerals. ... denotes a spacing character for clarity.</p>
<h2>A. 3 RESTRICTIONS TO PROMPT FORMATS SPACES AND SEPARATORS' COMBINATIONS</h2>
<p>We define several restrictions to ensure format naturalness. Users can additionally customize FORMATSPREAD by defining their own rules and restrictions between values. Our rules are as follows:</p>
<ul>
<li>If $B_{2}\left(X_{1}, \ldots, X_{n}, c\right)$ where $c$ does not contain a newline, then each $X_{i}$ 's separators and any subcomponents' separators should not contain a newline.</li>
<li>Similar to the rule above, if $B_{3}^{(n)}\left(d, j_{1}, \ldots, j_{n}, s_{1}, s_{2}, c, f_{1}, f_{2}\right)$ such that some separator contains a newline (i.e. $s_{1}$ contains a newline and/or $s_{2}$ contains a newline) then the space $c$ must also contain a newline.</li>
<li>For $B_{1}(d, s, f):=f(d) s&lt;$ text $&gt;, s$ must not be the empty string (i.e., there has to be some separation between descriptor and text).</li>
<li>Having $c$ be an empty string space in $B_{2}^{(n)}$ is only allowed if the first $n-1$ components are $B_{1}$ fields with an empty <text>. Similarly, the newline restrictions mentioned above only apply if the <text> is not empty. This rarely happens in prompt formats, but there are formats such as Question: <text> Options: A. <text> B. <text> where the Options: do not have a corresponding field.</li>
</ul>
<h2>A. 4 THOMPSON SAMPLING PriORS</h2>
<p>For the first exploration (i.e., finding the best-performing prompt format), we set an informative prior $\operatorname{Beta}(\alpha, \beta):=\operatorname{Beta}\left(\max \left(\frac{\beta \cdot x}{1-x}, 1.1\right), 5\right)$ for all arms $p_{i}$, where $x$ is the original format's accuracy. Our goal is to set an informative prior where the expected value of the prior distribution is the original format accuracy $x$, since a priori it is the only information we have about performance.</p>
<p>This restricts the parameters as follows:</p>
<p>$$
\begin{aligned}
\mathbb{E}[\operatorname{Beta}(\alpha, \beta)]=\frac{\alpha}{\alpha+\beta} &amp; =x \
\alpha &amp; =\alpha \cdot x+\beta \cdot x \
\alpha &amp; =\frac{\beta \cdot x}{1-x}
\end{aligned}
$$</p>
<p>Since $\beta$ will modulate how confident is the prior, and we want to avoid the model being overconfident, we fix $\beta=5$. Because we want to have an informative prior $\operatorname{Beta}(\alpha, \beta)$ with a Gaussian-like PDF, we force $\alpha&gt;1$ and $\beta&gt;1$. In extreme cases, forcing $\alpha&gt;1$ might alter the expected value. The first exploration's priors are thus exactly $\operatorname{Beta}(\alpha, \beta)$ with $\alpha=\max \left(\frac{\beta \cdot x}{1-x}, 1.1\right)$ and $\beta=5$ for all arms $p_{i}$.</p>
<p>For the second exploration (i.e., finding the worst-performing prompt format), the model has access to the first explorations' counters $S_{i}^{(E / B)}$ and $N_{i}^{(E / B)}$. Therefore, we set the second exploration's priors to be $\operatorname{Beta}\left(\alpha+S_{i}^{(E / B)}, \beta+\left(N_{i}^{(E / B)}-S_{i}^{(E / B)}\right)\right)$.</p>
<h1>B Additional Experiments' Information and Plots</h1>
<h2>B. 1 TASK SELECTION</h2>
<p>We use a number of heuristics to filter Super-NaturalInstructions tasks to our set of 53 evaluation tasks. Datasets should have at least 1000 samples to be considered. We also remove tasks whose instructions are too long (over 3,000 characters) and datasets with inputs longer than 2,000 characters, given that this makes performing inference at scale intractable. We also filter datasets whose valid outputs include more than 20 different strings, given that we focus on classification tasks.</p>
<p>We also removed tasks where we found a priori performance on the task was $0 \%$ accuracy using LLaMA-2-7B 1-shot. Some Super-NaturalInstructions tasks are derived from the same original dataset, but ask different questions. We did not include more than 4 tasks from the same original dataset.</p>
<p>Finally, we also searched for having socially impactful tasks. Those tasks were the only SuperNaturalInstructions tasks where we included a format if one was not provided by the dataset.</p>
<p>The selected tasks were the following 53: task050, task065, task069, task070, task114, task133, task155, task158, task161, task162, task163, task190, task213, task214, task220, task279, task280, task286, task296, task297, task316, task317, task319, task320, task322, task323, task325, task326, task327, task328, task335, task337, task385, task580, task607, task608, task609, task904, task905, task1186, task1283, task1284, task1297, task1347, task1387, task1419, task1420, task1421, task1423, task1502, task1612, task1678, task1724.
<img alt="img-10.jpeg" src="img-10.jpeg" /></p>
<p>Figure 11: Comparison between Llama-2-7B and Llama-2-70B spreads. Llama-2-70B was computed using 4bit quantization (Dettmers et al., 2022).</p>
<p>B. 2 Additional Results for Section 4.2</p>
<p>Table 3: Ratio of prompt format pairs $\left(p_{1}, p_{2}\right)$ such that if $p_{1}$ is worse than $p_{2}$ using model $M_{1}$, then the same trend holds for $M_{2}$.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Model 1 <br> $\left(M_{1}\right)$</th>
<th style="text-align: center;">Model 2 <br> $\left(M_{2}\right)$</th>
<th style="text-align: center;">Performance Relative <br> Ordering Preservation</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Llama-2-7b</td>
<td style="text-align: center;">Llama-2-13b</td>
<td style="text-align: center;">$57.46 \%$</td>
</tr>
<tr>
<td style="text-align: left;">Llama-2-7b</td>
<td style="text-align: center;">Falcon-2-7b</td>
<td style="text-align: center;">$55.91 \%$</td>
</tr>
<tr>
<td style="text-align: left;">Falcon-7b</td>
<td style="text-align: center;">Falcon-7b-Inst</td>
<td style="text-align: center;">$61.11 \%$</td>
</tr>
</tbody>
</table>
<p><img alt="img-11.jpeg" src="img-11.jpeg" /></p>
<p>Figure 12: Probability of a prompt $p$ being worse than $p^{\prime}$ by at least $d$ points using model $M^{\prime}$, given that prompt $p$ was better than prompt $p^{\prime}$ when using model $M$.</p>
<p>Formats are not inherently good or bad. Table 3 shows that if format $p_{1}$ has lower performance than format $p_{2}$ under model $M$, there is $&lt;0.62$ probability that this trend would hold under another model $M^{\prime}$ (random chance is 0.5 ). This weak relative order preservation suggests that prompt format performance in a model may not be extrapolated to a different model, or in other words, that there are no inherently good or bad formats. This finding is further supported by Figure 12, which shows that findings of a format being better or worse than another are often inconsistent across models.</p>
<p>Experiments with exact prefix matching accuracy. Here we show results with using exact prefix matching to compute accuracy. Often, failures in prefix matching are associated with degeneration, i.e., cases where the model does not answer any of the valid options, motivating the use of ranking accuracy. Degeneration makes models (specially smaller models) more unlikely to have high accuracy out of the box. As seen in Figure 6, prefix matching is linked to having higher changes when performing atomic changes. Moreover, exact prefix matching can lead to lower performance as generation is less constrained (see Figure 16). Table 4 shows examples of atomic changes yielding large accuracy changes with exact prefix matching metric.</p>
<p>Figure 13c shows spread remains regardless of model size increase, architecture change, or number of few-shot examples also when using exact prefix matching as accuracy metric. In line with the results shown for probability ranking in Section 4.2, Figure 15 shows that the probability of reversing performance trends between two models just by changing prompt remains high when using exact prefix matching as metric. Strikingly, spread is significantly higher than in the probability ranking setting (see Figure 14), with median spread ranging from 12 to 28 accuracy points depending on the model used. This further motivates the need for running FORMATSPREAD when benchmarking models with this accuracy metric. This increased spread may be partly due to degeneration, as we will detail next.</p>
<p>Degeneration. Sometimes when a model does not generate the correct answer with exact prefix matching, it also does not generate a valid response, i.e. it degenerates. We will now quantify this phenomenon using 53 SuperNaturalInstructions classification and multiple choice tasks.</p>
<p>Given a model, a task, and a format, let the centered mass be the ratio of examples where the model's output matched with any valid option (regardless of correctness). Table 5 shows that the correlation between accuracy and centered mass is moderate or high depending on the model. This suggests that very often when a model does not return a valid answer, it does not return any valid answer</p>
<p><img alt="img-12.jpeg" src="img-12.jpeg" /></p>
<p>Figure 13: Spread comparison between evaluating the same task under different models or n-shots using exact prefix matching as accuracy metric.
<img alt="img-13.jpeg" src="img-13.jpeg" /></p>
<p>Figure 14: Spread across models and $n$-shots. Exact prefix matching metric.
<img alt="img-14.jpeg" src="img-14.jpeg" />
(a) Accuracy boxplot for the selected 53 Super Natural-Instructions tasks, option ranking metric.
<img alt="img-15.jpeg" src="img-15.jpeg" /></p>
<p>Figure 15: Probability that model $M$ performs worse than $M^{\prime}$ by at least $d$ when using format $p^{\prime}$, given that $M$ performed better than $M^{\prime}$ by at least $d$ using format $p .53$ tasks, 1- and 5-shot. Exact prefix matching metric.
<img alt="img-16.jpeg" src="img-16.jpeg" />
(b) Accuracy boxplot selected 53 Super NaturalInstructions tasks, exact prefix matching metric.</p>
<p>Figure 16: Accuracy metric used can strongly impact final performance. 53 Super NaturalInstructions tasks shown. Ranking accuracy yields higher accuracies overall.
at all. This is especially true for Falcon models, where we observe an almost perfect correlation between accuracy and centered mass. In conclusion, prompt format chosen often do not solely affect accuracy, but they also affect the frequency in which a model is actually able to perform a task. This will especially affect tasks for which there are no alternative metrics. Further research may focus specifically on targeting features that cause degeneration.</p>
<p>Experiments with Instruction Induction tasks. All experiments thus far focused solely on classification tasks. We will now focus on tasks that require generating (short) text, and cannot be framed as classification tasks. We selected 10 tasks from Instruction Induction (Honovich et al., 2023) that require generating a unique, valid string to be considered a correct response. Examples include identifying the second letter of a word, adding numbers, or answering a synonym to a given word. Instruction Induction tasks also show a wide range of difficulty, resulting in varied settings to be</p>
<p>Table 4: Examples of atomic changes' impact on accuracy using prefix matching (probability ranking shown in Table 2). $}$ represents a text field; $p_{2}$ yields higher accuracy than $p_{1}$ for all tasks.</p>
<table>
<thead>
<tr>
<th style="text-align: center;">Task Id</th>
<th style="text-align: center;">Prompt Format $1\left(p_{1}\right)$</th>
<th style="text-align: center;">Prompt Format $2\left(p_{2}\right)$</th>
<th style="text-align: center;">Acc $p_{1}$</th>
<th style="text-align: center;">Acc $p_{2}$</th>
<th style="text-align: center;">Diff.</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">task213</td>
<td style="text-align: center;">Title: {} Sentence $&lt;$ X $&gt;$ : {}</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">Sentence $&lt;$ X $&gt;$ : {}</td>
<td style="text-align: center;">Title:({} Sentence $&lt;$ X $&gt;$ : : {}</td>
<td style="text-align: center;">0.113</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">| Sentence $&lt;$ X $&gt;$ : {}</td>
<td style="text-align: center;">| Sentence $&lt;$ X $&gt;$ : : {}</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Sentence $&lt;$ C $&gt;$ : {} } }</td>
<td style="text-align: center;">Sentence $&lt;$ C $&gt;$ : : {}</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">$&lt;$ i $&gt;$ : : : {} } }</td>
<td style="text-align: center;">Sentence $&lt;$ C $&gt;$ : : {}</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">Answer: {}</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">task296</td>
<td style="text-align: center;">Sentence I : : {} \nSentence II</td>
<td style="text-align: center;">Sentence I ) : {} \nSentence II</td>
<td style="text-align: center;">0.201</td>
<td style="text-align: center;">0.522</td>
<td style="text-align: center;">0.321</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">) : {} \nSentence III ) : {}</td>
<td style="text-align: center;">) : {} \nSentence III ) : {}</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">\nSentence IV ) : {} \nSentence</td>
<td style="text-align: center;">\nSentence IV ) : {} \nSentence</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">V ) : {} \nSentence VI ) : {}</td>
<td style="text-align: center;">V ) : {} \nSentence VI ) : {}</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">\nSentence VII ) : {} \nSentence</td>
<td style="text-align: center;">\nSentence VII ) : {} \nSentence</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">VIII ) : {} \nSentence IX ) : {}</td>
<td style="text-align: center;">VIII ) : {} \nSentence IX ) : {}</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">\nSentence X ) : {}, I : {},</td>
<td style="text-align: center;">\nSentence X ) : {}, I, : {}</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">II. : {}, Answer: {}</td>
<td style="text-align: center;">, 2. : {}, Answer: {}</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">task905</td>
<td style="text-align: center;">Tweet::: {}, \nLabel::: {},</td>
<td style="text-align: center;">Tweet::{}, \nLabel::{},</td>
<td style="text-align: center;">0.252</td>
<td style="text-align: center;">0.559</td>
<td style="text-align: center;">0.307</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">\nAnswer::: {}</td>
<td style="text-align: center;">\nAnswer:: {}</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">task317</td>
<td style="text-align: center;">Passage:: {} \nAnswer:: {}</td>
<td style="text-align: center;">Passage::{} \nAnswer::{}</td>
<td style="text-align: center;">0.245</td>
<td style="text-align: center;">0.546</td>
<td style="text-align: center;">0.301</td>
</tr>
<tr>
<td style="text-align: center;">task280</td>
<td style="text-align: center;">passage {}\n answer {}</td>
<td style="text-align: center;">passage: {}\n answer: {}</td>
<td style="text-align: center;">0.332</td>
<td style="text-align: center;">0.612</td>
<td style="text-align: center;">0.28</td>
</tr>
<tr>
<td style="text-align: center;">task050</td>
<td style="text-align: center;">SENTENCE - {} \nQUESTION - {}</td>
<td style="text-align: center;">SENTENCE\n\t{} \nQUESTION\n\t{}</td>
<td style="text-align: center;">0.244</td>
<td style="text-align: center;">0.504</td>
<td style="text-align: center;">0.26</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">\nANSWER - {}</td>
<td style="text-align: center;">\nANSWER\n\t{}</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;">task070</td>
<td style="text-align: center;">Beginning - {}\nMiddle [I]{}</td>
<td style="text-align: center;">Beginning - {}\nMiddle I]{}</td>
<td style="text-align: center;">0.143</td>
<td style="text-align: center;">0.3</td>
<td style="text-align: center;">0.157</td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">, Middle [II]{}\nEnding -</td>
<td style="text-align: center;">, Middle II]{}\nEnding -</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr>
<td style="text-align: center;"></td>
<td style="text-align: center;">{} \nAnswer - {}</td>
<td style="text-align: center;">{} \nAnswer - {}</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
</tbody>
</table>
<p>Table 5: Correlation between accuracy using exact prefix matching and the centered mass (the opposite of degeneration). 53 tasks, 10 formats each, evaluated on 1000 samples.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Model</th>
<th style="text-align: center;">n-shot</th>
<th style="text-align: center;">correlation between accuracy <br> $\&amp;$ and centered mass</th>
<th style="text-align: center;">p-value</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Llama-2-7b</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0.702</td>
<td style="text-align: center;">$5.1 \mathrm{E}-77$</td>
</tr>
<tr>
<td style="text-align: left;">Llama-2-7b</td>
<td style="text-align: center;">5</td>
<td style="text-align: center;">0.762</td>
<td style="text-align: center;">$4.9 \mathrm{E}-98$</td>
</tr>
<tr>
<td style="text-align: left;">Llama-2-13b</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0.639</td>
<td style="text-align: center;">$5.8 \mathrm{E}-61$</td>
</tr>
<tr>
<td style="text-align: left;">Llama-2-13b</td>
<td style="text-align: center;">5</td>
<td style="text-align: center;">0.662</td>
<td style="text-align: center;">$9.2 \mathrm{E}-67$</td>
</tr>
<tr>
<td style="text-align: left;">falcon-7b</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0.936</td>
<td style="text-align: center;">$7.1 \mathrm{E}-233$</td>
</tr>
<tr>
<td style="text-align: left;">falcon-7b</td>
<td style="text-align: center;">5</td>
<td style="text-align: center;">0.933</td>
<td style="text-align: center;">$8.4 \mathrm{E}-228$</td>
</tr>
<tr>
<td style="text-align: left;">falcon-7b-instruct</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">0.962</td>
<td style="text-align: center;">$3.6 \mathrm{E}-289$</td>
</tr>
<tr>
<td style="text-align: left;">falcon-7b-instruct</td>
<td style="text-align: center;">5</td>
<td style="text-align: center;">0.958</td>
<td style="text-align: center;">$5.5 \mathrm{E}-277$</td>
</tr>
</tbody>
</table>
<p>analyzed (see Figure 18b). Given that the collection does not contain human-generated formats, we applied a simple 'Input: {}\n Output: {}' format. Results for 1-shot and 5-shot settings show spread is still high across models and n-shot choices (see Figure 17).</p>
<p>Tasks are: antonyms, diff, first_word_letter, larger_animal, letters_list, num_to_verbal, second_word_letter, singular_to_plural, sum, synonyms.
<img alt="img-17.jpeg" src="img-17.jpeg" /></p>
<p>Figure 17: Spread comparison between evaluating the same task under different models or n-shots for Instruction Induction tasks. Exact prefix matching used as accuracy metric.</p>
<p><img alt="img-18.jpeg" src="img-18.jpeg" /></p>
<p>Figure 18: Instruction Induction tasks' spreads and accuracy across models. Exact prefix matching is used as accuracy metric.</p>
<p>Experiments with continuous metrics in open-ended text generation tasks. Throughout the paper we focus on tasks with a single valid output, whether in classification tasks or in short-text generation tasks. This decision is intentional, since it guarantees that a variation in the metric truly represents a variation in model performance. We have shown that spread remains high when considering option ranking or exact prefix matching as accuracy metric.</p>
<p>Since LLMs are often used in more open-ended generation contexts, we will now explore the performance variance across prompt formats when considering sentence-length generation tasks (e.g. generate the next sentence of a story, given the four initial sentences of a story, generate a question whose answer is the sentence given). To analyze the automatic generations, we use two widely used metrics: ROUGE-L (Lin, 2004), and BERTScore (Zhang et al., 2019). The first is an n-gram-based metric, and the latter is a model-based metric, and both are $[0,1]$ metrics where higher is better. Figure 19 shows that variance remains high for LLaMA-2-7B regardless of the metric and the number of n-shots considered, with LLaMA-2-7B 5-shot having $25 \%$ of tasks with a ROUGE-L spread of 0.098 or higher, and a BERTScore spread of 0.09 or higher.</p>
<p>We observe that the median spread is sometimes smaller than in the accuracy tasks. This may be because although ROUGE, BERTScore, and accuracy are all $[0,1]$ metrics, typical metric values may be different, which may in turn affect the final spread (an absolute difference). We leave it to future work to quantify the differences in style or content that each format may be inducing.</p>
<p>Finally, it is worth noting that text generation metrics are known to be noisier, and thus not all metric decreases necessarily correspond to a true performance loss, as is the case for accuracy in single-valid-output tasks. We used 17 SuperNatural Instructions tasks: task037, task038,
<img alt="img-19.jpeg" src="img-19.jpeg" /></p>
<p>Figure 19: Spread across n-shots for LLaMA-2-7B, considering ROUGE-L and BERTScore metrics. 17 sentence-level open-generation tasks are considered, all extracted from SuperNatural Instructions. 10 prompt formats are considered for each task.
task040, task067, task071, task072, task105, task216, task223, task240, task348, task389, task443, task845, task1326, task1401, task1613. We selected the 17 open-ended text generation tasks among those with at least 1000 samples, with some formatting present in the original task (e.g. 'Passage: ' <text>). We only considered tasks whose instructions were under 1,000 characters and that contained inputs no longer than 5,000 characters.</p>
<p>We limit generations to 50 tokens. To parse model outputs more faithfully, and given that none of our expected generations include a newline, we only consider a model’s generation up to the first newline (excluding leading spaces and newlines in a given generation). This consideration is important given that often models start to generate a new data sample from scratch, immediately after generating the requested answer.
Characterizing a model's accuracy distribution beyond spread. Spread gives a quantitative jump in information with respect to informing a single point in the performance distribution since it measures the distribution range (maximum minus minimum). However, distributions that may share the same range, may yield a widely different probability of obtaining each value in the distribution. Figure 20 plots the accuracy distribution of 30 tasks, sorted in decreasing order by standard deviation. Tasks with high standard deviation reflect a higher likelihood of obtaining dissimilar values when making a formatting selection; Figure 20 shows that the median standard distribution is $\sigma \approx 0.04$, which can be considered high in our context.
<img alt="img-20.jpeg" src="img-20.jpeg" /></p>
<p>Figure 20: Accuracy distribution across 500 formats for 30 tasks evaluated on 250 samples each, sorted by standard deviation in decreasing order. LLaMA-2-7B 1-shot, option ranking metric.</p>
<p>On factors influencing spread besides prompt formatting. We believe many factors beyond formatting may be influencing performance variance, but were unable to find a feature that reliably predicts spread. We found that the average prompt length in a task has a negligible correlation with its performance spread: $r=0.228\left(p=1.4 \times 10^{-7}\right)$ for exact prefix matching metric, and $r=-0.022(p=0.615)$ for option ranking metric, when jointly considering all models and nshots. Similarly, the standard deviation of the prompt length had negligible correlation with spread: $r=0.125(p=0.004)$ for exact prefix matching, and $r=-0.099(p=0.024)$ for option ranking metric. When considering each model individually, only LLaMA-2-7B with exact prefix matching showed a correlation $|r|&gt;0.5$, with the average prompt length having a correlation $r=0.559$ $p=6.86 \times 10^{-10}$. All other settings had $|r|&lt;0.36$.</p>
<h1>B. 3 PCA EXAMPLES</h1>
<p>Section 4.4 systematically analyzes whether we can predict the prompt format that generated a given pre-softmax activation layer (i.e., prompt embeddings) by using solely its top- $n$ principal components. Figure 21 shows the top two principal components for two different tasks where all 10 formats considered are easily identifiable solely with a prompt embedding's top two principal compoenents.
<img alt="img-21.jpeg" src="img-21.jpeg" /></p>
<p>Figure 21: Plot of the top two principal components of the last decoder layer of the prompt, as a representation of the output probability distribution. Two different tasks shown, with each prompt format shown in a different color.</p>
<h2>B. 4 Notable Features</h2>
<p>As discussed in Section 4.3, sometimes the choice of a constant may lead to significantly different accuracy ranges. Figures 22,23, and 24 show all strongly dissimilar choices of constants found on any given task, across 53 Super Natural-Instructions tasks, and on both accuracy metrics considered throughout the work. As can be appreciated, choices of constants do not consistently predict performance in isolation.</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>${ }^{6}$ We thoroughly describe the limitations of our method in Appendix C.&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref3:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref4:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>