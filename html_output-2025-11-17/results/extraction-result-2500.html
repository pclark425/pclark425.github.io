<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-2500 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-2500</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-2500</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-68.html">extraction-schema-68</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI systems or methods that generate scientific hypotheses, evaluate hypothesis quality, validate scientific claims, detect hallucinations, or quantify uncertainty in scientific reasoning.</div>
                <p><strong>Paper ID:</strong> paper-259202505</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2306.11648v1.pdf" target="_blank">Harnessing the Power of Adversarial Prompting and Large Language Models for Robust Hypothesis Generation in Astronomy</a></p>
                <p><strong>Paper Abstract:</strong> This study investigates the application of Large Language Models (LLMs), specifically GPT-4, within Astronomy. We employ in-context prompting, supplying the model with up to 1000 papers from the NASA Astrophysics Data System, to explore the extent to which performance can be improved by immersing the model in domain-specific literature. Our findings point towards a substantial boost in hypothesis generation when using in-context prompting, a benefit that is further accentuated by adversarial prompting. We illustrate how adversarial prompting empowers GPT-4 to extract essential details from a vast knowledge base to produce meaningful hypotheses, signaling an innovative step towards employing LLMs for scientific research in Astronomy.</p>
                <p><strong>Cost:</strong> 0.018</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e2500.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e2500.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI systems or methods that generate scientific hypotheses, evaluate hypothesis quality, validate scientific claims, detect hallucinations, or quantify uncertainty in scientific reasoning.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GPT-4</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Generative Pre-trained Transformer 4</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A large transformer-based language model from OpenAI used here in multiple roles (generator, adversarial critic, moderator) to produce, critique, and refine scientific hypotheses via in‑context and retrieval-augmented prompting.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Harnessing the Power of Adversarial Prompting and Large Language Models for Robust Hypothesis Generation in Astronomy</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>GPT-4 (multi-role instances)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>GPT-4 is a large autoregressive transformer language model. In this work three distinct GPT-4 instances are deployed as components of a pipeline: (1) a Generation instance that receives retrieval-augmented, context-compressed inputs and drafts hypotheses; (2) an Adversarial (Judge) instance that critiques the generator's output and highlights missing knowledge/weaknesses; and (3) a Moderator instance that reformulates and structures the judge feedback into targeted follow-up prompts for the generator. The generator operates with an ~8k token context window and ingests retrieved document chunks (1k-token chunks) plus compressed context.</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>LLM-based (retrieval-augmented / multi-instance LLM pipeline)</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Astronomy (Galactic Astronomy)</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_generation_method</strong></td>
                            <td>Retrieval-augmented in-context prompting: document corpus (up to N=1000 papers) is chunked, embedded, and similarity-searched; top chunks are contextually compressed and concatenated with the standalone query to form the prompt for GPT-4 Generation. The generator composes hypotheses from the assembled domain context.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>plausibility_assessment_method</strong></td>
                            <td>Plausibility is assessed via the adversarial GPT-4 judge (which highlights frailties) and by human expert scoring using a 3-category rubric (scientific accuracy, creativity & feasibility) whose average constitutes the hypothesis score.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_plausibility_balance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_quality_metrics</strong></td>
                            <td>Human expert rubric: each hypothesis scored on three categories (scientific accuracy, creativity and feasibility) and averaged to produce the final score (scale appears to be 1–5); AI judge outputs were also evaluated. Reported aggregate scores (examples): mean score ~2.5 (with 10-paper context) to ~4/5 (with 1000-paper context + adversarial prompting).</td>
                        </tr>
                        <tr>
                            <td><strong>pre_experiment_evaluation</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>validation_mechanism</strong></td>
                            <td>Human expert evaluation of generated hypotheses (two domain experts) using the rubric; internal AI-based critique loop (adversarial judge + moderator) used as pre-validation/refinement. No experimental/empirical verification of generated hypotheses reported.</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_measures</strong></td>
                            <td>Authors provide the curated 1,000-paper dataset and codebase (links referenced) for reproducibility; pipeline details include chunk size (1,000 tokens), embedding model used (text-ada-002), LangChain, and replication counts (multiple iterations, resampling description).</td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_prevention_method</strong></td>
                            <td>Retrieval-augmented in-context prompting (feeding relevant domain documents), contextual compression to remove irrelevant parts, and iterative adversarial prompting (judge critiques) to force grounding in retrieved literature.</td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_detection_method</strong></td>
                            <td>Adversarial GPT-4 judge critiques and human expert reviewers identify missing facts or incorrect claims; judge highlights areas of overlooked knowledge prompting generator to correct or expand.</td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance_testing</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_dataset</strong></td>
                            <td>Curated set of 1,000 Galactic Astronomy papers from NASA ADS (criteria: 'Gaia' in abstract, last ten years, refereed journals, keywords like 'galaxy kinematics/dynamics', etc.).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Key reported empirical results are human-evaluated quality scores: average hypothesis quality improved substantially with adversarial prompting and larger context. Example: mean quality score increased from ~2.5 (10 papers context) to ~4/5 (1000 papers + adversarial prompting). They also report increased consistency of scores and behavior across iterations; total produced artifacts: 60 hypotheses and 40 critiques for the main 1000-paper experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td>Compared to naive in-context prompting (no adversarial prompting) the adversarial-looped GPT-4 achieved much higher quality and a strong positive correlation between hypothesis quality and number of contextual papers. With nF=0 (no adversarial feedback), increasing the number of papers did not improve hypothesis quality.</td>
                        </tr>
                        <tr>
                            <td><strong>validated_on_real_science</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>novel_discoveries</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>GPT-4 improvements were mainly in technical detail rather than deeper insights per authors' analysis; reliance on LLM-generated critiques may not align fully with human expectations; no empirical/experimental verification of hypotheses; resource constraints for fine-tuning noted (hence approach uses in-context prompting).</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2500.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e2500.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI systems or methods that generate scientific hypotheses, evaluate hypothesis quality, validate scientific claims, detect hallucinations, or quantify uncertainty in scientific reasoning.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Adversarial Prompting</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Adversarial In‑Context Prompting (adversarial loop of generator → judge → moderator → generator)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A method where a primary LLM generates hypotheses, a secondary LLM adversarially critiques them, and a moderator LLM reformulates critique into feedback — iteratively driving the generator to expand, correct, and ground its outputs in retrieved literature.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Harnessing the Power of Adversarial Prompting and Large Language Models for Robust Hypothesis Generation in Astronomy</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Adversarial Prompting Loop</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Three-stage adversarial loop implemented with three GPT-4 instances: Generation (produces hypothesis from retrieved & compressed context), Adversarial Judge (critiques for frailties and missed context), Moderator (reformats critique into specific feedback questions), and iteration back to Generator. Iteration count (nF) controls number of adversarial attacks; demonstrated to increase 'knowledge footprint' and encourage the generator to incorporate overlooked topics from the corpus.</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>LLM-based (adversarial feedback loop) / retrieval-augmented</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Astronomy (Galactic Astronomy)</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_generation_method</strong></td>
                            <td>Iterative refinement: initial hypothesis from retrieval-augmented prompt; judge critiques highlight missing literature/arguments; moderator reframes critique into focused prompts; generator updates hypothesis accordingly. Uses similarity-retrieved document chunks and contextual compression as the knowledge base.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>plausibility_assessment_method</strong></td>
                            <td>Judge critiques evaluate frailties/limitations and the generator adjusts to increase plausibility; final human expert scoring used to quantify plausibility (rubric of accuracy, creativity, feasibility).</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_plausibility_balance</strong></td>
                            <td>Implicit trade-off enforced by adversarial critique: judge tends to force grounding and fill missing technical detail (increasing plausibility) while the generator can expand scope to incorporate broader literature (potentially increasing novelty); no explicit optimization metric balancing novelty vs plausibility reported.</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_quality_metrics</strong></td>
                            <td>Same human-expert rubric as used with GPT-4: three-category scores averaged to a 1–5 scale; authors report mean scores across runs and consistency improvements with adversarial iterations.</td>
                        </tr>
                        <tr>
                            <td><strong>pre_experiment_evaluation</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>validation_mechanism</strong></td>
                            <td>Primary validation is human-expert evaluation of hypotheses and AI-judge critique quality; adversarial loop itself functions as automated pre-validation/refinement. No subsequent empirical or experimental verification.</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_measures</strong></td>
                            <td>Experimental details: values of N_k (number of papers) tested: {1,10,100,1000}; number of adversarial iterations reported; total samples and replication counts provided; dataset and codebase links indicated to enable reproduction.</td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_prevention_method</strong></td>
                            <td>Adversarial prompting acts to reduce hallucination by forcing the generator to address judge-identified omissions and inconsistencies, combined with retrieval-augmented context which grounds outputs in real literature.</td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_detection_method</strong></td>
                            <td>The adversarial judge flags content inconsistent with or unsupported by retrieved context; human experts also identify hallucinated or unsupported claims during evaluation.</td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance_testing</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_dataset</strong></td>
                            <td>Experiments run on curated subsets of the 1,000-paper ADS corpus (N_k ∈ {1,10,100,1000}), with repeated runs and resampling described for smaller N_k.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Reported outcome: adversarial prompting produced significant improvements in hypothesis quality and consistency; example numeric change: average quality score rose from ~2.5 (10-paper context) to ~4/5 (1000-paper context + adversarial prompting). The number of generated items for main experiments: 60 hypotheses, 40 critiques.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td>Direct comparison to baseline of no-adversarial-loop (nF=0): without adversarial prompting, hypothesis quality did not improve with increased context; adversarial prompting produced marked improvements correlated with context size.</td>
                        </tr>
                        <tr>
                            <td><strong>validated_on_real_science</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>novel_discoveries</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Authors note the adversarial judge mainly improved technical detail rather than producing fundamentally deeper insights; need for better alignment of the judge with human expectations and an automated, objective hypothesis-evaluation pipeline; lack of empirical follow-up validation.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2500.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e2500.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI systems or methods that generate scientific hypotheses, evaluate hypothesis quality, validate scientific claims, detect hallucinations, or quantify uncertainty in scientific reasoning.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Astro-GPT / IdeaGPT Workflow</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Astro-GPT (retrieval-augmented in-context prompting pipeline; repository IdeaGPT referenced)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A retrieval + compression + GPT-4 pipeline for hypothesis generation: PDF→text→token-chunking→embedding→vector similarity retrieval→contextual compression→GPT-4 generation, with adversarial critique iterations.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Harnessing the Power of Adversarial Prompting and Large Language Models for Robust Hypothesis Generation in Astronomy</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Astro-GPT (IdeaGPT workflow)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Pipeline orchestration built using LangChain: (1) papers converted from PDF to text and chunked into ~1,000-token segments; (2) chunks embedded with OpenAI text-ada-002 embeddings and stored in vector DB; (3) query + chat history embedded and similarity search performed to retrieve relevant chunks; (4) LangChain contextual compression filters irrelevant content; (5) compressed context + standalone input fed to GPT-4 Generation; (6) adversarial loop optionally applied (judge + moderator). Codebase (IdeaGPT) and curated data are released for reproducibility.</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>Retrieval-augmented LLM pipeline</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Astronomy (Galactic Astronomy)</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_generation_method</strong></td>
                            <td>Retrieval-augmented generation: similarity search over embeddings to fetch supporting document chunks, contextual compression to reduce irrelevant material, then in-context prompting of GPT-4 to generate hypotheses. Iterative adversarial feedback can refine outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>plausibility_assessment_method</strong></td>
                            <td>Plausibility enforced via grounding in retrieved literature and via adversarial judge feedback; human experts scored plausibility as part of the rubric.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_plausibility_balance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_quality_metrics</strong></td>
                            <td>Human expert rubric (accuracy, creativity, feasibility averaged into a 1–5 score); reported mean scores across experimental conditions.</td>
                        </tr>
                        <tr>
                            <td><strong>pre_experiment_evaluation</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>validation_mechanism</strong></td>
                            <td>Human expert scoring of hypotheses; adversarial judge used as internal automated critic. No wet-lab or astronomical follow-up validation reported.</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_measures</strong></td>
                            <td>Detailed pipeline specifications (chunk size, embedding model, LangChain usage), curated dataset and code repository (IdeaGPT) referenced to enable reproduction; experimental replication counts provided.</td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_prevention_method</strong></td>
                            <td>Primary prevention via retrieval-augmentation (feeding domain literature) and contextual compression; adversarial iterations further reduce hallucination by making the generator address judge-identified gaps.</td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_detection_method</strong></td>
                            <td>Adversarial judge flags unsupported claims based on retrieved context; human reviewers check outputs for hallucinations.</td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance_testing</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_dataset</strong></td>
                            <td>Custom curated ADS corpus of 1,000 Galactic Astronomy papers; smaller N_k subsets used for ablation (1,10,100).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Empirical metric: human-evaluated scores improved with larger N_k and adversarial prompting (example: ~2.5→~4/5). The paper reports increased scope (knowledge footprint) visualized via embeddings/TSNE and consistency gains across iterations.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td>Compared to retrieval-augmented in-context prompting without adversarial loops, the Astro-GPT workflow with adversarial prompting produced significantly higher-quality and more consistent hypotheses.</td>
                        </tr>
                        <tr>
                            <td><strong>validated_on_real_science</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>novel_discoveries</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Authors note naive in-context prompting (even with large context) can produce 'fact jumbles' unless combined with adversarial critique; pipeline currently relies on human expert evaluation and lacks automated ground-truth validation.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2500.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e2500.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI systems or methods that generate scientific hypotheses, evaluate hypothesis quality, validate scientific claims, detect hallucinations, or quantify uncertainty in scientific reasoning.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>text-ada-002 embeddings</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>OpenAI text-ada-002 embedding model</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An OpenAI embedding model used to convert document chunks and queries into vector representations for similarity search in the retrieval pipeline.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Harnessing the Power of Adversarial Prompting and Large Language Models for Robust Hypothesis Generation in Astronomy</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>text-ada-002 embeddings</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>An embedding model (OpenAI) used to convert 1,000-token chunks (abstracts/paper text) and queries into vector embeddings stored in a vector database; similarity search over these embeddings retrieves context for the GPT-4 generator.</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>Embedding model / vectorization component</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Astronomy (used as infrastructure for text retrieval)</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_generation_method</strong></td>
                            <td>Supports hypothesis generation indirectly by enabling retrieval of semantically relevant document chunks via vector similarity.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>plausibility_assessment_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_plausibility_balance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_quality_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>pre_experiment_evaluation</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>validation_mechanism</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_measures</strong></td>
                            <td>Embedding model specified (text-ada-002) and chunking parameters (1,000 tokens) are reported.</td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_prevention_method</strong></td>
                            <td>By enabling retrieval of grounded context, embeddings reduce reliance on model-internal memorized facts and therefore help mitigate hallucinations.</td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance_testing</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_dataset</strong></td>
                            <td>Embeddings computed over the curated 1,000-paper ADS corpus (abstracts and chunks).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validated_on_real_science</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novel_discoveries</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>No embedding-specific limitations or quantitative retrieval recall/precision metrics provided.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2500.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e2500.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI systems or methods that generate scientific hypotheses, evaluate hypothesis quality, validate scientific claims, detect hallucinations, or quantify uncertainty in scientific reasoning.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LangChain</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>LangChain (pipeline library)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A software framework used to build the retrieval-augmented prompting pipeline including chunking, embedding, similarity search, contextual compression, and orchestration of LLM calls.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Harnessing the Power of Adversarial Prompting and Large Language Models for Robust Hypothesis Generation in Astronomy</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>LangChain pipeline components</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>LangChain is used for document pre-processing (PDF→text), chunking, embedding integration, similarity search orchestration, and contextual compression to produce compact, relevant context passed to GPT-4.</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>Software orchestration for retrieval-augmented LLMs</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Astronomy (pipeline infrastructure)</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_generation_method</strong></td>
                            <td>Enables retrieval-augmented in-context prompting by assembling and compressing retrieved document chunks for LLM prompts.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>plausibility_assessment_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_plausibility_balance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_quality_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>pre_experiment_evaluation</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>validation_mechanism</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_measures</strong></td>
                            <td>Use of LangChain, chunk sizes, embedding model, and links to code repository are provided to facilitate reproduction.</td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_prevention_method</strong></td>
                            <td>Supports hallucination mitigation indirectly by retrieving and compressing grounding documents before prompting the LLM.</td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance_testing</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_dataset</strong></td>
                            <td>Used with the curated ADS 1,000-paper corpus in experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validated_on_real_science</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novel_discoveries</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>LangChain is an orchestration tool; paper does not report limitations specific to LangChain beyond general pipeline-level limitations (e.g., need for good retrieval/compression strategies).</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2500.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e2500.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI systems or methods that generate scientific hypotheses, evaluate hypothesis quality, validate scientific claims, detect hallucinations, or quantify uncertainty in scientific reasoning.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>AI judge / AI generator / Moderator (roles)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>AI Judge, AI Generator, and Moderator (role-specific GPT-4 instances)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Named roles implemented via separate GPT-4 instances: the Generator drafts hypotheses, the Judge adversarially critiques them identifying weaknesses, and the Moderator reformats critique into focused follow-ups, forming an iterative refinement loop.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Harnessing the Power of Adversarial Prompting and Large Language Models for Robust Hypothesis Generation in Astronomy</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Multi-role LLM orchestration (Generator, Judge, Moderator)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Operationally distinct GPT-4 instances assigned to specialized tasks: the Generator produces initial hypotheses from retrieved context; the Judge analyzes and criticizes the hypothesis using the same contextual inputs, pinpointing missing lines of evidence or methodological weaknesses; the Moderator translates the judge's critique into actionable prompt-questions for the Generator to address in subsequent iterations. This modular role assignment fosters targeted adversarial refinement.</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>LLM-based role specialization within an adversarial pipeline</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Astronomy (Galactic Astronomy)</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_generation_method</strong></td>
                            <td>Generation by the Generator LLM using retrieval-augmented context; iterative refinement driven by Judge feedback reformulated by Moderator and reissued to Generator.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>plausibility_assessment_method</strong></td>
                            <td>Judge provides plausibility-oriented critique; final plausibility assessed by human experts via rubric.</td>
                        </tr>
                        <tr>
                            <td><strong>novelty_plausibility_balance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_quality_metrics</strong></td>
                            <td>Human-expert rubric and AI judge critique quality (evaluated by humans).</td>
                        </tr>
                        <tr>
                            <td><strong>pre_experiment_evaluation</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>validation_mechanism</strong></td>
                            <td>Internal automated critique (Judge + Moderator) and human expert scoring serve as the primary validation/refinement mechanism prior to any external scientific follow-up.</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_measures</strong></td>
                            <td>Role definitions, iteration counts (nF), and replication details are provided; codebase link referenced.</td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_prevention_method</strong></td>
                            <td>Judge role helps detect unsupported claims and pushes the Generator to ground outputs in retrieved literature, reducing hallucinations.</td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_detection_method</strong></td>
                            <td>Judge flags inconsistencies or unsupported claims; humans subsequently review judge outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance_testing</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_dataset</strong></td>
                            <td>1,000-paper ADS corpus and N_k subsets used in experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Improved human-evaluated hypothesis quality and consistency when roles are used in an iterative adversarial loop; specific aggregated scores reported (2.5→4/5 example).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td>Paper demonstrates that role-based adversarial looping outperforms a single-pass generation (no adversarial judge) even with the same contextual inputs.</td>
                        </tr>
                        <tr>
                            <td><strong>validated_on_real_science</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>novel_discoveries</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Authors note judge improvements tend to increase technical correctness more than deep conceptual novelty; alignment of AI judge with human expectations is imperfect and requires better automated evaluation strategies.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2500.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e2500.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of AI systems or methods that generate scientific hypotheses, evaluate hypothesis quality, validate scientific claims, detect hallucinations, or quantify uncertainty in scientific reasoning.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Adapters / LoRA</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Adapter-style fine-tuning methods (e.g., LoRA, Compacter)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Parameter-efficient fine-tuning approaches (adapter layers, LoRA low-rank updates) mentioned as alternative ways to adapt large LMs to domain tasks, but they were not executed in this study because of resource constraints.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Harnessing the Power of Adversarial Prompting and Large Language Models for Robust Hypothesis Generation in Astronomy</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Adapter-based domain adaptation (LoRA / Compacter)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Adapter approaches add small modules or low-rank parameter updates to a frozen large model to adapt it to domain-specific tasks with far lower compute and storage requirements than full fine-tuning. The paper cites LoRA and Compacter as promising but resource-requiring alternatives.</td>
                        </tr>
                        <tr>
                            <td><strong>system_type</strong></td>
                            <td>Parameter-efficient fine-tuning (adapter-based)</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>General (cited as applicable to domain-specific NLP tasks)</td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_generation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_assessment_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>plausibility_assessment_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novelty_plausibility_balance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hypothesis_quality_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>pre_experiment_evaluation</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validation_mechanism</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_measures</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_prevention_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_detection_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>hallucination_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>statistical_significance_testing</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>benchmark_dataset</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_baseline</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validated_on_real_science</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>novel_discoveries</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>limitations</strong></td>
                            <td>Mentioned as effective for domain adaptation but noted to be potentially inaccessible to resource-limited institutions; authors chose in-context prompting as a lower-cost alternative.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Gpt-4 technical report <em>(Rating: 2)</em></li>
                <li>Training language models to follow instructions with human feedback <em>(Rating: 2)</em></li>
                <li>Chain of thought prompting elicits reasoning in large language models <em>(Rating: 2)</em></li>
                <li>Self-consistency improves chain of thought reasoning in language models <em>(Rating: 1)</em></li>
                <li>An explanation of in-context learning as implicit bayesian inference <em>(Rating: 2)</em></li>
                <li>Low-Rank Adaptation of Large Language Models <em>(Rating: 1)</em></li>
                <li>Compacter: Efficient low-rank hypercomplex adapter layers <em>(Rating: 1)</em></li>
                <li>Learn to explain: Multimodal reasoning via thought chains for science question answering <em>(Rating: 2)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-2500",
    "paper_id": "paper-259202505",
    "extraction_schema_id": "extraction-schema-68",
    "extracted_data": [
        {
            "name_short": "GPT-4",
            "name_full": "Generative Pre-trained Transformer 4",
            "brief_description": "A large transformer-based language model from OpenAI used here in multiple roles (generator, adversarial critic, moderator) to produce, critique, and refine scientific hypotheses via in‑context and retrieval-augmented prompting.",
            "citation_title": "Harnessing the Power of Adversarial Prompting and Large Language Models for Robust Hypothesis Generation in Astronomy",
            "mention_or_use": "use",
            "system_name": "GPT-4 (multi-role instances)",
            "system_description": "GPT-4 is a large autoregressive transformer language model. In this work three distinct GPT-4 instances are deployed as components of a pipeline: (1) a Generation instance that receives retrieval-augmented, context-compressed inputs and drafts hypotheses; (2) an Adversarial (Judge) instance that critiques the generator's output and highlights missing knowledge/weaknesses; and (3) a Moderator instance that reformulates and structures the judge feedback into targeted follow-up prompts for the generator. The generator operates with an ~8k token context window and ingests retrieved document chunks (1k-token chunks) plus compressed context.",
            "system_type": "LLM-based (retrieval-augmented / multi-instance LLM pipeline)",
            "scientific_domain": "Astronomy (Galactic Astronomy)",
            "hypothesis_generation_method": "Retrieval-augmented in-context prompting: document corpus (up to N=1000 papers) is chunked, embedded, and similarity-searched; top chunks are contextually compressed and concatenated with the standalone query to form the prompt for GPT-4 Generation. The generator composes hypotheses from the assembled domain context.",
            "novelty_assessment_method": null,
            "plausibility_assessment_method": "Plausibility is assessed via the adversarial GPT-4 judge (which highlights frailties) and by human expert scoring using a 3-category rubric (scientific accuracy, creativity & feasibility) whose average constitutes the hypothesis score.",
            "novelty_plausibility_balance": null,
            "hypothesis_quality_metrics": "Human expert rubric: each hypothesis scored on three categories (scientific accuracy, creativity and feasibility) and averaged to produce the final score (scale appears to be 1–5); AI judge outputs were also evaluated. Reported aggregate scores (examples): mean score ~2.5 (with 10-paper context) to ~4/5 (with 1000-paper context + adversarial prompting).",
            "pre_experiment_evaluation": true,
            "validation_mechanism": "Human expert evaluation of generated hypotheses (two domain experts) using the rubric; internal AI-based critique loop (adversarial judge + moderator) used as pre-validation/refinement. No experimental/empirical verification of generated hypotheses reported.",
            "reproducibility_measures": "Authors provide the curated 1,000-paper dataset and codebase (links referenced) for reproducibility; pipeline details include chunk size (1,000 tokens), embedding model used (text-ada-002), LangChain, and replication counts (multiple iterations, resampling description).",
            "hallucination_prevention_method": "Retrieval-augmented in-context prompting (feeding relevant domain documents), contextual compression to remove irrelevant parts, and iterative adversarial prompting (judge critiques) to force grounding in retrieved literature.",
            "hallucination_detection_method": "Adversarial GPT-4 judge critiques and human expert reviewers identify missing facts or incorrect claims; judge highlights areas of overlooked knowledge prompting generator to correct or expand.",
            "hallucination_rate": null,
            "statistical_significance_testing": null,
            "uncertainty_quantification_method": null,
            "benchmark_dataset": "Curated set of 1,000 Galactic Astronomy papers from NASA ADS (criteria: 'Gaia' in abstract, last ten years, refereed journals, keywords like 'galaxy kinematics/dynamics', etc.).",
            "performance_metrics": "Key reported empirical results are human-evaluated quality scores: average hypothesis quality improved substantially with adversarial prompting and larger context. Example: mean quality score increased from ~2.5 (10 papers context) to ~4/5 (1000 papers + adversarial prompting). They also report increased consistency of scores and behavior across iterations; total produced artifacts: 60 hypotheses and 40 critiques for the main 1000-paper experiments.",
            "comparison_with_baseline": "Compared to naive in-context prompting (no adversarial prompting) the adversarial-looped GPT-4 achieved much higher quality and a strong positive correlation between hypothesis quality and number of contextual papers. With nF=0 (no adversarial feedback), increasing the number of papers did not improve hypothesis quality.",
            "validated_on_real_science": false,
            "novel_discoveries": null,
            "limitations": "GPT-4 improvements were mainly in technical detail rather than deeper insights per authors' analysis; reliance on LLM-generated critiques may not align fully with human expectations; no empirical/experimental verification of hypotheses; resource constraints for fine-tuning noted (hence approach uses in-context prompting).",
            "uuid": "e2500.0"
        },
        {
            "name_short": "Adversarial Prompting",
            "name_full": "Adversarial In‑Context Prompting (adversarial loop of generator → judge → moderator → generator)",
            "brief_description": "A method where a primary LLM generates hypotheses, a secondary LLM adversarially critiques them, and a moderator LLM reformulates critique into feedback — iteratively driving the generator to expand, correct, and ground its outputs in retrieved literature.",
            "citation_title": "Harnessing the Power of Adversarial Prompting and Large Language Models for Robust Hypothesis Generation in Astronomy",
            "mention_or_use": "use",
            "system_name": "Adversarial Prompting Loop",
            "system_description": "Three-stage adversarial loop implemented with three GPT-4 instances: Generation (produces hypothesis from retrieved & compressed context), Adversarial Judge (critiques for frailties and missed context), Moderator (reformats critique into specific feedback questions), and iteration back to Generator. Iteration count (nF) controls number of adversarial attacks; demonstrated to increase 'knowledge footprint' and encourage the generator to incorporate overlooked topics from the corpus.",
            "system_type": "LLM-based (adversarial feedback loop) / retrieval-augmented",
            "scientific_domain": "Astronomy (Galactic Astronomy)",
            "hypothesis_generation_method": "Iterative refinement: initial hypothesis from retrieval-augmented prompt; judge critiques highlight missing literature/arguments; moderator reframes critique into focused prompts; generator updates hypothesis accordingly. Uses similarity-retrieved document chunks and contextual compression as the knowledge base.",
            "novelty_assessment_method": null,
            "plausibility_assessment_method": "Judge critiques evaluate frailties/limitations and the generator adjusts to increase plausibility; final human expert scoring used to quantify plausibility (rubric of accuracy, creativity, feasibility).",
            "novelty_plausibility_balance": "Implicit trade-off enforced by adversarial critique: judge tends to force grounding and fill missing technical detail (increasing plausibility) while the generator can expand scope to incorporate broader literature (potentially increasing novelty); no explicit optimization metric balancing novelty vs plausibility reported.",
            "hypothesis_quality_metrics": "Same human-expert rubric as used with GPT-4: three-category scores averaged to a 1–5 scale; authors report mean scores across runs and consistency improvements with adversarial iterations.",
            "pre_experiment_evaluation": true,
            "validation_mechanism": "Primary validation is human-expert evaluation of hypotheses and AI-judge critique quality; adversarial loop itself functions as automated pre-validation/refinement. No subsequent empirical or experimental verification.",
            "reproducibility_measures": "Experimental details: values of N_k (number of papers) tested: {1,10,100,1000}; number of adversarial iterations reported; total samples and replication counts provided; dataset and codebase links indicated to enable reproduction.",
            "hallucination_prevention_method": "Adversarial prompting acts to reduce hallucination by forcing the generator to address judge-identified omissions and inconsistencies, combined with retrieval-augmented context which grounds outputs in real literature.",
            "hallucination_detection_method": "The adversarial judge flags content inconsistent with or unsupported by retrieved context; human experts also identify hallucinated or unsupported claims during evaluation.",
            "hallucination_rate": null,
            "statistical_significance_testing": null,
            "uncertainty_quantification_method": null,
            "benchmark_dataset": "Experiments run on curated subsets of the 1,000-paper ADS corpus (N_k ∈ {1,10,100,1000}), with repeated runs and resampling described for smaller N_k.",
            "performance_metrics": "Reported outcome: adversarial prompting produced significant improvements in hypothesis quality and consistency; example numeric change: average quality score rose from ~2.5 (10-paper context) to ~4/5 (1000-paper context + adversarial prompting). The number of generated items for main experiments: 60 hypotheses, 40 critiques.",
            "comparison_with_baseline": "Direct comparison to baseline of no-adversarial-loop (nF=0): without adversarial prompting, hypothesis quality did not improve with increased context; adversarial prompting produced marked improvements correlated with context size.",
            "validated_on_real_science": false,
            "novel_discoveries": null,
            "limitations": "Authors note the adversarial judge mainly improved technical detail rather than producing fundamentally deeper insights; need for better alignment of the judge with human expectations and an automated, objective hypothesis-evaluation pipeline; lack of empirical follow-up validation.",
            "uuid": "e2500.1"
        },
        {
            "name_short": "Astro-GPT / IdeaGPT Workflow",
            "name_full": "Astro-GPT (retrieval-augmented in-context prompting pipeline; repository IdeaGPT referenced)",
            "brief_description": "A retrieval + compression + GPT-4 pipeline for hypothesis generation: PDF→text→token-chunking→embedding→vector similarity retrieval→contextual compression→GPT-4 generation, with adversarial critique iterations.",
            "citation_title": "Harnessing the Power of Adversarial Prompting and Large Language Models for Robust Hypothesis Generation in Astronomy",
            "mention_or_use": "use",
            "system_name": "Astro-GPT (IdeaGPT workflow)",
            "system_description": "Pipeline orchestration built using LangChain: (1) papers converted from PDF to text and chunked into ~1,000-token segments; (2) chunks embedded with OpenAI text-ada-002 embeddings and stored in vector DB; (3) query + chat history embedded and similarity search performed to retrieve relevant chunks; (4) LangChain contextual compression filters irrelevant content; (5) compressed context + standalone input fed to GPT-4 Generation; (6) adversarial loop optionally applied (judge + moderator). Codebase (IdeaGPT) and curated data are released for reproducibility.",
            "system_type": "Retrieval-augmented LLM pipeline",
            "scientific_domain": "Astronomy (Galactic Astronomy)",
            "hypothesis_generation_method": "Retrieval-augmented generation: similarity search over embeddings to fetch supporting document chunks, contextual compression to reduce irrelevant material, then in-context prompting of GPT-4 to generate hypotheses. Iterative adversarial feedback can refine outputs.",
            "novelty_assessment_method": null,
            "plausibility_assessment_method": "Plausibility enforced via grounding in retrieved literature and via adversarial judge feedback; human experts scored plausibility as part of the rubric.",
            "novelty_plausibility_balance": null,
            "hypothesis_quality_metrics": "Human expert rubric (accuracy, creativity, feasibility averaged into a 1–5 score); reported mean scores across experimental conditions.",
            "pre_experiment_evaluation": true,
            "validation_mechanism": "Human expert scoring of hypotheses; adversarial judge used as internal automated critic. No wet-lab or astronomical follow-up validation reported.",
            "reproducibility_measures": "Detailed pipeline specifications (chunk size, embedding model, LangChain usage), curated dataset and code repository (IdeaGPT) referenced to enable reproduction; experimental replication counts provided.",
            "hallucination_prevention_method": "Primary prevention via retrieval-augmentation (feeding domain literature) and contextual compression; adversarial iterations further reduce hallucination by making the generator address judge-identified gaps.",
            "hallucination_detection_method": "Adversarial judge flags unsupported claims based on retrieved context; human reviewers check outputs for hallucinations.",
            "hallucination_rate": null,
            "statistical_significance_testing": null,
            "uncertainty_quantification_method": null,
            "benchmark_dataset": "Custom curated ADS corpus of 1,000 Galactic Astronomy papers; smaller N_k subsets used for ablation (1,10,100).",
            "performance_metrics": "Empirical metric: human-evaluated scores improved with larger N_k and adversarial prompting (example: ~2.5→~4/5). The paper reports increased scope (knowledge footprint) visualized via embeddings/TSNE and consistency gains across iterations.",
            "comparison_with_baseline": "Compared to retrieval-augmented in-context prompting without adversarial loops, the Astro-GPT workflow with adversarial prompting produced significantly higher-quality and more consistent hypotheses.",
            "validated_on_real_science": false,
            "novel_discoveries": null,
            "limitations": "Authors note naive in-context prompting (even with large context) can produce 'fact jumbles' unless combined with adversarial critique; pipeline currently relies on human expert evaluation and lacks automated ground-truth validation.",
            "uuid": "e2500.2"
        },
        {
            "name_short": "text-ada-002 embeddings",
            "name_full": "OpenAI text-ada-002 embedding model",
            "brief_description": "An OpenAI embedding model used to convert document chunks and queries into vector representations for similarity search in the retrieval pipeline.",
            "citation_title": "Harnessing the Power of Adversarial Prompting and Large Language Models for Robust Hypothesis Generation in Astronomy",
            "mention_or_use": "use",
            "system_name": "text-ada-002 embeddings",
            "system_description": "An embedding model (OpenAI) used to convert 1,000-token chunks (abstracts/paper text) and queries into vector embeddings stored in a vector database; similarity search over these embeddings retrieves context for the GPT-4 generator.",
            "system_type": "Embedding model / vectorization component",
            "scientific_domain": "Astronomy (used as infrastructure for text retrieval)",
            "hypothesis_generation_method": "Supports hypothesis generation indirectly by enabling retrieval of semantically relevant document chunks via vector similarity.",
            "novelty_assessment_method": null,
            "plausibility_assessment_method": null,
            "novelty_plausibility_balance": null,
            "hypothesis_quality_metrics": null,
            "pre_experiment_evaluation": true,
            "validation_mechanism": null,
            "reproducibility_measures": "Embedding model specified (text-ada-002) and chunking parameters (1,000 tokens) are reported.",
            "hallucination_prevention_method": "By enabling retrieval of grounded context, embeddings reduce reliance on model-internal memorized facts and therefore help mitigate hallucinations.",
            "hallucination_detection_method": null,
            "hallucination_rate": null,
            "statistical_significance_testing": null,
            "uncertainty_quantification_method": null,
            "benchmark_dataset": "Embeddings computed over the curated 1,000-paper ADS corpus (abstracts and chunks).",
            "performance_metrics": null,
            "comparison_with_baseline": null,
            "validated_on_real_science": null,
            "novel_discoveries": null,
            "limitations": "No embedding-specific limitations or quantitative retrieval recall/precision metrics provided.",
            "uuid": "e2500.3"
        },
        {
            "name_short": "LangChain",
            "name_full": "LangChain (pipeline library)",
            "brief_description": "A software framework used to build the retrieval-augmented prompting pipeline including chunking, embedding, similarity search, contextual compression, and orchestration of LLM calls.",
            "citation_title": "Harnessing the Power of Adversarial Prompting and Large Language Models for Robust Hypothesis Generation in Astronomy",
            "mention_or_use": "use",
            "system_name": "LangChain pipeline components",
            "system_description": "LangChain is used for document pre-processing (PDF→text), chunking, embedding integration, similarity search orchestration, and contextual compression to produce compact, relevant context passed to GPT-4.",
            "system_type": "Software orchestration for retrieval-augmented LLMs",
            "scientific_domain": "Astronomy (pipeline infrastructure)",
            "hypothesis_generation_method": "Enables retrieval-augmented in-context prompting by assembling and compressing retrieved document chunks for LLM prompts.",
            "novelty_assessment_method": null,
            "plausibility_assessment_method": null,
            "novelty_plausibility_balance": null,
            "hypothesis_quality_metrics": null,
            "pre_experiment_evaluation": true,
            "validation_mechanism": null,
            "reproducibility_measures": "Use of LangChain, chunk sizes, embedding model, and links to code repository are provided to facilitate reproduction.",
            "hallucination_prevention_method": "Supports hallucination mitigation indirectly by retrieving and compressing grounding documents before prompting the LLM.",
            "hallucination_detection_method": null,
            "hallucination_rate": null,
            "statistical_significance_testing": null,
            "uncertainty_quantification_method": null,
            "benchmark_dataset": "Used with the curated ADS 1,000-paper corpus in experiments.",
            "performance_metrics": null,
            "comparison_with_baseline": null,
            "validated_on_real_science": null,
            "novel_discoveries": null,
            "limitations": "LangChain is an orchestration tool; paper does not report limitations specific to LangChain beyond general pipeline-level limitations (e.g., need for good retrieval/compression strategies).",
            "uuid": "e2500.4"
        },
        {
            "name_short": "AI judge / AI generator / Moderator (roles)",
            "name_full": "AI Judge, AI Generator, and Moderator (role-specific GPT-4 instances)",
            "brief_description": "Named roles implemented via separate GPT-4 instances: the Generator drafts hypotheses, the Judge adversarially critiques them identifying weaknesses, and the Moderator reformats critique into focused follow-ups, forming an iterative refinement loop.",
            "citation_title": "Harnessing the Power of Adversarial Prompting and Large Language Models for Robust Hypothesis Generation in Astronomy",
            "mention_or_use": "use",
            "system_name": "Multi-role LLM orchestration (Generator, Judge, Moderator)",
            "system_description": "Operationally distinct GPT-4 instances assigned to specialized tasks: the Generator produces initial hypotheses from retrieved context; the Judge analyzes and criticizes the hypothesis using the same contextual inputs, pinpointing missing lines of evidence or methodological weaknesses; the Moderator translates the judge's critique into actionable prompt-questions for the Generator to address in subsequent iterations. This modular role assignment fosters targeted adversarial refinement.",
            "system_type": "LLM-based role specialization within an adversarial pipeline",
            "scientific_domain": "Astronomy (Galactic Astronomy)",
            "hypothesis_generation_method": "Generation by the Generator LLM using retrieval-augmented context; iterative refinement driven by Judge feedback reformulated by Moderator and reissued to Generator.",
            "novelty_assessment_method": null,
            "plausibility_assessment_method": "Judge provides plausibility-oriented critique; final plausibility assessed by human experts via rubric.",
            "novelty_plausibility_balance": null,
            "hypothesis_quality_metrics": "Human-expert rubric and AI judge critique quality (evaluated by humans).",
            "pre_experiment_evaluation": true,
            "validation_mechanism": "Internal automated critique (Judge + Moderator) and human expert scoring serve as the primary validation/refinement mechanism prior to any external scientific follow-up.",
            "reproducibility_measures": "Role definitions, iteration counts (nF), and replication details are provided; codebase link referenced.",
            "hallucination_prevention_method": "Judge role helps detect unsupported claims and pushes the Generator to ground outputs in retrieved literature, reducing hallucinations.",
            "hallucination_detection_method": "Judge flags inconsistencies or unsupported claims; humans subsequently review judge outputs.",
            "hallucination_rate": null,
            "statistical_significance_testing": null,
            "uncertainty_quantification_method": null,
            "benchmark_dataset": "1,000-paper ADS corpus and N_k subsets used in experiments.",
            "performance_metrics": "Improved human-evaluated hypothesis quality and consistency when roles are used in an iterative adversarial loop; specific aggregated scores reported (2.5→4/5 example).",
            "comparison_with_baseline": "Paper demonstrates that role-based adversarial looping outperforms a single-pass generation (no adversarial judge) even with the same contextual inputs.",
            "validated_on_real_science": false,
            "novel_discoveries": null,
            "limitations": "Authors note judge improvements tend to increase technical correctness more than deep conceptual novelty; alignment of AI judge with human expectations is imperfect and requires better automated evaluation strategies.",
            "uuid": "e2500.5"
        },
        {
            "name_short": "Adapters / LoRA",
            "name_full": "Adapter-style fine-tuning methods (e.g., LoRA, Compacter)",
            "brief_description": "Parameter-efficient fine-tuning approaches (adapter layers, LoRA low-rank updates) mentioned as alternative ways to adapt large LMs to domain tasks, but they were not executed in this study because of resource constraints.",
            "citation_title": "Harnessing the Power of Adversarial Prompting and Large Language Models for Robust Hypothesis Generation in Astronomy",
            "mention_or_use": "mention",
            "system_name": "Adapter-based domain adaptation (LoRA / Compacter)",
            "system_description": "Adapter approaches add small modules or low-rank parameter updates to a frozen large model to adapt it to domain-specific tasks with far lower compute and storage requirements than full fine-tuning. The paper cites LoRA and Compacter as promising but resource-requiring alternatives.",
            "system_type": "Parameter-efficient fine-tuning (adapter-based)",
            "scientific_domain": "General (cited as applicable to domain-specific NLP tasks)",
            "hypothesis_generation_method": null,
            "novelty_assessment_method": null,
            "plausibility_assessment_method": null,
            "novelty_plausibility_balance": null,
            "hypothesis_quality_metrics": null,
            "pre_experiment_evaluation": null,
            "validation_mechanism": null,
            "reproducibility_measures": null,
            "hallucination_prevention_method": null,
            "hallucination_detection_method": null,
            "hallucination_rate": null,
            "statistical_significance_testing": null,
            "uncertainty_quantification_method": null,
            "benchmark_dataset": null,
            "performance_metrics": null,
            "comparison_with_baseline": null,
            "validated_on_real_science": null,
            "novel_discoveries": null,
            "limitations": "Mentioned as effective for domain adaptation but noted to be potentially inaccessible to resource-limited institutions; authors chose in-context prompting as a lower-cost alternative.",
            "uuid": "e2500.6"
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Gpt-4 technical report",
            "rating": 2,
            "sanitized_title": "gpt4_technical_report"
        },
        {
            "paper_title": "Training language models to follow instructions with human feedback",
            "rating": 2,
            "sanitized_title": "training_language_models_to_follow_instructions_with_human_feedback"
        },
        {
            "paper_title": "Chain of thought prompting elicits reasoning in large language models",
            "rating": 2,
            "sanitized_title": "chain_of_thought_prompting_elicits_reasoning_in_large_language_models"
        },
        {
            "paper_title": "Self-consistency improves chain of thought reasoning in language models",
            "rating": 1,
            "sanitized_title": "selfconsistency_improves_chain_of_thought_reasoning_in_language_models"
        },
        {
            "paper_title": "An explanation of in-context learning as implicit bayesian inference",
            "rating": 2,
            "sanitized_title": "an_explanation_of_incontext_learning_as_implicit_bayesian_inference"
        },
        {
            "paper_title": "Low-Rank Adaptation of Large Language Models",
            "rating": 1,
            "sanitized_title": "lowrank_adaptation_of_large_language_models"
        },
        {
            "paper_title": "Compacter: Efficient low-rank hypercomplex adapter layers",
            "rating": 1,
            "sanitized_title": "compacter_efficient_lowrank_hypercomplex_adapter_layers"
        },
        {
            "paper_title": "Learn to explain: Multimodal reasoning via thought chains for science question answering",
            "rating": 2,
            "sanitized_title": "learn_to_explain_multimodal_reasoning_via_thought_chains_for_science_question_answering"
        }
    ],
    "cost": 0.018020249999999998,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Harnessing the Power of Adversarial Prompting and Large Language Models for Robust Hypothesis Generation in Astronomy</p>
<p>Ioana Ciucȃ 
Yuan-Sen Ting 
Sandor Kruk 
Kartheik Iyer 
Harnessing the Power of Adversarial Prompting and Large Language Models for Robust Hypothesis Generation in Astronomy</p>
<p>This study investigates the application of Large Language Models (LLMs), specifically GPT-4, within Astronomy. We employ in-context prompting, supplying the model with up to 1000 papers from the NASA Astrophysics Data System, to explore the extent to which performance can be improved by immersing the model in domainspecific literature. Our findings point towards a substantial boost in hypothesis generation when using in-context prompting, a benefit that is further accentuated by adversarial prompting. We illustrate how adversarial prompting empowers GPT-4 to extract essential details from a vast knowledge base to produce meaningful hypotheses, signaling an innovative step towards employing LLMs for scientific research in Astronomy.</p>
<p>Introduction</p>
<p>Significant strides in Natural Language Processing (NLP) have been made possible through attention mechanisms and transformer architecture, leading to the development of Large Language Models (LLMs) such as GPT-4 (Vig, 2019;Brown et al., 2020;Ouyang et al., 2022). These models exhibit extraordinary aptitude in understanding, generating, and interacting with human language. They go beyond deciphering complex linguistic patterns to making non-trivial deductions and forming relationships across diverse contexts (e.g., Devlin et al., 2018;Elkins &amp; Chun, 2020).</p>
<p>Two intriguing facets of these models have stirred excite-Proceedings of the 40 th International Conference on Machine Learning, Honolulu, Hawaii, USA. PMLR 202, 2023. Copyright 2023 by the author(s). ment for their potential that surpasses their initial intended applications. Firstly, despite LLMs' propensity to sample posterior means of languages-a factor that can occasionally result in non-trivial hallucination problems-improved performance has been witnessed through in-context prompting Wei et al., 2022;Zhang et al., 2022). This enhancement enables them to handle complex, domain-specific tasks (e.g., Radford &amp; Narasimhan, 2018;Brown et al., 2020;Lu et al., 2022). Secondly, these models, when combined with revolutionary technologies like Langchain 1 to provide extensive context to the LLMs, expand their functionality across a wide range of fields.</p>
<p>While methods like the use of adapters Karimi Mahabadi et al., 2021;Hu et al., 2021) can remarkably augment performance for domain-specific tasks through fine-tuning the LLMs, these approaches often prove challenging for institutions without sufficient resources. In this study, we delve into the application of low-cost incontext prompting Xie et al., 2021) in the realm of astronomy.</p>
<p>Astronomy offers a compelling case study due to three key reasons. Firstly, although the field is rich in literature, the inclusion of such text in the vast corpus used to train GPT models is probably limited. This lack leads to noticeable hallucination problems when employing naive versions of LLMs (Ciucȃ et al., 2023). Secondly, unlike domains that focus more on intensive, detailed studies, advancements in astronomy often stem from "connecting the dots" across different subfields due to the universality of underlying physical processes at various scales. This feature fosters the hypothesis that extensive in-context prompting could significantly enhance hypothesis generation if LLMs are initially exposed to a broad range of literature.</p>
<p>Lastly, astronomy's longstanding "open sky" policy makes it an ideal candidate for in-context prompting research. This policy ensures that most data sets are publicly available immediately or after a short proprietary period (Almeida et al., 2023;Fabricius et al., 2021). Further, the field possesses a comprehensive, well-curated literature database. The internet has enabled the archiving of astronomical knowledge, Figure 1. This figure illustrates the adversarial in-context prompting workflow using OpenAI's GPT-4 model. The procedure begins with the pre-processing and embedding of Galactic Astronomy papers. A similarity search is conducted on the embedded query, and relevant document chunks are retrieved. A further contextual compression is performed to remove irrelevant information from the chunks. These compressed texts serve as input to a GPT-4 instance, which generates an idea. This idea is then critiqued by a second GPT-4 model, and the feedback is moderated by a third GPT-4 model. with NASA's Astrophysics Data System hosting over 15 million resources, effectively covering the entire spectrum of astronomical literature utilized by researchers (Accomazzi et al., 2015;Borgman &amp; Wofford, 2021). This accessibility greatly aids our engagement with the astronomy database.</p>
<p>Literature retrieval and pre-processing</p>
<p>For this study, we focused our exploration on Galactic Astronomy, utilizing our domain expertise to assess the results. We selected Galactic Astronomy as our focal area due to its integrative nature, fusing knowledge from diverse subfields. The study of galaxy evolution not only incorporates the fundamental understanding of stars and stellar populations (Aouad et al., 2020;Sánchez et al., 2022) but it is also influenced by large-scale cosmological environmental factors (Singh et al., 2020;Whitney et al., 2021). Therefore, studying galaxy evolution provides both exciting challenges and abundant possibilities for harnessing implicit knowledge embedded within the vast network of literature.</p>
<p>Our study includes a selection of 1,000 papers related to Galactic Astronomy from the NASA ADS (Accomazzi et al., 2015) Astronomy collection. Our chosen papers were identified through a database query based on criteria such as 'Gaia' appearing in the abstract, publications from the last ten years (since the Gaia launch date), being refereed journal articles, and the inclusion of relevant keywords such as 'galaxy kinematics and dynamics', 'galaxy structure', 'galaxy disk', 'galaxy halo', 'galaxy abundances', and 'galaxy evolution'. Our initial query yielded more than 1,000 papers, leading us to prioritize the most recent publications. Our curated collection contains details such as the ArxivID, Publication Date, Authors, Title, Abstract, Citation, and Key, providing a comprehensive dataset for our analysis. The full dataset as well as the codebase used in our analysis can be found here for reproducibility 2 .</p>
<p>Astro-GPT Workflow</p>
<p>Our exploration capitalizes on the abilities of OpenAI's GPT-4 model (OpenAI, 2023). The first step in in-context prompting involves pre-processing 1,000 papers from the Galactic Astronomy corpus using the langchain library. Each paper, transformed from PDF to text, is subsequently segmented into 'chunks' of 1,000 tokens each. These segmented units are then embedded using OpenAI's text-ada-002 embedding model.</p>
<p>The retrieval phase begins with converting the chat history and input query into a standalone input, which is then embedded. A similarity search is conducted between the embedded query and the vector database. We then use langchain's contextual compression to filter out irrelevant information from the individual chunks. These final texts, combined with the standalone input, form the foundation upon which a GPT-4 model, having a context window of approximately 8,000 tokens, formulates ideas. To scrutinize the model's prowess, we design an adversarial experiment. This involves a secondary GPT-4 model that critiques the idea, highlighting its frailties and suggesting potential enhancements. This feedback is reformulated within a feedback-question structure by a third GPT-4 instance and returned to the initial model. Figure 2. Adversarial prompting and domain-specific context enrichment significantly enhance hypothesis generation quality. 60 hypotheses and 40 critiques generated by the AI were evaluated by two human experts, with the mean scores reported for individual instances. The iterations of adversarial prompting (nF ) was instrumental in driving substantial enhancements in both the quality and consistency of the AI judge and AI generator outputs, particularly when they were supplied with an extensive context (N = 1000 papers). Crucially, in the absence of adversarial prompting (nF = 0), the quality of the hypothesis remained stagnant despite the provision of ample context. This observation underscores the stark contrast and superior effectiveness of adversarial prompting. Implementing our experimental setup, we use N k papers, where k ∈ {1, 10, 100, 1000}. Each sample undergoes hypothesis generation by the 'Generation GPT-4' instance (our in-context prompted model on k papers). An adversarial response from 'Adversarial GPT-4' follows, which is reformulated by a moderator GPT-4 instance and fed back to the generator model. This cycle, yielding three hypotheses and two critiques per experiment, is repeated twice for each N k and replicated five times in total. The same approach is applied to 1,000 papers, without resampling, accumulating a total of 60 hypotheses and 40 critiques.</p>
<p>Results</p>
<p>Human Evaluation</p>
<p>Given the qualitative nature of hypothesis generation, we needed an assessment process that, while inherently subjective, would match the expectations of human experts. For this, we involved two domain experts in the field of Galactic Astronomy to evaluate the quality of the generated hypotheses. These were graded based on the number of papers included within the domain-specific context, and we computed the average score from these dual-human evaluations for each hypothesis. The hypotheses are graded based on a rubric of three categories -scientific accuracy, creativity and feasibility, and the average score of these three domains assumed to be the final score. We also evaluated the critiques provided by the AI judge, which had access to the same contextual information.</p>
<p>As illustrated in the left panel of Fig. 2, adversarial prompting proved to be a critical tool in markedly improving hypothesis generation. The quality of hypothesis generation, without adversarial prompting, showed little dependence on the number of papers, suggesting that in-context prompting alone, while helpful for mitigating hallucination, did not suffice for a comprehensive understanding of the corpus.</p>
<p>The introduction of adversarial prompting considerably altered this outcome. A significant improvement in the quality of hypothesis generation was observed both for the AI generator and the AI judge, even without explicitly aligning the models with human expectations. Notably, adversarial prompting introduced a strong correlation between hypothesis quality and the number of papers reviewed, especially at larger context (N = 1000). It also leads to a much more consistent in term of the quality of the hypotheses (and the critiques). The average quality score rose significantly from 2.5 (when 10 papers were used as context, where a score of 3/5 corresponds to a typical hypothesis by a competent PhD student) to a near-expert level of 4/5 when 1,000 papers were included, emphasizing the potential of adversarial prompting in enhancing the quality of scientific hypothesis generation. We refer to the Appendix for examples.</p>
<p>Exploration of Embeddings</p>
<p>To truly understand the power of adversarial prompting, we first passed the abstracts of our set of 1000 astronomy papers through the text-ada-002 embedding model and arranged them into a 2D TSNE projection. This captured the contextual differences and similarities of these 1000 papers.</p>
<p>For each hypothesis generated, we determined which papers inspired it by querying the GPT model. In Fig. 3, we visualized this 'knowledge footprint' for each hypothesis as black polygons within a green hull representing all the papers GPT-4 had access to. From Fig. 3's top panels, it's clear that as the number of papers grows, GPT broadens its scope, drawing on diverse topics to build interconnected hypotheses. We note that, even with a small training pool of 10 papers, we design our experiment in a way that the corpus still covers a wide range of topics, but GPT-4 lacks the context to connect them in a meaningful way, leading to more general hypotheses (see Appendix).</p>
<p>The bottom panel in Fig. 3, concentrating on the case with 1000 papers, explores how the knowledge footprint evolves with different numbers of adversarial attacks. In the preliminary iteration (bottom left), the judge ingeniously identifies areas of critique based on knowledge overlooked by the original response. This compels the generator to expand its scope further (as shown in the bottom middle and right panels), to appropriately address the criticism. As shown in some of the examples in the Appendix, adversarial prompting allows the GPT-4 model to genuinely benefit from a large number of contextual inputs, guiding the model towards a more coherent understanding of the topic, rather than creating a mere 'fact jumble'. The specific examples of hypotheses and corresponding critiques are shown in the Appendix.</p>
<p>Conclusion and Future Direction</p>
<p>In this research, we delved into a detailed examination of the GPT-4 model's ability to propose novel hypotheses in the domain of Galactic Astronomy using in-context prompting. Our findings confirm that in-context prompting significantly mitigates hallucination, leading to the generation of meaningful hypotheses that can compete with substantive thesis topics, as evaluated by domain experts. Importantly, we found that the inclusion of adversarial prompts enables the model to progressively enhance its performance based on the number of contextual papers. However, a naive implementation of in-context prompting without adversarial judgment fails to replicate this improvement.</p>
<p>While our study marks the inception of a pioneering exploration of in-context prompting for scientific hypothesis generation, it's clear that this dynamic field is rapidly evolving. Thus, we have identified several crucial areas for enhancement. These areas include (a) an improved and automated evaluation method for hypotheses. We have observed that while the AI judge can assist the AI generator, improvements are primarily in technical detail rather than deep insights. We propose leveraging well-curated question-and-answer pairs (e.g. Dugan et al., 2022) to better align the judge with human expectations. (b) Instead of focusing solely on hypothesis generation, integrating other downstream tasks and finite fine-tuning models with smaller adapter models could potentially improve inferences. We have commenced curating metadata from ADS to better design these tasks.</p>
<p>Broader Impact</p>
<p>In this study, our focus on in-context prompting, rather than the more computationally intensive fine-tuning, is inspired by the aim to democratize the utilization of LLMs for scientific inquiry. Current GPT models, due to their immense parameter sets, often render fine-tuning impractical. In the era of Large Language Models, it is crucial to determine whether all academic institutions, regardless of size or available computational resources, can keep pace with these rapidly advancing technologies.</p>
<p>This critical inquiry forms the crux of our study, and our findings present a hopeful outlook. Our study indicates that, with the right strategies and approaches with 'humans in the loop' as domain experts, the barrier to harnessing the full power of these advanced LLMs can be lowered. As a result, we envision a future where all institutions, regardless of size or resources, can contribute to and benefit from the swift advancements in AI, enhancing the collective endeavour of scientific discovery. Our journey into this new frontier of Large Language Models is just beginning, and it promises a thrilling ride full of unexpected insights and revolutionary breakthroughs.</p>
<p>A. Exemplary Hypotheses and Critiques Generated</p>
<p>This section presents three types of hypotheses generated through our in-context prompting and adversarial prompting techniques, along with the associated critiques provided by our adversarial GPT-4 model, which led to substantial improvements in hypothesis generation.</p>
<p>The first example demonstrates a hypothesis generated after subjecting the model to in-context prompting through 1000 papers, followed by two rounds of adversarial attacks.</p>
<p>I propose an investigation into the role of dark matter mini-halos in the formation and evolution of globular clusters (GCs) in the Milky Way. This study would combine the high-precision astrometric data from Gaia EDR3 and DR3 (Gaia Collaboration et al. 2016 with spectroscopic data from large ground-based surveys like APOGEE, GALAH, SDSS SEGUE, and LAMOST to characterize the dynamics of stars in the peripheral regions of GCs. The aim would be to determine whether these GCs are embedded in dark matter mini-halos, which could provide critical insights into their origins (Peebles 1984;Peñarrubia et al. 2017). The proposed research would build upon the probabilistic approach developed by Kuzma et al. (2021) for studying the peripheral regions of GCs, which utilizes a mixture model in spatial and proper motion space to model cluster, extra-tidal, and contaminant stellar populations. By extending this approach to include the effects of dark matter mini-halos on the kinematics of stars in GC outskirts, we can test the hypothesis that dark matter plays a significant role in the formation and evolution of GCs. Furthermore, this study would provide a better understanding of the distribution and properties of dark matter in the Milky Way, contributing to the broader field of near-field cosmology. Integrating this information with the existing knowledge of the hierarchical assembly of the Milky Way (Viswanathan et al. 2023) and the role of rapid gas accretion in the inner Galactic disc (Snaith et al. 2021) would help paint a more comprehensive picture of our Galaxy's formation history and its underlying dark matter distribution.</p>
<p>This hypothesis received high approval from the human jury due to its broad contextual understanding of Galactic Astronomy, a concrete thesis proposal, appropriate references for idea origins, and building upon existing methodologies and studies.</p>
<p>Conversely, the following hypothesis was produced when the in-context prompting was restricted to 10 papers. Hypotheses based on limited exposure to literature often appear generic, lacking substantial insights beyond minor improvements to existing work.</p>
<p>I propose a study investigating the role of intermediate-mass gas-rich mergers in the chemical and kinematic evolution of the Milky Way-like galaxies across a range of redshifts. This research would build upon the findings of Ciucȃ et al. (2023), which suggest that the Gaia-Sausage-Enceladus (GSE) merger significantly impacted the formation of the Galactic disc and the transition from the thick disc to the thin disc. The study could involve a combination of observational data from large spectroscopic surveys such as APOGEE, GALAH, and Gaia-ESO, as well as the utilization of high-resolution cosmological simulations like the Auriga project. Key objectives would include characterizing the chemical abundance patterns and kinematic properties of stars in the disc and halo components during and after the mergers and probing the impact of these mergers on the radial distribution and migration of stars across the Galactic disc. By focusing on intermediate-mass gas-rich mergers, this research would fill a knowledge gap in our understanding of the role these events play in shaping the structure and evolution of Milky Way-like galaxies. The findings would also provide valuable insights for refining galaxy formation models and contribute to a more comprehensive understanding of the complex history of our Galaxy.</p>
<p>Without sufficient context, the model tends to extrapolate based on existing literature, resulting in incremental, less innovative suggestions.</p>
<p>Importantly, despite the exposure to a corpus of 1000 papers, without adversarial attacks, the hypotheses can often seem like a jumble of facts, as shown in the example below: I propose a comprehensive, multi-wavelength exploration of the uncharted regions of the Galactic plane, particularly in the South Galactic cap, including areas below a declination of -65°. This astronomical research initiative can be achieved by combining existing large photometric, spectroscopic, and astrometric surveys, such as Gaia, LAMOST, APOGEE, and GALAH, with new high-resolution surveys aimed at mapping the uncovered areas of the Milky Way. This undertaking should prioritize the detection and characterization of previously undiscovered ultra-faint dwarf galaxies, chemically peculiar stars, and stellar streams, as well as the evaluation of their origins and potential implications for our understanding of the Milky Way's formation and evolution. This research proposal is inspired by the unexplored regions mentioned in Antoja et al. (2015), along with the possibilities for improvement suggested by Gorski and Barmby (2020) and the advancements in large-scale surveys discussed in studies such as Yuan et al. (2014) and An and Beers (2020). Expanding our knowledge of the uncharted regions of the Galactic plane will significantly contribute to our understanding of the structure, formation, and evolution of the Milky Way. Additionally, it will allow astronomers to identify and assess previously unknown populations of stars and their kinematic properties, further refining our knowledge of the various components and phenomena that shape our Galaxy.</p>
<p>Demonstrating adversarial prompting is critical to ensure that the GPT can harness the broad context provided in a meaningful way.</p>
<p>Finally, an example of high-quality critique provided by the adversarial GPT-4 model is showcased. These adversarial critiques, after being primed with 1000 papers, are highly accurate and can rival the quality of expert human critique.</p>
<p>The interdisciplinary approach proposed aims to provide a comprehensive understanding of the Milky Way's gravitational potential by combining photometric data, high-resolution simulations, and novel techniques to analyze phase-space spirals. However, there are several weaknesses and limitations to consider. First, the proposal relies heavily on photometric data, which, although less affected by sampling biases, may still be prone to uncertainties due to dust obscuration and crowding (Rix and Bovy 2013). Additionally, the accuracy of photometric metallicity measurements may be limited compared to spectroscopic data (An and Beers 2021). Second, while high-resolution simulations may enable better modeling of the Milky Way's potential, they are computationally expensive, and current mass and spatial resolutions may not be sufficient for accurate analysis (Darling and Widrow 2018). Furthermore, the complexity of the Milky Way, including its non-steady-state nature and the presence of various structures such as spiral arms and bars, adds challenges to the modeling process (Kipper et al. 2018). Third, novel techniques to analyze phase-space spirals may be subject to different sources of systematic bias (Widmark et al. 2021). The proposal does not fully address how these biases will be accounted for or the potential limitations of these techniques in the context of a complex and evolving galaxy. Lastly, the proposal does not extensively discuss the implications of various selection biases in spectroscopic surveys (Sanders and Das 2018), nor the challenges in incorporating the complexity of our galaxy in large-scale cosmological models (Everall et al. 2021c). In conclusion, while the interdisciplinary approach has merits, further work is needed to address these weaknesses and limitations for a more accurate and comprehensive understanding of the Milky Way's gravitational potential.</p>
<p>Figure 3 .
3Visual representation of each hypothesis's 'knowledge footprint', depicted as black polygons within the TSNE projection of the abstracts of our corpus comprising 1000 papers. As the quantity of papers consumed increases, the model leverages a more diverse array of topics, thus boosting the quality of the hypothesis (as seen in the top panels). The green hull in the top panel shows the overall knowledge base that the model have access through in-context prompting. The lower panel demonstrates how the 'knowledge footprint' evolves with varying quantities nF of adversarial attacks in the case of 1000 papers. The black polygon signifies the footprint of the original response, while the lime indicates the information utilized by the AI judge for critique.
https://python.langchain.com
https://github.com/errai34/IdeaGPT</p>
<p>Open Science at the Frontiers of Librarianship. A Accomazzi, M J Kurtz, E A Henneken, R Chyla, J Luker, C S Grant, D M Thompson, A Holachek, R Dave, S S Murray, 10.48550/arXiv.1503.04194Astronomical Society of the Pacific Conference Series. Holl, A., Lesteven, S., Dietrich, D., and Gasperini, A.492189ADS: The Next Generation Search PlatformAccomazzi, A., Kurtz, M. J., Henneken, E. A., Chyla, R., Luker, J., Grant, C. S., Thompson, D. M., Holachek, A., Dave, R., and Murray, S. S. ADS: The Next Generation Search Platform. In Holl, A., Lesteven, S., Dietrich, D., and Gasperini, A. (eds.), Open Science at the Frontiers of Librarianship, volume 492 of Astronomical Society of the Pacific Conference Series, pp. 189, April 2015. doi: 10.48550/arXiv.1503.04194.</p>
<p>. A Almeida, S F Anderson, M Argudo-Fernández, C Badenes, K Barger, J K Barrera-Ballesteros, C F Bender, E Benitez, F Besser, D Bizyaev, M R Blanton, J Bochanski, J Bovy, W N Brandt, J R Brownstein, J Buchner, E Bulbul, J N Burchett, M C Díaz, J K Carlberg, A R Casey, V Chandra, B Cherinka, C Chiappini, A A Coker, J Comparat, C Conroy, G Contardo, A Cortes, K Covey, J D Crane, K Cunha, C Dabbieri, J W D J Davis, M C Lee, N D Delgado, J E M Demasi, S Mille, F D Donor, J Dow, P Dwelly, T Eracleous, M Eriksen, J Fan, X Farr, E Frederick, S Fries, L Frinchaboy, P Gaensicke, B T Ge, J Ávila, C G Grabowski, K Grier, C Guiglion, G Gupta, P Hall, P Hawkins, K Hayes, C R Hermes, J J Hernández-García, L Hogg, D W Holtzman, J A Ibarra-Medel, H J Ji, A Jofre, P Johnson, J A Jones, A M Kinemuchi, K Kluge, M Koekemoer, A Kollmeier, J A Kounkel, M Krishnarao, D Krumpe, M Lacerna, I Lago, P J A Laporte, C Liu, A Liu, C Liu, X Lopes, A R Macktoobian, M Malanushenko, V Maoz, D Masseron, T Masters, K L Matijevic, G Mcbride, A Medan, I Merloni, A Morrison, S Myers, N Mészáros, S Negrete, C A Nidever, D L Nitschelm, C Oravetz, A Oravetz, D Pan, K Peng, Y Pinsonneault, M H Pogge, R Qiu, D De Andrade Queiroz, A B Ramirez, S V Rix, H.-W Rosso, D F Runnoe, J Salvato, M Sanchez, S F Santana, F A Saydjari, A Sayres, C Schlaufman, K C Schneider, D P Schwope, A Serna, J Shen, Y Sobeck, J Song, Y.-Y Souto, D Spoo, T Stassun, K G Steinmetz, M Straumit, I Stringfellow, G Sánchez-Gallego, J Taghizadeh-Popp, M Tayar, J Thakar, A Tissera, P B Tkachenko, A Toledo, H H Trakhtenbrot, B Trincado, J G F Troup, N Trump, J R Tuttle, S Ulloa, N Vazquez-Mata, J A Alfaro, P V Villanova, S Wachter, S Weijmans, A.-M Wheeler, A Wilson, J Wojno, L Wolf, J Xue, X.-X Ybarra, J E Zari, E Zasowski, G , The eighteenth data release of the sloan digital sky surveys: Targeting and first spectra from sdss-vAlmeida, A., Anderson, S. F., Argudo-Fernández, M., Badenes, C., Barger, K., Barrera-Ballesteros, J. K., Ben- der, C. F., Benitez, E., Besser, F., Bizyaev, D., Blanton, M. R., Bochanski, J., Bovy, J., Brandt, W. N., Brownstein, J. R., Buchner, J., Bulbul, E., Burchett, J. N., Díaz, M. C., Carlberg, J. K., Casey, A. R., Chandra, V., Cherinka, B., Chiappini, C., Coker, A. A., Comparat, J., Conroy, C., Contardo, G., Cortes, A., Covey, K., Crane, J. D., Cunha, K., Dabbieri, C., au2, J. W. D. J., Davis, M. C., Lee, N. D., Delgado, J. E. M., Demasi, S., Mille, F. D., Donor, J., Dow, P., Dwelly, T., Eracleous, M., Eriksen, J., Fan, X., Farr, E., Frederick, S., Fries, L., Frinchaboy, P., Gaensicke, B. T., Ge, J.,Ávila, C. G., Grabowski, K., Grier, C., Guiglion, G., Gupta, P., Hall, P., Hawkins, K., Hayes, C. R., Hermes, J. J., Hernández-García, L., Hogg, D. W., Holtzman, J. A., Ibarra-Medel, H. J., Ji, A., Jofre, P., Johnson, J. A., Jones, A. M., Kinemuchi, K., Kluge, M., Koekemoer, A., Kollmeier, J. A., Kounkel, M., Krishnarao, D., Krumpe, M., Lacerna, I., Lago, P. J. A., Laporte, C., Liu, A., Liu, C., Liu, X., Lopes, A. R., Mack- toobian, M., Malanushenko, V., Maoz, D., Masseron, T., Masters, K. L., Matijevic, G., McBride, A., Medan, I., Merloni, A., Morrison, S., Myers, N., Mészáros, S., Negrete, C. A., Nidever, D. L., Nitschelm, C., Oravetz, A., Oravetz, D., Pan, K., Peng, Y., Pinsonneault, M. H., Pogge, R., Qiu, D., de Andrade Queiroz, A. B., Ramirez, S. V., Rix, H.-W., Rosso, D. F., Runnoe, J., Salvato, M., Sanchez, S. F., Santana, F. A., Saydjari, A., Sayres, C., Schlaufman, K. C., Schneider, D. P., Schwope, A., Serna, J., Shen, Y., Sobeck, J., Song, Y.-Y., Souto, D., Spoo, T., Stassun, K. G., Steinmetz, M., Straumit, I., Stringfellow, G., Sánchez-Gallego, J., Taghizadeh-Popp, M., Tayar, J., Thakar, A., Tissera, P. B., Tkachenko, A., Toledo, H. H., Trakhtenbrot, B., Trincado, J. G. F., Troup, N., Trump, J. R., Tuttle, S., Ulloa, N., Vazquez-Mata, J. A., Alfaro, P. V., Villanova, S., Wachter, S., Weijmans, A.-M., Wheeler, A., Wilson, J., Wojno, L., Wolf, J., Xue, X.-X., Ybarra, J. E., Zari, E., and Zasowski, G. The eighteenth data release of the sloan digital sky surveys: Targeting and first spectra from sdss-v, 2023.</p>
<p>Coupling local to global star formation in spiral galaxies: the effect of differential rotation. C J Aouad, P A James, I V Chilingarian, 10.1093/mnras/staa1945Monthly Notices of the Royal Astronomical Society. 4964Aouad, C. J., James, P. A., and Chilingarian, I. V. Coupling local to global star formation in spiral galaxies: the effect of differential rotation. Monthly Notices of the Royal Astronomical Society, 496(4):5211-5226, jul 2020. doi: 10.1093/mnras/staa1945.</p>
<p>C L Borgman, M F Wofford, 10.48550/arXiv.2109.01707arXiv:2109.01707From Data Processes to Data Products: Knowledge Infrastructures in Astronomy. arXiv e-prints, art. Borgman, C. L. and Wofford, M. F. From Data Processes to Data Products: Knowledge Infrastructures in Astronomy. arXiv e-prints, art. arXiv:2109.01707, September 2021. doi: 10.48550/arXiv.2109.01707.</p>
<p>. T B Brown, B Mann, N Ryder, M Subbiah, J Kaplan, P Dhariwal, A Neelakantan, P Shyam, G Sastry, A Askell, S Agarwal, A Herbert-Voss, G Krueger, T Henighan, R Child, A Ramesh, D M Ziegler, J Wu, C Winter, C Hesse, M Chen, E Sigler, M Litwin, S Gray, B Chess, J Clark, C Berner, S Mccandlish, A Radford, I Sutskever, Amodei , D , Language models are few-shot learnersBrown, T. B., Mann, B., Ryder, N., Subbiah, M., Kaplan, J., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., Askell, A., Agarwal, S., Herbert-Voss, A., Krueger, G., Henighan, T., Child, R., Ramesh, A., Ziegler, D. M., Wu, J., Winter, C., Hesse, C., Chen, M., Sigler, E., Litwin, M., Gray, S., Chess, B., Clark, J., Berner, C., McCandlish, S., Radford, A., Sutskever, I., and Amodei, D. Language models are few-shot learners, 2020.</p>
<p>Y Chen, R Zhong, S Zha, G Karypis, H He, arXiv:2110.07814Metalearning via language model in-context tuning. arXiv preprintChen, Y., Zhong, R., Zha, S., Karypis, G., and He, H. Meta- learning via language model in-context tuning. arXiv preprint arXiv:2110.07814, 2021.</p>
<p>Chasing the impact of the Gaia-Sausage-Enceladus merger on the formation of the Milky Way thick disc. I Ciucȃ, D Kawata, Y.-S Ting, R J J Grand, A Miglio, M Hayden, J Baba, F Fragkoudi, S Monty, S Buder, Freeman , K , 10.1093/mnrasl/slad033Monthly Notices of the Royal Astronomical Society. Ciucȃ, I., Kawata, D., Ting, Y.-S., Grand, R. J. J., Miglio, A., Hayden, M., Baba, J., Fragkoudi, F., Monty, S., Buder, S., and Freeman, K. Chasing the impact of the Gaia-Sausage- Enceladus merger on the formation of the Milky Way thick disc. Monthly Notices of the Royal Astronomical Society, March 2023. doi: 10.1093/mnrasl/slad033.</p>
<p>J Devlin, M.-W Chang, K Lee, K Toutanova, Bert, 10.48550/arXiv.1810.04805arXiv:1810.04805Pre-training of Deep Bidirectional Transformers for Language Understanding. arXiv e-prints, art. Devlin, J., Chang, M.-W., Lee, K., and Toutanova, K. BERT: Pre-training of Deep Bidirectional Transform- ers for Language Understanding. arXiv e-prints, art. arXiv:1810.04805, October 2018. doi: 10.48550/arXiv. 1810.04805.</p>
<p>A feasibility study of answer-agnostic question generation for education. L Dugan, E Miltsakaki, S Upadhyay, E Ginsberg, H Gonzalez, D Choi, C Yuan, C Callison-Burch, 10.18653/v1/2022.findings-acl.151Findings of the Association for Computational Linguistics: ACL 2022. Dublin, IrelandAssociation for Computational LinguisticsDugan, L., Miltsakaki, E., Upadhyay, S., Ginsberg, E., Gon- zalez, H., Choi, D., Yuan, C., and Callison-Burch, C. A feasibility study of answer-agnostic question generation for education. In Findings of the Association for Compu- tational Linguistics: ACL 2022, pp. 1919-1926, Dublin, Ireland, May 2022. Association for Computational Lin- guistics. doi: 10.18653/v1/2022.findings-acl.151.</p>
<p>Can gpt-3 pass a writer's turing test. K Elkins, J Chun, Journal of Cultural Analytics. 522020Elkins, K. and Chun, J. Can gpt-3 pass a writer's turing test? Journal of Cultural Analytics, 5(2), 2020.</p>
<p>. C Fabricius, X Luri, F Arenou, C Babusiaux, A Helmi, T Muraveva, C Reylé, F Spoto, A Vallenari, T Antoja, E Balbinot, C Barache, N Bauchet, A Bragaglia, D Busonero, T Cantat-Gaudin, J M Carrasco, S Diakité, M Fabrizio, F Figueras, A Garcia-Gutierrez, A Garofalo, C Jordi, P Kervella, S Khanna, N Leclerc, E Licata, S Lambert, P M Marrese, A Masip, P Ramos, N Robichon, A C Robin, M Romero-Gómez, S Rubele, Weiler , 10.1051/0004-6361/202039834Astronomy &amp;amp. 6495AstrophysicsFabricius, C., Luri, X., Arenou, F., Babusiaux, C., Helmi, A., Muraveva, T., Reylé , C., Spoto, F., Vallenari, A., An- toja, T., Balbinot, E., Barache, C., Bauchet, N., Bragaglia, A., Busonero, D., Cantat-Gaudin, T., Carrasco, J. M., Di- akité, S., Fabrizio, M., Figueras, F., Garcia-Gutierrez, A., Garofalo, A., Jordi, C., Kervella, P., Khanna, S., Leclerc, N., Licata, E., Lambert, S., Marrese, P. M., Masip, A., Ramos, P., Robichon, N., Robin, A. C., Romero-Gómez, M., Rubele, S., and Weiler, M. <i>gaia</i>early data release 3. Astronomy &amp; Astrophysics, 649:A5, apr 2021. doi: 10.1051/0004-6361/202039834.</p>
<p>On the effectiveness of adapterbased tuning for pretrained language model adaptation. R He, L Liu, H Ye, Q Tan, B Ding, L Cheng, J.-W Low, L Bing, Si , L , arXiv:2106.03164arXiv preprintHe, R., Liu, L., Ye, H., Tan, Q., Ding, B., Cheng, L., Low, J.-W., Bing, L., and Si, L. On the effectiveness of adapter- based tuning for pretrained language model adaptation. arXiv preprint arXiv:2106.03164, 2021.</p>
<p>E J Hu, Y Shen, P Wallis, Z Allen-Zhu, Y Li, S Wang, L Wang, Chen , W Lora, 10.48550/arXiv.2106.09685arXiv:2106.09685Low-Rank Adaptation of Large Language Models. arXiv e-prints, art. Hu, E. J., Shen, Y., Wallis, P., Allen-Zhu, Z., Li, Y., Wang, S., Wang, L., and Chen, W. LoRA: Low-Rank Adap- tation of Large Language Models. arXiv e-prints, art. arXiv:2106.09685, June 2021. doi: 10.48550/arXiv.2106. 09685.</p>
<p>Compacter: Efficient low-rank hypercomplex adapter layers. R Karimi Mahabadi, J Henderson, S Ruder, Advances in Neural Information Processing Systems. 34Karimi Mahabadi, R., Henderson, J., and Ruder, S. Com- pacter: Efficient low-rank hypercomplex adapter layers. Advances in Neural Information Processing Systems, 34: 1022-1035, 2021.</p>
<p>Learn to explain: Multimodal reasoning via thought chains for science question answering. P Lu, S Mishra, T Xia, L Qiu, K.-W Chang, S.-C Zhu, O Tafjord, P Clark, A Kalyan, Advances in Neural Information Processing Systems. Koyejo, S., Mohamed, S., Agarwal, A., Belgrave, D., Cho, K., and Oh, A.Curran Associates, Inc35Lu, P., Mishra, S., Xia, T., Qiu, L., Chang, K.-W., Zhu, S.-C., Tafjord, O., Clark, P., and Kalyan, A. Learn to explain: Multimodal reasoning via thought chains for science question answering. In Koyejo, S., Mohamed, S., Agarwal, A., Belgrave, D., Cho, K., and Oh, A. (eds.), Advances in Neural Information Processing Systems, vol- ume 35, pp. 2507-2521. Curran Associates, Inc., 2022.</p>
<p>. abs/2303.08774OpenAI. Gpt-4 technical report. ArXiv. OpenAI. Gpt-4 technical report. ArXiv, abs/2303.08774, 2023.</p>
<p>L Ouyang, J Wu, X Jiang, D Almeida, C L Wainwright, P Mishkin, C Zhang, S Agarwal, K Slama, A Ray, J Schulman, J Hilton, F Kelton, L Miller, M Simens, A Askell, P Welinder, P Christiano, J Leike, R Lowe, 10.48550/arXiv.2203.02155arXiv:2203.02155Training language models to follow instructions with human feedback. arXiv e-prints, art. Ouyang, L., Wu, J., Jiang, X., Almeida, D., Wainwright, C. L., Mishkin, P., Zhang, C., Agarwal, S., Slama, K., Ray, A., Schulman, J., Hilton, J., Kelton, F., Miller, L., Simens, M., Askell, A., Welinder, P., Christiano, P., Leike, J., and Lowe, R. Training language models to follow instructions with human feedback. arXiv e-prints, art. arXiv:2203.02155, March 2022. doi: 10.48550/arXiv. 2203.02155.</p>
<p>Improving language understanding by generative pre-training. A Radford, K Narasimhan, Radford, A. and Narasimhan, K. Improving language un- derstanding by generative pre-training. 2018.</p>
<p>S F Sánchez, D C Medina, J K Barrera-Ballesteros, L Galbany, A Bolatto, T Wong, 10.48550/arXiv.2212.03738arXiv:2212.03738The local and global relations between Σ ⋆ , Σ SFR and Σ mol that regulate star-formation. arXiv e-prints, art. Sánchez, S. F., Gómez Medina, D. C., Barrera-Ballesteros, J. K., Galbany, L., Bolatto, A., and Wong, T. The local and global relations between Σ ⋆ , Σ SFR and Σ mol that regulate star-formation. arXiv e-prints, art. arXiv:2212.03738, December 2022. doi: 10.48550/arXiv. 2212.03738.</p>
<p>Study of galaxies on large-scale filaments in simulations. A Singh, S Mahajan, J S Bagla, 10.1093/mnras/staa1913Monthly Notices of the Royal Astronomical Society. 4972Singh, A., Mahajan, S., and Bagla, J. S. Study of galaxies on large-scale filaments in simulations. Monthly Notices of the Royal Astronomical Society, 497(2):2265-2275, jul 2020. doi: 10.1093/mnras/staa1913.</p>
<p>Visualizing attention in transformer-based language representation models. J Vig, arXiv:1904.02679arXiv preprintVig, J. Visualizing attention in transformer-based language representation models. arXiv preprint arXiv:1904.02679, 2019.</p>
<p>Self-consistency improves chain of thought reasoning in language models. X Wang, J Wei, D Schuurmans, Q Le, E Chi, D Zhou, arXiv:2203.11171arXiv preprintWang, X., Wei, J., Schuurmans, D., Le, Q., Chi, E., and Zhou, D. Self-consistency improves chain of thought reasoning in language models. arXiv preprint arXiv:2203.11171, 2022.</p>
<p>Chain of thought prompting elicits reasoning in large language models. J Wei, X Wang, D Schuurmans, M Bosma, E Chi, Q Le, D Zhou, arXiv:2201.11903arXiv preprintWei, J., Wang, X., Schuurmans, D., Bosma, M., Chi, E., Le, Q., and Zhou, D. Chain of thought prompting elic- its reasoning in large language models. arXiv preprint arXiv:2201.11903, 2022.</p>
<p>Galaxy evolution in all five CANDELS fields and IllustrisTNG: Morphological, structural, and the major merger evolution to z ∼ 3. A Whitney, L Ferreira, C J Conselice, Duncan , K , 10.3847/1538-4357/ac1422The Astrophysical Journal. 9192139Whitney, A., Ferreira, L., Conselice, C. J., and Duncan, K. Galaxy evolution in all five CANDELS fields and IllustrisTNG: Morphological, structural, and the major merger evolution to z ∼ 3. The Astrophysical Journal, 919(2):139, oct 2021. doi: 10.3847/1538-4357/ac1422.</p>
<p>An explanation of in-context learning as implicit bayesian inference. S M Xie, A Raghunathan, P Liang, T Ma, arXiv:2111.02080arXiv preprintXie, S. M., Raghunathan, A., Liang, P., and Ma, T. An explanation of in-context learning as implicit bayesian inference. arXiv preprint arXiv:2111.02080, 2021.</p>
<p>Automatic chain of thought prompting in large language models. Z Zhang, A Zhang, M Li, A Smola, arXiv:2210.03493arXiv preprintZhang, Z., Zhang, A., Li, M., and Smola, A. Automatic chain of thought prompting in large language models. arXiv preprint arXiv:2210.03493, 2022.</p>            </div>
        </div>

    </div>
</body>
</html>