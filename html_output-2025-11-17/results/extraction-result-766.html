<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-766 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-766</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-766</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-20.html">extraction-schema-20</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <p><strong>Paper ID:</strong> paper-173992893</p>
                <p><strong>Paper Title:</strong> Review of Causal Discovery Methods Based on Graphical Models</p>
                <p><strong>Paper Abstract:</strong> A fundamental task in various disciplines of science, including biology, is to find underlying causal relations and make use of them. Causal relations can be seen if interventions are properly applied; however, in many cases they are difficult or even impossible to conduct. It is then necessary to discover causal relations by analyzing statistical properties of purely observational data, which is known as causal discovery or causal structure search. This paper aims to give a introduction to and a brief review of the computational methods for causal discovery that were developed in the past three decades, including constraint-based and score-based methods and those based on functional causal models, supplemented by some illustrations and applications.</p>
                <p><strong>Cost:</strong> 0.025</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e766.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e766.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>FCI</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Fast Causal Inference</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A constraint-based causal discovery algorithm that outputs a Partial Ancestral Graph (PAG) and is asymptotically correct in the presence of latent (unmeasured) confounders by using conditional independence tests and orientation rules.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>Fast Causal Inference (FCI)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Starts from an undirected graph and prunes edges using conditional independence tests; then orients edges with a set of rules that allow for uncertainty due to latent confounders, producing a PAG that encodes adjacencies, possible directed edges, and bidirected edges indicating unmeasured confounding. It does not assume absence of latent common causes and therefore can distinguish some spurious associations caused by unobserved confounders.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Observational datasets (general; biological datasets cited)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Applied to purely observational data sets where latent confounders may exist (e.g., biological expression data); not an interactive/virtual lab per se but used on observational collections and sometimes combined with interventional/exogenous variable information.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td>Explicit modeling of latent confounding via orientation marks (o) and bidirected edges in PAG; uses conditional independence testing to detect relationships that are due to confounding.</td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>Unmeasured confounding (latent common causes), indirect associations arising from unobserved variables</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td>Systematic conditional independence tests across conditioning sets; orientation rules reveal patterns (e.g., colliders) and bidirected edges that indicate unmeasured confounders.</td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td>Asymptotic correctness under Causal Markov and Faithfulness assumptions and statistical consistency of CI tests; cannot always fully distinguish confounding vs direct effect but outputs uncertainty (o marks, bidirected edges) to indicate confounding possibilities.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>FCI asymptotically recovers correct ancestral relations even with latent confounders and represents uncertainty explicitly (e.g., bidirected edges), enabling explicit detection of some spurious associations due to unobserved common causes.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Review of Causal Discovery Methods Based on Graphical Models', 'publication_date_yy_mm': '2019-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e766.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e766.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>GFCI</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Greedy Fast Causal Inference (GFCI)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A hybrid algorithm combining score-based GES and constraint-based FCI: GES is used to produce a supergraph and FCI prunes and orients it to account for latent confounding, often improving empirical accuracy over FCI alone.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>GFCI (GES + FCI hybrid)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Runs GES to obtain an initial supergraph (high-recall skeleton) then applies FCI-style conditional independence pruning and orientation rules to account for latent confounders and refine the graph; aims to combine the strengths of score-based and constraint-based approaches.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Observational datasets (general)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Used on synthetic and empirical observational datasets where latent confounding may exist; not specific to interactive environments.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td>Leverages FCI's orientation and bidirected-edge representation to handle latent confounders; uses GES to produce a supergraph to reduce missed adjacencies (addresses indirectly spurious omission/false negatives).</td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>Unmeasured confounding, false negatives due to limited scoring/conditioning</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td>Score-guided search to propose edges (GES) and conditional independence tests plus FCI orientation to detect confounding-induced spurious associations.</td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td>Pruning of GES supergraph using conditional independence decisions (FCI) to remove edges likely due to spurious associations; empirical simulations in paper indicate improved accuracy over FCI alone.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td>Reported to be more accurate in many simulations than original FCI (textual claim; no numeric metrics given in this review).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Combining score-based supergraph (GES) with FCI pruning often improves empirical accuracy, helping to reduce errors that arise when only constraint-based pruning is used; retains capability to indicate latent confounders.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Review of Causal Discovery Methods Based on Graphical Models', 'publication_date_yy_mm': '2019-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e766.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e766.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>PC</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Peter-Clark (PC) algorithm</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A constraint-based causal discovery algorithm that recovers a Markov equivalence class (CPDAG) from conditional independence tests under the assumptions of Causal Markov, Faithfulness, i.i.d., and no latent confounders.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>PC algorithm</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Starts from a complete undirected graph and removes edges when conditional independence is detected given conditioning sets of increasing size, then orients v-structures and propagates orientations via deterministic rules to output a CPDAG representing a Markov equivalence class.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>High-dimensional observational data (e.g., genomics, fMRI preprocessing warnings noted)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Applied to i.i.d. observational data; scalable to sparse graphs with many variables; the review emphasizes checking data preprocessing (e.g., filtering) because it affects non-Gaussian features used by other methods.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>Does not handle latent confounders (unmeasured common causes) -- these are a primary source of spurious associations that PC cannot resolve.</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td>Conditional independence tests (e.g., Fisher Z, BIC differences) across conditioning sets to decide adjacencies.</td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td>Produces CPDAG representing equivalence class; cannot refute spurious associations due to unmeasured confounders; authors recommend bootstrapping and other diagnostics to assess stability.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>PC is consistent under its assumptions and scales well for sparse high-dimensional linear or multinomial cases but cannot handle latent confounders; preprocessing choices can create or remove non-Gaussian signals that some causal methods rely upon.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Review of Causal Discovery Methods Based on Graphical Models', 'publication_date_yy_mm': '2019-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e766.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e766.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LiNGAM</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Linear Non-Gaussian Acyclic Model (LiNGAM)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A class of functional causal models assuming linear relations with non-Gaussian independent noise, enabling identification of causal direction and structure via Independent Component Analysis (ICA).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>LiNGAM (ICA-LiNGAM, DirectLiNGAM)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Assumes X = B X + E with independent non-Gaussian noise components; identifies causal ordering and coefficients by applying ICA to recover independent sources and mapping ICA solution to structural matrix B; variants include DirectLiNGAM (recursive regression + independence tests) and sparse ICA variants and Two-Step improvements.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Continuous observational data (e.g., gene expression, neural signals)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Designed for continuous-variable datasets where at most one noise component is Gaussian; not interactive per se but applicable to empirical biological datasets.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td>Extensions (overcomplete ICA) can estimate effects of latent confounders; sparse ICA variants and Two-Step attempt to enforce sparsity to mitigate spurious links.</td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>Potentially handles latent confounders via overcomplete ICA in extensions; addresses spurious directionality that arises in linear-Gaussian degeneracy by requiring non-Gaussianity.</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td>Independent component analysis to detect independent noise sources and compare independence between residuals and predictors; uses non-Gaussianity to identify causal direction (Darmois–Skitovich/ICA theory).</td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td>Sparsity constraints on ICA weight matrices (ICA with sparse connections) to reduce spurious edges; Two-Step enforces sparsity in estimation.</td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td>Direction validated by independence tests between estimated noise and assumed cause; if independence holds only in one direction, the other is refuted.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Non-Gaussianity enables identifiability of causal directions in linear models; sparse and Two-Step extensions improve estimation and help control spurious edges, and overcomplete ICA can be used to model latent confounders in some settings.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Review of Causal Discovery Methods Based on Graphical Models', 'publication_date_yy_mm': '2019-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e766.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e766.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Two-Step</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Two-Step algorithm (ICA-based causal discovery with sparsity and confounder handling)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A two-phase procedure that first finds adjacencies (an undirected skeleton), then applies ICA-based techniques with sparsity constraints to orient edges and allow for latent confounding.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>Two-Step algorithm</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Uses an adjacency search to get an initial undirected graph, then applies ICA-based estimation with sparsity constraints (and optionally overcomplete ICA) to estimate causal directions and allow for unmeasured confounding; non-Gaussian features are exploited to orient edges and permit cycles.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Biological data (e.g., fMRI, gene/protein expression) and simulated time series used in empirical assessments</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Applied to empirical biological datasets and synthetic benchmarks; not inherently interactive but robust to certain measurement errors according to cited empirical studies.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td>Allows unmeasured confounding via overcomplete ICA; enforces sparsity in ICA weights to reduce spurious edges; adjacency search reduces candidate distractor connections before orientation.</td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>Unmeasured confounders, spurious edges due to dense/noisy estimates, measurement error (robustness up to certain variance levels noted)</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td>Adjacency search followed by ICA to identify independent components and infer confounding structure; sparsity encourages removal/downweighting of weak/spurious connections.</td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td>Sparsity regularization on ICA weight matrix; pruning of edges after adjacency search.</td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td>Directional decisions rest on independence properties of residuals and non-Gaussian ICA decomposition; failure to meet independence/ICA assumptions undermines inferred edges.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td>Reported (via Sanchez-Romero et al., 2019, cited) to have high precision but suffered recall losses in some simulated fMRI-style tests.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Two-Step uses adjacency plus ICA with sparsity to allow latent confounding and reduce spurious adjacencies; empirical comparisons cited indicate high precision but sometimes lower recall relative to alternatives.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Review of Causal Discovery Methods Based on Graphical Models', 'publication_date_yy_mm': '2019-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e766.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e766.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>FASK</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Fast Adjacency Skewness (FASK) algorithm</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An adjacency-search-based causal discovery method that uses non-Gaussian (skewness) features to orient edges and allows cyclic graphs; empirically robust to measurement error and performs well on fMRI-like simulations.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>FASK</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Performs an adjacency search to obtain an initial undirected graph, then uses non-Gaussianity (e.g., skewness-based tests) to direct edges, allowing for 2-cycles and feedback; can incorporate knowledge of exogenous interventions to improve recovery.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Biological datasets (Sachs protein-signaling dataset), fMRI time series simulations</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Applied to empirical datasets with known experimental interventions (Sachs) and simulated neuroimaging data; not a virtual lab but can leverage interventional knowledge when available.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td>Uses non-Gaussian statistics to distinguish causal directions (reducing spurious orientation) and is empirically robust to moderate measurement error; adjacency pruning reduces irrelevant variables.</td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>Measurement error (noise in variables), false orientations due to Gaussianity/weak signals, potential latent confounders not explicitly modeled (but adjacency step reduces spurious edges).</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td>Adjacency search followed by non-Gaussian (skewness-based) orientation tests; when experimental/exogenous knowledge is provided, uses it to orient edges and recover causal relations.</td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td>Empirical robustness checks; absence of expected edge (Mek→ERK missing in one application) noted as limitation; uses interventional knowledge to validate and orient edges where available.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td>Cited (Sanchez-Romero et al., 2019) as among methods with best precision and recall on simulated fMRI tasks; robust to simulated measurement error whose variance is no larger than measurement-free variance.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>FASK combines adjacency search with non-Gaussian orientation tests and can incorporate interventional knowledge; empirical studies cited show strong precision and recall and robustness to moderate measurement error, making it effective at reducing spurious orientations and noisy distractors.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Review of Causal Discovery Methods Based on Graphical Models', 'publication_date_yy_mm': '2019-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e766.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e766.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Causal Stability</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Causal Stability Ranking algorithm</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A stability-based pipeline that uses repeated subsampling, application of PC, and IDA-based total effect estimation to rank variables by stable causal influence, thereby downweighting spurious signals.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>Causal Stability Ranking</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Draw many subsamples (e.g., 100 subsamples of size n/2), run PC on each, estimate a lower bound on absolute total causal effect for each gene via IDA across DAGs implied by PC, compute minima per subsample, rank genes by effect magnitude, and aggregate ranks across thresholds q to obtain stable rankings that downweight unstable/spurious associations.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Large-scale gene expression datasets (Arabidopsis thaliana example)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Applied to genome-wide expression data with many potential distractors; not interactive but uses resampling to detect robust causal signals across heterogeneous samples.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td>Subsampling (stability selection) combined with aggregation of lower-bound total effect estimates; ranking by frequency in top-q lists downweights spurious, unstable associations.</td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>Irrelevant variables, unstable associations arising from sampling variability, weak spurious edges due to high-dimensionality or measurement noise</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td>Assess frequency of appearance and magnitude of estimated total causal effects across many subsamples; low-frequency/low-magnitude associations are detected as unstable (spurious) and demoted.</td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td>Use minima of estimated effects over DAGs and frequency across q thresholds to reduce influence of unstable/spurious genes; median rank across q values used as final robust ranking.</td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td>Experimental validation of top-ranked candidates (mutant experiments) used to confirm/refute inferred causal genes; empirical validation reduced false positives and found novel causal genes.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td>In the Arabidopsis example, among top 25 ranked genes 5 were known causal genes and 4 novel causal genes were experimentally validated (after excluding mutants with viability issues), indicating practical effectiveness in downweighting spurious signals.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Stability via subsampling plus IDA-based effect estimation can effectively prioritize true causal variables and downweight spurious associations; subsequent experimental validation confirmed several novel causal genes.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Review of Causal Discovery Methods Based on Graphical Models', 'publication_date_yy_mm': '2019-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e766.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e766.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Bootstrap / Subsampling (stability)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Bootstrap / Subsampling stability estimation</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Resampling-based approach recommended to assess reliability of discovered edges by estimating edge frequencies across bootstrap/subsample runs, helping detect and downweight spurious edges.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>Bootstrap / Subsampling stability</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Repeatedly run a causal search algorithm (e.g., PC) on bootstrap or subsample replicates of the data, and record frequency/probability of each discovered edge to quantify robustness; edges with low frequency are candidates for being spurious.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>General observational datasets (recommended across biological applications)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Applicable to any dataset amenable to a chosen causal search method; serves as a diagnostic/post-processing tool rather than a discovery algorithm itself.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td>Empirical frequency-based downweighting / thresholding: edges that are unstable across resamples are treated as likely spurious and downweighted or removed.</td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>Sampling variability-induced spurious associations, weak/dataset-specific associations, unstable edges due to preprocessing or noise</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td>Compute edge appearance frequencies across repeated bootstrap/subsample runs; low-frequency edges flagged as unstable/spurious.</td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td>Thresholding or ranking by frequency; incorporate frequency estimates into confidence assignments for edges.</td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td>Stability evidence used to deprioritize edges for follow-up; not a formal refutation but a practical filter; authors note that stable outputs are not guaranteed correct, but instability strongly suggests unreliability.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Bootstrapping/subsampling is recommended as a practical technique to estimate edge probabilities and detect spurious edges; instability across resamples is a strong signal that an inferred edge is unreliable.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Review of Causal Discovery Methods Based on Graphical Models', 'publication_date_yy_mm': '2019-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e766.8">
                <h3 class="extraction-instance">Extracted Data Instance 8 (e766.8)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>KCI</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Kernel-based Conditional Independence test (KCI)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A nonparametric kernel-based statistical test for conditional independence used to enable constraint-based causal discovery in nonlinear settings.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>Kernel-based conditional independence test (KCI)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Computes a test statistic using kernel embeddings of distributions to test whether X is independent of Y given Z without assuming parametric forms; can be plugged into PC/FCI-style algorithms to detect conditional independences in nonlinear/non-Gaussian data.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Nonlinear observational datasets (general; used within MEC estimation pipelines)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Used where dependencies are nonlinear and parametric CI tests (e.g., Fisher Z) are invalid; not inherently interactive.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td>By enabling reliable conditional independence detection in nonlinear settings, it helps avoid spurious edges that would arise from misspecified parametric CI tests.</td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>Nonlinear dependencies that could be mistaken for direct associations under parametric tests; model misspecification-induced spurious edges</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td>Nonparametric kernel-based CI test statistic and permutation/bootstrap for significance.</td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td>Used within constraint-based pipelines to more reliably eliminate edges via CI tests; thus helps refute spurious adjacency claims that arise from nonlinear dependencies.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>KCI provides a practical nonparametric CI test enabling constraint-based causal discovery in nonlinear settings and thereby reduces spurious edges arising from misspecified parametric CI tests.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Review of Causal Discovery Methods Based on Graphical Models', 'publication_date_yy_mm': '2019-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e766.9">
                <h3 class="extraction-instance">Extracted Data Instance 9 (e766.9)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Measurement-error methods</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Causal discovery with measurement error (identifiability conditions)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Analytical and algorithmic work characterizing identifiability of causal models when observed variables are corrupted by measurement error and proposing conditions under which underlying causal relations can still be identified.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>Causal discovery with measurement error (Zhang et al., 2017a, identifiability work)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Investigates sufficient conditions for partial or full identifiability of the causal model of the underlying measurement-error-free variables when observed data are contaminated by measurement noise with unknown variance; aims to enable adjusted causal discovery or correction procedures.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Observational datasets with measurement noise (general; biological measurements highlighted)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Applies to datasets where measurements are proxies/noisy instruments rather than exact variables; not an interactive/virtual lab method.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td>Explicit modeling of measurement error and derivation of identifiability conditions that allow recovery or partial identification of causal relations despite measurement noise (addresses spurious correlations induced by measurement error).</td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>Measurement error (instrument/proxy noise) that can create or mask conditional independence relations, leading to spurious causal inferences.</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td>Theoretical identifiability analysis; criteria to detect when recovery is possible based on assumptions about noise and structure.</td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td>Provide conditions under which causal edges inferred from noisy data can be corrected or identified; does not necessarily give a single downweighting algorithm but provides foundations for methods to handle measurementerror-induced spuriousness.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Measurement error can substantially change causal discovery outputs; Zhang et al. (2017a) provide identifiability conditions showing when the underlying causal model can be partially or fully recovered despite unknown measurement noise, offering a principled route to detect and address measurement-induced spurious signals.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Review of Causal Discovery Methods Based on Graphical Models', 'publication_date_yy_mm': '2019-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e766.10">
                <h3 class="extraction-instance">Extracted Data Instance 10 (e766.10)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Nonstationary / Distribution-shift methods</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Causal discovery from nonstationary / heterogeneous data (mechanism change detection)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Approaches that exploit changes across domains or over time (distribution shift) to detect causal skeletons and orient edges by treating mechanistic changes as informative signals rather than nuisances.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>Nonstationary / distribution-shift causal discovery (Huang et al., Zhang et al.)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Detects points or domains where mechanism parameters change, uses those changes to identify causal skeleton and orient edges (since causal mechanisms may change differently from spurious associations), and can estimate nonstationary driving forces; leverages heterogeneity as a source of identification.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Heterogeneous / time-varying observational datasets (multi-domain, time series)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Designed for datasets collected across changing environments or over time; not interactive experiments but can be used with multi-environment observational data or pooled datasets.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td>Uses distribution shifts/changes in mechanisms to separate stable causal relations from unstable spurious associations; mechanism-change detection and cross-domain contrasts act to downweight spurious correlations tied to particular contexts.</td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>Spurious associations that arise from pooled heterogeneous data, context-specific correlations, nonstationary noise/processes, and selection effects that vary across domains.</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td>Detect mechanism changes (e.g., change-point or domain-indexed changes) and compare conditional relations across domains; edges that vary in a context-consistent causal manner can be oriented while context-specific spurious links are demoted.</td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td>Exploit that spurious associations typically do not show the stable mechanistic change patterns that causal mechanisms do; use cross-domain consistency to refute spurious edges.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Distribution shift/nonstationarity can be beneficial for causal identification: by mining driving forces of change and contrasting domains, one can detect mechanism changes and use them to identify causal skeletons and directions while downweighting spurious, context-specific correlations.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Review of Causal Discovery Methods Based on Graphical Models', 'publication_date_yy_mm': '2019-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e766.11">
                <h3 class="extraction-instance">Extracted Data Instance 11 (e766.11)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Missing-data PC</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Modified PC for missing data (Tu et al., 2019)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A variant of the PC algorithm adapted to handle missing data whose output is asymptotically correct under certain assumptions on the missingness mechanism.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>Modified PC algorithm for missing data</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Adjusts the PC algorithm's conditional independence evaluations to account for missingness patterns (rather than ignoring or simple imputation), producing asymptotically correct output under assumptions about the missingness mechanism.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Observational datasets with missing entries (e.g., healthcare data)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Targets datasets where missingness is not completely at random and naive application of causal discovery would yield spurious edges; not a virtual lab method.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td>Explicitly models or conditions CI testing procedures on missingness mechanism assumptions to avoid spurious edges induced by nonrandom missingness.</td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>Spurious conditional dependencies/independencies introduced by outcome-dependent or nonrandom missing data mechanisms.</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td>Modify conditional independence tests to account for missingness mechanisms; theoretical conditions provided under which output is consistent.</td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td>Asymptotic correctness under stated missingness assumptions serves to refute spurious associations that arise solely from missing data patterns.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Missing data that are not handled appropriately can create spurious edges; a modified PC algorithm can produce asymptotically correct causal outputs when assumptions about the missingness mechanism hold.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Review of Causal Discovery Methods Based on Graphical Models', 'publication_date_yy_mm': '2019-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e766.12">
                <h3 class="extraction-instance">Extracted Data Instance 12 (e766.12)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Network Deconvolution</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Network Deconvolution</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A method to distinguish direct dependencies from indirect or transitive associations in networks, thereby reducing spurious inferred links that arise from indirect paths.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>Network Deconvolution</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Given an observed dependency matrix containing both direct and indirect effects, applies a deconvolution technique to estimate the direct dependency matrix by mathematically removing the contributions of indirect paths (e.g., via matrix algebra approximations), making inferred networks less affected by indirect/spurious associations.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Static dependency networks inferred from observational data (e.g., gene coexpression networks)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Preprocessing/postprocessing tool to sharpen inferred networks by removing indirect/transitive spurious edges; not an interactive environment method.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td>Mathematical deconvolution to remove indirect/transitive dependencies that act as distractors, yielding a matrix of direct dependencies.</td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>Indirect (transitive) associations, correlations due to network walk effects rather than direct causal links</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td>Matrix-based deconvolution separating direct from indirect contributions under model assumptions.</td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td>Subtract/attenuate indirect path contributions from observed dependencies to downweight spurious indirect edges.</td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Network deconvolution is a general method to reduce spurious indirect dependencies in inferred networks, helping downstream causal or association analyses focus on direct relationships.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Review of Causal Discovery Methods Based on Graphical Models', 'publication_date_yy_mm': '2019-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Estimating feedforward and feedback effective connections from fmri time series: Assessments of statistical methods <em>(Rating: 2)</em></li>
                <li>A linear non-Gaussian acyclic model for causal discovery <em>(Rating: 2)</em></li>
                <li>On the identifiability of the post-nonlinear causal model <em>(Rating: 2)</em></li>
                <li>Causal discovery in the presence of measurement error: Identifiability conditions <em>(Rating: 2)</em></li>
                <li>Causal discovery in the presence of missing data <em>(Rating: 2)</em></li>
                <li>Causal discovery from nonstationary/heterogeneous data: Skeleton estimation and orientation determination <em>(Rating: 2)</em></li>
                <li>Network deconvolution as a general method to distinguish direct dependencies in networks <em>(Rating: 2)</em></li>
                <li>Causal stability ranking <em>(Rating: 2)</em></li>
                <li>Discovering temporal causal relations from subsampled data <em>(Rating: 1)</em></li>
                <li>Kernel-based conditional independence test and application in causal discovery <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-766",
    "paper_id": "paper-173992893",
    "extraction_schema_id": "extraction-schema-20",
    "extracted_data": [
        {
            "name_short": "FCI",
            "name_full": "Fast Causal Inference",
            "brief_description": "A constraint-based causal discovery algorithm that outputs a Partial Ancestral Graph (PAG) and is asymptotically correct in the presence of latent (unmeasured) confounders by using conditional independence tests and orientation rules.",
            "citation_title": "",
            "mention_or_use": "mention",
            "method_name": "Fast Causal Inference (FCI)",
            "method_description": "Starts from an undirected graph and prunes edges using conditional independence tests; then orients edges with a set of rules that allow for uncertainty due to latent confounders, producing a PAG that encodes adjacencies, possible directed edges, and bidirected edges indicating unmeasured confounding. It does not assume absence of latent common causes and therefore can distinguish some spurious associations caused by unobserved confounders.",
            "environment_name": "Observational datasets (general; biological datasets cited)",
            "environment_description": "Applied to purely observational data sets where latent confounders may exist (e.g., biological expression data); not an interactive/virtual lab per se but used on observational collections and sometimes combined with interventional/exogenous variable information.",
            "handles_distractors": true,
            "distractor_handling_technique": "Explicit modeling of latent confounding via orientation marks (o) and bidirected edges in PAG; uses conditional independence testing to detect relationships that are due to confounding.",
            "spurious_signal_types": "Unmeasured confounding (latent common causes), indirect associations arising from unobserved variables",
            "detection_method": "Systematic conditional independence tests across conditioning sets; orientation rules reveal patterns (e.g., colliders) and bidirected edges that indicate unmeasured confounders.",
            "downweighting_method": null,
            "refutation_method": "Asymptotic correctness under Causal Markov and Faithfulness assumptions and statistical consistency of CI tests; cannot always fully distinguish confounding vs direct effect but outputs uncertainty (o marks, bidirected edges) to indicate confounding possibilities.",
            "uses_active_learning": null,
            "inquiry_strategy": null,
            "performance_with_robustness": null,
            "performance_without_robustness": null,
            "has_ablation_study": null,
            "number_of_distractors": null,
            "key_findings": "FCI asymptotically recovers correct ancestral relations even with latent confounders and represents uncertainty explicitly (e.g., bidirected edges), enabling explicit detection of some spurious associations due to unobserved common causes.",
            "uuid": "e766.0",
            "source_info": {
                "paper_title": "Review of Causal Discovery Methods Based on Graphical Models",
                "publication_date_yy_mm": "2019-06"
            }
        },
        {
            "name_short": "GFCI",
            "name_full": "Greedy Fast Causal Inference (GFCI)",
            "brief_description": "A hybrid algorithm combining score-based GES and constraint-based FCI: GES is used to produce a supergraph and FCI prunes and orients it to account for latent confounding, often improving empirical accuracy over FCI alone.",
            "citation_title": "",
            "mention_or_use": "mention",
            "method_name": "GFCI (GES + FCI hybrid)",
            "method_description": "Runs GES to obtain an initial supergraph (high-recall skeleton) then applies FCI-style conditional independence pruning and orientation rules to account for latent confounders and refine the graph; aims to combine the strengths of score-based and constraint-based approaches.",
            "environment_name": "Observational datasets (general)",
            "environment_description": "Used on synthetic and empirical observational datasets where latent confounding may exist; not specific to interactive environments.",
            "handles_distractors": true,
            "distractor_handling_technique": "Leverages FCI's orientation and bidirected-edge representation to handle latent confounders; uses GES to produce a supergraph to reduce missed adjacencies (addresses indirectly spurious omission/false negatives).",
            "spurious_signal_types": "Unmeasured confounding, false negatives due to limited scoring/conditioning",
            "detection_method": "Score-guided search to propose edges (GES) and conditional independence tests plus FCI orientation to detect confounding-induced spurious associations.",
            "downweighting_method": null,
            "refutation_method": "Pruning of GES supergraph using conditional independence decisions (FCI) to remove edges likely due to spurious associations; empirical simulations in paper indicate improved accuracy over FCI alone.",
            "uses_active_learning": null,
            "inquiry_strategy": null,
            "performance_with_robustness": "Reported to be more accurate in many simulations than original FCI (textual claim; no numeric metrics given in this review).",
            "performance_without_robustness": null,
            "has_ablation_study": null,
            "number_of_distractors": null,
            "key_findings": "Combining score-based supergraph (GES) with FCI pruning often improves empirical accuracy, helping to reduce errors that arise when only constraint-based pruning is used; retains capability to indicate latent confounders.",
            "uuid": "e766.1",
            "source_info": {
                "paper_title": "Review of Causal Discovery Methods Based on Graphical Models",
                "publication_date_yy_mm": "2019-06"
            }
        },
        {
            "name_short": "PC",
            "name_full": "Peter-Clark (PC) algorithm",
            "brief_description": "A constraint-based causal discovery algorithm that recovers a Markov equivalence class (CPDAG) from conditional independence tests under the assumptions of Causal Markov, Faithfulness, i.i.d., and no latent confounders.",
            "citation_title": "",
            "mention_or_use": "mention",
            "method_name": "PC algorithm",
            "method_description": "Starts from a complete undirected graph and removes edges when conditional independence is detected given conditioning sets of increasing size, then orients v-structures and propagates orientations via deterministic rules to output a CPDAG representing a Markov equivalence class.",
            "environment_name": "High-dimensional observational data (e.g., genomics, fMRI preprocessing warnings noted)",
            "environment_description": "Applied to i.i.d. observational data; scalable to sparse graphs with many variables; the review emphasizes checking data preprocessing (e.g., filtering) because it affects non-Gaussian features used by other methods.",
            "handles_distractors": false,
            "distractor_handling_technique": null,
            "spurious_signal_types": "Does not handle latent confounders (unmeasured common causes) -- these are a primary source of spurious associations that PC cannot resolve.",
            "detection_method": "Conditional independence tests (e.g., Fisher Z, BIC differences) across conditioning sets to decide adjacencies.",
            "downweighting_method": null,
            "refutation_method": "Produces CPDAG representing equivalence class; cannot refute spurious associations due to unmeasured confounders; authors recommend bootstrapping and other diagnostics to assess stability.",
            "uses_active_learning": null,
            "inquiry_strategy": null,
            "performance_with_robustness": null,
            "performance_without_robustness": null,
            "has_ablation_study": null,
            "number_of_distractors": null,
            "key_findings": "PC is consistent under its assumptions and scales well for sparse high-dimensional linear or multinomial cases but cannot handle latent confounders; preprocessing choices can create or remove non-Gaussian signals that some causal methods rely upon.",
            "uuid": "e766.2",
            "source_info": {
                "paper_title": "Review of Causal Discovery Methods Based on Graphical Models",
                "publication_date_yy_mm": "2019-06"
            }
        },
        {
            "name_short": "LiNGAM",
            "name_full": "Linear Non-Gaussian Acyclic Model (LiNGAM)",
            "brief_description": "A class of functional causal models assuming linear relations with non-Gaussian independent noise, enabling identification of causal direction and structure via Independent Component Analysis (ICA).",
            "citation_title": "",
            "mention_or_use": "mention",
            "method_name": "LiNGAM (ICA-LiNGAM, DirectLiNGAM)",
            "method_description": "Assumes X = B X + E with independent non-Gaussian noise components; identifies causal ordering and coefficients by applying ICA to recover independent sources and mapping ICA solution to structural matrix B; variants include DirectLiNGAM (recursive regression + independence tests) and sparse ICA variants and Two-Step improvements.",
            "environment_name": "Continuous observational data (e.g., gene expression, neural signals)",
            "environment_description": "Designed for continuous-variable datasets where at most one noise component is Gaussian; not interactive per se but applicable to empirical biological datasets.",
            "handles_distractors": null,
            "distractor_handling_technique": "Extensions (overcomplete ICA) can estimate effects of latent confounders; sparse ICA variants and Two-Step attempt to enforce sparsity to mitigate spurious links.",
            "spurious_signal_types": "Potentially handles latent confounders via overcomplete ICA in extensions; addresses spurious directionality that arises in linear-Gaussian degeneracy by requiring non-Gaussianity.",
            "detection_method": "Independent component analysis to detect independent noise sources and compare independence between residuals and predictors; uses non-Gaussianity to identify causal direction (Darmois–Skitovich/ICA theory).",
            "downweighting_method": "Sparsity constraints on ICA weight matrices (ICA with sparse connections) to reduce spurious edges; Two-Step enforces sparsity in estimation.",
            "refutation_method": "Direction validated by independence tests between estimated noise and assumed cause; if independence holds only in one direction, the other is refuted.",
            "uses_active_learning": null,
            "inquiry_strategy": null,
            "performance_with_robustness": null,
            "performance_without_robustness": null,
            "has_ablation_study": null,
            "number_of_distractors": null,
            "key_findings": "Non-Gaussianity enables identifiability of causal directions in linear models; sparse and Two-Step extensions improve estimation and help control spurious edges, and overcomplete ICA can be used to model latent confounders in some settings.",
            "uuid": "e766.3",
            "source_info": {
                "paper_title": "Review of Causal Discovery Methods Based on Graphical Models",
                "publication_date_yy_mm": "2019-06"
            }
        },
        {
            "name_short": "Two-Step",
            "name_full": "Two-Step algorithm (ICA-based causal discovery with sparsity and confounder handling)",
            "brief_description": "A two-phase procedure that first finds adjacencies (an undirected skeleton), then applies ICA-based techniques with sparsity constraints to orient edges and allow for latent confounding.",
            "citation_title": "",
            "mention_or_use": "mention",
            "method_name": "Two-Step algorithm",
            "method_description": "Uses an adjacency search to get an initial undirected graph, then applies ICA-based estimation with sparsity constraints (and optionally overcomplete ICA) to estimate causal directions and allow for unmeasured confounding; non-Gaussian features are exploited to orient edges and permit cycles.",
            "environment_name": "Biological data (e.g., fMRI, gene/protein expression) and simulated time series used in empirical assessments",
            "environment_description": "Applied to empirical biological datasets and synthetic benchmarks; not inherently interactive but robust to certain measurement errors according to cited empirical studies.",
            "handles_distractors": true,
            "distractor_handling_technique": "Allows unmeasured confounding via overcomplete ICA; enforces sparsity in ICA weights to reduce spurious edges; adjacency search reduces candidate distractor connections before orientation.",
            "spurious_signal_types": "Unmeasured confounders, spurious edges due to dense/noisy estimates, measurement error (robustness up to certain variance levels noted)",
            "detection_method": "Adjacency search followed by ICA to identify independent components and infer confounding structure; sparsity encourages removal/downweighting of weak/spurious connections.",
            "downweighting_method": "Sparsity regularization on ICA weight matrix; pruning of edges after adjacency search.",
            "refutation_method": "Directional decisions rest on independence properties of residuals and non-Gaussian ICA decomposition; failure to meet independence/ICA assumptions undermines inferred edges.",
            "uses_active_learning": null,
            "inquiry_strategy": null,
            "performance_with_robustness": "Reported (via Sanchez-Romero et al., 2019, cited) to have high precision but suffered recall losses in some simulated fMRI-style tests.",
            "performance_without_robustness": null,
            "has_ablation_study": null,
            "number_of_distractors": null,
            "key_findings": "Two-Step uses adjacency plus ICA with sparsity to allow latent confounding and reduce spurious adjacencies; empirical comparisons cited indicate high precision but sometimes lower recall relative to alternatives.",
            "uuid": "e766.4",
            "source_info": {
                "paper_title": "Review of Causal Discovery Methods Based on Graphical Models",
                "publication_date_yy_mm": "2019-06"
            }
        },
        {
            "name_short": "FASK",
            "name_full": "Fast Adjacency Skewness (FASK) algorithm",
            "brief_description": "An adjacency-search-based causal discovery method that uses non-Gaussian (skewness) features to orient edges and allows cyclic graphs; empirically robust to measurement error and performs well on fMRI-like simulations.",
            "citation_title": "",
            "mention_or_use": "mention",
            "method_name": "FASK",
            "method_description": "Performs an adjacency search to obtain an initial undirected graph, then uses non-Gaussianity (e.g., skewness-based tests) to direct edges, allowing for 2-cycles and feedback; can incorporate knowledge of exogenous interventions to improve recovery.",
            "environment_name": "Biological datasets (Sachs protein-signaling dataset), fMRI time series simulations",
            "environment_description": "Applied to empirical datasets with known experimental interventions (Sachs) and simulated neuroimaging data; not a virtual lab but can leverage interventional knowledge when available.",
            "handles_distractors": true,
            "distractor_handling_technique": "Uses non-Gaussian statistics to distinguish causal directions (reducing spurious orientation) and is empirically robust to moderate measurement error; adjacency pruning reduces irrelevant variables.",
            "spurious_signal_types": "Measurement error (noise in variables), false orientations due to Gaussianity/weak signals, potential latent confounders not explicitly modeled (but adjacency step reduces spurious edges).",
            "detection_method": "Adjacency search followed by non-Gaussian (skewness-based) orientation tests; when experimental/exogenous knowledge is provided, uses it to orient edges and recover causal relations.",
            "downweighting_method": null,
            "refutation_method": "Empirical robustness checks; absence of expected edge (Mek→ERK missing in one application) noted as limitation; uses interventional knowledge to validate and orient edges where available.",
            "uses_active_learning": null,
            "inquiry_strategy": null,
            "performance_with_robustness": "Cited (Sanchez-Romero et al., 2019) as among methods with best precision and recall on simulated fMRI tasks; robust to simulated measurement error whose variance is no larger than measurement-free variance.",
            "performance_without_robustness": null,
            "has_ablation_study": null,
            "number_of_distractors": null,
            "key_findings": "FASK combines adjacency search with non-Gaussian orientation tests and can incorporate interventional knowledge; empirical studies cited show strong precision and recall and robustness to moderate measurement error, making it effective at reducing spurious orientations and noisy distractors.",
            "uuid": "e766.5",
            "source_info": {
                "paper_title": "Review of Causal Discovery Methods Based on Graphical Models",
                "publication_date_yy_mm": "2019-06"
            }
        },
        {
            "name_short": "Causal Stability",
            "name_full": "Causal Stability Ranking algorithm",
            "brief_description": "A stability-based pipeline that uses repeated subsampling, application of PC, and IDA-based total effect estimation to rank variables by stable causal influence, thereby downweighting spurious signals.",
            "citation_title": "",
            "mention_or_use": "mention",
            "method_name": "Causal Stability Ranking",
            "method_description": "Draw many subsamples (e.g., 100 subsamples of size n/2), run PC on each, estimate a lower bound on absolute total causal effect for each gene via IDA across DAGs implied by PC, compute minima per subsample, rank genes by effect magnitude, and aggregate ranks across thresholds q to obtain stable rankings that downweight unstable/spurious associations.",
            "environment_name": "Large-scale gene expression datasets (Arabidopsis thaliana example)",
            "environment_description": "Applied to genome-wide expression data with many potential distractors; not interactive but uses resampling to detect robust causal signals across heterogeneous samples.",
            "handles_distractors": true,
            "distractor_handling_technique": "Subsampling (stability selection) combined with aggregation of lower-bound total effect estimates; ranking by frequency in top-q lists downweights spurious, unstable associations.",
            "spurious_signal_types": "Irrelevant variables, unstable associations arising from sampling variability, weak spurious edges due to high-dimensionality or measurement noise",
            "detection_method": "Assess frequency of appearance and magnitude of estimated total causal effects across many subsamples; low-frequency/low-magnitude associations are detected as unstable (spurious) and demoted.",
            "downweighting_method": "Use minima of estimated effects over DAGs and frequency across q thresholds to reduce influence of unstable/spurious genes; median rank across q values used as final robust ranking.",
            "refutation_method": "Experimental validation of top-ranked candidates (mutant experiments) used to confirm/refute inferred causal genes; empirical validation reduced false positives and found novel causal genes.",
            "uses_active_learning": false,
            "inquiry_strategy": null,
            "performance_with_robustness": "In the Arabidopsis example, among top 25 ranked genes 5 were known causal genes and 4 novel causal genes were experimentally validated (after excluding mutants with viability issues), indicating practical effectiveness in downweighting spurious signals.",
            "performance_without_robustness": null,
            "has_ablation_study": null,
            "number_of_distractors": null,
            "key_findings": "Stability via subsampling plus IDA-based effect estimation can effectively prioritize true causal variables and downweight spurious associations; subsequent experimental validation confirmed several novel causal genes.",
            "uuid": "e766.6",
            "source_info": {
                "paper_title": "Review of Causal Discovery Methods Based on Graphical Models",
                "publication_date_yy_mm": "2019-06"
            }
        },
        {
            "name_short": "Bootstrap / Subsampling (stability)",
            "name_full": "Bootstrap / Subsampling stability estimation",
            "brief_description": "Resampling-based approach recommended to assess reliability of discovered edges by estimating edge frequencies across bootstrap/subsample runs, helping detect and downweight spurious edges.",
            "citation_title": "",
            "mention_or_use": "mention",
            "method_name": "Bootstrap / Subsampling stability",
            "method_description": "Repeatedly run a causal search algorithm (e.g., PC) on bootstrap or subsample replicates of the data, and record frequency/probability of each discovered edge to quantify robustness; edges with low frequency are candidates for being spurious.",
            "environment_name": "General observational datasets (recommended across biological applications)",
            "environment_description": "Applicable to any dataset amenable to a chosen causal search method; serves as a diagnostic/post-processing tool rather than a discovery algorithm itself.",
            "handles_distractors": true,
            "distractor_handling_technique": "Empirical frequency-based downweighting / thresholding: edges that are unstable across resamples are treated as likely spurious and downweighted or removed.",
            "spurious_signal_types": "Sampling variability-induced spurious associations, weak/dataset-specific associations, unstable edges due to preprocessing or noise",
            "detection_method": "Compute edge appearance frequencies across repeated bootstrap/subsample runs; low-frequency edges flagged as unstable/spurious.",
            "downweighting_method": "Thresholding or ranking by frequency; incorporate frequency estimates into confidence assignments for edges.",
            "refutation_method": "Stability evidence used to deprioritize edges for follow-up; not a formal refutation but a practical filter; authors note that stable outputs are not guaranteed correct, but instability strongly suggests unreliability.",
            "uses_active_learning": false,
            "inquiry_strategy": null,
            "performance_with_robustness": null,
            "performance_without_robustness": null,
            "has_ablation_study": null,
            "number_of_distractors": null,
            "key_findings": "Bootstrapping/subsampling is recommended as a practical technique to estimate edge probabilities and detect spurious edges; instability across resamples is a strong signal that an inferred edge is unreliable.",
            "uuid": "e766.7",
            "source_info": {
                "paper_title": "Review of Causal Discovery Methods Based on Graphical Models",
                "publication_date_yy_mm": "2019-06"
            }
        },
        {
            "name_short": "KCI",
            "name_full": "Kernel-based Conditional Independence test (KCI)",
            "brief_description": "A nonparametric kernel-based statistical test for conditional independence used to enable constraint-based causal discovery in nonlinear settings.",
            "citation_title": "",
            "mention_or_use": "mention",
            "method_name": "Kernel-based conditional independence test (KCI)",
            "method_description": "Computes a test statistic using kernel embeddings of distributions to test whether X is independent of Y given Z without assuming parametric forms; can be plugged into PC/FCI-style algorithms to detect conditional independences in nonlinear/non-Gaussian data.",
            "environment_name": "Nonlinear observational datasets (general; used within MEC estimation pipelines)",
            "environment_description": "Used where dependencies are nonlinear and parametric CI tests (e.g., Fisher Z) are invalid; not inherently interactive.",
            "handles_distractors": null,
            "distractor_handling_technique": "By enabling reliable conditional independence detection in nonlinear settings, it helps avoid spurious edges that would arise from misspecified parametric CI tests.",
            "spurious_signal_types": "Nonlinear dependencies that could be mistaken for direct associations under parametric tests; model misspecification-induced spurious edges",
            "detection_method": "Nonparametric kernel-based CI test statistic and permutation/bootstrap for significance.",
            "downweighting_method": null,
            "refutation_method": "Used within constraint-based pipelines to more reliably eliminate edges via CI tests; thus helps refute spurious adjacency claims that arise from nonlinear dependencies.",
            "uses_active_learning": null,
            "inquiry_strategy": null,
            "performance_with_robustness": null,
            "performance_without_robustness": null,
            "has_ablation_study": null,
            "number_of_distractors": null,
            "key_findings": "KCI provides a practical nonparametric CI test enabling constraint-based causal discovery in nonlinear settings and thereby reduces spurious edges arising from misspecified parametric CI tests.",
            "uuid": "e766.8",
            "source_info": {
                "paper_title": "Review of Causal Discovery Methods Based on Graphical Models",
                "publication_date_yy_mm": "2019-06"
            }
        },
        {
            "name_short": "Measurement-error methods",
            "name_full": "Causal discovery with measurement error (identifiability conditions)",
            "brief_description": "Analytical and algorithmic work characterizing identifiability of causal models when observed variables are corrupted by measurement error and proposing conditions under which underlying causal relations can still be identified.",
            "citation_title": "",
            "mention_or_use": "mention",
            "method_name": "Causal discovery with measurement error (Zhang et al., 2017a, identifiability work)",
            "method_description": "Investigates sufficient conditions for partial or full identifiability of the causal model of the underlying measurement-error-free variables when observed data are contaminated by measurement noise with unknown variance; aims to enable adjusted causal discovery or correction procedures.",
            "environment_name": "Observational datasets with measurement noise (general; biological measurements highlighted)",
            "environment_description": "Applies to datasets where measurements are proxies/noisy instruments rather than exact variables; not an interactive/virtual lab method.",
            "handles_distractors": true,
            "distractor_handling_technique": "Explicit modeling of measurement error and derivation of identifiability conditions that allow recovery or partial identification of causal relations despite measurement noise (addresses spurious correlations induced by measurement error).",
            "spurious_signal_types": "Measurement error (instrument/proxy noise) that can create or mask conditional independence relations, leading to spurious causal inferences.",
            "detection_method": "Theoretical identifiability analysis; criteria to detect when recovery is possible based on assumptions about noise and structure.",
            "downweighting_method": null,
            "refutation_method": "Provide conditions under which causal edges inferred from noisy data can be corrected or identified; does not necessarily give a single downweighting algorithm but provides foundations for methods to handle measurementerror-induced spuriousness.",
            "uses_active_learning": null,
            "inquiry_strategy": null,
            "performance_with_robustness": null,
            "performance_without_robustness": null,
            "has_ablation_study": null,
            "number_of_distractors": null,
            "key_findings": "Measurement error can substantially change causal discovery outputs; Zhang et al. (2017a) provide identifiability conditions showing when the underlying causal model can be partially or fully recovered despite unknown measurement noise, offering a principled route to detect and address measurement-induced spurious signals.",
            "uuid": "e766.9",
            "source_info": {
                "paper_title": "Review of Causal Discovery Methods Based on Graphical Models",
                "publication_date_yy_mm": "2019-06"
            }
        },
        {
            "name_short": "Nonstationary / Distribution-shift methods",
            "name_full": "Causal discovery from nonstationary / heterogeneous data (mechanism change detection)",
            "brief_description": "Approaches that exploit changes across domains or over time (distribution shift) to detect causal skeletons and orient edges by treating mechanistic changes as informative signals rather than nuisances.",
            "citation_title": "",
            "mention_or_use": "mention",
            "method_name": "Nonstationary / distribution-shift causal discovery (Huang et al., Zhang et al.)",
            "method_description": "Detects points or domains where mechanism parameters change, uses those changes to identify causal skeleton and orient edges (since causal mechanisms may change differently from spurious associations), and can estimate nonstationary driving forces; leverages heterogeneity as a source of identification.",
            "environment_name": "Heterogeneous / time-varying observational datasets (multi-domain, time series)",
            "environment_description": "Designed for datasets collected across changing environments or over time; not interactive experiments but can be used with multi-environment observational data or pooled datasets.",
            "handles_distractors": true,
            "distractor_handling_technique": "Uses distribution shifts/changes in mechanisms to separate stable causal relations from unstable spurious associations; mechanism-change detection and cross-domain contrasts act to downweight spurious correlations tied to particular contexts.",
            "spurious_signal_types": "Spurious associations that arise from pooled heterogeneous data, context-specific correlations, nonstationary noise/processes, and selection effects that vary across domains.",
            "detection_method": "Detect mechanism changes (e.g., change-point or domain-indexed changes) and compare conditional relations across domains; edges that vary in a context-consistent causal manner can be oriented while context-specific spurious links are demoted.",
            "downweighting_method": null,
            "refutation_method": "Exploit that spurious associations typically do not show the stable mechanistic change patterns that causal mechanisms do; use cross-domain consistency to refute spurious edges.",
            "uses_active_learning": null,
            "inquiry_strategy": null,
            "performance_with_robustness": null,
            "performance_without_robustness": null,
            "has_ablation_study": null,
            "number_of_distractors": null,
            "key_findings": "Distribution shift/nonstationarity can be beneficial for causal identification: by mining driving forces of change and contrasting domains, one can detect mechanism changes and use them to identify causal skeletons and directions while downweighting spurious, context-specific correlations.",
            "uuid": "e766.10",
            "source_info": {
                "paper_title": "Review of Causal Discovery Methods Based on Graphical Models",
                "publication_date_yy_mm": "2019-06"
            }
        },
        {
            "name_short": "Missing-data PC",
            "name_full": "Modified PC for missing data (Tu et al., 2019)",
            "brief_description": "A variant of the PC algorithm adapted to handle missing data whose output is asymptotically correct under certain assumptions on the missingness mechanism.",
            "citation_title": "",
            "mention_or_use": "mention",
            "method_name": "Modified PC algorithm for missing data",
            "method_description": "Adjusts the PC algorithm's conditional independence evaluations to account for missingness patterns (rather than ignoring or simple imputation), producing asymptotically correct output under assumptions about the missingness mechanism.",
            "environment_name": "Observational datasets with missing entries (e.g., healthcare data)",
            "environment_description": "Targets datasets where missingness is not completely at random and naive application of causal discovery would yield spurious edges; not a virtual lab method.",
            "handles_distractors": true,
            "distractor_handling_technique": "Explicitly models or conditions CI testing procedures on missingness mechanism assumptions to avoid spurious edges induced by nonrandom missingness.",
            "spurious_signal_types": "Spurious conditional dependencies/independencies introduced by outcome-dependent or nonrandom missing data mechanisms.",
            "detection_method": "Modify conditional independence tests to account for missingness mechanisms; theoretical conditions provided under which output is consistent.",
            "downweighting_method": null,
            "refutation_method": "Asymptotic correctness under stated missingness assumptions serves to refute spurious associations that arise solely from missing data patterns.",
            "uses_active_learning": null,
            "inquiry_strategy": null,
            "performance_with_robustness": null,
            "performance_without_robustness": null,
            "has_ablation_study": null,
            "number_of_distractors": null,
            "key_findings": "Missing data that are not handled appropriately can create spurious edges; a modified PC algorithm can produce asymptotically correct causal outputs when assumptions about the missingness mechanism hold.",
            "uuid": "e766.11",
            "source_info": {
                "paper_title": "Review of Causal Discovery Methods Based on Graphical Models",
                "publication_date_yy_mm": "2019-06"
            }
        },
        {
            "name_short": "Network Deconvolution",
            "name_full": "Network Deconvolution",
            "brief_description": "A method to distinguish direct dependencies from indirect or transitive associations in networks, thereby reducing spurious inferred links that arise from indirect paths.",
            "citation_title": "",
            "mention_or_use": "mention",
            "method_name": "Network Deconvolution",
            "method_description": "Given an observed dependency matrix containing both direct and indirect effects, applies a deconvolution technique to estimate the direct dependency matrix by mathematically removing the contributions of indirect paths (e.g., via matrix algebra approximations), making inferred networks less affected by indirect/spurious associations.",
            "environment_name": "Static dependency networks inferred from observational data (e.g., gene coexpression networks)",
            "environment_description": "Preprocessing/postprocessing tool to sharpen inferred networks by removing indirect/transitive spurious edges; not an interactive environment method.",
            "handles_distractors": true,
            "distractor_handling_technique": "Mathematical deconvolution to remove indirect/transitive dependencies that act as distractors, yielding a matrix of direct dependencies.",
            "spurious_signal_types": "Indirect (transitive) associations, correlations due to network walk effects rather than direct causal links",
            "detection_method": "Matrix-based deconvolution separating direct from indirect contributions under model assumptions.",
            "downweighting_method": "Subtract/attenuate indirect path contributions from observed dependencies to downweight spurious indirect edges.",
            "refutation_method": null,
            "uses_active_learning": null,
            "inquiry_strategy": null,
            "performance_with_robustness": null,
            "performance_without_robustness": null,
            "has_ablation_study": null,
            "number_of_distractors": null,
            "key_findings": "Network deconvolution is a general method to reduce spurious indirect dependencies in inferred networks, helping downstream causal or association analyses focus on direct relationships.",
            "uuid": "e766.12",
            "source_info": {
                "paper_title": "Review of Causal Discovery Methods Based on Graphical Models",
                "publication_date_yy_mm": "2019-06"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Estimating feedforward and feedback effective connections from fmri time series: Assessments of statistical methods",
            "rating": 2,
            "sanitized_title": "estimating_feedforward_and_feedback_effective_connections_from_fmri_time_series_assessments_of_statistical_methods"
        },
        {
            "paper_title": "A linear non-Gaussian acyclic model for causal discovery",
            "rating": 2,
            "sanitized_title": "a_linear_nongaussian_acyclic_model_for_causal_discovery"
        },
        {
            "paper_title": "On the identifiability of the post-nonlinear causal model",
            "rating": 2,
            "sanitized_title": "on_the_identifiability_of_the_postnonlinear_causal_model"
        },
        {
            "paper_title": "Causal discovery in the presence of measurement error: Identifiability conditions",
            "rating": 2,
            "sanitized_title": "causal_discovery_in_the_presence_of_measurement_error_identifiability_conditions"
        },
        {
            "paper_title": "Causal discovery in the presence of missing data",
            "rating": 2,
            "sanitized_title": "causal_discovery_in_the_presence_of_missing_data"
        },
        {
            "paper_title": "Causal discovery from nonstationary/heterogeneous data: Skeleton estimation and orientation determination",
            "rating": 2,
            "sanitized_title": "causal_discovery_from_nonstationaryheterogeneous_data_skeleton_estimation_and_orientation_determination"
        },
        {
            "paper_title": "Network deconvolution as a general method to distinguish direct dependencies in networks",
            "rating": 2,
            "sanitized_title": "network_deconvolution_as_a_general_method_to_distinguish_direct_dependencies_in_networks"
        },
        {
            "paper_title": "Causal stability ranking",
            "rating": 2,
            "sanitized_title": "causal_stability_ranking"
        },
        {
            "paper_title": "Discovering temporal causal relations from subsampled data",
            "rating": 1,
            "sanitized_title": "discovering_temporal_causal_relations_from_subsampled_data"
        },
        {
            "paper_title": "Kernel-based conditional independence test and application in causal discovery",
            "rating": 1,
            "sanitized_title": "kernelbased_conditional_independence_test_and_application_in_causal_discovery"
        }
    ],
    "cost": 0.025423499999999998,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Review of Causal Discovery Methods Based on Graphical Models
June 2019</p>
<p>Momiao Xiong 
Paola Sebastiani 
Shaoyu Li 
Kun Zhang 
Clark Glymour 
Kun Zhang 
Peter Spirtes </p>
<p>University of Texas Health Science Center
United States</p>
<p>Boston University
United States</p>
<p>Department of Philosophy
University of North Carolina at Charlotte
United States</p>
<p>Carnegie Mellon University
PittsburghPAUnited States</p>
<p>Review of Causal Discovery Methods Based on Graphical Models</p>
<p>Frontiers in Genetics | www.frontiersin.org
1524June 201910.3389/fgene.2019.00524Received: 07 August 2018 Accepted: 13 May 2019REVIEW Edited by: Reviewed by: *Correspondence: Specialty section: This article was submitted to Statistical Genetics and Methodology, a section of the journal Frontiers in Genetics Citation: Glymour C, Zhang K and Spirtes P (2019) Review of Causal Discovery Methods Based on Graphical Models. Front. Genet. 10:524.directed graphical causal modelscausal discoveryconditional independencestatistical independencestructural equation modelsnon-Gaussian distributionnon-linear models
A fundamental task in various disciplines of science, including biology, is to find underlying causal relations and make use of them. Causal relations can be seen if interventions are properly applied; however, in many cases they are difficult or even impossible to conduct. It is then necessary to discover causal relations by analyzing statistical properties of purely observational data, which is known as causal discovery or causal structure search. This paper aims to give a introduction to and a brief review of the computational methods for causal discovery that were developed in the past three decades, including constraint-based and score-based methods and those based on functional causal models, supplemented by some illustrations and applications.</p>
<p>INTRODUCTION</p>
<p>Almost all of science is about identifying causal relations and the laws or regularities that govern them. Since the seventeenth century beginnings of modern science, there have been two kinds of procedures, and resulting kinds of data, for discovering causes: manipulating and varying features of systems to see what other features do or do not change; and observing the variation of features of systems without manipulation. Both methods shone in the seventeenth century, when they were intertwined then as they are today. Evangelista Torricelli manipulated the angles and shapes of tubes filled with mercury standing in a basin of the stuff, showing the height of the mercury in the tubes did not vary; Pascal had a manometer of Torricelli's design carried up a mountain, the Puy de Dome, to show that the height of the mercury did vary with altitude. Galileo, for whom Torricelli worked, had identified (qualitatively) the orbits of Jovian satellites from observational time series, and similarly characterized sunspots. Kepler, Galileo's northern contemporary, adduced his three laws from planetary observations, and a generation later Newton laid the foundations of modern physics with a gravitational law adduced from solar system observations and a single experiment, on pendulums. Modern molecular biology is an experimental subject, but the foundation of biology, in Darwin's Origin of Species, has only a single experiment, the drifting of seeds.</p>
<p>This paper is about the scientific application of a kind of representation of causal relations, directed graphical causal models (DGCMs), and computerized methods for finding true causal representations of that kind from data, whether observational or experimental or both. We focus on it here because while apparently first proposed in 2000 for studies of gene expression (Murphy and Mian, 1999;Friedman et al., 2000;Spirtes et al., 2000), the models have found wide use in systems biology, especially in omics and in neural connectivity studies, and there has recently been an explosion in the number of algorithms that have been proposed and applied for discovering such representations in biological applications.</p>
<p>A traditional way to discover causal relations is to use interventions or randomized experiments, which is in many cases too expensive, too time-consuming, or even impossible. Therefore, revealing causal information by analyzing purely observational data, known as causal discovery, has drawn much attention (Spirtes et al., 2000). Past decades have seen a series of cross-disciplinary advances in algorithms for identifying causal relations and effect sizes from observational data or mixed experimental and observational data. These developments promise to enable better use of appropriate "big data." They have already been applied in genomics, ecology, epidemiology, space physics, clinical medicine, neuroscience, and many other domains, often with experimental or quasiexperimental validation of their predictions. Causal discovery will be the focus of this review. In traditional causality research, algorithms for identification of causal effects, or inferences about the effects of interventions, when the causal relations are completely or partially known, address a different class of problems; see Pearl (2000) and references therein.</p>
<p>We will start with the so-called constraint-based as well as score-based methods for causal discovery. Since the 1990's, conditional independence relationships in the data have been exploited to recover the underlying causal structure. Typical (conditional independence) constraint-based algorithms include PC and Fast Causal Inference (FCI) (Spirtes et al., 2000). PC assumes that there is no confounder (unobserved direct common cause of two measured variables), and its discovered causal information is asymptotically correct. FCI gives asymptotically correct results even in the presence of confounders. Such approaches are widely applicable because they can handle various types of data distributions and causal relations, given reliable conditional independence testing methods. However, they do not necessarily provide complete causal information because they output (independence) equivalence classes, i.e., a set of causal structures satisfying the same conditional independences. The PC and FCI algorithms produce graphical representations of these equivalence classes. In cases without confounders, there also exist score-based algorithms that aim to find the causal structure by optimizing a properly defined score function. Among them, Greedy Equivalence Search (GES) (Chickering, 2003) is a well-known two-phase procedure that directly searches over the space of equivalence classes.</p>
<p>Recently it has been shown that algorithms based on properly defined Functional Causal Models (FCMs) are able to distinguish between different Directed Acyclic Graphs (DAGs) in the same equivalence class. This benefit is owed to additional assumptions on the data distribution than conditional independence relations. A FCM represents the effect variable Y as a function of the direct causes X and some noise term E, i.e., Y = f (X, E), where E is independent of X. Thanks to the constrained functional classes, the causal direction between X and Y is identifiable because the independence condition between the noise and cause holds only for the true causal direction and is violated for the wrong direction. We will review causal discovery methods based on linear non-Gaussian models  or non-linear models Zhang and Hyvärinen, 2009b), and discuss their applicability.</p>
<p>In practice, for reliable causal discovery one needs to address specific challenges that are often posed in the causal process or the sampling process to generate the observed data. Therefore, we will discuss how to deal with a number of such practical issues, which include causality in time series, measure error, missing data, non-stationarity or heterogeneity of the data, and selection bias. We finally briefly discuss the applications of causal search algorithms as well as some related methods in biology and offer some guidance for their choice and use.</p>
<p>DIRECTED GRAPHICAL CAUSAL MODELS</p>
<p>A DGCM has the following components: (1) a set of variables, regarded as "random variables," (2) a set of directed edges between pairs of variables, each edge regarded as the hypothesis that the two variables would be associated if all other variables were fixed at some values while the tail variable is exogenously varied, and (3) a joint probability distribution over the possible values of all of the variables. The variables can be time indexed, forming a set of causally related stochastic processes; some of the variables can be unmeasured; the variables can be categorical, ordinal, or continuous; there can be measurement error and selection bias, also graphically represented; and there can be (and are usually assumed to be) omitted sources of variation specific to each variable, often deemed "noise" or "disturbances." A class of DGCMs, commonly presented as "structural equation models" (SEMs), or functional causal models (FCMs), assumes the value of each variable is a deterministic function of its direct causes in the graph and the unmeasured disturbances. The function linking a variable to its direct causes can be any whatsoever, although linear models are most common. The class of DGCMs includes, but is more general than, regression models, factor models, ARM time series models, latent class models, and others. Requiring neither initial conditions (except in time series) nor boundary conditions, DGCMs contrast with differential and partial differential systems of equations, which can also be representations of a system of causal relations.</p>
<p>Note that not all directed graphical models have causal interpretations-traditional graphical models provide a compact, yet flexible, way to decompose the joint distribution of the data as a product of simpler factors (Koller and Friedman, 2009), and the second component of a DGCM given above is essential for a directed graph to have a causal meaning. It states that two variables with an edge in between are associated if all other variables were fixed at some values while the tail variable is exogenously varied and, hence, indicates that if X i → X j in the directed graph, then X i is a direct cause of X j . In other words, it says that if X i → X j in the directed graph, then there exist interventions on X i that will directly change the distribution (or value) of X j . The causal Bayesian network was defined in a similar way by Pearl (2000, p.23). The pairing of a directed graph and a joint probability distribution on values of its variables is subject to constraints. In the case of a directed graph without cycles (no closed directed paths) the constraint is that a graphical condition-d-separation-must imply conditional independence in the probability distribution.</p>
<p>A path from a vertex X 1 to a vertex X n is a sequence of distinct vertices &lt; X 1 , ..., X n &gt; such that for each pair of vertices X i and X i+1 , there is an edge X i → X i+1 or X i+1 → X i . A directed path from X i to X n is a path in which for each pair X i and X i+1 , X i → X i+1 . A variable X i is a collider on a path P iff the path contains X i−1 → X i ← X i+1 (i.e., X i is a common effect of its neighbors on the path); otherwise it is a non-collider. For three disjoint sets of variables X, Y, and S, X is d-separated from Y conditional on S iff all paths between any member of X and any member of Y are blocked by S. The path P is blocked by S if 1) any non-collider on P is in S or if 2) P contains a collider which is not in S and whose descendants are not in S, either.</p>
<p>The graphical property of d-separation and its connection with conditional independence has a more intuitive but less practically useful equivalent in the local Markov Condition: every variable, X, in a directed acyclic graph, is independent of its non-descendants conditional on its parents (the variables with edges directed into X). The Markov condition can be thought of as a generalization of a familiar principle in experimental inference: fixing the values of variables that directly influence some variable of interest, X, "screens off " more remote causes that can only influence X via the more direct causes. Graphs that have the same d-separation properties are usually called "Markov equivalent" and imply the same conditional independence relations; a collection of all directed acyclic graphs that are Markov equivalent is a Markov Equivalence Class (MEC). For linear systems, the graphical property of d-separation has been generalized to directed graphs with cycles-closed directed paths (Spirtes, 1995). For a system that has a graph that represents the marginalized graph of a larger system, there is a corresponding relation, m-separation (Ayesha et al., 2009). When the Markov condition is assumed to hold for a causal graph and its associated population distribution, it is called the Causal Markov Assumption.</p>
<p>It is important to note that d-separation and related properties provide necessary but not sufficient conditions for conditional independence relations in the joint probability distribution over the values of the variables. The probability distribution may have additional conditional independence relations that are not entailed by d-separation applied to a graph. When no such extra conditional independence relations hold the distribution is said to be faithful to the graph (and when assumed to be true of the causal graph and its corresponding population distribution is called the Causal Faithfulness Assumption).</p>
<p>The reason for regarding the graphical relations in a DGCM as causal claims, not just a representation of associations or dependence, is that a DGCM entails claims about the results of many hypothetical experiments: if an acyclic DGCM contains a directed edge X → Y, the experimental claim is that if every other variable represented in the graph is held fixed, X and Y will covary if X is forced to vary, but not if Y is forced to vary. These experimental predictions can be computed from the graph and the probability distribution (Spirtes et al., 2001).</p>
<p>TRADITIONAL CONSTRAINT-BASED AND SCORE-BASED CAUSAL DISCOVERY METHODS</p>
<p>Roughly speaking, causal search methods are nothing but statistical estimation of parameters describing a graphical causal structure. It is computationally intensive estimation, but statistical estimation of parameters nonetheless, and so understood, something familiar. Most statistical estimators give a number or an interval, the estimated correlation, directly as a function of the data. But other estimators are more laborious. In all but simple models, the estimate of a posterior probability distribution, for example, or the estimate of a cyclic structural equation model usually requires iterative or Monte Carlo procedures, sometimes explicitly described as "searches" (Hoff, 2009).</p>
<p>The parameters to be estimated in the simple case of an acyclic model with non-interactive causes and no unobserved confounders (a confounder is an unobservable direct common cause of two observed variables) are just the entries in an N × N matrix, where N is the number of variables, and an (i, j)th entry indicates whether variable j is the parent of variable i. When "latent" variables are allowed, two possible values for an entry are needed, one indicating a direct connection, the other indicating a confounding by an unobserved common cause. A further value can be added when a direct connection between a pair of variables is unknown rather than known to be absent. The issue is how to estimate any of these parameters.</p>
<p>Statistical estimation has various desiderata. Statistical "consistency," that is, under sampling assumptions, the estimates converge in probability or almost surely to the true value; uniform convergence, in which there are probabilistic bounds on the size of errors at finite sample sizes, etc. Graphical causal model search based on the Faithfulness assumption and which conditional independence relations hold has in general only "pointwise" consistency, which does not provide finite sample error probabilities and does not provide confidence intervals for the estimated structure; although in sequences of models in which the number of variables and sparsity of the graph is controlled as a function of the sample size, there is a uniform consistency result when assumptions stronger than Faithfulness are made (Kalisch and Bühlmann, 2007).</p>
<p>For the most part, there are two classes of search algorithms, and their sub-classes and "nearby methods." One class of search algorithms tries to efficiently search for a MEC of graphs that most closely entails (under the Causal Markov and Faithfulness Assumptions) the set of conditional independence relations judged to hold in the population. Another class of algorithms estimates the dependencies or conditional independencies of each variable on independent noises, and uses these relations to construct a directed graphical model. We will illustrate how each of these is possible, and mention some variants.</p>
<p>The PC Algorithm</p>
<p>One of the oldest algorithms that is consistent under i.i.d. sampling assuming no latent confounders is the PC algorithm (Spirtes et al., 2001), which provides a search architecture into which can be plugged many statistical procedures for deciding conditional independence. Suppose then we have some such statistical decision procedure, which might be a hypothesis test for conditional independence, or a method based on the difference of fitting scores such as the Bayesian Information 
(C) The X − Y edge is removed because X ⊥ ⊥ Y . (D) The X − W and Y − W edges are removed because X ⊥ ⊥ W | Z and Y ⊥ ⊥ W | Z. (E) After finding v-structures. (F) After orientation propagation.
Criterion (BIC) between models with and without a particular directed edge.</p>
<p>Let the true structure be as in Figure 1A. By d-separation, this structure implies that X is independent of Y, written X ⊥ ⊥ Y, and that X and Y are each independent of W conditional on Z, written {X, Y} ⊥ ⊥ W | Z. Suppose when called, the statistical decision procedure finds these relations. PC is based on the fact that under the causal Markov condition and the faithfulness assumption, when there is no latent confounder, two variables are directly causally related (with an edge in between) if and only if there does not exist any subset of the remaining variables conditioning on which they are independent (Spirtes et al., 2001). It works like this:</p>
<ol>
<li>
<p>Form a complete undirected graph, as in Figure 1B. 2. Eliminate edges between variables that are unconditionally independent; in this case that is the X − Y edge, giving the graph in Figure 1C. 3. For each pair of variables (A, B) having an edge between them, and for each variable C with an edge connected to either of them, eliminate the edge between A and B if A ⊥ ⊥ B | C as in Figure 1D. 4. For each pair of variables A, B having an edge between them, and for each pair of variables {C, D} with edges both connected to A or both connected to B, eliminate the edge between A and
B if A ⊥ ⊥ B | {C, D}.
Continue checking independencies conditional on subsets of variables of increasing size n until there are no more adjacent pairs (A, B), such that there is a subset of variables of size n such that all of the variables in the subset are adjacent to A or all adjacent to B. In the considered example, Z and W are not independent conditional on X or on Y or on both X and Y, so there are no further statistical decisions to make. Similarly for X and Z, and for Y and Z.</p>
</li>
<li>
<p>For each triple of variables (A, B, C) such that A and B are adjacent, B and C are adjacent, and A and C are not adjacent, orient the edges A − B − C as A → B ← C, if B was not in the set conditioning on which A and C became independent and the edge between them was accordingly eliminated. We call such a triple of variables a v-structure.</p>
</li>
</ol>
<p>In the example, Z was not conditioned on in eliminating the X−Y edge, so orient X − Z − Y as X → Z ← Y, with the result given in Figure 1E.</p>
<ol>
<li>For each triple of variables such that A → B − C, and A and C are not adjacent, orient the edge B − C as B → C. This is called orientation propagation.</li>
</ol>
<p>In Figure 1F,
Y → Z − W is oriented as Y → Z → W.
In this example, the true structure is recovered uniquely. There are several other simple orientation propagation rules that are not illustrated here. The inference steps illustrated are not tuned for the example; they are instances of a general set of rules that hold for any i.i.d. data from a directed acyclic graph. If the conditional independence decisions are correct in the large sample limit, the PC algorithm is guaranteed to converge to the true Markov Equivalence Class in the large sample limit, assuming the Causal Markov and Faithfulness assumptions, i.i.d. samples, and no unmeasured confounders. Note that in some examples, none of orientation rules will apply to a given undirected edge, and that edge will remain undirected in the output. This means that while the two variables are known to be adjacent, it is not known which direction the edge points, or equivalently, there are two different members of the MEC which differ in the direction of that edge. The graphical object with a mixture of directed and undirected edges is called a pattern or CPDAG (Completed Partially Directed Acyclic Graph) that represents a MEC of DAGs. For sparse graphs, the PC algorithm is feasible on at least tens of thousands of variables (in the linear or multinomial case, in which conditional independence test is computationally efficient).</p>
<p>It is worth noting that the output of causal discovery algorithms such as PC is typically different from and much more informative than the so-called "conditional independence graph" (Lauritzen, 1996), in which two variables are not adjacent if and only if they are conditionally independent given all the remaining variables. (The conditional independence graph reduces to the "partial correlation graph" in the special case of jointly Gaussian variables.) In conditional independence graphs, edges are undirected, so they do not have a causal interpretation. Furthermore, the adjacencies may be different from the estimated causal graph; for instance, in the above example, X and Y, although marginally independent, are not conditionally independent given the rest of the variables, i.e., {Z, W}. As a consequence, in the conditional independence graph they will be adjacent, different from the causal graph.</p>
<p>The FCI Algorithm</p>
<p>Since its inception, a large number of variations of the PC algorithm have been published and it has been supplemented with a variety of heuristics, or "wrappers." The most important generalization is the Fast Causal Inference (FCI) Algorithm (Spirtes et al., 2001), which tolerates and sometimes discovers unknown confounding variables. Its results have been shown to be asymptotically correct even in the presence of confounders. Figure 2A, where U is an unmeasured variable, illustrates how this is possible without illustrating the full complexity of the FCI algorithm. As with the first state of the PC procedure, FCI calls statistical independence judgements to prune an undirected graph, yielding Figure 2B.</p>
<p>The "o" mark means it can be an arrow head or an arrow tail. The reason for the "o" marks will become apparent. FCI orients edges by a procedure similar to PC but without assuming that every edge is directed one way or the other. The X Z edge was eliminated without conditioning on Y because X and Z are unconditionally independent; the X Y Z triple is therefore oriented as a "collider", X &gt; Y &lt;⊸ Z. In the same way, Y Z W is found to be a collider, Y &gt; Z &lt;⊸ W, yielding Figure 2C.</p>
<p>The bidirected edge between Y and Z indicates that there is at least one unmeasured confounder of Y and Z. The remaining "o" symbols at X and W indicate that the algorithm cannot tell whether the X, Y connection is a directed edge from X to Y, or an unmeasured confounder, or both; the same for the Z and W. In fact, no algorithm based entirely on conditional independence relations can determine which of these is the case.</p>
<p>In contrast to this example, in which one can determine that there is at least one unmeasured confounder of Y and Z, there are other situations in which one can exclude the possibility of having confounders. For instance, consider the causal graph in Figure 1A and suppose we have enough data generated by it. Then in the output of FCI, we know that there cannot be any confounder of Z and W, because otherwise X and W cannot be independent conditioning on Z (X and W are not d-separated by Z if Z and W have a confounder).</p>
<p>As with PC there are variants of FCI, mostly designed to speed up the algorithm at the cost of reduced information (e.g., see the RFCI algorithm Colombo et al., 2012).</p>
<p>The Greedy Equivalence Search Architecture</p>
<p>Instead of beginning with a complete undirected graph, as in PC and FCI, the Greedy Equivalence Search (GES) (Chickering, 2003) starts with an empty graph, and adds currently needed edges, and then eliminates unnecessary edges in a pattern. At each step in the algorithm as decision is made as to whether adding a directed edge to the graph will increase fit measured by some quasi-Bayesian score such as BIC, or even by the Z score of a statistical hypothesis test, the edge that most improves fit is added. The resulting model is then mapped to the corresponding Markov equivalence class, and the procedure continued. When the score can no longer be improved, the GES algorithm then asks, edge by edge, which edge removal, if any, will most improve the score, until no further edges can thus be removed. The GES procedure is not so easy to illustrate as is PC, because its trajectory depends on the relative strengths of the associations and conditional associations of the variables. In the large sample limit, however, the two algorithms converge on the same Markov Equivalence Class under assumptions that are nearly the same. On finite samples, the algorithms may give different results, and there is as yet no GES style algorithm for cases with unknown confounders. GFCI (Ogarrio et al., 2016), a combination of GES and FCI, using GES to find a supergraph of the skeleton and FCI to prune the supergraph of the skeleton and find the orientations. GFCI has, however, proved more accurate in many simulations than the original FCI algorithm.</p>
<p>NON-GAUSSIAN OR NON-LINEAR METHODS BASED ON FUNCTIONAL CAUSAL MODELS</p>
<p>Constraint-based methods for causal discovery involve conditional independence tests, which would be a difficult task if the form of dependence is unknown. It has the advantage that it is generally applicable, but the disadvantages are that faithfulness is a strong assumption and that it may require very large sample sizes to get good conditional independence tests. Furthermore, the solution of this approach to causal discovery is usually non-unique, and in particular, it does not help in determining causal direction in the two-variable case, where no conditional independence relationship is available.</p>
<p>What information can we use to fully determine the causal structure? A fundamental issue is given two variables, how to distinguish cause from effect. To do so, one needs to find a way to capture the asymmetry between them. Intuitively, one may think that the physical process that generates effect from cause is more natural or simple in some way than recovering the cause from effect. How can we represent this generating process, and in which way is the causal process more natural or simple than the backward process?</p>
<p>When talking about the causal relation between two variables, traditionally people were often concerned with the linear-Gaussian case, where the involved variables are Gaussian with a linear causal relation, or the discrete case. It turned out that the former case is one of the atypical situations where the causal asymmetry does not leave a footprint in the observed data or their joint distribution, as explained later in this section.</p>
<p>Recently several causal discovery approaches based on Functional Causal Models (FCMs) have been proposed for causal discovery from continuous variables. A FCM represents the effect Y as a function of the direct causes X and some unmeasurable factors or noise:
Y = f (X, ε; θ 1 ),(1)
where ε is the noise term that is assumed to be independent from X, the function f ∈ F explains how Y is generated from X, F is an appropriately constrained functional class, and θ 1 is the parameter set involved in f . We assume that the transformation from (X, ε) to (X, Y) is invertible, such that N can be uniquely recovered from the observed variables X and Y.</p>
<p>For convenience of presentation, let us assume that both X and Y are one-dimensional variables. Without precise knowledge on the data-generating process, the FCM should be flexible enough such that it could be adapted to approximate the true data-generating process; more importantly, the causal direction implied by the FCM has to be identifiable in most cases, i.e., the model assumption, especially the independence between the noise and cause, holds for only one direction, such that it implies the causal asymmetry between X and Y. Under the above conditions, one can then use FCMs to determine the causal direction between two variables, given that they have a direct causal relationship in between and do not have any confounder: for both directions, we fit the FCM, and then test for independence between the estimated noise term and the hypothetical cause, and the direction which gives an independent noise term is considered plausible. It has been shown that without any further assumption on the function f , causal direction is not identifiable because for both directions one can find an independent noise term (Hyvärinen and Pajunen, 1999;Zhang et al., 2015).</p>
<p>Several forms of the FCM have been shown to be able to produce unique causal directions, and have received practical applications. In the linear, non-Gaussian, and acyclic model (LiNGAM) , f is linear, and at most one of the noise term ε and cause X is Gaussian. In the postnonlinear (PNL) causal model (Zhang and Chan, 2006;Zhang and Hyvärinen, 2009b), the effect Y is further generated by a postnonlinear transformation on the non-linear effect of the cause X plus noise term ε:
Y = f 2 (f 1 (X) + ε),(2)
where both f 1 and f 2 are non-linear functions and f 2 is assumed to be invertible. 1 The post-nonlinear transformation f 2 represents sensor or measurement distortion, which is frequently encountered in practice. In particular, the PNL causal model has a very general form (LiNGAM is clearly a special case), but it has been shown to be identifiable in the generic case [except five specific situations given in Zhang and Hyvärinen (2009b)]. Another special case of the PNL causal model, the non-linear additive noise model Zhang and Hyvärinen, 2009a) assumes that f is non-linear with additive noise ε, i.e., that f 2 in Equation 2 is the identity mapping. Below we will discuss the identifiability of causal direction according to various FCMs, how to distinguish cause from effect with the FCM, and the applicability of causal discovery methods based on those FCMs. It is worth noting that in the discrete case, if one knows precisely what FCM class generated the effect from cause, which, for instance, may be the noisy AND or noisy XOR gate, then under mild conditions the causal direction can be easily seen from the data distribution. However, generally speaking, if the precise functional class of the causal process is unknown, in the discrete case it is difficult to recover the causal direction from observed data, especially when the cardinality of the variables is small. As an illustration, let us consider the situation where the causal process first generates continuous data and discretizes such data to produce the observed discrete ones. It is then not surprising that certain properties of the causal process are lost due to discretization, making causal discovery more difficult. In this paper we mainly focus on the continuous case. Readers who are interested in causal discovery from discrete variables or mixed discrete and continuous variables may refer to Peters et al. (2010) </p>
<p>Method Based on the Linear, Non-gaussian Model</p>
<p>The linear causal model in the two-variable case can be written as:
Y = bX + ε,(3)
where ε ⊥ ⊥ X. Let us first give an illustration with simple examples why it is possible to identify the causal direction between two variables in the linear case. Assume Y is generated from X in a linear form, i.e., Y = X + ε, where ε ⊥ ⊥ X. Figure 3 gives the scatterplot of 1,000 data points of the two variables X and Y (columns 1 and 3) and that of the predictor and regression residual for two different regression tasks (columns 2 and 4). The three rows correspond to different settings: X and E are both Gaussian (case 1), uniformly distributed (case 2), and distributed according to some super-Gaussian distribution (case 3). In the latter two settings, X and E are non-Gaussian, and one can see clearly that for regression of X given Y (the anti-causal or backward direction), the regression residual is not independent from the predictor anymore, although they are uncorrelated by construction of regression. In other words, in those two situations the regression residual is independent from the predictor only for the correct causal direction, giving rise to the causal asymmetry between X and Y. Rigorously speaking, if at most one of X and ε is Gaussian, the causal direction is identifiable, due to the independent component analysis (ICA) theory (Hyvärinen et al., 2001), or more fundamentally, due to the Darmois-Skitovich theorem (Kagan et al., 1973). This is known as the LiNGAM .</p>
<p>LiNGAM can be estimated from observational data in a computationally relatively efficient way. Suppose we aim to estimate the causal model underlying the observable random vector X = (X 1 , ..., X n ) ⊺ . (Note that here we abuse notation FIGURE 3 | Illustration of causal asymmetry between two variables with linear relations. The causal relation is X → Y . From top to bottom: X and E both follow the Gaussian distribution (case 1), uniform distribution (case 2), and Laplace distribution (case 3). The two columns on the left show the scatter plot of X and Y and that of X and the regression residual for regressing Y on X, and the two columns on the right correspond to regressing X on Y .</p>
<p>slightly by using X as a vector of random variables and X i as a random variable, while X denoted a random variable above.) In matrix form we can represent such causal relations with a matrix B, i.e., X = BX + E, where B can be permuted to a strictly lowertriangular matrix and E is the vector of independent error terms. This can be rewritten as:
E = (I − B)X,(4)
where I denotes the identity matrix. The approach of ICA-LiNGAM  estimate the matrix B in two steps. It first applies ICA (Hyvärinen et al., 2001) on the data:
Z = WX,(5)
such that Z has independent components. Second, an estimate of B can be found by permuting and resealing the matrix W, as implied by the correspondence between (Equations 4, 5). As the number of variables, n, increases, the estimated linear transformation W may more likely converge to local optima and involve more and more random errors, causing estimation errors in the causal model. Bear in mind that the causal matrix we aim to estimate, B, is very sparse because it can be permuted to a strictly lower-triangular matrix. Hence, to improve the estimation efficiency, one may enforce the sparsity constraint on the entries of W, as achieved by ICA with sparse connections  or the Two-Step method (Sanchez-Romero et al., 2019). Another way to reduce the estimation error is to find the causal ordering by recursively performing regression and independence test between the predictor and residual, as done by DirectLiNGAM .</p>
<p>It is worth mentioning that in the linear case, it is possible to further estimate the effect of the underlying confounders in the system, if there are any, by exploiting overcomplete ICA (which allows more independent sources than observed variables) . Furthermore, when the underlying causal model has cycles or feedbacks, which violates the acyclicity assumption, one may still be able to reveal the causal knowledge under certain assumptions (Lacerda et al., 2008;Sanchez-Romero et al., 2019).</p>
<p>Finally, one may then challenge the non-Gaussianity assumption in the LiNGAM model as well as its extensions.</p>
<p>Here we argue that in the linear case, non-Gaussian distributions are ubiquitous. Cramér's decomposition theorem states that if the sum of two independent real-valued random variables is Gaussian, then both of the summand variables much be Gaussian as well; see (Cramér, 1970, page 53). By induction, this means that if the sum of any finite independent real-valued variables is Gaussian, then all summands must be Gaussian. In other words, a Gaussian distribution can never be exactly produced by linear composition of variables any of which is non-Gaussian. This nicely complements the central limit theorem: (under proper conditions) the sum of independent variable get closer to Gaussian, but it cannot be exactly Gaussian, except all summand variables are Gaussian. This linear closure property of the Gaussian distribution implies the rareness of the Gaussian distribution and ubiquitousness of non-Gaussian distributions, if we believe the relations between variables are linear. However, the closer it gets to Gaussian, the harder it is to distinguish the direction. Hence, the practical question is, are the errors typically non-Gaussian enough to distinguish causal directions in the linear case?</p>
<p>Non-linear Methods</p>
<p>In practice non-linear transformation is often involved in the data generating process, and should be taken into account in the functional class. As a direct extension of LiNGAM, the non-linear additive noise model represents the effect as a non-linear function of the cause plus independent error :
Y = f AN (X) + ε.(6)
The above model, as well as LiNGAM, enforces rather strong constraints on the causal process. If the assumed FCM is too restrictive to be able to approximate the true data generating process, the causal discovery results may be misleading. Therefore, if the specific knowledge about the data generating mechanism is not available, to make it useful in practice, the assumed causal model should be general enough, such that it can reveal the data generating processes approximately. The PNL causal model takes into account the non-linear influence from the cause, the noise effect, and the possible sensor or measurement distortion in the observed variables (Zhang and Chan, 2006;Zhang and Hyvärinen, 2009b). See (2) for its form. It has the most general form among all well-defined FCMs according to which the causal direction is identifiable in the general case. (The model used in Mooij et al. (2010) does not impose structural constraints but assumes a certain type of smoothness; however, it does not lead to theoretical identifiability results.) Clearly it contains the linear model and non-linear additive noise model as special cases. The multiplicative noise model, Y = X · ε, where all involved variables are positive, is another special case, since it can be written as Y = exp(log X + log ε), where log ε is considered as a new noise term, f 1 (X) = log(X), and f 2 (·) = exp(·).</p>
<p>The identifiability of the causal direction is a crucial issue in FCM-based causal discovery. Since LiNGAM and the nonlinear additive noise model are special cases of the PNL causal model, the identifiability conditions of the causal direction for the PNL causal model also entail those for the former two FCMs. Such identifiability conditions for the PNL causal model was established by a proof by contradiction (Zhang and Hyvärinen, 2009b). It assumes the causal model holds in both directions X → Y and Y → X, and show that this implies very strong conditions on the distributions and functions involved in the model. Under certain conditions [e.g., p(ε) is positive on (−∞, +∞)], there are only all five cases in which the causal direction is not identifiable according to the PNL causal model (Zhang and Hyvärinen, 2009b). The first one is the linear-Gaussian case, in which the causal direction is well-known to be non-identifiable. Suppose the data were generated according to the PNL causal model in settings other than those specific conditions; then in principle, the backward direction does not follow the model, and the causal direction can be determined.</p>
<p>Generally speaking, causal discovery based on non-linear FCMs are not computationally as efficient as in the linear case. Non-linear causal models have been used for distinguishing cause from effect given two variables which are believed to be directly causally related Zhang and Hyvärinen, 2009b;Peters et al., 2017): they are fitted to data in both directions, and the direction in which the estimated noise is independent from the hypothetical cause (or equivalently, the direction with a higher likelihood) is regarded as causal direction. They can be easily combined with conditional independence-based methods (Zhang and Hyvärinen, 2009b): conditional independence-based methods estimate the MEC from observational data with nonlinear or non-parametric methods for conditional independence tests (e.g., the kernel-based method Zhang et al., 2011a), and then non-linear models are applied to further orient the undirected edges in the MEC.</p>
<p>SEVERAL BIOLOGICAL EXAMPLES</p>
<p>The Two-Step algorithm and the FASK algorithm (Sanchez-Romero et al., 2019) are two examples of procedures that use adjacency searches to provide an initial undirected directed graph which the algorithms then prune, refine, or extend. Non-Gaussian features of the signal are then used (in different ways) to direct edges, allowing cyclic graphs. Two-Step, but not FASK, also allows for unmeasured confounding. FASK has been applied (Ramsey and Bryan, 2018b) to a famous data set (Sachs's data set Sachs et al., 2005) recording various cellular protein concentrations under a variety of exogenous chemical inputs. Sach's gives an expert model, and in supplementary data gives additional connections for which the experimental literature is not entirely consistent. The data has been reanalyzed several times by various methods, generally not recovering Sach's model or the "expert" model alone or with supplementary edges. Allowing these supplementary edges as undirected edges, the "extended expert" model Ramsey and Andrews use is given in Figure 4.</p>
<p>Using FASK, and using the knowledge that the experimental treatments are exogenous, they recover the model, given in Figure 5, automatically with default values for the search algorithm. Figure 5 is very close to Figure 4, replacing undirected edges with directed edges or 2-cycles (cycles between only two variables) and supplementing some directed edges with a feedback reciprocity. The most noticeable fault in the FASK model is the absence of the Mek → ERK edge, which is wellestablished.</p>
<p>The Causal Stability algorithm is another example of an automated procedure applied to biological data (Stekhoven The Causal Stability Ranking algorithm that was used had the following steps. After the data was preprocessed, subsample of size n/2 were drawn 100 times. On each subsample, the PC algorithm was run, and then for each gene a lower bound on the absolute value of the total causal effect on time to flowering was estimated by the IDA algorithm, using the output pattern of the PC algorithm and the data as input. (Conceptually, the IDA algorithm estimates the total effect of a gene on time to flowering by estimating the total effect for each DAG represented by the output pattern of PC.) The minimum absolute values of the estimated total effect of each gene on time to flowering were then used to rank the genes. Finally, for a range of different q values ({100, 150, 200, ..., 2, 000}) the frequency with which each gene appeared in the top q genes was calculated. The median rank over the different values of q was then used to generate a final ranking of the genes.</p>
<p>When ordered in this way, the top 25 genes contained 5 genes that were known to cause time to flowering. Of the remaining 20 genes that were not known to cause time to flowering, 13 genes had readily available mutants that could be easily tested experimentally to see if the mutant plants differed significantly from the wild type with respect to time to flowering. Of the 13 mutants, 4 had viability issues. Of the 9 remaining genes without viability issues, 4 were novel genes found to cause time to flowering. </p>
<p>PRACTICAL ISSUES IN CAUSAL DISCOVERY</p>
<p>Causal discovery aims to find causal relations by analyzing observational data. The data are produced by not only the underlying causal process, but also the sampling process. In practice, to achieve reliable causal discovery, one needs to address specific challenges posed in the causal process or the sampling process. Below we report some particular issues that have recently been considered; for many of them, better approaches are still needed to improve the reliability and computational efficiency of causal discovery.</p>
<p>Causality in Time Series</p>
<p>Multivariate time series provide the data for many biological and other scientific inquiries, for example mRNA expression series in genomics, and Blood Oxygenation Level Dependent (BOLD) time series in neuropsychology. Finding the causal dynamics generating such data is challenging for many reasons, including that the generating process may be non-linear, the data acquisition rate may be much slower than the underlying rate of changes, there may be measurement error, the system may be non-stationary (i.e., the probability distributions of variables conditional on their causes may change, and even the causal relations may change) and there may be unmeasured confounding causes. The general problem of estimating the causal generating processes for time series is not close to solved, but there is progress in understanding how to deal with these problems in various classes of cases, and increased understanding of why popular methods do not work. In principle, any of the methods described previously, as well as others, can be used on time series. But their accuracies are sensitive to all of the factors just mentioned.</p>
<p>There are several strategies for treating time series data. One is to partition the data into disjoint "windows" and take the measurements in each unit as a data analytic unit. Another is to assume or estimate a number of lagged effects and treat all measurements separated by no more than that number of lags as a data analysis unit. That is a standard procedure in vector autoregression, or what is often called "Granger Causality." A further alternative is to treat the measurements at any time as independent of the measurements at any other time. Each has its disadvantages. The window method necessarily omits relations across windows and results may vary with the choice of window size. In the other two procedures, the units are not all independent, but most units are.</p>
<p>It is well-established that the most common procedure, Granger causality, is very sensitive to temporal aggregation or subsampling [for the effect of aggregation and subsampling and some possible ways to deal with them, see (Danks and Plis, 2013;Gong<em> et al., 2015;Gong et al., 2017)]. If the sampling rate is equal to the actual time interval required for a signal to propagate (and there is no confounder), Granger's method is very accurate. However, in many times series, data are subsampled or temporally aggregated due to the measuring device or sampling procedure, or for the purpose of efficient collection and storage. It has been shown that under suitable assumptions, the true causal relations are still identifiable from both subsampled and temporally aggregated data; interested readers may refer to Gong</em> et al. (2015); Gong et al. (2017) and references therein. In particular, It was shown that due to highly temporally aggregated data, time-delayed causal influences in the original causal process appear to be instantaneous in the aggregated time series, which implies that the estimated instantaneous causal relations from low-resolution aggregated data are consistent with the underlying causal influences (Gong et al., 2017).</p>
<p>On the application side, a good deal of research has been done on functional Magnetic Resonance Imaging (fMRI) time series, including a recent comparison of multiple methods. Roughly speaking, one can view fMRI data as some kind of highly temporally aggregated version of the underlying neural activities. The Two-Step and FASK procedures, described in section 5, prove to have the best precision (percentage of edges found that are correct) and recall (percentage of true edges that are found) (Sanchez-Romero et al., 2019). Remarkably, they are robust to (simulated) errors in variables whose variance is no larger than the measurement-free variance of the variables. Two-step retains high precision but has large recall losses; FASK retains both good precision and recall.</p>
<p>Other Issues</p>
<p>Below are some other issues that arise in many causal discovery tasks.</p>
<p>• Deterministic case. In a particular deterministic case where Y = f (X) without noise, it is impossible to make use of the independence between noise and the cause to find the causal direction. However, one may exploit a certain type of independence between the transformation f and the distribution of the cause X to characterize the causal asymmetry and determine the causal direction . • Nonstationary/heterogenous data. It is commonplace to encounter nonstationary or heterogeneous data, in which the underlying generating process changes over time or across data sets. Interestingly, if the qualitative causal structure is fixed and the mechanisms or parameters associated with the causal structure may change across data sets or over time (the mechanisms may change such that some causal links in the structure vanish over some time periods or domains), causal discovery may benefit from distribution shift because causal modeling and distribution shift are heavily coupled. This, in particular, inspires a framework for causal mechanism change detection, causal skeleton estimation, causal direction identification, and nonstationary driving force estimation (Huang et al., 2017;Zhang et al., 2017b). • Measurement error. Measurement error in the observed values of the variables can greatly change the output of various causal discovery methods. Given the ubiquity of measurement error caused by instruments or proxies used in the measuring process, this problem has received much attention, and sufficient conditions under which the causal model for the underlying measurement-error-free variables can be partially or completely identified in the presence of measurement error with unknown variance have been established (Zhang et al., 2017a). This will hopefully inspire a set of causal discovery methods dealing with measurement error. • Selection Bias. Selection bias is an important issue in statistical inference, which arises when the probability of including a data point into the sample depends on some attributes of the point. Selection bias, if not corrected, often distorts the results of statistical analysis and causal discovery and inference. In the presence of outcome-dependent selection bias, with FCM-based causal discovery it is possible to identify the correct causal direction and estimate properties of the causal mechanism (Zhang et al., 2016). More general situations with selection bias remain to be studied. • Missing data. Missing data are ubiquitous in many domains such as healthcare. When these data entries are not missing completely at random, the (conditional) independence relations in the observed data may be different from those in the complete data generated by the underlying causal process. Consequently, simply applying existing causal discovery methods to the observed data may lead to the wrong conclusions. A modified PC algorithm was proposed for causal discovery in the presence of missing data (Tu et al., 2019), whose output is asymptotically correct under certain assumptions.</p>
<p>APPLICATION OF CAUSAL DISCOVERY IN BIOLOGY AND SOME GUIDELINES TO PRACTICE</p>
<p>A great deal of research in biology applies traditional machine learning techniques to various data sets, e.g., genome sequencing data sets (Libbrecht and William, 2015), without trying to find causal relations. In contrast, within the past two decades there has been an increasing number of publications on reconstructing gene regulatory networks or other types of networks in biology; for reviews of this line of work, see e.g., (Narendra et al., 2011;Frolova, 2012;Marbach et al., 2012;Villaverde et al., 2013;Djordjevic et al., 2014;Sinoquet, 2014;Li et al., 2015;Liu, 2015;Hill et al., 2016;Banf and Rhee, 2017). Not all of them aimed to find causal information represented by directed graphs. Many studies tried to derive weaker notions of causal representations, by making use of pairwise dependence between variables (Butte and Kohane, 2001;Margolin et al., 2006), or estimating a partial correlation graph (de la Fuente et al., 2004), or finding a partial correlation graph and further combining it with heuristic methods to infer partial ordering (Opgen-Rhein and Strimmer, 2007), or learning particular types of undirected graph structure (e.g., a tree structure) from data (Huynh-Thu and Sanguinetti, 2015;Gitter et al., 2016), or discovering Markov Blankets of the variables (Ram and Chetty, 2011). Some work infers causal associations between gene expression and disease (Schadt et al., 2005)-luckily, the causal direction between gene expression and disease is known. A number of studies rely on Bayesian network learning to infer certain information of the network; see, e.g., (Pe'er et al., 2001;Auliac et al., 2008;Adabor et al., 2015). Causal discovery methods or their underlying ideas already received some applications in genetics. For instance, the idea of the PC algorithm was adopted to infer causal relationships among phenotypes (Neto et al., 2010), to estimate gene regulatory networks (Zhang et al., 2011b), and to model the isoprenoid gene network in Arabidopsis thaliana (Wille et al., 2004). Granger causal analysis received a number of applications in estimation of gene regulatory networks; see, e.g., (Michailidis and d'Alché Buc, 2013;Emad and Milenkovic, 2014;Carlin et al., 2017;Yang et al., 2017;Finkle et al., 2018), and similarly, some findings were based on dynamic Bayesian network learning from observational biological data (Yu et al., 2004;Wu and Liu, 2008;Vasimuddin and Srinivas, 2017). There are also applications of network inference methods to leverage multiple data sets (Reiss et al., 2006;Joshi et al., 2015;Zitnik and Zupan, 2015;Omranian et al., 2016). Extended approaches to specific types of network estimation problems also exist, including network deconvolution (Feizi et al., 2013) and network inference by ANOVA .</p>
<p>Overall, although the past 30 years witnessed remarkable progress in development of theories and practical methods for automated causal search, they received rather limited applications in biology-in fact, practical causal analysis is not a matter of pressing a few buttons. There are multiple algorithms available, many of them are poorly tested, some of them are poor implementations of good algorithms, some of them are just plain poor algorithms, all of them have choices of parameters, and all of them have conditions on the data distributions and other assumptions under which they will be informative rather than misleading. We offer some general guidelines to practice (see also Malinsky and Danks, 2018 (Tu et al., 2019), and an extension of the PC algorithm was also proposed there, whose results are asymptotically correct under certain assumptions on the missingness mechanism. 6. Decide whether the data may suffer from sample selection bias, or measurement error, or unmeasured common causes. If there is sample selection bias and/or unmeasured common causes, there are algorithms, GFCI, FCI, RFCI in the TETRAD suite, and Matlab procedures, Two-Step, that tolerate unknown latent common causes. 7. Specify known influences between measured variables, or known absences of influences. In experimental data, treatment should not be caused by putative effects of treatment. In fMRI studies, for example, stimuli can be convolved with a hemodynamic response function; in biological experiments, the application of a chemical dosage is an exogenous variable. Known exogenous relations can be used to test a search algorithm: they provide a "gold" standard. Further, known causal relations actively guide some search algorithms and result in improved recall and precision. 8. If something about the system is known, test search algorithms and parameter choices on simulated systems that, so far as possible, mimic the observed distributions. 9. There is no consensus about choosing parameter values for search. For undirected graphs estimated by LASSO, there is a cross-validation procedure or BIC for parameter setting.</p>
<p>For causal searches using a BIC score there is an adjustable penalty that forces sparsity on the output (in finite samples, of course). Work is in progress on how best to adjust search parameter values (e.g., the significance levels in hypothesis tests) as a function of sample size, number of variables, and sparsity. Search procedures generally do not have confidence intervals for their results, and a "test" of the whole of a high dimensional model seldom makes any sense: many weak dependencies will not be found, but cumulatively they contribute to the real distribution, and so failure of complete recall will result in rejection of a model. Further, in complex models something is wrong somewhere almost always (precision is not perfect), and the model as a whole will typically be rejected by a test. Comparison tests are of course possible-e.g., against a completely disconnected graphical model-but they are not informative about the truth of the selected model.</p>
<ol>
<li>There are very few publicly available competent tests of model search methods. New methods are proposed almost monthly, and published packages vary in quality of implementation. Accuracy recommendations based on public contests are limited to whatever algorithms were submitted to the contests and the particular properties of the data. For DAG searches for linear models (Ramsey and Bryan, 2018a) provides a careful assessment of the most prominent public methods. Bootstrapping an algorithm repeatedly on the data can be informative about how much to trust the output, and can give an estimate of the probabilities of edges . If the results vary widely over the different bootstrap samples, the output should not be trusted. Unfortunately, the converse is not true -stable output is not necessarily correct causal output.</li>
</ol>
<p>CONCLUSION AND DISCUSSIONS</p>
<p>Understanding causal relations is helpful for constructing interventions to achieve certain objectives and also enables making predictions under interventions. It is an important issue in most disciplines of science, especially in biology and neuroscience. A traditional way to discover causal relations is to use interventions or randomized experiments, which is, however, in many cases of interest too expensive, too timeconsuming, unethical, or even impossible. Therefore, inferring the underlying causal structure from purely observational data, or from combinations of observational and experimental data, has drawn much attention in various disciplines. With the rapid accumulation of huge volumes of data, it is necessary to develop automatic causal search algorithms that scale well. We have reviewed two types of causal search algorithms. One makes use of conditional independence relations in the data to find a Markov equivalence class of directed causal structures. Typical algorithms include the PC algorithm, FCI, and the GES algorithm. The other makes use of suitable classes of Remark on practical issues Confounder in the linear, non-Gaussian case Hoyer et al. (2008); feedback in linear cases Lacerda et al. (2008) structural equation models and is able to find a unique causal structure under certain assumptions, for which the condition that noise is independent from causes plays an important role. We have reviewed model classes including LiNGAM, the non-linear additive noise (ANM) model, and the post-nonlinear (PNL) causal model. Each of the useful methods has its own pros and cons. The PC algorithm and FCI, as typical methods relying on conditional independence relations, require decisions on conditional independence as input, which is straightforward in linear cases (for instance, by Fisher Z tests or differences in BIC scores) but rather difficult in general non-linear situations. For linear causal relations, the search procedures can scale very well (e.g., PC and GES can easily deal with tens of thousands of variables for sparse graphs). But on the other hand, their output is a Markov equivalence class, which contains all directed graphs sharing the same conditional independence relations-in this case, the output may not be informative enough in certain circumstances. Methods based on structure equations models have to resort to the functional form of the causal influence, and generally speaking, they cannot handle latent confounders in a straightforward way. The non-Gaussian or non-linear functional causal models help identify more detailed information of the causal process; however, causal search methods based on them usually do not scale as well as those conditional-independencebased methods. To estimate LiNGAM, the estimation methods Two-Step and FASK are feasible on thousands of variables generated by a sparse graph. Current methods for estimating non-linear causal models are feasible on only dozens of variables. Table 1 summarizes the assumptions and properties of the fundamental causal discovery methods reviewed in the paper, as well as a summary of the contributions to address some of the practical issues that often arise in causal discovery in biology, especially in genetics.</p>
<p>Finally, we note that for reliable causal discovery, one often needs to address particular challenges that may be posed in the causal process or in the sampling process to generate the observed data. Typical challenges include sampling bias in the data, various types of non-linear effects, existence of measurement error, confounding effects, and heterogeneity of the data. Better methods to deal with those issues will clearly improve the quality of causal structure search, especially in genetics.</p>
<p>Some Software Packages and Source Code</p>
<p>FIGURE 1 |
1Illustration of how the PC algorithm works. (A) Original true causal graph. (B) PC starts with a fully-connected undirected graph.</p>
<p>FIGURE 2 |
2IIllustration of how the FCI algorithm is able to determine the existence of latent confunders. (A) Original true causal graph. (B) After edges are removed because of conditional independence relations. (C) The output of FCI, indicating that there is at least one unmeasured confounder of Y and Z.</p>
<p>;Cai et al. (2018);Huang et al. (2018).</p>
<p>FIGURE 4 |
4The "extended expert" model for Sachs's data set). SeeSachs et al. (2005) orRamsey and Bryan (2018b) for the significance of the variables.et al., 2012). The question under consideration was which genes influence the time to flowering of the Arabadopsis thaliana flower. The available data had measurements of expression levels of 21,326 genes for 47 samples from diverse geographic origins.</p>
<p>FIGURE 5 |
5The Model for the Sach's Data estimated by the FASK algorithm.</p>
<p>; Sanchez-Romero et al. (2019); measurement error Zhang et al. (2017a); non-stationary times series or heterogeneous multiple data sets Huang et al. (2017); Zhang et al. (2017b); missing data Tu et al. (2019); subsampled or aggregated time series Danks and Plis (2013); Gong* et al. (2015); Gong et al. (2017), etc.</p>
<p>). 1. Look at the distributions of the variables. This can be done by visualization or by performing a statistical test. For continuous variables a critical question is whether the distribution is Gaussian or non-Gaussian. This can be checked by an Anderson-Darling Test or eyeballed via a Q-Q plot. If the variables are non-Gaussian, the scatterplots of paired variables can give an indication of whether their relations are linear, polynomial of some obvious kind, periodic, or a mixture of distributions. 2. Check that preprocessing software has not distorted the distributions. For example, standard "high pass" filtering in fMRI software, eliminates some or all of the non-Gaussianity in variables and, as a consequence, the best available algorithms for fMRI time series become uninformative. 3. For continuous variables, check to see if the data are actually mixtures of different causal processes. If the individual causal processes follow linear-Gaussian models, there is a tool-Unmixer-in the TETRAD suite of causal search tools (http://www.ccd.pitt.edu) , and a tool for non-Gaussian variables is in development. If there are a small number of multiple components, the Unmixer algorithm will sort cases; a distinct label as an exogenous variable can be attached to each case, identifying the component to which it belongs, and searches can be run with that additional information. Alternatively, an algorithm such as IMaGES, designed for differing distributions with different linear coefficients, can be run. 4. If the data contain both categorical and continuous variables and there can possibly be categorical variables that are effects and causes, the Conditional Gaussian search in TETRAD can address the problem. That algorithm has limitations suggested by its name: it assumes conditional on values on categorical parents that a continuous variable is Gaussian, and it assumes there are no latent confounders. Work is in progress on generalizations. Alternatively, the continuous variables can be discretized, which sometimes works best when the continuous variables have very nonlinear relations. Discretization has a terrible cost in effective sample size, and is only advisable when the number of samples is much larger compared to the number of variables. 5. There is no consensus about what to do about missing values. There is R software for imputing missing values, and commonly used simple strategies such as imputing a mode or median value of a variable, or even deleting an entire case if it has one or more missing values (not recommended). In search algorithms that proceed by evaluating conditional independence on specially chosen subsets of variables (such as the PC algorithm), evaluations can be done simply by ignoring missing values for the relevant variables. It has been shown that this scheme may produce spurious edges</p>
<p>TABLE 1 |
1Comparison of the fundamental causal discovery methods reviewed in this paper.PC 
FCI 
GES 
LiNGAM/PNL/ANM </p>
<p>Faithfulness assumption required? 
Yes 
Yes 
Some weaker condition 
required (not totally clear yet) </p>
<p>No </p>
<p>Specific assumptions on data 
distributions required? </p>
<p>No 
No 
Yes (usually assumes 
linear-Gaussian models or 
multinomial distributions) </p>
<p>Yes </p>
<p>Properly handle confounders? 
No 
Yes 
No 
No </p>
<p>Output 
Markov equivalence class 
Partial ancestral graph 
Markov equivalence class 
DAG as well as causal 
model (under the respective 
identifiability conditions) </p>
<p>June 2019 | Volume 10 | Article 524
Frontiers in Genetics | www.frontiersin.org
InZhang and Chan (2006) both functions f 1 and f 2 are assumed to invertible; this causal model, as a consequence, can be estimated by making use of post-nonlinear independent component analysis (PNL-ICA)(Taleb and Jutten, 1999), which assumes that the observed data are component-wise invertible transformations of linear mixtures of the independence sources to be recovered.
AUTHOR CONTRIBUTIONSAll authors listed have made a substantial, direct and intellectual contribution to the work, and approved it for publication.
Saga: a hybrid search algorithm for bayesian network structure learning of transcriptional regulatory networks. Fci, Zhang, 10.1016/j.jbi.2014.08.010• The Tetrad project webpage (Tetrad implements a large number of causal discovery methods, including PC and its variants. 53J. Biomed. Informat.• The Tetrad project webpage (Tetrad implements a large number of causal discovery methods, including PC and its variants, FCI, and LiNGAM): http://www.phil.cmu.edu/tetrad/ • Kernel-based conditional independence test (Zhang et al., 2011a): http://people.tuebingen.mpg.de/kzhang/KCI-test.zip • LiNGAM and its extensions (Shimizu et al., 2006, 2011): https://sites.google.com/site/sshimizu06/lingam • Fitting the nonlinear additive noise model (Hoyer et al., 2009): http://webdav.tuebingen.mpg.de/causality/additive-noise tar.gz • Distinguishing cause from effect based on the PNL causal model (Zhang and Hyvärinen, 2009b): http://webdav.tuebingen.mpg.de/causality/CauseOrEffect_ NICA.rar • Probabilistic latent variable models for distinguishing between cause and effect (Mooij et al., 2010): http://webdav.tuebingen.mpg.de/causality/nips2010-gpi- code.tar.gz • Information-geometric causal inference (Janzing et al., 2012): http://webdav.tuebingen.mpg.de/causality/igci.tar.gz REFERENCES Adabor, E. S., Acquaah-Mensah, G. K., and Oduro, F. T. (2015). Saga: a hybrid search algorithm for bayesian network structure learning of transcriptional regulatory networks. J. Biomed. Informat. 53, 27-35. doi: 10.1016/j.jbi.2014.08.010</p>
<p>Evolutionary approaches for the reverse-engineering of gene regulatory networks: a study on a biologically realistic dataset. C Auliac, V Frouin, X Gidrol, F Alché-Buc, 10.1186/1471-2105-9-91BMC Bioinformat. 991Auliac, C., Frouin, V., Gidrol, X., and d'Alché-Buc, F. (2008). Evolutionary approaches for the reverse-engineering of gene regulatory networks: a study on a biologically realistic dataset. BMC Bioinformat. 9:91. doi: 10.1186/1471-2105-9-91</p>
<p>Markov equivalence for ancestral graphs. A R Ayesha, T S Richardson, P Spirtes, 10.1214/08-AOS626Ann. Stat. 37Ayesha, A. R., Richardson, T. S., and Spirtes, P. (2009). Markov equivalence for ancestral graphs. Ann. Stat. 37, 2808-2837. doi: 10.1214/08-AOS626</p>
<p>Computational inference of gene regulatory networks: approaches, limitations and opportunities. M Banf, S Y Rhee, 10.1016/j.bbagrm.2016.09.003Biochim. Biophys. Gene Regul. Mechan. 1860Banf, M., and Rhee, S. Y. (2017). Computational inference of gene regulatory networks: approaches, limitations and opportunities. Biochim. Biophys. Gene Regul. Mechan. 1860, 41-52. doi: 10.1016/j.bbagrm. 2016.09.003</p>
<p>Mutual information relevance networks: functional genomic clustering using pairwise entropy measurements. A J Butte, I S Kohane, Pacific Symposium on Biocomputing. Butte, A. J., and Kohane, I. S. (2001). "Mutual information relevance networks: functional genomic clustering using pairwise entropy measurements, " in Pacific Symposium on Biocomputing, 418-429</p>
<p>Causal discovery from discrete data using hidden compact representation. R Cai, J Qiao, K Zhang, Z Zhang, Z Hao, Adv. Neural. Inf. Process. Syst. Cai, R., Qiao, J., Zhang, K., Zhang, Z., and Hao, Z. (2018). Causal discovery from discrete data using hidden compact representation. Adv. Neural. Inf. Process. Syst. 2018:2666-2674.</p>
<p>Prophetic granger causality to infer gene regulatory networks. D E Carlin, E O Paull, K Graim, C K Wong, A Bivol, P Ryabinin, 10.1371/journal.pone.0170340PLoS ONE. 12170340Carlin, D. E., Paull, E. O., Graim, K., Wong, C. K., Bivol, A., Ryabinin, P., et al. (2017). Prophetic granger causality to infer gene regulatory networks. PLoS ONE 12:e0170340. doi: 10.1371/journal. pone.0170340</p>
<p>Optimal structure identification with greedy search. D M Chickering, 10.1162/153244303321897717J. Mach. Learn. Res. 3Chickering, D. M. (2003). Optimal structure identification with greedy search. J. Mach. Learn. Res. 3, 507-554. doi: 10.1162/153244303321897717</p>
<p>Learning high-dimensional directed acyclic graphs with latent and selection variables. D Colombo, M H Maathuis, M Kalisch, T Richardson, 10.1214/11-AOS940Ann. Statist. 40Colombo, D., Maathuis, M. H., Kalisch, M., and Richardson, T. (2012). Learning high-dimensional directed acyclic graphs with latent and selection variables. Ann. Statist. 40, 294-321. doi: 10.1214/11-AOS940</p>
<p>Random Variables and Probability Distributions. H Cramér, Cambridge University PressCambridge3rd ednCramér, H. (1970). Random Variables and Probability Distributions, 3rd edn. Cambridge: Cambridge University Press.</p>
<p>Learning causal structure from undersampled time series. D Danks, S Plis, JMLR: Workshop and Conference Proceedings (NIPS Workshop on Causality. Danks, D., and Plis, S. (2013). "Learning causal structure from undersampled time series, " in JMLR: Workshop and Conference Proceedings (NIPS Workshop on Causality), 1-10</p>
<p>Discovery of meaningful associations in genomic data using partial correlation coefficients. A De La Fuente, N Bing, I Hoeschele, P Mendes, 10.1093/bioinformatics/bth445Bioinformatics. 20de la Fuente, A., Bing, N., Hoeschele, I., and Mendes, P. (2004). Discovery of meaningful associations in genomic data using partial correlation coefficients. Bioinformatics 20, 3565-3574. doi: 10.1093/bioinformatics/ bth445</p>
<p>How difficult is inference of mammalian causal gene regulatory networks?. D Djordjevic, A Yang, A Zadoorian, K Rungrugeecharoen, J W K Ho, 10.1371/journal.pone.0111661PLoS ONE. 9111661Djordjevic, D., Yang, A., Zadoorian, A., Rungrugeecharoen, K., and Ho, J. W. K. (2014). How difficult is inference of mammalian causal gene regulatory networks? PLoS ONE 9:e0111661. doi: 10.1371/journal.pone.0111661</p>
<p>Caspian: a causal compressive sensing algorithm for discovering directed interactions in gene networks. A Emad, O Milenkovic, 10.1371/journal.pone.0090781PLoS ONE. 990781Emad, A., and Milenkovic, O. (2014). Caspian: a causal compressive sensing algorithm for discovering directed interactions in gene networks. PLoS ONE 9:e0090781. doi: 10.1371/journal.pone.0090781</p>
<p>Network deconvolution as a general method to distinguish direct dependencies in networks. S Feizi, D Marbach, M Médard, M Kellis, 10.1038/nbt.2635Nat. Biotechnol. 31Feizi, S., Marbach, D., Médard, M., and Kellis, M. (2013). Network deconvolution as a general method to distinguish direct dependencies in networks. Nat. Biotechnol. 31, 726-733. doi: 10.1038/nbt.2635</p>
<p>Windowed granger causal inference strategy improves discovery of gene regulatory networks. J D Finkle, J J Wu, N Bagheri, 10.1073/pnas.1710936115Proc. Natl. Acad. Sci. U.S.A. 115Finkle, J. D., Wu, J. J., and Bagheri, N. (2018). Windowed granger causal inference strategy improves discovery of gene regulatory networks. Proc. Natl. Acad. Sci. U.S.A. 115, 2252-2257. doi: 10.1073/pnas.1710936115</p>
<p>Using bayesian networks to analyze expression data. N Friedman, M Linial, I Nachman, D Pe&apos;er, 10.1089/106652700750050961J. Comput. Biol. 7Friedman, N., Linial, M., Nachman, I., and Pe'er, D. (2000). Using bayesian networks to analyze expression data. J. Comput. Biol. 7, 601-620. doi: 10.1089/106652700750050961</p>
<p>Overview of methods of reverse engineering of gene regulatory networks: boolean and bayesian networks. A O Frolova, 10.7124/bc.000036Biopolym Cell. 28Frolova, A. O. (2012). Overview of methods of reverse engineering of gene regulatory networks: boolean and bayesian networks. Biopolym Cell 28, 163- 1622. doi: 10.7124/bc.000036</p>
<p>Unsupervised learning of transcriptional regulatory networks via latent tree graphical models. A Gitter, F Huang, R Valluvan, E Fraenkel, Anandkumar , A , arXiv:1609.06335Gitter, A., Huang, F., Valluvan, R., Fraenkel, E., and Anandkumar, A. (2016). Unsupervised learning of transcriptional regulatory networks via latent tree graphical models. ArXiv arXiv:1609.06335.</p>
<p>Discovering temporal causal relations from subsampled data. * Gong, M Zhang, * , K Schölkopf, B Tao, D Geiger, P , Proceedings of the 32th International Conference on Machine Learning (ICML 2015), (Lille). the 32th International Conference on Machine Learning (ICML 2015), (Lille)Gong<em>, M., Zhang</em>, K., Schölkopf, B., Tao, D., and Geiger, P. (2015). "Discovering temporal causal relations from subsampled data, " in Proceedings of the 32th International Conference on Machine Learning (ICML 2015), (Lille) 1898-1906.</p>
<p>Causal discovery from temporally aggregated time series. M Gong, K Zhang, B Schölkopf, C Glymour, D Tao, Proceedings of the 33rd Conference on Uncertainty in Artificial Intelligence. the 33rd Conference on Uncertainty in Artificial IntelligenceSydney, NSWGong, M., Zhang, K., Schölkopf, B., Glymour, C., and Tao, D. (2017). "Causal discovery from temporally aggregated time series, " in Proceedings of the 33rd Conference on Uncertainty in Artificial Intelligence (UAI 2017). (Sydney, NSW)</p>
<p>Inferring causal molecular networks: empirical assessment through a community-based effort. S M Hill, M Heiser, L Cokelaer, T Unger, M Nesser, N Carlin, D E , 10.1038/nmeth.3773Nat. Methods. 13Hill, S. M., M.Heiser, L., and Cokelaer, T., Unger, M., Nesser, N., Carlin, D. E., etal. (2016). Inferring causal molecular networks: empirical assessment through a community-based effort. Nat. Methods 13, 310-318. doi: 10.1038/nmeth.3773</p>
<p>A First Course in Bayesian Statistical Methods. P D Hoff, Springer Science &amp; Business MediaNew York, NYHoff, P. D. (2009). A First Course in Bayesian Statistical Methods. New York, NY: Springer Science &amp; Business Media.</p>
<p>Nonlinear causal discovery with additive noise models. P Hoyer, D Janzing, J Mooji, J Peters, B Schölkopf, Advances in Neural Information Processing Systems. Vancouver, BC21Hoyer, P., Janzing, D., Mooji, J., Peters, J., and Schölkopf, B. (2009). "Nonlinear causal discovery with additive noise models, " in Advances in Neural Information Processing Systems 21 (Vancouver, BC).</p>
<p>Estimation of causal effects using linear non-gaussian causal models with hidden variables. P O Hoyer, S Shimizu, A J Kerminen, M Palviainen, 10.1016/j.ijar.2008.02.006Int. J. Approx. Reason. 49Hoyer, P. O., Shimizu, S., Kerminen, A. J., and Palviainen, M. (2008). Estimation of causal effects using linear non-gaussian causal models with hidden variables. Int. J. Approx. Reason. 49, 362-378. doi: 10.1016/j.ijar.2008.02.006</p>
<p>Generalized score functions for causal discovery. B Huang, K Zhang, Y Lin, B Schölkopf, C Glymour, Proceedings of the ACM SIGKDD conference on Knowledge Discovery and Data Mining. the ACM SIGKDD conference on Knowledge Discovery and Data MiningLondon, UKHuang, B., Zhang, K., Lin, Y., Schölkopf, B., and Glymour, C. (2018). "Generalized score functions for causal discovery, " in Proceedings of the ACM SIGKDD conference on Knowledge Discovery and Data Mining (KDD2018) (London, UK).</p>
<p>Behind distribution shift: mining driving forces of changes and causal arrows. B Huang, K Zhang, J Zhang, R S Romero, C Glymour, B Schölkopf, Proceedings of IEEE 17th International Conference on Data Mining. IEEE 17th International Conference on Data MiningNew Orleans, LAHuang, B., Zhang, K., Zhang, J., Romero, R. S., Glymour, C., and Schölkopf, B. (2017). "Behind distribution shift: mining driving forces of changes and causal arrows, " in Proceedings of IEEE 17th International Conference on Data Mining (ICDM 2017) (New Orleans, LA).</p>
<p>Combining tree-based and dynamical systems for the inference of gene regulatory networks. V A Huynh-Thu, G Sanguinetti, 10.1093/bioinformatics/btu863Bioinformatics. 31Huynh-Thu, V. A., and Sanguinetti, G. (2015). Combining tree-based and dynamical systems for the inference of gene regulatory networks. Bioinformatics 31, 1614-1622. doi: 10.1093/bioinformatics/btu863</p>
<p>Independent Component Analysis. A Hyvärinen, J Karhunen, E Oja, John Wiley &amp; Sons, IncHyvärinen, A., Karhunen, J., and Oja, E. (2001). Independent Component Analysis. John Wiley &amp; Sons, Inc.</p>
<p>Nonlinear independent component analysis: existence and uniqueness results. A Hyvärinen, P Pajunen, Neur. Netw. 12Hyvärinen, A., and Pajunen, P. (1999). Nonlinear independent component analysis: existence and uniqueness results. Neur. Netw. 12, 429-439.</p>
<p>Information-geometric approach to inferring causal directions. D Janzing, J Mooij, K Zhang, J Lemeire, J Zscheischler, P Daniuvsis, 10.1016/j.artint.2012.01.002Art. Intell 182-183Janzing, D., Mooij, J., Zhang, K., Lemeire, J., Zscheischler, J., Daniuvsis, P., et al. (2012). Information-geometric approach to inferring causal directions. Art. Intell 182-183, 1-31. doi: 10.1016/j.artint.2012.01.002</p>
<p>Multi-species network inference improves gene regulatory network reconstruction for early embryonic development in drosophila. A Joshi, Y Beck, T Michoel, 10.1089/cmb.2014.0290J. Comput. Biol. 22Joshi, A., Beck, Y., and Michoel, T. (2015). Multi-species network inference improves gene regulatory network reconstruction for early embryonic development in drosophila. J. Comput. Biol. 22, 253-265. doi: 10.1089/cmb.2014.0290</p>
<p>Characterization Problems in Mathematical Statistics. A M Kagan, Y V Linnik, C R Rao, WileyNew York, NYKagan, A. M., Linnik, Y. V., and Rao, C. R. (1973). Characterization Problems in Mathematical Statistics. New York, NY: Wiley.</p>
<p>Estimating high-dimensional directed acyclic graphs with the PC-algorithm. M Kalisch, P Bühlmann, J. Mach. Learn. Res. 8Kalisch, M., and Bühlmann, P. (2007). Estimating high-dimensional directed acyclic graphs with the PC-algorithm. J. Mach. Learn. Res. 8, 613-636.</p>
<p>Probabilistic Graphical Models: Principles and Techniques. D Koller, N Friedman, MIT PressCambridge, MAKoller, D., and Friedman, N. (2009). Probabilistic Graphical Models: Principles and Techniques. Cambridge, MA: MIT Press.</p>
<p>Inferring gene regulatory networks by anova. R Küffner, T Petri, P Tavakkolkhah, L Windhager, R Zimmer, 10.1093/bioinformatics/bts143Bioinformatics. 28Küffner, R., Petri, T., Tavakkolkhah, P., Windhager, L., and Zimmer, R. (2012). Inferring gene regulatory networks by anova. Bioinformatics 28, 1376-1382. doi: 10.1093/bioinformatics/bts143</p>
<p>Discovering cyclic causal models by independent components analysis. G Lacerda, P Spirtes, J Ramsey, P O Hoyer, Proceedings of the 24th Conference on Uncertainty in Artificial Intelligence (UAI2008) (Helsinki). the 24th Conference on Uncertainty in Artificial Intelligence (UAI2008) (Helsinki)Lauritzen, S.; OxfordClarendon PressLacerda, G., Spirtes, P., Ramsey, J., and Hoyer, P. O. (2008). "Discovering cyclic causal models by independent components analysis, " in Proceedings of the 24th Conference on Uncertainty in Artificial Intelligence (UAI2008) (Helsinki), Lauritzen, S. (1996). Graphical Models. Oxford: Clarendon Press.</p>
<p>Gene networks in plant biology: approaches in reconstruction and analysis. Y Li, S A Pearl, Jackson , S A , 10.1016/j.tplants.2015.06.013Trends Plant Sci. 20Li, Y., Pearl, S. A., and Jackson, S. A. (2015). Gene networks in plant biology: approaches in reconstruction and analysis. Trends Plant Sci. 20, 664-675. doi: 10.1016/j.tplants.2015.06.013</p>
<p>Machine learning applications in genetics and genomics. M W Libbrecht, S N William, 10.1038/nrg3920Nat. Rev. Genet. 16Libbrecht, M. W., and William, S. N. (2015). Machine learning applications in genetics and genomics. Nat. Rev. Genet. 16, 321-32. doi: 10.1038/nrg3920</p>
<p>Reverse engineering of genome-wide gene regulatory networks from gene expression data. Z P Liu, 10.2174/1389202915666141110210634Curr. Genom. 16Liu, Z. P. (2015). Reverse engineering of genome-wide gene regulatory networks from gene expression data. Curr. Genom. 16, 3-22. doi: 10.2174/1389202915666141110210634</p>
<p>Causal discovery algorithms: a practical guide. D Malinsky, D Danks, 10.1111/phc3.12470Philos. Compass. 1312470Malinsky, D., and Danks, D. (2018). Causal discovery algorithms: a practical guide. Philos. Compass 13:e12470. doi: 10.1111/phc3.12470</p>
<p>Wisdom of crowds for robust gene network inference. D Marbach, J C Costello, R Küffner, N Vega, R J Prill, D M Camacho, 10.1038/nmeth.2016Nat. Methods. 9Marbach, D., Costello, J. C., Küffner, R., Vega, N., Prill, R. J., Camacho, D. M., et al. (2012). Wisdom of crowds for robust gene network inference. Nat. Methods 9, 796-804. doi: 10.1038/nmeth.2016</p>
<p>Aracne: an algorithm for the reconstruction of gene regulatory networks in a mammalian cellular context. A A Margolin, I Nemenman, K Basso, C Wiggins, G Stolovitzky, R D Favera, 10.1186/1471-2105-7-S1-S7BMC Bioinformat. 77Margolin, A. A., Nemenman, I., Basso, K., Wiggins, C., Stolovitzky, G., Favera, R. D., et al. (2006). Aracne: an algorithm for the reconstruction of gene regulatory networks in a mammalian cellular context. BMC Bioinformat. 7:S7. doi: 10.1186/1471-2105-7-S1-S7</p>
<p>Autoregressive models for gene regulatory network inference: Sparsity, stability and causality issues. G Michailidis, F Buc, 10.1016/j.mbs.2013.10.003Math. Biosci. 246Michailidis, G., and d'Alché Buc, F. (2013). Autoregressive models for gene regulatory network inference: Sparsity, stability and causality issues. Math. Biosci. 246, 326-334. doi: 10.1016/j.mbs.2013. 10.003</p>
<p>Probabilistic latent variable models for distinguishing between cause and effect. J Mooij, O Stegle, D Janzing, K Zhang, B Schölkopf, Advances in Neural Information Processing Systems. Curran, NY23Mooij, J., Stegle, O., Janzing, D., Zhang, K., and Schölkopf, B. (2010). "Probabilistic latent variable models for distinguishing between cause and effect, " in Advances in Neural Information Processing Systems 23 (NIPS 2010) (Curran, NY).</p>
<p>Modeling Gene expression data using dynamic Bayesian networks. K Murphy, S Mian, Berkeley, CAComputer Science Division, University of CaliforniaTechnical ReportMurphy, K., and Mian, S. (1999). Modeling Gene expression data using dynamic Bayesian networks. Berkeley, CA: Computer Science Division, University of California. Technical Report.</p>
<p>A comprehensive assessment of methods for de-novo reverse-engineering of genome-scale regulatory networks. V Narendra, N Lytkin, C F Aliferis, A Statnikov, 10.1016/j.ygeno.2010.10.003Genomics. 97Narendra, V., Lytkin, N., Aliferis, C. F., and Statnikov, A. (2011). A comprehensive assessment of methods for de-novo reverse-engineering of genome-scale regulatory networks. Genomics 97, 7-18. doi: 10.1016/j.ygeno.2010.10.003</p>
<p>Causal graphical models in systems genetics: a unified framework for joint inference of causal network and genetic architecture for correlated phenotypes. E C Neto, M P Keller, A D Attie, B S Yandell, 10.1214/09-AOAS288Ann. Appl. Stat. 4339Neto, E. C., Keller, M. P., Attie, A. D., and Yandell, B. S. (2010). Causal graphical models in systems genetics: a unified framework for joint inference of causal network and genetic architecture for correlated phenotypes. Ann. Appl. Stat. 4, 320-?339. doi: 10.1214/09-AOAS288</p>
<p>A hybrid causal search algorithm for latent variable models. J M Ogarrio, P Spirtes, Ramsey , J , JMLR Workshop and Conference Proceedings (International Conference on Probabilistic Graphical Models). 52Ogarrio, J. M., Spirtes, P., and Ramsey, J. (2016). "A hybrid causal search algorithm for latent variable models, " in JMLR Workshop and Conference Proceedings (International Conference on Probabilistic Graphical Models), Vol. 52, 368-379.</p>
<p>Gene regulatory network inference using fused lasso on multiple data sets. N Omranian, J M O Eloundou-Mbebi, B Mueller-Roeber, Z Nikoloski, 10.1038/srep20533Sci. Rep. 620533Omranian, N., Eloundou-Mbebi, J. M. O., Mueller-Roeber, B., and Nikoloski, Z. (2016). Gene regulatory network inference using fused lasso on multiple data sets. Sci. Rep. 6:20533. doi: 10.1038/srep20533</p>
<p>From correlation to causation networks: a simple approximate learning algorithm and its application to high-dimensional plant gene expression data. R Opgen-Rhein, K Strimmer, 10.1186/1752-0509-1-37BMC Syst. Biol. 137Opgen-Rhein, R., and Strimmer, K. (2007). From correlation to causation networks: a simple approximate learning algorithm and its application to high-dimensional plant gene expression data. BMC Syst. Biol. 1:37. doi: 10.1186/1752-0509-1-37</p>
<p>J Pearl, Causality: Models, Reasoning, and Inference. CambridgeCambridge University PressPearl, J. (2000). Causality: Models, Reasoning, and Inference. Cambridge: Cambridge University Press.</p>
<p>Inferring subnetworks from perturbed expression profiles. D Pe&apos;er, A Regev, G Elidan, N Friedman, 10.1093/bioinformatics/17.suppl-1.S215Bioinformatics. 17Pe'er, D., Regev, A., Elidan, G., and Friedman, N. (2001). Inferring subnetworks from perturbed expression profiles. Bioinformatics 17, S215-S224. doi: 10.1093/bioinformatics/17.suppl-1.S215</p>
<p>Identifying cause and effect on discrete data using additive noise models. J Peters, D Janzing, B Schölkopf, Proceedings of Conference on Artificial Intelligence and Statistics (Sardinia). Conference on Artificial Intelligence and Statistics (Sardinia)Peters, J., Janzing, D., and Schölkopf, B. (2010). "Identifying cause and effect on discrete data using additive noise models, " in Proceedings of Conference on Artificial Intelligence and Statistics (Sardinia).</p>
<p>Elements of Causal Inference: Foundations and Learning Algorithms. J Peters, D Janzing, B Schölkopf, MIT PressCambridgePeters, J., Janzing, D., and Schölkopf, B. (2017). Elements of Causal Inference: Foundations and Learning Algorithms. Cambridge: MIT Press.</p>
<p>A markov-blanket-based model for gene regulatory network inference. R Ram, M Chetty, 10.1109/TCBB.2009.70IEEE/ACM Trans. Comput. Biol. Bioinform. 8Ram, R., and Chetty, M. (2011). A markov-blanket-based model for gene regulatory network inference. IEEE/ACM Trans. Comput. Biol. Bioinform. 8, 353-367. doi: 10.1109/TCBB.2009.70</p>
<p>Comparison of public causal search packages on linear gaussian data with no latent variables. J D Ramsey, A Bryan, arxiv:1709.04240Ramsey, J. D., and Bryan, A. (2018a). Comparison of public causal search packages on linear gaussian data with no latent variables. arxiv arxiv:1709.04240.</p>
<p>J D Ramsey, A Bryan, arXiv:1805.03108Fast with interventional knowledge recovers edges from the sachs model. Ramsey, J. D., and Bryan, A. (2018b). Fast with interventional knowledge recovers edges from the sachs model. arxiv arXiv:1805.03108.</p>
<p>Integrated biclustering of heterogeneous genome-wide datasets for the inference of global regulatory networks. D Reiss, J Nitin, S Baliga, R Bonneau, 10.1186/1471-2105-7-280BMC Bioinform. 7280Reiss, D., Nitin, J., Baliga, S., and Bonneau, R. (2006). Integrated biclustering of heterogeneous genome-wide datasets for the inference of global regulatory networks. BMC Bioinform. 7: 280. doi: 10.1186/1471-2105-7-280</p>
<p>Causal protein-signaling networks derived from multiparameter single-cell data. K Sachs, O Perez, D Pe&apos;er, D A Lauffenburger, G P Nolan, 10.1126/science.1105809Science. 308Sachs, K., Perez, O., Pe'er, D., Lauffenburger, D. A., and Nolan, G. P. (2005). Causal protein-signaling networks derived from multiparameter single-cell data. Science 308, 523-529. doi: 10.1126/science.1105809</p>
<p>Estimating feedforward and feedback effective connections from fmri time series: Assessments of statistical methods. R Sanchez-Romero, J D Ramsey, K Zhang, M R K Glymour, B H Glymour, C , 10.1162/netn-a-00061Net. Neurosci. 3Sanchez-Romero, R., Ramsey, J. D., Zhang, K., M. R. K. Glymour, B. H., and Glymour, C. (2019). Estimating feedforward and feedback effective connections from fmri time series: Assessments of statistical methods. Net. Neurosci. 3, 274-306. doi: 10.1162/netn-a-00061</p>
<p>An integrative genomics approach to infer causal associations between gene expression and disease. E E Schadt, J Lamb, J Zhu, S Edwards, D Guhathakurta, 10.1038/ng1589doi: 10.1038/ ng1589Nat. Genet. 37Schadt, E. E., Lamb, J., Zhu, J., Edwards, S., Guhathakurta, D., et al. (2005). An integrative genomics approach to infer causal associations between gene expression and disease. Nat. Genet. 37, :710-717. doi: 10.1038/ ng1589</p>
<p>A linear non-Gaussian acyclic model for causal discovery. S Shimizu, P Hoyer, A Hyvärinen, A Kerminen, J. Mach. Learn. Res. 7Shimizu, S., Hoyer, P., Hyvärinen, A., and Kerminen, A. (2006). A linear non- Gaussian acyclic model for causal discovery. J. Mach. Learn. Res. 7, 2003-2030.</p>
<p>Directlingam: adirect method for learning a linear non-gaussian structural equation model. S Shimizu, T Inazumi, Y Sogawa, A Hyvärinen, Y Kawahara, T Washio, J. Mach. Learn. Res. 12Shimizu, S., Inazumi, T., Sogawa, Y., Hyvärinen, A., Kawahara, Y., Washio, T., et al. (2011). Directlingam: adirect method for learning a linear non-gaussian structural equation model. J. Mach. Learn. Res. 12, 1225-1248.</p>
<p>Directed cyclic graphical representations of feedback models. C Sinoquet, Postgenomics Genomics, Oxford, Uk: Oup Oxford, P Spirtes, Proceedings of the Eleventh Conference on Uncertainty in Artificial Intelligence. the Eleventh Conference on Uncertainty in Artificial IntelligenceMontreal, QCMorgan Kaufmann Publishers IncProbabilistic Graphical Models for GeneticsSinoquet, C. (2014). Probabilistic Graphical Models for Genetics, Genomics, and Postgenomics. Oxford, UK: OUP Oxford Spirtes, P. (1995). "Directed cyclic graphical representations of feedback models, " in Proceedings of the Eleventh Conference on Uncertainty in Artificial Intelligence (Montreal, QC: Morgan Kaufmann Publishers Inc.)</p>
<p>Constructing bayesian networks models of gene expression networks from microarray data. P Spirtes, C Glymour, R Scheines, Proceedings of the Atlantic Symposium on Computational Biology. the Atlantic Symposium on Computational BiologyNorth CarolinaSpirtes, P., Glymour, C., and Scheines, R. (2000). "Constructing bayesian networks models of gene expression networks from microarray data, " in Proceedings of the Atlantic Symposium on Computational Biology (North Carolina).</p>
<p>Causation, Prediction, and Search, 2nd edn. P Spirtes, C Glymour, R Scheines, MIT PressCambridge, MASpirtes, P., Glymour, C., and Scheines, R. (2001). Causation, Prediction, and Search, 2nd edn. Cambridge, MA: MIT Press.</p>
<p>Causal stability ranking. D J Stekhoven, I Moraes, G Sveinbjornsson, L Hennig, M H Maathuis, P Bühlmann, 10.1093/bioinformatics/bts523Bioinformatics. 28Stekhoven, D. J., Moraes, I., Sveinbjornsson, G., Hennig, L., Maathuis, M. H., and Bühlmann, P. (2012). Causal stability ranking. Bioinformatics 28, 2819-2823. doi: 10.1093/bioinformatics/bts523</p>
<p>Source separation in post-nonlinear mixtures. A Taleb, Jutten , C , IEEE Trans. Signal Process. 47Taleb, A., and Jutten, C. (1999). Source separation in post-nonlinear mixtures. IEEE Trans. Signal Process. 47, 2807-2820.</p>
<p>Causal discovery in the presence of missing data. R Tu, C Zhang, P Ackermann, K Mohan, H Kjellström, C Glymour, K Zhang, Proceedings AISTATS 2019 (Naha). AISTATS 2019 (Naha)Tu, R., Zhang, C., Ackermann, P., Mohan, K., Kjellström, H., Glymour, C., and Zhang, K. (2019). "Causal discovery in the presence of missing data, " in Proceedings AISTATS 2019 (Naha).</p>
<p>Parallel exact dynamic bayesian network structure learning with application to gene networks. M Vasimuddin, Srinivas , A , 2017 IEEE 24th International Conference on High Performance Computing (HiPC) (Jaipur). Vasimuddin, M., and Srinivas, A. (2017). "Parallel exact dynamic bayesian network structure learning with application to gene networks, " in 2017 IEEE 24th International Conference on High Performance Computing (HiPC) (Jaipur).</p>
<p>Reverse engineering cellular networks with information theoretic methods. A F Villaverde, J Ross, J R Banga, 10.3390/cells20203062Villaverde, A. F., Ross, J., and Banga, J. R. (2013). Reverse engineering cellular networks with information theoretic methods. Cells 2, 306-329. doi: 10.3390/cells2020306</p>
<p>Sparse graphical gaussian modeling of the isoprenoid gene network in arabidopsis thaliana. A Wille, P Zimmermann, E Vranová, 10.1186/gb-2004-5-11-r92Genome Biol. 592Wille, A., Zimmermann, P., and Vranová, etal., E. (2004). Sparse graphical gaussian modeling of the isoprenoid gene network in arabidopsis thaliana. Genome Biol. 5: R92. doi: 10.1186/gb-2004-5-11-r92</p>
<p>Dynamic bayesian networks modeling for inferring genetic regulatory networks by search strategy: comparison between greedy hill climbing and mcmc methods. H Wu, X Liu, Proceedings of World Academy of Science, Engineering and Technology. World Academy of Science, Engineering and Technology34Wu, H., and Liu, X. (2008). "Dynamic bayesian networks modeling for inferring genetic regulatory networks by search strategy: comparison between greedy hill climbing and mcmc methods, in Proceedings of World Academy of Science, Engineering and Technology, 34.</p>
<p>Reconstruction of complex directional networks with group lasso nonlinear conditional granger causality. G Yang, L Wand, Wang , X , 10.1038/s41598-017-02762-5Sci. Rep. 72991Yang, G., Wand, L., and Wang, X. (2017). Reconstruction of complex directional networks with group lasso nonlinear conditional granger causality. Sci. Rep. 7:2991. doi: 10.1038/s41598-017-02762-5</p>
<p>Advances to bayesian network inference for generating causal networks from observational biological data. J Yu, V A Smith, P P Wang, A J Hartemink, Jarvis , E D , 10.1093/bioinformatics/bth448Bioinformatics. 20Yu, J., Smith, V. A., Wang, P. P., Hartemink, A. J., and Jarvis, E. D. (2004). Advances to bayesian network inference for generating causal networks from observational biological data. Bioinformatics 20, 3594-3603. doi: 10.1093/bioinformatics/bth448</p>
<p>Extensions of ICA for causality discovery in the Hong Kong stock market. K Zhang, Chan , L , Proceedings of the 13th International Conference on Neural Information Processing. the 13th International Conference on Neural Information ProcessingHong KongZhang, K., and Chan, L. (2006). "Extensions of ICA for causality discovery in the Hong Kong stock market, " in Proceedings of the 13th International Conference on Neural Information Processing (ICONIP 2006) (Hong Kong).</p>
<p>Causal discovery in the presence of measurement error: Identifiability conditions. K Zhang, M Gong, J Ramsey, K Batmanghelich, P Spirtes, C Glymour, UAI 2017 Workshop on Causality: Learning, Inference, and Decision-Making. Sydney, NSWZhang, K., Gong, M., Ramsey, J., Batmanghelich, K., Spirtes, P., and Glymour, C. (2017a). "Causal discovery in the presence of measurement error: Identifiability conditions, " in UAI 2017 Workshop on Causality: Learning, Inference, and Decision-Making (Sydney, NSW).</p>
<p>Causal discovery from nonstationary/heterogeneous data: Skeleton estimation and orientation determination. K Zhang, B Huang, J Zhang, C Glymour, B Schölkopf, Proceedings of the International Joint Conference on Artificial Intelligence (IJCAI. the International Joint Conference on Artificial Intelligence (IJCAIMelbourne, VICZhang, K., Huang, B., Zhang, J., Glymour, C., and Schölkopf, B. (2017b). "Causal discovery from nonstationary/heterogeneous data: Skeleton estimation and orientation determination, " in Proceedings of the International Joint Conference on Artificial Intelligence (IJCAI) (Melbourne, VIC).</p>
<p>Acyclic causality discovery with additive noise: an information-theoretical perspective. K Zhang, A Hyvärinen, Proceedings of the European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases (ECML PKDD) 2009 (Bled). the European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases (ECML PKDD) 2009 (Bled)Zhang, K., and Hyvärinen, A. (2009a). "Acyclic causality discovery with additive noise: an information-theoretical perspective, " in Proceedings of the European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases (ECML PKDD) 2009 (Bled).</p>
<p>On the identifiability of the post-nonlinear causal model. K Zhang, A Hyvärinen, Proceedings of the 25th Conference on Uncertainty in Artificial Intelligence. the 25th Conference on Uncertainty in Artificial IntelligenceMontreal, QCZhang, K., and Hyvärinen, A. (2009b). "On the identifiability of the post-nonlinear causal model, " in Proceedings of the 25th Conference on Uncertainty in Artificial Intelligence (Montreal, QC).</p>
<p>ICA with sparse connections: revisited. K Zhang, H Peng, L Chan, A Hyvärinen, Proceedings of Interntions Conference on Independent Component Analysis and Blind Signal Separation (ICA2009) (Paraty). Interntions Conference on Independent Component Analysis and Blind Signal Separation (ICA2009) (Paraty)Zhang, K., Peng, H., Chan, L., and Hyvärinen, A. (2009). "ICA with sparse connections: revisited, " in Proceedings of Interntions Conference on Independent Component Analysis and Blind Signal Separation (ICA2009) (Paraty).</p>
<p>Kernel-based conditional independence test and application in causal discovery. K Zhang, J Peters, D Janzing, B Schölkopf, Proceedings of the 27th Conference on Uncertainty in Artificial Intelligence. the 27th Conference on Uncertainty in Artificial IntelligenceBarcelona)2011Zhang, K., Peters, J., Janzing, D., and Schölkopf, B. (2011a). "Kernel-based conditional independence test and application in causal discovery, " in Proceedings of the 27th Conference on Uncertainty in Artificial Intelligence (UAI 2011) (Barcelona).</p>
<p>On estimation of functional causal models: General results and application to post-nonlinear causal model. K Zhang, Z Wang, J Zhang, B Schölkopf, 10.1145/2700476ACM Trans. Intell. Syst. Technol. 713Zhang, K., Wang, Z., Zhang, J., and Schölkopf, B. (2015). On estimation of functional causal models: General results and application to post-nonlinear causal model. ACM Trans. Intell. Syst. Technol. 7:13. doi: 10.1145/27</p>
<p>On the identifiability and estimation of functional causal models in the presence of outcome-dependent selection. K Zhang, J Zhang, B Huang, B Schölkopf, C Glymour, Proceedings of the 32rd Conference on Uncertainty in Artificial Intelligence (UAI 2016). the 32rd Conference on Uncertainty in Artificial Intelligence (UAI 2016)New York, NYZhang, K., Zhang, J., Huang, B., Schölkopf, B., and Glymour, C. (2016). "On the identifiability and estimation of functional causal models in the presence of outcome-dependent selection, " in Proceedings of the 32rd Conference on Uncertainty in Artificial Intelligence (UAI 2016) (New York, NY).</p>
<p>Inferring gene regulatory networks from gene expression data by path consistency algorithm based on conditional mutual information. X Zhang, X M Zhao, K He, L Lu, Y Cao, J Liu, 10.1093/bioinformatics/btr626Bioinformatics. 28Zhang, X., Zhao, X. M., He, K., Lu, L., Cao, Y., Liu, J., et al. (2011b). Inferring gene regulatory networks from gene expression data by path consistency algorithm based on conditional mutual information. Bioinformatics 28, 98-104. doi: 10.1093/bioinformatics/ btr626</p>
<p>Gene network inference by fusing data from diverse distributions. M Zitnik, B Zupan, 10.1093/bioinformatics/btv258Bioinformatics. 31Zitnik, M., and Zupan, B. (2015). Gene network inference by fusing data from diverse distributions. Bioinformatics 31, i230-i239. doi: 10.1093/bioinformatics/btv258</p>            </div>
        </div>

    </div>
</body>
</html>