<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-2214 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-2214</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-2214</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-58.html">extraction-schema-58</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of validation approaches in automated or AI-driven scientific research systems, including experimental validation, computational validation, simulation-based validation, and comparisons between these approaches.</div>
                <p><strong>Paper ID:</strong> paper-281079256</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2509.01398v1.pdf" target="_blank">The Need for Verification in AI-Driven Scientific Discovery</a></p>
                <p><strong>Paper Abstract:</strong> Artificial intelligence (AI) is transforming the practice of science. Machine learning and large language models (LLMs) can generate hypotheses at a scale and speed far exceeding traditional methods, offering the potential to accelerate discovery across diverse fields. However, the abundance of hypotheses introduces a critical challenge: without scalable and reliable mechanisms for verification, scientific progress risks being hindered rather than being advanced. In this article, we trace the historical development of scientific discovery, examine how AI is reshaping established practices for scientific discovery, and review the principal approaches, ranging from data-driven methods and knowledge-aware neural architectures to symbolic reasoning frameworks and LLM agents. While these systems can uncover patterns and propose candidate laws, their scientific value ultimately depends on rigorous and transparent verification, which we argue must be the cornerstone of AI-assisted discovery.</p>
                <p><strong>Cost:</strong> 0.027</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e2214.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e2214.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of validation approaches in automated or AI-driven scientific research systems, including experimental validation, computational validation, simulation-based validation, and comparisons between these approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>AI-Descartes</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>AI-Descartes (neuro-symbolic generator–verifier framework)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A generator–verifier neuro-symbolic framework that first generates symbolic candidate models from data via symbolic regression and then formally verifies them against background theory using theorem proving; introduces a 'reasoning distance' to quantify consistency with axioms.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Combining data and theory for derivable scientific discovery with AI-Descartes.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_or_method_name</strong></td>
                            <td>AI-Descartes</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Physical sciences / automated equation discovery</td>
                        </tr>
                        <tr>
                            <td><strong>validation_type</strong></td>
                            <td>hybrid</td>
                        </tr>
                        <tr>
                            <td><strong>validation_description</strong></td>
                            <td>Sequential generator–verifier pipeline: (1) symbolic regression (formulated as a mixed-integer nonlinear program) enumerates candidate symbolic formulas that fit data; (2) a theorem-prover-based reasoning module computes a reasoning error (β(f)) measuring discrepancy between the candidate's predictions and derivable formulas from the background theory B (which is expressed in logical form). Candidates are ranked by empirical error ε(f) and reasoning error β(f). Capable of reasoning about unobserved variables and comparing alternative background theories by computing reasoning errors for each.</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_fidelity</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>experimental_validation_performed</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_simulation_vs_experiment</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validation_success_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_validation_standards</strong></td>
                            <td>Applies to domains with formalizable background theory (physical sciences); the paper argues physical sciences allow automated verification by deriving constraints/data from physical laws.</td>
                        </tr>
                        <tr>
                            <td><strong>when_simulation_sufficient</strong></td>
                            <td>Not specified; framework emphasizes formal reasoning vs simulation — no explicit claim that simulation alone suffices.</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_failures</strong></td>
                            <td>None specific to AI-Descartes described in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification</strong></td>
                            <td>Uses two explicit quantitative scores: empirical error ε(f) on data and reasoning error β(f) relative to the axioms; these are combined to rank candidates (no probabilistic error bars reported).</td>
                        </tr>
                        <tr>
                            <td><strong>fabrication_detection</strong></td>
                            <td>Yes — the verifier filters out hypotheses that numerically fit data but conflict with background theory, thereby detecting spurious or 'hallucinated' models that violate axioms.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_cost_time</strong></td>
                            <td>Qualitatively expensive: sequential generator then theorem-prover verification can be computationally intensive; paper notes verification is a bottleneck and the generator–verifier separation prevents joint optimization.</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_validation_approach</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>validation_limitations</strong></td>
                            <td>Sequential design prevents theory and data from being leveraged simultaneously; limited applicability to problems where background theory can be formalized; scalability and computational expense acknowledged.</td>
                        </tr>
                        <tr>
                            <td><strong>acceptance_credibility</strong></td>
                            <td>Paper argues explicit formal reasoning (reasoning distance and certificates) increases scientific credibility relative to purely data-driven fits, as it enforces consistency with background theory.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_gold_standard</strong></td>
                            <td>Not compared quantitatively to experimental gold standards in this paper.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2214.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e2214.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of validation approaches in automated or AI-driven scientific research systems, including experimental validation, computational validation, simulation-based validation, and comparisons between these approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>AI-Hilbert</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>AI-Hilbert (theory-guided derivable discovery via polynomial optimization)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A theory-integrated framework that enforces algebraic axioms during hypothesis generation by restricting hypotheses to polynomial (or rational) forms and solving semidefinite/SOS-based optimization problems to produce certificates of derivability from background theory.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Evolving scientific discovery by unifying data and background knowledge with ai hilbert.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_or_method_name</strong></td>
                            <td>AI-Hilbert</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Physical sciences / symbolic derivable discovery</td>
                        </tr>
                        <tr>
                            <td><strong>validation_type</strong></td>
                            <td>hybrid</td>
                        </tr>
                        <tr>
                            <td><strong>validation_description</strong></td>
                            <td>Formulates discovery as a constrained polynomial optimization problem using a 4-tuple (B, D, C(Λ), d_c). Converts the problem to a semidefinite (SOS) optimization Pr_sd and solves it to output a candidate polynomial q(x) and SOS multipliers. If distance d_c(q, G∩H)=0 then q(x) is certified derivable from the (complete) background theory; if d_c>0, AI-Hilbert returns a certificate of approximate derivability (useful when B is incomplete or inconsistent).</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_fidelity</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>experimental_validation_performed</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_simulation_vs_experiment</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validation_success_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_validation_standards</strong></td>
                            <td>Targets domains where background theory can be expressed as polynomial equalities/inequalities (physical/mathematical models); sufficiency judged by algebraic certificates of derivability.</td>
                        </tr>
                        <tr>
                            <td><strong>when_simulation_sufficient</strong></td>
                            <td>Not explicitly discussed; emphasis is on algebraic certification rather than simulation-only validation.</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_failures</strong></td>
                            <td>None specific described; paper notes failures occur when background theory is inconsistent or incomplete, in which case only approximate certificates are returned.</td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification</strong></td>
                            <td>Distance function d_c(·, G∩H) quantifies how far a candidate polynomial is from being derivable; solver outputs multipliers and slack if only approximate derivability is possible (no probabilistic intervals reported).</td>
                        </tr>
                        <tr>
                            <td><strong>fabrication_detection</strong></td>
                            <td>Certificates of derivability (or lack thereof) serve to detect models that are not consistent with background axioms, limiting acceptance of fabricated/hallucinated formulas.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_cost_time</strong></td>
                            <td>Computationally heavy: relies on mixed-integer conic optimization and SOS semidefinite relaxations; cost scales with polynomial degree, number of variables, and complexity of axioms.</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_validation_approach</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>validation_limitations</strong></td>
                            <td>Restricts hypothesis space to polynomials/rationals (limits expressivity); requires axioms to be written in polynomial form; incomplete or inconsistent B yields only approximate certificates.</td>
                        </tr>
                        <tr>
                            <td><strong>acceptance_credibility</strong></td>
                            <td>Provides algebraic certificates which increase formal credibility in domains amenable to polynomial representations.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_gold_standard</strong></td>
                            <td>No direct experimental comparison to empirical gold standards provided in this paper.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2214.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e2214.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of validation approaches in automated or AI-driven scientific research systems, including experimental validation, computational validation, simulation-based validation, and comparisons between these approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>PINNs</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Physics-Informed Neural Networks</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Neural networks trained with a composite loss that enforces fit to data, PDE residuals, and boundary/initial conditions to approximate solutions of known governing PDEs without explicit meshes.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Physics-informed neural networks: A deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_or_method_name</strong></td>
                            <td>Physics-Informed Neural Networks (PINNs)</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Scientific computing / fluid mechanics / heat diffusion / quantum mechanics (PDE domains)</td>
                        </tr>
                        <tr>
                            <td><strong>validation_type</strong></td>
                            <td>hybrid</td>
                        </tr>
                        <tr>
                            <td><strong>validation_description</strong></td>
                            <td>Training objective L_total = λ_d L_data + λ_f L_physics + λ_b L_boundary. Validation is typically via held-out data and by measuring PDE residuals (physics loss) and boundary-condition satisfaction; PINNs are used as mesh-free approximators and tested on canonical PDE benchmarks in the literature (paper references success across fluid mechanics, heat diffusion, quantum mechanics).</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_fidelity</strong></td>
                            <td>High-fidelity insofar as the true governing PDEs are known and accurately represent physics; fidelity depends on correctness of PDE, network capacity, and the balance of loss terms. The paper does not report numerical accuracy metrics.</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_validation_performed</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_simulation_vs_experiment</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validation_success_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_validation_standards</strong></td>
                            <td>Validation typically requires both data fit and low PDE residuals; balancing the three loss components is critical and domain-specific.</td>
                        </tr>
                        <tr>
                            <td><strong>when_simulation_sufficient</strong></td>
                            <td>Implied: when governing PDEs are trusted and data are scarce, PINNs can provide adequate computational validation; explicit conditions not precisely delineated.</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_failures</strong></td>
                            <td>Paper notes sensitivity to hyperparameter choice and difficulty balancing loss terms, which can degrade solution quality — specific empirical failure cases not enumerated here.</td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification</strong></td>
                            <td>Not standardized in PINNs description here; paper emphasizes need for systematic hyperparameter optimization but does not report uncertainty quantification methods (no error bars shown).</td>
                        </tr>
                        <tr>
                            <td><strong>fabrication_detection</strong></td>
                            <td>Not directly addressed; PINNs rely on physics residuals to prevent physically inconsistent fits but do not provide formal proof certificates.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_cost_time</strong></td>
                            <td>Cost depends on network training and evaluation of PDE residuals; sensitive architecture and hyperparameter tuning increases development time compared to classical solvers.</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_validation_approach</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>validation_limitations</strong></td>
                            <td>Soft enforcement of physics (via penalties) offers no formal guarantees of constraint satisfaction; requires careful tuning; architecture choices affect performance.</td>
                        </tr>
                        <tr>
                            <td><strong>acceptance_credibility</strong></td>
                            <td>PINNs increase plausibility by enforcing PDE residuals but lack formal guarantees—paper notes credibility depends on careful validation and hyperparameter tuning.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_gold_standard</strong></td>
                            <td>Not compared quantitatively here to classical numerical solvers or experiments within this review.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2214.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e2214.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of validation approaches in automated or AI-driven scientific research systems, including experimental validation, computational validation, simulation-based validation, and comparisons between these approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>HNN</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Hamiltonian Neural Networks</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Neural architectures that learn a scalar Hamiltonian function and derive dynamics via Hamilton's equations, thereby enforcing energy conservation by construction.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Hamiltonian neural networks</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_or_method_name</strong></td>
                            <td>Hamiltonian Neural Networks (HNNs)</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Dynamics / physical systems modeling</td>
                        </tr>
                        <tr>
                            <td><strong>validation_type</strong></td>
                            <td>computational validation</td>
                        </tr>
                        <tr>
                            <td><strong>validation_description</strong></td>
                            <td>Validation is structural: models are assessed on their ability to reproduce system trajectories while preserving conserved quantities (energy). Paper states verification for HNNs is typically limited to checking the enforced structural property (e.g., energy conservation) rather than broader theoretical derivability.</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_fidelity</strong></td>
                            <td>Captures conservation-law-consistent dynamics; fidelity depends on appropriateness of Hamiltonian formulation and training data. No numeric accuracy metrics reported here.</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_validation_performed</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_simulation_vs_experiment</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validation_success_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_validation_standards</strong></td>
                            <td>Satisfaction of conservation laws (e.g., energy) is taken as primary validation for HNNs.</td>
                        </tr>
                        <tr>
                            <td><strong>when_simulation_sufficient</strong></td>
                            <td>Sufficient when dynamics truly follow Hamiltonian structure; paper notes these methods assume the form of the law and therefore are not discovery tools for unknown laws.</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_failures</strong></td>
                            <td>Limitation: HNNs do not discover the underlying law; if the assumed Hamiltonian structure is incorrect, predictions will be structurally constrained but wrong.</td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification</strong></td>
                            <td>Not discussed in detail; typically empirical trajectory errors are reported in original HNN literature (not provided here).</td>
                        </tr>
                        <tr>
                            <td><strong>fabrication_detection</strong></td>
                            <td>Not directly addressed; structure-constrained learning reduces certain classes of spurious fits but does not provide formal proofs against invalid hypotheses.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_cost_time</strong></td>
                            <td>Training cost akin to neural model training; no quantitative cost comparisons provided.</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_validation_approach</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>validation_limitations</strong></td>
                            <td>Only enforces specific structural invariants; does not provide formal derivability or proofs; interpretability remains limited.</td>
                        </tr>
                        <tr>
                            <td><strong>acceptance_credibility</strong></td>
                            <td>Imposes physically meaningful inductive bias which can increase acceptance when conservation laws are relevant, but lacks formal verification guarantees.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_gold_standard</strong></td>
                            <td>No direct comparison to experimental gold standards reported here.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2214.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e2214.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of validation approaches in automated or AI-driven scientific research systems, including experimental validation, computational validation, simulation-based validation, and comparisons between these approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LNN</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Lagrangian Neural Networks</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Network architectures that model a system's Lagrangian and derive equations of motion via Euler–Lagrange equations to produce coordinate-invariant, constraint-aware dynamics.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Lagrangian neural networks</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_or_method_name</strong></td>
                            <td>Lagrangian Neural Networks (LNNs)</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Dynamics / physical systems modeling</td>
                        </tr>
                        <tr>
                            <td><strong>validation_type</strong></td>
                            <td>computational validation</td>
                        </tr>
                        <tr>
                            <td><strong>validation_description</strong></td>
                            <td>Validation focuses on reproducing system trajectories and satisfying invariances guaranteed by the Lagrangian formulation (e.g., coordinate invariance); like HNNs, validation is structural and empirical rather than formal theorem-based.</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_fidelity</strong></td>
                            <td>Captures dynamics consistent with assumed Lagrangian structure; fidelity depends on correctness of model form and training data; no numerical accuracy metrics provided here.</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_validation_performed</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_simulation_vs_experiment</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validation_success_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_validation_standards</strong></td>
                            <td>Verification tends to check invariances and empirical trajectory errors; no formal certificates.</td>
                        </tr>
                        <tr>
                            <td><strong>when_simulation_sufficient</strong></td>
                            <td>Sufficient when system follows Lagrangian mechanics and training data capture relevant dynamics.</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_failures</strong></td>
                            <td>Same structural limitation: if assumed Lagrangian form is inappropriate, learned dynamics will be mis-specified.</td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification</strong></td>
                            <td>Not discussed.</td>
                        </tr>
                        <tr>
                            <td><strong>fabrication_detection</strong></td>
                            <td>Not explicitly described.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_cost_time</strong></td>
                            <td>Typical neural training costs; specifics not provided.</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_validation_approach</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>validation_limitations</strong></td>
                            <td>Assumes (rather than discovers) underlying mechanics; limited formal guarantees.</td>
                        </tr>
                        <tr>
                            <td><strong>acceptance_credibility</strong></td>
                            <td>Structure improves plausibility and sample efficiency but does not replace formal verification.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_gold_standard</strong></td>
                            <td>No comparison to experimental standards in this review.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2214.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e2214.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of validation approaches in automated or AI-driven scientific research systems, including experimental validation, computational validation, simulation-based validation, and comparisons between these approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Formal theorem provers</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Formal theorem provers (Lean, Coq, Isabelle, AlphaProof)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Formal proof assistants (Lean, Coq, Isabelle) provide machine-checkable verification of mathematical theorems expressed in dependently-typed or higher-order logics; paired systems (e.g., AlphaProof) use LLMs to translate informal proofs into formal statements to enable automated proving.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>The lean theorem prover (system description</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_or_method_name</strong></td>
                            <td>Formal theorem proving (Lean/Coq/Isabelle, AlphaProof integrations)</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Mathematics / formal verification</td>
                        </tr>
                        <tr>
                            <td><strong>validation_type</strong></td>
                            <td>computational validation</td>
                        </tr>
                        <tr>
                            <td><strong>validation_description</strong></td>
                            <td>Formal proofs are encoded in a proof assistant language and machine-checked for logical correctness; some systems pair LLMs to translate informal problems into formal proofs (AlphaProof used LLMs to produce Lean statements enabling training and automated reasoning). Paper highlights that formal proof systems can verify mathematical results with high assurance but are limited in natural sciences due to lack of universally accepted axioms and the difficulty of formalizing informal scientific statements.</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_fidelity</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>experimental_validation_performed</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_simulation_vs_experiment</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validation_success_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_validation_standards</strong></td>
                            <td>In mathematics, formal derivability in a proof assistant is the gold standard for correctness; in natural sciences, formalization is often infeasible or incomplete.</td>
                        </tr>
                        <tr>
                            <td><strong>when_simulation_sufficient</strong></td>
                            <td>Not applicable — formal proofs provide logical certainty but require formalizable axioms; the paper asserts they cannot broadly replace empirical validation in many scientific domains.</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_failures</strong></td>
                            <td>Translating informal scientific statements into formal ones can introduce errors unless verified by humans; additionally, lack of agreed axioms across scientific theories limits applicability.</td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification</strong></td>
                            <td>Formal proofs provide boolean correctness (proved/not proved); do not provide probabilistic uncertainty measures for empirical claims.</td>
                        </tr>
                        <tr>
                            <td><strong>fabrication_detection</strong></td>
                            <td>Formal verification can detect logically inconsistent or non-derivable claims once formalized, but cannot detect empirically fabricated data that is consistent with axioms unless axioms constrain such fabrication.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_cost_time</strong></td>
                            <td>High cost in human effort to formalize domain knowledge and in computation for complex proofs; AlphaProof required large-scale translation efforts (millions of informal problems) to train LLMs.</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_validation_approach</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>validation_limitations</strong></td>
                            <td>Requires formalizable axioms and careful translation; not directly applicable to domains without firm axiomatic bases (e.g., many areas of chemistry/biology).</td>
                        </tr>
                        <tr>
                            <td><strong>acceptance_credibility</strong></td>
                            <td>In mathematics, machine-checked proofs substantially increase credibility; in empirical sciences, formal proofs are less directly persuasive without empirical corroboration.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_gold_standard</strong></td>
                            <td>Formal proving is the gold standard for mathematical correctness; the paper warns it is not a substitute for empirical verification in many sciences.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2214.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e2214.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of validation approaches in automated or AI-driven scientific research systems, including experimental validation, computational validation, simulation-based validation, and comparisons between these approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Symbolic regression tools</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Symbolic regression tools (PySR, AI Feynman, TuringBot, RSRM)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Data-driven methods that search over symbolic expressions to find parsimonious equations fitting data using evolutionary, annealing, physics-inspired heuristics, or transformer-based approaches.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>PySR: Fast & parallelized symbolic regression in Python/Julia.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_or_method_name</strong></td>
                            <td>Symbolic regression (PySR, AI Feynman, TuringBot, RSRM, etc.)</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Equation discovery / physical sciences / control</td>
                        </tr>
                        <tr>
                            <td><strong>validation_type</strong></td>
                            <td>computational validation</td>
                        </tr>
                        <tr>
                            <td><strong>validation_description</strong></td>
                            <td>Validation consists principally of empirical fit to training/held-out data and parsimony metrics (e.g., Pareto front). Some approaches combine neural fitting with physics heuristics (AI Feynman) or MCTS+RL (RSRM). The paper emphasizes that many SR tools lack formal reasoning and thus validation is limited to data fit and heuristics rather than provability.</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_fidelity</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>experimental_validation_performed</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_simulation_vs_experiment</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validation_success_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_validation_standards</strong></td>
                            <td>Common standard is goodness-of-fit plus simplicity and physical plausibility checks; no formal certificate of derivability is typically produced.</td>
                        </tr>
                        <tr>
                            <td><strong>when_simulation_sufficient</strong></td>
                            <td>Not discussed as a general rule; symbolic regression outputs often require follow-up theoretical or experimental verification.</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_failures</strong></td>
                            <td>Paper warns of spurious equations that fit training data but fail to generalize — a core motivation for integrated verification.</td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification</strong></td>
                            <td>Often limited to cross-validation errors or held-out RMSE; formal uncertainty quantification not standard across tools.</td>
                        </tr>
                        <tr>
                            <td><strong>fabrication_detection</strong></td>
                            <td>Not inherently designed to detect fabricated or hallucinated relations beyond cross-validation and plausibility heuristics.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_cost_time</strong></td>
                            <td>Search-heavy algorithms can be computationally intensive but typically cheaper than physical experiments; exact costs vary by method.</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_validation_approach</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>validation_limitations</strong></td>
                            <td>Lack of formal reasoning leads to potential acceptance of numerically-satisfactory but theoretically-invalid formulas.</td>
                        </tr>
                        <tr>
                            <td><strong>acceptance_credibility</strong></td>
                            <td>Empirical fits are often treated as candidate hypotheses that require further theoretical or experimental vetting before scientific acceptance.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_gold_standard</strong></td>
                            <td>Not directly compared to experimental gold standards within this review.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2214.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e2214.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of validation approaches in automated or AI-driven scientific research systems, including experimental validation, computational validation, simulation-based validation, and comparisons between these approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>RLHF</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Reinforcement Learning from Human Feedback</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A method to fine-tune language models by using human preference signals to shape outputs toward more desirable (plausible) responses, improving style and surface reliability but not guaranteeing factual correctness.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Fine-tuning language models from human preferences.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_or_method_name</strong></td>
                            <td>Reinforcement Learning from Human Feedback (RLHF)</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Language models / AI model alignment</td>
                        </tr>
                        <tr>
                            <td><strong>validation_type</strong></td>
                            <td>other</td>
                        </tr>
                        <tr>
                            <td><strong>validation_description</strong></td>
                            <td>RLHF uses human annotations/preferences as reward signals to steer model outputs. The paper emphasizes that RLHF improves plausibility and user-facing reliability but operates at the level of perceived correctness and does not provide principled scientific verification or guarantees; models still hallucinate confidently.</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_fidelity</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>experimental_validation_performed</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_simulation_vs_experiment</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validation_success_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_validation_standards</strong></td>
                            <td>Not a scientific validation standard; RLHF is a usability/aligning technique rather than a verification method for scientific truth.</td>
                        </tr>
                        <tr>
                            <td><strong>when_simulation_sufficient</strong></td>
                            <td>Not applicable; RLHF is not a substitute for empirical or formal validation.</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_failures</strong></td>
                            <td>Paper cites RLHF-tuned models continuing to produce confident false statements and algebraic/physical inconsistencies.</td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification</strong></td>
                            <td>RLHF does not provide calibrated uncertainty or formal error bounds for factual claims.</td>
                        </tr>
                        <tr>
                            <td><strong>fabrication_detection</strong></td>
                            <td>RLHF can reduce some types of low-quality outputs but does not reliably detect or prevent fabrication/hallucination.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_cost_time</strong></td>
                            <td>Human annotation and preference collection are costly and partial; RLHF provides improvements in style at the expense of expensive human-in-the-loop labeling.</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_validation_approach</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>validation_limitations</strong></td>
                            <td>RLHF addresses plausibility, not provability; subjective feedback is partial and cannot replace formal or experimental verification.</td>
                        </tr>
                        <tr>
                            <td><strong>acceptance_credibility</strong></td>
                            <td>Improves perceived credibility to humans but lacks objective guarantees; the paper highlights this as insufficient for scientific discovery.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_gold_standard</strong></td>
                            <td>Not comparable to formal theorem proving or experimental validation.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2214.8">
                <h3 class="extraction-instance">Extracted Data Instance 8 (e2214.8)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of validation approaches in automated or AI-driven scientific research systems, including experimental validation, computational validation, simulation-based validation, and comparisons between these approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>LLM-agent validation frameworks</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>LLM-based agent frameworks (ChemCrow, AtomAgents, SciAgents, LLM-SR)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Systems that frame LLMs as agents, integrating them with domain-specific tools (reaction predictors, synthesis planners, simulation engines) to design and iteratively test hypotheses; provide in-workflow validation via tool-assisted checks.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>LLM-SR: Scientific equation discovery via programming with large language models.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_or_method_name</strong></td>
                            <td>LLM-based agent frameworks (ChemCrow, AtomAgents, SciAgents, LLM-SR)</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Chemistry, materials, biomaterials, general scientific workflows</td>
                        </tr>
                        <tr>
                            <td><strong>validation_type</strong></td>
                            <td>hybrid</td>
                        </tr>
                        <tr>
                            <td><strong>validation_description</strong></td>
                            <td>Validation is performed by coupling LLM reasoning with external specialized tools: e.g., ChemCrow integrates GPT-4 with reaction prediction, retrosynthesis planning, and safety assessment modules; AtomAgents and SciAgents combine LLM reasoning with alloy/materials pipelines and specialized simulation or experimental planning tools. Validation in these frameworks can include in-silico checks, tool-based predictions, and integration with experimental planning pipelines.</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_fidelity</strong></td>
                            <td>Varies by integrated tool: can range from low-fidelity heuristics (retrosynthesis scoring) to higher-fidelity physics-based simulations if available; the paper gives no unified fidelity metrics.</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_validation_performed</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_simulation_vs_experiment</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validation_success_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_validation_standards</strong></td>
                            <td>Depends on domain: chemistry/materials workflows often follow in-silico screening followed by targeted experiments; the paper notes many discovery claims in applied domains remain unvalidated experimentally.</td>
                        </tr>
                        <tr>
                            <td><strong>when_simulation_sufficient</strong></td>
                            <td>Implied: simulation/tool validation may suffice for early-stage filtering, but domain-specific experimental validation is required for claims of discovery in applied fields.</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_failures</strong></td>
                            <td>Not enumerated, but the paper warns that tool-based validation can be misleading if tools are limited or not validated themselves.</td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification</strong></td>
                            <td>Varies by tool; the paper does not report consistent uncertainty quantification across agent frameworks.</td>
                        </tr>
                        <tr>
                            <td><strong>fabrication_detection</strong></td>
                            <td>Tool-based checks and safety assessment modules can catch some implausible or dangerous proposals, but no general fabrication-detection methodology is described.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_cost_time</strong></td>
                            <td>Agentic tool integration reduces manual effort for hypothesis generation and screening but does not remove downstream experimental costs; resource/time trade-offs depend on number of candidates and experimental bottlenecks.</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_validation_approach</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>validation_limitations</strong></td>
                            <td>Reliance on external tools whose fidelity varies; often stops at candidate generation/screening stages without experimental confirmation.</td>
                        </tr>
                        <tr>
                            <td><strong>acceptance_credibility</strong></td>
                            <td>Paper emphasizes such agentic workflows speed generation and preliminary validation, but scientific acceptance typically requires further empirical verification.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_gold_standard</strong></td>
                            <td>Not directly compared to randomized controlled trials or experimental gold standards in the review.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2214.9">
                <h3 class="extraction-instance">Extracted Data Instance 9 (e2214.9)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of validation approaches in automated or AI-driven scientific research systems, including experimental validation, computational validation, simulation-based validation, and comparisons between these approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Benchmarks for discovery</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Discovery and equation-discovery benchmarks (AI Feynman, SciBench, ScienceQA, MATH, LLM-SRBench)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Datasets and benchmarks used to evaluate symbolic and LLM-based discovery methods; many focus on rediscovery or textbook-style problems and therefore may not test genuine open-ended discovery or verification performance.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>LLM-SRBench: A new benchmark for scientific equation discovery with large language models.</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_or_method_name</strong></td>
                            <td>Benchmark datasets for discovery (AI Feynman, SciBench, ScienceQA, MATH, LLM-SRBench)</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Machine learning / symbolic regression / theorem proving / equation discovery</td>
                        </tr>
                        <tr>
                            <td><strong>validation_type</strong></td>
                            <td>computational validation</td>
                        </tr>
                        <tr>
                            <td><strong>validation_description</strong></td>
                            <td>Benchmarks are used to computationally validate model ability to rediscover known formulas or solve textbook problems; the paper criticizes many benchmarks for being in-distribution (allowing memorization) and for lacking explicit underlying theory, which hinders verification-based evaluation.</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_fidelity</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>experimental_validation_performed</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_simulation_vs_experiment</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validation_success_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_validation_standards</strong></td>
                            <td>Paper argues good benchmarks should (a) avoid being in training distribution, (b) test novelty/generalization, and (c) include underlying theory for verification — current benchmarks often fail these criteria.</td>
                        </tr>
                        <tr>
                            <td><strong>when_simulation_sufficient</strong></td>
                            <td>Not applicable; benchmarks are computational tests, not experimental substitutes.</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_failures</strong></td>
                            <td>Benchmarks that allow memorization lead to overestimation of models' discovery capabilities.</td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification</strong></td>
                            <td>Benchmarks typically report success/failure rates or error metrics but may not quantify epistemic novelty or theoretical consistency.</td>
                        </tr>
                        <tr>
                            <td><strong>fabrication_detection</strong></td>
                            <td>Benchmarks alone do not detect fabricated scientific claims; the paper calls for benchmarks that test consistency and novelty.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_cost_time</strong></td>
                            <td>Benchmarks reduce verification cost by providing automated evaluation but risk misleading conclusions without rigorous design.</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_validation_approach</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>validation_limitations</strong></td>
                            <td>Many datasets emphasize rediscovery, not open-ended theory formation; lack of background theory in benchmarks prevents verification-focused evaluation.</td>
                        </tr>
                        <tr>
                            <td><strong>acceptance_credibility</strong></td>
                            <td>Results on weak benchmarks can be misleading for scientific credibility; paper emphasizes need for better benchmarks.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_gold_standard</strong></td>
                            <td>Benchmarks are not substitutes for experimental validation; paper urges better benchmark design to reflect true scientific standards.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2214.10">
                <h3 class="extraction-instance">Extracted Data Instance 10 (e2214.10)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of validation approaches in automated or AI-driven scientific research systems, including experimental validation, computational validation, simulation-based validation, and comparisons between these approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Simulated discovery domains</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Simulated domains for scientific discovery (synthetic environments)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Synthetic or simulated problem domains used to evaluate AI discovery systems and reduce memorization (e.g., simulated physics tasks or procedurally generated discovery problems).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_or_method_name</strong></td>
                            <td>Simulated domains / synthetic discovery environments</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Methodology / benchmark design / AI evaluation</td>
                        </tr>
                        <tr>
                            <td><strong>validation_type</strong></td>
                            <td>low-fidelity simulation</td>
                        </tr>
                        <tr>
                            <td><strong>validation_description</strong></td>
                            <td>Researchers use simulated domains to create discovery tasks that are out-of-distribution for LLMs and other models, enabling testing of true reasoning and generalization; these domains are used to mitigate memorization in benchmarks but may not capture complexity of real experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_fidelity</strong></td>
                            <td>Low-to-moderate: simulations are purposely designed to be synthetic and to exercise reasoning rather than reproduce high-fidelity physical phenomena; paper provides no fidelity metrics.</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_validation_performed</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_simulation_vs_experiment</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validation_success_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_validation_standards</strong></td>
                            <td>Used as a proxy for open-ended discovery evaluation; paper stresses simulated domains should avoid being present in training corpora.</td>
                        </tr>
                        <tr>
                            <td><strong>when_simulation_sufficient</strong></td>
                            <td>Sufficient for testing reasoning/memorization properties of models, but not sufficient to validate real-world scientific claims.</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_failures</strong></td>
                            <td>Simulated tasks may fail to reflect practical complexities of empirical science, limiting external validity of positive results.</td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification</strong></td>
                            <td>Not discussed.</td>
                        </tr>
                        <tr>
                            <td><strong>fabrication_detection</strong></td>
                            <td>Simulated domains can detect model memorization/fabrication within synthetic contexts but not real-world fabrications.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_cost_time</strong></td>
                            <td>Creating high-quality simulated domains is resource-intensive but cheaper than real experiments; trade-offs exist between realism and generalizability tests.</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_validation_approach</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>validation_limitations</strong></td>
                            <td>Limited external validity; cannot serve as substitute for empirical validation in applied science.</td>
                        </tr>
                        <tr>
                            <td><strong>acceptance_credibility</strong></td>
                            <td>Success on simulated domains improves confidence in reasoning ability but not in real-world applicability; paper calls for better benchmarks bridging simulation and experiment.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_gold_standard</strong></td>
                            <td>Not comparable to experimental validation.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2214.11">
                <h3 class="extraction-instance">Extracted Data Instance 11 (e2214.11)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of validation approaches in automated or AI-driven scientific research systems, including experimental validation, computational validation, simulation-based validation, and comparisons between these approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Domain-specific empirical validation</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Domain-specific empirical validation practices (physical, chemical/biological, clinical)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>The paper contrasts domain norms: physical sciences favor controlled experiments and theory-driven verification (and sometimes high-fidelity simulation); chemistry/biology rely on manual experimentation and ontological frameworks; clinical sciences rely on RCTs, observational studies and meta-analyses for validation.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_or_method_name</strong></td>
                            <td>Domain-specific empirical validation practices</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Physical sciences, chemical & biological sciences, clinical sciences</td>
                        </tr>
                        <tr>
                            <td><strong>validation_type</strong></td>
                            <td>experimental</td>
                        </tr>
                        <tr>
                            <td><strong>validation_description</strong></td>
                            <td>Physical sciences: controlled experiments and data-driven simulations integrating background laws. Chemical/biological: manual experiments (genetic manipulation, behavioral observation), context-dependent ontologies. Clinical: randomized controlled trials (gold standard), observational studies, meta-analyses; validation relies on statistical inference for efficacy and safety.</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_fidelity</strong></td>
                            <td>Physical sciences: simulations can be high-fidelity when governing laws are known; chemistry/biology: simulations often lower-fidelity relative to experiments due to system complexity; clinical: simulations rarely sufficient, empirical trials required.</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_validation_performed</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_simulation_vs_experiment</strong></td>
                            <td>Paper asserts each domain has different balance; clinical domain regards RCTs as gold standard while simulations/observational studies are supportive but not definitive.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_success_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_validation_standards</strong></td>
                            <td>Physical: reproducible, quantifiable experiments tied to theory; Biological/Chemical: context-dependent experimentation and ontologies; Clinical: randomized controlled trials are gold standard.</td>
                        </tr>
                        <tr>
                            <td><strong>when_simulation_sufficient</strong></td>
                            <td>Paper suggests simulations can be sufficient in physical domains when grounded in correct governing equations, but in biological and clinical sciences simulation alone is usually insufficient.</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_failures</strong></td>
                            <td>Paper cites general concern that models/simulations can mislead if not validated by experiments; specific domain failures are not enumerated beyond engineering examples.</td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification</strong></td>
                            <td>Clinical and experimental sciences rely on statistical inference; physical sciences may use error bars and residuals; the paper emphasizes the need for domain-appropriate uncertainty measures but gives no standardization.</td>
                        </tr>
                        <tr>
                            <td><strong>fabrication_detection</strong></td>
                            <td>Empirical replication and independent verification are primary defenses against fabricated or spurious claims in experimental domains.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_cost_time</strong></td>
                            <td>Experimental validation is typically slow and expensive relative to computational screening; paper highlights verification bottleneck as limiting pace of discovery.</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_validation_approach</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>validation_limitations</strong></td>
                            <td>Differences in domain ontology and practicability limit transfer of formal verification methods; experimental costs and ethical constraints (clinical) reduce ability to empirically validate all AI-generated hypotheses.</td>
                        </tr>
                        <tr>
                            <td><strong>acceptance_credibility</strong></td>
                            <td>Paper stresses experimental verification (especially RCTs in clinical science) is key to community acceptance; computational/simulation validation alone is often insufficient.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_gold_standard</strong></td>
                            <td>Explicitly states RCTs are gold standard in clinical sciences; in physics, formal derivability and experiments constitute the highest standards.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2214.12">
                <h3 class="extraction-instance">Extracted Data Instance 12 (e2214.12)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of validation approaches in automated or AI-driven scientific research systems, including experimental validation, computational validation, simulation-based validation, and comparisons between these approaches.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Verification failure examples</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>High-consequence verification failures (Mars Climate Orbiter, Gimli Glider, medication dosing errors)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Historical incidents where lack of rigorous verification (unit mismatch, conversion errors, medication dosing mistakes) led to catastrophic or serious outcomes, used as cautionary examples for AI-driven discovery.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_or_method_name</strong></td>
                            <td>Historical verification failure case studies</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Aerospace engineering, aviation safety, clinical medicine</td>
                        </tr>
                        <tr>
                            <td><strong>validation_type</strong></td>
                            <td>other</td>
                        </tr>
                        <tr>
                            <td><strong>validation_description</strong></td>
                            <td>Examples: NASA Mars Climate Orbiter lost due to pound-vs-newton unit mismatch (1999); Gimli Glider fuel exhaustion due to pound/kilogram conversion during metric transition (1983); medication dosing errors from pound/kg confusion and wrong heparin vial selection. These illustrate that small verification lapses can have large consequences and motivate automated verification.</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_fidelity</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>experimental_validation_performed</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_simulation_vs_experiment</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validation_success_rate</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>domain_validation_standards</strong></td>
                            <td>Industrial and mission-critical engineering rely on rigorous automated verification and formal methods to ensure safety.</td>
                        </tr>
                        <tr>
                            <td><strong>when_simulation_sufficient</strong></td>
                            <td>Not applicable; these are cautionary real-world incidents showing need for robust verification beyond simulation.</td>
                        </tr>
                        <tr>
                            <td><strong>simulation_failures</strong></td>
                            <td>These are real-world failures due to human and process verification lapses rather than simulation inadequacy.</td>
                        </tr>
                        <tr>
                            <td><strong>uncertainty_quantification</strong></td>
                            <td>Not applicable.</td>
                        </tr>
                        <tr>
                            <td><strong>fabrication_detection</strong></td>
                            <td>Not applicable.</td>
                        </tr>
                        <tr>
                            <td><strong>validation_cost_time</strong></td>
                            <td>Examples highlight high downstream costs (financial, human) of inadequate verification — e.g., $125M Mars Climate Orbiter loss referenced.</td>
                        </tr>
                        <tr>
                            <td><strong>hybrid_validation_approach</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>validation_limitations</strong></td>
                            <td>Illustrative—serve as motivation but do not provide a method.</td>
                        </tr>
                        <tr>
                            <td><strong>acceptance_credibility</strong></td>
                            <td>Used to argue for stronger verification culture in scientific research and for automated verification pipelines.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_to_gold_standard</strong></td>
                            <td>Demonstrates that industrial gold-standard verification practices (automated checks, formal methods) are necessary in mission-critical contexts.</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Combining data and theory for derivable scientific discovery with AI-Descartes. <em>(Rating: 2)</em></li>
                <li>Evolving scientific discovery by unifying data and background knowledge with ai hilbert. <em>(Rating: 2)</em></li>
                <li>Physics-informed neural networks: A deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations. <em>(Rating: 2)</em></li>
                <li>Hamiltonian neural networks <em>(Rating: 1)</em></li>
                <li>Lagrangian neural networks <em>(Rating: 1)</em></li>
                <li>PySR: Fast & parallelized symbolic regression in Python/Julia. <em>(Rating: 1)</em></li>
                <li>AI Feynman: A physics-inspired method for symbolic regression. <em>(Rating: 1)</em></li>
                <li>Fine-tuning language models from human preferences. <em>(Rating: 1)</em></li>
                <li>LLM-SRBench: A new benchmark for scientific equation discovery with large language models. <em>(Rating: 2)</em></li>
                <li>Ai achieves silver-medal standard solving international mathematical olympiad problems. <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-2214",
    "paper_id": "paper-281079256",
    "extraction_schema_id": "extraction-schema-58",
    "extracted_data": [
        {
            "name_short": "AI-Descartes",
            "name_full": "AI-Descartes (neuro-symbolic generator–verifier framework)",
            "brief_description": "A generator–verifier neuro-symbolic framework that first generates symbolic candidate models from data via symbolic regression and then formally verifies them against background theory using theorem proving; introduces a 'reasoning distance' to quantify consistency with axioms.",
            "citation_title": "Combining data and theory for derivable scientific discovery with AI-Descartes.",
            "mention_or_use": "mention",
            "system_or_method_name": "AI-Descartes",
            "scientific_domain": "Physical sciences / automated equation discovery",
            "validation_type": "hybrid",
            "validation_description": "Sequential generator–verifier pipeline: (1) symbolic regression (formulated as a mixed-integer nonlinear program) enumerates candidate symbolic formulas that fit data; (2) a theorem-prover-based reasoning module computes a reasoning error (β(f)) measuring discrepancy between the candidate's predictions and derivable formulas from the background theory B (which is expressed in logical form). Candidates are ranked by empirical error ε(f) and reasoning error β(f). Capable of reasoning about unobserved variables and comparing alternative background theories by computing reasoning errors for each.",
            "simulation_fidelity": null,
            "experimental_validation_performed": false,
            "comparison_simulation_vs_experiment": null,
            "validation_success_rate": null,
            "domain_validation_standards": "Applies to domains with formalizable background theory (physical sciences); the paper argues physical sciences allow automated verification by deriving constraints/data from physical laws.",
            "when_simulation_sufficient": "Not specified; framework emphasizes formal reasoning vs simulation — no explicit claim that simulation alone suffices.",
            "simulation_failures": "None specific to AI-Descartes described in this paper.",
            "uncertainty_quantification": "Uses two explicit quantitative scores: empirical error ε(f) on data and reasoning error β(f) relative to the axioms; these are combined to rank candidates (no probabilistic error bars reported).",
            "fabrication_detection": "Yes — the verifier filters out hypotheses that numerically fit data but conflict with background theory, thereby detecting spurious or 'hallucinated' models that violate axioms.",
            "validation_cost_time": "Qualitatively expensive: sequential generator then theorem-prover verification can be computationally intensive; paper notes verification is a bottleneck and the generator–verifier separation prevents joint optimization.",
            "hybrid_validation_approach": true,
            "validation_limitations": "Sequential design prevents theory and data from being leveraged simultaneously; limited applicability to problems where background theory can be formalized; scalability and computational expense acknowledged.",
            "acceptance_credibility": "Paper argues explicit formal reasoning (reasoning distance and certificates) increases scientific credibility relative to purely data-driven fits, as it enforces consistency with background theory.",
            "comparison_to_gold_standard": "Not compared quantitatively to experimental gold standards in this paper.",
            "uuid": "e2214.0"
        },
        {
            "name_short": "AI-Hilbert",
            "name_full": "AI-Hilbert (theory-guided derivable discovery via polynomial optimization)",
            "brief_description": "A theory-integrated framework that enforces algebraic axioms during hypothesis generation by restricting hypotheses to polynomial (or rational) forms and solving semidefinite/SOS-based optimization problems to produce certificates of derivability from background theory.",
            "citation_title": "Evolving scientific discovery by unifying data and background knowledge with ai hilbert.",
            "mention_or_use": "mention",
            "system_or_method_name": "AI-Hilbert",
            "scientific_domain": "Physical sciences / symbolic derivable discovery",
            "validation_type": "hybrid",
            "validation_description": "Formulates discovery as a constrained polynomial optimization problem using a 4-tuple (B, D, C(Λ), d_c). Converts the problem to a semidefinite (SOS) optimization Pr_sd and solves it to output a candidate polynomial q(x) and SOS multipliers. If distance d_c(q, G∩H)=0 then q(x) is certified derivable from the (complete) background theory; if d_c&gt;0, AI-Hilbert returns a certificate of approximate derivability (useful when B is incomplete or inconsistent).",
            "simulation_fidelity": null,
            "experimental_validation_performed": false,
            "comparison_simulation_vs_experiment": null,
            "validation_success_rate": null,
            "domain_validation_standards": "Targets domains where background theory can be expressed as polynomial equalities/inequalities (physical/mathematical models); sufficiency judged by algebraic certificates of derivability.",
            "when_simulation_sufficient": "Not explicitly discussed; emphasis is on algebraic certification rather than simulation-only validation.",
            "simulation_failures": "None specific described; paper notes failures occur when background theory is inconsistent or incomplete, in which case only approximate certificates are returned.",
            "uncertainty_quantification": "Distance function d_c(·, G∩H) quantifies how far a candidate polynomial is from being derivable; solver outputs multipliers and slack if only approximate derivability is possible (no probabilistic intervals reported).",
            "fabrication_detection": "Certificates of derivability (or lack thereof) serve to detect models that are not consistent with background axioms, limiting acceptance of fabricated/hallucinated formulas.",
            "validation_cost_time": "Computationally heavy: relies on mixed-integer conic optimization and SOS semidefinite relaxations; cost scales with polynomial degree, number of variables, and complexity of axioms.",
            "hybrid_validation_approach": true,
            "validation_limitations": "Restricts hypothesis space to polynomials/rationals (limits expressivity); requires axioms to be written in polynomial form; incomplete or inconsistent B yields only approximate certificates.",
            "acceptance_credibility": "Provides algebraic certificates which increase formal credibility in domains amenable to polynomial representations.",
            "comparison_to_gold_standard": "No direct experimental comparison to empirical gold standards provided in this paper.",
            "uuid": "e2214.1"
        },
        {
            "name_short": "PINNs",
            "name_full": "Physics-Informed Neural Networks",
            "brief_description": "Neural networks trained with a composite loss that enforces fit to data, PDE residuals, and boundary/initial conditions to approximate solutions of known governing PDEs without explicit meshes.",
            "citation_title": "Physics-informed neural networks: A deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations.",
            "mention_or_use": "mention",
            "system_or_method_name": "Physics-Informed Neural Networks (PINNs)",
            "scientific_domain": "Scientific computing / fluid mechanics / heat diffusion / quantum mechanics (PDE domains)",
            "validation_type": "hybrid",
            "validation_description": "Training objective L_total = λ_d L_data + λ_f L_physics + λ_b L_boundary. Validation is typically via held-out data and by measuring PDE residuals (physics loss) and boundary-condition satisfaction; PINNs are used as mesh-free approximators and tested on canonical PDE benchmarks in the literature (paper references success across fluid mechanics, heat diffusion, quantum mechanics).",
            "simulation_fidelity": "High-fidelity insofar as the true governing PDEs are known and accurately represent physics; fidelity depends on correctness of PDE, network capacity, and the balance of loss terms. The paper does not report numerical accuracy metrics.",
            "experimental_validation_performed": false,
            "comparison_simulation_vs_experiment": null,
            "validation_success_rate": null,
            "domain_validation_standards": "Validation typically requires both data fit and low PDE residuals; balancing the three loss components is critical and domain-specific.",
            "when_simulation_sufficient": "Implied: when governing PDEs are trusted and data are scarce, PINNs can provide adequate computational validation; explicit conditions not precisely delineated.",
            "simulation_failures": "Paper notes sensitivity to hyperparameter choice and difficulty balancing loss terms, which can degrade solution quality — specific empirical failure cases not enumerated here.",
            "uncertainty_quantification": "Not standardized in PINNs description here; paper emphasizes need for systematic hyperparameter optimization but does not report uncertainty quantification methods (no error bars shown).",
            "fabrication_detection": "Not directly addressed; PINNs rely on physics residuals to prevent physically inconsistent fits but do not provide formal proof certificates.",
            "validation_cost_time": "Cost depends on network training and evaluation of PDE residuals; sensitive architecture and hyperparameter tuning increases development time compared to classical solvers.",
            "hybrid_validation_approach": true,
            "validation_limitations": "Soft enforcement of physics (via penalties) offers no formal guarantees of constraint satisfaction; requires careful tuning; architecture choices affect performance.",
            "acceptance_credibility": "PINNs increase plausibility by enforcing PDE residuals but lack formal guarantees—paper notes credibility depends on careful validation and hyperparameter tuning.",
            "comparison_to_gold_standard": "Not compared quantitatively here to classical numerical solvers or experiments within this review.",
            "uuid": "e2214.2"
        },
        {
            "name_short": "HNN",
            "name_full": "Hamiltonian Neural Networks",
            "brief_description": "Neural architectures that learn a scalar Hamiltonian function and derive dynamics via Hamilton's equations, thereby enforcing energy conservation by construction.",
            "citation_title": "Hamiltonian neural networks",
            "mention_or_use": "mention",
            "system_or_method_name": "Hamiltonian Neural Networks (HNNs)",
            "scientific_domain": "Dynamics / physical systems modeling",
            "validation_type": "computational validation",
            "validation_description": "Validation is structural: models are assessed on their ability to reproduce system trajectories while preserving conserved quantities (energy). Paper states verification for HNNs is typically limited to checking the enforced structural property (e.g., energy conservation) rather than broader theoretical derivability.",
            "simulation_fidelity": "Captures conservation-law-consistent dynamics; fidelity depends on appropriateness of Hamiltonian formulation and training data. No numeric accuracy metrics reported here.",
            "experimental_validation_performed": false,
            "comparison_simulation_vs_experiment": null,
            "validation_success_rate": null,
            "domain_validation_standards": "Satisfaction of conservation laws (e.g., energy) is taken as primary validation for HNNs.",
            "when_simulation_sufficient": "Sufficient when dynamics truly follow Hamiltonian structure; paper notes these methods assume the form of the law and therefore are not discovery tools for unknown laws.",
            "simulation_failures": "Limitation: HNNs do not discover the underlying law; if the assumed Hamiltonian structure is incorrect, predictions will be structurally constrained but wrong.",
            "uncertainty_quantification": "Not discussed in detail; typically empirical trajectory errors are reported in original HNN literature (not provided here).",
            "fabrication_detection": "Not directly addressed; structure-constrained learning reduces certain classes of spurious fits but does not provide formal proofs against invalid hypotheses.",
            "validation_cost_time": "Training cost akin to neural model training; no quantitative cost comparisons provided.",
            "hybrid_validation_approach": false,
            "validation_limitations": "Only enforces specific structural invariants; does not provide formal derivability or proofs; interpretability remains limited.",
            "acceptance_credibility": "Imposes physically meaningful inductive bias which can increase acceptance when conservation laws are relevant, but lacks formal verification guarantees.",
            "comparison_to_gold_standard": "No direct comparison to experimental gold standards reported here.",
            "uuid": "e2214.3"
        },
        {
            "name_short": "LNN",
            "name_full": "Lagrangian Neural Networks",
            "brief_description": "Network architectures that model a system's Lagrangian and derive equations of motion via Euler–Lagrange equations to produce coordinate-invariant, constraint-aware dynamics.",
            "citation_title": "Lagrangian neural networks",
            "mention_or_use": "mention",
            "system_or_method_name": "Lagrangian Neural Networks (LNNs)",
            "scientific_domain": "Dynamics / physical systems modeling",
            "validation_type": "computational validation",
            "validation_description": "Validation focuses on reproducing system trajectories and satisfying invariances guaranteed by the Lagrangian formulation (e.g., coordinate invariance); like HNNs, validation is structural and empirical rather than formal theorem-based.",
            "simulation_fidelity": "Captures dynamics consistent with assumed Lagrangian structure; fidelity depends on correctness of model form and training data; no numerical accuracy metrics provided here.",
            "experimental_validation_performed": false,
            "comparison_simulation_vs_experiment": null,
            "validation_success_rate": null,
            "domain_validation_standards": "Verification tends to check invariances and empirical trajectory errors; no formal certificates.",
            "when_simulation_sufficient": "Sufficient when system follows Lagrangian mechanics and training data capture relevant dynamics.",
            "simulation_failures": "Same structural limitation: if assumed Lagrangian form is inappropriate, learned dynamics will be mis-specified.",
            "uncertainty_quantification": "Not discussed.",
            "fabrication_detection": "Not explicitly described.",
            "validation_cost_time": "Typical neural training costs; specifics not provided.",
            "hybrid_validation_approach": false,
            "validation_limitations": "Assumes (rather than discovers) underlying mechanics; limited formal guarantees.",
            "acceptance_credibility": "Structure improves plausibility and sample efficiency but does not replace formal verification.",
            "comparison_to_gold_standard": "No comparison to experimental standards in this review.",
            "uuid": "e2214.4"
        },
        {
            "name_short": "Formal theorem provers",
            "name_full": "Formal theorem provers (Lean, Coq, Isabelle, AlphaProof)",
            "brief_description": "Formal proof assistants (Lean, Coq, Isabelle) provide machine-checkable verification of mathematical theorems expressed in dependently-typed or higher-order logics; paired systems (e.g., AlphaProof) use LLMs to translate informal proofs into formal statements to enable automated proving.",
            "citation_title": "The lean theorem prover (system description",
            "mention_or_use": "mention",
            "system_or_method_name": "Formal theorem proving (Lean/Coq/Isabelle, AlphaProof integrations)",
            "scientific_domain": "Mathematics / formal verification",
            "validation_type": "computational validation",
            "validation_description": "Formal proofs are encoded in a proof assistant language and machine-checked for logical correctness; some systems pair LLMs to translate informal problems into formal proofs (AlphaProof used LLMs to produce Lean statements enabling training and automated reasoning). Paper highlights that formal proof systems can verify mathematical results with high assurance but are limited in natural sciences due to lack of universally accepted axioms and the difficulty of formalizing informal scientific statements.",
            "simulation_fidelity": null,
            "experimental_validation_performed": false,
            "comparison_simulation_vs_experiment": null,
            "validation_success_rate": null,
            "domain_validation_standards": "In mathematics, formal derivability in a proof assistant is the gold standard for correctness; in natural sciences, formalization is often infeasible or incomplete.",
            "when_simulation_sufficient": "Not applicable — formal proofs provide logical certainty but require formalizable axioms; the paper asserts they cannot broadly replace empirical validation in many scientific domains.",
            "simulation_failures": "Translating informal scientific statements into formal ones can introduce errors unless verified by humans; additionally, lack of agreed axioms across scientific theories limits applicability.",
            "uncertainty_quantification": "Formal proofs provide boolean correctness (proved/not proved); do not provide probabilistic uncertainty measures for empirical claims.",
            "fabrication_detection": "Formal verification can detect logically inconsistent or non-derivable claims once formalized, but cannot detect empirically fabricated data that is consistent with axioms unless axioms constrain such fabrication.",
            "validation_cost_time": "High cost in human effort to formalize domain knowledge and in computation for complex proofs; AlphaProof required large-scale translation efforts (millions of informal problems) to train LLMs.",
            "hybrid_validation_approach": false,
            "validation_limitations": "Requires formalizable axioms and careful translation; not directly applicable to domains without firm axiomatic bases (e.g., many areas of chemistry/biology).",
            "acceptance_credibility": "In mathematics, machine-checked proofs substantially increase credibility; in empirical sciences, formal proofs are less directly persuasive without empirical corroboration.",
            "comparison_to_gold_standard": "Formal proving is the gold standard for mathematical correctness; the paper warns it is not a substitute for empirical verification in many sciences.",
            "uuid": "e2214.5"
        },
        {
            "name_short": "Symbolic regression tools",
            "name_full": "Symbolic regression tools (PySR, AI Feynman, TuringBot, RSRM)",
            "brief_description": "Data-driven methods that search over symbolic expressions to find parsimonious equations fitting data using evolutionary, annealing, physics-inspired heuristics, or transformer-based approaches.",
            "citation_title": "PySR: Fast & parallelized symbolic regression in Python/Julia.",
            "mention_or_use": "mention",
            "system_or_method_name": "Symbolic regression (PySR, AI Feynman, TuringBot, RSRM, etc.)",
            "scientific_domain": "Equation discovery / physical sciences / control",
            "validation_type": "computational validation",
            "validation_description": "Validation consists principally of empirical fit to training/held-out data and parsimony metrics (e.g., Pareto front). Some approaches combine neural fitting with physics heuristics (AI Feynman) or MCTS+RL (RSRM). The paper emphasizes that many SR tools lack formal reasoning and thus validation is limited to data fit and heuristics rather than provability.",
            "simulation_fidelity": null,
            "experimental_validation_performed": false,
            "comparison_simulation_vs_experiment": null,
            "validation_success_rate": null,
            "domain_validation_standards": "Common standard is goodness-of-fit plus simplicity and physical plausibility checks; no formal certificate of derivability is typically produced.",
            "when_simulation_sufficient": "Not discussed as a general rule; symbolic regression outputs often require follow-up theoretical or experimental verification.",
            "simulation_failures": "Paper warns of spurious equations that fit training data but fail to generalize — a core motivation for integrated verification.",
            "uncertainty_quantification": "Often limited to cross-validation errors or held-out RMSE; formal uncertainty quantification not standard across tools.",
            "fabrication_detection": "Not inherently designed to detect fabricated or hallucinated relations beyond cross-validation and plausibility heuristics.",
            "validation_cost_time": "Search-heavy algorithms can be computationally intensive but typically cheaper than physical experiments; exact costs vary by method.",
            "hybrid_validation_approach": false,
            "validation_limitations": "Lack of formal reasoning leads to potential acceptance of numerically-satisfactory but theoretically-invalid formulas.",
            "acceptance_credibility": "Empirical fits are often treated as candidate hypotheses that require further theoretical or experimental vetting before scientific acceptance.",
            "comparison_to_gold_standard": "Not directly compared to experimental gold standards within this review.",
            "uuid": "e2214.6"
        },
        {
            "name_short": "RLHF",
            "name_full": "Reinforcement Learning from Human Feedback",
            "brief_description": "A method to fine-tune language models by using human preference signals to shape outputs toward more desirable (plausible) responses, improving style and surface reliability but not guaranteeing factual correctness.",
            "citation_title": "Fine-tuning language models from human preferences.",
            "mention_or_use": "mention",
            "system_or_method_name": "Reinforcement Learning from Human Feedback (RLHF)",
            "scientific_domain": "Language models / AI model alignment",
            "validation_type": "other",
            "validation_description": "RLHF uses human annotations/preferences as reward signals to steer model outputs. The paper emphasizes that RLHF improves plausibility and user-facing reliability but operates at the level of perceived correctness and does not provide principled scientific verification or guarantees; models still hallucinate confidently.",
            "simulation_fidelity": null,
            "experimental_validation_performed": false,
            "comparison_simulation_vs_experiment": null,
            "validation_success_rate": null,
            "domain_validation_standards": "Not a scientific validation standard; RLHF is a usability/aligning technique rather than a verification method for scientific truth.",
            "when_simulation_sufficient": "Not applicable; RLHF is not a substitute for empirical or formal validation.",
            "simulation_failures": "Paper cites RLHF-tuned models continuing to produce confident false statements and algebraic/physical inconsistencies.",
            "uncertainty_quantification": "RLHF does not provide calibrated uncertainty or formal error bounds for factual claims.",
            "fabrication_detection": "RLHF can reduce some types of low-quality outputs but does not reliably detect or prevent fabrication/hallucination.",
            "validation_cost_time": "Human annotation and preference collection are costly and partial; RLHF provides improvements in style at the expense of expensive human-in-the-loop labeling.",
            "hybrid_validation_approach": false,
            "validation_limitations": "RLHF addresses plausibility, not provability; subjective feedback is partial and cannot replace formal or experimental verification.",
            "acceptance_credibility": "Improves perceived credibility to humans but lacks objective guarantees; the paper highlights this as insufficient for scientific discovery.",
            "comparison_to_gold_standard": "Not comparable to formal theorem proving or experimental validation.",
            "uuid": "e2214.7"
        },
        {
            "name_short": "LLM-agent validation frameworks",
            "name_full": "LLM-based agent frameworks (ChemCrow, AtomAgents, SciAgents, LLM-SR)",
            "brief_description": "Systems that frame LLMs as agents, integrating them with domain-specific tools (reaction predictors, synthesis planners, simulation engines) to design and iteratively test hypotheses; provide in-workflow validation via tool-assisted checks.",
            "citation_title": "LLM-SR: Scientific equation discovery via programming with large language models.",
            "mention_or_use": "mention",
            "system_or_method_name": "LLM-based agent frameworks (ChemCrow, AtomAgents, SciAgents, LLM-SR)",
            "scientific_domain": "Chemistry, materials, biomaterials, general scientific workflows",
            "validation_type": "hybrid",
            "validation_description": "Validation is performed by coupling LLM reasoning with external specialized tools: e.g., ChemCrow integrates GPT-4 with reaction prediction, retrosynthesis planning, and safety assessment modules; AtomAgents and SciAgents combine LLM reasoning with alloy/materials pipelines and specialized simulation or experimental planning tools. Validation in these frameworks can include in-silico checks, tool-based predictions, and integration with experimental planning pipelines.",
            "simulation_fidelity": "Varies by integrated tool: can range from low-fidelity heuristics (retrosynthesis scoring) to higher-fidelity physics-based simulations if available; the paper gives no unified fidelity metrics.",
            "experimental_validation_performed": false,
            "comparison_simulation_vs_experiment": null,
            "validation_success_rate": null,
            "domain_validation_standards": "Depends on domain: chemistry/materials workflows often follow in-silico screening followed by targeted experiments; the paper notes many discovery claims in applied domains remain unvalidated experimentally.",
            "when_simulation_sufficient": "Implied: simulation/tool validation may suffice for early-stage filtering, but domain-specific experimental validation is required for claims of discovery in applied fields.",
            "simulation_failures": "Not enumerated, but the paper warns that tool-based validation can be misleading if tools are limited or not validated themselves.",
            "uncertainty_quantification": "Varies by tool; the paper does not report consistent uncertainty quantification across agent frameworks.",
            "fabrication_detection": "Tool-based checks and safety assessment modules can catch some implausible or dangerous proposals, but no general fabrication-detection methodology is described.",
            "validation_cost_time": "Agentic tool integration reduces manual effort for hypothesis generation and screening but does not remove downstream experimental costs; resource/time trade-offs depend on number of candidates and experimental bottlenecks.",
            "hybrid_validation_approach": true,
            "validation_limitations": "Reliance on external tools whose fidelity varies; often stops at candidate generation/screening stages without experimental confirmation.",
            "acceptance_credibility": "Paper emphasizes such agentic workflows speed generation and preliminary validation, but scientific acceptance typically requires further empirical verification.",
            "comparison_to_gold_standard": "Not directly compared to randomized controlled trials or experimental gold standards in the review.",
            "uuid": "e2214.8"
        },
        {
            "name_short": "Benchmarks for discovery",
            "name_full": "Discovery and equation-discovery benchmarks (AI Feynman, SciBench, ScienceQA, MATH, LLM-SRBench)",
            "brief_description": "Datasets and benchmarks used to evaluate symbolic and LLM-based discovery methods; many focus on rediscovery or textbook-style problems and therefore may not test genuine open-ended discovery or verification performance.",
            "citation_title": "LLM-SRBench: A new benchmark for scientific equation discovery with large language models.",
            "mention_or_use": "mention",
            "system_or_method_name": "Benchmark datasets for discovery (AI Feynman, SciBench, ScienceQA, MATH, LLM-SRBench)",
            "scientific_domain": "Machine learning / symbolic regression / theorem proving / equation discovery",
            "validation_type": "computational validation",
            "validation_description": "Benchmarks are used to computationally validate model ability to rediscover known formulas or solve textbook problems; the paper criticizes many benchmarks for being in-distribution (allowing memorization) and for lacking explicit underlying theory, which hinders verification-based evaluation.",
            "simulation_fidelity": null,
            "experimental_validation_performed": false,
            "comparison_simulation_vs_experiment": null,
            "validation_success_rate": null,
            "domain_validation_standards": "Paper argues good benchmarks should (a) avoid being in training distribution, (b) test novelty/generalization, and (c) include underlying theory for verification — current benchmarks often fail these criteria.",
            "when_simulation_sufficient": "Not applicable; benchmarks are computational tests, not experimental substitutes.",
            "simulation_failures": "Benchmarks that allow memorization lead to overestimation of models' discovery capabilities.",
            "uncertainty_quantification": "Benchmarks typically report success/failure rates or error metrics but may not quantify epistemic novelty or theoretical consistency.",
            "fabrication_detection": "Benchmarks alone do not detect fabricated scientific claims; the paper calls for benchmarks that test consistency and novelty.",
            "validation_cost_time": "Benchmarks reduce verification cost by providing automated evaluation but risk misleading conclusions without rigorous design.",
            "hybrid_validation_approach": false,
            "validation_limitations": "Many datasets emphasize rediscovery, not open-ended theory formation; lack of background theory in benchmarks prevents verification-focused evaluation.",
            "acceptance_credibility": "Results on weak benchmarks can be misleading for scientific credibility; paper emphasizes need for better benchmarks.",
            "comparison_to_gold_standard": "Benchmarks are not substitutes for experimental validation; paper urges better benchmark design to reflect true scientific standards.",
            "uuid": "e2214.9"
        },
        {
            "name_short": "Simulated discovery domains",
            "name_full": "Simulated domains for scientific discovery (synthetic environments)",
            "brief_description": "Synthetic or simulated problem domains used to evaluate AI discovery systems and reduce memorization (e.g., simulated physics tasks or procedurally generated discovery problems).",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_or_method_name": "Simulated domains / synthetic discovery environments",
            "scientific_domain": "Methodology / benchmark design / AI evaluation",
            "validation_type": "low-fidelity simulation",
            "validation_description": "Researchers use simulated domains to create discovery tasks that are out-of-distribution for LLMs and other models, enabling testing of true reasoning and generalization; these domains are used to mitigate memorization in benchmarks but may not capture complexity of real experiments.",
            "simulation_fidelity": "Low-to-moderate: simulations are purposely designed to be synthetic and to exercise reasoning rather than reproduce high-fidelity physical phenomena; paper provides no fidelity metrics.",
            "experimental_validation_performed": false,
            "comparison_simulation_vs_experiment": null,
            "validation_success_rate": null,
            "domain_validation_standards": "Used as a proxy for open-ended discovery evaluation; paper stresses simulated domains should avoid being present in training corpora.",
            "when_simulation_sufficient": "Sufficient for testing reasoning/memorization properties of models, but not sufficient to validate real-world scientific claims.",
            "simulation_failures": "Simulated tasks may fail to reflect practical complexities of empirical science, limiting external validity of positive results.",
            "uncertainty_quantification": "Not discussed.",
            "fabrication_detection": "Simulated domains can detect model memorization/fabrication within synthetic contexts but not real-world fabrications.",
            "validation_cost_time": "Creating high-quality simulated domains is resource-intensive but cheaper than real experiments; trade-offs exist between realism and generalizability tests.",
            "hybrid_validation_approach": false,
            "validation_limitations": "Limited external validity; cannot serve as substitute for empirical validation in applied science.",
            "acceptance_credibility": "Success on simulated domains improves confidence in reasoning ability but not in real-world applicability; paper calls for better benchmarks bridging simulation and experiment.",
            "comparison_to_gold_standard": "Not comparable to experimental validation.",
            "uuid": "e2214.10"
        },
        {
            "name_short": "Domain-specific empirical validation",
            "name_full": "Domain-specific empirical validation practices (physical, chemical/biological, clinical)",
            "brief_description": "The paper contrasts domain norms: physical sciences favor controlled experiments and theory-driven verification (and sometimes high-fidelity simulation); chemistry/biology rely on manual experimentation and ontological frameworks; clinical sciences rely on RCTs, observational studies and meta-analyses for validation.",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_or_method_name": "Domain-specific empirical validation practices",
            "scientific_domain": "Physical sciences, chemical & biological sciences, clinical sciences",
            "validation_type": "experimental",
            "validation_description": "Physical sciences: controlled experiments and data-driven simulations integrating background laws. Chemical/biological: manual experiments (genetic manipulation, behavioral observation), context-dependent ontologies. Clinical: randomized controlled trials (gold standard), observational studies, meta-analyses; validation relies on statistical inference for efficacy and safety.",
            "simulation_fidelity": "Physical sciences: simulations can be high-fidelity when governing laws are known; chemistry/biology: simulations often lower-fidelity relative to experiments due to system complexity; clinical: simulations rarely sufficient, empirical trials required.",
            "experimental_validation_performed": null,
            "comparison_simulation_vs_experiment": "Paper asserts each domain has different balance; clinical domain regards RCTs as gold standard while simulations/observational studies are supportive but not definitive.",
            "validation_success_rate": null,
            "domain_validation_standards": "Physical: reproducible, quantifiable experiments tied to theory; Biological/Chemical: context-dependent experimentation and ontologies; Clinical: randomized controlled trials are gold standard.",
            "when_simulation_sufficient": "Paper suggests simulations can be sufficient in physical domains when grounded in correct governing equations, but in biological and clinical sciences simulation alone is usually insufficient.",
            "simulation_failures": "Paper cites general concern that models/simulations can mislead if not validated by experiments; specific domain failures are not enumerated beyond engineering examples.",
            "uncertainty_quantification": "Clinical and experimental sciences rely on statistical inference; physical sciences may use error bars and residuals; the paper emphasizes the need for domain-appropriate uncertainty measures but gives no standardization.",
            "fabrication_detection": "Empirical replication and independent verification are primary defenses against fabricated or spurious claims in experimental domains.",
            "validation_cost_time": "Experimental validation is typically slow and expensive relative to computational screening; paper highlights verification bottleneck as limiting pace of discovery.",
            "hybrid_validation_approach": true,
            "validation_limitations": "Differences in domain ontology and practicability limit transfer of formal verification methods; experimental costs and ethical constraints (clinical) reduce ability to empirically validate all AI-generated hypotheses.",
            "acceptance_credibility": "Paper stresses experimental verification (especially RCTs in clinical science) is key to community acceptance; computational/simulation validation alone is often insufficient.",
            "comparison_to_gold_standard": "Explicitly states RCTs are gold standard in clinical sciences; in physics, formal derivability and experiments constitute the highest standards.",
            "uuid": "e2214.11"
        },
        {
            "name_short": "Verification failure examples",
            "name_full": "High-consequence verification failures (Mars Climate Orbiter, Gimli Glider, medication dosing errors)",
            "brief_description": "Historical incidents where lack of rigorous verification (unit mismatch, conversion errors, medication dosing mistakes) led to catastrophic or serious outcomes, used as cautionary examples for AI-driven discovery.",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_or_method_name": "Historical verification failure case studies",
            "scientific_domain": "Aerospace engineering, aviation safety, clinical medicine",
            "validation_type": "other",
            "validation_description": "Examples: NASA Mars Climate Orbiter lost due to pound-vs-newton unit mismatch (1999); Gimli Glider fuel exhaustion due to pound/kilogram conversion during metric transition (1983); medication dosing errors from pound/kg confusion and wrong heparin vial selection. These illustrate that small verification lapses can have large consequences and motivate automated verification.",
            "simulation_fidelity": null,
            "experimental_validation_performed": false,
            "comparison_simulation_vs_experiment": null,
            "validation_success_rate": null,
            "domain_validation_standards": "Industrial and mission-critical engineering rely on rigorous automated verification and formal methods to ensure safety.",
            "when_simulation_sufficient": "Not applicable; these are cautionary real-world incidents showing need for robust verification beyond simulation.",
            "simulation_failures": "These are real-world failures due to human and process verification lapses rather than simulation inadequacy.",
            "uncertainty_quantification": "Not applicable.",
            "fabrication_detection": "Not applicable.",
            "validation_cost_time": "Examples highlight high downstream costs (financial, human) of inadequate verification — e.g., $125M Mars Climate Orbiter loss referenced.",
            "hybrid_validation_approach": null,
            "validation_limitations": "Illustrative—serve as motivation but do not provide a method.",
            "acceptance_credibility": "Used to argue for stronger verification culture in scientific research and for automated verification pipelines.",
            "comparison_to_gold_standard": "Demonstrates that industrial gold-standard verification practices (automated checks, formal methods) are necessary in mission-critical contexts.",
            "uuid": "e2214.12"
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Combining data and theory for derivable scientific discovery with AI-Descartes.",
            "rating": 2
        },
        {
            "paper_title": "Evolving scientific discovery by unifying data and background knowledge with ai hilbert.",
            "rating": 2
        },
        {
            "paper_title": "Physics-informed neural networks: A deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations.",
            "rating": 2
        },
        {
            "paper_title": "Hamiltonian neural networks",
            "rating": 1
        },
        {
            "paper_title": "Lagrangian neural networks",
            "rating": 1
        },
        {
            "paper_title": "PySR: Fast & parallelized symbolic regression in Python/Julia.",
            "rating": 1
        },
        {
            "paper_title": "AI Feynman: A physics-inspired method for symbolic regression.",
            "rating": 1
        },
        {
            "paper_title": "Fine-tuning language models from human preferences.",
            "rating": 1
        },
        {
            "paper_title": "LLM-SRBench: A new benchmark for scientific equation discovery with large language models.",
            "rating": 2
        },
        {
            "paper_title": "Ai achieves silver-medal standard solving international mathematical olympiad problems.",
            "rating": 1
        }
    ],
    "cost": 0.026985,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>The Need for Verification in AI-Driven Scientific Discovery
1 Sep 2025</p>
<p>Cristina Cornelio c.cornelio@samsung.com 
Samsung AI
CambridgeUK</p>
<p>Takuya Ito 
IBM Research
Yorktown Heights
USA</p>
<p>Ryan Cory-Wright 
Imperial Business School
LondonUK</p>
<p>Sanjeeb Dash 
IBM Research
Yorktown Heights
USA</p>
<p>Lior Horesh 
IBM Research
Yorktown Heights
USA</p>
<p>The Need for Verification in AI-Driven Scientific Discovery
1 Sep 202545C4E3C2E7946BC55E73773029B9338EarXiv:2509.01398v1[cs.AI]
Artificial intelligence (AI) is transforming the practice of science.Machine learning and large language models (LLMs) can generate hypotheses at a scale and speed far exceeding traditional methods, offering the potential to accelerate discovery across diverse fields.However, the abundance of hypotheses introduces a critical challenge: without scalable and reliable mechanisms for verification, scientific progress risks being hindered rather than being advanced.In this article, we trace the historical development of scientific discovery, examine how AI is reshaping established practices for scientific discovery, and review the principal approaches, ranging from data-driven methods and knowledge-aware neural architectures to symbolic reasoning frameworks and LLM agents.While these systems can uncover patterns and propose candidate laws, their scientific value ultimately depends on rigorous and transparent verification, which we argue must be the cornerstone of AI-assisted discovery.</p>
<p>Introduction</p>
<p>The overarching goal of science is to provide a set of universal, accurate, and interpretable explanations that describe the natural world.This involves discovering natural laws that not only make accurate predictions but are also corroborated by existing scientific literature.Such laws have historically been discovered through the scientific method, a systematic process that begins with a question and proceeds through a study phase during which researchers gather all prior knowledge and data pertaining to the phenomenon under investigation.This leads to the formulation of hypotheses, empirical validation, and iterative refinement.The scientific method enables the discovery of verifiable scientific truths by relying on substantiated and repeatable evidence, lending science its legitimacy and credibility.</p>
<p>The shift from dogmatic belief systems to a framework grounded in scientific theory and empirical verification, epitomized by the 16th-century transition from religious authority to human reason through the work of Copernicus, Galileo, and Bruno, marked a fundamental epistemological transformation leading to the Scientific Revolution [Leveillee, 2011].Indeed, Kepler's mathematical description of planetary motion, grounded in Tycho Brahe's observational data and Bacon's advocacy for inductive reasoning, established the foundation for modern empirical science [Bacon, 1878, Westfall, 1977].Critically, the consequences of this verification-driven methodology have been profound in the modern age.Verified discoveries such as germ theory [Latour, 1993], high-yield agricultural practices [Borlaug, 1970], and thermodynamic principles [Smil, 2004] have transformed medicine, food production, and energy systems.These advances were achieved through a disciplined integration of theoretical models and experimental validation.</p>
<p>However, the rate of major discoveries has declined in both absolute and relative terms over the past several decades [Bloom et al., 2020, Bhattacharya and Packalen, 2020, Arora et al., 2018].This decline is arguably due to the exhaustion of simple, low-dimensional theories, and the increasing complexity of modern scientific problems [Cowen, 2011] (see Fig. 1A).Amid these challenges, the rise of machine learning and artificial intelligence has introduced promising tools to augment hypothesis generation and data analysis for scientific discovery.However, many existing implementations of these data-driven systems lack formal mechanisms for logical inference that are essential for verifiable scientific discovery [Platt, 1964].In particular, generative AI models have shown remarkable capacity to rapidly generate novel scientific hypotheses [Gottweis et al., 2025, Yamada et al., 2025, Lu et al., 2024, Jumper et al., 2021].However, these outputs often lack empirical grounding and are frequently disconnected from established theoretical frameworks or domain-specific knowledge.This disconnect has led to an overwhelming influx of unverified hypotheses, straining verification pipelines that are essential for validating scientific discoveries [Beel et al., 2025, Gridach et al., 2025, Kulkarni et al., 2025] (see Fig. 1B).Consequently, developing robust methods to refine and verify hypotheses from data-driven approaches is critical to unlocking the full potential of AI in accelerating scientific progress (Fig. 1C).</p>
<p>Traditional scientific pipeline AI-assisted scientific pipeline</p>
<p>Verification bottleneck</p>
<p>Widen verification via automated verification</p>
<p>Accelerate scientific discoveries</p>
<p>Hypotheses crafted from theory and ontology</p>
<p>Rapid &amp; abundant AI-generated hypotheses</p>
<p>The Need for Improved Verification Methods</p>
<p>AI-generated hypotheses</p>
<p>Hypotheses Many Many Few Scientific Discoveries</p>
<p>A B C</p>
<p>Figure 1: The scientific method in the age of AI.A) In the traditional scientific method, theories guide the generation of testable hypotheses, which are then validated through experiments and data.B) However, with generative AI, hypotheses can be rapidly produced from data, but verification still relies on slow, manual evaluation by domain experts.C) Without widening this verification bottleneck (e.g., through automated/integrated verification) the pace of discovery remains limited, despite the acceleration promised by AI.</p>
<p>To address the limitations of purely data-driven approaches, several recent works propose hybrid frameworks.These approaches integrate machine learning with elements of symbolic reasoning, constraints imposition, and formal logic, aiming to ensure scientific validity alongside predictive accuracy (e.g., see Wiberg et al. [2025] for a review on integration between AI/ML and Operations Research techniques).For example, Kolmogorov-Arnold Networks (KANs) [Liu et al., 2025] replace fixed linear weights with learnable univariate functions, producing interpretable approximations of scientific relations.Hamiltonian Neural Networks (HNNs) [Greydanus et al., 2019] similarly enforce energy conservation by learning a Hamiltonian and deriving system dynamics from Hamilton's equations.While the learned models from both systems respect structural embeddings, verification for both systems is limited to their specific structural property.More recently, AI-Descartes [Cornelio et al., 2023a] introduced a general verification mechanism, where hypotheses were generated via a data-driven approach and later verified against known theory via theorem proving.Building upon that work, AI-Hilbert [Cory-Wright et al., 2024] integrated data and theory directly during the hypothesis generation stage, thereby constraining the search to expressions consistent with both data and theory.While both these approaches provide scientifically verifiable results, their application is limited to specific problem formulations in the physical sciences.Thus, while emerging computational tools offer great promise for broadly accelerating scientific discovery, their effectiveness hinges on ensuring resulting insights are not only predictive but also interpretable, verifiable, and aligned with foundational scientific knowledge.</p>
<p>In this article, we review recent progress in AI-driven scientific discovery, while underscoring the critical importance of verifying these methods throughout the discovery process.We begin by highlighting key historical examples where the failure to rigorously verify computational methods led to the collapse of critical missions, resulting in significant loss of life and financial cost.Next, we examine recent data-driven approaches to scientific discovery, highlighting their ability to uncover patterns and generate hypotheses from large datasets, particularly in domains where theoretical models are incomplete or unavailable.This is followed by a comparison with knowledge-aware methods, the emergence of derivable models that integrate symbolic reasoning, and the growing role of large language models (LLMs) in automating and augmenting scientific workflows.We conclude with a broader perspective on the heterogeneous role of verification across scientific domains, outlining current challenges and suggesting promising approaches for future research.</p>
<p>The Importance of Verification: Evidence from Examples</p>
<p>In 1999, NASA's Mars Climate Orbiter was lost when thruster data delivered in pounds per second was interpreted as Newtons per second, a unit mismatch that sent a $125 million spacecraft into the Martian atmosphere [NASA, 1999].Similarly, in 1983, Air Canada Flight 143 ("Gimli Glider") ran out of fuel mid-air after the ground crew incorrectly converted pounds to kilograms during Canada's metric transition, leaving the aircraft with roughly half the required fuel and forcing a dangerous emergency landing [Lockwood, 1985].Similar errors have been documented in hospitals: children given incorrect doses when weights noted in pounds were treated as kilograms [Bokser, 2013]; in a review of 1, 291 weight-related medication error reports to the Pennsylvania Patient Safety Authority, 23.2% involved pounds-kilograms confusion [Bailey et al., 2016]; and selection of high-strength heparin vials (10, 000 U/mL) were mistaken for low-strength ones [Institute for Safe Medication Practices Canada, 2008].The lesson from these domains is clear: without rigorous, automated verification, minor trivial errors can scale into disasters.</p>
<p>In automated scientific discovery, the same principle applies.Automated model-generation tools have transformed scientific discovery.Symbolic regression engines such as PySR [Cranmer, 2020] and AI Feynman [Udrescu and Tegmark, 2020], as well as neural architectures like Kolmogorov-Arnold Networks (KANs) [Liu et al., 2025], Hamiltonian Neural Networks (HNNs) [Greydanus et al., 2019], and Lagrangian Neural Networks (LNNs) [Cranmer et al., 2020a], now produce many new hypotheses quickly.This proliferation creates a new bottleneck: distinguishing between formulas that merely fit the data and those that are scientifically meaningful (Fig. 1).Without rigorous verification, the flood of generated hypotheses risks overwhelming the scientific process with plausible but superficial results.Thus, verification is an essential filter that separates genuine scientific discoveries from hallucinations or mere noisy interpolations that fail to generalize beyond the observed data.</p>
<p>The challenge of verification is further exacerbated by the rise of LLM-based tools whose reliability can be strongly questioned [Marcus, 2025, Kambhampati, 2024].Well-publicized examples of hallucinations from LLMs include the hallucination of legal cases cited in court filings [Weiss, 2023], the fabrication of biomedical references [Gravel et al., 2023], and outputs violating basic algebraic [Hendrycks et al., 2021] or physical consistency [Wang et al., 2023b].We refer to Zhang et al. [2025] for a recent review of LLMs and their use in scientific discovery.</p>
<p>One might argue that the latest generation of Large Language Models (LLMs), which utilize Reinforcement Learning from Human Feedback (RLHF) to steer outputs toward preferred outputs, already provide a form of verification [Ziegler et al., 2019].However, such feedback is not equivalent to scientific verification for several reasons.First, RLHF operates at the level of plausibility rather than truth: models are rewarded for producing outputs that appear correct to human evaluators.Second, the feedback is inherently partial and subjective, relying on limited annotations that cannot exhaustively cover the space of possible outputs.Third, RLHF provides no guarantees: models fine-tuned with feedback still generate confident but false statements and mathematically inconsistent expressions.</p>
<p>Thus, while reinforcement learning can improve the style and surface reliability of generated hypotheses, it does not address the deeper need for principled, automated verification against background theory and empirical constraints.For scientific discovery, this distinction is crucial: plausibility without proof cannot serve as the foundation of knowledge.</p>
<p>In the mathematical literature, the use of formal proof assistants for verification, such as Lean [De Moura et al., 2015], Coq [Bertot and Castéran, 2013], and Isabelle [Nipkow et al., 2002], has attracted considerable attention.These systems enable mathematical theorems to be expressed in a dependently typed language and verified computationally.For example, they can be used to verify that every result in an introductory analysis textbook is correct [Tao, 2025].Moreover, some recent works pair this technology with LLMs.For instance, the AlphaProof system from DeepMind [AlphaProof and AlphaGeometry teams, 2024] achieved a silver medal at the 2024 International Mathematics Olympiad by translating one million informal mathematical problems into Lean using natural language processing, allowing AlphaProof to be trained using reinforcement learning.However, since there is no commonly agreed-upon set of axioms for the natural sciences (e.g., quantum mechanics and gravity are not consistent), and the process of translating informal problems into formal statements can introduce errors unless verified by a user, a Lean-reinforcement learning approach cannot be broadly applied to scientific discovery.Finally, the growing recognition of verification challenges in AI-driven scientific discovery has catalyzed significant government investment in bridging formal methods with statistical AI approaches.In the United States, DARPA's portfolio is an example of this trend, featuring programs such as expMath [DARPA, 2025], which seeks to accelerate mathematics by developing AI systems capable of proposing and proving abstractions, and The Right Space (TRS) [DARPA, 2024c], which applies scientific machine learning to uncover tractable transformations for complex models.Other initiatives [DARPA, 2024b[DARPA, ,a,d, 2018]], including ReMath, PROVERS, V-SPELLS, and the completed HACMS program, further underscore the emphasis on formal verification in critical domains.These funding priorities reflect an acknowledgment that while generative AI excels at quick hypothesis generation and pattern discovery, scientific applications require the reliability and guarantees that only formal verification methods can provide.</p>
<p>AI Methods for Scientific Discovery</p>
<p>Motivated by the increasing importance of verification in scientific discovery and other domains involving AI, we next review the state-of-the-art methods used for scientific discovery.Figure 2 provides a qualitative map of the landscape, positioning the different major methods categories along three dimensions: the degree to which they are data-driven, the degree to which they are knowledge-driven and their associated computational complexity.We also discuss the limitations of the existing approaches and suggest strategies for future improvement.</p>
<p>Data-driven Methods</p>
<p>The data-driven discovery of symbolic formulae is a long-standing challenge in Artificial Intelligence [Kitano, 2016], and the central difficulty remains how to incorporate verification into the process.A variety of approaches have been proposed [Landajuela et al., 2022], ranging from neural networks designed to mimic human physical reasoning [Iten et al., 2020], to tree-structured LSTMs for handling symbolic expression trees and formula verification [Arabshahi et al., 2018], to logic-constrained GANs for image generation [Marra et al., 2018].Symbolic regression (SR) has played a prominent role in this space, with applications to extracting explicit relations from graph neural networks [Cranmer et al., 2020b], constructing analytic models for reinforcement learning control [Derner et al., 2019], or combining regression with Bayesian models [Jin et al., 2019].The AI Feynman family of methods [Udrescu andTegmark, 2020, Udrescu et al., 2020] exemplifies the integration of neural fitting with physics-inspired heuristics, while tools such as PySR [Cranmer, 2020, Cranmer et al., 2020b] and TuringBot [Schmidt and Lipson, 2009] use evolutionary or annealing-based search strategies to identify parsimonious equations.More recent methods, such as RSRM, combine Monte Carlo Tree Search with reinforcement learning for efficient symbolic exploration [Xu et al., 2024].Despite the progress, none of these approaches incorporates formal reasoning, leaving their outputs vulnerable to producing expressions that fit the data but lack theoretical grounding.</p>
<p>To address this gap, several works have attempted to combine SR or neural methods with logical consistency checking.The LGML system [Scott et al., 2020] augments learning with a module that verifies whether candidate functions satisfy constraints on their functional form, while LGGA [Ashok et al., 2021] extends this approach with genetic algorithms and auxiliary mathematical expressions.Similar ideas appear in Błądek and Krawiec [2019] counterexample-guided SR, in Kubalík et al. [2020,</p>
<p>Knowledge-driven discovery</p>
<p>Derivable models</p>
<p>Knowledge-aware NNs (PINNs, HNNs, LNNs)</p>
<p>Symbolic regression</p>
<p>Data-driven discovery</p>
<p>Automated theorem provers</p>
<p>Computational complexity</p>
<p>Linear regression</p>
<p>Kernel regression</p>
<p>Interactive theorem provers</p>
<p>Nonlinear regression (NNs, trees, etc.) Unsupervised (PCA, ICA, clustering, etc.)</p>
<p>Bayesian modeling</p>
<p>Program synthesis</p>
<p>Inductive Logic Programming</p>
<p>Figure 2: Qualitative Landscape of Computational Methods for Scientific Discovery.Different approaches span the spectrum between data-driven and knowledge-driven discovery.Data-driven methods, such as neural networks, can rapidly generate hypotheses but lack verifiability, whereas theory-driven methods, like automated theorem provers, offer rigorous verification but are often slow and undecidable.Derivable or science-aware approaches aim to bridge this gap by combining datadriven modeling with symbolic guarantees.The associated computational complexity reflects trade-offs between speed, interpretability, and verifiability.Note that this figure provides a qualitative illustration of the landscape of computational tools for scientific discovery, highlighting general trends across major categories.The position of specific methods in these categories may vary depending on data type, approach, or hybrid usage.2021] multi-objective framework that enforces nonlinear constraints as discrete data points, and in Engle and Sahinidis [2021] deterministic mixed-integer programming formulation with derivative constraints.These methods, however, remain limited to constraints on functional form rather than incorporating background-theory axioms that describe the scientific environment itself.</p>
<p>In parallel, the broader neuro-symbolic community has explored the integration of logic constraints into machine learning tools.Approaches include penalizing constraint violations in neural networks [Xu et al., 2018, Wang andPan, 2020] and embedding logical rules in the training process [Cornelio et al., 2023b, Li and Srikumar, 2019, Daniele and Serafini, 2020, Xie et al., 2019, Li et al., 2019].Inductive logic programming and rule induction [Tamaddoni-Nezhad et al., 2021, Sen et al., 2022, Evans and Grefenstette, 2018, Sadeghian et al., 2019, Law et al., 2018] provide another way of extracting logical knowledge from data, while program synthesis has gained renewed interest as a means of combining symbolic reasoning with statistical learning [Sun et al., 2022, Nye et al., 2020, Parisotto et al., 2017, Valkov et al., 2018, Yang et al., 2017].Yet, across all these efforts, formal verification of discovered formulas remains elusive: constraints typically ensure plausibility, not provability.The result is that many systems generate equations that appear valid but are not guaranteed to align with the underlying laws of nature.</p>
<p>Knowledge-aware methods</p>
<p>Scientific discovery and artificial intelligence have traditionally followed separate paradigms: the former rooted in theory and verification, and the latter in data-driven learning.As scientific problems become increasingly complex and data become increasingly abundant yet noisy or incomplete, there is a growing interest in integrating scientific knowledge into machine learning models.The resulting hybrid methods aim to combine the flexibility of learning-based approaches with the structure and generalizability offered by physical laws.</p>
<p>This section surveys approaches that leverage scientific knowledge in AI model design and training.We distinguish between physics-informed models, which learn the unknown solution of known governing equations by training neural networks to minimize data and physics residuals, and physics-inspired models, that encode known structures, such as conservation laws, directly in the network's architecture.We also consider symmetry-informed networks that embed invariance or equivariance directly into model operations, so that transformations of the input induce consistent transformations of the output.</p>
<p>Physics-Informed Neural Networks (PINNs).Physics-Informed Neural Networks (PINNs) incorporate governing physical laws into the learning process by embedding partial differential equations (PDEs) directly into the loss function [Raissi et al., 2019, Cuomo et al., 2022].These models are not intended to discover the governing equations themselves, but rather to approximate their solutions.The key idea is to replace or augment traditional numerical solvers by training a neural network that minimizes a composite loss consisting of: 1) A data loss term measuring the fit to observed data; 2) A physics loss term penalizing violation of the PDE; and 3) A boundary condition loss term ensuring physical consistency.Mathematically, for a PDE of the form F (x, u, ∇u, ∇ 2 u) = 0, the PINN approximates the solution u(x) with a neural network u θ (x), and minimizes:
L total = λ d L data + λ f L physics + λ b L boundary .
This approach has demonstrated success across various domains, including fluid mechanics, heat diffusion, and quantum mechanics.It provides an elegant, mesh-free framework capable of solving high-dimensional PDEs with limited data.</p>
<p>While PINNs represent a significant advance in scientific computing, the method requires carefully balancing multiple loss terms, and is therefore sensitive to network architecture choices.This highlights the importance of systematic hyperparameter optimization strategies.Additionally, the current approach relies on known governing equations as constraints, and the generic network architectures employed do not yet fully exploit problem-specific structural information.These characteristics have motivated active research directions focused on adaptive loss weighting schemes, physics-informed architecture design, and methods for discovering unknown governing equations from data [Lu et al., 2021].</p>
<p>Physics-inspired Neural Networks.Physics-inspired neural networks take a complementary approach: instead of embedding the governing equations into the training loss, they encode physical structure directly into the model architecture.These models are well-suited to systems governed by conservation laws, such as those following Hamiltonian or Lagrangian dynamics.</p>
<p>In Hamiltonian neural networks (HNNs) [Greydanus et al., 2019], the model learns a scalar-valued Hamiltonian function H(q, p), where q and p are generalized coordinates and momenta.The dynamics are then obtained by differentiating H according to Hamilton's equations:
dq dt = ∂H ∂p , dp dt = − ∂H ∂q .
enforcing conservation of energy by design.</p>
<p>Lagrangian neural networks (LNNs) [Cranmer et al., 2020a] instead model the Lagrangian L(q, q) and derive equations of motion via the Euler-Lagrange equations.This enables the incorporation of constraints and yields coordinate-invariant representations.</p>
<p>Physics-inspired networks, thus, encode domain knowledge directly into the architecture, allowing them to model both the its state and evolution in a structured way.However, as noted by Newman et al. [2024], these approaches do not discover the underlying laws; instead, they assume them, modeling the dynamics within the specified structural form.Furthermore, incorporating multiple types of physical constraints simultaneously (e.g., energy and momentum conservation alongside symmetry constraints) remains an open challenge.</p>
<p>Equivariant Neural Networks.Many physical systems exhibit symmetries such as translation, rotation, or permutation invariance.Equivariant neural networks explicitly incorporate such symmetries by ensuring that transformations of the input correspond to equivalent transformations of the output [Cohen and Welling, 2016].Formally, a function f is equivariant with respect to a group G if:
f (g • x) = g • f (x), ∀g ∈ G.
Equivariant Convolutional Neural Networks (G-CNNs), Spherical CNNs, and SE(3)-equivariant graph networks have been developed to model molecular systems, fluid dynamics, and lattice structures, among others [Weiler et al., 2021, Batzner et al., 2022].These networks often lead to improved sample efficiency and generalization.Symmetry-informed networks [Akhound-Sadegh et al., 2023] extend this concept to more general forms of structure, potentially including conservation laws and geometric constraints.These methods can be viewed as a broader class of equivariant models.However, as with physics-inspired networks, they often require manual specification of symmetry constraints and may not scale well when multiple symmetries coexist.</p>
<p>Knowledge-aware AI methods, while promising, still face ongoing challenges as they continue to evolve.Current approaches typically depend on experts to manually encode physical laws, architectural choices, or symmetry constraints into models, which limits scalability and automation.Moreover, the simultaneous incorporation of multiple physical principles presents significant computational and theoretical challenges.The interpretability of these models remains a key concern, as they often function as black boxes that provide limited insight into the underlying physical mechanisms they approximate.Most critically, existing methods typically lack formal guarantees regarding constraint satisfaction.Physical laws are commonly enforced through soft constraints via penalty terms in the loss function, which cannot ensure that the learned models rigorously adhere to all governing physical principles.These challenges underscore the need for formal frameworks that unify data-driven modeling with principled use of background knowledge, supporting rigorous verification.</p>
<p>Derivable models</p>
<p>A different line of work is represented by the methods of AI-Descartes [Cornelio et al., 2023a] and AI-Hilbert [Cory-Wright et al., 2024], which explicitly introduce background theory into the process of scientific discovery.In contrast to most existing methods, which either constrain functional forms or encode structural biases, these frameworks embed general scientific axioms and use them to guide or validate the discovery of candidate laws.AI-Descartes takes a verification-oriented perspective, generating hypotheses from data and then employing formal reasoning to test their consistency with background theory.AI-Hilbert, on the other hand, integrates theory directly into the hypothesis generation process, reducing the search space and enforcing consistency during model generation.[Cornelio et al., 2023a] is a neuro-symbolic framework for automated scientific discovery that couples symbolic regression with formal reasoning.The system adopts a generator-verifier paradigm, where any hypothesis generator can be paired with any formal verifier, allowing the generation of arbitrarily defined models without restrictions on functional classes, grammar, or structure.This modular yet sequential design ensures flexibility but prevents data and theory from being leveraged simultaneously: hypotheses are generated from data first and only then verified, a separation that limits the exploitation of their complementary strengths.</p>
<p>AI-Descartes. AI-Descartes</p>
<p>Formally, the system seeks to discover an unknown symbolic model y = f * (x), where x = (x 1 , . . ., x n ) are independent variables and y is the dependent variable.The inputs are defined as a 4-tuple ⟨B, C, D, M⟩, where B denotes the background knowledge, consisting of domain-specific axioms; C is the hypothesis class, describing the admissible symbolic models via a grammar and functional constraints; D is the dataset of m examples; and M specifies modeler preferences, such as acceptable error bounds or complexity measures.The discovery task is then framed as a multi-objective problem: the candidate function f must fit the data, remain consistent with B, and have bounded complexity and prediction error.</p>
<p>As outlined above, the AI-Descartes architecture is organized around two main modules following a generator-verifier design.The first is a symbolic regression (SR) module, formulated as a mixed-integer nonlinear programming (MINLP) problem, which enumerates candidate formulas that approximate the data and remains effective with very few, noisy data points.The second is a reasoning module, based on a theorem prover, that evaluates the logical relationship between a candidate model and the background theory.In particular, AI-Descartes introduces the concept of a reasoning distance, which measures the discrepancy between predictions of a candidate model f and the predictions of a formula derivable from B (assumed to be complete, i.e., containing all the axioms necessary to derive the ground-truth law).Each candidate hypothesis is evaluated both in terms of its empirical error ε(f ) relative to the data D, and its reasoning error β(f ) relative to the axioms in B. These two scores are combined to rank the hypotheses, with the top-ranked model being selected as the best candidate.The interplay between these two main components allows AI-Descartes to filter out spurious hypotheses that, while numerically accurate, violate known physical or logical constraints.</p>
<p>Unlike prior efforts that embed only structural constraints, AI-Descartes incorporates full background theories, expressed in logical form.This enables it to reason over unmeasured variables not present in the data and over non-obvious relations that go beyond the data itself.Building on this capability, AI-Descartes can also compare alternative background theories (possibly inconsistent to each other) by computing reasoning errors for each and selecting the set of axioms that is the most consistent with the data.</p>
<p>AI Hilbert.AI-Hilbert [Cory-Wright et al., 2024] is a theory-guided framework for automated scientific discovery that integrates background knowledge directly into hypothesis generation.In contrast to post hoc verification, AI-Hilbert couples data and theory in a single synthesis problem: candidate laws are constructed to satisfy the axioms as they are fit to the data.However, the method restricts the hypothesis space to polynomial (or, when admissible, rational) expressions, which enables algebraic constraints from the background theory to be enforced exactly or with controlled slack.</p>
<p>More formally, AI-Hilbert aims to discover an unknown polynomial formula q(•) ∈ R[x] which describes a physical phenomenon, and is consistent with both a background theory and a collection of experimental data.The inputs to AI-Hilbert are a four-tuple (B, D, C(Λ), d c ), where: 1) B denotes the relevant background theory, expressed as a collection of axioms: the union of the inequalities {g 1 (x) ≥ 0, . . ., g k (x) ≥ 0} defining G and the equalities {h 1 (x) = 0, . . ., h l (x) = 0} defining H, where g i , h j ∈ R[x] n (the ring of real polynomials in the n-tuple of variables x ∈ R n ).B is defined over n variables x 1 , . . ., x n .However, only t of these n variables can be measured and are directly relevant for explaining the observed phenomenon.In particular, we let x 1 denote the target variable.The remaining n − t variables appear in the background theory but are not directly observable.The background theory B is defined as complete if it contains all the axioms necessary to formally prove the target formula, and incomplete otherwise.Moreover, B is called inconsistent if it contains axioms that contradict each other, and consistent otherwise.A special case of inconsistency is when a formula that incorrectly describes the studied phenomenon is added to a consistent background theory.2) D := {x i } i∈[m] denotes a collection of data points, or measurements of an observed physical phenomenon, which may be few and noisy.3) C denotes a set of constraints and bounds which depend on a set of hyper-parameters Λ (e.g., bound on the degree of the polynomial q).4) d c (•, G ∩ H) denotes a distance function from an arbitrary polynomial to the background theory.</p>
<p>The AI-Hilbert algorithm has 4 main steps: Pr sd using a mixed-integer conic optimization solver, outputting a candidate formula and a set of
multipliers {α i } k i=1 , {β j } l j=1 .
The formula is of the form q(x) = 0 (where the only monomials with nonzero coefficients are those that only contain the variables x 1 , . . ., x t , the observable variables) and such that q
(x) = α 0 (x) + k i=1 α i (x)g i (x) + l j=1 β j (x)h j (x) if d c (q, G ∩ H) = 0,
which is a certificate of the fact that q is derivable from the complete background theory.If d c &gt; 0, for example, when the background theory is inconsistent or incomplete, then AI-Hilbert returns a certificate that q is approximately derivable from the background theory.</p>
<p>LLMs for Scientific Discovery</p>
<p>Recent advances in generative AI, and particularly large language models (LLMs), have opened new avenues for accelerating scientific discovery [Reddy and Shojaee, 2025].In materials discovery, generative graph-based models such as GNoME have drastically expanded the set of known stable materials, representing an order-of-magnitude increase in crystallographic diversity [Merchant et al., 2023a].More recently, LLMs have been used to extract domain knowledge from scientific literature, generate new material compositions, and guide experimental design, as demonstrated in systems like AtomAgents, which integrate LLM reasoning with alloy design pipelines [Ghafarollahi and Buehler, 2024].</p>
<p>Transformer-based models treat equation discovery as a numeric-to-symbolic generation task [Kamienny et al., 2022].However, state-of-the-art general-purpose LLMs, such as OpenAI GPT-5, still have limitations when it comes to symbolic discovery, often producing only relatively simple functional forms (e.g., when prompted with the binary star data in Cornelio et al. [2023a]).At the same time, their ability to make inferences from simple axiom systems has improved notably compared to older models (see Appendix A for more details).In parallel, multimodal approaches like SNIP embed equations and numerical data into smoother joint spaces to improve search efficiency [Meidani et al., 2024], while systems such as LLM-SR explore the use of LLMs as "scientist agents" that evolve equations in search of governing laws [Shojaee et al., 2024].Benchmarks, such as LLM-SRBench, have recently been introduced to systematically evaluate these methods in scientific equation discovery [Shojaee et al., 2025].These works highlight the growing role of generative and language-based models in pushing symbolic regression beyond handcrafted algorithms toward more generalizable AI-driven discovery.</p>
<p>Alongside these task-specific methods, domain-specialized scientific LLMs are being developed to serve as general-purpose research copilots.NatureLM [Xia et al., 2025] is a foundation model designed to unify the "languages of nature" across molecules, proteins, DNA, RNA, and materials, enabling cross-domain generation and design of drug molecules, protein binders, and CRISPR guides.Similarly, Galactica [Taylor et al., 2022], trained on 106B scientific tokens spanning papers, textbooks, chemical sequences, proteins, and code, outperforms general LLMs on scientific benchmarks and introduces specialized reasoning tokens for step-by-step problem solving.These models illustrate how domain-curated corpora and tailored architectures can significantly advance LLM-based scientific discovery.</p>
<p>Finally, LLMs can be framed as agents rather than passive tools: by coupling their broad knowledge bases with external tool integration, LLM-based agents can design, test, and refine hypotheses in ways that approximate the iterative scientific method.ChemCrow [M.Bran et al., 2024], for example, integrates GPT-4 with chemistry-specific tools for reaction prediction, retrosynthesis planning, and safety assessment, enabling both reasoning and validation within chemical workflows.Multi-agent frameworks, such as SciAgents, extend this paradigm by coordinating specialized LLM-based agents to collaboratively explore biomaterials design [Ghafarollahi and Buehler, 2025].Alongside general frameworks for opendomain hypothesis generation in the social sciences [Yang et al., 2024], biomedicine [Qi et al., 2023], and rediscovery settings such as MOOSE-Chem in chemistry [Yang et al., 2025], these systems demonstrate the potential of LLMs and generative models not only to accelerate discovery in targeted domains such as chemistry and materials science, but also to serve as versatile, reasoning-driven collaborators in the broader pursuit of new scientific laws.</p>
<p>Verification in the age of AI-driven science</p>
<p>Modern engineering industries regularly employ verification in the development and deployment of mission-critical technologies, including those in aerospace, medical devices, and autonomous systems.The rigorous process of verifying the accurate implementation of such technologies ensures that these complex systems function precisely as intended, mitigating risks of failure that could lead to catastrophic loss of life, environmental damage, or severe economic disruption.Through meticulous testing, simulation, and formal methods, verification tests validate the design integrity, software reliability, and hardware performance of technologies where even minor deviations can have profound consequences.Given the potentially far-reaching impacts and high costs of scientific research, why isn't a stringent and widespread culture of independent verification more commonly embedded within modern scientific research, rather than being largely limited to industrial applications?In this section, we illustrate examples of the importance of verification across research communities and outline ways to incorporate verification into scientific research to enhance the rigor of the scientific method for the modern age.</p>
<p>The role of verification across scientific domains</p>
<p>The proliferation of AI models in scientific research presents a transformative opportunity to accelerate the pace of scientific discovery.In particular, generative AI models have demonstrated the ability to produce novel hypotheses at rapid scales and speeds.However, the rapid generation of scientific hypotheses presents significant challenges.Many of these AI-generated hypotheses lack empirical verification and are often disconnected from established theoretical frameworks or domain-specific knowledge.However, the strength of a scientific theory lies in its empirical predictive power [Popper, 1959].Without iterative refinement through empirical verification of hypotheses, scientific theories fail to progress and remaining unable to make useful empirical predictions (see Fig. 3).The strength of a scientific theory lies in its empirical predictive power.Thus, the development of a scientific theory requires iterative empirical verification, with stronger theories offering more accurate predictions of observable phenomena.However, the balance between theoretical strength and predictive power varies across scientific domains, and often depends on the epistemic goals and maturity of each field, as well as the nature of the theories (e.g., formal versus ontological theories).</p>
<p>Empirical</p>
<p>In many applied scientific domains, such as drug discovery or materials science, the term "discovery" often refers primarily to the generation of hypotheses -such as identifying a promising molecular compound or material configuration -rather than their empirical verification [Reidenbach et al., 2025, Merchant et al., 2023b, Jain et al., 2022, Anstine and Isayev, 2023, Takeda et al., 2023].This usage underscores the importance of distinguishing between the act of proposing a candidate and the subsequent process of validating its efficacy, safety, or theoretical soundness.As a result, researchers are increasingly confronted with a deluge of unverified hypotheses, clogging (and potentially slowing) verification pipelines that are critical to validating scientific discoveries.However, verification strategies across scientific domains differ greatly in approach and empirical requirements due to differences in their theories and ontologies, as well as the epistemic goals of each field.Here we briefly discuss the variation of verification strategies across a few scientific domains, namely physical, biological and complex sciences, and clinical sciences.</p>
<p>In the physical sciences, verification is tightly coupled with formal theories and mathematical models.Hypotheses are often derived from well-established physical laws, and their verification typically involves controlled experiments or data-driven simulations that yield quantifiable and reproducible results that integrate and conform to these background laws [Udrescu and Tegmark, 2020].This tight integration of theory and data allows for the use of automated verification techniques that derive data from physical laws and theory [Cornelio et al., 2023a, Cory-Wright et al., 2024].</p>
<p>In contrast, however, many chemical, biological, and cognitive sciences present a more complex landscape for verification [Mock et al., 2024].Unlike physics, chemical, materials, and biological theories are often less formalized and more context-dependent, reflecting the inherent complexity of these systems and the variability of the epistemic goals across scientific domains.For example, verification in biology typically involves manual experimentation, such as genetic manipulation or behavioral observation, and relies heavily on ontological frameworks like evolutionary theory or systems biology, and less on explicit, quantitative laws.Though quantification is still important, it is often within the context of multi-variable and dynamical systems that are difficult to quantitatively derive from first principles.Nevertheless, efforts to build-in background knowledge (or incorporate a knowledgeconstrained search space) can improve the quality and validity of discovered hypotheses, thereby improving (and accelerating) scientific discovery in these domains (e.g., in chemistry [Yang et al., 2025], and in cognitive science [Castro et al., 2025]).</p>
<p>In medical and clinical sciences, there are additional layers of complexity.These tend to be shaped by ethical constraints, human variability, and pragmatic demands of clinical practice.Moreover, theories in clinical research are often probabilistic and population-based, rather than deterministic.Importantly, though the gold standard for verification strategies in clinical trials are randomized control trials, due to practical constraints of clinical research, verification strategies also include observational studies and meta-analyses of existing data.However, in all these cases, verification relies on statistical inference to assess efficacy and safety that are informed by ontological systems such as disease classifications and diagnostic criteria, which evolve over time.</p>
<p>Similar domain-specific variations in verification strategies are evident across various fields, including complex system sciences, earth sciences, social sciences, and engineering, among others, and each is shaped by its unique epistemic and methodological contexts.Despite the diversity of verification strategies across scientific domains, a unifying thread is the reliance on logical reasoning as the foundation for hypothesis testing and theory refinement.Whether through deductive modeling in physics, experimental inference in biology, or statistical evaluation in clinical sciences, the process of verification is fundamentally driven by structured, iterative reasoning.This echoes John Platt's notion of strong inference [Platt, 1964], where progress in science stems from the disciplined application of logic to generate, test, and eliminate hypotheses.While the form and tools of logical inference vary -from mathematical formalism (e.g., physical sciences) to ontological frameworks (e.g., biological sciences) to probabilistic models (e.g., clinical sciences) -the underlying commitment to rational analysis and verification remains constant.</p>
<p>Final Remarks and Future Challenges</p>
<p>In this work, we reviewed how AI is reshaping scientific discovery, with verification as a central open challenge.We reviewed a spectrum of methods, spanning from data-driven models to knowledge-based and hybrid approaches, illustrating their potential to accelerate hypothesis generation while also raising important concerns about their interpretability and reliability.The landscape we outlined highlights both the potential and the limits of contemporary AI, while pointing to the need to advance automated verification methods to improve AI-driven scientific discovery.There are many challenges ahead.In the next section we outline the most critical ones and discuss how they open promising directions for future research.</p>
<p>Challenges in AI-Driven Scientific Discovery</p>
<p>A major challenge for AI-driven scientific discovery is building benchmarks that genuinely capture open-ended scientific discovery and are not captured in the training distribution of existing AI systems.Existing datasets-such as AI Feynman [Udrescu and Tegmark, 2020], SciBench [Wang et al., 2023a], ScienceQA [Lu et al., 2022], and MATH [Hendrycks et al., 2021] focus on rediscovery or textbook-style problem solving, which neglects the complexity of theory formation.This is problematic because LLMs may depend on memorization rather than reasoning [Carlini et al., 2021, Wu et al., 2023], and unlike in theorem proving, most benchmarks lack explicit underlying theory, making verification-based evaluation nearly impossible.Indeed, whether an LLM is capable of making a scientific discovery often depends on the precise prompt used and even the notation used to describe a scientific discovery setting.Recent advances, such as simulated domains for scientific discovery [M.Bran et al., 2024, Shojaee et al., 2024] and the newly proposed LLM-SRBench [Shojaee et al., 2025], take steps toward mitigating memorization and evaluating true discovery.Nonetheless, key gaps remain in creating benchmarks that rigorously test novelty, generalizability, and scientific consistency [Cranmer et al., 2020b].</p>
<p>A second key challenge in AI-driven science is the unification of theory and data, since most existing methods focus either on empirical modeling or formal reasoning in isolation.While LLMs have shown promise in theorem proving [Jiang et al., 2023] and equation discovery from data [Shojaee et al., 2024], integrating these capabilities into a holistic framework remains an open problem.Efforts such as AI-Descartes [Cornelio et al., 2023a] and AI-Hilbert [Cory-Wright et al., 2024], as well as work in neuro-symbolic AI [De Raedt andKimmig, 2015, Ahmed et al., 2022], point toward promising directions for future development.However, challenges persist in deriving rigorous hypotheses from data, combining symbolic and neural approaches, and handling uncertainty within formal reasoning.</p>
<p>A third challenge in AI-driven discovery is ensuring that the use of AI does not overly homogenize science.The traditional scientific method is implemented differently by each scientist.This diversity, including the fact that scientists occasionally make mistakes, is a fundamental strength of science, as it enables different individuals to make distinct discoveries [Elliott, 2004].For instance, Alexander Fleming discovered penicillin by accident [Tan and Tatsumura, 2015], a "mistake" that an AI scientist would be unlikely to make.Ensuring that organic "mistakes" remain a part of the scientific method is another key challenge in the age of AI-driven discovery.</p>
<p>Conclusions</p>
<p>A key conclusion is that AI-driven scientific discovery compels us to reconsider the very notion of the "scientific method" itself.Traditionally, science has been portrayed as a systematic process of hypothesis generation, experimentation, and validation, but this narrative has been repeatedly challenged by philosophers such as Feyerabend [Feyerabend, 1975], who argue that rigid methodological rules neither capture nor enable true scientific progress.With the advent of generative models and inspired by industrial practices, however, we may be entering a new era in which verification becomes not just essential but also the primary bottleneck in scientific discovery.This shift would mark a departure from the traditional scientific method, reframing discovery as an iterative dialogue between creativity and verification, potentially laying the new groundwork for a new scientific paradigm.</p>
<p>[Step 1] The background theory B and data D are combined to generate a polynomial optimization problem Pr which targets a specific concept identified by the target variable x 1 .This is achieved by minimizing the distance d c , the model complexity and the error on the data, while integrating the bounds and constraints C. [Step 2] Pr is then reformulated as a semidefinite (or linear if no inequalities are present in the background theory) optimization problem Pr sd , by leveraging standard techniques from SOS optimization.[Step 3] Next, AI-Hilbert solves</p>
<p>Figure 3 :
3
Figure3: The role of verification in the development of scientific theories.The strength of a scientific theory lies in its empirical predictive power.Thus, the development of a scientific theory requires iterative empirical verification, with stronger theories offering more accurate predictions of observable phenomena.However, the balance between theoretical strength and predictive power varies across scientific domains, and often depends on the epistemic goals and maturity of each field, as well as the nature of the theories (e.g., formal versus ontological theories).</p>
<p>Figure 4 :
4
Figure 4: Prompt given to GPT-5 for binary star data used in AI Descartes (with variables relabeled as (d, m 1 , m 2 , p) → (x, y, z, u) and data columns permuted compared to the original dataset) and the output returned by GPT-5.The desired formula is u =</p>
<p>Figure 5 :
5
Figure5: Prompt and output given to GPT-4 for a simple artificial (not arising from any physical theory) example of the type used in AI Descartes.GPT-4 did not return a correct answer, which is f (d, k, z, g) = kzg z−d , whereas GPT-5 did (see Figure6for a comparison with GPT-5 on the same prompt).</p>
<p>Figure 6 :
6
Figure6: Prompt and output given to GPT-5 for a simple artificial (not arising from any physical theory) example of the type used in AI Descartes.GPT-4 did not return a correct answer, which is f (d, k, z, g) = kzg z−d , whereas GPT-5 did (see Figure5for a comparison with GPT-4 on the same prompt).</p>
<p>A AppendixIn this section, we give two examples of simple scientific discovery related queries given to a state-ofthe-art LLM, specifically GPT-5, the latest version of ChatGPT.In the first, we take data given in AI Descartes[Cornelio et al., 2023a]for two binary stars revolving around a common center of gravity and ask GPT-5 to find a function that best fits the data.The target function in this example is Kepler's third law of planetary motion.The data is scaled in such a manner that the period of revolution p is equal towhere d is the distance between the binary stars, and m 1 and m 2 stand for their masses.We rename the variables, (d, m 1 , m 2 , p) → (x, y, z, u), to avoid giving away information about the problem to GPT-5.In Figure4we show the prompt given to GPT-5 and its output.One can see that GPT-5 tries out a number of different functional forms -in other words it performs a limited symbolic regression exercise -and does not produce the desired function as a candidate solution.In Figure5we give the prompt at the top to GPT-4 and show its output, while in Figure6we show instead the output of GPT-5 on the same prompt.It is clear that GPT-4 fails to reason accurately with the axioms and comes up with the correct expression of the functional form relating the variables other than x, whereas GPT-5 produces the correct answer f (d, k, z, g) = kzg z−d and also the correct derivation.
Semantic probabilistic layers for neuro-symbolic learning. K Ahmed, S Teso, K.-W Chang, G Van Den Broeck, A Vergari, Advances in Neural Information Processing Systems. 202235</p>
<p>problems-at-silver-medal-level/. Announces AlphaProof (Lean-based formal reasoning) and AlphaGeometry 2. T Akhound-Sadegh, L Perreault-Levasseur, J Brandstetter, M Welling, S Ravanbakhsh, arXiv:2311.04293Lie point symmetry and physics informed networks. 2023. 20247arXiv preprintAi achieves silver-medal standard solving international mathematical olympiad problems. system scored 28/42 on IMO 2024</p>
<p>Generative Models as an Emerging Paradigm in the Chemical Sciences. D M Anstine, O Isayev, 10.1021/jacs.2c13467Journal of the American Chemical Society. 0002-786314516Apr. 2023American Chemical Society</p>
<p>Combining symbolic expressions and black-box function evaluations in neural programs. F Arabshahi, S Singh, A Anandkumar, In ICLR. 2018</p>
<p>The decline of science in corporate R&amp;D. A Arora, S Belenzon, A Patacconi, Strategic Management Journal. 3912018</p>
<p>Logic guided genetic algorithms (student abstract). D Ashok, J Scott, S J Wetzel, M Panju, V Ganesh, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial IntelligenceMay 202135</p>
<p>F Bacon, Novum organum. Clarendon press1878</p>
<p>Update on medication errors associated with incorrect patient weights. B R Bailey, M J Gaunt, M J Grissinger, Pennsylvania Patient Safety Advisory. 13206 2016Analysis found. 2% of events involved pounds-kilograms confusion (N=1,291</p>
<p>E(3)-equivariant graph neural networks for data-efficient and accurate interatomic potentials. S Batzner, A Musaelian, L Sun, M Geiger, J P Mailoa, M Kornbluth, N Molinari, T E Smidt, B Kozinsky, Nature Communications. 1312022</p>
<p>Evaluating sakana's ai scientist for autonomous research: Wishful thinking or an emerging reality towards' artificial research intelligence. J Beel, M.-Y Kan, M Baumgart, arXiv:2502.142972025arXiv preprint</p>
<p>Interactive theorem proving and program development: Coq'Art: the calculus of inductive constructions. Y Bertot, P Castéran, 2013Springer Science &amp; Business Media</p>
<p>Stagnation and scientific incentives. J Bhattacharya, M Packalen, 2020National Bureau of Economic ResearchTechnical report</p>
<p>Solving symbolic regression problems with formal constraints. I Błądek, K Krawiec, The Genetic and Evolutionary Computation Conference (GECCO '19). Prague, Czech RepublicACMJuly 13-17, 2019. 2019</p>
<p>Are ideas getting harder to find?. N Bloom, C I Jones, J Van Reenen, M Webb, American Economic Review. 11042020</p>
<p>S J Bokser, A weighty mistake. Agency for Healthcare Research and Quality (AHRQ). PSNet WebM&amp;M case commentary2013</p>
<p>Nobel lecture: The green revolution, peace, and humanity. N Borlaug, 1970</p>
<p>Extracting training data from large language models. N Carlini, F Tramer, E Wallace, M Jagielski, A Herbert-Voss, K Lee, A Roberts, T Brown, D Song, U Erlingsson, 30th USENIX Security Symposium (USENIX Security 21). 2021</p>
<p>Discovering Symbolic Cognitive Models from Human and Animal Behavior. P S Castro, N Tomasev, A Anand, N Sharma, R Mohanta, A Dev, K Perlin, S Jain, K Levin, N Éltető, W Dabney, A Novikov, G C Turner, M K Eckstein, N D Daw, K J Miller, K L Stachenfeld, 10.1101/2025.02.05.636732v1Feb. 2025New ResultsSection</p>
<p>T Cohen, M Welling, Group equivariant convolutional networks. International Conference on Machine Learning (ICML). 2016</p>
<p>Combining data and theory for derivable scientific discovery with AI-Descartes. C Cornelio, S Dash, V Austel, T R Josephson, J Goncalves, K L Clarkson, N Megiddo, B El Khadir, L Horesh, Nature Communications. 14117772023aNature Publishing Group</p>
<p>Learning where and when to reason in neuro-symbolic inference. C Cornelio, J Stuehmer, S X Hu, T Hospedales, International Conference on Learning Representations. 2023b</p>
<p>Evolving scientific discovery by unifying data and background knowledge with ai hilbert. R Cory-Wright, C Cornelio, S Dash, B El Khadir, L Horesh, Nature Communications. 15159222024</p>
<p>The great stagnation: How America ate all the low-hanging fruit of modern history, got sick, and will (eventually) feel better: A Penguin eSpecial from Dutton. T Cowen, 2011Penguin</p>
<p>PySR: Fast &amp; parallelized symbolic regression in Python/Julia. M Cranmer, 10.5281/zenodo.4041459Sept. 2020</p>
<p>M Cranmer, S Greydanus, S Hoyer, P Battaglia, D Spergel, S Ho, Lagrangian neural networks. International Conference on Learning Representations (ICLR). 2020a</p>
<p>Discovering symbolic models from deep learning with inductive biases. M Cranmer, A Sanchez-Gonzalez, P Battaglia, R Xu, K Cranmer, D Spergel, S Ho, NeurIPS. 2020. 2020b</p>
<p>Scientific machine learning through physics-informed neural networks: Where we are and what's next. S Cuomo, V Di Cola, F Giampaolo, G Rozza, M Raissi, F Piccialli, 10.1007/s10915-022-01939-z.pdfJournal of Scientific Computing. 9232022</p>
<p>A Daniele, L Serafini, arXiv:, 2009.06087Neural networks enhancement with logical knowledge. 2020</p>
<p>DARPA. High assurance cyber military systems (HACMS). 2018</p>
<p>reasoning-of-verifiers-enabling-robust-systems. DARPA. Pipelined reasoning of verifiers enabling robust systems (PROVERS). 2024a</p>
<p>DARPA. Recovery of symbolic mathematics from code. 2024bReMath</p>
<p>DARPA. The right space (TRS). 2024c</p>
<p>verified-security-and-performance-enhancement-of-large-legacy-software. DARPA. Verified security and performance enhancement of large legacy software V-SPELLS. 2024d</p>
<p>Exponentiating mathematics (expMath. DARPA. 2025</p>
<p>The lean theorem prover (system description. L De Moura, S Kong, J Avigad, F Van Doorn, J Raumer, International Conference on Automated Deduction. Springer2015</p>
<p>Probabilistic (logic) programming concepts. L De Raedt, A Kimmig, 10.1007/s10994-015-5494-z.pdfMachine Learning. 2015100</p>
<p>Symbolic regression for constructing analytic models in reinforcement learning. E Derner, J Kubalík, N Ancona, R Babuska, arXiv:, 1903.114832019</p>
<p>Error as means to discovery. K Elliott, Philosophy of Science. 7122004</p>
<p>Deterministic symbolic regression with derivative information: General methodology and application to equations of state. M R Engle, N V Sahinidis, AIChE Journal. e174572021</p>
<p>Learning explanatory rules from noisy data. R Evans, E Grefenstette, Journal of Artificial Intelligence Research. 612018</p>
<p>Against Method: Outline of an Anarchistic Theory of Knowledge. P Feyerabend, New Left Books. 1975</p>
<p>Atomagents: Alloy design and discovery through physics-aware multi-modal multi-agent artificial intelligence. A Ghafarollahi, M J Buehler, arXiv:2407.100222024arXiv preprint</p>
<p>Sciagents: automating scientific discovery through bioinspired multi-agent intelligent graph reasoning. A Ghafarollahi, M J Buehler, 10.1002/adma.202413523Advanced Materials. 372224135232025</p>
<p>Towards an ai co-scientist. J Gottweis, W.-H Weng, A Daryin, T Tu, A Palepu, P Sirkovic, A Myaskovsky, F Weissenberger, K Rong, R Tanno, arXiv:2502.188642025arXiv preprint</p>
<p>Learning to fake it: Limited responses and fabricated references provided by chatgpt for medical questions. J Gravel, M D'amours-Gravel, E Osmanlliu, 10.1016/j.mcpdig.2023.05.004Mayo Clinic Proceedings: Digital Health. 132023. 2023 Sep</p>
<p>Hamiltonian neural networks. S Greydanus, M Dzamba, J Yosinski, Advances in Neural Information Processing Systems. 201932</p>
<p>Agentic ai for scientific discovery: A survey of progress, challenges, and future directions. M Gridach, J Nanavati, K Z E Abidine, L Mendes, C Mack, arXiv:2503.089792025arXiv preprint</p>
<p>Institute for Safe Medication Practices Canada. Enhancing safety with unfractionated heparin: A national and international area of focus. D Hendrycks, C Burns, S Kadavath, A Arora, S Basart, E Tang, D Song, J Steinhardt, Proceedings of the Neural Information Processing Systems Track on Datasets and Benchmarks. the Neural Information Processing Systems Track on Datasets and Benchmarks2021. 2008. 20088Bulletin reference #5 cites the ISMP Medication Safety Alert!. on heparin errors</p>
<p>Discovering physical concepts with neural networks. R Iten, T Metger, H Wilming, L Rio, R Renner, Physical Review Letters. 1242020</p>
<p>Biological Sequence Design with GFlowNets. M Jain, E Bengio, A Hernandez-Garcia, J Rector-Brooks, B F P Dossou, C A Ekbote, J Fu, T Zhang, M Kilgour, D Zhang, L Simine, P Das, Y Bengio, Proceedings of the 39th International Conference on Machine Learning. the 39th International Conference on Machine LearningPMLRJune 2022</p>
<p>Draft, sketch, and prove: Guiding formal theorem provers with informal proofs. A Q Jiang, S Welleck, J P Zhou, W Li, J Liu, M Jamnik, T Lacroix, Y Wu, G Lample, International Conference on Learning Representations. 2023</p>
<p>Bayesian symbolic regression. Y Jin, W Fu, J Kang, J Guo, J Guo, arXiv[Methodology]:, 1910.088922019</p>
<p>Highly accurate protein structure prediction with AlphaFold. J Jumper, R Evans, A Pritzel, T Green, M Figurnov, O Ronneberger, K Tunyasuvunakool, R Bates, A Žídek, A Potapenko, A Bridgland, C Meyer, S A A Kohl, A J Ballard, A Cowie, B Romera-Paredes, S Nikolov, R Jain, J Adler, T Back, S Petersen, D Reiman, E Clancy, M Zielinski, M Steinegger, M Pacholska, T Berghammer, S Bodenstein, D Silver, O Vinyals, A W Senior, K Kavukcuoglu, P Kohli, D Hassabis, 10.1038/s41586-021-03819-2Nature. 1476-46875967873Aug. 2021Nature Publishing Group</p>
<p>Can large language models reason and plan?. S Kambhampati, Annals of the New York Academy of Sciences. 153412024</p>
<p>End-to-end symbolic regression with transformers. P.-A Kamienny, S Ascoli, G Lample, F Charton, Advances in Neural Information Processing Systems. S Koyejo, S Mohamed, A Agarwal, D Belgrave, K Cho, A Oh, Curran Associates, Inc202235</p>
<p>Artificial intelligence to win the Nobel prize and beyond: Creating the engine for scientific discovery. H Kitano, AI Magazine. 371Apr. 2016</p>
<p>Symbolic regression driven by training data and prior knowledge. J Kubalík, E Derner, R Babuška, Proceedings of the 2020 Genetic and Evolutionary Computation Conference. the 2020 Genetic and Evolutionary Computation Conference2020</p>
<p>Multi-objective symbolic regression for physics-aware dynamic modeling. J Kubalík, E Derner, R Babuška, Expert Systems with Applications. 1821152102021</p>
<p>A Kulkarni, F Alotaibi, X Zeng, L Wu, T Zeng, B M Yao, M Liu, S Zhang, L Huang, D Zhou, arXiv:2505.04651Scientific hypothesis generation and validation: Methods, datasets, and future directions. 2025arXiv preprint</p>
<p>A unified framework for deep symbolic regression. M Landajuela, C S Lee, J Yang, R Glatt, C P Santiago, T N Mundhenk, I Aravena, G Mulcahy, B Petersen, Advances in Neural Information Processing Systems (NeurIPS). 2022</p>
<p>The Pasteurization of France. B Latour, 1993Harvard University Press</p>
<p>Inductive learning of answer set programs from noisy examples. M Law, A Russo, K Broda, arXiv:, 1808.084412018</p>
<p>Copernicus, galileo, and the church: Science in a religious world. N P Leveillee, Inquiries Journal. 3052011</p>
<p>T Li, V Srikumar, arXiv:, 1906.06298Augmenting neural networks with first-order logic. 2019</p>
<p>T Li, V Gupta, M Mehta, V Srikumar, arXiv:, 1909.00126A logic-driven framework for consistency of neural models. 2019</p>
<p>KAN: Kolmogorov-arnold networks. Z Liu, Y Wang, S Vaidya, F Ruehle, J Halverson, M Soljačić, T Y Hou, M Tegmark, International Conference on Learning Representations (ICLR). 2025</p>
<p>G H Lockwood, Final report of the board of inquiry: Accident involving air canada boeing 767 c-gaun at gimli, manitoba. Lockwood23 july 1983. 1985Government catalogue confirms publication details</p>
<p>The ai scientist: Towards fully automated open-ended scientific discovery. C Lu, C Lu, R T Lange, J Foerster, J Clune, D Ha, arXiv:2408.062922024arXiv preprint</p>
<p>Learning nonlinear operators via deeponet based on the universal approximation theorem of operators. L Lu, P Jin, G Pang, Z Zhang, G E Karniadakis, 10.1038/s42256-021-00302-5Nature Machine Intelligence. 332021</p>
<p>Learn to explain: Multimodal reasoning via thought chains for science question answering. P Lu, S Mishra, T Xia, L Qiu, K.-W Chang, S.-C Zhu, O Tafjord, P Clark, A Kalyan, Advances in Neural Information Processing Systems. 202235</p>
<p>Augmenting large language models with chemistry tools. A M Bran, S Cox, O Schilter, C Baldassari, A D White, P Schwaller, Nature Machine Intelligence. 652024</p>
<p>Llms are not like you and me-and never will be. G Marcus, 2025</p>
<p>G Marra, F Giannini, M Diligenti, M Gori, arXiv:, 1807.09202Constraint-based visual generation. 2018</p>
<p>SNIP: Bridging mathematical symbolic and numeric realms with unified pre-training. K Meidani, P Shojaee, C K Reddy, A B Farimani, The Twelfth International Conference on Learning Representations. 2024</p>
<p>Scaling deep learning for materials discovery. A Merchant, S Batzner, S S Schoenholz, M Aykol, G Cheon, E D Cubuk, Nature. 62479902023a</p>
<p>Scaling deep learning for materials discovery. A Merchant, S Batzner, S S Schoenholz, M Aykol, G Cheon, E D Cubuk, 10.1038/s41586-023-06735-9Nature. 1476-46876247990Dec. 2023b</p>
<p>Recent advances in generative biology for biotherapeutic discovery. M Mock, C J Langmead, P Grandsard, S Edavettal, A Russell, 10.1016/j.tips.2024.01.003Trends in Pharmacological Sciences. 0165-6147453Mar. 2024Elsevier</p>
<p>NASA. Mars climate orbiter mishap investigation board phase i report. 1999</p>
<p>Stable tensor neural networks for efficient deep learning. E Newman, L Horesh, H Avron, M E Kilmer, 10.3389/fdata.2024.1363978/pdfFrontiers in Big Data. 713639782024</p>
<p>Isabelle/HOL: a proof assistant for higher-order logic. T Nipkow, M Wenzel, L C Paulson, 2002Springer</p>
<p>Learning compositional rules via neural program synthesis. M Nye, A Solar-Lezama, J Tenenbaum, B M Lake, Advances in Neural Information Processing Systems. H Larochelle, M Ranzato, R Hadsell, M Balcan, H Lin, Curran Associates, Inc202033</p>
<p>E Parisotto, A -R. Mohamed, R Singh, L Li, D Zhou, P Kohli, Neuro-symbolic program synthesis. International Conference on Learning Representations. 2017</p>
<p>Strong Inference. J R Platt, 10.1126/science.146.3642.347Science. 1463642Oct. 1964American Association for the Advancement of Science</p>
<p>The logic of scientific discovery. K R Popper, 1959Publisher: Basic Books</p>
<p>Large language models are zero shot hypothesis proposers. B Qi, K Zhang, H Li, K Tian, S Zeng, Z.-R Chen, B Zhou, NeurIPS 2023 Workshop on Instruction Tuning and Instruction Following. 2023</p>
<p>Physics-informed neural networks: A deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations. M Raissi, P Perdikaris, G E Karniadakis, Journal of Computational Physics. 3782019</p>
<p>Towards scientific discovery with generative ai: Progress, opportunities, and challenges. C K Reddy, P Shojaee, 10.1609/aaai.v39i27.35084Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial IntelligenceApr. 202539</p>
<p>Applications of Modular Co-Design for De Novo 3D Molecule Generation. D Reidenbach, F Nikitin, O Isayev, S Paliwal, arXiv:2505.18392May 2025</p>
<p>Drum: End-to-end differentiable rule mining on knowledge graphs. A Sadeghian, M Armandpour, P Ding, D Z Wang, Advances in Neural Information Processing Systems. H Wallach, H Larochelle, A Beygelzimer, F Alché-Buc, E Fox, R Garnett, Curran Associates, Inc201932</p>
<p>Distilling free-form natural laws from experimental data. M Schmidt, H Lipson, Science. 32459232009</p>
<p>J Scott, M Panju, V Ganesh, LGML: Logic Guided Machine Learning. 2006.03626, 2020</p>
<p>Neuro-symbolic inductive logic programming with logical neural networks. P Sen, B W S R De Carvalho, R Riegel, A G Gray, AAAI. 222022</p>
<p>Llm-sr: Scientific equation discovery via programming with large language models. P Shojaee, K Meidani, S Gupta, A B Farimani, C K Reddy, arXiv:2404.184002024arXiv preprint</p>
<p>LLM-SRBench: A new benchmark for scientific equation discovery with large language models. P Shojaee, N.-H Nguyen, K Meidani, A B Farimani, K D Doan, C K Reddy, Forty-second International Conference on Machine Learning. 2025</p>
<p>Enriching the Earth: Fritz Haber, Carl Bosch, and the Transformation of World Food Production. V Smil, 2004MIT Press</p>
<p>. J J Sun, M Tjandrasuwita, A Sehgal, A Solar-Lezama, S Chaudhuri, Y Yue, O Costilla-Reyes, arXiv:2210.050502022Neurosymbolic programming for science. arXiv preprint</p>
<p>Foundation Model for Material Science. S Takeda, A Kishimoto, L Hamada, D Nakano, J R Smith, 10.1609/aaai.v37i13.26793Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence202337</p>
<p>Humanmachine scientific discovery. A Tamaddoni-Nezhad, D A Bohan, G A Milani, A Raybould, S Muggleton, Human-like machine intelligence. Oxford University Press2021</p>
<p>Alexander fleming (1881-1955): discoverer of penicillin. S Y Tan, Y Tatsumura, Singapore medical journal. 5673662015</p>
<p>A lean companion to "analysis i. T Tao, 2025</p>
<p>R Taylor, M Kardas, G Cucurull, T Scialom, A Hartshorn, E Saravia, A Poulton, V Kerkez, R Stojnic, arXiv:2211.09085Galactica: A large language model for science. 2022arXiv preprint</p>
<p>AI Feynman 2.0: Paretooptimal symbolic regression exploiting graph modularity. S Udrescu, A Tan, J Feng, O Neto, T Wu, M Tegmark, Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems. H Larochelle, M Ranzato, R Hadsell, M Balcan, H Lin, NeurIPS2020. 2020. December 6-12, 2020, virtual, 2020</p>
<p>AI Feynman: A physics-inspired method for symbolic regression. S.-M Udrescu, M Tegmark, Science Advances. 6162020</p>
<p>Houdini: Lifelong learning as program synthesis. L Valkov, D Chaudhari, A Srivastava, C Sutton, S Chaudhuri, Advances in Neural Information Processing Systems. 201831</p>
<p>Integrating deep learning with logic fusion for information extraction. W Wang, S J Pan, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence202034</p>
<p>Scibench: Evaluating college-level scientific problem-solving abilities of large language models. X Wang, Z Hu, P Lu, Y Zhu, J Zhang, S Subramaniam, A R Loomba, S Zhang, Y Sun, W Wang, arXiv:2307.106352023aarXiv preprint</p>
<p>NEWTON: Are large language models capable of physical reasoning?. Y Wang, J Duan, D Fox, S Srinivasa, 10.18653/v1/2023.findings-emnlp.652Findings of the Association for Computational Linguistics: EMNLP 2023. SingaporeAssociation for Computational Linguistics2023b</p>
<p>Judge finds out why brief cited nonexistent cases-ChatGPT did the research. M Weiler, P Forré, E Verlinde, M Welling, arXiv:2106.06020Coordinate independent convolutional networks-isometry and gauge equivariant convolutions on riemannian manifolds. 2021. 2023arXiv preprint</p>
<p>R S Westfall, The Construction of Modern Science: Mechanisms and Mechanics. Cambridge University Press1977</p>
<p>Synergizing artificial intelligence and operations research: Perspectives from informs fellows on the next frontier. H Wiberg, T Dai, H Lam, R Kulkarni, INFORMS Journal on Data Science. 2025</p>
<p>Reasoning or reciting? exploring the capabilities and limitations of language models through counterfactual tasks. Z Wu, L Qiu, A Ross, E Akyürek, B Chen, B Wang, N Kim, J Andreas, Y Kim, arXiv:2307.024772023arXiv preprint</p>
<p>Nature language model: Deciphering the language of nature for scientific discovery. Y Xia, P Jin, S Xie, L He, C Cao, R Luo, G Liu, Y Wang, Z Liu, Y.-J Chen, Z Guo, Y Bai, P Deng, Y Min, Z Lu, H Hao, H Yang, J Li, C Liu, J Zhang, J Zhu, R Bi, K Wu, W Zhang, K Gao, Q Pei, Q Wang, X Liu, Y Li, H Zhu, Y Lu, M Ma, Z Wang, T Xie, K Maziarz, M Segler, Z Yang, Z Chen, Y Shi, S Zheng, L Wu, C Hu, P Dai, T.-Y Liu, H Liu, T Qin, arXiv:2502.075272025arXiv preprint</p>
<p>Embedding symbolic knowledge into deep networks. Y Xie, Z Xu, M S Kankanhalli, K S Meel, H Soh, Advances in neural information processing systems. 201932</p>
<p>A semantic loss function for deep learning with symbolic knowledge. J Xu, Z Zhang, T Friedman, Y Liang, G Broeck, International conference on machine learning. PMLR2018</p>
<p>Reinforcement symbolic regression machine. Y Xu, Y Liu, H Sun, The Twelfth International Conference on Learning Representations. 2024</p>
<p>The ai scientist-v2: Workshop-level automated scientific discovery via agentic tree search. Y Yamada, R T Lange, C Lu, S Hu, C Lu, J Foerster, J Clune, D Ha, arXiv:2504.080662025arXiv preprint</p>
<p>Differentiable learning of logical rules for knowledge base reasoning. F Yang, Z Yang, W W Cohen, 201730Advances in neural information processing systems</p>
<p>Large language models for automated open-domain scientific hypotheses discovery. Z Yang, X Du, J Li, J Zheng, S Poria, E Cambria, ACL 2024 findings. 2024</p>
<p>Moose-chem: Large language models for rediscovering unseen chemistry scientific hypotheses. Z Yang, W Liu, B Gao, T Xie, Y Li, W Ouyang, S Poria, E Cambria, D Zhou, The Thirteenth International Conference on Learning Representations. 2025</p>
<p>Exploring the role of large language models in the scientific method: from hypothesis to discovery. Y Zhang, S A Khan, A Mahmud, H Yang, A Lavin, M Levin, J Frey, J Dunnmon, J Evans, A Bundy, Artificial Intelligence. 11142025</p>
<p>D M Ziegler, N Stiennon, J Wu, T B Brown, A Radford, D Amodei, P Christiano, G Irving, arXiv:1909.08593Fine-tuning language models from human preferences. 2019arXiv preprint</p>            </div>
        </div>

    </div>
</body>
</html>