<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-726 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-726</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-726</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-20.html">extraction-schema-20</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <p><strong>Paper ID:</strong> paper-273233720</p>
                <p><strong>Paper Title:</strong> <a href="https://export.arxiv.org/pdf/2410.07191v2.pdf" target="_blank">Curb Your Attention: Causal Attention Gating for Robust Trajectory Prediction in Autonomous Driving</a></p>
                <p><strong>Paper Abstract:</strong> Trajectory prediction models in autonomous driving are vulnerable to perturbations from non-causal agents whose actions should not affect the ego-agent's behavior. Such perturbations can lead to incorrect predictions of other agents' trajectories, potentially compromising the safety and efficiency of the ego-vehicle's decision-making process. Motivated by this challenge, we propose Causal tRajecTory predICtion (CRiTIC), a novel model that utilizes a causal discovery network to identify inter-agent causal relations over a window of past time steps. To incorporate discovered causal relationships, we propose a novel Causal Attention Gating mechanism to selectively filter information in the proposed Transformer- based architecture. We conduct extensive experiments on two autonomous driving benchmark datasets to evaluate the robustness of our model against non-causal perturbations and its generalization capacity. Our results indicate that the robustness of predictions can be improved by up to 54% without a significant detriment to prediction accuracy. Lastly, we demonstrate the superior domain generalizability of the proposed model, which achieves up to 29% improvement in cross-domain performance. These results underscore the potential of our model to enhance both robustness and generalization capacity for trajectory prediction in diverse autonomous driving domairis.4</p>
                <p><strong>Cost:</strong> 0.015</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e726.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e726.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>CDN (CRiTIC)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Causal Discovery Network (within CRiTIC)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>An object-centric causal discovery module that infers a summary inter-agent causal graph from agent-centric trajectory representations using an MPNN, continuous edge relaxation, sparsity regularization, and an auxiliary denoising task.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>Causal Discovery Network (CDN)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>CDN takes map-aware, agent-centric representations and runs a single-layer Message Passing Neural Network (MPNN) to produce pairwise edge logits; edges are modelled as continuous relaxations of Bernoulli variables via the BinConcrete (Concrete/BinaryConcrete) distribution to allow backpropagation. The resulting weighted adjacency matrix A (edges e_ij in [0,1]) is thresholded at inference time to produce a discrete summary causal graph. Training includes (i) sparsity regularization implemented as KL divergence between the marginal edge probability and a Bernoulli prior p (information-bottleneck encouragement), and (ii) an auxiliary Denoising Autoencoder (two-layer GCN over downsampled temporal nodes) that reconstructs masked temporal agent representations conditioned on the candidate graph to encourage edges that help predict/mask reconstruction (motivated by Granger-causality).</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Waymo Open Motion Dataset (WOMD) and INTERACTION dataset</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Interactive driving datasets of real-world traffic scenes (observational, multi-agent interactions). They are not open-ended experimental labs; the data are recorded observational trajectories with scene context and human-annotated causal labels used for evaluation and perturbation tests (e.g., RemoveNonCausal).</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td>Explicit edge selection via learned adjacency (MPNN + BinConcrete) combined with an information-bottleneck style sparsity prior (KL to Bernoulli(p)) and an auxiliary DAE reconstruction loss that encourages edges needed for reconstructing/matching temporal dynamics; non-selected agents are treated as non-causal.</td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>Irrelevant/ non-causal agents (spurious correlations arising from correlated trajectories), measurement/noise in agent features indirectly (addressed indirectly by denoising), and scene-level spurious interactions.</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td>Edge weights e_ij learned by MPNN represent candidate causal influence; auxiliary DAE reconstruction loss uses masked temporal nodes so that edges that enable reconstruction are favored; thresholding the learned continuous edge probabilities at inference yields detected causal vs non-causal links. Sparsity prior biases detection toward fewer edges.</td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td>Downstream gating of attention (CAG) uses the learned adjacency to multiply/attenuate attention weights so that non-causal agents contribute little to the prediction; during training sparsity prior creates a limited attention bandwidth directing model to rely on selected edges.</td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td>Empirical intervention-style evaluation: RemoveNonCausal perturbation (removing agents labeled as non-causal) and measuring change in prediction metrics; auxiliary DAE also acts to 'refute' spurious edges because edges that do not help reconstruct masked temporal signals receive lower loss-driven support. No formal statistical refutation (e.g., conditional independence tests) beyond these mechanisms is used.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td>CRiTIC (with CDN + CAG + sparsity) yields substantial robustness gains under RemoveNonCausal perturbation: the paper reports up to a 54% improvement in the causality-based robustness metric relative to next-best baselines on OnlyAV setting and up to 53% on PlusAV (text reports 'up to 54%'). The model also achieves improved cross-domain generalization (up to 29% improvement in reported DG experiments). Reported numeric examples are in Table I and III of the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td>Baseline (non-causal) models such as MTR, SceneTransformer, Wayformer show larger performance drops under RemoveNonCausal perturbation; the paper reports larger relative ∆minADE drops for these baselines (see Table I). The paper also notes CRiTIC incurs minimal net performance degradation on nominal benchmarks (mAP drop < ~1%).</td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Learning an explicit object-centric summary causal graph via an MPNN with continuous relaxation and sparsity prior substantially improves robustness to removal of non-causal agents; the auxiliary DAE improves the precision/PR-AUC of the discovered edges and robustness further. Sparsity (information bottleneck) is a crucial knob/trade-off: higher sparsity increases RemoveNonCausal robustness but reduces 'social attention' and may harm nominal recovery; CRiTIC enables explicit control of sparsity at inference-time by thresholding edge probabilities.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Curb Your Attention: Causal Attention Gating for Robust Trajectory Prediction in Autonomous Driving', 'publication_date_yy_mm': '2025-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e726.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e726.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>CAG</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Causal Attention Gating</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A Transformer attention modification that uses the learned causal adjacency to gate and reweight self-attention so the model attends preferentially to causal agents and injects noise into non-causal contributions.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>Causal Attention Gating (CAG)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>CAG modifies the standard scaled dot-product attention by elementwise-multiplying the softmax attention logits Φ (Softmax(QK^T / sqrt(d_k))) with the learned adjacency A (Φ ⊙ A). The attended value becomes (Φ ⊙ A) V' plus an auxiliary noise term α (Φ ⊙ A_C) N where A_C = J − A (non-causal mask), N is Gaussian noise and α is a noise scale (set to zero at inference). This effectively preserves and amplifies attention to agents labeled causal by CDN and injects noise / reduces signal contribution from non-causal agents during training.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>Same as CDN: WOMD and INTERACTION datasets (Transformer backbone for multi-agent trajectory prediction).</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Transformer-based prediction backbone receiving agent-centric inputs; the environment is observational traffic data with multi-agent interactions.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td>Downweighting by gating attention with learned adjacency and explicit noise injection into non-causal attention channels (multiplicative masking of attention logits and additive/noisy value contributions).</td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>Non-causal agent influences and spuriously correlated agent behaviors</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td>Relies on CDN to detect which agents are causal (uses adjacency A); CAG itself does not detect but uses the detection output to gate.</td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td>Multiplicative gating of attention logits by adjacency (Φ ⊙ A) and additive Gaussian noise scaled by non-causal mask (α(Φ ⊙ A_C)N) during training to reduce influence of non-causal agents.</td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td>Indirect: by reducing the contribution of suspected non-causal agents during prediction and showing improved robustness under removal perturbations, the method empirically supports refutation of spurious attention pathways. No formal causal refutation test beyond perturbation evaluation is provided.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td>When combined with CDN and sparsity regularization, CAG yields large reductions in robustness degradation under RemoveNonCausal perturbations (paper reports up to 54% relative improvement in robustness vs baselines).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td>Without CAG (or without sparse CDN guidance), models are more susceptible to large performance drops when non-causal agents are removed; the paper's ablations indicate the causal gating helps direct attention and improve robustness.</td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Gating attention with an estimated causal graph and injecting noise to non-causal channels is an effective mechanism to downweight spurious agent signals and produce trajectory predictors that are less sensitive to removal of non-causal agents; the technique is simple to integrate into Transformer backbones and supports an adjustable sparsity trade-off.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Curb Your Attention: Causal Attention Gating for Robust Trajectory Prediction in Autonomous Driving', 'publication_date_yy_mm': '2025-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e726.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e726.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>DAE-GCN (aux)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Auxiliary Denoising Autoencoder implemented with a Graph Convolutional Network</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A self-supervised auxiliary task that reconstructs masked downsampled temporal agent representations using a GCN over a block lower-triangular graph derived from the CDN adjacency, promoting edges that enable temporal prediction consistent with Granger-style causality.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>Denoising Autoencoder (DAE) over GCN</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>Temporal agent representations are downsampled (group-average pooling into T' chunks) and flattened to create nodes v_t_i; edges are taken from a block lower-triangular expansion of the CDN adjacency, linking past→future nodes and self-edges. A two-layer GCN tries to reconstruct randomly node-masked inputs (node-wise masking). Gradients from the DAE are stopped from flowing back into AgentNet representations (StopGradient) to avoid collapse, but the DAE loss trains the CDN/adjacency to favor edges that help reconstruct masked temporal dynamics, i.e., edges useful under a Granger-like definition.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>WOMD and INTERACTION (same dataset contexts as the main model)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Observational multi-agent driving scenes; DAE is trained self-supervised on these recorded interactions (no active interventions).</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td>Detects edges that are not useful for temporal reconstruction (i.e., spurious) by penalizing candidate graphs that fail to reconstruct masked node features; indirectly downweights spurious edges in the learned adjacency.</td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>Spurious temporal correlations from non-causal agents and noise in agent trajectories that do not help reconstruct masked temporal chunks.</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td>Edges that fail to help GCN reconstruct masked node features receive less training signal and thus lower learned edge probabilities; DAE loss provides auxiliary supervision for distinguishing causal from spurious edges.</td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td>Indirect via lowering learned edge probability for edges that do not aid denoising reconstruction, which then propagate to downstream attention gating to reduce their influence.</td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td>No formal statistical refutation; empirical: edges unsupported by reconstruction are suppressed by the learning signal and result in reduced downstream influence; evaluated by improved PR-AUC and robustness metrics in ablations.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td>Ablation shows adding the DAE improves PR-AUC for edge prediction and increases robustness compared to models without it; the paper reports the DAE contributes to improved edge-quality (PR-AUC) and robustness (see Table IV).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td>Without the DAE, CDN still yields robustness gains (mainly due to MPNN and sparsity), but edge quality and some robustness improvements are lower (ablation rows in Table IV show reduced PR-AUC and higher ∆minADE).</td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Self-supervised denoising over temporal nodes helps the CDN learn edges that are useful for predicting future dynamics (in line with Granger-causality), improving edge precision (PR-AUC) and contributing to robustness; it is a helpful auxiliary supervision but not the sole source of robustness (MPNN main driver).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Curb Your Attention: Causal Attention Gating for Robust Trajectory Prediction in Autonomous Driving', 'publication_date_yy_mm': '2025-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e726.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e726.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>SparsityReg / IB</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Adjacency Sparsity Regularization (Information-Bottleneck style)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A sparsity regularizer on the learned adjacency implemented as KL divergence to a Bernoulli prior that creates an information bottleneck, forcing the model to select only a small set of causal edges and limiting attention bandwidth.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>Adjacency sparsity regularization (KL to Bernoulli prior)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>During training a regularization loss is applied: KL divergence between the marginal edge probability (learned by CDN) and a fixed Bernoulli(p) prior; choosing a small p biases the model toward sparse graphs, creating a limited inter-agent information bandwidth (information bottleneck). This reduces the model's ability to exploit spurious features by forcing attention to a few agents.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>WOMD and INTERACTION datasets (applied in CRiTIC training)</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>Observational driving data where many agents are present; sparsity regularization controls how many agents are deemed causally influential.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td>Regularization-based variable selection: enforces sparse adjacency so spurious/less-useful agent links are discouraged.</td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>Irrelevant/non-causal agents and spuriously correlated behaviors</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td>Not a detector per se; it biases the learned edge distribution so fewer edges survive; in combination with DAE and edge thresholding, this helps identify spurious vs causal links.</td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td>Indirect: fewer edges means non-selected agents' contributions are downweighted/removed via CAG at inference; sparsity thus reduces overall influence of distractors.</td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td>Sparsity does not directly refute a specific spurious edge but reduces false positives by imposing a prior that favors fewer causal links; empirical refutation is via RemoveNonCausal perturbation tests.</td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td>Higher sparsity correlates with higher robustness to RemoveNonCausal perturbations (paper shows a strong relation in Fig.3), but extreme sparsity (very few or zero edges) trivially yields robustness at the cost of ignoring social context.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td>Without sparsity regularization the learned graph can degenerate to dense connectivity and models exploit spurious correlations, leading to larger performance drops under non-causal perturbations; CRiTIC without sparsity shows worse robustness in experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Sparsity regularization is a simple, effective way to create an information bottleneck that encourages the model to select truly causal agents and improves robustness; however, sparsity is a trade-off and must be tuned (very high sparsity can harm nominal performance). The CRiTIC design allows explicit control of sparsity at inference via thresholding.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Curb Your Attention: Causal Attention Gating for Robust Trajectory Prediction in Autonomous Driving', 'publication_date_yy_mm': '2025-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e726.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e726.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of causal discovery methods, especially those that handle distractors or spurious correlations in virtual labs or interactive environments, including techniques for detecting, downweighting, or refuting spurious signals.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>ACD</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Amortized Causal Discovery</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A learning-based causal discovery approach that amortizes inference of causal graphs conditioned on observed time-series, exploiting shared dynamics across samples and Granger-causality principles.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Amortized causal discovery: Learning to infer causal graphs from time-series data</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>method_name</strong></td>
                            <td>Amortized Causal Discovery (ACD) (referenced)</td>
                        </tr>
                        <tr>
                            <td><strong>method_description</strong></td>
                            <td>ACD assumes samples are generated by different underlying causal graphs but share a common dynamics model g; it trains an amortized inference module which maps time-series x_{≤t} to a candidate causal graph G_s and a shared dynamics model conditioned on G_s to predict next states. ACD leverages Granger-style temporal causality and separates graph inference from dynamics prediction to enable efficient inference of graphs from observational time-series.</td>
                        </tr>
                        <tr>
                            <td><strong>environment_name</strong></td>
                            <td>General time-series causal discovery benchmarks (mentioned as conceptual foundation); not run in CRiTIC experiments</td>
                        </tr>
                        <tr>
                            <td><strong>environment_description</strong></td>
                            <td>ACD is a general method for causal discovery from observational time-series; it is not tied to a particular interactive simulation in this paper, but CRiTIC builds on its formulation for amortized discovery.</td>
                        </tr>
                        <tr>
                            <td><strong>handles_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>distractor_handling_technique</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>spurious_signal_types</strong></td>
                            <td>Conceptually addresses spurious temporal correlations across time-series by using graph-conditioned dynamics, but method details in original ACD paper determine exact handling.</td>
                        </tr>
                        <tr>
                            <td><strong>detection_method</strong></td>
                            <td>ACD learns to infer graphs from observational sequences using amortized inference networks; detection is via learned inference mapping from x_{≤t} to graph structures.</td>
                        </tr>
                        <tr>
                            <td><strong>downweighting_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>refutation_method</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>uses_active_learning</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>inquiry_strategy</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_with_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>performance_without_robustness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>has_ablation_study</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>number_of_distractors</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>CRiTIC explicitly states it builds on the ACD formulation for amortized Granger-style causal discovery but extends/adapts it for object-centric trajectory prediction in autonomous driving by adding MPNN, BinConcrete relaxation, sparsity KL prior, and a DAE auxiliary task; ACD itself is not experimentally evaluated here.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Curb Your Attention: Causal Attention Gating for Robust Trajectory Prediction in Autonomous Driving', 'publication_date_yy_mm': '2025-05'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Amortized causal discovery: Learning to infer causal graphs from time-series data <em>(Rating: 2)</em></li>
                <li>CausalAgents: A robustness benchmark for motion forecasting <em>(Rating: 2)</em></li>
                <li>Neural Granger causality <em>(Rating: 2)</em></li>
                <li>Cadet: a causal disentanglement approach for robust trajectory prediction in autonomous driving <em>(Rating: 2)</em></li>
                <li>Toward causal representation learning <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-726",
    "paper_id": "paper-273233720",
    "extraction_schema_id": "extraction-schema-20",
    "extracted_data": [
        {
            "name_short": "CDN (CRiTIC)",
            "name_full": "Causal Discovery Network (within CRiTIC)",
            "brief_description": "An object-centric causal discovery module that infers a summary inter-agent causal graph from agent-centric trajectory representations using an MPNN, continuous edge relaxation, sparsity regularization, and an auxiliary denoising task.",
            "citation_title": "here",
            "mention_or_use": "use",
            "method_name": "Causal Discovery Network (CDN)",
            "method_description": "CDN takes map-aware, agent-centric representations and runs a single-layer Message Passing Neural Network (MPNN) to produce pairwise edge logits; edges are modelled as continuous relaxations of Bernoulli variables via the BinConcrete (Concrete/BinaryConcrete) distribution to allow backpropagation. The resulting weighted adjacency matrix A (edges e_ij in [0,1]) is thresholded at inference time to produce a discrete summary causal graph. Training includes (i) sparsity regularization implemented as KL divergence between the marginal edge probability and a Bernoulli prior p (information-bottleneck encouragement), and (ii) an auxiliary Denoising Autoencoder (two-layer GCN over downsampled temporal nodes) that reconstructs masked temporal agent representations conditioned on the candidate graph to encourage edges that help predict/mask reconstruction (motivated by Granger-causality).",
            "environment_name": "Waymo Open Motion Dataset (WOMD) and INTERACTION dataset",
            "environment_description": "Interactive driving datasets of real-world traffic scenes (observational, multi-agent interactions). They are not open-ended experimental labs; the data are recorded observational trajectories with scene context and human-annotated causal labels used for evaluation and perturbation tests (e.g., RemoveNonCausal).",
            "handles_distractors": true,
            "distractor_handling_technique": "Explicit edge selection via learned adjacency (MPNN + BinConcrete) combined with an information-bottleneck style sparsity prior (KL to Bernoulli(p)) and an auxiliary DAE reconstruction loss that encourages edges needed for reconstructing/matching temporal dynamics; non-selected agents are treated as non-causal.",
            "spurious_signal_types": "Irrelevant/ non-causal agents (spurious correlations arising from correlated trajectories), measurement/noise in agent features indirectly (addressed indirectly by denoising), and scene-level spurious interactions.",
            "detection_method": "Edge weights e_ij learned by MPNN represent candidate causal influence; auxiliary DAE reconstruction loss uses masked temporal nodes so that edges that enable reconstruction are favored; thresholding the learned continuous edge probabilities at inference yields detected causal vs non-causal links. Sparsity prior biases detection toward fewer edges.",
            "downweighting_method": "Downstream gating of attention (CAG) uses the learned adjacency to multiply/attenuate attention weights so that non-causal agents contribute little to the prediction; during training sparsity prior creates a limited attention bandwidth directing model to rely on selected edges.",
            "refutation_method": "Empirical intervention-style evaluation: RemoveNonCausal perturbation (removing agents labeled as non-causal) and measuring change in prediction metrics; auxiliary DAE also acts to 'refute' spurious edges because edges that do not help reconstruct masked temporal signals receive lower loss-driven support. No formal statistical refutation (e.g., conditional independence tests) beyond these mechanisms is used.",
            "uses_active_learning": false,
            "inquiry_strategy": null,
            "performance_with_robustness": "CRiTIC (with CDN + CAG + sparsity) yields substantial robustness gains under RemoveNonCausal perturbation: the paper reports up to a 54% improvement in the causality-based robustness metric relative to next-best baselines on OnlyAV setting and up to 53% on PlusAV (text reports 'up to 54%'). The model also achieves improved cross-domain generalization (up to 29% improvement in reported DG experiments). Reported numeric examples are in Table I and III of the paper.",
            "performance_without_robustness": "Baseline (non-causal) models such as MTR, SceneTransformer, Wayformer show larger performance drops under RemoveNonCausal perturbation; the paper reports larger relative ∆minADE drops for these baselines (see Table I). The paper also notes CRiTIC incurs minimal net performance degradation on nominal benchmarks (mAP drop &lt; ~1%).",
            "has_ablation_study": true,
            "number_of_distractors": null,
            "key_findings": "Learning an explicit object-centric summary causal graph via an MPNN with continuous relaxation and sparsity prior substantially improves robustness to removal of non-causal agents; the auxiliary DAE improves the precision/PR-AUC of the discovered edges and robustness further. Sparsity (information bottleneck) is a crucial knob/trade-off: higher sparsity increases RemoveNonCausal robustness but reduces 'social attention' and may harm nominal recovery; CRiTIC enables explicit control of sparsity at inference-time by thresholding edge probabilities.",
            "uuid": "e726.0",
            "source_info": {
                "paper_title": "Curb Your Attention: Causal Attention Gating for Robust Trajectory Prediction in Autonomous Driving",
                "publication_date_yy_mm": "2025-05"
            }
        },
        {
            "name_short": "CAG",
            "name_full": "Causal Attention Gating",
            "brief_description": "A Transformer attention modification that uses the learned causal adjacency to gate and reweight self-attention so the model attends preferentially to causal agents and injects noise into non-causal contributions.",
            "citation_title": "here",
            "mention_or_use": "use",
            "method_name": "Causal Attention Gating (CAG)",
            "method_description": "CAG modifies the standard scaled dot-product attention by elementwise-multiplying the softmax attention logits Φ (Softmax(QK^T / sqrt(d_k))) with the learned adjacency A (Φ ⊙ A). The attended value becomes (Φ ⊙ A) V' plus an auxiliary noise term α (Φ ⊙ A_C) N where A_C = J − A (non-causal mask), N is Gaussian noise and α is a noise scale (set to zero at inference). This effectively preserves and amplifies attention to agents labeled causal by CDN and injects noise / reduces signal contribution from non-causal agents during training.",
            "environment_name": "Same as CDN: WOMD and INTERACTION datasets (Transformer backbone for multi-agent trajectory prediction).",
            "environment_description": "Transformer-based prediction backbone receiving agent-centric inputs; the environment is observational traffic data with multi-agent interactions.",
            "handles_distractors": true,
            "distractor_handling_technique": "Downweighting by gating attention with learned adjacency and explicit noise injection into non-causal attention channels (multiplicative masking of attention logits and additive/noisy value contributions).",
            "spurious_signal_types": "Non-causal agent influences and spuriously correlated agent behaviors",
            "detection_method": "Relies on CDN to detect which agents are causal (uses adjacency A); CAG itself does not detect but uses the detection output to gate.",
            "downweighting_method": "Multiplicative gating of attention logits by adjacency (Φ ⊙ A) and additive Gaussian noise scaled by non-causal mask (α(Φ ⊙ A_C)N) during training to reduce influence of non-causal agents.",
            "refutation_method": "Indirect: by reducing the contribution of suspected non-causal agents during prediction and showing improved robustness under removal perturbations, the method empirically supports refutation of spurious attention pathways. No formal causal refutation test beyond perturbation evaluation is provided.",
            "uses_active_learning": false,
            "inquiry_strategy": null,
            "performance_with_robustness": "When combined with CDN and sparsity regularization, CAG yields large reductions in robustness degradation under RemoveNonCausal perturbations (paper reports up to 54% relative improvement in robustness vs baselines).",
            "performance_without_robustness": "Without CAG (or without sparse CDN guidance), models are more susceptible to large performance drops when non-causal agents are removed; the paper's ablations indicate the causal gating helps direct attention and improve robustness.",
            "has_ablation_study": true,
            "number_of_distractors": null,
            "key_findings": "Gating attention with an estimated causal graph and injecting noise to non-causal channels is an effective mechanism to downweight spurious agent signals and produce trajectory predictors that are less sensitive to removal of non-causal agents; the technique is simple to integrate into Transformer backbones and supports an adjustable sparsity trade-off.",
            "uuid": "e726.1",
            "source_info": {
                "paper_title": "Curb Your Attention: Causal Attention Gating for Robust Trajectory Prediction in Autonomous Driving",
                "publication_date_yy_mm": "2025-05"
            }
        },
        {
            "name_short": "DAE-GCN (aux)",
            "name_full": "Auxiliary Denoising Autoencoder implemented with a Graph Convolutional Network",
            "brief_description": "A self-supervised auxiliary task that reconstructs masked downsampled temporal agent representations using a GCN over a block lower-triangular graph derived from the CDN adjacency, promoting edges that enable temporal prediction consistent with Granger-style causality.",
            "citation_title": "here",
            "mention_or_use": "use",
            "method_name": "Denoising Autoencoder (DAE) over GCN",
            "method_description": "Temporal agent representations are downsampled (group-average pooling into T' chunks) and flattened to create nodes v_t_i; edges are taken from a block lower-triangular expansion of the CDN adjacency, linking past→future nodes and self-edges. A two-layer GCN tries to reconstruct randomly node-masked inputs (node-wise masking). Gradients from the DAE are stopped from flowing back into AgentNet representations (StopGradient) to avoid collapse, but the DAE loss trains the CDN/adjacency to favor edges that help reconstruct masked temporal dynamics, i.e., edges useful under a Granger-like definition.",
            "environment_name": "WOMD and INTERACTION (same dataset contexts as the main model)",
            "environment_description": "Observational multi-agent driving scenes; DAE is trained self-supervised on these recorded interactions (no active interventions).",
            "handles_distractors": true,
            "distractor_handling_technique": "Detects edges that are not useful for temporal reconstruction (i.e., spurious) by penalizing candidate graphs that fail to reconstruct masked node features; indirectly downweights spurious edges in the learned adjacency.",
            "spurious_signal_types": "Spurious temporal correlations from non-causal agents and noise in agent trajectories that do not help reconstruct masked temporal chunks.",
            "detection_method": "Edges that fail to help GCN reconstruct masked node features receive less training signal and thus lower learned edge probabilities; DAE loss provides auxiliary supervision for distinguishing causal from spurious edges.",
            "downweighting_method": "Indirect via lowering learned edge probability for edges that do not aid denoising reconstruction, which then propagate to downstream attention gating to reduce their influence.",
            "refutation_method": "No formal statistical refutation; empirical: edges unsupported by reconstruction are suppressed by the learning signal and result in reduced downstream influence; evaluated by improved PR-AUC and robustness metrics in ablations.",
            "uses_active_learning": false,
            "inquiry_strategy": null,
            "performance_with_robustness": "Ablation shows adding the DAE improves PR-AUC for edge prediction and increases robustness compared to models without it; the paper reports the DAE contributes to improved edge-quality (PR-AUC) and robustness (see Table IV).",
            "performance_without_robustness": "Without the DAE, CDN still yields robustness gains (mainly due to MPNN and sparsity), but edge quality and some robustness improvements are lower (ablation rows in Table IV show reduced PR-AUC and higher ∆minADE).",
            "has_ablation_study": true,
            "number_of_distractors": null,
            "key_findings": "Self-supervised denoising over temporal nodes helps the CDN learn edges that are useful for predicting future dynamics (in line with Granger-causality), improving edge precision (PR-AUC) and contributing to robustness; it is a helpful auxiliary supervision but not the sole source of robustness (MPNN main driver).",
            "uuid": "e726.2",
            "source_info": {
                "paper_title": "Curb Your Attention: Causal Attention Gating for Robust Trajectory Prediction in Autonomous Driving",
                "publication_date_yy_mm": "2025-05"
            }
        },
        {
            "name_short": "SparsityReg / IB",
            "name_full": "Adjacency Sparsity Regularization (Information-Bottleneck style)",
            "brief_description": "A sparsity regularizer on the learned adjacency implemented as KL divergence to a Bernoulli prior that creates an information bottleneck, forcing the model to select only a small set of causal edges and limiting attention bandwidth.",
            "citation_title": "here",
            "mention_or_use": "use",
            "method_name": "Adjacency sparsity regularization (KL to Bernoulli prior)",
            "method_description": "During training a regularization loss is applied: KL divergence between the marginal edge probability (learned by CDN) and a fixed Bernoulli(p) prior; choosing a small p biases the model toward sparse graphs, creating a limited inter-agent information bandwidth (information bottleneck). This reduces the model's ability to exploit spurious features by forcing attention to a few agents.",
            "environment_name": "WOMD and INTERACTION datasets (applied in CRiTIC training)",
            "environment_description": "Observational driving data where many agents are present; sparsity regularization controls how many agents are deemed causally influential.",
            "handles_distractors": true,
            "distractor_handling_technique": "Regularization-based variable selection: enforces sparse adjacency so spurious/less-useful agent links are discouraged.",
            "spurious_signal_types": "Irrelevant/non-causal agents and spuriously correlated behaviors",
            "detection_method": "Not a detector per se; it biases the learned edge distribution so fewer edges survive; in combination with DAE and edge thresholding, this helps identify spurious vs causal links.",
            "downweighting_method": "Indirect: fewer edges means non-selected agents' contributions are downweighted/removed via CAG at inference; sparsity thus reduces overall influence of distractors.",
            "refutation_method": "Sparsity does not directly refute a specific spurious edge but reduces false positives by imposing a prior that favors fewer causal links; empirical refutation is via RemoveNonCausal perturbation tests.",
            "uses_active_learning": false,
            "inquiry_strategy": null,
            "performance_with_robustness": "Higher sparsity correlates with higher robustness to RemoveNonCausal perturbations (paper shows a strong relation in Fig.3), but extreme sparsity (very few or zero edges) trivially yields robustness at the cost of ignoring social context.",
            "performance_without_robustness": "Without sparsity regularization the learned graph can degenerate to dense connectivity and models exploit spurious correlations, leading to larger performance drops under non-causal perturbations; CRiTIC without sparsity shows worse robustness in experiments.",
            "has_ablation_study": true,
            "number_of_distractors": null,
            "key_findings": "Sparsity regularization is a simple, effective way to create an information bottleneck that encourages the model to select truly causal agents and improves robustness; however, sparsity is a trade-off and must be tuned (very high sparsity can harm nominal performance). The CRiTIC design allows explicit control of sparsity at inference via thresholding.",
            "uuid": "e726.3",
            "source_info": {
                "paper_title": "Curb Your Attention: Causal Attention Gating for Robust Trajectory Prediction in Autonomous Driving",
                "publication_date_yy_mm": "2025-05"
            }
        },
        {
            "name_short": "ACD",
            "name_full": "Amortized Causal Discovery",
            "brief_description": "A learning-based causal discovery approach that amortizes inference of causal graphs conditioned on observed time-series, exploiting shared dynamics across samples and Granger-causality principles.",
            "citation_title": "Amortized causal discovery: Learning to infer causal graphs from time-series data",
            "mention_or_use": "mention",
            "method_name": "Amortized Causal Discovery (ACD) (referenced)",
            "method_description": "ACD assumes samples are generated by different underlying causal graphs but share a common dynamics model g; it trains an amortized inference module which maps time-series x_{≤t} to a candidate causal graph G_s and a shared dynamics model conditioned on G_s to predict next states. ACD leverages Granger-style temporal causality and separates graph inference from dynamics prediction to enable efficient inference of graphs from observational time-series.",
            "environment_name": "General time-series causal discovery benchmarks (mentioned as conceptual foundation); not run in CRiTIC experiments",
            "environment_description": "ACD is a general method for causal discovery from observational time-series; it is not tied to a particular interactive simulation in this paper, but CRiTIC builds on its formulation for amortized discovery.",
            "handles_distractors": null,
            "distractor_handling_technique": null,
            "spurious_signal_types": "Conceptually addresses spurious temporal correlations across time-series by using graph-conditioned dynamics, but method details in original ACD paper determine exact handling.",
            "detection_method": "ACD learns to infer graphs from observational sequences using amortized inference networks; detection is via learned inference mapping from x_{≤t} to graph structures.",
            "downweighting_method": null,
            "refutation_method": null,
            "uses_active_learning": null,
            "inquiry_strategy": null,
            "performance_with_robustness": null,
            "performance_without_robustness": null,
            "has_ablation_study": null,
            "number_of_distractors": null,
            "key_findings": "CRiTIC explicitly states it builds on the ACD formulation for amortized Granger-style causal discovery but extends/adapts it for object-centric trajectory prediction in autonomous driving by adding MPNN, BinConcrete relaxation, sparsity KL prior, and a DAE auxiliary task; ACD itself is not experimentally evaluated here.",
            "uuid": "e726.4",
            "source_info": {
                "paper_title": "Curb Your Attention: Causal Attention Gating for Robust Trajectory Prediction in Autonomous Driving",
                "publication_date_yy_mm": "2025-05"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Amortized causal discovery: Learning to infer causal graphs from time-series data",
            "rating": 2,
            "sanitized_title": "amortized_causal_discovery_learning_to_infer_causal_graphs_from_timeseries_data"
        },
        {
            "paper_title": "CausalAgents: A robustness benchmark for motion forecasting",
            "rating": 2,
            "sanitized_title": "causalagents_a_robustness_benchmark_for_motion_forecasting"
        },
        {
            "paper_title": "Neural Granger causality",
            "rating": 2,
            "sanitized_title": "neural_granger_causality"
        },
        {
            "paper_title": "Cadet: a causal disentanglement approach for robust trajectory prediction in autonomous driving",
            "rating": 2,
            "sanitized_title": "cadet_a_causal_disentanglement_approach_for_robust_trajectory_prediction_in_autonomous_driving"
        },
        {
            "paper_title": "Toward causal representation learning",
            "rating": 1,
            "sanitized_title": "toward_causal_representation_learning"
        }
    ],
    "cost": 0.01505025,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><p>Curb Your Attention: Causal Attention Gating for Robust Trajectory Prediction in Autonomous Driving
6 Mar 2025</p>
<p>Ehsan Ahmadi 
Ray Mercurius 
Soheil Alizadeh 
Kasra Rezaee 
Amir Rasouli 
Curb Your Attention: Causal Attention Gating for Robust Trajectory Prediction in Autonomous Driving
6 Mar 2025E7E81FD950D356CD6EFF7464DCF116B8arXiv:2410.07191v2[cs.RO]
Trajectory prediction models in autonomous driving are vulnerable to perturbations from non-causal agents whose actions should not affect the ego-agent's behavior.Such perturbations can lead to incorrect predictions of other agents' trajectories, potentially compromising the safety and efficiency of the ego-vehicle's decision-making process.Motivated by this challenge, we propose Causal tRajecTory predICtion (CRiTIC), a novel model that utilizes a causal discovery network to identify inter-agent causal relations over a window of past time steps.To incorporate discovered causal relationships, we propose a novel Causal Attention Gating mechanism to selectively filter information in the proposed Transformer-based architecture.We conduct extensive experiments on two autonomous driving benchmark datasets to evaluate the robustness of our model against non-causal perturbations and its generalization capacity.Our results indicate that the robustness of predictions can be improved by up to 54% without a significant detriment to prediction accuracy.Lastly, we demonstrate the superior domain generalizability of the proposed model, which achieves up to 29% improvement in cross-domain performance.These results underscore the potential of our model to enhance both robustness and generalization capacity for trajectory prediction in diverse autonomous driving domains. 4OriginalRemove Noncausal CRiTIC (Ours)MTR[2]</p>
<p>I. Introduction</p>
<p>Trajectory prediction is a vital part of autonomous driving (AD) research and has received increased attention in recent years, witnessing many advancements in this field [1][2][3][4].Given the safety-critical nature of autonomous driving systems, the robustness of prediction models to noise and distribution shifts is of utmost importance.</p>
<p>Existing prediction models, despite achieving high accuracy, often heavily rely on spurious features such as the behavior of non-causal agents.Such a reliance leads to safety-critical issues and limits generalization of these models to new scenarios [5].For example, consider the scenario shown in Fig. 2. Vehicles Y and R exhibit highly correlated trajectories until reaching the intersection.At this point, their correlation breaks as Y intends to turn left.Here, vehicle B is the autonomous vehicle whose behavior depends on the prediction results.A model exploiting the correlation between R and Y might incorrectly predict that Y would continue following R, potentially causing a collision between Y and B. As shown in Fig. 1, the vulnerability of state-of-the-art models to non-causal agent removal perturbation exists in real-world scenarios (top row).This problem, however, can be remedied by effectively distinguishing between causal and non-causal relationships (bottom row).</p>
<p>Fig. 1: Robustness qualitative samples.The AV is shown in green.In CRiTIC's scene visualizations, the likelihood of a non-ego agent being causal is shown by its color saturation.The orange borderline indicates that the agent is labeled causal based on human labels [5].The ground truth, and predictions are shown in orange, and purple colors, respectively.Our model's performance is less affected by the intervention compared with the non-causal model.</p>
<p>To suppress the impact of spurious correlations, causal representation learning methods can be adopted to learn invariant causal latent variables [6].For instance, in the inertia and collision problems in imitation learning, causal variables are extracted from input latent space to train the motion planner [7].The model in [8] splits the variables into invariant, spurious, and style confounder features for pedestrian motion forecasting.For both of the approaches the learned representations are scene-centric.Although shown to be effective, compared to object-centric causal discovery approaches, causal disentanglement in scene-centric latent space is less interpretable and controllable (more about this in Section IV-B).</p>
<p>To this end, we propose CRiTIC, a novel object-centric causal trajectory prediction model that employs a separate Causal Discovery Network (CDN) to identify causal inter-agent relations and predict the future trajectory conditioned on the causal graph estimated by the CDN.The CRiTIC is designed to enhance robustness and generalizability in trajectory prediction.For causal discovery, we create an information bottleneck (IB) in the training process to force the model to dedicate its limited attention capacity to the most relevant agents.We also use a self-supervised graph structure learning (GSL) auxiliary task to improve the performance of the CDN.Training Inference 0.9 0.8 0.9 0.2 0.8 0.9 0.7 0.1 0.7 0.8 0.9 0.1 0.1 0.2 0.0 0.9 To integrate the resulting causal graph into the prediction module, we introduce a causal attention gating (CAG) mechanism that suppresses information from non-causal agents in the attention sub-layers of Transformer networks, which are extensively used in trajectory prediction models and other applications.
1 1 1 0 1 1 1 0 1 1 1 0 0 0 0 1 Stop Gradient Sampling Masking Concatenation Autonomous Vehicle
In summary, our contributions are as follows:</p>
<p>• We propose CRiTIC, a novel agent-centric causal model with explicit inter-agent causal relation reasoning (formulated in Section III) to have enhanced interpretability, robustness, generalization, and inference-time social attention controllability for trajectory prediction task (Section IV-B).• We propose a novel causal attention-gating mechanism that modulates the attention weights in our Transformer-based trajectory prediction model to only pay attention to the proposed causal agents by the CDN.This mechanism creates a dynamic information bottleneck which is effective in identifying causal relations (Section IV-C).• We conduct extensive experiments, showcasing the enhanced robustness and superior generalization capacity of our model thanks to its causal reasoning power (Section V).</p>
<p>II. Related Work Graph Structure Learning.Given a set of input feature vectors, the goal of GSL is to simultaneously learn the graph structure and the node representations that are optimized for a downstream task [9].Several approaches have been proposed, including neural NRI, which learns the latent structure using VAEs [10], IDGL that iteratively learns node features and graph structure using bi-level optimization [11], LDS, which models edges with learned Bernoulli distribution, and uses a sampling approach to generate the graph [12], and SLAPS that relies on a denoising autoencoder (DAE) in a self-supervised manner to reconstruct the node features and predict the node labels simultaneously [13].</p>
<p>In our work, we are mainly interested in the application of the GSL in causal structure discovery to infer causal relations in observational data.There are three main approaches to causal structure discovery: constraint-based [14], score-based [15], and learning-based [16].The objective of these methods is to identify a shared causal graph from which all the sample data is generated.</p>
<p>The amortized causal discovery (ACD) method exploits the idea of Granger-causality (see Section III) to identify causal graphs from purely observational data.It assumes data samples are generated by various causal graphs, while their underlying dynamics model is shared [17].This method benefits from a separate causal discovery module and a dynamics model which is conditioned on the causal graph generated by the former module.Hence, ACD is a suitable causal discovery approach, however, it is not designed for trajectory prediction in traffic scenarios where the model needs to process complex context information, e.g.various map elements, traffic lights, and multimodal futures.Our work builds on top of ACD's formulation for amortized causal discovery from observational data and extends it for the application of autonomous driving.Trajectory Prediction.Autonomous driving systems rely heavily on accurate prediction of other road users, such as pedestrians [18][19][20][21][22][23] and other vehicles [24][25][26][27][28][29] to ensure safe and efficient navigation through dynamic environments.There are several components that can be the focus of the research in this area, such as representation and encoding of the input data [3,[30][31][32][33][34][35][36], multi-modality and intention prediction [1,[37][38][39][40][41][42], and interaction modeling between the agents [3,43,44].</p>
<p>Prediction models often focus on feature correlations without considering meaningful causal relations, which are crucial for enhancing robustness and generalizability.Recent approaches have incorporated causal feature learning to address this issue.For instance, the model in [8] improves out-of-distribution generalization by categorizing latent variables into domain-invariant causal variables, domain-specific confounders, and spurious features, suppressing the latter during training to rely on causal features.Similarly, the authors of [45] propose a counterfactual analysis method that mitigates environmental bias using counterfactual interventions.However, while these models utilize scene-centric representations, they lack explicit modeling of inter-agent causal relations and do not employ disentangled representations for individual agents.</p>
<p>To investigate the robustness of the prediction models, the authors of [5] selected three state-of-the-art trajectory models, namely MultiPath++ [1], SceneTransformer [3], and Wayformer [4] and evaluated them under various perturbations applied to the data.The authors used human-annotated data to apply non-causal agent perturbations and showed that the performance of the aforementioned models was heavily impacted.They propose a heuristic data augmentation method to remove context vehicles during the training time.We, however, opt for an end-to-end model-centric approach that does not require heuristic function engineering.Our model addresses the causal robustness issue by explicitly identifying the causal graph and employing it in the trajectory prediction process.</p>
<p>III. Problem Formulation</p>
<p>Trajectory Prediction.The goal is to predict future trajectories (in XY Z coordinates) of target agents T ∈ R Ntarg×M ×T f ×3 (where N targ represents the number of target agents, M = 6 and T f denote the number of modes and future time steps, respectively) given the observed agents' trajectories S A and scene context S M as: T = F(S A , S M ).The observed trajectories S A ∈ R N obs ×T h ×D 0 a (where N obs is the number of observed agents in the scene, T h is the number of history time steps, and D 0 a is the dimension of agent features) include features, such as coordinates, heading angle, velocity, dimensions, and agent type.The scene context S M ∈ R Nm×Np×D 0 m represents map components (e.g., lanes, road boundaries) as N m polylines, each consisting of up to N p points, and characterized by position, component type, and dynamic states with the total feature dimension of D 0 m .Causal Graphical Models.The Causal Graphical model describes the distribution of a set of random variables with a Directed Acyclic Graph (DAG), which is represented as
G 1:T = {V 1:T , E 1:T }.
Here, we assume that the node variables are based on
N time series V 1:T = {V 1:T i } N i=1 . The edges E 1:T = {(v t i , v t j )|v t i , v t j ∈ V 1:T , v t i causes v t j }
represent the causal relationships between the variables.Based on causal Markov assumption, a variable v t i is independent of its non-decendents given its parents.The Summary Causal Graph (SCG) (referred to as a causal graph for brevity), G = {V, E}, is a compact version of the temporal causal graph, which captures the overall causal relationships between variables across all time steps:
E = {(v i , v j )|∃t, t ′ : (v t i , v t ′ j ) ∈ E 1:T }, V = {v i } N i=1 .
Granger causality is a commonly used method in the domain of observational time series data [46], which in our case is well suited for the trajectory prediction problem.A variable X is said to "Granger-cause" variable Y if past values of X provide statistically significant information about future values of Y , beyond what is already contained in the past values of Y alone.</p>
<p>For causal trajectory prediction, we adopt the formulation of the amortized causal discovery (ACD) approach, which builds upon the principles of Granger causality [17].Its key assumption is that for a set of data samples x s , with a varying set of summary causal graphs, G s , there exists a shared dynamics model g that
x t+1 s = g(x ≤t s , G s ) + ε t+1 s .
Here, G s represents the causal graph for sample s, x s ∈ R Ns×T denotes N s time series of length T , and ε t+1 s is the independent noise term modeling inherent aleatoric uncertainty of the data.This formulation allows us to separate the data generation process into two components and express the process as:
x t+1 s ≈ f θ (x ≤t s , f ϕ (x ≤t s ))
, with the components: (i) causal discovery model f ϕ -this is the CDN module explained in Section IV-B-which infers the causal structure from the observed data, and (ii) shared dynamics model f θ -this is the trajectory prediction backbone, T, discussed in Section IV-C-which predicts future states based on past observations and the inferred causal structure.</p>
<p>IV. Methods</p>
<p>CRiTIC is composed of three modules: (i) AgentNet which processes each agent and its surrounding map locally (Section IV-A); (ii) Causal Discovery Network (CDN) that constructs the causal graph based on the past interactions of the agents (Section IV-B); and (iii) trajectory prediction backbone (Section IV-C), which acts as the shared dynamics model as introduced in Section IV and predicts the future given the agent representations and the causal graph.</p>
<p>A. AgentNet: Generating Agent-Centric Representations</p>
<p>AgentNet is composed of two submodules: trajectory encoder and map-encoder.First, the raw map and agent inputs are presented in an agent-centric approach [1,2].The context information generated by the map encoder is fused with the outputs of the trajectory encoder to form the contextual agent representations.Note that in this stage the agents' states are encoded independently, as we need disentangled agent representations for explicit causal agent interaction modeling via the CDN.Map Encoder.We encode each map component using a PointNet-based encoder [47], followed by a max-pooling layer,
S ′ M = MaxPool(PFFN(S M )), where PFFN is a point-wise feed-forward network, S ′ M ∈ R Nm×D 1 m
is the matrix of map features, and D 1 m is the dimension of the map features.To efficiently incorporate map information into agent representations, we employ a multi-context gating (MCG) layer [1] to gather information from N m map elements into a concise map context vector
S ′′ M ∈ R D 2 m
, where S ′′ M = MCG(S ′ M ).Context-aware Trajectory Encoder.The agents' states, while presented in the target agent's coordinate frame, are processed using a Pointnet-based encoder [47], followed by a max-pooling and a GRU layer [48] used to encode the Kinematics of the agents.</p>
<p>To get intermediate temporal trajectory representations we have S ′</p>
<p>A = MLP(S A ), where S ′ A ∈ R N obs ×T ×D 1 a and D 1 a is the dimension of the intermediate agent representations.Then,
S ′′ A = GRU(MaxPool(S ′ A )) ⊕ S ′′ M ,
where ⊕ represents the concatenation operator.Here, the single map context vector S ′′ M is concatenated with each agent's representation separately.This results in S ′′ A ∈ R N obs ×D 2 a , the matrix of map-aware agent representations with dimension D 2 a .</p>
<p>B. Causal Discovery Network (CDN)</p>
<p>We capture the inter-agent causal relations in the form of a directed graph, where the nodes are the agent representations and the edges indicate the causal relations among the agents.The role of CDN is to process the set of map-aware agent representations generated by AgentNet and identify the structure of the causal summary graph.In other words, CDN determines whether for each pair of agents (i, j), whether agent i has a causal influence on agent j.</p>
<p>For trajectory prediction problem we opt for summary causal graph, as it captures all the causal relations over the span of past T h time steps.It also doesn't need to satisfy extra graph acyclicity constraint of instantaneous causal graphs, which are DAGs making the training process of CDN more tractable.As shown in Fig. 2, CDN is made of two major components discussed below: Message Passing Neural Network (MPNN).Inspired by the expressiveness of the MPNNs [49] in processing of the dynamic relations of moving objects in [10,17], we adopt a single layer MPNN as the core of the causal discovery network:
s 1 i = γ 0 (s 0 i ),s 2 i = γ 1   s 1 i , j∈N (i) ϕ 1 s 1 i , s 1 j   , e ij = ρ(W MPNN T ϕ 2 (s 2 i , s 2 j ), λ) i ̸ = j 1 i = j ,(1)
where s 0 i ∈ S ′′ A is an individual initial node representation in the MPNN, and it is set to representation vector of the agent i generated by AgentNet.Consequently, s 1  i and s 2 i are intermediate node representations of agent i.The set N (i) includes neighbors of node i (we assume to have an initial fully-connected adjacency graph without self-loops), γ 0 , γ 1 , ϕ 1 , ϕ 2 are two-layer MLP networks and W MPNN is a learnable linear projection weight.</p>
<p>Causal edges could be presented by binary discrete random variables which have Bernoulli distributions.However, training models with discrete variables is challenging due to the non-differentiability of the sampling operation.To overcome this issue, we replace the binary edge variables with a low-variance continuous relaxation of it named "BinConcrete" [50], which is represented by the function ρ in the above equation.It is defined as: BinConcrete(α, λ) .= Sigmoid((L + log α)/λ), where λ is the temperature hyperparameter and L = log U + log(1 − U ), where U is a random variable sampled from a uniform distribution.Finally, the weighted edges e ij ∈ [0, 1] form the weighted adjacency matrix A.</p>
<p>During inference, we apply a confidence threshold value τ to obtain a discrete causal graph.This approach allows us to adjust the sparsity of the causal graph at the inference time via the threshold value.We further discuss this feature with insights from the empirical results in Section V. Sparsity Regularization.A possible degenerate state for the causal discovery network is always generating a densely connected graph, or in the extreme case, a fully connected graph.Obviously, such a graph is not able to discriminate causal vs. non-causal relations.Inspired by the sparsity of causal interactions among the agents [5], we add an adjacency matrix sparsity regularization loss.This loss is defined as the KL divergence between the marginal probability of an edge being causal and a fixed prior binary distribution with the hyperparameter p indicating the marginal probability for having a causal link.A small value of this parameter creates an information bottleneck by inducing a sparse causal interaction graph.The causally gated backbone prediction model, as explained later in IV-C, has limited information interchange bandwidth among agent representations.Therefore, the model is incentivized to allocate its limited attention capacity to truly causal agents to minimize the loss function.</p>
<p>Auxiliary Denoising Autoencoder (DAE). Following the definition of the Granger causality for time series data in</p>
<p>Section IV, the causal graph aids the prediction of future variables from the past value of its parents.Motivated by this we add the DAE task as an auxiliary supervision to facilitate the causal discovery.In this task, the objective is to reconstruct the values of the masked intermediate temporal agent representations generated by AgentNet based on the values of the other nodes and the causal graph.Note that, using temporal features for this task best matches the definition of Granger causality.</p>
<p>Thereby, we employ a two-layer graph convolutional network (GCN) as a denoising autoencoder (DAE), where the graph is defined as: G DAE = {V DAE , E DAE }, the nodes are V DAE = {v t i |v t i ∈ H 0 , i ∈ {1, . . ., N }, t ∈ {1, . . ., T ′ }}, where for computational efficiency we downsample the temporal agent representations,
H 0 = Flatten(GroupAvgPool(SG(S ′ A ))) ∈ R N DAE ×Dat
, where N DAE = T ′ × N obs , T ′ = 3 is the downsampled temporal dimension, and D at = D 1 a is the feature dimension of the temporal agent representations.Downsampling is done via group average pooling, with groups defined by chunking the temporal dimension.The tensor Flatten operation is then applied so that each node v t i corresponds to a specific agent at a particular chunked temporal state.To avoid the model collapse to naïve solutions, we detach the gradients using the Stop Gradient operation denoted by SG so the DAE loss cannot directly affect representation learning in AgentNet.The edges are defined as
E DAE = {(v t i , v t ′ j )|t ≤ t ′ , (e ij = 1 or i = j)}.
The edges E DAE correspond to the adjacency matrix A DAE , which is a block lower-triangular extension of the adjacency matrix generated by the CDN.</p>
<p>Next, we mask a random selection of nodes using a binary mask M ∈ R N DAE ×Dat controlled by the masking ratio r.The masked representation is given by H 1 = H 0 ⊙ M, where ⊙ is the Hadamard product operator.We constrain the mask to have an all-equal last dimension, i.e., we perform node-wise masking.Subsequently, the GCN layers are defined as:
H 2 = ReLU ÃDAE H 1 W 1 , H 3 = ÃDAE H 2 W 2 ,</p>
<p>C. Causal Trajectory Prediction</p>
<p>Causal Attention Gating (CAG).In the Transformer architecture, query tokens attend to the key tokens according to their attention weights controlled by the attention mechanism [51].</p>
<p>We propose causal attention gating that uses the adjacency matrix of the causal graph generated by CDN to morph the attention weights towards causal agents.Inspired by [52], we introduce the CausalAttention function that is derived by applying CAG to conventional attention mechanism [51]:
CausalAttn(Q, K, V, A) = (Φ ⊙ A)V ′ + α(Φ ⊙ A C ) N, (2)
where
Φ = Softmax( QK T √ d k ), A C = J − A, J ∈ R N obs ×N
obs is an all-ones matrix, V ′ denotes the column-normalized value matrix in attention layers, N = N (0, 1) is a Gaussian noise matrix of the shape R N obs ×dv , d v and d k are the dimensions of the key and value vectors, respectively.The noise scale hyperparameter α is set to zero at the inference time.</p>
<p>Assuming a satisfactory performance of CDN in estimating causal relations, the model is encouraged to attend to the causal agents as the value of the other agent tokens contains large noise.Therefore their contribution is not productive in lowering the trajectory prediction loss.Backbone Network.The backbone network, MTR [2], is composed of 6 layers of Transformer encoder blocks, a dense prediction (DFP) network, and 6 layers of decoder Transformer blocks with latent anchors and dynamic map query layers following [2].In this study we focus on the inter-agent causal discovery, and so unlike the original backbone model, we only feed the map-aware agent representations to the Encoder network and apply CAG for its self-attention layers (with global attention).This modification is only made to isolate and focus on inter-agent causal relationships without interference from map-based interactions.We leave the investigation of agent-map causal interactions as an important direction for future work.Training Objective.The total loss is a weighted sum of the described loss terms discussed thus far, including Prediction, DFP, DAE, and Sparsity, where the weights are tuned as hyperparameters.</p>
<p>V. Experiments A. Experimental Settings</p>
<p>Dataset: We use the Waymo Open Motion Dataset (WOMD) [53] for which 1.1 seconds is used to predict the 8-second future trajectory of target agents.For the robustness experiments, similar to [5], we modify the set of target agents to have: (i) PlusAV setting for which the autonomous vehicle (AV) (which is specified in the dataset) is added to the set of target agents, and (ii) OnlyAV setting, where the AV is the only target agent.</p>
<p>We also evaluate our model using the INTERACTION [54] dataset, which contains a diverse set of driving scenarios captured from 11 locations around the globe.For this dataset, the task is to predict 3 seconds of future trajectory given 1 second of history.Evaluation Metrics.We use the standard benchmark metrics of WOMD and INTERACTION including minADE, minFDE, mAP, and Miss Rate (MR) [53].Following the evaluation protocol in [5], we also assess the model's robustness to causality-based perturbation by reporting ∆-metrics given by
1 N N i=1 m i
Original − m i Perturbed .Implementation Details.We set the batch size to 400 for the OnlyAV setting, and 80 for the other settings.We use an AdamW optimizer [55] with weight decay set to 0.1 to train the model for 30 epochs.The learning rate is set to 1e − 4, and after epoch 22, it is halved every two epochs.A linear learning rate warm-up is also used over the first epoch.</p>
<p>B. Quantitative Analysis</p>
<p>Robustness Experiments.To study the robustness and generalization of the CRiTIC model under causality-based domain shifts, we use scene perturbation tests with the causal agent annotation by Sun et al. [5].In Tab.I, we present the result for RemoveNonCausal perturbation, where all agents tagged as non-causal are removed.Evaluating based on the relative performance drop rate metric, ∆minADE minADE Original , our model shows significant improvement by up to 54% and 53% compared to the next best model for both the OnlyAV and PlusAV settings, respectively.As expected, the CRiTIC model has less performance drop for RemoveNonCausal perturbations as its attention is directed towards causal agents, and it is less reliant on non-causal agents.Note that, we use the minADE metric in the robustness experiments following [5], however, we should note that it is not the primary ranking metric in Waymo's prediction challenge.</p>
<p>Moreover, the sparsity of the predicted causal graph for our model is adjustable at inference time using the threshold hyperparameter.The sparsity is the ratio of the number of edges in the graph to the number of edges in a fully connected graph (we exclude the self-loop edges in this calculation).Since we are performing edge classification under the causal structure discovery task, to evaluate the alignment of the predicted edge classes (causal vs. non-causal, which is presented by e ij in Eq. 1) with the human label [5], we report precision, recall, and robustness under RemoveNonCausal perturbation for various causal graph sparsity values (see Fig. 3).</p>
<p>We observe a high correlation between sparsity and robustness and backed by the empirical results, we argue that causal robustness, evaluated by the RemoveNonCausal perturbation test, should not be discussed without considering the degree of social attention of the model.For instance, for a socially ignorant (zero sparsity), we can achieve 100% robustness, but this is not favorable.We advise that the sparsity of the causal graph in the causal prediction model vs. the causal robustness of the model should be considered as a trade-off and the sparsity should be tuned through safety analysis which is beyond the scope of this paper.Thanks to the separate CDN module and an explicit causal interaction graph, we can explicitly measure and control the sparsity of the causal graph for the CRiTIC model.This makes our model more interpretable and more controllable which are critical for the autonomous driving application.Additionally, we observed that even once the causal gating is removed (when sparsity is 100 %), CRiTIC is still more robust than the baselines presented in Tab.I.This is an indirect influence of CDN in training a causal trajectory model, which persists even if the CDN module is removed.We hypothesize that this is due to the information bottleneck, which encourages the model to align its attention weights with the causal graph discovered by CDN.Trajectory Prediction Benchmarking.In Tab.II, we compare our model with several state-of-the-art models based on the validation and test sets of the WOMD for the marginal motion prediction challenge.In this challenge, the future motion of the target agents is predicted independently of each other.To make a fair comparison, we denoted the models that are evaluated based on ensembling.Based on these results, we can see that besides achieving better robustness, our model performs similar or better compared to the baseline models.Domain Generalization (DG).We compare the DG performance of our model with several baselines on various domain splits of the INTERACTION dataset.We conduct cross-scenario DG experiments (see [58] for details) where both the driving scenarios and the locations are different.As shown in Tab.III, CRiTIC shows better performance compared to the baseline models.Based on the results, we hypothesize that the DG improvement is the result of having a causality-aware model.We speculate that part of the domain shift is caused by non-causal agents and since CRiTIC is empowered by the causal discovery network, it is less dependent on non-causal agents and less influenced by the domain shift created by non-causal agents.Therefore, being causality-aware leads CRiTIC to be less affected by domain shift and have better DG performance.</p>
<p>C. Ablation Study</p>
<p>We have conducted ablation studies to show the effectiveness of each part in our model.First, we remove the denoising autoencoder GCN, and then we ablate the whole causal discovery network.As shown in Tab.IV, we observe that the main robustness improvement against RemoveNonCausal perturbation  comes from the MPNN layer.Meanwhile, adding the DAE module has its role in improving the robustness metric and improving the performance of the causal discovery module which is measured by the area under the precision-recall curve (PR-AUC) metric.</p>
<p>Note that forcing the model to only attend to causal agents (by restricting exploitation of spurious features in our case), makes it robust to perturbations but at the cost of justifiable performance drop (less than 1% mAP drop).A non-causal model, on the other hand, has unrestricted access to all of the spuriously correlated features, and the model reaches an slight performance gain by overfitting to them.However, this makes it more vulnerable to the RemoveNonCausal domain shift which breaks the spurious correlations.</p>
<p>VI. Conclusion</p>
<p>We proposed a novel causal trajectory prediction model, namely CRiTIC, that is significantly more robust against causal perturbations compared to state-of-the-art trajectory prediction models.Our framework utilizes a causal discovery network in which we incorporated a self-supervised denoising auxiliary task to guide the causal discovery.Moreover, we proposed a novel causal attention-gating mechanism that when combined with sparsity regularization of the causal graph, creates an information bottleneck and directs the model's limited attention capacity in the Transformer architecture toward the causal agents.</p>
<p>We conducted extensive experimentation, including agent removal perturbation tests on our model and state-of-the-art prediction models.The results showed our model achieves up to 54% improvement in terms of a causality-based robustness metric with minimal degradation in the performance.In addition, by conducting single-scenario and cross-scenario domain generalization experiments, we observed a better DG performance of the CRiTIC compared with the baseline models.In the future, we intend to extend our approach to address the issue of confounder variables and explicitly take into account road elements in the causal graph.</p>
<p>Fig. 2 :
2
Fig. 2: An overview of CRiTIC.In this architecture, Causal Discovery Network receives the agent representations and generates a causality adjacency matrix.The matrix is used by a Transformer-based prediction backbone to shape the attention toward the causal agents.</p>
<p>Fig. 3 :
3
Fig. 3: Precision, recall, and the robustness against RemoveNonCausal perturbation for the PlusAV setting.The robustness metric is defined by (1 − ∆minADE minADE Org ) × 100.</p>
<p>TABLE I :
I
[5]ustness results based on RemoveNoncausal perturbation.The metrics are reported for the AV agent, for which we have the causality labels.The upper half of the table shows OnlyAV (OAV) and the lower half PlusAV (PAV) settings.(†)indicates results are based on[5], ( ‡) indicates the model is trained on 20% of the training set, and for all of the metrics lower values are better.The letter P indicates the metric is reported for the perturbed set and the S# indicates sparsity percentage.Letters M and J stand for marginal prediction and joint prediction, respectively.
ModelminADE minADE P ∆minADE∆minADE minADEMultiPath++-OAV †[1]0.3760.3950.14137.5%SceneTransformer-OAV-M[3]0.2500.2650.06726.8%Wayformer-OAV †[4]0.3930.4060.10125.7%MTR-OAV-M [2]0.3390.3600.07321.5%CRiTIC-OAV-M-SP4 (ours)0.3890.3990.03879.9 %CRiTIC-OAV-M-SP20 (ours)0.3620.3800.058016.0%MultiPath++-PAV †[1]0.9000.9450.22625.1%SceneTransformer-PAV-J † [3]0.4930.5040.17034.5%SceneTransformer-PAV-M †[3]0.3050.3280.08126.6%MTR-PAV-M ‡ [2]0.3840.4070.07519.5%CRiTIC-PAV-M-S4 ‡ (ours)0.4260.4410.0409.4%CRiTIC-PAV-M-S20 ‡ (ours)0.3950.4130.06115.4%</p>
<p>TABLE II :
II
Benchmarking results on WOMD.( †) indicates result are achieved by using model ensembling, (↓) and (↑) indicate lower and higher values are better.
ModelmAP↑minADE↓ minFDE↓ MissRate↓Wayformer factorized †[4]0.41200.54501.1260.412Multipath++ †[1]0.40920.55571.15770.1340Motion-LM †[56]0.43640.55091.11990.1058MTR-A † [2]0.44920.56401.13440.1160TestMTR [2]0.41290.60501.22070.1351SceneTransformer[3]0.27900.61201.21200.1560HDGT[57]0.28540.59331.20550.1511CRiTIC (ours)0.41740.60251.22760.1342MTR-A † [2]0.45510.55971.12990.1167Val.MTR[2]0.41640.60461.22510.1366CRiTIC (ours)0.41900.59831.22250.1342</p>
<p>TABLE III :
III
[58]in Generalization results on INTERACTION dataset.The ADE, and FDE metrics are shown for test/train domain.The last two columns shows the metric differences across the test and train domains.The results above the dashed line are derived based on[58].(†)indicated that the model is augmented based on the CILF method[58], (↓) sign indicates the lower value is better.
ModelADE↓FDE↓∆ADE↓ ∆FDE↓S-LSTM [59]2.19/1.136.62/3.291.063.33CS-LSTM [44]2.22/1.126.67/3.291.13.38MFP [37]2.17/1.146.53/3.411.033.12S-LSTM † [58]2.09/1.07 6.37/3.151.023.22CS-LSTM †[58]2.10/1.036.48/3.091.073.39MFP † [58]2.10/1.10 6.36/3.311.03.05MTR [2]0.42/0.14 1.07/0.340.280.73CRiTIC (Ours)0.39/0.191.07/0.510.20.56</p>
<p>TABLE IV :
IV
Ablation Experiment Results.The study is done in the PlusAV setting.The MPNN is the main body of CDN without DAE and the ∆minADE minADE Org is computed by applying RemoveNonCausal perturbations.(↓) and (↑) indicate lower and higher values are better.
MPNNGCN DAEmAP↑minADE↓∆minADE minADE Org(%)↓PR-AUC ↑0.82380.385123.6 %NA✓0.81770.391015.7 %0.348✓✓0.81790.395115.4 %0.373
University of Alberta. eahmadi@ualberta.ca
Noah's Ark Laboratory, Huawei Technologies Canada. first.last@huawei.com.
Cornell University. Work done during internship at Huawei Technologies Canada.
The project page is hosted at: http://ehsan-ami.github.io/critic</p>
<p>Multipath++: Efficient information fusion and trajectory aggregation for behavior prediction. B Varadarajan, A Hefny, A Srivastava, K S Refaat, N Nayakanti, A Cornman, K Chen, B Douillard, C P Lam, D Anguelov, ICRA. 2022</p>
<p>Motion transformer with global intention localization and local movement refinement. S Shi, L Jiang, D Dai, B Schiele, NeurIPS2022</p>
<p>Scene transformer: A unified architecture for predicting future trajectories of multiple agents. J Ngiam, V Vasudevan, B Caine, Z Zhang, H T L Chiang, J Ling, R Roelofs, A Bewley, C Liu, A Venugopal, D J Weiss, B Sapp, Z Chen, J Shlens, ICLR. 2022</p>
<p>Wayformer: Motion forecasting via simple &amp; efficient attention networks. N Nayakanti, R Al Rfou, A Zhou, K Goel, K S Refaat, B Sapp, ICRA2023</p>
<p>CausalAgents: A robustness benchmark for motion forecasting. L Sun, R Roelofs, B Caine, K S Refaat, B Sapp, S Ettinger, W Chai, ICRA2024</p>
<p>Toward causal representation learning. B Schölkopf, F Locatello, S Bauer, N R Ke, N Kalchbrenner, A Goyal, Y Bengio, Proceedings of the IEEE. the IEEE2021</p>
<p>Causal imitative model for autonomous driving. M R Samsami, M Bahari, S Salehkaleybar, A Alahi, arXiv:2112.039082021</p>
<p>Towards robust and adaptive motion forecasting: A causal representation perspective. Y Liu, R Cadei, J Schweizer, S Bahmani, A Alahi, CVPR. 2022</p>
<p>Y Zhu, W Xu, J Zhang, Y Du, J Zhang, Q Liu, C Yang, S Wu, arXiv:2103.03036A survey on graph structure learning: Progress and opportunities. 2021</p>
<p>Neural relational inference for interacting systems. T Kipf, E Fetaya, K.-C Wang, M Welling, R Zemel, ICML. 2018</p>
<p>Iterative deep graph learning for graph neural networks: Better and robust node embeddings. Y Chen, L Wu, M Zaki, NeurIPS2020</p>
<p>Learning discrete structures for graph neural networks. L Franceschi, M Niepert, M Pontil, X He, ICML. 2019</p>
<p>SLAPS: Self-supervision improves structure learning for graph neural networks. B Fatemi, L E Asri, S M Kazemi, NeurIPS2021</p>
<p>On causal discovery from time series data using FCI. D Entner, P O Hoyer, 2010Probabilistic Graphical Models</p>
<p>Optimal structure identification with greedy search. D M Chickering, JMLR. 32002</p>
<p>Neural Granger causality. A Tank, I Covert, N Foti, A Shojaie, E B Fox, PAMI. 4482021</p>
<p>Amortized causal discovery: Learning to infer causal graphs from time-series data. S Löwe, D Madras, R Zemel, M Welling, CLeaR2022</p>
<p>Pedformer: Pedestrian behavior prediction via cross-modal attention modulation and gated multitask learning. A Rasouli, I Kotseruba, ICRA2023</p>
<p>Graph-based spatial transformer with memory replay for multi-future pedestrian trajectory prediction. L Li, M Pagnucco, Y Song, CVPR. 2022</p>
<p>Learning pedestrian group representations for multi-modal trajectory prediction. I Bae, J.-H Park, H.-G Jeon, ECCV. 2022</p>
<p>Dice: Diverse diffusion model with scoring for trajectory prediction. Y Choi, R C Mercurius, S Mohamad Alizadeh, A Shabestary, Rasouli, IV2024</p>
<p>Bifold and semantic reasoning for pedestrian behavior prediction. A Rasouli, M Rohani, J Luo, ICCV. 2021</p>
<p>SGCN: Sparse graph convolution network for pedestrian trajectory prediction. L Shi, L Wang, C Long, S Zhou, M Zhou, Z Niu, G Hua, CVPR. 2021</p>
<p>Cadet: a causal disentanglement approach for robust trajectory prediction in autonomous driving. M Pourkeshavarz, J Zhang, A Rasouli, CVPR. 2024</p>
<p>Destine: Dynamic goal queries with temporal transductive alignment for trajectory prediction. R Karim, S M A Shabestary, A Rasouli, ICRA2024</p>
<p>LaPred: Lane-aware prediction of multi-modal future trajectories of dynamic agents. B Kim, S H Park, S Lee, E Khoshimjonov, D Kum, J Kim, J S Kim, J W Choi, CVPR. 2021</p>
<p>HiVT: Hierarchical vector transformer for multi-agent motion prediction. Z Zhou, L Ye, J Wang, K Wu, K Lu, CVPR. 2022</p>
<p>LTP: Lane-based trajectory prediction for autonomous driving. J Wang, T Ye, Z Gu, J Chen, CVPR. 2022</p>
<p>Learning lane graph representations for motion forecasting. M Liang, B Yang, R Hu, Y Chen, R Liao, S Feng, R Urtasun, ECCV. 2020</p>
<p>LatentFormer: Multi-agent transformer-based interaction modeling and trajectory prediction. E Amirloo, A Rasouli, P Lakner, M Rohani, J Luo, arXiv:2203.018802022</p>
<p>LookOut: Diverse multi-future prediction and planning for self-driving. A Cui, S Casas, A Sadat, R Liao, R Urtasun, ICCV. 2021</p>
<p>Implicit latent variable model for scene-consistent motion forecasting. S Casas, C Gulino, S Suo, K Luo, R Liao, R Urtasun, ECCV. 2020</p>
<p>Latent variable sequential set transformers for joint multi-agent motion prediction. R Girgis, F Golemo, F Codevilla, M Weiss, J A D'souza, S E Kahou, F Heide, C Pal, ICLR. 2022</p>
<p>VectorNet: Encoding hd maps and agent dynamics from vectorized representation. J Gao, C Sun, H Zhao, Y Shen, D Anguelov, C Li, C Schmid, CVPR. 2020</p>
<p>Learn tarot with mentor: A meta-learned self-supervised approach for trajectory prediction. M Pourkeshavarz, C Chen, A Rasouli, ICCV. 2023</p>
<p>Tract: A training dynamics aware contrastive learning framework for long-tail trajectory prediction. J Zhang, M Pourkeshavarz, A Rasouli, IV2024</p>
<p>Multiple futures prediction. C Tang, R R Salakhutdinov, NeurIPS2019</p>
<p>Trajectron++: Multi-agent generative trajectory forecasting with heterogeneous data for control. T Salzmann, B Ivanovic, P Chakravarty, M Pavone, ECCV. 2020</p>
<p>GOHOME: Graph-oriented heatmap output for future motion estimation. T Gilles, S Sabatini, D Tsishkou, B Stanciulescu, F Moutarde, ICRA2022</p>
<p>MUSE-VAE: Multi-scale VAE for environment-aware long term trajectory prediction. M Lee, S S Sohn, S Moon, S Yoon, M Kapadia, V Pavlovic, CVPR. 2022</p>
<p>TNT: Target-driven trajectory prediction. H Zhao, J Gao, T Lan, C Sun, B Sapp, B Varadarajan, Y Shen, Y Shen, Y Chai, C Schmid, CoRL2020</p>
<p>A novel benchmarking paradigm and a scaleand motion-aware model for egocentric pedestrian trajectory prediction. A Rasouli, ICRA2024</p>
<p>AgentFormer: Agent-aware transformers for socio-temporal multi-agent forecasting. Y Yuan, X Weng, Y Ou, K M Kitani, ICCV. 2021</p>
<p>Convolutional social pooling for vehicle trajectory prediction. N Deo, M M Trivedi, CVPRW. 2018</p>
<p>Human trajectory prediction via counterfactual analysis. G Chen, J Li, J Lu, J Zhou, ICCV. 2021</p>
<p>Investigating causal relations by econometric models and cross-spectral methods. C W Granger, Econometrica: Journal of the Econometric Society. 1969</p>
<p>PointNet: Deep learning on point sets for 3d classification and segmentation. C R Qi, H Su, K Mo, L J Guibas, CVPR. 2017</p>
<p>Learning continuous phrase representations and syntactic parsing with recursive neural networks. R Socher, C D Manning, A Y Ng, NeurIPS2010</p>
<p>Neural message passing for quantum chemistry. J Gilmer, S S Schoenholz, P F Riley, O Vinyals, G E Dahl, ICML. 2017</p>
<p>The concrete distribution: A continuous relaxation of discrete random variables. C J Maddison, A Mnih, Y W Teh, ICLR2017</p>
<p>Attention is all you need. A Vaswani, N Shazeer, N Parmar, J Uszkoreit, L Jones, Others , NeurIPS2017</p>
<p>Ignorance is bliss: Robust control via information gating. M Tomar, R Islam, M E Taylor, S Levine, P Bachman, NeurIPS2023</p>
<p>Large scale interactive motion forecasting for autonomous driving: The waymo open motion dataset. S Ettinger, S Cheng, B Caine, C Liu, H Zhao, S Pradhan, Y Chai, B Sapp, C R Qi, Y Zhou, Z Yang, A Chouard, P Sun, J Ngiam, V Vasudevan, A Mccauley, J Shlens, D Anguelov, ICCV. 2021</p>
<p>INTERACTION dataset: An international, adversarial and cooperative motion dataset in interactive driving scenarios with semantic maps. W Zhan, L Sun, D Wang, H Shi, A Clausse, M Naumann, J Kummerle, H Konigshof, C Stiller, A De La Fortelle, arXiv:1910.030882019</p>
<p>Decoupled weight decay regularization. I Loshchilov, F Hutter, ICLR. 2019</p>
<p>MotionLM: Multi-agent motion forecasting as language modeling. A Seff, B Cera, D Chen, M Ng, A Zhou, N Nayakanti, K S Refaat, R Al-Rfou, B Sapp, ICCV. 2023</p>
<p>HDGT: Heterogeneous driving graph transformer for multi-agent trajectory prediction via scene encoding. X Jia, P Wu, L Chen, Y Liu, H Li, J Yan, 2023PAMI</p>
<p>CILF: Causality inspired learning framework for out-of-distribution vehicle trajectory prediction. S Li, Q Xue, Y Zhang, X Li, Asian Conference on Pattern Recognition. 2023</p>
<p>Social LSTM: Human trajectory prediction in crowded spaces. A Alahi, K Goel, V Ramanathan, A Robicquet, L Fei-Fei, S Savarese, CVPR. 2016</p>            </div>
        </div>

    </div>
</body>
</html>