<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-2551 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-2551</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-2551</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-65.html">extraction-schema-65</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of multi-agent AI systems that coordinate to perform scientific research tasks, including details about their coordination mechanisms, communication protocols, feedback mechanisms, agent specializations, and performance results.</div>
                <p><strong>Paper ID:</strong> paper-ead6121fbc787d508dc6a6d7106f72bf0d647d03</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/ead6121fbc787d508dc6a6d7106f72bf0d647d03" target="_blank">Multi-Agent Collaboration: Harnessing the Power of Intelligent LLM Agents</a></p>
                <p><strong>Paper Venue:</strong> arXiv.org</p>
                <p><strong>Paper TL;DR:</strong> A novel framework for enhancing the capabilities of large language models (LLMs) by leveraging the power of multi-agent systems and provides an avenue for advancing the capabilities and performance of LLMs through collaboration and knowledge exchange among intelligent agents.</p>
                <p><strong>Paper Abstract:</strong> In this paper, we present a novel framework for enhancing the capabilities of large language models (LLMs) by leveraging the power of multi-agent systems. Our framework introduces a collaborative environment where multiple intelligent agent components, each with distinctive attributes and roles, work together to handle complex tasks more efficiently and effectively. We demonstrate the practicality and versatility of our framework through case studies in artificial general intelligence (AGI), specifically focusing on the Auto-GPT and BabyAGI models. We also examine the"Gorilla"model, which integrates external APIs into the LLM. Our framework addresses limitations and challenges such as looping issues, security risks, scalability, system evaluation, and ethical considerations. By modeling various domains such as courtroom simulations and software development scenarios, we showcase the potential applications and benefits of our proposed multi-agent system. Our framework provides an avenue for advancing the capabilities and performance of LLMs through collaboration and knowledge exchange among intelligent agents.</p>
                <p><strong>Cost:</strong> 0.016</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e2551.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e2551.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of multi-agent AI systems that coordinate to perform scientific research tasks, including details about their coordination mechanisms, communication protocols, feedback mechanisms, agent specializations, and performance results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>IGA Framework</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Intelligent Generative Agent Multi-Agent Framework</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A graph-based black-box framework that composes multiple LLM-based agents (IGAs) and plugins as nodes, connected by explicit communication edges; agents have typed roles, state, and permissions (create/stop) and can be dynamically added to solve complex tasks via collaboration, feedback, and plugin-mediated resource access.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Intelligent Generative Agent (IGA) Multi-Agent Framework</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>A general-purpose, graph-modeled multi-agent system G(V,E) where vertices V are LLM-driven agents and plugins and edges E are communication channels. Each agent A_i is a tuple (L_i, R_i, S_i, C_i, H_i) specifying its language model instance/config, role, internal state/knowledge/thoughts, permission to create agents, and the set of agents it can halt. Plugins P_j encapsulate functionality, configuration, and usage constraints. Communication uses message tuples m = (S_m, A_m, D_m) (content, action, metadata). The framework supports dynamic agent creation, a supervisor/halt mechanism, stateless oracle agents for critique, and plugin-based shared storage (vector DBs, communication boards) enabling many-to-many communication.</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_agents</strong></td>
                            <td>variable</td>
                        </tr>
                        <tr>
                            <td><strong>agent_specializations</strong></td>
                            <td>Designer/Planner agents (system design, agent-role assignment), Task-decomposition agents (subtask creation), Task-prioritization agents, Execution agents (performing tasks, code execution, browsing), Memory/Storage agents (vector DB plugins), Oracle agents (stateless critics/scholars), Supervisor agents (monitoring and halting), Plugin agents (API connectors, file managers, test runners, debuggers), Domain-role agents in case studies (judge, jury, attorneys, UX designer, product manager, software architect, developer, tester, debugger).</td>
                        </tr>
                        <tr>
                            <td><strong>research_phases_covered</strong></td>
                            <td>Idea generation, task decomposition, literature review (via browsing plugins), implementation/execution (code run, API calls), iterative evaluation/refinement, summarization, debugging, reporting; adaptable to full research workflow (from hypothesis generation to experimental execution and evaluation).</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_mechanism</strong></td>
                            <td>Flexible graph-based orchestration: centralized or hierarchical when a main/creator agent coordinates spawned agents; supervisor-based hierarchical oversight with halting authority; sequential pipelines for structured workflows (e.g., task creation -> prioritization -> execution); dynamic decentralized collaboration via shared plugins/boards enabling many-to-many interactions.</td>
                        </tr>
                        <tr>
                            <td><strong>communication_protocol</strong></td>
                            <td>Message passing over explicit edges: messages are tuples (S_m: natural-language or structured content, A_m: action label e.g., assign-task/report/request, D_m: metadata such as timestamp/sender/receiver). Plugins provide shared-memory-style interfaces (vector DBs, communication boards) and API-call formats; primary formats are natural-language prompts and structured API-call representations mediated by plugins.</td>
                        </tr>
                        <tr>
                            <td><strong>feedback_mechanism</strong></td>
                            <td>Inter-agent feedback (agents critique each other via messages or role-play/Inception prompting), self-feedback (agents perform self-assessment / iterative refinement), oracle-agent critiques (stateless agents provide isolated feedback), supervisor monitoring that issues halt or corrective commands; feedback can be used to refine outputs iteratively or change agent roles/tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>communication_frequency</strong></td>
                            <td>Configurable: commonly on-demand or after each operation/step; supports continuous monitoring by supervisor or oracle agents, and communication at defined phase transitions (e.g., after task completion or between pipeline stages).</td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>General scientific and engineering research workflows, plus concrete case studies in software development and courtroom simulation; applicable to literature review, experiment design/execution, API-driven data retrieval, and multi-step computational tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>coordination_benefits</strong></td>
                            <td>Qualitative benefits: division of labor (specialization), reduced hallucination via oracle/verification agents, ability to parallelize subtasks, improved modularity and flexibility (dynamic add/remove agents), potential for higher reliability through critique/refinement loops; paper provides no quantitative results.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_challenges</strong></td>
                            <td>Looping and runaway behavior in autonomous chains of thoughts, security risks when agents execute code or access external resources (especially in continuous/autonomous modes), scalability/resource exhaustion from uncontrolled agent proliferation, difficulty in standardized evaluation and metrics, potential communication overhead and role/task overlap without careful coordination.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_studies</strong></td>
                            <td>none (no empirical ablation studies reported in this paper).</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_configurations</strong></td>
                            <td>Design suggestions rather than empirically derived optima: include a Supervisor Agent for loop detection and halting, use stateless Oracle Agents for isolated critique, limit agent creation permissions (C_i) and provide resource-management modules to cap proliferation, decompose workflows into specialized agents (task-creation, prioritization, execution) and use plugins (vector DBs/boards) for shared context. No numerical optimal settings reported.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Multi-Agent Collaboration: Harnessing the Power of Intelligent LLM Agents', 'publication_date_yy_mm': '2023-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2551.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e2551.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of multi-agent AI systems that coordinate to perform scientific research tasks, including details about their coordination mechanisms, communication protocols, feedback mechanisms, agent specializations, and performance results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Auto-GPT (modeled)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Auto-GPT (treated as main-agent with plugins and spawned agents)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Auto-GPT is modeled within the framework as a principal autonomous agent that chains 'thoughts', uses plugins for browsing, memory, and code execution, and has the ability to spawn sub-agents and halt them; known failure modes include getting stuck in loops and security risks when run continuously.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Auto-GPT modeled as multi-agent system</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>A single main autonomous agent (the Auto-GPT instance) that maintains a chain-of-thought state, can spawn auxiliary agents and connect to multiple plugins (internet browsing, long/short-term memory, file execution, summarization). The spawned agents and plugins are represented as nodes in the graph; communications include task assignments, requests for information, and execution commands. An oracle agent is proposed for summarization and criticism of the main agent's outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_agents</strong></td>
                            <td>variable (1 main + dynamically spawned co-agents)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_specializations</strong></td>
                            <td>Main Auto-GPT agent (autonomous planner and executor), spawned worker agents (subtask executors with assigned roles), plugins as specialized function providers (browser, memory manager, file executor, summarizer), oracle critic agent (stateless summarization/critique).</td>
                        </tr>
                        <tr>
                            <td><strong>research_phases_covered</strong></td>
                            <td>Autonomous task decomposition and execution, web-based literature/data retrieval, code execution/testing, summarization/reporting; can cover implementation and execution phases of research workflows.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_mechanism</strong></td>
                            <td>Centralized control by the main Auto-GPT agent which creates and delegates to co-agents; optionally hierarchical with added Supervisor Agent overseeing loops and halting misbehaving co-agents; shared workspace (files/boards) via plugins for coordination.</td>
                        </tr>
                        <tr>
                            <td><strong>communication_protocol</strong></td>
                            <td>Natural-language-based messages and structured plugin calls; use of shared storage/plugins (file system, communication board) to pass artifacts; messages carry content, action labels, and metadata as per framework message tuple convention.</td>
                        </tr>
                        <tr>
                            <td><strong>feedback_mechanism</strong></td>
                            <td>Oracle critiques (stateless) and optional human-in-the-loop authorization; the framework suggests supervisor monitoring and inter-agent feedback but Auto-GPT's native design relies on chained thoughts and internal self-prompting rather than structured peer feedback.</td>
                        </tr>
                        <tr>
                            <td><strong>communication_frequency</strong></td>
                            <td>Frequent/stepwise (chains of thoughts proceed sequentially with messages and plugin interactions at each step); continuous when configured in 'continuous' mode, otherwise on-demand between thought steps.</td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>General autonomous task execution including coding, debugging, web research, and multi-step workflows; suggested use for automating research tasks but not demonstrated experimentally in paper.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Qualitatively compared against single-agent ChatGPT-style usage (more autonomous), but no quantitative comparisons provided; known limitations such as looping noted.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_benefits</strong></td>
                            <td>Allows chaining of subtasks, autonomy in multi-step workflows, sharing of file workspace across co-agents, potential reduction in human prompting; suggested benefit of adding Supervisor/Oracle agents to mitigate loops and hallucinations.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_challenges</strong></td>
                            <td>Prone to becoming stuck in loops when chaining thoughts, security vulnerabilities when executing external code or accessing the internet in continuous mode, lack of structured inter-agent critique unless explicitly added.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_studies</strong></td>
                            <td>none (no experimental ablation reported).</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_configurations</strong></td>
                            <td>Recommended mitigations: add a Supervisor Agent to detect loops and halt misbehavior, use stateless Oracle Agents to vet sensitive actions, restrict agent creation permissions and require human authorization for high-risk operations; no empirical tuning provided.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Multi-Agent Collaboration: Harnessing the Power of Intelligent LLM Agents', 'publication_date_yy_mm': '2023-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2551.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e2551.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of multi-agent AI systems that coordinate to perform scientific research tasks, including details about their coordination mechanisms, communication protocols, feedback mechanisms, agent specializations, and performance results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>BabyAGI (modeled)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>BabyAGI (three-chain LLM agent system)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>BabyAGI is represented as three LLM chains—task creation, task prioritization, and execution—mapped to distinct agents interacting via a vector database plugin for storing and retrieving task context; the paper suggests modeling each chain as a separate agent within the framework to gain modularity and enable feedback loops.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>BabyAGI modeled as a 3-agent pipeline</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>A pipeline-style multi-agent composition where Task-Creation Agent generates new tasks from objectives, Task-Prioritization Agent orders tasks, and Execution Agent attempts task completion; a vector-database plugin stores results and context (retrieval for future tasks). Optionally, a user-interaction/refinement agent mediates user prompts and places them into task storage.</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_agents</strong></td>
                            <td>3 (task-creation, task-prioritization, execution) plus supporting storage/plugins</td>
                        </tr>
                        <tr>
                            <td><strong>agent_specializations</strong></td>
                            <td>Task Creation Agent (idea/hypothesis/subtask generation), Task Prioritization Agent (scheduling and ordering), Execution Agent (performs tasks, calls APIs, runs code), Vector DB plugin (context storage/retrieval), optional User-Interaction/Refinement Agent.</td>
                        </tr>
                        <tr>
                            <td><strong>research_phases_covered</strong></td>
                            <td>Idea/task generation, prioritization and planning, execution/implementation, storage of results for literature/context retrieval; supports iterative task-based research workflows.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_mechanism</strong></td>
                            <td>Sequential pipeline (task creation -> prioritization -> execution) mediated by shared vector database for context; coordination is centralized around the pipeline flow rather than decentralized consensus.</td>
                        </tr>
                        <tr>
                            <td><strong>communication_protocol</strong></td>
                            <td>Structured outputs between chains (natural language prompts and embeddings saved/retrieved from a vector DB plugin); messages and artifacts passed through plugin storage rather than direct peer-to-peer messaging.</td>
                        </tr>
                        <tr>
                            <td><strong>feedback_mechanism</strong></td>
                            <td>Contextual feedback via stored execution results in the vector DB enabling future tasks to use past outputs; the paper proposes adding explicit feedback loops and self-feedback agents to enable iterative refinement but reports no experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>communication_frequency</strong></td>
                            <td>Per task step: communication occurs at each pipeline transition (after task creation, after prioritization, upon execution completion) and when retrieving context from vector DB.</td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>General task automation and iterative workflows, applicable to multi-step research tasks where tasks and results are stored and used for subsequent steps.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>coordination_benefits</strong></td>
                            <td>Modularity and clearer separation of responsibilities, easier modification/extension, ability to reuse stored task results to improve future tasks, potential for better interpretability and debugging compared to monolithic chaining.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_challenges</strong></td>
                            <td>Pipeline rigidity may limit dynamic rebalancing, reliance on vector DB quality for context retrieval, no quantitative evaluation provided; general framework challenges (scalability, evaluation) apply.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_studies</strong></td>
                            <td>none (no empirical ablations reported).</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_configurations</strong></td>
                            <td>Suggested configuration: explicitly model the three chains as agents, provide vector DB plugin for context, and add feedback/self-refinement agents for iterative improvement; no quantitative optima given.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Multi-Agent Collaboration: Harnessing the Power of Intelligent LLM Agents', 'publication_date_yy_mm': '2023-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2551.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e2551.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of multi-agent AI systems that coordinate to perform scientific research tasks, including details about their coordination mechanisms, communication protocols, feedback mechanisms, agent specializations, and performance results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Gorilla (modeled)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Gorilla: Large language model connected with massive APIs</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Gorilla is a fine-tuned LLaMA-based system that learns to map prompts to API calls by retrieving API documentation; it integrates retrieval at training and inference to reduce hallucination and stay up to date with API changes.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Gorilla: Large language model connected with massive apis</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>mention</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Gorilla (API-integrated LLM)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>Modeled in the framework as a single fine-tuned agent (LLaMA derivative) augmented with retriever and plugin modules representing APIs and their documentation. The agent uses retrieval during training and inference to ground generated API calls in current documentation and maps natural-language prompts to structured API calls.</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_agents</strong></td>
                            <td>1 (single fine-tuned agent) though the framework suggests decomposing into multiple agents per API if desired</td>
                        </tr>
                        <tr>
                            <td><strong>agent_specializations</strong></td>
                            <td>API-integration agent (maps prompts to API calls using retrieved docs), Retriever plugin (fetches API docs), per-API plugins (call implementations and documentation storage), potential verifier agent (suggested) to detect hallucinations.</td>
                        </tr>
                        <tr>
                            <td><strong>research_phases_covered</strong></td>
                            <td>Implementation/execution that requires API calls, documentation retrieval for up-to-date behavior, and mitigation of hallucinations during inference; applicable to experimental pipelines that require interfacing with external services.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_mechanism</strong></td>
                            <td>Single-agent with plugin-mediated coordination; central agent consults retriever and plugins rather than peer agents; framework suggests possible decomposition into multiple agents each owning an API plugin for more complex coordination.</td>
                        </tr>
                        <tr>
                            <td><strong>communication_protocol</strong></td>
                            <td>Structured API-call representations informed by retrieved documentation; prompt-to-API mapping uses retrieval results as grounding; inter-component communication via plugin interfaces and structured API formats.</td>
                        </tr>
                        <tr>
                            <td><strong>feedback_mechanism</strong></td>
                            <td>Retriever-based grounding reduces hallucination; paper suggests adding a dedicated verification/mitigation agent to check the main agent's outputs (proposed improvement), but Gorilla itself relies on retrieval rather than multi-agent critique.</td>
                        </tr>
                        <tr>
                            <td><strong>communication_frequency</strong></td>
                            <td>Retriever consulted during both training and inference; runtime communications occur on-demand when API functionality is required.</td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>API-heavy tasks, software integration, automated code generation that requires calling external services; can be leveraged in research pipelines needing live API interactions.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td>Paper claims improvements in writing API calls relative to GPT-4 (qualitative statement in this paper), but no numeric metrics are reported here.</td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td>Claimed improvement over GPT-4 for API-call generation (as cited), but this paper provides no quantitative comparisons or reproduced benchmarks.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_benefits</strong></td>
                            <td>Grounding in API documentation reduces hallucination for API calls and adapts to changing API versions; plugin decomposition could allow more flexible real-time updates without retraining the whole model.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_challenges</strong></td>
                            <td>Single-agent design may struggle with overlapping API functionality and complex multi-API coordination; the paper proposes per-API agents and a verifier agent as improvements but offers no empirical results.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_studies</strong></td>
                            <td>none reported in this paper for Gorilla within the multi-agent framework.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_configurations</strong></td>
                            <td>Suggested improvements: assign different agents to different APIs with dedicated plugins, and include a verification/anti-hallucination agent; no empirical configuration guidelines provided.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Multi-Agent Collaboration: Harnessing the Power of Intelligent LLM Agents', 'publication_date_yy_mm': '2023-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2551.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e2551.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of multi-agent AI systems that coordinate to perform scientific research tasks, including details about their coordination mechanisms, communication protocols, feedback mechanisms, agent specializations, and performance results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Oracle Agent</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Oracle (stateless critique) Agent</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A stateless, memory-less agent that processes an input in isolation and returns critique or verification; intended to provide predictable, isolated feedback used to vet outputs or approve sensitive operations.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Oracle Agent (stateless verifier)</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>An agent designed to be memory-less so that each interaction is independent; it receives a single input and returns a verdict/critique without reference to prior state. Common uses include summarization, answer criticism, and authorization decisions for sensitive plugin actions.</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_agents</strong></td>
                            <td>1 (can be multiple independent oracle agents instantiated as needed)</td>
                        </tr>
                        <tr>
                            <td><strong>agent_specializations</strong></td>
                            <td>Stateless critique/verifier: checks outputs for correctness, summarizes content, evaluates whether an action is malicious or authorized.</td>
                        </tr>
                        <tr>
                            <td><strong>research_phases_covered</strong></td>
                            <td>Evaluation/verification and safety checks, post-generation critique and refinement prior to publishing or executing actions.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_mechanism</strong></td>
                            <td>On-demand invocation by other agents; not part of long-running stateful coordination—acts as an isolated service node in the communication graph.</td>
                        </tr>
                        <tr>
                            <td><strong>communication_protocol</strong></td>
                            <td>Receives isolated natural-language input or structured artifact and returns natural-language or structured critique/approval; follows the m=(S_m,A_m,D_m) message structure in synchronous request-response fashion.</td>
                        </tr>
                        <tr>
                            <td><strong>feedback_mechanism</strong></td>
                            <td>Provides direct critique or accept/reject signals that other agents use to refine or abort actions; used to simulate human-in-the-loop vetting in an automated way.</td>
                        </tr>
                        <tr>
                            <td><strong>communication_frequency</strong></td>
                            <td>On-demand per sensitive action or after agent outputs that require verification (e.g., before code execution or final reporting).</td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>Safety and evaluation tasks across domains; applicable wherever isolated, predictable evaluation is required (fact-checking, summarization validation, authorization).</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>coordination_benefits</strong></td>
                            <td>Predictable, isolated critique reduces propagation of stateful bias, can mitigate hallucination and risky actions by providing an independent check, reduces human load by automating vetting steps.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_challenges</strong></td>
                            <td>Being stateless, oracles may lack contextual nuance across multi-step interactions; effectiveness depends on oracle prompt design and underlying model competence; may add latency if invoked frequently.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_studies</strong></td>
                            <td>none reported.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_configurations</strong></td>
                            <td>Use oracle agents for high-risk steps and combine with supervisor oversight; keep oracle interactions isolated and stateless to maintain predictability; no empirical tuning provided.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Multi-Agent Collaboration: Harnessing the Power of Intelligent LLM Agents', 'publication_date_yy_mm': '2023-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e2551.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e2551.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of multi-agent AI systems that coordinate to perform scientific research tasks, including details about their coordination mechanisms, communication protocols, feedback mechanisms, agent specializations, and performance results.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Supervisor Agent</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Supervisor (monitoring and halting) Agent</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A specialized supervisory agent that monitors agent activities, detects loops or deviations from tasks, and can issue halt commands to misbehaving agents to enforce correct operation and resource limits.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>system_name</strong></td>
                            <td>Supervisor Agent</td>
                        </tr>
                        <tr>
                            <td><strong>system_description</strong></td>
                            <td>An agent with oversight permissions that periodically inspects activity logs, task lists, and recent outputs to detect errors (e.g., looping behavior) or divergence from goals; upon detection it can issue halt commands to agents (per H_i permissions) or request corrective actions.</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_agents</strong></td>
                            <td>1 (or a small set of supervisory agents) depending on system design</td>
                        </tr>
                        <tr>
                            <td><strong>agent_specializations</strong></td>
                            <td>Monitoring (detect loops, stalls, resource usage), Enforcement (halt commands, restart policies), Feedback (issue guidance to main agents), Resource management (alerting when thresholds reached).</td>
                        </tr>
                        <tr>
                            <td><strong>research_phases_covered</strong></td>
                            <td>Ongoing execution oversight and evaluation; primarily an operational phase that ensures safe, goal-aligned execution of research tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_mechanism</strong></td>
                            <td>Hierarchical supervisory control: Supervisor inspects subordinate agents and exerts authority to halt or redirect them; integrates with resource-management modules to control agent proliferation.</td>
                        </tr>
                        <tr>
                            <td><strong>communication_protocol</strong></td>
                            <td>Periodic or event-triggered reviews via messages/queries to agents and plugins; issues control messages (halt/restart/modify-role) following the same message tuple format; may rely on logs or plugin-stored activity records.</td>
                        </tr>
                        <tr>
                            <td><strong>feedback_mechanism</strong></td>
                            <td>Issues corrective commands, requests for refinement, or halts; can also provide summaries to human operators and trigger oracle evaluations for disputed outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>communication_frequency</strong></td>
                            <td>Periodic (monitoring intervals) and event-driven (on detecting anomalies or threshold breaches); can also act continuously when configured for real-time oversight.</td>
                        </tr>
                        <tr>
                            <td><strong>task_domain</strong></td>
                            <td>Operational safety and control across any domain where agents are executing tasks—especially important for tasks involving code execution, internet access, or other sensitive operations.</td>
                        </tr>
                        <tr>
                            <td><strong>performance_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>baseline_comparison</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>coordination_benefits</strong></td>
                            <td>Helps prevent infinite loops and runaway agent behavior, enforces resource constraints, reduces need for constant human oversight, improves system robustness and safety.</td>
                        </tr>
                        <tr>
                            <td><strong>coordination_challenges</strong></td>
                            <td>Supervisor becomes a single point of failure or bottleneck if not designed with scaling in mind; correctness depends on quality of anomaly detection heuristics; potential for overzealous halting causing unnecessary interruptions.</td>
                        </tr>
                        <tr>
                            <td><strong>ablation_studies</strong></td>
                            <td>none reported.</td>
                        </tr>
                        <tr>
                            <td><strong>optimal_configurations</strong></td>
                            <td>Grant supervisory halting authority selectively (only to designated creators/supervisors), pair supervisor with oracle critics for nuanced decisions, and combine with resource-management thresholds to prevent over-proliferation; no quantitative guidance provided.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Multi-Agent Collaboration: Harnessing the Power of Intelligent LLM Agents', 'publication_date_yy_mm': '2023-06'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Generative agents: Interactive simulacra of human behavior <em>(Rating: 2)</em></li>
                <li>Camel: Communicative agents for "mind" exploration of large scale language model society <em>(Rating: 2)</em></li>
                <li>Gorilla: Large language model connected with massive apis <em>(Rating: 2)</em></li>
                <li>Language model cascades <em>(Rating: 1)</em></li>
                <li>Improving language model negotiation with self-play and in-context learning from ai feedback <em>(Rating: 1)</em></li>
                <li>Teaching large language models to self-debug <em>(Rating: 1)</em></li>
                <li>Self-refine: Iterative refinement with self-feedback <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-2551",
    "paper_id": "paper-ead6121fbc787d508dc6a6d7106f72bf0d647d03",
    "extraction_schema_id": "extraction-schema-65",
    "extracted_data": [
        {
            "name_short": "IGA Framework",
            "name_full": "Intelligent Generative Agent Multi-Agent Framework",
            "brief_description": "A graph-based black-box framework that composes multiple LLM-based agents (IGAs) and plugins as nodes, connected by explicit communication edges; agents have typed roles, state, and permissions (create/stop) and can be dynamically added to solve complex tasks via collaboration, feedback, and plugin-mediated resource access.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "Intelligent Generative Agent (IGA) Multi-Agent Framework",
            "system_description": "A general-purpose, graph-modeled multi-agent system G(V,E) where vertices V are LLM-driven agents and plugins and edges E are communication channels. Each agent A_i is a tuple (L_i, R_i, S_i, C_i, H_i) specifying its language model instance/config, role, internal state/knowledge/thoughts, permission to create agents, and the set of agents it can halt. Plugins P_j encapsulate functionality, configuration, and usage constraints. Communication uses message tuples m = (S_m, A_m, D_m) (content, action, metadata). The framework supports dynamic agent creation, a supervisor/halt mechanism, stateless oracle agents for critique, and plugin-based shared storage (vector DBs, communication boards) enabling many-to-many communication.",
            "number_of_agents": "variable",
            "agent_specializations": "Designer/Planner agents (system design, agent-role assignment), Task-decomposition agents (subtask creation), Task-prioritization agents, Execution agents (performing tasks, code execution, browsing), Memory/Storage agents (vector DB plugins), Oracle agents (stateless critics/scholars), Supervisor agents (monitoring and halting), Plugin agents (API connectors, file managers, test runners, debuggers), Domain-role agents in case studies (judge, jury, attorneys, UX designer, product manager, software architect, developer, tester, debugger).",
            "research_phases_covered": "Idea generation, task decomposition, literature review (via browsing plugins), implementation/execution (code run, API calls), iterative evaluation/refinement, summarization, debugging, reporting; adaptable to full research workflow (from hypothesis generation to experimental execution and evaluation).",
            "coordination_mechanism": "Flexible graph-based orchestration: centralized or hierarchical when a main/creator agent coordinates spawned agents; supervisor-based hierarchical oversight with halting authority; sequential pipelines for structured workflows (e.g., task creation -&gt; prioritization -&gt; execution); dynamic decentralized collaboration via shared plugins/boards enabling many-to-many interactions.",
            "communication_protocol": "Message passing over explicit edges: messages are tuples (S_m: natural-language or structured content, A_m: action label e.g., assign-task/report/request, D_m: metadata such as timestamp/sender/receiver). Plugins provide shared-memory-style interfaces (vector DBs, communication boards) and API-call formats; primary formats are natural-language prompts and structured API-call representations mediated by plugins.",
            "feedback_mechanism": "Inter-agent feedback (agents critique each other via messages or role-play/Inception prompting), self-feedback (agents perform self-assessment / iterative refinement), oracle-agent critiques (stateless agents provide isolated feedback), supervisor monitoring that issues halt or corrective commands; feedback can be used to refine outputs iteratively or change agent roles/tasks.",
            "communication_frequency": "Configurable: commonly on-demand or after each operation/step; supports continuous monitoring by supervisor or oracle agents, and communication at defined phase transitions (e.g., after task completion or between pipeline stages).",
            "task_domain": "General scientific and engineering research workflows, plus concrete case studies in software development and courtroom simulation; applicable to literature review, experiment design/execution, API-driven data retrieval, and multi-step computational tasks.",
            "performance_metrics": null,
            "baseline_comparison": null,
            "coordination_benefits": "Qualitative benefits: division of labor (specialization), reduced hallucination via oracle/verification agents, ability to parallelize subtasks, improved modularity and flexibility (dynamic add/remove agents), potential for higher reliability through critique/refinement loops; paper provides no quantitative results.",
            "coordination_challenges": "Looping and runaway behavior in autonomous chains of thoughts, security risks when agents execute code or access external resources (especially in continuous/autonomous modes), scalability/resource exhaustion from uncontrolled agent proliferation, difficulty in standardized evaluation and metrics, potential communication overhead and role/task overlap without careful coordination.",
            "ablation_studies": "none (no empirical ablation studies reported in this paper).",
            "optimal_configurations": "Design suggestions rather than empirically derived optima: include a Supervisor Agent for loop detection and halting, use stateless Oracle Agents for isolated critique, limit agent creation permissions (C_i) and provide resource-management modules to cap proliferation, decompose workflows into specialized agents (task-creation, prioritization, execution) and use plugins (vector DBs/boards) for shared context. No numerical optimal settings reported.",
            "uuid": "e2551.0",
            "source_info": {
                "paper_title": "Multi-Agent Collaboration: Harnessing the Power of Intelligent LLM Agents",
                "publication_date_yy_mm": "2023-06"
            }
        },
        {
            "name_short": "Auto-GPT (modeled)",
            "name_full": "Auto-GPT (treated as main-agent with plugins and spawned agents)",
            "brief_description": "Auto-GPT is modeled within the framework as a principal autonomous agent that chains 'thoughts', uses plugins for browsing, memory, and code execution, and has the ability to spawn sub-agents and halt them; known failure modes include getting stuck in loops and security risks when run continuously.",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_name": "Auto-GPT modeled as multi-agent system",
            "system_description": "A single main autonomous agent (the Auto-GPT instance) that maintains a chain-of-thought state, can spawn auxiliary agents and connect to multiple plugins (internet browsing, long/short-term memory, file execution, summarization). The spawned agents and plugins are represented as nodes in the graph; communications include task assignments, requests for information, and execution commands. An oracle agent is proposed for summarization and criticism of the main agent's outputs.",
            "number_of_agents": "variable (1 main + dynamically spawned co-agents)",
            "agent_specializations": "Main Auto-GPT agent (autonomous planner and executor), spawned worker agents (subtask executors with assigned roles), plugins as specialized function providers (browser, memory manager, file executor, summarizer), oracle critic agent (stateless summarization/critique).",
            "research_phases_covered": "Autonomous task decomposition and execution, web-based literature/data retrieval, code execution/testing, summarization/reporting; can cover implementation and execution phases of research workflows.",
            "coordination_mechanism": "Centralized control by the main Auto-GPT agent which creates and delegates to co-agents; optionally hierarchical with added Supervisor Agent overseeing loops and halting misbehaving co-agents; shared workspace (files/boards) via plugins for coordination.",
            "communication_protocol": "Natural-language-based messages and structured plugin calls; use of shared storage/plugins (file system, communication board) to pass artifacts; messages carry content, action labels, and metadata as per framework message tuple convention.",
            "feedback_mechanism": "Oracle critiques (stateless) and optional human-in-the-loop authorization; the framework suggests supervisor monitoring and inter-agent feedback but Auto-GPT's native design relies on chained thoughts and internal self-prompting rather than structured peer feedback.",
            "communication_frequency": "Frequent/stepwise (chains of thoughts proceed sequentially with messages and plugin interactions at each step); continuous when configured in 'continuous' mode, otherwise on-demand between thought steps.",
            "task_domain": "General autonomous task execution including coding, debugging, web research, and multi-step workflows; suggested use for automating research tasks but not demonstrated experimentally in paper.",
            "performance_metrics": null,
            "baseline_comparison": "Qualitatively compared against single-agent ChatGPT-style usage (more autonomous), but no quantitative comparisons provided; known limitations such as looping noted.",
            "coordination_benefits": "Allows chaining of subtasks, autonomy in multi-step workflows, sharing of file workspace across co-agents, potential reduction in human prompting; suggested benefit of adding Supervisor/Oracle agents to mitigate loops and hallucinations.",
            "coordination_challenges": "Prone to becoming stuck in loops when chaining thoughts, security vulnerabilities when executing external code or accessing the internet in continuous mode, lack of structured inter-agent critique unless explicitly added.",
            "ablation_studies": "none (no experimental ablation reported).",
            "optimal_configurations": "Recommended mitigations: add a Supervisor Agent to detect loops and halt misbehavior, use stateless Oracle Agents to vet sensitive actions, restrict agent creation permissions and require human authorization for high-risk operations; no empirical tuning provided.",
            "uuid": "e2551.1",
            "source_info": {
                "paper_title": "Multi-Agent Collaboration: Harnessing the Power of Intelligent LLM Agents",
                "publication_date_yy_mm": "2023-06"
            }
        },
        {
            "name_short": "BabyAGI (modeled)",
            "name_full": "BabyAGI (three-chain LLM agent system)",
            "brief_description": "BabyAGI is represented as three LLM chains—task creation, task prioritization, and execution—mapped to distinct agents interacting via a vector database plugin for storing and retrieving task context; the paper suggests modeling each chain as a separate agent within the framework to gain modularity and enable feedback loops.",
            "citation_title": "",
            "mention_or_use": "mention",
            "system_name": "BabyAGI modeled as a 3-agent pipeline",
            "system_description": "A pipeline-style multi-agent composition where Task-Creation Agent generates new tasks from objectives, Task-Prioritization Agent orders tasks, and Execution Agent attempts task completion; a vector-database plugin stores results and context (retrieval for future tasks). Optionally, a user-interaction/refinement agent mediates user prompts and places them into task storage.",
            "number_of_agents": "3 (task-creation, task-prioritization, execution) plus supporting storage/plugins",
            "agent_specializations": "Task Creation Agent (idea/hypothesis/subtask generation), Task Prioritization Agent (scheduling and ordering), Execution Agent (performs tasks, calls APIs, runs code), Vector DB plugin (context storage/retrieval), optional User-Interaction/Refinement Agent.",
            "research_phases_covered": "Idea/task generation, prioritization and planning, execution/implementation, storage of results for literature/context retrieval; supports iterative task-based research workflows.",
            "coordination_mechanism": "Sequential pipeline (task creation -&gt; prioritization -&gt; execution) mediated by shared vector database for context; coordination is centralized around the pipeline flow rather than decentralized consensus.",
            "communication_protocol": "Structured outputs between chains (natural language prompts and embeddings saved/retrieved from a vector DB plugin); messages and artifacts passed through plugin storage rather than direct peer-to-peer messaging.",
            "feedback_mechanism": "Contextual feedback via stored execution results in the vector DB enabling future tasks to use past outputs; the paper proposes adding explicit feedback loops and self-feedback agents to enable iterative refinement but reports no experiments.",
            "communication_frequency": "Per task step: communication occurs at each pipeline transition (after task creation, after prioritization, upon execution completion) and when retrieving context from vector DB.",
            "task_domain": "General task automation and iterative workflows, applicable to multi-step research tasks where tasks and results are stored and used for subsequent steps.",
            "performance_metrics": null,
            "baseline_comparison": null,
            "coordination_benefits": "Modularity and clearer separation of responsibilities, easier modification/extension, ability to reuse stored task results to improve future tasks, potential for better interpretability and debugging compared to monolithic chaining.",
            "coordination_challenges": "Pipeline rigidity may limit dynamic rebalancing, reliance on vector DB quality for context retrieval, no quantitative evaluation provided; general framework challenges (scalability, evaluation) apply.",
            "ablation_studies": "none (no empirical ablations reported).",
            "optimal_configurations": "Suggested configuration: explicitly model the three chains as agents, provide vector DB plugin for context, and add feedback/self-refinement agents for iterative improvement; no quantitative optima given.",
            "uuid": "e2551.2",
            "source_info": {
                "paper_title": "Multi-Agent Collaboration: Harnessing the Power of Intelligent LLM Agents",
                "publication_date_yy_mm": "2023-06"
            }
        },
        {
            "name_short": "Gorilla (modeled)",
            "name_full": "Gorilla: Large language model connected with massive APIs",
            "brief_description": "Gorilla is a fine-tuned LLaMA-based system that learns to map prompts to API calls by retrieving API documentation; it integrates retrieval at training and inference to reduce hallucination and stay up to date with API changes.",
            "citation_title": "Gorilla: Large language model connected with massive apis",
            "mention_or_use": "mention",
            "system_name": "Gorilla (API-integrated LLM)",
            "system_description": "Modeled in the framework as a single fine-tuned agent (LLaMA derivative) augmented with retriever and plugin modules representing APIs and their documentation. The agent uses retrieval during training and inference to ground generated API calls in current documentation and maps natural-language prompts to structured API calls.",
            "number_of_agents": "1 (single fine-tuned agent) though the framework suggests decomposing into multiple agents per API if desired",
            "agent_specializations": "API-integration agent (maps prompts to API calls using retrieved docs), Retriever plugin (fetches API docs), per-API plugins (call implementations and documentation storage), potential verifier agent (suggested) to detect hallucinations.",
            "research_phases_covered": "Implementation/execution that requires API calls, documentation retrieval for up-to-date behavior, and mitigation of hallucinations during inference; applicable to experimental pipelines that require interfacing with external services.",
            "coordination_mechanism": "Single-agent with plugin-mediated coordination; central agent consults retriever and plugins rather than peer agents; framework suggests possible decomposition into multiple agents each owning an API plugin for more complex coordination.",
            "communication_protocol": "Structured API-call representations informed by retrieved documentation; prompt-to-API mapping uses retrieval results as grounding; inter-component communication via plugin interfaces and structured API formats.",
            "feedback_mechanism": "Retriever-based grounding reduces hallucination; paper suggests adding a dedicated verification/mitigation agent to check the main agent's outputs (proposed improvement), but Gorilla itself relies on retrieval rather than multi-agent critique.",
            "communication_frequency": "Retriever consulted during both training and inference; runtime communications occur on-demand when API functionality is required.",
            "task_domain": "API-heavy tasks, software integration, automated code generation that requires calling external services; can be leveraged in research pipelines needing live API interactions.",
            "performance_metrics": "Paper claims improvements in writing API calls relative to GPT-4 (qualitative statement in this paper), but no numeric metrics are reported here.",
            "baseline_comparison": "Claimed improvement over GPT-4 for API-call generation (as cited), but this paper provides no quantitative comparisons or reproduced benchmarks.",
            "coordination_benefits": "Grounding in API documentation reduces hallucination for API calls and adapts to changing API versions; plugin decomposition could allow more flexible real-time updates without retraining the whole model.",
            "coordination_challenges": "Single-agent design may struggle with overlapping API functionality and complex multi-API coordination; the paper proposes per-API agents and a verifier agent as improvements but offers no empirical results.",
            "ablation_studies": "none reported in this paper for Gorilla within the multi-agent framework.",
            "optimal_configurations": "Suggested improvements: assign different agents to different APIs with dedicated plugins, and include a verification/anti-hallucination agent; no empirical configuration guidelines provided.",
            "uuid": "e2551.3",
            "source_info": {
                "paper_title": "Multi-Agent Collaboration: Harnessing the Power of Intelligent LLM Agents",
                "publication_date_yy_mm": "2023-06"
            }
        },
        {
            "name_short": "Oracle Agent",
            "name_full": "Oracle (stateless critique) Agent",
            "brief_description": "A stateless, memory-less agent that processes an input in isolation and returns critique or verification; intended to provide predictable, isolated feedback used to vet outputs or approve sensitive operations.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "Oracle Agent (stateless verifier)",
            "system_description": "An agent designed to be memory-less so that each interaction is independent; it receives a single input and returns a verdict/critique without reference to prior state. Common uses include summarization, answer criticism, and authorization decisions for sensitive plugin actions.",
            "number_of_agents": "1 (can be multiple independent oracle agents instantiated as needed)",
            "agent_specializations": "Stateless critique/verifier: checks outputs for correctness, summarizes content, evaluates whether an action is malicious or authorized.",
            "research_phases_covered": "Evaluation/verification and safety checks, post-generation critique and refinement prior to publishing or executing actions.",
            "coordination_mechanism": "On-demand invocation by other agents; not part of long-running stateful coordination—acts as an isolated service node in the communication graph.",
            "communication_protocol": "Receives isolated natural-language input or structured artifact and returns natural-language or structured critique/approval; follows the m=(S_m,A_m,D_m) message structure in synchronous request-response fashion.",
            "feedback_mechanism": "Provides direct critique or accept/reject signals that other agents use to refine or abort actions; used to simulate human-in-the-loop vetting in an automated way.",
            "communication_frequency": "On-demand per sensitive action or after agent outputs that require verification (e.g., before code execution or final reporting).",
            "task_domain": "Safety and evaluation tasks across domains; applicable wherever isolated, predictable evaluation is required (fact-checking, summarization validation, authorization).",
            "performance_metrics": null,
            "baseline_comparison": null,
            "coordination_benefits": "Predictable, isolated critique reduces propagation of stateful bias, can mitigate hallucination and risky actions by providing an independent check, reduces human load by automating vetting steps.",
            "coordination_challenges": "Being stateless, oracles may lack contextual nuance across multi-step interactions; effectiveness depends on oracle prompt design and underlying model competence; may add latency if invoked frequently.",
            "ablation_studies": "none reported.",
            "optimal_configurations": "Use oracle agents for high-risk steps and combine with supervisor oversight; keep oracle interactions isolated and stateless to maintain predictability; no empirical tuning provided.",
            "uuid": "e2551.4",
            "source_info": {
                "paper_title": "Multi-Agent Collaboration: Harnessing the Power of Intelligent LLM Agents",
                "publication_date_yy_mm": "2023-06"
            }
        },
        {
            "name_short": "Supervisor Agent",
            "name_full": "Supervisor (monitoring and halting) Agent",
            "brief_description": "A specialized supervisory agent that monitors agent activities, detects loops or deviations from tasks, and can issue halt commands to misbehaving agents to enforce correct operation and resource limits.",
            "citation_title": "here",
            "mention_or_use": "use",
            "system_name": "Supervisor Agent",
            "system_description": "An agent with oversight permissions that periodically inspects activity logs, task lists, and recent outputs to detect errors (e.g., looping behavior) or divergence from goals; upon detection it can issue halt commands to agents (per H_i permissions) or request corrective actions.",
            "number_of_agents": "1 (or a small set of supervisory agents) depending on system design",
            "agent_specializations": "Monitoring (detect loops, stalls, resource usage), Enforcement (halt commands, restart policies), Feedback (issue guidance to main agents), Resource management (alerting when thresholds reached).",
            "research_phases_covered": "Ongoing execution oversight and evaluation; primarily an operational phase that ensures safe, goal-aligned execution of research tasks.",
            "coordination_mechanism": "Hierarchical supervisory control: Supervisor inspects subordinate agents and exerts authority to halt or redirect them; integrates with resource-management modules to control agent proliferation.",
            "communication_protocol": "Periodic or event-triggered reviews via messages/queries to agents and plugins; issues control messages (halt/restart/modify-role) following the same message tuple format; may rely on logs or plugin-stored activity records.",
            "feedback_mechanism": "Issues corrective commands, requests for refinement, or halts; can also provide summaries to human operators and trigger oracle evaluations for disputed outputs.",
            "communication_frequency": "Periodic (monitoring intervals) and event-driven (on detecting anomalies or threshold breaches); can also act continuously when configured for real-time oversight.",
            "task_domain": "Operational safety and control across any domain where agents are executing tasks—especially important for tasks involving code execution, internet access, or other sensitive operations.",
            "performance_metrics": null,
            "baseline_comparison": null,
            "coordination_benefits": "Helps prevent infinite loops and runaway agent behavior, enforces resource constraints, reduces need for constant human oversight, improves system robustness and safety.",
            "coordination_challenges": "Supervisor becomes a single point of failure or bottleneck if not designed with scaling in mind; correctness depends on quality of anomaly detection heuristics; potential for overzealous halting causing unnecessary interruptions.",
            "ablation_studies": "none reported.",
            "optimal_configurations": "Grant supervisory halting authority selectively (only to designated creators/supervisors), pair supervisor with oracle critics for nuanced decisions, and combine with resource-management thresholds to prevent over-proliferation; no quantitative guidance provided.",
            "uuid": "e2551.5",
            "source_info": {
                "paper_title": "Multi-Agent Collaboration: Harnessing the Power of Intelligent LLM Agents",
                "publication_date_yy_mm": "2023-06"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Generative agents: Interactive simulacra of human behavior",
            "rating": 2
        },
        {
            "paper_title": "Camel: Communicative agents for \"mind\" exploration of large scale language model society",
            "rating": 2
        },
        {
            "paper_title": "Gorilla: Large language model connected with massive apis",
            "rating": 2
        },
        {
            "paper_title": "Language model cascades",
            "rating": 1
        },
        {
            "paper_title": "Improving language model negotiation with self-play and in-context learning from ai feedback",
            "rating": 1
        },
        {
            "paper_title": "Teaching large language models to self-debug",
            "rating": 1
        },
        {
            "paper_title": "Self-refine: Iterative refinement with self-feedback",
            "rating": 1
        }
    ],
    "cost": 0.01618875,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>Multi-Agent Collaboration: Harnessing the Power of IntElligent LLM Agents</h1>
<p>Yashar Talebirad<br>University of Alberta<br>Edmonton, Alberta, Canada<br>talebira@ualberta.ca</p>
<p>Amirhossein Nadiri<br>York University<br>Toronto, Ontario, Canada<br>anadiri@yorku.ca</p>
<h4>Abstract</h4>
<p>In this paper, we present a novel framework for enhancing the capabilities of large language models (LLMs) by leveraging the power of multi-agent systems. Our framework introduces a collaborative environment where multiple intelligent agent components, each with distinctive attributes and roles, work together to handle complex tasks more efficiently and effectively. We demonstrate the practicality and versatility of our framework through case studies in artificial general intelligence (AGI), specifically focusing on the Auto-GPT and BabyAGI models. We also examine the "Gorilla" model, which integrates external APIs into the LLM. Our framework addresses limitations and challenges such as looping issues, security risks, scalability, system evaluation, and ethical considerations. By modeling various domains such as courtroom simulations and software development scenarios, we showcase the potential applications and benefits of our proposed multi-agent system. Our framework provides an avenue for advancing the capabilities and performance of LLMs through collaboration and knowledge exchange among intelligent agents.</p>
<h2>1 Introduction</h2>
<p>The field of artificial intelligence is rapidly advancing, bringing with it the complexity and challenges of deploying AI models to manage an array of tasks. In response to these challenges, researchers are delving into multi-agent systems where multiple AI entities collaborate towards a common goal [1]. One such multi-agent system can be seen in the work of [2], who introduced generative agents that imitate plausible human behavior within an interactive sandbox environment. Another instance of this exploration is Camel [3], in which a system is introduced which leverages a Large Language Model (LLM) to generate diverse and detailed instructions for a wide range of tasks. It incorporates role-playing scenarios where two agents interact, thereby demonstrating the potential of such systems in handling complex real-world scenarios. In a similar vein, our paper proposes the use of multiple LLMs, each bearing diverse characteristics, to enhance performance across a range of tasks.</p>
<p>We focus particularly on the recent iterations of the Generative Pretrained Transformer (GPT) models, GPT-4 and GPT-3.5-turbo. From content creation and question-answering systems to language translation, GPT models have manifested immense potential across a plethora of applications. Early experiments with GPT-4 [4] reinforces this fact, showing GPT-4's ability to solve complex tasks across diverse fields, approaching human-level performance. As a result, the adeptness of these models at managing complex language tasks makes them ideal candidates for our purposes. Moving forward, we will use the term "Intelligent Generative Agents" (IGAs) to refer to a series of agents, each equipped with unique attributes and roles. GPT models, despite their commendable text generation capabilities, operate as isolated entities in their conventional form. They lack the capability to collaborate with other agents or draw from external knowledge repositories. This inherent shortcoming restricts their utility in complex scenarios that necessitate collaborative efforts and information sharing among multiple intelligent systems.</p>
<p>Our proposed use of multiple IGAs stems from the notion that diversity in a system enhances performance. The idea is based on the principle of division of labor, where each agent specializes in a specific function, thereby improving the efficiency and effectiveness of the system as a whole. This mirrors the concept of teamwork in human systems, where different individuals contribute their expertise to complete a task. A diverse set of agents, each configured with unique</p>
<p>strengths, can collectively handle a wider range of potential inputs, outputs, and processing strategies. Furthermore, delegating different roles to each agent introduces more flexibility and efficiency in the context task management. This brings about the concept of "multi-agent systems", in which numerous IGAs interact and collaborate to achieve a shared goal. These agents are capable of creating subtasks, seeking information, and soliciting assistance from each other, and can also engage in competitive evaluation for better outcomes. The emphasis on collaboration and knowledge exchange in multi-agent systems can bolster the problem-solving proficiency of GPT models, thereby paving the way for more sophisticated intelligent systems. In fact, our proposed multi-agent system also aims to make strides toward achieving a higher level of artificial general intelligence (AGI). The development and deployment of advanced generative AI models like GPT-4, represent significant steps towards AGI [5]. By fostering collaboration and knowledge exchange among multiple IGAs, our system seeks to further this progress. It aims to emulate the diverse and adaptable problem-solving capabilities that are characteristic of an AGI, thereby pushing the boundaries of what AI can achieve.
Our proposed abstraction allows users to engage with a "black box" by providing an initial prompt and receiving the final output without grappling with the underlying complexities of agent collaborations and interactions. Consider, for instance, taking inspiration from the success of Generative Adversarial Networks (GANs), where two networks (a generator and a discriminator) work collaboratively to produce better results, a simple yet effective multi-agent system can be made utilizing two IGAs: One with memory and one with Internet access. By combining their strengths, these agents could cooperate to reduce the occurrence of 'hallucinations' or false information generation, thereby increasing the reliability of the output [6]. This could be particularly beneficial in tasks where accuracy and fact-checking are critical.</p>
<p>The objectives of this paper are to explore and demonstrate the potential of having multiple agents within a black box environment for enhanced collaboration and problem-solving. The specific objectives are outlined as follows:</p>
<ul>
<li>Introducing a General Framework: The primary objective is to pave the way for the creation of more powerful AGI models. By providing a general framework for multi-agent systems using LLMs, we aim to push the boundaries of what AI can achieve, thereby contributing to the advancement toward Artificial General Intelligence.</li>
<li>Adaptive and Dynamic System: We introduce a system that is adaptive and can change itself to suit the tasks at hand. Having a static structure will limit a system to a set of predefined tasks. The possibility of addition and removal of agents in the system will make it flexible and capable of solving more complex problems.</li>
<li>Multi-Agent Collaboration: In this paper, we explore the use of multiple LLMs in a collaborative manner. This collaboration aims to enhance performance across diverse tasks, utilizing the strengths of each agent and encouraging a synergistic relationship amongst them.</li>
</ul>
<p>By effectively addressing these objectives, this paper aims to significantly advance the understanding and utilization of multi-agent collaboration in the realm of IGAs. The exploration and demonstration of such a model of collaboration serve as a stepping stone for future research in this domain.
The remainder of this paper is organized as follows: We begin by laying the foundation of our discussion in Section 2, where we introduce the essential components that make up the proposed framework. Following this, Section 3 provides a comprehensive description of the proposed multi-agent framework and its functionalities. In Section 4, we explore various potential use cases and applications of this framework, demonstrating its versatility and adaptability. Section 5 then discusses the potential challenges associated with our approach, shedding light on its limitations. We conclude our discussion in Section 6, where we summarize the main points of our discussion, draw final conclusions, and suggest directions for future research in this domain.</p>
<h1>2 Building Blocks of the Multi-Agent System</h1>
<p>The environment in which the multi-agent system operates can be considered a black box. This is due to the inherent nature of IGAs, which are trained on vast amounts of data and generate outputs based on complex internal computations that are not directly observable or interpretable. This black box environment is a digital workspace where multiple instances of IGAs interact and collaborate. This workspace provides a shared platform for the agents to communicate, exchange information, and perform tasks. Additionally, plugins can be used to provide additional functionality or capabilities to agents. They can be seen as a specialized tool or service that agents can utilize to perform specific tasks or access certain (internal or external) resources. Any of the agents or plugins can also be responsible with receiving the initial prompt from the user or responding to the main user.</p>
<p>We denote the black box environment as a graph $G(V, E)$, where $V$ is the set of vertices representing the IGAs and the plugins, and $E$ is the set of edges representing the connection channels between the agents and the plugins, and between the agents themselves.</p>
<h1>2.1 Agent Representation</h1>
<p>Each agent $i \in V$ is represented as a tuple $A_{i}=\left(L_{i}, R_{i}, S_{i}, C_{i}, H_{i}\right)$, where:</p>
<ul>
<li>$L_{i}$ refers to the language model instance utilized by the agent. This encompasses the model's type (such as GPT-4 or GPT-3.5-turbo) and its specific configuration parameters, including the 'temperature' setting which influences the degree of randomness in the agent's output. The choice of the language model can be dictated by the task requirements. For instance, while GPT-4, due to its exceptional reasoning capabilities, could be assigned tasks demanding deep insights and complex problem-solving, GPT-3.5-turbo could be employed for tasks requiring quicker execution owing to its faster performance.</li>
<li>$R_{i}$ is the role of the agent. The role defines the responsibilities of the agent and provides the agent with a sense of purpose and direction, guiding its actions and interactions. More specifically, these responsibilities are the tasks or functions the agent is expected to carry out within the system. For instance, an agent's responsibilities could include processing and responding to user queries, coordinating interactions between other agents, managing resources, or overseeing a particular aspect of the system's operations.</li>
<li>$S_{i}$ is the state of the agent, encompassing its current knowledge base and its "thoughts". The agent's state evolves over time based on the tasks it performs and the interactions it has with other agents or the environment.</li>
<li>The "knowledge" component of the state can be seen as a representation of the agent's current understanding or awareness of its environment, tasks, and interactions. It's updated whenever the agent learns new information or gains a new understanding.</li>
<li>"Thoughts" in this context can be interpreted as the agent's current focus or intent [7]. They represent what the agent is currently contemplating or planning, based on its knowledge and the task at hand. Thoughts may inform the agent's next action and may be updated after each operation. They may also encapsulate the agent's internal dialogue or reasoning process as it works towards its goal.</li>
<li>$C_{i}$ is the boolean property indicating whether an agent has the ability to create new agents. By setting this property to true, an agent can dynamically generate new agents within the system.</li>
<li>$H_{i}$ is the set of agents that this agent has the authority to halt. By specifying the agents that can be halted, an agent can exercise control over the execution of other agents within the system.</li>
</ul>
<h3>2.2 Plugin Representation</h3>
<p>Each plugin $j \in V$ is represented as a tuple $P_{j}=\left(F_{j}, C_{j}, U_{j}\right)$, where:</p>
<ul>
<li>$F_{j}$ is the set of the functionalities of the plugin, which are the actions that an agent can perform. This can include accessing and manipulating digital resources within this environment, such as files and databases, and interacting with external systems through APIs and other interfaces.</li>
<li>$C_{j}$ are the configurations associated with the plugin. Parameters are variables that are set when the plugin is initialized. Examples include API keys for accessing specific services, or threshold values to determine specific behavior. Parameters help in customizing the functionality of the plugin according to the task or application at hand.</li>
<li>$U_{j}$ is the set of usage constraints or conditions that govern the usage of the plugin. These constraints define the boundaries and capabilities of the plugin and can include limitations in terms of computational resources, input data types, and output capabilities.</li>
</ul>
<h3>2.3 Connection and Message Representation</h3>
<p>Each edge $e_{i j} \in E$ connects an agent $A_{i}$ to either a plugin $P_{j}$ or another agent $A_{j}$ using a communication channel. Each agent can send messages through the channels that it is connected to, and each message $m \in M_{i j}$, sent from agent $A_{i}$ to $A_{j}$, is represented as a tuple $m=\left(S_{m}, A_{m}, D_{m}\right)$, where:</p>
<ul>
<li>$S_{m}$ is the content of the message.</li>
<li>
<p>$A_{m}$ is the action associated with the message, which can be a task assignment, a report, a request, or any other action.</p>
</li>
<li>
<p>$D_{s o}$ is the metadata associated with the message, which can include information such as the timestamp, sender, receiver, and potentially additional context-specific data.</p>
</li>
</ul>
<p>Another approach to data transmission between agents can involve the use of plugins. For example, plugins designed for data storage can serve as shared databases, enabling different agents to access and retrieve information stored by other agents. Further extending this concept, a plugin could act as a communication board, enabling multi-directional communication between multiple agents. This essentially forms a many-to-many communication platform within the system.</p>
<h1>3 Detailing Proposed Framework</h1>
<p>In any multi-agent system, the nature of interaction and collaboration between the agents play a significant role in determining the overall system performance. This section explores the ways in which these interactions can be managed and optimized, particularly in the context of a system composed of multiple IGAs.</p>
<h3>3.1 System Design</h3>
<p>The design of a multi-agent system involves determining the number of agents, the required plugins, establishing connections between agents and plugins, creating connections between agents to enable communication, and assigning roles and properties of agents. This design aims to optimize the configuration and align it with the desired end goal of the system, enabling efficient collaboration and interaction among the agents.</p>
<p>While designing the system, the following steps are taken:</p>
<ul>
<li>Agent Roles: Roles for the agents are identified and defined within the environment, based on the specific requirements of the task at hand. Each agent is assigned a role, which specifies their responsibilities and duties in the system.</li>
<li>Agent-Plugin Connections: Connections between agents and plugins are established to provide agents with additional functionality. By connecting agents to plugins, agents gain access to tools, resources, or external services that enhance their capabilities. These connections allow agents to leverage the functionalities of the plugins.</li>
<li>Agent-Agent Connections: Connections between agents are created to enable communication and collaboration. These connections allow agents to exchange messages, share information, and cooperate toward achieving the common goal.</li>
<li>System Operations: Agents can be granted specific permissions to create new agents or halt a specific set of agents. Also, any of the plugins or agents can be responsible for receiving the initial prompt from the user or responding to them.</li>
</ul>
<p>By carefully designing the system with well-defined agents, plugins and the connections between them, the framework enables efficient multi-agent interaction and collaboration. This design allows agents to effectively communicate, coordinate, and work together towards achieving the common goal within the black box environment.</p>
<h3>3.2 Dynamic Addition of Agents</h3>
<p>In certain scenarios, an agent with the ability to create new agents may dynamically add additional agents to the system. This capability enables agents to distribute their workload and assign specific responsibilities to enhance collaboration and workload management. This need may arise as a byproduct of a sudden increase in the workload of the system. When a new agent is created, the creator assigns the new agent a role, grants it the necessary properties, and establishes connections with other agents and plugins. These properties and connections are subsets of those available to the creator agent. Also, a connection to the creator is established.</p>
<p>Once the new agent is created and initialized, it operates independently within its defined role. The creator agent sets a clear goal for the new agent, providing initial guidance to ensure a smooth transition of responsibilities. By allowing agents to dynamically create new agents and delegate tasks, the system can effectively manage workloads, enhance parallel processing capabilities, and improve overall system performance. This dynamic approach fosters a collaborative environment where agents can dynamically organize and distribute tasks, ultimately contributing to the achievement of the common goal.</p>
<p>The fact that a designer designed the system and defined the capabilities, connections, and permissions of the agents does not contradict the dynamic addition of agents and their ability to distribute workload and delegate responsibilities.</p>
<p>Although the designer has designed the initial framework, the dynamic addition of agents allows for flexibility and adaptation within the designed system. It empowers the agents themselves to make decisions and create new agents based on their own assessments of workload and the need for assistance. The designer's role is to provide the initial structure and guidelines, but the system allows for agent autonomy and self-organization.
Hence, system design and the dynamic addition of agents function harmoniously. The initial framework laid out by the designer serves as a robust foundation, while the agents' ability to dynamically adapt and distribute workload ensures flexibility and resilience under changing conditions and demands.</p>
<h1>3.3 Feedback and Self-Feedback Mechanisms</h1>
<p>Feedback mechanisms play a pivotal role in multi-agent systems, enabling agents to learn from their experiences and adapt their strategies for improved performance. These mechanisms can be categorized into inter-agent feedback and self-feedback [8, 9, 10]. Inter-agent feedback involves agents providing constructive criticism to each other based on their interactions and collaborations. Such feedback can help agents identify areas of improvement and adapt their strategies accordingly, enabling continuous learning and improvement within the system [8]. Some multi-agent systems employ inter-agent feedback by involving agents into role-playing. This approach involves designing specific prompts (denoted as Inception Prompting in [3]) to guide chat agents toward task completion while maintaining consistency with the main goal. This approach can be integrated in the proposed model, giving different roles to multiple agents and connecting them together.
Self-feedback, on the other hand, involves agents assessing their own performance and identifying areas of improvement. This can be achieved through a self-assessment mechanism where agents evaluate their performance based on predefined criteria or goals. This self-assessment can help agents identify their strengths and weaknesses, adapt their strategies, and improve their problem-solving capabilities [9]. In the proposed model, self-feedback can be simulated by a pair of connected agents: one with the role of giving feedback and the other tasked with refining the response based on the feedback received. Note that this simulation removes the need for a human to ask for possible refinement of the response.</p>
<h3>3.4 Oracle Agent</h3>
<p>An oracle agent is a unique type of agent in the system that operates in a stateless and memory-less manner. Unlike other agents that may maintain a state or memory to guide their actions, an oracle agent performs actions based solely on the current input it receives, without any regard for past inputs or outputs. This characteristic makes oracle agents particularly useful in scenarios where the task at hand is independent of previous interactions or states.
Every interaction with an oracle agent is treated as an isolated event, independent of any previous interactions. This makes oracle agents highly predictable, as their actions are solely determined by the current input and not influenced by any past events. oracle agents are mainly designed to be utilized by other agents. For instance, an oracle agent can give feedback on the response of the other agents, and let them refine their responses before proceeding.</p>
<h3>3.5 Halting Mechanism and Supervision</h3>
<p>The proposed framework incorporates an essential mechanism whereby an agent can halt other agents under certain conditions. This capability is crucial for effective management and coordination of tasks within a multi-agent system. Specifically, this ability can be granted to any agent in the system, including those that create new agents. The authority to halt becomes inherently necessary for these parent agents to maintain control and ensure the proper functioning of their created agents.
In practice, an agent halting another would involve signaling the targeted agent to cease its current activity. This signaling could be in the form of a command or a message transmitted via the communication interfaces defined within the system. Upon receiving this signal, the halted agent would immediately stop its current operation and wait for further instructions. Depending upon the system design, it could either enter an idle state or undertake a default operation in such instances. For creator agents and the agents they created, the halting mechanism works similarly. If a creator agent identifies undesirable activity in its created agent, it can initiate the halt command, causing them to stop their current operation immediately. This interaction emphasizes the supervisory role of the creator agent, ensuring that created agent functions correctly and does not deviate from its intended role.
In fact, this supervisory role can be enhanced by the introduction of a specialized "Supervisor Agent". This Supervisor Agent can monitor the progress and task list of the main agent, providing timely feedback when necessary. For example, if an agent is stuck in a loop or deviates from its assigned task, the Supervisor Agent can detect these issues by reviewing</p>
<p>recent activities. Upon such detection, the Supervisor Agent can initiate the halt command, prompting the main agent to cease its current operation and change its course of action. This mechanism not only facilitates better task management but also reduces the need for constant human monitoring and intervention in the feedback process.</p>
<h1>3.6 Autonomous System Design</h1>
<p>One notable aspect of the proposed framework is the potential role of an intelligent LLM as the system designer. The unique capabilities of an IGA extend beyond being just an agent within the environment, as it possesses the ability to fulfill the role of designing the system itself. It can consider the system's objectives, constraints, and desired functionalities to define the roles and responsibilities assigned to each agent. Additionally, the IGA can employ its knowledge of communication protocols and collaborative frameworks to determine the optimal interactions and connections between agents, plugins, and other system components. Drawing upon its comprehensive understanding of the problem domain, combined with precise system formulation and specified objectives, the IGA can design an effective system that optimally addresses the task at hand. Alternatively, after a human designs the initial system, an IGA can analyze the system structure, roles, interactions, and connections, and provide feedback and refinement to an already designed system. The IGA can also utilize its natural language generation capabilities to communicate the system design to the system owners. It can provide clear and concise descriptions of the agents' positions, roles, and interactions, allowing for a comprehensive understanding of the system's structure and functioning.</p>
<h2>4 Use Cases and Applications</h2>
<p>This section aims to demonstrate the practicality and versatility of the proposed multi-agent framework by examining its applicability to existing AI models. We focus specifically on two cutting-edge artificial general intelligence (AGI) models, Auto-GPT ${ }^{1}$ and BabyAGI ${ }^{2}$, and examine how our framework could potentially enhance their design and operation. We explore the models' main components, their operation, and limitations, and how our framework could be applied to improve their performance. Additionally, we discuss potential modifications that our framework can add, thus offering a broader understanding of the potential applications and benefits of the proposed multi-agent system.</p>
<h3>4.1 Artificial General Intelligence: Auto-GPT</h3>
<p>Auto-GPT is an experimental open-source AI application that has been gaining significant attention due to its promising autonomous abilities. It is considered a step towards AGI, a type of AI that can perform human-level intellectual tasks. Auto-GPT has internet access, long-term and short-term memory management, GPT-4 for text generation, and file storage and summarization with GPT-3.5. It can perform tasks that ChatGPT [11] can do, such as debugging code and writing an email, but it can also complete more advanced tasks with fewer prompts. Auto-GPT's design is based on the concept of thoughts, which are essentially the steps it takes to complete a task.</p>
<h3>4.1.1 Model</h3>
<p>The framework on which Auto-GPT runs can be modeled using our proposed framework. We can consider the Auto-GPT's main agent as a single agent in our model. The agent's goal is to perform tasks autonomously by chaining thoughts together, while working towards the goals specified by the user. The state of the agent includes the current task it is working on, and the chain of thoughts it has generated so far. This agent can also create other agents and halt any of them. Plugins can be represented as external services or tools that the agent uses to perform its tasks. For example, browsing the internet, managing memory, interacting with files, executing code, generating images, and similar tasks can be identified as plugins in our framework. There will also be an oracle agent, which is responsible for tasks such as summarization and criticizing the responses of the main agent. These plugins, along with the agents the main agent creates, can all be considered as nodes in the graph corresponding to the system, and the connections between the Auto-GPT agent and its plugins, along with the connections between the agent and the other agents it makes, can be represented as edges in the graph. Messages sent through these connections may include task assignments, requests for information, or commands to execute certain operations.</p>
<h3>4.1.2 Limitations and Possible Improvements</h3>
<p>Despite its potential, Auto-GPT faces several challenges and limitations. One significant obstacle is that it might get stuck in a loop, rendering it unable to function properly. The looping issue is a result of the system's reliance on chaining</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>thoughts together to perform tasks. While this approach allows the system to perform complex tasks, it also makes it prone to getting stuck in loops, especially when dealing with complex or ambiguous problems. However, features that are proposed in our framework can possibly address this shortcoming, and open further avenues for improvements. For instance, the agent's inability to realize when it has got stuck or notice that it has gone off task can potentially be mitigated by adding the "Supervisor Agent" that was introduced in Section 3.5.
As another example, one can implement a concept of co-agents, where multiple autonomous instances of Auto-GPT could collaborate, share a workspace for files, and communicate in a board, essentially mimicking a team of humans working remotely, with each having a specific role.
Additionally, the system's ability to interact with files and execute code opens up a wide range of possibilities for its use, but it also introduces potential security risks. These risks are possibly alleviated by having a human provide feedback and authorizing each step, but this step is completely ignored when using the app's "continuous" mode. This means that the system should be designed with robust security measures in place to prevent unauthorized access or misuse. This can be done using a state-less oracle agent, which can monitor each sensitive task and decide if it is indeed malicious or not.</p>
<h1>4.2 Artificial General Intelligence: BabyAGI</h1>
<p>BabyAGI is an AI agent that can generate and attempt to execute tasks based on a given objective. BabyAGI operates based on three LLM chains: Task creation chain, Task prioritization chain, and Execution chain.</p>
<h3>4.2.1 Model</h3>
<p>In our proposed framework, BabyAGI can be modeled as a system of interconnected agents, each with a specific role. The agents in BabyAGI include a task creation agent, a task prioritization agent, and an execution agent. In addition to these agents, BabyAGI uses a vector database to store and retrieve task results for context. This can be modeled as a plugin in our framework that interacts with a vector database, with operations for storing and retrieving data. Furthermore, there can be an additional agent in our framework that interacts with the user, refines the input, and places it into the task storage.</p>
<h3>4.2.2 Limitations and Possible Improvements</h3>
<p>Our framework can potentially improve upon the current implementation of BabyAGI by providing a more structured and modular approach to designing the system. By modeling each agent, plugin, and operation explicitly, our framework can make it easier to understand and modify the system. Furthermore, our framework's support for feedback loop can enable the agents in BabyAGI to learn from their own performance and improve over time.</p>
<h3>4.3 The "Gorilla" Model</h3>
<h3>4.3.1 Model</h3>
<p>The Gorilla system [12] is based on a fine-tuned LLaMA [13] model with additional capabilities to retrieve documents and integrate this information during both training and inference. It is capable of extending beyond mere language modelling, embracing features that enable interaction with external APIs, handling document retrieval, and adaptation to version changes. In this system, API calls and their documentation are used to instruct the LLM about the specific tasks each API can handle. The model learns to map prompts to API calls by using a retrieval system to access the most up-to-date API documentation from the database. Gorilla also mitigates hallucination and adapts to changes in API documentation by using a retriever during training and inference.
In our framework, we need a single agent to model the Gorilla system. To handle APIs, our model can employ plugins, which can be seen as extensions or modules designed to handle specific tasks. This results in enhanced flexibility and versatility in the system that allows it to handle a broader range of tasks.</p>
<h3>4.3.2 Limitations and Possible Improvements</h3>
<p>Although integrating information during both training and inference shows significant improvements over GPT-4 in writing API calls, our model offers a more generalized and robust framework that can be customized to different use cases. For example, our model can handle real-time updates to APIs and their documentation more efficiently by updating the relevant agent's knowledge base, rather than having to update the entire model. Additionally, it can handle overlapping functionality between different APIs more elegantly by deciding between different agents based on their functionality.</p>
<p>Our model can also potentially improve the process of mitigating hallucinations by using a dedicated agent for this task. This agent could verify the main agent's responses to find out when the agent is hallucinating and intervene to correct the output.</p>
<p>Our model can further improve the process of interacting with APIs by employing different agents for different APIs, each equipped with its plugin for the relevant API documentation. This would allow our model to handle more complex tasks and interactions, as it can leverage the combined capabilities of multiple agents at once.</p>
<h1>4.4 Case Study</h1>
<p>In this section, we will delve into two distinct case studies to illustrate the practical applications of our proposed multi-agent system. These case studies, namely a court simulation and a software development scenario, have been chosen due to their inherent complexity and the necessity for diverse roles and interactions within them. Both scenarios involve a multitude of tasks and responsibilities that need to be coordinated effectively for successful outcomes. By employing our multi-agent framework, we aim to demonstrate how such complex processes can be modeled in a common framework. Each agent in the system will be assigned a specific role, mirroring the real-world roles in these scenarios. They will be equipped with the necessary tools and capabilities to fulfill their responsibilities, thereby contributing to the overall objective.</p>
<h3>4.4.1 Court Simulation</h3>
<p>Before the introduction of new LLMs, attempts to simulate environments like a courtroom required training with specific data [14]. However, with the recent advancements in the area of language models, the training process might not be necessary anymore. In this context, our framework can be utilized to model the various roles and interactions that take place within a courtroom. This includes the roles of the judge, jury, attorneys, witnesses, and even the court clerk. Each of these roles can be represented by an agent within the system, with specific responsibilities and capabilities assigned to them.</p>
<ul>
<li>Judge Agent: The Judge Agent is responsible for overseeing the proceedings, making rulings on legal issues, and ultimately delivering the verdict in non-jury trials. This agent would require a plugin that provides access to a comprehensive database of legal knowledge and precedents, enabling it to make informed decisions.</li>
<li>Jury Agent: The Jury Agent is responsible for determining the facts of the case and delivering a verdict in jury trials. This agent would require a plugin that allows it to understand and evaluate the evidence presented during the trial.</li>
<li>Attorney Agents: The Attorney Agents represent the prosecution and the defence in the trial. They are responsible for presenting their respective cases, cross-examining witnesses, and making closing arguments. These agents would require plugins that provide access to legal knowledge, as well as plugins that enable them to understand and generate persuasive arguments.</li>
<li>Witness Agents: The Witness Agents provide testimony during the trial. They would require plugins that allow them to accurately recall and describe events.</li>
<li>Court Clerk Agent: The Court Clerk Agent is responsible for administrative tasks such as maintaining court records and administering oaths. This agent would require plugins that enable it to manage and retrieve documents, as well as plugins that allow it to perform its administrative duties.</li>
</ul>
<p>The interactions between these agents would be governed by a set of predefined rules and protocols, simulating the procedures followed in a real courtroom. For instance, the Judge Agent could issue instructions to the other agents, the Attorney Agents could question the Witness Agents, and the Jury Agent could request clarification or additional information from any of the other agents.
In terms of operations, the simulation process would proceed in stages, similar to a real trial. The Attorney agents would present their opening statements, followed by the presentation of evidence and witness testimony. The Jury Agent would then deliberate and deliver a verdict, after which the Judge Agent would conclude the proceedings.
This simulation could be used for a variety of purposes, such as training for law students, testing new legal theories, or even automating certain aspects of the legal process. However, it's important to note that while our framework can simulate the process and interactions in a courtroom, it cannot fully replicate the complexities of human decision-making and judgement. Therefore, any outcomes produced by the simulation should be interpreted with caution.</p>
<h1>4.4.2 Software Development</h1>
<p>Our model can be effectively used in the context of software development, enabling the creation of a multi-agent system where each agent embodies a specific role integral to the software development process. By assigning distinct responsibilities to individual agents, the development process can be significantly optimized and streamlined. The key roles, as derived from the software development team structure, can be represented as follows:</p>
<ul>
<li>User Experience Designer: This agent is responsible for understanding and designing the user experience. It can use a plugin that simulates user interactions to test different designs and gather data on user preferences. The agent can then use this data to refine the design.</li>
<li>Product Manager: The Product Manager is responsible for understanding the needs of the users and defining the product's features accordingly. It can use a plugin that collects and analyzes user feedback to understand what features are most important to the users. This agent can also interact with the User Experience Designer Agent to ensure that the product's design aligns with the users' needs.</li>
<li>Software Architect: The Software Architect Agent is responsible for designing the software's architecture. It can use a plugin that simulates different architectural designs to test their performance and scalability. This agent can also interact with the Software Developer Agent to ensure that the architecture is implemented correctly.</li>
<li>Software Developer: The Software Developer is responsible for writing the code that implements the software's features. It can use a plugin that provides access to a code repository to store and manage the code. This agent can also interact with the Software Architect Agent to ensure that the code aligns with the architecture.</li>
<li>Software Tester: The Software Tester is responsible for testing the software to ensure that it works correctly. It can use a plugin that automates the testing process, running a suite of tests on the code and reporting any failures. This agent can also interact with the Software Developer Agent to help identify and fix any bugs in the code.</li>
<li>User Interface Designer: The User Interface Designer is responsible for designing the software's user interface. It can use a plugin that simulates user interactions to test different designs and gather data on user preferences. This agent can then use this data to refine the design.</li>
<li>Debugger: The Debugger is responsible for identifying and fixing bugs in the code. It can use a plugin that provides debugging tools to help identify the cause of any bugs. This agent can also interact with the Software Developer Agent to help fix the bugs.</li>
<li>Oracle Agent: The oracle agent in this context can be used to provide feedback on the overall software development process. It can assess the performance of the other agents and provide feedback to help them improve. For example, it might suggest that the Software Developer Agent needs to write more efficient code, or that the User Experience Designer Agent needs to consider a different design approach.</li>
</ul>
<p>In this way, our model can be used to utilize a more efficient and effective software development process. By assigning specific roles to each agent and using plugins to enhance their capabilities, we can create a system that is capable of automating the development process of a high-quality software, based on the user's needs.</p>
<h2>5 Challenges and Limitations</h2>
<p>Multi-agent systems, by their very nature, are complex entities. They involve the interaction of multiple autonomous agents, each with its own capabilities and objectives. This complexity, while being a source of the system's strength, also gives rise to a host of challenges and limitations. In the following subsections, we will explore some of these challenges, shedding light on the potential hurdles that need to be overcome in the context of multi-agent systems.</p>
<h3>5.1 Challenges of a Dynamic System</h3>
<p>The dynamic addition of agents, while offering the potential for enhanced flexibility and adaptability, also presents several challenges. One of the primary concerns is the risk of over-proliferation of agents, which could lead to resource exhaustion or inefficiencies in the system. To mitigate this risk, the system needs to incorporate mechanisms to monitor and control the creation of new agents.</p>
<p>Specifically, the system needs to employ a resource management module that tracks the computational resources consumed by each agent and the system as a whole. This module can alert the system when resource usage approaches</p>
<p>a predefined threshold, triggering measures to prevent resource exhaustion. These measures could include halting the creation of new agents.</p>
<p>In addition to resource management, the system also needs to ensure that the dynamic addition of agents does not lead to inefficiencies or conflicts. This is achieved through a coordination mechanism that oversees the assignment of roles and tasks to the agents. When a new agent is created, this mechanism ensures that its role and tasks do not overlap significantly with those of existing agents, thereby preventing redundancies and potential conflicts.</p>
<h1>5.2 Scalability</h1>
<p>Scalability is another significant challenge in multi-agent systems. As the system grows in size and complexity, maintaining the performance and efficiency of the system can become increasingly difficult. The computational resources required for managing the interactions and operations of a large number of agents can be substantial. Additionally, as the number of agents increases, the potential for conflicts and inconsistencies also increases, which can further impact the performance of the system.</p>
<h3>5.3 System Evaluation</h3>
<p>Evaluating the performance of a multi-agent system can be challenging due to the complexity and diversity of the tasks that the system can handle. Traditional evaluation metrics might not be sufficient or appropriate for assessing the performance of the system. Therefore, new evaluation metrics and methodologies might need to be developed to accurately measure the performance of the system and its individual agents.</p>
<h3>5.4 Ethical Considerations</h3>
<p>The use of multi-agent systems also raises several ethical considerations. For instance, the system might make decisions or take actions that have significant impacts on individuals or society. Therefore, it is crucial to ensure that the system operates in an ethical manner and that it respects the rights and interests of all users. This requires careful design and oversight of the system, as well as the implementation of appropriate ethical guidelines and safeguards.</p>
<h2>6 Conclusion</h2>
<p>In this paper, we proposed a novel framework for enhancing the performance and capabilities of LLMs by leveraging the power of multi-agent systems. Our framework introduces a black box environment where multiple IGAs, each with unique attributes and roles, collaborate to handle complex tasks more efficiently and effectively. By introducing collaboration and knowledge exchange among these agents, our system seeks to push the boundaries of what AI can achieve, potentially paving the way towards achieving a higher level of AGI.</p>
<p>Despite the potential benefits, the proposed framework also presents several challenges and limitations, including issues related to security and privacy, agent design and training, system evaluation, and ethical considerations. Addressing these challenges will require further research and development, as well as careful consideration of the ethical implications of deploying such systems. Another promising direction for future work could involve the use of the proposed framework to specific use cases or domains. For instance, the framework could be adapted to handle complex tasks in areas such as healthcare, finance, education, or transportation. This could provide valuable insights into the practical utility and potential impact of the proposed framework.</p>
<h2>References</h2>
<p>[1] David Dohan, Winnie Xu, Aitor Lewkowycz, Jacob Austin, David Bieber, Raphael Gontijo Lopes, Yuhuai Wu, Henryk Michalewski, Rif A. Saurous, Jascha Sohl-dickstein, Kevin Murphy, and Charles Sutton. Language model cascades, 2022.
[2] Joon Sung Park, Joseph C. O’Brien, Carrie J. Cai, Meredith Ringel Morris, Percy Liang, and Michael S. Bernstein. Generative agents: Interactive simulacra of human behavior, 2023.
[3] Guohao Li, Hasan Abed Al Kader Hammoud, Hani Itani, Dmitrii Khizbullin, and Bernard Ghanem. Camel: Communicative agents for "mind" exploration of large scale language model society, 2023.
[4] Sébastien Bubeck, Varun Chandrasekaran, Ronen Eldan, Johannes Gehrke, Eric Horvitz, Ece Kamar, Peter Lee, Yin Tat Lee, Yuanzhi Li, Scott Lundberg, Harsha Nori, Hamid Palangi, Marco Tulio Ribeiro, and Yi Zhang. Sparks of artificial general intelligence: Early experiments with gpt-4, 2023.</p>
<p>[5] Chaoning Zhang, Chenshuang Zhang, Chenghao Li, Yu Qiao, Sheng Zheng, Sumit Kumar Dam, Mengchun Zhang, Jung Uk Kim, Seong Tae Kim, Jinwoo Choi, Gyeong-Moon Park, Sung-Ho Bae, Lik-Hang Lee, Pan Hui, In So Kweon, and Choong Seon Hong. One small step for generative ai, one giant leap for agi: A complete survey on chatgpt in aigc era, 2023.
[6] Yejin Bang, Samuel Cahyawijaya, Nayeon Lee, Wenliang Dai, Dan Su, Bryan Wilie, Holy Lovenia, Ziwei Ji, Tiezheng Yu, Willy Chung, Quyet V. Do, Yan Xu, and Pascale Fung. A multitask, multilingual, multimodal evaluation of chatgpt on reasoning, hallucination, and interactivity, 2023.
[7] Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian Ichter, Fei Xia, Ed Chi, Quoc Le, and Denny Zhou. Chain-of-thought prompting elicits reasoning in large language models, 2023.
[8] Yao Fu, Hao Peng, Tushar Khot, and Mirella Lapata. Improving language model negotiation with self-play and in-context learning from ai feedback, 2023.
[9] Xinyun Chen, Maxwell Lin, Nathanael Schärli, and Denny Zhou. Teaching large language models to self-debug, 2023.
[10] Aman Madaan, Niket Tandon, Prakhar Gupta, Skyler Hallinan, Luyu Gao, Sarah Wiegreffe, Uri Alon, Nouha Dziri, Shrimai Prabhumoye, Yiming Yang, Shashank Gupta, Bodhisattwa Prasad Majumder, Katherine Hermann, Sean Welleck, Amir Yazdanbakhsh, and Peter Clark. Self-refine: Iterative refinement with self-feedback, 2023.
[11] OpenAI. Introducing chatgpt. https://openai.com/blog/chatgpt, 2022. Accessed: 2023-06-04.
[12] Shishir G. Patil, Tianjun Zhang, Xin Wang, and Joseph E. Gonzalez. Gorilla: Large language model connected with massive apis, 2023.
[13] Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, et al. Llama: Open and efficient foundation language models. arXiv preprint arXiv:2302.13971, 2023.
[14] Sil Hamilton. Blind judgement: Agent-based supreme court modelling with gpt, 2023.</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>${ }^{1}$ https://github.com/Significant-Gravitas/Auto-GPT
${ }^{2}$ https://github.com/yoheinakajima/babyagi&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>