<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-1528 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-1528</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-1528</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-29.html">extraction-schema-29</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of simulators used for training models or agents on scientific reasoning tasks (especially in thermodynamics, circuits, or biology), including details about simulator fidelity levels and transfer performance to real-world or different contexts.</div>
                <p><strong>Paper ID:</strong> paper-29114ac517348c33ae66185c802c7fcefacd9705</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/29114ac517348c33ae66185c802c7fcefacd9705" target="_blank">Efficient emulation of relativistic heavy ion collisions with transfer learning</a></p>
                <p><strong>Paper Venue:</strong> Physical Review C</p>
                <p><strong>Paper TL;DR:</strong> This work uses transfer learning to map the parameter dependencies of one model emulator onto another, leveraging similarities between different simulations of heavy ion collisions, and reduces the numerical cost of comprehensive uncertainty quantification when studying multiple collision systems and exploring different models.</p>
                <p><strong>Paper Abstract:</strong> Measurements from the Large Hadron Collider (LHC) and the Relativistic Heavy Ion Collider (RHIC) can be used to study the properties of quark-gluon plasma. Systematic constraints on these properties must combine measurements from different collision systems and methodically account for experimental and theoretical uncertainties. Such studies require a vast number of costly numerical simulations. While computationally inexpensive surrogate models (“emulators”) can be used to efficiently approximate the predictions of heavy ion simulations across a broad range of model parameters, training a reliable emulator remains a computationally expensive task. We use transfer learning to map the parameter dependencies of one model emulator onto another, leveraging similarities between different simulations of heavy ion collisions. By limiting the need for large numbers of simulations to only one of the emulators, this technique reduces the numerical cost of comprehensive uncertainty quantification when studying multiple collision systems and exploring different models.</p>
                <p><strong>Cost:</strong> 0.019</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e1528.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e1528.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of simulators used for training models or agents on scientific reasoning tasks (especially in thermodynamics, circuits, or biology), including details about simulator fidelity levels and transfer performance to real-world or different contexts.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>JETSCAPE full-model pipeline</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>JETSCAPE multistage heavy ion collision simulation framework (full-model pipeline used in this work)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A multistage, high-fidelity simulation pipeline for relativistic heavy ion collisions combining initial-state, pre-equilibrium, viscous hydrodynamics, particlization, and hadronic transport modules; used to generate costly training data for emulators in this paper.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>simulator_name</strong></td>
                            <td>JETSCAPE full-model pipeline</td>
                        </tr>
                        <tr>
                            <td><strong>simulator_description</strong></td>
                            <td>A composed simulator built from modules (T_R ENTo initial energy deposition, a freestreaming pre-equilibrium stage, MUSIC viscous hydrodynamics, iS3D particlization sampler with different viscous-correction options, and SMASH hadronic transport/afterburner). Produces observables (multiplicities, mean pT, flow coefficients, etc.) with stochastic event-by-event fluctuations.</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>fluid dynamics / high-energy nuclear physics (quark-gluon plasma phenomenology)</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_level</strong></td>
                            <td>high-fidelity multistage physics simulation (end-to-end modeling of heavy-ion collisions across stages: initial state → pre-equilibrium → viscous hydrodynamics → particlization → hadronic transport)</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_characteristics</strong></td>
                            <td>Includes fluctuating initial conditions (stochastic event ensembles), viscous relativistic hydrodynamics (MUSIC), explicit particlization algorithms (iS3D) with multiple viscous-correction models, and microscopic hadronic rescattering/decays via SMASH; computationally expensive (O(1000) CPU-hours per design point on average) and produces per-design-point ensembles (2500 event realizations per design-point were used to compute means/errors).</td>
                        </tr>
                        <tr>
                            <td><strong>model_or_agent_name</strong></td>
                            <td>Gaussian Process emulators / transfer-learning emulators trained on JETSCAPE outputs</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Surrogate emulators: (i) standard Gaussian Process (GP) emulators per observable; (ii) a transfer learning emulator built as an additive KO-like model f_T(x)=ρ f_S(x)+δ(x) with GPs on f_S and δ.</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task</strong></td>
                            <td>Emulate simulator outputs (observables) across a 17-dimensional parameter space for Bayesian parameter estimation and sensitivity analysis of QGP properties; enable fast likelihood evaluations for MCMC-based inference.</td>
                        </tr>
                        <tr>
                            <td><strong>training_performance</strong></td>
                            <td>Source training used m=473 design points (each design point summarized from 2500 simulated events) and test evaluation used 100 held-out design points; standard GP emulators trained on the target alone reach an asymptotic MSE (not numerically tabulated) using all 473 target points. Transfer-learning emulators reached similar or better MSE with far fewer target training points (e.g., for Au+Au target, TL achieved comparable accuracy with roughly half the target training points; for some particlization changes TL required ≈35 target points to reach within 10% of asymptotic accuracy).</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_target</strong></td>
                            <td>Different collision systems (e.g., Pb+Pb at 2.76 TeV → Au+Au at 0.2 TeV) and different model variants (different particlization viscous-correction schemes: Grad ↔ CE ↔ PTB); ultimately used within downstream Bayesian parameter inference and sensitivity analyses.</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_performance</strong></td>
                            <td>Qualitative/numeric statements: TL reduced MSE relative to GP for small n (example: at n=47 target points, TL had ~50% of the MSE of GP for Au+Au target); for CE particlization TL reached within 10% of asymptotic MSE with only 35 target points and remained useful down to as few as 5 points; computational savings translate to large CPU-hour reductions because full-model runs cost ~O(1000) CPU-hours each.</td>
                        </tr>
                        <tr>
                            <td><strong>compares_fidelity_levels</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_comparison_results</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>minimal_fidelity_discussion</strong></td>
                            <td>No explicit claim of a minimum simulator fidelity required for successful transfer; paper requires same parameterization between source and target and notes TL works best when source and target share qualitative trends.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_cases</strong></td>
                            <td>No explicit catastrophic failures reported; authors note TL advantage diminishes once a large fraction (~60%+) of target training points are used. TL is less beneficial when source and target differ substantially, though still beneficial in studied cases (e.g., different collision energy vs different particlization models show varying degrees of TL benefit).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Efficient emulation of relativistic heavy ion collisions with transfer learning', 'publication_date_yy_mm': '2022-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1528.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e1528.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of simulators used for training models or agents on scientific reasoning tasks (especially in thermodynamics, circuits, or biology), including details about simulator fidelity levels and transfer performance to real-world or different contexts.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>T_R ENTo</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>T_R ENTo initial energy deposition model</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A phenomenological initial-state model that parametrizes deposited energy density immediately after nuclear impact; used as the initial-conditions module in the full-model pipeline.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>simulator_name</strong></td>
                            <td>T_R ENTo</td>
                        </tr>
                        <tr>
                            <td><strong>simulator_description</strong></td>
                            <td>Initial-state generator producing spatial initial energy/entropy density profiles with tunable parameters (including a normalization N and parameters controlling granularity), used to seed hydrodynamic evolution.</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>initial conditions / high-energy nuclear physics</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_level</strong></td>
                            <td>medium-to-high fidelity phenomenological initial-state model (captures event-by-event geometric fluctuations and parameterized physics for heavy-ion collisions)</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_characteristics</strong></td>
                            <td>Models spatial fluctuations and normalization; parameterized granularity and other shape parameters; stochastic (event-by-event) realizations used to produce ensemble-averaged observables.</td>
                        </tr>
                        <tr>
                            <td><strong>model_or_agent_name</strong></td>
                            <td>Used as a module within the full-model simulator pipeline</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Deterministic/stochastic physics-based initial-condition generator (not a learned agent in this work).</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task</strong></td>
                            <td>Provide initial conditions for hydrodynamic simulations; influences multiplicities, flow observables, and sensitivities analyzed by emulators.</td>
                        </tr>
                        <tr>
                            <td><strong>training_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>transfer_target</strong></td>
                            <td>Other collision systems and particlization/hydrodynamic variants via transfer of emulator knowledge</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>compares_fidelity_levels</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_comparison_results</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>minimal_fidelity_discussion</strong></td>
                            <td>No explicit minimal fidelity discussion specific to T_R ENTo; discrepancy GP sensitivity analysis shows normalization N and T_R ENTo parameters are important for transfer differences between systems.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_cases</strong></td>
                            <td>Not reported; sensitivity analysis revealed T_R ENTo parameters drive differences in some observables (e.g., v2 sensitivity), indicating their critical role for transfer accuracy.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Efficient emulation of relativistic heavy ion collisions with transfer learning', 'publication_date_yy_mm': '2022-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1528.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e1528.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of simulators used for training models or agents on scientific reasoning tasks (especially in thermodynamics, circuits, or biology), including details about simulator fidelity levels and transfer performance to real-world or different contexts.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Freestreaming model</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Freestreaming pre-equilibrium model</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A simple pre-equilibrium stage model that approximates the earliest weakly-coupled dynamics by free streaming for a tunable time before hydrodynamic evolution starts.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>simulator_name</strong></td>
                            <td>Freestreaming module (freestream-milne repository referenced)</td>
                        </tr>
                        <tr>
                            <td><strong>simulator_description</strong></td>
                            <td>Approximates pre-equilibrium evolution by free-streaming of energy density for a model-dependent duration; parameterizes the free-streaming time as an input.</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>pre-equilibrium dynamics / high-energy nuclear physics</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_level</strong></td>
                            <td>medium-fidelity approximation for early-time dynamics (simplified weak-coupling free-streaming instead of a full kinetic-theory evolution)</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_characteristics</strong></td>
                            <td>Simplified dynamics: neglects interactions during the pre-equilibrium interval except via free streaming; parameterized free-streaming duration controls early radial/anisotropic flow buildup.</td>
                        </tr>
                        <tr>
                            <td><strong>model_or_agent_name</strong></td>
                            <td>Used as the pre-equilibrium module in full-model simulations</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Physics-based module (not learned agent); parameter(s) control duration of free-streaming.</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task</strong></td>
                            <td>Model early-time evolution to set conditions for viscous hydrodynamics; contributes to observables emulated and to discrepancy sensitivity between systems.</td>
                        </tr>
                        <tr>
                            <td><strong>training_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>transfer_target</strong></td>
                            <td>Target collision systems and particlization models via emulator transfer</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>compares_fidelity_levels</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_comparison_results</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>minimal_fidelity_discussion</strong></td>
                            <td>Paper notes discrepancy GPs for some observables are sensitive to pre-equilibrium parameters, implying that pre-equilibrium fidelity can matter for transfer between collision energies.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_cases</strong></td>
                            <td>Not explicitly reported; differences in pre-equilibrium modeling contribute to discrepancy and affect transfer efficiency between energies.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Efficient emulation of relativistic heavy ion collisions with transfer learning', 'publication_date_yy_mm': '2022-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1528.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e1528.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of simulators used for training models or agents on scientific reasoning tasks (especially in thermodynamics, circuits, or biology), including details about simulator fidelity levels and transfer performance to real-world or different contexts.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>MUSIC</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>MUSIC relativistic viscous hydrodynamics code</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A 3+1D viscous hydrodynamic solver used to model the near-equilibrium QGP evolution stage in the multistage simulation pipeline.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>simulator_name</strong></td>
                            <td>MUSIC</td>
                        </tr>
                        <tr>
                            <td><strong>simulator_description</strong></td>
                            <td>A relativistic viscous hydrodynamics code that evolves energy-momentum tensors with shear and bulk viscosity parameterizations and supplies fluid output at particlization.</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>viscous hydrodynamics / fluid dynamics in heavy-ion collisions</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_level</strong></td>
                            <td>high-fidelity hydrodynamic evolution (3+1D viscous hydrodynamics with temperature-dependent transport coefficients)</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_characteristics</strong></td>
                            <td>Models dissipative hydrodynamic evolution including shear and bulk viscosities as parameterized functions of temperature; numerically resolves spacetime evolution until a switching temperature T_sw.</td>
                        </tr>
                        <tr>
                            <td><strong>model_or_agent_name</strong></td>
                            <td>Hydrodynamic module within full-model pipeline</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Physics-based PDE solver; not a learned agent in this work.</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task</strong></td>
                            <td>Predict evolution of QGP and map initial-state inputs to fluid variables at particlization, affecting final-state observables emulated.</td>
                        </tr>
                        <tr>
                            <td><strong>training_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>transfer_target</strong></td>
                            <td>Other model variants and collision systems as part of emulator transfer</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>compares_fidelity_levels</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_comparison_results</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>minimal_fidelity_discussion</strong></td>
                            <td>No explicit minimal fidelity claims, but sensitivity analysis indicates viscosities modeled in MUSIC are relevant to discrepancy in some observables across systems.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_cases</strong></td>
                            <td>None reported.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Efficient emulation of relativistic heavy ion collisions with transfer learning', 'publication_date_yy_mm': '2022-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1528.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e1528.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of simulators used for training models or agents on scientific reasoning tasks (especially in thermodynamics, circuits, or biology), including details about simulator fidelity levels and transfer performance to real-world or different contexts.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>iS3D</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>iS3D particlization sampler</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A particlization/sampling module that converts fluid output to particles using the Cooper-Frye prescription and implements different viscous correction ansätze (Grad, Chapman–Enskog, PTB).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>simulator_name</strong></td>
                            <td>iS3D sampler</td>
                        </tr>
                        <tr>
                            <td><strong>simulator_description</strong></td>
                            <td>Sampler implementing Cooper-Frye particlization with multiple viscous-correction models (Grad, Chapman–Enskog (CE), Pratt–Torrieri–Bernhard (PTB) implementations) to generate hadronic distributions at switching temperature.</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>particlization / hadronization modeling in heavy-ion collisions</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_level</strong></td>
                            <td>module-level fidelity varies by viscous-correction model: different approximations to out-of-equilibrium distribution functions (Grad: second-order expansion; CE: linearized RTA solution; PTB: positive-definite exponential ansatz).</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_characteristics</strong></td>
                            <td>Includes different viscous correction treatments at particlization: Grad (polynomial expansion), CE (RTA linearization), PTB (exponential ansatz guaranteeing positive distributions); choice affects hadronic yields and spectra and thus emulator behavior.</td>
                        </tr>
                        <tr>
                            <td><strong>model_or_agent_name</strong></td>
                            <td>Particlization module within full-model pipeline</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Physics-based sampler; multiple algorithmic variants for viscous corrections used as distinct model variants (treated as separate targets in transfer experiments).</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task</strong></td>
                            <td>Provide final-state particle distributions for hadronic afterburner and observables used in emulator training; differences between these variants are a primary axis for transfer-learning experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>training_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>transfer_target</strong></td>
                            <td>Transfer learning between particlization variants: source = Grad particlization; targets = CE and PTB particlization models in Pb+Pb collisions.</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_performance</strong></td>
                            <td>TL performance varied by variant: for CE target TL performed extremely well (needed ≈35 target training points to reach within 10% of asymptotic MSE; good even down to 5 points); for PTB target TL provided improved performance over GP but required more target points before advantage diminished (~60% of n_max).</td>
                        </tr>
                        <tr>
                            <td><strong>compares_fidelity_levels</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_comparison_results</strong></td>
                            <td>Different viscous-correction prescriptions represent different modeling approximations rather than formal low/high fidelity; CE and Grad were qualitatively very similar (hence high TL efficacy) while PTB differed more (less TL advantage but still beneficial).</td>
                        </tr>
                        <tr>
                            <td><strong>minimal_fidelity_discussion</strong></td>
                            <td>Paper implies that when source and target share close qualitative trends (as for Grad↔CE) very little target data are needed; no formal minimal fidelity threshold is given.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_cases</strong></td>
                            <td>No explicit failures, but TL advantage shrinks when model differences are larger (e.g., PTB case required more target training to reach similar accuracy).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Efficient emulation of relativistic heavy ion collisions with transfer learning', 'publication_date_yy_mm': '2022-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1528.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e1528.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of simulators used for training models or agents on scientific reasoning tasks (especially in thermodynamics, circuits, or biology), including details about simulator fidelity levels and transfer performance to real-world or different contexts.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>SMASH</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>SMASH hadronic transport code</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A microscopic Boltzmann transport code used to model hadronic decays and rescatterings after particlization in the simulation pipeline.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>simulator_name</strong></td>
                            <td>SMASH</td>
                        </tr>
                        <tr>
                            <td><strong>simulator_description</strong></td>
                            <td>Microscopic hadronic afterburner that propagates produced hadrons through rescatterings and decays using Boltzmann transport; contributes the majority (~80%) of CPU time per design point in these simulations.</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>microscopic transport / hadronic physics</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_level</strong></td>
                            <td>high-fidelity microscopic transport for hadronic stage (many resonance channels, scattering processes, and decays modeled explicitly)</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_characteristics</strong></td>
                            <td>Includes hadronic rescattering and decay channels, detailed microscopic interactions; computationally demanding and dominant in CPU cost.</td>
                        </tr>
                        <tr>
                            <td><strong>model_or_agent_name</strong></td>
                            <td>Hadronic afterburner module within full-model pipeline</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Physics-based Boltzmann solver; not a learned agent here.</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task</strong></td>
                            <td>Model final-state hadronic interactions to produce observables for emulator training.</td>
                        </tr>
                        <tr>
                            <td><strong>training_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>transfer_target</strong></td>
                            <td>Same as above (target collision systems, particlization variants); difference in hadronic stage cost influences overall computational savings from TL.</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>compares_fidelity_levels</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_comparison_results</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>minimal_fidelity_discussion</strong></td>
                            <td>Authors note 80% of CPU time is used here; thus reducing required target design points via TL directly yields large CPU savings because SMASH-dominated cost per design point is high.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_cases</strong></td>
                            <td>None reported.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Efficient emulation of relativistic heavy ion collisions with transfer learning', 'publication_date_yy_mm': '2022-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1528.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e1528.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of simulators used for training models or agents on scientific reasoning tasks (especially in thermodynamics, circuits, or biology), including details about simulator fidelity levels and transfer performance to real-world or different contexts.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Gaussian Process (GP) emulators</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Gaussian Process surrogate emulators</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Standard non-parametric GP emulators used to approximate expensive full-model simulator outputs across parameter space, providing mean predictions and predictive uncertainties for Bayesian inference.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>simulator_name</strong></td>
                            <td>Gaussian Process emulator</td>
                        </tr>
                        <tr>
                            <td><strong>simulator_description</strong></td>
                            <td>A probabilistic interpolator (squared-exponential kernel used) producing posterior mean and variance for simulator outputs conditioned on training data; used per-observable as surrogate in Bayesian calibration.</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>statistical emulation / surrogate modeling for scientific simulations</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_level</strong></td>
                            <td>n/a (statistical surrogate approximating high-fidelity simulator outputs)</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_characteristics</strong></td>
                            <td>Provides uncertainty quantification for interpolation; trained on limited sets (typically hundreds) of full-model runs; predictive quality depends on number and spread of design points.</td>
                        </tr>
                        <tr>
                            <td><strong>model_or_agent_name</strong></td>
                            <td>GP emulator (per-observable)</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Gaussian Process regression with anisotropic squared-exponential covariance, hyperparameters fit by maximum likelihood; plug-in predictive equations used.</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task</strong></td>
                            <td>Interpolate simulator outputs for use in likelihood evaluation and MCMC sampling (Bayesian parameter estimation); quantify emulator uncertainty to include in total uncertainty budget.</td>
                        </tr>
                        <tr>
                            <td><strong>training_performance</strong></td>
                            <td>Standard GP trained on target alone requires many target design points (up to 473 in the study) to reach asymptotic MSE; for small n GP has significantly higher MSE than TL (e.g., for n=47 in Au+Au example GP had ~2x the MSE of TL).</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_target</strong></td>
                            <td>N/A (GP is baseline surrogate for target simulator)</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>compares_fidelity_levels</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_comparison_results</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>minimal_fidelity_discussion</strong></td>
                            <td>No explicit minimal-fidelity discussion; GP performance dependent on density and coverage of training design points.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_cases</strong></td>
                            <td>GP emulators trained with very small target datasets perform poorly compared to TL when a related source simulator is available.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Efficient emulation of relativistic heavy ion collisions with transfer learning', 'publication_date_yy_mm': '2022-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1528.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e1528.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of simulators used for training models or agents on scientific reasoning tasks (especially in thermodynamics, circuits, or biology), including details about simulator fidelity levels and transfer performance to real-world or different contexts.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Transfer-learning emulator (KO-style)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Transfer learning emulator based on an additive Kennedy–O'Hagan (KO) style GP model</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A transfer-learning emulation approach that models the target simulator as f_T(x)=ρ f_S(x)+δ(x) with GPs on source and discrepancy, enabling reuse of a costly source emulator to reduce target training needs and to analyze systematic differences via the discrepancy GP.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>here</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>simulator_name</strong></td>
                            <td>Transfer-learning GP emulator (additive KO-like model)</td>
                        </tr>
                        <tr>
                            <td><strong>simulator_description</strong></td>
                            <td>A multifidelity/transfer emulator where the known source emulator prediction is scaled by a learned correlation coefficient ρ and corrected by a GP-modeled discrepancy δ(x); hyperparameters estimated by maximum likelihood and predictive equations derived in closed form.</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>statistical emulation / domain adaptation for scientific simulations</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_level</strong></td>
                            <td>n/a (statistical transfer model leveraging high-fidelity source emulator to emulate related target simulations with fewer target runs)</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_characteristics</strong></td>
                            <td>Models linear correlation plus flexible discrepancy GP; retains uncertainty quantification; requires source and target to share parameterization; allows sensitivity analysis on δ(x) (Sobol indices) to identify parameter groups responsible for differences.</td>
                        </tr>
                        <tr>
                            <td><strong>model_or_agent_name</strong></td>
                            <td>Transfer-learning GP emulator</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Additive GP model: f_T(x)=ρ f_S(x)+δ(x), where f_S and δ are independent GPs with their own kernels/hyperparameters; ρ and GP hyperparameters fit by maximum likelihood; closed-form predictive mean/variance used for emulation.</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task</strong></td>
                            <td>Learn parameter-to-observable mappings for a target simulator while leveraging a previously trained source emulator; reduce number of costly full-model target runs required for accurate emulation; enable discrepancy-based sensitivity analyses.</td>
                        </tr>
                        <tr>
                            <td><strong>training_performance</strong></td>
                            <td>Demonstrated strong empirical benefits: for Au+Au target using Pb+Pb source, TL reduced required target training points by roughly a factor of two to reach within 10% of asymptotic MSE; for CE particlization TL reached within 10% of asymptotic MSE with ≈35 target points and gave useful accuracy down to ≈5 points. Exact MSE numbers not tabulated in paper (plots reported).</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_target</strong></td>
                            <td>Targets are other simulation variants or collision systems (e.g., different center-of-mass energy collisions or different particlization viscous-correction models); downstream target also includes Bayesian inference tasks and sensitivity analyses.</td>
                        </tr>
                        <tr>
                            <td><strong>transfer_performance</strong></td>
                            <td>Empirically the TL emulator consistently outperformed the standard GP when target training data are scarce. Quantified examples: ~2× MSE reduction at n=47 for Au+Au target; ~3× or more MSE reduction for some particlization-target cases at n~50; TL advantage reduced as n approaches full training set (≈473).</td>
                        </tr>
                        <tr>
                            <td><strong>compares_fidelity_levels</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_comparison_results</strong></td>
                            <td>Not a fidelity comparison study per se; rather, TL effectiveness depends on similarity between source and target models: greatest savings when qualitative trends are very close (Grad↔CE), reduced but still useful when differences are larger (Grad↔PTB, or large energy changes).</td>
                        </tr>
                        <tr>
                            <td><strong>minimal_fidelity_discussion</strong></td>
                            <td>No formal minimal fidelity specification; pragmatic guidance: TL performs well when source and target share qualitative trends in observables and use identical parameterizations; authors note requirement that source and target share same set of parameters.</td>
                        </tr>
                        <tr>
                            <td><strong>failure_cases</strong></td>
                            <td>No explicit failure cases, but the paper notes diminishing returns for TL when many target training points are available (>~60% of n_max) and reduced TL advantage when source and target are less similar (e.g., some particlization variants).</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Efficient emulation of relativistic heavy ion collisions with transfer learning', 'publication_date_yy_mm': '2022-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e1528.8">
                <h3 class="extraction-instance">Extracted Data Instance 8 (e1528.8)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of simulators used for training models or agents on scientific reasoning tasks (especially in thermodynamics, circuits, or biology), including details about simulator fidelity levels and transfer performance to real-world or different contexts.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>EMUKIT</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Emukit emulation toolkit</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A software package used to implement the transfer-learning emulator and to manage emulator training and active learning; used by the authors to implement the transfer learning emulation pipelines.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>simulator_name</strong></td>
                            <td>EMUKIT (software package)</td>
                        </tr>
                        <tr>
                            <td><strong>simulator_description</strong></td>
                            <td>A Python toolbox for emulation and Bayesian optimization, enabling construction and evaluation of surrogate models including GPs and related active-learning workflows; used here to implement transfer-learning emulators.</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>software / statistical emulation tooling</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_level</strong></td>
                            <td>n/a (software tool)</td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_characteristics</strong></td>
                            <td>Provides implementations of emulators/active learning algorithms; used as the implementation backbone for experiments.</td>
                        </tr>
                        <tr>
                            <td><strong>model_or_agent_name</strong></td>
                            <td>EMUKIT-based implementations of GP and transfer-learning emulators</td>
                        </tr>
                        <tr>
                            <td><strong>model_description</strong></td>
                            <td>Software-level implementation of GP regression and the KO-like transfer model described in the paper.</td>
                        </tr>
                        <tr>
                            <td><strong>reasoning_task</strong></td>
                            <td>Tooling to train emulators that approximate simulator outputs for Bayesian calibration tasks.</td>
                        </tr>
                        <tr>
                            <td><strong>training_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>transfer_target</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>transfer_performance</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>compares_fidelity_levels</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>fidelity_comparison_results</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>minimal_fidelity_discussion</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>failure_cases</strong></td>
                            <td></td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Efficient emulation of relativistic heavy ion collisions with transfer learning', 'publication_date_yy_mm': '2022-01'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Multisystem Bayesian constraints on the transport coefficients of QCD matter <em>(Rating: 2)</em></li>
                <li>Phenomenological constraints on the transport properties of QCD matter with data-driven model averaging <em>(Rating: 2)</em></li>
                <li>Predicting the output from a complex computer code when fast approximations are available <em>(Rating: 2)</em></li>
                <li>Emulation of physical processes with emukit <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-1528",
    "paper_id": "paper-29114ac517348c33ae66185c802c7fcefacd9705",
    "extraction_schema_id": "extraction-schema-29",
    "extracted_data": [
        {
            "name_short": "JETSCAPE full-model pipeline",
            "name_full": "JETSCAPE multistage heavy ion collision simulation framework (full-model pipeline used in this work)",
            "brief_description": "A multistage, high-fidelity simulation pipeline for relativistic heavy ion collisions combining initial-state, pre-equilibrium, viscous hydrodynamics, particlization, and hadronic transport modules; used to generate costly training data for emulators in this paper.",
            "citation_title": "",
            "mention_or_use": "use",
            "simulator_name": "JETSCAPE full-model pipeline",
            "simulator_description": "A composed simulator built from modules (T_R ENTo initial energy deposition, a freestreaming pre-equilibrium stage, MUSIC viscous hydrodynamics, iS3D particlization sampler with different viscous-correction options, and SMASH hadronic transport/afterburner). Produces observables (multiplicities, mean pT, flow coefficients, etc.) with stochastic event-by-event fluctuations.",
            "scientific_domain": "fluid dynamics / high-energy nuclear physics (quark-gluon plasma phenomenology)",
            "fidelity_level": "high-fidelity multistage physics simulation (end-to-end modeling of heavy-ion collisions across stages: initial state → pre-equilibrium → viscous hydrodynamics → particlization → hadronic transport)",
            "fidelity_characteristics": "Includes fluctuating initial conditions (stochastic event ensembles), viscous relativistic hydrodynamics (MUSIC), explicit particlization algorithms (iS3D) with multiple viscous-correction models, and microscopic hadronic rescattering/decays via SMASH; computationally expensive (O(1000) CPU-hours per design point on average) and produces per-design-point ensembles (2500 event realizations per design-point were used to compute means/errors).",
            "model_or_agent_name": "Gaussian Process emulators / transfer-learning emulators trained on JETSCAPE outputs",
            "model_description": "Surrogate emulators: (i) standard Gaussian Process (GP) emulators per observable; (ii) a transfer learning emulator built as an additive KO-like model f_T(x)=ρ f_S(x)+δ(x) with GPs on f_S and δ.",
            "reasoning_task": "Emulate simulator outputs (observables) across a 17-dimensional parameter space for Bayesian parameter estimation and sensitivity analysis of QGP properties; enable fast likelihood evaluations for MCMC-based inference.",
            "training_performance": "Source training used m=473 design points (each design point summarized from 2500 simulated events) and test evaluation used 100 held-out design points; standard GP emulators trained on the target alone reach an asymptotic MSE (not numerically tabulated) using all 473 target points. Transfer-learning emulators reached similar or better MSE with far fewer target training points (e.g., for Au+Au target, TL achieved comparable accuracy with roughly half the target training points; for some particlization changes TL required ≈35 target points to reach within 10% of asymptotic accuracy).",
            "transfer_target": "Different collision systems (e.g., Pb+Pb at 2.76 TeV → Au+Au at 0.2 TeV) and different model variants (different particlization viscous-correction schemes: Grad ↔ CE ↔ PTB); ultimately used within downstream Bayesian parameter inference and sensitivity analyses.",
            "transfer_performance": "Qualitative/numeric statements: TL reduced MSE relative to GP for small n (example: at n=47 target points, TL had ~50% of the MSE of GP for Au+Au target); for CE particlization TL reached within 10% of asymptotic MSE with only 35 target points and remained useful down to as few as 5 points; computational savings translate to large CPU-hour reductions because full-model runs cost ~O(1000) CPU-hours each.",
            "compares_fidelity_levels": false,
            "fidelity_comparison_results": "",
            "minimal_fidelity_discussion": "No explicit claim of a minimum simulator fidelity required for successful transfer; paper requires same parameterization between source and target and notes TL works best when source and target share qualitative trends.",
            "failure_cases": "No explicit catastrophic failures reported; authors note TL advantage diminishes once a large fraction (~60%+) of target training points are used. TL is less beneficial when source and target differ substantially, though still beneficial in studied cases (e.g., different collision energy vs different particlization models show varying degrees of TL benefit).",
            "uuid": "e1528.0",
            "source_info": {
                "paper_title": "Efficient emulation of relativistic heavy ion collisions with transfer learning",
                "publication_date_yy_mm": "2022-01"
            }
        },
        {
            "name_short": "T_R ENTo",
            "name_full": "T_R ENTo initial energy deposition model",
            "brief_description": "A phenomenological initial-state model that parametrizes deposited energy density immediately after nuclear impact; used as the initial-conditions module in the full-model pipeline.",
            "citation_title": "",
            "mention_or_use": "use",
            "simulator_name": "T_R ENTo",
            "simulator_description": "Initial-state generator producing spatial initial energy/entropy density profiles with tunable parameters (including a normalization N and parameters controlling granularity), used to seed hydrodynamic evolution.",
            "scientific_domain": "initial conditions / high-energy nuclear physics",
            "fidelity_level": "medium-to-high fidelity phenomenological initial-state model (captures event-by-event geometric fluctuations and parameterized physics for heavy-ion collisions)",
            "fidelity_characteristics": "Models spatial fluctuations and normalization; parameterized granularity and other shape parameters; stochastic (event-by-event) realizations used to produce ensemble-averaged observables.",
            "model_or_agent_name": "Used as a module within the full-model simulator pipeline",
            "model_description": "Deterministic/stochastic physics-based initial-condition generator (not a learned agent in this work).",
            "reasoning_task": "Provide initial conditions for hydrodynamic simulations; influences multiplicities, flow observables, and sensitivities analyzed by emulators.",
            "training_performance": null,
            "transfer_target": "Other collision systems and particlization/hydrodynamic variants via transfer of emulator knowledge",
            "transfer_performance": null,
            "compares_fidelity_levels": false,
            "fidelity_comparison_results": "",
            "minimal_fidelity_discussion": "No explicit minimal fidelity discussion specific to T_R ENTo; discrepancy GP sensitivity analysis shows normalization N and T_R ENTo parameters are important for transfer differences between systems.",
            "failure_cases": "Not reported; sensitivity analysis revealed T_R ENTo parameters drive differences in some observables (e.g., v2 sensitivity), indicating their critical role for transfer accuracy.",
            "uuid": "e1528.1",
            "source_info": {
                "paper_title": "Efficient emulation of relativistic heavy ion collisions with transfer learning",
                "publication_date_yy_mm": "2022-01"
            }
        },
        {
            "name_short": "Freestreaming model",
            "name_full": "Freestreaming pre-equilibrium model",
            "brief_description": "A simple pre-equilibrium stage model that approximates the earliest weakly-coupled dynamics by free streaming for a tunable time before hydrodynamic evolution starts.",
            "citation_title": "",
            "mention_or_use": "use",
            "simulator_name": "Freestreaming module (freestream-milne repository referenced)",
            "simulator_description": "Approximates pre-equilibrium evolution by free-streaming of energy density for a model-dependent duration; parameterizes the free-streaming time as an input.",
            "scientific_domain": "pre-equilibrium dynamics / high-energy nuclear physics",
            "fidelity_level": "medium-fidelity approximation for early-time dynamics (simplified weak-coupling free-streaming instead of a full kinetic-theory evolution)",
            "fidelity_characteristics": "Simplified dynamics: neglects interactions during the pre-equilibrium interval except via free streaming; parameterized free-streaming duration controls early radial/anisotropic flow buildup.",
            "model_or_agent_name": "Used as the pre-equilibrium module in full-model simulations",
            "model_description": "Physics-based module (not learned agent); parameter(s) control duration of free-streaming.",
            "reasoning_task": "Model early-time evolution to set conditions for viscous hydrodynamics; contributes to observables emulated and to discrepancy sensitivity between systems.",
            "training_performance": null,
            "transfer_target": "Target collision systems and particlization models via emulator transfer",
            "transfer_performance": null,
            "compares_fidelity_levels": false,
            "fidelity_comparison_results": "",
            "minimal_fidelity_discussion": "Paper notes discrepancy GPs for some observables are sensitive to pre-equilibrium parameters, implying that pre-equilibrium fidelity can matter for transfer between collision energies.",
            "failure_cases": "Not explicitly reported; differences in pre-equilibrium modeling contribute to discrepancy and affect transfer efficiency between energies.",
            "uuid": "e1528.2",
            "source_info": {
                "paper_title": "Efficient emulation of relativistic heavy ion collisions with transfer learning",
                "publication_date_yy_mm": "2022-01"
            }
        },
        {
            "name_short": "MUSIC",
            "name_full": "MUSIC relativistic viscous hydrodynamics code",
            "brief_description": "A 3+1D viscous hydrodynamic solver used to model the near-equilibrium QGP evolution stage in the multistage simulation pipeline.",
            "citation_title": "",
            "mention_or_use": "use",
            "simulator_name": "MUSIC",
            "simulator_description": "A relativistic viscous hydrodynamics code that evolves energy-momentum tensors with shear and bulk viscosity parameterizations and supplies fluid output at particlization.",
            "scientific_domain": "viscous hydrodynamics / fluid dynamics in heavy-ion collisions",
            "fidelity_level": "high-fidelity hydrodynamic evolution (3+1D viscous hydrodynamics with temperature-dependent transport coefficients)",
            "fidelity_characteristics": "Models dissipative hydrodynamic evolution including shear and bulk viscosities as parameterized functions of temperature; numerically resolves spacetime evolution until a switching temperature T_sw.",
            "model_or_agent_name": "Hydrodynamic module within full-model pipeline",
            "model_description": "Physics-based PDE solver; not a learned agent in this work.",
            "reasoning_task": "Predict evolution of QGP and map initial-state inputs to fluid variables at particlization, affecting final-state observables emulated.",
            "training_performance": null,
            "transfer_target": "Other model variants and collision systems as part of emulator transfer",
            "transfer_performance": null,
            "compares_fidelity_levels": false,
            "fidelity_comparison_results": "",
            "minimal_fidelity_discussion": "No explicit minimal fidelity claims, but sensitivity analysis indicates viscosities modeled in MUSIC are relevant to discrepancy in some observables across systems.",
            "failure_cases": "None reported.",
            "uuid": "e1528.3",
            "source_info": {
                "paper_title": "Efficient emulation of relativistic heavy ion collisions with transfer learning",
                "publication_date_yy_mm": "2022-01"
            }
        },
        {
            "name_short": "iS3D",
            "name_full": "iS3D particlization sampler",
            "brief_description": "A particlization/sampling module that converts fluid output to particles using the Cooper-Frye prescription and implements different viscous correction ansätze (Grad, Chapman–Enskog, PTB).",
            "citation_title": "",
            "mention_or_use": "use",
            "simulator_name": "iS3D sampler",
            "simulator_description": "Sampler implementing Cooper-Frye particlization with multiple viscous-correction models (Grad, Chapman–Enskog (CE), Pratt–Torrieri–Bernhard (PTB) implementations) to generate hadronic distributions at switching temperature.",
            "scientific_domain": "particlization / hadronization modeling in heavy-ion collisions",
            "fidelity_level": "module-level fidelity varies by viscous-correction model: different approximations to out-of-equilibrium distribution functions (Grad: second-order expansion; CE: linearized RTA solution; PTB: positive-definite exponential ansatz).",
            "fidelity_characteristics": "Includes different viscous correction treatments at particlization: Grad (polynomial expansion), CE (RTA linearization), PTB (exponential ansatz guaranteeing positive distributions); choice affects hadronic yields and spectra and thus emulator behavior.",
            "model_or_agent_name": "Particlization module within full-model pipeline",
            "model_description": "Physics-based sampler; multiple algorithmic variants for viscous corrections used as distinct model variants (treated as separate targets in transfer experiments).",
            "reasoning_task": "Provide final-state particle distributions for hadronic afterburner and observables used in emulator training; differences between these variants are a primary axis for transfer-learning experiments.",
            "training_performance": null,
            "transfer_target": "Transfer learning between particlization variants: source = Grad particlization; targets = CE and PTB particlization models in Pb+Pb collisions.",
            "transfer_performance": "TL performance varied by variant: for CE target TL performed extremely well (needed ≈35 target training points to reach within 10% of asymptotic MSE; good even down to 5 points); for PTB target TL provided improved performance over GP but required more target points before advantage diminished (~60% of n_max).",
            "compares_fidelity_levels": false,
            "fidelity_comparison_results": "Different viscous-correction prescriptions represent different modeling approximations rather than formal low/high fidelity; CE and Grad were qualitatively very similar (hence high TL efficacy) while PTB differed more (less TL advantage but still beneficial).",
            "minimal_fidelity_discussion": "Paper implies that when source and target share close qualitative trends (as for Grad↔CE) very little target data are needed; no formal minimal fidelity threshold is given.",
            "failure_cases": "No explicit failures, but TL advantage shrinks when model differences are larger (e.g., PTB case required more target training to reach similar accuracy).",
            "uuid": "e1528.4",
            "source_info": {
                "paper_title": "Efficient emulation of relativistic heavy ion collisions with transfer learning",
                "publication_date_yy_mm": "2022-01"
            }
        },
        {
            "name_short": "SMASH",
            "name_full": "SMASH hadronic transport code",
            "brief_description": "A microscopic Boltzmann transport code used to model hadronic decays and rescatterings after particlization in the simulation pipeline.",
            "citation_title": "",
            "mention_or_use": "use",
            "simulator_name": "SMASH",
            "simulator_description": "Microscopic hadronic afterburner that propagates produced hadrons through rescatterings and decays using Boltzmann transport; contributes the majority (~80%) of CPU time per design point in these simulations.",
            "scientific_domain": "microscopic transport / hadronic physics",
            "fidelity_level": "high-fidelity microscopic transport for hadronic stage (many resonance channels, scattering processes, and decays modeled explicitly)",
            "fidelity_characteristics": "Includes hadronic rescattering and decay channels, detailed microscopic interactions; computationally demanding and dominant in CPU cost.",
            "model_or_agent_name": "Hadronic afterburner module within full-model pipeline",
            "model_description": "Physics-based Boltzmann solver; not a learned agent here.",
            "reasoning_task": "Model final-state hadronic interactions to produce observables for emulator training.",
            "training_performance": null,
            "transfer_target": "Same as above (target collision systems, particlization variants); difference in hadronic stage cost influences overall computational savings from TL.",
            "transfer_performance": null,
            "compares_fidelity_levels": false,
            "fidelity_comparison_results": "",
            "minimal_fidelity_discussion": "Authors note 80% of CPU time is used here; thus reducing required target design points via TL directly yields large CPU savings because SMASH-dominated cost per design point is high.",
            "failure_cases": "None reported.",
            "uuid": "e1528.5",
            "source_info": {
                "paper_title": "Efficient emulation of relativistic heavy ion collisions with transfer learning",
                "publication_date_yy_mm": "2022-01"
            }
        },
        {
            "name_short": "Gaussian Process (GP) emulators",
            "name_full": "Gaussian Process surrogate emulators",
            "brief_description": "Standard non-parametric GP emulators used to approximate expensive full-model simulator outputs across parameter space, providing mean predictions and predictive uncertainties for Bayesian inference.",
            "citation_title": "",
            "mention_or_use": "use",
            "simulator_name": "Gaussian Process emulator",
            "simulator_description": "A probabilistic interpolator (squared-exponential kernel used) producing posterior mean and variance for simulator outputs conditioned on training data; used per-observable as surrogate in Bayesian calibration.",
            "scientific_domain": "statistical emulation / surrogate modeling for scientific simulations",
            "fidelity_level": "n/a (statistical surrogate approximating high-fidelity simulator outputs)",
            "fidelity_characteristics": "Provides uncertainty quantification for interpolation; trained on limited sets (typically hundreds) of full-model runs; predictive quality depends on number and spread of design points.",
            "model_or_agent_name": "GP emulator (per-observable)",
            "model_description": "Gaussian Process regression with anisotropic squared-exponential covariance, hyperparameters fit by maximum likelihood; plug-in predictive equations used.",
            "reasoning_task": "Interpolate simulator outputs for use in likelihood evaluation and MCMC sampling (Bayesian parameter estimation); quantify emulator uncertainty to include in total uncertainty budget.",
            "training_performance": "Standard GP trained on target alone requires many target design points (up to 473 in the study) to reach asymptotic MSE; for small n GP has significantly higher MSE than TL (e.g., for n=47 in Au+Au example GP had ~2x the MSE of TL).",
            "transfer_target": "N/A (GP is baseline surrogate for target simulator)",
            "transfer_performance": null,
            "compares_fidelity_levels": false,
            "fidelity_comparison_results": "",
            "minimal_fidelity_discussion": "No explicit minimal-fidelity discussion; GP performance dependent on density and coverage of training design points.",
            "failure_cases": "GP emulators trained with very small target datasets perform poorly compared to TL when a related source simulator is available.",
            "uuid": "e1528.6",
            "source_info": {
                "paper_title": "Efficient emulation of relativistic heavy ion collisions with transfer learning",
                "publication_date_yy_mm": "2022-01"
            }
        },
        {
            "name_short": "Transfer-learning emulator (KO-style)",
            "name_full": "Transfer learning emulator based on an additive Kennedy–O'Hagan (KO) style GP model",
            "brief_description": "A transfer-learning emulation approach that models the target simulator as f_T(x)=ρ f_S(x)+δ(x) with GPs on source and discrepancy, enabling reuse of a costly source emulator to reduce target training needs and to analyze systematic differences via the discrepancy GP.",
            "citation_title": "here",
            "mention_or_use": "use",
            "simulator_name": "Transfer-learning GP emulator (additive KO-like model)",
            "simulator_description": "A multifidelity/transfer emulator where the known source emulator prediction is scaled by a learned correlation coefficient ρ and corrected by a GP-modeled discrepancy δ(x); hyperparameters estimated by maximum likelihood and predictive equations derived in closed form.",
            "scientific_domain": "statistical emulation / domain adaptation for scientific simulations",
            "fidelity_level": "n/a (statistical transfer model leveraging high-fidelity source emulator to emulate related target simulations with fewer target runs)",
            "fidelity_characteristics": "Models linear correlation plus flexible discrepancy GP; retains uncertainty quantification; requires source and target to share parameterization; allows sensitivity analysis on δ(x) (Sobol indices) to identify parameter groups responsible for differences.",
            "model_or_agent_name": "Transfer-learning GP emulator",
            "model_description": "Additive GP model: f_T(x)=ρ f_S(x)+δ(x), where f_S and δ are independent GPs with their own kernels/hyperparameters; ρ and GP hyperparameters fit by maximum likelihood; closed-form predictive mean/variance used for emulation.",
            "reasoning_task": "Learn parameter-to-observable mappings for a target simulator while leveraging a previously trained source emulator; reduce number of costly full-model target runs required for accurate emulation; enable discrepancy-based sensitivity analyses.",
            "training_performance": "Demonstrated strong empirical benefits: for Au+Au target using Pb+Pb source, TL reduced required target training points by roughly a factor of two to reach within 10% of asymptotic MSE; for CE particlization TL reached within 10% of asymptotic MSE with ≈35 target points and gave useful accuracy down to ≈5 points. Exact MSE numbers not tabulated in paper (plots reported).",
            "transfer_target": "Targets are other simulation variants or collision systems (e.g., different center-of-mass energy collisions or different particlization viscous-correction models); downstream target also includes Bayesian inference tasks and sensitivity analyses.",
            "transfer_performance": "Empirically the TL emulator consistently outperformed the standard GP when target training data are scarce. Quantified examples: ~2× MSE reduction at n=47 for Au+Au target; ~3× or more MSE reduction for some particlization-target cases at n~50; TL advantage reduced as n approaches full training set (≈473).",
            "compares_fidelity_levels": false,
            "fidelity_comparison_results": "Not a fidelity comparison study per se; rather, TL effectiveness depends on similarity between source and target models: greatest savings when qualitative trends are very close (Grad↔CE), reduced but still useful when differences are larger (Grad↔PTB, or large energy changes).",
            "minimal_fidelity_discussion": "No formal minimal fidelity specification; pragmatic guidance: TL performs well when source and target share qualitative trends in observables and use identical parameterizations; authors note requirement that source and target share same set of parameters.",
            "failure_cases": "No explicit failure cases, but the paper notes diminishing returns for TL when many target training points are available (&gt;~60% of n_max) and reduced TL advantage when source and target are less similar (e.g., some particlization variants).",
            "uuid": "e1528.7",
            "source_info": {
                "paper_title": "Efficient emulation of relativistic heavy ion collisions with transfer learning",
                "publication_date_yy_mm": "2022-01"
            }
        },
        {
            "name_short": "EMUKIT",
            "name_full": "Emukit emulation toolkit",
            "brief_description": "A software package used to implement the transfer-learning emulator and to manage emulator training and active learning; used by the authors to implement the transfer learning emulation pipelines.",
            "citation_title": "",
            "mention_or_use": "use",
            "simulator_name": "EMUKIT (software package)",
            "simulator_description": "A Python toolbox for emulation and Bayesian optimization, enabling construction and evaluation of surrogate models including GPs and related active-learning workflows; used here to implement transfer-learning emulators.",
            "scientific_domain": "software / statistical emulation tooling",
            "fidelity_level": "n/a (software tool)",
            "fidelity_characteristics": "Provides implementations of emulators/active learning algorithms; used as the implementation backbone for experiments.",
            "model_or_agent_name": "EMUKIT-based implementations of GP and transfer-learning emulators",
            "model_description": "Software-level implementation of GP regression and the KO-like transfer model described in the paper.",
            "reasoning_task": "Tooling to train emulators that approximate simulator outputs for Bayesian calibration tasks.",
            "training_performance": null,
            "transfer_target": null,
            "transfer_performance": null,
            "compares_fidelity_levels": null,
            "fidelity_comparison_results": "",
            "minimal_fidelity_discussion": "",
            "failure_cases": "",
            "uuid": "e1528.8",
            "source_info": {
                "paper_title": "Efficient emulation of relativistic heavy ion collisions with transfer learning",
                "publication_date_yy_mm": "2022-01"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Multisystem Bayesian constraints on the transport coefficients of QCD matter",
            "rating": 2
        },
        {
            "paper_title": "Phenomenological constraints on the transport properties of QCD matter with data-driven model averaging",
            "rating": 2
        },
        {
            "paper_title": "Predicting the output from a complex computer code when fast approximations are available",
            "rating": 2
        },
        {
            "paper_title": "Emulation of physical processes with emukit",
            "rating": 1
        }
    ],
    "cost": 0.01899225,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>Efficient emulation of relativistic heavy ion collisions with transfer learning</h1>
<p>D. Liyanage, ${ }^{1}$ Y. Ji, ${ }^{2}$ D. Everett, ${ }^{1}$ M. Heffernan, ${ }^{3}$ U. Heinz, ${ }^{1}$ S. Mak, ${ }^{2}$ and J.-F. Paquet ${ }^{4}$<br>${ }^{1}$ Department of Physics, The Ohio State University, Columbus OH 43210.<br>${ }^{2}$ Department of Statistical Science, Duke University, Durham NC 27708.<br>${ }^{3}$ Department of Physics, McGill University, Montréal QC H3A 2T8, Canada.<br>${ }^{4}$ Department of Physics, Duke University, Durham NC 27708.</p>
<h4>Abstract</h4>
<p>Measurements from the Large Hadron Collider (LHC) and the Relativistic Heavy Ion Collider (RHIC) can be used to study the properties of quark-gluon plasma. Systematic constraints on these properties must combine measurements from different collision systems and methodically account for experimental and theoretical uncertainties. Such studies require a vast number of costly numerical simulations. While computationally inexpensive surrogate models ("emulators") can be used to efficiently approximate the predictions of heavy ion simulations across a broad range of model parameters, training a reliable emulator remains a computationally expensive task. We use transfer learning to map the parameter dependencies of one model emulator onto another, leveraging similarities between different simulations of heavy ion collisions. By limiting the need for large numbers of simulations to only one of the emulators, this technique reduces the numerical cost of comprehensive uncertainty quantification when studying multiple collision systems and exploring different models.</p>
<h2>I. INTRODUCTION</h2>
<p>The RHIC and LHC collider facilities create nuclear matter under extreme conditions by colliding heavy nuclei at relativistic velocities. These high energy collisions melt the nuclei and create a strongly interacting, exotic phase of nuclear matter called quark-gluon plasma (QGP) [1]. The QGP filled the universe microseconds after the Big Bang, before it cooled down to produce atomic hydrogen, helium and other light atomic nuclei that we observe in the universe today [2]. Due to its extremely short lifetime $\left(\sim 10^{-23} \mathrm{~s}\right)$ and size $\left(\sim 10^{-14} \mathrm{~m}\right)$, the QGP created in relativistic heavy ion collisions cannot be observed directly; it can only be studied through the final particles it emits.</p>
<p>Modeling of relativistic nuclear collisions is a challenge that involves a succession of phases of many-body nuclear physics with different degrees of freedom; the QGP is only one of them. Realistic numerical simulations of such collisions have many physical parameters that are related to the properties of this QGP. To constrain these properties, one must effectively solve the inverse problem, i.e. find the model parameters, including their uncertainties, for which simulated observables agree well with the experimental data.</p>
<p>Relativistic heavy ion collision experiments have accumulated a vast body of measurements and are continuing to do so. These experimental data vary widely in the size of their uncertainties, which can also have non-trivial correlations. Theoretical simulations add additional uncertainties to the error budget, of two different types: statistical (aleatoric) uncertainties from measuring a finite number of samples from a stochastic process, and systematic (epistemic) uncertainties arising from imperfect modeling of the (not yet fully understood or only approximately implemented) physics underlying the dynamical evolution process. These experimental and theoretical uncertainties limit the precision with which the desired model parameters can be inferred.</p>
<p>Bayesian inference or Bayesian parameter estimation is a modern statistical method that provides a way to reliably infer the properties of QGP, by accounting methodically for both theoretical and experimental uncertainties. Tremendous progress has been made in the study of relativistic heavy ion collisions over the past decade by providing increasingly reliable constraints and error estimates for the properties of QGP using Bayesian statistical techniques [3-14]. As both the model and data have uncertainties, comparing them results in a probability distribution for the model parameters, specifying the probability for a model with a given set of parameters to provide predictions that agree with the experimental observations. A single model with $n$ parameters will have an $n$-dimensional probability distribution, called in brief "the posterior", describing its agreement with a set of measurements. For a class of competing models, the dimensionality of model parameter space increases accordingly. Bayesian uncertainty quantification depends on the ability to accurately sample this posterior probability distribution, which is generally not known analytically [15]. Markov Chain Monte Carlo (MCMC) techniques provide such sampling methods [16]. They are practical only if fast approximations of otherwise expensive computer simulations are available. Emulation with surrogate models has thus become an essential component in any Bayesian inference involving a computationally expensive likelihood function.</p>
<p>Emulators are machine learning models that provide a computationally efficient prediction of the simulator over the parameter space when trained on a sparse set of full simulation data. While a modeler can choose from a wide range of learning models (e.g., linear regression, decision trees, neural networks) as surrogates for expensive simulations, the standard practice in relativistic nuclear physics [4-14] has been to use Gaussian Process (GP) emulators [17]. There are two reasons for this: (i) GPs provide a flexible non-parametric framework for emulation modeling and (ii) they also provide an efficient quantifica-</p>
<p>tion of the predictive uncertainty associated with the interpolation between training points in the $n$-dimensional parameter space. In Bayesian parameter estimation, the latter integrates seamlessly with the aleatoric and epistemic uncertainties to yield an accurate quantification of the total uncertainty for the inferred model parameters.</p>
<p>Relativistic heavy ion collision experiments have been conducted at various experimental facilities around the world, using different collision systems (ranging from $\mathrm{p}+\mathrm{p}$ and $\mathrm{p}+A$ to $\mathrm{U}+\mathrm{U}$ ) and different collision energies (ranging from $\sqrt{s_{\mathrm{NN}}}=3 \mathrm{GeV}$ to 13 TeV ). ${ }^{1}$ When studying these different systems with Bayesian parameter inference methods, one typically builds separate emulators for each individual system. Each collision is simulated using a multistage model [14, 20-29] that describes the successive dynamical evolution stages. For each stage there typically exist multiple physics models ("modules") based on different physics assumptions. Mixing-andmatching these modules leads to a plethora of theoretical models that, in principle, could all be used to simulate the collision. As recently shown using Bayesian Model Averaging [11], this ambiguity in the theoretical framework can add a significant model uncertainty in the parameter inference. But accounting for it systematically requires studying multiple models, and this generates a need for efficient emulators describing the predictions from different but typically closely related evolution models. If each model emulator needs the same number of training data, the computational cost for building the emulators scales linearly with the number of models. This quickly renders a global Bayesian parameter inference, which includes a representative set of simulation models to describe large sets of experimental data from a variety of collision systems, computationally infeasible.</p>
<p>We introduce here a novel emulation method that significantly reduces the computational barrier for a global Bayesian parameter estimation by requiring a smaller volume of training data for building accurate emulators. This is accomplished by realizing that physical observables from different collision systems are related to each other by common trends resulting from the uniqueness of the underlying physics, and that predictions for these observables from models based on different sets of approximations for this underlying physics also share common trends reflecting this common ancestry. We use "transfer learning" [30-32] to transfer knowledge about such trends from emulators for a specific model trained on a larger, much more expensive set of already existing training data generated for a previously analyzed system, to new emulators for a different simulation model of the same collision system or for simulations of a different collision system. We provide illustrative examples on the use of</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup>this new technique; the code ${ }^{2}$ generating these examples, including full documentation, can be found at [34].</p>
<p>This work is organized as follows. Sec. II provides an introduction to transfer learning and Gaussian Process emulation. Applications of transfer learning techniques for emulation of relativistic heavy ion collisions are introduced and illustrated in Sec. III. In Sec. IV we illustrate a new way of performing sensitivity analysis offered by transfer learning. We then compare the accuracy of and computational savings from the new emulation method to the existing usage of Gaussian Processes in Sec. V. Applications of this method and its limitations in analyzing relativistic heavy ion collisions and beyond are discussed in Sec. VI. We conclude in Sec. VII with an outlook on future work. The Appendix describes the standardization process for experimental observables used in our work.</p>
<h2>II. TRANSFER LEARNING AND GAUSSIAN PROCESS EMULATION</h2>
<h2>A. Transfer learning</h2>
<p>Transfer learning methods (see, e.g., [32, 35]) aim to improve learning in a designated task (called the target task), by leveraging information from other related tasks (called source tasks). This is in contrast to traditional machine learning methods, which instead build separate learning models for each task in isolation. Transfer learning methods are becoming increasingly popular in the machine learning literature, since it allows for efficient learning of target systems where training data can be expensive to obtain [36].</p>
<p>While there are many types of transfer learning models, the one most relevant for the current study is inductive transfer learning [32], where the source and target problems have identical input domains but different tasks. In such problems, the training data for the target task is typically scarce, so a model trained solely on such data does not provide good predictive performance. Existing transfer learning techniques tackle this problem by learning and correcting the bias between source and target tasks. One such method is TrAdaBoost [37], which weighs each source data point by a measure of similarity to the target for better classification performance on the target task. This approach is extended for regression tasks in [38]. [39] proposes an importance-weighted approach for reweighing the source data to predict on the target task. The authors of [40] present an adaptive transfer learning model using Gaussian processes, in which a transfer kernel learns to model similarities between target and source tasks. Their model assumes the same kernel for both target and source, with a dissimilarity parameter accounting for the correlation between them. Our proposed model builds on these ideas but</p>
<p><sup id="fnref:1"><a class="footnote-ref" href="#fn:1">2</a></sup></p>
<p>takes instead an additive approach where we introduce a discrepancy function between source and target, modeled by a GP. This provides a more flexible way of transferring information and also makes it possible to analyze the differences between source and target via sensitivity analysis on the discrepancy function. A comprehensive survey on existing transfer learning techniques can be found in [41].</p>
<p>The proposed transfer learning emulator is based on the popular Kennedy-O'Hagan (KO) model for multifidelity emulation [31]. Here we address the bias between target and source by applying a correlation factor and a discrepancy function. This work provides a novel application of the KO model for modeling heavy ion collisions between different nuclear species, or for the same species using different but related dynamical evolution codes.</p>
<h2>B. Gaussian process emulation</h2>
<p>Gaussian processes (GPs) [42] are a popular choice for emulation of computer simulations [43] and have been exploited in diverse applications from rocket design [44] to 3D printing [45]. GPs are an essential tool for Bayesian parameter estimation of complex simulation models, where they are used to efficiently interpolate between full model runs taken on a sparse set of design points in a high-dimensional parameter space, largely due to their ability to efficiently provide a probabilistic quantification of the incurred interpolation uncertainty.</p>
<p>Let $f(\mathbf{x})$ denote the simulation output at parameter point $\mathbf{x}=\left(x_{1}, \cdots, x_{q}\right) \in \mathcal{X}$, where $\mathcal{X}$ is the parameter space. A Gaussian process is a stochastic process ${f(\mathbf{x}) \in \mathbb{R}: \mathbf{x} \in \mathcal{X}}$, for which any finite collection of points $f\left(\mathbf{x}<em n="n">{1}\right), \ldots, f\left(\mathbf{x}</em>\right)\right]$. This will be denoted as}\right)$ have a joint Gaussian distribution. A GP is fully characterized by a mean function $\mu(\mathbf{x})=\mathbb{E}[f(\mathbf{x})]$ and a covariance function $k\left(\mathbf{x}, \mathbf{x}^{\prime}\right)=$ $\operatorname{Cov}\left[f(\mathbf{x}), f\left(\mathbf{x}^{\prime</p>
<p>$$
f(\cdot) \sim \operatorname{GP}{\mu(\cdot), k(\cdot, \cdot)}
$$</p>
<p>The mean function $\mu(\mathbf{x})$ denotes the mean of the process while the covariance function controls the smoothness of its sample paths.</p>
<p>From a Bayesian perspective, the GP model $f(\cdot)$ prior to conditioning on data from the full model runs represents a modeler's prior belief on the simulation output before observing it. In practice, the mean function $\mu(\cdot)$ prior to conditioning is typically set to be a constant $\mu$. There are several popular choices for the covariance function $k(\cdot, \cdot)$, including Gaussian ${ }^{3}$, Matérn, and cubic covariances [42]. In this study, we employ the anisotropic Gaussian covariance function, widely used for computer</p>
<p><sup id="fnref2:0"><a class="footnote-ref" href="#fn:0">1</a></sup>experiment emulators [17]:</p>
<p>$$
k^{\mathrm{SE}}\left(\mathbf{x}, \mathbf{x}^{\prime}\right)=\sigma^{2} \exp \left[-\sum_{j=1}^{q} \frac{\left(x_{j}-x_{j}^{\prime}\right)^{2}}{2 l_{j}^{2}}\right]
$$</p>
<p>Here $\sigma^{2}&gt;0$ is a variance parameter controlling the variation of the process around its mean, while the parameters $l_{j}&gt;0(j=1,2, \cdots, q)$ are characteristic length-scales. Larger $l_{j}$ induce stronger correlations between nearby points, resulting in smoother sample paths, whereas smaller $l_{j}$ result in more wiggly sample paths.</p>
<p>We now integrate the data obtained from the full model simulations. Suppose noisy outputs $\mathbf{y}=\left(y_{1}, \ldots, y_{n}\right)$ are simulated at parameters $\mathbf{x}<em n="n">{1}, \ldots, \mathbf{x}</em>$ via the sampling model</p>
<p>$$
y_{i}=f\left(\mathbf{x}<em i="i">{i}\right)+\epsilon</em>\right)
$$}, \quad \epsilon_{i} \stackrel{i . i . d .}{\sim} N\left(0, \gamma^{2</p>
<p>where $\epsilon_{i}$ represents statistical uncertainty, i.i.d. stands for "independent and identically distributed", and $N\left(0, \gamma^{2}\right)$ denotes a Gaussian normal distribution with zero mean and variance $\gamma^{2}$. Conditioning on the data $\mathbf{y}$ (and assuming fixed parameters $\mu, \sigma^{2}$ and $l$ ), the posterior distribution of $f$ at a new point on the parameter space $\mathbf{x}_{\text {new }}$ can be shown to be [17]</p>
<p>$$
\left[f\left(\mathbf{x}<em _new="{new" _text="\text">{\text {new }}\right) \mid \mathbf{y}\right] \sim N\left(\mu^{<em>}\left(\mathbf{x}_{\text {new }}\right), \sigma^{2^{</em>}}\left(\mathbf{x}</em>\right)\right)
$$}</p>
<p>where the posterior mean and variance are given by</p>
<p>$$
\begin{aligned}
\mu^{<em>}\left(\mathbf{x}<em _new="{new" _text="\text">{\text {new }}\right) &amp; =\mu+\mathbf{k}</em>}}^{\top}\left(\mathbf{K}+\gamma^{2} \mathbf{I<em n="n">{n}\right)^{-1}\left(\boldsymbol{y}-\mu \mathbf{1}</em>\right) \
\sigma^{2^{</em>}}\left(\mathbf{x}<em _new="{new" _text="\text">{\text {new }}\right) &amp; =k\left(\mathbf{x}</em>}}, \mathbf{x<em _new="{new" _text="\text">{\text {new }}\right)-\mathbf{k}</em>}}^{\top}\left(\mathbf{K}+\gamma^{2} \mathbf{I<em _new="{new" _text="\text">{n}\right)^{-1} \mathbf{k}</em>
\end{aligned}
$$}</p>
<p>Here, $\mathbf{k}<em _new="{new" _text="\text">{\text {new }}=\left[k\left(\mathbf{x}</em>}}, \mathbf{x<em i="1">{i}\right)\right]</em>}^{n}$ is the covariance vector between the $n$ existing design points of full-model runs and a new, interpolated point in the parameter space, and $\mathbf{K}=\left[k\left(\mathbf{x<em j="j">{i}, \mathbf{x}</em>\right)<em _new="{new" _text="\text">{i, j=1}^{n}\right]$ is the covariance matrix for the simulated data. Equations $(3,4)$ provide the basis for emulator modeling: the posterior mean $\mu^{<em>}\left(\mathbf{x}<em _new="{new" _text="\text">{\text {new }}\right)$ serves as the emulator model prediction at a new point $\mathbf{x}</em>$, and the posterior variance $\sigma^{2^{}</em>}}\left(\mathbf{x}</em>$ and $l$ are first estimated using the maximum likelihood method [46], then plugged into the predictive equations (4) for emulation (see [17] for further details on plug-in predictors).}}\right)$ yields a quantification of emulator model uncertainty. A key appeal of GP emulators is that both their prediction and uncertainty can be efficiently computed via such closed-form expressions. In practice, the parameters $\mu, \sigma^{2</p>
<h2>C. Emulator model specification</h2>
<p>We now extend the above GP modeling framework to build a transfer learning emulator model. Let $f_{T}(\mathbf{x})$ denote the simulator output at parameter $\mathbf{x}$ for the target system, i.e., the system for which data ${ }^{4}$ are limited and</p>
<p><sup id="fnref2:1"><a class="footnote-ref" href="#fn:1">2</a></sup></p>
<p>emulation is desired. Let $f_{S}(\mathbf{x})$ denote the simulator output at parameter $\mathbf{x}$ for the source system, i.e., the system for which a large set of simulation data is available. We assume that the source and target systems share the same parameter space.</p>
<p>We adopt the following transfer learning model linking the source and target systems:</p>
<p>$$
f_{T}(\mathbf{x})=\rho f_{S}(\mathbf{x})+\delta(\mathbf{x})
$$</p>
<p>Here, $\rho$ is a linear correlation coefficient linking the source system to the target and will be estimated from data using maximum likelihood methods. The function $\delta(\mathbf{x})$ models the discrepancy (i.e. systematic differences) between source and target after accounting for correlations. Since neither $f_{S}(\mathbf{x})$ nor $\delta(\mathbf{x})$ are known with certainty, we then place independent priors on both terms:</p>
<p>$$
f_{S}(\mathbf{x}) \sim \mathrm{GP}\left{\mu_{S}, k_{S}^{\mathrm{SE}}(\cdot, \cdot)\right}, \quad \delta(\mathbf{x}) \sim \mathrm{GP}\left{\mu_{\delta}, k_{\delta}^{\mathrm{SE}}(\cdot, \cdot)\right}
$$</p>
<p>where different variance and length-scale parameters are used for the squared-exponential kernels $k_{S}^{\mathrm{SE}}$ and $k_{\delta}^{\mathrm{SE}}$. As before, the GP mean parameters $\mu_{S}$ and $\mu_{\delta}$, variances $\sigma_{S}^{2}$ and $\sigma_{\delta}^{2}$, and length-scales $l_{S}$ and $l_{\delta}$ are estimated from data using maximum likelihood methods.</p>
<p>Consider now the simulation data for training: for the source system, suppose noisy outputs $\mathbf{y}<em 1="1">{S}=\left(y</em>}^{S}, \ldots, y_{m}^{S}\right)$ are available at parameters $\mathbf{X<em 1="1">{S}=\left(\mathbf{x}</em>\right)$ via the sampling model}^{S}, \ldots, \mathbf{x}_{m}^{S</p>
<p>$$
y_{i}^{S}=f_{S}\left(\mathbf{x}<em i="i">{i}^{S}\right)+\epsilon</em>\right), \quad i=1, \ldots, m
$$}^{S}, \quad \epsilon_{i}^{S} \stackrel{i.i.d.}{\sim} N\left(0, \gamma_{S}^{2</p>
<p>For the target system, suppose also that noisy outputs $\mathbf{y}<em 1="1">{T}=\left(y</em>}^{T}, \ldots, y_{n}^{T}\right)$ are simulated at parameters $\mathbf{X<em 1="1">{T}=$ $\left(\mathbf{x}</em>\right)$ via}^{T}, \ldots, \mathbf{x}_{n}^{T</p>
<p>$$
y_{j}^{T}=f_{T}\left(\mathbf{x}<em j="j">{j}^{T}\right)+\epsilon</em>\right), \quad j=1, \ldots, n
$$}^{T}, \quad \epsilon_{j}^{T i . i . d} \stackrel{i.i.d.}{\sim} N\left(0, \gamma_{T}^{2</p>
<p>The goal is to to realize computational savings by keeping the sample size $n$ for the target system much smaller than the sample size $m$ for the source system.</p>
<p>Conditioning on both sets of data $\mathbf{y}<em T="T">{S}$ and $\mathbf{y}</em>$ can be shown to be}$ (and assuming fixed GP model parameters), the posterior distribution for the target system $f_{T}$ at a new parameter $\mathbf{x}_{\text {new }</p>
<p>$$
\left[f_{T}\left(\mathbf{x}<em S="S">{\text {new }}\right) \mid \mathbf{y}</em>}, \mathbf{y<em T="T">{T}\right] \sim N\left(\mu</em>^{<em>}\left(\mathbf{x}<em T="T">{\text {new }}\right), \sigma</em>^{2 </em>}\left(\mathbf{x}_{\text {new }}\right)\right)
$$</p>
<p>where the posterior mean and variance of the transfer learning emulator model are given by</p>
<p>$$
\begin{aligned}
\mu_{T}^{<em>}\left(\mathbf{x}<em S="S">{\text {new }}\right)= &amp; \rho \mu</em> \
&amp; +\mathbf{k}}+\mu_{\delta<em S="S">{\text {new }}^{\top} \mathbf{\Sigma}^{-1}\left(\left[\begin{array}{l}
\mathbf{y}</em> \
\mathbf{y}<em S="S">{T}
\end{array}\right]-\left[\begin{array}{c}
\mu</em>} \mathbf{1<em S="S">{m} \
\left(\rho \mu</em>}+\mu_{\delta}\right) \mathbf{1<em T="T">{n}
\end{array}\right]\right) \
\sigma</em>^{2 </em>}\left(\mathbf{x}<em S="S">{\text {new }}\right)= &amp; \rho^{2} \mathbf{k}</em>}\left(\mathbf{x<em _new="{new" _text="\text">{\text {new }}, \mathbf{x}</em>}}\right)+\mathbf{k<em _new="{new" _text="\text">{\delta}\left(\mathbf{x}</em>}}, \mathbf{x<em _new="{new" _text="\text">{\text {new }}\right) \
&amp; -\mathbf{k}</em>
\end{aligned}
$$}}^{\top} \mathbf{\Sigma}^{-1} \mathbf{k}_{\text {new }</p>
<p>with $\mathbf{k}<em _new="{new" _text="\text">{\text {new }}=\left[\mathbf{k}</em>}}^{\mathrm{S}}, \mathbf{k<em _new="{new" _text="\text">{\text {new }}^{\mathrm{T}}\right]$ and $\mathbf{k}</em>}}^{S}=\left[k\left(\mathbf{x<em i="i">{\text {new }}, \mathbf{x}</em>\right)\right]<em _new="{new" _text="\text">{i=1}^{m}$, $\mathbf{k}</em>}}^{T}=\left[k\left(\mathbf{x<em j="j">{\text {new }}, \mathbf{x}</em>\right)\right]<em S="S">{j=1}^{n}$, and
$\mathbf{\Sigma}=\left[\begin{array}{ll}\mathbf{K}</em>}\left(\mathbf{X<em S="S">{S}\right)+\gamma</em>}^{2} \mathbf{1<em S="S">{m} &amp; \rho \mathbf{K}</em>}\left(\mathbf{X<em T="T">{S}, \mathbf{X}</em>}\right) \ \rho \mathbf{K<em S="S">{S}\left(\mathbf{X}</em>}, \mathbf{X<em S="S">{T}\right)^{T} &amp; \rho^{2} \mathbf{K}</em>}\left(\mathbf{X<em _delta="\delta">{T}\right)+\mathbf{K}</em>}\left(\mathbf{X<em T="T">{T}\right)+\gamma</em>\right]$.}^{2} \mathbf{1}_{n}\end{array</p>
<p>Equation (10) provides the predictive equations for our transfer learning emulator model: $\mu_{T}^{<em>}\left(\mathbf{x}<em T="T">{\text {new }}\right)$ serves as the emulator model prediction while $\sigma</em>^{2 </em>}\left(\mathbf{x}_{\text {new }}\right)$ quantifies its uncertainty. These closed-form equations enable efficient probabilistic predictions from the proposed model. As before, the parameters $\mu, \sigma^{2}, l$ and $\rho$ are estimated using maximum likelihood [46] (first for the source, then for the discrepancy), then used in the predictive equations (10) for emulation of the target system.</p>
<p>The discrepancy function $\delta(\mathbf{x})$, which captures the systematic differences between the source and target, can then be estimated from equation (5) as:</p>
<p>$$
\hat{\delta}(\mathbf{x})=\mu_{T}^{<em>}(\mathbf{x})-\rho \mu_{S}^{</em>}(\mathbf{x})
$$</p>
<p>where $\mu_{T}^{<em>}(\mathbf{x})$ is the posterior mean in equation (10) and $\mu_{S}^{</em>}(\mathbf{x})$ is the posterior mean of Gaussian process emulator in equation (4). A careful analysis of the estimated discrepancy function $\hat{\delta}(\mathbf{x})$ can yield useful insights on the different physics between the source and target systems. We explore this further in Section IV.</p>
<p>The above transfer learning emulator model is closely related to the KO model which is widely used for multifidelity emulation. The KO model aims to emulate a high-fidelity computer simulation, using data simulated from lower-fidelity approximations of the same system. The KO model is similar in spirit to Equation (5) in that the high-fidelity code is modeled as a linear autoregressive formulation of the low-fidelity code, plus a discrepancy term to account for systematic bias. The key difference for the proposed model is that instead of transferring learning from simulations of different fidelities for the same system, our emulator model is trained by transferring knowledge between high-fidelity simulations of different systems that have common traits.</p>
<h2>III. TRANSFER LEARNING EMULATORS FOR RELATIVISTIC HEAVY ION COLLISIONS</h2>
<p>All large scale Bayesian parameter estimations for relativistic heavy ion collisions have been made computationally feasible by using GPs as surrogates for computationally expensive simulations. The biggest computational cost associated with any such analysis is in generating training data for the GPs. In this section, we compare the accuracy and the computational cost associated with two distinct emulation methods: direct emulation with traditional Gaussian Processes and our novel transfer learning emulation method. We show that transfer learning requires significantly fewer training data from the computationally expensive simulation and thus lowers the computational barrier associated with Bayesian parameter estimation for complex problems, such as the one posed by the dynamical modeling of relativistic heavy ion collisions. Transfer learning is a particularly powerful tool for situations where (i) the training data on the target alone are insufficient to fit a good emulator, and</p>
<table>
<thead>
<tr>
<th>Observable Type</th>
<th>Centralities</th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td>$\mathrm{Au}+\mathrm{Au}$ at 0.2 TeV</td>
<td>$\mathrm{Pb}+\mathrm{Pb}$ at 2.76 TeV</td>
<td></td>
</tr>
<tr>
<td>Charged particle multiplicity; $d N_{c h} / d \eta$</td>
<td>None</td>
<td>$[0-5],[60-70]$</td>
<td></td>
</tr>
<tr>
<td>Pion multiplicity; $d N_{\pi} / d y$</td>
<td>$[0-5],[40-50]$</td>
<td>$[0-5],[60-70]$</td>
<td></td>
</tr>
<tr>
<td>Mean transverse momenta of pions; $\left\langle p_{T}\right\rangle_{\pi}$</td>
<td>$[0-5],[40-50]$</td>
<td>$[0-5],[60-70]$</td>
<td></td>
</tr>
<tr>
<td>Two-particle elliptic flow; $v_{2}{2}$</td>
<td>$[0-5],[40-50]$</td>
<td>$[0-5],[60-70]$</td>
<td></td>
</tr>
<tr>
<td>Fluctuation in the mean transverse momentum; $\delta p_{T} / p_{T}$</td>
<td>None</td>
<td>$[0-5],[55-60]$</td>
<td></td>
</tr>
</tbody>
</table>
<p>TABLE I. Observables used for emulation
(ii) the amount of training data available on the source is much larger than that for the target.</p>
<h2>A. Multistage model of relativistic heavy ion collision simulations</h2>
<p>The relativistic heavy ion collision model used in the present work [14] involves the following modules describing different evolution stages:</p>
<ol>
<li>$\mathrm{T}_{\mathrm{R}}$ ENTo: A phenomenological model of the initial energy deposition after the impact of the nuclei [47, 48].</li>
<li>Freestreaming: A model for weakly-coupled preequilibrium dynamics, covering the first $\mathrm{fm} / c$ or so [49-51].</li>
<li>Relativistic viscous hydrodynamics, describing the dissipative evolution of near-equilibrium QCD matter with the code MUSIC [52-56].</li>
<li>Particlization: Conversion of the fluid into particles after it cools down below the critical temperature where QGP converts back into hadrons, described by the Cooper-Frye formula [57, 58]. To parameterize the local hadron phase space distributions using only the ten components of the energy momentum tensor evolved by the hydrodynamic model, three different models with different physics assumptions are explored:
(a) Grad viscous corrections, which expand the distribution function up to second order in hadron momenta [59];
(b) Chapman-Enskog (CE) viscous corrections, which solve the Relaxation-TimeApproximation Boltzmann equation for linearized corrections to the distribution function [60]; and
(c) Pratt-Torrieri-Bernhard (PTB) modified equilibrium viscous corrections [61] which uses an exponential ansatz ensuring a positive definite distribution function.</li>
</ol>
<p>These corrections are implemented using the iS3D sampler $[62,63]$.
5. Hadronic decays and re-scatterings are modeled with Boltzmann kinetic transport using the code SMASH [64, 65].</p>
<p>To apply and test transfer learning techniques in this setting, we use a very large set of full-model simulation data that were generated for calibrating the JETSCAPE modeling framework [14], including the following systems:</p>
<ol>
<li>$\mathrm{Pb}+\mathrm{Pb}$ collisions at $\sqrt{s_{\mathrm{NN}}}=2.76 \mathrm{TeV}$ with
(a) Grad viscous corrections,
(b) Chapman-Enskog viscous corrections, and
(c) Pratt-Torrieri-Bernhard viscous corrections;</li>
<li>$\mathrm{Au}+\mathrm{Au}$ collisions at $\sqrt{s_{\mathrm{NN}}}=0.2 \mathrm{TeV}$ center of mass energy with Grad viscous corrections.</li>
</ol>
<p>All these simulations share the same set of 17 model parameters described in [11, 14]. For model calibration, full-model simulations were performed at 500 design points that uniformly cover the 17-dimensional parameter space within a finite 17-dimensional cube described in [11, 14], using maximin Latin Hypercube sampling [66]. ${ }^{5}$ For each design point and each particlization model, 2500 simulations were performed with stochastically fluctuating initial conditions and particlization results. For each design point and particlization model, a multitude of experimental observables were computed and compared with the corresponding experimental data. We use full-model predictions for only a subset of these observables (listed in Table I) to illustrate the proposed transfer learning emulator. For simplicity, we focus here on only two collision centralities, "central" ( $[0 \%-5 \%]$ centrality) and "peripheral" ( $[40 \%-50 \%]$ centrality for the $\mathrm{Au}+\mathrm{Au}$ collisions at RHIC, and $[55 \%-60 \%]$ or $[60 \%-70 \%]$ (whichever was the most peripheral bin available) for the $\mathrm{Pb}+\mathrm{Pb}$ collisions at the LHC ), and also leave out the yields and mean transverse momenta of kaons and protons, charged hadron triangular flow and transverse energy $\left(E_{T}\right)$ distributions.</p>
<p>For each choice of collision system and particlization model, we thus have a set of 473 samples of the parameter space (design points) that provide mean values and</p>
<p><sup id="fnref3:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>errors for each observable to train its emulator. To test the performance of the trained emulator we also generated additional test data sets for each model: 100 design points from a separate maximin Latin Hypercube design. Note that the emulators are not trained directly on the observables (as predicted by the simulations) listed in Table 1: we first perform a standardization of each of the observables using the means and variances of the source simulation data. These transformations are slightly different from those used in [14] – see Appendix A for details.</p>
<p>The test data set for each model is used to evaluate the performance of each emulator by calculating the mean squared error (MSE):</p>
<p>$$
\text{MSE} = \sum_{\substack{i \in { \text{test design} } \
l \in { \text{observables} }}} \frac{\left[\hat{Y}<em _mathbf_i="\mathbf{i">{\text{sim}}^l(\mathbf{x}</em>}}) - \hat{Y<em _mathbf_i="\mathbf{i">{\text{emu}}^l(\mathbf{x}</em>,
$$}})\right]^2}{N_{\text{test}}N_{\text{obs}}</p>
<p>where $\mathbf{x}<em _text_sim="\text{sim">{\mathbf{i}}$ are the model parameters for the $i^{th}$ test design point and $\hat{Y}</em>$ observable. We will show plots of the MSE for target emulators constructed with $n$ target training points (1 ≤ $n$ ≤ 473), using either the standard GP training protocol or the transfer learning protocol, and compare their performance as a function of $n$. As discussed in Sec. II C, the transfer learning emulator is trained by using these $n$ sets of target data on top of a source emulator that has been previously trained with a larger number $m$ of design points from the source system (here $m = 473$).}}^l$, $\hat{Y}_{\text{emu}}^l$ represent standardized (See Appendix A) simulation and emulation outputs for the $l^{th</p>
<h3>B. Transfer learning between different collision systems</h3>
<p>As our first application of transfer learning methods, we build emulators for simulated Au+Au collisions at $\sqrt{s_{\text{NN}}} = 0.2 \, \text{TeV}$ as the target system, using available trained emulators for Pb+Pb collisions at $\sqrt{s_{\text{NN}}} = 2.76 \, \text{TeV}$ as our source. The two emulation methods discussed previously are trained for each of the six observables shown in the Au+Au column of Table 1, as a function of the number of design points $n$ for which full-model simulations of the target system are available. We do this by first randomly dividing the total set of $n_{\text{max}} = 473$ simulation data for the target from previous work [11, 14] into 10 roughly equal size sets (nine batches of 47 plus one batch of 50 design points). We then train the emulators using only one batch of target design points, and then repeat the training procedure after successively adding the remaining batches. After each training step, we compare the predictions for the observables from the trained emulators with the full-model test data for the 100 parameter sets in the test design, and compute its mean squared error (MSE, Eq. (12)). The result is shown in Fig. 1 as a function of the number $n$ of target designs used for training.</p>
<p><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p><strong>FIG. 1.</strong> Mean squared error prediction accuracy of emulators for Au+Au collisions at $\sqrt{s_{\text{NN}}} = 200 \, \text{GeV}$ using the Grad particlization model. The transfer learning emulator uses a source emulator trained on model simulations for Pb+Pb collisions at $\sqrt{s_{\text{NN}}} = 2700 \, \text{GeV}$. The MSE shown is averaged over all observables, but the curves for the MSE of individual observables look all very similar. See text for discussion.</p>
<p>The dashed orange line in the figure (labeled GP) shows the MSE for the GP emulator of the target system using the standard training protocol, without any help from the source system emulator. The dotted red horizontal line shows the final MSE reached by this method using all 473 available target design points from the full-model simulation data, with the shaded band representing a 10% variation around this value. The solid blue line (labeled TL) shows the MSE for the proposed transfer learning emulation method, which, in addition to the $n$ target design points, also makes use of the information from the previously trained, costly GP emulator for the source system. The two red dots indicate the smallest number $n$ of target design points needed, for each emulator, for its MSE to come within 10% of the "asymptotic precision" (defined by the MSE at the maximally available number of target training points) shown by the dotted red line.</p>
<p>The solid blue curve denoting the transfer learning MSE clearly shows that the TL emulator is more accurate than the traditional GP emulator (dashed orange curve), for all values $n$ of the number of target design points used. The relative advantage of the transfer learning emulator is particularly evident for small numbers of target system design points. For example, when using only 47 design points for Au+Au, the transfer learning emulator has approximately half the mean squared error of the traditional emulator. Note that, even in the "asymptotic limit" when all 473 target design points are</p>
<p>used, the proposed transfer learning emulator still yields improved precision over the standard GP emulator, by leveraging information from the source system emulator.</p>
<p>As expected, for both emulator models, the emulation prediction error (in terms of MSE) decreases monotonically with increasing number of target training points $n$. For the proposed transfer learning emulator, the rate of decrease is not always uniform, which suggests that there is a diminishing marginal decrease in MSE for each additional target design point. In other words, at a certain point, the "new" information provided by the target training data is minor compared with the "old" information already contributed by the source system emulator.</p>
<p>Another way to quantify the success of the proposed transfer learning emulator is via the two large red dots in Fig. 1, where it can be seen that the same $\mathrm{Au}+\mathrm{Au}$ collision simulation can be emulated with the same accuracy at half the number of full-model simulations. This level of success of transfer learning is quite encouraging, considering that the target here ( $\mathrm{Au}+\mathrm{Au}$ at $\sqrt{s_{\mathrm{NN}}}=200 \mathrm{GeV}$ ) involves collisions at more than an order of magnitude lower center of mass energy than the source system ( $\mathrm{Pb}+\mathrm{Pb}$ collisions at $\sqrt{s_{\mathrm{NN}}}=2760 \mathrm{GeV}$ ).</p>
<h2>C. Transfer learning between different viscous corrections at particlization</h2>
<p>As discussed in Section III A, the multistage dynamical modelling of heavy ion collisions requires approximations and switching between different physical pictures which is associated with theoretical uncertainty: different modelling choices can be made in each collision stage, based on different assumptions or approximations of the governing physics. Different choices lead to models whose predictions differ from each other in quantitative detail but share qualitative features and common trends under variation of certain experimental control parameters, such as collision energy, collision centrality, system size etc. For each such model variant, teaching these trends to an emulator for its observables requires evaluating the full model at a large number of design points. Transfer learning offers a more computationally efficient strategy: after having spent large numerical resources on the training of sufficiently accurate emulators for the observables predicted for one such model variant (the source), equally accurate emulators for other variants (the targets) can be obtained at a fraction of the cost by transferring some of the qualitative tendencies from source to the targets.</p>
<p>We illustrate this idea here by considering as source and targets model variants obtained by swapping out one particular module in the multistage model, the particlization module (we refer to the discussion in Sec. III A). We consider $\mathrm{Pb}+\mathrm{Pb}$ collisions at the LHC, simulated with Grad model particlization, as our "source", and the same collisions simulated with Pratt-Torrieri-Bernhard (PTB, Fig. 2) or Chapman-Enskog particlization (CE, Fig. 3) as our "targets".</p>
<p>The data we work with are the simulated model out-
<img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>FIG. 2. Mean squared error prediction accuracy of emulators for $\mathrm{Pb}+\mathrm{Pb}$ collisions at $\sqrt{s_{\mathrm{NN}}}=2760 \mathrm{GeV}$ using the Pratt-Torrieri-Bernhard particlization model. The transfer learning emulator uses a source emulator trained on model simulations for $\mathrm{Pb}+\mathrm{Pb}$ collisions at the same $\sqrt{s_{\mathrm{NN}}}$ using the Grad particlization model. The MSE shown is averaged over all observables, but the curves for the MSE of individual observables look all very similar. See text for discussion.
puts for each of the three particlization models from the same design points discussed in the preceding subsection, a maximum of 473 points for emulator training plus a fixed number of 100 design points for emulator testing. Different from before, a larger set of observables is available for $\mathrm{Pb}+\mathrm{Pb}$ collisions at the LHC than we had to emulate for $\mathrm{Au}+\mathrm{Au}$ collisions at RHIC (c.f. Table I). We follow the same training strategy as described in the preceding subsection, for emulators predicting the model outputs for this larger set of observables but using the same design point batches as considered before. To zero in on the relative performance of the TL and GP emulators for the hypothetical case where only very small numbers of target model design points are available, we additionally divided the 473 total target design points to which had access randomly into smaller batches of 5 design points each, allowing studies of the evolution of the emulators' MSE with $n$ for smaller $n$-values (see inset in Fig. 3).</p>
<p>In Figs. 2 and 3 we note that the transfer learning emulators again already approach their asymptotic accuracy within $10 \%$ for a much smaller number of target design points than those generated with the standard GP training protocol, similar to the preceding subsection. We also note that for the case of different particlization routines shown in Figs. 2 and 3 the accuracy advantage of the TL emulators over their GP siblings begins to disappear once about $60 \%$ of the maximally available number of target training points $\left(n_{\mathrm{mx}}=473\right)$ have been used.</p>
<p><img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>FIG. 3. Same as Fig. 2 but for a target using Chapman-Enskog particlization.</p>
<p>For small numbers of target design points <em>n</em> ~ 50, the TL emulators have approximately one third or less of the mean squared error of the traditional GP emulators for the targets involving a change of particlization model, compared to the factor two reduction for the target involving a lower collision energy studied in Sec. III B. Amazingly, the inset in Fig. 3 shows that for the CE particlization model the MSE prediction accuracy of the TL emulator needs only 35 target training points to reach within 10% of its asymptotic value, and is not much worse even for as few as only 5 target training points. This means that the qualitative trends of the observables predicted by the Grad and CE particlization models must be very close (much closer than between the source and the other two target models studied in this work), and teaching these trends to the target emulator via transfer learning almost completely obviates the need for additional information from full-model simulations of the target model. While this is clearly a special situation, it illustrates the huge cost-saving potential of transfer learning if ways can be found to reliably diagnose the convergence of the emulator accuracy towards its asymptotic value.</p>
<h2>IV. SENSITIVITY ANALYSIS</h2>
<p>There is evident interest in understanding the effect of individual model parameters on specific observables, to gain intuition about what the experimental data might tell us about the underlying physics and medium properties. This relation between parameters and observables is often explored through "sensitivity analysis", though the exact method varies. Examples from the field of heavy ion physics can be found in Refs. [5, 14, 67, 68].</p>
<p>Transfer learning offers an interesting new way of performing sensitivity analysis, by systematically investigating which model parameters contribute to non-trivial differences in parameter dependencies between source and target models. As described in Sec. II, Eq. (11), these differences can be characterized by the correlation coefficient ρ and its corresponding discrepancy function δ(x). By estimating both ρ and δ(x) from data, we can then perform a sensitivity analysis on the estimated discrepancy function δ(x). Below, we perform such an analysis using the proposed transfer learning emulator and the scenarios discussed in the preceding section.</p>
<p>There are two main types of sensitivity analysis methods from the uncertainty quantification literature [69]: local or global ones. Local sensitivity analysis can quantify the model sensitivity for an observable at a fixed parameter value, such as the maximum a posteriori (MAP) estimate obtained from parameter inference. On the other hand, global sensitivity analysis provides an averaged quantification of sensitivity for each parameter over the full parameter space. In what follows, we focus on the latter global sensitivity analysis of the estimated discrepancy function δ(x) (11).</p>
<p>We first introduce the first-order Sobol' indices [70], a popular method for analyzing global sensitivity. Sobol' indices [71, 72] quantify the importance of each parameter for a given function δ(x), by decomposing its contribution to the variance of δ(·) over the parameter space. The first-order Sobol' index for model parameter x<sup>j</sup> is defined as:</p>
<p>$$\frac{\text{Var}<em X__-j="X_{-j">{X_j}\left(\mathbb{E}</em>$$}}(\delta(X)|X_j)\right)}{\text{Var}_{X}(\delta(X))}, \qquad j = 1, \dots, q. \tag{13</p>
<p>Here, X<sup>j</sup> is an independent uniform random variable for parameter x<sup>j</sup> over its parameter range, and X = (X<sub>1</sub>, ..., X<sub>q</sub>) is its corresponding random vector for all parameters. The term E<sub>X<sub>−j</sub></sub>(δ(X)|x<sup>j</sup>) is called the main effect of parameter x<sup>j</sup>: given fixed j-th parameter X<sup>j</sup> = x<sup>j</sup>, it averages the function δ(·) uniformly over the remaining parameters X<sub>−j</sub> = X \ X<sup>j</sup>. This is formally defined as</p>
<p>$$\mathbb{E}<em -j="-j">{X</em>$$}}(\delta(X)|X_j) = \int_{X_{-j}} \delta(x_1, \dots, x_q) \, dU(x_1, \dots, x_{j-1}, x_{j+1}, \dots, x_q), \tag{14</p>
<p>where U(x<sub>1</sub>, ..., x<sub>j-1</sub>, x<sub>j+1</sub>, ..., x<sub>q</sub>) is the uniform probability measure over X<sub>−j</sub>, the parameter space X omitting the j-th parameter. The first-order Sobol' index (13) thus quantifies the importance of parameter x<sup>j</sup>, by taking the ratio of Var<sub>X<sup>j</sup></sub>(E<sub>X<sub>−j</sub></sub>(δ(X)|X<sup>j</sup>)), the variance accounted for by the main effects E<sub>X<sub>−j</sub></sub>(δ(X)|X<sup>j</sup>), over Var<sub>X</sub>(Y), the total variance of δ(·) over all parameters. For costly simulations such as for heavy ion collisions, the integral in (14) can be expensive to evaluate. A standard approach [69] (which we adopt) is to replace the expensive</p>
<p>$\delta(\cdot)$ with the estimated discrepancy $\hat{\delta}(\cdot)$ (11) from the emulator model.</p>
<p>One can further modify the Sobol’ indices in (13) by grouping together similar model input parameters. The grouped Sobol’ indices in [70] accomplish this. The $q$ input parameters $\mathbf{X}=\left(X_{1}, \cdots, X_{q}\right)$ (assumed again to be uniformly distributed) are first divided into $J$ groups $\left(\mathbb{X}<em J="J">{1}, \cdots, \mathbb{X}</em>\right)$, given by:</p>
<p>$$
\left(X_{1}, \cdots, X_{q}\right)=(\underbrace{X_{1}, \ldots, X_{k_{1}}}<em 1="1">{\mathbb{X}</em>}}, \ldots, \underbrace{X_{k_{J-1}+1}, \ldots, X_{q}<em J="J">{\mathbb{X}</em>)
$$}</p>
<p>The first-order grouped Sobol' indices can then be defined as:</p>
<p>$$
S_{j}=\frac{\operatorname{Var}<em j="j">{\mathbb{X}</em>}}\left(\mathbb{E<em -j="-j">{\mathbb{X}</em>}}\left(Y \mid \mathbb{X<em _mathbf_X="\mathbf{X">{j}\right)\right)}{\operatorname{Var}</em>, \quad j=1, \cdots, J
$$}}(Y)</p>
<p>where $\mathbb{X}<em j="j">{-j}=\mathbf{X} \backslash \mathbb{X}</em>$ consists of all parameters except for those in group $j$.</p>
<p>In our implementation, all simulation models consider the same $q=17$ input model parameters. We group these parameters into six groups according to similarities of their functionality in our model. We employ the following parameter grouping: ${ }^{6}$</p>
<ul>
<li>N : The normalization parameter in $\mathrm{T}_{\mathrm{R}}$ ENTo</li>
<li>$\mathrm{T}<em _mathrm_R="\mathrm{R">{\mathrm{R}} \mathrm{E}$ : All other parameters in the $\mathrm{T}</em>$ ENTo initialstate module.}</li>
<li>Free-streaming: Parameters controlling the freestreaming time</li>
<li>$\eta / s$ : All model inputs that parameterize the temperature dependence of the specific shear viscosity.</li>
<li>$\zeta / s$ : All model inputs that parameterize the temperature dependence of the specific bulk viscosity.</li>
<li>$T_{s w}$ : The particlization temperature separating hydrodynamics and hadronic transport.</li>
</ul>
<p>This grouping provides meaningful insight on the global sensitivity of the discrepancy between the source and target systems. Our grouped sensitivity analysis agrees with previous sensitivity studies, while providing more concise results with clearer implications.</p>
<p>The left column of Fig. 4 shows the global sensitivity of the model for $\mathrm{Pb}+\mathrm{Pb}$ collisions at 2.76 TeV with Grad viscous corrections, obtained from the source model emulators discussed before. The six panels in that column correspond to three different observables, each at two different centralities. Within each panel, each of the six</p>
<p><sup id="fnref4:0"><a class="footnote-ref" href="#fn:0">1</a></sup><img alt="img-3.jpeg" src="img-3.jpeg" /></p>
<p>FIG. 4. First order group Sobol' sensitivities of the $\mathrm{Pb}+\mathrm{Pb}$ 2.76 TeV source simulation (left) and of the discrepancy GP for $\mathrm{Au}+\mathrm{Au} 200 \mathrm{GeV}$ target simulation (right).
bars represents a different group of model parameters. In central collisions ( $0-5 \%$ centrality), the overall pion yield is mostly sensitive to the normalization constant $N$ for the initial energy density profile, the pion mean transverse momentum reacts most strongly to changes in the specific bulk viscosity, and the charged hadron elliptic flow is most sensitive to $\mathrm{T}<em 2="2">{\mathrm{R}}$ ENTo model parameters (in particular, to the granularity of the initial energy density fluctuations). At first it may seem surprising that $v</em>$ ENTo parameters than to}$ reacts more strongly to the $\mathrm{T}_{\mathrm{R}</p>
<p>the specific shear viscosity but this becomes clearer once one remembers that $\eta / s$ controls the hydrodynamic response to the initial-state source eccentricity $\epsilon_{2}$, i.e. the ratio $v_{2} / \epsilon_{2}$. The large sensitivity of $v_{2}$ to the $\mathrm{T}<em 2="2">{\mathrm{R}}$ ENTo parameters really reflects their dominant effect on $\epsilon</em>}$ which is bigger than that of $\eta / s$ on the ratio $v_{2} / \epsilon_{2}$. In peripheral collisions, on the other hand, the left column of Fig. 4 exhibits additional sensitivities that are much less prominent in central collisions: The overall pion yield now also exhibits sensitivity to the $\mathrm{T<em _mathrm_R="\mathrm{R">{\mathrm{R}}$ ENTo parameters; this would be consistent with a stronger viscous heating effects caused by increased granularity in the smaller fireballs generated when the nuclei hit each other at larger impact parameters. The pion mean transverse momentum shows additional sensitivity to the $\mathrm{T}</em>$ grows in relative importance.}}$ ENTo parameters and free-streaming time which control the early build-up of radial flow [49]. And the influence of $\eta / s$ on the charged hadron $v_{2</p>
<p>In the right column of Fig. 4 we show the sensitivity of the discrepancy GPs between $\mathrm{Pb}+\mathrm{Pb} \sqrt{s_{\mathrm{NN}}}=2.76$ TeV Grad (source) and $\mathrm{Au}+\mathrm{Au} \sqrt{s_{\mathrm{NN}}}=200 \mathrm{GeV}$ (target) model outputs. Clearly, for all three observables, at both collision centralities, the discrepancy GPs share a high sensitivity to the normalization parameter $N$. This is expected since the most striking difference between these two collision systems is their total multiplicity, driven by the much higher collision energy at the LHC compared to RHIC. We further observe that the discrepancy GPs related to mean transverse momentum $\left(\left\langle p_{T}\right\rangle_{\pi}\right)$ and flow observables $\left(v_{2}{2}\right)$ have a significant sensitivity to the model parameters related to the pre-equilibrium stage, both via the $\mathrm{T}<em _mathrm_R="\mathrm{R">{\mathrm{R}}$ ENTo initialization model and the duration of the free-streaming stage. This indicates that the pre-equilibrium dynamics depends sensitively on the center of mass energy of the collision. Interestingly, the discrepancy GPs for the mean transverse momentum observable are found to be insensitive to the $\mathrm{T}</em>$ In other words, these observables share roughly the same degree of sensitivity to these parameters at both collision energies - these are the types of systematic trends in the simulations that make transfer learning efficient.}}$ ENTo parameters and the switching temperature (which is mostly constrained by the chemical composition of the final hadronic stage [14]). Similarly, the discrepancy GPs for the elliptic flow observables show only weak sensitivity to the specific viscosities. ${ }^{7</p>
<p>In Fig. 5 we show the analogous sensitivity plots for the discrepancy GPs for the $\mathrm{Pb}+\mathrm{Pb}$ CE (left column) and $\mathrm{Pb}+\mathrm{Pb}$ PTB (right column) target models. ${ }^{8}$ Com-</p>
<p><sup id="fnref5:0"><a class="footnote-ref" href="#fn:0">1</a></sup><img alt="img-4.jpeg" src="img-4.jpeg" /></p>
<p>FIG. 5. First order group Sobol' sensitivities of discrepancy GPs. $\mathrm{Pb}+\mathrm{Pb}$ with CE viscous corrections (left) and $\mathrm{Pb}+\mathrm{Pb}$ with PTB viscous corrections (right).</p>
<p>pared to Fig. 4 we include two additional observables (the total charged hadron multiplicity density $d N_{\mathrm{ch}} / d \eta$ and the normalized $p_{T}$-fluctuations $\left.\delta p_{T} /\left\langle p_{T}\right\rangle\right)$, again for two collision centralities, resulting in ten panels for each target model. In central collisions, for both targets the majority of the discrepancy GPs (with the exception of the ones emulating the $p_{T}$ fluctuations and elliptic flow) are found to be most sensitive to the bulk viscosity parameters. Remembering that here the difference between source and targets is how the viscous corrections are handled during particlization, the sensitivity to the viscosity parameterizations is not surprising. More insightful is the observation that the sensitivity to the bulk viscosity sector is mostly stronger than to the shear sector. This may be related to the fact that particlization at $T_{\mathrm{sw}}$ happens just after hadronization of the QGP, and that the bulk viscosity peaks near the hadronization phase transition. The situation is, however, more complex in peripheral collisions where the sensitivities to the bulk and shear viscous sectors of parameter space differ between the CE and PTB targets. Furthermore, the mean values and fluctuations of the pion transverse momenta show dominant sensitivities to different sectors of the parameter space than the other observables. All this suggests that Bayesian inference based on the available experimental data should allow us to discriminate between the different particlization models based on their ability to describe the full spectrum of observations, and that combining the strengths and weaknesses of these different models in the future via Bayesian Model Mixing [74, 75] may lead to overall tighter constraints on the fireball properties.</p>
<p>We close this section by noting that relating the source and target model emulators in the form (5) and identifying the corresponding linear correlation coefficient $\rho$ and discrepancy $\hat{\delta}(\mathbf{x})$ may be a very broadly applicable technique for gaining valuable insights into qualitative similarities and differences between different models and into their success and/or failure in describing a given set of experimental data.</p>
<h2>V. COMPUTATIONAL SAVINGS FROM TRANSFER LEARNING</h2>
<p>Relativistic heavy ion collision experiments produce measurements for hundreds of observables. Since their dynamics is too complex to be described analytically, they are studied theoretically by building phenomenological models that are calibrated with the experimental data. The models have multiple parameters describing properties of the collision dynamics that can not (yet) be computed from first principles and must be inferred using the experimental measurements. After calibration the models can be tested by predicting and measuring additional observables. Since both the experimental data and simulation model outputs have uncertainties associated with them, model calibration (a.k.a. solving "the inverse problem") requires a probabilistic framework.</p>
<p>As already briefly summarized in the Introduction,</p>
<p>Bayesian parameter inference is a framework that allows for a systematic probabilistic accounting for our knowledge about the model and its uncertainties. It is based on Bayes theorem,</p>
<p>$$
\mathcal{P}\left(\mathbf{x} \mid \mathbf{y}<em _mathrm_exp="\mathrm{exp">{\mathrm{exp}}\right)=\frac{\mathcal{P}\left(\mathbf{y}</em>
$$}} \mid \mathbf{x}\right) \mathcal{P}(\mathbf{x})}{\mathcal{P}\left(\mathbf{y}_{\mathrm{exp}}\right)</p>
<p>Here $\mathcal{P}(\mathbf{x})$ is prior probability for the parameters $\mathbf{x}$, and $\mathcal{P}\left(\mathbf{y}<em _exp="{exp" _text="\text">{\text {exp }} \mid \mathbf{x}\right)$ is the likelihood function, describing the probability that model output with a given set of model parameters $x$ agrees with the experimental data $\mathbf{y}</em>$. It is usually assumed to be a Gaussian,}</p>
<p>$$
\mathcal{P}\left(\mathbf{y}_{\exp } \mid \mathbf{x}\right)=\frac{1}{\sqrt{|2 \pi \boldsymbol{\Sigma}|}} \exp \left[-\frac{1}{2} \mathbf{y}^{\top} \boldsymbol{\Sigma}^{-1} \mathbf{y}\right]
$$</p>
<p>where $\mathbf{y} \equiv\left[\mathbf{y}<em _exp="{exp" _text="\text">{\text {sim }}(\mathbf{x})-\mathbf{y}</em>}}\right]$ is the deviation between model prediction and experimental measurement, and $\boldsymbol{\Sigma}$ is the total uncertainty, obtained by adding the experimental and simulation uncertainties: $\boldsymbol{\Sigma}=\boldsymbol{\Sigma<em _sim="{sim" _text="\text">{\text {exp }}+\boldsymbol{\Sigma}</em>|$ denotes its determinant.}}(\mathbf{x})$. For heavy ion collisions $\mathbf{y}$ is a vector that can have more than 100 components, and $\boldsymbol{\Sigma}$ is a quadratic matrix of the same dimensionality; $|\boldsymbol{\Sigma</p>
<p>The term $\mathcal{P}\left(\mathbf{x} \mid \mathbf{y}<em _exp="{exp" _text="\text">{\text {exp }}\right)$ on the left hand side of Eq. (16) is called the posterior (short for "the posterior probability density"). It describes the probability of the model parameters $\mathbf{x}$ given the experimental data $\mathbf{y}</em>$}}$, and it is the main quantity of interest in Bayesian parameter inference. Its functional form is generally not known analytically, in particular not for heavy ion collisions. To find the most likely range for the parameters $\mathbf{x}$ and quantify their uncertainty requires numerical techniques for finely sampling the posterior in the neighborhood of the MAP values of the parameters. This is typically achieved by using Markov Chain Monte Carlo (MCMC) techniques. ${ }^{9</p>
<p>For each MCMC sample of the posterior (16) the likelihood function (17) must be evaluated; this requires knowledge of the model prediction $\mathbf{y}<em _sim="{sim" _text="\text">{\text {sim }}$ at the sampled parameter set $\mathbf{x}$. In a high-dimensional parameter space millions of MCMC samples are needed to explore the posterior in sufficient detail. In principle, this requires running the full-model simulation millions of times. For heavy ion collisions this is practically infeasible, due to the computational cost of each model simulation. This is where numerically cheap surrogate models (emulators) for $\mathbf{y}</em>$ when evaluating the}}(\mathbf{x})$ come to the rescue. They can be trained by using very much smaller numbers of full-model simulations (typically hundreds, not millions). They do introduce an additional emulation (or interpolation) uncertainty which is known and can be simply added to the total simulation uncertainty $\boldsymbol{\Sigma}_{\text {sim }</p>
<p><sup id="fnref6:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>Gaussian function (17), but which we want to keep at or below the other uncertainties.</p>
<p>The biggest computational cost is now associated with training the emulators, which requires generating fullmodel simulation output at the training points. The number of training points needed to build an accurate emulator is therefore of crucial importance. For example, one of the very recent Bayesian inference attempts in relativistic heavy ion collisions [67] which went beyond the work in [14] by emulating additional observables and multiple collision systems, used 64 million CPU hours for emulator training. The authors of [67] considered only a single evolution model which does not provide access to estimating modeling uncertainties as in [11].</p>
<p>The analysis in [11] calibrated each of the different model variants by using the same set of training points, thus multiplying the cost of emulator training by the number of variants. For the extended set of collision systems and higher-statistics observables studied in [67] this would already no longer be practical. The transfer learning technique presented in this work lowers this barrier by reducing the number of training points for subsequent model variants once an accurate emulator has been trained for the first model.</p>
<p>The full-model simulations used in this paper take on average $\mathcal{O}(1000)$ CPU hours for each design point in model parameter space [14]. A majority ( $80 \%$ ) of the CPU time is spent on the hadron transport stage after particlization; the remaining CPU time ( $20 \%$ ) is mostly utilized by the hydrodynamic QGP evolution code. In figure 6 we show the CPU hours needed to build accurate emulators for the three target model variants discussed in this work, with or without transfer learning
<img alt="img-5.jpeg" src="img-5.jpeg" /></p>
<p>FIG. 6. Comparison between computational resources used by transfer learning (left blue bars) and the traditional GP emulation method (right orange bars).
from a previously trained source emulator (whose training cost was about $25 \%$ higher than the middle orange bar). ${ }^{10}$ For this plot, we decided on the required number of training samples for each emulator by requiring convergence of the mean squared error to within $10 \%$ of the "asymptotic" accuracy, as shown in Figs. 1-3. We note that the transfer learning method incurs significantly less computational cost compared to the standard GP training protocol. When the source and target models have a much in common (such as the $\mathrm{Pb}+\mathrm{Pb}$ Grad and $\mathrm{Pb}+\mathrm{Pb}$ CE models), the computational savings can exceed an order of magnitude (see right bars in Fig. 6).</p>
<p>We note, however, that the cost for the 100 full-model test samples needed to evaluate the MSE and the cost for determining its "asymptotic" value are not accounted for in Fig. 6. ${ }^{11}$ The (possibly large) computational cost for additional test runs can be largely avoided by using a cross-validation approach [76], which randomly splits the available target data into training and validation sets multiple times. One then obtains an error estimate by fitting the emulator on the training set and testing on the validation set, cycling through the different splits. Cross-validation error estimates, however, are known to be upwardly biased [76]. This should not be a big issue when using the cross-validation MSEs as a criterion for how many full-model target simulations to use in transfer learning. For the current study, however, we were interested in a precise understanding of the convergence properties of the transfer learning method and therefore elected to use unbiased MSE estimators by running a new set of test samples for validation.</p>
<h2>VI. IMPLICATIONS FOR THE STUDY OF HEAVY ION COLLISIONS</h2>
<p>Theoretical progress in the phenomenological study of relativistic heavy ion collisions is made by developing increasingly accurate theoretical models of the collisions that can describe both past and future experimental data. Bayesian parameter estimation in relativistic heavy ion physics approaches this aim in two different ways: First, including more experimental data in the analysis, by using multiple collision systems and adding new observables, leads to tighter bounds on the QGP properties. Second, accounting more faithfully for theoretical uncertainties results in more robust uncertainty estimates for</p>
<p><sup id="fnref7:0"><a class="footnote-ref" href="#fn:0">1</a></sup></p>
<p>the QGP parameters. Accounting for model differences by Bayesian Model Averaging (BMA, as done in [11]) usually results in weaker constraints (broader posteriors) on the plasma properties, but does not account differentially for specific strengths and weaknesses of each model in different regions of parameter space. Bayesian Model Mixing [74, 75] has the potential to mitigate this shortcoming, leading to modeling uncertainties that lie between those of BMA and those of a single model analysis.</p>
<p>For both approaches, improved knowledge extraction comes at a steep computational cost. Mitigation calls for the development of increasingly efficient emulation techniques, to reduce as much as possible the need for computationally expensive runs of increasingly complex models. This work offers transfer learning as one such instrument in the Bayesian inference tool box with the potential for significant numerical cost savings. As shown in Sec. III, it addresses both the need for including more observables and for studying multiple variants of the theoretical model. By cutting the cost of Bayesian parameter estimation, we open the door to viable systematic analyses of measurements from heavy ion data from multiple collision systems, accounting for multiple sources of theoretical model uncertainties, and yielding increasingly accurate constraints on the properties of the plasma.</p>
<h2>VII. CONCLUSIONS AND OUTLOOK</h2>
<p>In this work we introduced and studied transfer learning as a novel method for training emulators for relativistic heavy ion collision simulations. We showed that this method is surprisingly effective and can significantly reduce the computational cost associated with building emulators. Furthermore, we saw that there is a wealth of information in the discrepancy GP which is a by-product of transfer learning methods and offers new ways of comparison between different simulation models. To decipher the information in the discrepancy GPs, we performed a global first order Sobol' sensitivity analysis in Sec. IV.</p>
<p>The transfer learning method introduced in this work has the limitation of requiring the same set of parameters in both the target and source models. We have ideas for a more general knowledge transferring framework that can
handle different parameterizations of source and target, but this will have to wait for future work.</p>
<p>The field of relativistic heavy ion collisions has generated a multitude of different dynamical simulation models, and their number keeps growing. A systematic approach to accurately account for the theoretical uncertainties introduced by these model ambiguities is urgently needed from a statistical and informationtheoretical perspective [75]. With the present contribution we hope to help lower the barrier to implementing such a paradigm change.</p>
<h2>ACKNOWLEDGMENTS</h2>
<p>We thank the JETSCAPE Collaboration for providing the relativistic heavy ion collision simulation data used in this work. D.L., D.E. and U.H. were supported by the NSF CSSI program under grant OAC-2004601, and within the framework of the JETSCAPE Collaboration under NSF Award No. ACI-1550223, as well as by the DOE Office of Science, Office for Nuclear Physics under Award No. DE-SC0004286. J.-F.P. acknowledges support by DOE Award No. DE-FG02-05ER41367. M.H. is supported by the Natural Sciences and Engineering Research Council of Canada.</p>
<h2>Appendix A: Standardization of the observables</h2>
<p>We standardize all simulation data before they are used to train the emulators. This is achieved by performing a standard normal transformation (A1) on the training and test data, using the means and variances of the predicted observables of our source model, i.e. for $\mathrm{Pb}+\mathrm{Pb}$ collisions at $\sqrt{s_{\mathrm{NN}}}=2.76 \mathrm{TeV}$ with Grad viscous corrections:
$\tilde{Y}<em j="j">{j}^{l}=\frac{Y</em>$,
$\mu_{\text {Grad }}^{l}=\sum_{i} \frac{Y_{i, \text { Grad }}^{l}}{N_{\text {train }}}, \quad\left(\sigma_{\text {Grad }}^{l}\right)^{2}=\sum_{i} \frac{\left(Y_{i, \text { Grad }}^{l}-\mu_{\text {Grad }}^{l}\right)^{2}}{N_{\text {train }}}$.
$Y_{i, \text { Grad }}^{l}$ is the $l^{\text {th }}$ observable from the source simulation $i$, and $i$ is summed over all events in the training design.
[1] M. Gyulassy and L. McLerran, New forms of QCD matter discovered at RHIC, Nucl. Phys. A 750, 30 (2005), arXiv:nucl-th/0405013.
[2] K. Yagi, T. Hatsuda, and Y. Miake, Quark-Gluon Plasma: From Big Bang to Little Bang, Cambridge Monogr. Part. Phys. Nucl. Phys. Cosmol. 23, 1 (2005).
[3] H. Petersen, C. Coleman-Smith, S. A. Bass, and R. Wolpert, Constraining the initial state granularity with bulk observables in $\mathrm{Au}+\mathrm{Au}$ collisions at $\sqrt{s_{\mathrm{NN}}}=$ 200 GeV , J. Phys. G 38, 045102 (2011), arXiv:1012.4629 [nucl-th].
[4] J. Novak, K. Novak, S. Pratt, J. Vredevoogd, C. Coleman-Smith, and R. Wolpert, Determining Fun-
damental Properties of Matter Created in Ultrarelativistic Heavy-Ion Collisions, Phys. Rev. C89, 034917 (2014), arXiv:1303.5769 [nucl-th].
[5] E. Sangaline and S. Pratt, Toward a deeper understanding of how experiments constrain the underlying physics of heavy-ion collisions, Phys. Rev. C93, 024908 (2016), arXiv:1508.07017 [nucl-th].
[6] J. E. Bernhard, P. W. Marcy, C. E. Coleman-Smith, S. Huzurbazar, R. L. Wolpert, and S. A. Bass, Quantifying properties of hot and dense QCD matter through systematic model-to-data comparison, Phys. Rev. C 91, 054910 (2015), arXiv:1502.00339 [nucl-th].}^{l}-\mu_{\text {Grad }}^{l}}{\sigma_{\text {Grad }}^{l}</p>
<p>[7] J. E. Bernhard, J. S. Moreland, S. A. Bass, J. Liu, and U. Heinz, Applying Bayesian parameter estimation to relativistic heavy-ion collisions: simultaneous characterization of the initial state and quark-gluon plasma medium, Phys. Rev. C94, 024907 (2016), arXiv:1605.03954 [nuclth].
[8] J. S. Moreland, J. E. Bernhard, and S. A. Bass, Bayesian calibration of a hybrid nuclear collision model using p Pb and $\mathrm{Pb}-\mathrm{Pb}$ data at energies available at the CERN Large Hadron Collider, Phys. Rev. C 101, 024911 (2020), arXiv:1808.02106 [nucl-th].
[9] J. E. Bernhard, Bayesian parameter estimation for relativistic heavy-ion collisions, Ph.D. thesis, Duke U. (2018-04-19), arXiv:1804.06469 [nucl-th].
[10] J. E. Bernhard, J. S. Moreland, and S. A. Bass, Bayesian estimation of the specific shear and bulk viscosity of quark-gluon plasma, Nature Phys. 15, 1113 (2019).
[11] D. Everett et al. (JETSCAPE), Phenomenological constraints on the transport properties of QCD matter with data-driven model averaging, Phys. Rev. Lett. 126, 242301 (2021), arXiv:2010.03928 [hep-ph].
[12] G. Nijs, W. van der Schee, U. Gürsoy, and R. Snellings, Transverse momentum differential global analysis of heavy-ion collisions, Phys. Rev. Lett. 126, 202301 (2021), arXiv:2010.15130 [nucl-th].
[13] G. Nijs, W. van der Schee, U. Gürsoy, and R. Snellings, Bayesian analysis of heavy ion collisions with the heavy ion computational framework Trajectum, Phys. Rev. C 103, 054909 (2021), arXiv:2010.15134 [nucl-th].
[14] D. Everett et al. (JETSCAPE), Multisystem Bayesian constraints on the transport coefficients of QCD matter, Phys. Rev. C 103, 054904 (2021), arXiv:2011.01430 [hepph].
[15] R. Trotta, Bayes in the sky: Bayesian inference and model selection in cosmology, Contemporary Physics 49, $71-104$ (2008).
[16] G. Peters, Markov Chain Monte Carlo: stochastic simulation for bayesian inference (2nd ed)., Statistics in Medicine 27, 3213 (2008), https://onlinelibrary.wiley.com/doi/pdf/10.1002/sim. 3240.
[17] T. J. Santner, B. J. Williams, W. I. Notz, and B. J. Williams, The Design and Analysis of Computer Experiments (Springer, 2003).
[18] F. Liu, E. Wang, X.-N. Wang, N. Xu, and B.-W. Zhang, eds., The 28th International Conference on Ultrarelativistic Nucleus-Nucleus Collisions: Quark Matter 2019, Nucl. Phys. A1005 (2020).
[19] https://indico.cern.ch/event/792436/.
[20] S. Bass and A. Dumitru, Dynamics of hot bulk QCD matter: From the quark gluon plasma to hadronic freezeout, Phys. Rev. C 61, 064909 (2000), arXiv:nucl-th/0001033.
[21] C. Nonaka and S. A. Bass, Space-time evolution of bulk QCD matter, Phys. Rev. C75, 014902 (2007), arXiv:nucl-th/0607018 [nucl-th].
[22] T. Hirano, U. Heinz, D. Kharzeev, R. Lacey, and Y. Nara, Mass ordering of differential elliptic flow and its violation for phi mesons, Phys. Rev. C77, 044909 (2008), arXiv:0710.5795 [nucl-th].
[23] H. Petersen, J. Steinheimer, G. Burau, M. Bleicher, and H. Stocker, A Fully Integrated Transport Approach to Heavy Ion Reactions with an Intermediate Hydrodynamic Stage, Phys. Rev. C78, 044901 (2008), arXiv:0806.1695 [nucl-th].
[24] H. Song, S. A. Bass, and U. Heinz, Viscous QCD matter in a hybrid hydrodynamic+Boltzmann approach, Phys. Rev. C83, 024912 (2011), arXiv:1012.0555 [nucl-th].
[25] U. Heinz, C. Shen, and H. Song, The viscosity of quarkgluon plasma at RHIC and the LHC, AIP Conf. Proc. 1441, 766 (2012), arXiv:1108.5323 [nucl-th].
[26] H. Song, S. Bass, and U. Heinz, Spectra and elliptic flow for identified hadrons in 2.76 A TeV $\mathrm{Pb}+\mathrm{Pb}$ collisions, Phys. Rev. C89, 034919 (2014), arXiv:1311.0157 [nuclth].
[27] X. Zhu, F. Meng, H. Song, and Y.-X. Liu, Hybrid model approach for strange and multistrange hadrons in 2.76A $\mathrm{TeV} \mathrm{Pb}+\mathrm{Pb}$ collisions, Phys. Rev. C91, 034904 (2015), arXiv:1501.03286 [nucl-th].
[28] S. Ryu, J.-F. Paquet, C. Shen, G. Denicol, B. Schenke, S. Jeon, and C. Gale, Effects of bulk viscosity and hadronic rescattering in heavy ion collisions at energies available at the BNL Relativistic Heavy Ion Collider and at the CERN Large Hadron Collider, Phys. Rev. C97, 034910 (2018), arXiv:1704.04216 [nucl-th].
[29] C. Gale, S. Jeon, and B. Schenke, Hydrodynamic modeling of heavy-ion collisions, International Journal of Modern Physics A 28, 1340011 (2013), https://doi.org/10.1142/S0217751X13400113.
[30] M. C. Kennedy and A. O'Hagan, Bayesian calibration of computer models, Journal of the Royal Statistical Society: Series B (Statistical Methodology) 63, 425 (2001).
[31] M. C. Kennedy and A. O'Hagan, Predicting the output from a complex computer code when fast approximations are available, Biometrika 87, 1 (2000).
[32] S. J. Pan and Q. Yang, A survey on transfer learning, IEEE Transactions on Knowledge and Data Engineering 22, 1345 (2010).
[33] A. Paleyes, M. Pullin, M. Mahsereci, N. Lawrence, and J. González, Emulation of physical processes with emukit, in Second Workshop on Machine Learning and the Physical Sciences, NeurIPS (2019).
[34] https://github.com/danOSU/ TransferLearningEmulation.
[35] L. Torrey and J. Shavlik, Transfer learning, in Handbook of research on machine learning applications and trends: algorithms, methods, and techniques (IGI global, 2010) pp. 242-264.
[36] https://ftp.cs.wisc.edu/machine-learning/ shavlik-group/torrey.handbook09.pdf.
[37] W. Dai, Q. Yang, G.-R. Xue, and Y. Yu, Boosting for transfer learning, in Proceedings of the 24th International Conference on Machine Learning, ICML '07 (Association for Computing Machinery, New York, NY, USA, 2007) p. 193-200.
[38] D. Pardoe and P. Stone, Boosting for regression transfer, in Proceedings of the 27th International Conference on International Conference on Machine Learning, ICML'10 (Omnipress, Madison, WI, USA, 2010) p. 863-870.
[39] J. Garcke and T. Vanck, Importance weighted inductive transfer learning for regression, in Machine Learning and Knowledge Discovery in Databases, edited by T. Calders, F. Esposito, E. Hüllermeier, and R. Meo (Springer Berlin Heidelberg, Berlin, Heidelberg, 2014) pp. 466-481.
[40] B. Cao, S. J. Pan, Y. Zhang, D.-Y. Yeung, and Q. Yang, Adaptive transfer learning, in proceedings of the AAAI Conference on Artificial Intelligence, Vol. 24 (2010).
[41] F. Zhuang, Z. Qi, K. Duan, D. Xi, Y. Zhu, H. Zhu, H. Xiong, and Q. He, A comprehensive survey on transfer</p>
<p>learning, Proceedings of the IEEE 109, 43 (2020).
[42] C. E. Rasmussen, Gaussian processes in machine learning, in Advanced Lectures on Machine Learning: ML Summer Schools 2003, Canberra, Australia, February 2 14, 2003, Tübingen, Germany, August 4 - 16, 2003, Revised Lectures, edited by O. Bousquet, U. von Luxburg, and G. Rätsch (Springer Berlin Heidelberg, Berlin, Heidelberg, 2004) pp. 63-71.
[43] J. Sacks, W. J. Welch, T. J. Mitchell, and H. P. Wynn, Design and Analysis of Computer Experiments, Statistical Science 4, 409 (1989).
[44] S. Mak, C.-L. Sung, X. Wang, S.-T. Yeh, Y.-H. Chang, V. R. Joseph, V. Yang, and C. F. J. J. Wu, An efficient surrogate model for emulation and physics extraction of large eddy simulations, Journal of the American Statistical Association 113, 1443 (2018).
[45] J. Chen, S. Mak, V. R. Joseph, and C. Zhang, Function-on-function kriging, with applications to threedimensional printing of aortic tissues, Technometrics 63, 384 (2021).
[46] G. Casella and R. L. Berger, Statistical Inference (Cengage Learning, 2021).
[47] J. S. Moreland, J. E. Bernhard, and S. A. Bass, Alternative ansatz to wounded nucleon and binary collision scaling in high-energy nuclear collisions, Phys. Rev. C92, 011901 (2015), arXiv:1412.4708 [nucl-th].
[48] https://github.com/Duke-QCD/trento.git.
[49] J. Liu, C. Shen, and U. Heinz, Pre-equilibrium evolution effects on heavy-ion collision observables, Phys. Rev. C 91, 064906 (2015), [Erratum: Phys.Rev.C 92, 049904 (2015)], arXiv:1504.02160 [nucl-th].
[50] W. Broniowski, W. Florkowski, M. Chojnacki, and A. Kisiel, Free-streaming approximation in early dynamics of relativistic heavy-ion collisions, Phys. Rev. C80, 034902 (2009), arXiv:0812.3393 [nucl-th].
[51] https://github.com/derekeverett/ freestream-milne.
[52] B. Schenke, S. Jeon, and C. Gale, (3+1)D hydrodynamic simulation of relativistic heavy-ion collisions, Phys. Rev. C82, 014903 (2010), arXiv:1004.1408 [hep-ph].
[53] B. Schenke, S. Jeon, and C. Gale, Elliptic and triangular flow in event-by-event (3+1)D viscous hydrodynamics, Phys. Rev. Lett. 106, 042301 (2011), arXiv:1009.3244 [hep-ph].
[54] J.-F. Paquet, C. Shen, G. S. Denicol, M. Luzum, B. Schenke, S. Jeon, and C. Gale, Production of photons in relativistic heavy-ion collisions, Phys. Rev. C93, 044906 (2016), arXiv:1509.06738 [hep-ph].
[55] A. Kurganov and E. Tadmor, New High-Resolution Central Schemes for Nonlinear Conservation Laws and Convection-Diffusion Equations, Journal of Computational Physics 160, 241 (2000).
[56] http://www.physics.mcgill.ca/music/.
[57] F. Cooper and G. Frye, Comment on the single particle distribution in the hydrodynamic and statistical thermodynamic models of multiparticle production, Phys. Rev. D 10, 186 (1974).
[58] F. Cooper, G. Frye, and E. Schonberg, Landau's hydrodynamic model of particle production and electron positron annihilation into hadrons, Phys. Rev. D11, 192
(1975).
[59] H. Grad, On the kinetic theory of rarefied gases, Commun. Pure Appl. Math 2, 331 (1949).
[60] S. Chapman, T. G. Cowling, and D. Burnett, The mathematical theory of non-uniform gases: an account of the kinetic theory of viscosity, thermal conduction and diffusion in gases (Cambridge university press, 1990).
[61] S. Pratt and G. Torrieri, Coupling Relativistic Viscous Hydrodynamics to Boltzmann Descriptions, Phys. Rev. C82, 044901 (2010), arXiv:1003.0413 [nucl-th].
[62] M. McNelis, D. Everett, and U. Heinz, Particlization in fluid dynamical simulations of heavy-ion collisions: The iS3D module, Comput. Phys. Commun. 258, 107604 (2021), arXiv:1912.08271 [nucl-th].
[63] https://github.com/derekeverett/iS3D.
[64] J. Weil et al., Particle production and equilibrium properties within a new hadron transport approach for heavy-ion collisions, Phys. Rev. C94, 054905 (2016), arXiv:1606.06642 [nucl-th].
[65] https://github.com/smash-transport/smash.
[66] M. D. Morris and T. J. Mitchell, Exploratory designs for computational experiments, Journal of Statistical Planning and Inference 43, 381 (1995).
[67] J. E. Parkkila, A. Onnerstad, F. Taghavi, C. Mordasini, A. Bilandzic, and D. J. Kim, New constraints for qcd matter from improved bayesian parameter estimation in heavy-ion collisions at lhc (2021), arXiv:2111.08145 [hepph].
[68] D. Everett, Quantifying the quark-gluon plasma, Ph.D. thesis, The Ohio State University (2021), arXiv:2107.11362 [hep-ph].
[69] B. Iooss and P. Lemaitre, A review on global sensitivity analysis methods, in Uncertainty Management in Simulation-Optimization of Complex Systems (Springer, 2015) pp. 101-122.
[70] J. Jacques, C. Lavergne, and N. Devictor, Sensitivity analysis in presence of model uncertainty and correlated inputs, Reliability Engineering \&amp; System Safety 91, 1126 (2006).
[71] I. M. Sobol', On sensitivity estimation for nonlinear mathematical models, Matematicheskoe modelirovanie 2, 112 (1990).
[72] S. IM, Sensitivity estimates for nonlinear mathematical models, Math. Model. Comput. Exp 1, 407 (1993).
[73] E. Borgonovo, S. Tarantola, E. Plischke, and M. D. Morris, Transformations and invariance in the sensitivity analysis of computer experiments, Journal of the Royal Statistical Society: Series B 76, 925 (2014).
[74] J. R. Coleman, Topics in Bayesian computer model emulation and calibration, with applications to high-energy particle collisions, Ph.D. thesis, Duke University, Department of Statistical Science (2019).
[75] D. R. Phillips et al., Get on the BAND Wagon: A bayesian framework for quantifying model uncertainties in nuclear dynamics, J. Phys. G 48, 072001 (2021), arXiv:2012.07704 [nucl-th].
[76] J. Friedman, T. Hastie, and R. Tibshirani, The Elements of Statistical Learning (Springer Series in Statistics, 2001).</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>10 Different viscous corrections during particlization in the $\mathrm{Pb}+\mathrm{Pb}$ system at LHC energies affect only the hadronic evolution after particlization. Since we take the source simulations as given, we exclude in the figure the computational cost incurred up to particlization. With this accounting, exploring the effects of different viscous corrections in the same collision system requires only $\mathcal{O}(800)$ CPU hours per design point on average, for both emulation methods.
11 Accounting for the cost of generating the 100 full-model test samples would add about 100,000 CPU hours to each of the bars displayed in Fig. 6.&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref3:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref4:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref5:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref6:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref7:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
<li id="fn:1">
<p>${ }^{4}$ Here and in the following "data" is short for "full-model simulation predictions".&#160;<a class="footnote-backref" href="#fnref:1" title="Jump back to footnote 2 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:1" title="Jump back to footnote 2 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>