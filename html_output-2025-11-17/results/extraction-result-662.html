<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Extraction extraction-result-662 - Theorizer</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css">
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <div class="header">
        <a href="../index.html"><i class="fas fa-flask"></i> Theorizer</a>
    </div>

    <div class="content">
        <h1>Extracted Data Details for extraction-result-662</h1>

        <div class="section">
            <h2>Extracted Data (Header)</h2>
            <div class="info-section">
                <p><strong>Extraction ID:</strong> extraction-result-662</p>
                <p><strong>Extraction Schema Used (ID):</strong> <a href="../schemas/extraction-schema-19.html">extraction-schema-19</a></p>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of variability, reproducibility, or stochasticity in language model-driven scientific experiments, including sources of variability, reproducibility metrics, and methods to improve reproducibility.</div>
                <p><strong>Paper ID:</strong> paper-a0b07f40de7b307dfc40e5c569af0d14d4160e8e</p>
                <p><strong>Paper Title:</strong> <a href="https://www.semanticscholar.org/paper/a0b07f40de7b307dfc40e5c569af0d14d4160e8e" target="_blank">Common 7B Language Models Already Possess Strong Math Capabilities</a></p>
                <p><strong>Paper Venue:</strong> arXiv.org</p>
                <p><strong>Paper TL;DR:</strong> This paper shows that the LLaMA-2 7B model with common pre-training already exhibits strong mathematical abilities, as evidenced by its impressive accuracy when selecting the best response from 256 random generations, and finds that simply scaling up the SFT data can significantly enhance the reliability of generating correct answers.</p>
                <p><strong>Paper Abstract:</strong> Mathematical capabilities were previously believed to emerge in common language models only at a very large scale or require extensive math-related pre-training. This paper shows that the LLaMA-2 7B model with common pre-training already exhibits strong mathematical abilities, as evidenced by its impressive accuracy of 97.7% and 72.0% on the GSM8K and MATH benchmarks, respectively, when selecting the best response from 256 random generations. The primary issue with the current base model is the difficulty in consistently eliciting its inherent mathematical capabilities. Notably, the accuracy for the first answer drops to 49.5% and 7.9% on the GSM8K and MATH benchmarks, respectively. We find that simply scaling up the SFT data can significantly enhance the reliability of generating correct answers. However, the potential for extensive scaling is constrained by the scarcity of publicly available math questions. To overcome this limitation, we employ synthetic data, which proves to be nearly as effective as real data and shows no clear saturation when scaled up to approximately one million samples. This straightforward approach achieves an accuracy of 82.6% on GSM8K and 40.6% on MATH using LLaMA-2 7B models, surpassing previous models by 14.2% and 20.8%, respectively. We also provide insights into scaling behaviors across different reasoning complexities and error types.</p>
                <p><strong>Cost:</strong> 0.019</p>
            </div>
        </div>

        <div class="section">
            <h2>Extracted Data (Details)</h2>
            <div class="extraction-instance-container" id="e662.0">
                <h3 class="extraction-instance">Extracted Data Instance 0 (e662.0)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of variability, reproducibility, or stochasticity in language model-driven scientific experiments, including sources of variability, reproducibility metrics, and methods to improve reproducibility.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Pass@N</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Pass@N metric</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A metric that counts a problem as solved if at least one correct answer appears among N random generations; used to reflect a model's potential when multiple stochastic samples are available.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Common 7B Language Models Already Possess Strong Math Capabilities</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>LLaMA-2-7B (SFT variants)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>7B</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Mathematical reasoning / NLP</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_task</strong></td>
                            <td>Solving GSM8K and MATH benchmarks via chain-of-thought generations</td>
                        </tr>
                        <tr>
                            <td><strong>variability_sources</strong></td>
                            <td>Stochastic decoding (sampling randomness across N generations), temperature setting during generation, prompt/CoT sampling variability, model initialization and SFT data differences (amount and synthetic vs real).</td>
                        </tr>
                        <tr>
                            <td><strong>variability_measured</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>variability_metrics</strong></td>
                            <td>Pass@N (proportion of problems solved at least once among N samples).</td>
                        </tr>
                        <tr>
                            <td><strong>variability_results</strong></td>
                            <td>Pass@256 = 97.7% (GSM8K) and 72.0% (MATH) for LLaMA-2-7B (with 7.5K SFT); Pass@1 / first-answer accuracy much lower (49.5% GSM8K, 7.9% MATH) showing large spread across samples.</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_assessed</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_metrics</strong></td>
                            <td>Comparison of Pass@N across different SFT data scales and sampling regimes (Pass@1 vs Pass@256), and comparisons across base models and synthetic/real SFT sets.</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_results</strong></td>
                            <td>Pass@256 changes little with more SFT data, indicating upper capability is stable; primary gains from SFT scaling are in single-sample stability (Pass@1 / PassRatio increases).</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_challenges</strong></td>
                            <td>High variance between individual stochastic generations (many incorrect samples even when correct sample exists among many draws).</td>
                        </tr>
                        <tr>
                            <td><strong>mitigation_methods</strong></td>
                            <td>Scale supervised fine-tuning (SFT) data (real or synthetic) to increase probability that a single generation is correct; increase N and aggregate; use verification/resampling strategies.</td>
                        </tr>
                        <tr>
                            <td><strong>mitigation_effectiveness</strong></td>
                            <td>Scaling SFT from small (7.5K) to large (960K GSM8K synthetic) raised Pass@1-like metrics from ~49.5% to 82.6% (GSM8K) and MATH from ~7.9% to 40.6%, while Pass@256 remained high throughout.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_without_controls</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_runs</strong></td>
                            <td>256 generations per test problem (for Pass@256 and PassRatio@256 evaluations).</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Pass@N shows that correct answers are often present among many stochastic generations (high Pass@256), but single-sample reliability is poor; scaling SFT data strongly increases single-sample reliability while Pass@256 saturates.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Common 7B Language Models Already Possess Strong Math Capabilities', 'publication_date_yy_mm': '2024-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e662.1">
                <h3 class="extraction-instance">Extracted Data Instance 1 (e662.1)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of variability, reproducibility, or stochasticity in language model-driven scientific experiments, including sources of variability, reproducibility metrics, and methods to improve reproducibility.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>PassRatio@N</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>PassRatio@N metric</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Fraction of the N generated answers that are correct for each problem, averaged across problems; used as a lower-variance substitute to Pass@1 for measuring per-sample stability.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Common 7B Language Models Already Possess Strong Math Capabilities</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>LLaMA-2-7B (SFT variants)</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>7B</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Mathematical reasoning / NLP</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_task</strong></td>
                            <td>Measuring within-sample correctness rate among N stochastic outputs</td>
                        </tr>
                        <tr>
                            <td><strong>variability_sources</strong></td>
                            <td>Sampling randomness (temperature and decoding), SFT data scale and composition, CoT length and prompt variability.</td>
                        </tr>
                        <tr>
                            <td><strong>variability_measured</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>variability_metrics</strong></td>
                            <td>PassRatio@N = E[c/N] where c is number of correct answers among N samples.</td>
                        </tr>
                        <tr>
                            <td><strong>variability_results</strong></td>
                            <td>PassRatio@256 = 48.2% (GSM8K) and 7.9% (MATH) for base SFT models, substantially lower than Pass@256, indicating low per-sample correctness frequency.</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_assessed</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_metrics</strong></td>
                            <td>Tracked PassRatio@256 and Pass@256 across increasing SFT data sizes; compared PassRatio growth to Pass@1.</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_results</strong></td>
                            <td>PassRatio@256 increases substantially with more SFT data (mirrors Pass@1 trends), confirming data-scaling reduces sampling variability and raises per-sample correctness rate.</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_challenges</strong></td>
                            <td>Large gap between Pass@256 and PassRatio@256 reveals instability of single-sample outputs even when model capability exists.</td>
                        </tr>
                        <tr>
                            <td><strong>mitigation_methods</strong></td>
                            <td>Increase SFT data scale (real or synthetic), resample training to emphasize longer CoT steps, question verification in synthetic data pipeline.</td>
                        </tr>
                        <tr>
                            <td><strong>mitigation_effectiveness</strong></td>
                            <td>Resampling to increase proportion of complex CoT samples increased PassRatio@256 from 71.1% to 72.8% in one experiment; larger SFT scales produced larger PassRatio improvements (numbers reported across scales).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_without_controls</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_runs</strong></td>
                            <td>256 generations per problem for PassRatio@256 measurement.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>PassRatio@N quantifies the instability (low per-sample correctness) and shows that SFT data scaling is effective at reducing sampling variability and increasing the fraction of correct stochastic outputs.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Common 7B Language Models Already Possess Strong Math Capabilities', 'publication_date_yy_mm': '2024-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e662.2">
                <h3 class="extraction-instance">Extracted Data Instance 2 (e662.2)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of variability, reproducibility, or stochasticity in language model-driven scientific experiments, including sources of variability, reproducibility metrics, and methods to improve reproducibility.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Temperature / Decoding Stochasticity</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Temperature and stochastic decoding settings</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Sampling temperature and decoding strategy (greedy vs sampled) are explicit sources of stochasticity affecting generation diversity and correctness frequency.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Common 7B Language Models Already Possess Strong Math Capabilities</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>LLaMA-2 family; GPT-4 Turbo used for data synthesis</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Mathematical reasoning / NLP</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_task</strong></td>
                            <td>Generation of CoT solutions and synthetic questions, evaluation with multiple stochastic draws</td>
                        </tr>
                        <tr>
                            <td><strong>variability_sources</strong></td>
                            <td>Temperature (authors used 0.7 for evaluation; typical math models use greedy temp=0), decoding strategy (greedy vs sampling), randomness of sampling.</td>
                        </tr>
                        <tr>
                            <td><strong>variability_measured</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>variability_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>variability_results</strong></td>
                            <td>Authors note evaluation uses temperature 0.7 for diversity; comment that most math models use greedy (temp=0) but impact is minimal — no formal quantitative comparison provided.</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_assessed</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_challenges</strong></td>
                            <td>Sampling randomness from temperature and decoding leads to variability between runs and between single-sample outcomes.</td>
                        </tr>
                        <tr>
                            <td><strong>mitigation_methods</strong></td>
                            <td>Authors sometimes compare greedy decoding examples and note using larger N (many samples) or SFT scaling to make single-sample outputs more reliable; they set temperature explicitly in experiments (0.7 evaluation, 1.0 for data synthesis).</td>
                        </tr>
                        <tr>
                            <td><strong>mitigation_effectiveness</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_without_controls</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_runs</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Temperature and decoding choices are recognized as sources of stochasticity; the paper fixes evaluation temperature and demonstrates that data scaling mitigates resultant single-sample instability.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Common 7B Language Models Already Possess Strong Math Capabilities', 'publication_date_yy_mm': '2024-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e662.3">
                <h3 class="extraction-instance">Extracted Data Instance 3 (e662.3)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of variability, reproducibility, or stochasticity in language model-driven scientific experiments, including sources of variability, reproducibility metrics, and methods to improve reproducibility.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>SFT Data Scaling (real vs synthetic)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Supervised fine-tuning (SFT) data scale and synthetic augmentation</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Scaling supervised fine-tuning data with synthetic math questions (generated + verified by GPT-4 Turbo) to reduce output variability and increase single-sample accuracy.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Common 7B Language Models Already Possess Strong Math Capabilities</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>LLaMA-2-7B, LLaMA-2-13B, LLaMA-2-70B, Mistral-7B</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>7B / 13B / 70B depending on experiment</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Mathematical reasoning / NLP</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_task</strong></td>
                            <td>Fine-tuning base LLMs on increasing amounts of math SFT data (real and synthetic) and evaluating on GSM8K and MATH.</td>
                        </tr>
                        <tr>
                            <td><strong>variability_sources</strong></td>
                            <td>Limited SFT data causes instability in single-sample outputs; differences between real vs synthetic SFT quality; distributional mismatch of CoT complexity in training samples.</td>
                        </tr>
                        <tr>
                            <td><strong>variability_measured</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>variability_metrics</strong></td>
                            <td>Pass@1 / PassRatio@256 and Pass@256 as functions of SFT data size.</td>
                        </tr>
                        <tr>
                            <td><strong>variability_results</strong></td>
                            <td>Small SFT (7.5K) yields Pass@1 ~49.5% (GSM8K) and 7.9% (MATH) for LLaMA-2-7B; scaling synthetic SFT to 960K (GSM8K) increases to 82.6% (GSM8K) and 40.6% (MATH) respectively; synthetic data nearly as effective as real per Table 1.</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_assessed</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_metrics</strong></td>
                            <td>Tracked Pass@1 and PassRatio/Pass@256 across SFT scales and synthetic vs real splits; ablations on verification and different synthetic methods.</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_results</strong></td>
                            <td>Synthetic SFT scales show near-perfect scaling behavior and consistent improvements across base models, suggesting reproducible gains from data scaling.</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_challenges</strong></td>
                            <td>Scarcity of public real math questions limits scaling; potential distributional gaps (fewer complex CoT examples) can reduce gains on harder problems.</td>
                        </tr>
                        <tr>
                            <td><strong>mitigation_methods</strong></td>
                            <td>Generate large-scale synthetic SFT (up to ~1M samples) with GPT-4 Turbo, verify generated questions, resample to increase complex CoT proportion, and perform ablations comparing synthetic strategies.</td>
                        </tr>
                        <tr>
                            <td><strong>mitigation_effectiveness</strong></td>
                            <td>Scaling SFT to 960K GSM8K produced +33.1 percentage points over 7.5K baseline (approx., for Pass@1); resampling to increase complex CoT improved PassRatio@256 from 71.1% to 72.8% (reported improvement).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_without_controls</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_runs</strong></td>
                            <td>Evaluations involved 256 stochastic generations per test example; SFT experiments run over 3 epochs with given hyperparameters.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Scaling SFT data — especially with high-quality synthetic questions and verification — is a highly effective mitigation for stochastic instability, substantially increasing single-sample correctness while leaving Pass@256 largely unchanged.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Common 7B Language Models Already Possess Strong Math Capabilities', 'publication_date_yy_mm': '2024-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e662.4">
                <h3 class="extraction-instance">Extracted Data Instance 4 (e662.4)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of variability, reproducibility, or stochasticity in language model-driven scientific experiments, including sources of variability, reproducibility metrics, and methods to improve reproducibility.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Question Verification (synthetic pipeline)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Question verification and refinement in synthetic data generation</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A step in the synthetic data pipeline where generated questions are validated and refined (by attempting solutions/verifiers) to improve synthetic sample quality and downstream stability.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Common 7B Language Models Already Possess Strong Math Capabilities</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-4 Turbo (used for generation/verification) and LLaMA-2-70B for downstream ablation</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Data synthesis for mathematical reasoning</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_task</strong></td>
                            <td>Generating synthetic math questions and chain-of-thought answers, verifying and refining them before SFT.</td>
                        </tr>
                        <tr>
                            <td><strong>variability_sources</strong></td>
                            <td>Noisy or invalid synthetic questions that introduce label noise or distributional artifacts.</td>
                        </tr>
                        <tr>
                            <td><strong>variability_measured</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>variability_metrics</strong></td>
                            <td>Pass@1 on MATH with and without verification (ablation).</td>
                        </tr>
                        <tr>
                            <td><strong>variability_results</strong></td>
                            <td>Question verification yields modest improvements: e.g., Xwin-Math-70B (7.5K) Pass@1 = 28.9% with verification vs 28.1% without (-0.8); at 30K: 37.6% vs 36.6% (-1.0). No significant impact observed on GSM8K.</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_assessed</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_metrics</strong></td>
                            <td>Ablation table comparing with/without verification across SFT sizes (Table 5).</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_results</strong></td>
                            <td>Verification consistently improves performance on MATH by ~0.8–1.0 percentage points in small-scale tests, indicating modest but reproducible quality gains.</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_challenges</strong></td>
                            <td>Verification overhead and imperfect verifier may still miss subtle errors; effect size modest and dataset-dependent.</td>
                        </tr>
                        <tr>
                            <td><strong>mitigation_methods</strong></td>
                            <td>In-prompt verification combining attempted solution and verification to filter/refine questions before SFT.</td>
                        </tr>
                        <tr>
                            <td><strong>mitigation_effectiveness</strong></td>
                            <td>Small but consistent improvement on MATH benchmark (≈0.8–1.0% absolute lift in Pass@1 in ablations reported).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_without_controls</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_runs</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Question verification in synthetic pipelines slightly improves downstream single-sample accuracy on harder benchmarks (MATH) and is an inexpensive mitigation to reduce noisy synthetic variability.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Common 7B Language Models Already Possess Strong Math Capabilities', 'publication_date_yy_mm': '2024-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e662.5">
                <h3 class="extraction-instance">Extracted Data Instance 5 (e662.5)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of variability, reproducibility, or stochasticity in language model-driven scientific experiments, including sources of variability, reproducibility metrics, and methods to improve reproducibility.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Single-step accuracy model</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Estimated single-step reasoning accuracy (Acc_step) derived from Acc_final = Acc_step^s</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A model that relates final-answer accuracy to per-step reasoning accuracy across s Chain-of-Thought steps, enabling estimation of single-step reliability from observed final accuracies.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Common 7B Language Models Already Possess Strong Math Capabilities</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Xwin-Math-7B variants</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>7B</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Mathematical reasoning / analysis of stochastic error propagation</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_task</strong></td>
                            <td>Inferring per-step error rates from final-answer accuracies across problems annotated with s CoT steps.</td>
                        </tr>
                        <tr>
                            <td><strong>variability_sources</strong></td>
                            <td>Per-step inference error variability, heterogeneous CoT lengths across problems, sampling variability across generations.</td>
                        </tr>
                        <tr>
                            <td><strong>variability_measured</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>variability_metrics</strong></td>
                            <td>Estimated Acc_step computed from Acc_final and annotated s; also normalized first-error position (as measured by GPT-4 Turbo).</td>
                        </tr>
                        <tr>
                            <td><strong>variability_results</strong></td>
                            <td>Estimated Acc_step improves with SFT data: 78.9% (7.5K), 89.7% (120K), 94.2% (960K); normalized first-error position increases from 67.1 to 90.9 across same scales, indicating later occurrence of the first mistake with more data.</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_assessed</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_metrics</strong></td>
                            <td>Fitted Acc_step values over several SFT sizes and fits using different subsets (first four points vs all points) to examine fit quality.</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_results</strong></td>
                            <td>Acc_step estimates are reproducible across experiments and indicate that SFT scaling increases per-step reliability; however, deviations for the largest scales suggest distributional effects (fewer hard problems in training).</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_challenges</strong></td>
                            <td>Model assumes independence of steps and consistent s across methods; fit deviations indicate real-data heterogeneity (complex problems underrepresented).</td>
                        </tr>
                        <tr>
                            <td><strong>mitigation_methods</strong></td>
                            <td>Resample training to increase proportion of problems with longer CoT to improve Acc_step for complex questions.</td>
                        </tr>
                        <tr>
                            <td><strong>mitigation_effectiveness</strong></td>
                            <td>Resampling improved accuracy for complex questions and increased PassRatio@256 modestly (example: 71.1% → 72.8%).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_without_controls</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_runs</strong></td>
                            <td>256 generations per test question used to estimate Acc_final distributions.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Modeling final accuracy as Acc_step^s provides a useful lens: SFT scaling raises per-step accuracy significantly, which explains much of the observed stabilization in final answers; targeted resampling further mitigates complex-step failures.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Common 7B Language Models Already Possess Strong Math Capabilities', 'publication_date_yy_mm': '2024-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e662.6">
                <h3 class="extraction-instance">Extracted Data Instance 6 (e662.6)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of variability, reproducibility, or stochasticity in language model-driven scientific experiments, including sources of variability, reproducibility metrics, and methods to improve reproducibility.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Error-type analysis</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Calculation vs reasoning error breakdown</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>Categorization and tracking of error types during SFT scaling to determine which error modes are most readily corrected by increased data.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Common 7B Language Models Already Possess Strong Math Capabilities</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Xwin-Math-7B</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>7B</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Mathematical reasoning / error analysis</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_task</strong></td>
                            <td>Classify incorrect answers into calculation errors (numeric/computation) vs reasoning errors (conceptual, condition loss) and track proportions as SFT data scales.</td>
                        </tr>
                        <tr>
                            <td><strong>variability_sources</strong></td>
                            <td>Model reasoning process stochasticity, dataset composition (complex vs simple problems), and training target quality.</td>
                        </tr>
                        <tr>
                            <td><strong>variability_measured</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>variability_metrics</strong></td>
                            <td>Proportion of error types (calculation vs reasoning) across SFT scales (visualized in Figure 5).</td>
                        </tr>
                        <tr>
                            <td><strong>variability_results</strong></td>
                            <td>As SFT synthetic data increases, the percentage of calculation errors decreases more rapidly than reasoning errors; exact percentages not fully enumerated but trend clearly reported.</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_assessed</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_metrics</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_results</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_challenges</strong></td>
                            <td>Reasoning errors are more persistent and less addressed by naive SFT scaling compared to calculation errors.</td>
                        </tr>
                        <tr>
                            <td><strong>mitigation_methods</strong></td>
                            <td>Resampling to include more complex CoT examples and targeted data selection to improve reasoning-chain robustness.</td>
                        </tr>
                        <tr>
                            <td><strong>mitigation_effectiveness</strong></td>
                            <td>Observed trend that calculation mistakes decline faster than reasoning mistakes with increased SFT; no explicit numeric reduction reported beyond plots.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_without_controls</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_runs</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Scaling SFT data reduces numerical calculation errors substantially faster than conceptual reasoning errors, indicating different mitigation needs for the two error classes.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Common 7B Language Models Already Possess Strong Math Capabilities', 'publication_date_yy_mm': '2024-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e662.7">
                <h3 class="extraction-instance">Extracted Data Instance 7 (e662.7)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of variability, reproducibility, or stochasticity in language model-driven scientific experiments, including sources of variability, reproducibility metrics, and methods to improve reproducibility.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Leakage / LM loss check (Δ1, Δ2)</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>LM loss comparison metrics for synthetic data leakage detection (Δ1, Δ2)</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A validation that synthetic data generation did not leak evaluation benchmarks, using comparisons of language-model loss across regenerated and reference sets and two derived deltas (Δ1, Δ2).</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Common 7B Language Models Already Possess Strong Math Capabilities</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>GPT-4 Turbo (for regeneration), evaluated LM loss on LLaMA-based fine-tuned models</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Data synthesis validation / ML evaluation</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_task</strong></td>
                            <td>Detecting possible benchmark data leakage in synthetic generation by comparing LM loss on train/regenerated/test/regenerated-reference datasets and computing Δ1 and Δ2.</td>
                        </tr>
                        <tr>
                            <td><strong>variability_sources</strong></td>
                            <td>Potential overlap/leakage between training seeds and evaluation questions, regeneration strategy randomness.</td>
                        </tr>
                        <tr>
                            <td><strong>variability_measured</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>variability_metrics</strong></td>
                            <td>LM loss on: test-regen, test-ref, train, train-regen; Δ1 = L_test-regen - L_test-ref; Δ2 = L_test-regen - L_train-regen.</td>
                        </tr>
                        <tr>
                            <td><strong>variability_results</strong></td>
                            <td>Reported values: GSM8K: L_test-regen=0.52, L_test-ref=0.50, L_train=0.11, L_train-regen=0.33, Δ1=0.02, Δ2=0.19. MATH: L_test-regen=0.59, L_test-ref=0.58, L_train=0.23, L_train-regen=0.39, Δ1=0.01, Δ2=0.20. Authors interpret Δ1≈0 and Δ2≫0 as evidence of no leakage.</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_assessed</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_metrics</strong></td>
                            <td>Δ1 and Δ2 metrics as above; comparison across two benchmarks.</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_results</strong></td>
                            <td>Δ1 small (~0.01–0.02) and Δ2 substantial (~0.19–0.20) supports claim that regenerated test data are similar to reference test while differing from regenerated training, indicating no obvious leakage.</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_challenges</strong></td>
                            <td>LM loss comparisons are an indirect test; small Δ1 does not guarantee zero overlap but authors conclude no leakage.</td>
                        </tr>
                        <tr>
                            <td><strong>mitigation_methods</strong></td>
                            <td>Regenerate answers/questions for training/test subsets and compute LM loss deltas to detect unnatural closeness implying leakage.</td>
                        </tr>
                        <tr>
                            <td><strong>mitigation_effectiveness</strong></td>
                            <td>Quantitatively supports low risk of leakage for the reported synthetic generation process given observed deltas.</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_without_controls</strong></td>
                            <td>False</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_runs</strong></td>
                            <td><span class="empty-note">null</span></td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Using LM loss deltas (Δ1, Δ2) is an effective quantitative check for synthetic-data leakage; reported small Δ1 and large Δ2 are interpreted as evidence that the synthetic pipeline did not leak evaluation questions into training.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Common 7B Language Models Already Possess Strong Math Capabilities', 'publication_date_yy_mm': '2024-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
            <div class="extraction-instance-container" id="e662.8">
                <h3 class="extraction-instance">Extracted Data Instance 8 (e662.8)</h3>
                <div class="extraction-query"><strong>Extraction Query:</strong> Extract any mentions of variability, reproducibility, or stochasticity in language model-driven scientific experiments, including sources of variability, reproducibility metrics, and methods to improve reproducibility.</div>
                <table>
                    <thead>
                        <tr>
                            <th style="width: 30%;">Field</th>
                            <th style="width: 70%;">Value</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>name_short</strong></td>
                            <td>Resampling CoT complexity</td>
                        </tr>
                        <tr>
                            <td><strong>name_full</strong></td>
                            <td>Resampling training data to increase Chain-of-Thought (CoT) length proportion</td>
                        </tr>
                        <tr>
                            <td><strong>brief_description</strong></td>
                            <td>A data selection/resampling intervention to increase the share of training samples with longer CoT solutions to raise performance on complex problems and improve single-sample stability.</td>
                        </tr>
                        <tr>
                            <td><strong>citation_title</strong></td>
                            <td>Common 7B Language Models Already Possess Strong Math Capabilities</td>
                        </tr>
                        <tr>
                            <td><strong>mention_or_use</strong></td>
                            <td>use</td>
                        </tr>
                        <tr>
                            <td><strong>model_name</strong></td>
                            <td>Xwin-Math-7B</td>
                        </tr>
                        <tr>
                            <td><strong>model_size</strong></td>
                            <td>7B</td>
                        </tr>
                        <tr>
                            <td><strong>scientific_domain</strong></td>
                            <td>Data augmentation for reasoning tasks</td>
                        </tr>
                        <tr>
                            <td><strong>experimental_task</strong></td>
                            <td>Resampling the 960K synthetic dataset to upweight problems with longer annotated CoT steps and measuring effects on accuracy across CoT lengths.</td>
                        </tr>
                        <tr>
                            <td><strong>variability_sources</strong></td>
                            <td>Imbalanced distribution of CoT lengths in training data leading to underperformance on multi-step problems.</td>
                        </tr>
                        <tr>
                            <td><strong>variability_measured</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>variability_metrics</strong></td>
                            <td>Change in mean accuracy versus annotated CoT steps; change in PassRatio@256 before/after resampling.</td>
                        </tr>
                        <tr>
                            <td><strong>variability_results</strong></td>
                            <td>Resampling increased accuracy for harder (longer CoT) problems without degrading simpler-problem accuracy; PassRatio@256 increased from 71.1% to 72.8% after resampling.</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_assessed</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_metrics</strong></td>
                            <td>Before/after resampling comparisons on GSM8K with same model and evaluation protocol.</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_results</strong></td>
                            <td>Observed reproducible gains for complex problems and modest improvement in overall per-sample correctness rate.</td>
                        </tr>
                        <tr>
                            <td><strong>reproducibility_challenges</strong></td>
                            <td>Requires reliable annotation of CoT length and careful selection to avoid distributional mismatch.</td>
                        </tr>
                        <tr>
                            <td><strong>mitigation_methods</strong></td>
                            <td>Resample training distribution to upweight long-CoT problems; combine with large SFT scale.</td>
                        </tr>
                        <tr>
                            <td><strong>mitigation_effectiveness</strong></td>
                            <td>Improved accuracy for complex problems and modest overall PassRatio gain (≈1.7 percentage points increase in reported example).</td>
                        </tr>
                        <tr>
                            <td><strong>comparison_with_without_controls</strong></td>
                            <td>True</td>
                        </tr>
                        <tr>
                            <td><strong>number_of_runs</strong></td>
                            <td>256 generations per test problem used for evaluation comparisons.</td>
                        </tr>
                        <tr>
                            <td><strong>key_findings</strong></td>
                            <td>Targeted resampling to increase CoT complexity in training data is an effective and reproducible method to improve multi-step reasoning reliability and single-sample stability.</td>
                        </tr>
                        <tr>
                            <td><strong>source_info</strong></td>
                            <td>{'paper_title': 'Common 7B Language Models Already Possess Strong Math Capabilities', 'publication_date_yy_mm': '2024-03'}</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="section">
            <h2>Potentially Relevant New Papers (mentioned by this paper)</h2>
            <ol>
                <li>Let's verify step by step <em>(Rating: 2)</em></li>
                <li>Chain-of-thought prompting elicits reasoning in large language models <em>(Rating: 2)</em></li>
                <li>Metamath: Bootstrap your own mathematical questions for large language models <em>(Rating: 2)</em></li>
                <li>Training a helpful and harmless assistant with reinforcement learning from human feedback <em>(Rating: 1)</em></li>
                <li>Learning from mistakes makes llm better reasoner <em>(Rating: 1)</em></li>
            </ol>
        </div>

        <div class="section">
            <h2>Extracted Data (Debug)</h2>
            <pre><code>{
    "id": "extraction-result-662",
    "paper_id": "paper-a0b07f40de7b307dfc40e5c569af0d14d4160e8e",
    "extraction_schema_id": "extraction-schema-19",
    "extracted_data": [
        {
            "name_short": "Pass@N",
            "name_full": "Pass@N metric",
            "brief_description": "A metric that counts a problem as solved if at least one correct answer appears among N random generations; used to reflect a model's potential when multiple stochastic samples are available.",
            "citation_title": "Common 7B Language Models Already Possess Strong Math Capabilities",
            "mention_or_use": "use",
            "model_name": "LLaMA-2-7B (SFT variants)",
            "model_size": "7B",
            "scientific_domain": "Mathematical reasoning / NLP",
            "experimental_task": "Solving GSM8K and MATH benchmarks via chain-of-thought generations",
            "variability_sources": "Stochastic decoding (sampling randomness across N generations), temperature setting during generation, prompt/CoT sampling variability, model initialization and SFT data differences (amount and synthetic vs real).",
            "variability_measured": true,
            "variability_metrics": "Pass@N (proportion of problems solved at least once among N samples).",
            "variability_results": "Pass@256 = 97.7% (GSM8K) and 72.0% (MATH) for LLaMA-2-7B (with 7.5K SFT); Pass@1 / first-answer accuracy much lower (49.5% GSM8K, 7.9% MATH) showing large spread across samples.",
            "reproducibility_assessed": true,
            "reproducibility_metrics": "Comparison of Pass@N across different SFT data scales and sampling regimes (Pass@1 vs Pass@256), and comparisons across base models and synthetic/real SFT sets.",
            "reproducibility_results": "Pass@256 changes little with more SFT data, indicating upper capability is stable; primary gains from SFT scaling are in single-sample stability (Pass@1 / PassRatio increases).",
            "reproducibility_challenges": "High variance between individual stochastic generations (many incorrect samples even when correct sample exists among many draws).",
            "mitigation_methods": "Scale supervised fine-tuning (SFT) data (real or synthetic) to increase probability that a single generation is correct; increase N and aggregate; use verification/resampling strategies.",
            "mitigation_effectiveness": "Scaling SFT from small (7.5K) to large (960K GSM8K synthetic) raised Pass@1-like metrics from ~49.5% to 82.6% (GSM8K) and MATH from ~7.9% to 40.6%, while Pass@256 remained high throughout.",
            "comparison_with_without_controls": true,
            "number_of_runs": "256 generations per test problem (for Pass@256 and PassRatio@256 evaluations).",
            "key_findings": "Pass@N shows that correct answers are often present among many stochastic generations (high Pass@256), but single-sample reliability is poor; scaling SFT data strongly increases single-sample reliability while Pass@256 saturates.",
            "uuid": "e662.0",
            "source_info": {
                "paper_title": "Common 7B Language Models Already Possess Strong Math Capabilities",
                "publication_date_yy_mm": "2024-03"
            }
        },
        {
            "name_short": "PassRatio@N",
            "name_full": "PassRatio@N metric",
            "brief_description": "Fraction of the N generated answers that are correct for each problem, averaged across problems; used as a lower-variance substitute to Pass@1 for measuring per-sample stability.",
            "citation_title": "Common 7B Language Models Already Possess Strong Math Capabilities",
            "mention_or_use": "use",
            "model_name": "LLaMA-2-7B (SFT variants)",
            "model_size": "7B",
            "scientific_domain": "Mathematical reasoning / NLP",
            "experimental_task": "Measuring within-sample correctness rate among N stochastic outputs",
            "variability_sources": "Sampling randomness (temperature and decoding), SFT data scale and composition, CoT length and prompt variability.",
            "variability_measured": true,
            "variability_metrics": "PassRatio@N = E[c/N] where c is number of correct answers among N samples.",
            "variability_results": "PassRatio@256 = 48.2% (GSM8K) and 7.9% (MATH) for base SFT models, substantially lower than Pass@256, indicating low per-sample correctness frequency.",
            "reproducibility_assessed": true,
            "reproducibility_metrics": "Tracked PassRatio@256 and Pass@256 across increasing SFT data sizes; compared PassRatio growth to Pass@1.",
            "reproducibility_results": "PassRatio@256 increases substantially with more SFT data (mirrors Pass@1 trends), confirming data-scaling reduces sampling variability and raises per-sample correctness rate.",
            "reproducibility_challenges": "Large gap between Pass@256 and PassRatio@256 reveals instability of single-sample outputs even when model capability exists.",
            "mitigation_methods": "Increase SFT data scale (real or synthetic), resample training to emphasize longer CoT steps, question verification in synthetic data pipeline.",
            "mitigation_effectiveness": "Resampling to increase proportion of complex CoT samples increased PassRatio@256 from 71.1% to 72.8% in one experiment; larger SFT scales produced larger PassRatio improvements (numbers reported across scales).",
            "comparison_with_without_controls": true,
            "number_of_runs": "256 generations per problem for PassRatio@256 measurement.",
            "key_findings": "PassRatio@N quantifies the instability (low per-sample correctness) and shows that SFT data scaling is effective at reducing sampling variability and increasing the fraction of correct stochastic outputs.",
            "uuid": "e662.1",
            "source_info": {
                "paper_title": "Common 7B Language Models Already Possess Strong Math Capabilities",
                "publication_date_yy_mm": "2024-03"
            }
        },
        {
            "name_short": "Temperature / Decoding Stochasticity",
            "name_full": "Temperature and stochastic decoding settings",
            "brief_description": "Sampling temperature and decoding strategy (greedy vs sampled) are explicit sources of stochasticity affecting generation diversity and correctness frequency.",
            "citation_title": "Common 7B Language Models Already Possess Strong Math Capabilities",
            "mention_or_use": "use",
            "model_name": "LLaMA-2 family; GPT-4 Turbo used for data synthesis",
            "model_size": null,
            "scientific_domain": "Mathematical reasoning / NLP",
            "experimental_task": "Generation of CoT solutions and synthetic questions, evaluation with multiple stochastic draws",
            "variability_sources": "Temperature (authors used 0.7 for evaluation; typical math models use greedy temp=0), decoding strategy (greedy vs sampling), randomness of sampling.",
            "variability_measured": false,
            "variability_metrics": null,
            "variability_results": "Authors note evaluation uses temperature 0.7 for diversity; comment that most math models use greedy (temp=0) but impact is minimal — no formal quantitative comparison provided.",
            "reproducibility_assessed": false,
            "reproducibility_metrics": null,
            "reproducibility_results": null,
            "reproducibility_challenges": "Sampling randomness from temperature and decoding leads to variability between runs and between single-sample outcomes.",
            "mitigation_methods": "Authors sometimes compare greedy decoding examples and note using larger N (many samples) or SFT scaling to make single-sample outputs more reliable; they set temperature explicitly in experiments (0.7 evaluation, 1.0 for data synthesis).",
            "mitigation_effectiveness": null,
            "comparison_with_without_controls": true,
            "number_of_runs": null,
            "key_findings": "Temperature and decoding choices are recognized as sources of stochasticity; the paper fixes evaluation temperature and demonstrates that data scaling mitigates resultant single-sample instability.",
            "uuid": "e662.2",
            "source_info": {
                "paper_title": "Common 7B Language Models Already Possess Strong Math Capabilities",
                "publication_date_yy_mm": "2024-03"
            }
        },
        {
            "name_short": "SFT Data Scaling (real vs synthetic)",
            "name_full": "Supervised fine-tuning (SFT) data scale and synthetic augmentation",
            "brief_description": "Scaling supervised fine-tuning data with synthetic math questions (generated + verified by GPT-4 Turbo) to reduce output variability and increase single-sample accuracy.",
            "citation_title": "Common 7B Language Models Already Possess Strong Math Capabilities",
            "mention_or_use": "use",
            "model_name": "LLaMA-2-7B, LLaMA-2-13B, LLaMA-2-70B, Mistral-7B",
            "model_size": "7B / 13B / 70B depending on experiment",
            "scientific_domain": "Mathematical reasoning / NLP",
            "experimental_task": "Fine-tuning base LLMs on increasing amounts of math SFT data (real and synthetic) and evaluating on GSM8K and MATH.",
            "variability_sources": "Limited SFT data causes instability in single-sample outputs; differences between real vs synthetic SFT quality; distributional mismatch of CoT complexity in training samples.",
            "variability_measured": true,
            "variability_metrics": "Pass@1 / PassRatio@256 and Pass@256 as functions of SFT data size.",
            "variability_results": "Small SFT (7.5K) yields Pass@1 ~49.5% (GSM8K) and 7.9% (MATH) for LLaMA-2-7B; scaling synthetic SFT to 960K (GSM8K) increases to 82.6% (GSM8K) and 40.6% (MATH) respectively; synthetic data nearly as effective as real per Table 1.",
            "reproducibility_assessed": true,
            "reproducibility_metrics": "Tracked Pass@1 and PassRatio/Pass@256 across SFT scales and synthetic vs real splits; ablations on verification and different synthetic methods.",
            "reproducibility_results": "Synthetic SFT scales show near-perfect scaling behavior and consistent improvements across base models, suggesting reproducible gains from data scaling.",
            "reproducibility_challenges": "Scarcity of public real math questions limits scaling; potential distributional gaps (fewer complex CoT examples) can reduce gains on harder problems.",
            "mitigation_methods": "Generate large-scale synthetic SFT (up to ~1M samples) with GPT-4 Turbo, verify generated questions, resample to increase complex CoT proportion, and perform ablations comparing synthetic strategies.",
            "mitigation_effectiveness": "Scaling SFT to 960K GSM8K produced +33.1 percentage points over 7.5K baseline (approx., for Pass@1); resampling to increase complex CoT improved PassRatio@256 from 71.1% to 72.8% (reported improvement).",
            "comparison_with_without_controls": true,
            "number_of_runs": "Evaluations involved 256 stochastic generations per test example; SFT experiments run over 3 epochs with given hyperparameters.",
            "key_findings": "Scaling SFT data — especially with high-quality synthetic questions and verification — is a highly effective mitigation for stochastic instability, substantially increasing single-sample correctness while leaving Pass@256 largely unchanged.",
            "uuid": "e662.3",
            "source_info": {
                "paper_title": "Common 7B Language Models Already Possess Strong Math Capabilities",
                "publication_date_yy_mm": "2024-03"
            }
        },
        {
            "name_short": "Question Verification (synthetic pipeline)",
            "name_full": "Question verification and refinement in synthetic data generation",
            "brief_description": "A step in the synthetic data pipeline where generated questions are validated and refined (by attempting solutions/verifiers) to improve synthetic sample quality and downstream stability.",
            "citation_title": "Common 7B Language Models Already Possess Strong Math Capabilities",
            "mention_or_use": "use",
            "model_name": "GPT-4 Turbo (used for generation/verification) and LLaMA-2-70B for downstream ablation",
            "model_size": null,
            "scientific_domain": "Data synthesis for mathematical reasoning",
            "experimental_task": "Generating synthetic math questions and chain-of-thought answers, verifying and refining them before SFT.",
            "variability_sources": "Noisy or invalid synthetic questions that introduce label noise or distributional artifacts.",
            "variability_measured": true,
            "variability_metrics": "Pass@1 on MATH with and without verification (ablation).",
            "variability_results": "Question verification yields modest improvements: e.g., Xwin-Math-70B (7.5K) Pass@1 = 28.9% with verification vs 28.1% without (-0.8); at 30K: 37.6% vs 36.6% (-1.0). No significant impact observed on GSM8K.",
            "reproducibility_assessed": true,
            "reproducibility_metrics": "Ablation table comparing with/without verification across SFT sizes (Table 5).",
            "reproducibility_results": "Verification consistently improves performance on MATH by ~0.8–1.0 percentage points in small-scale tests, indicating modest but reproducible quality gains.",
            "reproducibility_challenges": "Verification overhead and imperfect verifier may still miss subtle errors; effect size modest and dataset-dependent.",
            "mitigation_methods": "In-prompt verification combining attempted solution and verification to filter/refine questions before SFT.",
            "mitigation_effectiveness": "Small but consistent improvement on MATH benchmark (≈0.8–1.0% absolute lift in Pass@1 in ablations reported).",
            "comparison_with_without_controls": true,
            "number_of_runs": null,
            "key_findings": "Question verification in synthetic pipelines slightly improves downstream single-sample accuracy on harder benchmarks (MATH) and is an inexpensive mitigation to reduce noisy synthetic variability.",
            "uuid": "e662.4",
            "source_info": {
                "paper_title": "Common 7B Language Models Already Possess Strong Math Capabilities",
                "publication_date_yy_mm": "2024-03"
            }
        },
        {
            "name_short": "Single-step accuracy model",
            "name_full": "Estimated single-step reasoning accuracy (Acc_step) derived from Acc_final = Acc_step^s",
            "brief_description": "A model that relates final-answer accuracy to per-step reasoning accuracy across s Chain-of-Thought steps, enabling estimation of single-step reliability from observed final accuracies.",
            "citation_title": "Common 7B Language Models Already Possess Strong Math Capabilities",
            "mention_or_use": "use",
            "model_name": "Xwin-Math-7B variants",
            "model_size": "7B",
            "scientific_domain": "Mathematical reasoning / analysis of stochastic error propagation",
            "experimental_task": "Inferring per-step error rates from final-answer accuracies across problems annotated with s CoT steps.",
            "variability_sources": "Per-step inference error variability, heterogeneous CoT lengths across problems, sampling variability across generations.",
            "variability_measured": true,
            "variability_metrics": "Estimated Acc_step computed from Acc_final and annotated s; also normalized first-error position (as measured by GPT-4 Turbo).",
            "variability_results": "Estimated Acc_step improves with SFT data: 78.9% (7.5K), 89.7% (120K), 94.2% (960K); normalized first-error position increases from 67.1 to 90.9 across same scales, indicating later occurrence of the first mistake with more data.",
            "reproducibility_assessed": true,
            "reproducibility_metrics": "Fitted Acc_step values over several SFT sizes and fits using different subsets (first four points vs all points) to examine fit quality.",
            "reproducibility_results": "Acc_step estimates are reproducible across experiments and indicate that SFT scaling increases per-step reliability; however, deviations for the largest scales suggest distributional effects (fewer hard problems in training).",
            "reproducibility_challenges": "Model assumes independence of steps and consistent s across methods; fit deviations indicate real-data heterogeneity (complex problems underrepresented).",
            "mitigation_methods": "Resample training to increase proportion of problems with longer CoT to improve Acc_step for complex questions.",
            "mitigation_effectiveness": "Resampling improved accuracy for complex questions and increased PassRatio@256 modestly (example: 71.1% → 72.8%).",
            "comparison_with_without_controls": true,
            "number_of_runs": "256 generations per test question used to estimate Acc_final distributions.",
            "key_findings": "Modeling final accuracy as Acc_step^s provides a useful lens: SFT scaling raises per-step accuracy significantly, which explains much of the observed stabilization in final answers; targeted resampling further mitigates complex-step failures.",
            "uuid": "e662.5",
            "source_info": {
                "paper_title": "Common 7B Language Models Already Possess Strong Math Capabilities",
                "publication_date_yy_mm": "2024-03"
            }
        },
        {
            "name_short": "Error-type analysis",
            "name_full": "Calculation vs reasoning error breakdown",
            "brief_description": "Categorization and tracking of error types during SFT scaling to determine which error modes are most readily corrected by increased data.",
            "citation_title": "Common 7B Language Models Already Possess Strong Math Capabilities",
            "mention_or_use": "use",
            "model_name": "Xwin-Math-7B",
            "model_size": "7B",
            "scientific_domain": "Mathematical reasoning / error analysis",
            "experimental_task": "Classify incorrect answers into calculation errors (numeric/computation) vs reasoning errors (conceptual, condition loss) and track proportions as SFT data scales.",
            "variability_sources": "Model reasoning process stochasticity, dataset composition (complex vs simple problems), and training target quality.",
            "variability_measured": true,
            "variability_metrics": "Proportion of error types (calculation vs reasoning) across SFT scales (visualized in Figure 5).",
            "variability_results": "As SFT synthetic data increases, the percentage of calculation errors decreases more rapidly than reasoning errors; exact percentages not fully enumerated but trend clearly reported.",
            "reproducibility_assessed": false,
            "reproducibility_metrics": null,
            "reproducibility_results": null,
            "reproducibility_challenges": "Reasoning errors are more persistent and less addressed by naive SFT scaling compared to calculation errors.",
            "mitigation_methods": "Resampling to include more complex CoT examples and targeted data selection to improve reasoning-chain robustness.",
            "mitigation_effectiveness": "Observed trend that calculation mistakes decline faster than reasoning mistakes with increased SFT; no explicit numeric reduction reported beyond plots.",
            "comparison_with_without_controls": false,
            "number_of_runs": null,
            "key_findings": "Scaling SFT data reduces numerical calculation errors substantially faster than conceptual reasoning errors, indicating different mitigation needs for the two error classes.",
            "uuid": "e662.6",
            "source_info": {
                "paper_title": "Common 7B Language Models Already Possess Strong Math Capabilities",
                "publication_date_yy_mm": "2024-03"
            }
        },
        {
            "name_short": "Leakage / LM loss check (Δ1, Δ2)",
            "name_full": "LM loss comparison metrics for synthetic data leakage detection (Δ1, Δ2)",
            "brief_description": "A validation that synthetic data generation did not leak evaluation benchmarks, using comparisons of language-model loss across regenerated and reference sets and two derived deltas (Δ1, Δ2).",
            "citation_title": "Common 7B Language Models Already Possess Strong Math Capabilities",
            "mention_or_use": "use",
            "model_name": "GPT-4 Turbo (for regeneration), evaluated LM loss on LLaMA-based fine-tuned models",
            "model_size": null,
            "scientific_domain": "Data synthesis validation / ML evaluation",
            "experimental_task": "Detecting possible benchmark data leakage in synthetic generation by comparing LM loss on train/regenerated/test/regenerated-reference datasets and computing Δ1 and Δ2.",
            "variability_sources": "Potential overlap/leakage between training seeds and evaluation questions, regeneration strategy randomness.",
            "variability_measured": true,
            "variability_metrics": "LM loss on: test-regen, test-ref, train, train-regen; Δ1 = L_test-regen - L_test-ref; Δ2 = L_test-regen - L_train-regen.",
            "variability_results": "Reported values: GSM8K: L_test-regen=0.52, L_test-ref=0.50, L_train=0.11, L_train-regen=0.33, Δ1=0.02, Δ2=0.19. MATH: L_test-regen=0.59, L_test-ref=0.58, L_train=0.23, L_train-regen=0.39, Δ1=0.01, Δ2=0.20. Authors interpret Δ1≈0 and Δ2≫0 as evidence of no leakage.",
            "reproducibility_assessed": true,
            "reproducibility_metrics": "Δ1 and Δ2 metrics as above; comparison across two benchmarks.",
            "reproducibility_results": "Δ1 small (~0.01–0.02) and Δ2 substantial (~0.19–0.20) supports claim that regenerated test data are similar to reference test while differing from regenerated training, indicating no obvious leakage.",
            "reproducibility_challenges": "LM loss comparisons are an indirect test; small Δ1 does not guarantee zero overlap but authors conclude no leakage.",
            "mitigation_methods": "Regenerate answers/questions for training/test subsets and compute LM loss deltas to detect unnatural closeness implying leakage.",
            "mitigation_effectiveness": "Quantitatively supports low risk of leakage for the reported synthetic generation process given observed deltas.",
            "comparison_with_without_controls": false,
            "number_of_runs": null,
            "key_findings": "Using LM loss deltas (Δ1, Δ2) is an effective quantitative check for synthetic-data leakage; reported small Δ1 and large Δ2 are interpreted as evidence that the synthetic pipeline did not leak evaluation questions into training.",
            "uuid": "e662.7",
            "source_info": {
                "paper_title": "Common 7B Language Models Already Possess Strong Math Capabilities",
                "publication_date_yy_mm": "2024-03"
            }
        },
        {
            "name_short": "Resampling CoT complexity",
            "name_full": "Resampling training data to increase Chain-of-Thought (CoT) length proportion",
            "brief_description": "A data selection/resampling intervention to increase the share of training samples with longer CoT solutions to raise performance on complex problems and improve single-sample stability.",
            "citation_title": "Common 7B Language Models Already Possess Strong Math Capabilities",
            "mention_or_use": "use",
            "model_name": "Xwin-Math-7B",
            "model_size": "7B",
            "scientific_domain": "Data augmentation for reasoning tasks",
            "experimental_task": "Resampling the 960K synthetic dataset to upweight problems with longer annotated CoT steps and measuring effects on accuracy across CoT lengths.",
            "variability_sources": "Imbalanced distribution of CoT lengths in training data leading to underperformance on multi-step problems.",
            "variability_measured": true,
            "variability_metrics": "Change in mean accuracy versus annotated CoT steps; change in PassRatio@256 before/after resampling.",
            "variability_results": "Resampling increased accuracy for harder (longer CoT) problems without degrading simpler-problem accuracy; PassRatio@256 increased from 71.1% to 72.8% after resampling.",
            "reproducibility_assessed": true,
            "reproducibility_metrics": "Before/after resampling comparisons on GSM8K with same model and evaluation protocol.",
            "reproducibility_results": "Observed reproducible gains for complex problems and modest improvement in overall per-sample correctness rate.",
            "reproducibility_challenges": "Requires reliable annotation of CoT length and careful selection to avoid distributional mismatch.",
            "mitigation_methods": "Resample training distribution to upweight long-CoT problems; combine with large SFT scale.",
            "mitigation_effectiveness": "Improved accuracy for complex problems and modest overall PassRatio gain (≈1.7 percentage points increase in reported example).",
            "comparison_with_without_controls": true,
            "number_of_runs": "256 generations per test problem used for evaluation comparisons.",
            "key_findings": "Targeted resampling to increase CoT complexity in training data is an effective and reproducible method to improve multi-step reasoning reliability and single-sample stability.",
            "uuid": "e662.8",
            "source_info": {
                "paper_title": "Common 7B Language Models Already Possess Strong Math Capabilities",
                "publication_date_yy_mm": "2024-03"
            }
        }
    ],
    "potentially_relevant_new_papers": [
        {
            "paper_title": "Let's verify step by step",
            "rating": 2
        },
        {
            "paper_title": "Chain-of-thought prompting elicits reasoning in large language models",
            "rating": 2
        },
        {
            "paper_title": "Metamath: Bootstrap your own mathematical questions for large language models",
            "rating": 2
        },
        {
            "paper_title": "Training a helpful and harmless assistant with reinforcement learning from human feedback",
            "rating": 1
        },
        {
            "paper_title": "Learning from mistakes makes llm better reasoner",
            "rating": 1
        }
    ],
    "cost": 0.0187275,
    "model_str": "gpt-5-mini"
}</code></pre>
        </div>
        <div class="section">
            <h2>Paper</h2>
            <div class="paper-content"><h1>Common 7B Language Models Already Possess Strong Math Capabilities</h1>
<p>Chen Li ${ }^{1,4}$, Weiqi Wang ${ }^{2,4}$, Jingcheng $\mathbf{H u}^{3,4}$, Yixuan Wei ${ }^{3,4}$, Nanning Zheng ${ }^{1}$, Han $\mathbf{H u}^{4}$, Zheng Zhang ${ }^{4 <em>}$, Houwen Peng ${ }^{4 </em>}$<br>${ }^{1}$ IAIR, Xi'an Jiaotong University ${ }^{2}$ University of Science and Technology of China<br>${ }^{3}$ Tsinghua University ${ }^{4}$ Microsoft Research Asia<br>edward82@stu.xjtu.edu.cn {v-weiqiwang, t-jingchu, t-yixuanwei, zhez, houwen.peng}@microsoft.com<br>nnzheng@xjtu.edu.cn ancientmooner@gmail.com</p>
<h4>Abstract</h4>
<p>Mathematical capabilities were previously believed to emerge in common language models only at a very large scale or require extensive math-related pre-training. This paper shows that the LLaMA-2 7B model with common pretraining already exhibits strong mathematical abilities, as evidenced by its impressive accuracy of $97.7 \%$ and $72.0 \%$ on the GSM8K and MATH benchmarks, respectively, when selecting the best response from 256 random generations. The primary issue with the current base model is the difficulty in consistently eliciting its inherent mathematical capabilities. Notably, the accuracy for the first answer drops to $49.5 \%$ and $7.9 \%$ on the GSM8K and MATH benchmarks, respectively. We find that simply scaling up the SFT data can significantly enhance the reliability of generating correct answers. However, the potential for extensive scaling is constrained by the scarcity of publicly available math questions. To overcome this limitation, we employ synthetic data, which proves to be nearly as effective as real data and shows no clear saturation when scaled up to approximately one million samples. This straightforward approach achieves an accuracy of $82.6 \%$ on GSM8K and $40.6 \%$ on MATH using LLaMA-2 7B models, surpassing previous models by $14.2 \%$ and $20.8 \%$, respectively. We also provide insights into scaling behaviors across different reasoning complexities and error types.</p>
<h2>1 Introduction</h2>
<p>Mathematical capabilities have long been considered so challenging that they are thought to emerge in common language models only at a very large scale. For instance, studies by (Wei et al., 2022a,b) suggest that only models with size exceeding 50</p>
<p><sup id="fnref:0"><a class="footnote-ref" href="#fn:0">1</a></sup><img alt="img-0.jpeg" src="img-0.jpeg" /></p>
<p>Figure 1: The orange star markers represent the accuracy achieved by selecting the best response from 256 random generations of the LLaMA-2 7B model. The high accuracy on the MATH (left) and GSM8K (right) benchmarks ( $72.0 \%$ and $97.7 \%$, respectively) suggest that the LLaMA-2 7B already possesses strong mathematical capabilities, although the stability in generating correct answers could be enhanced. This paper demonstrates that by scaling synthetic SFT data, the stability can be significantly improved as evidenced by the curves. Through this straightforward scaling of SFT data, the top-performing model has exceeded an early GPT-4 model by $10.3 \%$ on the MATH benchmark.
billion parameters can attain meaningful accuracy or benefit from chain-of-thought processing on math problems. A strategy to equip smaller language models with mathematical abilities involves creating math-specific base models trained on hundreds of billions of math-related pre-training data (Lewkowycz et al., 2022; Azerbayev et al., 2023). However, the accuracy of such models remains modest; for example, Llemma-7B (Azerbayev et al., 2023) only achieves $36.4 \%$ on the GSM8K dataset (Cobbe et al., 2021) and $18.0 \%$ on the MATH dataset (Hendrycks et al., 2021).</p>
<p>In this paper, we demonstrate that common language models of small size, such as the LLaMA-2 7B model (Touvron et al., 2023b), already possess strong mathematical capabilities without specific pre-training on math-related data. Surprisingly, we find that with supervised fine-tuning on just thousands of math questions (noting that the SFT stage does not enhance capabilities as stated in</p>
<p>Table 1: Comparison of SFT data scaling with real versus synthetic math questions. It reveals that synthetic math questions are nearly as effective as real ones.</p>
<table>
<thead>
<tr>
<th>Data size</th>
<th>GSM8K-real</th>
<th>GSM8K-syn</th>
<th>MATH-real</th>
<th>MATH-syn</th>
</tr>
</thead>
<tbody>
<tr>
<td>0.94K</td>
<td>26.7</td>
<td>25.9</td>
<td>4.2</td>
<td>3.9</td>
</tr>
<tr>
<td>1.88K</td>
<td>32.8</td>
<td>31.9</td>
<td>5.6</td>
<td>4.9</td>
</tr>
<tr>
<td>3.75K</td>
<td>43.3</td>
<td>42.2</td>
<td>6.6</td>
<td>6.0</td>
</tr>
<tr>
<td>7.50K</td>
<td>50.2</td>
<td>49.5</td>
<td>8.4</td>
<td>7.9</td>
</tr>
</tbody>
</table>
<p><em>Bai et al. (2022); Ouyang et al. (2022)</em>), the model can correctly solve 97.7% of GSM8K questions and 72.0% of MATH questions, when selecting the best answer from 256 random generations, as indicated by the orange star marks in Figure 1. It is noteworthy that the accuracy has even outperformed those reported for the GPT-4 model, which achieved 92.0% on GSM8K and 42.5% on MATH . Therefore, we conclude that the LLaMA-2 7B model has indeed developed strong mathematical capabilities. The primary issue is the lack of guarantee that the correct answer will be digged out, as most generations are incorrect. In fact, the accuracy drops to 49.5% on GSM8K and 7.9% on MATH if we consider only one random generation per question. We refer to this as the instability issue.</p>
<p>To address the instability issue, we first observe that the accuracy improves almost in linear or even super-linear with exponentially increased supervised fine-tuning (SFT) data. Moreover, we note that the accuracy is far from reaching a plateau when utilizing all available GSM8K and MATH training data (as shown in Table 1). This observation encourages us to further scale up the SFT data. However, we face a challenge as there is a lack of publicly accessible real data to support this continuous scaling.</p>
<p>To overcome this limitation, we turn to synthetic data, employing a prestigious language model, namely GPT-4 Turbo, to produce synthetic math questions. We find that a straightforward "brand-new" generation strategy, which prompts the GPT-4 Turbo to create a completely new question based on preference ones and then applies a simple verifier (also GPT-4 Turbo based), has been highly effective. Specifically, as indicated in Table 1, the use of synthetically generated math questions can achieve accuracy nearly on par with that of real questions, highlighting the potential of synthetic SFT math questions for the scaling purpose.</p>
<p>Leveraging synthetic data has allowed us to scale our SFT data significantly, for instance, from 7.5K to 960K on GSM8K and from 7.5K to 480K on MATH. This data scaling shows nearly perfect scaling behavior, as drawn in Figure 1. Specifically, by simply scaling the SFT data, our model has become the first to exceed 80% and 40% accuracy on GSM8K and MATH, respectively, using a standard LLaMA-2 7B base model (achieving 82.6% and 40.6% respectively).</p>
<p>The straightforward synthetic SFT data proves effective from stronger base models as well, such as LLaMA-2 70B, which achieves 90.6% on GSM8K and 52.8% on MATH. To the best of our knowledge, this is the first open-source model to exceed 90% accuracy on GSM8K. It is also the first open-source model to outperform GPT-4 (i.e., GPT-4-0314) on the MATH benchmark, demonstrating the efficacy of our simple synthetic scaling method.</p>
<p>In addition to the strong results, we have also gleaned insights into the effectiveness of our approach: 1) As the scale of SFT data increases, the model's accuracy tends to plateau when utilizing 256 attempts; however, there is a marked increase using 1 response. This indicates that while the model's upper capability limit remains fairly constant, the performance gains are primarily due to enhanced stability in generating correct answers. 2) The accuracy of solving math problems follows a power law with respect to the number of chain-of-thought (CoT) steps with different SFT data quantities. An expanded SFT dataset improves the reliability of each reasoning step. Further increasing the proportion of training samples with longer CoT steps through resampling can significantly improve the accuracy of the model for difficult questions. 3) An analysis of error types during the scaling process reveals that calculation errors are more readily mitigated compared to reasoning errors.</p>
<h2>2 Examine Math Capability of Language Models</h2>
<p>Metrics We employ two metrics to examine the math capabilities of language models.</p>
<p><sup>2</sup>Concurrently, DeepSeek-MATH-7B <em>Shao et al. (2024)</em> also surpasses 80% accuracy. However, their approach relies on a much stronger base model extensively pre-trained on math-related corpora and a sophisticated RL algorithm. Our results are complementary to theirs.</p>
<p>The first is a Pass@N metric</p>
<p>$\operatorname{Pass}@\mathrm{N}=\operatorname*{\mathbb{E}}_{\text {Problems }}[\min (c, 1)],$ (1)</p>
<p>where $c$ represents the number of correct answers out of $N$ responses. This metric considers a question to be solved if at least one correct answer is produced from $N$ random generations. We employ this metric to reflect the potential or capability of a model in solving a math question. To enhance the diversity of the $N$ generations, we set the temperature of the generation process to $0.7^{3}$.</p>
<p>The second is a PassRatio@N metric</p>
<p>$\operatorname{PassRatio}@\mathrm{N}=\operatorname*{\mathbb{E}}_{\text {Problems }}\left[\frac{c}{N}\right],$ (2)</p>
<p>which measures the percentage of correct answers within the $N$ generated answers. This metric is somewhat equivalent to Pass@1, but with reduced variance.</p>
<p>Observations Based on these two metrics, we examine the performance of the LLaMA-2 models on the GSM8K and the MATH benchmarks as shown in Figure 1. To adapt models for these two benchmarks in instruction-following settings, we use their SFT versions, which are trained with a limited amount of SFT data (i.e., 7.5K). As demonstrated in (Bai et al., 2022; Ouyang et al., 2022), the SFT stage does not enhance capabilities (and may even lead to a reduction, as mentioned in the context of "alignment taxes"). Therefore, employing the SFT version provides a fair assessment of the models' mathematical capabilities.</p>
<p>We first observe that the Pass@256 metrics for the LLaMA-2 7B model on both benchmarks are remarkably high: $97.7 \%$ on GSM8K and $72.0 \%$ on MATH. This suggests that the LLaMA-2 7B model possesses a strong capability for solving mathematical problems.</p>
<p>We then notice that the PassRatio@256 is significantly lower than that of Pass@256, being 48.2\% on GSM8K and 7.9\% on MATH. This suggests that while the correct answers to most math questions are present within 256 random generations, there is no assurance that the correct answers will consistently be extracted, a phenomenon we refer to as an "instability issue".</p>
<p><sup id="fnref2:0"><a class="footnote-ref" href="#fn:0">1</a></sup>In the following, we will present a simple approach to significantly reduce the instability issue.</p>
<h2>3 Scaling SFT Data using Synthetic Math Questions</h2>
<p>In this section, we first demonstrate that scaling up the limited real SFT data can significantly alleviate the instability issue. We also observe that the accuracy has not yet plateaued when using the full available GSM8K and MATH training data. We consider further scaling up SFT data using synthetic math questions. To this aim, we introduce a straight-forward method for synthetic data generation utilizing the GPT-4 Turbo API. The synthetic data proves to be as effective as real math questions. Consequently, we boldly scale the synthetic SFT data to 960 K on GSM8K and 480 K on MATH, respectively, resulting in nearly perfect scaling behavior, and reach state-of-the-art accuracy.</p>
<p>Scaling using Real Math Questions We begin by examining the scaling behavior of real math questions across the entire GSM8K and MATH training sets. As indicated in Table 1, we observe a consistent accuracy improvement, increasing from $26.7 \%$ to $50.2 \%$ on GSM8K, and from $4.2 \%$ to $8.4 \%$ on MATH, with no signs of saturation.</p>
<p>Synthetic SFT Data Generation Since the real data has been exhausted, we contemplate further scaling up SFT data using synthetically generated math questions.</p>
<p>We introduce a straightforward three-step approach with the assistance of the GPT-4 Turbo API:</p>
<ul>
<li>Step 1. Generate a new math question. We request the GPT-4 Turbo API to generate a brand-new question using a reference math question as a starting point. To improve the validity of the new questions, we incorporate three rules into the prompt: Firstly, the new question must obey common knowledge; secondly, it should be solvable independently of the original question; and thirdly, it must not include any answer responses. Besides, we have set specific formatting requirements for questions and answers tailored to various target datasets.</li>
<li>Step 2. Verify the question. We further enhance the quality of the generated questions by validating and refining them through attempted solutions. By integrating solving and</li>
</ul>
<p>verification steps into a single prompt, we have found that this approach consistently elevates the validity of questions across different benchmarks.</p>
<ul>
<li>Step 3. Generate chain-of-thought (CoT) answers. We request GPT-4 Turbo to produce a chain-of-thought (CoT) answer response for each newly generated question.</li>
</ul>
<p>The detailed prompt designs are shown in Appendix A.</p>
<p>Comparison of Synthetic SFT Data versus Real Data To assess the quality of the synthetically generated math questions, we evaluate their effectiveness against real questions from the GSM8K and MATH training sets, utilizing a LLaMA-2 7B model, as detailed in Table 1. The results indicate that the synthetic math questions are nearly as effective as the real ones.</p>
<p>We also explored various other synthetic methods as proposed in previous works (Xu et al., 2023; Yu et al., 2023; An et al., 2023). These methods also prove to be effective, though marginally less so than the our approach, as illustrated in Figure 6.</p>
<p>Scaling to about a Million SFT Math Data Considering the effectiveness of the synthetic approach, we substantially increase the scale of the SFT data for both GSM8K and MATH problems, to 960 K and 480 K , respectively. Figure 1 presents the main reasults utilizing various sizes of the LLaMA2 series. The straightforward scaling strategy yields state-of-the-art accuracy.</p>
<p>It is also worth noting that the accuracy has not yet reached its peak. Exploring the effects of additional scaling will be left as our future research.</p>
<h2>4 Experiments</h2>
<h3>4.1 Datasets and Evaluations</h3>
<p>We conduct experiments on 5 benchmarks to evaluate the efficacy of the proposed method.
GSM8K (Cobbe et al., 2021). This is a highquality, linguistically diverse math dataset, whose math knowledge mainly covers grade school level. It includes 7,473 training examples and 1,319 test cases. In this work, we use its training set as the given questions to generate new synthetic data.
MATH (Hendrycks et al., 2021). This dataset focuses on competitive-level math problems that requires high levels of reasoning ability and mathematical knowledge. It consists of 7,500 training
examples and 5,000 test cases. We use the training examples to generate synthetic data.
SVAMP (Patel et al., 2021). This dataset comprises elementary-level math problems. We utilize all 1,000 of its test cases to assess the cross-dataset performance of our models.
ASDiv (Miao et al., 2021). This dataset contains a set of math problems with diverse language patterns and types of questions. We adopt the test set of 2,305 problems as evaluation benchmark.
Hungarian National High School Exam This evaluation benchmark is first introduced by Grok1 (xAI, 2023), which is designed for evaluating the out-of-domain capability of math models. It consists of 33 challenging problems.</p>
<p>It is worth noting that the final answers of Hungarian National High School Exam dataset is annotated by human, while other benchmarks are labelled using automatic scripts, similar to previous works (Luo et al., 2023; Gou et al., 2023).</p>
<h3>4.2 Implementation Details</h3>
<p>In data synthesis, we utilize the GPT-4 Turbo API, setting the temperature to 1.0 for both question and answer generation.</p>
<p>For supervised fine-tuning, we employ the Adam optimizer with a cosine learning rate schedule spanning a total of 3 epochs of training. The maximum learning rate is set $2 \mathrm{e}-5$ (except that $2 \mathrm{e}-6$ for the Mistral-7b model) and there is a $4 \%$ linear warmup. The maximum token length is set 2048, and the Vicuna-v1.1 (Zheng et al., 2023) system prompt is used. All experiments are conducted on $8 \times$ Nvidia H100 GPUs. Our most resource-intensive experiment, involving a 70B model and 960K data points, takes 1900 H100 GPU hours.</p>
<p>For evaluation, we use the same prompt as used in SFT and set the maximum sequence length to 2048. The vLLM (Kwon et al., 2023) is used in answer generation.</p>
<h3>4.3 Main Results and Comparison with State-of-the-art Models</h3>
<p>In this comparison, we examine both in-domain benchmarks, GSM8K/MATH, and out-of-domain benchmarks, such as the Hungarian National High School Exam. For in-domain evaluation of each benchmark, we utilize data synthesized from its respective training samples. For GSM8K, 960K synthetic data is employed, while for MATH, 480K synthetic data is used. For out-domain evaluation,</p>
<p>Table 2: Math reasoning performances of various LLMs.</p>
<table>
<thead>
<tr>
<th>Model</th>
<th>GSM8K</th>
<th>MATH</th>
</tr>
</thead>
<tbody>
<tr>
<td>Closed-source models</td>
<td></td>
<td></td>
</tr>
<tr>
<td>GPT-4 Turbo (1106)</td>
<td>94.8</td>
<td>64.5</td>
</tr>
<tr>
<td>GPT-4-0314</td>
<td>94.7</td>
<td>52.6</td>
</tr>
<tr>
<td>GPT-4 (Achiam et al., 2023)</td>
<td>92.0</td>
<td>42.5</td>
</tr>
<tr>
<td>Claude-2 (Anthropic, 2023)</td>
<td>88.0</td>
<td>-</td>
</tr>
<tr>
<td>GPT-3.5-Turbo (OpenAI, 2023a)</td>
<td>80.8</td>
<td>34.1</td>
</tr>
<tr>
<td>Open-source models LLaMA-2-7B</td>
<td></td>
<td></td>
</tr>
<tr>
<td>WizardMath-7B (Luo et al., 2023)</td>
<td>54.9</td>
<td>10.7</td>
</tr>
<tr>
<td>MuggleMath-7B (Li et al., 2023)</td>
<td>68.4</td>
<td>-</td>
</tr>
<tr>
<td>MetaMath-7B (Yu et al., 2023)</td>
<td>66.5</td>
<td>19.8</td>
</tr>
<tr>
<td>LEMA-LLaMA-2-7B (An et al., 2023)</td>
<td>54.1</td>
<td>9.4</td>
</tr>
<tr>
<td>Xwin-Math-7B (ours)</td>
<td>82.6</td>
<td>40.6</td>
</tr>
<tr>
<td>Open-source models Mistral-7B</td>
<td></td>
<td></td>
</tr>
<tr>
<td>WizardMath-7B-v1.1 (Luo et al., 2023)</td>
<td>83.2</td>
<td>33.0</td>
</tr>
<tr>
<td>MetaMath-Mistral-7B (Yu et al., 2023)</td>
<td>77.4</td>
<td>28.2</td>
</tr>
<tr>
<td>Xwin-Math-Mistral-7B (ours)</td>
<td>89.2</td>
<td>43.7</td>
</tr>
<tr>
<td>Open-source models Llemma-7B</td>
<td></td>
<td></td>
</tr>
<tr>
<td>MetaMath-Llemma-7B (Yu et al., 2023)</td>
<td>69.2</td>
<td>30.0</td>
</tr>
<tr>
<td>Xwin-Math-Llemma-7B (ours)</td>
<td>84.2</td>
<td>47.2</td>
</tr>
<tr>
<td>Open-source models LLaMA-2-13B</td>
<td></td>
<td></td>
</tr>
<tr>
<td>WizardMath-13B (Luo et al., 2023)</td>
<td>63.9</td>
<td>14.0</td>
</tr>
<tr>
<td>MuggleMath-13B (Li et al., 2023)</td>
<td>74.0</td>
<td>-</td>
</tr>
<tr>
<td>MetaMath-13B (Yu et al., 2023)</td>
<td>72.3</td>
<td>22.4</td>
</tr>
<tr>
<td>LEMA-LLaMA-2-13B (An et al., 2023)</td>
<td>65.7</td>
<td>12.6</td>
</tr>
<tr>
<td>Xwin-Math-13B (ours)</td>
<td>88.1</td>
<td>44.9</td>
</tr>
<tr>
<td>Open-source models LLaMA-2-70B</td>
<td></td>
<td></td>
</tr>
<tr>
<td>WizardMath-70B (Luo et al., 2023)</td>
<td>81.6</td>
<td>22.7</td>
</tr>
<tr>
<td>MuggleMath-70B (Li et al., 2023)</td>
<td>82.3</td>
<td>-</td>
</tr>
<tr>
<td>MetaMath-70B (Yu et al., 2023)</td>
<td>82.3</td>
<td>26.6</td>
</tr>
<tr>
<td>LEMA-LLaMA-2-70B (An et al., 2023)</td>
<td>83.5</td>
<td>25.0</td>
</tr>
<tr>
<td>Xwin-Math-70B (ours)</td>
<td>90.6</td>
<td>52.8</td>
</tr>
</tbody>
</table>
<p>we test models trained using GSM8K, MATH, or a mixed of two synthetic sets.</p>
<p>For base models, we consider both common language models, i.e., LLaMA-2 7B/13B/70B/Mistral7B, and math-specific models, such as Llemma-7B, to assess the generality of the proposed approach.</p>
<p>In-Domain Results Table 2 presents a comparison of the proposed approach with the state-of-the-art open and closed-source models. Across all base models, our method significantly outperforms the previous best approaches that use the same pretrained base model.</p>
<p>On LLaMA-2-7B, our approach exceeds the prior best by absolutely +14.2 on GSM8K (compared to MuggleMath-7B (Li et al., 2023)), and by +20.8 on MATH (compared to MetaMath-7B (Yu et al., 2023)), respectively. It even surpasses several latest 70B models dedicated for math capabilities, such as WizardMath-70B (Luo et al., 2023) (82.6 versus 81.6 on GSM8K). On LLaMA-2-13B, the Table 3: Hungarian national high school exam test result of various LLMs.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Model</th>
<th style="text-align: center;">Test Score (\%)</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">GPT-4 (Achiam et al., 2023)</td>
<td style="text-align: center;">68</td>
</tr>
<tr>
<td style="text-align: left;">Grok-1 (xAI, 2023)</td>
<td style="text-align: center;">59</td>
</tr>
<tr>
<td style="text-align: left;">Claude-2 (Anthropic, 2023)</td>
<td style="text-align: center;">55</td>
</tr>
<tr>
<td style="text-align: left;">GPT-3.5 Turbo (OpenAI, 2023a)</td>
<td style="text-align: center;">41</td>
</tr>
<tr>
<td style="text-align: left;">DeepSeek-LLM-67B-Chat (Bi et al., 2024)</td>
<td style="text-align: center;">58</td>
</tr>
<tr>
<td style="text-align: left;">Xwin-Math-70B (480K GSM8K)</td>
<td style="text-align: center;">22</td>
</tr>
<tr>
<td style="text-align: left;">Xwin-Math-70B (120K MATH)</td>
<td style="text-align: center;">51</td>
</tr>
<tr>
<td style="text-align: left;">Xwin-Math-70B (480K MATH)</td>
<td style="text-align: center;">59</td>
</tr>
<tr>
<td style="text-align: left;">Xwin-Math-70B (480K Mix)</td>
<td style="text-align: center;">65</td>
</tr>
</tbody>
</table>
<p>improvements are +14.1 on GSM8K (compared to MuggleMath-13B (Li et al., 2023)) and +22.5 on MATH (compared to MetaMath-13B (Yu et al., 2023)), respectively. On LLaMA-2-70B, the gains are +7.1 on GSM8K (compared to LEMA-LLaMA-2-70B (An et al., 2023)) and +26.2 on MATH (compared to MetaMath-70B (Yu et al., 2023)), respectively.</p>
<p>On a stronger common language model, i.e., Mistral-7B, the improvements are +6.0 on GSM8K and +10.7 on MATH (compared to WizardMath-7B-v1.1 (Luo et al., 2023)), respectively.</p>
<p>On a math-specific base model, such as Llemma7B, the gains are +15.0 on GSM8K and +17.2 on MATH (compared to MetaMath-Llemma-7B (Luo et al., 2023)), respectively.</p>
<p>It is also noteworthy that our LLaMA-2-70B model achieves competitive accuracy with early versions of GPT-4 on GSM8K and MATH. To our knowledge, this is the first LLaMA-based model to outperform GPT-4-0314 on MATH.</p>
<p>These results demonstrate the significant effectiveness and broad applicability of scaling synthetic math SFT data.</p>
<p>Out-of-Domain Results We test the models trained using GSM8K, MATH, or a mixed of two synthetic sets on an out-of-domain benchmark, Hungarian National High-School Exam Test, following the practice in (xAI, 2023).</p>
<p>Table 3 shows the results. Our model trained on the mixing data (240K MATH synthetic data + 240K GSM8K synthetic data) ranked as the second, just behind the GPT-4 and much better than other models. Additionally, we plot the correlation between GSM8K and Hungarian national high-school exam scores in Appendix B. The results show that there is no significant benchmark overfitting in our model.</p>
<p>Figure. 2 (Left) presents the results of the model</p>
<p><img alt="img-1.jpeg" src="img-1.jpeg" /></p>
<p>Figure 2: Comparing the increase in SFT data scale using either a single dataset or mixed datasets.</p>
<p><img alt="img-2.jpeg" src="img-2.jpeg" /></p>
<p>Figure 3: The Pass@256 and PassRatio@256 curve with increasing data size on GSM8K and MATH benchmark.</p>
<p>The mass and mass ratio (MAR) are the main parameters. The MATH is trained on GSM8K synthetic data, while Figure 2 presents the results of the model trained on MATH. We find that the accuracy of other benchmarks also improves as the amount of data increases for models trained with either GSM8K or MATH synthetic data. We also note that the generalization behaviors differ for GSM8K and MATH models: 1) SVAMP and ASDiv benefit more from GSM8K models than from MATH models. 2) While MATH models perform relatively well on the GSM8K benchmark, GSM8K models perform considerably worse on MATH benchmarks.</p>
<p>Figure 2 (Right) shows the results of models using a mixture of GSM8K and MATH in a 1:1 ratio. These models exhibit balanced scaling behaviors in both in-domain and out-of-domain benchmarks.</p>
<h3>4.4 What Happens behind Performance Improvements?</h3>
<p><strong>Pass@256 v.s. PassRatio@256</strong> To deepen the understanding behind the performance improvements, we tracked Pass@N metric and PassRatio@N metric under different data sizes. The results are shown in Figure 3. With very limited synthetic data (<em>e.g.</em>, 7.5K samples), the Xwin-Math-70B model already has very high Pass@256, indicating the strong ability to generate correct answers through multiple attempts. Meanwhile, the Pass@256 metric only changed slightly with increasing the amount of used data. In contrast, PassRatio@256, which reflects the stability to generate correct answers, increases significantly with the amount of synthetic data, and its growth trend is similar to that of Pass@1. This result confirms our hypothesis that the performance improvements are mainly caused by better stability in the answer generation rather than stronger ability to answer the question.</p>
<p><strong>Estimated Single-step Reasoning Accuracy</strong> Because of the Chain-of-Thought (CoT) are adopted in inference, the process of answer mathematical problems is completed by a multi-step reasoning process. Therefore, we hypothesize that the increase in final answer accuracy can be interpreted by the improvement in single-step reasoning accuracy. Based on this assumption, if one question can be theoretically answered by <em>s</em> reasoning steps in CoT, the final answer accuracy can be approximately as high as the number of times the single-step reasoning accuracy:</p>
<p>$$Acc_{final} = Acc_{step}^s \tag{3}$$</p>
<p>With this equation, step accuracy can be estimated from the final answer accuracy. We experimented on GSM8K. For each question in the test</p>
<p><img alt="img-3.jpeg" src="img-3.jpeg" /></p>
<p>Figure 4: Left: The relationship between the mean accuracy on the GSM8K and the number of annotated CoT steps with data increasing. The solid line is fitted using all seven points, while the dashed line is fitted using the first four points. Right: Changes in mean accuracy when resampling is used to increase the CoT lengeh of training data.</p>
<p>set, we generated 256 responses and used the number of steps in the GSM8k test set's CoT annotations as the theoretical CoT steps. We draw the curve to show the relationship between the number of CoT reasoning steps and mean final answer accuracy and show the fitted curve based on Equation. 3. We test Xwin-Math-7B models with different synthetic data, and the results are shown in Figure 4. The solid line is fitted using all seven points and Table 4 shows the estimated single-step accuracy when using different amounts of data using all data points, and it can be seen that the single-step accuracy improve significantly with more data.</p>
<p>However, when we fit based on Equation. 3 to the first four points, as shown in dashed lines, we found that the latter three points were significantly below the curve. We believe this phenomenon may be related to the smaller proportion of more complex problems in the training data. Therefore, we resampled the 960K synthetic data according to the number of sentences in CoT solution. As can be seen from Figure 4 (right), when the proportion of complex problems is increased, the accuracy for simpler problems remains virtually unchanged, but the accuracy for more complex problems can be significantly improved. Moreover, the utilization of data resampling can increase the model's Pass-Ratio@256 from 71.1 to 72.8. This experimental result provides new insights into data selection for mathematical reasoning tasks.</p>
<p>In addition, we further used the GPT-4 Turbo to find the position where the first step in our answer was wrong and normalized that position by the total number of steps in each answer. As the estimated single-step accuracy gets higher, the first</p>
<p>Table 4: The estimated single-step reasoning accuracy and the average normalized first error position by GPT-4 Turbo in Xwin-Math-7B on GSM8K benchmark.</p>
<table>
<thead>
<tr>
<th>Data size</th>
<th>Estimated Accstep</th>
<th>Normalized first error position</th>
</tr>
</thead>
<tbody>
<tr>
<td>7.5K</td>
<td>78.9</td>
<td>67.1</td>
</tr>
<tr>
<td>120K</td>
<td>89.7</td>
<td>83.9</td>
</tr>
<tr>
<td>960K</td>
<td>94.2</td>
<td>90.9</td>
</tr>
</tbody>
</table>
<p><img alt="img-4.jpeg" src="img-4.jpeg" /></p>
<p>Figure 5: Changes in the proportion of calculation and reasoning mistake during data increased.</p>
<p>error position of the normalization is postponed.</p>
<p><strong>The Improvement in the Accuracy of Numerical Calculations is More Significant than Logical Reasoning</strong></p>
<p>The performance of the model gradually improves as the synthetic data increases. For a deeper understanding, we analyze the error proportion for different types of errors on GSM8K. We categorized errors into two types: reasoning errors and calculation errors. Reasoning errors primarily encompass issues such as loss of conditions and concept confusion, while calculation errors include incorrect analysis of quantitative relationships and numerical computation mistakes. Based on the experimental results illustrated in Figure 5, we observe a gradual decrease in the percentage of calculation errors, suggesting that GSM8K is correcting calculation errors at a faster rate than reasoning errors.</p>
<h3>4.5 Ablations on the Data Synthetic Schema</h3>
<p><strong>Comparison with Other Data Synthetic Methods</strong></p>
<p>We compared our approach with the following common used data synthetic methods:</p>
<p><em>Add Constraint.</em> Adding one more constraint to the original question while keeping others unchanged, which is used in WizardMath and MuggleMath.</p>
<p><em>Change Numbers.</em> Changing the numbers that appear in the problem while keeping the context intact, which is used in MuggleMath.</p>
<p><em>Change Background.</em> Changing the background in</p>
<p><img alt="img-5.jpeg" src="img-5.jpeg" /></p>
<p>Figure 6: GSM8K and MATH performance of different synthetic methods.</p>
<p>Table 5: Ablation of question verification on MATH.</p>
<table>
<thead>
<tr>
<th>Model</th>
<th>Pass@1 (%)</th>
</tr>
</thead>
<tbody>
<tr>
<td>Xwin-Math-70B (7.5K data)</td>
<td>28.9</td>
</tr>
<tr>
<td>Xwin-Math-70B (7.5K data) w/o verification</td>
<td>28.1 (-0.8)</td>
</tr>
<tr>
<td>Xwin-Math-70B (30K data)</td>
<td>37.6</td>
</tr>
<tr>
<td>Xwin-Math-70B (30K data) w/o verification</td>
<td>36.6 (-1.0)</td>
</tr>
</tbody>
</table>
<p>The question while keeping others the same.</p>
<p><em>The Combination of Changing Numbers and Background.</em> A hybrid approach that combines changing both numbers and background.</p>
<p><em>MetaMath Approach.</em> The synthetic methods proposed in MetaMath, including answer augmentation, rephrasing question, self-verification question, and FOBAR question. In experiments, we follow the implementation of MetaMath but use GPT-4 Turbo instead of GPT-3.5 Turbo to generate response data using their released questions.</p>
<p>The experimental results in Figure 6 show that when the data size is relatively small, <em>e.g.</em>, 7.5k and 30k samples, the performance gap between the different methods is negligible. However, as the data size increases, our method and the method with added constraints show stronger performance. This suggests that the choice of data synthetic strategy becomes more critical as the data size increases, and that some methods can scale the data more efficiently, thus improving the performance.</p>
<p><strong>Effects of Question Verification.</strong> The question verification is used to further improve the generation quality. In our experiments, we found it can improve the performance on MATH benchmark, the results are shown in Table 5, while we do not see significantly impact on GSM8K dataset.</p>
<h2>5 Related Works</h2>
<p><strong>Large Language Models</strong> Large language models (Brown et al., 2020; Achiam et al., 2023; Touvron et al., 2023a,b) have made significant achievements, with impressive performance on a wide range of tasks. Currently, closed-source large language models, represented by GPT (Brown et al., 2020; Achiam et al., 2023), Gemini (Team et al., 2023), Grok (xAI, 2023), and Claude-2 (Anthropic, 2023), are the most advanced models in terms of performance. However, open-source models, represented by LLaMA (Touvron et al., 2023a), LLaMA-2 (Touvron et al., 2023b) and Mixtral (Jiang et al., 2024), have also progressed rapidly, and have even shown competitive performance with the closed-source models on some tasks. Our work, which aims to improve the performance of open-source LLMs on mathematical tasks by fine-tuning them on synthetic data.</p>
<p><strong>Reasoning Framework for Improving Mathematical Capability</strong> Chain-of-thoughts (Wei et al., 2022b) encourages the LLMs perform multistep reasoning by specific designed prompts and can improve reasoning performance. Based on this work, many subsequent works suggesting further improvements (Fu et al., 2022; Zhang et al., 2022; Kojima et al., 2022). The above works focus primarily on how to improve performance through better prompt design or inference strategies without fine-tuning the model, whereas our work focuses on how to improve the model itself, and thus these approaches are complementary to ours.</p>
<p><strong>Fine-tuned LLM for Math</strong> Another sort of works (Lightman et al., 2023; Luo et al., 2023; Azerbayev et al., 2023; Yue et al., 2023; Yu et al., 2023; An et al., 2023; Li et al., 2023; Gou et al., 2023) try to improve performance directly by training the model on mathematical data. A direct way is to use fine-tuning to improve models. One widely used method is to use synthetic data, which is very close to our approach: MetaMath (Yu et al., 2023) presents to bootstrap questions to augment data. LeMA (An et al., 2023) collects mistake-correction data pairs by using GPT-4 as a corrector. And MuggleMath (Li et al., 2023) augments the GSM8K dataset by incorporating GPT-4 with a series of predefined operations. Compared to these synthetic data-based efforts, our data synthetic method is much simpler and more scalable due to introduce less prior and constraint.</p>
<p><strong>SFT Data Scaling</strong> Recently, some research efforts have focused on the data scale for supervised fine-tuning. For instance, LIMA (Zhou et al., 2023) mentions that fine-tuning with 1,000 high-quality</p>
<p>instructions can yield impressive results in various general tasks. Other studies have indicated that performance scales with data size in mathematical and coding tasks (Dong et al., 2023). Recent work (Bi et al., 2024) even uses 1.5 million data for instruct fine-tuning to obtain top performance. However, the intrinsic reasons behind this scaling effect have not been thoroughly investigated.</p>
<h2>6 Conclusion</h2>
<p>This study reveals that common 7B language models, such as LLaMA-2 7B, already exhibit strong mathematical capabilities, challenging the previous belief that advanced mathematical reasoning is exclusive to larger, more extensively pre-trained models. By significantly scaling up SFT data, we have markedly improved the stability of the model's mathematical problem-solving skills. Our methodology has enabled the Xwin-Math models to reach performance levels comparable to, and in some instances surpassing, those of their larger counterparts. Our analysis also indicates that the enhancements are primarily attributable to heightened accuracy in single-step reasoning and a extra resampling of training data can improve the accuracy of harder questions. Additionally, we see more substantial reduction of calculation errors as opposed to logical reasoning errors. Our research contributes valuable insights into the mathematical capabilities of large language models.</p>
<h2>Acknowledgments</h2>
<p>Chen Li and Nanning Zheng were supported in part by NSFC under grant No. 62088102. Thank Shengnan An at IAIR, Xi'an Jiaotong University for his valuable advice on this work.</p>
<h2>References</h2>
<p>Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, et al. 2023. Gpt-4 technical report. arXiv preprint arXiv:2303.08774.</p>
<p>Shengnan An, Zexiong Ma, Zeqi Lin, Nanning Zheng, Jian-Guang Lou, and Weizhu Chen. 2023. Learning from mistakes makes llm better reasoner. arXiv preprint arXiv:2310.20689.</p>
<p>Anthropic. 2023. Model card and evaluations for claude models.</p>
<p>Zhangir Azerbayev, Hailey Schoelkopf, Keiran Paster, Marco Dos Santos, Stephen McAleer, Albert Q Jiang, Jia Deng, Stella Biderman, and Sean Welleck. 2023. Llemma: An open language model for mathematics. arXiv preprint arXiv:2310.10631.</p>
<p>Yuntao Bai, Andy Jones, Kamal Ndousse, Amanda Askell, Anna Chen, Nova DasSarma, Dawn Drain, Stanislav Fort, Deep Ganguli, Tom Henighan, Nicholas Joseph, Saurav Kadavath, Jackson Kernion, Tom Conerly, Sheer El-Showk, Nelson Elhage, Zac Hatfield-Dodds, Danny Hernandez, Tristan Hume, Scott Johnston, Shauna Kravec, Liane Lovitt, Neel Nanda, Catherine Olsson, Dario Amodei, Tom Brown, Jack Clark, Sam McCandlish, Chris Olah, Ben Mann, and Jared Kaplan. 2022. Training a helpful and harmless assistant with reinforcement learning from human feedback.</p>
<p>Xiao Bi, Deli Chen, Guanting Chen, Shanhuang Chen, Damai Dai, Chengqi Deng, Honghui Ding, Kai Dong, Qiushi Du, Zhe Fu, et al. 2024. Deepseek llm: Scaling open-source language models with longtermism. arXiv preprint arXiv:2401.02954.</p>
<p>Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. 2020. Language models are few-shot learners. Advances in neural information processing systems, 33:1877-1901.</p>
<p>Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, et al. 2021. Training verifiers to solve math word problems. arXiv preprint arXiv:2110.14168.</p>
<p>Guanting Dong, Hongyi Yuan, Keming Lu, Chengpeng Li, Mingfeng Xue, Dayiheng Liu, Wei Wang, Zheng Yuan, Chang Zhou, and Jingren Zhou. 2023. How abilities in large language models are affected by supervised fine-tuning data composition. arXiv preprint arXiv:2310.05492.</p>
<p>Yao Fu, Hao Peng, Ashish Sabharwal, Peter Clark, and Tushar Khot. 2022. Complexitybased prompting for multi-step reasoning. arXiv preprint arXiv:2210.00720.</p>
<p>Zhibin Gou, Zhihong Shao, Yeyun Gong, Yujiu Yang, Minlie Huang, Nan Duan, Weizhu Chen, et al. 2023. Tora: A tool-integrated reasoning agent for mathematical problem solving. arXiv preprint arXiv:2309.17452.</p>
<p>Dan Hendrycks, Collin Burns, Saurav Kadavath, Akul Arora, Steven Basart, Eric Tang, Dawn Song, and Jacob Steinhardt. 2021. Measuring mathematical problem solving with the math dataset. arXiv preprint arXiv:2103.03874.</p>
<p>Albert Q Jiang, Alexandre Sablayrolles, Antoine Roux, Arthur Mensch, Blanche Savary, Chris Bamford, Devendra Singh Chaplot, Diego de las Casas, Emma Bou Hanna, Florian Bressand, et al. 2024. Mixtral of experts. arXiv preprint arXiv:2401.04088.</p>
<p>Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo, and Yusuke Iwasawa. 2022. Large language models are zero-shot reasoners. Advances in neural information processing systems, 35:22199-22213.</p>
<p>Woosuk Kwon, Zhuohan Li, Siyuan Zhuang, Ying Sheng, Lianmin Zheng, Cody Hao Yu, Joseph E. Gonzalez, Hao Zhang, and Ion Stoica. 2023. Efficient memory management for large language model serving with pagedattention. In Proceedings of the ACM SIGOPS 29th Symposium on Operating Systems Principles.</p>
<p>Aitor Lewkowycz, Anders Andreassen, David Dohan, Ethan Dyer, Henryk Michalewski, Vinay Ramasesh, Ambrose Slone, Cem Anil, Imanol Schlag, Theo Gutman-Solo, Yuhuai Wu, Behnam Neyshabur, Guy Gur-Ari, and Vedant Misra. 2022. Solving quantitative reasoning problems with language models.</p>
<p>Chengpeng Li, Zheng Yuan, Guanting Dong, Keming Lu, Jiancan Wu, Chuanqi Tan, Xiang Wang, and Chang Zhou. 2023. Query and response augmentation cannot help out-of-domain math reasoning generalization. arXiv preprint arXiv:2310.05506.</p>
<p>Hunter Lightman, Vineet Kosaraju, Yura Burda, Harri Edwards, Bowen Baker, Teddy Lee, Jan Leike, John Schulman, Ilya Sutskever, and Karl Cobbe. 2023. Let's verify step by step. arXiv preprint arXiv:2305.20050.</p>
<p>Haipeng Luo, Qingfeng Sun, Can Xu, Pu Zhao, Jianguang Lou, Chongyang Tao, Xiubo Geng, Qingwei Lin, Shifeng Chen, and Dongmei Zhang. 2023. Wizardmath: Empowering mathematical reasoning for large language models via reinforced evol-instruct. arXiv preprint arXiv:2308.09583.</p>
<p>Shen-Yun Miao, Chao-Chun Liang, and Keh-Yih Su. 2021. A diverse corpus for evaluating and developing english math word problem solvers. arXiv preprint arXiv:2106.15772.</p>
<p>OpenAI. 2023a. Gpt-3.5 turbo fine-tuning and api updates.</p>
<p>OpenAI. 2023b. GPT-4 technical report. CoRR, abs/2303.08774.</p>
<p>Long Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida, Carroll L. Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, John Schulman, Jacob Hilton, Fraser Kelton, Luke Miller, Maddie Simens, Amanda Askell, Peter Welinder, Paul Christiano, Jan Leike, and Ryan Lowe. 2022. Training language models to follow instructions with human feedback.</p>
<p>Arkil Patel, Satwik Bhattamishra, and Navin Goyal. 2021. Are nlp models really able to solve simple math word problems? arXiv preprint arXiv:2103.07191.</p>
<p>Zhihong Shao, Peiyi Wang, Qihao Zhu, Runxin Xu, Junxiao Song, Mingchuan Zhang, Y. K. Li, Y. Wu, and Daya Guo. 2024. Deepseekmath: Pushing the limits of mathematical reasoning in open language models.</p>
<p>Gemini Team, Rohan Anil, Sebastian Borgeaud, Yonghui Wu, Jean-Baptiste Alayrac, Jiahui Yu, Radu Soricut, Johan Schalkwyk, Andrew M Dai, Anja Hauth, et al. 2023. Gemini: a family of highly capable multimodal models. arXiv preprint arXiv:2312.11805.</p>
<p>Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, et al. 2023a. Llama: Open and efficient foundation language models. arXiv preprint arXiv:2302.13971.</p>
<p>Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, et al. 2023b. Llama 2: Open foundation and fine-tuned chat models. arXiv preprint arXiv:2307.09288.</p>
<p>Jason Wei, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian Borgeaud, Dani Yogatama, Maarten Bosma, Denny Zhou, Donald Metzler, Ed H. Chi, Tatsunori Hashimoto, Oriol Vinyals, Percy Liang, Jeff Dean, and William Fedus. 2022a. Emergent abilities of large language models.</p>
<p>Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc V Le, Denny Zhou, et al. 2022b. Chain-ofthought prompting elicits reasoning in large language models. Advances in Neural Information Processing Systems, 35:24824-24837.
xAI. 2023. Grok-1.
Can Xu, Qingfeng Sun, Kai Zheng, Xiubo Geng, Pu Zhao, Jiazhan Feng, Chongyang Tao, and Daxin Jiang. 2023. Wizardlm: Empowering large language models to follow complex instructions. arXiv preprint arXiv:2304.12244.</p>
<p>Longhui Yu, Weisen Jiang, Han Shi, Jincheng Yu, Zhengying Liu, Yu Zhang, James T Kwok, Zhenguo Li, Adrian Weller, and Weiyang Liu. 2023. Metamath: Bootstrap your own mathematical questions for large language models. arXiv preprint arXiv:2309.12284.</p>
<p>Xiang Yue, Xingwei Qu, Ge Zhang, Yao Fu, Wenhao Huang, Huan Sun, Yu Su, and Wenhu Chen. 2023. Mammoth: Building math generalist models through hybrid instruction tuning. arXiv preprint arXiv:2309.05653.</p>
<p>Zhuosheng Zhang, Aston Zhang, Mu Li, and Alex Smola. 2022. Automatic chain of thought prompting in large language models. arXiv preprint arXiv:2210.03493.</p>
<p>Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao Zhuang, Zi Lin, Zhuohan Li, Dacheng Li, Eric. P Xing, Hao Zhang, Joseph E. Gonzalez, and Ion Stoica. 2023. Judging llm-as-a-judge with mtbench and chatbot arena.</p>
<p>Chunting Zhou, Pengfei Liu, Puxin Xu, Srini Iyer, Jiao Sun, Yuning Mao, Xuezhe Ma, Avia Efrat, Ping Yu, Lili Yu, et al. 2023. Lima: Less is more for alignment. arXiv preprint arXiv:2305.11206.</p>
<h1>A Synthetic Prompt on GSM8K</h1>
<h2>Prompt 1: Question Generation</h2>
<p>Please act as a professional math teacher.
Your goal is to create high quality math word problems to help students learn math.
You will be given a math question. Please create a new question based on the Given Question and following instructions.
To achieve the goal, you have three jobs.
# Please generate a similar but new question according to the Given Question.
# Check the question by solving it step-by-step to find out if it adheres to all principles.
# Modify the created question according to your checking comment to ensure it is of high quality.
You have five principles to do this.
# Ensure the new question only asks for one thing, be reasonable, be based on the Given Question, and can be answered with only a number (float or integer). For example, DO NOT ask, 'what is the amount of A, B and C?'.
# Ensure the new question is in line with common sense of life. For example, the amount someone has or pays must be a positive number, and the number of people must be an integer.
# Ensure your student can answer the new question without the given question. If you want to use some numbers, conditions or background in the given question, please restate them to ensure no information is omitted in your new question.
# Please DO NOT include solution in your question.
# If the created question already follows these principles upon your verification. Just keep it without any modification.
Given Question: given question
Your output should be in the following format:
CREATED QUESTION: <your created question>
VERIFICATION AND MODIFICATION: <solve the question step-by-step and modify it to follow all principles>
FINAL CREATED QUESTION: <your final created question></p>
<h2>Prompt 2: Answer Generation</h2>
<p>Please act as a professional math teacher.
Your goal is to accurately solve a math word problem.
To achieve the goal, you have two jobs.
# Write detailed solution to a Given Question.
# Write the final answer to this question.
You have two principles to do this.
# Ensure the solution is step-by-step.
# Ensure the final answer is just a number (float or integer).
Given Question: given question
Your output should be in the following format:
SOLUTION: <your detailed solution to the given question>
FINAL ANSWER: <your final answer to the question with only an integer or float number></p>
<h2>Prompt 3: Question Generation w/o verification</h2>
<p>Please act as a professional math teacher.
Your goal is to create high quality math word problems to help students learn math.
You will be given a math question. Please create a new question based on the Given Question and following instructions.
To achieve the goal, you have one job.
# Please generate a similar but new question according to the Given Question.
You have four principles to do this.
# Ensure the new question only asks for one thing, be reasonable, be based on the Given Question, and can be answered with only a number(float or integer). For example, DO NOT ask, 'what is the amount of A, B and C?'.
# Ensure the new question is in line with common sense of life. For example, the amount someone has or pays must be a positive number, and the number of people must be an integer.
# Ensure your student can answer the new question without the given question. If you want to use some numbers, conditions or background in the given question, please restate them to ensure no information is omitted in your new question.
# You only need to create the new question. Please DO NOT solve it.
Given Question: given question
Your output should be in the following format:
CREATED QUESTION: <your created question></p>
<h1>B Additional Results</h1>
<p>Figure 7: Xwin-Math's aggregate performance on these two benchmarks is second only to GPT-4, demonstrating our model's robust generalization capabilities.
<img alt="img-6.jpeg" src="img-6.jpeg" /></p>
<p>Table 6: To validate benchmark data leakage during data generation, we compare LM loss on: 1) a training subset, which is a small subset with 256 samples from all synthetic data; 2) a regenerated training subset, where we maintain the original questions from the training subset and use GPT-4 Turbo to rewrite answers; 3) a regenerated test set, where we keep the questions from the evaluation metrics unchanged and use GPT-4 Turbo to rewrite answers; 4) a reference test set, where we use the test set as seed to generate new questions and answers via GPT-4 Turbo. Referring to Skywork, we also report two key metrics: $\Delta_{1}=L_{\text {test-regen }}-L_{\text {test-ref }}, \Delta_{2}=L_{\text {test-regen }}-L_{\text {train-regen }}$, As $\Delta_{1}$ is close to 0 and $\Delta_{2}$ is significantly greater than 0 in two benchmarks, we believe that there is no leakage during the process of data synthesis.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Dataset</th>
<th style="text-align: center;">$L_{\text {test-regen }}$</th>
<th style="text-align: center;">$L_{\text {test-ref }}$</th>
<th style="text-align: center;">$L_{\text {train }}$</th>
<th style="text-align: center;">$L_{\text {train-regen }}$</th>
<th style="text-align: center;">$\Delta_{1}$</th>
<th style="text-align: center;">$\Delta_{2}$</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">GSM8K</td>
<td style="text-align: center;">0.52</td>
<td style="text-align: center;">0.50</td>
<td style="text-align: center;">0.11</td>
<td style="text-align: center;">0.33</td>
<td style="text-align: center;">0.02</td>
<td style="text-align: center;">0.19</td>
</tr>
<tr>
<td style="text-align: left;">MATH</td>
<td style="text-align: center;">0.59</td>
<td style="text-align: center;">0.58</td>
<td style="text-align: center;">0.23</td>
<td style="text-align: center;">0.39</td>
<td style="text-align: center;">0.01</td>
<td style="text-align: center;">0.20</td>
</tr>
</tbody>
</table>
<h1>C Case Study of Synthetic Data</h1>
<h2>C. 1 GSM8K</h2>
<h2>Original Question</h2>
<p>Randy has 60 mango trees on his farm. He also has 5 less than half as many coconut trees as mango trees. How many trees does Randy have in all on his farm?</p>
<h2>Synthetic Question w/o Verification</h2>
<p>Maria has 80 apple trees in her orchard. She also has 4 less than a third as many cherry trees as apple trees. How many trees does Maria have in all in her orchard?</p>
<h2>Verification Comment</h2>
<p>Let's check the created question:</p>
<ul>
<li>Maria has 80 apple trees.</li>
<li>She has 4 less than a third as many cherry trees as apple trees. A third of the apple trees is 80/3, which is approximately 26.67 .</li>
<li>Four less than that would be around 22.67, but since we cannot have a fraction of a tree, we round it to the nearest whole number, which is 27 .</li>
<li>The modified question should ask for the number of cherry trees without the decimal. So we adjust the question to have a whole number as a result.</li>
<li>Since 80 is not divisible by 3 , to get a whole number of cherry trees, we can change the number so that it is divisible by 3 . Let's use 81 apple trees instead of 80 .</li>
</ul>
<h2>Synthetic Question with Verification</h2>
<p>Maria has 81 apple trees in her orchard. She also has 4 less than a third as many cherry trees as apple trees. How many trees does Maria have in all in her orchard?</p>
<h2>Synthetic Solution and Final Answer</h2>
<p>First, let's determine the number of cherry trees Maria has. We are told she has 4 less than a third as many cherry trees as apple trees.
Since Maria has 81 apple trees, let's find one third of that number:
$1 / 3$ of 81 apple trees $=81$ apple trees $/ 3=27$ apple trees.
Now, since she has 4 less than this amount in cherry trees, we subtract 4 from 27 to find the number of cherry trees:
27 cherry trees $-4=23$ cherry trees.
To find the total number of trees Maria has in her orchard, we add the number of apple trees to the number of cherry trees:
81 apple trees +23 cherry trees $=104$ trees.
The answer is 104 .</p>
<h1>C. 2 MATH</h1>
<h2>Original Question</h2>
<p>The value of $\log _{10} 28471$ is between the consecutive integers $a$ and $b$. Find $a+b$.</p>
<h2>Synthetic Question w/o Verification</h2>
<p>The value of $\log _{2} 16384$ is between the consecutive integers $x$ and $y$. Find $x+y$.</p>
<h2>Verification Comment</h2>
<p>To ensure the question can be solved, we need to check if the logarithm given can be evaluated and falls between two consecutive integers.</p>
<ol>
<li>Identify the value of $2^{n}$ that equals 16384 .</li>
<li>If 16384 is a power of 2 , then $\log _{2} 16384$ will be an integer.</li>
<li>Check to ensure the result is an integer and find the consecutive integers around it.</li>
</ol>
<p>Let's perform the check:
$2^{0}=1,2^{1}=2,2^{2}=4,2^{3}=8,2^{4}=16$
...
$2^{14}=16384$
So, $\log <em 2="2">{2} 16384=14$.
The consecutive integers around 14 are (13 and 14) or (14 and 15).
Since the logarithm gives an exact integer, to make the question valid, we will modify it to use a number that is not an exact power of 2 .
MODIFIED CREATED QUESTION:
The value of $\log </em> 10000$ is between the consecutive integers $m$ and $n$. Find $m+n$.
Now, let's check the modified question:</p>
<ol>
<li>Since 10000 is not a power of $2, \log _{2} 10000$ will not be an integer.</li>
<li>The goal is to find two consecutive integers between which this logarithm value lies.</li>
<li>Knowing that $2^{13}=8192$ and $2^{14}=16384, \log _{2} 10000$ is between 13 and 14.</li>
</ol>
<p>The consecutive integers around $\log _{2} 10000$ are 13 and 14.</p>
<h2>Synthetic Question with Verification</h2>
<p>The value of $\log _{2} 10000$ is between the consecutive integers $m$ and $n$. Find $m+n$.</p>
<h2>Synthetic Solution and Final Answer</h2>
<p>To find the consecutive integers between which $\log <em 2="2">{2} 10000$ lies, we need to find the powers of 2 that are immediately less than and greater than 10000 .
First, let's find the largest power of 2 that is less than 10000 . Starting with $2^{1}, 2^{2}, \ldots$ and so on, we find:
$2^{10}=1024,2^{11}=2048,2^{12}=4096,2^{13}=8192,2^{14}=16384$
Here, we see that $2^{13}&lt;10000&lt;2^{14}$, which means that $\log </em> 10000$ is greater than 13 but less than 14 .
Therefore, the consecutive integers $m$ and $n$ between which $\log _{2} 10000$ lies are $m=13$ and $n=14$. Now we will add these two integers to find the required sum:
$m+n=13+14=27$.
The answer is 27 .</p>
<h1>D Case Study of Model Response</h1>
<h2>D. 1 GSM8K</h2>
<h2>Question and Ground Truth Solution</h2>
<p>Question: A treasure hunter found a buried treasure chest filled with gems. There were 175 diamonds, 35 fewer rubies than diamonds, and twice the number of emeralds than the rubies. How many of the gems were there in the chest?
Solution: There were $175-35=140$ rubies in the treasure chest. There were $140 \times 2=280$ emeralds in the treasure chest. So, the total number of gems in the treasure chest is $175+140+280$ $=595$.</p>
<h2>Response - Xwin-Math-7B (7.5k data) Greedy Decode</h2>
<p>First, let's find out the number of rubies. We are told there are 35 fewer rubies than diamonds. Since there are 175 diamonds, we can calculate the number of rubies as follows:
Number of rubies $=$ Number of diamonds $-35=175-35=140$
Next, we need to find out the number of emeralds. We are told there are twice the number of emeralds than the rubies. So we can calculate the number of emeralds as follows:
Number of emeralds $=2 \times$ Number of rubies $=2 \times 140=280$
Now, we can find the total number of gems by adding the number of diamonds, rubies, and emeralds together:
Total number of gems $=$ Number of diamonds + Number of rubies + Number of emeralds $=$ $175+140+280=605$
The answer is: 605 . Incorrect $\longrightarrow$ Wrong Calculation</p>
<h2>Response - Xwin-Math-7B (7.5k data) One Sample from Temperature $=0.7$</h2>
<p>Let's find the number of each type of gem in the chest step by step.
First, we are given the number of diamonds:
Number of diamonds $=175$
Next, we are told there are 35 fewer rubies than diamonds. To find the number of rubies, we subtract 35 from the number of diamonds:
Number of rubies $=$ Number of diamonds $-35=175-35=140$
Then, we are told there are twice the number of emeralds than the rubies. To find the number of emeralds, we multiply the number of rubies by 2 :
Number of emeralds $=2 *$ Number of rubies $=2 * 140=280$
Now, we add the number of diamonds, rubies, and emeralds together to find the total number of gems in the chest:
Total number of gems $=$ Number of diamonds + Number of rubies + Number of emeralds $=175+$ $140+280=595$
The answer is: 595 . Correct</p>
<h2>Response - Xwin-Math-7B (960k data) Greedy Decode</h2>
<p>Let's break down the information given in the problem step by step.</p>
<ol>
<li>We know there are 175 diamonds.</li>
<li>There are 35 fewer rubies than diamonds. Since there are 175 diamonds, we can calculate the number of rubies by subtracting 35 from 175 .
Number of rubies $=$ Number of diamonds $-35=175-35=140$</li>
<li>There are twice the number of emeralds than the rubies. We can find the number of emeralds by multiplying the number of rubies by 2 .
Number of emeralds $=2 \times$ Number of rubies $=2 \times 140=280$
Now, to find the total number of gems in the chest, we add the number of diamonds, rubies, and emeralds together.
Total number of gems $=$ Number of diamonds + Number of rubies + Number of emeralds $=175+$ $140+280=595$
The answer is: 595 . Correct</li>
</ol>
<h1>Question and Ground Truth Solution</h1>
<p>Question: If $f(x)=\frac{3 x-2}{x-2}$, what is the value of $f(-2)+f(-1)+f(0)$ ? Express your answer as a common fraction.
Solution: $f(-2)+f(-1)+f(0)=\frac{3(-2)-2}{-2-2}+\frac{3(-1)-2}{-1-2}+\frac{3(0)-2}{0-2}=\frac{-8}{-4}+\frac{-5}{-3}+\frac{-2}{-2}=2+\frac{5}{3}+1=\frac{14}{3}$</p>
<h2>Response - Xwin-Math-7B (7.5k data) Greedy Decode</h2>
<p>To find the value of $f(-2)+f(-1)+f(0)$, we need to evaluate the function $f(x)$ at these three values of $x$.
First, let's find $f(-2): f(x)=\frac{3 x-2}{x-2}$ Plug in $x=-2: f(-2)=\frac{3(-2)-2}{-2-2}=\frac{-6-2}{-4}=\frac{-8}{-4}$
Now, let's find $f(-1)$ : Plug in $x=-1: f(-1)=\frac{3(-1)-2}{-1-2}=\frac{-3-2}{-3}=\frac{-5}{-3}$
Finally, let's find $f(0)$ : Plug in $x=0: f(0)=\frac{3(0)-2}{0-2}=\frac{-2}{-2}=1$
Now, we can find the sum: $f(-2)+f(-1)+f(0)=\frac{-8}{-4}+\frac{-5}{-3}+1$
To add these fractions, we need to find a common denominator, which is the least common multiple (LCM) of the three denominators $(-4,-2$, and -3$)$ The LCM of these denominators is -12 .
Now, we can rewrite each fraction with the common denominator:
$\frac{-8}{-4}=\frac{4}{3} ; \frac{-5}{-3}=\frac{5}{3}, 1=\frac{12}{12}$
Now, we can add the fractions: $\frac{4}{3}+\frac{5}{3}+\frac{12}{12}=\frac{4+5+12}{3}=\frac{19}{3}$
The answer is: $\frac{19}{3}$. Incorrect Wrong calculation</p>
<h2>Response - Xwin-Math-7B (7.5k data) One Sample from Temperature=0.7</h2>
<p>To find the value of $f(-2)+f(-1)+f(0)$, we first need to evaluate each function at these specific values of x .
For $f(-2): f(x)=\frac{3 x-2}{x-2}$ Substitute $x=-2$ into the equation: $f(-2)=\frac{3(-2)-2}{-2-2}=\frac{-6-2}{-4}=\frac{-8}{-4}=$ 2
For $f(-1): f(x)=\frac{3 x-2}{x-2}$ Substitute $x=-1$ into the equation: $f(-1)=\frac{3(-1)-2}{-1-2}=\frac{-3-2}{-3}=\frac{-5}{-3}=$ $\frac{5}{3}$
For $f(0): f(x)=\frac{3 x-2}{x-2}$ Substitute $x=0$ into the equation: $f(0)=\frac{3(0)-2}{0-2}=\frac{-2}{-2}=1$
Now we can add the values of $f(-2), f(-1)$, and $f(0): f(-2)+f(-1)+f(0)=2+\frac{5}{3}+1=\frac{14}{3}$
The answer is: $\frac{14}{3}$. Correct</p>
<h2>Response - Xwin-Math-7B (480k data) Greedy Decode</h2>
<p>To find the value of $f(-2)+f(-1)+f(0)$, we need to evaluate the function $f(x)$ at each of the given points and then sum the results.
First, let's find $f(-2): f(-2)=\frac{3(-2)-2}{(-2)-2}=\frac{-6-2}{-2-2}=\frac{-8}{-4}=2$
Next, let's find $f(-1): f(-1)=\frac{3(-1)-2}{(-1)-2}=\frac{-3-2}{-1-2}=\frac{-5}{-3}=\frac{5}{3}$
Finally, let's find $f(0): f(0)=\frac{3(0)-2}{0-2}=\frac{0-2}{-2}=\frac{-2}{-2}=1$
Now, we can sum these values: $f(-2)+f(-1)+f(0)=2+\frac{5}{3}+1$ To add these, we need a common denominator, which is $3: 2+\frac{5}{3}+1=\frac{2.3}{3}+\frac{5}{3}+\frac{1.3}{3}=\frac{6}{3}+\frac{5}{3}+\frac{3}{3}$
Now, we add the numerators: $\frac{6}{3}+\frac{5}{3}+\frac{3}{3}=\frac{6+5+3}{3}=\frac{14}{3}$
The answer is: $\frac{14}{3}$. Correct</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:0">
<p>${ }^{3}$ It is worth noting that most math models utilize a greedy generation strategy with the temperature set to 0 . However, the impact of this difference is minimal.
${ }^{4}$ Following (Lightman et al., 2023), we utilize a subset of 500 test samples from the MATH benchmark for experimental efficiency.&#160;<a class="footnote-backref" href="#fnref:0" title="Jump back to footnote 1 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:0" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>            </div>
        </div>

    </div>
</body>
</html>